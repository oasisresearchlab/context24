QuickSkill : Novice Skill Estimation in Online Multiplayer Games Chaoyun Zhang ∗ Tencent Shenzhen , China hidan . zhang @ gmail . com Kai Wang ∗ Tencent Shenzhen , China wangjinjie722 @ gmail . com Hao Chen Tencent Shenzhen , China fitzhchen @ tencent . com Ge Fan Tencent Shenzhen , China gefan @ tencent . com Yingjie Li Tencent Shenzhen , China wallaceyjli @ tencent . com Lifang Wu Tencent Shenzhen , China danniewu @ tencent . com Bingchao Zheng Tencent Shenzhen , China novazheng @ tencent . com ABSTRACT Matchmaking systems are vital for creating fair matches in online multiplayer games , which directly affects players’ satisfactions and game experience . Most of the matchmaking systems largely rely on precise estimation of players’ game skills to construct equitable games . However , the skill rating of a novice is usually inaccurate , as current matchmaking rating algorithms require considerable amount of games for learning the true skill of a new player . Using these unreliable skill scores at early stages for matchmaking usually leads to disparities in terms of team performance , which causes negative game experience . This is known as the “cold - start” problem for matchmaking rating algorithms . To overcome this conundrum , this paper proposes QuickSkill , a deep learning based novice skill estimation framework to quickly probe abilities of new players in online multiplayer games . Quick - Skill extracts sequential performance features from initial few games of a player to predict his / her future skill rating with a dedi - cated neural network , thus delivering accurate skill estimation at the player’s early game stage . By employing QuickSkill for match - making , game fairness can be dramatically improved in the initial cold - start period . We conduct experiments in a popular mobile mul - tiplayer game in both offline and online scenarios . Results obtained with two real - world anonymized gaming datasets demonstrate that proposed QuickSkill delivers precise estimation of game skills for novices , leading to significantly lower team skill disparities and better player game experience . To the best of our knowledge , pro - posed QuickSkill is the first framework that tackles the cold - start problem for traditional skill rating algorithms . CCS CONCEPTS • Appliedcomputing → Computergames ; • Computingmethod - ologies → Neural networks . ∗ Both authors contributed equally to this work . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , topostonserversortoredistributetolists , requirespriorspecificpermission and / or a fee . Request permissions from permissions @ acm . org . CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA © 2022 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 978 - 1 - 4503 - 9236 - 5 / 22 / 10 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3511808 . 3557070 KEYWORDS Game Skill Estimation , Online Multiplayer Game , Game Matchmak - ing , Deep Learning ACM Reference Format : Chaoyun Zhang , Kai Wang , Hao Chen , Ge Fan , Yingjie Li , Lifang Wu , and Bingchao Zheng . 2022 . QuickSkill : Novice Skill Estimation in Online Multiplayer Games . In Proceedings of the 31st ACM International Conference on Information and Knowledge Management ( CIKM ’22 ) , October 17 – 21 , 2022 , Atlanta , GA , USA . ACM , New York , NY , USA , 11 pages . https : / / doi . org / 10 . 1145 / 3511808 . 3557070 1 INTRODUCTION Game matchmaking systems aim at searching comparable team - mates and opponents for players to form a fair match , such that all teams in a game have similar abilities . They are massively employed in online multiplayer games [ 1 – 3 ] , such as League of Legends . A good matchmaking system avoids disparities as far as possible , since weak teams and players will sense tremendous frustration if they are overwhelmed in a game [ 2 ] . The quality of matchmaking therefore directly affects players’ satisfaction and retention [ 4 ] , and the life cycle of the game [ 5 ] . A matchmaking service makes a decision depending on many criteria , whereas the principal factor is the players’ skills scores ( a . k . a matchmaking rates ) . The matchmaking rate ( MMR ) quantifies players’ game abilities by aggregating their historical competition outcomes or / and performance features into a scalar [ 6 ] , which is used to compare and rank players’ strength at the same game event [ 7 ] . The most classical and popular MMR algorithms employed in online games is the TrueSkill - family [ 8 ] . These methods update a player’s MMR after each match given the outcome of the game [ 8 ] . In general , the accuracy of the MMR grows with the number of games used for learning . However , industrial applications of TrueSkill suggest that it bears significant shortcomings when assessing skills of novices , especially for online multiplayer games . A new player joins the game with enormous skill uncertainty and limited information , while their game strengths diversify . New players are not always poor players – they may have experience of other similar games . This makes ratings in initial games unreliable , until it observes outcomes of sufficient matches . In addition , TrueSkill suffers from unstabitily at the early stage and slow convergence , known as the “cold - start” problem [ 9 ] [ 10 ] [ 11 ] . This dramatically affects the accuracy of the a r X i v : 2208 . 07704v1 [ c s . L G ] 15 A ug 2022 CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Zhang , et al . , 0 10 20 30 40 50 Num . of Games 400 600 800 1000 1200 1400 MM R Cold - start Period Player1 Player2 Figure 1 : An example of TrueSkill MMRs evolution of two players generated in an online multiplayer game . skill rating , which indirectly leads to overwhelming games † and negative game experience . Fig . 1 shows an example of TrueSkill MMRs evolution of two players who have different strengths in an online multiplayer game . Observe that although their MMRs disperse after 40 games , two curves interweave in the cold - start pe - riod . This indicates that the two players with huge ability difference may be matched in a game , which causes significant unfairness . Estimating the game skill for a new player is not straightforward . First , the strength of a player is summarized via various game performance features . As TrueSkill - based algorithms build upon Bayesian graphical models , working with a large features space will lead to a huge probabilistic graph model . This makes the inference problem mathematically intractable . Therefore , these models are usually oversimplified , which fail to reflect the player’s ability in diverse perspectives [ 12 ] . In addition , a player’s skill is less relevant to the side information of the player , such as registration data . Skills in dissimilar games also bring little of help for inferring the player’s skill in the targeted domain , as these games may have completely different contexts . As such , legacy methods that tackle the user cold - start for recommender systems ( e . g . , [ 13 – 15 ] ) , are not applicable to the skill estimation . This further complicates the cold - start problem in game skill rating context , making it a “Achilles’ Heel” for traditional models . Though traditional MMR algorithms are unreliable in the initial games , their accuracy grows with the number of matches for learn - ing , and converges after certain games . We observe that converged MMRs estimated by TrueSkill - based models after the cold - start period can better reflect the real game abilities of players at their novice phases ( see Sec . 4 . 4 ) . This makes future converged MMRs appropriate labels , which can be learned and correlated with the players’ performance in early games using machine learning . Contributions . To exploit the future converged MMRs and rem - edy the cold - start issue , this paper introduces QuickSkill , a fast and accurate deep learning based skill estimation framework tailored to new players for online multiplayer games . Unlike TrueSkill and its variants , which only take binary outcomes of the match or limited performance features for learning , QuickSkill extracts comprehen - sive sequential in - game features from each combat match , to profile the multi - dimension game ability of a player . We design a dedicated deep learning model MMR - Net , which accepts feature snapshots collected at different time slices in a game as inputs , and predicts † Referring to the games where the level of one team is much higher than another one . the “future” MMR provided by the TrueSkill family of the player . These look - ahead MMRs are more accurate than their counterparts in the cold - start period . By substituting original skill ratings with predicted MMRs , proposed QuickSkill delivers more precise skill estimation , which significantly improves the fairness of matchmak - ing . This buffers the infancy stage of TrueSkill , allowing them to improve during the initial learning period . We evaluate our proposed framework on anonymized bench - mark datasets collected in two different game modes in a well - known online mobile Multiplayer Online Battle Arena ( MOBA ) game , for both offline and online scenarios . Experiments show that compared to TrueSkill and its variants , our QuickSkill achieves more accurate estimation of players’ skills for novices in the cold - start period . By employing the proposed framework for match - making , over 20 % overwhelming games at novice stages can be eliminated , leading to significantly better game fairness and player game experience . Importantly , proposed QuickSkill can be effi - ciently deployed as an online machine learning service with limited computing resources requirement . To the best of our knowledge , proposed QuickSkill is the first framework that tackles the cold - start problem for traditional MMR models . 2 RELATED WORK In this section , we review related research and industry practice on game matchmaking and player skill rating . 2 . 1 Player Skill Rating Most game matchmaking systems build upon accurate player skill rating , which profiles the overall strength of an individual player with a matchmaking rate ( MMR ) . Classical MMR algorithms are based on Bayesian probabilistic graphical models . In this case , the MMR of each new player is initialized with a unified score , and is gradually updated after each game . Popular MMR algorithms include ELO [ 16 ] , ELO - MMR [ 6 ] , TrueSkill [ 8 ] , Glicko [ 17 ] , and their variants or extensions ( e . g . , [ 18 ] [ 19 ] ) . The well - known ELO system [ 16 ] has been widely employed to estimate players’ abilities in two - player games , e . g . , GO and chess . The TrueSkill [ 8 ] model extends Bayesian rating systems to a multiplayer manner , which plays an important role in matchmaking for many different games . These algorithms however , only update with binary win - loss outcomes of matches , while ignoring the performance of players and are biased in many cases . TrueSkill2 [ 18 ] utilizes fine - grained features for the skill estimation , by leveraging players’ performance and correlating around - game features . This delivers more accurate estimation and enables faster convergence . As aforementioned rating systems require considerable amount of games for learning , the skill estimation for novices are generally inaccurate [ 9 ] [ 10 ] [ 11 ] . Research toward estimating beginners’ skills in online games remains largely unexplored . 2 . 2 Matchmaking in Online Multiplayer Games With players’ MMRs provided , the matchmaking system [ 20 ] forms a fair game by finding comparable players for each competition with similar total team MMRs . A sophisticated matchmaking system not only considers the MMR scalar of each player in the matchmaking QuickSkill : Novice Skill Estimation in Online Multiplayer Games CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA pool , but also the player profiles and team cooperative effects inher - ent to multiplayer matches ( e . g . , [ 5 , 21 ] ) . This usually leads to more equatable games . For instance , Delalleau et al . , employ a neural net - work to predict player enjoyment to achieve better matchmaking [ 22 ] . Similarly , research in [ 5 ] completes the matchmaking process at two stages : it first uses a model to predict the outcome of the game , then finds the optimal matchmaking by heuristics sorting . Deng et al . , [ 12 ] use reinforcement learning to resolve matchmaking for multiplayer games from the global player pool . This achieves better game equality compared to traditional two - stage approaches . In general , MMRs remains the core of most matchmaking sys - tems [ 20 ] , affecting directly game experience and retention of play - ers [ 23 ] . This is particularly important for novices , who have limited number of games to probe their game abilities . 3 QUICKSKILL : A DEDICATED NOVICE SKILL ESTIMATION FRAMEWORK In this section , we first give a brief background and formalize the problem of novice skill estimation . Next , we introduce the over - all architecture of the QuickSkill framework . Finally , we present MMR - Nets , the core deep learning predictor of the system , and explain how to learn the game skill of a player with complex , se - quential in - game features in a popular mobile MOBA game . 3 . 1 Background and Problem Formulation Multiplayer Online Battle Arena ( MOBA ) Game . MOBA ( e . g . , Defense of the Ancients , Mobile Legends ) is one of the most popular game families in both personal computer ( PC ) and mobile game markets . It is considered as a mix of real - time strategy , role - playing and action games . In the classical MOBA game setting [ 24 ] , 5 players controlling different game characters are matched as a team to play against another one . Players gain coins and become stronger by seizing game resources and slaying their enemies . All players in a team work collaboratively to destroy the opponent’s base as an ultimate goal . In a MOBA game , skill balance between teams has substantial impact on the game experience for players . MMRandGameMatchmaking . Thematchmakingrate ( MMR ) is a score that represents the game skill of a player . Higher MMR means the player are stronger and will generally perform better in the game . Normally , the score is updated after the each match given the outcome of the game , as well as the player’s game performance . We formally denote the MMR of the player 𝑝 at the game 𝑖 as 𝑠 𝑝 , 𝑖 . This score will be used for matchmaking at the game 𝑖 + 1 . Normally , the MOBA matchmaking system searches two teams comprising multiple players with similar skill levels to construct a combat match . The overall matchmaking rules are complicated , while there are two common criteria should be followed . Namely : ( 1 ) The players’ skills in the same team should be close , i . e . , | 𝑠 𝛼𝑝 , 𝑖 − 𝑠 𝛼𝑝 ′ , 𝑖 ′ | ≤ 𝜏 , ∀ 𝑝 , 𝑝 ′ , and | 𝑠 𝛽𝑝 , 𝑖 − 𝑠 𝛽𝑝 ′ , 𝑖 ′ | ≤ 𝜏 , ∀ 𝑝 , 𝑝 ′ . Here 𝛼 and 𝛽 are the team indices , 𝑝 , 𝑝 ′ are players in two teams and 𝜏 denotes the player’s skill gap threshold . ( 2 ) The summation of skills of all players in a team should be close to another , i . e . , | (cid:205) 𝑝 𝑠 𝛼𝑝 , 𝑖 − (cid:205) 𝑝 ′ 𝑠 𝛽𝑝 ′ , 𝑖 ′ | ≤ 𝜑 , where 𝜑 is the team’s skill gap threshold . Normally , teams with higher Game 1 Game 2 Game N Game K 𝑠 ! , # Prediction Prediction … Games in the cold - start period Figure 2 : An illustration of the objective of QuickSkill . skills are supposed to win with higher probabilities , provided that MMRs are accurate . Matchmaking algorithms used in this paper follow these two basic rules , to guarantee the fairness of a game as much as possible . Key Observation . Classical MMR algorithms , i . e . , TrueSkill [ 8 ] and its upgraded variant TrueSkill2 [ 18 ] suffer from the cold - start problem . Their MMRs calculated are relatively inaccurate and unsta - ble before 𝐶 games . The 𝐶 is the number of games in the cold - start period and may vary from different MMR algorithms . In this paper , we set 𝐶 = 18 for TrueSkill and TrueSkill2 based on our observation on online deployment , as both models converge after 18 games . Notably , with the number of games increasing , their MMRs be - come more precise and stable . We observe that these future MMRs naturally become a satisfying indicators that can better reflect the actual game strength of a player at the novice stage . If we foresee players’ future MMRs and use them for matchmaking in the cold - start period , the fairness of the game can be substantially improved . Therefore , we design QuickSkill to “gaze into the future” , by pre - dicting players’ future MMR scores given their game performance at novice stages . The inferred MMRs replace the original TrueSkill rating and are employed for matchmaking at their novices stages . We illustrate the principle of QuickSkill in Fig . 2 . Problem Formulation . Predicting the future MMR of a player requires his / her performance feature snapshots at different time in novice games . Denoting the targeted MMR label in the look - ahead game 𝐾 for player 𝑝 as 𝑠 𝑝 , 𝐾 , and the game performance features at time slice 𝑡 of the game 𝑖 as 𝑋 𝑡𝑝 , 𝑖 , we formulate the problem as : ˆ 𝑠 𝑝 , 𝑖 = argmax 𝑠 𝑝 , 𝐾 p ( 𝑠 𝑝 , 𝐾 | 𝑋 1 𝑝 , 𝑖 , · · · , 𝑋 𝑇𝑝 , 𝑖 ) . ( 1 ) Here , p is the probability distribution , ˆ 𝑠 𝑝 , 𝑖 is the predicted future MMR of at the game 𝑖 for player 𝑝 , and will be used for matchmaking before game 𝐶 . Note that game 𝐾 is the future game used for the MMR ground truth , while game 𝑖 is the current match . We conduct detailed analysis and experiments of the choice of different future 𝐾 in Sec . 4 . 4 . The base MMR algorithms employed for the label 𝑠 𝑝 , 𝐾 are flexible , where we select TrueSkill and TrueSkill2 in this study . 3 . 2 QuickSkill in a Nutshell QuickSkill is a novel deep learning framework that specifically designed for novice game skill rating . It includes two important components , namely ( i ) offline training ; and ( ii ) online serving . Offline Training . In the offline training process , QuickSkill collects large amount of game performance data of players at their novice stages , and labels each sample with the players’ future MMR 𝑠 𝑝 , 𝐾 . In the case of MOBA games , players’ performance is profiled by their statistics at different stages of a game [ 24 ] . To fully capture CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Zhang , et al . , Figure 3 : An illustration of the online serving process . the player’s performance , we collect game feature snapshots every 3 minutes to construct comprehensive profiles of a player . Next , we train a dedicated transformer - based MMR - Nets with the aforemen - tioned features by minimizing the mean squared error between the predicted ˆ 𝑠 𝑝 , 𝑖 and the ground truth 𝑠 𝑝 , 𝐾 . Online Serving . At the stage of online serving , QuickSkill pre - dicts a MMR ˆ 𝑠 𝑝 , 𝑖 after each game 𝑖 in the cold - start period , given the sequential performance features of the players . The ˆ 𝑠 𝑝 , 𝑖 substitutes the raw TrueSkill MMR and is employed for the matchmaking phase in the following games 𝑖 + 1 . We show the online serving process in Fig . 3 . QuickSkill buffers the infancy stage of TrueSkill based MMRs models , improving the skill rating at their early learning stages . Once the algorithm that computes the MMR gains suffi - cient games for learning and moves out of the cold - start period , the matchmaking system switches to the original algorithm for the game matchmaking . This means that QuickSkill retires for the corresponding player after game 𝐶 . 3 . 3 Feature Design for Skill Learning Recall that the objective of a team in a MOBA game play is to destroy their opponent’s base . This is however , a complicated process and cannot be accomplished at one stroke . Strength of one player is quite limited , hence players in a team need to work collaboratively to achieve the ultimate goal [ 25 ] . These factors make the entire MOBA game play complex . The skill level of a MOBA player is profiled from different di - mensions [ 12 ] . In this paper , we collect their statistics in a game from various perspectives to fully capture the player’s performance and skill . These include ( i ) personal statistics ; ( ii ) teammate statis - tics ; and ( iii ) opponent statistics . Personal statistics includes the player’s own game - related features , e . g . , kills , death , gold . These features reflect the player’s own performance in a specific game . In addition , performance of teammates and opponents are important references for comparisons between the targeted player and other participants in the same game . We therefore add the teammate and opponent statistics ( e . g . , average team / opponent kills , average team / opponent gold ) to the feature set , to distinguish the target with other players . Note that all features collected in this study do not embrace personal information of players , therefore the data collected does not raise privacy concerns . In addition , A MOBA game can be naturally partitioned into various game phases by different time in a game , where each game phase reflects the players’ performance in different dimensions [ 12 ] . For example , at the early phase of the game , player’s statistics Snapshot 𝑋 " + Line - up Embedding Game Features Embedding + … 𝐻 ! ! 𝐻 " ! 𝐻 # ! … 𝐻 ! " 𝐻 " " 𝐻 # " … 𝐻 ! $ % ! 𝐻 " $ % ! 𝐻 # $ % ! … 𝐻 ! ! 𝐻 " ! 𝐻 # ! … 𝐻 ! " 𝐻 " " 𝐻 # " … 𝐻 ! $ % ! 𝐻 " $ % ! 𝐻 # $ % ! Omnidirectional Attention Predicted MMR 𝑠̂ # , % Aggregation Layers … Position Embedding Snapshot 𝑋 & Snapshot 𝑋 ’ Figure 4 : The overall architecture of the proposed MMR - Nets . represents his skill at the laning stage , while the importance of team battles grows with the game time . The result of final team battle , usually has decisive effects on the game outcome . In order to comprehensively capture the player’s game strength , performance at different phases in a game should be leveraged and weighted for model learning . To this end , we sample the aforementioned statistics features snapshot every 3 minutes in a game , to deliver their performance evolution to the MMR - Nets for skill learning , which is detailed next . 3 . 4 Learning Game Skills With MMR - Nets Deep learning has been widely employed to model complex correla - tions for multivariate time series in different areas ( e . g . , [ 26 – 30 ] ) . To leverage the heterogeneous sequential game features and achieve accurate skill learning , we design a transformer - based MMR - Net , to extract important information from different feature channels . We show the overall structure of the MMR - Net in Fig . 4 . The pro - posed MMR - Net includes three important components , namely ( i ) embedding layers ; ( ii ) OmniNet layers ; and ( iii ) aggregation lay - ers . The model is fed with a sequence of feature snapshots i . e . , { 𝑋 1 , · · · , 𝑋 𝑇 } , where each slice includes 115 features , profiling the player’s performance from multiple perspectives . Performance Snapshots Embedding . The discretized inputs are first processed by an embedding layer , which comprises three components , namely line - up embedding , game features embedding and position embedding . The line - up of a MOBA game refers to the character list controlled by each team . Since different characters have synergy or suppression effect on each other [ 5 ] , the line - up makes significant impact to the player’s performance and the out - come of the game [ 5 ] . We therefore isolate the line - up information from other features , and encode them with a dedicated embedding QuickSkill : Novice Skill Estimation in Online Multiplayer Games CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA layer . Game features embedding encodes other sparse performance features of the player in a game into a dense space . The model also includes a regular position embedding , to facilitate the sequential information processing by the transformer structure . Finally , line - up and game features embedding are concatenated and added with the position embedding , which constructs the full embedding for different feature snapshots . Sequential Learning with OmniNets . Embedded features are subsequently processed by an OmniNet , which stands for Omnidi - rectional Representations from Transformers [ 31 ] . Vanilla transformers build upon multi - head self - attention blocks , which enables to learn contributions of different time slices dynami - cally . They are widely employed for sequential learning in different applications [ 32 – 34 ] . In order to take advantage of this property , we employ the transformer structure as a base to learn the corre - lation and importance between skills and player’s performance of different phases in a game automatically . Compared to traditional Transformers [ 35 ] , the OmniNet intro - duces an additional omnidirectional attention as a meta learner , which connects hidden representations across all layers in the model and weights their importance automatically . The operation of the omnidirectional attention is formulated as : 𝑂 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 = Attention ( 𝐻 11 , 𝐻 21 , · · · , 𝐻 𝐿 − 1 𝑁 ) , ( 2 ) where 𝑂 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 is the output of the omnidirectional attention , and 𝐻 𝑙𝑇 denotes the hidden layer of the model in layer 𝑙 at time state 𝑇 . As the omnidirectional attention operates over all hidden layers of the transformer , the 𝑂 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 returns a tensor with ( 𝐿 − 1 ) × 𝑇 × 𝑑 dimensions . 𝑂 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 is added with the output of the final layer of the transformer , after dimension reduced by a Multiplayer Perception ( MLP ) , i . e . , OmniNet ( 𝑋 ) = Transformer ( 𝑋 ) 𝐿 − 1 + 𝑀𝐿𝑃 ( 𝑂 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 ) , ( 3 ) where Transformer ( 𝑋 ) 𝐿 − 1 is the output of the transformer . The global attention in the OmniNet enables to access the knowledge of the entire network , which helps capture patterns across differ - ent features interweaving over different time in a game . This is particularly suitable for the skill learning , as the performance fea - tures are inter - correlated across different game phases . Reinforcing such correlations improves the model representability and helps the OmniNet better capture the complex link between performance and game skill . Moreover , the global attention can be regarded as a form of residual learning [ 36 ] , which is beneficial for the gradient propagation and can be learnt in an end - to - end manner . Features Aggregation & Prediction . Finally , outputs from the OmniNet are passed to a dense aggregation layer , to combine the high - level features embedding and make the skill prediction ˆ 𝑠 𝑝 , 𝑖 . The aggregation layer gathers outputs from all time states , to maxi - mize the sequential information utility . This enables to summarize the player’s performance from a global picture of a game . The entire model is trained by minimising a standard 𝐿 2 loss between inferred skills and ground truth future MMR , i . e . , 𝐿 ( Θ ) = 1 N ∑︁ N ( 𝑠 𝑝 , 𝐾 − ˆ 𝑠 𝑝 , 𝑖 ) 2 , ( 4 ) where Θ denote the trainable parameters of the MMR - Net , and N is the number of samples used for training . Online Deployment . Our MMR - Nets are efficient in both of - fline and online processes . Training the MMR - Net with million - scale data on average requires around 6 hours in a single machine with 8 NVIDIA V100 GPUs . Once trained , the model only needs to be updated every few weeks to meet the online data drift . In the online serving , we deploy 10 containers ( 4 cores , 2G memory ) for feature pre - processing and 15 containers ( 4 cores , 2G memory ) for TF - serving . The average response time of QuickSkill is around 20 ms . This is sufficient to meet the requirement of the mobile MOBA game , as updated MMRs are only required in the matchmaking for the next game , which happens after a few seconds from the current game at the soonest . 4 EXPERIMENTS To evaluate the performance of QuickSkill , we employ datasets collected in a well - known mobile MOBA game for two different game modes . We provide comprehensive comparisons with differ - ent baseline deep learning models , as well as two state - of - the - art MMR algorithms from multiple perspectives . All models are imple - mented using TensorFlow [ 37 ] . We train all architectures with a computing cluster with 8 NVIDIA V100 GPUs . 4 . 1 Datasets As current publicly available dataset does not contain sufficient game features required in this study , we collect new heterogeneous datasets in a well - known mobile MOBA game ‡ for two different game modes , i . e . , normal and ranking . We show summary statistics of the datasets in Table 1 . Both datasets are collected in 20 days , where data collected in the first 13 days are employed for training and validation , and the rest are for testing . This generates two large datasets with up to 80 million samples , which are sufficient for the model training and evaluation . Table 1 : Statistics of the online MOBA dataset . Mode Training Validation Testing Normal 34M 4M 14M Ranking 44M 8M 28M We note that both normal and ranking game modes share the same game context and objectives , while players usually treat two modes with different seriousness . In the normal game mode , players tend to be more casual and sometimes choose unskilled characters for practice and entertainment . On the contrary , players take the ranking mode more seriously , as it provides more explicit grade to the players to exhibit their game level . For each data , we collect 115 features for each snapshot , where snapshots are sampled every 3 minutes in a game . Each data sample only retains the last 12 feature snapshots , to shear overlength games . Therefore , the dimension of the input fed to the model becomes 115 × 12 . MMRs estimated by TrueSkill and TrueSkill2 after the cold - start periods will be also collected as true labels for the skill learning . As a final remark on data collection , we stress that all data col - lections were carried out in compliance with applicable regulations . ‡ Due to the non - disclosure agreement , the name of the game employed for the case study cannot be disclosed . CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Zhang , et al . , In addition , the dataset we employ for our study does not contain personal information about individual players . This implies that the dataset is fully anonymized and desensitized , thus its use for our purposes does not raise privacy concerns . 4 . 2 Benchmarks and Performance Metrics We implement several baseline models for comparison , and design dedicated metrics to comprehensively quantify the performance of proposed QuickSkill . Benchmarks . We compare the performance of our proposed QuickSkill with two classical MMR algorithms , namely Trueskill [ 8 ] and Trueskill2 [ 18 ] . In particular , ( 1 ) Trueskill isaprobabilisticMMRmodelthatupdatesaplayer’s rating depending only on the game outcome ( win / lose ) . It is one of the most popular MMR algorithms and widely em - ployed in online multiplayer games . ( 2 ) Trueskill2 evolves from its ancestor by introducing extra features into the model , such as player experience and skill in other game modes . It usually converges faster with higher accuracy compared to Trueskill . We train proposed QuickSkill with labels obtained from both TrueSkill and TrueSkill2 for comparisons . Deep learning models employed in QuickSkill are flexible . We compare the proposed MMR - Net with different machine learn - ing models , namely Linear Regression ( LR ) , Multilayer Perceptron ( MLP ) , Gated Recurrent Unit ( GRU ) and Transformer . MLP is the most simple neural network architecture that has been widely em - ployed from different purposes [ 38 ] . GRU [ 39 ] is a popular model for time series modelling . We use this architecture to model the sequential game performance features of players . Transformer [ 35 ] is a simplified version of MMR - Net , as it removes the global atten - tion in the model . MLP , GRU and Transformer are equipped with similar embedding layers . In addition , we train a simplified version of the MMR - Net with features only collected in the last time slice ( MMR - Net 𝑒𝑛𝑑 ) for an ablation study . We show in Table 2 the detailed configuration along with the number of parameters for each model considered in this study . We employ standard configuration for LR , MLP and GRU . Transformer and MMR - Net share similar configurations to ensure fair compari - son . The MMR - Net 𝑒𝑛𝑑 only input the last feature snapshot , while the rest of setting is the same as the MMR - Net . Overall , the number of parameters is close for GRU , Transformer and MMR - Net , while the MLP has the most number of parameters . Performance Metrics . The accuracy of a MMR algorithm can be only quantified by indirect indicators , as it is difficult to measure a player’s game skill with an explicit value . To this end , we de - sign different performance metrics to evaluate the performance of proposed QuickSkill from three different perspectives , namely ( i ) model precision ; ( ii ) game outcome correlation ; and ( iii ) effects of players’ game experience . We employ different metrics to evaluate the performance of our framework , as detailed next . Since skill estimation is modelled as a regression problem , we select the classical Mean Absolute Error ( MAE ) and Mean Square Error ( MSE ) to assess the precision of the model . MAE and MSE are computed to evaluate the difference between the predicted MMRs ˆ 𝑠 𝑝 , 𝑖 and the ground truth 𝑠 𝑝 , 𝐾 . Table 2 : Configuration of all models considered in this paper . Model Configuration Parameters LR A standard LR model with one - hot features . 1381 MLP Three hidden layers , with ( 128 , 256 , 256 ) hidden units for each layers . 3 , 659 , 501 GRU Two hidden layers with ( 128 , 258 ) hidden units for each layers . 1 , 926 , 765 Transformer 6 hidden layers , model dim = 160 , heads = 10 , with sequence length = 12 . 1 , 968 , 301 MMR - Net 6 hidden layers , model dim = 160 , heads = 10 , with sequence length = 12 . 2 , 071 , 347 MMR - Net 𝑒𝑛𝑑 6 hidden layers , model dim = 160 , heads = 10 , with sequence length = 1 . 1 , 763 , 907 Normally , teams with higher total MMRs are supposed to win a match with a higher probability , if estimated MMRs for individual player are accurate . The correlations between winning probabil - ities and team MMR difference therefore become a good indirect indicator that reflectS the precision of estimated MMRs [ 12 , 18 ] . We formally define the win rate as : Win rate = N 𝑊𝑖𝑛𝑠 N . ( 5 ) Here N 𝑊𝑖𝑛𝑠 denotes the number of games where a given team is the winner , and N is the total number of games used for the evaluation . Recall that matchmaking systems serve to improve the players’ game experience . Lastly , we evaluate if players’ game experience can be improved by substituting traditional MMR algorithms with QuickSkill . This is the most vital metric of matchmaking . In this study , we use the difference between a player’s kill and death for this purpose , i . e . , | 𝐾𝐷 | = | K − D | , where K and D are the number of kills and deaths of the character controlled by the player . In a MOBA game , a player always try to kill the opponents and avoid death . Therefore , large values of | 𝐾𝐷 | mean a player is matched with incompatible teammates or opponents , which may lead to negative experience for the player or / and other participants [ 2 ] . 4 . 3 Offline Results on Novice Skill Estimation We first train the proposed MMR - Nets and other baselines with MMRs computed by TrueSkill and TrueSkill2 at game 18 , i . e . , 𝐾 = 18 , which are the MMRs obtained at the end of the cold - start period ( 𝐶 = 18 ) . We also investigate how QuickSkill behaves when training with different MMR labels , i . e . , TrueSkill and TrueSkill2 , as well as the influence of training with sequential features . We report the mean and standard deviation of MAE and MSE , and the win rates of the teams with higher predicted MMRs of a game ( denoted as win - rate ℎ ) on both datasets in Table 3 . The precision of the MMRs model has positive correlations with the win - rate ℎ metric used in QuickSkill : Novice Skill Estimation in Online Multiplayer Games CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Table 3 : The mean±std of MAE , MSE as well as win - rate ℎ of the team with high predicted MMRs ( the higher the better ) across all models considered , evaluated on mobile MOBA datasets collected in normal and ranking game modes with 𝐾 = 18 . Model Normal Ranking TrueSkill TrueSkill2 TrueSkill TrueSkill2 MAE MSE win - rate ℎ MAE MSE win - rate ℎ MAE MSE win - rate ℎ MAE MSE win - rate ℎ LR 0 . 61 ± 0 . 20 0 . 40 ± 0 . 11 51 . 3 % 1 . 42 ± 0 . 61 2 . 08 ± 1 . 02 50 . 4 % 1 . 41 ± 0 . 66 2 . 00 ± 1 . 03 51 . 2 % 1 . 48 ± 0 . 70 2 . 22 ± 1 . 32 52 . 8 % MLP 0 . 56 ± 0 . 18 0 . 33 ± 0 . 09 54 . 2 % 1 . 09 ± 0 . 31 1 . 20 ± 0 . 45 60 . 8 % 0 . 72 ± 0 . 32 0 . 55 ± 0 . 21 54 . 1 % 1 . 40 ± 0 . 56 2 . 01 ± 1 . 15 60 . 4 % GRU 0 . 54 ± 0 . 19 0 . 30 ± 0 . 09 54 . 6 % 1 . 07 ± 0 . 32 1 . 17 ± 0 . 41 61 . 1 % 0 . 69 ± 0 . 26 0 . 51 ± 0 . 18 54 . 3 % 1 . 37 ± 0 . 52 1 . 90 ± 1 . 09 61 . 0 % Transformer 0 . 51 ± 0 . 18 0 . 28 ± 0 . 08 55 . 2 % 1 . 06 ± 0 . 31 1 . 07 ± 0 . 40 61 . 3 % 0 . 69 ± 0 . 24 0 . 50 ± 0 . 18 54 . 4 % 1 . 34 ± 0 . 50 1 . 86 ± 1 . 08 61 . 1 % MMR - Net 0 . 49 ± 0 . 18 0 . 25 ± 0 . 08 55 . 4 % 1 . 02 ± 0 . 30 1 . 04 ± 0 . 36 61 . 6 % 0 . 66 ± 0 . 23 0 . 47 ± 0 . 17 54 . 7 % 1 . 30 ± 0 . 50 1 . 75 ± 1 . 06 61 . 5 % MMR - Net 𝑒𝑛𝑑 0 . 59 ± 0 . 21 0 . 37 ± 0 . 11 53 . 5 % 1 . 18 ± 0 . 39 1 . 42 ± 0 . 51 59 . 8 % 0 . 70 ± 0 . 24 0 . 53 ± 0 . 20 54 . 0 % 1 . 40 ± 0 . 53 1 . 96 ± 1 . 12 60 . 2 % MMR 𝑜𝑟𝑖 0 . 66 ± 0 . 27 0 . 46 ± 0 . 14 51 . 4 % 1 . 23 ± 0 . 44 1 . 56 ± 0 . 66 54 . 0 % 1 . 41 ± 0 . 67 2 . 02 ± 0 . 99 51 . 0 % 1 . 41 ± 0 . 55 1 . 98 ± 1 . 12 53 . 6 % the table . MMR - Net 𝑒𝑛𝑑 s are only trained with end - game feature snapshots , and MMR 𝑜𝑟𝑖 denotes original MMR values estimated by TrueSkill / TrueSkill2 in each game . Observe that the proposed MMR - Nets in general obtain superior performance over other benchmark models for both datasets , as they achieve lower MAE / MSE and higher win - rate ℎ . This suggests that the omnidirectional attentions improve the representability of the model , which enables better encoding of the heterogeneous game features . In addition , sequential models , including MMR - Net , Transformer and GRU , achieve better performance over the MLP and LR . In comparison with the MMR - Net 𝑒𝑛𝑑 , which only employs the last feature snapshot for training , the MMR - Net performs signif - icantly better . This indicates that the skill of a player can be profiled more precisely by evaluating his performance at different phases of the game , demonstrating the superiority of the feature design described in section 3 . 3 . Taking a closer look at Table 3 , it appears that the original MMR 𝑜𝑟𝑖 estimated after each game achieves the worst performance , which indicates that TrueSkill and TrueSkill2 in the cold - start pe - riod are inaccurate and unreliable . As a comparison , our MMR - Nets obtain up to 4 % and 7 . 9 % higher win - rate ℎ , yielding a remarkable improvement . In addition , MMRs estimated by TrueSkill2 are more accurate than its TrueSkill , as models trained with TrueSkill2 labels achieve significantly better performance in terms of win - rate ℎ . In conclusion , by combining the MMR - Nets with TrueSkill2 labels , proposed QuickSkill obtains the best results across all metrics on both datasets , by achieving up to 21 . 1 % lower MAE and 11 . 2 % higher win - rate ℎ than other baselines . Furthermore , incorporat - ing sequential features at different phases in a game significantly improves the performance of QuickSkill . Correlation of Team Win Rate and MMR Difference . Next , we investigate the correlation between game outcomes and team MMR differences . As the team MMR is the summation of all players’ MMRs in the team , the more accurate the MMR model is , teams with higher total MMRs should win with higher probabilities . This means that win rates should have a stronger positive correlation with the team MMR difference . We compute the win rate of the team as a function of the team MMR difference of three MMR models considered for the normal game mode , as shown in Fig . 5 . Observe that team win rates grow with the MMR team difference for all MMR models , as expected . Compared to other baselines , proposed QuickSkill exhibits the strongest positive correlation between the MMR difference and win rates , which suggests that QuickSkill is more accurate than its counterparts . Figure 5 : Team win rates w . r . t . team MMR difference of three MMR models evaluated in the normal mode dataset . The bars in the figures represent the number of games in each bucket . Team skill difference generally grows with the team MMR differ - ence 𝜑 . A large 𝜑 means that the MMR model believes the match - making is unfair , and should be avoided . We denote games with team MMR difference 𝜑 > 40 ( suggested by the game designer ) as “unfair” games identified by the MMR models ( the leftest and right - est bars in the figure ) . Interestingly , TrueSkill senses the most num - ber of unfair games , whereas these games are not truly unfair . This is reflected by the fact that both underdog ( lower MMR ) and favorite ( higher MMR ) teams identified by TrueSkill only achieve almost 50 % win rates . TrueSkill2 only senses 0 . 85 % unfair games , while these games have more extreme win rates . Notably , the proportion of unfair games identified by proposed QuickSkill is 20 . 87 % , and the win rates of these games are the most extreme . This means those games identified by QuickSkill were indeed unfair games . By setting the team MMR gap threshold 𝜑 = 40 , games with 𝜑 > 40 will be eliminated , if using our QuickSkill for matchmaking . This reduces significant amount of overwhelming games . 4 . 4 Learning with Different “Future” Selecting an appropriate 𝐾 as targets is not straightforward , as MMR labels 𝑠 𝑝 , 𝐾 with a small 𝐾 are inaccurate and unstable , while configuring a large 𝐾 may cause the labels to over deviate from the players’ skills in early games , as players make progress and gain experience in every game . In order to find proper MMRs for learning targets , we tune label 𝑠 𝑝 , 𝐾 with different 𝐾 , to evaluate the effect of learning with different “future” . We show the win - rate ℎ results of predictions of QuickSkill and corresponding ground truths for both TrueSkill and TrueSkill2 in two datasets in Table 4 . Observe that 𝐾 = 18 in general achieves the highest win - rate ℎ for both QuickSkill and ground truths for most of the cases . The win - rate ℎ grows with the 𝐾 when 𝐾 ≤ 𝐶 , but become stable af - terward . This suggests that simply setting 𝐾 = 𝐶 delivers a good CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Zhang , et al . , Table 4 : Comparisons of win - rate ℎ of the team with high predicted / ground truth MMRs between different 𝐾 configurations . 𝐾 Normal Ranking TrueSkill TrueSkill2 TrueSkill TrueSkill2 QuickSkill Ground truth QuickSkill Ground truth QuickSkill Ground truth QuickSkill Ground truth 12 54 . 1 % 58 . 1 % 60 . 2 % 71 . 9 % 53 . 9 % 57 . 5 % 60 . 2 % 72 . 3 % 15 54 . 5 % 59 . 3 % 60 . 8 % 72 . 8 % 53 . 7 % 58 . 2 % 60 . 8 % 73 . 8 % 18 55 . 4 % 59 . 6 % 61 . 6 % 72 . 3 % 54 . 0 % 58 . 5 % 61 . 5 % 74 . 0 % 21 55 . 3 % 59 . 4 % 61 . 3 % 70 . 6 % 53 . 9 % 58 . 2 % 61 . 7 % 72 . 6 % Figure 6 : Ratios of players with | 𝐾𝐷 | ≥ 8 in a game w . r . t . team MMR difference comparison in the normal mode dataset . Line charts refer to the ratio of players with | 𝐾𝐷 | ≥ 8 in each bucket and bar charts represent the number of players . performance for the objective of novice skills estimation , and can be employed as a standard configuration . On the other hand , TrueSkill2 always achieves better results over TrueSkill , for both QuickSkill prediction and ground truth . This reconfirms that TrueSkill2 pro - vides more accurate and reliable MMR labels for learning . 4 . 5 Online Effect on Players’ Game Experience In a real online game , a player’s game experience is dramatically affected by the player’s | 𝐾𝐷 | = | K − D | . Large values of | 𝐾𝐷 | sug - gest that the player overwhelms or is overwhelmed by opponents , leading to negative game experience . MMR algorithms used for matchmaking affect the skills of players , which naturally influ - ence the | 𝐾𝐷 | of participants . To evaluate the relation between different MMR algorithms employed and players’ game experience , we calculate the ratio of players with | 𝐾𝐷 | ≥ 8 as a function of team MMR difference in normal games , as shown in Fig . 6 . These games with extreme | 𝐾𝐷 | > 8 result in frustration for new players based on our surveys , and are one of the key reasons for churn [ 40 ] . We select QuickSkill trained with TrueSkill2 for a case study . Similarly , we denote games with team difference 𝜑 > 40 as “un - fair” games sensed by MMR models . Observe that players with extreme | 𝐾𝐷 | were quite evenly distributed across difference in - tervals calculated by MMR TrueSkill2 ( green bars ) , while they are concentrated in QuickSkill’s intervals at the two poles ( blue bars ) . Specifically , in unfair games identified by QuickSkill , the propor - tion of players with | 𝐾𝐷 | ≥ 8 is 3 . 73 % , while the same metric is 0 . 08 % for TrueSkill2 . This suggests that by setting the team MMR gap threshold 𝜑 = 40 , using QuickSkill for matchmaking can effectively reduce extreme player experience , which significantly improves their satisfaction . Tuning attention to Fig . 7 , where we show the ratio of players with | 𝐾𝐷 | ≥ 8 as a function of the team MMR difference ranking Figure 7 : Ratios of players with | 𝐾𝐷 | ≥ 8 in a game w . r . t . team MMR difference comparison in the ranking mode dataset . Line charts refer to the ratio of players with | 𝐾𝐷 | ≥ 8 in each bucket and bar charts represent the quantity of players . games . Compared to TrueSkill , the performance of our QuickSkill is also remarkable . In the unfair games identified by QuickSkill , the proportion of players with | 𝐾𝐷 | ≥ 8 is 2 . 01 % , while the same metric is 0 . 09 % for TrueSkill . These evaluations prove the effectiveness of QuickSkill in a different game mode , which further demonstrates the robustness of the proposed system . 4 . 6 Win Rate Comparison in Cold - start Periods We now delve deeper into the performance of QuickSkill at differ - ent stages of the cold - start period . To this end , in Fig . 8 we show the correlation between team win rate and MMR difference , where each subplot in the figure collects all games with different average num - bers of matches that participants have played . This corresponds to different stages of the cold - start period . Recall that the team win rate should be positively related to the team MMR difference , if MMRs calculated for each player are accurate . Observe that our QuickSkill performs significantly better than other baselines when average game numbers are small ( i . e . , average game number < 15 ) , while its advantage fades when its counter - parts gain more games for learning . This is reflected by the slope of each curve – QuickSkill exhibits much stronger correlations between team win rate and MMR difference at early games than other baselines . Their performance becomes fairly close when av - erage numbers of games is between [ 15 , 18 ) . Interestingly , 18 is exactly the number of games of the cold - start period . After game 18 , the system switches to TrueSkill2 for matchmaking . As when exceeding the cold - start period , QuickSkill shows no advantages over TrueSkill2 , while it has already fulfilled its goal for beginners . 4 . 7 Attention Visualization We conclude our experiments by examining the exact sequential importance learned by the proposed MMR - Net . To this end , we visualize as a heatmap the averaged weights of the omnidirectional QuickSkill : Novice Skill Estimation in Online Multiplayer Games CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Figure 8 : Win rate comparison with respect to team MMR difference of three MMR models across different average numbers of games evaluated in the normal mode dataset . Bars in the figures represent the number of games in each difference interval . LaningPhase Teamfight Game ends Figure 9 : Heatmap visualization of the omnidirectional at - tention module . Weights are averaged over layers . attention module of a sample in Fig . 9 . Lighter color represents greater attention weight values . Observe that the MMR - Net com - mits less attention at the early stage of the game corresponding to the laning phase . The importance grows with time , reaching a peak at the final team battle , which becomes a showdown of the game . The player’s performance at these stages highly affects the judgment of the model . The significance drops rapidly with the end of the game , as the outcome becomes a foregone conclusion . This shows that the MMR - Nets indeed capture keys that affect the skill of a player in a MOBA game , which highly meets our expectations . 5 CONCLUSIONS This paper proposes QuickSkill , an original deep learning based novice skill estimation framework to improve the player skill rating in the cold - start period for traditional MMR algorithms . QuickSkill collects multiple feature snapshots in a game to comprehensively profile the performance of players , and predicts their future MMRs , which are generally more accurate and reliable . To model the cor - relations between players’ game abilities and their in - game perfor - mance , we design a dedicated model MMR - Net , which evolves the classical Transformer with an omnidirectional attention operator . This augments the representability of the model and enables more accurate MMR predictions . We evaluate the proposed framework on anonymized datasets collected in two different game modes of a popular mobile MOBA game . Offline experiment results sug - gest that QuickSkill achieves superior performance over TrueSkill , TrueSkill2 and other baseline models in terms of accuracy . Im - portantly , our online evaluations show that using QuickSkill for matchmaking leads to significantly better game fairness by reduc - ing overwhelming games and players’ extreme game experience . To the best of our knowledge , our QuickSkill is the first deep learning CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA Zhang , et al . , based framework that tackles the cold - start problem of skill rating in online multiplayer games . REFERENCES [ 1 ] MarkClaypool , JonathanDecelle , GabrielHall , andLindsayO’Donnell . Surrender at 20 ? matchmaking in league of legends . In 2015 IEEE GEM , pages 1 – 4 , 2015 . [ 2 ] Maxime Véron , Olivier Marin , and Sébastien Monnet . Matchmaking in multi - playeron - linegames : studyingusertracestoimprovetheuserexperience . In Proc . of Network and Operating System Support on Digital Audio and Video Workshop , pages 7 – 12 , 2014 . [ 3 ] Muhammad Farrel Pramono , Kevin Renalda , and Harco Leslie Hendric Spits Warnars . MatchmakingproblemsinMOBAgames . IndonesianJournalofElectrical Engineering and Computer Science , 11 ( 3 ) : 908 – 917 , 2018 . [ 4 ] Mingliu Chen , Adam N Elmachtoub , and Xiao Lei . Matchmaking strategies for maximizing player engagement in video games . SSRN 3928966 , 2021 . [ 5 ] Linxia Gong , Xiaochuan Feng , Dezhi Ye , Hao Li , Runze Wu , Jianrong Tao , Changjie Fan , and Peng Cui . Optmatch : Optimized matchmaking via modeling the high - order interactions on the arena . In Proc . of the International Conference on Knowledge Discovery & Data Mining , pages 2300 – 2310 , 2020 . [ 6 ] Aram Ebtekar and Paul Liu . Elo - MMR : A rating system for massive multiplayer competitions . In Proc . of the Web Conference , pages 1772 – 1784 , 2021 . [ 7 ] Thore Graepel and Ralf Herbrich . Ranking and matchmaking . Game Developer Magazine , 25 : 34 , 2006 . [ 8 ] Ralf Herbrich , Tom Minka , and Thore Graepel . Trueskill : A bayesian skill rat - ing system . In Proc . of the 19th international conference on neural information processing systems , pages 569 – 576 , 2006 . [ 9 ] Jung Yeon Park , Seang - Hwane Joo , Frederik Cornillie , Han LJ van der Maas , and Wim Van den Noortgate . An explanatory item response theory method for alleviating the cold - start problem in adaptive learning environments . Behavior research methods , 51 ( 2 ) : 895 – 909 , 2019 . [ 10 ] Maciej Pankiewicz . A warm - up for adaptive online learning environments – the elo rating approach for assessing the cold start problem . In 28th International Conference on Computers in Education , pages 324 – 329 , 2020 . [ 11 ] Anurag Sarkar and Seth Cooper . An online system for player - vs - level match - making in human computation games . In IEEE Conference on Games ( CoG ) , pages 1 – 4 . IEEE , 2021 . [ 12 ] Qilin Deng , Hao Li , Kai Wang , Zhipeng Hu , Runze Wu , Linxia Gong , Jianrong Tao , Changjie Fan , and Peng Cui . Globally optimized matchmaking in online games . In Proc . of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining , pages 2753 – 2763 , 2021 . [ 13 ] Jizhe Wang , Pipei Huang , Huan Zhao , Zhibo Zhang , Binqiang Zhao , and Dik Lun Lee . Billion - scale commodity embedding for e - commerce recommendation in alibaba . In Proc . of the 24th ACM SIGKDD Conference on Knowledge Discovery & Data Mining , pages 839 – 848 , 2018 . [ 14 ] Ruobing Xie , Zhijie Qiu , Jun Rao , Yi Liu , Bo Zhang , and Leyu Lin . Internal and contextual attention network for cold - start multi - channel matching in recom - mendation . In IJCAI , pages 2732 – 2738 , 2020 . [ 15 ] Ge Fan , Chaoyun Zhang , Junyang Chen , Baopu Li , Zenglin Xu , Yingjie Li , Luyu Peng , and Zhiguo Gong . Field - aware variational autoencoders for billion - scale userrepresentationlearning . In 38thInternationalConferenceonDataEngineering ( ICDE ) , pages 3413 – 3425 . IEEE , 2022 . [ 16 ] Ralph Allan Bradley and Milton E Terry . Rank analysis of incomplete block designs : I . the method of paired comparisons . Biometrika , 39 ( 3 / 4 ) : 324 – 345 , 1952 . [ 17 ] Mark E Glickman . The Glicko system . Boston University , 16 : 16 – 17 , 1995 . [ 18 ] TomMinka , RyanCleven , andYordanZaykov . Trueskill2 : Animprovedbayesian skill rating system . Tech . Rep . , 2018 . [ 19 ] Mark E Glickman . Example of the Glicko - 2 system . Boston University , pages 1 – 6 , 2012 . [ 20 ] Justin Manweiler , Sharad Agarwal , Ming Zhang , Romit Roy Choudhury , and Paramvir Bahl . Switchboard : a matchmaking system for multiplayer mobile games . In Proc . of the international conference on Mobile systems , applications , and services , 2011 . [ 21 ] Anna Sapienza , Palash Goyal , and Emilio Ferrara . Deep neural networks for optimal team composition . Frontiers in big Data , 2 : 14 , 2019 . [ 22 ] Olivier Delalleau , Emile Contal , Eric Thibodeau - Laufer , Raul Chandias Ferrari , Yoshua Bengio , and Frank Zhang . Beyond skill rating : Advanced matchmaking in ghost recon online . IEEE Transactions on Computational Intelligence and AI in Games , 4 ( 3 ) : 167 – 177 , 2012 . [ 23 ] Jing Li and Dong - Min Cho . A study on game satisfaction and game balance of MOBA game in new season update . Journal of Korea Multimedia Society , 24 ( 8 ) : 1161 – 1170 , 2021 . [ 24 ] Marçal Mora - Cantallops and Miguel - Ángel Sicilia . MOBA games : A literature review . Entertainment computing , pages 128 – 138 , 2018 . [ 25 ] Young Ji Kim , David Engel , Anita Williams Woolley , Jeffrey Yu - Ting Lin , Naomi McArthur , and Thomas W Malone . What makes a strong team ? using collective intelligence to predict team performance in league of legends . In Proc . of the ACM conference on computer supported cooperative work and social computing , pages 2316 – 2329 , 2017 . [ 26 ] Chaoyun Zhang , Marco Fiore , Iain Murray , and Paul Patras . CloudLSTM : A recurrent neural model for spatiotemporal point - cloud stream forecasting . In QuickSkill : Novice Skill Estimation in Online Multiplayer Games CIKM ’22 , October 17 – 21 , 2022 , Atlanta , GA , USA AAAI , 2020 . [ 27 ] Chaoyun Zhang , Paul Patras , and Hamed Haddadi . Deep learning in mobile and wireless networking : A survey . IEEE Communications surveys & tutorials , 21 ( 3 ) : 2224 – 2287 , 2019 . [ 28 ] Chaoyun Zhang , Marco Fiore , Cezary Ziemlicki , and Paul Patras . Microscope : mobile service traffic decomposition for network slicing as a service . In Proc . of the 26th ACM MobiCom , pages 1 – 14 , 2020 . [ 29 ] Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . BERT : Pre - training of deep bidirectional transformers for language understanding . In NAACL - HLT , 2019 . [ 30 ] Chaoyun Zhang , Mingjun Zhong , Zongzuo Wang , Nigel Goddard , and Charles Sutton . Sequence - to - point learning with neural networks for nonintrusive load monitoring . In AAAI , 2018 . [ 31 ] Yi Tay , Mostafa Dehghani , Vamsi Aribandi , Jai Gupta , Philip M Pham , Zhen Qin , Dara Bahri , Da - Cheng Juan , and Donald Metzler . Omninet : Omnidirectional rep - resentations from transformers . In International Conference on Machine Learning , pages 10193 – 10202 . PMLR , 2021 . [ 32 ] Shiyang Li , Xiaoyong Jin , Yao Xuan , Xiyou Zhou , Wenhu Chen , Yu - Xiang Wang , and Xifeng Yan . Enhancing the locality and breaking the memory bottleneck of transformerontimeseriesforecasting . AdvancesinNeuralInformationProcessing Systems , 32 , 2019 . [ 33 ] George Zerveas , Srideepika Jayaraman , Dhaval Patel , Anuradha Bhamidipaty , and Carsten Eickhoff . A transformer - based framework for multivariate time series representation learning . In Proc . of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining , pages 2114 – 2124 , 2021 . [ 34 ] Haoyi Zhou , Shanghang Zhang , Jieqi Peng , Shuai Zhang , Jianxin Li , Hui Xiong , and Wancai Zhang . Informer : Beyond efficient transformer for long sequence time - series forecasting . In AAAI , 2021 . [ 35 ] Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . Attention is all you need . In Advances in neural information processing systems , pages 5998 – 6008 , 2017 . [ 36 ] Gao Huang , Zhuang Liu , Laurens Van Der Maaten , and Kilian Q Weinberger . Densely connected convolutional networks . In Proc . of the IEEE CVPR , pages 4700 – 4708 , 2017 . [ 37 ] Martín Abadi et al . TensorFlow : A system for large - scale machine learning . In OSDI , volume 16 , 2016 . [ 38 ] Alireza Khotanzad and J - H Lu . Classification of invariant image representations using a neural network . IEEE Transactions on Acoustics , Speech , and Signal Processing , 38 ( 6 ) : 1028 – 1038 , 1990 . [ 39 ] Kyunghyun Cho , Bart van Merriënboer , Dzmitry Bahdanau , and Yoshua Bengio . On the properties of neural machine translation : Encoder – decoder approaches . In Proc . of the Eighth Workshop on Syntax , Semantics and Structure in Statistical Translation , pages 103 – 111 , 2014 . [ 40 ] John Winn , Christopher Bishop , and Tom Diethe . Model - Based Machine Learning . Microsoft Research , 2015 .