Yulia Tyumeneva , Alena Valdman , Martin Karnoy HOW WELL DO YOU NEED TO KNOW IT TO USE IT ? BASIC RESEARCH PROGRAM WORKING PAPERS SERIES : EDUCATION WP BRP 14 / EDU / 2014 This Working Paper is an output of a research project implemented at the National Research University Higher School of Economics ( HSE ) . Any opinions or claims contained in this Working Paper do not necessarily reflect the views of HSE . Yulia Tyumeneva 1 , Alena Valdman , Martin Karnoy HOW WELL DO YOU NEED TO KNOW IT TO USE IT ? 2 There is currently a large body of literature about applying knowledge gained in class to real - life situations . However , comparatively little is known about how a student’s mastery of the material affects his or her ability to transfer this knowledge to unfamiliar settings . Our research seeks to illuminate the relationship between a student’s subject mastery level and his or her knowledge transfer to out - of - subject contexts . We use data from TIMSS mathematics ( 8 grade ) and PISA mathematics to evaluate the link between subject mastery level – in this case , the mastery level of mathematics – and the transfer of learned math . Building off previous discussions of TIMSS and PISA test differences , we consider TIMSS performance as the mastery level of school mathematics , and PISA performance as the ability to transfer learned math to an out - of - subject context . The sample included 4 , 241 Russian students who took part in both the TIMSS 2011 and PISA 2012 cycles . In our study , we first divide the students into six groups according to their performance in the TIMSS . Then we identify the most difficult PISA test items based on the Rasch Model . Finally , we determine what percentage of the most difficult PISA items were answered correctly in every TIMSS group . This percentage served as a measure of the ability to successfully transfer knowledge . We found a positive relation between subject mastery level and the ability to transfer learned math to an out - of - subject context . The higher the mastery level of mathematics , the higher the probability that knowledge will be transferred . However , this link was not linear : only the highest mastery level contributed significantly to knowledge transfer . At other mastery levels , the rate of successful transfer differentiated only slightly . These results imply the importance of making certain that students have truly mastered curriculum before moving to new topics . Additionally , the non - linear nature of the link suggests that educators should begin rethinking how test results are interpreted . JEL classification : I21 . Key words : transfer , subject knowledge , subject mastery level , out - of - subject context , PISA , TIMSS . 1 National Research University Higher School of Economics , e - mail : jutu @ yandex . ru 2 The authors would like to thank Elena Kardanova , senior researcher of the International Laboratory for Educational Policy Research at the Graduate School of Education ( HSE ) , for her crucial help in data scaling . 3 Introduction A fundamental goal for all educators is leaving students with the ability to apply the knowledge acquired in class to solve problems beyond the classroom’s boundaries . One of the main problems with achieving this goal is understanding the link between the abstract knowledge of a subject and the concrete application of that knowledge in real - life situations . If a student can calculate the area of a square or rectangle , can he or she also calculate the amount of wallpaper needed to paper a room ? In other words , we are speaking of transferring knowledge to an out - of - subject context . Furthermore , we wonder if the basic ability to calculate the area of a square is enough to facilitate knowledge transfer , or whether the student must also be able to calculate the area of any nonstandard figure ? Here , the student’s level of subject mastery presumably has an effect on the knowledge transfer process as well . Despite a large body of literature , researchers have yet to reach a consensus on these essential questions about the mechanisms and conditions of knowledge transfer . Beginning with Edward Thorndike’s early works and continuing to the present day ( Thorndike and Woodworth , 1901 ) , specialists in the cognitive sciences , as well as in educational psychology , have debated and investigated how students apply what they learn in school . However , relatively less attention has been paid to knowledge transfer in specific subjects – namely , the transfer of knowledge from a formal discipline such as math or chemistry . Still less is known about the role of a student’s level of subject mastery in utilizing what he or she already knows . Thus far , research has primarily focused on the effects of specific educational programs on knowledge transfer . Fong , Krantz , and Nisbett ( 1986 ) observed that statistical training for students had a significant impact on their thinking about everyday problems . In another study , Lehman , Lempert , and Nisbett ( 1988 ) showed that educational programs for lawyers , psychologists , and doctors had a positive effect on their statistical and methodological reasoning abilities in out - of - subject contexts . Moreover , VanderStoep and Shaughnessy ( 1997 ) also found that student - psychologists who took a course on research methods performed better on tests for statistical and methodological reasoning in out - of - subject contexts than students who took a course on developmental psychology . Across the board , these findings demonstrate the positive effect of training in specific subjects on knowledge transfer to out - of - subject contexts . But these researchers did not explore the circumstances 4 surrounding these successful transfers ; specifically , they did not determine how well the students mastered what they were taught , and the relationship of this mastery level to the success rate of knowledge transfer . Several experimental studies performed by cognitive psychologists suggest that knowledge transfer occurs only in particular circumstances . In these works , one such circumstance is the student’s depth of understanding , or what we call the “subject mastery level” . Understanding a problem at a deep , structural level led to students transferring knowledge more effectively ( Brown et al . , 1989 ) . As Barnett and Ceci ( 2002 ) emphasized , the presence of “deep understanding” has the largest impact on a student’s ability to transfer knowledge successfully . Again , however , the nature of the relationship between the subject mastery level and knowledge transfer remains unexplored in these studies . One potential approach to shedding light on this relationship involves using results from two common international achievement tests : TIMSS and PISA . Both tests assess students of similar ages in mathematics , and the specific content being tested partly coincides ( for a detailed comparative analysis of the test frameworks see Dossey , 2006 ; Wu , 2009 ; Wu , 2010 ) . Nonetheless , the TIMSS and PISA can be viewed as different in terms of their main objectives : TIMSS math tasks address subject mastery level , while PISA math tasks are designed to assess how well students can transfer their knowledge to a wide range of out - of - subject contexts . PISA’s mathematical tasks consist of so - called “everyday mathematics” , where mathematical content is embedded in non - mathematical , “real - world” settings ( OECD , 2013 ) . In this sense , PISA operates mostly in out - of - subject contexts , such as choosing the best tariff , calculating a dose of medicine , or estimating the payment period for a new car . To solve these types of problems , the student must transfer his or her mathematical subject knowledge to an out - of - subject context . This knowledge transfer typically contains a number of steps . At first , the student must recognize and extract the essential mathematics from an out - of - subject context . After doing so , the student must provide the mathematical structure needed to restate the problem in a mathematical form . Next , the student must perform the proper computations and apply the correct mathematical concepts to the reformulated problem . Finally , the student must translate these mathematical solutions back into the 5 out - of - subject context of the original problem and then interpret the results ( OECD , 2013 ) . Unlike the PISA , the vast majority of TIMSS math items assess only knowledge of “inner” mathematics ( Wu , 2010 ) , meaning calculations , manipulations , and the use of mathematical facts to solve problems already formulated mathematically . In practice , this means that TIMSS tasks largely do not require transferring math to an out - of - subject context and back . Only one domain of the TIMSS test – the so - called “applying” domain ( Mullis et al . , 2012 ) – includes tasks that partially involve recognizing and interpreting mathematics in an out - of - subject context , but even these tasks contain consecutive hints that point out the problem’s hidden mathematical structure and thereby facilitate the transfer of knowledge . 3 Two official test examples can help further illuminate this crucial conceptual difference between the TIMSS and PISA ( see Appendix A ) . In the first task , the student must calculate the minimum number of boxes of a certain known size needed to hold a known number of eggs ( TIMSS 2011 , content domain “Numbers” , cognitive domain “Applying” ) . This is a typical word problem with a clear mathematical structure . The second task requires the student to figure out which music or picture files to add or delete from a memory stick of a given storage capacity ( PISA 2012 , content domain “Quantity” ) . This task demands that the student identify the mathematical structure hidden in the out - of - subject context , without offering any hints as to the connection between the word problem and the specific mathematical concepts needed to solve it . Although both of these tasks appeal to the same mathematical skills ( arithmetic , comparison of quantities , division with a remainder ) , the PISA task obviously demands knowledge transfer , while the TIMSS task does not . An opportunity to exploit this difference between the test frameworks arose when a group of Russian students took both the TIMSS and PISA tests in successive years . These test data presented us with a chance to begin answering questions about the nature of the relationship between subject mastery level and knowledge transfer . Does the success rate of knowledge transfer increase consistently as the subject 3 Additionally , in contrast to PISA , TIMSS math items generally do not contain distracting information . TIMSS includes only information that should be used to solve the problem , and typically does not combine different forms of information ( texts , tables , charts , or graphs ) in one item . PISA , by contrast , often includes different forms , requiring the student to connect this different information . TIMSS tasks also seem more familiar to students since the problems are formulated similarly to those seen in textbooks , enabling students to apply learned math directly . PISA tasks appear to be pieces of “real - world” ( that is , “out - of - subject” ) information that prevent test - takers from immediately applying what they know . Examples of both PISA and TIMSS tasks can be found in the Appendix . 6 mastery level increases ? Or is there a threshold or a certain depth of understanding that a student must attain in order to apply what he or she has learned ? In this paper , we conduct an analysis that integrates the TIMSS and PISA data from tests given to the same sample of students . Our focus is on illuminating the links between subject mastery level and knowledge transfer to out - of - subject contexts . We first break the students up into groups according to their TIMSS results , creating a spectrum of subject mastery levels . Then we examine how well each of those groups performed on the most difficult PISA tasks , thereby effectively measuring knowledge transfer to out - of - subject contexts . Ultimately , we find that each subject mastery level affects knowledge transfer efficiency differently , meaning that the link is non - linear . Integrating TIMSS and PISA Performance Our Data Our initial sample contained 4 , 241 Russian students from 229 schools who took part in both the TIMSS ( 2011 ) and PISA ( 2012 ) test cycles . The sample consisted 49 . 8 % of girls and 50 . 2 % of boys , with a mean age of 15 . 9 years in 2012 ( SD = 0 . 5 years ) . This sample was representative for Russian students aged 14 to 15 years in terms of both school size and school location . This particular TIMSS test included a total of 219 math tasks , representing four subject domains ( Algebra – 71 tasks , Data and Chances – 43 tasks , Numbers – 61 tasks , and Geometry – 44 tasks ) and three cognitive domains ( Knowing – 80 tasks , Applying – 87 tasks , and Reasoning – 52 tasks ) . The PISA test was comprised of 85 math tasks covering four content domains ( Shape and Space , Quantity , Uncertainty and Data , and Change and Relationships ) and three cognitive domains ( Formulate , Employ , and Interpret ) . We do not present a distribution of tasks across domains because we only had access to the overall test scores , which combined achievement in all mathematical domains . 4 Strategy and Procedures 4 Student performance in PISA is typically expressed not through test scores , but through so - called “plausible values” ( PV ) , which are generated by the test developer much later than when PISA is actually administered in a given country . During our research , we did not yet have access to PVs for the 2012 PISA cycle . Accordingly , we had to scale PISA “row scores” to reach test scores for individuals . Detailed information on this procedure can be found below . 7 The aim of the data analysis was to examine how PISA performance changes as TIMSS performance increases . To record increasing TIMSS performance , we divided the students into six groups based on their average results in overall TIMSS mathematics plausible values ( PVs ) , ranging from the lowest to the highest achievers . Each group contained 16 . 7 % of the students , with Group 1 comprised of students with the highest TIMSS PVs , and Group 6 comprised of students with the lowest PVs . We also grouped students based on their PVs in the content domains ( Algebra , Geometry , Data and Chances , and Numbers ) and cognitive domains ( Knowing , Applying , and Reasoning ) . To identify the difficulty of PISA tasks , we first employed Item Response Theory ( IRT ) , namely Rasch’s One Parametric Model . Doing so , we determined the ten and twenty tasks with the highest difficulty factor , which ranged from 1 . 25 to 3 . 96 logits . The number of “most difficult” PISA tasks was arbitrary . We were guided by the fact that the most difficult PISA items typically ask students to mathematically model relationships and changes presented in non - mathematical contexts . This suggests that the most difficult PISA tasks best represent a test of knowledge transfer to an out - of - subject context . We then used this information to calculate what percentage of the most difficult PISA tasks were solved in each TIMSS group . This value represented the ability to transfer subject knowledge to an out - of - subject context . Finally , we compared the ability of students to transfer mathematics knowledge with their mastery level of mathematics , as shown by TIMSS results . We observed how the percentage of most difficult PISA tasks solved correctly changed throughout all six TIMSS groups . We paid special attention to any jumps in these percentages , which can indicate that reaching a certain subject mastery level is necessary for facilitating knowledge transfer . To check the robustness of our results for different types of items , we selected the ten and twenty easiest PISA items , as well as several random subsets of PISA tasks , and performed the same comparison using the results for those sets of tasks . 8 Results Descriptive statistics As our combined TIMSS - PISA sample could differ from the representative original TIMSS sample , we compared the observed distribution of TIMSS math scores with normal distributions . The math TIMSS scores of Russian 8 th graders ranged from 309 . 85 to 804 . 03 . The average score for Russia is 543 . 81 , while the international average is 500 . The results showed that the observed distribution differs greatly from a normal one with a left - sided skewness ( Skewness = - 0 . 17 ; Excess = - 0 . 33 ; Kolmogorov - Smirnov test : stat . = 0 . 03 , p≤ 0 . 00 ) . However , as an additional test showed , the score distribution in the original 2011 TIMSS 8 th grade sample was similar . This clearly reflects a Russian peculiarity concerning the skills and knowledge measured in the TIMSS : there are a number of extremely low scores while the overall national achievement in TIMSS is relatively high . Percentage of difficult PISA tasks solved correctly in each TIMSS group The percentage of the most difficult PISA tasks solved correctly in each TIMSS group was determined based on the number of tasks that were presented to each TIMSS group . This percentage was calculated for groups based either on overall PV in the TIMSS ( Figure 1 ) , the subject sub - domains ( Algebra , Geometry , Data and Chances , and Numbers ) , or the cognitive skills ( Knowing , Applying , and Reasoning ) ( Tables 3 and 4 ) . As seen in Figure 1 , there is a positive relationship between TIMSS achievement and the number of most difficult PISA tasks solved correctly . The higher a student’s PV in the TIMSS , the more PISA tasks the student is able to solve . However , we should pay attention to the difference in the percentage of solved tasks between the different TIMSS groups . In the first ( “best” ) TIMSS group , 21 . 6 % of the most difficult PISA tasks were solved correctly . In the second ( “second best” ) TIMSS - group , students solved considerably fewer tasks correctly , at just 9 . 8 % . The difference between the first and the second TIMSS groups is 12 % . If we look at the differences in percentage of tasks solved correctly between other TIMSS groups ( say the second and the third , the third and the fourth , and so on ) , we see that the differences range from 1 – 2 . 5 percent . The same pattern , consisting of a small but uniform difference in the percentage of tasks solved correctly between the 9 second and all subsequent groups , compared with a sharp difference between the first and the second groups , can also be observed for the twenty most difficult PISA tasks ( Appendix B ) . Figure 1 . Percent of tasks solved correctly from the 10 ( and 20 ) most difficult PISA tasks in each TIMSS group , % . Moreover , the pattern continued when the TIMSS groups were broken down further along mathematical content domains ( Algebra , Geometry , Data and Chances , and Numbers ) . We observed an approximately 9 - 10 percent “jump” in the proportion of tasks solved correctly between the first and second groups , while the difference between the subsequent TIMSS groups remained flat ( Table 1 ) . 21 , 6 9 , 8 7 , 3 5 , 3 4 , 3 3 , 2 30 , 8 18 , 1 12 , 9 9 , 0 6 , 3 4 , 7 TIMSS group with highest math PV 2 3 4 5 TIMSS group with lowest math PV Percentage of the 10 most difficult PISA tasks solved correctly in each TIMSS group Percentage of the 20 most difficult PISA tasks solved correctly in each TIMSS group 10 Table 1 . Percentage of tasks solved correctly from the 10 hardest PISA tasks in each TIMSS group based on PVs in the content domains . Group Algebra Data and Chances Numbers Geometry ( 1 ) The highest achievers in TIMSS specific content domain 20 . 5 20 . 7 20 . 2 20 . 0 ( 2 ) 10 . 1 10 . 7 11 . 4 11 . 1 ( 3 ) 7 . 5 6 . 9 7 . 1 7 . 5 ( 4 ) 5 . 7 5 . 4 5 . 5 5 . 5 ( 5 ) 4 . 6 4 . 6 4 . 0 4 . 8 ( 6 ) The lowest achievers in TIMSS specific content domain 3 . 2 3 . 6 3 . 5 2 . 7 We again observed a similar pattern when comparing achievement across TIMSS groups split up according to cognitive domains ( Knowing , Applying , and Reasoning ) . Between the first ( “best” ) and second TIMSS groups , we see a considerable 10 - 11 percent difference in PISA performance . Moving down the chain from the second to the third TIMSS group , the success rate for solving the most difficult PISA tasks changes by only 1 - 3 percent ( Table 2 ) . The fact that the “applying” domain in TIMSS did not show a linear relation to performance in PISA is likely explained by what these domains measure . All cognitive domains in the TIMSS ( Knowing , Applying , and Reasoning ) measure one wide construct rather than different narrow constructs . 5 It seems that the construct measured by TIMSS is distinctive from the construct measured by PISA . Where TIMSS measures “subject knowing , applying and reasoning” , PISA measures the construct of “knowing , applying , and reasoning in a non - academic context . ” 5 These cognitive domains share a significantly large part of their variance , from 64 % to 80 % . 11 Table 2 . Percent of tasks solved correctly from the 10 most difficult PISA tasks in each TIMSS group based on PVs in the cognitive domains . Group Knowing Applying Reasoning ( 1 ) The highest achievers in TIMSS specific cognitive skills 20 . 4 21 . 0 20 . 2 ( 2 ) 10 . 1 10 . 4 10 . 1 ( 3 ) 8 . 6 7 . 5 7 . 3 ( 4 ) 4 . 5 5 . 2 5 . 1 ( 5 ) 4 . 5 4 . 0 4 . 8 ( 6 ) The lowest achievers in TIMSS specific cognitive skills 3 . 5 3 . 5 4 . 1 Transforming percentages into logits A direct comparison of the percentages of tasks solved correctly may not be a fully accurate measure because percentages can overestimate the proportion of cases near the ends of a distribution and underestimate those in the middle . The logit transformation “pulls out” those proportions that are close to 0 and 1 , while “squeezing” proportions close to 0 . 5 . A logit is defined as a logarithm of the odds . If p is the probability of an event , then ( 1 – p ) is the probability of not observing the event , and the odds of the event are p / ( 1 – p ) . The logit transformation was used for the recalculation : Z = ln [ P / ( 1 - P ) ] In this equation , ln is the natural logarithm ( e ) , and P is the percentage represented as a proportion between zero and one . We used this transformation to obtain a new measurement of the gain in PISA performance across each TIMSS group . Again , we performed the logit transformation for overall mathematics , as well as for all of the content and cognitive domains ( detailed results are shown in Appendix B , Tables 3 and 4 ) . 12 In general , the results after the logit transformation repeat the earlier results obtained in percentages . Students from “the best” TIMSS group show the largest gain in terms of PISA performance . There is also a flat difference between the second and subsequent TIMSS groups , in comparison with the jump between the first and second groups Checking robustness We calculated the gain in PISA performance for the easiest and random subsets of PISA tasks ( Appendix B , Tables 1 - 4 ) . We did not find the accustomed pattern in the gain of performance expressed in either percentages or in logits . For the easiest PISA tasks , a noticeable gain was observed between the sixth ( “lowest” ) and fifth TIMSS groups , but only as a percentage ( not for logits ) . For the random subsets of PISA tasks , no jumps in performance were found ; each level in TIMSS achievement gained roughly equally in PISA performance . Discussion The aim of this study was to understand how subject mastery level influences knowledge transfer to out - of - subject contexts . Generally , our results show that the better a student masters mathematics , the higher the probability that he or she will be able to transfer this subject knowledge to solve problems in out - of - subject contexts . Interestingly , this relationship between level of subject mastery and knowledge transfer is not linear . Only the highest mastery level significantly facilitated transfer . The medium and low levels of subject knowledge did not contribute considerably to knowledge transfer . The same pattern occurs for each content and cognitive domain of TIMSS mathematics . Only the highest levels of subject mastery produce noticeable gains in solving the most difficult PISA tasks . The remaining middle mastery levels led to little differentiation in PISA performance . We expected that the set of tasks from the TIMSS “applying” domain best predict performance in PISA , given that the “applying domain involves the application of mathematical tools in a range of contexts” ( TIMSS 2011 Assessment Frameworks , p . 43 ) , making this set of items formally closer to PISA’s contextual tasks . However , we again found the same relationships between the subject mastery 13 level and knowledge transfer across all cognitive domains , including “applying” . Only the highest mastery level contributed considerably to PISA performance . Any claim about the implications of this relationship is hampered by the extremely generalized nature of the test content we analyzed ( “mathematical knowledge” ) . Technically speaking , we should have identified TIMSS and PISA tasks that measure strictly the same mathematical skill or topic . Then we should have compared student performance in these tasks . However , due to the test design , too few students solve the same problems in the TIMSS and PISA . This design allows us to estimate population characteristics more efficiently , but it does make it impossible to come to a precise conclusion about individual proficiency . 6 Nevertheless , our basic finding suggests that educators should begin rethinking how test results are interpreted . The 10 - percent jump from a “B : to an “A” proves significantly more efficient at giving students skills for life than the jump from a “C” to a “B” . Additionally , spending extra time ensuring that students truly grasp the material may be a more effective use of classroom hours than moving quickly between many topics . As always , educators should strive to give students knowledge that will serve them well outside the classroom . Now we know that students must not simply know a subject , but master it in order to use it . References Barnett , S . , & Ceci , S . J . ( 2002 ) . When and where do we apply what we learn ? A taxonomy for far transfer . Psychological Bulletin , 128 , 612 – 637 . Brown , A . L . , Kane , M . J . , & Long , C . ( 1989 ) . Analogical Transfer in Young Children : Analogies as Tools for Communication and Exposition . Applied Cognitive Psychology , 3 , 275 - 293 . Dossey , J . A . , McCrone , S . . , & O ' Sullivan , C . ( 2006 ) . Problem solving in the PISA and TIMSS 2003 assessments technical report . National Center for Education Statistics , Institute of Education Sciences , U . S . Dept . of Education . 6 TIMSS and PISA are designed in such a way that their tests do not represent each sub - subject area of mathematics to a full extent . Instead of test scores in both TIMSS and PISA , there are plausible values ( PVs ) generated on a base of all available data , including both student responses to the test items and all relevant background data . PVs directly estimate the characteristics of student populations and sub - populations . Through PVs we can assess performance in mathematics as a whole , as well as in mathematical domains , but we cannot assess an individual across separate test items ( Mullis et al , 2012 ) . 14 Fong , G . T . , Krantz , D . H . , & Nisbett , R . E . ( 1986 ) . The effects of statistical training on thinking about everyday problems . Cognitive Psychology , 18 ( 3 ) , 253 – 292 . Gentner , D . , Loewenstein , J . , & Thompson , L . ( 2003 ) . Learning and transfer : A general role for analogical encoding . Journal of Educational Psychology , 95 ( 2 ) , 393 – 405 . doi : 10 . 1037 / 0022 - 0663 . 95 . 2 . 393 Gick , M . , Reed , S . K . , Ernst , G . W . , & Banerji , R . ( 1974 ) . The role of analogy in transfer between similar problem states . Cognitive Psychology , 6 , 436 – 450 . Hutchison , D . , & Schagen , I . ( 2007 ) . Comparisons between PISA and TIMSS - Are we the man with two watches ? In Loveless , T . ( Eds . ) , Lessons Learned - What international assessments tell us about math achievement . Washington , D . C . : Brookings Institute Press , 227 - 261 Lehman , D . R . , Lempert , R . O . , & Nisbett , R . E . ( 1988 ) . The effects of graduate training on reasoning : Formal discipline and thinking about everyday - life events . American Psychologist , 43 ( 6 ) , 431 – 442 . Mullis , I . V . S . , Martin , M . O . , Ruddock G . J . , O ' Sullivan C . Y . , & Preuscho ﬀ C . ( 2009 ) . TIMSS 2011 Assessment Frameworks . TIMSS & PIRLS International Study Center , Boston College . OECD ( 2013 ) . PISA 2012 Assessment and Analytical Framework : Mathematics , Reading , Science , Problem Solving and Financial Literacy , OECD Publishing . Thorndike , E . L . , & Woodworth , R . S . ( 1901 ) . The influence of improvement in one mental function upon the efficiency of other functions . Psychological Review , 8 , 384 - 395 . VanderStoep , S . W . , & Shaughnessy , J . J . ( 1997 ) . Taking a Course in Research Methods Improves Reasoning About Real - Life Events . Teaching of Psychology , 24 ( 2 ) , 122 – 124 . Wu , M . ( 2009 ) . A comparison of PISA and TIMSS 2003 achievement results in mathematics . Prospects , 39 , 33 – 46 ( 1 ) Wu , M . ( 2009 ) . A . A Critical Comparison of the Contents of PISA and TIMSS Mathematics Assessments , University of Melbourne ( 2 ) Wu , M . ( 2010 ) . Comparing the Similarities and Differences of PISA 2003 and TIMSS . OECD Education Working Papers . No . 32 . OECD Publishing 15 Appendix A 16 17 18 Appendix B Table 1 . Proportion of tasks solved correctly from the 10 ( and 20 ) most difficult , most easiest , and random PISA tasks in each TIMSS group , % . The most difficult The easiest random 1 random 2 random 3 random 4 10 20 10 20 10 20 10 20 10 20 10 20 The highest TIMSS group 1 21 . 6 30 . 8 91 . 7 89 . 8 69 . 7 65 . 1 80 . 6 60 . 8 89 . 2 70 . 1 83 . 8 63 . 3 2 9 . 8 18 . 1 87 . 9 83 . 8 58 . 6 54 . 9 71 . 5 48 . 4 83 . 1 61 . 2 76 . 3 52 . 8 3 7 . 3 12 . 9 85 . 7 81 . 1 53 . 1 49 . 5 67 . 5 43 . 1 82 . 2 57 . 3 70 . 0 46 . 5 4 5 . 3 9 . 0 83 . 1 75 . 2 46 . 9 42 . 8 58 . 5 36 . 5 77 . 6 51 . 5 62 . 6 39 . 8 5 4 . 3 6 . 3 79 . 0 69 . 0 38 . 2 36 . 3 51 . 1 29 . 7 73 . 6 45 . 6 56 . 8 34 . 1 The lowest TIMSS group 6 3 . 2 4 . 7 67 . 8 55 . 7 28 . 3 27 . 0 37 . 6 22 . 1 61 . 5 37 . 9 45 . 1 26 . 5 19 Table 2 . The performance gain for the 10 and 20 most difficult , easiest , and random PISA tasks in each TIMSS group , % . The most difficult The easiest random 1 random 2 random 3 random 4 The gain between 10 20 10 20 10 20 10 20 10 20 10 20 1st & 2nd 11 . 8 12 . 8 3 . 8 5 . 9 11 . 2 10 . 3 9 . 0 12 . 3 6 . 1 8 . 9 7 . 5 10 . 5 2nd & 3rd 2 . 5 5 . 2 2 . 2 2 . 7 5 . 4 5 . 4 4 . 1 5 . 3 0 . 9 3 . 9 6 . 4 6 . 3 3rd & 4th 2 . 0 3 . 9 2 . 5 6 . 0 6 . 2 6 . 7 9 . 0 6 . 6 4 . 6 5 . 8 7 . 4 6 . 8 4th & 5th 1 . 0 2 . 7 4 . 1 6 . 2 8 . 7 6 . 5 7 . 4 6 . 8 4 . 0 5 . 9 5 . 8 5 . 7 5th & 6th 1 . 1 1 . 6 11 . 2 13 . 3 9 . 9 9 . 3 13 . 5 7 . 6 12 . 1 7 . 7 11 . 7 7 . 5 20 Table 3 . Proportion of tasks solved correctly from the 10 ( and 20 ) most difficult , easiest , and random PISA tasks in each TIMSS group , logits . The most difficult The easiest random 1 random 2 random 3 random 4 10 20 10 20 10 20 10 20 10 20 10 20 The highest TIMSS group - 1 . 3 - 0 . 8 2 . 4 2 . 2 0 . 8 0 . 6 1 . 4 0 . 4 2 . 1 0 . 9 1 . 6 0 . 5 2 - 2 . 2 - 1 . 5 2 . 0 1 . 6 0 . 3 0 . 2 0 . 9 - 0 . 1 1 . 6 0 . 5 1 . 2 0 . 1 3 - 2 . 5 - 1 . 9 1 . 8 1 . 5 0 . 1 0 . 0 0 . 7 - 0 . 3 1 . 5 0 . 3 0 . 8 - 0 . 1 4 - 2 . 9 - 2 . 3 1 . 6 1 . 1 - 0 . 1 - 0 . 3 0 . 3 - 0 . 6 1 . 2 0 . 1 0 . 5 - 0 . 4 5 - 3 . 1 - 2 . 7 1 . 3 0 . 8 - 0 . 5 - 0 . 6 0 . 0 - 0 . 9 1 . 0 - 0 . 2 0 . 3 - 0 . 7 The lowest TIMSS group - 3 . 4 - 3 . 0 0 . 7 0 . 2 - 0 . 9 - 1 . 0 - 0 . 5 - 1 . 3 0 . 5 - 0 . 5 - 0 . 2 - 1 . 0 21 Table 4 . The gain of performance for the 10 and 20 most difficult , easiest , and random PISA tasks in each TIMSS group , logits . The most difficult The easiest random 1 random 2 random 3 random 4 The gain between 10 20 10 20 10 20 10 20 10 20 10 20 1st & 2nd 0 . 9 0 . 7 0 . 4 0 . 5 0 . 5 0 . 4 0 . 5 0 . 5 0 . 5 0 . 4 0 . 5 0 . 4 2nd & 3rd 0 . 3 0 . 4 0 . 2 0 . 2 0 . 2 0 . 2 0 . 2 0 . 2 0 . 1 0 . 2 0 . 3 0 . 3 3rd & 4th 0 . 3 0 . 4 0 . 2 0 . 4 0 . 3 0 . 3 0 . 4 0 . 3 0 . 3 0 . 2 0 . 3 0 . 3 4th & 5th 0 . 2 0 . 4 0 . 3 0 . 3 0 . 4 0 . 3 0 . 3 0 . 3 0 . 2 0 . 2 0 . 2 0 . 2 5th & 6th 0 . 3 0 . 3 0 . 6 0 . 6 0 . 4 0 . 4 0 . 6 0 . 4 0 . 6 0 . 3 0 . 5 0 . 4 22 For correspondence : Yulia Tyumeneva , National Research University Higher School of Economics , International Laboratory for Educational Policy Analysis , senior researcher . E - mail : jutu @ yandex . ru , mobile phone : 89104075140 Тюменева Ю . А . , старший научный сотрудник Международной лаборатории анализа образовательной политики . Any opinions or claims contained in this Working Paper do not necessarily reflect the views of HSE . © Tyumeneva , Valdman , 2014