44 Technological Frames and User Innovation : Exploring Technological Change in Community Moderation Teams CHARLES KIENE , University of Washington , USA JIALUN " AARON " JIANG , University of Colorado Boulder , USA BENJAMIN MAKO HILL , University of Washington , USA Management of technological change in organizations is one of the most enduring topics in the literature on computer - supported cooperative work . The successful navigation of technological change is both more challenging and more critical in online communities that are entirely mediated by technology than it is in traditional organizations . This paper presents an analysis of 14 in - depth interviews with moderators of subcommunities of one technological platform ( Reddit ) that added communities on a new technological platform ( Discord ) . Moderation teams experienced several problems related to moderating content at scale as well as a disconnect between the affordances of Discord and their assumptions based on their experiences on Reddit . We found that moderation teams used Discord’s API to create scripts and bots that augmented Discord to make the platform work more like tools on Reddit . These tools were particularly important in communities struggling with scale . Our findings suggest that increasingly widespread end user programming allow users of social computing systems to innovate and deploy solutions to unanticipated design problems by transforming new technological platforms to align with their past expectations . CCS Concepts : • Human - centered computing → Collaborative and social computing ; Empirical stud - ies in collaborative and social computing ; • Information systems → Chat ; Web interfaces ; Keywords : technological change ; moderation ; bots ; online communities ; social computing ; chat ; computer - mediated communication ; Discord ACM Reference Format : Charles Kiene , Jialun " Aaron " Jiang , and Benjamin Mako Hill . 2019 . Technological Frames and User Innovation : Exploring Technological Change in Community Moderation Teams . In Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , CSCW , Article 44 ( November 2019 ) . ACM , New York , NY . 23 pages . https : / / doi . org / 10 . 1145 / 3359146 1 INTRODUCTION The introduction of new technology to a group provides opportunities for members to restructure the way they interact , work , and communicate . The introduction of new tools can be particularly disruptive in fully mediated settings like online communities where groups’ entire activity can be augmented or changed through shifts in underlying technological platforms . Over four decades , an interdisciplinary body of research has sought to understand the social processes through which groups integrate new technologies in a diverse range of organizational settings . One of the most important insights from this body of work is Orlikowski’s concept of technological frames Authors’ addresses : Charles Kiene , University of Washington , Department of Communication , Seattle , WA , 98195 , USA , ckiene @ uw . edu ; Jialun " Aaron " Jiang , University of Colorado Boulder , Department of Information Science , ENVD 201 , 1060 18th St . Boulder , CO , 80309 , USA , aaron . jiang @ colorado . edu ; Benjamin Mako Hill , University of Washington , Department of Communication , Seattle , WA , 98195 , USA , makohill @ uw . edu . Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . © 2019 Copyright held by the owner / author ( s ) . 2573 - 0142 / 2019 / 11 - ART44 https : / / doi . org / 10 . 1145 / 3359146 Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 2 Kiene et al . which suggests that group members’ shared “assumptions , expectations , and knowledge [ used ] to understand technology” profoundly structure the way new technology is adopted and used [ 45 ] . One implication of the technological frames perspective is that users’ shared understandings of technology as they approach a new technology can lead them to use new systems like the tools with which they are already familiar . For example , the ethnographic study at the center of Orlikowski’s seminal papers described an organization familiar with email that used a database - driven knowledge - base system with email functionality ( Lotus Notes ) like the stand - alone email clients the firms’ employees had used in the past [ 42 , 45 ] . Like the broader body of research on the social construction of technology upon which Orlikowski’s research built [ 5 , 15 , 46 ] , the technological frames approach treats technology as constructed through social processes . Like other social constructionist perspectives , the technological frames approach describes technology as evolving over time through a complex interplay between engineering and social processes driving use and adoption . This study builds on the technological frames approach and contributes to the discussion on technological change in groups by examining the work of online community moderation teams . How do these groups , whose work is entirely mediated by technology , manage the adoption of entirely new technology that changes their entire mediated environment ? To answer this question , we drew from an analysis of 14 in - depth interviews with representatives of eight volunteer content moderation teams . Each team manages an online community using the same technological platform ( Reddit ) that had also recently added the same second technological platform ( a text and voice - based chat system called Discord ) . The most important themes that emerged from an analysis of our interview data focused on the way that moderation teams’ technological frames—drawn from their shared experience on Reddit—drove the way that they approached problems challenges posed by the new technological platform . Although some of this occurred in the socially constituted ways that previous research has described , our participants also repeatedly described using bots , scripts , and programmable APIs to build new technology to modify and add to the underlying technological systems provided by Discord—typically to make features of Discord work like moderation tools in Reddit . We found that this type of user - driven innovation played a particularly key role in communities that were struggling to support vast numbers of users . Our findings highlight both the shifting nature and the continued salience of technological frames due to the advent of APIs , bots , automation , and widespread end user programming [ 40 ] . Although technology frame - based understandings treat technology as fundamentally constituted by its users , the construction of technology by its users has typically been understood to occur socially . Our analysis suggests that users of online platforms construct their own technological artifacts as well . Technological frames shape not only the way that technology is constructed socially but—in a surprisingly direct way—the way that users are reconfiguring the technological basis of their artifacts themselves . Of course , the types of APIs and bots at the heart of our analysis are increasingly common features of new social computing systems . This paper explores the ways in which these new systems are being used , designed , redesigned , and rebuilt by users in ways that are structured by their past experiences in older social computing systems . 2 THEORETICAL BACKGROUND For users of contemporary social computing systems , technological change is inevitable and unavoidable . Although there is broad recognition that shifts in technology can be disruptive to organizations [ 4 , 31 , 32 , 43 ] , there is no consensus as to how and when effects will be felt or how Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 3 change should be managed . Much of this disagreement reflects important philosophical differences among scholars as to the ways that technology structures social behavior . The question of how technology influences social behavior lies at the heart of the argument around “technological determinism” that constitutes the most crucial debate in the social study of technology [ 24 ] . In broad strokes , determinists argue that technology pre - configures social action by constraining what users of a tool can and cannot do [ 37 , 60 ] . On the other hand , social constructionists argue that a technology’s effect is the product of social processes through which tools are used [ 5 , 46 ] . A range of approaches attempt to walk a middle ground . For example , discussions of affordances typically conceive of the effects of technology on social action as both determined and constructed by seeking to understand how technology makes certain types of behaviors easier or more difficult [ 7 , 16 , 17 , 53 ] . Advocates of all three theoretical lenses have made technological change a central point of empirical inquiry . They do so both because technological change provides a useful setting to investigate the interaction between technology and society and because technological change reflects an important challenge toward which a better understanding of the relationship between technology and society can be usefully applied . As a result , an enormous literature has emerged in social computing , management , and organizational studies that has attempted to outline the way that groups manage and navigate technological shifts . Many studies of technological change in organizations that adopt a more deterministic perspective draw from the literature on the management of innovation where technological change is both a desirable and manipulable output of an organization’s work ( e . g . , the product of an R & D lab ) [ 1 ] or an exogenous feature of an organization’s external environment that puts pressure on an organization by punishing groups whose products cannot keep up with a shifting technological landscape [ 2 , 55 , 56 ] . Work in this vein typically seeks to characterize patterns of change in industries that affect organizations and to outline ways that organizations can maximize performance in a shifting environment . An influential approach to understanding the effect of technological change in the social com - puting literature draws from social constructionism to understand how the behavior and work of organizations is restructured by the introduction of technology . An archetype of this approach , Barley’s classic study of two hospitals used ethnographic data to show that the introduction of CT scanners catalyzed two distinct patterns of social restructuring—one productive and another dysfunctional [ 3 ] . Building on this work , Orlikowski’s deeply influential studies of Lotus Notes , published originally in CSCW , used the introduction of the Notes groupware into several orga - nizations as an opportunity to describe processes through which technological change can have unpredictable effects—or very little effect at all—when technology bumps up against social struc - tures aligned against its “success” [ 42 , 43 , 45 ] . Work building on these classic studies has repeatedly demonstrated that the effect of technological change within organizations is constituted through complex and contingent social processes that operate at the level of groups’ shared technological frames [ 12 , 33 , 38 , 50 ] . Although nearly three decades old , Orlikowski’s work on Notes remains important in part because the salience of technological change for groups has increased enormously . Today , a large body of CSCW research focuses on social computing systems like online communities , where all work , all interaction , and all communication is technologically mediated . This technology can be changed by platforms operators , and it routinely is through updates and redesigns . Kraut and Resnick’s book - length review of online community research is organized around “design decisions”—most of them technological in nature that typically involve making changes to platform software [ 28 ] . A growing body of work has shown how the introduction of relatively small design changes into the software of online communities can have large effects on behavior of communities using the Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 4 Kiene et al . platform [ 6 , 23 , 28 , 39 ] . These changes are important to community members and sometimes prompt major protests [ 11 , 36 ] . 2 . 1 Key Concepts Our study attempts to explain how moderation teams of online communities , whose work is entirely mediated by technology , handle an incredibly disruptive technological change : a technological shift caused by adding a new technological platform for community discussion . In a thematic analysis of interviews with 14 moderators of eight communities , we found that moderation teams adapted to technological change by creating new technological innovations using application programming interfaces ( APIs ) and bots that transformed aspects of their new platform ( Discord ) so that it would work like moderation tools in their old platform ( Reddit ) . Although our findings were inductive and emerged from the thematic analysis of our interview transcripts , our description of these findings relies on a series of concepts from the scholarly literature . In particular , we rely on Orlikowski’s concept of technological frames [ 45 ] and von Hippel’s concept of user innovation [ 58 ] . We provide brief descriptions of both concepts below . 2 . 1 . 1 Technological frames . Our analysis relies heavily on Orlikowski’s concept of technological frames which describes the shared meaning that groups use to understand and interact with a technology [ 42 , 45 ] . Orlikowski’s concept builds on seminal work by Goffman who used the term “frames” to describe the cognitive templates that individuals use to render social experiences more interpretative and actionable [ 21 ] . Orlikowski and Gash explain that technological frames are used “to identify that subset of members’ organizational frames that concern the assumptions , expectations , and knowledge they use to understand technology in organizations” [ 45 ] . Following Orlikowski and Gash , we use technological frames as a conceptual framework in order to “track changes in the meanings people ascribe to information technology over time , thus providing a way of investigating the processes and outcomes of organizational change” [ 45 ] . 2 . 1 . 2 User innovation . Our analysis also makes use of von Hippel’s concept of user innovation . User innovation represents a central stream in innovation research over the last several decades inspired by empirical work that shows that technology is frequently designed by users who are creating new products , techniques , and services to solve their own problems [ 57 , 58 ] . Although it can involve de novo creations , user innovation often involves bricolage , modification , end user pro - gramming , and automation that augments existing technologies . According to the user innovation model , creators of successful new technologies require a combination of “need information” and “solution information” to guide the design of their innovations [ 58 ] . We also rely on von Hippel’s description of how collaborative innovation processes involving both designers and users can be supported through innovation toolkits which reflect the “coordinated sets of ‘user friendly’ design tools that enable users to develop new production innovations for themselves” [ 59 ] . This study contributes to understandings of user innovation by exploring when and where users seek out and use need information and solution information to develop innovations with end user programming toolkits like APIs . 3 EMPIRICAL SETTING There are two features of our empirical setting that we believe make it an excellent place to learn about technological change in online communities . First , the online communities we consider all rely on technological platforms that mediate all parts of their activity [ 19 , 20 , 30 ] . Second , we consider a single technological shift that occurs repeatedly across a range of groups . The latter feature is important because research has shown that the effect of the same technological shift can differ enormously across social contexts [ 3 ] . Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 5 Our study focuses on the experiences of moderation teams of communities on the Internet - based collaborative filtering site and message - board Reddit that had added the chat system Discord as an additional technological platform for community discussion . Although our 14 participants span eight distinct communities that vary in many ways , each team experienced change from the same technology ( Reddit ) to the same new technology ( Discord ) . Before presenting our findings , we first provide information on our empirical setting by briefly providing background on online community moderation , Reddit , and Discord . 3 . 1 Online Community Moderation Teams The effective management of members and content in online communities is critical to their success [ 28 ] . Grimmelmann explains that managers of online communities—referred to as “moderators” or “admins”—are charged with developing and implementing systems of governance which “structure participation in a community to facilitate cooperation and prevent abuse” [ 22 ] . Many of the websites that host online communities regulate content through a Terms of Service and content moderators hired by the platform . A large portion of moderation activity also occurs within semi - autonomous subcommunities , like groups on Facebook and subreddits on Reddit , which are managed by volunteer moderators who develop and enforce rules tailored to their subcommunities [ 14 , 20 , 28 , 48 ] . An emerging body of work has begun to explore the problems facing volunteer community moderators . These moderators face a range of challenges including the need to manage disruptions caused by newcomers and the emotional difficulties associated with monitoring and sanctioning misbehavior and traumatic content [ 13 , 20 , 27 , 48 , 61 ] . Volunteer community moderators are constantly challenged by problems associated with mem - bership growth and the limitations of their technological and human resources [ 9 , 20 ] . Community growth is often accompanied by an increase in unsocialized newcomers and content [ 27 , 28 ] . The limited availability of volunteer community moderators means that sanctioning misbehavior and content may be delayed [ 29 ] . Automated moderation tools are often developed and used by vol - unteer community moderators as a strategy for managing content in larger online communities [ 18 , 20 , 25 , 47 ] . However , these are most often imperfect solutions as moderators still need to make nuanced decisions about when and how to enforce sanctions in ambiguous situations [ 48 ] . This study explores these challenges further by examining how moderation teams of online communi - ties that added a new platform for community discussion managed new and different social and technological affordances . 3 . 2 Reddit Each of the communities represented in our study began as subcommunities of Reddit . Founded in 2005 , Reddit is a social news aggregation and discussion site that uses user - created forums to host topic - based communities called subreddits . Subreddits are tailored to a wide variety of topics . These range from more general interest sites like / r / politics and / r / science to more niche interests , such as popular TV shows or video games like / r / twinpeaks and / r / skyrim . Members of subreddit communities interact with each other through forum style posts , comment threads , and a voting - based collaborative filtering feature that allows users to curate the content in their communities by issuing an “upvote” or a “downvote” on posts and comments . Each subreddit is created and moderated by volunteer users of Reddit [ 14 , 36 ] . These moderation teams are self - organized and create and enforce their own rules to keep their communities on topic and distinct from other subreddit communities [ 14 , 27 ] . Although specific visual elements can be modified by communities , communities share the same structural properties . An example of a popular subreddit community devoted to “things that make you go AWW ! – like puppies , bunnies , babies , and so on . . . " is shown in Fig . 1 . Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 6 Kiene et al . Fig . 1 . An example of the interface for Reddit from the / r / aww subreddit community devoted to “things that make you go AWW ! – like puppies , bunnies , babies , and so on . . . " 3 . 3 Discord Each of the subreddit communities in our study had decided to add Discord as a technological platform to host synchronous community discussion . Discord is a free , cross - platform voice , video and text chat app with over 200 million users organized into millions of user - created communities called “servers” . Although it is a general purpose chat application , Discord was originally developed to support gaming communities and has several features that make it well suited for use by gamers . Many of the largest Discord servers are game - related . Discord servers range from small groups for friends to massive communities with hundreds of thousands of members . Discord uses a feature that allows the server creator to set levels of permissions within each server which are assigned to custom user roles like “Member , ” “Moderator” or “Admin . ” Additionally , moderators can also use Discord’s developer portal 1 to interact with the platform’s public API and to invite user - created bots to their server . An example of a Discord server community is shown in Figure 2 . Interactions in Discord servers occur either in text channels , which resemble a chatroom and voice channels where users talk to each other using microphones . The moderation teams of subreddit communities in our study began adopting Discord servers to facilitate a live chat social experience alongside the asynchronous experience of their subreddit communities . 4 METHODS This project was conducted in close coordination with a different interview study of moderation in Discord led by a distinct ( but overlapping ) research team [ 26 ] . While observing Discord in preparation for the studies , we observed a number of subreddit communities with Discord servers managed by overlapping teams of moderators . We were intrigued as to how these teams would navigate the very different affordances of Discord as they shifted their work from Reddit . We 1 https : / / discordapp . com / developers / applications / archived at https : / / perma . cc / S8E6 - AAF5 Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 7 Fig . 2 . A screenshot of the user interface for the Discord application . The far left sidebar lists all of the Discord server communities the user has joined . The second sidebar from the left lists the text and voice channels of the Discord server the user is currently viewing . The middle area is for the scrolling text chat , and the right sidebar lists the members on the selected server , categorized by their “role . ” designed this study to understand how . Although this study and Jiang et al . ’s [ 26 ] study involve separate interview protocols and conducted subject recruitment independently , some data were shared between them . Because every subject interviewed as part of this study was also a Discord moderator , all subjects in this study were asked questions from the protocol used in Jiang et al . [ 26 ] and are included in that study’s dataset . Because most of the Discord moderators in Jiang et al . [ 26 ] did not represent subreddit communities that had added Discord , the reverse is not true . We conducted a total of 14 semi - structured interviews for this study in January and February 2019 with moderators from eight different communities with a presence on both Reddit and Discord . All moderators were from communities that first existed as subreddit communities on Reddit . We used statistically non - representative , stratified sampling to guide the process of subject recruitment [ 54 ] . In particular , we stratified by community size on Discord to ensure that we have communities with both small and large Discord presences . Table 1 details the population characteristics of the communities recruited into our study . It includes the total community members on both Reddit and Discord , the total number of community members online at the time of data collection , and the type of content the communities were created to discuss . Subreddit communities managed by our participants ranged in size from 120 , 000 to more than 13 million total members , whereas Discord communities ranged in size from 1 , 100 to over 170 , 000 total members . Because of its history as a tool for gaming communities , video games were a common thematic focus among the communities our interviewees managed ; six of the eight communities were fan communities for video game titles . Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 8 Kiene et al . Community Topic ID Discord Discord Reddit Reddit Total Online Total Online A Game ( MMORPG ) P1 , P3 55 , 251 12 , 538 974 , 286 5 , 300 B Creative writing P2 , P5 1 , 137 138 13 , 026 , 051 7 , 700 C Game modification P4 3 , 246 910 126 , 143 1 , 600 D Game ( Farming sim ) P6 , P7 , P8 24 , 542 6 , 942 294 , 211 1 , 700 E Game ( FPS ) P9 171 , 608 35 , 273 2 , 049 , 341 5 , 500 F Game ( FPS ) P10 , P11 63 , 001 21 , 821 886 , 214 8 , 100 G Game ( MOBA ) P12 , P13 29 , 173 5 , 273 525 , 402 8 , 400 H TV series P14 8 , 231 1 , 335 1 , 695 , 548 3 , 700 Table 1 . Population data from Reddit and Discord subcommunities . Discord numbers were measured at March 8 , 2019 and Reddit numbers were measured on March 21 , 2019 . “Total” numbers describe the aggregate number of community members including users not online at the time of data collection . “Online” numbers refer to the number of community members online at the time that data was collected . “Reddit Online” numbers are rounded by the Reddit interface and are reported as provided . Farming sim , MMORPG , FPS , and MOBA are types of video games . ID Community Gender Age Location Occupation Interview Time P1 A M 26 US Network Admin 50 P2 B M 37 US Software Dev 60 P3 A M 24 US Retail Manager 67 P4 C F 26 US Student 57 P5 B F 32 US Mother 74 P6 D F 24 NL Student 62 P7 D M 27 US Network Engineer 97 P8 D F 22 US Student 51 P9 E M 23 NL Student 67 P10 F F 24 UK Call Center Rep 56 P11 F M 29 US IT Technician 74 P12 G M 23 UK — 61 P13 G M 39 UK — 63 P14 H M 21 US Student 42 Table 2 . Community , gender , age , location , occupation , and interview time in minutes for the participants in our study . Data is marked as “—” when subjects opted not to provide this information . Recruitment messages were sent directly to moderation teams on Discord . We used snowball sampling techniques to recruit individual moderators after initial contact with the moderation team . Potential interview participants were screened via a Google form that sought to confirm that all participants were adults , spoke English , and were members of the moderation teams of Discord server communities that originated from Reddit . Participants who met these inclusion criteria were verified to be moderators manually before being scheduled for voice call interviews conducted over the Internet using their choice of voice call platform . All participants chose Discord for private voice interviews . The lead author recruited , interviewed , and transcribed 12 of the 14 interviews in this study ( Community A - F and H ) , whereas the second author recruited , conducted , and transcribed interviews with the two moderators of Community G . Each participant was compensated with Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 9 $ 20 for their time and involvement in this study . Table 2 describes the participants’ gender , age , location , and occupation . Interviews were on average 63 minutes long , and the median age of our participants was 25 . Nine of the participants identified as male while the other five identified as female . The majority of our participants were located in the United States . Following interview guidelines by Charmaz [ 10 ] , interviews were semi - structured . Our interview protocol sought to explore the concrete experiences of moderators , the meanings of their work , and the decisions they take in managing their communities . We asked participants to tell stories about their experiences joining their moderation team , enforcing rules , and using Discord’s tools . We also asked participants to describe the ways in which their moderation teams were organized and where and how communication took place . Finally , we asked participants to describe their moderation experiences on Discord in comparison to Reddit . A copy of our interview protocol is included in our supplemental material . To more fully inform our understanding of the technological and organizational challenges of moderating in Discord , the first and second author created Discord accounts and a server . We used this server to experiment with Discord’s moderation tools as well as the user - created bots mentioned in the interviews . We carried out some of the processes described in these interviews and recorded them as screenshots we have included throughout our findings as illustrations . Our analytic methods were based on Braun and Clarke’s approach to conducting thematic analysis drawn from psychology [ 8 ] . Using inductive , open coding techniques , the first author performed an initial round of line - by - line coding of the interview transcripts . Emergent code groups like managing growth or wanting efficiency on the platform were discussed with the two lead authors and contributed to the development of thematic categories related to the challenges moderation teams faced in adapting to technological change as well as the solutions that emerged in the form of end user programming innovations [ 10 ] . These themes influenced a series of memos produced by the lead author that were iterated on repeatedly after discussions with the research team . The findings reported in this paper reflect the ideas developed in those memos and address the empirical puzzles that emerged through the course of the study . The design and execution of this study attempted to account for ethical considerations for the privacy and protection of our research subjects . We took several steps to protect both . Our data collection , analysis , and publication plans were vetted and approved by the Institutional Review Boards of both universities involved in this project . Additionally , all participants were fully briefed about the study before being interviewed and explicit consent was obtained . Finally , both participants and their communities were made anonymous and no direct identifiers to participants were recorded alongside the data collection for any part of this study . 5 FINDINGS Three major themes emerged from our analysis which are described in the sections below . The themes centered on challenges of moderation work in the new technological context of Discord ( § 5 . 1 ) , the effect of community growth and membership size on making this work more difficult ( § 5 . 2 ) , and the strategies of adapting to these challenges through end user programming innovations of the platform ( § 5 . 3 ) . 5 . 1 Challenges of a New Technological Platform Our participants described the differences in the social [ 7 ] and technological [ 16 ] affordances of Discord and Reddit as a challenge for moderation work . Most notable in these comparisons were differing norms for user interactions afforded by Discord and on Reddit . P1 described this difference in Discord , saying , “you have to follow a certain rule set to be able to even post something [ on Reddit ] , whereas Discord is just like a free chat room . ” This “free chat room” is different from Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 10 Kiene et al . Reddit’s forum style posting because Discord affords synchronous communication options of instant messages in its text channels and voice communication in its voice channels . P12 elaborates on this difference saying , “Reddit has anti - spam like protection I think , like someone can’t make like twelve posts , where in Discord you can generally just like post twelve times in like one second , nothing’s going to stop you . ” Discord’s instant messaging style of communication in its text channels means moderators must be actively monitoring user content at all points in time . P4 described the work of moderating this chat room environment of Discord as , “it’s kind of rough because if you miss it , it’s really hard to go back to something that happened eight hours ago and the conversation moved on and be like ‘hey , don’t do that . ’ ” Conversations on Discord servers , compared with subreddit communities , complicated the work of moderation as instant messaging chat channels allow for rapidly moving , informal conversations between community members that can be difficult to track and monitor for misbehavior and rule breaking . Although one of the biggest differences in the affordances between Reddit and Discord is the voice channels available in Discord , nearly all of our participants reported rarely having to perform moderation work in these spaces . When asked about moderating voice channels , P11 said , “there’s generally not much going on in there . We’ll sometimes hop in from time to time , but there’s usually not very many issues that come up with them . ” In communities like P1’s and P4’s , the voice channels were rarely used at all . P1 explained , “we really don’t use those . . . when you make a server , they come with voice channels , so we just really never deleted them . . . so it’s been quite a while since they’ve actually been touched . ” For many communities in our study , voice channels were either completely inactive , like those that P1 described , or they were actively used by community members but rarely generated work for the moderation team . From the perspective of a moderator , the other key difference between Reddit and Discord lies in their tools available to assist with moderating . On Reddit , moderators are afforded an entire set of built - in " mod tools " 2 that include an " Automoderator " bot which can be customized to automate content moderation with filters that search for words , URLs , or patterns , a moderator action log system known as “Mod log” that records and details moderator actions in the community ( Fig . 3 ) , and a moderator mail feature known as “Modmail” that functions as a shared mail system for all of the members of a community’s moderation team ( Figure 4 ) . In addition to these tools , Reddit community members outside moderation teams assist in the governance of their community with Reddit’s voting system and reporting features . Discord affords moderators the “Audit Log” feature ( Fig . 5 ) which functions similar to Reddit’s Mod log , but it lacks the Automoderator and the Modmail tools afforded to moderators on Reddit . Discord’s built - in tool for filtering explicit content is its “Explicit Content Filter” ( Fig . 6 ) but , unlike the Automoderator on Reddit , it cannot be customized . In both platforms , moderators can mute , kick , or ban other members from their communities and can delete contented submitted by community members . 5 . 2 Problems from Community Growth and Size in Discord Communities Our interviews revealed that these differences in affordances posed many challenges to community governance . These challenges were aggravated when Discord communities increased in membership size . Increases in membership can threaten the stability of online communities [ 9 , 41 ] . Past work has shown that governance strategies play an important role in effectively managing this growth on social media platforms [ 27 , 34 ] . While the moderators of relatively small Discord communities we interviewed reported fewer challenges in managing their community with Discord’s affordances , moderators of larger Discord communities felt that Discord’s features limited their ability to govern their communities . 2 https : / / www . reddit . com / r / ModSupport / wiki / moderator - tools archived at https : / / perma . cc / 6VJL - ZXXF Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 11 Fig . 3 . The “Mod log” feature provided by Reddit in the “Mod Tools . ” Fig . 4 . The “Modmail” feature provided by Reddit in the “Mod Tools . ” Fig . 5 . Discord’s built - in “Audit Log . ” The “Filter by User” feature filters moderator actions ( such as a moderator deleting a comment or banning a user ) , but context for why a community member was warned or banned is not recorded . One of the biggest challenges in moderating large Discord servers reported in our interviews was managing information related to community governance . Many of the moderators of large Discord communities that we interviewed , like P7 , shared the sentiment that Discord’s moderation tools Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 12 Kiene et al . Fig . 6 . Discord’s built - in “Explicit Content Filter . ” These filters cannot be customized , and there are no specific explanations for the specific content that is filtered with this tool . are “very rudimentary and [ do ] not have a lot of features for logging input and stuff like that . ” P7 pointed out that the built in tools in Discord , like the Audit Log depicted in Figure 5 , are insufficient in a large Discord community , saying , “when you’ve got a server of 22 , 000 people , finding a specific warning for a specific user in our user log book kind of gets hard . ” Moreover , Discord’s Audit Log contains information about actions that moderators have taken in the server but cannot retrieve information on actions taken against specific community members or record why a member was sanctioned in the past . Moderators reported that the lack of this functionality made consistent rule enforcement challenging because moderators had no efficient system for sharing information on the offenses committed by community members . The limited availability of volunteer moderators creates another challenge in managing online communities in that volunteer moderators are often online at different times of the day and typically moderate only when they have the free time to do so [ 20 ] . A community member may want to solve a problem they are having through a private message with a member of the moderation team , but if that moderator is not online , the problem may go unsolved . With an increase in community membership size , a number of potential problems for community members may go unresolved in these ways . Platforms like Reddit have built - in solutions for this problem in the form of the Modmail system which moderators like P9 emphasized as essential for large communities because “if you didn’t have it , you’d have to do it on a one by one basis . ” Moderators of larger Discord communities , like P11 , felt that running larger communities is “a lot to actually keep track of and run and manage " and compared his work to “running a small city . ” While the moderation teams of communities that grew slower and sustained relatively small communities could work around the limitations of the Discord platform , moderation teams of larger communities felt that they could not . P5 , the head moderator of Community B in both the subreddit and the Discord server , compared moderating her community on the subreddit , which hosts 13 million members , to their Discord server , which hosts only 1 , 100 users : In the Discord , we need to step in as mods maybe two to three times a month and actually . . . kick someone from the channel or ban someone from the channel . So , there’s not a whole lot to do in the actual Discord channel . Whereas , like I said , on [ the subreddit ] , there’s , there’s a lot of rules that every post on the sub has to adhere to . ( P5 ) According to P5 , managing their small Discord server involves less work than managing their large subreddit population . In small Discord communities like B and C , there was less content to moderate and fewer community members to manage . P2 described the social makeup of Community B saying , “there are maybe like a dozen or so people that are regularly commenting and . . . some people come in , chat a bit for a few days and then just sort of drift off and then only pop in when there’s actual conversation . ” P2 described his community as just “people shooting the shit . ” P2’s description evokes Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 13 the idea of a virtual “third place” [ 51 ] and implies that the relatively low number of community members in his Discord server constitute a small , close - knit group of friends socializing together in real time . With less content to moderate as a result of fewer active members , these moderation teams of smaller communities offered little criticism of Discord’s built - in tools for performing moderation and governance . In sum , our subjects’ experiences suggest that differences in membership sizes of Discord com - munities resulted in differences of opinions about the efficiency of Discord’s moderation tools . Moderation teams of Discord communities that experienced massive membership growth and supported large communities felt that Discord’s built - in moderation tools were insufficient for conducting content moderation at scale and were unable to help moderators track and record community members’ offenses . These volunteer community moderators were charged with manag - ing the content of tens of thousands of community members ; doing so within the limitations of Discord’s built - in moderation tools presented a problem that required innovative solutions . 5 . 3 User Innovations for Solving Technological Problems As a result of fewer appropriate affordances , moderation teams of large Discord communities were tasked with solving problems related to three major forms of community moderation work made more challenging by the problems of membership growth : scaled content moderation , manag - ing information about community members , and the limited availability of their volunteer staff . Representatives of the moderation teams we interviewed solved these problems through the imple - mentation of tools they developed themselves using Discord’s API . In this section , we describe the user innovations created by moderators to solve these problems and show how they were drawn from moderators’ technological frames governing online communities on Reddit . 5 . 3 . 1 Tools for scaled content moderation . One of the most important tasks of community moderators is content moderation [ 22 ] . Content moderation typically involves monitoring and removing messages with certain behaviors , words , phrases and images forbidden by community rules [ 14 , 20 ] . Moderation teams of online communities expecting massive increases in membership size have to strategically manage the corresponding growth in content with moderation systems that can scale [ 27 , 48 ] . In large online communities , the sheer number of members results in an overwhelming amount of content that must be evaluated and may be impossible to conduct this evaluation effectively with traditional moderation techniques that involve human moderators viewing and deciding on each piece of content [ 20 ] . This was true for the communities in our study . One effective strategy for solving the problem of scaled content moderation is the implementation of automatic word detection and filtering [ 20 , 48 ] . However , the community moderators of Discord servers are limited to a very basic set of word filtering options in Discord’s “Explicit Content Filter” ( Fig . 6 ) which offers no customization features and only gives a vague description of what type of content is being filtered . To solve the problem of content moderation at scale , the moderation teams we interviewed intro - duced user - created bots equipped with automated word filtering options that could be customized with text - matching regular expressions . For example , P7’s Discord community implemented a repurposed IRC bot called “UB3R - B0T” that constantly scans the text channels in their community for pre - defined words or phrases . Once a word or phrase is found , UB3R - B0T will record the offending message , post the message as a logged action in a private channel for their moderation team , delete the original message containing the offending word or phrase , and then automatically notify the moderation team that their automated word filter has been activated by the offending community member . The moderators will then look at the offending message caught by UB3R - B0T Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 14 Kiene et al . and decide if and how to sanction the community member . P7 described why this was useful in his moderation work : It makes it so that rather than having to watch every single channel all of the time for this sort of thing or rely on users to tell us when someone is basically running amuck , posting derogatory terms and terrible things that Discord wouldn’t catch itself . . . so it makes it that we don’t have to watch every channel . ( P7 ) Making the reference to a hot - key for searching within Discord , P7 described this tool as “basically control - F on steroids . ” Not having to “watch every channel” frees up moderators to focus on other moderation tasks and reduces the amount of total moderation work in general . Other moderators of large Discord communities we interviewed used similar bots . P10 recalled how the bot in her server helps prevent people from “spamming” their community with unwanted content like links to other Discord servers and how this is helpful in a large Discord community where “you may not have , the team , like , the amount of people that you need” to “do it all manually . ” Doing the work manually may simply not be possible with a small team of volunteers tasked with moderating the content of hundreds of thousands of people . P14 described how the moderation bot in his community makes it so the moderators don’t have to “wait for someone to come by and see it . . . Or we don’t want someone to have to tag all the mods so that they’ll see it . . . not have to be here and watching the chat constantly . ” Bots were also used to automate tasks like quickly deleting spam messages in a semi - automated manner . P10 described how “you can just say [ to the bot ] like ’clear50’ and it’ll clear out the last 50 messages in the channel . ’ In sum , the use of these bots , each designed to fill the needs of the particular community that deployed it , suggests that the problem of scaled content moderation can be solved with end user programming innovations that automate aspects of their work . The bots described by our interviewees afford moderators in large Discord communities custom tools for content moderation at scale in the same way that Reddit’s Automoderator is used to automate custom content moderation in large subreddit communities . End user programming options in Discord allowed for the creation of bots that could do more efficient and custom content moderation than Discord’s “Explicit Content Filter” tool . These bots operate in a way that is similar to the way in which Reddit’s Automoderator simultaneously prevents unwanted spam and prohibited language in subreddit communities . Innovations like these bots facilitate the governance of moderation teams in Discord communities by providing them with content moderation tools that can help “structure participation in a community to facilitate cooperation and prevent abuse” at scale [ 22 ] . 5 . 3 . 2 Tools for managing community information . Making informed decisions for when and how to enforce rules in online communities is another major aspect of moderation work [ 20 , 47 ] . Moderation teams in large Discord communities were challenged with keeping track of the vast amounts of community member sanctions and moderation actions that typically inform these decisions . Discord’s built - in moderation tools for tracking this kind of information , the " Audit Log " , was repeatedly described as insufficient for organizing and retrieving information about community member offenses and their history in the Discord community . As a solution , moderation teams for these communities implemented user - created bots built with Discord’s API to record and dump this information in private text channels in their Discord server , often referring to these text channels as “moderation logs” or “mod logs” . This information , described by moderators as a “user history” within the community , was made easily retrievable by bots that would take commands to parse the moderation logs channel for the member’s Discord username . The moderators in our study described the effectiveness of the moderation log innovation imple - mented into their Discord server communities . For example , P9 reflected on how the moderation log Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 15 Fig . 7 . An example of a moderator using the Dyno bot to apply a warning to a community member who has broken a rule and record the reason for the warning . The moderator does so by using the command “ ? warn < username > ” in a private text channel . Fig . 8 . An example of moderation logs using Dyno in Discord . After the command to warn a community member has been issued by the moderator , the bot sends a private message to the user telling them that they have been warned and for what reason . Then , the bot records this information into a text channel that acts as an informal database of community information and that is only viewable by the moderation team . tool allowed him to easily retrieve user histories and that it “just helps keep everything organized and consistent , and if you , if we didn’t have it , it would just be a huge , huge hassle . ” Moderators we interviewed valued “organized and consistent” information as it helped to decide on an appropriate level of sanctions to apply to a community member who has broken a rule or caused problems with other members . An example using a widely used bot named Dyno 3 illustrates the process . As we show in Fig . 7 , a moderator using the tool will issue a text command to a moderation bot in a private text channel ( with “ ? warn < user > < reason > ” ) to select the community member by their username and supply a reason for why they are being warned , muted , or banned . The bot then sends a private message to the community member telling them they have been warned and why and records each case in a message in the moderation logs text channel , as shown in Fig . 8 . In Fig . 9 , we show how a moderator may then use the bot to retrieve the community member’s “history” by issuing a new command to the bot ( “ ? warnings < user > ” ) . Using the bot , the moderator can search through the moderation logs text channel to organize and retrieve all of the instances in which the selected community member has been warned and for what reasons . P11 explained that this process “helps to determine if they should just get another warning or they should get a mute , or maybe they’ve been warned 20 times in a month and maybe they should get a ban instead . ” In this way , the bot represents an innovation that helps inform how moderators should enforce rules and apply sanctions on offending community members . 3 https : / / dyno . gg / archived at https : / / perma . cc / UQ5J - P52S Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 16 Kiene et al . Fig . 9 . An example of a moderator pulling up the user history of a community member in a Discord server using the Dyno bot . The bot searches through the moderation logs text channel for all warnings pertaining to the specified community member , organizes it chronologically , and then returns the list of warning information back to the moderator who requested it . The moderator does so using the “ ? warnings < username > ” command . While the innovation of a Mod Log transformed Discord text channels into private , searchable databases , they were also used to track and record member offenses that can disappear or change due to Discord’s edit and delete message feature . Moderators pointed out that Discord allows users to delete or edit their own messages . P11 described this problem saying , “we’ve had a couple of times where people will post a message that’s extremely inappropriate but then instantly delete it before a mod could actually see it . ” In this way , community members could circumvent the rules against harassment and offensive language by deleting offensive messages before moderators have a chance to see them . To address this problem , user - created bots like those in P11 and P7’s communities were pro - grammed to instantly record any message that is deleted or edited in a public text channel and post it into the private , " Mod Log " text channel . P7 described the bot in his community that does this saying that it “records anything that’s deleted so whenever a user does something wrong and realize they’ve done something wrong and deletes it , no , no , no , no , no . Sorry dude . But you did it and we know you did it . ” The moderation log system affords Discord moderators a greater sense of control in governing their communities by limiting the ways in which community members can circumvent the rules . However , it also alters the affordances of Discord’s platform by removing members ability to delete one’s chat messages in a way that moderators cannot see . Tools resulting from the innovative use of a bot and private text channel essentially functioned as a facsimile of the Mod Logs tool used to manage community member information by moderation teams on Reddit ( Fig . 3 ) . The choice to implement a Mod Logs type of solution to this problem—and to describe it as such—suggests that the moderation teams framed the problem in reference to their experience on Reddit . The moderation teams of large Discord communities teams were able to use technological frames as a resource for making sense of their challenges in their new technological platform and as well to provide potential “solution information” to guide the innovation of user - created tools to overcome these challenges [ 45 , 58 ] . 5 . 3 . 3 Tools for mediating communication with community members . Communication between moderation teams and community members is one of the most important aspects of community moderation [ 48 ] . However , because they are volunteers , community moderators are limited in their availability to respond promptly to private messages about problems or questions from members of their community . On Reddit , a crucial tool mediating and organizing communication between community members and moderators is the Modmail system . This tool , depicted in Fig . Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 17 Fig . 10 . An example of the innovated Modmail system on Discord simulated by the authors and using a third - party free / libre open source software Modmail bot ( https : / / github . com / kyb3r / modmail archived at https : / / perma . cc / UNW2 - U65T ) made available by kyb3r on GitHub . 4 , allows moderators to collaborate on addressing issues and questions from members in their community by affording moderation teams of individual subreddit communities a shared mail system . A message sent to the Modmail for a Reddit community is visible to , and can be replied to by , anyone and everyone in that community’s moderation team . Reddit’s tool helps to address the problems of limited availability of volunteer moderation teams by ensuring that communication with community members is not one moderator’s sole responsibility . Moderators of large Discord communities in our study reported that their moderation teams were initially challenged with mediating private communications with their community members . No Modmail style system that can facilitate this kind of communication is built in to Discord like it is on Reddit . Moderators reported that this led to inefficiencies in large Discord communities as more community members meant potentially more problems sent in private messages for the moderation team to resolve . To solve this problem , moderation teams of the Discord communities in our study developed and deployed communication tools modeled after Reddit’s Modmail , using a combination of bots developed with Discord’s API and private text channels . P9 described how the tool they used in Discord works : So instead of having somebody DM a moderator specifically and then having to talk . . . indirectly with the team , a [ text ] channel is made for that specific question and everybody can see that and comment on that . And then whoever’s online responds to the community member through the bot , but everybody else is able to see what is being responded . ( P9 ) P9’s moderation team even named the bot facilitating this system the “Mod Mail Bot , ” directly invoking the tool on Reddit that the bot was attempting to emulate . For P9 , the Mod Mail Bot made communication between members of the community and the moderation team more efficient by redirecting all messages for the moderation team to a single location where moderators can observe , discuss , and collaborate on resolving problems . We demonstrate an example of a Modmail bot using a free , open source version of such a bot in Fig . 10 . P11 , who created and constantly updates the bots in his community , described how the Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 18 Kiene et al . Modmail bot afforded collaboration with other moderators to resolve issues or questions from members of the community : So say I started a conversation with someone , but then I get busy and I’m not able to respond . Another mod is instantly able to see what’s going on , pick up that conversation and respond back to them . ( P11 ) In this example , P11 describes how the bot reduced the work of his moderation team so that moderators in his community do not have to take on community member questions or issues on their own . Another moderator , P1 , commented on the Modmail bot in his community and explained how this tool afforded privacy to community members with questions concerning sensitive topics , saying “ [ the Modmail bot ] posts it [ the member’s question ] in our Modmail channel – actually on the server—so that we can see . . . in a more private setting because someone doesn’t [ always want to ] ask their question out in the open . ” These Modmail systems also reduced some of the emotional labor of moderating by allowing community members voice their complaints to the moderation team through the bot rather than through private messages with individual moderators . P7 explained that his Modmail bot makes the work of communication between members of the community and the moderation team more efficient by funneling interactions into a central location so that individual moderators don’t have to carry the emotional burden of dealing with upset members of their community . Instead , upset members of the community , as P7 describes it , “explode on the bot , ” which helps diverts harassment so that it can be managed by the entire moderation team . These innovative uses of Discord’s private text channels and bots resulted in new communication tools that mediated and organized private communication between community members and their moderation teams . As we discussed in § 5 . 1 and show in Fig . 4 , a similar a tool called “Moderator Mail " exists in Reddit’s mod toolkit . As communities grew in size on Discord and the work of moderation began to scale , moderation teams’ technological frames from Reddit offered potential models for a technological innovation on Discord that could solve problems they were facing and more efficiently organize and mediate private communication with their community members . Discord’s API allowed moderation teams to implement a hacked stand - in of Reddit’s Modmail system by reconfiguring private text channels through bots . 6 DISCUSSION In this study , we interviewed volunteer community moderation teams that added a new techno - logical platform as a way of understanding the way that groups whose work is entirely mediated by technology navigate challenges caused by technological change . Although the different social and technological affordances of Discord presented challenges for the work of all the moderation teams we interviewed , the additional difficulties caused by scale elevated these challenges into crises . We found that Discord community moderators sought innovative solutions to the problems associated with community growth that were modeled after the moderation tools they used to govern communities on Reddit . Bots created with Discord’s end user programming toolkit enabled these moderation teams to manage community growth by automating content moderation , track - ing information of community members , and more efficiently facilitating private communication between the moderation team and individual community members . These innovations restructured aspects of the Discord platform in ways that caused them to resemble the systems used on Reddit . In this way , groups were neither entirely constrained by the new technology’s affordances nor forced to adopt entirely new ways of doing their work . This study diverges in important ways from the way that social constructionists like Orlikowski describe technological change and frames . Orlikowski primarily invokes frames as social structures Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 19 that limit and constrain what a technological system can and cannot do [ 44 , 45 ] . Orlikowski’s users’ existing email frame means that they do not use the more powerful Lotus Notes in ways that extend far beyond email . In this study , frames acted as resources that , combined with the end user programming toolkits of the API , enabled Discord moderators to adapt to problems related to technological change and scale in creative and powerful ways . End user programming allowed for online groups to reduce the tension between their technological frames and the affordances of new technology . They did so by giving users the agency and ability to work around the new system’s constraints to make the systems more familiar to the users . Our findings point to the way that technological frames provide a resource of “solution information” [ 58 ] that structures and enables innovation , adaptability , and a more effective version of a new technology than even its creators might have imagined . 6 . 1 Reconstructing Systems of Governance This study shows how several moderation teams of online communities that added a new platform adapted to technological change and the new challenges that it brought by using end user program - ming toolkits to repurpose aspects of the new platform into systems that are similar to moderation tools used in other contexts . Frames acted as resources influencing the design of innovations in that Discord moderation teams recreated tools by modeling them closely after Mod Tools found on Reddit . These tools not only performed similar function but were often also given identical names like the “Mod Log” and “Modmail . ” By filling their new platforms with tools similar to those used in past platforms , users also reconstruct and reconstitute certain aspects of governance and power from their past platforms . Geiger [ 18 ] called for future research into power interplay between platforms and bespoke code like bots stating that “in broader conversations about how platforms govern and are governed , we must seek out and critically investigate all the bespoke code that is being developed in places far away from the traditional sites of platform - based power . ” Research on bots in social computing has examined how bots engage in mundane tasks like facilitating information infrastructure and archiving [ 52 ] and preventing abusive language [ 62 ] . A more recent but more promising line of research seeks to understand moderation activity of bots in online communities [ 47 ] . Although the day - to - day activities of these types of technologies can seem inconsequential , Geiger [ 18 ] connects these types of activities to central questions of power and community governance and the way that technologies like bots are causing these to shift from platforms to users . Past work has also shown how the built - in technological affordances of platforms like Reddit can reproduce systems of bias and power found offline [ 35 ] . This study shows how some of Reddit’s systems are subsequently reproduced elsewhere . We hope to see future work explore the ways tools for moderation from one platform reproduced in another may also reproduce systems of governance and power . The technological and organizational transformations we describe above were shaped by con - ditions specific to communities in which they occurred . Geiger [ 18 ] showed that the inundation of user - created bots in Wikipedia influenced new governance policies in Wikipedia that intro - duced a bureaucratic system of registering new bots as a way of halting the influx . In an almost reverse sense , inundations of new community members may also affect the governance of online communities , as Shaw and Hill [ 49 ] show in their work on the effect of population growth on governance structures in wikis . Shaw and Hill found that conditions like population size in wikis may correspond with shifts from democratic management toward more oligarchical governance . Moderation teams of Discord server communities with small population sizes in this study use fewer organizational tools and reported less governance activity compared to larger communities . Smaller communities may not require the moderation tools and governance systems used by larger communities . Our findings suggest that increases in membership size may exacerbate the problems Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 20 Kiene et al . associated with technological change for community managers like moderators by increasing their work and requiring more advanced systems and tools for community governance . 6 . 2 Implications for Community Moderation Our findings have important implications for volunteer community moderators navigating the challenges of adding a new platform for community discussion . When adding new technology , volunteer moderators should seek out platforms with robust end user programming capabilities . As designers cannot anticipate every problem that may arise for community moderators , the ability to create their own applications affords moderators agency in solving their problems with custom solutions [ 40 ] . Although taking advantage of APIs will require work on the side of moderators including learning a programming language and developing solutions on their own , our findings show that the payoff for moderation teams is often worth the cost . By using bots to automate the flagging of questionable content , log users’ histories , and facilitate communication between moderation teams and community members , moderation teams were able to extend the functionality of Discord in order to manage community growth resulting in greater efficiency and more effective governance [ 18 , 40 ] . 6 . 3 Implications for Design Our findings also have important implications for designers and programmers of social media applications and the platforms that host online communities . Our findings suggest that platform developers should consider the effect that membership size has on the work required of volunteer moderation teams and take steps to better support these users with tools to manage community growth . Recent work has pointed to the importance of Reddit’s Automoderator in helping volunteer community moderators manage their work [ 25 ] . Similarly , this study supports the notion that moderators should be equipped with customizable tools to automate tasks like content moderation . Effective moderation is crucial to the success of online communities [ 22 , 28 ] and supporting moderation teams with tools like the ones used by the moderation teams in this study could potentially help communities succeed when managing problems from membership growth . The specific moderation tools we describe were effective enough in Reddit that moderators expended significant personal time and effort to reproduce them in Discord . They are likely examples of useful types of tools for the effective support of moderation at scale in other online settings as well . More important than the specific features we describe , our study suggests that designers of new systems need not worry about trying to implement every feature that users might want . Our findings show how end user toolkits like APIs can facilitate the successful navigation of technological change by affording users the ability to build custom solutions according to their needs . In this study , moderators generated ideas for solutions related to scale that Discord’s developers had almost certainly not anticipated . Our findings suggest that online communities can thrive when they are empowered to draw from their technological frames to innovate custom solutions to unforeseen design problems . 7 CONCLUSION We investigated the challenges of technological change experienced by volunteer moderation teams of online communities that added a new technological platform with different social and technological affordances . While moderators of small Discord communities felt their work was manageable with the new platform’s built - in moderation tools , teams from large communities were challenged with content moderation at scale , managing community information , and organizing communication with their community members . We show that teams’ technological frames , drawn from their experience using Reddit’s moderation tools , influenced the strategic design and use of a Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 21 range of user innovations built using Discord’s API . These innovations took the form of bots that transformed features of Discord in ways that made the platform function like moderation tools available on Reddit . We discuss the consequences of technological change in online communities in terms of the organizational and governance systems that are reconstituted when users are given the tools to reconstruct their technological platform in ways that resemble familiar systems of governance . We argue that end user programming toolkits , like Discord’s API , can provide online communities with the building blocks to develop the tools to sustain growth and adapt to change . Designers can speculate as to how to best support users of a new system . Our work shows how , through user innovation driven guided by technological frames , users can build the systems they need through inspiration drawn from the systems they already know . ACKNOWLEDGMENTS This work was supported by the National Science Foundation ( awards IIS - 1617129 and IIS - 1617468 ) . Feedback and support for this work came from members of the Community Data Science Collective and from the University of Washington Department of Communication . The manuscript benefited from excellent feedback from several anonymous referees and associate chairs at CSCW . Lastly , we want to thank the moderators who participated in this study for sharing their experiences and stories with us and who , without their contributions , would not have made this work possible . REFERENCES [ 1 ] Thomas J . Allen . 1984 . Managing the flow of technology : Technology transfer and the dissemination of technological information within the R & D organization . MIT Press , Cambridge , MA . [ 2 ] Philip Anderson and Michael L . Tushman . 1990 . Technological discontinuities and dominant designs : A cyclical model of technological change . Administrative Science Quarterly 35 , 4 ( 1990 ) , 604 – 633 . https : / / doi . org / 10 . 2307 / 2393511 [ 3 ] Stephen R . Barley . 1986 . Technology as an occasion for structuring : evidence from observations of ct scanners and the social order of radiology departments . Administrative Science Quarterly 31 , 1 ( 1986 ) , 78 – 108 . https : / / doi . org / 10 . 2307 / 2392767 [ 4 ] Michael Barrett , Eivor Oborn , Wanda J . Orlikowski , and JoAnne Yates . 2011 . Reconfiguring boundary relations : Robotic innovations in pharmacy work . Organization Science 23 , 5 ( April 2011 ) , 1448 – 1466 . https : / / doi . org / 10 . 1287 / orsc . 1100 . 0639 [ 5 ] Wiebe E Bijker , Thomas Parke Hughes , and T . J Pinch ( Eds . ) . 1987 . The social construction of technological systems : New directions in the sociology and history of technology . MIT Press , Cambridge , MA . [ 6 ] Jeremy Blackburn and Haewoon Kwak . 2014 . Stfu noob ! : Predicting crowdsourced decisions on toxic behavior in online games . In Proceedings of the 23rd International Conference on World Wide Web ( WWW ’14 ) . ACM , New York , NY , USA , 877 – 888 . https : / / doi . org / 10 . 1145 / 2566486 . 2567987 [ 7 ] Erin Bradner . 2001 . Social affordances of computer - mediated communication technology : Understanding adoption . In CHI ’01 Extended Abstracts on Human Factors in Computing Systems ( CHI EA ’01 ) . ACM , New York , NY , USA , 67 – 68 . https : / / doi . org / 10 . 1145 / 634067 . 634111 [ 8 ] Virginia Braun and Victoria Clarke . 2006 . Using thematic analysis in psychology . Qualitative Research in Psychology 3 , 2 ( Jan . 2006 ) , 77 – 101 . https : / / doi . org / 10 . 1191 / 1478088706qp063oa [ 9 ] Brian S . Butler . 2001 . Membership size , communication activity , and sustainability : A resource - based model of online social structures . Information Systems Research 12 , 4 ( Dec . 2001 ) , 346 – 362 . https : / / doi . org / 10 . 1287 / isre . 12 . 4 . 346 . 9703 [ 10 ] Kathy Charmaz . 2015 . Constructing grounded theory : A practical guide through qualitative analysis ( 2nd ed . ) . SAGE , Thousand Oaks , California . [ 11 ] Nicole Crenshaw and Bonnie Nardi . 2016 . " It was more than just the game , it was the community " : Social affordances in online games . In Proceedings of the 49th Hawaii International Conference on System Sciences ( HICSS ’16 ) . IEEE Computer Society , Koloa , Hawaii , 3781 – 3790 . https : / / doi . org / 10 . 1109 / HICSS . 2016 . 471 [ 12 ] Elizabeth Davidson . 2006 . A Technological Frames Perspective on Information Technology and Organizational Change . The Journal of Applied Behavioral Science 42 , 1 ( March 2006 ) , 23 – 39 . https : / / doi . org / 10 . 1177 / 0021886305285126 [ 13 ] Bryan Dosono and Bryan Semaan . 2019 . Moderation practices as emotional labor in sustaining online communities : The case of AAPI identity work on Reddit . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI ’19 ) . ACM , New York , NY , USA , 142 : 1 – 142 : 13 . https : / / doi . org / 10 . 1145 / 3290605 . 3300372 Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . 44 : 22 Kiene et al . [ 14 ] Casey Fiesler , Jialun " Aaron " Jiang , Joshua McCann , Kyle Frye , and Jed R . Brubaker . 2018 . Reddit rules ! Character - izing an ecosystem of governance . In ICWSM . AAAI , North America , 72 – 81 . http : / / cmci . colorado . edu / ~ cafi5706 / icwsm18 - redditrules . pdf [ 15 ] Janet Fulk . 1993 . Social construction of communication technology . AMJ 36 , 5 ( Oct . 1993 ) , 921 – 950 . https : / / doi . org / 10 . 5465 / 256641 [ 16 ] William W . Gaver . 1991 . Technology affordances . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’91 ) . ACM , New York , NY , USA , 79 – 84 . https : / / doi . org / 10 . 1145 / 108844 . 108856 [ 17 ] William W . Gaver . 1992 . The affordances of media spaces for collaboration . In Proceedings of the 1992 ACM Conference on Computer - supported Cooperative Work ( CSCW ’92 ) . ACM , New York , NY , USA , 17 – 24 . https : / / doi . org / 10 . 1145 / 143457 . 371596 [ 18 ] R . Stuart Geiger . 2014 . Bots , bespoke , code and the materiality of software platforms . Information , Communication & Society 17 , 3 ( March 2014 ) , 342 – 356 . https : / / doi . org / 10 . 1080 / 1369118X . 2013 . 873069 [ 19 ] Tarleton Gillespie . 2010 . The politics of ‘platforms’ . New Media & Society 12 , 3 ( May 2010 ) , 347 – 364 . https : / / doi . org / 10 . 1177 / 1461444809342738 [ 20 ] Tarleton Gillespie . 2018 . Custodians of the Internet : Platforms , content moderation , and the hidden decisions that shape social media . Yale University Press , New Haven . [ 21 ] Erving Goffman . 1959 . The presentation of self in everyday life ( 1 ed . ) . Anchor , London . [ 22 ] James Grimmelmann . 2015 . The Virtues of Moderation . 17 Yale Journal of Law & Technology 42 ( 2015 ) . https : / / doi . org / 10 . 31228 / osf . io / qwxf5 [ 23 ] AaronHalfaker , R . StuartGeiger , JonathanT . Morgan , andJohnRiedl . 2013 . Theriseanddeclineofanopencollaboration system : How Wikipedia’s reaction to popularity is causing its decline . American Behavioral Scientist 57 , 5 ( May 2013 ) , 664 – 688 . https : / / doi . org / 10 . 1177 / 0002764212469365 [ 24 ] Lee Humphreys . 2010 . Technological determinism . In Encyclopedia of Science and Technology Communication . SAGE Publications , Inc . , Thousand Oaks , California , US . [ 25 ] Shagun Jhaver , Iris Birman , Eric Gilbert , and Amy Bruckman . 2019 . Human - machine collaboration for content regulation : The case of Reddit Automoderator . ACM Trans . Comput . - Hum . Interact . 26 , 5 ( July 2019 ) , 31 : 1 – 31 : 35 . https : / / doi . org / 10 . 1145 / 3338243 [ 26 ] Jialun " Aaron " Jiang , Charles Kiene , Skyler Middler , Jed R . Brubaker , and Casey Fiesler . 2019 . Moderation challenges in voice - based online communities on Discord . In Proc . ACM Hum . - Comput . Interact . ( CSCW ’19 ) , Vol . 3 . ACM , New York , NY , USA , 23 . https : / / doi . org / 10 . 1145 / 3359157 [ 27 ] Charles Kiene , Andrés Monroy - Hernández , and Benjamin Mako Hill . 2016 . Surviving an “Eternal September” : How an online community managed a surge of newcomers . In Proceedings of the 2016 ACM Conference on Human Factors in Computing Systems ( CHI ’16 ) . ACM , New York , NY , 1152 – 1156 . https : / / doi . org / 10 . 1145 / 2858036 . 2858356 [ 28 ] Robert E . Kraut , Paul Resnick , and Sara Kiesler . 2012 . Building successful online communities : Evidence - based social design . MIT Press , Cambridge , MA . [ 29 ] Cliff Lampe and Paul Resnick . 2004 . Slash ( dot ) and Burn : Distributed Moderation in a Large Online Conversation Space . In Conference on Human Factors in Computing Systems ( CHI ’04 ) . ACM , Vienna , Austria , 543 – 550 . https : / / doi . org / 10 . 1145 / 985692 . 985761 [ 30 ] Ganaele Langlois . 2013 . Participatory culture and the new governance of communication : the paradox of participatory media . Television & New Media 14 , 2 ( March 2013 ) , 91 – 105 . https : / / doi . org / 10 . 1177 / 1527476411433519 [ 31 ] Dorothy Leonard - Barton . 1988 . Implementation as mutual adaptation of technology and organization . Research Policy 17 , 5 ( Oct . 1988 ) , 251 – 267 . https : / / doi . org / 10 . 1016 / 0048 - 7333 ( 88 ) 90006 - 6 [ 32 ] Paul M . Leonardi and Stephen R . Barley . 2008 . Materiality and change : Challenges to building better theory about technologyandorganizing . InformationandOrganization 18 , 3 ( Jan . 2008 ) , 159 – 176 . https : / / doi . org / 10 . 1016 / j . infoandorg . 2008 . 03 . 001 [ 33 ] Angela Lin and Leiser Silva . 2005 . The social and political construction of technological frames . European Journal of Information Systems 14 , 1 ( March 2005 ) , 49 – 59 . https : / / doi . org / 10 . 1057 / palgrave . ejis . 3000521 [ 34 ] Zhiyuan Lin , Niloufar Salehi , Bowen Yao , Yiqi Chen , and Michael S . Bernstein . 2017 . Better when it was smaller ? Community content and behavior after massive growth . . In ICWSM . AAAI , North America , 132 – 141 . https : / / aaai . org / ocs / index . php / ICWSM / ICWSM17 / paper / view / 15628 [ 35 ] Adrienne Massanari . 2017 . # Gamergate and The Fappening : How Reddit’s algorithm , governance , and culture support toxic technocultures . New Media & Society 19 , 3 ( March 2017 ) , 329 – 346 . https : / / doi . org / 10 . 1177 / 1461444815608807 [ 36 ] J . Nathan Matias . 2016 . Going dark : Social factors in collective action against platform operators in the Reddit blackout . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems ( CHI ’16 ) . ACM , New York , NY , 1138 – 1151 . https : / / doi . org / 10 . 1145 / 2858036 . 2858391 [ 37 ] Marshall McLuhan . 1964 . Understanding media : The extensions of man . McGraw - Hill , New York , NY . Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 . Technological Frames and User Innovation 44 : 23 [ 38 ] Natalja Menold . 2008 . How to use information technology for cooperative work : Development of shared technological frames . Comput Supported Coop Work 18 , 1 ( Sept . 2008 ) , 47 . https : / / doi . org / 10 . 1007 / s10606 - 008 - 9083 - 6 [ 39 ] Jonathan T . Morgan and Aaron Halfaker . 2018 . Evaluating the impact of the Wikipedia teahouse on newcomer socialization and retention . In Proceedings of the 14th International Symposium on Open Collaboration ( OpenSym ’18 ) . ACM , New York , NY , USA , 20 : 1 – 20 : 7 . https : / / doi . org / 10 . 1145 / 3233391 . 3233544 [ 40 ] Bonnie A . Nardi . 1993 . A small matter of programming : Perspectives on end user computing . MIT Press , Cambridge , MA , USA . [ 41 ] Mancur Olson . 1965 . The logic of collective action : Public goods and the theory of groups . Harvard University Press , Cambridge , MA . [ 42 ] Wanda J . Orlikowski . 1992 . Learning from notes : Organizational issues in groupware implementation . In Proceedings of the 1992 ACM Conference on Computer - supported Cooperative Work ( CSCW ’92 ) . ACM , New York , NY , USA , 362 – 369 . https : / / doi . org / 10 . 1145 / 143457 . 143549 [ 43 ] Wanda J . Orlikowski . 1996 . Improvising organizational transformation over time : A situated change perspective . Information Systems Research 7 , 1 ( March 1996 ) , 63 – 92 . https : / / doi . org / 10 . 1287 / isre . 7 . 1 . 63 [ 44 ] Wanda J . Orlikowski . 2000 . Using technology and constituting structures : A practice lens for studying technology in organizations . Organization Science 11 , 4 ( Aug . 2000 ) , 404 – 428 . https : / / doi . org / 10 . 1287 / orsc . 11 . 4 . 404 . 14600 [ 45 ] Wanda J . Orlikowski and Debra C . Gash . 1994 . Technological frames : Making sense of information technology in organizations . ACM Trans . Inf . Syst . 12 , 2 ( April 1994 ) , 174 – 207 . https : / / doi . org / 10 . 1145 / 196734 . 196745 [ 46 ] Trevor J . Pinch and Wiebe E . Bijker . 1984 . The social construction of facts and artefacts : Or how the sociology of science and the sociology of technology might benefit each other . Soc Stud Sci 14 , 3 ( Aug . 1984 ) , 399 – 441 . https : / / doi . org / 10 . 1177 / 030631284014003004 [ 47 ] Joseph Seering , Juan Pablo Flores , Saiph Savage , and Jessica Hammer . 2018 . The social roles of bots : evaluating impact of bots on discussions in online communities . Proc . ACM Hum . - Comput . Interact . 2 , CSCW ( Nov . 2018 ) , 157 : 1 – 157 : 29 . https : / / doi . org / 10 . 1145 / 3274426 [ 48 ] Joseph Seering , Tony Wang , Jina Yoon , and Geoff Kaufman . 2019 . Moderator engagement and community devel - opment in the age of algorithms . New Media & Society 21 ( Jan . 2019 ) , 1417 – 1443 . Issue 7 . https : / / doi . org / 10 . 1177 / 1461444818821316 [ 49 ] Aaron Shaw and Benjamin Mako Hill . 2014 . Laboratories of oligarchy ? How the iron law extends to peer production . J Commun 64 , 2 ( 2014 ) , 215 – 238 . https : / / doi . org / 10 . 1111 / jcom . 12082 [ 50 ] Nancy Shaw , Lee - Partridge Eng , and James Ang . 1997 . Understanding end - user computing through technological frames . In Proceedings of the 18th International Conference on Information Systems . ICIS 1997 Proceedings , 37 . [ 51 ] Constance A . Steinkuehler and Dmitri Williams . 2006 . Where everybody knows your ( screen ) name : Online games as “third places” . Journal of Computer - Mediated Communication 11 , 4 ( Oct . 2006 ) , 885 – 909 . https : / / doi . org / 10 . 1111 / j . 1083 - 6101 . 2006 . 00300 . x [ 52 ] Ed Summers and Ricardo Punzalan . 2017 . Bots , seeds and people : Web archives as infrastructure . In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing ( CSCW ’17 ) . ACM , New York , NY , USA , 821 – 834 . https : / / doi . org / 10 . 1145 / 2998181 . 2998345 [ 53 ] Jeffrey W . Treem and Paul M . Leonardi . 2013 . Social media use in organizations : Exploring the affordances of visibility , editability , persistence , and association . Annals of the International Communication Association 36 , 1 ( Jan . 2013 ) , 143 – 189 . https : / / doi . org / 10 . 1080 / 23808985 . 2013 . 11679130 [ 54 ] Jan E . Trost . 1986 . Statistically nonrepresentative stratified sampling : A sampling technique for qualitative studies . Qual Sociol 9 , 1 ( March 1986 ) , 54 – 57 . https : / / doi . org / 10 . 1007 / BF00988249 [ 55 ] Michael L . Tushman and Philip Anderson . 1986 . Technological discontinuities and organizational environments . Administrative Science Quarterly 31 , 3 ( Sept . 1986 ) , 439 – 465 . http : / / www . jstor . org / stable / 2392832 [ 56 ] James M . Utterback . 1997 . Mastering the dynamics of innovation : How companies can seize opportunities in the face of technological change . Harvard Business School Press , Boston , MA , USA . [ 57 ] Eric von Hippel . 1988 . The sources of innovation . Oxford University Press , New York , NY . [ 58 ] Eric von Hippel . 2006 . Democratizing innovation . The MIT Press , Cambridge , MA , USA . [ 59 ] Eric von Hippel and Ralph Katz . 2002 . Shifting innovation to users via toolkits . Management Science 48 , 7 ( 2002 ) , 821 – 833 . http : / / www . jstor . org / stable / 822693 [ 60 ] LangdonWinner . 1980 . Doartifactshavepolitics ? Daedalus 109 , 1 ( 1980 ) , 121 – 136 . http : / / www . jstor . org / stable / 20024652 [ 61 ] Yvette Wohn . 2019 . Volunteer moderators in twitch micro communities : How they get involved , the roles they play , and the emotional labor they experience . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI’19 ) . ACM , Glasgow , UK . [ 62 ] Li - Yin Young . 2018 . The effect of moderator bots on abusive language use . In Proceedings of the International Conference on Pattern Recognition and Artificial Intelligence ( PRAI 2018 ) . ACM , New York , NY , USA , 133 – 137 . https : / / doi . org / 10 . 1145 / 3243250 . 3243257 Proceedings of the ACM on Human - Computer Interaction , Vol . 3 , No . CSCW , Article 44 . Publication date : November 2019 .