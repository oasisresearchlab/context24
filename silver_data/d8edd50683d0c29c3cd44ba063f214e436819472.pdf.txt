Get Mobile December 2017 | Volume 21 , Issue 4 16 [ HIGHLIGHTS ] CARD - STUNT AS A SERVICE : Empowering a Massively Packed Crowd for Instant Collective Expressiveness 17 December 2017 | Volume 21 , Issue 4 Get Mobile I ll u s t r a t i o n , i s t o c k p h o t o . c o m [ STANDARDS ] [ HIGHLIGHTS ] I magine a densely packed crowd with a common voice , such as people in a candlelight vigil or a protest . We envision an innovation through mobile computing technologies to empower such crowds . We present Card - stunt as a Service ( CaaS ) , a mobile service allowing them to instantly create a massive collective visualization by simply holding their phones up . The key challenge is to achieve instant , infrastructure - free , decimeter - level localization of individuals in a massively packed crowd , within a low latency . CaaS addresses the challenges by mobile visible - light sensing and scalable constrained optimization . Within less than a minute , each person is given individualized pixels so that they can do their part in the overall visualization * . Excerpted from “Card - stunt as a Service : Empowering a Massively Packed Crowd for Instant Collective Expressiveness , ” from MobiSys 2017 , Proceedings of the 15 th Annual ACM International Conference on Mobile Systems , Applications , and Services , with permission . https : / / dl . acm . org / citation . cfm ? id = 3081357 © ACM 2017 Consider a large crowd gathered in a public space to express a common voice to the community , e . g . , 100k + people participate in a candlelight vigil for a political protest [ 1 ] . Imagine they hold not candles but their phones ; each phone automatically glows on and off in a coordinated way so that all of the phones collectively visualize a massive symbol on top of the crowd . Why would we want it ? It will provide a new prominent medium empowering the crowd’s message and attracting the community to listen ; people will be able to express their messages in a more impactful and visually compelling way by blending their scattered banners and flags into a single massive one . Fundamentally , it would be an innovation in a sense that mobile computing technologies facilitate a new form of instant collaborative crowd activities in the real world , through which people can stimulate their communities . Such a mobile technology would serve not only public activism but also diverse collective visualization events , such as commercial promotions , flash mobs , and collective artworks . In our paper [ 2 ] , we propose Card - stunt as a Service ( CaaS ) , metaphorically named after the massive sport - supporting Chungkuk Yoo † KAIST , Daejeon , South Korea Inseok Hwang ‡ IBM Research , Austin , TX Seungwoo Kang KOREATECH , Cheonan , South Korea Myung - Chul Kim IBM Corporation , Austin , TX Seonghoon Kim and Daeyoung Won KAIST , Daejeon , South Korea Yu Gu Visa , Austin , TX Junehwa Song KAIST , Daejeon , South Korea Editors : Nic Lane and Xia Zhou * CaaS demonstration video is available . https : / / youtu . be / oGsmUaRxLzU † This work was done in part while the first author was on an internship at IBM Research – Austin . ‡ The corresponding author . Get Mobile December 2017 | Volume 21 , Issue 4 18 [ HIGHLIGHTS ] Alternatively , users may improvise physical cardboard with two sides colored differently as shown in Figure 1 ( bottom ) . CaaS can send timely cues to users’ phones , signaling them to flip the cardboards to achieve the same visualization . Our unique challenge to realize an instant collective visualization is how to achieve ( 1 ) infrastructure - free , ( 2 ) decimeter - level localization of individuals , ( 3 ) in a densely packed crowd , while ( 4 ) maintaining a low latency for people possibly scaling up to tens of thousands . We do not assume any localization infrastructure like beacons [ 13 ] , Wi - Fi access points [ 14 ] , or an omniscient camera [ 7 ] as those are unlikely in typical gathering places like public squares . Likewise , existing peer - to - peer localization schemes [ 4 ] [ 5 ] [ 6 ] are not an option , as the one - by - one pair - wise sensing is impractical for handling such a density of people . CaaS tackles those challenges through elaborate mobile - side visible - light angle - of - arrival ( AoA ) sensing and server - side constrained optimization . To ensure CaaS is suitable for real - world deployment , we carefully devise and implement : ( 1 ) fast and robust multi - target visual AoA observations under diverse lighting conditions , partial occlusions , and varying phone orientations when handheld , and ( 2 ) scalable and accurate computation strategies to reconstruct the optimal device locations given all the AoA observations . We built a working prototype and conducted extensive experiments to evaluate the step - by - step performances of CaaS under diverse conditions discussed above . We deployed CaaS to 49 co - located participants , where CaaS demonstrated successful reconstruction of individual locations at a typical error radius of 15 cm . FIGURE 1 . Small - scale demonstrations of CaaS with 49 participants . Top : Night mode with glowing phone screens . Bottom : Daylight mode with pieces of cardboard raised or flipped upon individual cues given to each user’s phone . FIGURE 2 . CaaS use case . activities that are seen in a stadium . CaaS is a new genre of mobile - crowd service to help densely packed crowds express their messages with impact . It enables a crowd to instantly and collectively visualize symbols using their mobile devices . For instance , Figure 1 demonstrates a small group of people using CaaS to perform small - scale , collective visualizations . Imagine a visualization of this kind created by a much larger number of people and at a higher people - per - symbol density . How would we realize a dynamic , high - quality collective visualization today without CaaS ? We refer to the process of planning a traditional card stunt ; it requires month - long planning for each venue , rehearsals for specific participants and , often , a significant budget to hire a professional production . Such a huge cost would be impractical for most people in our collective visualization scenarios . CaaS requires only smartphones ; as soon as a crowd packs into a place like a public square , CaaS lets them create collective visualizations instantly . CaaS automatically determines each user’s relative location within the crowd , divides a symbol into a 2 - D matrix of pixels , and assigns each pixel to the mobile device at the right location . Each device locally displays the assigned pixel in full - screen . To visualize time - varying symbols , each mobile device may be assigned a timed sequence of pixels . On occasions when sunlight is so strong that a phone’s display is indiscernible even at its full - brightness , CaaS may glow a phone’s flashlight instead at the visualization phase . C aa S IS A NEW GENRE OF MOBILE - CROWD SERVICE TO HELP DENSELY PACKED CROWDS EXPRESS THEIR MESSAGES WITH IMPACT Raise Transceive Assign Reconstruct smartphones overhead for a few seconds to maximize the line - of - sight chances among the devices . device IDs as hue transition sequences and measure AoAs between cameras and screens . pixels to each device and let them automatically perform collective visualization . all device locations by solving an optimization problem on the collected AoA observations . 19 December 2017 | Volume 21 , Issue 4 Get Mobile 0 2000 4000 6000 8000 10000 nz = 14374 0 2000 4000 6000 8000 10000 ( 1 ) ( 2 ) ( 3 ) ( 4 ) Observation loss [ HIGHLIGHTS ] VISION - BASED COLLECTIVE LOCALIZATION WITH CROWD COOPERATION For timely relative localization of all indi - viduals in a dense crowd with no infra - structure and no known reference locations , CaaS adopts visible - light AoA ( angle of arrival ) observations between cameras and displays of the participants’ phones , followed by server - side optimization . This offers key advantages to the CaaS context : multiple pairs can sense simultaneously while hardly interfering with each other . Most smartphone cameras have sufficiently good optical systems capable of high - precision AoA observation from a light source within their FoV ( field of view ) ; the multi - path issue is hardly a concern compared to wire - less - or sound - based sensing . Collectively processing mobile - side AoA observations , server - side optimization enables all devices’ relative locations to be reconstructed in an accurate and timely manner . Applying the approach of vision - based collective localization , we design CaaS for a densely packed crowd under the use case shown in Figure 2 . C aa S ARCHITECTURE The CaaS architecture consists of mobile applications and server - side services ( Figure 3a ) . Each instance of the CaaS Mobile Application observes local AoAs and displays the assigned pixels . The Server - side CaaS Service collects the observations , computes all devices’ relative locations , and determines the pixel for each device . C aa S MOBILE APPLICATION The CaaS Mobile Application provides a user with user interfaces to join a collective visualization event , view original symbols to be displayed in an event , and give individual cues to raise a phone overhead . Upon joining an event , the Symbol Sequence Transceiver retrieves a device - specific identifier ( ID ) from the server , encodes it into a hue - transition sequence ( Figure 3b ) , and displays the sequence on its screen . There are two reasons why we use the sequential code rather than a spatial code such as [ 8 ] [ 9 ] to encode an ID ; sequential codes are robust to partial occlusions in between the camera and screens , and device screens are seen too small in observers’ cameras . A 5 - inch screen at 6 meters away makes only a few pixels on an observer’s FoV . At the same time , transmitting an ID through a screen , the Symbol Sequence Transceiver detects and decodes other devices’ hue - transition sequences from the rear camera . For robust decoding under diverse lighting conditions , we manipulate exposure settings of the camera for three major outdoor lighting conditions : night , daylight - ambient , and daylight - backlight ( i . e . , camera faces the sun ) . Overall , we achieve low packet error rates under diverse lighting conditions at a distance , i . e . , less FIGURE 3 . CaaS architecture and its key features . ( a ) CaaS Architecture ( d ) Feasible region ( c ) Partition Planning ( b ) Observing AoA Get Mobile December 2017 | Volume 21 , Issue 4 20 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 8 0 1 2 3 4 5 6 7 8 FIGURE 4 . Reconstruction performance evaluation settings and results . Blue hollow circle ( ) : ground - truth locations ; Red solid circle ( ) : CaaS - reconstructed locations . ( a ) Uniform spacing in night ( b ) Variable spacing in daytime than 10 % until 9 meters at night , less than 5 % until 6 meters under daylight . After decoding each ID , the AoA Observer measures its AoA from its on - image location and applies sensor compensations . In Figure 3b , the AoA θ ij can be computed with given parameters from Android APIs [ 2 ] [ 3 ] . Note that a device held in a user’s hand would have nonzero orientation angles α x , α y , α z values in Figure 3b . We standardize the varying orientations by the phones’ inertial sensors [ 10 ] . We evaluate AoA errors under real handheld conditions ; the average AoA error was 1 . 23° ( σ = 1 . 03° ) . The decoded IDs and AoA values are sent to the server . The Visualizer displays the pixels assigned to the device by the server . SERVER - SIDE C aa S SERVICE The Observation Collector collects the mobile - side observations . Once collection is done , the Crowd Reconstructor computes individual devices’ relative locations using the observations . To achieve this , our Parallelized Optimization Problem Builder builds a constrained optimization problem describing the optimal locations of the devices for the given observations . To ensure high - quality visualization within an interactive latency acceptable to the on - site participants , we designed two sets of constrained optimization problems . One is based on a nonpolynomial cost function exhibiting highly accurate localization results at a typical spatial error of a few centimeters but rapidly growing computation time along the number of people . The other is based on a quadratic cost function , exhibiting a typical spatial error of a few decimeters but much slower - growing computation time by at least two orders of magnitude . The rationale is that a larger number of people are able to visualize at a higher pixels - per - symbol density , making the visualization less sensitive to subtle spatial errors . In spite of each AoA observation lacking the distance to the target , we note that the target would exist within a spatially bounded region , which can be derived from the mobile sensor ' s intrinsic error ranges , a physical limitation on the observable distance , and the minimal nonoverlapping inter - personal distance . We define the optimization constraints accordingly as in Figure 3d . We found through emulations that even the quadratic optimization takes more than a minute of computation time for a crowd of 5000 people or more , on a moderate desktop - grade hardware . To keep the computation time scalable to the growth of the crowd , the Parallelized Optimization Problem Builder also intelligently divides the problem into smaller pieces and invokes one or more Solver Instances to compute them in parallel . We use the RCM reordering [ 11 ] to find smaller partitions of people who have high intra - partition observations but limited inter - partition dependencies ( see Figure 3c ) . This strategy is very effective , e . g . , completing the reconstruction for 40000 people in 7 . 52 seconds at a mean spatial error of only 24 centimeters through parallel computation with 32 Solver Instances . C aa S DEPLOYMENT WITH 49 PARTICIPANTS We conducted small - scale deployments using CaaS to reconstruct a crowd of 49 participants and demonstrate CaaS - guided collective visualization . We deployed twice – once under daylight ( 73200 lux ) and another time at night . The phone models included Nexus ( 5 , 6 , 5X , 6P ) and Galaxy ( S6 , Note5 ) with display sizes of 4 . 95 to 5 . 96 inches and camera’s horizontal FoVs of 59 . 6° to 68 . 1° . We demonstrate scenarios in which those 49 participants collectively visualize one letter at a time with their phones ( at night ) or cardboard ( under daylight ) . Each person was responsible for one of the 49 pixels . To measure the localization accuracy , we asked the participants to stand on 7 × 7 grids with 75 cm spacing ( Figure 4a ) . We also conducted variably spaced cases ; [ HIGHLIGHTS ] 21 December 2017 | Volume 21 , Issue 4 Get Mobile each participant stood on a random grid point of their choice out of 81 points of a 9 × 9 grid ( Figure 4b ) . Importantly , the ground truth locations of the phones are not aligned on the grids in either case . Each phone is handheld , so that there is a random displacement from the center of the human body . We manually labeled the ground truth locations as seen in the snapshots . As shown in Figure 4 , under all conditions , the average localization errors were less than 15 cm . Using CaaS , as shown in Figure 1 , participants successfully performed a collective visualization for “MOBISYS” under both lighting conditions . CONCLUSION We present Card - stunt as a Service ( CaaS ) , a service enabling a densely packed crowd to instantly visualize symbols collectively using their mobile devices and server - side services . CaaS features novel robust mobile visual observation and scalable optimization techniques to achieve high - density , infrastructure - free , and fast crowd reconstruction in real environments . Our implementation is robust and effective , demonstrating decimeter - level accuracies in real 49 - person deployments , regardless of the devices’ orientation and placement , and of lighting conditions . Our scalable computing strategy exhibits steadily low computing time even for emulated groups of tens of thousands of devices . Beyond our main scenarios , CaaS would open up creative opportunities for people to express their ideas in a massive and prominent way . n Chungkuk Yoo is pursuing a PhD in School of Computing at KAIST . Within the broad spectrum of mobile computing , his research interests lie in mobile applications for in - situ social interaction in real world . He is also interested in mobile systems for visual sensing and recognition . Inseok Hwang is a Research Staff Member at IBM Research , Austin , TX , and an IBM Master Inventor . His current research focus is sensory cognitive systems on mobile / embedded platforms . He received his PhD in Computer Science from KAIST . He is a recipient of the Best Paper Award at ACM CSCW . Seungwoo Kang is an assistant professor in the School of Computer Science and Engineering , KOREATECH . He received a PhD in computer science from KAIST . His research interests include mobile and ubiquitous computing , power - aware context sensing , and IoT systems . His focus is on building novel mobile systems and applications . Myung - Chul Kim received his PhD degree in Electrical Engineering from University of Michigan . His research interests span multi - objective / combinatorial optimization for electronic design automation ( EDA ) . He is the recipient of the Best Paper Award at IEEE / ACM ICCAD with three BPA nominations . He is currently with IBM . Seonghoon Kim is a PhD student in the School of Computing , KAIST . His research interests include mobile and pervasive computing systems , context - aware and ubiquitous services , social and crowd computing services and rural computing . Daeyoung Won is a PhD student at KAIST . His research interests include human computer interaction , social computing , and embodied connection . Yu Gu is a lead engineer at Visa . Previously he was a research scientist for IBM Watson Health / IBM Research Austin from 2014 to 2017 , and an assistant professor at Singapore University of Technology and Design from 2010 to 2014 . He is author and co - author of more than 100 peer - reviewed papers . Junehwa Song is a professor at the School of Computing and KAIST Endowed Chair Professor , KAIST . Previously , he was a Research Staff Member at IBM T . J . Watson Research Center , Yorktown Heights , NY . He received his PhD in Computer Science from University of Maryland at College Park in 1997 . REFERENCES [ 1 ] South Korean protesters march against president again . http : / / edition . cnn . com / 2016 / 11 / 12 / asia / south - korean - protest - president - park [ 2 ] Yoo , C . , Hwang , I . , Kang , S . , Kim , M . C . , Kim , S . , Won , D . , . . . & Song , J . ( 2017 , June ) . “Card - stunt as a service : Empowering a massively packed crowd for instant collective expressiveness . ” In Proceedings of the 15th Annual International Conference on Mobile Systems , Applications , and Services ( pp . 121 - 135 ) . ACM [ 3 ] Yoo , C . , Hwang , I . , Rozner , E . , Gu , Y . , & Dickerson , R . F . ( 2016 , May ) . SymmetriSense : Enabling near - surface interactivity on glossy surfaces using a single commodity smartphone . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems ( pp . 5126 - 5137 ) . ACM [ 4 ] Peng , C . , Shen , G . , Zhang , Y . , Li , Y . , & Tan , K . ( 2007 , November ) . Beepbeep : A high accuracy acoustic ranging system using cots mobile devices . In Proceedings of the 5th international conference on embedded networked sensor systems ( pp . 1 - 14 ) . ACM . [ 5 ] Vasisht , D . , Kumar , S . , & Katabi , D . ( 2016 , March ) . Decimeter - level localization with a single WiFi access point . In Proceedings of the 13th Usenix Conference on Networked Systems Design and Implementation ( pp . 165 - 178 ) . USENIX . [ 6 ] Hwang , I . , Jang , H . , Park , T . , Choi , A . , Lee , Y . , Hwang , C . , Choi , Y . , Nachman , L . , & Song , J . ( 2012 , June ) . Leveraging children’s behavioral distribution and singularities in new interactive environments : Study in kindergarten field trips . In Proceedings of the 10th International Conference on Pervasive Computing ( pp . 39 - 56 ) . Springer . [ 7 ] Schwarz , J . , Klionsky , D . , Harrison , C . , Dietz , P . , & Wilson , A . ( 2012 , May ) . Phone as a pixel : enabling ad - hoc , large - scale displays using mobile devices . In Proceedings of the SIGCHI Conference on Human factors in Computing Systems ( pp . 2235 - 2238 ) . ACM . [ 8 ] Hermans , F . , McNamara , L . , Sörös , G . , Rohner , C . , Voigt , T . , & Ngai , E . ( 2016 , June ) Focus : Robust visual codes for everyone . In Proceedings of the 14th ACM International Conference on Mobile Systems , Applications , and Services ( pp . 319 - 332 ) . ACM . [ 9 ] Hao , T . , Zhou , R . , & Xing , G . ( 2012 , June ) . Cobra : color barcode streaming for smartphone systems . In Proceedings of the 10th International Conference on Mobile Systems , Applications , and Services ( pp . 85 - 98 ) . ACM . [ 10 ] Zhou , P . , Li , M . , & Shen , G . ( 2014 , September ) . Use it free : Instantly knowing your phone attitude . In Proceedings of the 20th Annual International Conference on Mobile Computing and Networking ( pp . 605 - 616 ) . ACM . [ 11 ] Cuthill , E . , & McKee , J . ( 1969 , August ) . Reducing the bandwidth of sparse symmetric matrices . In Proceedings of the 1969 24th national conference ( pp . 157 - 172 ) . ACM . [ 12 ] Li , T . , Liu , Q . , & Zhou , X . ( 2016 , June ) . Practical human sensing in the light . In Proceedings of the 14th Annual International Conference on Mobile Systems , Applications , and Services ( pp . 71 - 84 ) . ACM . [ 13 ] Liu , K . , Liu , X . , & Li , X . ( 2013 , June ) . Guoguo : Enabling fine - grained indoor localization via smartphone . In Proceedings of the 11th Annual International Conference on Mobile Systems , Applications , and Services ( pp . 235 - 248 ) . ACM . [ 14 ] Mariakakis , A . T . , Sen , S . , Lee , J . , & Kim , K . H . ( 2014 , June ) . Sail : Single access point - based indoor localization . In Proceedings of the 12th Annual International Conference on Mobile Systems , Applications , and Services ( pp . 315 - 328 ) . ACM . [ HIGHLIGHTS ]