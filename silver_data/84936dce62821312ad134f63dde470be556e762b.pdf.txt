XXX - X - XXXX - XXXX - X / XX / $ XX . 00 ©20XX IEEE Leveraging the Potential of Generative AI to Accelerate Systematic Literature Reviews : An Example in the Area of Educational Technology Pablo Castillo - Segura Department of Telematics Engineering Universidad Carlos III de Madrid Leganés , Spain ORCID : 0000 - 0003 - 4176 - 9580 Carmen Fernández Panadero Department of Telematics Engineering Universidad Carlos III de Madrid Leganés , Spain ORCID : 0000 - 0003 - 4855 - 2923 Carlos Alario - Hoyos Department of Telematics Engineering Universidad Carlos III de Madrid Leganés , Spain ORCID : 0000 - 0002 - 3082 - 0814 Carlos Delgado Kloos Department of Telematics Engineering Universidad Carlos III de Madrid Leganés , Spain ORCID : 0000 - 0003 - 4093 - 3705 Abstract — Generative Artificial Intelligence ( AI ) is dramatically changing the way people work in many industries , including academia . Beyond its use for teaching , generative AI can also have a major impact on accelerating research processes . For example , generative AI can facilitate the identification of relevant articles when conducting a systematic literature review ( SLR ) . This article compares six AIs ( Forefront , GetGPT , ThebAI , Claude , Bard , and H2O ) with their respective large language models ( LLMs ) when classifying 596 articles in the screening phase of an SLR . This SLR is aimed at exploring the development of non - technical skills with the support of technology in the field of medical education . Forefront with the LLM GPT - 4 was the AI that obtained better results . The impact of this research is expected to contribute towards automating some of the phases of SRLs . Nevertheless , it is important to keep in mind limitations associated with the technology used to support this research , such as the rapid changes that AIs and their LLMs are currently undergoing , or potential restrictions on the number of requests per minute that AIs can receive as well as restrictions on the geographical location ( since not all these AIs are available in all countries ) . Keywords — Generative AI , large language models ( LLMs ) , systematic literature review ( SLRs ) , screening phase , educational technology I . I NTRODUCTION Generative Artificial Intelligence ( AI ) has been a breakthrough over the past few months , especially since the release of ChatGPT [ 1 ] by OpenAI [ 2 ] on November 30 , 2022 [ 3 ] . ChatGPT demonstrated , for the first time , that an AI could have strong conversational capabilities , being able to engage in text - based dialogue similar to human conversation on a variety of topics [ 4 ] . The fact that OpenAI decided to release ChatGPT with the large language model ( LLM ) GPT3 . 5 for open use and then , in March 2023 , to release GPT4 to be used from ChatGPT at a reduced cost of $ 20 per month meant that many people around the world could test and share different scenarios and use cases , which helped to increase the popularity of this tool in particular and of generative AI in general [ 5 ] . Nevertheless , ChatGPT is far from perfect , as it sometimes makes up answers when it does not know them , suffering from the so - called hallucinations [ 6 ] , and also has biases due to the data used for training the LLMs ChatGPT uses [ 7 ] . A recent study even reported a decrease in the performance of ChatGPT with GPT - 4 over time in the case of some types of tasks [ 8 ] . Nevertheless , the most important lesson learned , however , is that ChatGPT showed the potential for generative AI to transform many industries by automating routine tasks [ 9 ] . One of the industries that is most likely to suffer from the transformation initiated by ChatGPT and generative AI is education [ 10 ] . For example , this technology can help teachers to better plan their courses and lessons , facilitate the creation of content ( videos , podcasts , slides , etc . ) , facilitate the generation of formative and summative assessment activities ( quizzes , assignments , etc . ) and even facilitate the grading of students’ work and the provision of feedback , becoming a kind of virtual teaching assistant for professors [ 11 ] [ 12 ] . Generative AI can also be useful to help students , acting as a tutor available 24 / 7 , providing explanations adapted to the student’s knowledge level , or complementary activities to reinforce learning [ 12 ] [ 13 ] . Nevertheless , there are also risks associated with the misuse of generative AI in education . Actually , the main debate on the impact of generative AI in education after the release of ChatGPT focused on the potential of this technology for students to cheat when submitting assignments or doing exams , as generative AI has proven very efficient to write essays or solve complex problems in just a few seconds [ 14 ] [ 15 ] . Nonetheless , the information provided by generative AI is not necessarily correct and verification and critical thinking skills are required by the students to avoid accepting incorrect information as valid . This is an open debate between universities that currently choose to restrict the use of generative AI , returning to written exams with pen and paper and oral exams , and those universities that choose to teach how to properly use generative AI to better prepare students for their future work [ 16 ] . Beyond misuse and misinformation , other risks of generative AI in education include privacy breaches ( in relation to student data ) , decreased human 2023 W o r l d E ng i n ee r i ng E du ca ti on F o r u m - G l ob a l E ng i n ee r i ng D ea n s C oun c il ( W EE F - G E D C ) | 979 - 8 - 3503 - 1602 - 5 / 23 / $ 31 . 00 © 2023 I EEE | DO I : 10 . 1109 / W EE F - G E D C 59520 . 2023 . 10344098 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . interaction ( especially when working in groups if the initial answer provided by the AI is assumed to be correct ) , and accessibility issues ( by making this technology more easily available to some students and not to others ) [ 17 ] . The impact of generative AI on academia does not only affect teaching , but also affects research [ 18 ] . For example , generative AI can assist in different phases of research such as generating ideas , framing relevant research questions , synthesizing the related state of the art , performing data analysis , drawing conclusions , or improving manuscript writing , among others [ 19 ] . Generative AI can also support the editorial processes of article review , accelerating the publication of papers as the bottleneck is often in finding appropriate reviewers . All this opens new challenges and opportunities that require the definition of appropriate policies and ethical guidelines , from how to properly cite the use of generative AI tools when writing a paper [ 20 ] , [ 21 ] , or what happens when incorrect information is presented in a paper due to the use of generative AI ( including for example the use of non - existent references ) [ 22 ] , among many others . Various publishers and journals have already published guidelines with instructions for authors on how to use generative AI in academic and scientific publishing [ 23 ] . In any case , the potential of generative AI to enhance the research and publication process seems clear . Among all the phases of scientific and academic research one where significant automation can take place and therefore can benefit the most from the use of generative AI is the realization of a systematic literature review ( SLR ) [ 24 ] [ 25 ] . The aim of this article is to contribute to demonstrate the potential of generative AI tools to accelerate the realization of SLRs . In particular , once an initial set of articles on a given topic is obtained through queries in the usual research databases ( Scopus , Web of Science . . . ) , the aim is to see to what extent generative AI tools can help in the screening phase , selecting or discarding articles based on their abstract . This raises the research question of what is the accuracy that can be obtained with different AIs and their corresponding LLMs when selecting or discarding articles as part of SLRs compared to the processing of human experts ? An experiment is conducted within the scope of an SLR in the area of educational technology , specifically in relation to the training of medical personnel in non - technical skills with the support of technology . Six AIs with their corresponding LLMs are used ( Forefront with GPT - 4 [ 26 ] GetGPT with GPT - 3 . 5 turbo [ 27 ] , ThebAI with GPT - 3 . 5 turbo [ 28 ] , Claude with Claude 2 [ 29 ] , Bard with LaMDA [ 30 ] , and H2O with falcon - 40b [ 31 ] ) . Finally , it is important to mention that the experiment is conducted between June and July 2023 , which is relevant due to the fast pace in which generative AI is evolving . The rest of this article is structured as follows . The next section discusses the role of AI in accelerating research processes in academia introducing some relevant related tools . Next , there is a description of the methodology used , including the SLR conducted , the classification process followed , and the six generative AIs used with their corresponding LLMs . The results obtained with the six AIs are then presented and discussed including several metrics to determine the best performers . The limitations of the experiment are highlighted in the following section . The last section draws the conclusions and outlines some lines of future work . II . AI T OOLS FOR R ESEARCH The amount of research papers is growing at increasing speed . Therefore , it is difficult to keep track of the relevant literature for a particular topic . What are the main insights of each paper ? Moreover , how to make sure the claims posed in the papers are based on evidence ? LLMs are good in analyzing large quantities of text . Therefore , no wonder that there are several AI tools focusing on research literature and helping researchers navigate it [ 18 ] [ 25 ] [ 32 ] . For instance , ResearchRabbit [ 33 ] announces itself as a Spotify for papers . You can build your own collection of papers and the system recommends additional relevant papers for this collection . Interactive visualizations present the papers in form of a graph to conveniently navigate the collections . These visualizations also include , for example , the connections between authors . But what are the main insights of the papers ? Consensus [ 34 ] can help with that . It uses AI to highlight the insights in papers . You can ask a research question and get the answer from papers already published . Elicit [ 35 ] also helps in extracting key information from papers , apart from helping to find relevant papers and assisting with brainstorming , summarization , and text classification . Then , there are applications that allow to interact with PDFs and to question them , being the PDF format the most widely used in scientific publications . A specific application is ChatPDF [ 36 ] , a general purpose one is Claude [ 29 ] . Summarization is also a feature generally found in generative AI applications . This allows to rapidly extract the main insights of a paper . Asking to rephrase or changing the tone of a text can also help in better understanding these insights . Scite [ 37 ] allows to see how a paper has been cited . It provides the context of the citation and a classification describing whether it provides supporting or contrasting evidence for the cited claim . In addition , as with the previous tools , it is also useful for obtaining answers to questions supported by published articles . There are many more applications , like Scholarcy ( to summarize articles ) [ 38 ] , Inciteful ( to find relevant literature on a certain topic ) [ 39 ] , Scispace ( to explain complex academic text with simple words ) [ 40 ] , with more coming out continuously . They are specialized in handling research papers , but often are not based on the latest versions of the available LLMs . For instance , Elicit is based today on GPT - 3 . Although this may change any day , it makes sense using general purpose LLMs and fine - tune them with adequate prompts . Then , there are also of interest other features of LLMs that are useful for any document ( including , of course , scientific articles ) , such as correction of orthographic and grammatical errors [ 41 ] , change of tone to make the sentences and paragraphs sound more professional , translations if needed , etc . [ 42 ] . Some examples are Wordtune [ 43 ] or Grammarly [ 44 ] , among many others . There are also many other specific tasks in the research domain in which LLMs and AI tools can be helpful . In the case of this paper , the focus is on the appropriate classification of articles based on their abstract . This classification is made within the process known as screening as part of an SLR and consists of selecting or discarding the articles initially obtained on a certain topic from queries in scientific Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . databases . Six AIs with their respective LLMs are tested to determine their accuracy , among other relevant metrics , in this specific research task to assess whether it is worthwhile to use this technology when conducting SLRs . III . M ETHODOLOGY This section presents the methodology used to answer the research question of the accuracy that can be obtained with different AI tools and their LLMs when selecting or discarding articles as part of an SLR . The section starts by describing the SLR used as an example for this research . The classification process for articles is then presented , in particular , the Python script developed to invoke the AI tools and the corresponding prompt are described . Then the AI tools and LLMs used are presented . A . Systematic Literature Review The experiment stems from the realization of a systematic literature review ( SLR ) in the area of educational technology . This SLR aims to provide insights on how technology , in particular IoT ( Internet of Things ) , can contribute in the automation and objective assessment of non - technical skills on group physical tasks with a focus on medical training . Since this type of scenarios are usually related to learning , some terms needs to be clarified first : 1 ) “non - technical skill” is defined as the cognitive , behavioral , motivational , emotional and interpersonal skills needed by a learner during any physical task [ 45 ] ; and 2 ) “objective assessment” is defined as the measurement and evaluation of non - technical skills , usually collected by sensors and calculated by algorithms . This SLR was presented following the recommendations of PRISMA ( Preferred Reporting Items for Systematic Reviews and MetaAnalysis ) statement [ 46 ] . Previous literature reviews about non - technical skills were examined to identify keywords often used in scenarios related to the development of non - technical skills [ 47 ] [ 48 ] [ 49 ] . The most commonly used terms are : collaboration , coordination , cooperation , leadership , teamwork , stress , situation awareness , resilience , decision making , and emotional regulation . Several SLRs about objective measurement of non - technical skills were also examined [ 51 ] [ 52 ] [ 53 ] . Some of the sensors used for measuring non - technical skills are physiological devices ( e . g . , EEG - Electroencephalogram ) , eye tracking , cameras , microphones , etc . Cha & Yu [ 54 ] already presented an SLR about objective measurement of non - technical skills in surgeons , and screened more than 15 , 000 papers using one large query in different scientific databases . Nevertheless , in this SLR , multiple smaller queries that complement each other were executed in the database Scopus to avoid creating a wide query . These individual searches are based on the different non - technical skills terms that were found in the SLRs . 2 , 624 papers were identified after performing all queries in Scopus . 187 duplicated papers were removed in the first step . Afterwards , and according to PRISMA guidelines , the papers need to be screened , reading their abstracts , excluding papers that are out - of - scope and including the ones within the scope of the SLR . This classification process was automated by testing some AI tools with the abstracts of 596 randomly selected papers ( 22 . 7 % ) ; initially 600 papers were selected but 4 of them had an empty abstract and were discarded . Fig . 1 shows this specific PRISMA process highlighted in yellow . Fig . 1 . PRISMA guidelines . AI tools can help in the process highlighted in yellow as part of the screening phase . B . Classification process All the results from the individual queries in Scopus were stored in BibTex format [ 55 ] . The information exported from Scopus was the following : author , title , year , DOI , and abstract . Additionally , Scopus added these parameters : type of document ( e . g . , article or conference ) , the identifier of the paper ( i . e . , author - year ) , and the Scopus URL . A Python script was developed with the aim of asking several AIs if these abstracts were within or outside the scope of the SLR . For some of the tested AIs ( i . e . , Forefront , GetGPT , ThebAI , H2O and Google Bard ) , the script uses the gpt4free library [ 56 ] . This python library collects all the scripts to request information from different online AI tools . Most of the AIs available in the library do not require any authentication to use them ( e . g . , GetGPT , H2O ) , which facilitates the automatic classification process . Some other AI tools provided by the library allow configuring some parameters in the requests such as the “frequency penalty” , “presence penalty” , “temperature” or “Top P” ( e . g . , GetGPT ) . Although these parameters control the likelihood of GetGPT to repeat the same response and its randomness [ 57 ] , for these tests the default values were used . The other AIs tested did not allow changing these attributes in the requests . In the case of Claude , the script uses the unofficial claude - api library [ 58 ] . The python script supports the selection of the folder in which the BibTex files are located and the AI with which the tests will be performed . Once both parameters are selected , the script iterates over the . bib files and sends a request to the specified AI to classify the abstracts . The following aspects were taken into account to create the prompt used in the queries : 1 ) the tested AI tools use conversational models oriented to text analysis ; 2 ) these AI tools work with deep learning techniques , which makes it difficult to keep track of how the response was obtained ; and 3 ) classification problems previously identified by the research team are avoided . The review of these three points leads to the following prompt : “Answer only with YES or NO if the follo wing text talks about how to measure non - technical skills ( e . g . , collaboration , coordination , cooperation , leadership , teamwork , stress , situation awareness , resilience , decision making or emotional regulation ) with objective measurements ( e . g . , EEG , eye tracking , microphone , audio recordings , physiological sensors , or multimodal data ) while doing a physical task . Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Then , justify your answer in 2 sentences : ” . Each part of the prompt is explained in detail below : a ) Answer only with YES or NO if the following text : An output with only YES or NO is requested to the AI , instead of requesting a summary , since a binary classifier is needed . b ) talks about how to measure non - technical skills ( e . g . , collaboration , coordination , cooperation , leadership , teamwork , stress , situation awareness , resilience , decision making or emotional regulation ) : The AI is asked to discriminate whether or not the item belongs to a specific topic : “objectively measure non - technical skills on physical tasks” , but some examples are provided related with non - technical skills ( e . g . , collaboration , leadership , stress , decision making , etc . ) . Keywords obtained from other SLRs were provided on these examples [ 47 ] [ 48 ] [ 49 ] which , based on the reviewers experience , are known to be usually included in papers as specific terms , instead of just using the general term “non - techn ical skills” [ 50 ] . c ) with objective measurements ( e . g . , EEG , eye tracking , microphone , audio recordings , physiological sensors , or multimodal data ) while doing a physical task : Some examples are also included in the prompt to correctly classify papers that are related only to how to objectively measure non - technical skills ( e . g . , EEG sensor , eye tracking , microphone , etc . ) . Since there are no general terms to define this topic , some keywords found in other SLRs were provided as specific terms [ 51 ] [ 52 ] [ 53 ] . d ) Then , justify your answer in 2 sentences : The AIs tested for this process are trained with Neural Networks , so it is difficult to understand which process the AI used to generate the response . This part of the prompt provides insight into the process the AI followed for each request . e ) Abstract : Finally , the abstract of each paper is given at the end of the prompt so that the AI could read it and interpret it . After receiving the result of the request , the script dumps it into an Excel file and waits a sleeping time before sending another request to the AI . The sleeping time is crucial , since some AIs get blocked if the frequency of queries is high . Before running the tests with all the abstracts , the maximum number of requests per minute that each AI accepts until it blocks is checked . Theb is configured with a sleeping time of 1 second ( i . e . , 60 requests per minute ) , H2O with 3 seconds ( 20 requests per minute ) , Claude with 10 seconds ( 6 requests per minute ) , Bard with 60 seconds ( 1 request per minute ) and GetGPT with 120 seconds ( 1 request every 2 minutes ) . Also , each result is saved as soon as it is received from the AI . Otherwise , the AI could get blocked because of the maximum number of requests per minute and throw an error , causing the script to lose all the answers provided until that moment . The last step of the classification process is to obtain the accuracy of the answers . 596 abstracts are analyzed and manually classified by the research team , so that they can be automatically compared with the classification results provided by the AIs . For this purpose , another script collects all the results from the different AIs and determines the classification based on their responses . Even though most of the AIs respond directly with “YES” or “NO” before writing the justification , others do not . This script is also in charge of dealing with responses such as “the text does not talk about it” or responses that are not clear , such as “I am sorry but I do not understand your question” , “As an AI , I am not able to . . . ” or ‘Based on my training data , I cannot find evidence . . . ” . Finally , the results are sorted and the accuracy and some additional metrics are calculated . C . AI Tools The automatic classification process explained on the previous section was supported by six different AIs , which use different LLMs : Forefront [ 26 ] ( model GPT - 4 ) ; GetGPT [ 27 ] & Theb [ 28 ] ( model GPT - 3 . 5 turbo ) ; Claude [ 29 ] ( model Claude 2 ) ; Bard [ 30 ] ( model LaMDA ) ; H2O [ 31 ] ( model falcon - 40b ) . GetGPT and Theb use GPT - 3 . 5 turbo , while Forefront uses GPT - 4 . Both LLMs were developed by OpenAI [ 2 ] , but GPT4 is a much more complex model ( more than 175 billion parameters ) and was trained with a larger database . Also , it showed better results than GPT - 3 . 5 on many tasks ( e . g . , solving exams ) [ 59 ] . LaMDA is a model created by Google that was published in 2020 [ 60 ] . Google Bard was announced in February 2023 and it is still on experimental phase [ 61 ] . H2O uses Falcon , which is a LLM developed by Technology Innovation Institute . In its latest version ( i . e . , Falcon - 40b ) Falcon uses part of other LLMs training computes , such as GPT - 3 or PaLM , which is another model developed by Google [ 62 ] . Claude 2 was built by Anthropic [ 63 ] . IV . R ESULTS Some metrics of the confusion matrix were calculated with the aim of measuring the performance between the AI classification results : 1 ) “True Positive” ( TP ) measures the percentage of papers that the AI and the research team classified as within scope ; 2 ) “True Negative” ( TN ) measures the percentage of papers that the AI and the research team classified as out - ofscope ; 3 ) “False Positive” ( FP ) measures the percentage of papers that the AI classified as in - scope whereas the manual classification by the research team classified as out - of - scope ; 4 ) “False Negative” ( FN ) measures the percentage of papers that the AI classified as out - of - scope whereas the manual classification by the research team classified as in - scope ; 5 ) “Empty result” ( ER ) measures the percentage of papers that were manually classified by the research team but for which the AI could not provide a “YES” or “NO” answer ( the response is e . g . , “I do not understand your question” ) . The metrics of the classification process for each AI tool are detailed in Table I . Parameters in bold are required to be optimized for this case . The sum of TP , TN , FP , FN , and ER refers to the percentage of total number of papers ( 596 ) in all cases . It is important to bear in mind that the manual classification of the research team detected a significantly higher number of articles that should be discarded ( 481 80 . 7 % ) compared to those that should be selected ( 115 - 19 . 3 % ) . Additional metrics were used to compare the performances of each AI tool . These performance metrics are “Precision” ( Prec ) , “Negative Prediction” ( Neg Pred ) , “Sensitivity” ( Sens ) , “Specificity” ( Spec ) , “Accuracy” ( Acc ) and “F - measure” ( Fmeas ) . These additi onal performance metrics were calculated based on Table II . Prec is an indicator of the number of correct papers out of all papers classified as Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . in - scope . Neg Pred is an indicator of the number of correct papers out of all papers classified as out - of - scope . Sens measures the papers correctly classified as in - scope out of all those in - scope . Spec measures the papers correctly classified as out - of - scope out of all those out - of - scope . Acc is defined as the percentage of papers correctly classified out of all the papers . F - meas is an indicator of the tests’ accuracy , calculated with the harmonic mean of Prec and Sens . It is worth mentioning that empty results ( ER ) were not taken into account for the calculation of these performance metrics . TABLE I . M ETRICS OF R ESULTS FOR E ACH AI T OOL ( % ) TABLE II . D EFINITION OF P ERFORMANCE M ETRICS Some aspects of the metrics should be clarified before analyzing the results . If TP and TN are high the model is good . Nevertheless , this needs to be complemented by a low FN , which means that not so many papers are discarded even when they should be included in the scope . If FN is high , many relevant papers will be excluded and the research team in charge of the literature review will miss them . A high FP means that some papers will be marked as within scope , when they should not , but the research team in charge of the literature review still has the possibility to discard them later in the subsequent SLR processes . Finally , a high ER means that the author should check or read the abstract for many papers , as if the AI had not helped much . Regarding the performance metrics , Prec and Spec are not so important , since they are calculated with FP , and a low number means that the research team has to read more papers in the subsequent SLR processes . By contrast , Neg Pred and Sens are important because they use FN for their calculation . A low value on these metrics means that many relevant papers have been excluded and the research team will miss them . Acc is a good predictor of the overall performance of the AI classifiers , but with unbalanced categories it could be misleading [ 64 ] . On the contrary , F - meas could give a more comprehensive view of the classification performed by the AI tools . Based on results from Table I , H2O showed the highest number of ER ( 11 . 4 % ) , which will require more work of the research team . Claude had the least percentage of ER ( 0 . 3 % ) , followed by Bard ( 0 . 7 % ) , Forefront ( 1 . 1 % ) , Theb ( 1 . 4 % ) and GetGPT ( 2 . 7 % ) . Regarding TN , several AIs had good and similar results : Theb with 75 . 0 % , Bard with 74 . 0 % and GetGPT with 73 . 8 % , out of the total 80 . 7 % that should be classified . Then , Claude and Forefront had 63 . 6 % and 63 . 4 % , respectively , while the worst performance was for H2O with 53 . 0 % . Most of the tested AIs showed almost the same percentage of TP : Claude with 7 . 2 % , H2O with 5 . 7 , Bard with 5 . 2 % , Theb with 4 . 4 % and GetGPT with 3 . 7 % out of 19 . 3 % that should be selected . Only Forefront obtained the highest value , 10 . 4 % . Regarding FN , the lowest value was for Forefront with 8 . 6 % , followed by H2O with 11 . 7 % , Claude with 12 . 1 % , Bard with 13 . 9 % , Theb with 14 . 8 % , and GetGPT with 15 . 1 % . FP was not so important , but H2O had the worst result with 18 . 1 % , which was also similar in the cases of Claude , with 16 . 8 % , and Forefront , with 16 . 4 % . Theb , GetGPT , and Bard had the best results for FP with 4 . 5 % , 4 . 7 % and 6 . 2 % , respectively . Based on the metrics from Table III , the AI with the best performance in Sens is Forefront , with 54 . 9 % , followed by Claude , with 37 . 4 % , and H2O , with 32 . 7 % . The worst performance in Sens was for Bard ( 27 . 2 % ) , Theb ( 22 . 8 % ) and GetGPT ( 19 . 6 % ) . The best Neg Pred was for Forefront ( 88 . 1 % ) , followed by Claude ( 84 . 0 % ) , Bard ( 84 . 2 % ) , Theb ( 83 . 6 % ) , GetGPT ( 83 . 0 % ) and H2O ( 81 . 9 % ) . Regarding F - meas , Forefront also had the best performance ( 45 . 4 % ) , followed by Bard ( 34 . 1 % ) , Claude ( 33 . 3 % ) and Theb ( 31 . 1 % ) . GetGPT and H2O had the worst results in F - meas ( 27 . 2 % and 27 . 6 % , respectively ) . TABLE III . A DDITIONAL M ETRICS OF THE R ESULS FOR E ACH A I T OOL All in all , Forefront got the best overall performance ( despite the high FP , which makes Spec and Prec low ) followed by Bard and Claude . These results also confirmed that GPT - 4 model ( from Forefront ) offers a better performance compared to GPT - 3 . 5 from GetGPT and Theb . This is because GPT - 4 is more complex , which in this case also leads to better results . Also , LaMDA model from Google Bard provides good results with a slightly better classification than Claude 2 model , although both AIs are more likely to classify an abstract as out of scope . Despite the fact that the H2O model ( Falcon - 40b ) uses training computes from GPT - 3 . 5 and PaLM models together , it showed the worst results . V . L IMITATIONS Some technological limitations were found during the experiment of automatic articles classification for an SLR with AI tools ( see Table IV ) . First , several of the AIs available in the library [ 56 ] became inactive shortly after the experiment Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . took place . This is the case of Forefront and Theb , which are no longer available at this time , as the URL is not accessible . This is due to the constant change in AI policies on the Internet . The second limitation is the maximum number of requests per minute supported for each AI tool . Many publicly available or paid AIs are limiting the possibility of automating processes . For example , Forefront only allowed 24 requests per hour for the most expensive fee . Analyzing 2 , 500 abstracts for an SLR at 12 requests / min would mean getting all the results in less than 4 hours , while 24 requests / hour would mean getting the results in more than 4 days . The third limitation was the need for using VPNs ( Virtual Private Networks ) to access some AIs . Google Bard or Claude had different policies depending on the region , so it is possible that some countries have no access to some of these AIs . The last limitation is that AIs are under constant development , so the accuracy of the results may change . For example , Google Bard was in experimental phase at the time the experiment took place , so it could improve in the future . TABLE IV . S UMMARY OF M AIN T ECHNOLOGICAL L IMITATIONS VI . C ONCLUSIONS AND F UTURE W ORK This paper explored the potential of some AI tools and their respective LLMs to assist the research team in the classification process of articles selected after the corresponding queries to scientific databases ( screening phase ) while conducting an SLR . The proper realization of an SLR is a very relevant task ( although sometimes rather cumbersome ) when working on a line of research . Therefore , it is important to be able to automate at least part of the process of conducting an SLR , something to which this article contributes with an example and the AI tools tested . This article tries to open new ways of using AI tools to accelerate research tasks , taking advantage of the popularity that AI tools have experienced in the last year . It is important to note that these AI tools are constantly changing and therefore this paper is a first exploratory study of such potential . It was possible to assess the accuracy in the classification of 596 article abstracts along with other complementary metrics . Forefront with GPT - 4 presented the best overall performance when classifying these abstracts , but it is not possible to fully rely on it . There is still work to be done by the research team to fully classify some abstracts . Future work includes continuing the exploration of AI tools to support SLRs as well as other research processes . For example , the potential of AI tools to extract insights from the full text or articles should be further researched . Additional experiments must be performed with other AIs and LLMs , which are evolving at a very fast pace [ 65 ] [ 66 ] . A CKNOWLEDGEMENTS This work was supported in part by grant PID2020112584RB - C31 ( H2O Learn project ) funded by MCIN / AEI / 10 . 13039 / 501100011033 , and in part by theMadrid Regional Government through the Multiannual Agreement with UC3M in the line of Excellence of University Professors EPUC3M21 ) , and in the context of the V PRICIT ( Regional Programme of Research and Technological Innovation ) , a project which is co - funded by the European Structural Funds ( FSE and FEDER ) . Partial support has also been received from the European Commission through Erasmus + Capacity Building in the Field of Higher Education project PROF - XXI ( 609767 - EPP1 - 2019 - 1 - ESEPPKA2 - CBHE - JP ) , MICROCASA ( 101081924 ERASMUS - EDU - 2022 - CBHE - STRAND - 2 ) , EUCare4 . 0 ( 2021 - 1 - FR01 - KA220 - VET - 000024860 ) , and POEM - SET ( 2021 - FR01 - KA220 - HED - 000032171 ) . This publication reflects the views only of the authors and funders cannot be held responsible for any use which may be made of the information contained therein . R EFERENCES [ 1 ] ChatGPT ( 2023 ) . Retrieved August 1 , 2023 from https : / / chat . openai . com [ 2 ] OpenAI ( 2023 ) . Retrieved August 1 , 2023 from https : / / openai . com [ 3 ] Lo , C . K . ( 2023 ) . What is the impact of ChatGPT on education ? A rapid review of the literature . Education Sciences , 13 ( 4 ) , 410 , 1 - 15 . https : / / doi . org / 10 . 3390 / educsci13040410 [ 4 ] Dergaa , I . , Chamari , K . , Zmijewski , P . , & Saad , H . B . ( 2023 ) . From human writing to artificial intelligence generated text : examining the prospects and potential threats of ChatGPT in academic writing . Biology of Sport , 40 ( 2 ) , 615 - 622 . https : / / doi . org / 10 . 5114 / biolsport . 2023 . 125623 [ 5 ] Phung , T . , Padurean , V . A . , Cambronero , J . , Gulwani , S . , Kohn , ˘ T . , Majumdar , R . , . . . & Soares , G . ( 2023 ) . Generative AI for Programming Education : Benchmarking ChatGPT , GPT - 4 , and Human Tutors . International Journal of Management , 21 ( 2 ) , 100790 , 1 - 24 . https : / / doi . org / 10 . 48550 / arXiv . 2306 . 17156 [ 6 ] Alkaissi , H . , & McFarlane , S . I . ( 2023 ) . Artificial hallucinations in ChatGPT : implications in scientific writing . Cureus , 15 ( 2 ) , 1 - 4 . https : / / doi . org / 10 . 7759 % 2Fcureus . 35179 [ 7 ] Ray , P . P . ( 2023 ) . ChatGPT : A comprehensive review on background , applications , key challenges , bias , ethics , limitations and future scope . Internet of Things and Cyber - Physical Systems , 3 ( 2023 ) , 121 - 154 . https : / / doi . org / 10 . 1016 / j . iotcps . 2023 . 04 . 003 [ 8 ] Chen , L . , Zaharia , M . , Zou , J . ( 2023 ) . How is ChatGPT’s behavior changing over time ? arXiv preprint arXiv : 2307 . 09009 , 1 - 23 . https : / / doi . org / 10 . 48550 / arXiv . 2307 . 09009 [ 9 ] George , A . S . , & George , A . H . ( 2023 ) . A review of ChatGPT AI’s impact on several business sectors . Partners Universal International Innovation Journal , 1 ( 1 ) , 9 - 23 . https : / / doi . org / 10 . 5281 / zenodo . 7644359 [ 10 ] Firat , M . ( 2023 ) . What ChatGPT means for universities : Perceptions of scholars and students . Journal of Applied Learning and Teaching , 6 ( 1 ) , 1 - 7 . https : / / doi . org / 10 . 37074 / jalt . 2023 . 6 . 1 . 22 [ 11 ] Agarwal , K . ( 2023 ) . AI in Education - Evaluating ChatGPT as a Virtual Teaching Assistant . IJFMR - International Journal For Multidisciplinary Research , 5 ( 4 ) , 1 - 12 . https : / / doi . org / 10 . 36948 / ijfmr . 2023 . v05i04 . 4484 [ 12 ] Gimpel , H . , Hall , K . , Decker , S . , Eymann , T . , Lammermann , L . , M¨ adche , ¨ A . , . . . & Vandrik , S . ( 2023 ) . Unlocking the power of generative AI models and systems such as GPT - 4 and ChatGPT for higher education : A guide for students and lecturers . Hohenheim Discussion Papers in Business , Economics and Social Sciences No . 02 - 2023 , Universitat¨ Hohenheim , Stuttgart , Germany . http : / / hdl . handle . net / 10419 / 270970 [ 13 ] Pardos , Z . A . , & Bhandari , S . ( 2023 ) . Learning gain differences between ChatGPT and human tutor generated algebra hints , 1 - 5 . arXiv Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . preprint arXiv : 2302 . 06871 . https : / / doi . org / 10 . 48550 / arXiv . 2302 . 06871 [ 14 ] Cotton , D . R . , Cotton , P . A . , & Shipway , J . R . ( 2023 ) . Chatting and cheating : Ensuring academic integrity in the era of ChatGPT . Innovations in Education and Teaching International , 1 - 12 . https : / / doi . org / 10 . 1080 / 14703297 . 2023 . 2190148 [ 15 ] Lim , W . M . , Gunasekara , A . , Pallant , J . L . , Pallant , J . I . , & Pechenkina , E . ( 2023 ) . Generative AI and the future of education : Ragnarok or¨ reformation ? A paradoxical perspective from management educators . The International Journal of Management Education , 21 ( 2 ) , 100790 , 113 . https : / / doi . org / 10 . 1016 / j . ijme . 2023 . 100790 [ 16 ] Dwivedi , Y . K . , Kshetri , N . , Hughes , L . , Slade , E . L . , Jeyaraj , A . , Kar , A . K . , . . . & Wright , R . ( 2023 ) . “So what if ChatGPT wrote it ? ” Multidisciplinary perspectives on opportunities , challenges and implications of generative conversational AI for research , practice and policy . International Journal of Information Management , 71 , 102642 , 1 - 63 . https : / / doi . org / 10 . 1016 / j . ijinfomgt . 2023 . 102642 [ 17 ] Dempere , J . , Modugu , K . , Hesham , A . , & Ramasamy , L . K . ( 2023 ) . The Impact of ChatGPT on Higher Education . Frontiers in Education , Vol . 8 , 1206936 . https : / / doi . org / 10 . 3389 / feduc . 2023 . 1206936 [ 18 ] Xames , M . D . , & Shefa , J . ( 2023 ) . ChatGPT for research and publication : Opportunities and challenges . Journal of Applied Learning and Teaching , 6 ( 1 ) , 1 - 6 . Advance online publication . https : / / doi . org / 10 . 37074 / jalt . 2023 . 6 . 1 . 20 [ 19 ] Liebrenz , M . , Schleifer , R . , Buadze , A . , Bhugra , D . , & Smith , A . ( 2023 ) . Generating scholarly content with ChatGPT : ethical challenges for medical publishing . The Lancet Digital Health , 5 ( 3 ) , e105 - e106 . https : / / doi . org / 10 . 1016 / S2589 - 7500 ( 23 ) 00019 - 5 [ 20 ] Polonsky , M . J . , & Rotman , J . D . ( 2023 ) . Should Artificial Intelligent Agents be Your Co - author ? Arguments in Favour , Informed by ChatGPT . Australasian Marketing Journal , 31 ( 2 ) , 91 - 96 . https : / / doi . org / 10 . 1177 / 14413582231167882 [ 21 ] Hosseini , M . , Resnik , D . B . , & Holmes , K . ( 2023 ) . The ethics of disclosing the use of artificial intelligence tools in writing scholarly manuscripts . Research Ethics , 1 - 17 . https : / / doi . org / 10 . 1177 / 17470161231180449 [ 22 ] Rahimi , F . , & Abadi , A . T . B . ( 2023 ) . ChatGPT and publication ethics . Archives of medical research , 54 ( 3 ) , 272 - 274 . https : / / doi . org / 10 . 1016 / j . arcmed . 2023 . 03 . 004 [ 23 ] Ganjavi , C . , Eppler , M . B . , Pekcan , A . , Biedermann , B . , Abreu , A . , Collins , G . S . , . . . & Cacciamani , G . E . ( 2023 ) . Bibliometric Analysis of Publisher and Journal Instructions to Authors on Generative - AI in Academic and Scientific Publishing , 1 - 97 . arXiv preprint arXiv : 2307 . 11918 . https : / / doi . org / 10 . 48550 / arXiv . 2307 . 11918 [ 24 ] Kitchenham , B . , Brereton , O . P . , Budgen , D . , Turner , M . , Bailey , J . , & Linkman , S . ( 2009 ) . Systematic literature reviews in software engineering – a systematic literature review . Information and software technology , 51 ( 1 ) , 7 - 15 . https : / / doi . org / 10 . 1016 / j . infsof . 2008 . 09 . 009 [ 25 ] Haman , M . , & Skolnˇ ´ık , M . ( 2023 ) . Using ChatGPT to conduct a literature review . Accountability in Research , 1 - 3 . https : / / doi . org / 10 . 1080 / 08989621 . 2023 . 2185514 [ 26 ] Forefront ( 2023 ) . Retrieved August 1 , 2023 , from https : / / forefront . ai [ 27 ] GetGPT ( 2023 ) . Retrieved August 1 , 2023 , from http : / / chat . getgpt . world [ 28 ] Theb ( 2023 ) . Retrieved August 1 , 2023 , from https : / / chatbot . theb . ai [ 29 ] Claude ( 2023 ) . Retrieved August 1 , 2023 , from https : / / claude . ai [ 30 ] Bard ( 2023 ) . Retrieved August 1 , 2023 , from https : / / bard . google . com [ 31 ] H2O ( 2023 ) . Retrieved August 1 , 2023 , from https : / / gpt - gm . h2o . ai [ 32 ] Peres , R . , Schreier , M . , Schweidel , D . , & Sorescu , A . ( 2023 ) . On ChatGPT and beyond : How generative artificial intelligence may affect research , teaching , and practice . International Journal of Research in Marketing , 40 ( 2 ) , 269 - 275 . https : / / doi . org / 10 . 1016 / j . ijresmar . 2023 . 03 . 001 [ 33 ] ResearchRabbit ( 2023 ) . Retrieved August 1 , 2023 , from https : / / researchrabbit . ai [ 34 ] Consensus ( 2023 ) . Retrieved August 1 , 2023 , from https : / / consensus . app [ 35 ] Elicit ( 2023 ) . Retrieved August 1 , 2023 , from https : / / elicit . org [ 36 ] ChatPDF ( 2023 ) . Retrieved August 1 , 2023 , from https : / / chatpdf . com [ 37 ] Scite ( 2023 ) . Retrieved August 1 , 2023 , from https : / scite . ai [ 38 ] Scholarcy ( 2023 ) . Retrieved August 1 , 2023 , from https : / scholarcy . com [ 39 ] Inciteful ( 2023 ) . Retrieved August 1 , 2023 , from https : / / inciteful . xyz [ 40 ] Scispace ( 2023 ) . Retrieved August 1 , 2023 , from https : / / typeset . io [ 41 ] Adams , D . , & Chuah , K . M . ( 2022 ) . Artificial intelligence - based tools in research writing : current trends and future potentials . Artificial Intelligence in Higher Education , 169 - 184 . [ 42 ] Salvagno , M . , Taccone , F . S . , & Gerli , A . G . ( 2023 ) . Can artificial intelligence help for scientific writing ? . Critical care , 27 ( 1 ) , 1 - 5 . https : / / doi . org / 10 . 1186 / s13054 - 023 - 04390 - 0 [ 43 ] Wordtune ( 2023 ) . Retrieved August 1 , 2023 , from https : / / wordtune . com [ 44 ] Grammarly ( 2023 ) . Retrieved August 1 , 2023 , from https : / / grammarly . com [ 45 ] Panadero , E . ( 2017 ) . A review of self - regulated learning : Six models and four directions for research . Frontiers in psychology , 8 , 422 , 1 - 28 . https : / / doi . org / 10 . 3389 / fpsyg . 2017 . 00422 [ 46 ] Moher , D . , Liberati , A . , Tetzlaff , J . , Altman , D . G . , & PRISMA Group * . ( 2009 ) . Preferred reporting items for systematic reviews and metaanalyses : the PRISMA statement . Annals of internal medicine , 151 ( 4 ) , 264 - 269 . https : / / doi . org / 10 . 1136 / bmj . b2535 [ 47 ] Østergaard , D . , Dieckmann , P . , & Lippert , A . ( 2011 ) . Simulation and CRM . Best Practice & Research Clinical Anaesthesiology , 25 ( 2 ) , 239249 . https : / / doi . org / 10 . 1016 / j . bpa . 2011 . 02 . 003 [ 48 ] Gross , B . , Rusin , L . , Kiesewetter , J . , Zottmann , J . M . , Fischer , M . R . , Pruckner , S . , & Zech , A . ( 2019 ) . Crew resource management¨ training in healthcare : a systematic review of intervention design , training conditions and evaluation . BMJ open , 9 ( 2 ) , e025247 , 1 - 13 http : / / dx . doi . org / 10 . 1136 / bmjopen - 2018 - 025247 [ 49 ] Hayes , P . , Bearman , C . , Butler , P . , & Owen , C . ( 2021 ) . Non - technical skills for emergency incident management teams : A literature review . Journal of Contingencies and Crisis Management , 29 ( 2 ) , 185 - 203 . https : / / doi . org / 10 . 1111 / 1468 - 5973 . 12341 [ 50 ] Castillo - Segura , P . , Fernandez - Panadero , C . , Alario - Hoyos , C . , Muñoz - Merino , P . J . , & Kloos , C . D . ( 2021 ) . Objective and automated assessment of surgical technical skills with IoT systems : A systematic literature review . Artificial Intelligence in Medicine , 112 , 102007 , 1 - 17 . https : / / doi . org / 10 . 1016 / j . artmed . 2020 . 102007 [ 51 ] Praharaj , S . , Scheffel , M . , Drachsler , H . , & Specht , M . ( 2021 ) . Literature review on co - located collaboration modeling using multimodal learning analytics — Can we go the whole nine yards ? . IEEE Transactions on Learning Technologies , 14 ( 3 ) , 367 - 385 . https : / / doi . org / 10 . 1109 / TLT . 2021 . 3097766 [ 52 ] Schneider , B . , Sung , G . , Chng , E . , & Yang , S . ( 2021 ) . How can highfrequency sensors capture collaboration ? A review of the empirical links between multimodal metrics and collaborative constructs . Sensors , 21 ( 24 ) , 8185 . https : / / doi . org / 10 . 3390 / s21248185 [ 53 ] Noroozi , O . , Pijeira - D´ıaz , H . J . , Sobocinski , M . , Dindar , M . , Jarvela , S . , & Kirschner , P . A . ( 2020 ) . Multimodal data indicators for capturing cognitive , motivational , and emotional learning processes : A systematic literature review . Education and Information Technologies , 25 , 54995547 . https : / / doi . org / 10 . 1007 / s10639 - 020 - 10229 - w [ 54 ] Cha , J . S . , & Yu , D . ( 2022 ) . Objective measures of surgeon nontechnical skills in surgery : A scoping review . Human Factors , 64 ( 1 ) , 42 - 73 . https : / / doi . org / 10 . 1177 / 0018720821995319 [ 55 ] BibTeX . org . Format . Retrieved August 1 , 2023 , from https : / / www . bibtex . org / Format [ 56 ] xtekky ( 2023 ) . gpt4free [ Source code ] . GitHub . Retrieved August 1 , 2023 , from https : / / github . com / xtekky / gpt4free [ 57 ] Kublik , S . , & Saboo , S . ( 2022 ) . GPT - 3 . O’Reilly Media , Incorporated . [ 58 ] KoushikNavuluri ( 2023 ) . Claude - API [ Source code ] . GitHub . Retrieved August 1 , 2023 , from https : / / github . com / KoushikNavuluri / Claude - API [ 59 ] GPT - 4 ( 2023 ) . Research . OpenAI . Retrieved August 1 , 2023 , from https : / / openai . com / research / gpt - 4 [ 60 ] LaMDA ( 2023 ) . AI Technology . Blog google . Retrieved August 1 , 2023 , from https : / / blog . google / technology / ai / lamda / [ 61 ] Bard Google AI ( 2023 ) . AI Technology . Blog google . Retrieved August 1 , 2023 , from https : / / blog . google / technology / ai / bard - google - ai - searchupdates / [ 62 ] Falcon ( 2023 ) . TII . Retrieved August 1 , 2023 , from https : / / falcom . tii . ae / [ 63 ] Anthropic ( 2023 ) . Retrieved August 1 , 2023 , from https : / / www . anthropic . com Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . [ 64 ] Wang , L . , Han , M . , Li , X . , Zhang , N . , & Cheng , H . ( 2021 ) . Review of classification methods on unbalanced data sets . IEEE Access , 9 , 6460664628 . https : / / doi . org / 10 . 1109 / ACCESS . 2021 . 3074243 [ 65 ] Gozalo - Brizuela , R . , & Garrido - Merchan , E . C . ( 2023 ) . ChatGPT is not all you need . A State of the Art Review of large Generative AI models , 1 - 22 . arXiv preprint arXiv : 2301 . 04655 . https : / / doi . org / 10 . 48550 / arXiv . 2301 . 04655 [ 66 ] Chang , Y . , Wang , X . , Wang , J . , Wu , Y . , Zhu , K . , Chen , H . , . . . & Xie , X . ( 2023 ) . A survey on evaluation of large language models , 1 - 25 . arXiv preprint arXiv : 2307 . 03109 . https : / / doi . org / 10 . 48550 / arXiv . 2301 . 04655 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply .