13 A Review of Worked Examples in Programming Activities KASIA MULDNER , JAY JENNINGS , and VERONICA CHIARELLI , Department of Cognitive Science , Carleton University , Canada This article reviews literature on worked examples in the context of programming activities . We focus on two types of examples , namely , code - tracing and code - generation , because there is sufficient research on these to warrant a review . We synthesize key results according to themes that emerged from the review . This synthesis aims to provide practical guidance for educators and shed light on future research opportunities . While there is established work in some areas ( e . g . , dynamic code - tracing examples in the form of program visualization tools , utility of subgoals in code - generation examples , and incomplete examples in the form of Parsons puzzles ) , there are also gaps . Thus , the article concludes with directions for future work on examples in computer science education . CCS Concepts : • Social and professional topics → Computing education ; Additional Key Words and Phrases : Worked examples , review , code - tracing examples , code - generation examples ACM Reference format : Kasia Muldner , Jay Jennings , and Veronica Chiarelli . 2022 . A Review of Worked Examples in Programming Activities . ACM Trans . Comput . Educ . 23 , 1 , Article 13 ( December 2022 ) , 35 pages . https : / / doi . org / 10 . 1145 / 3560266 1 INTRODUCTION A traditional worked example , also referred to as a worked - out example or simply example , shows a problem statement and a step - by - step derivation of the solution [ 100 ] . Examples can facilitate problem - solving performance and learning [ 3 , 19 , 100 ] , with the caveat that outcomes depend on several factors . One factor is student experience in the target domain . Examples are especially beneficial for novices but lose their effectiveness as students gain experience [ 56 ] . Other factors include the way examples are designed [ 117 ] and integrated with instructional activities [ 122 ] , as well as how constructively students study examples [ 16 ] . Findings from studies with worked ex - amples in various domains ( e . g . , algebra , statistics , geometry ) were reviewed by Atkinson et al . [ 3 ] . However , the review was done over twenty years ago . van Gog and Rummel [ 123 ] subsequently reviewed work on examples using both cognitive and social - cognitive perspectives , describing why examples are effective and how they should be designed . More recently , van Gog et al . [ 124 ] provided an overview of ways that examples support knowledge acquisition . These more recent This work was supported by NSERC Discovery Grant No . 1507 . Authors’ address : K . Muldner ( corresponding author ) , J . Jennings , and V . Chiarelli , Department of Cognitive Science , Carleton University , Canada ; email : kasia . muldner @ carleton . ca . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . © 2022 Association for Computing Machinery . 1946 - 6226 / 2022 / 12 - ART13 $ 15 . 00 https : / / doi . org / 10 . 1145 / 3560266 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 2 K . Muldner et al . contributions were not comprehensive reviews and did not describe findings from computer sci - ence education ( CSE ) . To fill this gap , we review and synthesize research on examples in CSE . Our goal is to present a review of worked example research in the context of students learning to program . We take a narrative approach , by describing the literature and corresponding results . We synthesize the results according to five themes that emerged from the review , highlighting interventions that were effective ( or not ) as well as opportunities for future work . To date , research in CSE has focused on worked examples related to two key programming activ - ities , namely , code tracing and code generation . Code tracing involves evaluating what happens in a program by tracing its execution step - by - step to predict program output . This is a foundational skill [ 91 , 137 ] but one that students find challenging [ 62 , 121 ] . Documented issues include incom - plete traces [ 20 , 29 ] and / or traces with errors [ 29 ] , possibly due to incorrect mental models of how the computer executes a program [ 113 ] . Some students report using code tracing only if an initial search for the code’s meaning fails [ 21 ] and not knowing where to start [ 138 ] , something we anec - dotally witnessed in our classroom . Examples can help students learn the skill of code tracing by illustrating the step - by - step mechanics of a code trace . We refer to these examples as code - tracing examples . The second type of example with considerable CSE research is a code - generation example . As the name implies , code - generation examples show the source code for a program written in a pro - gramming language—they may also include additional information beyond just the code , such as explanations about the program components and / or program subgoals . Like code tracing , code generation is a key skill [ 137 ] that is challenging to learn [ 91 , 93 , 103 ] . As highlighted by a recent review [ 93 ] , students experience difficulties with syntactic principles ( e . g . , missing semi - colons in Java ) , conceptual principles ( e . g . , related to variables , conditionals , loops ) , and strategic princi - ples ( e . g . , planning and designing programs ) . Code - generation examples can support learning by illustrating solutions to programming problems similar to ones students are working on . Beyond code tracing and code generation , examples have potential to support learning of other programming skills ( e . g . , translation from human - language descriptions into programming lan - guage syntax [ 137 ] ) . However , our review focuses on code - tracing and code - generation examples , because there is sufficient research on these to warrant a review . 1 . 1 Background : Theoretical Foundations Examples play a fundamental role in the early and intermediate phases of cognitive skill acquisition in various problem - solving domains [ 2 , 16 , 116 , 128 , 130 ] . A prominent theory promoting the in - tegration of examples with problem - solving activities is cognitive load theory ( CLT ) [ 116 ] . The theory predicts that solving problems produces a high cognitive load , because novices do not have well - formed schemas . Schemas are mental representations that guide problem solving . If schemas are not present , then students must mentally search for the domain principles needed to derive the problem solution . Even if a correct principle is identified , learning is diminished , because the search overloads working memory , leaving few resources for learning . To address this , CLT proposes that examples be integrated into problem - solving activities . A common approach involves interleaving examples with problems by providing an example first , followed by a similar problem , followed by another example and problem , and so on . The example in an example - problem pair provides an opportunity for schema acquisition ( e . g . , in the computing domain , a schema could correspond to a high - level algorithm or plan [ 112 ] ) . The problem provides practice with the application of the schema , needed for schema automation . A series of classic experiments in the algebra domain showed that students learned more when examples were interleaved with problems , as compared to when only problems were available [ 19 , 118 ] ; this result has been replicated in other domains like engineering [ 122 ] and programming ( Experiment 1 [ 119 ] ) . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 3 In addition to providing a theoretical account for the proposed benefits of examples , CLT also provides recommendations on ( 1 ) when examples are beneficial , i . e . , in the early stages of skill acquisition , and ( 2 ) how to design examples to increase learning . One recommendation relates to the modality used to present the example components . Examples are commonly text - based , but this is not optimal if they include separate components that need to be integrated ( e . g . , a geometry example with a diagram and a text - based solution that references the diagram ) . In this case , presenting the example components using different modalities will reduce split attention [ 82 ] . To illustrate using the geometry example , the solution could be presented using an audio recording rather than via text , allowing students to listen to an explanation of the solution and look at the diagram at the same time . While programs are not diagrams in the traditional sense , the modality principle is certainly relevant to programming activities ( e . g . , an example that includes a program and its code trace both in written form has the potential to split student attention ) . Social - cognitive theories propose an additional mechanism associated with learning from exam - ples , namely , self - efficacy . Self - efficacy is belief in one’s ability to succeed on a task . This line of work uses modelling examples , which involve a human deriving a problem solution in real time ( thus providing a worked example ) . Schunk et al . [ 107 ] demonstrated that students’ self - efficacy for math improved significantly more after observing videos showing a coping model ( a peer who made mistakes while solving a problems ) , as compared to a mastery condition where the peer did not make mistakes ( Experiment 1 ) ; learning also improved significantly more in the coping model group . The proposed explanation was that witnessing a peer make mistakes demonstrated errors are a natural by - product of learning rather than a sign of low ability . While the domain in this study was math , self - efficacy is also a strong predictor of programming activity outcomes [ 61 ] . Yet another relevant body of work relates to theories on the impact of students’ engagement with instructional materials ( e . g . , Reference [ 17 ] ) . In her seminal work , Chi et al . [ 16 ] analyzed students’ think - aloud verbalizations as they studied physics examples . Some students merely paraphrased the example solutions , while other students self - explained the solutions by making inferences beyond what the solution showed ( e . g . , by re - deriving example solution steps ) . Students who self - explained learned more than students who paraphrased . The benefit of self - explanation for learning has been replicated by hundreds of studies ( e . g . , References [ 9 , 18 , 83 , 101 , 136 ] ) , with the caveat that most were not in the CSE domain . Not all students spontaneously self - explain [ 16 , 84 , 101 ] or produce quality self - explanations [ 99 ] . Thus , other work has investigated how to design instructional materials , including examples , to promote self - explanation . To illustrate , learning was increased when students were provided with some assistance ( hints or feedback ) as they self - explained examples of programs by specifying subgoals in the programs [ 66 ] . We describe this work in Section 3 . 2 . 1 . 2 Examples in Programming Activities An example always includes a problem statement and the corresponding solution—it may also include additional information , such as explanation about how the solution was derived , subgoals labelling the solution , and so on . In the CSE domain , there is a range of creative opportunities for designing different types of examples , including : • Text - based “static” examples of the type shown in textbooks • Modelling examples corresponding to a teacher or student generating a solution in real time ; the example solution evolves dynamically over time rather than being presented all at once • “Dynamic” code - tracing examples presented with program visualization tools that show a step - by - step solution of a code trace—students advance through the solution , for instance by pressing a button that moves the program execution forward to the next step and shows the variable values at that step ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 4 K . Muldner et al . • Other dynamic examples showing the solution in animated form • Incomplete examples ( examples with gaps ) showing partial solutions that students are tasked with completing ( e . g . , Parsons puzzles , which consist of shuffled lines of code that must be rearranged to produce a working program ) Our review includes studies involving these various types of examples . 1 . 3 Procedure for Finding Relevant Articles and Inclusion Criteria Articles were identified using several methods . We began with targeted searches in selective pro - gramming education venues , including : ( 1 ) International Computing Education Research Confer - ence ( ICER ) , ( 2 ) Conference on Innovation and Technology in Computer Science Education ( ITiCSE ) , ( 3 ) Special Interest Group on Computer Science Education Technical Symposium ( SIGCSE ) , ( 4 ) IEEE Symposium on Visual Languages and Human Centric Computing ( VL / HCC ) , ( 5 ) ACM Transactions on Computing Education ( TOCE ) , and ( 6 ) Computer Science Education Journal ( CSEJ ) . Each venue was searched separately . The primary search terms and phrases we used included “worked examples” ( or “worked - out examples” ) , programming , learning , and students ; because examples are broadly characterized in the programming domain ( see Section 1 . 2 ) , we included additional terms , namely , animation , visualization , Parsons , notional , live programming , live coding , code tracing . In sum , we searched each of the six venues listed above using the following search query : [ programming AND students AND learning AND [ “worked examples” OR “worked - out examples” OR animation OR visualization OR Parsons OR notional OR “live program - ming” OR “live coding” OR “code tracing” ] ] The terms corresponding to programming , students , and learning were applied to the full text in the search criteria . To make the analysis of the search results feasible , the additional terms were included in the full text when the number of hits from the search produced fewer than 200 results— if the search produced over 200 potential papers , then the additional terms were restricted to the paper titles / abstracts / keywords ( with one exception : the results related to ACM TOCE produced a slightly higher number of potential results , but we kept the search general without restricting it to avoid missing relevant papers ) . Table 1 , Phase 1 , top , shows the results , including the number of hits the search produced for each venue and the number of papers included in the present review based on the inclusion criteria ( described shortly ) . Note that the final number of papers in Table 1 only includes ones relevant to the theme of our review , namely , research on code - tracing or code - generation worked examples . As expected , the search sometimes produced papers that mentioned the keywords in some other context , but the work in the paper was not focused on examples . To illustrate , Cunningham et al . [ 20 ] ’s work investigates how students solve code - tracing problems by sketching and tracing . The paper was retrieved by the search engine because the term “worked example” appears in the pa - per’s bibliography . However , examples were not part of the instructional context of this work , and so the paper was not included in the final set of results in Table 1 ( it appears in the bibliography because we cite it in a broader context to illustrate challenges associated with solving code - tracing problems ) . The full list of citations used in the present review is in Appendix A . To avoid missing relevant papers , we subsequently expanded the search to include key databases ( Phase 2 , Table 1 ) , including ( 1 ) SpringerLink , ( 2 ) IEEE Xplore Digital Library , ( 3 ) Wiley Online Jour - nals , ( 4 ) ACM Digital Library , and ( 5 ) Science Direct Journals . Each venue was searched separately . To make phase 2 search feasible , we ( 1 ) added the criteria that papers had to be published on or after 2000 ( since Atkinson et al . [ 3 ] provided a review in 2000 ) and ( 2 ) narrowed the scope of the search terms , using the following search query : ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 5 Table 1 . Paper Selection Process and Results Venue # Initial papers # Included papers Phase 1 : International Computing Education Research Conference ( ICER ) 191 11 Conference on Innovation and Technology in Computer Science Education ( ITiCSE ) 1 74 4 Special Interest Group on Computer Science Education Technical Symposium ( SIGCSE ) 2 117 9 IEEE Symposium on Visual Languages and Human Centric Computing ( VL / HCC ) 162 0 ACM Transactions on Computing Education ( TOCE ) 244 4 Computer Science Education Journal ( CSEJ ) 99 3 Phase 2 : SpringerLink 3 617 13 IEEE Xplore Digital Library 182 6 Wiley Online Journals 144 2 ACM Digital Library 4 254 16 Science Direct Journals 5 61 5 Other ( e . g . , snowballing ) : — 14 Note : the results for Phase 2 may include duplicates from Phase 1 for the # Initial papers column but not for the # Included papers column—the latter only includes papers not part of Phase 1’s final count . The search terms were applied to the full paper text , with the following exceptions / notes ( see paper for when a full vs . restricted search was used ) : 1 ITiCSE full search = 418 , restricted search used ; 2 SIGCSE full search = 755 , restricted search used ; 3 SpringerLink full search used as restricted search not available ; 4 Science Direct Journals full search = 561 , restricted search used . [ programming AND students AND learning AND [ “worked examples” OR “worked - out examples” ] ] Results for phase 2 are also in Table 1 ( following phase 1 results ) . As for phase 1 , if the search produced over 200 results , then we restricted the additional search terms to the title / abstract / key - words ( see Table 1 , Phase 2 for two exceptions : ( 1 ) the ACM Digital Library search was close to this threshold , and so we checked all titles / abstracts , and ( 2 ) the SpringerLink search , which to the best of our knowledge only allows limiting search terms to the title ( without including the abstract and keywords ) —this was too limiting , and so we checked all results . We read titles and abstracts of the papers , and based on relevance and inclusion criteria ( see below ) , the full paper . If the paper cited a paper ( s ) that was relevant but older , then we retrieved , read , and included the paper ( s ) in the present review when it added new insights—see Other por - tion of Table 1 , bottom , based on this snowballing approach ( i . e . , following citations in papers we identified ) and our knowledge of worked example research . Inclusion criteria : Broadly , the present review includes papers that involved an evaluation of an example - based instructional activity relevant to programming education . Specifically , our in - clusion criteria included studies with human participants that investigated learning and related ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 6 K . Muldner et al . Fig . 1 . Structure of the review : Outline . outcomes from activities involving code - tracing or code - generation examples . Both quantitative and qualitative research was included , conducted in laboratories and classrooms . For quantitative work , we focused on experimental or quasi - experimental studies , but if particularly relevant , then we also report on single - condition studies . Theoretical papers were not included , nor were anec - dotal accounts of experiences teaching in the classroom or survey - based papers that only asked students to self - report on learning . We only included papers written in English and published in journals or conference proceedings ( short papers , posters , books , and workshop papers were generally not included ) . 1 . 4 Structure of the Review To highlight factors that influence learning from examples , we organized the review using a frame - work from an earlier , domain - general example review [ 3 ] , adapting the framework as needed to the present context . The present framework , shown in Figure 1 , includes work on : ( 1 ) Ways to design examples , i . e . , intra - example features . Intra - example features include ones related to presentation format , example appearance , and features for encouraging effective example processing . We organized this part of the review according to whether the example showed a relatively complete solution ( see ( i + ii ) in Figure 1 ) or an incomplete solution with gaps ( see ( iii ) in Figure 1 ) . For the former , we further categorized existing work according to the type of example ( code tracing , see ( i ) in Figure 1 or code generation , see ( ii ) in Figure 1 ) , as well as additional sub - categories for each type . For code - tracing examples , we classified work according to the following sub - categories : modelling examples , examples and the notional machine , dynamic examples presented with program visualization tools , and other design features . For code - generation examples , the review is structured according to three sub - categories , namely , modelling examples , examples and subgoals , and other example design features . As far as code - tracing and code - generation examples with gaps ( see ( iii ) in Figure 1 ) , the review includes two sub - categories : traditional examples and examples in the form of Parsons puzzles . ( 2 ) Ways to integrate examples into lessons and instructional activities , i . e . , inter - example features . For this category , we described research on approaches for integrating examples into instructional materials . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 7 We now describe research based on the outline above , starting with work on code - tracing examples . 2 CODE - TRACING EXAMPLES In this section , we review work on code - tracing examples . As described above , this type of example shows a code trace of a program ( in contrast to code - tracing problems , which require students to generate the code trace ) . 2 . 1 Modelling Examples Recall that modelling examples involve a human deriving the example solution in real time . Hertz and Jump [ 42 ] analyzed the impact of supplementing standard course instruction with modelling examples of code traces . The examples were provided by an instructor during class ; students were also given code - tracing exercises , replacing aspects of the original lectures . The class had signif - icantly higher lab grades and a lower drop - out rate , as compared to a prior class that did not receive the modelling examples . However , since the class given modelling examples also included code - tracing practice , it is not possible to attribute these positive outcomes to only the examples . The studies we next describe involved instructional videos with modelling examples of code traces . Lee and Muldner [ 60 ] manipulated the narration style used in videos . Three types of videos were created , corresponding to the three study conditions : ( 1 ) a monologue video showing an instructor delivering a programming lesson that included dynamic , step - by - step examples of code traces ; ( 2 ) a dialog video showing the instructor and a student going over the same lesson together in the form of a dialogue ; ( 3 ) a control video identical to the monolog video except the instructor was not visible in the video . The participants were university students with no prior university - level programming experience ( N = 77 ) . Analysis of eye - tracking data showed that students did look at the instructor ( monolog video ) as well as instructor and student ( dialog video ) but this did not impact learning or self - efficacy , as reported by frequentist and Bayesian statistics ( the latter provided substantial evidence for the null model ) . Morrison [ 78 ] evaluated the effect of modality in instructional videos showing code traces of short programs ; the participants were undergraduate students ( final analysis : N = 61 ) . Three modal - ities were tested in three corresponding conditions , namely , explanations of code traces presented as text , or as audio , or as text + audio ( the programs related to the traces were shown as text ) . Based on cognitive load theory , the authors predicted that the audio group would have the best perfor - mance and the text + audio group the worst performance . Briefly , this is because text explanations about program segments had potential to split student attention between the program and the ex - planation . If the explanation is presented using audio instead of text , then split attention should be mitigated . When the data was grouped by question type averaged across the instructional videos , descriptively , the expected pattern was found for recall questions , i . e . , the audio group had the highest scores . However , this was not the case for the transfer or code - purpose questions – in fact for the transfer questions , the text group had highest scores . Inferential statistics were not reported for these analyses but overall , the main effect of modality was not significant . Zavgorodniaia et al . [ 140 ] subsequently conducted a study with the same three conditions and a larger sample size ( N = 186 ) . Participants were recruited from Mechanical Turk . Descriptively , the audio + text group scored higher on the posttest but overall , no significant differences were found between groups . This study had the potential limitation that it recruited Mechanical Turk participants , who may have had various levels of motivation to engage with the study activities . Zavgorodniaia et al . [ 141 ] addressed this limitation by running another study with the same three conditions but with undergraduate students ( final analysis : N = 77 ) . The results again showed no significant effect of modality . This study involved instructional videos about Dijkstra’s algorithm rather than code ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 8 K . Muldner et al . tracing , but we include it here for two reasons . First , this work provides additional evidence re - lated to the modality effect in CSE research . Second , the modality effect has predominantly been found in contexts that involve diagrams , and the materials in this study were diagrammatic . In contrast , studies in the CSE domain have involved computer programs , which have diagrammatic characteristics but are not traditional diagrams . Thus , the fact a different activity still produced null results shows this pattern is not limited to contexts that involve code . 2 . 2 Code - tracing Examples and the Notional Machine We next describe studies that presented the entire example all at once in a “static” text format , without dynamic elements like live demonstrations or visualizations . The studies investigated the utility of examples showing a basic model of the notional machine . This term , introduced by Du Boulay [ 10 ] , refers to an abstraction of the computer that “serves the purpose of understanding what happens during program execution” [ 113 ] . Early work by Mayer and colleagues compared several code - tracing example designs , 1 hypothe - sizing that examples with information about the notional machine will be more effective than ones without . Mayer [ 72 ] used a between - subjects design in a series of three experiments . Experiment 1 ( N = 80 ) evaluated four code - tracing example designs : ( 1 ) model - based examples showed the code trace using a notional machine diagram corresponding to a high - level metaphor of the computer ( e . g . , a ticket window to symbolize input , a message notepad to symbolize output ) ; ( 2 ) text - based examples showed the same information but without a corresponding model ; ( 3 ) model + flow chart examples included both the notional machine and a flow chart ; ( 4 ) text + flow chart examples in - cluded both the text and a flow chart . The model and model + flow chart groups had the highest scores on the posttest code - tracing questions ; the model + flow chart group had the highest scores on code - generation questions . In sum , including a notional machine diagram in code - tracing exam - ples was beneficial . Experiment 2 ( N = 40 ) , replicated that model - based examples result in better performance on code - tracing questions than text - only examples . However , for code - generation questions , the text - only examples led to better performance . A third experiment ( N = 56 ) addi - tionally manipulated type of practice ( code tracing , code generation ) . For low prior - knowledge students , test performance was highest either when model - based examples were coupled with code - generation practice or when text - only examples were coupled with code - tracing practice . Thus , complimentary example design and practice opportunities improved performance . For the high prior - knowledge students , the effect of example design or practice type was not significant . Bayman and Mayer [ 6 ] also manipulated the design of code - tracing examples in instructional materials . Two of the designs were similar to the ones described above , namely , model - based examples that included the notional machine diagram , and text - only examples that showed the code - tracing steps in written form without the diagram . Two additional designs corresponded to model + text examples that provided both a model and the corresponding text , and text - based summary examples similar to text - only examples but briefer . These four types of examples were labelled as conceptual in nature , and were compared to a control condition given standard exam - ples . Standard examples were the most general , stating what happened in a program only at a high level . For low prior - knowledge students , the four conceptual - example groups all had descriptively higher posttest performance on code - tracing questions than the standard - example group , but the effect was significant only for two comparisons ( text - only versus standard examples ; model + text versus standard examples ) . For high prior - knowledge students , the main effect of example type was not significant . However , for programming questions , an interaction emerged between prior 1 Inthesepapers , insomecasestheexampleswerereferredtoasinstructionalmaterials—wecharacterizedthemasexamples based on our analysis of these materials . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 9 knowledge and example type , with high prior - knowledge students benefiting more from standard than conceptual examples , while the opposite was true for low prior - knowledge students . The results from the above studies show the value of including detailed code - traces in examples for low prior - knowledge students , but more work is needed to confirm the optimal example format . In general , however , examples that include a diagram of the notional machine may help students develop appropriate mental models of the notional machine . Mayer [ 74 ] reviewed 20 studies investigating the utility of mental models in lessons about various topics , including code tracing . The synthesized results showed that model - based instruction increased conceptual recall and transfer of problem - solving skills , compared to lessons without a model , particularly for low prior - knowledge students . 2 . 3 Code - tracing Examples Provided by Program Visualization Tools Program visualization tools aim to help users understand the behaviour of programs , by illustrating the step - by - step flow of execution in a program and the corresponding program state at each step . Thus , program visualization tools can serve as proxies for notional machines [ 114 ] and their output can be characterized as a dynamic example of a code trace . A related type of tool involves visualization of general algorithms ( e . g . , sorting algorithms ) , rather than concrete programs . While algorithm and program visualization tools share common - alities , here we focus on program visualization tools , both because they are directly relevant to code - tracing examples and to manage the scope of the review . We do not include work on visual - ization tools in the context of debugging programs , because this activity is outside the scope of this review . However , for some of the studies described below , visualization tools may have been used for a variety of purposes , particularly for studies collecting data from standard class activities . We categorized studies in this section according to three themes : ( 1 ) visualization tools com - pared to traditional code - tracing activities , ( 2 ) design of visualization features , and ( 3 ) interactivity with visualization tools . 2 . 3 . 1 Visualization Tools Compared to Traditional Code - Tracing Activities . A pertinent question is whether using a visualization tool increases learning and related outcomes over traditional activ - ities like code tracing on paper . Sorva et al . [ 114 ] reviewed program visualization tools and studies that evaluated their effectiveness . At the time of that review ( 2013 ) , seven studies experimentally compared program visualization against traditional activities ( such as tracing programs on paper ) . Five of the seven studies reported that program visualization resulted in more learning and / or higher performance than traditional activities , while the other two studies reported null results . The majority of research identified through our review found that visualization tools improved learning and / or performance over standard instruction without such tools [ 4 , 43 , 55 , 90 , 110 , 139 ] , but with some exceptions where no significant benefit of visualization was reported [ 47 , 76 , 86 ] . The visualization tools and structure of the experimental and control groups in these studies varied . In two studies [ 4 , 76 ] , for the experimental group , the teacher used the visualization tool to show the target concepts , but students did not have access to the tool ; the control group was shown code - tracing examples using a traditional approach like a blackboard . Of these two studies , Awasekar [ 4 ] reported the experimental group performed significantly better on a posttest than the control group ( the participants were first - year engineering students , N = 60 ) . Descriptively , Mladenović et al . [ 76 ] found the same pattern , i . e . , the experimental group had higher posttest scores and larger pretest to posttest gains ( the participants were fifth - grade students , N = 98 ) . However , in this study there was no significant difference between the two groups in the immediate or delayed posttest scores , perhaps due to power issues ( the analysis was done on posttest scores without accounting for the pretest , which reduces experimental power ) . In general , the test scores were low ( around ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 10 K . Muldner et al . 55 % for the immediate posttest and below 50 % for the delayed posttest ) and gains were modest , perhaps because this study recruited a young population . With two exceptions [ 47 , 86 ] , the remaining studies we identified [ 43 , 55 , 90 , 110 , 139 ] reported the experimental group significantly outperformed the control group . In studies showing a ben - efit of visualization tools , the experimental group had access to the visualization tool and could manipulate it . Three studies involved a control group that had access to a standard IDE without the visualization [ 43 , 110 , 139 ] , while the other studies involved a control group that used class materials [ 55 , 90 ] . To illustrate with several examples , Shi et al . [ 110 ] ran a study with two condi - tions . The experimental group used the PlanAni tool , which visualized and animated variables as students used the tool to step through a program . The visualizations showed the role a variable plays in the program ( e . g . , footprints for a counter / stepper variable , a stone for a constant variable ) . The control group worked with an IDE ( Pelles C ) that included a debugger but no visualizations . Analysis of data from a study with university students ( N = 55 ) showed that participants in the PlanAni group had marginally higher scores on program construction questions in the final exam and significantly higher overall SOLO scores on these questions ( the SOLO taxonomy character - izes student understanding according to levels of increasing complexity ) . As a second example , Yang et al . [ 139 ] compared performance on code comprehension and program output prediction questions ( the participants were graduate students , N = 75 ) . To answer the questions , the exper - imental group used a tool called JaguarCode , which provided a dynamic run - time visualization of Java program states . The control group used the NetBeans environment , but without access to standard functionalities ( e . g . , debugger ) . The experimental group had significantly higher perfor - mance , with the caveat that this group had the advantage of scaffolding provided by JaguarCode while they were answering the questions . One potential explanation for why visualization tools are beneficial is that they are engaging . Ebel and Ben - Ari [ 25 ] reported on student engagement in an introductory programming high - school class ( N = 10 ) . The visualization tool used was Jeliot , which animates the program’s exe - cution by showing the flow of execution and visualizing the program state . Student attention was the primary outcome of interest . Analysis of recorded class activities that involved Jeliot showed students had very few episodes of inattention compared to other problem - solving activities that did not involve the tool . While learning was not measured in this study , a review of evaluations with Jeliot showed this tool can help students learn [ 8 ] . We next describe several examples of research that did not find an overall significant benefit of a visualization tool . PL - Tutor is a computer tutor that shows program state and execution and additionally prompts students to answer conceptual questions as they code trace programs [ 86 ] . A study with first - year university students ( final analysis : N = 37 ) compared learning from a PL - Tutor group and a control group that used Codecademy ( learning was operationalized as gain from pretest to posttest ) . The difference in gain scores between conditions was not significant . When learning was analyzed separately in each condition , the gain from pretest to posttest was only significant for the experimental group ( with the caveat that this group also had significantly lower pretest scores and so more room to gain at posttest ) . Huang et al . [ 47 ] also did not find a significant main effect of their visualization tool . The tool showed the runtime values of a program using so - called projection boxes . The projection visualized , for instance , the program state and corresponding variables using a table for a given line of code . The participants were undergraduate students ( N = 237 ) taking an introductory programming class . The class labs consisted of a variety of activities , including code tracing . In a given lab , participants either used the projection - box tool , or a version that did not include projection boxes . After a lab , participants completed a brief posttest ; on one occasion , they were also given a pretest prior to the lab activities . No significant ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 11 effects of condition were found , with the caveat that the tests used a small number of multiple choice questions ( 4 – 6 ) and so the analyses may have lacked sensitivity to detect groups differences . 2 . 3 . 2 Design of Visualization Features . We now review work on the design of visualization tool features . Some tools emphasize the roles that variables play in a program . Nevalainen and Sa - janiemi [ 87 ] compared two versions of the PlanAni visualization tool . Both versions allowed par - ticipants to step through a program , but only the experimental version provided an animation of operations on variables ( e . g . , assignment , comparison ) . In the control version , the animations were removed and variable roles were shown in a static format . The participants were university students who recently completed an introductory programming course ( N = 16 ) . An eye tracker was used to collect information on student attention . The viewing patterns for the two tool ver - sions were similar and the dynamic group devoted little attention to the variable animation . There was no significant difference between the static and animated groups on the posttest . However , experimental power may have been an issue given the small sample size . In a similar study , Sajaniemi et al . [ 106 ] compared two program visualization tools . One was a metaphor - based tool that visualized program elements using metaphors to familiar objects and / or actions ( e . g . , parameter passing depicted as a flying envelope containing the parameters ) . The second tool was Jeliot , which used basic shapes to represent program elements . The study was conducted as part of a university class , with students using the tools during labs . Tool use was counterbalanced : students either started with the metaphor - based tool and later used Jeliot or vice versa . On three occasions students were asked to code trace a program and produce a corre - sponding drawing ( the sample sizes varied , with 22 students completing all three drawing tasks ) . The tool used before this activity influenced the contents of the drawings ( e . g . , drawings had less metaphorical content after using Jeliot ) ; learning was not measured . Loboda and Brusilovsky [ 63 ] evaluated the impact of adapting visualization features to a stu - dent’s progress . Visualizations were provided by two versions of the cWADEIn tool , which used animation to code trace the evaluation of complex program expressions . The adaptive version adjusted animation speed and instructional explanations to a student’s progress , and showed its assessment of student knowledge via progress bars in the interface . The static tool version did not include any of these elements . A within - subjects study was used to compare the two cWADEIn versions , with university students as participants ( N = 14 ) . There was no significant difference between the two versions in mean gain scores ( posttest − pretest ) , possibly due to a ceiling effect . Eye - tracking analysis showed the adaptive version attracted more attention and a post question - naire indicated students generally preferred it over the non - adaptive version . The studies described above involved code - tracing examples that showed correct solutions . In contrast , erroneous examples include incorrect steps . Erroneous examples may foster learning by encouraging students to self - explain why a solution is incorrect [ 24 ] , but may also place high demands on working memory [ 35 ] . Moreno et al . [ 77 ] investigated the utility of “conflicting visual - izations , ” namely , visualizations that include errors ( e . g . , animating the else part of an if statement when the if condition is true ) . A study was conducted with university students ( N = 18 ) enrolled in an introductory programming course . All students used the Jeliot visualization tool but only the experimental group was given conflicting animations and tasked with identifying error ( s ) in the vi - sualization ( the control group used the standard , correct version of Jeliot to debug programs ) . The experimental group had higher gains from pretest to posttest but the difference between groups was not significant , possibly due to the small sample size . Griffin [ 34 ] also evaluated the effect of erroneous examples . The participants were students in a university programming class ( N = 78 ) . Both experimental and control groups code - traced programs using a visualization tool but in the experimental group , twenty percent of the programs included bugs ( programs in the control group ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 12 K . Muldner et al . were all correct ) . Learning was measured by class tests , a final exam , and a placement exam . No significant differences were found between the two groups on these measures , perhaps because the exposure to erroneous examples in this study was relatively brief . 2 . 3 . 3 Interactivity with Visualization Tools . We next describe studies that manipulated the level of interactivity and / or engagement with a visualization tool . Banerjee et al . [ 5 ] ’s study took place in a technology - constrained classroom , where students did not have direct access to a visualization tool and instead watched their instructor using the tool . Two experiments were conducted with first - year undergraduate students ( Experiment 1 : N = 78 ; Experiment 2 : N = 231 ) . Familiarity with active learning strategies was manipulated so that only participants for experiment 2 had prior experience with these strategies . In both experiments , the experimental group had to make predic - tions on the tool’s output ( high engagement condition ) while the control did not ( low engagement condition ) . In both experiments the difference in posttest scores was not significant , but based on classroom observation the experimental group had a significantly higher active engagement . Al - Barakati and Al - Aama [ 1 ] compared three conditions : ( 1 ) passively watching an instructor using the PlanAni visualization tool , ( 2 ) actively using the PlanAni tool to step through code , ( 3 ) working on problems without a visualization tool . Note that the first two groups both had ac - cess to code - trace examples provided by the PlanAni tool , but what differs is how they interacted with the examples . The participants were female undergraduate students taking an introductory programming class ( N = 91 ) ; the study was conducted over five weeks as part of the class labs and learning was assessed by a test . There was no significant difference in overall test scores between groups but the passively watching group had significantly higher scores on the debugging questions . Rather than comparing interactivity with code - tracing examples , Urquiza - Fuentes and Velazquez - Iturbide [ 120 ] compared learning from viewing code - tracing examples versus solving code - tracing problems . Specifically , participants either ( 1 ) viewed program animations provided by the WinHIPE program visualization tool on individual computers ( i . e . , code - tracing examples group ) , ( 2 ) constructed animations of code traces with WinHIPE ( i . e . , code - tracing problems group ) , or ( 3 ) worked on problems assigned by the teacher with access to WinHIPE but without its animation functionalities ( control group ) . The participants were students from an introductory programming class ( N = 132 ) . The impact of viewing versus constructing depended on the complex - ity of the posttest question . For high - complexity questions , the findings mirror the pattern above , in that the ‘viewing’ group performed best overall . For the medium - complexity questions , viewing and constructing groups had similar scores and both were significantly higher than the control group . As another example , Cetin [ 13 ] reported that constructing program animations produced significantly higher posttest performance than solving problems without access to a visualization tool . This study is less relevant for the present review , because it did not involve examples . The above - described studies manipulated interactivity and / or engagement through visualiza - tion tool features . Another way to manipulate engagement is through collaboration [ 17 ] . Rajala et al . [ 97 ] analyzed why students working collaboratively with the ViLLE visualization tool learned significantly more than students working alone ; the participants were students in a first - year com - puter science course ( N = 112 ) . The analysis showed that students working in pairs ( 1 ) spent more time on the target activities , particularly the difficult exercises , and ( 2 ) were more engaged . 2 . 4 Code - tracing Examples : Other Design Features We now review other research on the design of code - tracing examples . Kumar [ 58 ] evaluated a computer tutor that aimed to encourage students to be constructive as they read code - tracing examples ; the tutor presented the examples when an incorrect code - tracing problem solution was submitted . The tutor was evaluated over three semesters in a programming university - level class ( N = 730 ) —students were given access to the tutor and worked with it on their own time . The ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 13 experimental group used a tutor version with prompts to self - explain the code - tracing examples , while the control group had the same tutor but without the prompts ( both groups received the code - trace examples ) . No significant difference was found between the two groups on gain scores ( posttest − pretest ) . The control group did solve significantly more practice problems with the tutor , but this was likely because they did not have to provide self - explanations , which take time . In contrast to this research , prior work has reported benefits of self - explanation but much of it was done in experimental settings . In this study , students were not supervised or graded on their self - explanations , and so may have devoted less effort to the self - explanation task . The next three studies used a single - group design , reducing the validity of causal conclusions regarding effects of independent variables on outcomes . However , we briefly describe these studies because they involved code - tracing examples . Hosseini et al . [ 46 ] included animated and annotated examples in their instructional materials . The animated examples showed a dynamic code - trace of a program , while the annotated examples included static explanations of a line ( s ) of code in the ex - ample ( and did not dynamically visualize the program’s execution ) . Students in an undergraduate introductory programming course ( N = 109 ) had access to both types of examples through an on - line system ( studying the examples was voluntary ) . Accessing animated examples was positively associated with higher course grades , while the opposite was true for the annotated examples ( more access was associated with lower grades ) . Sirkiä and Sorva [ 111 ] analyzed how much stu - dents used animated examples embedded into an interactive e - book that was the primary textbook in an introductory programming course . The 567 students who passed the course viewed on aver - age more than half of the available examples . There was a weak positive association between the number of examples viewed and course assignment scores . Brusilovsky et al . [ 11 ] reported that students performed better in a programming course when they engaged with multiple activities ( including animated examples of code traces and annotated examples ) . 3 CODE - GENERATION EXAMPLES We next review research on code - generation examples . Recall that this type of example shows the final program along with the problem statement , and may include additional information , for instance on how the program was constructed . We begin with modelling examples . 3 . 1 Modelling Code - generation Examples Rubin [ 105 ] tested the utility of modelling examples in a classroom setting ( N = 146 ) using a between - subjects study . In the modelling condition , the instructor generated programs during class step - by - step , describing their reasoning as the program evolved ( this is referred to as live coding ) . Occasionally , the instructor would inadvertently make mistakes and have to modify the program . In the other condition , the examples were static instead of dynamic , i . e . , the complete program was presented at once and not modified . There were no significant differences between the groups on the exams , assignments , and overall course scores , but the modelling - example group performed better on the final course project . Raj et al . [ 95 ] also did not find a significant difference between the modelling ( live coding ) example and static - example groups . Descriptively , the static - example group performed better on the posttest and had higher pretest to posttest gains , while the modelling group had essentially zero gain ( i . e . , no learning occurred ) . However , this effect was not significant ( the standard deviation in gain scores was very high and so the analysis may have lacked power ) . As summarized above , there is not substantial evidence that modelling examples improve learn - ing over static examples , a conclusion echoed by a recent synthesis of results from studies evaluat - ing the live coding approach [ 108 ] . However , students find live coding useful [ 32 , 48 , 96 , 105 , 115 ] , more so than standard lectures [ 105 ] . Survey results from a class given both modelling and static ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 14 K . Muldner et al . examples [ 48 ] showed that each format had its benefits . For instance , students reported liking that static examples allowed them to study at their own pace but appreciated that modelling examples provided information on the instructor’s reasoning . 3 . 2 Code - generation Example Design : Subgoals Learning of various topics is improved if example solutions are supplemented with subgoals ( e . g . , References [ 12 , 68 ] ) . Subgoals are high - level statements about the purpose of example solution steps . In the context of programming , subgoals can relate parts of a program to higher - level objec - tives and / or algorithms . Margulieux et al . [ 67 ] evaluated the effectiveness of subgoals in a two - condition study with novice university students tasked with the creation of Android App Inventor programs ( Experi - ment 1 , N = 40 ) . The experimental group was given examples of programs supplemented with high - level subgoals ( e . g . , create component , set output , set conditions , define variables ) , while the control group received the same examples but without the subgoals . The experimental group performed significantly better on both an immediate posttest and a delayed posttest . A separate study with university students [ 64 ] ( Experiment 1 , N = 120 ) replicated the result that example subgoals im - prove problem - solving performance , additionally demonstrating this was the case when students could use the instructional materials ( including examples ) during the assessment period ( Experi - ment 2 , N = 120 ) . These studies were conducted in a laboratory setting with university students . As described next , key results transferred to a classroom context and / or younger populations . Margulieux et al . [ 69 ] provided examples with subgoals to three sections of a university pro - gramming class ( N = 120 ) , while two other sections had examples without subgoals ( N = 145 ) . Students given subgoals performed significantly better on quizzes ( but not the exam ) . The subgoal group had lower dropout rates , a promising finding . Margulieux et al . [ 70 ] found some evidence that subgoals helped high - school students write programs using a block - based programming envi - ronment . Joentausta and Hellas [ 54 ] also recruited a young population ( 9 - and 10 - year - old students , N = 43 ) . Examples with subgoals helped students complete significantly more levels in an online programming environment , as compared to examples without subgoals or no examples at all . The effect of worked examples with subgoals on self - efficacy was not significant . Thus far , we have described studies that provided subgoals as part of the example solution . The next series of studies evaluated the utility of asking students to construct the subgoals under various conditions . The proposed mechanism used to generate the subgoals was self - explanation , which can be used to fill gaps in instructional materials . Margulieux and Catrambone [ 66 ] ran a between - subjects laboratory study with university stu - dents ( N = 250 ) , manipulating two factors , namely , subgoal format and feedback . The activities corresponded to programming problems involving Android App Inventor . Five types of subgoal formats were included : ( 1 ) subgoals present in the example ( passive engagement ) , ( 2 ) subgoals had to be selected using a dropdown list ( active engagement ) , ( 3 ) and three constructive - engagement conditions that required students to generate the subgoals , either with ( 3i ) no guidance about where to put the subgoals in the example solution , ( 3ii ) some guidance showing where subgoals were needed ( via blank lines in the example students had to complete ) , or ( 3ii ) high guidance by not only showing where the subgoals were needed but also hints . Half of the students in these five groups received correctness feedback while the other half did not . Thus , the study used a 5 ( subgoal format ) × 2 ( feedback ) design , with a total of 10 conditions . Participants first studied the provided examples ( and generated the subgoals if required by their condition ) and then were asked to write programs without access to the examples ; the outcome measure was performance on the programming task . The two guided constructive groups ( 3ii and 3iii , see above ) performed best on the programming task , but with the caveat that this was only the case if one type of ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 15 assistance ( hints or feedback ) was provided but not both . Another caveat is that performance in the constructive groups was similar to the active and passive groups in some cases ( e . g . , when the constructive group was given high guidance and feedback , and the passive group was given feedback ; see Figure 8 [ 66 ] ) . The above study highlights that encouraging students to be constructive may not be as clear cut as simply asking them to self - explain , as there are interactions between level of engagement ( passive , active , constructive ) and level of assistance provided ( hints , feedback ) . Margulieux and Catrambone [ 65 ] also found that the relationship between learning and subgoal format depended on level of assistance , but here the subgoals were inserted into problems rather than examples , and so we do not describe the work further . Hints and feedback are examples of assistance manipulated in recently described studies . An - other form of assistance corresponds to the similarity between programs students are working on ( i . e . , the problems ) and examples used to aid program generation . When problem - example simi - larity is high , the example provides a lot of assistance , because its solution can easily be applied to generate the program ; when the similarity is reduced , the example program needs modifica - tion , requiring students to reason about how to make it suitable for the problem . The next set of studies examined how these two levels of assistance ( low and high problem - example similarity ) interacted with subgoal format to impact programming performance ; all studies used three lev - els of subgoal format , namely , no subgoals , given subgoals , and subgoal placeholders ( blank lines indicating subgoal location but requiring students to construct the subgoals ) . Morrison et al . [ 81 ] used a factorial design , namely , 2 ( low , high problem - example similarity ) × 3 ( no subgoals , given subgoals , subgoal placeholders ) for a total of six conditions . The participants were university students ( N = 66 ) . After completing a pretest , participants were given instructional materials that included examples and problem pairs ( with similarity and subgoal format manipu - lated according to condition ) . After the instructional period , participants solved four programming problems ( assessment # 1 ) , completed two additional assessments , and then completed a posttest . Outcome measures corresponded to scores from the first assessment period and the posttest . A significant interaction emerged , with best performance in conditions where students were ei - ther ( 1 ) given high - similarity examples and had to generate the subgoal labels , or ( 2 ) given low - similarity examples that had the subgoal labels provided . Additional data was subsequently col - lected [ 80 ] ( final sample size : N = 119 ) , with analysis focused on the second assessment period that involved a Parsons problem . With scores on this problem as the dependent variable , performance was best for conditions in which subgoals were provided and there was no significant interaction between subgoal format and problem - example similarity . When analysis of this new data set used programming performance as the outcome measure , however , intermediate assistance was best [ 71 ] , replicating the earlier result reported above . This suggests the effect of assistance may depend on the outcome measure ( e . g . , traditional program - generation problems versus Parsons puzzles ) . Morrison et al . [ 79 ] aggregated data from these studies—the pattern of results reported by the individual studies held . Jennings and Muldner [ 53 ] also found intermediate forms of assistance resulted in the most learning , in the context of code - tracing activities involving examples . 3 . 3 Code - generation Examples : Other Design Features The next two studies varied the design of examples showing finished programs . Harsley et al . [ 39 ] compared several example designs in a between - subjects study with university students ( N = 66 ) , including standard examples , analogical examples that used an analogy to a real - world situation , and standard examples + separate analogical explanation . Examples were presented by a tutoring system and were available to students as they solved programming problems ; example solutions were shown iteratively rather than all at once , by requiring a button click to progress to the next ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 16 K . Muldner et al . solution step . There was no significant difference in posttest performance between groups but students did learn in all conditions . Ichinco et al . [ 49 ] investigated the effect of example annotation style on programming performance . Middle - school students ( N = 80 ) used a block - based environ - ment to modify 12 programs with access to examples ( one per task ) . There were four conditions : ( 1 ) no annotations , ( 2 ) brief annotations ( high - level explanation of code ) , ( 3 ) line - by - line anno - tations ( detailed explanation of code on a per line basis ) , and ( 4 ) visual emphasis ( red highlight around salient lines ) . Problem - example similarity was varied ( high for half of the problem - example pairs , low for the other half ) . Students wrote more correct programs when given examples with annotations than without , but this benefit only existed when the problem was paired with a similar example . The type of annotation did not have a significant effect on programming performance , perhaps because students found it difficult to effectively use the examples . Beege et al . [ 7 ] investigated the effect of different types of bugs in program examples , namely , ones due to syntactic errors and / or semantic errors . A study was conducted using a 2 ( syntactic errors : yes or no ) × 2 ( semantic errors : yes or no ) design . The participants were university students ( N = 128 ) who were novice programmers . Participants received examples of Python code and had to review the code and identify bugs ( if any ) . The outcome measures corresponded to three types of posttest questions : program generation , syntax questions , and semantics questions . Descrip - tively , the effect of bugs on all question types was small , but a significant interaction emerged for performance on the semantic questions . Specifically , the presence of one type of bug ( syntactic or semantic ) resulted in higher test performance than if both types of bugs were present or no bugs were present . 4 INCOMPLETE EXAMPLES ( EXAMPLES WITH GAPS ) One way to support students during programming activities is through examples that include gaps in their solutions that students are asked to complete . Because the example provides scaffolding by including part of the solution , this has the potential to improve learning , as we now describe . 4 . 1 Traditional Examples with Gaps Van Merriënboer [ 126 ] argued that in traditional computer science education , a better link is needed between example studying and code generation and proposed that example completion and modification activities address this gap . A study was conducted involving a course with 10 weekly sessions and high - school students as participants ( N = 57 ) . The completion group was given examples of working programs and had to complete them by adding functionality , while the generation group wrote programs with access to a worked example of a similar program . The completion group wrote significantly more correct programs at posttest ( there was no difference between groups on factual knowledge ) . Cognitive load operationalized as perceived difficulty increased for the generation group during the course but remained stable for the completion group . While these results highlight benefits of example - completion activities , the completion group spent more time per session , and so the findings warrant replication with time on task held constant . This was done in a follow up study with novice undergraduate students ( N = 40 ) [ 127 ] , who either completed examples of existing programs or wrote programs from scratch . There was no difference in time on task between groups but the benefits of program completion persisted : on the posttest , the completion group wrote more semantically correct programs . More recently , Van Merriënboer et al . [ 125 ] also found that program completion was superior to program generation ( Experiment 3 ) . Here , novice undergraduate students ( N = 87 ) were assigned either to completion or generation groups . The completion group performed better on far transfer tasks ( activities involving programming in other languages ) and reported lower cognitive load . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 17 Chang et al . [ 14 ] found the same pattern ( better performance by the completion group ) , with the caveat that inferential statistics were not reported . 4 . 2 Parsons Puzzles The studies described above required students to complete example programs by adding function - ality to the programs . Another type of a completion activity popular in the programming domain corresponds to Parsons puzzles . In a Parsons puzzle , a student is given a collection of shuffled program fragments and tasked with assembling them to form a complete solution [ 88 ] . Thus , a Parsons puzzle can be characterized as an incomplete example ( one where the gap corresponds to the order of the program lines ) . As summarized in a recent review [ 23 ] , compared to traditional code - generation activities , Par - sons puzzles reduce completion time but there is not evidence they improve learning . To illustrate , Zhi et al . [ 142 ] analyzed performance on programming activities involving a version of the Snap ! environment . The participants were students enrolled in an introductory class for non - CS majors ; the analysis was based on data from six semesters ( N ≈ 50 per semester ) . In some semesters the labs involved Parsons puzzle activities , while in other semesters the labs used classic code - generation activities . The Parsons groups completed their exercises faster but learning was comparable to the generation groups . Ericson and colleagues also compared code generation and Parsons puzzles but outside of the classroom context , using two studies [ 26 , 27 ] . The results replicated the pattern described above , with the Parsons group finishing problems faster but not learning more than the code - generation group . Both studies involved undergraduate students , with participants first completing worked examples interleaved with problems and then a posttest . Ericson et al . [ 27 ] ’s study ( N = 135 ) included three conditions : ( 1 ) Parsons puzzles with distractors ( additional lines of code not useful for the solution ) , ( 2 ) code generation , and ( 3 ) fixing programs with the same errors as the distractors . The Parsons group was faster but there were no significant differences between the groups in posttest scores . In a second study , Ericson et al . [ 26 ] investigated whether adapting the difficulty of a Parsons puzzle influenced learning . Adaptation was triggered by the number of help requests and the number of attempts on the last puzzle—when there were many help requests or solution attempts , the number of puzzle distractors was reduced . The study ( N = 126 ) included four conditions ( standard Parsons puzzles , Parsons puzzles with adaptation , code generation , and a control group that solved off - task problems ) . Once again , the Parsons groups were faster but there were no significant differences between the groups in posttest scores . The next study we describe focused on performance . Haynes and Ericson [ 40 ] compared two activities : adaptive Parsons problems with distractors versus code generation . The participants were under - graduate students ( final analysis : N = 95 ) ; a within - subjects design was used . With one exception , the Parsons condition spent significantly less time solving the problems than the code generation condition . Descriptively , the Parsons condition reported lower cognitive load , but this effect was only significant for a subset of the problems . 4 . 2 . 1 Design of Parsons Puzzles . The design of a Parsons puzzle has potential to impact learning and related states . One design consideration is whether the puzzle includes distractors . As was the case for the Ericson et al . [ 27 ] work described above , Harms et al . [ 38 ] evaluated the impact of distractors in puzzles , but rather than adapting the number of distractors , they manipulated if they were present or not in a two condition between - subjects study . The participants were children between ages of 10 and 15 ( N = 92 ) working with a block - based programming environment called Looking Glass . Participants first worked on Parsons puzzles ( training phase ) and then completed transfer tasks ( transfer phase ) . During training , distractors significantly increased time on task and cognitive load , as well as reduced the number of correctly completed problems . There were ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 18 K . Muldner et al . no significant differences in transfer performance between groups in terms of time , cognitive load , or correctness . Kumar [ 59 ] tested whether pairing distractors next to one another in a puzzle was more beneficial than randomly distributing distractors . The study was conducted within a university programming class ( N = 511 ) ; performance was assessed using grades on the puzzles . An interaction emerged , with paired distractors improving performance on long puzzles but not on short ones . This study also investigated lenient versus strict grading , in terms of whether a penalty was given for incorrect actions . Students took advantage of the lenient grading by completing more actions before submitting their solution but this did not impact the correctness of the submitted puzzle ( both groups had similar performance ) . Another design consideration relates to whether a Parsons puzzle encourages constructive rea - soning . Fabic et al . [ 28 ] tested the effect of self - explanation prompts in a two - condition study . The participants , both university and high - school students ( N = 70 ) , worked with a computer tutor to solve Parsons puzzles . Both conditions were given puzzles that had gaps in some of the code that they had to fill , but only the experimental group was prompted by the tutor to self - explain ( the control group did not receive prompts ) . The prompted group had significantly higher normal - ized gain scores , suggesting that the prompts did increase constructive reasoning . Weinman et al . [ 135 ] conducted two studies to compare the efficacy of Parsons problems with gaps versus code generation for teaching about programming patterns—here , we focus on study 2 . The study was carried out in a university programming class over several weeks ( N = 43 ) . In the initial exposure phase , students worked on exercises involving the same code patterns . The exercises were instan - tiated either as code - writing exercises ( control group ) or as Parsons puzzles with gaps in some of the program lines that students had to complete ( experimental group ) . In the subsequent acquisi - tion phase , students wrote programs in response to a prompt and their solutions were analyzed to identify the code patterns used . The Parsons group solutions included more patterns from the exposure phase , indicating this group learned more patterns ( with the caveat that this was true only for programs similar to the exposure phase , while for programs requiring more transfer , there was no difference in pattern application between the two groups ) . Hosseini et al . [ 45 ] evaluated the Program Construction Examples ( PCEX ) tool , which is a computer tutor that provides multimedia - style program construction examples . The examples included interactive explanations accessed by clicking a button , as well as prompts to encourage constructive reasoning . The prompts , called challenge activities , required students to complete gaps in a program by dragging lines of code from a set of options into the missing fields ( thus these examples are similar to Parsons puzzles but some program lines are already ordered ) . The participants were university students ( N = 62 – 71 depending on the analysis ) . Learning was positively correlated with use of the examples but the single - group design makes it difficult to draw causal conclusions about the benefit of examples . This limitation was addressed by a follow - up between - subjects study [ 44 ] conducted within the context of a university programming class ( N = 194 and N = 170 based on number of students who took the midterm and exam , respectively ) . All students in the class were given access to the PCEX tool but only the experi - mental group’s examples included prompts related to the challenge activities ( the control group’s examples did not include the challenge activities ) . Use of the tool was voluntary and both groups received bonus points for using it . The analysis method was a regression—here , we focus on the learning results . A key predictor in the analysis corresponded to students’ work on examples , operationalized as viewing of example components , time spent on them , and viewing of example explanations ( available in both conditions , albeit with slight differences ) . Work with examples in the experimental group increased posttest scores more than work with examples in the control group . Moreover , the experimental condition obtained marginally higher grades on a complex exam question ( differences between other question scores were not significant ) . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 19 A third design consideration relates to the type of feedback provided by a Parsons puzzle . Typically , Parsons puzzles provide line - by - line correctness feedback ( where incorrect lines are flagged , for instance by colouring them red [ 88 ] ) . Helminen et al . [ 41 ] compared learning from this type of feedback against high - level execution feedback . Execution feedback was provided by automatically testing a submitted puzzle using a test suite of cases and showing the actual and expected result for each case . The study was conducted in the context of a university programming class ( N = 445 ) and the results were based on an assignment for which one group received line - by - line feedback and the other group high - level feedback . While there was some indication that line - by - line feedback was better than execution feedback , no reliable differences were found and the authors concluded that definitive conclusions could not be made . 5 INTEGRATING EXAMPLES INTO INSTRUCTIONAL MATERIALS How should examples be integrated into programming activities ? We next describe studies that tackle this question , starting with studies manipulating various sequencing mechanisms . 5 . 1 Example Sequencing Mayer [ 73 ] tested when to provide code - tracing examples showing the notional machine model ( always present , never present , present during the instruction + practice phase but not during the posttest , present during posttest only ) ( Experiment 1 , N = 80 ) . The groups with access to the model examples during the instruction + practice phase had higher test performance than the groups without access to the model examples . There was no difference in performance between the groups with access to the model during the test , showing it is not just the mere presence of the notional machine model that is beneficial but also the timing of its presentation . Similarly , Mayer and Bromage [ 75 ] found that presenting example of the notional machine model at the start of instruction resulted in higher recall of conceptual ideas and novel inferences than if the model was presented later on in the lesson . The proposed explanation for these findings was that presenting a model early on facilitates the assimilation of new concepts . The next studies we describe investigated sequencing of examples with other activities and / or materials . Jennings and Muldner [ 53 ] implemented a code - tracing tutor that interleaved code - tracing examples with code - tracing problems . The sequencing of the examples was manipulated in an experimental study with university students ( N = 97 ) . Specifically , some participants saw a code - tracing example before solving the corresponding problem , while other participants saw the example after solving the problem ( the example was not available during problem solving ) . The example - problem order provides more assistance than the problem - example order , because if the example comes first , it provides opportunity to learn a schema to guide subsequent prob - lem solving . However , initially struggling to solve the problem may be beneficial , as demonstrated by studies in other domains [ 57 ] . Students in the problem - example order spent longer solving the code - tracing problems but there was no significant difference in pretest to posttest gains between the two instructional orders . The next study varied the order of explanations . Wang et al . [ 131 ] investigated whether code - tracing examples provided by the Jeliot program anima - tion tool should be preceded or followed by explanations of the animation . The participants were post - graduate and graduate students ( N = 18 ) . The animation - first group performed better on a posttest . Trafton and Reiser [ 119 ] tested four interleaving mechanisms in the context of code - generation activities : interleaved examples ( example1 , isomorphic problem , example2 , isomorphic problem , etc . ) , blocked examples ( all examples presented sequentially , followed by all problems presented sequentially ) , interleaved problems ( problem1 , isomorphic problem , problem2 , isomorphic prob - lem , etc . ) , and blocked problems ( problem1 , problem 2 , . . . isomorphic problem1 , isomorphic ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 20 K . Muldner et al . problem2 , . . . ; this condition was blocked by problem similarity ) . Results from a study with a between - subjects design ( Experiment 1 , N = 40 ) showed that ( 1 ) the interleaved example group outperformed the interleaved problem group and ( 2 ) the blocked problem group outperformed the blocked example group . Descriptively , the interleaved example group had the highest test scores , followed by the blocked problem group ( the paper does not report if this difference is significant ) . In Experiment 2 ( N = 40 ) , students solved problems using a tutoring system that provided assistance for program generation . Students were given either examples followed by problems or problems followed by isomorphic problems . The main finding was that students who initially solved prob - lems performed better on the posttest than students who initially studied examples . These results do not replicate ones from Experiment 1 , potentially because in Experiment 2 , the tutoring system provided assistance for problem solving . The next three studies involved undergraduate students taking a database course . Najar and Mitrovic [ 109 ] compared learning from interleaved examples and problems , examples only , and problems only in a between - subjects study with undergraduate students ( N = 34 ) . Students in the example conditions were provided procedural prompts , while students in the problem conditions were given conceptual prompts . Learning was operationalized using normalized gain scores . The example - only group learned significantly less than both the interleaved and problem - only groups . While overall learning between interleaved and problem - only groups was similar , the interleaved group gained more on conceptual test questions , while the problem - only group gained marginally more on procedural questions . Chen et al . [ 15 ] also tested example - problem interleaving mecha - nisms , here comparing the impact of example - problem pairs that were correct versus erroneous example - problem pairs ( N = 26 for final analysis ) . While there was no significant difference in learning between conditions , the erroneous - example group had fewer errors during the instruc - tional period . Najar et al . [ 85 ] implemented a computer tutor capable of adapting the instructional activity presented , either a problem to solve , an example to study , or a faded example that had some but not all steps provided . A between - subjects study was conducted with two conditions : adaptive versus static sequencing ( final analysis : N = 46 ) . Both conditions were given a series of activities ( i . e . , problems , examples , faded examples ) , but in the adaptive condition the activity was tailored to student performance and self - reported mental effort . The adaptive group had significantly higher normalized gain scores . We next review studies that involved tutoring systems that aimed to help students write pro - grams by selecting similar examples . Thus , in this work the integration of examples into instruc - tional activities was tailored to the program the student was writing . The ELM - PE tutoring system includes a selection mechanism that aims to find examples similar to the program the student is writing [ 134 ] . The evaluation showed that the system chose better examples than predetermined textbook examples and closely matched expert programmers’ example selections . Wang et al . [ 133 ] supplemented the block - based programming environment Snap ! with examples and functionality to select examples similar to the program being written . A qualitative approach was used to evalu - ate the system ( N = 9 undergraduate students ) . The main result was that students used examples to make progress and to reduce effort by copying the example solution . The next system we describe , called Example Guru , aimed to select examples that fulfilled two criteria : ( 1 ) helped students write programs using Application Programming Interfaces ( APIs ) and ( 2 ) showcased a novel approach a novice would not be familiar with [ 50 ] . The system selected API examples during code genera - tion activities in the block - based Looking Glass environment . Example Guru was evaluated with children aged 10 – 15 ( N = 78 ) in a between - subjects study , where the control group used a version of the system that did not make example suggestions but did provide access to documentation . Participants accessed API examples in the Example Guru condition significantly more than in the documentation condition and used more novel approaches in their programs when working with ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 21 Example Guru . Hamouda et al . [ 36 ] designed a computer tutor for recursion that included both problems and examples . Here , students had to select examples on their own rather than having the system perform the selection . The tutor helped students ( N = 109 ) perform better on the exam but the study did not isolate whether this benefit was due to the presence of examples or other scaffolding in the tutor . 5 . 2 Number of Examples to Present on Given Page : One Versus Two ? Another consideration is how many examples to show on a given page ( or screen if an educational technology is used ) . Providing more than one example on a single page potentially facilitates com - parison of the presented examples , which could encourage learning ( e . g . , via abstraction of super - ficial features and attention to the domain - relevant aspects of the solutions ) . Patitsas et al . [ 89 ] tested this hypothesis in a two - condition study ( N = 83 completed all study components ) . The experimental group was given two examples on the same worksheet page . The examples showed two different programs for insertion into a hashtable and students were asked to ( 1 ) compare and contrast them , and ( 2 ) write a program to delete from the hashtable . The control group saw only one example at a time ( on the first worksheet , the first insertion program and instructions to write the deletion program ; on the second worksheet , the second insertion program ) . Thus , both groups had an example to guide them as they wrote the deletion program , but only the experimental group had access to both examples at once . The experimental group improved more from pretest to posttest on code - reading and code - writing questions . Davidovic et al . [ 22 ] evaluated two factors in their study , namely , number examples ( one or two ) and adaptation ( present or absent ) for a total of four conditions . The participants were undergrad - uate students ( N = 77 for final analysis ) who worked with a computer tutor on a recursion lesson . Based on the condition , the tutor either provided one or two examples and provided adaptation or did not . Adaptation corresponded to remedial help and adaptive content selection delivered by the tutor . When adaptation was present , students learned significantly more when they had access to two examples as compared to a single example . In contrast , there was no difference in learning from one versus two examples when adaptation was not present . A potential explanation is that processing two examples may be cognitively demanding and the adaptive version of the tutoring system provided remedial help that might have aided that process . Price et al . [ 92 ] tested the impact of asking students to compare two example solutions , here in the context of a university programming class where the study activities were part of the class homework . Homework involved using an online system to write programs that were automati - cally scored—students were required to re - submit incorrect solutions until they obtained a correct one . After students submitted a correct solution , they were given the opportunity to see the in - structor’s solution . Here , the student and instructor solutions can both be characterized as worked examples . When students did click to see the instructor’s solution , they were either not given a prompt , or they were prompted to self - explain the instructor’s solution ( explain prompts ) , and / or prompted to compare and contrast their solution with the instructor’s solution ( compare prompts ) . The prompts were randomized after each problem and over time students may have experienced all three prompt types . The key result was that students submitted more correct programs after receiving the explain prompts than after receiving the compare prompts . The impact of prompt type on learning was not assessed . Gadgil et al . [ 30 ] conducted a similar study and did assess learn - ing , albeit in a different domain corresponding to the circulatory system . Students learned more from compare prompts than prompts to explain an expert solution . These two studies measured different outcomes , namely , performance measured by program correctness ( Price et al . ) versus learning ( Gadgil et al . ) . Thus , the impact of prompt type may depend on the dependent variable of interest , although more work is needed before this conclusion can be made . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 22 K . Muldner et al . Fig . 2a . Synthesis of results : Themes 1 and 2 . Null results shown in blue . Unless otherwise stated , the depen - dent variable is learning . 6 DISCUSSION The goal of the present review was to describe research related to worked examples and student learning in the programming domain . We focused on code - tracing and code - generation examples , because there is sufficient research on these to warrant a review . The review was organized to emphasize ( 1 ) ways that example design impacts outcomes like learning ( including complete ex - amples and examples with gaps ) , and ( 2 ) ways to integrate examples into instructional activities . 6 . 1 Synthesis of Results To make salient the findings and opportunities for future research , we synthesized the results by extracting themes that emerged from the review . The themes are shown in Figures 2a – 2c and include ( 1 ) modelling examples in the classroom , ( 2 ) design to encourage constructive behaviors , ( 3 ) design features specific to code - tracing example design , ( 4 ) general design features , and ( 5 ) integration of examples into lessons . With the exception of theme 3 , a theme includes work on code - tracing and code - generation examples ( the type of example is identified with the label CT for code tracing and CodeGen for code generation ) . The citations in Figures 2a – 2c correspond to many but not all of the reviewed papers ( our goal was to highlight key citations , with a focus ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 23 on learning and / or performance outcomes ) . Significant results are shown in black font while null results are indicated with a ≈ symbol and are shown in blue font . Unless otherwise indicated , the outcome variable is learning ( operationalized in the studies as pretest to posttest gains and / or posttest performance ) . We begin by describing patterns of results for each theme . 6 . 1 . 1 Theme 1 : Modelling Examples in the Classroom . For research related to theme 1 , an in - structor presented the example solution step by step in a live demonstration ( e . g . , code traced on the board ; implemented a program from scratch during class ) . While instructional videos can in - clude modelling examples , we classified this work under theme 4 , because it also relates to example design . Modelling examples have potential to promote learning as they pace the timing of solution presentation and they typically include rationale for the solution steps . However , the findings from reviewed studies do not provide evidence that modelling examples improve learning over other types of examples . 6 . 1 . 2 Theme 2 : Designs to Encourage Constructive Behaviours . Theme 2 encapsulates work on ways to encourage constructive processing of examples . One approach involves using general prompts to self - explain complete example solutions ( see ( A ) in Figure 2a ) . The one study we found testing this approach produced null results ( no significant benefit of prompting ) . However , as we describe next , numerous other studies did find benefits of self - explanation and related constructive activities . One way to encourage students to engage constructively with examples is to give them incomplete examples that have gaps in their solutions . Older work shows that incomplete examples resulted in more learning than complete examples ( see ( B ) in Figure 2a ) . More recently , researchers have tested the utility of gaps corresponding to example solution subgoals . The benefit of this type of gap depends on the level of assistance : intermediate level of assistance was best , see ( C ) in Figure 2a ( with the caveat that one study did not support this pattern ) . Parsons puzzles are another type of an incomplete example ( see ( D ) in Figure 2a ) . One type of ‘gap’ in Parsons puzzles corresponds to the ordering of the solution steps . Studies using Parsons puzzles with this type of gap reported a time benefit but no learning advantage . However , when prompts for self - explanation were added to Parsons puzzles and / or gaps that students had to fill , a learning benefit was reported over puzzles without prompts or gaps . Thus , it may be that the re - ordering alone is too subtle of an intervention to impact learning , and so additional scaffolds are needed . Yet another opportunity to encourage constructive processing of examples is by including errors in example solutions that students are tasked with fixing ( see ( E ) in Figure 2a ) . To date , however , the results have been mixed in terms of the utility of erroneous examples , with only one study providing some evidence that erroneous examples improved learning . 6 . 1 . 3 Theme 3 : Design Features Specific to Code - tracing Examples . Theme 3 ( Figure 2b ) synthe - sizes research on the design of CT examples . Some older work ( see ( G ) in Figure 2b ) highlights that including a notional machine model in code - tracing examples improves learning . However , this benefit may exist only for low prior - knowledge students and moreover , more work is needed on what code - tracing example design fosters most learning . A second stream of work in this theme corresponds to program visualizations that act as a dynamic code - tracing example ( see ( H ) in Figure 2b ) . The majority of studies that compared activities with a visualization tool to traditional activities found the visualization condition resulted in better performance and / or learning . However , these results need to be interpreted with some caveats . Many of these studies used traditional computer science populations . Programming courses are increasingly required for students not majoring in computer science , and it is unclear if benefits of visualization tools will transfer to these other populations , particularly if the visualizations include technical concepts not required for understanding of the notional ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 24 K . Muldner et al . Fig . 2b . Synthesis of results : Theme 3 . Null results shown in blue . Unless otherwise stated , the dependent variable is learning . machine . A second caveat is that visualizations in many studies in Section 2 . 3 . 1 were compared to traditional class activities . However , if traditional activities do not involve explicit instruction on code tracing and sketching , then it is not surprising that visualization tools came out on top . Finally , as Cunningham et al . [ 21 ] argue , “ humans are different than compilers , ” and so the patterns students infer from programs while code tracing need to be considered in the design of visualization tools . To date , however , work on different visualization features reported null effects ( e . g . , dynamic versus static animation features , metaphorical versus standard features ) . Perhaps the tested design features had a relatively small effect on learning , and so larger sample sizes are needed ( many of the corresponding studies involved modest sample sizes ) . Moreover , more studies are needed on how students code trace to determine features to include in visualization ( with some foundations provided through existing work , e . g . , References [ 20 , 21 , 29 , 52 ] ) . Another important factor relates to students’ level of engagement and / or interactivity with vi - sualization tools . While several studies did not result in a significant difference between merely viewing the program visualization and other more active conditions ( like predicting or stepping through the visualization ) , in one study an interaction emerged between how students use the animation and concept difficulty , highlighting the importance of considering additional factors in experimental designs . 6 . 1 . 4 Theme 4 : Design Features ( General ) . The fourth theme encapsulated work investigating general example - design features ( see Figure 2c , top ) . Work classified under theme 4 on visual and / or auditory design features reported null effects . For instance , the example narration style ( dialogue versus monologue ) did not have a significant effect on learning ( see ( I ) in Figure 2c ) ; neither did the modality ( audio versus text narration of the example solution , see ( J ) in Figure 2c ) or visual style ( analogy versus standard , see ( K ) in Figure 2c ) . However , example annotations and subgoals significantly improved learning ( see ( L ) and ( M ) , respectively , in Figure 2c ) . The latter feature corresponds to a substantial research program with multiple studies and so the benefits of including subgoals in example solutions is well documented and replicated . While the subgoal ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 25 Fig . 2c . Synthesis of results : Themes 4 – 5 . Null results shown in blue . Unless otherwise stated , the dependent variable is learning . studies involved code - generation examples , code - tracing examples may also benefit from includ - ing subgoals . 6 . 1 . 5 Theme 5 : Integration of Examples into Lessons . The fifth and final theme corresponds to work examining effective ways to integrate examples into learning materials ( see Figure 2c , bot - tom ) . The majority of these studies focused on instructional order ( see ( N ) in Figure 2c ) , namely , when to present examples ( early on versus later in the lesson ; before or after a corresponding problem ) . For code - tracing examples , examples with the notional machine model were more ben - eficial if they were provided early in a lesson than if they only made available later in the lesson . There is some evidence that interleaving examples and problems ( example first , followed by a similar problem ) is beneficial , but the pattern differs between studies ( e . g . , one showed that in - terleaved example - problems were superior to interleaved problems without examples , but a sec - ond study only found a benefit of interleaved example - problems when compared to an examples - only condition , with no significant difference between the interleaved example - problems and problems - only conditions ) . In general , more research is needed to identify optimal sequencing mechanisms . In addition to sequencing considerations , integration of examples into instructional materials also relates to how many examples should be presented at a given point ( see ( O ) in Figure 2c ) . Here , two studies found some evidence that showing two examples produces more learning than a sequential presentation including one example at a time . A third study found the opposite pattern , but the outcome measure was performance on a programming problem rather than learning . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 26 K . Muldner et al . 6 . 2 Opportunities for Future Work Our review highlights active areas of research on examples in computing education , including studies demonstrating the utility of including subgoals in code - generation examples , code - tracing examples scaffolded by program visualization tools , and interventions encouraging constructive reasoning related to incomplete examples . The review also identified a number of opportunities for further research . We describe some now . Research on examples outside of the programming domain provides guidelines on example de - sign , including the modality used to present the example solution [ 3 ] . Using a single modality to present an example may by suboptimal if the example includes several components that need to be integrated to understand the example solution ( e . g . , as is the case for code - tracing examples that include a program and its code trace ) . In such instances , cognitive load theory proposes using dif - ferent modalities to present the example . However , the research in computing education reviewed here did not find significant effects of modality [ 78 , 140 , 141 ] . While these findings contrast with results from other domains ( e . g . , Reference [ 3 ] ) , as Zavgorodniaia et al . [ 141 ] caution , we should not conclude that there is something unusual about the computing domain given that other expla - nations are possible ( e . g . , the actual modality effect is smaller than reported and so larger sample sizes than currently used are required to demonstrate it ) . In general , more studies are needed to provide guidelines for CSE educators on ways to integrate example components . Another research opportunity relates to contexts that make examples available during problem - solving activities like code tracing or code generation . Here , one approach to aid problem solving involves making an analogy between the target problem and source example . Broadly , an analogy requires a comparison between two non - identical entities . General theories of analogical problem solving [ 2 , 31 , 33 ] propose specific mechanisms for resolving problem - example differences and guiding the transfer of the example solution . The success of the transfer depends on problem - example similarity . When similarity is low , students fail to correctly apply the example solution even when it is relevant for the problem , as demonstrated in various math domains [ 98 , 104 ] . While high similarity facilitates copying of the example [ 98 ] , this does not help students learn the domain principles [ 84 , 129 , 130 ] . In sum , if examples are present as students solve problems , then the level of problem - example similarity is important . Several computing education studies have manipulated problem - example similarity [ 71 , 79 , 81 ] , but more work is needed . Research is also needed to help students use examples effectively . Wang et al . [ 132 ] reported that students often failed to even attempt to find an example and once they did , they encountered challenges using it ( e . g . , knowing how to adapt the example solution to the problem ) . Similarly , Ichinco et al . [ 49 ] found students had difficulty understanding the example and how it was relevant for helping to solve the target problem . Even if students do see examples as useful , they may still need support to use effective strategies , e . g . , self - explanation rather than copying . How to promote such strategies is an open question as to the best of our knowledge there are no studies on this aspect in the CSE domain . Another opportunity pertains to promoting learning through example comparison activities , which involve showing several examples at once . To date , there are very few studies in this area that use programming activities . Comparison activities can promote procedural flexibility [ 102 ] , which is the ability to solve problems using multiple strategies . Programming activities are ideally suited for this skill , since programs can typically be written in various ways . Comparison activities may also foster schema formation . Recall that schemas are general structures needed to guide problem solving and promote transfer . In the programming domain , a schema can correspond to the algorithm underlying the solution . The kind of schema students acquire may be influenced by the similarity of the examples involved in the comparison activity [ 94 ] but this aspect needs investigation in the context of programming activities . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 27 While there are notable exceptions [ 44 , 53 , 58 ] , more research is also needed on integrating ex - amples into adaptive technologies such as tutoring systems . Such technologies have the potential to track students’ progress as they study examples by keeping track of time on task , hint access , and whatever other assistance or scaffolding the example provides . This ability to monitor stu - dents’ interactions has two advantages . First , it provides the opportunity to provide just - in - time interventions . For instance , Conati and Vanlehn [ 18 ] built a tutor that monitors how effectively students self - explain physics examples and provides prompts to self - explain when students are not reasoning constructively . A second advantage is that technologies can provide process data , which can be mined to explore associations between behaviors in the system and learning outcomes . This in turn can inform theories on how students learn from examples . Other gaps include the low rate of replication , something others have also acknowledged [ 37 ] , as well as novel analysis methods . Some of the studies in the present review reported null results obtained with Null Hypothesis Significance testing . This framework is only designed to identify differences between conditions and if null results are obtained , no conclusions can be drawn . In contrast , Bayesian statistics do allow for claims about null results . For instance , the Bayes factor is “a ratio that contrasts the likelihood of the data fitting under the null hypothesis with the likelihood of fitting under the alternative hypothesis” [ 51 ] . The advantage of using this analysis technique is that it provides evidence for both models , null and alternative . If sufficient evidence exists for the null ( see Reference [ 51 ] for guidelines on interpreting Bayes factor results ) , then claims can be made about null results . Thus , expanding the standard analysis techniques to include Bayesian statistics is another opportunity to strengthen results and associated implications . 6 . 3 Final Remarks Our review describes research in computing education on the design and integration of examples to promote learning and related outcomes . We focused the review on two types of examples , namely , code - tracing and code - generation examples . The synthesis of the results from the reviewed studies highlights effective approaches for designing and integrating examples , as well as points to areas that need further research . ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 28 K . Muldner et al . APPENDIX A INCLUDED PAPERS Code - tracing ( CT ) Examples : Modelling Examples [ 42 , 60 , 78 , 140 , 141 ] CT Examples and the Notional Machine [ 6 , 72 , 113 ] CT Examples and Visualization Tools [ 4 , 25 , 43 , 47 , 55 , 76 , 86 , 90 , 110 , 114 , 139 ] Design of Visualization Features [ 34 , 63 , 77 , 87 , 106 ] Impact of Interactivity Level With a Visualization Tool [ 1 , 5 , 13 , 97 , 120 ] CT Examples : Other Design Features [ 11 , 46 , 58 , 111 ] Code - generation ( CodeGen ) Examples : Modelling CodeGen Examples [ 95 , 105 , 108 ] Student preferences for Modelling examples [ 32 , 48 , 96 , 115 ] CodeGenExample Design : Subgoals [ 54 , 64 – 71 , 79 – 81 ] Code - generation Examples : Other Design Features [ 7 , 39 , 49 ] Examples with Gaps : Traditional Examples with Gaps [ 14 , 125 – 127 ] Parsons Puzzles : General [ 23 , 26 , 27 , 40 , 142 ] Design of Parsons Puzzles [ 28 , 38 , 41 , 44 , 45 , 59 , 135 ] Integrating examples with instructional materials : Sequencing [ 15 , 36 , 36 , 50 , 53 , 73 , 75 , 85 , 109 , 119 , 131 , 133 , 134 ] One vs . Two Examples [ 22 , 89 , 92 ] REFERENCES [ 1 ] Nouf M . Al - Barakati and Arwa Y . Al - Aama . 2009 . The effect of visualizing roles of variables on student performance in an introductory programming course . In Proceedings of the 14th Annual ACM SIGCSE Conference on Innovation and Technology in Computer Science Education . ACM , New York , NY , 228 – 232 . https : / / doi . org / 10 . 1145 / 1562877 . 1562949 [ 2 ] John R . Anderson . 1993 . Rules of the Mind . Psychology Press . https : / / doi . org / 10 . 4324 / 9781315806938 [ 3 ] Robert K . Atkinson , Sharon J . Derry , Alexander Renkl , and Donald Wortham . 2000 . Learning from examples : Instruc - tional principles from the worked examples research . Rev . Edu . Res . 70 , 2 ( 2000 ) , 181 – 214 . https : / / doi . org / 10 . 3102 / 00346543070002181 [ 4 ] Dipali D . Awasekar . 2013 . Effect of program visualization to teach computer programming in a resource constrained classroom . In Proceedings of the IEEE 5th International Conference on Technology for Education . IEEE , 93 – 100 . https : / / doi . org / 10 . 1109 / T4E . 2013 . 31 [ 5 ] Gargi Banerjee , Sahana Murthy , and Sridhar Iyer . 2015 . Effect of active learning using program visualization in technology - constrained college classrooms . Res . Pract . Technol . Enhanced Learn . 10 , 1 ( 2015 ) , 1 – 25 . https : / / doi . org / 10 . 1186 / s41039 - 015 - 0014 - 0 [ 6 ] Piraye Bayman and Richard E . Mayer . 1988 . Using conceptual models to teach BASIC computer programming . J . Edu . Psychol . 80 , 3 ( 1988 ) , 291 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 80 . 3 . 291 [ 7 ] Maik Beege , Sascha Schneider , Steve Nebel , Justus Zimm , Sarah Windisch , and Günter D . Rey . 2021 . Learning pro - gramming from erroneous worked - examples . Which type of error is beneficial for learning ? Learn . Instruct . 75 ( 2021 ) , 101497 . https : / / doi . org / 10 . 1016 / j . learninstruc . 2021 . 101497 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 29 [ 8 ] Mordechai Ben - Ari , Roman Bednarik , Ronit B . B . Levy , Gil Ebel , Andrés Moreno , Niko Myller , and Erkki Sutinen . 2011 . A decade of research and development on program animation : The Jeliot experience . J . Visual Lang . Comput . 22 , 5 ( 2011 ) , 375 – 384 . https : / / doi . org / 10 . 1016 / j . jvlc . 2011 . 04 . 004 [ 9 ] Kiran Bisra , Qing Liu , John C . Nesbit , Farimah Salimi , and Philip H . Winne . 2018 . Inducing Self - Explanation : A Meta - Analysis . Edu . Psychol . Rev . 30 , 3 ( 2018 ) , 703 – 725 . https : / / doi . org / 10 . 1007 / s10648 - 018 - 9434 - x [ 10 ] Benedict Du Boulay . 1986 . Some difficulties of learning to program . J . Edu . Comput . Res . 2 , 1 ( 1986 ) , 57 – 73 . https : / / doi . org / 10 . 2190 / 3LFX - 9RRF - 67T8 - UVK9 . arXiv : https : / / doi . org / 10 . 2190 / 3LFX - 9RRF - 67T8 - UVK9 [ 11 ] Peter Brusilovsky , Lauri Malmi , Roya Hosseini , Julio Guerra , Teemu Sirkiä , and Kerttu Pollari - Malmi . 2018 . An in - tegrated practice system for learning programming in Python : Design and evaluation . Res . Pract . Technol . Enhanced Learn . 13 , 1 ( 2018 ) , 1 – 40 . https : / / doi . org / 10 . 1186 / s41039 - 018 - 0085 - 9 [ 12 ] Richard Catrambone . 1998 . The subgoal learning model : Creating better examples so that students can solve novel problems . J . Exper . Psychol . : Gen . 127 , 4 ( 1998 ) , 355 . https : / / doi . org / 10 . 1037 / 0096 - 3445 . 127 . 4 . 355 [ 13 ] Ibrahim Cetin . 2020 . Teaching loops concept through visualization construction . Inform . Edu . Int . J . 19 , 4 ( 2020 ) , 589 – 609 . https : / / doi . org / 10 . 15388 / infedu . 2020 . 26 [ 14 ] Kuo - En Chang , Bea - Chu Chiao , Sei - Wang Chen , and Rong - Shue Hsiao . 2000 . A programming learning system for beginners - A completion strategy approach . IEEE Trans . Edu . 43 , 2 ( 2000 ) , 211 – 220 . https : / / doi . org / 10 . 1109 / 13 . 848075 [ 15 ] Xingliang Chen , Antonija Mitrovic , and Moffat Mathews . 2016 . Do erroneous examples improve learning in addition to problem solving and worked examples ? In Proceedings of the Intelligent Tutoring Systems Conference , Alessandro Micarelli , John Stamper , and Kitty Panourgia ( Eds . ) . Springer International Publishing , Cham , 13 – 22 . [ 16 ] Michelene T . H . Chi , Miriam Bassok , Matthew W . Lewis , Peter Reimann , and Robert Glaser . 1989 . Self - explanations : How students study and use examples in learning to solve problems . Cogn . Sci . 13 , 2 ( 1989 ) , 145 – 182 . https : / / doi . org / 10 . 1016 / 0364 - 0213 ( 89 ) 90002 - 5 [ 17 ] Michelene T . H . Chi . 2009 . Active - constructive - interactive : A conceptual framework for differentiating learning ac - tivities . Top . Cogn . Sci . 1 , 1 ( 2009 ) , 73 – 105 . https : / / doi . org / 10 . 1111 / j . 1756 - 8765 . 2008 . 01005 . x [ 18 ] Cristina Conati and Kurt Vanlehn . 2000 . Toward computer - based support of meta - cognitive skills : A computational framework to coach self - explanation . Int . J . Artific . Intell . Edu . 11 ( 2000 ) , 398 – 415 . [ 19 ] Graham Cooper and John Sweller . 1987 . Effects of schema acquisition and rule automation on mathematical problem - solving transfer . J . Edu . Psychol . 79 , 4 ( 1987 ) , 347 . [ 20 ] Kathryn Cunningham , Sarah Blanchard , Barbara Ericson , and Mark Guzdial . 2017 . Using tracing and sketching to solve programming problems : Replicating and extending an analysis of what students draw . In Proceedings of the ACM Conference on International Computing Education Research ( ICER’17 ) . ACM , New York , NY , 164 – 172 . https : / / doi . org / 10 . 1145 / 3105726 . 3106190 [ 21 ] Kathryn Cunningham , Shannon Ke , Mark Guzdial , and Barbara Ericson . 2019 . Novice rationales for sketching and tracing , and how they try to avoid it . In Proceedings of the ACM Conference on Innovation and Technology in Computer Science Education ( ITiCSE’19 ) . ACM , New York , NY , 37 – 43 . https : / / doi . org / 10 . 1145 / 3304221 . 3319788 [ 22 ] Aleksandar Davidovic , Jim Warren , and Elena Trichina . 2003 . Learning benefits of structural example - based adaptive tutoring systems . IEEE Trans . Edu . 46 , 2 ( 2003 ) , 241 – 251 . https : / / doi . org / 10 . 1109 / TE . 2002 . 808240 [ 23 ] YuemengDu , AndrewLuxton - Reilly , andPaulDenny . 2020 . Areviewofresearchonparsonsproblems . In Proceedings of the 22nd Australasian Computing Education Conference ( ACE’20 ) . ACM , New York , NY , 195 – 202 . https : / / doi . org / 10 . 1145 / 3373165 . 3373187 [ 24 ] Kelley Durkin and Bethany Rittle - Johnson . 2012 . The effectiveness of using incorrect examples to support learning about decimal magnitude . Learn . Instruct . 22 , 3 ( 2012 ) , 206 – 214 . https : / / doi . org / 10 . 1016 / j . learninstruc . 2011 . 11 . 001 [ 25 ] Gil Ebel and Mordechai Ben - Ari . 2006 . Affective effects of program visualization . In Proceedings of the 2nd Inter - national Workshop on Computing Education Research ( ICER’06 ) . ACM , New York , NY , 1 – 5 . https : / / doi . org / 10 . 1145 / 1151588 . 1151590 [ 26 ] Barbara J . Ericson , James D . Foley , and Jochen Rick . 2018 . Evaluating the efficiency and effectiveness of adaptive parsons problems . In Proceedings of the ACM Conference on International Computing Education Research ( ICER’18 ) . ACM , New York , NY , 60 – 68 . https : / / doi . org / 10 . 1145 / 3230977 . 3231000 [ 27 ] Barbara J . Ericson , Lauren E . Margulieux , and Jochen Rick . 2017 . Solving parsons problems versus fixing and writing code . In Proceedingsofthe17thKoliCallingInternationalConferenceonComputingEducationResearch ( KoliCalling’17 ) . ACM , New York , NY , 20 – 29 . https : / / doi . org / 10 . 1145 / 3141880 . 3141895 [ 28 ] Geela V . F . Fabic , Antonija Mitrovic , and Kourosh Neshatian . 2019 . Evaluation of parsons problems with menu - based self - explanation prompts in a mobile python tutor . Int . J . Artific . Intell . Edu . 29 , 4 ( 2019 ) , 507 – 535 . https : / / doi . org / 10 . 1007 / s40593 - 019 - 00184 - 0 [ 29 ] Sue Fitzgerald , Beth Simon , and Lynda Thomas . 2005 . Strategies that students use to trace code : An analysis based in grounded theory . In Proceedings of the 1st International Workshop on Computing Education Research ( ICER’05 ) . ACM , New York , NY , 69 – 80 . https : / / doi . org / 10 . 1145 / 1089786 . 1089793 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 30 K . Muldner et al . [ 30 ] Soniya Gadgil , Timothy J . Nokes - Malach , and Michelene T . H . Chi . 2012 . Effectiveness of holistic mental model confrontation in driving conceptual change . Learn . Instruct . 22 , 1 ( 2012 ) , 47 – 61 . https : / / doi . org / 10 . 1016 / j . learninstruc . 2011 . 06 . 002 [ 31 ] Dedre Gentner . 1983 . Structure - mapping : A theoretical framework for analogy . Cogn . Sci . 7 , 2 ( 1983 ) , 155 – 170 . https : / / doi . org / 10 . 1016 / S0364 - 0213 ( 83 ) 80009 - 3 [ 32 ] Nasser Giacaman . 2012 . Teaching by example : Using analogies and live coding demonstrations to teach parallel computing concepts to undergraduate students . In Proceedings of the IEEE 26th International Parallel and Distributed Processing Symposium Workshops and PhD Forum . IEEE , 1295 – 1298 . https : / / doi . org / 10 . 1109 / IPDPSW . 2012 . 158 [ 33 ] Mary L . Gick and Keith J . Holyoak . 1980 . Analogical problem solving . Cogn . Psychol . 12 , 3 ( 1980 ) , 306 – 355 . https : / / doi . org / 10 . 1016 / 0010 - 0285 ( 80 ) 90013 - 4 [ 34 ] Jean M . Griffin . 2019 . Designing intentional bugs for learning . In Proceedings of the 1st UK and Ireland Computing Education Research Conference . ACM , New York , NY , Article 5 , 7 pages . https : / / doi . org / 10 . 1145 / 3351287 . 3351289 [ 35 ] Cornelia S . Große and Alexander Renkl . 2007 . Finding and fixing errors in worked examples : Can this foster learning outcomes ? Learn . Instruct . 17 , 6 ( 2007 ) , 612 – 634 . https : / / doi . org / 10 . 1016 / j . learninstruc . 2007 . 09 . 008 [ 36 ] SallyHamouda , StephenH . Edwards , HichamG . Elmongui , JeremyV . Ernst , andCliffordA . Shaffer . 2018 . RecurTutor : An interactive tutorial for learning recursion . ACM Trans . Comput . Edu . 19 , 1 , Article 1 ( Nov . 2018 ) , 25 pages . https : / / doi . org / 10 . 1145 / 3218328 [ 37 ] Qiang Hao , David H . Smith IV , Naitra Iriumi , Michail Tsikerdekis , and Amy J . Ko . 2019 . A systematic investigation of replications in computing education research . ACM Trans . Comput . Edu . 19 , 4 , Article 42 ( Aug 2019 ) , 18 pages . https : / / doi . org / 10 . 1145 / 3345328 [ 38 ] Kyle J . Harms , Jason Chen , and Caitlin L . Kelleher . 2016 . Distractors in parsons problems decrease learning efficiency for young novice programmers . In Proceedings of the ACM Conference on International Computing Education Research ( ICER’16 ) . ACM , New York , NY , 241 – 250 . https : / / doi . org / 10 . 1145 / 2960310 . 2960314 [ 39 ] Rachel Harsley , Nick Green , Mehrdad Alizadeh , Sabita Acharya , Davide Fossati , Barbara Di Eugenio , and Omar AlZoubi . 2016 . Incorporating analogies and worked out examples as pedagogical strategies in a computer science tutoring system . In Proceedings of the 47th ACM Technical Symposium on Computing Science Education ( SIGCSE’16 ) . ACM , New York , NY , 675 – 680 . https : / / doi . org / 10 . 1145 / 2839509 . 2844637 [ 40 ] Carl C . Haynes and Barbara J . Ericson . 2021 . Problem - solving efficiency and cognitive load for adaptive parsons problems vs . writing the equivalent code . In Proceedings of the CHI Conference on Human Factors in Computing Systems ( CHI’21 ) . ACM , New York , NY , Article 60 , 15 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445292 [ 41 ] Juha Helminen , Petri Ihantola , Ville Karavirta , and Satu Alaoutinen . 2013 . How do students solve parsons program - ming problems ? – Execution - based vs . line - based feedback . In Proceedings of the Learning and Teaching in Computing and Engineering . IEEE , 55 – 61 . https : / / doi . org / 10 . 1109 / LaTiCE . 2013 . 26 [ 42 ] Matthew Hertz and Maria Jump . 2013 . Trace - based teaching in early programming courses . In Proceedings of the 44th ACM Technical Symposium on Computer Science Education ( SIGCSE’13 ) . ACM , New York , NY , 561 – 566 . https : / / doi . org / 10 . 1145 / 2445196 . 2445364 [ 43 ] Jane Hoffswell , Arvind Satyanarayan , and Jeffrey Heer . 2018 . Augmenting code with in situ visualizations to aid program understanding . In Proceedings of the CHI Conference on Human Factors in Computing Systems ( CHI’18 ) . ACM , New York , NY , 1 – 12 . https : / / doi . org / 10 . 1145 / 3173574 . 3174106 [ 44 ] Roya Hosseini , Kamil Akhuseyinoglu , Peter Brusilovsky , Lauri Malmi , Kerttu Pollari - Malmi , Christian Schunn , and Teemu Sirkiä . 2020 . Improving engagement in program construction examples for learning python programming . Int . J . Artific . Intell . Edu . 30 , 2 ( 2020 ) , 299 – 336 . https : / / doi . org / 10 . 1007 / s40593 - 020 - 00197 - 0 [ 45 ] Roya Hosseini , Kamil Akhuseyinoglu , Andrew Petersen , Christian D . Schunn , and Peter Brusilovsky . 2018 . PCEX : Interactive program construction examples for learning programming . In Proceedings of the 18th Koli Calling In - ternational Conference on Computing Education Research ( KoliCalling’18 ) . ACM , New York , NY , Article 5 , 9 pages . https : / / doi . org / 10 . 1145 / 3279720 . 3279726 [ 46 ] Roya Hosseini , Teemu Sirkiä , Julio Guerra , Peter Brusilovsky , and Lauri Malmi . 2016 . Animated examples as practice content in a Java programming course . In Proceedings of the 47th ACM Technical Symposium on Computing Science Education ( SIGCSE’16 ) . ACM , New York , NY , 540 – 545 . https : / / doi . org / 10 . 1145 / 2839509 . 2844639 [ 47 ] Ruanqianqian Huang , Kasra Ferdowsi , Ana Selvaraj , Adalbert Gerald Soosai Raj , and Sorin Lerner . 2022 . Investigat - ing the impact of using a live programming environment in a CS1 course . In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education ( SIGCSE’22 ) . ACM , New York , NY , 495 – 501 . https : / / doi . org / 10 . 1145 / 3478431 . 3499305 [ 48 ] Derek Hwang , Vardhan Agarwal , Yuzi Lyu , Divyam Rana , Satya Ganesh Susarla , and Adalbert Gerald Soosai Raj . 2021 . A qualitative analysis of lecture videos and student feedback on static code examples and live coding : A case study . In Proceedings of the Australasian Computing Education Conference ( ACE’21 ) . ACM , New York , NY , 147 – 157 . https : / / doi . org / 10 . 1145 / 3441636 . 3442317 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 31 [ 49 ] Michelle Ichinco , Kyle J . Harms , and Caitlin Kelleher . 2017 . Towards understanding successful novice example use in blocks - based programming . J . Visual Lang . Sent . Syst . 3 ( 2017 ) , 101 – 118 . https : / / doi . org / 10 . 18293 / VLSS2017 - 009 [ 50 ] Michelle Ichinco , Wint Yee Hnin , and Caitlin L . Kelleher . 2017 . Suggesting API usage to novice programmers with the example guru . In Proceedings of the CHI Conference on Human Factors in Computing Systems ( CHI’17 ) . ACM , New York , NY , 1105 – 1117 . https : / / doi . org / 10 . 1145 / 3025453 . 3025827 [ 51 ] Andrew F . Jarosz and Jennifer Wiley . 2014 . What are the odds ? A practical guide to computing and reporting Bayes factors . J . Problem Solv . 7 , 1 ( 2014 ) , 2 . https : / / doi . org / 10 . 7771 / 1932 - 6246 . 1167 [ 52 ] Jay Jennings and Kasia Muldner . 2021 . Investigating students’ reasoning in a code - tracing tutor . In Proceedings of the 22nd International Conference on Artificial Intelligence in Education ( AIED’21 ) . Springer - Verlag , Berlin , 203 – 214 . https : / / doi . org / 10 . 1007 / 978 - 3 - 030 - 78292 - 4 _ 17 [ 53 ] Jay Jennings and Kasia Muldner . 2021 . When does scaffolding provide too much assistance ? A code - tracing tutor investigation . Int . J . Artific . Intell . Edu . 31 , 4 ( 2021 ) , 784 – 819 . https : / / doi . org / 10 . 1007 / s40593 - 020 - 00217 - z [ 54 ] Johanna Joentausta and Arto Hellas . 2018 . Subgoal labeled worked examples in K - 3 education . In Proceedings of the 49th ACM Technical Symposium on Computer Science Education ( SIGCSE’18 ) . ACM , New York , NY , 616 – 621 . https : / / doi . org / 10 . 1145 / 3159450 . 3159494 [ 55 ] Erkki Kaila , Teemu Rajala , Mikko - Jussi Laakso , and Tapio Salakoski . 2010 . Effects of course - long use of a program visualization tool . In Proceedings of the 12th Australasian Conference on Computing Education , Vol . 103 . ACM , 97 – 106 . [ 56 ] Slava Kalyuga , Paul Ayres , Paul Chandler , and John Sweller . 2003 . The expertise reversal effect . Edu . Psychol . 38 , 1 ( 2003 ) , 23 – 31 . https : / / doi . org / 10 . 1207 / S15326985EP3801 _ 4 . arXiv : https : / / doi . org / 10 . 1207 / S15326985EP3801 _ 4 [ 57 ] Manu Kapur . 2014 . Productive failure in learning math . Cogn . Sci . 38 , 5 ( 2014 ) , 1008 – 1022 . https : / / doi . org / 10 . 1111 / cogs . 12107 [ 58 ] Amruth N . Kumar . 2014 . An evaluation of self - explanation in a programming tutor . In Proceedings of the International Conference on Intelligent Tutoring Systems . Springer International Publishing , 248 – 253 . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 07221 - 0 _ 30 [ 59 ] Amruth N . Kumar . 2019 . Helping students solve parsons puzzles better . In Proceedings of the ACM Conference on Innovation and Technology in Computer Science Education ( ITiCSE’19 ) . ACM , New York , NY , 65 – 70 . https : / / doi . org / 10 . 1145 / 3304221 . 3319735 [ 60 ] BridjetLeeandKasiaMuldner . 2020 . Instructionalvideodesign : Investigatingtheimpactofmonologue - anddialogue - stylepresentations . In ProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems ( CHI’20 ) . ACM , New York , NY , 1 – 12 . https : / / doi . org / 10 . 1145 / 3313831 . 3376845 [ 61 ] Alex Lishinski , Aman Yadav , Jon Good , and Richard Enbody . 2016 . Learning to program : Gender differences and interactive effects of students’ motivation , goals , and self - efficacy on performance . In Proceedings of the ACM Con - ference on International Computing Education Research ( ICER’16 ) . ACM , New York , NY , 211 – 220 . https : / / doi . org / 10 . 1145 / 2960310 . 2960329 [ 62 ] Raymond Lister , Elizabeth S . Adams , Sue Fitzgerald , William Fone , John Hamer , Morten Lindholm , Robert McCart - ney , Jan Erik Moström , Kate Sanders , Otto Seppälä , Beth Simon , and Lynda Thomas . 2004 . A multi - national study of reading and tracing skills in novice programmers . In Working Group Reports from ITiCSE on Innovation and Technol - ogy in Computer Science Education ( ITiCSE - WGR’04 ) . ACM , New York , NY , 119 – 150 . https : / / doi . org / 10 . 1145 / 1044550 . 1041673 [ 63 ] Tomasz D . Loboda and Peter Brusilovsky . 2010 . User - adaptive explanatory program visualization : Evaluation and insights from eye movements . User Model . User - Adapt . Interact . 20 , 3 ( 2010 ) , 191 – 226 . https : / / doi . org / 10 . 1007 / s11257 - 010 - 9077 - 1 [ 64 ] Lauren E . Margulieux and Richard Catrambone . 2016 . Improving problem solving with subgoal labels in expository text and worked examples . Learn . Instruct . 42 ( 2016 ) , 58 – 71 . https : / / doi . org / 10 . 1016 / j . learninstruc . 2015 . 12 . 002 [ 65 ] Lauren E . Margulieux and Richard Catrambone . 2017 . Using learners’ self - explanations of subgoals to guide initial problemsolvinginappinventor . In ProceedingsoftheACMConferenceonInternationalComputingEducationResearch ( ICER’17 ) . ACM , New York , NY , 21 – 29 . https : / / doi . org / 10 . 1145 / 3105726 . 3106168 [ 66 ] Lauren E . Margulieux and Richard Catrambone . 2019 . Finding the best types of guidance for constructing self - explanations of subgoals in programming . J . Learn . Sci . 28 , 1 ( 2019 ) , 108 – 151 . https : / / doi . org / 10 . 1080 / 10508406 . 2018 . 1491852 [ 67 ] Lauren E . Margulieux , Richard Catrambone , and Mark Guzdial . 2016 . Employing subgoals in computer programming education . Comput . Sci . Edu . 26 , 1 ( 2016 ) , 44 – 67 . https : / / doi . org / 10 . 1080 / 08993408 . 2016 . 1144429 [ 68 ] Lauren E . Margulieux , Richard Catrambone , and Laura M . Schaeffer . 2018 . Varying effects of subgoal labeled exposi - tory text in programming , chemistry , and statistics . Instruct . Sci . 46 , 5 ( 2018 ) , 707 – 722 . https : / / doi . org / 10 . 1007 / s11251 - 018 - 9451 - 7 [ 69 ] Lauren E . Margulieux , Briana B . Morrison , and Adrienne Decker . 2020 . Reducing withdrawal and failure rates in introductory programming with subgoal labeled worked examples . Int . J . STEM Edu . 7 , 1 ( 2020 ) , 1 – 16 . https : / / doi . org / 10 . 1186 / s40594 - 020 - 00222 - 7 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 32 K . Muldner et al . [ 70 ] Lauren E . Margulieux , Briana B . Morrison , Baker Franke , and Harivololona Ramilison . 2020 . Effect of implementing subgoals in Code . org’s intro to programming unit in computer science principles . ACM Trans . Comput . Edu . 20 , 4 , Article 26 ( Oct . 2020 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3415594 [ 71 ] Lauren E . Margulieux , Briana B . Morrison , Mark Guzdial , and Richard Catrambone . 2016 . Training learners to self - explain : Designing instructions and examples to improve problem solving . In Proceedings of the International Confer - ence of the Learning Sciences ( ICLS’16 ) , Vol . 2 . International Society of the Learning Sciences , 98 – 105 . Retrieved from https : / / www . isls . org / icls / 2016 / docs / ICLS2016 _ Volume _ 1 _ 30June2016 . pdf . [ 72 ] Richard E . Mayer . 1975 . Different problem - solving competencies established in learning computer programming with and without meaningful models . J . Edu . Psychol . 67 , 6 ( 1975 ) , 725 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 67 . 6 . 725 [ 73 ] Richard E . Mayer . 1976 . Some conditions of meaningful learning for computer programming : Advance organizers and subject control of frame order . J . Edu . Psychol . 68 , 2 ( 1976 ) , 143 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 68 . 2 . 143 [ 74 ] Richard E . Mayer . 1989 . Models for understanding . Rev . Edu . Res . 59 , 1 ( 1989 ) , 43 – 64 . https : / / doi . org / 10 . 3102 / 00346543059001043 [ 75 ] Richard E . Mayer and Bruce K . Bromage . 1980 . Difference recall protocols for technical texts due to advance orga - nizers . J . Edu . Psychol . 72 , 2 ( 1980 ) , 209 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 72 . 2 . 209 [ 76 ] Monika Mladenović , Žana Žanko , and Marin A . Cuvic . 2021 . The impact of using program visualization techniques on learning basic programming concepts at the K - 12 level . Comput . Appl . Eng . Edu . 29 , 1 ( 2021 ) , 145 – 159 . https : / / doi . org / 10 . 1002 / cae . 22315 [ 77 ] Andrés Moreno , Erkki Sutinen , and Mike Joy . 2014 . Defining and evaluating conflictive animations for programming education : The case of Jeliot ConAn . In Proceedings of the 45th ACM Technical Symposium on Computer Science Education ( SIGCSE’14 ) . ACM , New York , NY , 629 – 634 . https : / / doi . org / 10 . 1145 / 2538862 . 2538888 [ 78 ] Briana B . Morrison . 2017 . Dual modality code explanations for novices : Unexpected results . In Proceedings of the ACM Conference on International Computing Education Research ( ICER’17 ) . ACM , New York , NY , 226 – 235 . https : / / doi . org / 10 . 1145 / 3105726 . 3106191 [ 79 ] Briana B . Morrison , Lauren E . Margulieux , and Adrienne Decker . 2020 . The curious case of loops . Comput . Sci . Edu . 30 , 2 ( 2020 ) , 127 – 154 . https : / / doi . org / 10 . 1080 / 08993408 . 2019 . 1707544 [ 80 ] Briana B . Morrison , Lauren E . Margulieux , Barbara Ericson , and Mark Guzdial . 2016 . Subgoals help students solve Parsons problems . In Proceedings of the 47th ACM Technical Symposium on Computing Science Education ( SIGCSE’16 ) . ACM , New York , NY , 42 – 47 . https : / / doi . org / 10 . 1145 / 2839509 . 2844617 [ 81 ] Briana B . Morrison , Lauren E . Margulieux , and Mark Guzdial . 2015 . Subgoals , context , and worked examples in learn - ing computing problem solving . In Proceedings of the 11th Annual International Conference on Computing Education Research ( ICER’15 ) . ACM , New York , NY , 21 – 29 . https : / / doi . org / 10 . 1145 / 2787622 . 2787733 [ 82 ] Seyedreza Mousavi , Renae Low , and John Sweller . 1995 . Reducing cognitive load by mixing auditory and visual presentation modes . J . Edu . Psychol . 87 , 2 ( 1995 ) , 319 – 334 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 87 . 2 . 319 [ 83 ] Kasia Muldner , Winslow Burleson , and Michelene Chi . 2014 . Learning from self - explaining emergent phenomena . In Proceedings of the International Conference of the Learning Sciences ( ICLS’14 ) , Vol . 2 . International Society of the Learning Sciences , 847 – 854 . [ 84 ] Kasia Muldner and Cristina Conati . 2010 . Scaffolding meta - cognitive skills for effective analogical problem solving via tailored example selection . Int . J . Artific . Intell . Edu . 20 , 2 ( 2010 ) , 99 – 136 . https : / / doi . org / 10 . 3233 / JAI - 2010 - 0004 [ 85 ] Amir Shareghi Najar , Antonija Mitrovic , and Bruce M . McLaren . 2016 . Learning with intelligent tutors and worked examples : selecting learning activities adaptively leads to better learning outcomes than a fixed curriculum . User Model . User - Adapt . Interact . 26 , 5 ( Dec . 2016 ) , 459 – 491 . https : / / doi . org / 10 . 1007 / s11257 - 016 - 9181 - y [ 86 ] Greg L . Nelson , Benjamin Xie , and Amy J . Ko . 2017 . Comprehension first : Evaluating a novel pedagogy and tutoring system for program tracing in CS1 . In Proceedings of the ACM Conference on International Computing Education Research ( ICER’17 ) . ACM , New York , NY , 42 – 51 . https : / / doi . org / 10 . 1145 / 3105726 . 3106178 [ 87 ] Seppo Nevalainen and Jorma Sajaniemi . 2006 . An experiment on short - term effects of animated versus static vi - sualization of operations on program perception . In Proceedings of the 2nd International Workshop on Computing Education Research ( ICER’06 ) . ACM , New York , NY , 7 – 16 . https : / / doi . org / 10 . 1145 / 1151588 . 1151591 [ 88 ] Dale Parsons and Patricia Haden . 2006 . Parson’s programming puzzles : A fun and effective learning tool for first programming courses . In Proceedings of the 8th Australasian Conference on Computing Education ( ACE’06 ) . Australian Computer Society , AUS , 157 – 163 . [ 89 ] Elizabeth Patitsas , Michelle Craig , and Steve Easterbrook . 2013 . Comparing and contrasting different algorithms leads to increased student learning . In Proceedings of the 9th Annual International ACM Conference on International Computing Education Research ( ICER’13 ) . ACM , New York , NY , 145 – 152 . https : / / doi . org / 10 . 1145 / 2493394 . 2493409 [ 90 ] José Baltasar García Pérez - Schofield , Matías García - Rivera , Francisco Ortin , and María J . Lado . 2019 . Learning memory management with C - Sim : A C - based visual tool . Comput . Appl . Eng . Edu . 27 , 5 ( 2019 ) , 1217 – 1235 . https : / / doi . org / 10 . 1002 / cae . 22147 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 33 [ 91 ] D . N . Perkins , Chris Hancock , Renee Hobbs , Fay Martin , and Rebecca Simmons . 1986 . Conditions of learning in novice programmers . J . Edu . Comput . Res . 2 , 1 ( 1986 ) , 37 – 55 . https : / / doi . org / 10 . 2190 / GUJT - JCBJ - Q6QU - Q9PL [ 92 ] ThomasW . Price , JosephJayWilliams , JaemarieSolyst , andSamihaMarwan . 2020 . Engagingstudentswithinstructor solutions in online programming homework . In Proceedings of the CHI Conference on Human Factors in Computing Systems . ACM , New York , NY , 1 – 7 . https : / / doi . org / 10 . 1145 / 3313831 . 3376857 [ 93 ] Yizhou Qian and James Lehman . 2017 . Students’ misconceptions and other difficulties in introductory programming : A literature review . ACM Trans . Comput . Edu . 18 , 1 , Article 1 ( Oct . 2017 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3077618 [ 94 ] Jill L . Quilici and R . Mayer . 1996 . Role of examples in how students learn to categorize statistics word problems . J . Edu . Psychol . 88 , 1 ( 1996 ) , 144 – 161 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 88 . 1 . 144 [ 95 ] Adalbert Gerald Soosai Raj , Pan Gu , Eda Zhang , Arokia Xavier Annie R . , Jim Williams , Richard Halverson , and Jignesh M . Patel . 2020 . Live - coding vs static code examples : Which is better with respect to student learning and cognitive load ? In Proceedings of the 22nd Australasian Computing Education Conference ( ACE’20 ) . ACM , New York , NY , 152 – 159 . https : / / doi . org / 10 . 1145 / 3373165 . 3373182 [ 96 ] Adalbert Gerald Soosai Raj , Jignesh M . Patel , Richard Halverson , and Erica Rosenfeld Halverson . 2018 . Role of live - coding in learning introductory programming . In Proceedings of the 18th Koli Calling International Conference on Computing Education Research ( KoliCalling’18 ) . ACM , New York , NY , Article 13 , 8 pages . https : / / doi . org / 10 . 1145 / 3279720 . 3279725 [ 97 ] TeemuRajala , ErkkiKaila , JohannesHolvitie , RikuHaavisto , Mikko - JussiLaakso , andTapioSalakoski . 2011 . Compar - ing the collaborative and independent viewing of program visualizations . In Proceedings of the Frontiers in Education Conference ( FIE’11 ) . IEEE Computer Society , F3G – 1 - 1 – F3G – 7 . https : / / doi . org / 10 . 1109 / FIE . 2011 . 6142795 [ 98 ] Stephen K . Reed , Alexandra Dempster , and Michael Ettinger . 1985 . Usefulness of analogous solutions for solving algebra word problems . J . Exper . Psychol . : Learn . , Mem . Cogn . 11 , 1 ( Jan . 1985 ) , 106 – 125 . https : / / doi . org / 10 . 1037 / / 0278 - 7393 . 11 . 1 . 106 [ 99 ] Alexander Renkl . 1997 . Learning from worked - out examples : A study on individual differences . Cogn . Sci . 21 , 1 ( 1997 ) , 1 – 29 . https : / / doi . org / 10 . 1016 / S0364 - 0213 ( 99 ) 80017 - 2 [ 100 ] Alexander Renkl . 2014 . Toward an instructionally oriented theory of example - based learning . Cogn . Sci . 38 ( 2014 ) , 1 – 37 . https : / / doi . org / 10 . 1111 / cogs . 12086 [ 101 ] Bethany Rittle - Johnson , Abbey M . Loehr , and Kelley Durkin . 2017 . Promoting self - explanation to improve math - ematics learning : A meta - analysis and instructional design principles . ZDM Math . Edu . 49 ( 2017 ) , 599 – 611 . https : / / doi . org / 10 . 1007 / S11858 - 017 - 0834 - Z [ 102 ] Bethany Rittle - Johnson , Jon R . Star , and Kelley Durkin . 2012 . Developing procedural flexibility : Are novices prepared to learn from comparing procedures ? Brit . J . Edu . Psychol . 82 , Pt 3 ( 2012 ) , 436 – 55 . [ 103 ] A . Robins , J . Rountree , andN . Rountree . 2003 . Learningandteachingprogramming : Areviewanddiscussion . Comput . Sci . Edu . 13 , 2 ( 2003 ) , 137 – 172 . [ 104 ] Brian H . Ross . 1987 . This is like that : The use of earlier problems and the separation of similarity effects . J . Exper . Psychol . : Learn . , Mem . Cogn . 13 , 4 ( Oct . 1987 ) , 629 – 639 . https : / / doi . org / 10 . 1037 / 0278 - 7393 . 13 . 4 . 629 [ 105 ] Marc J . Rubin . 2013 . The effectiveness of live - coding to teach introductory programming . In Proceedings of the 44th ACM Technical Symposium on Computer Science Education ( SIGCSE’13 ) . ACM , New York , NY , 651 – 656 . https : / / doi . org / 10 . 1145 / 2445196 . 2445388 [ 106 ] Jorma Sajaniemi , Marja Kuittinen , and Taina Tikansalo . 2008 . A study of the development of students’ visualizations of program state during an elementary object - oriented programming course . J . Edu . Res . Comput . 7 , 4 , Article 3 ( Jan . 2008 ) , 31 pages . https : / / doi . org / 10 . 1145 / 1316450 . 1316453 [ 107 ] Dale Schunk , Antoinette R . Hanson , and Paula D . Cox . 1987 . Peer - model attributes and children’s achievement be - haviors . J . Edu . Psychol . 79 , 1 ( 1987 ) , 54 – 61 . https : / / doi . org / 10 . 1037 / 0022 - 0663 . 79 . 1 . 54 [ 108 ] Ana Selvaraj , Eda Zhang , Leo Porter , and Adalbert Gerald Soosai Raj . 2021 . Live coding : A review of the literature . In Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education . ACM , New York , NY , 164 – 170 . https : / / doi . org / 10 . 1145 / 3430665 . 3456382 [ 109 ] Amir Shareghi Najar and Antonija Mitrovic . 2013 . Examples and tutored problems : How can self - explanation make a difference to learning ? In Artificial Intelligence in Education , H . Chad Lane , Kalina Yacef , Jack Mostow , and Philip Pavlik ( Eds . ) . Springer , Berlin , 339 – 348 . [ 110 ] Nianfeng Shi , Zhiyu Min , and Ping Zhang . 2017 . Effects of visualizing roles of variables with animation and IDE in novice program construction . Telemat . Informat . 34 , 5 ( 2017 ) , 743 – 754 . https : / / doi . org / 10 . 1016 / j . tele . 2017 . 02 . 005 [ 111 ] Teemu Sirkiä and Juha Sorva . 2015 . How do students use program visualizations within an interactive ebook ? In Proceedings of the 11th Annual International Conference on International Computing Education Research ( ICER’15 ) . ACM , New York , NY , 179 – 188 . https : / / doi . org / 10 . 1145 / 2787622 . 2787719 [ 112 ] Elliot Soloway and Kate Ehrlich . 1984 . Empirical studies of programming knowledge . IEEE Trans . Softw . Eng . SE - 10 , 5 ( 1984 ) , 595 – 609 . https : / / doi . org / 10 . 1109 / TSE . 1984 . 5010283 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . 13 : 34 K . Muldner et al . [ 113 ] Juha Sorva . 2013 . Notional machines and introductory programming education . ACM Trans . Comput . Edu . 31 , 2 , Article 8 ( July 2013 ) , 31 pages . https : / / doi . org / 10 . 1145 / 2483710 . 2483713 [ 114 ] Juha Sorva , Ville Karavirta , and Lauri Malmi . 2013 . A review of generic program visualization systems for introduc - tory programming education . ACM Trans . Comput . Edu . 13 , 4 , Article 15 ( Nov . 2013 ) , 64 pages . https : / / doi . org / 10 . 1145 / 2490822 [ 115 ] Ben Stephenson . 2019 . Coding demonstration videos for CS1 . In Proceedings of the 50th ACM Technical Symposium on Computer Science Education ( SIGCSE’19 ) . ACM , New York , NY , 105 – 111 . https : / / doi . org / 10 . 1145 / 3287324 . 3287445 [ 116 ] John Sweller . 2011 . Cognitive load theory , in Psychology of Learning and Motivation , Vol . 55 . Academic Press , 37 – 76 . https : / / doi . org / 10 . 1016 / B978 - 0 - 12 - 387691 - 1 . 00002 - 8 [ 117 ] John Sweller , Paul Ayres , and Slava Kalyuga . 2011 . The split - attention effect . In Cognitive Load Theory . Springer , New York , NY , 111 – 128 . https : / / doi . org / 10 . 1007 / 978 - 1 - 4419 - 8126 - 4 _ 9 [ 118 ] JohnSwellerandGrahamA . Cooper . 1985 . Theuseofworkedexamplesasasubstituteforproblemsolvinginlearning algebra . Cogn . Instruct . 2 , 1 ( 1985 ) , 59 – 89 . [ 119 ] John G . Trafton and Brian J . Reiser . 1993 . Studying examples and solving problems : Contributions to skill acqui - sition . In Proceedings of the 15th Annual Conference of the Cognitive Science Society . Lawrence Erlbaum Associates , 1017 – 1022 . [ 120 ] Jaime Urquiza - Fuentes and J . Ángel Velázquez - Iturbide . 2013 . Toward the effective use of educational program animations : The roles of student’s engagement and topic complexity . Comput . Edu . 67 ( 2013 ) , 178 – 192 . https : / / doi . org / 10 . 1016 / j . compedu . 2013 . 02 . 013 [ 121 ] Vesa Vainio and Jorma Sajaniemi . 2007 . Factors in novice programmers’ poor tracing skills . In Proceedings of the 12th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education ( ITiCSE’07 ) . ACM , New York , NY , 236 – 240 . https : / / doi . org / 10 . 1145 / 1268784 . 1268853 [ 122 ] Tamara van Gog , Liesbeth Kester , and Fred Paas . 2011 . Effects of worked examples , example - problem , and problem - example pairs on novices’ learning . Contemp . Edu . Psychol . 36 , 3 ( 2011 ) , 212 – 218 . https : / / doi . org / 10 . 1016 / j . cedpsych . 2010 . 10 . 004 [ 123 ] Tamara van Gog and Nikol Rummel . 2010 . Example - Based Learning : Integrating Cognitive and Social - Cognitive Research Perspectives . Edu . Psychol . Rev . 22 , 2 ( June 2010 ) , 155 – 174 . https : / / doi . org / 10 . 1007 / s10648 - 010 - 9134 - 7 [ 124 ] Tamara van Gog , Nikol Rummel , and Alexander Renkl . 2019 . Learning how to solve problems by studying examples . In The Cambridge Handbook of Cognition and Education , John Dunlosky and Katherine A . Editors Rawson ( Eds . ) . Cambridge University Press , 183 – 208 . [ 125 ] JeroenJ . G . vanMerriënboer , JanGerritSchuurman , MarcelB . M . deCroock , andFredPaas . 2002 . Redirectinglearners attention during training : Effects on cognitive load , transfer test performance and training efficiency . Learn . Instruct . 12 , 1 ( 2002 ) , 11 – 37 . https : / / doi . org / 10 . 1016 / S0959 - 4752 ( 01 ) 00020 - 2 [ 126 ] Jeroen J . G . Van Merriënboer . 1990 . Strategies for programming instruction in high school program : Program com - pletion vs . program generation . J . Edu . Comput . Res . 6 , 3 ( 1990 ) , 265 – 285 . https : / / doi . org / 10 . 2190 / 4NK5 - 17L7 - TWQV - 1EHL [ 127 ] Jeroen J . G . van Merriënboer and Marcel B . M . de Croock . 1992 . Strategies for computer - based programming instruc - tion : Program completion vs . program generation . J . Edu . Comput . Res . 8 , 3 ( 1992 ) , 365 – 394 . https : / / doi . org / 10 . 2190 / MJDX - 9PP4 - KFMT - 09PM [ 128 ] Kurt VanLehn . 1996 . Cognitive skill acquisition . Annu . Rev . Psychol . 47 , 1 ( 1996 ) , 513 – 539 . https : / / doi . org / 10 . 1146 / annurev . psych . 47 . 1 . 513 . arXiv : https : / / doi . org / 10 . 1146 / annurev . psych . 47 . 1 . 513 PMID : 15012487 . [ 129 ] Kurt VanLehn . 1998 . Analogy events : How examplesare used during problem solving . Cogn . Sci . 22 , 3 ( 1998 ) , 347 – 388 . [ 130 ] Kurt VanLehn . 1999 . Rule - learning events in the acquisition of a complex skill : An evaluation of cascade . J . Learn . Sci . 8 , 1 ( 1999 ) , 71 – 125 . https : / / doi . org / 10 . 1207 / s15327809jls0801 _ 3 [ 131 ] PengWang , RomanBednarik , andAndrésMoreno . 2012 . Duringautomaticprogramanimationexplanationsafteran - imations have greater impact than before animations . In Proceedings of the 12th Koli Calling International Conference on Computing Education Research ( KoliCalling’12 ) . ACM , New York , NY , 100 – 109 . https : / / doi . org / 10 . 1145 / 2401796 . 2401808 [ 132 ] Wengran Wang , Archit Kwatra , James Skripchuk , Neeloy Gomes , Alexandra Milliken , Chris Martens , Tiffany Barnes , and Thomas Price . 2021 . Novices’ learning barriers when using code examples in open - ended programming . In Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V . 1 . ACM , New York , NY , 394 – 400 . https : / / doi . org / 10 . 1145 / 3430665 . 3456370 [ 133 ] Wengran Wang , Yudong Rao , Rui Zhi , Samiha Marwan , Ge Gao , and Thomas W . Price . 2020 . Step Tutor : Supporting students through step - by - step example - based feedback . In Proceedings of the ACM Conference on Innovation and TechnologyinComputerScienceEducation ( ITiCSE’20 ) . ACM , NewYork , NY , 391 – 397 . https : / / doi . org / 10 . 1145 / 3341525 . 3387411 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 . A Review of Worked Examples in Programming Activities 13 : 35 [ 134 ] Gerhard Weber . 1996 . Individual selection of examples in an intelligent learning environment . Int . J . Artific . Intell . Edu . 7 , 1 ( 1996 ) , 3 – 31 . [ 135 ] Nathaniel Weinman , Armando Fox , and Marti A . Hearst . 2021 . Improving instruction of programming patterns with faded Parsons problems . In Proceedings of the CHI Conference on Human Factors in Computing Systems ( CHI’21 ) . ACM , New York , NY , Article 53 , 4 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445228 [ 136 ] Ruth Wylie and Michelene T . H . Chi . 2014 . The self - explanation principle in multimedia learning . In The Cambridge Handbook of Multimedia Learning ( 2nd ed . ) , Richard E . Mayer ( Ed . ) . Cambridge University Press , 413 – 432 . https : / / doi . org / 10 . 1017 / CBO9781139547369 . 021 [ 137 ] Benjamin Xie , Dastyni Loksa , Greg L . Nelson , Matthew J . Davidson , Dongsheng Dong , Harrison Kwik , Alex Hui Tan , Leanne Hwa , Min Li , and Amy J . Ko . 2019 . A theory of instruction for introductory programming skills . Comput . Sci . Edu . 29 , 2 – 3 ( 2019 ) , 205 – 253 . https : / / doi . org / 10 . 1080 / 08993408 . 2019 . 1565235 [ 138 ] Benjamin Xie , Greg L . Nelson , and Amy J . Ko . 2018 . An explicit strategy to scaffold novice program tracing . In Proceedings of the 49th ACM Technical Symposium on Computer Science Education ( SIGCSE’18 ) . ACM , New York , NY , 344 – 349 . https : / / doi . org / 10 . 1145 / 3159450 . 3159527 [ 139 ] Jeong Yang , Young Lee , and Kai - Hsiung Chang . 2018 . Evaluations of JaguarCode : A web - based object - oriented pro - gramming environment with static and dynamic visualization . J . Syst . Softw . 145 ( 2018 ) , 147 – 163 . https : / / doi . org / 10 . 1016 / j . jss . 2018 . 07 . 037 [ 140 ] Albina Zavgorodniaia , Arto Hellas , Otto Seppälä , and Juha Sorva . 2020 . Should explanations of program code use audio , text , or both ? A replication study . In Proceedings of the 20th Koli Calling International Conference on Computing EducationResearch ( KoliCalling’20 ) . ACM , NewYork , NY , Article5 , 10pages . https : / / doi . org / 10 . 1145 / 3428029 . 3428050 [ 141 ] Albina Zavgorodniaia , Artturi Tilanterä , Ari Korhonen , Otto Seppälä , Arto Hellas , and Juha Sorva . 2021 . Algorithm visualization and the elusive modality effect . In Proceedings of the 17th ACM Conference on International Computing Education Research ( ICER’21 ) . ACM , New York , NY , 368 – 378 . https : / / doi . org / 10 . 1145 / 3446871 . 3469747 [ 142 ] Rui Zhi , Min Chi , Tiffany Barnes , and Thomas W . Price . 2019 . Evaluating the effectiveness of Parsons problems for block - based programming . In Proceedings of the ACM Conference on International Computing Education Research ( ICER’19 ) . ACM , New York , NY , 51 – 59 . https : / / doi . org / 10 . 1145 / 3291279 . 3339419 Received 31 July 2021 ; revised 20 May 2022 ; accepted 4 August 2022 ACM Transactions on Computing Education , Vol . 23 , No . 1 , Article 13 . Publication date : December 2022 .