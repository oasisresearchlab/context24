Machine Learning in District Heating System Energy Optimization Samuel Idowu Lule˚a University of Technology Lule˚a , Sweden Email : samuel . idowu @ ltu . se Christer ˚Ahlund Lule˚a University of Technology Lule˚a , Sweden Email : christer . ahlund @ ltu . se Olov Schel´en Lule˚a University of Technology Lule˚a , Sweden Email : olov . schelen @ ltu . se Abstract —This paper introduces a work in progress , where we intend to investigate the application of Reinforcement Learning ( RL ) and online Supervised Learning ( SL ) to achieve energy op - timization in District - Heating ( DH ) systems . We believe RL is an ideal approach since this task falls under the control - optimization problem where RL has yielded optimal results in previous work . The magnitude and scale of a DH system complexity incurs the curse of dimensionalities and model , hereby making RL a good choice since it provides a solution for the problem . To assist RL even further with the curse of dimensionalities , we intend to investigate the use of SL to reduce the state space . To achieve this , we shall use historical data to generate a heat load sub - model for each home . We believe using the output of these sub - models as feedback to the RL algorithm could signiﬁcantly reduce the complexity of the learning task . Also , it could reduce convergence time for the RL algorithm . The desired goal is to achieve a real - time application , which takes operational actions when it receives new direct feedback . However , considering the dynamics of DH system such as large time delay and dissipation in DH network due to various factors , we hope to investigate things such as the appropriate data sampling rate and new parameters / sensors that could improve knowledge about the state of the system , especially on the consumer side of the DH network . Keywords — Pervasive computing , reinforcement learning , online supervised learning , district heating system , smart city I . I NTRODUCTION The nature of a learning problem determines the Machine Learning ( ML ) type that would be most suitable for the task at hand . Today , there are various techniques emanating from the three main types of ML ( i . e . supervised , unsupervised and reinforcement learning ) , each designed to suit a speciﬁc group of problems . For problems under the pervasive context , one of the most desired features of a learning system is the ability to support continuous learning and utilize the adapted model either in real - time or near real - time . This need is largely based on the expectation of systems to readjust to changes in its properties over time in unforeseen ways . This concept is popularly referred to as concept drift [ 13 ] . Concept drift is peculiar to many fundamental processes , especially those that relate to human activities . Changes could come as a result of varying underlying factors , and hence it needs to be taken into consideration in a learning process . Therefore , in a system that has a tendency of concept drift , if an ML technique without continuous learning capability is employed , then it is important to periodically re - train or re - model [ 4 ] . For systems that cannot provide continuous accurate labeled feedback , classical Supervised Learning ( SL ) without online capability is ideal . For other problems , which could provide continuous labeled feedback when making use of the model . Such problems would beneﬁt from the constant feedback that helps regulate the gen - erated model to stay relevant in the near future . Such systems interact with the outer physical environment periodically to receive the state observation of such environment . In general , it is most appropriate to employ some automated form of remodeling in a real - time system that should be adaptive to variations in its outer environment . An ML method may have the capability of taking into account periodic and continuous feedback . This ensures reliable results in future even in the face of concept drift . Nevertheless , the choice of ML technique chosen for such tasks still depends largely on the problem at hand . To this end , a group of ML methods that is suitable for such purpose is the adaptive online methods of SL . These have proved useful for problems relating to online classiﬁcations and regression problems . Secondly , Reinforcement Learning ( RL ) supports online learning in problems relating to achieving speciﬁcally deﬁned goals or control optimization . By default , RL involves the use of continuous direct feedback to learn how to achieve a deﬁned goal . In learning tasks with huge dimension of parameters , large dimension size could cause overﬁtting [ 7 ] if sufﬁciently large amount of training samples is not available . For continuous learning , the use of more samples with time eventually helps reduce overﬁtting . SL methods have proved applicable in many practical problems while the other machine learning methods have not been able to make such claim . This has led to much focus on SL . District Heating ( DH ) related works such as [ 1 ] [ 2 ] have addressed DH systems using mathematical models for optimal control . Others have used statistical models to predict heat demands from consumers . Designing a complete and accurate model of a DH system would require more than a trivial approach . The non - triviality stems from its magnitude , scale and complex interaction between various units of the DH network , such as pipes and heat - exchanger . As a result of the DH’s dynamic properties , which require a high level of details , its model would require high computation times and intensive computational resource for solving optimization problems . Considering the curse of dimensionality and the curse of model that plague a system such as this , opting for a solution , which would avoid the construction of a theoretical model while providing the solution for an optimal control seems an excellent choice . RL method comes in handy here since the model - free methods of RL do not need the transition probability matrices , and it stores the value functions with function approximation methods [ 5 ] . 2014 IEEE International Conference on Pervasive Computing and Communications Work in Progress 978 - 1 - 4799 - 2736 - 4 / 14 / $ 31 . 00 ©2014 IEEE 224 A . Objectives The objectives of this paper are described as follows : • The foremost intention of this paper is to identify a suitable ML approach that could enhance energy efﬁciency at the consumer side of a DH system . • To identify and brieﬂy discuss possible energy saving strategies and relating parameters in the DH system , which are crucial for the target system . • To motivate the need for an online prediction method , which would be adaptable to changes in underlying factors that inﬂuence heat load pattern . This paper is organized as follows : section 2 describes the brief overview of ML that relates to this work ; section 3 describes components and characteristics DH system ; section 4 discusses the proposed approach to this work and the paper concludes in section 5 . II . M ACHINE L EARNING ML applies suitable algorithms on data for a learning problem . Tom Mitchell [ 9 ] , deﬁned a well - posed learning Problem : A computer program is said to learn from experience E ( observed examples ) with respect to some task T and some performance measure P if its performance on T , as measured by P , improves with experience E . Therefore , we can deﬁne ML as one that can learn from experience with respect to some class of tasks and a performance measure [ 9 ] . In general terms , ML can be clearly deﬁned as set of methods that can automatically detect patterns ( general regularities ) in empirical data , such as sensor data or databases and then use the discovered patterns to predict future data , or execute other types of decision making under uncertainty [ 10 ] . ML is divided into three principal groups ; Supervised Learning ( predictive learning approach ) , unsupervised learning ( descriptive learning approach ) and RL [ 10 ] . In the following sub - sections , we shall present a brief overview of supervised learning and reinforcement learning . A . Supervised Learning In this approach , the task is to learn a mapping from input x to output y , given a labeled set of input - output pairs D = { ( x i , y i ) } Ni = 1 . Where D is the training set , and N is the cardinality of the training set [ 10 ] . Each example input x i is a D – dimensional vector of values representing the features of an instance . The output y i part of the training set represents the class or label of its respective features [ 10 ] . The type of output variable , y i differentiates the two types of tasks performed under the SL . In cases where the output variable y i is categorical or nominal , these types of ML tasks are referred to as classiﬁcation or pattern recognition [ 10 ] [ 6 ] . The common algorithms used for classiﬁcation tasks include Naive Bayes , C4 . 5 decision trees and kNN ( k Nearest Neighbor ) . The second SL type is referred to as regression , where the output variable , y i , is a real - valued scalar [ 10 ] [ 6 ] . Common algorithms used for regression include linear regression as well as CART ( Classiﬁcation and Regression Tree ) , which can also be used for classiﬁcation tasks . Traditionally , SL is performed ofﬂine , i . e . a one - time generation of a model estimate from a batch of instances . When it is important for learn on the ﬂy with new instances being obtained in the near future . Such a situation requires us to perform online learning , where we can update the model estimates as each new data instance arrives . Online gradient descent [ 15 ] is a simple example of online learning algorithm . B . Reinforcement Learning Reinforcement learning is learning what to do ( i . e . how to map situations to actions with the goal to maximize a numerical reward signal ) [ 12 ] . The actions to be taken to achieve the goal is not given as it is with other types of ML , but a learner must discover which actions gives the most reward by trying them [ 12 ] . Russell et al , describe RL as a form of learning where the agent learns from a series of reinforcements – rewards or punishments [ 11 ] . The most important aspects of the RL system include ; sensation – ability to sense the state of the environment , action – must be able to take actions , which affects state of its environment and goal – system must have goals relating to the state of the environment [ 12 ] . Q - learning [ 14 ] is one of the common algorithms used for RL . RL algorithms have its root in Dynamic Programming ( DP ) algorithms . For classical dynamic programming style , to obtain an optimal solution , there is a need to generate the transition probability and reward matrices from the given random variables . In the case of RL however , given the same distributions of governing random variables , a near - optimal solution can be solved by the use of a simulator and RL algorithm without the overhead of transition probability and reward matrices . III . E NERGY O PTIMIZATION IN D ISTRICT H EATING S YSTEM The work in progress centers on energy optimization within a DH system and a Combined Heat and Power ( CHP ) plant . In this section , we describe the target system , which includes the energy plant , the DH network and the consumer end - points . We also discuss the complexities of a DH system that makes it difﬁcult to model in traditional ways , and hence a necessity for a learning approach . A . Heat Distribution Network and Consumers End - Points A DH System is a system for distributing heat generated in a centralized location for residential and commercial heat - ing requirements such as space heating and domestic water heating . A DH network provides a means of distributing heat energy to different homes . From the CHP plant , heat is distributed to the customer in the form of hot water via a network of insulated pipes . DH system consist of feed and return lines . At the consumer level , the DH network is usually connected to the building heating system via a building level substation . This consists of heat exchangers , sensors , control valve actuators , speed pump controls , ﬂow meter and gauges . The heat supplied is mainly used in the form of space heating and domestic hot water . Currently , the target plant provides heat for 4119 substations connected to the DH network . Consumer billing relies on a 24 - hour periodic measurement of energy consumption . In a bid to capture the most information about the state of the DH system periodically , we aim to employ the use of 2014 IEEE International Conference on Pervasive Computing and Communications Work in Progress 225 appropriate sensing devices that would report the state of the system in a real - time manner . There is a need for periodic report of parameters from various units within the DH system , such as the substations . Additional sensors shall be deployed to provide data that gives better insight regarding energy usage patterns in homes . This will support data collection from remote metering devices and transfer the data to a central system wirelessly . The smart meters are capable of providing real - time / near real - time reporting and heat quality monitoring . Currently , measurements on primary side of DH network are collected in a periodic manner of 24 hours . In this work , we aim to identify and collect useful additional data from the secondary side of the DH network ( i . e . at the consumer side of the DH system ) . Also , we intend to have a faster data collection rate of at least 1 hour . B . Complex characteristics of DH system Modeling a complete DH system can be a complex task to achieve , either for operational planning or optimization . The complexity comes by as a result of the dynamics of the system and its components as well as multiple factors and parameters that affect its operation . Such complex system requires a smarter way of modeling instead of the classical modeling approach . The operation of a DH system is partly affected by the energy demand patterns in consumers’ home and the factors relating to the distribution network . One of such factor is the time delay in DH network . The time delay in a DH network is usually large compared with time delays in other parts of the DH system ( e . g . building level substation ) . The time delays appearing in the network are mostly as a result of the transportation time of the DH water from the production plant to consumers and back again . It can take several hours before a consumer registers a change in the supply temperature from the plant . Also , there is usually response delay at the CHP plant to changes at the consumer’s side . In bigger systems , it can take up to 10 - 12 hours before the change has reached the most distant consumer [ 1 ] . Heat loss to the surrounding environment or heat storage in the environment adds to the complexity of DH system . Another factor is the change in performance state of a DH system over time due to conditions such as deterioration of network pipes or valve controls . Other factors that affect the operations of a DH system are the outdoor air temperature , time of the day , season of the year , dissipation ( i . e . the friction loss in pipes converts the pumping energy into heat energy , which tends to raise the temperature of the heating water ) [ 1 ] as well as pressure and ﬂow rate . IV . P ROPOSED A PPROACH The objective is to optimize energy usage in DH system and hence minimize cost of production in CHP . We focus on the optimization in consumer homes as we believe this would result in efﬁciency across the entire DH network , and hence reduce production cost at the CHP plant and auxiliary boilers . We investigate how we can maintain steady energy demands from homes ( i . e . ﬂattening peak demands ) and maintaining a very low return temperature , which increases the efﬁciency of power generation in the CHP plant . Previous work on heat load forecast shows that the outdoor temperature together with the social behavior of consumers have the greatest inﬂuence on the heat demand in homes [ 3 ] . Erik ( 2002 ) further used these factors as the core of the load prediction model developed for heat - load prediction and also discussed other factors that affect heat load . Figure 1 shows the conceptual illustration of the proposed approach . Fig . 1 . Illustration of proposed approach . Online SL models are used to predict heat demand for each consumer while using the actual heat demand as feedback . The RL algorithm controls the charge / discharge of accumulators and load balancing within home ( space heating and domestic hot water ) . In addition to direct observation space of the DH network , the RL algorithm gets feedback from heat demand models of various homes . Online prediction of energy demands in home : With the help of online SL ( depicted in Figure 1 as Heat Demand models ) , we plan to predict energy demand in domestic heating systems ( space heating and hot water ) . Each home shall use related parameters to pre - determine the expected energy demand periodically . Simultaneously , the solution aims to integrate into smart city systems . We shall investigate how existing knowledge captured by smart city systems could improve heat load predictions from consumers . Our system will be integrated with the Sense Smart City platform [ 8 ] . Behavioral information that relates to occupants of homes such as user location , activities and age are of interest in this regard . We believe this would provide a new level of information that could result in better heat demand prediction for homes . Existing historical data will play an important role here , as we aim to start with designing an appropriate heat demand prediction model based on them . The outcome of the online model generated from the learning phase shall be used as input for the RL algorithm , hence reducing the state space ( see Figure 2 ) . Fig . 2 . Reduction of state space used by the RL agent . Each home has a separate SL model for predicting its heat load . 2014 IEEE International Conference on Pervasive Computing and Communications Work in Progress 226 In line with the objectives addressed in this paper , we motivate the use of optimal control of energy distribution strategies in a DH system as a mean to increased energy efﬁciency . We predict that with a well - learned optimal control of the discharge and charge operation of heat storage units such as accumulators ( as well as other necessary factors ) , higher efﬁciency could be achieved in the DH network . Also , increased control of heat load - balancing within homes can also provide better energy efﬁciency . The balancing shall be mainly between the space heating and hot water supply ( e . g . waste from hot - water usage could be recycled for space heating ) . The extensive data collection on the consumer end of the network implies the ability to monitor the energy supplied and used for space heating as well as for domestic hot water separately . We believe this can help to achieve energy usage efﬁciency by employing heat load balancing strategy . The project also aims to use accumulators at the building level substations to save heat energy and thereby ﬂattening demand proﬁle . Heat accumulators have been used mostly at the network - level ( primary side ) to maximize energy efﬁciency in DH system . We aim to investigate the possibilities of obtaining higher efﬁciency with the use of accumulators in homes . We aim to learn the optimal control of charge and discharge action for the accumulator in each building using a RL approach . This will work in close connection with the expected energy demand from homes and other necessary factors . The load proﬁle can be used to decide when to heat the accumulator . Heat load prediction at homes shall be approached from the supervised ML style . We plan to use historical data to assist in generating the required prediction model . The following shows parameters to be considered in the relation to the ML approach . SL - Parameters for the heat load predictions : Some of the currently identiﬁed parameters include outdoor tempera - ture , social behavior , type of building / consumer , number of occupants , time of day , season , day of the week , information from smart city system . RL - Observation space : Some of the identiﬁed observation space includes the supply temperature from CHP to DH network , return temperature back to CHP , temperature , pres - sure and ﬂow rate at several points within the DH network , expected heat demand from consumers ( predicted using other parameters ) , information about state of accumulators , ground temperature around pipes at several points . RL - Action space : The main control actions will be charging and discharging of heat storage . Also , valve control for using recycled hot water for space heating . RL - Rewards : The peaks in heat demand from homes directly affects the changes in return ﬂow temperature . Hence having a steady return ﬂow implies steady heat demand in home . Therefore , we can have positive valued reward for every step while the temperature of the return ﬂow is steady ( e . g . within a speciﬁc range ) . RL - Termination : An RL agent requires a way to determine when to end a trial episode ( i . e . how to determine when a learning attempt fails ) . A RL episode should terminate when the temperature changes of the return ﬂow exceeds a speciﬁed value . V . C ONCLUSION This paper introduced a work at its preliminary stage . To achieve increased energy efﬁciency at the consumer side of a DH system , we identify that an appropriate method requires a combination of ML approaches . We recognize SL as a suitable method for heat load prediction ( ML data - driven energy estimation ) while RL is suitable for the optimal control of heat storage and load balancing strategies . The ﬁrst part of the proposed approach deals with the estimation of heat load pattern in homes and the prediction of heat demand from the consumer’s side . The work shall go beyond commonly used parameters in similar work that involves heat load prediction . As future work , we intend to install new smart sensors at the consumer side , to gather needful parameter about heat consumption in homes . Furthermore , we aim to consider the social behaviors of home occupants by taking advantage of existing smart city platform . This would prove as effective integration of smart city components . The second part of this work intends to consider the entire DH system and its multiple units as a whole , and learn how to achieve optimal control of identiﬁed strategies within the network . The main strategy here is the use of heat storage in homes ; hence we seek to achieve an optimal control of charge and discharge actions of heat storage systems . A CKNOWLEDGMENT We gratefully acknowledge the support and collaboration of Skellefte˚a Kraft AB , Skellefte˚a , Sweden . R EFERENCES [ 1 ] Atli Benonysson , Benny Bhm , and Hans F . Ravn . Operational optimiza - tion in a district heating system . Energy Conversion and Management , 36 ( 5 ) : 297 – 314 , 1995 . [ 2 ] Soon - Young Choi , Kee - Youn Yoo , Jeong - Bin Lee , Chee Burm Shin , and Myung - June Park . Mathematical modeling and control of thermal plant in the district heating system of Korea . Applied Thermal Engineering , 30 ( 14 - 15 ) : 2067 – 2072 , October 2010 . [ 3 ] Erik Dotzauer . Simple model for prediction of loads in district - heating systems . Applied Energy , 73 ( 3 - 4 ) : 277 – 284 , November 2002 . [ 4 ] Wei Fan , Yi an Huang , Haixun Wang , and Philip S . Yu . Active mining of data streams . In in Proceedings of the Fourth SIAM International Conference on Data Mining , pages 457 – 461 . [ 5 ] Abhijit Gosavi . Simulation - Based Optimization : Parametric Opti - mization Techniques and Reinforcement Learning . Kluwer Academic Publishers , Norwell , MA , USA , 2003 . [ 6 ] Peter Harrington . Machine Learning in Action . Manning Publications Co , Greenwich , CT , USA , 2012 . [ 7 ] Douglas M . Hawkins . The problem of overﬁtting . Journal of chemical information and computer sciences , 44 ( 1 ) : 1 – 12 , 2004 . [ 8 ] http : / / sensesmartcity . org / . Sense smart city project , 2012 . [ 9 ] Thomas M . Mitchell . Machine Learning . McGraw - Hill , Inc , New York , NY , USA , 1 edition , 1997 . [ 10 ] Kevin P . Murphy . Machine Learning : A Probabilistic Perspective ( Adaptive Computation and Machine Learning series ) . The MIT Press , aug 2012 . [ 11 ] Stuart Russell and Peter Norvig . Artiﬁcial Intelligence : A Modern Approach . Prentice Hall , 3 ; 3rd edition , dec 2009 . [ 12 ] Richard S . Sutton and Andrew G . Barto . Reinforcement Learning : An Introduction . MIT Press , 1998 . [ 13 ] Alexey Tsymbal . The problem of concept drift : deﬁnitions and related work . Technical Report MSU - CSE - 00 - 2 , Department of Computer Science , Trinity College Dublin , Ireland , 2004 . [ 14 ] ChristopherJ . C . H . Watkins and Peter Dayan . Q - learning . Machine Learning , 8 ( 3 - 4 ) : 279 – 292 , 1992 . [ 15 ] Martin Zinkevich . Online convex programming and generalized in - ﬁnitesimal gradient ascent , 2003 . 2014 IEEE International Conference on Pervasive Computing and Communications Work in Progress 227