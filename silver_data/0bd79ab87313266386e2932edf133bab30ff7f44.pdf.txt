KIESLERET AL . ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT AND ROBOT – LIKE AGENT Sara Kiesler , Aaron Powers , Susan R . Fussell , and Cristen Torrey Carnegie Mellon University People’s physical embodiment and presence increase their salience and importance . We predicted people would anthropomorphize an embod - ied humanoid robot more than a robot – like agent , and a collocated more than a remote robot . A robot or robot – like agent interviewed participants about their health . Participants were either present with the robot / agent , or interacted remotely with the robot / agent projected life – size on a screen . Participants were more engaged , disclosed less undesirable be - havior , and forgot more with the robot versus the agent . They ate less and anthropomorphized most with the collocated robot . Participants inter - acted socially and attempted conversational grounding with the ro - bot / agent though aware it was a machine . Basic questions remain about how people resolve the ambiguity of interacting with a humanlike nonhuman . By virtue of our shared global fate and similar DNA , we humans increasingly ap - preciate our similarity to nature’s living things . At the same time , we want ma - chines , animals , and plants to meet our needs . Both impulses perhaps motivate the increasing developmentof humanlike robotsand software agents . In this article , we examine social context moderation of anthropometric interactions between people and humanlike machines . We studied whether an embodied humanlike robot would elicit stronger anthropomorphic interactions than would a software agent , and whether physical presence moderated this effect . At the outset , robots and agents differ from ordinary computer programs in that they have autonomy , interact with the environment , and initiate tasks ( Franklin & Graesser , 1996 ) . The marriage of artificial intelligence and computer science has made possible robots and agents with humanlike capabilities , such as lifelike ges - tures and speech . Typically , “robot” refers to a physically – embodied system whereas “agent” refers to a software system . Examples of humanlike robots are NASA’s Robonaut—a humanoid that can hand tools to an astronaut ( robonaut . jsc . nasa . gov / robonaut . html ) , Honda’s Asimo , and Hiroshi Ishiguro’s 169 Social Cognition , Vol . 26 , No . 2 , 2008 , pp . 169 - 181 ThisresearchwassupportedbyNationalScienceFoundationgrantsIIS – 0121426andHSD – 0624275 . We thank Hau – Yu Wong , Sean Gilroy , Greg Armstrong , Judy Matthews , and the People and Robots , Nursebot , and Social Robots project teams for their suggestions and help . Correspondence concerning this article should be addressed to Sara Kiesler , E – mail : kiesler @ cs . cmu . edu . android , Gemini . Software agents include animated icons like Clippit , the Microsoft Office 97 software assistant , voice conversational help bots on websites , and three – dimensional characters and avatars in online virtual worlds . Anyone who has tried to make an airline reservation with “Alan , ” the automated telephone system , knows we have far to go before machines interact smoothly and naturally with people . Yet robots and agents have begun to give researchers a unique window on human social cognition ( Scassellati , 2004 ) . People stereotype software agents based on their humanlike faces ( Yee , Bailenson , & Rickertsen , 2007 ) or voice ( Nass & Brave , 2005 ) , and they think baby – face robots are sociable ( Powers & Kiesler , 2006 ) . Participants assume a robot has different knowledge of landmarks depending on its purported nationality ( Lee , Kiesler , Lau , & Chiu , 2005 ) and differ - ent knowledge of dating depending on whether its voice is male or female ( Powers et al . , 2005 ) . People also project their attitudes onto machines , and they respond positively to similarity in features or behaviors that , in people , encourage projection ( Ames , 2004 ) . A human face on a software agent induces participants to cooperate with the agent as much as they do with a real person ( Parise , Kiesler , Sproull , & Waters , 1999 ) . Participants recognize extroverted and introverted synthetic speech on a book buying website and reveal similarity – attraction responses in their book re - views and reviewer ratings ( Nass & Lee , 2001 ) . Mimicry in an agent ( Bailenson & Yee , 2005 ) and perspective taking in a robot ( Torrey , Powers , Marge , Fussell , & Kiesler , 2006 ) lead to more favorable attitudes . The cognitive process of anthropomorphism may involve some variant of in - stance – based ( e . g . , Hintzman , 1986 ) or exemplar – based processing ( e . g . , Linville , Fischer , & Salovey , 1989 ) and analogistic mapping ( Gentner & Markman , 1997 ) . Viewing a humanlike machine may activate associations created from experience with people , machines , and population stereotypes of fantasy characters . For exam - ple , a lifelike robot that tells a joke might activate exemplars of the nonsocial cate - gory , machines , and of the social category , humorous people . Combining these exemplars could lead to the experience of an integrated concept , such as cheerful robot . A machine that engages with the environment is likely to enervate this process ( e . g . , Scholl & Tremoulet , 2000 ; Rakison & Poulin – Dubois , 2001 ) . In Heider and Simmel’s ( 1944 ) film ( http : / / anthropomorphism . org / psychology2 . html ) , partici - pants perceived a meaningful structure in the movement of three animated objects , and created elaborate social narratives to describe them ( see also Berry , Misovich , Kean , & Baron , 1992 ) . Running the Heider – Simmel film backwards , or changing its speed , destroys its perceived meaningfulness , implying dependence on precise psychophysical events . Nonetheless , perceptual events do not explain all social aspects of anthropomor - phism . In one study , participants who owned a dog were more cooperative with a doglike software agent than those who did not own a dog ( Parise et al . , 1999 ) . In an - other study , when participants were asked to imagine “their own dog” or “a neigh - bor’s dog” enacting the identical behavior , they explained their imagined own dogs’ behavior more anthropomorphically ; this difference held even among those who did not actually own a dog ( Experiment 1 , Kiesler , Lee , & Kramer , 2006 ) . This result mirrors people’s tendencies to attribute more complex human qualities to people they like ( Leyens et al . , 2000 ) . If our relationship with an animal or object changes how we anthropomorphize it ( Kiesler , Lee , & Kramer , 2006 ) , then a con - 170 KIESLER ET AL . text – sensitive process of anthropomorphizing machines and animals would seem to exist , running in parallel to perceptual processes . Perhaps such a process evolved as humans learned to protect and value other people and animals ( Caporael & Heyes , 1997 ) . If anthropomorphism is partly a value prescription process that facilitates poten - tial interaction , then face – to – face interaction with a humanlike machine should prompt greater anthropomorphism of the machine . Two important attributes of face – to – face interaction are that one’s partner is embodied and that he or she is physically present . The actual presence of others is physiologically arousing , caus - ing “social facilitation” ( Zajonc , 1965 ) . Embodimentand presence could make a ma - chine salient and important , encouraging anthropomorphism . Embodiment is not the same as presence . We are more engaged with real , embod - ied people than those who are projected even if they are not actually interacting with us ( e . g . , Schmitt , Gilovich , Goore , & Joseph , 1986 ) . The human brain processes embodied structures differently than those that appear in two dimensions ( e . g . , Kawamichi , Kikuchi , & Ueno , 2005 ) . We think this distinction is true of technology as well . Software agents on a screen a few inches away can move in lifelike ways that today’s robots cannot—swim , fly , and run . On the other hand , a robot is three – dimensional , moves in 3 – D space , and can manipulate objects or even touch us . In accomplishing such actions , robots must obey gravity and the limitations of their electro – mechanical systems . Just one study evaluated the impact of embodi - mentin machines . Yamato Shinozawa , Naya , & Kogure ( 2001 ) compareda small ro - botic rabbit with an agent that looked like the same robot , presented on a computer monitor . Both were about three feet from the participant . The authors reported that participants felt closer to the robot but were more influenced by the agent’s choice on a simple color selection task . The authors did not measure anthropomorphism , however . Another characteristic of face – to – face interaction that can make interactions sa - lient and important is that one’s partner is physically collocated . This proximity causes people to structure their representations concretely ( Henderson , Fujita , Trope , & Liberman , 2006 ) and increases people’s concern with being evaluated , or “evaluation apprehension” ( Guerin , 1986 ) . Evaluation apprehension may be re - sponsible for conformity to others in their presence , choking effects , and reduced disclosure of sensitive information in the presence of others . For the reasons described above , we hypothesized : H1 . Participants will anthropomorphize a robot more than a robot – like soft - ware agent . They will find it more lifelike , more engaging , and more like - able . They will be more influenced by the robot than the agent , but will disclose less personal information to the robot . H2 . Participants will anthropomorphize a collocated robot more than a re - mote robot projected on a large screen before them . They will find the collocated robot more humanlike , more engaging and likeable , be more influenced by it , but will disclose less personal information to it . We also measured participants’ memory for the agent’s or robot’s dialogue but did not make a prediction . People may process face – to – face conversation more deeply than remote conversation but their involvement in conversational grounding and self – presentation might interfere with remembering the material discussed . ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT 171 METHOD The design was a between – groups design ( Robot vs . Agent × Present vs . Projected ) . In the robot conditions , the participant was either collocated with the robot ( Figure 1A ) or in a different room and saw the robot projected in real time onto a large screen ( Figure 1B ) . In the agent conditions , the participant was either collocated with a computer monitor on which the agent was displayed ( Figure 1C ) or in a dif - ferent room from the monitor and saw the agent projected live onto a large screen ( Figure 1D ) . PARTICIPANTS We recruited 113 participants from the community in and near Carnegie Mellon University . They were paid $ 10 . Participants were 52 % male , with an average age of 26 years ( range 17 – 57 ) . The participants represented 56 fields of study or work , in - cluding architecture , film and theatre , business , medicine , and journalism . Only 10 participants specialized in computer science or robotics . Because of our attempt to add an additional factor , we assigned twice as many participants to each robot con - dition ( remote robot n = 38 , collocated robot n = 37 ) than to each agent condition ( ns = 19 ) . In half of each robot condition , the robot moved autonomously from the door - 172 KIESLER ET AL . FIGURE 1 . Four conditions of the experiment . A = Robot present with participant , B = Robot re - moteand projected tothe participant , C = Software agent present withparticipant , D = Software agent remote and projected to the participant way to the participant at the beginning of the experiment . This manipulation did not have any effect on the results , and we have collapsed across these conditions . PROCEDURE The experimenter told participants that their goal was to “have a discussion with this robot about basic health habits . ” So that different instructions did not influence outcomes , the experimenter referred to the interviewer as a “robot” in every condi - tion . The robot or robot – like agent spoke aloud to the participants and participants replied by typing on a keyboard ( see below ) . The robot or agent asked the partici - pants about their exercise , diet , weight and height , mental well being , and teeth flossing , and encouraged them to engage in healthy behaviors such as eating less fat and more salads , and exercising more . The robot or agent also asked five sensitive questions from the Crowne and Marlowe ( 1960 ) social desirability scales , such as “Have you ever deliberately said something against someone ? ” The robot or agent also told several jokes . ( e . g . , “Do you know , why did the lettuce go red ? ” “Because it saw the salad dressing . ” ) The dialogue took 10 – 15 minutes . At the end of the ses - sion , the experimenter reentered the room , asked participants to complete an online questionnaire , and offered them a bowl of snack bars . EQUIPMENT The robot Nursebot was used in the robot conditions . Nursebot has an animated face with 17 degrees of freedom , including eyebrows , eyelids , eyes , mouth , and neck . It stands 53 inches tall , with a head about 8 inches wide and 7 inches high . In the present condition , the robot stood 44 inches away from the subject . In the remote projected condition , the robot was in another room ; an image of the robot was pro - jected onto a large screen 50 inches away from the participant , to control for the ro - bot’s apparent size . The software agent’s appearance was created from a photo of the robot’s head and neck . In the present condition , the head was displayed 4 . 5 inches wide and 3 . 5 inches tall on an LCD screen , 21 inches away from the partici - pant . In the remote projected condition , the agent’s head , 16 inches tall and 13 inches wide , was projectedonthelarge screen , 50 inches away fromtheparticipant . The robot’s facial motions were scripted to match the content of the dialogue . In the present and projected robot conditions , the lips were synched with a male voice , using Theta ( Lenzo & Black , 2007 ) . As expected , participants rated the robot / agent as more masculine than feminine ( F [ 1 , 109 ] = 4 . 9 , p < . 05 ) . Like the robot , the agent movedits lips in synchrony with its male – voice speech . However , the agent was not as physically expressive as the robot , in that it could not turn its body , or move its head , eyes , or eyebrows . The robot and agent spoke all of their lines aloud . The second author built a dia - logue engine that branched and could ask for more elaboration of vague responses . The participants typed all of their responses on an interface similar to instant messaging . Their typed input appeared on a monitor on the robot ( Present Robot condition ) or below the agent or robot on the monitor or the projected image . We did not use speech recognition because this technology is still too primitive ; we wanted to allow participants to converse as fully as possible . We kept a record of all conversations . ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT 173 DEPENDENT VARIABLES The measures are described in Table 1 . The behavioral measures included engage - ment ( interview time ) , disclosure , social influence , and conversational memory . We also administered a posttestquestionnaire to obtain self – reports of participants’ subjective experience and attributions of the robot or agent . The manipulation check of the embodimentmanipulation ( robot vs . agent ) was to count the number of participants who said that the robot was not “real . ” To check on the manipulation of presence we measured participants’ rated sense of presence . 174 KIESLER ET AL . TABLE 1 . Measures in the Experiment . Type of Measure Measure Scale or Observation Manipulationcheck Self – report : Sense of pres - ence Felt presence , real discussion , same place ( 3 items , α = . 74 ) Engagement Time with robot Minutes in conversation ( log ) Disclosure Disclosure of sensitive infor - mation Did the participant admit negative behavior ? How much did the participant disclose about him - self / herself in response to disclosure questions ? ( Log word count ) Social influence Eating Did the participant eat health bars rather than candy bars ? Did the participant eat fewer calories ? Self – report : Intentions Did the participant agree to read for pleasure , eat salads , exercise ( how often ) , and floss his / her teeth next week ? Conversationalmemory Memory of information from robot Number of information facts recalled out of 8 possible . Attributions Self – report : Lifelikeness Humanlike , lifelike , machinelike ( rev . ) , natural ( 1 – 7 scale , 4 items , α = . 83 ) Self – report : Traits Dominant ( 1 – 7 scale , 4 items , α = . 83 ) Trustworthy ( 1 – 7 scale , 5 items , α = . 83 ) Sociable ( 1 – 7 scale , 10 items , α = . 89 ) Responsive ( 1 – 7 scale , 6 items , α = . 88 ) Competent ( 1 – 7 scale , 14 items , α = . 93 ) Respectful ( 1 – 7 scale , 3 items , α = . 76 ) Other Self – report : Task enjoyment Conversation helpfulness ( 1 – 7 scale , 9 items , α = . 91 ) Good content ( 1 – 7 scale , 3 items , α = . 69 ) Enjoyment of task ( 1 – 7 scale , 7 items , α = . 87 ) Self – report : Mood Affect ( 1 – 7 scale , 4 items , α = . 83 ) Self report : Effort NASA workload ( 1 – 7 scale , 3 items , α = . 65 ) RESULTS Tests of the hypotheses were conducted using analysis of variance to examine the difference between the robot and agent condition , and a planned contrast of the ro - bot conditions to test the difference between the present robot and the projected robot . PRELIMINARY ANALYSES Several participants were not fluent English speakers and had trouble understand - ing machine – generated speech . The questionnaire item , “I was able to understand what the robot was saying , ” predicted incomplete or “I don’t understand you” re - sponses during the interview with the robot or agent . We used scores on the speech comprehension item as a covariate in the analyses . In some analyses reported be - low , there are fewer than 113 scores due to machine malfunction or participants’ not responding to a questionnaire item . We transformed skewed variables ( time , word counts , calories ) using a log transformation . Of the 38 participants in the agent conditions , 12 complained that the agent was not a “real robot” ( e . g . , “I was expecting an actual robot—a physical being . ” ) . No participants complained in the robot conditions that the robot was not real . Partici - pantsin thepresentconditionsfelt a greater sense of presencewiththepresentrobot or agent than in the projected conditions ( F [ 1 , 108 ] = 3 . 8 , p = . 05 ) . Participants also felt a greater sense of presence with the robot versus the agent ( F [ 1 , 108 ] = 4 . 3 , p < . 05 ) suggesting thatembodimentand presenceare notentirely independentfactors . ENGAGEMENT We predicted the robot would be more engaging than the agent , and the present ro - bot more engaging than the projected robot , as measured by the amount of time that the participant spent with the robot or agent . The main effect for robot versus agent was significant , M = 13 . 8 minutes ( SE = . 21 ) versus M = 12 . 9 minutes ( SE = . 29 ) ; ( F [ 1 , 105 ] = 6 . 5 , p = . 01 ) . The presence main effect and interaction term were not signifi - cant , and neither planned contrast was significant . DISCLOSURE The agent or robot asked the participants five sensitive questions . We hypothesized participants would disclose less about themselves to the robot than to the agent , particularly when the robot was present . Those in the robot condition tended to ad - mit fewer indiscretions ( F [ 1 , 108 ] = 2 . 9 , p = . 09 ) . We also counted the number of words that the participants used to describe their socially undesirable behavior ( e . g . , “I told my sister I hated her” ) and compared that number with the number of words that participants used in the rest of the interview . Of those who elaborated their disclosures , those who interacted with the robot disclosed comparatively less than participants who interacted with the agent ( interaction F [ 1 , 115 ] = 4 . 2 , p < . 05 ) . Responses to the present and projected robots did not differ . ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT 175 INFLUENCE Nearly all participants said they intended to exercise and eat less fat in the future , and the robot or agent did not influence these responses . However , participants’ re - sponses to the offer of snack bars did differ by condition . When participants were present with the agent or robot , they were more likely to choose a health bar than a candy bar ( interaction ( F [ 1 , 108 ] = 3 . 3 , p = . 07 ) and those who chose a snack bar and interacted with the collocated robot ate fewer calories ( interaction F [ 1 , 70 ] = 3 . 1 , p = . 08 ; Present robot vs . Projected robot contrast F = 6 . 4 , p = . 01 ) . CONVERSATIONAL MEMORY The questionnaire contained 8 memory questions . Those in the robot condition re - membered fewer items correctly ( M = 4 . 9 , SE = . 18 ) than did those in the agent con - dition ( M = 5 . 6 , SE = . 25 ; F [ 1 , 107 ] = 5 . 7 , p = . 01 ) . The robot might have been more distracting than the agent due to the participant’s greater effort at self – presentation or conversational grounding . ATTRIBUTIONS Participants rated the robot as more lifelike than the agent ( F [ 1 , 108 ] = 10 , p < . 01 ) . These ratings are shown in figure 2 . The interaction with presence was not signifi - cant ( F = 1 . 4 ) . A within – subjects analysis across the trait scales showed that participants rated the robot as having a stronger and more positive personality than the agent ( F [ 1 , 176 KIESLER ET AL . FIGURE 2 . Ratings of the robot’s and robot - like agent’s lifelikeness 1 1 . 5 2 2 . 5 3 3 . 5 4 4 . 5 R o b o t P r e s e n t R o b o t P r o j e c t e d A g e n t P r e s e n t A g e n t P r o j e c t e d L i f e li k e n e ss S c a l e 108 ] = 10 . 2 , p < . 01 ) . The ratings shown in figure 3 show that the robot was viewed as more dominant , trustworthy , sociable , responsive , competent , and respectful . The interaction with presence was not significant ( F = . 5 ) but , as predicted , the contrast of present robot versus projected robot was significant ( F = 5 . 1 , p < . 05 ) . OTHER MEASURES Ratings of how much participants enjoyed the task were not different across condi - tions ( overall mean = 5 . 8 on the 7 point scale ) . Ratings of the helpfulness of the robot showed a marginal preference for the robot’s contribution over the agent’s ( M = 5 . 1 , SE = . 2 vs . M = 4 . 5 SE = . 25 ; F [ 1 , 112 ] = 3 . 6 , p = . 06 ) . Also , ratings of the information content in the interview showed a trend to prefer the robot’s content ( even though it was identical to the agent’s ; p = . 1 ) , and there was a significant main effect of pres - ence , present mean = 4 . 8 , SE = . 17 vs . projected mean = 4 . 2 , SE = . 17 ( F [ 1 , 112 ] = 6 . 5 , p = . 01 ) . DISCUSSION We predicted a robot would be more engaging than an agent . Our results indicate that interacting with the embodied robot was a more compelling experience for par - ticipants and elicited more anthropomorphic interaction and attributions . Partici - pants spent more time with the robot , liked it better , attributed to its stronger , more positive personality traits , and said it was more lifelike . Consistent with previous research on face – to – face interaction , participants were more inhibited with the ro - bot than with the agent ; they disclosed less socially undesirable behavior to it and consumed fewer calories after interacting with it . In short , these differences suggest that the participants interacted with the robot more as a person than they did with the agent . We also hypothesized that participants would find a collocated robot more compelling than a remote robot projected lifesize on a screen . Although some trends in this direction were evident ( see , for example , trends in Figure 3 ) , most of these comparisons were not statistically significant . Two unusual aspects of the en - vironment probably contributed to the weakness of the presence variable . First , participants experienced the robot as more present than the agent ; this finding rep - licates previous research suggesting that embodiment may be confounded with sense of presence ( Nowak & Biocca , 2003 ) . Second , the robotin the remotecondition was projected life – size in high resolution on a large screen . This high fidelity might have reduced the robot’s apparent remoteness . This experiment tested only one instantiation of a robot and agent . We had only one autonomous robot , and the agent was modeled on the likeness of the robot to control for differences in appearance across conditions . Even small differences in the shape of the robot’s head can affect participants’ perceptions of a robot ( Powers & Kiesler , 2006 ) . Had wechosena different robot – agentpair tostudy , for example , a robot versus a 3 – D agent in an immersive virtual environment , the results might be different . Because of the comparative weakness of the presence variable , this experiment does not settle a question we posed earlier , as to whether anthropomorphism is an automatic “bottom up” feature matching process or whether it is modified by social context as suggested by previous research ( e . g . , Kiesler et al . , 2006 ) . Anthropomor - ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT 177 phic responses to the robot as compared with the agent might have been elicited by the robot’s greater expressiveness , which in turn could have facilitated the partici - pant’s relationship with the machine ( Berry , Butler , & Rosis , 2005 ) . UNDERSTANDING ANTHROPOMORPHISM Previous research and everyday experience suggest that even when people’s ab - stract understanding of an entity is clearly not anthropomorphic , their social behav - ior and attributions may be anthropomorphic ( Barrett & Keil , 1996 ) . In this experiment , participants knew they were conversing with a machine but their con - versations were surprisingly true to social scripts of the sort one would expect in an experiment with a human confederate . Although we asked participants to answer the robot’s health questions , we did not require that they converse socially with it . However , social conversation was the rule for participants . When the robot / agent said “hello , ” all participants replied with a hello or more informally ( “hi , ” “hi there , ” or “hey” ) , and many participants volunteered how they were feeling , “I missed lunch , ” “I didn’t sleep too well last night” ) . Those in the robot condition were slightly more informal ( 57 % versus 49 % in the agent condition ) , assessed by counting slang ( e . g . , “hi” versus “hello” ) . When the robot or agent told a joke , many participants laughed aloud and almost all typed a response , “he he , ” or “ha ha . ” When the robot or agent complained about 178 KIESLER ET AL . FIGURE 3 . Trait ratings of the robot and robot - like agent its difficulty in exercising , participants answered politely , with sympathy ( “that’s too bad , ” “ I’m sorry to hear that , ” “me too” ) , or with advice ( “robots don’t need to exercise , ” “you’re not missing much” ) . When the robot bemoaned its weight , par - ticipants made light of it ( “you look pretty trim” ) or commiserated ( “I worry about my weight too” ) . Just twelve participants mentioned technology ( “technology is improving , ” “yes , batteries weigh a lot” ) . One comment illustrates how partici - pants integrated machine conceptswithanthropomorphicinteraction , “Yeah , I hate carrying heavy laptop batteries around ! ” In another memorable session , a servo in the robot’s head broke and began burning during the experiment , causing a thin trail of smoke to rise out of the robot’s head . Instead of retrieving the experimenter , the participant typed to the robot , “Your head is smoking . ” The robot / agentcould not be interrupted and sometimes did not have the partici - pant’s responses in its database , so it was fairly ineffective at conversational grounding . Participants showed some understanding of this inadequacy , but none - theless attempted repair to achieve shared meaning . For example , in the context of talking about eating salads , the robot / agent asked participants if they had heard a joke about lettuce . A participant knew the joke ( “I’ve heard that before” ) and gave the punch line but the robot gave it anyway . The participant then repeated twice , “I knew that one . ” After the experiment , the most commoncomplaint about the exper - iment , other than that the voice should be more intelligible , was that the robot needed to be more flexible and interruptible ( “ . . . if it could do that , that would be awesome” ) . Previous work and the informal observations noted above suggest that people may hold parallel but different understandings of a machine ( and by extension , any nonhuman ) —a level that consists of nonanthropomorphic abstract knowledge or beliefs about the entity , and a more concrete , socially – engaged level consisting of anthropomorphicmeanings and behaviors . Since Francis Bacon , the latter phenom - enon has been derogated , characterized as “folk psychology , ” and was the target of science education ( see Guthrie , 1993 ; Mitchell , 1997 ) . A counter – movement has pointed to the biological similarity we hold with animals ( Crist , 1999 ) and the func - tional usefulness of anthropomorphicthinking ( Panksepp , 2003 ) . We speculate that a debate about whether anthropomorphic meaning is educable or not , fallacy or truth , is likely tocontinueevenas wediscover its basis in human social cognition . ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT 179 REFERENCES Ames , D . R . ( 2004 ) . Insidethemindreader’stool kit : Projectionandstereotypinginmental state inference . Journal of Personality and Social Psychology , 87 , 340 – 353 . Bailenson , J . N . , & Yee , N . ( 2005 ) . Digitalchame - leons : Automatic assimilation of nonver - bal gestures in immersive virtual envi - ronments . Psychological Science , 16 , 814 – 819 . Barrett , J . L . , & Keil , F . C . ( 1996 ) . Conceptualiz - ing a nonnatural entity : Anthropomor - phism in God concepts . Cognitive Psychology , 31 , 219 – 247 . Berry , D . S . , Misovich , S . J . , Kean , K . J . , & Baron , R . M . ( 1992 ) . Effects of disruption of structure and motion on perceptions of socialcausality . PersonalityandSocialPsy - chology Bulletin 18 , 237 – 244 . Berry , D . C . , Butler , L . T . , & de Rosis , F . ( 2005 ) . Evaluating a realistic agent in an ad - vice – giving task . International Journal of Human – Computer Studies , 65 , 304 – 327 . 180 KIESLER ET AL . Caporael , L . R . , & Heyes , C . M . ( 1997 ) . Why anthropomorphize ? Folk psychologies and other stories . In R . W . Mitchell , N . S . Thompson , and H . L . Miles Eds . Anthro - pomorphism , anecdotes and animals ( pp . 59 – 73 ) . Albany : State University of New York Press . Crowne , D . P . , & Marlowe , D . ( 1960 ) . A new scaleofsocialdesirabilityindependentof psychopathology . Journal of Consulting Psychology , 24 , 349 – 354 . Crist , E . ( 1999 ) . Images of Animals : Anthropomor - phism and Animal Mind . Philadelphia : Temple University Press . Franklin , S . , & Graesser , A . ( 1996 ) . Is it an agent , orjustaprogram ? Ataxonomyforauton - omous agents . Proceedings of the Third In - ternationalWorkshoponAgentTheories , Ar - chitectures , and Languages , ( p . 2135 ) Springer – Verlag . Gentner , D . , & Markman , A . ( 1997 ) . Structure mapping in analogy and similarity . American Psychologist 52 , 45 – 56 . Guthrie , S . E . ( 1993 ) . Faces in the Clouds : A New TheoryofReligion . NewYork : OxfordUni - versity Press . Guerin , B . ( 1986 ) . Mere presence effects in hu - mans . Journal of Experimental Social Psy - chology , 22 , 38 – 77 . Henderson , M . D . , Fujita , K . , Trope , Y . , & Liberman , N . ( 2006 ) . Transcending the “here” : The effect of spatial distance on social judgment . Journal of Personality and Social Psychology , 91 , 845 – 856 . Heider , F . , & Simmel , M . ( 1944 ) An experimen - tal study of apparent behavior . American Journal of Psychology , 57 , 243 – 249 . Hintzman , D . ( 1986 ) . Scheme abstraction in a multiple – trace memory model . Psycho - logical Review , 93 , 441 – 428 . Kawamichi , H . , Kikuchi , Y . , & Ueno , S . ( 2005 ) . IEEE Transactions on Magnetics , 10 , 4200 – 4202 . Kiesler , S . , Lee , S – L . , & Kramer , A . ( 2006 ) . Rela - tionshipeffectsinpsychologicalexplana - tions of nonhuman behavior . Anthrozoos , 19 , 335 – 352 . Lee , S . , Kiesler , S . , Lau , I . Y . , & Chiu , C . – Y . ( 2005 , April ) . Human mentalmodels of human - oid robots . Proceedings of the 2005 IEEE International Conference on Robotics and Automation , ICRA ‘05 ( pp . 2767 – 2772 ) . Barcelona , Spain . Lenzo , K . A . , & Black , A . W . ( 2007 ) . Theta , Cepstral . Retrieved April 7 , 2007 , from http : / / www . cepstral . com . Leyens , J . , Paladino , P . M . , Rodriguez – Torres , R . , Vaes , J . , Demoulin , S . , Rodri - guez – Perez , A . & Gaunt , R . ( 2000 ) . The emotional side of prejudice : The attribu - tion of secondary emotions to ingroups and outgroups . Personality and Social Psy - chology Review , 4 , 186 – 197 . Linville , P . W . , Fischer , G . W . , & Salovey , P . ( 1989 ) . Perceived distributions of the characteristics of in – group and out – group members : Empirical evidence and a computer simulation . Journal of Person - ality and Social Psychology , 57 , 165 – 188 . Mitchell , N . , Thompson , S . , & Miles , H . L . ( 1997 ) . Anthropomorphism , Anecdotes and Animals . Albany : StateUniversityofNew York Press . Nass , C . , & Lee , K . M . ( 2001 ) . Does com - puter – synthesized speech manifest per - sonality ? Experimental tests of recogni - tion , similarity – attraction , and consistency – attraction . Journal of Experi - mental Psychology : Applied , 7 , 171 – 181 . Nass , C . & Brave , S . ( 2005 ) . Wired for speech : How voice activates and advances the hu - man – computer relationship . Cambridge , MA : MIT Press . Nowak , K . L . , & Biocca , F . ( 2003 ) . The effect of agencyandanthropomorphismonusers’ senseoftelepresence , copresence , andso - cial presence in virtual environments . Presence , 12 , 481 – 494 . Panksepp , J . ( 2003 ) Can anthropomorphic anal - yses of separation cries in other animals inform us about the emotional nature of social loss in humans ? Comment on Blumberg and Sokoloff ( 2001 ) . Psycholog - ical Review , 110 , 376 – 388 . Parise , S . , Kiesler , S . , Sproull , L . , & Waters , K . ( 1999 ) . Cooperating with life – like inter - faceagents . ComputersinHumanBehavior , 15 , 123 – 142 . Powers , A . , & Kiesler , S . ( 2006 , March ) . The advi - sorrobot : Tracingpeople’smentalmodelfrom a robot’s physical attributes . Conference on Human – Robot Interaction , HRI , 2006 . ( pp . 218 – 225 ) . Salt Lake City , UT . Powers , A . , Kramer , A . D . I . , Lim , S . , Kuo , J . , Lee , S – L . , & Kiesler , S . ( 2005 , August ) . Eliciting information from people with a gendered humanoid robot . Proceedings of the 14th IEEE International Workshop on Robot and Human Interactive Com - munication ROMAN 2005 . Nashville , TN . ANTHROPOMORPHIC INTERACTIONS WITH A ROBOT 181 Rakison , D . H . , & Poulin – Dubois , D . ( 2001 ) . De - velopmental origin of the animate – inani - mate distinction . Psychological Bulletin , 127 , 209 – 228 . Scassellati , B . ( 2004 ) . Theory of mind for a hu - manoid robot . Autonomous Robots , 12 , 13 – 24 . Schmitt , B . H . , Gilovich , T . , Goore , N . , & Joseph , L . ( 1986 ) . Mere presence and social facili - tation : One more time . Journal of Experi - mental Social Psychology , 22 , 242 – 248 . Scholl , B . J . , & Tremoulet , P . D . ( 2000 ) . Percep - tualcausalityandanimacy . TrendsinCog - nitive Science , 4 , 200 – 309 . Torrey , C . , Powers , A . , Marge , M . , Fussell , S . R . , & Kiesler , S . ( 2006 , March ) . Effects of adaptive robot dialogue on information exchange and social relation . Proceed - ings of the Conference on Human – Robot Interaction , HRI , 2006 ( pp . 126 – 133 ) . Salt Lake City , UT . Yamato , J . , Shinozawa , K . , Naya , F . , & Kogure , K . ( 2001 , July ) . Evaluation of communi - cation with robot and agent : Are robots better social actors than agents ? In Pro - ceedings of the 8th International Confer - ence on Human – Computer Interaction , INTERACT ‘01 ( pp . 690 – 691 ) . Tokyo , Japan . Yee , N . , Bailenson , J . N . , & Rickertsen , K . ( 2007 ) . A meta – analysis of the impact of the in - clusion and realism of human – like faces on user experiences in interfaces . In Pro - ceedings of the Conference on Human Computing Systems , HRI , CHI ‘07 . ( pp . 1 – 10 ) . NY : ACM Press . Zajonc , R . B . ( 1965 ) . Social facilitation . Science , 149 , 269 – 274 .