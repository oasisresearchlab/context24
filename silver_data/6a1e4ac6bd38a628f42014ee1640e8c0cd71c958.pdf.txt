Going Extreme : Comparative Analysis of Hate Speech in Parler and Gab Abraham Israeli Oren Tsur Department of Software and Information System Engineering Ben - Gurion University of the Negev Beer - Sheva , Israel isabrah @ post . bgu . ac . il orentsur @ bgu . ac . il Abstract Social platforms such as Gab and Parler , branded as ‘free - speech’ networks , have seen a signiﬁcant growth of their user base in recent years . This popularity is mainly attributed to the stricter moderation enforced by mainstream platforms such as Twitter , Facebook , and Reddit . In this work we pro - vide the ﬁrst large scale analysis of hate - speech on Parler . We experiment with an array of algorithms for hate - speech detection , demonstrating limitations of transfer learning in that domain , given the illusive and ever changing nature of the ways hate - speech is delivered . In order to improve clas - siﬁcation accuracy we annotated 10K Parler posts , which we use to ﬁne - tune a BERT classiﬁer . Classiﬁcation of individ - ual posts is then leveraged for the classiﬁcation of millions of users via label propagation over the social network . Classify - ing users by their propensity to disseminate hate , we ﬁnd that hate mongers make 16 . 1 % of Parler active users , and that they have distinct characteristics comparing to other user groups . We ﬁnd that hate mongers are more active , more central and express distinct levels of sentiment and convey a distinct array of emotions like anger and sadness . We further complement our analysis by comparing the trends discovered in Parler and those found in Gab . To the best of our knowledge , this is among the ﬁrst works to analyze hate speech in Parler in a quantitative manner and on the user level , and the ﬁrst annotated dataset to be made available to the community . 1 Introduction [ Warning : Some of the readers may ﬁnd the language in the examples provided in this manuscript o ﬀ ensive . ] Social platforms like Twitter , Facebook , and Reddit have become a central communication channel for billions of users 1 . However , the immense popularity of social platforms resulted in a signiﬁcant rise in the toxicity of the discourse , ranging from cyber - bullying to explicit hate speech and calls for violence against individuals and groups ( Waseem and Hovy 2016 ; Mondal , Silva , and Benevenuto 2017 ; Laub 2019 ; Ziems et al . 2020 ) . Women , people of color , the LGBT community , Muslims , immigrants , and Jews are among the most targeted groups . Recent studies report on a surge in Is - lamophobia ( Akbarzadeh 2016 ; Sunar 2017 ; Osman 2017 ; 1 Facebook reported on 2 . 9 Billion monthly active users ( re - trieved 07 / 28 / 2021 ) , see : https : / / tinyurl . com / 2p8r4wd6 Chandra et al . 2021 ) , antisemitism ( ADL 2020 ; Zannettou et al . 2020 ) , xenophobia ( Iwama 2018 ; Entorf and Lange 2019 ) , hate of Asians ( An et al . 2021 ; Vidgen et al . 2020a ) and hate crimes ( Dodd and Marsh 2017 ; Levin and Reitzel 2018 ; Edwards and Rushin 2018 ; Perry et al . 2020 ) . Facing an increased public and legislature scrutiny , main - stream social platforms ( e . g . , Facebook , Twitter , Reddit ) committed to a stricter enforcement of community stan - dards , curbing levels of hate on the platform 2 , 3 . The stricter moderation of content drove many users into joining alternative social platforms such as Parler and Gab . Touting their commitment to ‘free speech’ and ‘no moder - ation’ policy , these platforms attract users suspended from mainstream platforms , conspiracy theorists , extremists and other unhinged users , as well as ‘free - speech’ advocates . User migration to Parler and Gab was not only grass - root . The platforms were promoted by prominent news anchors and political ﬁgures . For example , U . S . Senator Ted Cruz ( R - TX ) tweeted “I’m proud to join @ parler app – a platform gets what free speech is all about – and I’m excited to be a part of it . Let’s speak . Let’s speak freely . And let’s end the Silicon Valley censorship” ( 6 / 25 / 2020 ) , and Sean Hannity , a popular host and commentator on Fox news , informed the viewers of his daily show that “I saw that the president had joined it . At least there is a place , it’s like Twitter , it’s called Parler , I have an account there . . . good for you because the president joined , because they are censoring him and Dan Scavino and everybody else” ( 1 / 8 / 2021 ) . Hate , brewing online , often spills to the streets ( Hankes and Amend 2019 ; Munn 2019 ; Malevich and Robertso 2019 ; Thomas 2019 ) . Thus , defending ‘hate speech’ under the right for ‘free speech’ may manifest itself through very con - crete actions in “real life” . The perpetrator of the Pittsburgh synagogue shooting 4 was active on Gab , referring to “the infestations of jews” . His ﬁnal post , minutes before opening ﬁre in the synagogue , was “I can’t sit by and watch my people get slaughtered . Screw your optics , I’m going in . ” Similarly , the storming of the U . S . Capitol on January 6 , 2021 was found by the U . S . Senate investigation committee to be encouraged and coordinated on Parler ( Peters et al . 2021 ) . Indeed , hate speech does plague Parler – a number of 2 https : / / tinyurl . com / muvn4hma 3 https : / / tinyurl . com / yc3kx6wp 4 https : / / tinyurl . com / 6rpn5j67 a r X i v : 2201 . 11770v1 [ c s . S I ] 27 J a n 2022 Post Content Target 1 Raimondo can stick her mask mandate in her cunt . come tell me to my face it will be the last time we here from this bitch Women 2 WDammit I hate kikes so much . Filthy , hooked nosed , baby penis sucking parasites Jewish people 3 Muslim terrorists did this and obama brought them here to run our government . Gotta get rid of Obammy , Omar and all these other fucking Muslims Muslims 4 Remember what ( ( ( they ) ) ) want to take from you Jewish People 5 SMASH these radical freaks all over AMERICA ! ! Clean this mess up LGBTQ 6 The CHINA plan is for biden to bring millions and millions of CHINA virus infected illegal savages into america . Asians , Immigrants 7 Now the blacks not only want welfare , free college , free healthcare , free housing , free food , free clothes , free transportation , free tampons , but they want the white man money . Wake up and smell the dog shit . The Black Community 8 DemonKKKrats love rape and murder . Praying . Democrats Table 1 : A sample of posts from Parler social platform . examples is presented in Table 1 . Notably , some posts are more explicit than others – using vulgar language ( e . g . , posts # 1 – # 3 ) , explicitly mentioning the targeted individual / group ( e . g . , # 1 , # 3 , # 6 , # 7 ) , while other posts are using nick - names , codes and implicit references ( e . g . , # 2 , # 4 , # 5 , # 8 ) . Striking the right balance between contradicting values ( e . g . , the freedom of speech vs . public safety of members of protected groups ) is a walk on a tightrope . We believe , however , that a data - oriented analysis may help individuals and policy maker alike at reaching an informed balance . In this work we focus on Parler social platform , investigat - ing the proliferation of hate speech on the platform , both on the post level and on the user level . We identify three distinct groups of users ( hate mongers , regular users and hate ﬂirts ) and show signiﬁcant di ﬀ erences between them in terms of language , emotion , activity level and role in the network . We further compare our result to the hateful dynamics observed in the Gab platform . Contribution Our contribution in this paper is fourfold : ( i ) We compare an array of state - of - the - art algorithms for hate detection , showing they all fail to accurately identify nuanced and novel manifestations of hate speech found on Parler , ( ii ) We share the ﬁrst annotated Parler dataset , containing 10K Parler posts , each post labeled by the level of hate it conveys , ( iii ) We ﬁne - tune a BERT - based classiﬁer to achieve accurate classiﬁcation , and modify DeGroot’s di ﬀ usion model ( Golub and Jackson 2010 ) in order to allow analysis on the platform level , and ﬁnally ( iv ) We provide the ﬁrst large scale analysis of the proliferation of hate in Parler and compare it to the user dynamics in Gab . The remainder of the paper is organized as follows : Section 2 provides a brief review of the relevant literature . A detailed description of the datasets and the annotation procedure are given in Section 3 . In Section 4 we present the computational methods we use for the post and user level classiﬁcation , and results follow in Section 5 . A detailed analysis of hate levels and user propensity for hate speech in Parler and Gab is provided in Section 6 . Finally , Section 7 o ﬀ ers some discussion regarding some of the observations , including ethical considerations . 2 Related Work A growing body of research studies the magnitude and the di ﬀ erent manifestations of hate speech in social me - dia ( Knuttila 2011 ; Chandrasekharan et al . 2017 ; Zannettou et al . 2018 ; Zampieri et al . 2020 ; Ranasinghe and Zampieri 2020 ) , among others . Here , we present an overview of the current literature through three di ﬀ erent perspectives : ( i ) The detection of hate speech on the post level , ( ii ) The detec - tion of hate - promoting users , and ( iii ) The characterization of hate speech on the platform level . Post - level classiﬁcation Most previous works address the detection of hate in textual form . Keywords and sentence structure in Twitter and Whisper were used in ( Mondal , Silva , and Benevenuto 2017 ; Saleem et al . 2017 ) , demon - strating the limitations of a lexical approach . The use of code words , ambiguity and dog - whistling , and the challenges they introduce to text - based models were studied by ( Davidson et al . 2017 ; Ribeiro et al . 2017 ; Arviv , Hanouna , and Tsur 2021 ) . The detection of implicit forms of hate speech is addressed by Magu , Joshi , and Luo ( 2017 ) which detects the use of hate code words ( e . g . , google , skype , bing and skittle to refer to Black people , Jews , Chi - nese , and Muslims , respectively ) using SVM classiﬁer based on bag - of - words feature vectors . ElSherief et al . ( 2021 ) in - troduced a benchmark corpus of 22 . 5K tweets to study im - plicit hate speech . The authors presented baseline results over this dataset using Jigsaw Perspective 5 , SVM , and dif - ferent variants of BERT ( Devlin et al . 2018 ) . The use of demographic features such as gender and loca - tion in the detection of hate speech is explored by Waseem and Hovy ( 2016 ) , and user meta features , e . g . , account age , posts per day , number of followers / friends , are used by Ribeiro et al . ( 2017 ) . Computational methods for the detection of hate speech and abusive language range from SVM and logistic regres - sion ( Davidson et al . 2017 ; Waseem and Hovy 2016 ; No - bata et al . 2016 ; Magu , Joshi , and Luo 2017 ) , to neural 5 https : / / www . perspectiveapi . com architectures such as RNNs and CNNs ( Zhang , Robinson , and Tepper 2016 ; Gamb¨ack and Sikdar 2017 ; Del Vigna12 et al . 2017 ; Park and Fung 2017 ) . Transformer - based ar - chitectures achieved signiﬁcant improvements , see ( Moza - fari , Farahbakhsh , and Crespi 2019 ; Aluru et al . 2020 ; Samghabadi et al . 2020 ; Salminen et al . 2020 ; Qian et al . 2021 ; Kennedy et al . 2020 ; Arviv , Hanouna , and Tsur 2021 ) , among others . In an e ﬀ ort to mitigate the need for extensive annotation some works use transformers to generate more samples , e . g . , ( Vidgen et al . 2020b ; Wullach , Adler , and Minkov 2020 , 2021 ) . Zhou et al . ( 2021 ) integrate features from external resources to support the model performance . In order to account for the sometimes elusive and coded language and the unfortunate variety of targeted groups ( Schmidt and Wiegand 2017 ; Ross et al . 2017 ) , a set of func - tional test was suggested by R¨ottger et al . ( 2020 ) , allowing an quick evaluation of hate - detection models . Classiﬁcation of hate users Characterizing accounts that are instrumental in the propagation of hate and violence is gaining interest from the research community and indus - try alike , whether in order to better understand the phe - nomena or in order to suspend major perpetrators instead of removing sporadic content . Detection and characteriza - tion of hateful Twitter and Gab users was tackled by Ribeiro et al . ( 2018 ) ; Mathew et al . ( 2018 , 2019 ) ; Arviv , Hanouna , and Tsur ( 2021 ) , among others . An annotated dataset of a few hundreds of Twitter users was released as part of a shared task in CLEF 2021 , see ( Bevendor ﬀ et al . 2021 ) for an overview of the data and the submissions . An annotated dataset of Twitter users using the ambiguous ( ( ( ) ) ) ( ‘echo’ ) symbol was released by Arviv , Hanouna , and Tsur ( 2021 ) . Hate speech on Parler and Gab While most prior work focus on the manifestations of hate in the mainstream plat - forms , a number of works do address alternative platforms such as Gab and Parler . Two annotated Gab datasets were in - troduced by Kennedy et al . ( 2018 ) and by Qian et al . ( 2019 ) . We use these datasets in this work as we compare Parler to Gab . Focusing on users , rather than posts , Das et al . ( 2021 ) experiment with an array of models for hate users classi - ﬁcation . Lima et al . ( 2018 ) aims to understand what users join the platform and what kind of content they share , while Jasser et al . ( 2021 ) conduct a qualitative analysis studying Gab’s platform norms , given the lack of moderation . Gal - lacher and Bright ( 2021 ) explore whether users seek out Gab in order to express hate , or that the toxic attitude is adopted after joining the platform . The spread of hate speech and the di ﬀ usion dynamics of the content posted by hateful and non - hateful Gab users is modeled by Mathew et al . ( 2019 ) and Mathew et al . ( 2020 ) . Parler , launched in August 2018 and experiencing its im - pressive expansion of user base from late in 2020 , is only beginning to draw the attention of the research commu - nity . Early works analysed the language in Parler in sev - eral aspects such as QAnon content ( Sipka , Hannak , and Urman 2021 ) , COVID - 19 vaccine ( Baines , Ittefaq , and Ab - wao 2021 ) , and the 2021 Capitol riots ( Esser 2021 ) . The ﬁrst dataset of Parler messages was introduced by Aliapoulios et al . ( 2021 ) , along with a basic statistical analysis of the data , e . g . , the number of posts and the number of regis - tered users per month , along with the most popular tokens , bigrams , and hashtags in the data . Ward ( 2021 ) used a list of predeﬁned keywords ( hate terms ) , assessing the level of hate - speech on the platform . Our work di ﬀ ers from these works in a number of fun - damental aspects . First , we combine textual and social ( net - work ) signals in order to detect both hateful posts and hate - promoting accounts . Second , We suggest models that rely on state - of - the - art neural architectures and computational methods , while previous work detects hate speech by match - ing a ﬁxed set of keywords from a predeﬁned list of hate terms . Furthermore , we provide a thorough analysis of the applicability of di ﬀ erent algorithms , trained and ﬁne - tuned on various datasets and tasks . Third , we provide a broader context to our analysis of the proliferation of hate in Parler , as we compare and contrast it to trends observed on Gab . 3 Data In this section we describe the datasets used for this work – starting with a general overview of the platforms , then pro - viding a detailed description of the datasets and the annota - tion procedure . 3 . 1 Parler and Gab Social Platforms Parler Alluding to the french verb ‘to speek’ , Parler was launched on August 2018 . The platform brands itself as “The World’s Town Square” a place in which users can “Speak freely and express yourself openly , without fear of being “deplatforme” for your views . ” 6 . Parler users post texts ( called parlays ) of up to 1 , 000 char - acters . Users can reply to parlays and to previous replies . Parler supports a reposting mechanism similar to Twitters retweets ( referred to as ‘echos’ ) . Throughout this paper we refer to echo posts as reposts , not to confuse with the ( ( ( ) ) ) ( echo ) hate symbol . Parler’s o ﬃ cial guidelines 7 explicitly allow “trolling” and “not - safe - for - work” content , include only two “Principles” prohibiting “unlawful acts” , citing “Obvious examples in - clude : child sexual abuse material , content posted by or on behalf of terrorist organizations , intellectual property theft . ” and spamming . By January 2021 , 13 . 25M users have joined Parler and its mobile application was the most downloaded app in Ap - ple’s App Store . This growth is attributed to celebrities and political ﬁgures promoting the platform ( see Section 1 ) and the stricter moderation enforced by Facebook and Twitter , culminating with the suspension of the @ realDonaldTrump account from Twitter and Facebook . Gab Gab , launched on August 2016 , was created as an al - ternative to Twitter and it positioning itself as putting “peo - ple and free speech ﬁrst” and welcoming users suspended 6 Parler branding on its landing page ( accessed : 1 / 10 / 2022 ) . 7 parler . com / documents / guidelines . pdf ( accessed : 1 / 15 / 2022 ) Parler Gab Users 4 . 08M 144 . 3K Posts 20 . 59M 7 . 95M Replies 84 . 55M 5 . 92M Reposts 77 . 93M 8 . 24M Time - Span 08 / 2018 – 01 / 2021 08 / 2016 – 01 / 2018 Table 2 : Datasets Statistics . Replies are comments to main posts . Reposts are equivalent to retweets in Twitter . from other social networks ( Zannettou et al . 2018 ) . Gab posts ( called gabs ) are limited to 300 - characters , and users can repost , quote or reply to previously created gabs . Gab permits pornographic and obscene content , as long as it is la - beled NSFW ( Not - Safe - For - Work ) . Previous research ﬁnds that Gab is a politically oriented system – while many users who use the platform are extremists , the majority of users are Caucasians - conservatives - males ( Lima et al . 2018 ) . For more details about gab usage , users and manifestations of hate see references at Section 2 . 3 . 2 Parler and Gab Corpora We use the Parler and Gab datasets published by Aliapoulios et al . ( 2021 ) and Zannettou et al . ( 2018 ) , respectively . The Parler dataset is unlabeled , therefore annotation is required . We describe the annotation procedure and label statistics in Section 3 . 3 . Both datasets include posts and users’ meta data , though the Parler dataset is richer , containing more attributes such as registration time and total number of likes . Each of the datasets is composed of millions of posts and replies , see Table 2 . The Parler dataset is bigger , containing more posts and more users , however , on average , Gab users post more content per user . We note that there is no temporal overlap between the two datasets . We discuss this point and its im - pact on the analysis and comparison in Section 7 . We use three Gab annotated datasets which are all sam - pled from the unlabeled Gab corpus we use : ( i ) The Gab Hate Corpus – 27 . 5K Gab posts published by Kennedy et al . ( 2018 ) , ( ii ) 9 . 5K Gab posts published by Qian et al . ( 2019 ) , and ( iii ) 5K posts published by ( Arviv , Hanouna , and Tsur 2021 ) . In total , we collect a corpus of 42 . 1K annotated Gab posts . 7 . 7K ( 18 . 4 % ) of the posts are tagged as hateful . 3 . 3 Parler Data Annotation Hate speech takes di ﬀ erent forms in di ﬀ erent social plat - forms ( Wiegand , Ruppenhofer , and Kleinbauer 2019 ) and across time ( Florio et al . 2020 ) . It is often implicit ( ElSherief et al . 2021 ) , targeting a variety of groups . Consequently , transfer learning remains a challenge for hate - speech de - tection , and annotated Parler data is needed in order to achieve accurate classiﬁcation . This challenges and the sig - niﬁcant improvements in performance achieved by proper ﬁne - tuning are demonstrated through extensive experimen - tation , see Section 4 . 1 . In the remainder of this section we describe the annotation procedure and the annotated dataset we use . The annotation task was designed as follows : 10K posts were sampled from the full Parler corpus . All posts met the following criteria : ( i ) Primary language is English ; ( ii ) A post should be at least 10 characters long ; ( iii ) The post does not contain a URL ; and ( iv ) The post is neither a repost nor a comment . The 10K annotated posts were not randomly selected from the Parler corpus . A random selection of posts would have led to an extremely imbalanced dataset as most of the posts do not contain hate speech . Hence , we opt to stratiﬁed sampling . This sampling process relies on an approximation of the likelihood of each post to include hateful content . We used a pretrained hate speech prediction model to approxi - mate this likelihood . Annotation was done by 112 student ( more than half of them are graduate students ) , who were provided detailed guidelines and training involving the various types of hate speech , the elusiveness of hate expressions using coded lan - guage , how to detect it , and a number of examples of dif - ferent types . Each of the annotators was prompted with a list of 300 posts and had to assign each with a Lickert score ranging from 1 ( not hate ) to 5 ( extreme or explicit hate ) . We provided annotators only with the textual content of the post . Each of the 10K posts was annotated by three anno - tators . Annotators presented a satisfying agreement level of 72 % and a Cohen’s Kappa of 0 . 44 . Labels of posts with a low agreement level 8 were ignored ( ∼ 7 % of the annotated posts ) . We deﬁne a post as hateful ( non - hateful ) if its aver - age score is higher ( lower ) than three . We omit posts with an average score of exactly three . Accordingly , 3224 of the 10K posts ( 32 . 8 % ) were labeled as hateful and 6053 ( 59 . 8 % ) as non - hateful . We make this annotated corpus available in the project’s repository 9 – the ﬁrst public annotated corpus of Parler . 4 Methods In this work we are interested in the detection of hate , both on the post level and the account level . Our interest in the post level classiﬁcation is twofold . Given an accurate clas - siﬁer , we can : ( a ) Approximate the hate degree in di ﬀ erent aggregation levels – e . g . , over all social network , and per user , and ( b ) Use the post - level predictions to support train - ing a user level classiﬁer . A review of the various post level classiﬁers is provided in Section 4 . 1 and our modiﬁcations to a di ﬀ usion - based model for user classiﬁcation are pre - sented in Section 4 . 2 . Ethical considerations related to user classiﬁcation are discussed at the end of Section 7 . 4 . 1 Post Level Classiﬁcation Models We ﬁne - tune the DistilBERT ( Sanh et al . 2019 ) transformer on each of the datasets , obtaining two ﬁne - tuned models ( re - ferred to as Our - FT BERT ) . We compare the performance of 8 We deﬁne low agreement as posts labeled with least three unique values or if the di ﬀ erence between annotations was higher than 2 . 9 https : / / github . com / NasLabBgu / parler - hate - speech Figure 1 : An illustration of the di ﬀ usion model over three nodes . Self loops represent the total number of posts per node . In step ( a ) we build the repost network and assign each node with an initial belief – seed hate mongers with a value of one and others with a value of zero . In steps ( b ) and ( c ) we convert the network to a belief network – reversing the edges’ direction and normalizing their weight . In step ( d ) we run the di ﬀ usion process and get a belief score per node , which is indicated in the graph by the darkness of each node . the models on the respective datasets against four competi - tive models : 1 . Jigsaw Perspective : A widely used commercial model to detect hate and toxic content , developed by Google . Jig - saw was found to perform well in an array of tasks related to hate - speech detection ( R¨ottger et al . 2020 ) . Jigsaw im - plementation is not public and the service is provided as a black - box through an online API 10 . 2 . deHateBERT ( Aluru et al . 2020 ) : An adaptation of the BERT Transformer for hate - speech detection – the pre - trained transformer was ﬁne - tuned on a corpus of 96 . 3K text snippets from Twitter and from the white supremacist forum Stormfront . org . The authors indicate that 15 . 01K ( 15 . 6 % ) training samples were labeled as hate - speech . 3 . Twitter - roBERTa ( Barbieri et al . 2020 ) : This model uses the RoBERTa ( Liu et al . 2019 ) architecture , speciﬁcally ﬁne - tuned on the task of hate - speech detection of micro - messages . The authors used a corpus of 13K tweets , 5 . 2K ( 40 % ) of them are labeled as hate speech . 4 . HateBase ( Tuckwood 2017 ) : HateBase is a multilan - guage vocabulary of hate terms that is maintained on order to assist in content moderation and research . We use 68 explicit hate terms that were used in prior works Mathew et al . ( 2018 , 2019 ) . These terms were mainly se - lected from HateBase’s English lexicon and is composed only of explicit hate terms like ‘kike’ ( slur targeting Jews , see post # 2 in Table 1 ) , ‘paki’ ( slur against Muslims , es - pecially with Pakistani roots ) , and ‘cunt’ ( see post # 1 in Table 1 ) . 4 . 2 User Level Classiﬁcation Ideally , an account should be classiﬁed as a hate account based on the content it posts ( or likes ) . However , this seem - ingly straight forward approach is severely limited by am - biguity , vagueness , dog - whistling , and emerging idioms and racial slurs . For example , deﬁning a threshold of k hateful posts is still not well deﬁned . How explicit these k posts should be ? would 2 k less explicit posts make the cut ? is one post enough to declare a user a hate - monger ? Moreover , deﬁning a threshold does not account for networked aspect of the data and the fact that “birds of a feather ﬂock together” ( Himelboim , McCreery , and Smith 2013 ) . 10 https : / / www . perspectiveapi . com In order to leverage the network structure , we view each platform as a social network with users as nodes and reposts as directed edges . Edges are weighted to reﬂect levels of en - gagement , as illustrated in Figure 1 ( a ) : a directed edge ( A , B ) with a weight of 6 indicates that user A reposted 6 posts orig - inally posted by user B . We build on the di ﬀ usion - based approached for the de - tection of hate mongers , proposed by Mathew et al . ( 2019 ) , modifying it in order to achieve a more accurate classiﬁca - tion . The basic di ﬀ usion - based classiﬁcation is achieved in two stages : ( a ) Identifying a seed group of hate mongers . ( b ) Applying a di ﬀ usion model over the social network . We use the DeGroot’s hate di ﬀ usion model ( Golub and Jackson 2010 ) which outputs an estimated belief value ( i . e . , “hate” ) per user , over the [ 0 , 1 ] range . A toy example of the di ﬀ usion process is illustrated in Figure 1 . In our experiments we set the number of di ﬀ usion iterations to three . One clear advan - tage of this approach over fully supervised methods is that it does not require a large dataset annotated on the user level . Modiﬁed Di ﬀ usion Model We modiﬁed the di ﬀ usion model used by Ribeiro et al . ( 2018 ) and Mathew et al . ( 2019 ) in two ways : ( i ) Seed deﬁnition . Instead of taking a lexi - cal approach in order to identify users posting more than k hateful posts , we use our ﬁne - tuned Transformers . We ar - gue that ﬁne - tuning the classiﬁers for each social network signiﬁcantly improves the classiﬁcation on the post level ( as demonstrated in Section 5 . 1 ) , and ultimately , improves the performance of the di ﬀ usion model ; and ( ii ) Hateful users deﬁnition . In the original di ﬀ usion process , hate ( as well as “not - hate” ) labels are di ﬀ used through the network . This way , seed hate mongers may end with a low belief ( hate ) score , which in turn propagates to their neighbours . How - ever , seed users were chosen due to the fact that they post a signiﬁcant number of undoubtedly hateful posts . Fixing the hate score of these users results in a more accurate labeling of the accounts in the network . 5 Classiﬁcation Results 5 . 1 Post Level Results We use the annotated corpora ( see Section 3 . 3 ) to ﬁne - tune the pretrained Transformer on each social platform , splitting the labeled data to train ( 60 % ) , validation ( 20 % ) , and test ( 20 % ) sets . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 0 . 4 0 . 6 0 . 8 1 Recall P r ec i s i on Our - FT - BERT deHateBERTJigsawTwitter - roBERTa Parler Classiﬁers 0 0 . 2 0 . 4 0 . 6 0 . 8 1 0 . 2 0 . 4 0 . 6 0 . 8 1 Recall P r ec i s i on Our - FT - BERT deHateBERTJigsawTwitter - roBERTa Gab Classiﬁers Figure 2 : Precision - Recall ( PR ) curves – post level . Results are over the test set . FT - BERT stands for Fine Tuned BERT . The or - ange diamond ( (cid:95) ) marks the PR performance of the lexical - based approach ( HateBase ) . Unlike the other four methods , this approach cannot be controlled by a threshold parameter , hence only a single PR value is available . The precision - recall curves of the Parler and Gab mod - els are presented in Figure 2 . Our ﬁne - tuned models signif - icantly outperforms the other models in both datasets . We wish to point out that while the popular keyword base ap - proach ( HateBase ) achieves a high precision and a moderate recall on the Gab data , outperforming all Transformer mod - els except the platform ﬁne - tuned ones , it collapses in both measures on the newer Parler dataset . These results reval - idate the limitations of lexical approaches , and of neural methods that are not ﬁne - tuned for the speciﬁc dataset ( even though they were ﬁne - tuned for a similar task – hate speech detection in another microblogging platform ) . 5 . 2 User Level Results As described in Section 4 . 2 , in order to classify accounts we use a di ﬀ usion model . The di ﬀ usion process is seeded with a set of hateful accounts . The choice of seed accounts involves the following steps : ( i ) After establishing the accuracy of the ﬁne - tuned models ( Section 5 . 1 ) we use these models to la - bel all the posts in the respective dataests . ( ii ) Opting for a conservative assignment of seed users , we consider only posts with hate score ( likelihood ) over 0 . 95 ( 0 . 9 ) in the Par - ler ( Gab ) dataset to be hateful . Finally , ( iii ) Users posting 10 or more hateful posts are labeled as seed accounts . We take the conservative approach in steps ( ii ) and ( iii ) in order to control the often noisy di ﬀ usion process . Simulating the modiﬁed di ﬀ usion process described in Section 4 . 2 we obtain a hate score per user . For analysis pur - poses we divide users to three distinct groups – hate mongers ( denoted HM ) , composed of the users making the top quar - tile of hate scores ; normal users ( denoted N ) making the bot - tom quartile ; the rest of the users ( denoted (cid:103) HM ) suspected as “ﬂirting” with hate mongers and hate dissemination . Users with a low level of activity ( less than ﬁve posts or users join - ing the network in the last 60 days ) were not considered 11 . The distribution of active users by type is presented in Fig 3 . 11 87 . 1 % ( 63 . 4 % ) of the users in Parler ( Gab ) . Praler Gab 16 . 1 10 42 . 4 41 . 7 41 . 5 48 . 3 A c ti v e U s e r s ( % ) HM (cid:103) HM N Figure 3 : Distribution of the active users in Parler and Gab Evaluation of the di ﬀ usion model A user - level annotated dataset of 798 Gab users was shared by Das et al . ( 2021 ) . We use this dataset to validate the performance of the dif - fusion models – both the standard and our modiﬁed models ( see Section 4 . 2 ) . We ﬁnd our modiﬁed model to outperform the standard models , achieving precision / recall / F1 - scores of 0 . 9 / 0 . 54 / 0 . 678 , comparing to of 0 . 95 / 0 . 34 / 0 . 5 . Therefore , re - sults and analysis in the remainder of the paper are based on the modiﬁed di ﬀ usion model . 6 Hate Analysis In this section we provide a comprehensive analysis of the propensity for hate speech on Parler and Gab 6 . 1 Hate on the Post Level Taking our conservative approach , we ﬁnd that hate posts are more frequent in Parler ( 3 . 29 % ) than in Gab ( 2 . 13 % ) . However , we ﬁnd that 13 . 95 % of Parler users share at least one hateful post – signiﬁcantly lower number compared to Gab ( 18 . 58 % ) . We ﬁnd that 65 . 5 % of the hate content in Parler is posted as a reply to other parlays . This reﬂects a signiﬁcant over - representation of replies compared with full corpus distribution ( 46 . 2 % of posts are replies , see Table 2 ) . Similarly , 38 . 9 % of the hate content on Gab are replies . 6 . 2 Hate on the User Level We provide an analysis of the characteristics of the HM , (cid:103) HM and N accounts on an array of attributes , ranging from ac - tivity levels to centrality , sentiment and the emotions they convey . Activity level Activity levels are compared via four fea - tures – number of posts , replies , reposts , and users’ age ( measured in days ) . HM are the most active user group in both platforms across all activity types ( see Figure 4 ) . We ﬁnd that the (cid:103) HM users have similar characteristics in both platforms – they share less content than the HM users , repost more content than the N group , and their tendency to reply is lower com - pared to the N users . ( a ) Parler ( b ) Gab Figure 4 : Activity measures per user group . Numbers are averaged per measure and group . We use a log - scale over the y - axis . Interestingly , although the HM make only 16 . 1 % ( 10 % ) of the active users in Parler ( Gab ) – they generate a dispro - portional number of posts : 30 . 6 % ( 59 . 45 % ) of the posts in Parler ( Gab ) . The same holds for replies – the HM users post 36 . 68 % ( 75 . 57 % ) of the replies in Parler ( Gab ) . When aggre - gating all activity types ( post / reply / repost ) – the HM users generate 41 . 23 % ( 71 . 38 % ) of the content in Parler ( Gab ) . User Age ( days from account creation to the most recent post in the data ) , is an exceptional feature . We observed only insigniﬁcant di ﬀ erences between the three user groups . This observation holds for both platforms . However , collapsing the groups – we do ﬁnd a signiﬁcant di ﬀ erence between the two platforms . Gab users are “older” with an average age of 323 . 9 compared to 189 . 6 of the Parler users . We hypothe - size that the di ﬀ erence is a result of the way both platform evolve over time , given the unfolding of events driving users to these platforms ( see Sections 1 and 3 . 1 ) . Popularity and Engagement We quantify the popular - ity level of users based on the number of followers they have . Figure 5 presents numbers for both platforms . On both platforms hate mongers ( HM ) are signiﬁcantly more pop - ular compared to all other user groups . In Parler , the me - dian number of followers is 121 compared to 15 and 12 of (cid:103) HM and N , respectively . The same holds for Gab – a me - dian value of 160 for HM users compared to 43 and 41 of the other two user groups . Interestingly , although Parler is a much larger social platform ( mainly in terms of registered users , see Section 3 and Table 2 ) we do not see a signiﬁcant higher number of followers in Parler . Moreover , when cal - culating the number of followers over the whole population , the median in Gab is three times higher – 48 vs . 16 . Engagement level is measured by the number of followees each account has ( the number of accounts a user follows ) . We ﬁnd that hate mongers are highly engaged in both plat - forms compared to other user groups . In Parler , the median followees number of HM users is 106 – signiﬁcantly higher than 46 and 36 median values of the (cid:103) HM and N users , re - spectively . A similar pattern holds for Gab . Account’s self description Analogue to the account’s de - scription in Twitter , Parler users can provide a short descrip - tive / biographical text to appear next to the user’s avatar . For example , the biography that is associated with a speciﬁc Par - ler user is : “Conservative banned by mainstream social me - dia outlets for calling the leftists out for what they really are ! ( a ) Parler Followers ( b ) Gab Followers Figure 5 : Followers distributions . Followers are the number of ac - counts that follow a user . The extreme percentiles ( 2 . 5 % ) of the data are omitted for visualization purposes . Rectangles below each distribution are the ± standard division around the average ; The vertical line in each rectangle represent the median . Been awake for YEARS ! # trump2020 # maga” . We use this content to further assess users commitment to the platform , assuming more engaged users are , the more likely they add the description to their proﬁle . We ﬁnd that while only 35 . 8 % of the N users use the biography ﬁeld , 59 . 6 % of the HM users provide the description in their pro - ﬁle . We also ﬁnd that the average ( median ) biographical text length of HM users is 128 . 6 ( 134 ) – considerably longer , compared to (cid:103) HM and N users who included the description in their proﬁle , with an average ( median ) of 99 . 4 ( 90 ) and 94 . 6 ( 84 ) , respectively . Social Structure We further analyze the di ﬀ erences be - tween Parler and Gab platforms over the di ﬀ erent user groups from a social network analysis ( SNA ) perspective , based on the reposts network . Table 3 provides an overview of a number of centrality measures . The HM users have a signiﬁcantly higher values in all measures in both plat - forms . Interestingly , the full order between the di ﬀ erent user groups is kept only for the ‘betweeness’ centrality , while other centrality measures a less stable comparing the (cid:103) HM and N groups . Analysing the degree distribution of users provides an in - teresting di ﬀ erence between the platforms . In line with the numbers in Table 3 , HM users have the most distinctive dis - tribution in both Parler and Gab . However , while the (cid:103) HM and the N group distributions are inseparable in Gab , the Parler user groups have distinct distributions ( see Figure 6 ) . These distributions highlight the distinctiveness of the loca - tion of HM users in the network , as well the role of the (cid:103) HM compared to N users . Linguistic features We compare the sentiment expressed and the emotions conveyed by di ﬀ erent user groups . We use pretrained BERT models for both the sentiment 12 and emo - tion 13 predictions . Results are presented in Table 4 . Looking 12 https : / / huggingface . co / nlptown / bert - base - multilingual - uncased - sentiment 13 https : / / huggingface . co / bhadresh - savani / distilbert - base - uncased - emotion HM (cid:103) HM N P a r l e r ID Centrality 3 . 26 × 10 − 5 1 . 43 × 10 − 6 3 . 64 × 10 − 6 OD Centrality 4 . 01 × 10 − 5 1 . 97 × 10 − 6 2 . 31 × 10 − 6 Betweenness 3 . 43 × 10 − 6 1 . 61 × 10 − 7 1 . 1 × 10 − 7 PageRank 1 . 11 × 10 − 6 2 . 47 × 10 − 7 4 . 74 × 10 − 7 G a b ID Centrality 3 . 35 × 10 − 3 1 . 18 × 10 − 4 2 . 81 × 10 − 4 OD Centrality 3 . 35 × 10 − 3 4 . 06 × 10 − 4 9 . 92 × 10 − 5 Betweenness 1 . 43 × 10 − 4 6 . 11 × 10 − 6 4 . 54 × 10 − 6 PageRank 8 . 85 × 10 − 5 7 . 17 × 10 − 6 9 . 68 × 10 − 6 Table 3 : Structural features . Values are averaged over all users in each user group . ‘ID’ and ‘OD’ are the in - degree and out - degree respectively . ( a ) Parler ( b ) Gab Figure 6 : Social networks degree distribution . We present the in - degree distributions . Network is based on reposts . p ( k ) ( y - axis ) is the probability value per a each node’s degree ( x - axis ) . We use a log - scale over both the axis . at the Parler users , we ﬁnd a small though signiﬁcant ( p - value < 10 − 3 ) tendency of HM to express a more negative sentiment . The same holds for Gab , although the sentiment expressed by (cid:103) HM is closer to the sentiment of the HM users , rather to that of the N users . Aggregating the emotion pre - dictions , we ﬁnd that HM users tend to convey more Anger and Sadness than the other groups . This observation holds for both Parler and Gab , although Anger is more prominent . Anger Joy Sad Fear Sentiment P a r l e r HM 48 % 37 . 9 % 7 . 4 % 5 . 1 % 2 . 63 (cid:103) HM 41 . 9 % 44 . 3 % 6 . 7 % 5 . 3 % 2 . 84 N 33 . 6 % 55 . 7 % 5 % 4 . 3 % 2 . 84 G a b HM 40 . 0 % 44 . 5 % 7 . 2 % 6 . 3 % 2 . 55 (cid:103) HM 35 . 9 % 49 . 7 % 5 . 9 % 7 . 1 % 2 . 56 N 35 . 5 % 51 . 1 % 6 . 0 % 5 . 7 % 2 . 67 Table 4 : Emotions and sentiment analysis . The four leftmost columns are the distribution of emotions per user group while the rightmost column is the median sentiment score . The sentiment spans over [ 1 , 5 ] ( i . e . , 5 is the highest score ) . We omit Love and Surprise emotions since their proportion in all groups is negligible . 7 Discussion Seed hate mongers One design choice critical to this work , a ﬀ ecting the user - level analysis , is the way we deﬁne seed hate mongers ( see Section 4 . 2 ) . Previous works used lexicon based solutions . We decided to use our post level classiﬁcation model which signiﬁcantly outperformed other alternatives . However , both solutions rely on counting the number of hate posts per user . This binary deﬁnition lacks the sensitivity to mark hate mongers in a more nuanced way . Alternative methods to mark seed hate mongers should be considered in future work . Two possible directions are sum - mation of the probabilities yielded by the hate post classiﬁer , and averaging the number of hate posts per user are two op - tional alternatives . However , we wish to stress that opting for a conservative labeling of seed users achieves a cleaner di ﬀ usion process – a process that is usually prone to noise . Parler users In this work , we make use of a Parler dataset introduces by Aliapoulios et al . ( 2021 ) . One limitation of this dataset is that it includes only part of the Parler full cor - pus . However , data were not sampled at random – the au - thors retrieved data based on users’ identity ( i . e . , all data for 4 . 08M users out of 13 . 25M ) , providing a decent coverage of a signiﬁcant part of the network . Time span Given that we provide a comparison between trends in Parler and Gab , it is important to note the datasets span di ﬀ erent and non - overlapping time - frames ( see Table 2 ) . Therefor , the comparison we provide should be read cau - tiously . We do note , however , that each of the datasets was crawled from the early days of the social platform and spans over a similar range of time ( 17 months ) . Moreover , the time disparity between the dataset could be considered as an advantage – allowing to examine the generalization per - formance of hate speech models , as we report in Section 5 . 1 . Ethical Considerations Analysing and modeling hate speech in a new social platform such as Parler is of great im - portance . However , classifying users as hate mongers , based on the output of an algorithm , may result in marking users falsely ( which may result in suspension or other measures taken against them ) . While we always opted for a conser - vative approach , as well as focusing on aggregate measures characterizing the trends of a platform , we note that user la - beling should be used in a careful manner , ideally involving a ‘man - in - the - loop’ . Considering the annotation task – the annotation process did not include any information about the identity of the users . In addition , we warned our human annotators about the possible inappropriate content of the posts . 8 Conclusion To the best of our knowledge , we present the ﬁrst large - scale computational analysis of hate speech on Parler , and provide a comparison to trends observed in the Gab platform . We annotate and share a the ﬁrst Parler dataset , contain - ing 10K posts labeled by the level of hate they convey . We used this dataset to ﬁne - tune a transformer model to be used to mark a seed set of users in a di ﬀ usion model , resulting in user - level classiﬁcation . We ﬁnd signiﬁcant di ﬀ erences be - tween hate mongers ( HM ) and other user groups : HM rep - resent only 16 . 1 % and 10 % of the active users in Parler and Gab respectively . However , they create 41 . 23 % of the con - tent in Parler and 71 . 38 % of the content in Gab . We ﬁnd that HM are show higher engagement and they have sig - niﬁcantly more followers and followees . Other di ﬀ erences are manifested through the sentiment level expressed and the emotions conveyed . References ADL . 2020 . ANTISEMITIC INCIDENTS HIT ALL - TIME HIGH IN 2019 . URL https : / / www . adl . org . il / en / news / antisemitic - incidents - hit - all - time - high - in - 2019 / . Akbarzadeh , S . 2016 . The Muslim Question in Australia : Islamophobia and Muslim Alienation . Journal of Muslim Minority A ﬀ airs 36 ( 3 ) : 323 – 333 . Aliapoulios , M . ; Bevensee , E . ; Blackburn , J . ; Bradlyn , B . ; De Cristofaro , E . ; Stringhini , G . ; and Zannettou , S . 2021 . An Early Look at the Parler Online Social Network . arXiv preprint arXiv : 2101 . 03820 . Aluru , S . S . ; Mathew , B . ; Saha , P . ; and Mukherjee , A . 2020 . Deep learning models for multilingual hate speech detec - tion . arXiv preprint arXiv : 2004 . 06465 . An , J . ; Kwak , H . ; Lee , C . S . ; Jun , B . ; and Ahn , Y . - Y . 2021 . Predicting Anti - Asian Hateful Users on Twitter dur - ing COVID - 19 . arXiv preprint arXiv : 2109 . 07296 . Arviv , E . ; Hanouna , S . ; and Tsur , O . 2021 . It’sa Thin Line Between Love and Hate : Using the Echo in Modeling Dy - namics of Racist Online Communities . In Proceedings of the International AAAI Conference on Web and Social Me - dia , volume 15 , 61 – 70 . Baines , A . ; Ittefaq , M . ; and Abwao , M . 2021 . # Scam - demic , # Plandemic , or # Scaredemic : What Parler Social Media Platform Tells Us about COVID - 19 Vaccine . Vac - cines 9 ( 5 ) : 421 . Barbieri , F . ; Camacho - Collados , J . ; Neves , L . ; and Espinosa - Anke , L . 2020 . Tweeteval : Uniﬁed benchmark and com - parative evaluation for tweet classiﬁcation . arXiv preprint arXiv : 2010 . 12421 . Bevendor ﬀ , J . ; Chulvi , B . ; De La Pe˜na Sarrac´en , G . L . ; Kestemont , M . ; Manjavacas , E . ; Markov , I . ; Mayerl , M . ; Potthast , M . ; Francisco , R . ; Rosso , P . ; Stamatatos , E . ; Stein , B . ; Matti , W . ; Wolska , M . ; and Zangerle , E . 2021 . Overview of PAN 2021 : Authorship Veriﬁcation , Proﬁling Hate Speech Spreaders on Twitter , and Style Change Detection . In 12th International Conference of the CLEF Association ( CLEF 2021 ) . Springer . Chandra , M . ; Reddy , M . ; Sehgal , S . ; Gupta , S . ; Buduru , A . B . ; and Kumaraguru , P . 2021 . ” A Virus Has No Religion” : Analyzing Islamophobia on Twitter During the COVID - 19 Outbreak . In Proceedings of the 32nd ACM Con - ference on Hypertext and Social Media , 67 – 77 . Chandrasekharan , E . ; Pavalanathan , U . ; Srinivasan , A . ; Glynn , A . ; Eisenstein , J . ; and Gilbert , E . 2017 . You can’t stay here : The e ﬃ cacy of reddit’s 2015 ban examined through hate speech . Proceedings of the ACM on Human - Computer Interaction 1 ( CSCW ) : 31 . Das , M . ; Saha , P . ; Dutt , R . ; Goyal , P . ; Mukherjee , A . ; and Mathew , B . 2021 . You too Brutus ! Trapping Hateful Users in Social Media : Challenges , Solutions & Insights . In Pro - ceedings of the 32nd ACM Conference on Hypertext and So - cial Media , 79 – 89 . Davidson , T . ; Warmsley , D . ; Macy , M . ; and Weber , I . 2017 . Automated hate speech detection and the problem of o ﬀ en - sive language . In Eleventh international aaai conference on web and social media . Del Vigna12 , F . ; Cimino23 , A . ; Dell’Orletta , F . ; Petrocchi , M . ; and Tesconi , M . 2017 . Hate me , hate me not : Hate speech detection on facebook . In Proceedings of the First Italian Conference on Cybersecurity ( ITASEC17 ) , 86 – 95 . Devlin , J . ; Chang , M . - W . ; Lee , K . ; and Toutanova , K . 2018 . Bert : Pre - training of deep bidirectional transformers for lan - guage understanding . arXiv preprint arXiv : 1810 . 04805 . Dodd , V . ; and Marsh , S . 2017 . Anti - Muslim hate crimes in - crease ﬁvefold since London Bridge attacks . The Guardian 7 . Edwards , G . S . ; and Rushin , S . 2018 . The e ﬀ ect of Pres - ident Trump’s election on hate crimes . Available at SSRN 3102652 . ElSherief , M . ; Ziems , C . ; Muchlinski , D . ; Anupindi , V . ; Sey - bolt , J . ; De Choudhury , M . ; and Yang , D . 2021 . Latent Ha - tred : A Benchmark for Understanding Implicit Hate Speech . arXiv preprint arXiv : 2109 . 05322 . Entorf , H . ; and Lange , M . 2019 . Refugees welcome ? Un - derstanding the regional heterogeneity of anti - foreigner hate crimes in Germany . Understanding the Regional Hetero - geneity of Anti - Foreigner Hate Crimes in Germany ( January 30 , 2019 ) . ZEW - Centre for European Economic Research Discussion Paper ( 19 - 005 ) . Esser , A . C . 2021 . How does the language of corpora from radicalized communities discovered on Parler compare to online conversations on Twitter regarding the 2021 Capitol riots and election fraud ? Master’s thesis . Florio , K . ; Basile , V . ; Polignano , M . ; Basile , P . ; and Patti , V . 2020 . Time of your hate : The challenge of time in hate speech detection on social media . Applied Sciences 10 ( 12 ) : 4180 . Gallacher , J . ; and Bright , J . 2021 . Hate Contagion : Measur - ing the spread and trajectory of hate on social media . Gamb¨ack , B . ; and Sikdar , U . K . 2017 . Using convolutional neural networks to classify hate - speech . In Proceedings of the ﬁrst workshop on abusive language online , 85 – 90 . Golub , B . ; and Jackson , M . O . 2010 . Naive learning in social networks and the wisdom of crowds . American Economic Journal : Microeconomics 2 ( 1 ) : 112 – 49 . Hankes , K . ; and Amend , A . 2019 . ASPI explains : 8chan . URL https : / / www . aspistrategist . org . au / aspi - explains - 8chan / . Himelboim , I . ; McCreery , S . ; and Smith , M . 2013 . Birds of a feather tweet together : Integrating network and content anal - yses to examine cross - ideology exposure on Twitter . Journal of computer - mediated communication 18 ( 2 ) : 154 – 174 . Iwama , J . A . 2018 . Understanding hate crimes against immi - grants : C onsiderations for future research . Sociology com - pass 12 ( 3 ) : e12565 . Jasser , G . ; McSwiney , J . ; Pertwee , E . ; and Zannettou , S . 2021 . ‘Welcome to # GabFam’ : Far - right virtual community on Gab . New Media & Society 14614448211024546 . Kennedy , B . ; Atari , M . ; Davani , A . M . ; Yeh , L . ; Omrani , A . ; Kim , Y . ; Coombs , K . ; Havaldar , S . ; Portillo - Wightman , G . ; Gonzalez , E . ; et al . 2018 . The Gab Hate Corpus : A collec - tion of 27k posts annotated for hate speech . Kennedy , B . ; Jin , X . ; Davani , A . M . ; Dehghani , M . ; and Ren , X . 2020 . Contextualizing hate speech classiﬁers with post - hoc explanation . arXiv preprint arXiv : 2005 . 02439 . Knuttila , L . 2011 . User unknown : 4chan , anonymity and contingency . First Monday 16 ( 10 ) . Laub , Z . 2019 . Hate Speech on Social Media : Global Comparisons . URL https : / / www . cfr . org / backgrounder / hate - speech - social - media - global - comparisons . Levin , B . ; and Reitzel , J . D . 2018 . Report to the nation : hate crimes rise in US cities and counties in time of division and foreign interference . Lima , L . ; Reis , J . C . ; Melo , P . ; Murai , F . ; Araujo , L . ; Vikatos , P . ; and Benevenuto , F . 2018 . Inside the right - leaning echo chambers : Characterizing gab , an unmoderated social system . In 2018 IEEE / ACM International Confer - ence on Advances in Social Networks Analysis and Mining ( ASONAM ) , 515 – 522 . IEEE . Liu , Y . ; Ott , M . ; Goyal , N . ; Du , J . ; Joshi , M . ; Chen , D . ; Levy , O . ; Lewis , M . ; Zettlemoyer , L . ; and Stoyanov , V . 2019 . Roberta : A robustly optimized bert pretraining ap - proach . arXiv preprint arXiv : 1907 . 11692 . Magu , R . ; Joshi , K . ; and Luo , J . 2017 . Detecting the hate code on social media . In Eleventh International AAAI Con - ference on Web and Social Media . Malevich , S . ; and Robertso , T . 2019 . Violence begetting vi - olence : An examination of extremist content on deep Web social networks . URL https : / / ﬁrstmonday . org / ojs / index . php / fm / article / download / 10421 / 9403 . Mathew , B . ; Dutt , R . ; Goyal , P . ; and Mukherjee , A . 2019 . Spread of hate speech in online social media . In Proceedings of the 10th ACM conference on web science , 173 – 182 . Mathew , B . ; Illendula , A . ; Saha , P . ; Sarkar , S . ; Goyal , P . ; and Mukherjee , A . 2020 . Hate begets hate : A temporal study of hate speech . Proceedings of the ACM on Human - Computer Interaction 4 ( CSCW2 ) : 1 – 24 . Mathew , B . ; Kumar , N . ; Goyal , P . ; Mukherjee , A . ; et al . 2018 . Analyzing the hate and counter speech accounts on twitter . arXiv preprint arXiv : 1812 . 02712 . Mondal , M . ; Silva , L . A . ; and Benevenuto , F . 2017 . A mea - surement study of hate speech in social media . In Proceed - ings of the 28th acm conference on hypertext and social me - dia , 85 – 94 . Mozafari , M . ; Farahbakhsh , R . ; and Crespi , N . 2019 . A BERT - based transfer learning approach for hate speech de - tection in online social media . In International Confer - ence on Complex Networks and Their Applications , 928 – 940 . Springer . Munn , L . 2019 . Alt - right pipeline : Individual journeys to ex - tremism online . URL https : / / ﬁrstmonday . org / ojs / index . php / fm / article / download / 10108 / 7920 . Nobata , C . ; Tetreault , J . ; Thomas , A . ; Mehdad , Y . ; and Chang , Y . 2016 . Abusive language detection in online user content . In Proceedings of the 25th international conference on world wide web , 145 – 153 . Osman , M . N . B . M . 2017 . Retraction : Understanding Is - lamophobia in Asia : The Cases of Myanmar and Malaysia . Islamophobia Studies Journal 4 ( 1 ) : 17 – 36 . Park , J . H . ; and Fung , P . 2017 . One - step and two - step clas - siﬁcation for abusive language detection on twitter . arXiv preprint arXiv : 1706 . 01206 . Perry , B . ; Akca , D . ; Karakus , F . ; Bastug , M . F . ; et al . 2020 . Planting Hate Speech to Harvest Hatred : How Does Politi - cal Hate Speech Fuel Hate Crimes in Turkey ? International Journal for Crime , Justice and Social Democracy 9 ( 2 ) . Peters , G . ; Portman , R . ; Klobuchar , A . ; and Blunt , R . 2021 . Examining The U . S . Capitol Attack : a review of the security planning and response failures . URL https : / / www . hsgac . senate . gov / imo / media / doc / HSGAC & RulesFullReport ExaminingU . S . CapitolAttack . pdf . Qian , J . ; Bethke , A . ; Liu , Y . ; Belding , E . ; and Wang , W . Y . 2019 . A benchmark dataset for learning to intervene in on - line hate speech . arXiv preprint arXiv : 1909 . 04251 . Qian , J . ; Wang , H . ; ElSherief , M . ; and Yan , X . 2021 . Life - long Learning of Hate Speech Classiﬁcation on Social Me - dia . arXiv preprint arXiv : 2106 . 02821 . Ranasinghe , T . ; and Zampieri , M . 2020 . Multilingual o ﬀ en - sive language identiﬁcation with cross - lingual embeddings . arXiv preprint arXiv : 2010 . 05324 . Ribeiro , M . ; Calais , P . ; Santos , Y . ; Almeida , V . ; and Meira Jr , W . 2018 . Characterizing and detecting hateful users on twit - ter . In Proceedings of the International AAAI Conference on Web and Social Media , volume 12 . Ribeiro , M . H . ; Calais , P . H . ; Santos , Y . A . ; Almeida , V . A . ; and Meira Jr , W . 2017 . ”Like Sheep Among Wolves” : Characterizing Hateful Users on Twitter . arXiv preprint arXiv : 1801 . 00317 . Ross , B . ; Rist , M . ; Carbonell , G . ; Cabrera , B . ; Kurowsky , N . ; and Wojatzki , M . 2017 . Measuring the reliability of hate speech annotations : The case of the european refugee crisis . arXiv preprint arXiv : 1701 . 08118 . R¨ottger , P . ; Vidgen , B . ; Nguyen , D . ; Waseem , Z . ; Mar - getts , H . ; and Pierrehumbert , J . 2020 . Hatecheck : Func - tional tests for hate speech detection models . arXiv preprint arXiv : 2012 . 15606 . Saleem , H . M . ; Dillon , K . P . ; Benesch , S . ; and Ruths , D . 2017 . A web of hate : Tackling hateful speech in online social spaces . arXiv preprint arXiv : 1709 . 10159 . Salminen , J . ; Hopf , M . ; Chowdhury , S . A . ; Jung , S . - g . ; Almerekhi , H . ; and Jansen , B . J . 2020 . Developing an online hate classiﬁer for multiple social media platforms . Human - centric Computing and Information Sciences 10 ( 1 ) : 1 . Samghabadi , N . S . ; Patwa , P . ; Srinivas , P . ; Mukherjee , P . ; Das , A . ; and Solorio , T . 2020 . Aggression and misogyny detection using bert : A multi - task approach . In Proceedings of the Second Workshop on Trolling , Aggression and Cyber - bullying , 126 – 131 . Sanh , V . ; Debut , L . ; Chaumond , J . ; and Wolf , T . 2019 . Dis - tilBERT , a distilled version of BERT : smaller , faster , cheaper and lighter . ArXiv abs / 1910 . 01108 . Schmidt , A . ; and Wiegand , M . 2017 . A survey on hate speech detection using natural language processing . In Pro - ceedings of the ﬁfth international workshop on natural lan - guage processing for social media , 1 – 10 . Sipka , A . ; Hannak , A . ; and Urman , A . 2021 . Comparing the Language of QAnon - related content on Parler , Gab , and Twitter . arXiv preprint arXiv : 2111 . 11118 . Sunar , L . 2017 . The long history of Islam as a collective “other” of the west and the rise of Islamophobia in the US after Trump . Insight Turkey 19 ( 3 ) : 35 – 52 . Thomas , E . 2019 . ASPI explains : 8chan . URL https : / / www . aspistrategist . org . au / aspi - explains - 8chan / . Tuckwood , C . 2017 . Hatebase : Online database of hate speech . The Sentinal Project . Available at : https : / / www . hatebase . org . Vidgen , B . ; Botelho , A . ; Broniatowski , D . ; Guest , E . ; Hall , M . ; Margetts , H . ; Tromble , R . ; Waseem , Z . ; and Hale , S . 2020a . Detecting East Asian prejudice on social media . arXiv preprint arXiv : 2005 . 03909 . Vidgen , B . ; Thrush , T . ; Waseem , Z . ; and Kiela , D . 2020b . Learning from the worst : Dynamically generated datasets to improve online hate detection . arXiv preprint arXiv : 2012 . 15761 . Ward , E . 2021 . Parlez - vous le hate ? : Examining topics and hate speech in the alternative social network Parler . Mas - ter’s thesis , University of Waterloo . Waseem , Z . ; and Hovy , D . 2016 . Hateful symbols or hate - ful people ? predictive features for hate speech detection on twitter . In Proceedings of the NAACL student research work - shop , 88 – 93 . Wiegand , M . ; Ruppenhofer , J . ; and Kleinbauer , T . 2019 . De - tection of abusive language : the problem of biased datasets . In Proceedings of the 2019 conference of the North Amer - ican Chapter of the Association for Computational Lin - guistics : human language technologies , volume 1 ( long and short papers ) , 602 – 608 . Wullach , T . ; Adler , A . ; and Minkov , E . 2020 . Towards hate speech detection at large via deep generative modeling . IEEE Internet Computing 25 ( 2 ) : 48 – 57 . Wullach , T . ; Adler , A . ; and Minkov , E . 2021 . Fight Fire with Fire : Fine - tuning Hate Detectors using Large Samples of Generated Hate Speech . arXiv preprint arXiv : 2109 . 00591 . Zampieri , M . ; Nakov , P . ; Rosenthal , S . ; Atanasova , P . ; Karadzhov , G . ; Mubarak , H . ; Derczynski , L . ; Pitenis , Z . ; and C¸¨oltekin , C¸ . 2020 . SemEval - 2020 task 12 : Multilingual of - fensive language identiﬁcation in social media ( O ﬀ ensEval 2020 ) . arXiv preprint arXiv : 2006 . 07235 . Zannettou , S . ; Bradlyn , B . ; De Cristofaro , E . ; Kwak , H . ; Sirivianos , M . ; Stringini , G . ; and Blackburn , J . 2018 . What is gab : A bastion of free speech or an alt - right echo cham - ber . In Companion Proceedings of the The Web Conference 2018 , 1007 – 1014 . International World Wide Web Confer - ences Steering Committee . Zannettou , S . ; Finkelstein , J . ; Bradlyn , B . ; and Blackburn , J . 2020 . A quantitative approach to understanding online anti - semitism . In Proceedings of the International AAAI Confer - ence on Web and Social Media , volume 14 , 786 – 797 . Zhang , Z . ; Robinson , D . ; and Tepper , J . 2016 . Hate speech detection using a convolution - LSTM based deep neural net - work . Zhou , X . ; Yong , Y . ; Fan , X . ; Ren , G . ; Song , Y . ; Diao , Y . ; Yang , L . ; and Lin , H . 2021 . Hate Speech Detection Based on Sentiment Knowledge Sharing . In Proceedings of the 59th Annual Meeting of the Association for Computational Lin - guistics and the 11th International Joint Conference on Nat - ural Language Processing ( Volume 1 : Long Papers ) , 7158 – 7166 . Ziems , C . ; He , B . ; Soni , S . ; and Kumar , S . 2020 . Racism is a virus : Anti - asian hate and counterhate in social media during the covid - 19 crisis . arXiv preprint : 2005 . 12423 .