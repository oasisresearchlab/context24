MacGyver : Are Large Language Models Creative Problem Solvers ? Yufei Tian 1 ∗ Abhilasha Ravichander 2 Lianhui Qin 24 Ronan Le Bras 2 Raja Marjieh 3 Nanyun Peng 1 Yejin Choi 25 Thomas L . Griffiths 3 Faeze Brahman 2 1 University of California , Los Angeles , 2 Allen Institute for Artificial Intelligence 3 Princeton University , 4 University of California , San Diego , 5 University of Washington yufeit @ cs . ucla . edu Abstract We explore the creative problem - solving ca - pabilities of modern large language models ( LLMs ) in a constrained setting . The setting requires circumventing a cognitive bias known in psychology as “functional fixedness” to use familiar objects in innovative or unconventional ways . To this end , we create M AC G YVER , an automatically generated dataset consisting of 1 , 600 real - world problems that deliberately trig - ger functional fixedness and require thinking ‘out - of - the - box’ . We then present our collection of problems to both LLMs and humans to com - pare and contrast their problem - solving abili - ties . We show that M AC G YVER is challeng - ing for both groups , but in unique and comple - mentary ways . For example , humans typically excel in solving problems that they are famil - iar with but may struggle with tasks requiring domain - specific knowledge , leading to a higher variance . On the other hand , LLMs , being ex - posed to a variety of highly specialized knowl - edge , attempt broader problems but are prone to overconfidence and propose actions that are physically infeasible or inefficient . We also provide a detailed error analysis of LLMs , and demonstrate the potential of enhancing their problem - solving ability with novel prompting techniques such as iterative step - wise reflec - tion and divergent - convergent thinking . This work provides insight into the creative problem - solving capabilities of humans and AI and il - lustrates how psychological paradigms can be extended into large - scale tasks for comparing humans and machines . 1 Introduction Creativity has long been considered the driving force behind modern civilization , and one of the hallmarks of human intelligence ( Guilford , 1967b ; Hennessey , 1995 ) . As large language models ∗ Work in progress . The research project was conducted when the first author interned at AI2 . Problem ( a ) : I need to roll out dough evenly but don ' t have a rolling pin . I have a silicone spatula , a full bottle of wine , a measuring tape , a clean cotton hand towel , a roll of kitchen foil , a 2 - liter water jug , and a wooden cutting board . How should I proceed ? Problem ( b ) : I want to heat my leftover pizza in the hotel room but there is no microwave . I have an iron , a pair of socks , a coffee mug , a notepad , a robe , an electric kettle , foil sheets , and a hairdryer . I cannot directly iron the pizza for food safety reasons . How to heat the pizza using these items only ? “Boil the water with kettle . Wrap pizza with foil . Use the steam to heat the pizza ! ” “Take the cotton towel and roll it up tightly to form a cylindrical shape ! ” Problem ( c ) : I have a flat tire , but my lug wrench is broken . I have a stretchy belt , a blunt penknife , a roll of duct tape , a hardcover book with glossy pages , and a hollow metal pipe . The metal pipe is rusted , breaking under force . How to replace the flat tire ? “Strengthen the pipe with duct tape . Use the reinforced pipe as a lever . ” Figure 1 : Examples of the problems in our M AC G YVER dataset and the corresponding GPT - 4 solutions . Here , ( a ) and ( b ) are solvable while ( c ) is not , yet the LLM fails to identify the unsolvable problem . Pictures , drawn by DALL · E 3 , are for illustration purposes only and may not accurately reflect the text . In our experiment , all inputs to human and LLMs are natural language text . ( LLMs ) have become increasingly powerful , re - searchers have begun to investigate their reasoning ability in problem - solving tasks ( Yao et al . , 2022 ; Brahman et al . , 2023 ) and their capacity for cre - ativity as demonstrated by expressing humor and generating artistic content ( Mittal et al . , 2022 ; Hes - sel et al . , 2023 ; Ramesh et al . , 2022 ; Chakrabarty a r X i v : 2311 . 09682v1 [ c s . C L ] 16 N ov 2023 Model Description Example Mini - C Developmental achievement in the learning process . A pupil applying a strategy learned in a math class into her science project . Little - C Everyday innovation that ordinary people engage with . Removing wrinkles on a shirt without possession of an iron . Pro - C Professional expertise Writing poems or stories that receive professional recognition . Big - C Legendary innovation that redirect a field . Albert Einstein arriving at general relativity . Table 1 : The Four - C model of creativity . et al . , 2022 ; Tian et al . , 2023 ) . However , everyday activities that involve creative thinking and uncon - ventional use of objects have not been explored to the same extent . In this work , we contribute a new challenge benchmark for creative problem solv - ing , hoping to critically assess humans and modern LLMs when it comes to ‘thinking out - of - the - box’ . Kaufman and Beghetto ( 2009 ) proposed the Four - C model , categorizing human creative activi - ties into four categories shown in Table 1 . Although a person is most likely to engage with Little - C : daily activities , the majority of AI - related creativ - ity research belongs to Pro - C : professional exper - tise , such as writing high - quality stories ( Mirowski et al . , 2023 ; Chakrabarty et al . , 2023 ) . We recog - nize one bottleneck for systematically investigating the under - studied Little - C as the lack of a sizable dataset of problems that one might encounter in daily life , which require creativity . To bridge this gap , we curate M AC G YVER , a novel unconventional problem - solving dataset consisting of 1 , 683 sets of verbal problems that re - quire human - like creativity in the realm of physical reasoning ( § 2 ) . Drawing inspiration from the cog - nitive science literature ( Duncker and Lees , 1945 ) , we collect problem scenarios that deliberately push against the cognitive bias towards functional fixed - ness , requiring agents to employ familiar objects in innovative or unconventional ways . To this end , we design a novel and labor - efficient pipeline to collect progressively more challenging problem - solving scenarios . The scenarios are further verified by hu - mans as requiring unconventional usage of objects to find a solution . For example , solving problem ( a ) in Figure 1 requires using the wine bottle as a makeshift rolling pin . 1 Each problem in our dataset is then paired with at least one human - provided or 1 If the problem is unsolvable given the presented tools and constraints , such as problem ( c ) in Figure 1 , we also expect the language agent to identify such infeasibility and provide a short justification . verified solution . To the best of our knowledge , M AC G YVER is the first dataset of unconventional everyday problems that requires both key elements of creativity ( Guilford , 1967a ) : divergent thinking ( to come up with creative and unconventional usage of objects ) and convergent thinking ( to accomplish a given goal efficiently ) . Next , we use the resulting dataset as a bench - mark to evaluate the creative problem - solving abil - ities of both human participants and recent LLMs , including GPT - 3 . 5 ( OpenAI , 2022 ) , GPT - 4 ( Ope - nAI , 2023 ) , PaLM2 ( Anil et al . , 2023 ) , Claude2 ( Anthropic , 2023 ) , and Llama2 ( Touvron et al . , 2023 ) ( § 4 ) . Our results reveal a substantial gap between most LMs and human . While the best per - forming LM , GPT - 4 , complements the capability of an arbitrary human under certain domain - specific settings ( e . g . , fixing a hole on the wall ) , humans’ collective wisdom so far is still invincible . Ad - ditionally , GPT - 4 struggles to identify unsolvable problems and often exhibit misleading helpfulness by suggesting solutions in such inappropriate cases ( 62 % ) . Upon manually analyzing LLMs’ responses , we identify their common error types to be 1 ) propos - ing physically infeasible , unnecessary , or wrong steps that deviate from the intended goal , and 2 ) hallucinating . We then propose two new prompt - ing strategies to mitigate the common error types : 1 ) a self - reflection based strategy to verify the fea - sibility of each generated step , and 2 ) a cognitive - science - inspired strategy of first divergently explor - ing the potential use of presented tools and then converging on the problem solution . Experimental results show the efficacy of both strategies ( § 6 ) . 2 M AC G YVER Dataset In this section , we introduce the labor - efficient pipeline we used to create the M AC G YVER dataset . Notably , we combine the generative strength of LLMs , i . e . , GPT - 4 ( § 2 . 1 ) , with the verification abil - ity of human annotators ( § 2 . 2 ) . Each data point in our dataset includes a problem clearly stating the constraints , goal to accomplish , and available tools , paired with at least one human - provided or human - verified answer ( § 2 . 4 ) . 2 . 1 Progressive Problem Refinement for Dataset Creation LLMs have been shown to be helpful for brain - storming and idea generation ( Girotra et al . , 2023 ) . Solution : use the kitchen tongs ! [ Iteration 3 ] Add additional items as distractors . [ Iteration 2 ] Add constraints to veto the solution Constraint added : The tongs are also slightly shorter than the jar . Problem : You have a tall and narrow cookie jar , a pair of chopsticks , a roll of sticky tape , rubber bands and a pair of kitchen tongs . The jar is too narrow for your hand to fit in and the chopsticks are slightly shorter than the jar . How can you retrieve the cookies using only these items ? [ Iteration 1 ] Generate the vanilla scenario The Cookie Jar Problem You have a tall and narrow cookie jar , a piece of string , a plastic straw , a pair of kitchen tongs , some napkins , a pair of chopsticks , a roll of sticky tape , rubber bands and a magnet . The jar is too narrow for your hand to fit in and both the chopsticks and tongs are slightly shorter than the jar . How can you retrieve the cookies using only these items ? GPT - 4 Human Figure 2 : Progressive problem refinement with GPT - 4 . We carefully design refinement steps that gradually increase a problem’s complexity by adding specific object properties as constraints to veto a previous solution ( i . e . , Iteration 2 ) , and adding distracting objects that are ( likely ) not involved in the solution the problem ( i . e . , Iteration 3 ) . After that , human verifiers judge the quality of refined problems . We thus explore their potential for generating prob - lem settings quickly and at a large scale , instead of asking humans to rack their brains coming up with thousands of constrained scenarios from scratch . Figure 2 provides an illustration of our problem collection pipeline , showing how we combine hu - man and machine inputs . Specifically , we propose a progressive problem - refinement approach that grad - ually increases problem complexity by 1 ) adding specific object properties ( e . g . , material , size , etc . ) as constraints to veto a previous solution and 2 ) adding distracting objects that are not involved in the solution the problem . From a cognitive per - spective on problem - solving ( Knoblock , 1991 ) , the first refinement step reduces the search space by removing the most straightforward path , while the second step further complicates the problem by adding more branches to the search space . We implement this pipeline through a dialogue interaction with GPT - 4 . Human assessment results ( detailed in appendix A . 1 ) confirm that both steps within the progressive refinement approach pose additional challenges to the LLM , and after the two iterations , the original problem requires more creativity and becomes more challenging . 2 . 2 Human Verification Process After generating the challenging scenarios , we in - volve human verifiers to judge if the final versions of the problems 1 ) are solvable ( i . e . , it is possible to find a reasonable and safe solution using the pre - sented tools ) , unsolvable , or need more clarification ( i . e . , the setup is vague or contradictory , which will be discarded ) , and 2 ) for those that are solvable , Problem ( All ) Solvable Unsolvable Total Count 1 , 306 377 1 , 683 Percentage 77 . 6 % 22 . 4 % 100 % Problem ( Solvable Subset ) Unconv . Conv . Total Count 1 , 073 233 1 , 306 Percentage 82 . 2 % 17 . 8 % 100 . 0 % Table 2 : Statistics of the entire M AC G YVER dataset ( top ) . Number of solvable problems that require uncon - ventional use of tools ( bottom ) . whether solving them efficiently requires creative thinking ( i . e . , using objects to achieve goals they were not originally designed for – unconventional usage ) . Each problem is annotated by three human verifiers from Amazon Mechanical Turk . 2 The av - erage inter - annotator agreement ( IAA ) , measured by Cohen’s Kappa , are 0 . 67 and 0 . 77 for tasks 1 ) and 2 ) , respectively . In total , we created 1 , 683 problems . A detailed breakdown are presented in Table 2 . Of those , 78 % are solvable and 22 % are unsolvable . Another 7 % of all problems were discarded after being anno - tated by at least one annotator to be ambiguous or contradictory . For the subset of solvable prob - lems , 82 % require using tools in an innovative or unconventional manner . 2 . 3 Diversity Control and Check Intuitively , we want to avoid generating multiple problems with familiar goals and constraints . We 2 The detailed verification interface can be found in Ap - pendix B . Tool Affordance Freq . duct tape sealing ; tying or connecting 2 . 0 % plastic bag container or holding items ; covering 0 . 7 % flashlight illumination 0 . 7 % aluminum foil covering ; heating ; sealing 0 . 6 % hairdryer heating ; drying ; making noise 0 . 5 % ruler measuring ; straightening 0 . 4 % broom cleaning ; sweeping ; reaching high areas 0 . 4 % spoon eating ; stirring ; measuring 0 . 4 % toothbrush cleaning ; spraying 0 . 4 % mag . glass magnifying ; starting fire 0 . 4 % rope tying or connecting ; reaching high areas 0 . 4 % hammer flattening ; gripping things ; making noise 0 . 3 % yoga mat stretching ; sitting / stepping ; covering 0 . 3 % towel wetting ; covering ; absorbing 0 . 3 % frisbee playing ; throwing 0 . 3 % toothpick cleaning ; separating 0 . 3 % Table 3 : Examples of most commonly presented tools , their featured affordances , and frequency in the entire dataset . We randomly pick 16 tools from the top 40 frequent ones in the M AC G YVER dataset . In total , more than 3 , 800 different tools appear in our dataset . take several measures to make sure the collected problems are diverse , comprehensive , and free of repetitive patterns . Diversity Control Firstly , before the first itera - tion , we hand craft more than 50 tags of locations and activities , aiming to ensure that our data col - lection pipeline delves into a variety of topics . The tags cover diverse range of human activities , from indoor ones such as home arrangement and work - ing in the office , to outdoor ones such as hiking , gardening , and playing with water . These prede - fined tags are integrated into the prompt that we used to query GPT - 4 for problem curation at Iter - ation 1 . Secondly , all problems are generated and refined in batches of 15 rather than one by one , as we find out the former results in significantly higher diversity . We then leverage a widely - used sentence transformer model ( Reimers and Gurevych , 2020 ) to filter out any newly generated problem that is semantically similar to the existing ones in our database . Diversity Check After the final iteration , we parse the objects presented as tools among all gen - erated problems . Intuitively , we consider two same objects with different properties ( e . g . , plastic knife and metal knife ; eyeglasses and magnifying glass ) to be different . In total , 3 , 800 unique tools have h o l d i n g i t e m s 10 . 6 % ( 937 ) c o v e r i n g 9 . 5 % ( 836 ) t y i n g o r c o n n e c t i n g 5 . 8 % ( 5 0 8 ) c l e a n i n g 5 . 3 % ( 465 ) p r o t e c t i o n 4 . 6 % ( 406 ) m e a s u r i n g 3 . 1 % ( 276 ) e a t e n a s f oo d 3 . 1 % ( 271 ) s e a li n g 3 . 0 % ( 265 ) m a k i n g n o i s e 2 . 6 % ( 2 2 9 ) r e a c h i n g h i g h a r e a s 2 . 6 % ( 2 2 8 ) h e a t i n g 2 . 5 % ( 222 ) g r i pp i n g t h i n g s 2 . 5 % ( 219 ) c u tt i n g 2 . 0 % d r a w i n g / w r i t i n g 2 . 0 % d e c o r a t i o n 1 . 7 % s i tt i n g / s t e pp i n g 1 . 5 % ill u m i n a t i o n 1 . 4 % s t a r t i n g f i r e 1 . 4 % s e p a r a t i n g 1 . 3 % p o w e r i n g d e v i c e s e p a r a t i o n s t r e t c h i n g d r i n k i n g r e f l e c t i n g c o o li n g c o o k i n g d i g g i n g p l a y i n g r e a d i n g O t h e r s 25 . 0 % ( 2211 ) Affordance of Presented Tools Figure 3 : Affordances of the presented tools in our M AC G YVER dataset and their frequency ( and count ) . Note that one object may have multiple affordances ( e . g . , paddle boards can be used for boating , reaching high areas , and exercise ) . been identified . We then compute their frequency and leverage GPT - 4 to analyze their affordances . 3 Examples of the most frequent tools and their af - fordances are shown in Table 3 . Finally , a pie chart showing the tool affordances can be found in Fig - ure 3 . We found that holding items and covering are the top two types , followed by tying or connecting and cleaning . The long tails in both illustrations signify a desirable level of diversity . 2 . 4 Collecting Gold Solutions Our final step towards data collection is to pair each problem with a gold answer . For the solvable subset , the answer is a feasible solution written step by step . For the unsolvable subset , the answer is a correct explanation for why the stated goal cannot be achieved . To save human effort , we start by leveraging the generative strengths of a powerful LLM , i . e . , GPT - 4 . Specifically , we first prompt GPT - 4 to generate a solution for each problem in the M AC G YVER dataset . Then , human verifiers assess whether the generated solutions are valid . Only if all three ver - ifiers agree that a solution is valid , it becomes part of our dataset . Otherwise , we ask human workers to write down a solution ( for solvable subset ) or a 3 Refer to Appendix A for more details such as the detailed list of all tags and the prompt used to analyze tool affordance . justification ( for unsolvable subset ) . 3 Assessing the Task Difficulty To gauge the challenge of our unconventional problem - solving task posed to the most recent and powerful LLMs , we evaluate the zero - shot perfor - mance of GPT - 4 model ( OpenAI , 2023 ) . Neverthe - less , existing automatic evaluation techniques fall short to assess the efficacy of a presented solution . Therefore , we recruit human annotators to evaluate the quality of the GPT - 4’s answers on the entire M AC G YVER Dataset . Assessment Setup . For a solvable problem , hu - man annotators are asked to judge if the presented solution is 1 . 1 feasible and efficient , 1 . 2 feasible yet inefficient , or 1 . 3 infeasible . The machine - generated answer may also wrongly assume the problem is unsolvable and gives a wrong justifica - tion ( 1 . 4 ) . For an unsolvable problem , they need to judge if the presented answer 2 . 1 correctly iden - tifies the problem as unsolvable , and 2 . 2 gives the right justification . Similarly , the answer may also wrongly assume the problem is solvable and gives a wrong solution ( 2 . 3 ) . Each GPT - 4 answer is annotated by three work - ers , with an average inter - annotator agreement ( IAA ) of 0 . 71 as measured by Cohen’s Kappa , in - dicating a substantially strong agreement . Inter - estingly , we notice that human workers disagree more often when deciding whether a solution is efficient or inefficient . Upon further investigation , we realize this is partially due to the limitation of individual annotator’s capability – a person who is unaware of the most efficient solution might label a sub - optimal one as highly efficient . Therefore , for those generated solutions linked to solvable prob - lems , instead of taking the majority vote , we take the worse labels as the golden label ( e . g . , taking ‘in - eff . ’ from [ ‘eff . ’ , ‘ineff . ’ , ‘eff . ’ ] ) . For all other cases , we still take the majority votes as gold labels . We find such modification leads to a more accurate set of labels . GPT - 4 Performance . We report the perfor - mance on the solvable and unsolvable subset in Table 4a and Table 4b , respectively . Our prelimi - nary findings indicate that , firstly , LLMs as strong as GPT - 4 still exhibit limitations in solving uncon - ventional problems , with only 18 . 9 % likelihood of providing an efficient solution , while 37 . 5 % like - lihood of providing an infeasible solution . Our Solutions Feasible & eff . ( ↑ ) Feasible & ineff . Infeasible ( ↓ ) LLM says unsolv . ( ↓ ) Count 247 555 490 14 Percentage 18 . 9 % 42 . 5 % 37 . 5 % 1 . 1 % ( a ) Performance on the subset of the M AC G YVER dataset that humans think is solvable . Answers Correct for right reason ( ↑ ) Correct for wrong reason LLM says solvable ( ↓ ) Count 135 8 234 Percentage 35 . 8 % 2 . 1 % 62 . 1 % ( b ) Performance on the subset of the M AC G YVER dataset that humans think is unsolvable . Correct for right reason means that the LLM correctly identifies the problem is unsolvable , and gives the right justification . Correct for wrong reason means that it correctly identifies the problem is unsolvable , but gives an incorrect justification . Table 4 : GPT - 4 performance on M AC G YVER dataset . analysis in the later section ( § 6 ) shows that one common mistake is it failing to realize the conse - quences of actions and tool affordances in the given context . For example , proposing to use chopsticks to lift up the egg yolk . Secondly , GPT - 4 displays overconfidence , often suggesting solutions to prob - lems that are inherently unsolvable . This could be partially due to GPT - 4 being trained with RLHF ( Ouyang et al . , 2022 ) , maximizing its helpfulness . Moreover , the model struggles to discern whether a problem description is sufficiently concrete for res - olution or too ambiguous , necessitating additional context . 4 Benchmarking Humans and LLMs A natural follow - up question is how well mod - ern LLMs perform on this task , as compared to humans . We evaluate the performance of several recent LLMs , namely PaLM2 ( Anil et al . , 2023 ) , Claude2 ( Anthropic , 2023 ) , Llama2 ( Touvron et al . , 2023 ) , GPT - 3 . 5 ( OpenAI , 2022 ) , and GPT - 4 on a subset of 188 problems from the M AC G YVER . 4 In addition , we gauge the capability of average humans on the same set of tasks . 4 . 1 Collecting Independent Human Responses We assessed human capability by recruiting par - ticipants who are new to this task . To this end , 4 Note that this particular subset is biased towards solvable problems and does not constitute a representative sample of the entire M AC G YVER dataset . We are currently working on expanding the pool and establishing a more representative subset for benchmarking purposes . independent solutions were collected from a pool of N = 252 UK participants on Prolific . 5 We intentionally used a different platform and target population from those of the human evaluators ( i . e . , MTurk and US ) to minimize any chances of over - lap . For a given problem , participants indicated whether they believed the problem is solvable , un - solvable , or required further clarification . If solv - able , they provided a step - by - step solution , and otherwise they explained why the problem was un - solvable . A screenshot of the elicitation interface is shown in Figure 14 . Overall , we elicited an average of four responses per problem and each participant contribute to up to five different problems . 4 . 2 Collecting Machine Responses We collected machine solutions from seven differ - ent LLMs . In the prompt , we instruct an LLM to either provide a feasible and efficient solution to a problem if it thinks the problem is solvable , or otherwise a justification explaining why the given problem is unsolvable . If the problem is consid - ered solvable by the LLM , the LLM will be asked to write the solution step - by - step and indicate the tools needed to achieve each step . To explore whether different sizes of the same model plays a role in its problem solving ability , we include three variations of Llama2 ( i . e . , - 7b , - 13b , - 70b ) , as well as two variants of GPT model family ( i . e . , gpt - 3 . 5 - turbo , gpt - 4 - 0613 ) . For each LLM , we adopt Nucleus sampling ( Holtzman et al . , 2020 ) and return the top one sequence , with T = 0 . 7 and p = 0 . 95 . Additional GPT - 4 Responses For a fair compar - ison with humans , we emulate the same setup in § 4 . 1 by obtaining multiple solutions per problem from a single LLM . However , exhaustive human evaluation is costly . To address this , we opted to elicit multiple solutions exclusively from the most potent LLM , GPT - 4 . To align with the varying number of human responses for different problems , we also adjusted the quantity of collected GPT - 4 answers to match that of human answers . On average , we elicited four GPT - 4 solutions per prob - lem through separate API call . To this end , four manually - designed instructions are used to prompt GPT - 4 to reduce repetition among separate ses - sions . For each API call , we still adopt Nucleus sampling and return the top one sequence . 5 https : / / www . prolific . co 4 . 3 Human Evaluation Human annotators were asked to evaluate if a pre - sented answer is correct or wrong by selecting one out of six fine - grained categories : A ( or B ) cor - rectly giving a feasible and efficient ( or less effi - cient ) solution to a solvable problem ; C correctly identifying an unsolvable problem and giving the right justification ; D giving a partially incorrect an - swer , for example , one step is infeasible ; E giving a mostly or entirely wrong answer ; and F failing to identify the correct solvability status of the problem . Following the same rationale in § 3 , we switch our aggregation method from majority vote to worse vote if and only if all annotators agree the proposed solution is either efficient or inefficient . The screen - shots of human evaluation interface can be found in Appendix Figure 15 and 16 . 4 . 4 Benchmark Results We report the benchmark results in Table 5 . Type A , B , and C are the three aspects of correct responses , while the remaining D , E , and F are aspects of the wrong ones . At a glance , despite varying in their characteristics , all of the benchmarked LLMs lag behind the performance of humans . 4 . 4 . 1 Performance with Single Effort As is mentioned in § 4 . 2 , only the top one response is collected for a LLM per problem . Hence , we first list the LLMs’ performances with their single best answers on the top seven rows of Table 5 . For human participants , there is no single person who approached all problems . Therefore , to simulate an arbitrary person’s individual performance , we take a random response from each problem . We see that most recent LLMs achieve a mere 35 % to 40 % chance of success . Although GPT - 4 and Claude3 stand out among the tested LLMs , their best attempts still under - perfom an arbitrary ( average ) person with total correct rate of 65 . 9 % . Interestingly , we do observe that different fam - ilies of LLMs have dissimilar behaviors . For ex - ample , PaLM2 and GPT - 4 are overly verbose and often suggest solutions to problems that are inher - ently unsolvable . Such behavior is reflected in their remarkably low numbers in column C : correctly identify an unsolvable problem . On the contrary , other LLMs such as Llama2 - 7b , Claude2 , and GPT - 3 . 5 are much more conservative and always fail to realize that a constrained problem can still be solv - able , which is reflected in their high numbers in column F . Correct ( % ) Wrong ( % ) A . Eff - icient B . Less Efficient C . Uns - olvable Correct in Total ( ↑ ) D . Partial E . Mostly F . Fail to Identify Wrong in Total ( ↓ ) Single Effort Llama2 - 7b 8 . 8 19 . 4 7 . 8 36 . 0 5 . 1 27 . 2 31 . 8 64 . 1 Llama2 - 13b 11 . 9 27 . 4 2 . 7 42 . 0 10 . 2 31 . 4 16 . 4 58 . 0 Llama2 - 70b 11 . 0 24 . 7 5 . 0 40 . 7 13 . 2 26 . 5 19 . 6 59 . 3 PaLM2 15 . 8 22 . 8 0 . 0 38 . 6 10 . 5 35 . 5 15 . 4 61 . 4 Claude2 13 . 7 22 . 6 14 . 6 50 . 9 9 . 0 13 . 7 26 . 4 49 . 1 GPT - 3 . 5 12 . 7 15 . 5 10 . 3 38 . 5 9 . 9 12 . 2 39 . 4 61 . 5 GPT - 4 ( Random ) 26 . 0 34 . 6 2 . 3 62 . 9 12 . 8 14 . 4 9 . 9 37 . 1 Human ( Random ) 27 . 1 28 . 2 10 . 6 65 . 9 6 . 9 13 . 3 13 . 8 34 . 0 Multiple Efforts Average GPT - 4 27 . 9 34 . 0 1 . 3 63 . 2 12 . 8 15 . 5 8 . 6 36 . 9 Average Human 29 . 7 28 . 5 9 . 0 67 . 2 5 . 2 11 . 1 16 . 5 32 . 8 Best GPT - 4 68 . 1 19 . 1 5 . 3 92 . 5 3 . 2 2 . 1 2 . 1 7 . 4 Best Human 77 . 7 13 . 3 6 . 9 97 . 9 1 . 1 1 . 1 0 . 0 2 . 2 Table 5 : Top : Benchmark results of seven LLMs and human with a single best effort . For each LLM , its best one solution is evaluated per problem . For human participants , there is no single participant who worked on all problems . So we take a random response from each problem . Bottom : Comparison between GPT - 4 and human where we evaluated multiple solutions per problem . The best performance , which can be viewed as an upper bound , is computed by taking the individual best answer ( out of 4 ) for each problem We use boldface to denote the best performance and underline to denote the second best . Comparing the three variants of Llama2 , we find that the larger Llama models ( 13b and 70b ) excel in correctly identifying the solvability status ( col - umn F ) . In other words , a smaller model ( 7b ) is more subject to getting fooled by the presented con - straints and falsely recognize a constrained prob - lem as unsolvable . Beyond this , however , it appears that scaling up the model size does not significantly unleash more power for unconventional problem - solving . 4 . 4 . 2 Performance with Multiple Efforts Recall that we collect multiple solutions per prob - lem for GPT - 4 and humans . With these , we com - pute the average and best performance . The best performance , which can be viewed as an upper bound , is computed by taking the individual best answer for each problem . The results are shown in the bottom four rows of Table 5 . In addition , we compute the majority performance by considering a binary annotation ( i . e . , correct or wrong ) of each problem . We find that the majority of humans are 77 . 7 % correct , surpassing that of GPT - 4 ( 70 . 7 % ) . From Table 5 we see that on average human par - ticipants are slightly worse than GPT - 4 in coming up with a correct solution ( especially inefficient ones , column B ) , which is potentially owing to functional fixedness . In general , humans still out - perform GPT - 4 due to the fact that GPT - 4 seldom correctly identifies an unsolvable problem . More - over , the best of the four human answers , which can be considered as a form of collective wisdom , clearly leads to a near perfect performance . Finally , human participants seems to struggle with certain problems ( column F ) . We hypothe - size that an individual person , who likely does not have domain - specific knowledge in all aspects of life , may not outperform a single LLM such as GPT - 4 , which is trained on massive amount of data and a wide variety of tasks . However , when con - sidered collectively as a group , with each person contributing their unique expertise and wisdom , hu - man intelligence exceeds that of LLMs . To verify our hypothesis and gain deeper insights into the relationship between the intelligence of humans and LLMs , we conduct further analyses in the next section . 5 Comparing GPT - 4 with Humans 5 . 1 Humans have higher variance than LLMs . We plot the kernel density estimate ( KDE ) of in - dividual human and GPT - 4 responses in Figure 4 . We can see that humans either approach a prob - lem perfectly or fail totally . Namely , once humans understand the task and acquire the relevant knowl - edge , they can always propose a feasible and of - Fail MostlyWrong PartiallyWrong LessEfficient Perfect D en s i t y Human vs GPT - 4 on Creative Problem Solving Individual GPT - 4 Individual Human Figure 4 : The kernel density estimate of individual hu - man and GPT - 4 answers . ten the most efficient solution . On the other hand , GPT - 4 responses fall more into the middle ( infea - sible , partially correct , or inefficient ) , owning to its ability to aggregate and synthesize information from a wide range of sources it has been trained on . However , GPT - 4 is sometimes ignorant of the tool affordances or consequences of its proposed actions , lacking the depth of understanding that humans possess ( see more detailed error analysis in § 6 . 1 ) . 5 . 2 Humans possess better general everyday knowledge , but less domain - specifically . Next , we visualize the capability of humans and GPT - 4 on individual problems in a 2D plot in Fig - ure 5 . Accordingly , we convert the categorical la - bels into numerical scores ranging from 0 ( Fail ) to 1 ( Perfect ) . Since there are multiple solutions per problem , we take the numerical average score after the conversion . Each dot in Figure 5 represents a problem , with its color representing the category of the task . We also plot the diagonal line : the farther away a point is from this dashed line , the larger the gap between humans and GPT - 4 . We find that humans are better at solving tasks requiring general , everyday knowledge that they are familiar with , such as household and personal life . For those requiring domain - specific knowl - edge such as gardening / farming / fishing , humans perform noticeably worse than GPT - 4 . The same argument holds when we manually inspect the out - liers : those few problems that belongs to everyday categories yet humans are poor at . Unsurprisingly , they are problems such as fixing a hole in the wall ( category : household ) , demonstrating the concept of refraction without a prism ( category : school ) , and making a sundial ( category : beach ) , which a 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 Human scores 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 G P T - 4 sc o r es 2D visualization of individual problems household personal life in the city school / office / work Category seaside / snow / beach camping / in the wild gardening / farming / fishing Figure 5 : 2D visualization of human ( x - axis ) and GPT - 4 ( y - axis ) performance on individual problems . Each dot represents a problem , with its color representing seven different categories . Humans are better at solv - ing creative problems that they are familiar with ( e . g . , household ) , than those requiring domain - specific knowl - edge ( e . g . , gardening / farming / fishing ) . random average person might have little experience with . Overall , the different creative strengths of hu - mans and AI systems such as GPT - 4 highlight the complementary nature of human and AI problem - solving capabilities . This suggests that the most effective solutions to problems that require thinking outside the box might arise from a collaborative ap - proach that leverages the strengths of both humans and AI . 6 Enhancing LLMs’ Problem Solving Ability In this section , we investigate whether different prompting strategies can enhance the problem - solving abilities of existing LLMs . In § 6 . 1 , we con - duct a detailed error analysis on GPT - 4 , showing it is weakest at identifying the correct tool affordance and physical feasibility . In § 6 . 2 , we propose two new prompting strategies that effectively reduce its mistakes . 6 . 1 Error Analysis for GPT - 4 To better understand the limitations of LLMs and provide insight into potential improvement , we manually analyzed a subset of 200 solutions gen - erated by GPT - 4 that are marked as infeasible by Error Description Example Freq . ( 1 ) Wrong tool usage . Using tools in ways that are physically infeasible or not afforded Using the stapler to staple the duct tape on top of broken glasses . 42 . 4 % ( 2 ) Not achieving the goal . The proposed approach contains unnecessary or wrong steps towards the stated goal To save space when packing , use the scissors to cut the comforter into smaller pieces . 17 . 7 % ( 3 ) Using unavailable tools . Proposing to use tools that are not available . - 16 . 9 % ( 4 ) Wrong spatial understanding Putting the shoe box inside the empty DVD case . 10 . 8 % ( 5 ) Unfaithful to constraints . Ignoring a constraint added to a tool or a situation - 9 . 5 % Table 6 : Categories of common errors made by the most potent LLM , GPT - 4 . It is highly prone to coming up with actions that are physically infeasible , unnecessary , or wrong . Note that one erroneous solution may have more than one type of mistake . human annotators . We identified five categories of common error types which are listed and exempli - fied in Table 6 . We find that GPT - 4 is highly prone to propos - ing physically infeasible , unwanted , or wrong actions . In Table 6 , error type ( 1 ) wrong tool usage accounts for close to half of all the errors made ( 42 . 4 % ) , followed by ( 2 ) not achieving the goal ( 17 . 7 % ) . It is crucial to highlight that LLMs act in a fictional setting , failing to realize the con - sequences of their proposed actions and the affor - dances of tools in the given unconventional context . While one can argue that LLMs lack direct inter - action with the physical world , the human solvers similarly contemplate the same task purely in their minds , without any visual or physical cues . Hallu - cination is also evident in problem solving tasks . We discover two types of hallucination : ( 3 ) using unavailable tools and ( 4 ) unfaithful to constraints , which account for 16 . 9 % + 9 . 5 % = 26 . 4 % of all the errors made . 6 . 2 Improving LLMs’ Problem Solving Ability via Prompting The common error types in Table 6 motivates us to explore techniques to enhance LLMs’ problem solving abilities . Specifically , we explore two prompting strategies as illustrated in Figure 6 : 6 • Iterative Step - Wise Reflection : A self - reflection - based strategy . After the LLM gen - erates an initial solution , we prompt it to verify if each step is physically feasible and afforded . Subsequently , LLMs modifies the original so - lution iteratively until no more modifications 6 The original prompts for both strategies can be found in Appendix C . are needed . • Divergent - Convergent Thinking : A cognitive - science - inspired strategy . The LLM is prompted to first brainstorm the affordance of each presented object ( i . e . , divergent thinking ) and conclude whether they are useful , followed by generating the steps towards the stated goal ( i . e . , convergent thinking ) . We implement both prompting strategies with GPT - 4 on randomly sampled 180 solvable prob - lems that do not have overlap with those used in § 6 . 1 . The performance of the standard prompt - ing and two proposed improvements are shown in Figure 7 . In short , both proposed prompt - ing methods contribute to a reduction in infeasi - ble solutions . Intuitively , Iterative Step - Wise Reflection , which is designed to verify the feasi - bility of steps , has a larger improvement in reduc - ing infeasible solutions ( 9 . 7 % vs 4 . 3 % drop ) ; while Divergent - Convergent Thinking , which is de - signed for better preparation before generating the solution , is more helpful in generating efficient so - lutions ( 6 . 5 % vs 2 . 2 % gain ) . We are in the process of testing the efficacy of both prompting strategies on other LLMs . 7 Limitations and Future Directions Limitations . Measuring how well a model can solve creative problems is hard due to the lack of standardized automated metrics . For example , as - suming the availability of multiple references , pop - ular automatic NLG metrics exhibit a weak corre - lation with human judgment , with Pearson correla - tion coefficients of 0 . 07 for BLEU - 2 / BLEU - 3 ( Pa - pineni et al . , 2002 ) and 0 . 12 for BertScore ( Zhang Solution with Vanilla Prompting : Use the chopstick to gently lift the yolk out of the bowl , leaving the egg white behind . Be careful not to break the yolk . Figure 6 : Illustration of the two proposed prompting strategies : iterative step - wise reflection ( left ) and divergent - convergent thinking ( right ) . 10 20 30 40 50 Feasible & e ﬀ . ( ↑ ) Feasible & ine ﬀ . Infeasible ( ↓ ) 26 . 9 36 36 . 6 21 . 5 45 . 7 32 . 3 31 . 2 38 . 7 30 . 1 Vanilla Re f lect Div - Conv Figure 7 : Results of different prompting strategies . We compare 1 ) vanilla prompting , 2 ) iterative step - wise reflection ( reflect ) , and 3 ) divergent - convergent thinking ( div - conv ) . et al . , 2019 ) . Our experiments thus rely on human evaluation process , which is relatively slow and costly . Therefore , new proposals for efficient and automatic evaluation framework for creative and sequential planning could be a compelling future direction . Another limitation of our study lies in the na - ture of our problems being generated by an LLM , GPT - 4 . Despite its strengths in exploring a unique and novel angle of problem - solving , it might also exhibit inherent biases and tendencies of the under - lying model . Given GPT - 4’s predominant training on English - speaking data , we may inadvertently reflect the cultural nuances of North American and European contexts . Future Directions . We believe the M AC G YVER dataset opens up the door for multiple future di - rections . In this work , we provide a preliminary attempt to improve the problem solving ability of LLMs via two prompting methods . We encourage future work to investigate other planning and rea - soning strategies to enhance LLMs with physical knowledge , spatial understanding , and reduce hal - lucination . Additionally , to ameliorate the mistakes made in the fictional setting , one may also build agents that can interact with the physical ( or sim - ulated ) world and get feedback from the environ - ment . However , we anticipate the need for rigorous efforts to build that simulated environment . An - other exciting direction for future work could be human - AI collaboration for eliciting the best an - swers across a wide spectrum of problems , as we already show in § 5 that humans and AI have com - plementary strengths in creative problem - solving . 8 Related Work Creativity Theory Guilford ( 1967a ) defines a meaningful creative process as an interplay be - tween spontaneous ( divergent , to come up with novel ideas ) and controlled ( convergent , to sat - isfy the demand of the task ) modes of thinking . Kaufman and Beghetto ( 2009 ) proposed the Four - C model , categorizing human creative activities into Mini - C : developmental creativity in the learn - ing process , Little - C : everyday innovation that ordinary people have knowledge of and engage with ( such as removing wrinkles on a shirt without possession of an iron ) , Pro - C : professional exper - tise such as writing poems or painting artwork , and Big - C : highly eminent innovation few people en - gage with . However , Little - C , daily activities that involve divergent thinking and creative usage of objects in which an average person may often participate , are still under - explored . One challenge for systemat - ically investigating the under - studied topic is the lack of a sizable dataset of creative problems that one might encounter in daily life . For example , re - cent work ( Koivisto and Grassini , 2023 ) conducts experiments about divergent thinking on the fol - lowing objects : rope , box , pencil , and candle . We bridge this gap by proposing a novel dataset con - taining 1 , 600 everyday problems . Cognitive Bias Functional fixedness is a cog - nitive bias that makes it difficult to use familiar objects in unconventional or creative ways . For instance , when someone struggles to see a chair as anything other than a seat , this is functional fixedness . Understanding these biases is crucial because they subtly influence everyday decisions and problem - solving approaches , often without us being aware of their impact . We show that over 82 % of the solvable problems in the M AC G YVER dataset require using tools unconventionally to by - pass such a bias . Machine Physical Reasoning Previous research such as Hong et al . ( 2021 ) and Bakhtin et al . ( 2019 ) has investigated physical reasoning in visual con - texts without language . In the realm of language - based physical reasoning , earlier studies primarily focused on understanding physical concepts and at - tributes of various objects , such as PROST ( Aroca - Ouellette et al . , 2021 ) , and NEWTON ( Wang et al . , 2023 ) . Relatedly , SWAG ( Zellers et al . , 2018 ) intro - duced and tackled the task of grounded common - sense inference about physical situations . PIQA ( Bisk et al . , 2020 ) , which tests machines’ physi - cal commonsense reasoning ability with goal and solution pairs , is most similar to ours . While profi - ciency in addressing problems in our M AC G YVER dataset involves all the above abilities , our empha - sis extends beyond . We put a distinct focus on the unconventional tool usage , reasoning over the af - fordance of tools and ruling out unnecessary ones , and how individual objects can be used as a combi - nation to achieve a complex goal . 9 Conclusions We propose a novel task and the accompanying M AC G YVER dataset for unconventional problem solving , focusing on everyday activities which mir - ror the kinds of creativity that most people have to engage in . We evaluate and compare both LLMs’ and humans’ performance on the M AC G YVER benchmark and show the impotence of the mod - ern LLMs in proposing physically feasible actions towards a stated goal . Nonetheless , LLMs can be complementary to human capabilities under certain domain - specific settings . Finally , we propose two new prompting methods that effectively improve the reasoning ability of LLMs . 10 Acknowledgements This work was funded in part by DARPA MCS pro - gram through NIWC Pacific ( N66001 - 19 - 2 - 4031 ) , the NOMIS Foundation , and the Allen Institute for AI . We thank Jena D . Hwang , Ilia Sucholutsky and Mosaic team members for the helpful discussions . References Rohan Anil , Andrew M Dai , Orhan Firat , Melvin John - son , Dmitry Lepikhin , Alexandre Passos , Siamak Shakeri , Emanuel Taropa , Paige Bailey , Zhifeng Chen , et al . 2023 . Palm 2 technical report . arXiv preprint arXiv : 2305 . 10403 . Anthropic . 2023 . Model card and evaluations for claude models . Stéphane Aroca - Ouellette , Cory Paik , Alessandro Ron - cone , and Katharina Kann . 2021 . Prost : Physical reasoning about objects through space and time . In Findings of the Association for Computational Lin - guistics : ACL - IJCNLP 2021 , pages 4597 – 4608 . Anton Bakhtin , Laurens van der Maaten , Justin Johnson , Laura Gustafson , and Ross Girshick . 2019 . Phyre : A new benchmark for physical reasoning . In Ad - vances in Neural Information Processing Systems , volume 32 . Curran Associates , Inc . Yonatan Bisk , Rowan Zellers , Jianfeng Gao , Yejin Choi , et al . 2020 . Piqa : Reasoning about physical com - monsense in natural language . In Proceedings of the AAAI conference on artificial intelligence , volume 34 , pages 7432 – 7439 . Faeze Brahman , Chandra Bhagavatula , Valentina Py - atkin , Jena D Hwang , Xiang Lorraine Li , Hirona J Arai , Soumya Sanyal , Keisuke Sakaguchi , Xiang Ren , and Yejin Choi . 2023 . Plasma : Making small language models better procedural knowledge mod - els for ( counterfactual ) planning . arXiv preprint arXiv : 2305 . 19472 . Tuhin Chakrabarty , Vishakh Padmakumar , Faeze Brah - man , and Smaranda Muresan . 2023 . Creativity sup - port in the age of large language models : An empiri - cal study involving emerging writers . arXiv preprint arXiv : 2309 . 12570 . Tuhin Chakrabarty , Vishakh Padmakumar , and He He . 2022 . Help me write a poem : Instruction tuning as a vehicle for collaborative poetry writing . In Proceed - ings of the 2022 Conference on Empirical Methods in Natural Language Processing , pages 6848 – 6863 , Abu Dhabi , United Arab Emirates . Association for Computational Linguistics . Karl Duncker and Lynne S Lees . 1945 . On problem - solving . Psychological monographs , 58 ( 5 ) : i . Karan Girotra , Lennart Meincke , Christian Terwiesch , and Karl T Ulrich . 2023 . Ideas are dimes a dozen : Large language models for idea generation in innova - tion . Available at SSRN 4526071 . Joy P Guilford . 1967a . Creativity : Yesterday , today and tomorrow . The Journal of Creative Behavior , 1 ( 1 ) : 3 – 14 . Joy Paul Guilford . 1967b . The nature of human intelli - gence . Beth A Hennessey . 1995 . Social , environmental , and developmental issues and creativity . Educational Psychology Review , 7 : 163 – 183 . Jack Hessel , Ana Marasovic , Jena D . Hwang , Lillian Lee , Jeff Da , Rowan Zellers , Robert Mankoff , and Yejin Choi . 2023 . Do androids laugh at electric sheep ? humor “understanding” benchmarks from the new yorker caption contest . In Proceedings of the 61st Annual Meeting of the Association for Compu - tational Linguistics ( Volume 1 : Long Papers ) , pages 688 – 714 , Toronto , Canada . Association for Compu - tational Linguistics . Ari Holtzman , Jan Buys , Li Du , Maxwell Forbes , and Yejin Choi . 2020 . The curious case of neural text degeneration . In 8th International Conference on Learning Representations , ICLR 2020 , Addis Ababa , Ethiopia , April 26 - 30 , 2020 . OpenReview . net . Yining Hong , Li Yi , Joshua B . Tenenbaum , Antonio Torralba , and Chuang Gan . 2021 . PTR : A benchmark for part - based conceptual , relational , and physical reasoning . CoRR , abs / 2112 . 05136 . James C Kaufman and Ronald A Beghetto . 2009 . Be - yond big and little : The four c model of creativity . Review of general psychology , 13 ( 1 ) : 1 – 12 . Craig A Knoblock . 1991 . Search reduction in hierar - chical problem solving . In AAAI , volume 91 , pages 686 – 691 . Citeseer . Mika Koivisto and Simone Grassini . 2023 . Best hu - mans still outperform artificial intelligence in a cre - ative divergent thinking task . Scientific Reports , 13 ( 1 ) : 13601 . Piotr Mirowski , Kory W Mathewson , Jaylen Pittman , and Richard Evans . 2023 . Co - writing screenplays and theatre scripts with language models : Evaluation by industry professionals . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems , pages 1 – 34 . Anirudh Mittal , Yufei Tian , and Nanyun Peng . 2022 . AmbiPun : Generating humorous puns with ambigu - ous context . In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Tech - nologies , pages 1053 – 1062 , Seattle , United States . Association for Computational Linguistics . OpenAI . 2022 . Introducing chatgpt . OpenAI . 2023 . Gpt - 4 technical report . Long Ouyang , Jeffrey Wu , Xu Jiang , Diogo Almeida , Carroll Wainwright , Pamela Mishkin , Chong Zhang , Sandhini Agarwal , Katarina Slama , Alex Ray , John Schulman , Jacob Hilton , Fraser Kelton , Luke Miller , Maddie Simens , Amanda Askell , Peter Welinder , Paul F Christiano , Jan Leike , and Ryan Lowe . 2022 . Training language models to follow instructions with human feedback . In Advances in Neural Information Processing Systems , volume 35 , pages 27730 – 27744 . Curran Associates , Inc . Kishore Papineni , Salim Roukos , Todd Ward , and Wei - Jing Zhu . 2002 . Bleu : a method for automatic evalu - ation of machine translation . In Proceedings of the 40th Annual Meeting of the Association for Compu - tational Linguistics , pages 311 – 318 , Philadelphia , Pennsylvania , USA . Association for Computational Linguistics . Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical text - conditional image generation with clip latents . arXiv preprint arXiv : 2204 . 06125 , 1 ( 2 ) : 3 . Nils Reimers and Iryna Gurevych . 2020 . Making monolingual sentence embeddings multilingual us - ing knowledge distillation . In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing . Association for Computational Linguistics . Yufei Tian , Anjali Narayan - Chen , Shereen Oraby , Alessandra Cervone , Gunnar Sigurdsson , Chenyang Tao , Wenbo Zhao , Tagyoung Chung , Jing Huang , and Nanyun Peng . 2023 . Unsupervised melody - to - lyrics generation . In Proceedings of the 61st Annual Meet - ing of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 9235 – 9254 , Toronto , Canada . Association for Computational Linguistics . Hugo Touvron , Louis Martin , Kevin Stone , Peter Al - bert , Amjad Almahairi , Yasmine Babaei , Nikolay Bashlykov , Soumya Batra , Prajjwal Bhargava , Shruti Bhosale , et al . 2023 . Llama 2 : Open founda - tion and fine - tuned chat models . arXiv preprint arXiv : 2307 . 09288 . Yi Ru Wang , Jiafei Duan , Dieter Fox , and Siddhartha Srinivasa . 2023 . Newton : Are large language mod - els capable of physical reasoning ? arXiv preprint arXiv : 2310 . 07018 . Shunyu Yao , Jeffrey Zhao , Dian Yu , Nan Du , Izhak Shafran , Karthik Narasimhan , and Yuan Cao . 2022 . React : Synergizing reasoning and acting in language models . arXiv preprint arXiv : 2210 . 03629 . Rowan Zellers , Yonatan Bisk , Roy Schwartz , and Yejin Choi . 2018 . SWAG : A large - scale adversarial dataset for grounded commonsense inference . In Proceed - ings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 93 – 104 , Brus - sels , Belgium . Association for Computational Lin - guistics . Tianyi Zhang , Varsha Kishore , Felix Wu , Kilian Q Weinberger , and Yoav Artzi . 2019 . Bertscore : Eval - uating text generation with bert . arXiv preprint arXiv : 1904 . 09675 . A More information on the M AC G YVER Dataset A . 1 Does the data collection pipeline result in progressively challenging problems ? To test whether our data creation pipeline ( in Fig - ure 2 ) is indeed iteratively posing challenge to a previous iteration , we collect GPT - 4 answers to iteration 1 , 2 , and 3 of 200 problems , and run the same human evaluation process described in § 4 . 3 . GPT - 4’s performance on all three iterations of the same set of problems can be found in Table 7 . As the problems get iteratively refined , the ratio of feasible and efficient solutions decrease , and the ratio of infeasible answers increase . This reflects that most potent LLM , GPT - 4 , indeed finds the problems increasingly challenging . Solutions Feasible & eff . ( ↑ ) Feasible & ineff . Infeasible ( ↓ ) LLM says unsolv . ( ↓ ) Iteration 1 39 . 1 % 36 . 8 % 24 . 0 % 0 . 1 % Iteration 2 34 . 7 % 32 . 2 % 31 . 7 % 1 . 4 % Iteration 3 25 . 4 % 37 . 9 % 35 . 7 % 1 . 0 % Table 7 : GPT - 4 performance on iteration 1 , 2 , and 3 of 200 problems . Numbers in each row add up too 100 % . A . 2 Tags used for Diversity Control We list all the tags ( i . e . , locations and activities ) used to curate the dataset in Table 8 . They are introduced to prompt the LLM for diversity control , and can be broadly divided into Indoors / Household , Neutral , and Outdoors . A . 3 Analyzing Tool Affordance We leverage GPT - 4 to analyze the affordance of presented tools in the M AC G YVER dataset . Specif - ically , we start with a small set of hand - crafted af - fordance as seed . Despite being required to choose only from this fixed list of affordances , GPT - 4 does not strictly follow our instruction , and sometimes returns new types that are not included in the seed list . We then gradually expand the list of affor - dances with newly generated ones . We use the following prompt : B Human Annotation Details B . 1 Evaluation Setup We used qualification tasks to recruit 160 qualified annotators on Mechanical Turk . They are paid over 18 USD per hour for all the tasks except for the Indoors / Household Neutral Outdoors bedroom at a party at the beach closet or storage organization classroom and university lecture hall backyard gardening cooking a complex dish dog training beach cleanups , or planning a beach event dining room garage boat trip fitness workouts going out for a meal campsite setting gym and sports facilities plants , flowers and garden city streets and sidewalks hair styling and care public speaking construction work home improvement recycling and waste management desert survival in a hotel room school and student activity exploring a cave indoors arrangement school science fair farm duties kitchen science laboratory forest and jungle library swimming hiking , camping , and traveling living room university campus in the parks office and work vehicle maintenance in the rain packing things up weather preparation and response in the winter personal grooming and beauty routine in the zoo shopping on the playground playing with snow playing with water rooftop terrace Table 8 : The tags ( i . e . , locations and activities ) used to curate the dataset for diversity control . They can be broadly divided into Indoors / Household , Neutral , and Outdoors . human study mentioned in § 4 . 1 . All participants iof human study provide informed consent in ac - cordance with an approved Princeton University institutional review board ( IRB ) protocol ( 10859 ) , and they are paid at a rate of 12 USD per hour . B . 2 Task Interfaces Data Collection and Difficulty Assessment . In practice , we combine the questions of data collec - tion ( § 2 ) and difficulty assessment ( § 3 ) into one single task . The detailed human annotation inter - face , including the instructions , examples , and the actual task and be found in Figure 9 to Figure 13 . Human Study A screenshot of the interface to elicit independent human responses is shown in Figure 14 . For a given problem , participants in - dicate whether they believe the problem is solv - able , unsolvable , or required further clarification . If solvable , they provide a step - by - step solution , and otherwise they explain why the problem was unsolvable . Benchmark Evaluation The screenshots of our human evaluation interface for the benchmark ex - periment can be found in Figure 15 and 16 . C The Prompts for Improving LLM’s Ability Figure 17 and Figure 18 list the actual prompts for two strategies : step - by - step verify and Divergent - Convergent Thinking . 1 < −− Instruction . −− > 2 You need to write the most common affordances of an item . Please choose one or more options from the following : 3 < −− Seed list to expand with . −− > 4 Container / holding items , covering , heating , measuring , drawing / writing , cleaning , sitting / stepping , tying or connecting , illumination , stretching , starting fire , sealing , cutting , separation , reaching high areas , powering devices , digging , making noise , flatten , cutting , gripping things , reflecting , eaten as food . 5 6 < −− Examples . −− > 7 Here are some examples : 8 rice : eaten as food 9 case : container / holding items , protection , covering 10 ruler : measuring , straightening 11 box : container / holding items 12 pencil : drawing / writing , 13 14 < −− Actual Task . −− > 15 Please write the common types of affordances of the following tools . 16 17 1 . { Tool 1 } . 18 . . . 19 N . { Tool N } . Figure 8 : The prompt used to analyze tool affordance . We start with a list of affordances as seed . We gradually expand our list thanks to the fact that GPT - 4 does cannot strictly follow our instruction and occasionally gener - ates other affordances not belonging the predefined set . Figure 9 : Human Annotation Interface for Data Collection and Difficulty Assessment , Page 1 . Figure 10 : Human Annotation Interface for Data Collection and Difficulty Assessment , Page 2 . Figure 11 : Human Annotation Interface for Data Collection and Difficulty Assessment , Page 3 . Figure 12 : Human Annotation Interface for Data Collection and Difficulty Assessment , Page 4 . Figure 13 : Human Annotation Interface for Data Collection and Difficulty Assessment , Page 5 . Figure 14 : Human Study Interface to Collect Independent Human Responses . Figure 15 : Human Evaluation Interface for Benchmarking , Page 1 . Figure 16 : Human Evaluation Interface for Benchmarking , Page 2 . 1 < −− Round 1 : −− > 2 User : { Problem Statement } 3 If the problem is solvable , provide a concise solution . Use step1 , step2 , etc , and mention the tools to achieve each step . Use as few steps as possible and the answer should ideally be less than 100 words . 4 5 If you cannot find a feasible solution , just say that it is not possible and give a very short justification . 6 7 Assistant : { Answer } 8 9 < −− Round 2 : −− > 10 User : Now , please verify if each step is physically feasible and afforded . After that , modify the solution if needed . 11 Use the following format : 12 Step 1 : . . . 13 Step 2 : . . . 14 . . . 15 Conclusion 1 : Whether the problem is indeed solvable given all the constraints 16 Conclusion 2 : ( If still solvable ) No modification needed / Modification needed . 17 18 19 Modified solution : 20 Assistant : { Response and Updated solution } 21 < −− Repeat until no modification is needed . −− > Figure 17 : Prompt used for the step - by - step verify strategy . 1 User : { Problem Statement } 2 Give a feasible solution very concisely . Note that some tools are not useful , so please analyze the affordance of each presented object , and rule out unnecessary ones first . 3 4 5 Use the following format : 6 1 . List the affordance of presented items and whether they are useful 7 2 . Summary : list useful tools 8 3 . If the problem is solvable under all these constraints , write the solution . Use step1 , step2 , etc , and mention the tools to achieve each step . Use as few steps as possible and the answer should ideally be less than 100 words . 9 10 If you cannot find a feasible solution , just say that it is not possible and give a very short justification . 11 12 Assistant : { Analysis of the affordance and the main answer } Figure 18 : Prompt used for the divergent - convergent thinking strategy .