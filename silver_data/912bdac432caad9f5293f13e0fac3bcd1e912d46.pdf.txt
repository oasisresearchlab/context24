Value - Centred HCI Gilbert Cockton School of Computing & Technology , Sir Tom Cowie Campus , University of Sunderland , St . Peter’s Way , Sunderland SR6 0DD , UK . Gilbert . Cockton @ sunderland . ac . uk ABSTRACT HCI is misdefined . We need to redefine it . HCI is misfocused . We need to refocus it . HCI has a window of opportunity to recreate itself as a design discipline . It must focus on the intention of gifted design , which is to improve the world by delivering new sources of value . A focus on value creates a paradoxical discipline that fuses subjectivity and objectivity in a single process . HCI must be objectively systematic and reliable in the pursuit of subjective value . Traditional disciplines have delivered truth . The goal of HCI is to deliver value . In my invited presentation , I will outline why we can and must change within HCI , where we are now ( and how we got there ) , what I believe we should change to . I close with a research agenda for value - centred HCI . Author Keywords Keywords : Value - centred HCI , Design , Guidelines , Usability , Context , Stakeholders . ACM Classification Keywords ACM : H . 1 . 2 – User / Machine Systems INTRODUCTION Existing definitions of HCI are inadequate . They deferentially accept the role defined for us by sponsors in government and business . They reflect what others want us to do , rather than what we can do . We need to change because we must and because we can . We must change because we have exhausted all current intellectual trajectories . Our luck is running out with guidelines . Usefulness cannot be achieved solely through quality in use . Value cannot be delivered solely through fit to context . We have pursued all current HCI goals of guidance , quality and fit to their logical conclusions , but they do not fully support design . They are all necessary , because we must have design options , avoid poor quality in use , and achieve fitness for purpose . However , they are not sufficient for worthwhile design , which must deliver value . We have taken the best from computing , psychology and sociology , but none can deliver gifted design’s focus on value . Innovation , quality and fit are worthless if they do not deliver value . HCI is at a unique point in its history . For over three decades it has been driven by computers that were initially too expensive but then became too cheap . Currently , there are no foreseeable new digital technologies . Computers have become mobile and embedded . They have become media as well as information channels . They have become loci of experience as well as work horses . They have become ambient and proactive as well as deskbound and reactive . They have become immersive and intrusive . We can wear them as well as sit in front of them . They are connected using copper , light and radio waves . They can sense . HCI may not be forced to deal with radically new technologies for several years . It should take advantage of this and renew itself . To do so , it needs to look beyond computing , psychology and sociology to a design movement that seeks value above all else . We have exhausted all current intellectual trajectories I will defend this position by recourse to history . I will then describe the current state of HCI , where each once dominant discipline is now an also - ran . HCI history has been one of hegemony rather than conquest or annihilation . One decade’s establishment became the next decade’s underclass , but every contributing discipline remains intact , active , effective and influential . There is one last piece to slot into the HCI jigsaw . I will argue that only a focus on delivering value can be the basis for a complete and effective HCI . HCI cannot deliver value as an objective applied science . Rather , it should focus on subjective value , picking and choosing what it needs from contributing disciplines , respecting their intellectual values , but not subordinating itself to them . Rather , they should co - operate in the pursuit of value . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . NordiCHI ' 04 , October 23 - 27 , 2004 Tampere , Finland Copyright 2004 ACM 1 - 58113 - 857 - 1 / 04 / 10 . . . $ 5 . 00 A VERY SHORT CRITICAL HISTORY OF HCI HCI is at least three decades old ( I collapse the pre - history of HCI into the 1970s and begin there ) . Each decade is presented as four intertwined histories : technology ; sponsors’ attitudes towards HCI ; HCI itself ; and me myself ! Value - centred HCI is inherently subjective , so I use well understood examples from my own collaborative research , which began just after HCI’s pre - history . Each decade’s potted history ends with an assessment of the role of luck and magic . While we should not rely on luck and still less present it as magic , much of HCI has been luck masquerading as magic . The role of luck and magic in each decade is thus assessed . The System - Centred Seventies Technology HCI began as a response to user difficulties with timesharing [ 39 ] . Computers were too costly to stand idle while one user interacted for a fraction of each second . However , they were also too costly to be unusable due to system response variability or poorly designed interfaces . Sponsors Much of the value of time - sharing applications could be degraded if not destroyed by poor usability . Data entry errors could be very costly to correct . These and other problems forced system sponsors to press for improved quality in use . Many used collections of guidelines . Feature - based rules are very attractive to system sponsors , since staff with no training in psychology and no knowledge of intended usage contexts can use them . HCI It was largely left to computing specialists to resolve early ease of use problems . There were ergonomists working in computing , and there were psychological experiments on interactive computing , but the classic guidelines papers were largely written by computing experts and published in the computing literature . Fred Hansen’s seminal paper on the Emily text editor [ 23 ] began his user engineering principles with Know the User . Hansen’s other three alliterative principles of Minimize Memorization , Optimize Operations and Engineer for Errors had the virtue of being Directives for Designers , with only a few refined into rules that we would recognise as guidelines ( e . g . , “Use names not numbers” ) . Hansen’s paper drew on the limited intellectual resources that computing could then bring to bear on HCI . Common sense , it would seem , could still get you a long way , exposing the importance of usage contexts ( “Know the User” ) , the cognitive nature of interaction ( “Minimise Memorization” , “Optimise Operations” ) and the pervasiveness of human error ( “Engineer for Errors” ) . Hansen’s focus on designer responsibilities moved to system features with Tony Wasserman , who offered advice on how to ‘idiot - proof’ systems . In the systems - centred era , use of a good guideline could protect systems from dangerous users . One idiot - proofing technique was to “allow the user to express the same message in more than one way” [ 45 ] . The belief here is that any form of alternative input will idiot - proof a system . Yet in public systems such as ATMs , alternative input forms are rare ( better accessibility may change this ) . Alternative ways of expressing withdrawal amounts are effective ( fixed amounts for speed , keyed amounts for flexibility at the expense of more time and errors ) , but other alternatives could complicate usage without delivering value . There is no magic in alternative inputs . The right alternatives at the right time will deliver quality in use , but Wasserman glossed over such contingencies . Counter examples are trivially easy to generate , e . g . , six extra randomly placed alternatively worded ‘yes’ , ‘no’ and ‘cancel’ buttons on a dialog box ? This sloppy approach to evidence was exposed as psychologists challenged the hegemony of computing in HCI . The first major HCI conference ( Gaithersburg 1982 ) established psychology’s decade of dominance , just as a young researcher attempted to address problems with guidelines ( lack of generality , mutual incompatibility ) . Martin Maguire resolved this by restricting guidelines to applicable contexts [ 30 ] . His grounding of guideline applicability in users , tasks and application domains heralded contextual research a decade before it took hold . In the meantime , psychologists focused on the poor evidence for guidelines and looked to experimental method to deliver authoritative design guidance . Gilbert I was at still at secondary school in 1971 . I went to university in 1977 to study History , so I’m back to my first discipline in this section ! In 1978 , I used a computer for the first time , when a friend took me into the computing tower at his university . We played golf and then lunar lander on a teletype , which bored me . Back at my university , I studied the history of political ideas . Marx argued that considering objects independently of their social relations results in alienating commodity fetishism . Objects become totems , stripped of their human origins and meaning [ 31 ] . I saw no connection at the time with guidelines , but I can now . Guidelines consider objects independently of their usage context . The result is a totemic view of features with magic powers in all contexts . In 1979 , motivated by values of practicality and principle , I changed to an Education degree . We applied philosophy , psychology and sociology to the design of curricula and learning experiences . This early applied inter - disciplinary training provided an excellent basis for HCI research and practice . However , unlike HCI , Education asks searching questions about its role and what has sufficient value to be worth teaching . It does not merely accept the instructions of government sponsors and business critics . It looks for core principles that rise above current policies and fashions . Looking back , I can see that being inter - disciplinary and applied is not enough . A discipline’s coherence comes from its core values . HCI will not become a true discipline until it develops , expresses , discusses , agrees and integrates a set of core values . Luck and Magic Pre - historical HCI did progress . Much of today’s user interface components were in place by 1979 . They were described so that others could copy them . Advice on their use was packaged as guidelines . Guidelines however should not work . A few minutes watching real users using guideline conformant design will disabuse any open mind of a belief in magic . Usability cannot reside in a system any more than strength can reside in a chair ( if it does , it presumably runs out and away when it sees a truck coming ! ) Chairs do not break because of any inherent strength , but because they are lucky that people rather than trucks sit on them ! Too many stakeholders in software development are too ready to believe in guideline magic . They can defend their belief on the basis of selective evidence , since , like chairs , guidelines do strike lucky : they work when the right users interact with a system in the right way . Otherwise , like chairs , they break when their luck runs out . A guideline gets lucky when contexts of use are sufficiently similar to maximise the chance of delivering quality in use for the task steps supported by recommended features . Thus Recognition not recall generally works because the former is always cognitively easier than the latter ( if not then something must not be recognisable ) . However , this guideline breaks down when entering one’s name . A menu of the world’s countries ( Wake Island included ) is bad enough when ordering on - line , but a menu of the world’s population would be unusable ! Although I know the United Kingdom when I eventually see it , I may never get to see my name to recognise it . Recognition not recall fails when browsing costs outweigh recall costs . The User - Centred Eighties Technology Timesharing gave the first nudge to HCI , but Moore’s law [ 34 ] barged into it and propelled it for two decades . The exponential increase in transistors per circuit took Intel from 2 , 250 transistors on the 4004 in 1971 to 42 , 000 , 000 on the Pentium 4 in 2000 . This made the IBM PC , Alto , Lisa and Macintosh possible , as well as the mobile and embedded technologies of the 1990s . Sponsors In the 1970s , poor usability was a nuisance for a small but growing body of users who were not primarily computer specialists . In the 1980s , as computers arrived in virtually every workplace , poor usability became a crisis that threatened the effectiveness of businesses , as well as the health and well being of an unprepared workforce . HCI was invented by government and business sponsors as a result . With far less knowledge than a guidelines author , they used naïve terms such as “user friendly” , “intuitive” and “natural” . Computer usage would be smooth and pleasant because they would work like people ( speech , natural language ) in ways that required no training . National HCI programmes were established in the UK ( Alvey ) , USA ( MCC ) and Japan ( 5 th Generation ) , as well within the European ESPRIT programme . HCI was defined by those who needed it , not by those who did it . The naïve words of outsiders remain in daily use . The HCI community is not comfortable with them . Terms like “usability” continue to cause problems ( it’s so little of what we do ) . The words of well - intentioned amateurs would dominate HCI’s public image for two decades . HCI The nascent HCI community fully understood the crisis but initially tried to apply discipline to the problem . The Psychology of Human - Computer Interaction [ 3 ] did not meet wild hopes for usability at the click of a button : “Designing interactive computer systems to be efficient and easy to use is important so that people in our society may realise the potential benefits of computer - based tools . Our purpose in this book is to help lay a scientific foundation for an applied psychology concerned with human users of interactive computer systems . This book is our attempt to span the gap between science and application . We have tackled a small piece of the general problem . ” [ 3 , p . vii ] This caution contrasts sharply with outsiders’ expectations that rules could be applied to interactive systems to make them intuitive , error - free and effective , independently of user knowledge and task complexity . These expectations still exist . I recently read a job advert in my national press for a local government web - editor , who would be responsible for ensuring optimal usability ! The Psychology of Human - Computer Interaction made no claim to cover a complete discipline , but only the psychology of HCI . The first reference to HCI as a new discipline was Bill Curtis’ paper in the first of what became the HCI International conference series [ 16 ] . It presented a computer scientist’s view of HCI as an interdisciplinary practice to be formed in the crucible of a new discipline . The implication was that adding human science to computing would result in better design , a view repeated in this definition : “HCI studies are concerned with understanding how people use computer systems so that better systems can be designed which more closely meet users’ needs” [ 40 ] . This defines HCI as a design science , not as a human science . The human side of HCI is a means to an end , the end being better design . Disciplines such as psychology , sociology , cultural and media studies , art , politics and economics can and do study interactions between humans and computers without doing HCI research . They often come up with radical positions ( e . g . , [ 24 ] ) . However , what distinguishes HCI is the intention to improve design . The belief that an understanding of computer usage was enough to improve design came from the sponsors of research programmes ( psychologists readily agreed , but perversely sociologists were not included in early HCI programmes ) . Knowledge of computer usage is essential to successful design , but I will argue that it is not enough . Even so , design guidance is best based on evidence rather than feature magic . Usability resides in interaction . To see it ( or its absence ) , we must watch people interact . There are many ways to observe , with or without experimental control . Experimental studies began as a way to form or choose between guidelines . However , formal experimental settings were too expensive for routine use ( and generally restricted to low level feature comparisons , e . g . , [ 38 ] ) . So discount methods were born [ 33 ] and we just watched how test users got on . Observable usability problems must be defined in terms of user behaviour , but this may result in the overgeneralisation that psychology tries to avoid . Yet , psychological approaches to usability did propose generic criteria for usability problems [ 26 ] : 1 . the user articulates a goal and cannot succeed in attaining it within three minutes , 2 . the user explicitly gives up 3 . the user articulates a goal and has to try three or more actions to find a solution 4 . the user creates an item in his new document different from the corresponding item in the target document 5 . the user expresses surprise 6 . the user expresses some negative affect or says something is a problem 7 . the user makes a design suggestion 8 . the system crashes 9 . the evaluator generalizes a group of previously detected problems into a new problem . Such criteria have no more authority or generality than the guidelines that psychologists rubbished . Generic usability criteria replace a drought of evidence with a deluge . User difficulties are easy to expose . User testing runs the risk of drowning development teams in fat reports of irrelevant and / or trivial user difficulties . User testing has no noise filter . The more we test , the more we need one . Thus the SUPEX method [ 12 ] uses thresholds to remove irrelevant problems using criteria agreed with system sponsors . These criteria are specific to the intended value for a digital product or service . They are not generic properties of user behaviour . Instead , they should express the quality in use required to deliver intended value from specific system capabilities . Even with value - centred filtering of observed user difficulties , some evidence remains beyond user testing . Quality in use can only apply to the capabilities and content of a system . What is not there cannot be made usable . My local public transport web site fails to support its intended audience . It is completely in English , despite the presence of an international airport . It assumes large amounts of local knowledge on bus routes and metro station location . However , user testing can only pick this up if we know what counts as “good fit” and design tests to assess it . If a web site is intended for international travellers , then we should expect some multi - lingual support . If this exists , then testing must involve a range of users who can demonstrate that this support is effective . A focus on quality in use is restricted to user experience with a system’s implemented functionality . Testing may find evidence of an oversight , but not the oversight itself . Inspection methods perform better here , as an analyst may note problems for key tasks , but this is not a “prediction” that can be “validated” in user tests . Instead , we are thrown onto reasoning about what is and isn’t a key task ( ditto for typical users ) . Such analysis is not empirical . These things cannot be directly observed . The challenge of finding gaps in designs heralded the next shift in HCI . Leading HCI teams such as Digital’s found that systems that did well in laboratory testing often did less well in the real world [ 46 ] . For them , test design could not overcome the gap between laboratory scripts and the realities of the working world . Gilbert I moved in the opposite direction to HCI in the 1980s ! I completed my Education degree and then taught History and Social Studies in a secondary school . With free support from two housemates ( one a PC hardware designer ) , I wrote teaching programs and bought my first computer ( a Commodore VIC ) . In 1983 , I left teaching to enrol as a Computer Science PhD student , shifting focus from CAL authoring to user interface management systems . I published on formal methods [ 8 ] , formal models [ 7 ] and software architecture into the early 1990s [ 9 ] . I became motivated by the values of computer science and wanted to do HCI on computing’s terms . After my PhD studentship , I designed a new office application for timesharing systems and encountered a conflict between guidelines . I used this as an example on an Open University HCI course [ 37 ] . I resolved the conflict by favouring human - centred principles over system - centred guidelines , but only after using a prototype ! I wasted screen space rather than disorient users [ 37 ] . However , my focus in system design was on innovation rather than evaluation . I remained motivated by the value placed on innovation within engineering disciplines . I never signed up to the hegemony of psychology in 1980s HCI , especially as my experience from education was that social perspectives were far more effective than cognitive ones . I would happily wait until HCI caught up ! Luck and Magic Empirical psychology should have driven luck and magic out of HCI , but then we witnessed the miracle of the Five Test Users [ 27 ] ( who find all important usability problems ) . Once again , luck was dressed up as magic . Discount user testing remains popular as the preferred approach in ‘practical’ HCI settings . Guidelines remain even more popular , because zero test users are enough ! Only where budgets get large and the cost of poor usability exceeds 7 or 8 digits do we see large user studies [ 43 ] . User testing strikes lucky with poorly designed systems . Severe usability problems pop up with great frequency when a bad system is tested . Usability problems are harder to find with ( not in ) well - designed systems , where obvious problems get removed long before testing . Dennis Wixon argues that the goal of user testing is not to find usability problems , but to understand and fix them [ 1 ] . Discount user testing has little to offer on either front . Establishing causation ( understanding ) requires some experimental control . Generating solutions requires an understanding of interaction design that relies on analytical rather than empirical methods . Usability laboratories are not the place to collect the wide range of data required to assess the fit between an interactive system and its intended context of use . In this sense , psychology was more blind than computing had been . A mathematical science ( which is what computer science has largely been until recently ) cannot be expected to have a broad grasp on the collection and analysis of evidence . A human science has no excuses , and yet the psychological HCI of the 1980s had not even caught up with Maguire’s understanding of guidelines . As a result , just as psychology had pushed computer science aside , so sociology trumped psychology to become HCI’s King of the Hill . The Context - Centred Nineties Technology Computers became ubiquitous , arriving on almost every work surface in the workplace , in every appliance , in mobile devices , in intelligent buildings , in transport and increasingly on or in our bodies . This required HCI to move from office productivity applications to embrace a wide range of issues that had to be studied in the field . As computers moved off the desktop , HCI had to follow . Sponsors System sponsors remained naïve . Politicians declared that e - government would be usable and accessible , and commissioned guidelines to underpin this . However , HCI expertise has influenced some guidelines , which emphasises the design process over design features . In business , new product management has developed a good understanding of HCI . HCI input became more proactive , with expertise applied to much of the design of mobile devices and a wide range of interactive appliances . Investment in contextual field studies and evaluation was justified for new products , but existing products and bespoke systems still suffered from limited HCI inputs . As a result , much HCI work remained reactive . We were asked to work miracles on poorly designed technology . When we could not ( or added unacceptable costs ) , we were seen as being unable to deliver . Not only were we still recruited on terms that we should not have accepted , we were also sacked for reasons beyond our control . Despite increased willingness to embrace HCI , there have been mixed expectations on what contextual approaches can deliver . The most naïve saw context as a mould that could be mechanically applied to designs to make them fit their expected usage patterns . The most confident regarded field studies as a floodlight that would bring all hidden facts on users , activities and environments into clear view . HCI Quality in use lies in interaction , and not in the system . Achieving quality in use for the system as designed is not enough . User testing can only test what’s there . Ease of use and learning can be achieved in the lab , but in the real world , a system may still not deliver . 1980s user testing focused on generic psychological measures such as time on task , error rate and task completion rates . However , these can only predict real world effectiveness if the right tasks are tested in the right way . This is highly context specific . Hansen implored us to Know the User . A decade later , Maguire contextualised guidelines for specific users , tasks and application domains [ 30 ] . HCI took another decade to make serious attempts at researching and describing contexts of use . Ethnographic methods were applied [ 42 ] . Scenarios [ 4 ] and later personas [ 15 ] were developed as contextual ‘discount’ representations for field study data . Eventually , even a mainstream software standard such as ISO / IEC 9126 was changed to endorse the contextual basis for quality in use [ 2 ] . Context - centred HCI benefits both design and evaluation . Scenarios can be used to generate design models [ 4 ] . Personas and scenarios can be used to assess fit between a design and its intended usage context . Personas can provide a framework for test user recruitment . Scenarios can form the basis for scripted tasks in user testing . As a result , we increasingly see interaction designs that delight rather than just deliver . Understanding actual users , their goals and activities clear underpins the best transactional web sites . However , context - centred HCI , like user testing , has no noise filter , and suffers diminishing returns in the face of improving designs . Finding misfits between usage contexts and systems is rarely challenging . There can be no closure to lists of such mismatches [ 32 ] . However , as with usability problems , focusing on relevant non - trivial misfits between designs and usage contexts is a major challenge [ 10 ] . It too cannot be resolved within the resources available to contextual design . It turned out that the Grounded Design method [ 10 ] needs a noise filter of relevance criteria , which has to be agreed with system sponsors , directly referring to the intended value for a digital product or service . Gilbert I got even further behind HCI in the early 1990s . I co - edited a computing working group’s monograph on interactions between design , software architecture and software tools [ 21 ] . Then my first two PhD students tempted me away from HCI as computer science . Darryn Lavery uncovered the damaged goods of discount methods [ 28 ] . Steven Clarke linked contextual information directly to design , with novel results [ 6 , 11 ] . Steven and Darryn helped me to jump two decades in five years ! By 1996 my research has re - focused on improving the assessment of usability methods [ 14 ] and on visualising the fit between a system and its context of use [ 11 ] . I later also provided HCI input to accessibility research [ 18 ] . I’d put computing’s thirst for innovation behind me and was again motivated by the values of the human sciences . I wanted to improve the assessment of evaluation methods and to understand the precise relationship between contextual information and design . I eventually realised that solving both problems would not be enough to support effective design . Both finding significant usability problems in inspection and testing , and also discovering highly relevant aspects of usage contexts , owe too much to luck . Steven’s first case study provides a good example . He designed a new admissions system for a Computing MSc course . Student applications followed a pre - defined flow through assessment , referee reports , offer letters , acceptance letters and confirmations . However , several weeks before enrolment closed , the course admissions tutor had to ensure that all places were filled by suitable students who had confirmed their attendance . At this point , the proper procedure was too slow , and was replaced by a box by the tutor’s desk . The most promising unaccepted students were at the top of the box . When the course was full , new applications were inserted at an appropriate level . If there were still places , or an accepted student withdrew , someone at the top would be made an offer . The admissions tutor worked through the top using phone and email to make offers , chase referees and collect acceptances . The box was discovered by chance . An MSc student who was implementing the system for her project raised many detailed questions about requirements . She did so as the admissions tutor had switched over to his box . Steven visited him to resolve some issues , saw the box in action , and had it explained to him . Despite careful interviews over a period of several weeks a few months earlier , no box was ever mentioned . If we had implemented a system on the basis of ‘official’ slow track requirements , it could have been impossible to reliably fill up the MSc course . Luck or Magic ? There is no magic in ethnographic sociology as practised in HCI . This mature empirical discipline has difficulties with prescriptive design recommendations [ 42 ] . It delegates magic to developers , who can be very creative with links between context and design . However , as elements of context only become relevant in the face of specific design proposals , knowing contextual information relevant to grounding design decisions is largely a matter of luck , unless one has the luxury of carrying out more field research as oversights become apparent . System sponsors look to field studies as a mould or floodlight , when they are often no more than a candle , which , if held in the right place at the right time , will expose some critical fact about usage . Luck remains a key determinant of success for context - centred HCI . You must see the right bit of context at the right time and associate this with the right aspect of design . Context will never function as a mould , any more than there will be ‘rules’ of usability . However , we want contextual research to be a searchlight , and not a floodlight or candle . Candles unreliably reveal too little . Floodlights overwhelmingly reveal too much . Searchlights fully illuminate broad areas . Experimental psychology by contrast offers good spotlights , which are ideal for resolving detailed design questions that cannot be addressed through contextual research [ 18 ] , but are too focused to shed light on a wide sweep of relevant contextual factors . Sociological approaches to HCI are difficult to aim . Indeed , the methods and values of ethnographically inspired sociology are highly resistant to the idea of aim and focus . Research methodologies are carefully designed to minimise the impact of bias during observation and analysis . However , this wide ranging view fails to align its focus with the goal of gifted design , which is changing the world rather than merely describing it [ 42 ] . VALUE MUST BECOME HCI’S DOMINANT CONCERN There is currently a power vacuum in HCI . Computing , psychology and sociology have staked and lost their claim to hegemony . All are essential , but none can dominate given their clear shortcomings . HCI must look elsewhere for intellectual focus . In the last few years my research on usability and contextual design hit the same brick wall . There is no objective way to apply a noise filter to the flood of user difficulties from user testing and the avalanche of potential contextual misfit from field studies . However , my work with Eamon Doherty and Chris Bloor on brain - body interfaces [ 18 , 19 ] revealed a possible way forward . We have published guidelines [ 19 ] , which appears hypocritical given my above critique . My apparent hypocrisy continued with experimental studies to decide on key design parameters for a simple communication system . I also supported Eamon on field work that now occupies over 30cm of shelf space in my office . A truce between guidelines and psychology is possible . Our guidelines for brain - body interfaces for communication [ 19 ] are based on evidence . They thus have more authority than the opinions of 1970s computing experts . They do not fully generalise however , since they are based on the design options that we explored during Eamon’s PhD . Another PhD student , Paul Gnanayutham , has evaluated alternatives to Eamon’s tunnels interfaces [ 20 ] . On the basis of this work , we may revise our guidelines . However , for mainstream software design , there is little if any time to experiment . To support informed choice , properly presented guidelines should focus on description , i . e . , on presenting design options . Evidence for the effectiveness of a feature should be presented , especially where comparisons to alternative design options exist . However , no evidence will ever establish the absolute superiority of a feature beyond all reasonable doubt . It is the responsibility of software designers to understand the evidence , if any , for choosing an option and to make their own decisions , double checking if necessary via user testing . Sociologists expected to replace psychology as the basis for HCI design decisions . This appeared to be possible for innovative application areas , but not for new technology , where experiments are required to refine design details [ 18 ] . Quality in use is impacted by low level design variables such as layout , labelling , messages , images , size , distance , and input device settings . While fit to context does occur in the world , quality in use is a property of interaction . Changes to user interface designs can and do improve quality in use . We thus used a long series of experiments to arrive at the tunnel interface developed in Eamon’s research [ 18 ] . Contextual research was vital in our work . Initial designs were driven by the needs of clinicians who sought evidence for a change of diagnosis ( i . e . , from comatose to persistent vegetative state ) . Brain - body interfaces generate noise which causes erratic cursor behaviour . Simple maze and button interfaces can be activated when a head set is not on anyone’s head , so interfaces must require explicit control to achieve results . However , complex obstacles were unacceptable to parents and carers who did not require a clinician’s level of certainty . Contextual research brought these conflicting values into the open [ 18 ] . It also decimated the population of people who could benefit from a brain - body interface , since it turned out that most participants who could not officially use any existing assistive technology were doing so on home visits ! Official assessments of capability did not match the reality of what could be achieved with the support of relatives . Value and Design Our work with severely impaired individuals was sufficiently charged to bring values to the centre of our design process . Carers and parents simply would not accept designs based on the values of medical diagnosis . We had to steer a course that met the needs of carers and clinicians . The final adjudicator between guidelines , experiments and contextual factors was not objective and descriptive , but subjective and value laden . I regard my work with Eamon Doherty and Chris Bloor as my most complete HCI contribution to date . It combines all four intellectual ingredients that I now see as necessary and sufficient for successful design : innovation , psychological experiment , contextual understanding and intended product value . The last is HCI’s keystone . Nothing will stay in place without it . The others are sides of a design arch . On one side is innovation . On the other is fitness for purpose and appropriate quality in use , demonstrated through evaluation based on a deep understanding of expected usage contexts . One of the reviewers of our CUU paper [ 18 ] objected to its emotional content and tone . We ignored this reviewer . Values are emotive . We must get used to expressing them with all due force in HCI . PREPARING FOR VALUE - CENTRED HCI HCI in the twenty first century must place value at the heart of its endeavours . To do this , the existing HCI components of design guidance , quality in use and fit to context need to be reshaped to subordinate them to the delivery of intended product value . Value can take many forms . It is not solely a question of capitalist profits and sales . It can be political , personal , organisational , cultural , experiential or spiritual [ 10 ] . Our role should be to understand what is valued by a system’s stakeholders and support them in delivering this value . To deliver value through HCI , we need to put computing , psychology and sociology in their proper places . We need to accept computing research ( and new media creatives ) as sources of innovation . Sociology provides the understandings required to shape innovations to usage contexts . Psychology supports design refinement and evaluation of interaction . We should not expect computing to shape , refine or evaluate its innovations for valuable usage . We should value it for its innovation and not berate it for its lack of empirical sophistication . Rather than force computing approaches into looking like empirical HCI , we should accept their exasperating mix of unmotivated description and wild unsupported claims . Rather than attack computing for its oafishness , we should work with its contributions as it currently delivers them . The role of HCI is to take novel proposals from computing and creative media and to systematically ground and evaluate them to separate the valuable from the worthless . We should accept computing and creative design as sources of innovation and expect no more of them . Neanderthal HCI and Innovation The computer science approach to HCI has remained unchanged since its hegemony in HCI’s pre - history . In HCI , the Neanderthals have not become extinct . Some still carry on research in 2004 that is barely distinguishable from Hansen’s well intentioned ( and smart with it ) amateurism in 1971 [ 23 ] . Computing’s claims for its innovations ( such as 1970s guidelines ) are based on the belief that objects can have fixed properties with fixed consequences for quality in use . This is utter nonsense , but computing’s main contributions are not claims , but descriptions . Computing publications are largely descriptive , outlining algorithms , architectures , or design and analysis methods . Evaluation rarely goes beyond the simple “buildability” of engineering . No more evidence is required beyond the existence of an innovative artefact . Once completed , computing experts celebrate with a chorus of rash claims . Thus : “We have argued that functional languages are powerful primarily because they provide two new kinds of glue : higher - order functions and lazy evaluation . ” [ 25 , p . 15 ] and “Using a model , those responsible for a software development project ' s success can assure themselves that business functionality is complete and correct , end - user needs are met , and program design supports requirements for scalability , robustness , security , extendibility , and other characteristics” [ 36 ] This is acceptable within a mindset heavily influenced by mathematics , a platonic world of ideal forms with invariant attributes . Thus , the properties of the natural numbers hold regardless of who is counting and what is being counted . Computer science approaches in HCI remain platonic and idealist : e . g . , formal methods [ 17 ] or patterns [ 44 ] . Even usability inspection methods are mostly system - centred [ 13 ] . Thus the last version of Heuristic Evaluation [ 35 ] is one computer scientist’s synthesis of selected guidelines that overlap with Wasserman’s . Problems arise when computers reify mathematics and bring it into contact with the real world . The innocent idealism of mathematics ( restrained by logic and proof ) is suddenly confronted by a world of complex relations . Thus almost all programming remains imperative , despite the power of “higher - order functions and lazy evaluation” [ 25 ] . In the mathematical world of symbols on paper , such power is unobstructed . In the real world , the determinants of all computer usage , including programming languages , are overwhelming human . In reifying logical reasoning , computers have brought the platonic idealism of mathematics into contact with the materialist ontology of Marx [ 31 ] . Computing’s objects become commodity fetishes with totemic power as a result of their alienation from the world of social relations . The fundamental unit of reality is the relation , and not the object . Thus , water has no invariant boiling point , but boils at 100ºC when the atmospheric pressure is 760 mmHg . All so - called physical “properties” are relative to some reference context . Thus the colour , weight and physical dimensions of an object vary according to ambient light , gravity , temperature and pressure . Empirical scientists instinctively challenge platonic nonsense . Computing approaches to HCI have been suppressed for two decades , but their roots in an idealist mindset are too deep to allow their easy removal as weeds from HCI’s garden . I do not reject computing as irrational and undisciplined . The first part of my HCI career was in computer science . I thus sympathise with Henry Lieberman’s impassioned attack on the tyranny of evaluation [ 29 ] , but not for the reasons that he gives . Shuman Zhai rightly points out that flaws in evaluation methods do not remove the need for them [ 47 ] . However , there is a time and a place for everything . The time to evaluate creative contributions is in the context of an integrated prototype , supported as needed by fine tuning experiments , but in the overall context of knowing what needs to be delivered and then assessing whether it is . HCI should not kill geeks who hack out golden eggs . Public Policy is Different Allowances made for the naïve optimism of computing do not transfer to public policy . The gap between real HCI and public policy has grown wider . Public policy remains infatuated with the transformative power of technology . Thus providing teachers and students with laptops will have a profound impact on education . On - line discussion groups and voting will reinvigorate democracy . Electronic patient records will transform healthcare systems . Biometrics will protect us all from terrorism . Technological utopianism is the order of the day , still firmly rooted in HCI’s Neanderthal pre - history of luck masquerading as magic . The HCI community must educate policy makers to take a more balanced view . There is evidence that this is working . In the UK , HCI experts have advised on security biometrics and on web site usability for e - government . Their input is clear in the relevant public documents . Similar balance is seen in some accessibility standards . For example , Arizona’s policy states its limitations [ 41 ] : Individuals with ( or without ) disabilities access the Web with widely varying sets of capabilities , software , and hardware . … this policy does not include requirements for … every known accessibility need , due to known limitations … as follows : Braille – this policy does not address Braille production . Synthesized Speech production – not covered . . . Input Modalities – no voice input , only keyboard and pointing devices . It is refreshing to see a policy that understands that absolute accessibility cannot be achieved by simple adherence to any body of guidelines , since this belief dominates too many current stances on accessibility [ 5 ] . A truce with the irrationality of computing and creatives should not extend to public policy . HCI must ensure that public policy on information and communication technologies is wholly focused on value , and that it fully understands the role of quality in use and fit to context in ensuring that at least full value is delivered . Putting Design at the Centre of HCI HCI needs to focus on design . We must protect sources of innovation from premature and heavy handed evaluation and contextual analysis . We must respect the intellectual space where computing experts and design creatives generate new ideas . However , they in turn must recognise that they are not equipped to develop systems that deliver maximum value to a wide range of stakeholders . HCI needs to adopt a facilitating role in design , taking inputs from all stakeholders in a manner that retains a constant focus on the starting point of all gifted designs : an intent to deliver specific value . VALUE - CENTRED HCI HCI must cut loose from externally imposed definitions and agendas . Existing definitions of HCI start in the wrong place [ 40 ] . We cannot get reliably and systematically from HCI studies in psychology or sociology to better systems which more closely meet users’ needs . What currently gets us there is luck masquerading as magic . Supposedly objective HCI cannot distinguish between what does and does not matter . This is because importance is neither universal nor objective . Something is important because it matters to someone , because it either does or does not deliver things of value . I have been asked to define ‘value’ — how platonic ! Armed with such a definition , I could presumably tell system sponsors that “that’s not what I call value ! ” If stakeholders tell me something is valuable , I may probe and challenge , but if they hold their ground they will allay my doubts . The issue then becomes whether any software design can deliver the desired value . If none can , that has no bearing at all on the integrity and validity of someone’s values . It just adds another section to the perimeter of what is currently possible in software design . In summary , you don’t define value . You talk to people about it . HCI needs noise filters for user testing and a search light for contextual research . It needs to be systematic , reliable and credible , and cannot rely on luck or magic . A focus on value can provide what we currently lack in HCI . The intended value for a product or service is a highly effective noise filter that can readily separate critical usability problems from irrelevant ones ( however objectively ‘severe’ they are ) . Intended value is an effective searchlight , helping us to focus on aspects of context that are critical to delivering value . It guides us towards a systematic approach to HCI . A Research Agenda for Value - Centred HCI For intended value to become the focus for HCI , we must elicit and express value and derive targets from it . A framework for value - centred HCI thus requires : • means to elicit and express intended value … • … that support derivation of targets for quality in use and fit to context … • … against which design achievements can be measured Value - centred HCI is thus a process that begins with value representations and ends by measuring achievement . This sets three clear research agendas : ( i ) representing value ; ( ii ) deriving targets and ( iii ) measuring achievement . Some of the latter is in place , but the first has yet to be addressed in research publications . Nor has the second , since it is wholly dependent on the first . Success overall will be measured by increased consistency in the effectiveness of HCI and less need for good luck . Elements of value - centred design can be found in best industrial practice at IBM , UIE and In Context Enterprises . We need to move all HCI to focus on the delivery of intended value . It cannot be an add - on to existing approaches . Instead we have to modify existing methods and techniques to accept and maintain a focus on value throughout their application . Quality in use and fit to context matter because they can both degrade , or even destroy , intended value . This is largely the focus of HCI techniques , that is , damage limitation . Occasionally , timely HCI input can put an end to expensive mistakes and deny the possibility of delivering intended value , as in Project Ernestine [ 22 ] . Less negatively , HCI approaches succeed when intended value can be delivered by appropriate quality in use and fit to context . At their best , designs delight users with their capabilities and user experience . Here , gifted design donates unexpected value . The relationship between intended value and the HCI concerns of quality in use and fit to context can be summarised via the Five Ds : Deny , Destroy , Degrade , Deliver , Donate Denial of achievable value should occur as early as possible in a system development life cycle . Destruction of intended value must be avoided at all costs ( and HCI has saved many products here ) , but some degradation may ( regrettably ) be acceptable . In some circumstances , competitive advantage may only be possible through products that give ( donate ) more than users expect . Apple’s position owes much to this . Examples of Value - Centred HCI The first full example of value - centred HCI is my work with Eamon Doherty [ 18 , 19 ] . The synthesis of experimentally derived guidelines and contextually grounded design goals was only made possible by a central focus on delivering value for both clinicians and carers . However , we reached this position because of the clarity with which stakeholders expressed the values behind positions on system capability . Like most HCI people , we were lucky ! What is much more challenging is the deliberate pursuit of value - centred HCI from the outset of system development . A framework for value - centred HCI has been outlined above , but little of it is in place . Until it is , I cannot fully illustrate deliberate value - centred HCI . All I can do is sketch how a focus on value could operate , using a van hire web site as an example . A van hire web site has to deliver value for : • Site / company managers and investors • Customers • Operational staff , especially at depots The main source of value for management may be return on investment , brand image and market share . For customers , value comes from the ability to hire an appropriate van for a suitable period for an acceptable cost ( money , time , convenience ) . For operational staff , collection and return of vans needs to proceed smoothly . The web site alone cannot fully deliver all this value . Pricing policy , pick up and return policies , depot location and opening hours , van range and availability , and insurance and personal document requirements are factors beyond the web site . They all have a critical impact on achieved value . Targets thus need to be set that let the web site protect existing value in a van - hire product , and where possible , add value through site features . Value can be delivered ( even added ) for customers by addressing obstacles to purchase . Can an appropriate van be easily found ( e . g . , van volume is less helpful than photos of what a van can carry and dimensions of usable load space ) ? How do I get to the depot , when is it open and what must I take with me ? How long can I hire the van for , and how does this relate to price ? What is the full price for a hire ? For operational staff , the web site needs to ensure that customers ( or valid representatives ) turn up at the right place at the right time with the right documents . For management , the site must deliver enough sales to meet its profit targets . If the web site does even more , then all stakeholders would be delighted . Management would exceed targets and build brand loyalty , customers would feel they had a gift rather than a purchase , and depot staff would have stress free working days . Only some of the above can be measured during site usage . Value - centred HCI requires a broad view of system evaluation . Precise statements of value and systematic derivation of targets also present major challenges for research and practice . CONCLUSIONS I have argued that argued that the attempts of computing , psychology and sociology to dominate HCI have all failed . Collectively , they have much to offer , but this is still not enough . There is a gap . The gap cannot be filled by any existing discipline , other than a specific form of design that focuses on value above all else . I call this gifted design due to its potential to donate unexpected value . We are at the start of an exciting intellectual journey that must interweave the objective and the subjective . Its focus on intended value will let us banish the infuriating “it depends” from the HCI phrase book . It won’t depend because we will know what we are trying to achieve . We have to accept the challenge of re - focusing existing HCI approaches on subjective value . We need to embrace the paradox that we can only become effective , systematic and consistent by applying objectivity in the service of subjectivity . I see no other ways over HCI’s current brick walls . If the above arguments are sound , then we need to embrace a new research agenda . If not , we must find another one , before HCI’s luck finally runs out . REFERENCES 1 . Barnum , C . , Bevan , N . , Cockton , G . , Nielsen , J . , Spool , J . , and Wixon , D . , “The " Magic Number 5 " : Is It Enough for Web Testing ? ” in CHI 2003 Extended Abstracts , ACM , 698 - 699 , 2003 . 2 . Bevan , N . , “Quality in use : Meeting user needs for quality , ” J . System and Softwar e , 49 ( 1 ) , 89 - 96 , 1999 . 3 . Card , S . K . , Moran , T . , and Newell , A . , The Psychology of Human - Computer Interaction , Lawrence Erlbaum Associates , 1983 . 4 . Carroll , J . M . ( ed . ) , Scenario Based Design : Envisioning Work and Technology in Systems Development , Wiley , 1995 . 5 . Cassidy , B . , Cockton , G . and Coventry , L . , “An Interaction Analysis Approach to Accessibility , ” to appear in Proc . HCI 2004 , Vol 2 , 2004 . 6 . Clarke , S , Encouraging the Effective Use of Contextual Information in Design , PhD Thesis , Department of Computing Science , University of Glasgow , 1997 . 7 . Cockton , G . , “A New Model for Separable Interactive Systems , ” in Proc . INTERACT ' 87 , eds . H . - J . Bullinger and B . Shackel , North - Holland , 1033 - 1038 , 1987 . 8 . Cockton , G . , “Designing abstractions for communication control , ” in Formal Methods in Human Computer Interaction , eds . M . D . Harrison and H . W . Thimbleby , Cambridge University Press , 233 - 271 , 1990 . 9 . Cockton G . , “The Architectural Bases of Design Re - use” in User Interface Management and Design , eds . D . A . Duce , M . R . Gomes , F . R . A . Hopgood and J . R . Lee , Springer - Verlag , 15 34 , 1991 . 10 . Cockton , G . , “From Quality in Use to Value in the World” , in CHI 2004 Extended Abstracts , ACM , ISBN 1 - 5811 3 - 703 - 6 , 1287 - 1290 , 2004 . 11 . Cockton , G . and Clarke , S . , “Using Contextual Information Effectively in Design” , in Proc . INTERACT 99 , eds . A . Sasse and C . Johnson , 578 - 585 , 1999 . 12 . Cockton , G . and Lavery , D . " A Framework for Usability Problem Extraction” , in Proc . INTERACT 99 , eds . A . Sasse and C . Johnson , 347 - 355 , 1999 . 13 . Cockton , G . , Lavery , D . , and Woolrych , A . , “Inspection - based methods” , in The Human - Computer Interaction Handbook , eds . J . Jacko and A . Sears , 1118 – 38 , Lawrence Erlbaum Associates , 2003 . 14 . Cockton , G . & Woolrych , A . , “Understanding Inspection Methods : Lessons from an Assessment of Heuristic Evaluation , ” in People & Computers XV , eds . A . Blandford , J . Vanderdonckt and P . D . Gray , Springer - Verlag , 171 - 92 , 2001 15 . Cooper , A . and Reimann , R . M , About Face 2 . 0 : The Essentials of Interaction Design , Wiley 2003 . 16 . Curtis , B . , “The crucible of a new discipline , ” in Proc . First U . S . A - Japan Conference on Human - Computer Interaction , G . Salvendy ( ed . ) , Elsevier , 67 - 72 , 1984 17 . Dix , A . J . , Formal Methods for Interactive Systems , Academic Press , 1991 . 18 . Doherty E . P , Cockton G . , Bloor C . & Benigno , D . , “Mixing Oil and Water : Transcending Method Boundaries in Assistive Technology for Traumatic Brain Injury , ” in Proc . First Conference on Universal Usability , eds . J . Sholtz and J . Thomas , ACM , 110 - 117 , 2000 . 19 . Doherty E . P , Cockton G . , Bloor C . & Benigno , D . , “Improving the Performance of the Cyberlink Mental Interface with the Yes / No Program , ” in Proc . CHI 2001 , eds . Eds . J . A . Jacko , A . Sears , M . Beaudouin - Lafon & R . J . K Jacob , ACM , 69 - 76 , 2001 . 20 . Gnanayutham , P . , Bloor C . , and Cockton G . “Artificial Intelligence to Enhance a Brain Computer Interface , ” in Proceedings of HCI International 2003 , ed . C . Stephanidis 1397 - 1401 , LEA 2003 . 21 . Gram , C . and Cockton , G . ( eds . ) , Design Principles for Interactive Systems , Chapman and Hall , 1996 22 . Gray , W . D . , John , B . E . , & Atwood , M . E . , “Project Ernestine : Validating GOMS for predicting and explaining real - world task performance , ” Human Computer Interaction . , 8 ( 3 ) , 237 - 309 , 1993 . 23 . Hansen , W . J . , “User Engineering Principles for Interactive Systems” in Fall Joint Computer Conference , 523 - 532 , AFIPS , 1971 . 24 . Haraway , D . , Simians , Cyborgs , and Women : The Reinvention of Nature . Routledge , 1991 25 . Hughes , J . , Why Functional Programming Matters , http : / / www . md . chalmers . se / ~ rjmh / Papers / whyfp . pdf , last accessed 28 / 7 / 04 . 26 . John , B . E . , & Mashyna , M . M , “Evaluating a multimedia authoring tool , ” J . American Society for Information Science , 48 ( 11 ) , 1004 - 1022 , 1997 . 27 . Landauer , T . K . and Nielsen , J . “A Mathematical Model of the Finding of Usability Problems , ” in Proc . INTERCHI ’93 , 206 - 213 , 1993 . 28 . Lavery , D . Cockton , G . and Atkinson , M . P . , " Comparison of Evaluation Methods Using Structured Usability Problem Reports , " in Behaviour and Information Technology , 16 ( 4 ) , 246 - 266 . 1997 29 . Lieberman , H . The Tyranny of Evaluation , http : / / web . media . mit . edu / ~ lieber / Misc / Tyranny - Evaluation . html , last accessed 28 / 7 / 04 . 30 . Maguire , M . , “An Evaluation of Published Recommendations on the Design of Man - Computer Dialogues , ” Int . J . Man - Machine Studies , 16 ( 3 ) , 237 - 261 , 1982 . 31 . Marx , K . , Economic & Philosophical Manuscripts of 1844 , Progress Publishers , Moscow 1959 ; 32 . Martin , D . , Bowers , J . , Wastell , D . G . , “The interactional affordances of technology : an ethnography of human - computer interaction in an ambulance control centre” , in People and Computers XII , eds . H . Thimbleby , B . O ' Conaill and P . Thomas , Springer , 263 - 281 , 1997 . 33 . Monk , A . F . , Wright , P . C . , Davenport , L . & Haber , J . Improving your human - computer interface : a practical technique , Prentice - Hall , 1993 . 34 . Moore , G . E . , “Cramming more components onto integrated circuits , ” in Electronics , 38 ( 8 ) , 1965 . 35 . Nielsen , J . “Enhancing the Explanatory Power of Usability Heuristics” , in Proc . CHI ' 94 , eds . B . Adelson , S . Dumais , S . , and J . Olson , ACM , 152 - 158 , 1994 . 36 . Object Management Group , Introduction to OMG ' s Unified Modeling Language™ ( UML® ) , http : / / www . omg . org / gettingstarted / what _ is _ uml . htm , last accessed 28 / 7 / 04 . 37 . Open University PMT607 course team with G . Cockton , Design Tools , PMT607 ( HCI ) Unit 8 , Open University : Milton Keynes , 1990 . 38 . Perlman , G . , “Making the right choices with menus , ” in Proc . INTERACT’84 , 291 - 7 , 1984 . 39 . Pew , R . W . , “Evolution of human - computer interaction : from Memex to Bluetooth and beyond” , in The Human - Computer Interaction Handbook , eds . J . Jacko and A . Sears , 1 – 17 , LEA , 2003 40 . Preece . J . A Guide to Usability : Human Factors in Computing , Addison Wesley , 1992 41 . State of Arizona , POLICY P130 Web Site Accessibility , http : / / gita . state . az . us / policies _ standards / html / p130 _ web _ site _ accessibility _ policy . htm , last accessed 28 / 7 / 04 42 . Sommerville , I . , Rodden , T . , Bentley , R . , and Sawyer , P . “Sociologists can be surprisingly useful in interactive systems design , ” in People and Computers VII , eds . A . Monk , D . Diaper and M . Harrison , 341 - 353 , 1992 . 43 . Spool , J . and Schroeder , W . “Testing Websites : Five Users is Nowhere Near Enough , ” in CHI 2001 Extended Abstracts , ACM , 285 - 286 , 2001 . 44 . van Welie , M . , and van der Veer , G . C . , “Pattern Languages in Interaction Design : Structure and Organization” , in Proc INTERACT 2003 , 2003 . 45 . Wasserman , A . I . , “The design of idiot - proof interactive systems , ” in Proc . National Computer Conference , AFIPS , M34 - M38 , 1973 . 46 . Whiteside , J . , Bennett , J . , & Holtzblatt , K . , “Usability engineering : Our experience and evolution , ” in Handbook of HCI , 1st Edition , ed . M . Helander . , North - Holland , 791 - 817 , 1988 . 47 . Zhai , S . , Evaluation is the worst form of HCI research except all those other forms that have been tried , http : / / www . almaden . ibm . com / u / zhai / papers / Evaluation Democracy . htm , last accessed 28 / 7 / 04 .