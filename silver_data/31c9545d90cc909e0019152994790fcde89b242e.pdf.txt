Mobile Collaboration for Human and Canine Police Explosive Detection Teams Joelle Alcaidinho , Larry Freil , Taylor Kelly , Kayla Marland , Chunhui Wu , Bradley Wittenbrook , Giancarlo Valentin , Melody Jackson joelle , larry . freil , kmarland3 , tkelly , cwu310 , bradley . wittenbrook , giancarlo , melodymoorejackson @ gatech . edu Georgia Tech ABSTRACT We designed a communication system for law enforcement ofﬁcers to use when conducting explosive detection searches with multiple agencies . Dogs trained in explosive detection work alongside human handlers to form a K9 team , which are an integral part of these searches . Ofﬁcers in K9 teams have a strong bond and communication with these dogs , but noisy locations , long distances , and crowded spaces present challenges . In addition , other ofﬁcers assigned as backup often lack the experience to read the cues from the canine , which hinders the speed and effectiveness of the team . Coordinat - ing a search with teams from different municipalities presents challenges due to a lack of standard collaboration tools . Get - ting the right information as quickly as possible saves lives , whether this information is about the areas that have been searched or the location of an explosive device . We hope that in addition to increasing public safety , our system will make working conditions safer for law enforcement ofﬁcers and their canines . Author Keywords Explosive detection ; K9 ; Police ; Animal Computer – Interaction ; collaborative maps ; law enforcement ; ACM Classiﬁcation Keywords H . 5 . 3 Information Interfaces and Presentation ( e . g . , HCI ) : Group and Organization Interfaces INTRODUCTION Law enforcement is an integral part of our society , yet HCI re - search that supports law enforcement is under - explored . There is even less research involving police working dog teams . The majority of working dogs in police and military K9 occupa - tions are trained to detect explosive devices [ 5 ] . Although instruments designed to detect explosive devices are available , the detector dog is still the “fastest , most versatile , reliable Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . Request permissions from Permissions @ acm . org . CSCW ’17 , February 25 – March 01 , 2017 , Portland , OR , USA ©2017 ACM 978 - 1 - 4503 - 4335 - 0 / 17 / 03 . . . $ 15 . 00 DOI : http : / / dx . doi . org / 10 . 1145 / 2998181 . 2998271 real - time explosive detection device available” [ 12 ] . One hu - man handler and one dog trained to detect explosives form a K9 team . In scenarios that involve special events ( e . g . , a road race ) , are time - sensitive ( e . g . , an emergency ) , or cover a large area , multiple K9 teams , often from different municipalities , are commonly deployed . These municipalities are often dif - ferent from those of other K9 units , other ofﬁcers securing the perimeter , or ofﬁcers in the Explosive Ordnance Disposal ( EOD ) unit . Issues with cross - municipality communication are exacerbated by a lack of both a shared secure radio channel and access to a common mapping software . Our goal is to cre - ate a system that improves communication between agencies , K9 teams , ofﬁcers securing the perimeter , ofﬁcers providing cover , and EOD units . The impetus for this research , which began in early 2014 , came from the social climate around law enforcement challenges and the technical solutions proposed by both policy makers and the community at large [ 15 ] . As HCI researchers we were compelled to better understand these challenges . While we have not addressed all of them , we believe that what we learned and subsequently developed , is a good initial step in incorporating tools from HCI research to the design of law enforcement systems . RELATED WORK We begin by discussing related literature from three research areas and describe how each one inﬂuenced our work . Designing for Groups As the name suggests , the ﬁeld of Computer Supported Coop - erative Work ( CSCW ) has a rich history of research in support - ing cooperative work in groups [ 18 ] . Of particular relevance to our research is Goyal and Fussell’s work [ 17 ] looking at the role sensemaking translucence has for crime analysts with a goal of promoting “timely information sharing and reducing conﬁrmation bias” and the research by Mackenzie et . al on emergency decision - making and remote distributed team col - laboration [ 31 ] . This prior work , coupled with the research by Halverson , provided us with a lens with which to examine the collaboration inherent in an explosive detection search [ 19 ] and gave us valuable insights into the decision - making ramiﬁcations of our design choices . The work by Lundgren et . al [ 28 ] supplied a practical design framework for the de - signing of new mobile experiences for collocated interaction Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 925 as well as a framework for analysing existing ones . Johnson , Gibson , and Mutlu explore remote collaboration between par - ticipants using head - mounted displays and handheld devices [ 24 ] . Their results served to motivate the device selection in our system , as well as the design of the interaction with collocated participants . Mobile Collaboration Luyten et al . [ 29 ] discussed ad - hoc collaborations with an arbitrary number of users with small - sized displays early on . Since then , collaborative annotations , particularly those cre - ated on mobile devices , have become a thriving research area . Gauglitz et . al’s description of annotation - based collaboration served as a reference for ofﬁcer annotations on our maps [ 13 ] . Lucero et . al explored collaborative interactions with mobile phones , which inﬂuenced how we envisioned ofﬁcers creating their search plans [ 27 ] . Ashikaga et . al examined how to make single - user map interactions suitable for collaborative work by multiple mobile users [ 2 ] . Schweitzer et . al described a system focused on smartphone annotations to document con - struction work [ 42 ] . We have been particularly inspired by the work of Cheng et . al [ 6 ] as we develop the prototype of our system , speciﬁcally with the user experience of collaborative annotation and documentation tools . Animal – Computer Interaction Although the ﬁeld of Animal – Computer Interaction ( ACI ) is relatively new , there is a body of previous work documenting interactions between animals and computing devices . Early examples include remote entertainment and training by Hu et al . [ 21 ] and Resner [ 38 ] . ACI research that involves wearable technology in particular includes the harness - based FIDO sys - tem , as well as work by Savage and Wingrave [ 23 , 41 , 45 ] . The muzzle [ 14 ] and collar [ 36 , 1 ] are also areas in which wearable technology has been integrated . Although we reference the ﬁeld of ACI , our work does not as - sume all of the ontological commitments of some of the more popular work in this discipline [ 32 ] . This is due to canine - assisted law enforcement being an anthropocentric activity that pre - dates the ﬁeld of ACI . Our goal is to maximize the wellbeing of all participants , dogs included , within the con - straints of law enforcement . However , we do consider how our design affects dogs and how to better accommodate them within the system . While computing research with explosive detection teams is limited , early work by Ferworn [ 9 ] describes a Canine Aug - mentation Technology system that includes microphones , cam - eras , and GPS designed for police search and rescue dogs . Bozkurt [ 4 ] builds upon this idea of the cyber - enhanced work - ing dog , speciﬁcally search and rescue dogs , by adding multi - ple inertial sensors , Wi - Fi , ECG , PPG , and vibration motors to the dog’s harness . Our approach deviates from previous work by focusing on the communication between the handler , dog , and other explosive detection teams while striving to minimize the amount of equipment worn by the dog . Ofﬁcer Engagement Number Observed 25 Interviewed 4 Feedback 2 Table 1 . Composition of ofﬁcer participation in this research Participant Jurisdiction K9 Handler P1 Campus Yes P2 Campus Yes P3 County No P4 County Yes Table 2 . Interviewed participants by jurisdiction and occupation . METHOD AND SETTING We describe how we used Contextual Design to understand the current work process among law enforcement teams in explosive detection searches . Overview Our goal was to design a system that would address the unique challenges of cross - municipal explosive detection searches . To this end we largely followed the design process from Con - textual Design , as well leveraged insights from Distributed Cognition for Teamwork ( DiCoT ) [ 3 , 11 ] . To guide our under - standing of the current ofﬁcer work process during a search , and to help us discover breakdowns , we chose to use the lens of Distributed Cognition [ 20 ] . Distributed Cognition is par - ticularly helpful for exposing system - workings at a level that would have design implications [ 40 ] . Additionally , we used thick descriptions as described by Crabtree for understanding collaborative work in our analysis of our observations of the ofﬁcers [ 7 ] . Following the design process from Contextual Design , we began with Contextual Inquiry followed by Work Modeling . During the Work Modeling phase we used Distributed Cogni - tion to generate models representing the work of the ofﬁcers . During Consolidation , we created tabular representations of the system that were inspired by DiCoT , and used these to generate requirements for our system . We merged the Work Redesign and User Environment Design phases and moved to prototyping and testing with our participants as early as possible to accommodate for multiple iterations of our system based on their feedback . Participants For this study we observed 25 ofﬁcers , interviewed four and obtained system design feedback from two ( Table 1 ) . Participants were recruited based on geographic proximity starting from the local campus department and extending to the county - level . The four participants interviewed included both campus - level and county - level ofﬁcers ( Table 3 . 2 ) . Contextual Inquiry We began the Contextual Inquiry phase by speaking with ofﬁ - cers from multiple jurisdictions ; these included the Campus Police Department ( CPD ) , two municipal police departments , Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 926 Figure 1 . Graphical representation of representational states and processes during a cross - municipal explosive detection search event . Agents are circular . Triangles represent memory . Arrows represent processing and the ﬂow of information . and two county deputies . The conversations focused on un - derstanding their current work practices and challenges . In addition to the conversations , we also observed 25 K9 ex - plosive detection teams training from multiple counties and municipal police departments . Training sessions which simu - late various search scenarios were the closest environment we had to observe the ofﬁcers at work during a “real search . " The searches we observed were conducted both off and on - leash . We noticed communication breakdowns in both scenarios . These breakdowns have multiple causes , although they can largely be attributed to a misread or missed alert from the dog . While an experienced handler is typically very adept at recognizing these alerts , the same cannot be said of backup ofﬁcers with less experience . Even experienced handlers can have difﬁculty seeing and hearing alerts in dark and noisy environments . The ofﬁcers also expressed frustration at hav - ing access to new technologies , namely , Google Glass , but being unable to effectively integrate them into their practice [ 30 ] . The purchase of Google Glass by their department was intended to explore the usage of a head - mounted device that offered largely hands - free interaction . Google Glass seemed promising to their superiors , but was unused by the ofﬁcers reportedly due to a lack of suitable applications . Following the observations , we conducted a series of inter - views with four ofﬁcers . Three of the ofﬁcers are the human handler of a K9 team ( P1 , P2 , & P4 ) , one of the ofﬁcers serves in a leadership position ( P1 ) , and another ofﬁcer serves as backup for K9 teams ( P3 ) . Two of these ofﬁcers are from the Campus Police Department ( P1 and P2 ) and two are from a county in another state ( P3 and P4 ) . Two of these interviews occurred in person at the workplace of the ofﬁcers and were accompanied by additional observations of their practice ( P1 and P2 ) . All observations occurred in the United States and all ofﬁcers interviewed were also based in the United States . While we saw similar challenges across localities , we recog - nize that these might not be the case outside , or even in all jurisdictions within the United States . ANALYSIS & FINDINGS In this section we describe our Distributed Cognition analysis and ﬁndings that were a result of the ﬁrst three stages of Contextual Design . Distributed Cognition A key issue that the ofﬁcers mentioned , which we also ob - served , were the challenges around communication across agencies and municipalities . Because each team , as well as the ofﬁcers supporting the perimeter , can come from a differ - ent jurisdiction , there is no common tool that allows for live updating of search areas . Even within the same municipality , the map that displays positions of the teams can only be up - dated by the dispatcher and is displayed on a laptop computer . Because of this limitation , the mapping tool is underused and ofﬁcers have to rely on other tools and personnel to commu - nicate . The coordination process we observed and that was described by the ofﬁcers was complicated and , on occasion , involved “runners " . Runners are ofﬁcers tasked with running between K9 teams and backup ofﬁcers to update their infor - mation . Our Distributed Cognition diagram ( Figure 1 ) is a result of the analysis of a cross - municipal explosive detection search event involving two K9 teams ( each from different municipalities ) , one ofﬁcer acting as a runner , with four ofﬁ - cers setting the perimeter ( three from the same municipality ) . This diagram does not account for aviation support , which is commonly used in well - funded departments to check the position of the ofﬁcers setting the perimeter , the K9 teams , and update Dispatch , the central public safety communications coordination center . Dispatch provides information to the ofﬁcers setting the perimeter over the radio ( or through the mapping ) and call software that is on their department supplied laptops . These laptops remain in a mount inside their vehicles . Only Dis - patch can update the information displayed in this mapping and call software which is abbreviated on the diagram as Map ( D ) . Ofﬁcers can communicate with Dispatch , and with each other , through the radio if they share a channel in common or a preexisting mutual aid channel . Ofﬁcers without this access to Dispatch use their phones to call Dispatch . In the diagram , Ofﬁcers 1 - 3 have access to both Map ( D ) and radio commu - nication , Ofﬁcer ( 4 ) not being from the same municipality , has access to information through a Runner . The Runner has access to radio communication and Map ( D ) . Runners are re - sponsible for communicating with other personnel who do not have access to these tools . This communication is commonly done by running to each location and verbally relaying the Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 927 information or updating a paper map , depicted on the diagram as Map ( P ) . K9 Handler ( 2 ) has access to the radio and Map ( D ) but needs to communicate to the other K9 handler through the Runner . K9 Handler ( 1 ) must use the Runner to maintain communication with the other ofﬁcers . Both canine members of the K9 team can only communicate with their handlers . Communication with the Explosive Ordnance Disposal ( EOD ) team is done through Dispatch . The diagram was helpful in providing us a way to visualize the breakdowns , as well as the demands on working mem - ory ( WM ) . Distributed Cognition made the issues to be ﬁxed clearer , and served as framework that guided our design for a common tool . Without a common tool , particularly one that was mobile , there are delays in communication . To alleviate these issues , phone calls and communication apps like those for text messaging , annotated paper maps distributed by runners , and aviation support conﬁrming positioning through helicopter ﬂight have all been used . The primary concern of the K9 handlers is that these communication issues cause frequent stops that impact the dog’s ability to search and work . This concern is a particularly pressing issue in hot climates where the work time is already shorter due to the heat . Our focus was placed on reducing communication errors , improving the time to response of K9 signals , and addressing the need for a mobile map that every team member was able to access and update . System Design Requirements After the observations and interviews , we discovered key re - quirements for our system design . In particular , that the system must allow the ofﬁcers to perform these tasks : • Receive notiﬁcations of important events from scent detec - tion events • View details about those events • Annotate a map that all other ofﬁcers can also view and annotate • View an updated map without needing to refresh , and sup - port displaying photos from the scene • View the position of all users of the app , backup or K9 teams on a map In addition the system should : • Be accessible to a variety of municipalities and not require special hardware to deploy • Be low - cost , as cost was a frequently cited barrier to the deployment of municipality speciﬁc software • Provide mobile access • If possible , the system should explore the use of a head - mounted display ( i . e . Google Glass ) as a hands - free com - munication tool OUR SYSTEM We created a system that would address the key requirements . In this section , we describe each component of our system , beginning with the wearable for the dog . Dog Wearable We opted to instrument a Ray Allen K9 harness [ 37 ] ( Fig - ure 2 ) for the dog to notify ofﬁcers using the system about the following events : • When they have found the explosive • Whether the explosive was stable or unstable • To send the signal of where this scent was located The wearable activation interfaces were modeled on the prin - ciples of Georgia Tech’s FIDO project [ 23 ] . Our contribution is not in the design of the harness , but in its integration into our system . Because the most pressing tasks require binary discrimination between two alternatives , we relied on two interfaces ( bite and tug ) to each generate one alert . Each inter - face relied on a speciﬁc sensor . The bite interface relied on a capacitive sensor composed of four metal plates . The tug inter - face relied on a stretch resistor ( 10 cm ) attached to a brightly colored ball placed on the side of the dog harness . Finally , we used an infrared proximity sensor ( VCNL4000 ) to detect when dogs were in a ‘down’ position . This sensor was instrumented due to the ‘down’ position being the most frequently used for the dog to alert their handler that they found something of interest . Each one of these sensors was connected to an on - board micro - controller ( ATMEGA 328 ) that polled their values every loop - cycle as described by Jackson et . al [ 23 ] . If a predetermined threshold value for any of these interfaces was exceeded an alert was generated . The Arduino - based hub sends a Bluetooth message to a ruggedized cellphone also contained in the waterproof box ( OtterBox 1000 Series case ) within the hub . This phone uses an internal GPS module to determine where the harness is and sends a message to the API with the current location tagged . Figure 2 . K9 ofﬁcer modelling the harness with tug sensor to indicate “Unstable Item Found” API Overview Once a dog triggers an interface , the Arduino serializes the resulting signal and sends it to a smart - phone attached to the harness . An application running on the smart - phone then takes that signal and translates it to a RESTful JSON request [ 25 ] . The API controllers listen for these requests and take corresponding action to create , update , or destroy models in the Postgresql database hosted on Heroku [ 34 ] . Once the Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 928 models have been touched , the web service utilizes Pusher to update all clients ( web or mobile ) with the new data . Utilizing this technique , events can be triggered on the harness and all clients will be notiﬁed in real - time . Web Portal The web portal is built using Ruby on Rails and hosted on Heroku . We have developed a fully functional web portal ( Fig - ure 3 ) for analyzing and managing events [ 8 ] . It is primarily used in an after - the - fact manner for documenting events and analysis of dog activation data . With these goals in mind , the web portal has been designed to deliver its data in a straight - forward manner that facilitates searching through the doc - umentation . It has been designed and built to feel like an application . To achieve this interaction , we have utilized Web 2 . 0 techniques such as AJAX and unobtrusive JavaScript to allow real - time modiﬁcations and live updates to the website . The recent events page contains a list of all search events organized based on how recent they occurred . A search box on that page allows users to search through all events , and provides auto - complete functionality for quick and accurate searching . The events are indexed through a NoSQL - based system powered by ElasticSearch [ 16 ] . This system indexes all ﬁelds of the event model so users can search by alert , description , and location . The current K9 page allows users to manage the current status and training certiﬁcations of the dogs in a K9 unit , which is made up of at least two K9 teams . Additionally , users can click the recent events button to browse events involving particular dogs . This Maps page provides a geospatial overlay of all events within 30 miles ( 48 . 2 km ) of the user’s location . Events are clustered by location to allow for quick navigation and identiﬁcation , and once an event has been found , users can click on the event name to navigate to the recent event page of that event . Figure 3 . Maps page showing geospatial overlay of all events within 30 miles of the user . Mobile phone application The application ( ‘app’ ) is divided into three sections . The ﬁrst two sections are applicable to all ofﬁcers that are working alongside K9 teams , while the last section contains an item that is ( training session details ) speciﬁc to canine handlers : 1 . View all the department’s K9 teams in a list and display a map of the position of each team member 2 . Review current and past events dealing with scent detection events 3 . Record details from training sessions with the K9 teams The All K9s is the ﬁrst view presented to the user . It displays a list of all the canines in a given department with a name and picture . In addition , there is also a map view of all the canines and ofﬁcers actively participating in a search ( Figure 4 ) . We found that a map view of every canine allowed the user to perform actions like quickly ﬁnd the nearest canine to some target location . In the app , both views are presented and can be switched by a toggle button . The app remembers the user’s preference and persists that view across launches . Figure 4 . Event alert screenshot [ left ] , and canine location overlay [ right ] . After selecting a dog from either view , the user gets a few more details about them : current status , current location , and the ability to get directions to that location . However , more details are hidden in an information panel that is revealed by hitting the Info button in the top right corner . This button shows the K9 handler’s name , dog age , team certiﬁcations or training , harness interfaces , and recent events for that K9 team . It also gives the user a chance to subscribe to a speciﬁc K9 team on various devices . Subscribing to a K9 team allows the activity and training details for that team to be followed . While the Info view gives an overview of the canine’s details , certain cells can expand on their short summary . For instance , all of the harness interfaces ( as well as other possible attachments ) can be shown with details . The ofﬁcer could also browse a complete list of their certiﬁcates and completed training . Events contains information on the search tasks . When ca - nines are in the ﬁeld , ofﬁcers need to be notiﬁed whenever important events , like detection of a scent , occur . Activating the notiﬁcation ( or navigating within the app ) takes the user to the event view . This view displays important information about the search : the canines assigned , the trails of their past locations , locations of harness interface activations , and re - sources associated with the event ( Figure 5 ) . From here , an ofﬁcer can quickly get directions to the location , as well as augment the event with additional resources such as images captured at the scene . Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 929 Figure 5 . Example of K9 search activity [ left ] , and ofﬁcer annotations [ right ] . Each color represents a K9 team . The map in the event view is dynamic , allowing ofﬁcers to zoom in to see more detail or focus on speciﬁc dog trails . This behavior is also important when ofﬁcers add their own annotations to a map , as ofﬁcers can continue to pan and zoom in the map , while their annotations stay associated with speciﬁc latitude / longitude points . These map annotations , as well as any user photos , are up - loaded to the FIDO K9 server for later viewing and analysis . These resources , as well as pictures taken by ofﬁcers at the scene , are also available within the app . When the CPD ( like most K9 teams ) perform training exercises with their K9 dogs , there is a large document , the training log , that must be completed with details about the training . The ofﬁcers ﬁll this paper document with the information , and then transcribe that into a spreadsheet when they return to the ofﬁce . This transcription takes additional time and requires the ofﬁcers to look up information that is needed for the spreadsheet like weather details . Instead of creating a one – to – one mapping from the paper form to the app , we sought to automate the form as much as possible . With the information the app already has on the K9 teams , several ﬁelds were made easier : dog names could be selected from an auto - populated list , and the handler would not need to be speciﬁed by the user , because it is already known by selecting the canine . The training location can be set using the phone’s location ( given the user’s permission ) . Similarly , we are using an API provided by Forecast . io [ 10 ] to get hyper - localized and detailed weather information at the user’s location . This API allows us to automatically ﬁll out tedious details such as the humidity , overcast , and wind speed . When creating new training aids , we are able to use similar techniques to reduce the number of required actions by the CPD . By integrating this training information into the smart - phone app , the time to complete the training log is signiﬁcantly decreased . Google Glass The promising results of Johnson , Gibson , and Mutlu coupled with the ofﬁcers interested in utilizing department purchased Google Glass motivated us to integrate this device into our sys - tem [ 24 ] . In our system , Google Glass [ 30 ] , the head - mounted interface , supports real - time communication and collaboration between the dog , the handler and accompanying ofﬁcers . It can display and transmit much more information with minimal diversion of the ofﬁcer’s gaze . Glass allows ofﬁcers working with a dog to get real - time updates on what the dog is alerting to , as well as augment the canine’s feedback with their own input . Live cards ( from the Google Glass UX design kit ) support ongoing tasks , such as emergency incidents , and allow the ofﬁcer to request additional backup . During a search , the handler wearing Google Glass will be able to see the current location of the K9 team , as well as the path already searched . When the dog scents a suspicious object , a signal would be sent to the handler’s Google Glass to trigger it with a sound to notify the ofﬁcer of the emergency . If the handler needs additional backup or support , he could send the request along with information from the dog whether the explosive device is stable or unstable to Dispatch . Ofﬁcers wearing Google Glass would receive the notiﬁcation and view the event , and get directions ( Figure 6 ) . Figure 6 . Google Glass providing directions to ofﬁcer . In this scenario , we predict the time that it currently takes to route an alert to the appropriate department would be mini - mized . While awaiting the arrival of backup ofﬁcers or the EOD unit , the K9 team will be able to see the current location of backup . They would also be able increase documentation by taking photos or videos of the package and its surrounding area . When backup arrives on the scene , they would be able to see the location of both the handler and the item . Once the K9 alert is resolved , the handler can dismiss the task and all accompanying ofﬁcers will be notiﬁed that the situation has been resolved . In addition , ofﬁcers wearing Google Glass can access the static cards for more information . The static cards display text , images and video content . The content could contain text information about an incident , images or video of suspicious objects . Static cards are documentation of past events . SYSTEM EVALUATION We demonstrated a functional prototype of our system during an explosive detection training session with one K9 explo - sive detection team . For safety reasons , we were not able to participate in live searches because our participation might Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 930 compromise the integrity of the process . This training session was the closest environment we could participate in to simu - late our system without compromising safety . This training session involved locating a speciﬁc scent inside of a build - ing on a university campus . A second team observed and commented on the training session . These ofﬁcers were part of the original group that was observed during the require - ments gathering process . They also provided feedback on the mobile phone app prototypes on two occasions prior to the functional prototype explosive detection trial . The latter feedback session included a walk - through of the high ﬁdelity mobile phone app prototype and was invaluable in shaping the design of the application [ 39 ] . Due to security concerns , we were unable to deploy the app in - the - wild . Concerns around the impact on the current training practices of the ofﬁcers also prohibited us from conducting a ﬁeld evaluation outside of the demonstration of the functional prototype . The mapping interface with collaborative annotation and scent alerts was universally valued by the ofﬁcers . They expressed that this technology allowed them to coordinate searches better than using radio transceivers , which were often not universally ac - cessible . Being able to download an app and quickly share information with other ofﬁcers would remove many of the barriers to communication as its use was not restricted to a speciﬁc municipality . One ofﬁcer ( P2 ) said , “I like the fact that we could live track our active K9 teams during a sweep to ﬁnd out the areas that had been searched already . This feature allowed us to search more efﬁciently because we could simply look at the application to determine what areas still needed to be searched . This could be done much more quickly than having to call each handler for an update . ” [ 22 ] . The ofﬁcer ( P3 ) who routinely provides backup for K9 teams , saw value in the app beyond working alongside K9 teams : “This program enables law enforcement personnel to in - put vital information in real - time and keeps all personnel on the same page . Managing personnel in a crisis sit - uation is a daunting task , especially when hundreds of lives could be at stake . This tool would greatly ease the logistical nightmare of keeping track of our personnel and assigning / reassigning posts as critical information evolves . ” On the other hand , the ofﬁcers agreed that the head - mounted interface was not as useful as the mobile phone app because there was no way to securely attach it during the vigorous movements of a search . Similarly , the mobile phone app did not affect visibility and had longer battery life than the head - mounted display . There was interest , however , in utilizing some of the aspects they appreciated such as gesture con - trol ( similar to those built into Google Glass ) and hands - free glanceable notiﬁcations but in a different form factor , like that of a watch . Similarly , due to the mobile nature of police work , ofﬁcers predicted they would rarely use the desktop web interface , even at the police station or inside their cars . Instead , we found the web portal is better - suited for a different audience , namely dispatchers . So , we decided to focus on the mobile phone application . DISCUSSION One of the technical challenges we encountered was indoor location sensing . For example in multi - level environments ( e . g . , sport stadiums ) , GPS is not sufﬁcient to indicate the ﬂoor of the alert . The simulated alerts generated through the instrumented har - ness were well received by ofﬁcers . Nonetheless , the ofﬁcers were concerned about the practical difﬁculties the harness could encounter during searches . For example , the freely moving ( hanging ) , wearable interfaces ( tug and bite ) could catch on nearby objects . Because search environments are often hard - to - reach and compact , this limitation posed a non - trivial problem . Nonetheless , the ability to signal to handlers provides a way to decrease search time and minimize fatigue . Instead of making the dog harness smaller , we wanted to explore a different method for the dog to communicate with the handler that would not involve freely - moving ( hanging ) interfaces on their body . This in turn led to our exploration of intentional gestures that could be classiﬁed by an inertial sensor and communicated wirelessly to the handler’s mobile phone [ 43 ] . We believe that this direction will better address the needs of our users , both human and canine , and will unite what is most promising in our system . One aspect we did not adequately consider were the changing regulations for law enforcement concerning the security of and availability of their search data . With the testimony of K9 teams being a valuable part of legal proceedings , it is important to be transparent , yet also secure , in how we handle these data [ 35 ] . As with concerns around handlers inadvertently cueing their canines to alert [ 26 ] , so could concerns arise around the documentation of the canine alerts in our system . This aspect of our system needs to be strengthened in future work . CONCLUSION & FUTURE WORK Further development is needed on the mobile phone applica - tion to integrate voice communication and better track indoor location . We believe that the Apple iBeacon [ 33 ] might be a promising , low - cost option for indoor location in frequently searched sites like sport venues . Use of this technology , which is currently being deployed at multiple stadiums in the United States , is planned to be tested on our campus this year [ 44 ] . In addition , we also need to alter how we handle K9 team search data to meet regulations established within this past year . By making the app freely available , barriers to implementa - tion around cost would be removed . While not all ofﬁcers had access to head - mounted interfaces such as Google Glass , they all had a department - issued smart - phone . To prevent the same issues that the current systems have from being repeated , future work should also add a voice channel , thereby covering each of the communication channels the ofﬁcers need in a universally accessible application . Future work should also include grounding in implicit coordination , communication overhead , and situation awareness literature . In addition , a deeper exploration of the role of incident command which covers both police operations and inter - agency collaboration would be beneﬁcial . Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 931 We hope that by sharing our diagram , information on the current process , and system prototype details with the CSCW community more research will be done in this under - explored space . Initial response to our work has been positive and law enforcement ofﬁcers have provided actionable feedback . We are encouraged by the response and believe that this system has the potential to improve the lives of K9 teams , law enforcement ofﬁcers , and the communities they serve . ACKNOWLEDGMENTS We would like to thank all of the law enforcement ofﬁcers , both human and canine , who have participated in this research . This work was supported by the National Science Foundation under Grant IIS - 1320690 , the GVU Center , the Wearable Computing Center , and Intel Corporation . REFERENCES 1 . Joelle Alcaidinho , Giancarlo Valentin , Stephanie Tai , Brian Nguyen , Krista Sanders , Melody Jackson , Eric Gilbert , and Thad Starner . 2015 . Leveraging Mobile Technology to Increase the Permanent Adoption of Shelter Dogs . In Proceedings of the 17th International Conference on Human - Computer Interaction with Mobile Devices and Services . ACM , 463 – 469 . 2 . Erika Ashikaga , Mayu Iwata , Daijiro Komaki , Takahiro Hara , and Shojiro Nishio . 2011 . Exploring map - based interactions for co - located collaborative work by multiple mobile users . In Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems . ACM , 417 – 420 . 3 . Hugh Beyer and Karen Holtzblatt . 1999 . Contextual design . In interactions , Vol . 6 . ACM , 32 – 42 . 4 . Alican Bozkurt , David L Roberts , Barbara L Sherman , Rita Brugarolas , Sean Mealin , John Majikes , Pu Yang , and Robert Loftin . 2014 . Toward cyber - enhanced working dogs for search and rescue . Intelligent Systems , IEEE 29 , 6 ( 2014 ) , 32 – 39 . 5 . Walter F Burghardt . 2003 . Behavioral considerations in the management of working dogs . In Veterinary Clinics of North America : Small Animal Practice , Vol . 33 . Elsevier . 6 . Kelvin Cheng , Liang He , Xiaojun Meng , David A Shamma , Dung Nguyen , and Anbarasan Thangapalam . 2015 . CozyMaps : Real - time Collaboration on a Shared Map with Multiple Displays . In Proceedings of the 17th International Conference on Human - Computer Interaction with Mobile Devices and Services . ACM , 46 – 51 . 7 . Andy Crabtree . 2006 . Designing collaborative systems : A practical guide to ethnography . Springer Science & Business Media . 8 . Paul Dix . 2010 . Service - oriented design with Ruby and Rails . Addison - Wesley Professional . 9 . Alexander Ferworn , Alireza Sadeghian , Kevin Barnum , Hossein Rahnama , Huy Pham , Carl Erickson , Devin Ostrom , and Lucia Dell’Agnese . 2006 . Urban search and rescue with canine augmentation technology . In System of Systems Engineering , IEEE / SMC International Conference on . IEEE , 5 – pp . 10 . Forecast . io . 2012 . The Dark Sky Forecast API . ( 2012 ) . https : / / developer . forecast . io Version 6 . 11 . Dominic Furniss and Ann Blandford . 2010 . DiCoT modeling : from analysis to design . In Proceedings of CHI workshop bridging the gap : moving from contextual analysis to design . Atlanta , GA . 10 – 15 . 12 . Kenneth G Furton and Lawrence J Myers . 2001 . The scientiﬁc foundation and efﬁcacy of the use of canines as chemical detectors for explosives . In Talanta , Vol . 54 . Elsevier , 487 – 500 . 13 . Steffen Gauglitz , Benjamin Nuernberger , Matthew Turk , and Tobias Höllerer . 2014 . World - stabilized annotations and virtual scene navigation for remote collaboration . In Proceedings of the 27th annual symposium on User interface software and technology . ACM , 449 – 459 . 14 . Irit Gazit , Yizhar Lavner , Gil Bloch , Ophir Azulai , Allen Goldblatt , and Joseph Terkel . 2003 . A simple system for the remote detection and analysis of snifﬁng in explosives detection dogs . In Behavior Research Methods , Instruments , & Computers , Vol . 35 . Springer , 82 – 89 . 15 . Andrew Gelman , Jeffrey Fagan , and Alex Kiss . 2012 . An analysis of the New York City police department’s " stop - and - frisk " policy in the context of claims of racial bias . J . Amer . Statist . Assoc . ( 2012 ) . 16 . Clinton Gormley and Zachary Tong . 2015 . Elasticsearch : The Deﬁnitive Guide . " O’Reilly Media , Inc . " . 17 . Nitesh Goyal and Susan R Fussell . 2016 . Effects of Sensemaking Translucence on Distributed Collaborative Analysis . Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing ( 2016 ) , 288 – 302 . DOI : http : / / dx . doi . org / 10 . 1145 / 2818048 . 2820071 18 . Jonathan Grudin . 1994 . Computer - supported cooperative work : History and focus . In Computer . IEEE , 19 – 26 . 19 . Christine A Halverson . 2002 . Activity theory and distributed cognition : Or what does CSCW need to DO with theories ? . In Computer Supported Cooperative Work , Vol . 11 . Springer , 243 – 267 . 20 . James Hollan , Edwin Hutchins , and David Kirsh . 2000 . Distributed cognition : toward a new foundation for human - computer interaction research . In ACM Transactions on Computer - Human Interaction ( TOCHI ) , Vol . 7 . ACM , 174 – 196 . 21 . Fung Hu , Danny Silver , and André Trudel . 2007 . LonelyDog @ Home . In Web Intelligence and Intelligent Agent Technology Workshops , IEEE / WIC / ACM International Conferences on . IEEE , 333 – 337 . 22 . PackTrack Inc . 2016 . Our Features . ( 2016 ) . https : / / packtrackapp . com / features Version 3 . Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 932 23 . Melody M Jackson , Giancarlo Valentin , Larry Freil , Lily Burkeen , Clint Zeagler , Scott Gilliland , Barbara Currier , and Thad Starner . 2015 . FIDO – Facilitating interactions for dogs with occupations : wearable communication interfaces for working dogs . Personal and Ubiquitous Computing 19 , 1 ( 2015 ) , 155 – 173 . 24 . Steven Johnson , Madeleine Gibson , and Bilge Mutlu . 2015 . Handheld or Handsfree ? : Remote Collaboration via Lightweight Head - Mounted Displays and Handheld Devices . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing . ACM , 1825 – 1836 . 25 . Markus Lanthaler and Christian Gütl . 2012 . On using JSON - LD to create evolvable RESTful services . In Proceedings of the Third International Workshop on RESTful Design . ACM , 25 – 32 . 26 . Lisa Lit , Julie B Schweitzer , and Anita M Oberbauer . 2011 . Handler beliefs affect scent detection dog outcomes . Animal cognition 14 , 3 ( 2011 ) , 387 – 394 . 27 . Andrés Lucero , Jaakko Keränen , and Hannu Korhonen . 2010 . Collaborative use of mobile phones for brainstorming . In Proceedings of the 12th international conference on Human computer interaction with mobile devices and services . ACM , 337 – 340 . 28 . Sus Lundgren , Joel E Fischer , Stuart Reeves , and Olof Torgersson . 2015 . Designing mobile experiences for collocated interaction . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing . ACM , 496 – 507 . 29 . Kris Luyten , Kristof Verpoorten , and Karin Coninx . 2007 . Ad - hoc co - located collaborative work with mobile devices . In Proceedings of the 9th international conference on Human computer interaction with mobile devices and services . ACM , 507 – 514 . 30 . Zhihan Lv , Liangbing Feng , Haibo Li , and Shengzhong Feng . 2014 . Hand - free motion interaction on google glass . In SIGGRAPH Asia Mobile Graphics and Interactive Applications . ACM , 21 . 31 . Colin Mackenzie , Peter Fu - Ming Hu , Carsten Fausboll , Michael Nerlich , Thomas Benner , David Gagliano , Warren Whitlock , David Lam , and Yan Xiao . 2007 . Challenges to remote emergency decision - making for disasters or Homeland Security . In Cognition , Technology & Work , Vol . 9 . Springer , 15 – 24 . 32 . Clara Mancini . 2011 . Animal - computer interaction : a manifesto . Interactions 18 , 4 ( 2011 ) , 69 – 73 . 33 . Paul Martin , Bo - Jhang Ho , Nicholas Grupen , Samuel Munoz , and Mani Srivastava . 2014 . An ibeacon primer for indoor localization : demo abstract . In Proceedings of the 1st ACM Conference on Embedded Systems for Energy - Efﬁcient Buildings . ACM , 190 – 191 . 34 . Neil Middleton , Richard Schneeman , and others . 2013 . Heroku : Up and Running . " O’Reilly Media , Inc . " . 35 . Richard Myers . 2006 . Detector Dogs and Probable Cause . George Mason Law Review 14 , 1 ( 2006 ) . 36 . Mikko Paldanius , Tuula Kärkkäinen , Kaisa Väänänen - Vainio - Mattila , Oskar Juhlin , and Jonna Häkkilä . 2011 . Communication technology for human - dog interaction : exploration of dog owners’ experiences and expectations . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems . ACM , 2641 – 2650 . 37 . Inc Ray Allen . 2016 . GHOST Series K9 Gear Ray Allen . ( 2016 ) . https : / / www . rayallen . com / product / GHOST - Series - Ultimate - Dog - Harness / Ghost - Series - K9 - Harnesses Version 2 . 38 . Benjamin Resner . 2001 . Rover at Home : Computer Mediated Remote Interaction for Dogs . In Media Arts and Sciences MS , Cambridge , Massachusetts Institute of Technology . 39 . Yvonne Rogers . 2004 . New theoretical approaches for HCI . Annual review of information science and technology 38 , 1 ( 2004 ) , 87 – 143 . 40 . Yvonne Rogers . 2012 . HCI theory : classical , modern , and contemporary . In Synthesis Lectures on Human - Centered Informatics , Vol . 5 . Morgan & Claypool Publishers , 1 – 129 . 41 . Jesus Savage , RA Sanchez - Guzman , Walterio Mayol - Cuevas , Leobardo Arce , Alejandro Hernandez , Laura Brier , Felipe Martinez , Anaid Velazquez , and Gerardo Lopez . 2000 . Animal - machine interfaces . In Wearable Computers , The Fourth International Symposium on . IEEE , 191 – 192 . 42 . Jörg Schweitzer and Ralf Dörner . 2013 . Capturing on site laser annotations with smartphones to document construction work . In Proceedings of the 26th annual symposium on User interface software and technology . ACM , 357 – 362 . 43 . Giancarlo Valentin , Joelle Alcaidinho , Ayanna Howard , Melody M Jackson , and Thad Starner . 2016 . Creating collar - sensed motion gestures for dog - human communication in service applications . In Proceedings of the 2016 ACM International Symposium on Wearable Computers . ACM , 100 – 107 . 44 . Maria Varsamou and Theodore Antonakopoulos . 2014 . A bluetooth smart analyzer in iBeacon networks . In Consumer Electronics of Berlin ( ICCE - Berlin ) , IEEE Fourth International Conference on . IEEE , 288 – 292 . 45 . Chadwick A Wingrave , Jeremy Rose , Todd Langston , and Joseph J LaViola Jr . 2010 . Early explorations of CAT : Canine amusement and training . In CHI Extended Abstracts on Human Factors in Computing Systems . ACM , 2661 – 2670 . Session : Emergency & Safety Work - Collaboration around CSCW 2017 , February 25 – March 1 , 2017 , Portland , OR , USA 933