Power System Speech Recognition Method Based on Natural Language Processing Yonghui Re Information Technology Center , Yunnan Power Grid Co . , Ltd . , Kunming , China lih18473915958 @ 163 . com Yanxu Jin Information Technology Center , Yunnan Power Grid Co . , Ltd . , Kunming , China lih18473915954 @ 163 . com Chenglin Li * Information Technology Center , Yunnan Power Grid Co . , Ltd . , Kunming , China tianyuxin011031 @ 163 . com Fengbo Kong Information Technology Center , Yunnan Power Grid Co . , Ltd . , Kunming , China lih18473915654 @ 163 . com Yan Shi Information Technology Center , Yunnan Power Grid Co . , Ltd . , Kunming , China h18473915958 @ 163 . com Abstract —Aiming at the problem that the recognition accuracy of the system will decline when the target speaker voice tested in the speech recognition system and the speaker voice of the training data are significantly different , a power system speech recognition method based on natural language processing is proposed . It is speaker adaptation in the feature space . By adding speaker identity vector I - Vector auxiliary information to the DNN acoustic model , the speaker difference information in the feature is removed , the impact of speaker difference is reduced , and semantic information is retained . The experimental results on TEDLIUM open source data set show that the word error rate WER of the system is 7 . 7 % and 6 . 7 % higher than that of the baseline DNN acoustic model when the feature of this method is fbank and fMLLR respectively . Keywords—Deep neural network , Speaker Adaption , Acoustic model I . I NTRODUCTION In recent years , the deep neural network DNN has achieved great success in speech recognition . In speech acoustic modeling , the HMM - DNN system based on the hidden Markov deep neural network has better acoustic distinguishability than the traditional HMM - GMM system [ 1 ] , and has significantly improved the recognition accuracy . Therefore , DNN model has become the mainstream acoustic model in large vocabulary continuous speech recognition . However , the DNN acoustic model still has the same problem as the GMM acoustic model , that is , the target speaker voice and the speaker voice of the training data do not match . When the system recognizes a speaker voice that has not been met , the recognition accuracy will decline . For GMM model , speaker adaptive SA technology has been proved to be able to effectively reduce the performance degradation caused by speaker differences [ 2 - 3 ] . It uses a small amount of target speaker data , that is , adaptive data to modify the parameters of the speaker independent SI model or transform the characteristics of the target speaker to improve the accuracy of the target speaker modeling . Speaker adaptation is divided into model domain and feature domain adaptation . In model domain speaker adaptation based on DNN acoustic model , the simplest method is to directly update the SI model parameters using the target speaker ' s adaptive data [ 4 ] . However , due to the huge parameters of DNN model , a small amount of adaptive data is prone to over - fitting problems . The other method is to insert a linear transformation layer on the trained SI model . In the adaptive stage , only the linear transformation layer is adaptively adjusted for different speakers . The linear input network LIN , the linear hidden layer network LHN , and the linear output network LON are proposed in the literature [ 5 ] respectively to realize the adaptive adjustment of the linear transformation layer at different positions of the DNN network . These methods reduce the influence of over - fitting to a certain extent , but only make adaptive adjustment to a certain layer , and the effect improvement is not obvious . The core idea of document is to add a small amount of adaptive parameters to each hidden layer of DNN model . In the adaptive stage , a small amount of data can be used to achieve global adaptive parameter adjustment , which has a good effect . In the speaker adaptation in the feature domain , literature [ 6 ] proposes to map the target speaker ' s features to the speaker - independent space through a separate small network , plus i vector auxiliary information , and then train the DNN acoustic model based on the new features . This method improves the accuracy of system recognition to a certain extent , but the training process is relatively complex , because there are two network models , which need to be trained back and forth between the two networks , and it is unstable , and the prediction calculation is large . Reference [ 13 - 14 ] proposes a feature domain speaker adaptation method based on speaker coding SC . SC also represents the speaker difference information , but the acquisition process of SC is more complex than i - vector . It is necessary to decode the adaptive data on the SI - DNN model to obtain the " real label " , and then use these labels to update the SC of the target speaker . This paper proposes a new speaker adaptation method based on neural network . The adaptive layer shared by all speakers is introduced into the initial DNN model . According to the discriminative objective function of the voice frame , joint training is conducted on the entire training set to learn the connection weights of the adaptive layer , so that the target speaker i - vector information can be mapped to the features of the DNN model layer by layer through the adaptive layer , so as to remove the speaker difference information in the features _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 979 - 8 - 3503 - 1060 - 3 / 23 / $ 31 . 00 ©2023 IEEE 1240 2023 I EEE 5 t h I n t e r n a ti on a l C on f e r e n ce on C i v il A v i a ti on S a f e t y a nd I n f o r m a ti on T ec hno l ogy ( I CC A S I T ) | 979 - 8 - 3503 - 1060 - 3 / 2 3 / $ 31 . 00 © 2023 I EEE | DO I : 10 . 1109 / I CC A S I T 58768 . 2023 . 10351566 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . and retain the semantic information , Reduce the decrease of recognition rate caused by the difference between novel speakers , and improve the system performance . II . M ODEL A . I - Vector The traditional I - Vector , as an important technology to represent speaker differences , has been successfully applied in the field of speaker identification and speaker verification . The I - Vector method is the same as the classical joint factor analysis ( JFA ) [ 7 ] modeling method , which is based on the GMM - UBM general background model of Gaussian mixture model . The difference is that the I - Vector method is to establish a separate change subspace to model different changes of voice signals , including speaker information and channel information changes , The following formula is its core idea : s s V m Tw (cid:32) (cid:14) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:11)(cid:20)(cid:12) s V is the GMM mean hypervector of the speaker s , m is UBM . The mean hypervector is used to represent information independent of the speaker and channel . T is a total change subspace matrix , which completes the mapping of high - dimensional GMM mean hyper - vector to low - dimensional space , and generates low - dimensional vector ws , which is called identity vector , which has speaker differentiation and is subject to standard normal distribution . Because I - Vector has good speaker differentiation , and speech features include speaker information , our goal is to remove speaker information from speech features , retain semantic information , and make speech features more speaker normalization . So we use I - Vector to assist DNN in acoustic modeling , so that it can cope with the voice of different speakers . B . SA - DNN speaker adaptation The structure of speaker adaptive model based on neural network is shown in Figure 1 . Insert the adaptive layer shared by all speakers in the first few layers of the initial DNN model , as shown in the dark bar in the figure . It corresponds to the I - Vector vector of the target speaker ' s identity information . When recognizing the speech of each speaker , its corresponding I - Vector is extracted . Fig . 1 . SA - DNN network model structure The new neural network in this paper is called SA DNN . In subsequent experiments , adaptive layers of 1 to 5 layers will be added in order to study its performance changes . The forward calculation formula of SA - DNN network is as follows : i i i i i t t s W x V w b (cid:68) (cid:32) (cid:14) (cid:14) 1 i P (cid:100) (cid:100) (cid:3) (cid:3)(cid:3)(cid:3)(cid:11)(cid:21)(cid:12)(cid:3) i i i i t t W x b (cid:68) (cid:32) (cid:14) 1 i P (cid:100) (cid:100) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:11)(cid:22)(cid:12) ( ) i i t t y (cid:86)(cid:68)(cid:32) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:11)(cid:23)(cid:12) The purpose of adding adaptive layer is to transform features layer by layer by embedding I - Vector vector , remove speaker information in features , retain its semantic information , and turn speaker related features into speaker independent features . Fig . 2 . shows a voice feature in the test set . The second hidden layer output is obtained through SA - DNN and DNN models respectively . The number of points in the two figures is the same in the plane space reduced to 2 dimensions through PCA . Because the voice mainly contains semantic information and speaker information , after PCA is reduced to 2 dimensions , the x coordinate represents semantic information , and the y coordinate represents speaker information . As can be seen from Fig . 2 ( where the unit scale of x coordinate and y coordinate is the same ) , although both x coordinate and y coordinate are correspondingly reduced in scale , compared with the circle in the right figure , the left figure is compressed in the y coordinate direction , like a rectangle , indicating that the SA - DNN model can significantly reduce the speaker information in the feature , making the feature more semantically distinguishable . Fig . 2 . PCA dimension reduction of network characteristics When training SA - DNN , we mainly learn two types of parameters . The first is the ordinary DNN weight , and the second is the adaptive layer weight . The update formula of the ordinary DNN weight is shown in Formula ( 8 ) and Formula ( 9 ) . The weight update of the adaptive layer also uses the error backpropagation algorithm . The gradient of the adaptive layer is as follows : i i T t t s i i i t C C w V V (cid:68) (cid:68) (cid:119) (cid:119) (cid:119) (cid:32) (cid:32)(cid:143) (cid:119) (cid:119) (cid:119) 1 i P (cid:100) (cid:100) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:11)(cid:24)(cid:12) Due to the existence of gradient disappearance , the amplitude of back - propagation gradient ( from the output layer to the initial layers of the network ) will decrease sharply for the deep neural network . Therefore , when the gradient descent method is used to update the network weights , the weights of 1241 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . the initial layers change very slowly , so that they cannot learn effectively from the samples . Moreover , the adaptive layer in this paper is inserted into the first several layers of DNN network , with more weights distributed . To solve this problem , the network can be pre - trained by using the stack noise - reducing self - coder SDA [ 8 ] layered pre - training network to obtain a good network initial value . Finally , BP algorithm is used to fine - tune the network . SDA is composed of multi - layer DA . The hidden layer output of the previous layer of DA is used as the input of the next layer of DA . The input layer and hidden layer of each DA correspond to the two adjacent layers of DNN . For the SA - DNN model in this paper , we will use the I - Vector of the adaptive layer and the output value of the hidden layer as the input of one layer of DA for training , and the other layers will still follow the normal pre - training method III . E XPERIMENTAL RESULTS AND ANALYSIS The experimental data is the standard TEDLIUM data set , which is produced by the LIUM team ( the contributor of CMUShinx open source speech recognition tool ) and is specially used for the open data of speech recognition task . The corpus contains TED speech audio , corresponding annotation text and pronunciation dictionary . The corpus is divided into training set , development set and test set . The training set contains 774 TED speeches , a total of 118 hours . The decoding is carried out in the development set ( including 8 speech audio ) and test set ( 11 speech audio ) . Every TED speech in the corpus is a speaker , and all decoding uses the 3 - gram language model provided by Cantab TEDLIUM Release 1 . 1 . The system evaluation index is the word error rate WER in automatic speech recognition . Let N be the total number of words manually labeled in the corpus test set ( the correct number of words ) , the labeled text is T , the decoded text O is generated after decoding , and the minimum editing distance between the text T and the text O is calculated , that is , the number of inserted words I , the number of deleted words D , and the number of replaced words R , as shown in Formula ( 17 ) is the calculation formula of WER : * 100 % I D R WER N (cid:14) (cid:14) (cid:32) (cid:3) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:11)(cid:25)(cid:12) The software environment for the experiment is the open source Kaldi speech recognition system [ 9 - 12 ] and PDNN framework . Kaldi is used for data preparation , feature extraction , HMM GMM model training , language model integration , and decoding network construction . PDNN is used to train the acoustic model of neural network . Before training the DNN model , the HMM - GMM model needs to be trained . The 13 - dimensional MFCC and its first - order and second - order difference of Meier frequency cepstrum coefficient are used , with a total of 39 - dimensional MFCC features . For all voice data of each speaker , the cepstrum mean variance normalized CMVN is used to preprocess the features and train the three - phoneme HMM - GMM system . Then , the 39 - dimensional feature is extended to the left and right by 4 frames , and the LDA transform is reduced to the 40 - dimensional feature through linear discriminant analysis . Then the maximum likelihood linear transformation MLLT is performed on the 40 - dimensional features to obtain the HMM - GMM system of LDA + MLLT . Finally , the maximum likelihood linear regression fMLLR technology in feature space is used to normalize the 39 - dimensional MFCC features [ 13 ] . Use the new fMLLR features to continue to optimize the HMM - GMM system , thus forming the HMM - GMM speech recognition system of LDA + MLLT + fMLLR . There are 4082 context - sensitive HMM states in HMM . A better three - phoneme HMM - GMM recognition system is obtained through the above training , and the training data is forcibly aligned on the system to obtain the real label ( context - sensitive HMM status ID ) corresponding to each frame of voice . At this time , it is used for supervised DNN model training . In the experiment , two features are used for DNN model training . The 40 - dimensional fbank feature ( FilterBankFeature ) [ 14 ] , according to the CMVN regulation of each speaker and the 40 - dimensional fMLLR feature generated above , the feature is expanded by 5 frames left and right to obtain 440 - dimensional DNN input , and the hidden layer has 6 layers , The number of nodes in each layer is 1024 , and the number of nodes in softmax layer is 4082 for context - sensitive HMM status . At this time , the DNN network structure is 440 - 1024 - 1024 - 1024 - 1024 - 1024 - 1024 - 4082 , and the training set and cross validation set account for 95 % and 5 % of the training data respectively Before training , conduct SDA pre - training first . Here , conduct five rounds of SDA pre - training for each hidden layer . Then the BP algorithm is used for global fine - tuning , and the initial learning rate is set to 0 . 08 during the training process . When the error of the verification set is less than a certain value after two rounds of training , the learning rate will be halved until the fixed number of halving times . In different data sets , these learning parameters are determined according to experiments . Table I shows the baseline system performance of the two characteristics . TABLE I . WER OF DNN BASELINE SYSTEM features WER % fbank 16 . 9 fMLLR 16 . 3 The experiment first extracts the I - Vector vector from each sentence in the training set and the test set . Here the general background model UBM and the total change matrix T are trained in the whole training set of the corpus . The extracted I - Vector is 100 dimensions and has been adjusted in length . Then add 1 to 5 adaptive layers to the DNN model . Table II shows the WER indicators of the test set under different conditions . TABLE II . WER % OF TEST SETS WITH DIFFERENT ADAPTIVE LAYERS features Adaptive layers 1 2 3 4 5 fbank 16 . 7 15 . 6 17 . 5 18 . 6 19 . 5 fMLLR 16 . 1 15 . 2 17 . 1 18 . 2 19 . 1 As can be seen from Table II , when adding adaptive layers 1 and 2 , the effect is better than the baseline system , but when adding adaptive layers 3 , 4 and 5 , the effect is worse than the baseline system . The reason is that the training data is not enough , only more than 100 hours . The more adaptive layers , the more network parameters , and the over - fitting of training . When the adaptive layers are 3 , 4 , and 5 in the training process , the accuracy of the training set and the cross - validation set differ greatly , and the accuracy of the validation set is not high . This explanation can be verified on another large data set . 1242 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . The experiment was further carried out on the Switchboard - I telephone corpus . The training set includes 309 hours of Switchboard - I and 20 hours of CallHomeEnglish , a total of 1540 different speakers , and the test set is eval2000 ( Hub5 ' 00 ) , including 1831 voice messages from 40 speakers , All decoders use the bigram language model from the Switchboard - I labeled text training . It can be seen from Table III that when the training data increases , the effect is still better than the baseline system when the adaptive layer is 3 , 4 , and 5 . This shows that adding auxiliary information to the DNN model is beneficial to improve the system performance . When the number of layers exceeds 3 , the effect will tend to a fixed value , indicating that the increase in the number of layers can no longer improve the system performance . TABLE III . WER % OF TEST SETS WITH DIFFERENT ADAPTIVE LAYERS OF S WITCHBOARD features Adaptive layers baseline 1 2 3 4 5 fbank 15 . 7 15 . 0 14 . 7 15 . 2 15 . 3 15 . 3 fMLLR 15 . 2 14 . 7 14 . 4 14 . 8 14 . 9 14 . 9 IV . C ONCLUSION This paper proposes a power system speech recognition method based on natural language processing . By introducing the adaptive layer shared by all speakers on the DNN model , combined with the speaker I - Vector information , it can remove the speaker difference information in the feature layer by layer , retain the semantic information to be recognized , reduce the impact of the novel speaker phoneme , achieve rapid speaker adaptation , and improve the system recognition accuracy . R EFERENCES [ 1 ] Hinton G , Deng L , Yu D , et al . Deep Neural Networks for Acoustic Modeling in Speech Recognition : The Shared Views of Four Research Groups [ J ] . IEEE Signal Processing Magazine , 2012 ( 6 ) : 29 . [ 2 ] Navidi W C , Churchill G A , Von H A . Methods for inferring phylogenies from nucleic acid sequence data by using maximum likelihood and linear invariants . [ J ] . Molecular Biology & Evolution , 1991 ( 1 ) : 128 - 143 . [ 3 ] Yu L , Zhang X , Yin H . An extreme learning machine based virtual sample generation method with feature engineering for credit risk assessment with data scarcity [ J ] . Expert Systems with Application , 2022 ( Sep . ) : 202 . [ 4 ] Guo J , Di J , Gao X , et al . Discriminative Ability for Adverse Outcomes After Hip Fracture Surgery : A Comparison of Three Commonly Used Comorbidity - Based Indices [ J ] . Gerontology , 2021 : 1 - 13 . [ 5 ] Perets B , Kozdoba M , Mannor S . Whats Missing ? Learning Hidden Markov Models When the Locations of Missing Observations are Unknown [ J ] . 2022 . [ 6 ] Mukherjee P , Chakraborty B , Debnath N C . A Natural Language Processing based Automated Knowledge Provider System with Speech Recognition [ C ] / / International Conference on Computer Applications in Industry and Engineering . 2016 . [ 7 ] G . J . Brostow and R . Cipolla . Unsupervised Bayesian Detection of Independent Motion in Crowds , 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition ( CVPR ' 06 ) , 2006 , pp . 594 - 601 . [ 8 ] Kim W , Lee S , Chang Y , et al . Hivemind : social control - and - use of IoT towards democratization of public spaces [ C ] / / MobiSys ' 21 : The 19th Annual International Conference on Mobile Systems , Applications , and Services . 2021 . [ 9 ] C . J . Leggetter and P . C . Woodland . Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models [ J ] . Computer Speech & Language , 1995 , 9 . [ 10 ] Wang X , Chen G , Wei Z , et al . Comparison on Effect of Astragalus Polysaccnaride Powders and Injects on Immune Function and Growth of Chickens [ J ] . China Poultry , 2007 . [ 11 ] Vincent P , Larochelle H , Lajoie I , et al . Stacked Denoising Autoencoders : Learning Useful Representations in a Deep Network with a Local Denoising Criterion [ J ] . Journal of Machine Learning Research , 2010 , 11 ( 12 ) : 3371 - 3408 . [ 12 ] Miao Y . Kaldi + PDNN : Building DNN - based ASR Systems with Kaldi and PDNN : Computer ence , 10 . 48550 / arXiv . 1401 . 6984 [ P ] . 2014 . [ 13 ] Zhang X , Zhang J . Depositional feature and mode of sand - conglomerate bodies in the lower third member of Shahejie Formation in Shengtuo area [ J ] . Shiyou Xuebao / Acta Petrolei Sinica , 2008 , 29 ( 4 ) : 533 - 538 . [ 14 ] N . Zeghidour , N . Usunier , I . Kokkinos , T . Schaiz , G . Synnaeve and E . Dupoux . Learning Filterbanks from Raw Speech for Phone Recognition , 2018 IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , 2018 , pp . 5509 - 5513 1243 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply .