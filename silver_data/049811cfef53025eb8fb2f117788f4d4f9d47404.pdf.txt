CHI 2000 * 1 - 6 APRIL 2000 Doctoral Consortium Providing Integrated Toolkit - Level Support for Ambiguity in Recognition - Based Interfaces Jennifer Mankoff College of Computing & Graphics , Visualization , & Usability Center Georgia Institute of Technology Atlanta , GA 30332 - 0280 + 1 - 404 - 385 - 0257 jmankoff @ cc . gatech . edu http : / / www . cc . gatech . edu / fce / errata / ABSTRACT Recognition technologies are being used extensively in both the commercial and research worlds . But recognizers are still error - prone , and this results in performance prob - lems and brittle dialogues . These problems are a barrier to acceptance and usefulness of recognition systems . Better interfaces to recognition systems , which can help to reduce the burden of recognition errors , are difficult to build be - cause of lack of knowledge about the ambiguity inherent in recognition . We have extended a user interface toolkit in order to model and to provide structured support for ambi - guity at the input event level 7 . This makes it possible to build re - usable interface components for resolving ambi - guity and dealing with recognition errors . These interfaces can help to reduce the negative effects of recognition er - rors . By providing these components at a toolkit level , we make it easier for application writers to provide good sup - port for error handling . And we can explore new types of interfaces for resolving a more varied range of ambiguity . Keywords Pen and speech recognition , recognition errors , ambiguity . INTRODUCTION AND BACKGROUND Technologies such as speech , gesture , and handwriting recognition , have made great strides in recent years . By providing support for more natural forms of communica - tion , recognition can make computers more accessible . Recognition is particularly useful in settings where a key - board and mouse are not available , such as very large or very small displays , and mobile and ubiquitous computing . However , recognizers are error - prone , and this can confuse the user , cause performance problems , and result in brittle interaction dialogues . For example , Suhm found that the speed of spoken input to computers was only 40 words per minute ( wpm ) because of recognition errors , even though humans speak at 120 wpm 12 . One cause of errors is mis - recognition . Another cause is inherent ambiguity . Ambiguity arises when there is more than one possible way to interpret the user ' s input . Words like ' he , ' and ' it ' Â© Copyright on this material is held by the author ( s ) . are examples of ambiguous input . Although we cannot eliminate ambiguity , we can build interfaces which reduce it and reduce its negative effects on users . For example , Suhm found that user satisfaction and input speed both increased when he added support for multimodal error handling to a speech dictation system 12 . McGee et al . found that they were able to reduce ambiguity in a multimodal system by combining results from different recognizers 8 . Similar studies in the uni - modal pen and speech communities are described in our survey of interfaces to recognition systems 6 Interfaces which help the user deal with ambiguity depend on having knowledge about the ambiguity resulting from the recognition process . Yet existing user interface tool - kits have no way to model ambiguity , much less expose it to the interface components , nor do they provide explicit support for resolving ambiguity . PRINCIPLED SUPPORT FOR AMBIGUITY Our primary innovation is to explicitly model ambiguity in the user interface toolkit , thus making ambiguity accessi - ble to interface components . We do by extending the con - cept of hierarchical events 9 to include ambiguity . Our toolkit - level solution makes it possible to build re - usable components and strategies for resolving ambiguity . It also allows us to give the user feedback about how their input is being interpreted before we know for sure exactly which interpretation is correct . Our secondary innovation is to support ambiguity and rec - ognition at the input level , so that objects receive recogni - tion results through the same mechanism as mouse and keyboard events . Our solution relieves the application of the burden of dealing directly with recognition results and recognition ambiguity , while providing re - usable user in - terface components that implement common techniques for handling ambiguity . Our approach differs from other toolkits which support recognized input such as Amulet 4 and various multimodal toolkits 8 , 10 , which provide varying amounts of support for ambiguity , but require the application writer to deal with recognition results directly . In addition , we have developed a model of three different types of ambiguity which are commonly encountered . The first , and most common , is recognition ambiguity . Figure ~ HE FI = ITILI ~ " ZS l = l ~ fTl ~ " 77 Doctoral Consortium CHI 2000 * 1 - , $ APRIL 2000 ( a ) ( b ) I Darth Vader said : J - ~ - | r = a . I ~ X Figure 1 : A menu of possible interpretations of the user ' s input . ( a ) The user dictating text . ( b ) The user drawing a button in Burlap . la and lb both show examples of this . The second is seg - mentation ambiguity , which arises when it is unclear how to group user input . For example , should ' a r o u n d ' be interpreted as ' a round ' or ' around . ' The third type of ambiguity , target ambiguity , arises when the target of the user ' s input is unclear . This is best illus - trated by a classic example from the world of multimodal computing : In the sentence ' ~ out that there , " what does there refer to ? Figure 2 shows another example of target ambiguity : which checkbox is the user checking ? We have extended the user interface toolkit SubArctic 1 , 2 to provide explicit access to all three types of ambi - guity at an input level . We have written two applications making use of four recognizers ( IBM ' s ViaVoice TM , a unistroke gesture recognizer 5 , the context toolkit 7 , and our own ) and three types of input ( speech , pen , and identity ) . Figure la shows our first application , a simple word prediction system . Figure lb shows our second ap - plication , a user - interface sketching system called Burlap based on SILK ( Sketching Interfaces Like Krazy 3 ) . RESOLVING AMBIGUITY IN THE INTERFACE The purpose of building toolkit - level support for ambiguity is to allow us to build better interfaces to recognition sys - tems . As stated in the introduction , user interface tech - niques can help reduce the negative effects of ambiguity on things like user productivity and input speed . We call this class of techniques mediators . The menu in Figure la & b is an example of a mediator . It implements a technique called an n - best list . This is one of several techniques sup - ported by our toolkit and covered in more detail in our survey of interfaces to recognition systems 6 . One key advantage of our toolkit is support for feedback about events before ambiguity has been resolved . We separate feedback about events from action on events in order to give the user early feedback about what may be done with their input . This allows us to support a much larger range of mediation strategies including very lazy mediation . For example , in Burlap , we can wait to medi - ate a sketched widget until the user tries to interact with it . A second advantage is support for components which know nothing about ambiguity . For example , neither the text area in Figure la nor the application know that the ~ I Figure 2 - Target a m - Figure 3 . An biguity : Which check - application box did the user specific me - intend to check ? diator input is coming from a recognizer , yet we are still able to involve the user in mediation . Finally , our infrastructure makes it easier to experiment with mediators that take advantage of application - specific knowledge to weave mediation more naturally into the flow of the user ' s interaction ( See Figure 3 ) . CONCLUSIONS We have provided principled , toolkit level support for a model of ambiguity in recognition . Our solution addresses a wide range of user interface techniques found in the lit - erature , and allows us to explore new techniques which may address additional causes of error in recognition - based input . However , our work goes further than simply providing easy access to existing techniques . In particular , as shown in our survey , existing systems almost exclu - sively provide support for recognition ambiguity . We plan to investigate potential user interface techniques for deal - ing with segmentation and target ambiguity , and to inves - tigate interface strategies for dealing with ambiguity in other domains such as context - aware computing . ACKNOWLEDGMENTS I would like to thank Gregory Abowd , Scott Hudson , and Anind Dey . This work was supported in part by the Na - tional Science Foundation under grants IRI - 9703384 , EIA - 9806822 , IRI - 9500942 and IIS - 9800597 . REFERENCES 1 Edwards , W . K . , et al . Systematic output modification in a 2D U ! tool - kit . In Proc . of UIST ' 97 . pp . 151 - 158 . 2 Hudson , S . and Smith , ! . supporting dynamic downloadable appearances in an extensible user interface toolkit . In Proc . of UIST ' 9Z Oct . 1997 . pp . 159 - 168 . 3 Landay , J . A . and Myers , B . A . Interactive sketching for the early stages of user interface design . In Proc . of CHI ' 95 . pp . 43 - 50 . 4 Landay , J . A . and Myers , B . A . Extending an existing user interface toolkit to support gesture recognition . In Proc . INTERCHl ' 93 . pp . 91 - 92 . 5 Long , A . C . et al . Implications for a gesture design tool . In Proc . of CHl ' 99 . pp . 40 - 47 . 6 Mankoff , J . and Abowd , G . D . Error correction techniques for handwrit - ing , speech , and other ambiguous or error prone systems . Technical Report GIT - GVU - 99 - 18 . 1999 . 7 Mankoff , J . Hudson , S . E . and Abowd , G . D . Providing integrated toolkit - level support for ambiguity in recognition - based interfaces . In Proceedings t ~ ' CHI ' 2000 . To Appear . 8 McGee , D . R . , et al . Confirmation in multimodat systems . In Proc . of COLING - ACL ' 98 . Montreal , Canada . 9 Myers , B . A . and Kosbie , D . S . Reusable hierarchical command objects . In Proceedhzgs of CHI 96 conJerence on Human Jactors in computing sys - tems . 1996 . Pp . 260 - 267 . 10 Nigay , 1 . and Coutaz , J . A Generic platform addressing the multimodal challenge . In Proc . of CHl ' 95 . pp . 98 - 105 . I 1 Salber , D . et aL The context toolkit : Aiding the development of con - text - enabled applications . In Proc . of CHl ' 99 . pp . 434 - 441 . 12 Suhm , B . et al . Model - based and empirical evaluation of multimodal interactive error correction . In Proc of CHl ' 99 . pp . 584 - 591 . 78