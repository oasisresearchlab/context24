ARPACK USERS GUIDE : Solution of Large Scale Eigenvalue Problems by Implicitly Restarted Arnoldi Methods . R . B . Lehoucq , D . C . Sorensen , C . Yang - DRAFT - 31 July 96 Contents 1 Introduction to ARPACK 11 1 . 1 Important Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 1 . 2 Getting Started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1 . 3 Reverse Communication Interface . . . . . . . . . . . . . . . . . . . . . 13 1 . 4 Availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1 . 5 Installation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 1 . 6 Documentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 1 . 7 Dependence on LAPACK and BLAS . . . . . . . . . . . . . . . . . . . 15 1 . 8 Expected Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 1 . 9 PARPACK . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 1 . 10 Trouble Shooting and Problems . . . . . . . . . . . . . . . . . . . . . . 16 1 . 11 Research Funding of ARPACK . . . . . . . . . . . . . . . . . . . . . . 16 2 Getting Started with ARPACK 17 2 . 1 Directory Structure and Contents . . . . . . . . . . . . . . . . . . . . . 17 2 . 2 Getting Started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2 . 3 An Example for a Symmetric Eigenvalue Problem . . . . . . . . . . . 19 2 . 3 . 1 The Reverse Communication Interface . . . . . . . . . . . . . . 20 2 . 3 . 2 Post Processing for Eigenvalues and Eigenvectors . . . . . . . . 22 2 . 3 . 3 Setting up the problem . . . . . . . . . . . . . . . . . . . . . . 22 2 . 3 . 4 Storage Declarations . . . . . . . . . . . . . . . . . . . . . . . . 24 2 . 3 . 5 Stopping Criterion . . . . . . . . . . . . . . . . . . . . . . . . . 24 2 . 3 . 6 Initial Parameter Settings . . . . . . . . . . . . . . . . . . . . . 25 2 . 3 . 7 Setting the Starting Vector . . . . . . . . . . . . . . . . . . . . 26 2 . 3 . 8 Trace Debugging Capability . . . . . . . . . . . . . . . . . . . . 26 3 General Use of ARPACK 29 3 . 1 Naming Conventions , Precisions and Types . . . . . . . . . . . . . . . 29 3 . 2 Shift and Invert Spectral Transformation Mode . . . . . . . . . . . . . 30 3 . 2 . 1 M is Hermitian Positive De(cid:12)nite . . . . . . . . . . . . . . . . . 33 3 . 2 . 2 M is NOT Hermitian Positive Semi { De(cid:12)nite . . . . . . . . . . 34 3 . 3 Reverse Communication Structure for Shift - Invert . . . . . . . . . . . 34 3 CONTENTS 4 3 . 3 . 1 Shift and invert on a Generalized Eigen - problem . . . . . . . . 34 3 . 4 Using the Computational Modes . . . . . . . . . . . . . . . . . . . . . 37 3 . 5 Computational Modes for Real Symmetric Problems . . . . . . . . . . 39 3 . 6 Post - Processing for Eigenvectors Using dseupd . . . . . . . . . . . . . 40 3 . 7 Computational Modes for Real Non - Symmetric Problems . . . . . . . 42 3 . 8 Post - Processing for Eigenvectors Using dneupd . . . . . . . . . . . . . 44 3 . 9 Computational Modes for Complex Problems . . . . . . . . . . . . . . 45 3 . 10 Post - Processing for Eigenvectors Using zneupd . . . . . . . . . . . . . 47 4 The Implicitly Restarted Arnoldi Method 49 4 . 1 Structure of the Eigenvalue Problem . . . . . . . . . . . . . . . . . . . 50 4 . 2 Krylov Subspaces and Projection Methods . . . . . . . . . . . . . . . . 53 4 . 3 The Arnoldi Factorization . . . . . . . . . . . . . . . . . . . . . . . . . 54 4 . 4 Restarting the Arnoldi Method . . . . . . . . . . . . . . . . . . . . . . 57 4 . 5 The Generalized Eigenvalue Problem . . . . . . . . . . . . . . . . . . . 62 4 . 5 . 1 Structure of the Spectral Transformation . . . . . . . . . . . . 63 4 . 5 . 2 Eigenvector / Null - Space Puri(cid:12)cation . . . . . . . . . . . . . . . 64 4 . 6 Stopping Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 5 Computational Routines 69 5 . 1 ARPACK subroutines . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5 . 1 . 1 XYaupd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5 . 1 . 2 XYaup2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5 . 1 . 3 XYaitr . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 5 . 1 . 4 Xgetv0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5 . 1 . 5 Xneigh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5 . 1 . 6 [ s , d ] seigt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 5 . 1 . 7 [ s , d ] Yconv . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 5 . 1 . 8 XYapps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 5 . 1 . 9 XYeupd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 5 . 2 LAPACK routines used by ARPACK . . . . . . . . . . . . . . . . . . . 77 5 . 3 BLAS routines used by ARPACK . . . . . . . . . . . . . . . . . . . . . 79 A Templates and Driver Routines 81 A . 1 Symmetric Drivers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 A . 1 . 1 Selecting a Symmetric Driver . . . . . . . . . . . . . . . . . . . 83 A . 1 . 2 Identify OP and B for the Driver . . . . . . . . . . . . . . . . . . 85 A . 1 . 3 The Reverse Communication Interface . . . . . . . . . . . . . . 86 A . 1 . 4 Modify the problem dependent variables . . . . . . . . . . . . . 89 A . 1 . 5 Postprocessing and Accuracy Checking . . . . . . . . . . . . . . 91 A . 2 Real Nonsymmetric Drivers . . . . . . . . . . . . . . . . . . . . . . . . 91 A . 2 . 1 Selecting a Non - symmetric Driver . . . . . . . . . . . . . . . . 91 A . 2 . 2 Identify OP and B for the Driver . . . . . . . . . . . . . . . . . . 94 - DRAFT - 31 July 96 CONTENTS 5 A . 2 . 3 The Reverse Communication Interface . . . . . . . . . . . . . . 94 A . 2 . 4 Modify the Problem Dependent Variables . . . . . . . . . . . . 96 A . 2 . 5 Postprocessing and Accuracy Checking . . . . . . . . . . . . . . 98 A . 3 Complex Drivers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 A . 3 . 1 Selecting a Complex Arithmetic Driver . . . . . . . . . . . . . . 99 A . 3 . 2 Identify OP and B for the Driver to be Modi(cid:12)ed . . . . . . . . . 100 A . 3 . 3 The Reverse Communication Interface . . . . . . . . . . . . . . 101 A . 3 . 4 Modify the Problem Dependent Variables . . . . . . . . . . . . 102 A . 3 . 5 Post - processing and Accuracy Checking . . . . . . . . . . . . . 104 A . 4 Band Drivers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 A . 4 . 1 Selecting a Band Storage Driver . . . . . . . . . . . . . . . . . 105 A . 4 . 2 Store the matrix correctly . . . . . . . . . . . . . . . . . . . . . 107 A . 4 . 3 Modify problem dependent variables . . . . . . . . . . . . . . . 107 A . 4 . 4 Modify other variables if necessary . . . . . . . . . . . . . . . . 107 A . 4 . 5 Accuracy checking . . . . . . . . . . . . . . . . . . . . . . . . . 108 A . 5 The Singular Value Decomposition . . . . . . . . . . . . . . . . . . . . 108 A . 5 . 1 The SVD Drivers . . . . . . . . . . . . . . . . . . . . . . . . . . 110 B Tracking the progress of ARPACK 111 C The XYaupd ARPACK Routines 115 C . 1 DSAUPD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 C . 2 DNAUPD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 C . 3 ZNAUPD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 - DRAFT - 31 July 96 List of Figures 1 . 1 An example of the reverse communication interface used by ARPACK . 14 2 . 1 The ARPACK directory structure . . . . . . . . . . . . . . . . . . . . . 19 2 . 2 The reverse communication interface in example program dssimp . . . 21 2 . 3 Post Processing for Eigenvalues and Eigenvectors using desupd . . . . . 23 2 . 4 Storage declarations needed for ARPACK subroutine dsaupd . . . . . 25 2 . 5 How to initiate the trace debugging capability in ARPACK . . . . . . . 26 2 . 6 Output from a Debug session for dsaupd . . . . . . . . . . . . . . . . . 28 3 . 1 Reverse communication interface for Shift - Invert . . . . . . . . . . . . . 35 3 . 2 Reverse communication interface for Shift - Invert contd . . . . . . . . . 36 3 . 3 Calling the ARPACK subroutine dnaupd . . . . . . . . . . . . . . . . . 38 3 . 4 Calling the ARPACK subroutine dsaupd . . . . . . . . . . . . . . . . . 39 3 . 5 Post - Processing for Eigenvectors Using dseupd . . . . . . . . . . . . . . 41 3 . 6 Calling the ARPACK subroutine dnaupd . . . . . . . . . . . . . . . . . 42 3 . 7 Post - Processing for Eigenvectors Using dneupd . . . . . . . . . . . . . . 44 3 . 8 Calling the ARPACK subroutine znaupd . . . . . . . . . . . . . . . . . 46 3 . 9 Post - Processing for Eigenvectors Using cneupd . . . . . . . . . . . . . . 47 4 . 1 An Implicitly Restarted Arnoldi Iteration as Implemented by ARPACK . 50 4 . 2 Algorithm 1 : Implicitly Shifted QR - iteration . . . . . . . . . . . . . . 52 4 . 3 Algorithm 2 : The k - Step Arnoldi Factorization . . . . . . . . . . . . 56 4 . 4 Algorithm 3 : An Implicitly Restarted Arnoldi Method ( IRAM ) . . . 59 4 . 5 The set of rectangles represents the matrix equation VmHm + fme T m of an Arnoldi factorization . The unshaded region on the right is a zero matrix of m (cid:0) 1 columns . . . . . . . . . . . . . . . . . . . . . . . . . . 61 4 . 6 After performing m (cid:0) k implicitly shifted qr steps on Hm , the middle set of pictures illustrates VmQmH + m + fme T m Qm : The last p columns of fme T m Qm are nonzero because of the qr iteration . . . . . . . . . . . 61 4 . 7 An implicitly restarted length k Arnoldi factorization results after dis - carding the last m (cid:0) k columns . . . . . . . . . . . . . . . . . . . . . . 61 5 . 1 High level implementation of the IRAM / IRLM in ARPACK . . . . . . 70 7 LIST OF FIGURES 8 5 . 2 Outline of algorithm used by subroutine XYeupd to compute Schur vectors and possibly eigenvectors . . . . . . . . . . . . . . . . . . . . . . 76 A . 1 Reverse communication structure . . . . . . . . . . . . . . . . . . . . . 87 A . 2 Compute w A T Av by Blocks . . . . . . . . . . . . . . . . . . . . 109 - DRAFT - 31 July 96 List of Tables 2 . 1 List of the simple drivers illustrating the use of ARPACK . . . . . . . . 19 2 . 2 Parameters for the top level ARPACK routines . . . . . . . . . . . . . . 22 3 . 1 Available precisions and data types for ARPACK . . . . . . . . . . . . 30 3 . 2 Double Precision Top level routines in ARPACK subdirectory SRC . . . 31 3 . 3 The various settings for the argument which in saupd . . . . . . . . . 39 3 . 4 The various settings for the argument which in naupd . . . . . . . . . 42 5 . 1 Description of the auxiliary subroutines of ARPACK . . . . . . . . . . 72 5 . 2 Description of the LAPACK computational routines used by ARPACK . 77 5 . 3 Description of the LAPACK auxiliary routines used by ARPACK . . . 78 5 . 4 Description of the Level three BLAS used by ARPACK . . . . . . . . . 79 5 . 5 Description of the Level two BLAS used by ARPACK . . . . . . . . . . 79 5 . 6 Description of the Level one BLAS used by ARPACK . . . . . . . . . . 80 A . 1 The functionality of the symmetric drivers . . . . . . . . . . . . . . . . 82 A . 2 The operators OP and B . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 A . 3 The eigenvalues of interest for symmetric eigenvalue problems . . . . . 89 A . 4 The functionality of the non - symmetric drivers . . . . . . . . . . . . . . 92 A . 5 The operators OP and B . . . . . . . . . . . . . . . . . . . . . . . . . . . 94 A . 6 The eigenvalues of interest for non - symmetric eigenvalue problems . . . 97 A . 7 The functionality of the complex arithmetic drivers . . . . . . . . . . . 99 A . 8 The operators OP and B . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 A . 9 The eigenvalues of interest for complex arithmetic eigenvalue problems . 103 A . 10 Band storage drivers for symmetric eigenvalue problems . . . . . . . . 105 A . 11 Band storage drivers for non - symmetric eigenvalue problems . . . . . . 106 A . 12 Band storage drivers for Complex arithmetic eigenvalue problems . . . 106 B . 1 Sample output produced by dsaupd . . . . . . . . . . . . . . . . . . . . 112 B . 2 Description of the message level settings for ARPACK . . . . . . . . . . 114 9 Chapter 1 Introduction to ARPACK ARPACK is a collection of Fortran77 subroutines designed to solve large scale eigen - value problems . ARPACK stands for ARnoldi PACKage . ARPACK software is capable of solving large scale non Hermitian standard and generalized eigenvalue problems from signi(cid:12)cant application areas . The software is designed to compute a few , say k , eigenvalues with user speci(cid:12)ed features such as those of largest real part or largest magnitude using n (cid:1) O ( k ) + O ( k 2 ) storage . No auxiliary storage is required . A set of Schur basis vectors for the desired k dimensional eigen - space is computed which is numerically orthogonal to working precision . Eigenvectors are also available upon request . The Arnoldi process is a technique for approximating a few eigenvalues and cor - responding eigenvectors of a general n (cid:2) n matrix . It is most appropriate for large structured matrices A where structured means that a matrix - vector product w Av requires O ( n ) rather than the usual O ( n 2 ) (cid:13)oating point operations ( Flops ) . This soft - ware is based upon an algorithmic variant of the Arnoldi process called the Implicitly Restarted Arnoldi Method ( IRAM ) . When the matrix A is symmetric it reduces to a variant of the Lanczos process called the Implicitly Restarted Lanczos Method ( IRLM ) . These variants may be viewed as a synthesis of the Arnoldi / Lanczos process with the Implicitly Shifted QR technique that is suitable for large scale problems . For many standard problems , a matrix factorization is not required . Only the action of the matrix on a vector is needed . In this chapter , we give an overview of the package . Chapter 2 explains how the user can quickly start using ARPACK while Chapter 3 gives a comprehensive descrip - tion of how to utilize the full capabilities of ARPACK . An overview of the theory of Krylov subspace projection methods and the underlying algorithms implemented in ARPACK is the subject of Chapter 4 . The (cid:12)nal chapter discusses the implementation details of the main computational routines in ARPACK . Appendix A is a guide on how to use the example driver routines as templates . Experienced users who are already familiar with large scale eigenvalue computations may (cid:12)nd it most productive to go directly to this appendix , locate the suitable driver and modify that for the partic - 11 1 . 1 . IMPORTANT FEATURES 12 ular application . Appendix B describes the trace debugging capability that is easily turned on in order to monitor progress and output important intermediate computed quantities . Checkpointing to guard against loss of intermediate computational results due to system or hardware failure is possible . A description of how to recover and restart in the event of a fault is provided in Appendix B . 1 . 1 Important Features The important features of ARPACK are : (cid:15) A reverse communication interface . (cid:15) Ability to return k eigenvalues which satisfy a user speci(cid:12)ed criterion such as largest real part , largest absolute value , largest algebraic value ( symmetric case ) , etc . For many standard problems , the action of the matrix on a vector w Av is all that is needed . (cid:15) A (cid:12)xed pre - determined storage requirement su(cid:14)ces throughout the computa - tion . Usually this is n(cid:1)O ( k ) + O ( k 2 ) where k is the number of eigenvalues to be computed and n is the order of the matrix . No auxiliary storage or interaction with such devices is required during the course of the computation . (cid:15) Sample driver routines are included that may be used as templates to imple - ment various spectral transformations to enhance convergence and to solve the generalized eigenvalue problem . (cid:15) Special consideration is given to the generalized problem Ax = Mx(cid:21) for singular or ill - conditioned symmetric positive semi - de(cid:12)nite M . (cid:15) Eigenvectors and / or Schur vectors may be computed on request . A Schur basis of dimension k is always computed . The Schur basis consists of vectors which are numerically orthogonal to working accuracy . Computed eigenvectors of symmetric matrices are also numerically orthogonal . (cid:15) The numerical accuracy of the computed eigenvalues and vectors is user spec - i(cid:12)ed . Residual tolerances may be set to the level of working precision . At working precision , the accuracy of the computed eigenvalues and vectors is con - sistent with the accuracy expected of a dense method such as the implicitly shifted QR iteration . (cid:15) Multiple eigenvalues o(cid:11)er no theoretical or computational di(cid:14)culty other than additional matrix - vector products required to expose the multiple instances . This is made possible through the implementation of de(cid:13)ation techniques simi - lar to those employed to make the implicitly shifted QR algorithm robust and practical . Since a block method is not required , the user does not need to - DRAFT - 31 July 96 CHAPTER 1 . INTRODUCTION TO ARPACK 13 \ guess " the correct block size that would be needed to capture multiple eigen - values . 1 . 2 Getting Started Easy to use sample driver routines are available . These simple drivers have been constructed to illustrate the use of ARPACK in the simplest cases of (cid:12)nding a few eigenvalues and corresponding eigenvectors of largest magnitude . Simple drivers for all precisions and data types are provided and these may be used as templates to easily begin using ARPACK . Chapter 2 describes how to get started by using these example driver programs . 1 . 3 Reverse Communication Interface The reverse communication interface is one of the most important aspects of the design of ARPACK . This interface avoids having to express a matrix - vector product through a subroutine with a (cid:12)xed calling sequence . This means that the user is free to choose any convenient data structure for the matrix representation . Moreover , if the matrix is not available explicitly , the user is free to express the action of the matrix on a vector through a subroutine call or a code segment . It is not necessary to conform to a (cid:12)xed format for a subroutine interface and hence there is no need to communicate data through the use of COMMON . A typical usage of this interface is illustrated with the example in Figure 1 . 1 . As usual , with reverse communication , control is returned to the calling program when interaction with the matrix A is required . The action requested of the calling program is simply to perform the task indicated by the reverse communication pa - rameter ido ( in this case multiply the vector held in the array workd beginning at location ipntr ( 1 ) and inserting the result into the array workd beginning at location ipntr ( 2 ) ) . Note that the call to the subroutine matvec in this code segment is simply meant to indicate that this matrix - vector operation is taking place . The user is free to use any available mechanism or subroutine to accomplish this task . In par - ticular , no speci(cid:12)c data structure is imposed and indeed , no explicit representation of the matrix is even required . One only needs to supply the action of the matrix on the speci(cid:12)ed vector . 1 . 4 Availability The codes are available by anonymous ftp from ftp . caam . rice . edu or by connecting directly to the URL ftp : / / ftp . caam . rice . edu / pub / software / ARPACK - DRAFT - 31 July 96 1 . 5 . INSTALLATION 14 10 continue call snaupd ( ido , bmat , n , which , . . . , workd , . . . , info ) if ( ido . eq . newprod ) then call matvec ( ' A ' , n , workd ( ipntr ( 1 ) ) , workd ( ipntr ( 2 ) ) ) else return endif go to 10 Figure 1 . 1 : An example of the reverse communication interface used by ARPACK . To get the software by anonymous ftp , connect by ftp to ftp . caam . rice . edu and login as anonymous . Then change directories to pub / people / software / ARPACK or connect directly to the URL as described above and follow the instructions in the README (cid:12)le in that directory . The ARPACK software is also available on Netlib in the directory scalapack . 1 . 5 Installation The instructions in the README (cid:12)le that will explain how to retrieve a compressed tar file and how to unbundle this (cid:12)le . A few options are available . One of these is to retrieve the (cid:12)le dist96 . tar . Z Then issue the instruction zcat dist96 . tar . Z | tar - xvf - This will automatically create a directory named ARPACK . This directory should have the following contents : BLAS DOCUMENTS EXAMPLES LAPACK README SRC UTIL Makefile ARmake . inc ARMAKES - DRAFT - 31 July 96 CHAPTER 1 . INTRODUCTION TO ARPACK 15 Instructions on how to proceed are given in the ARPACK / README (cid:12)le . After minor modi(cid:12)cations to the (cid:12)le makefile , issuing the command make lib will compile all subroutines and create the archive libarpack < PLATFORM > . a in the ARPACK directory . Here , < PLATFORM > denotes the environment where the ARPACK library is built . For example , if the make were done on a SUN Sparc4 , the library would be archived in libarpack SUN4 . a . Instructions in README explain how to proceed . Disk storage requirements for the directory structure shown above is just under 5 Megabytes . 1 . 6 Documentation In addition to this user ' s guide , complete documentation of usage , data requirements , error and warning conditions is provided in the header of the source code for each subroutine . There is su(cid:14)cient documentation included in the README (cid:12)les , DOCUMENTS directory , and headers of the codes in SRC and the EXAMPLES subdirectories to begin using ARPACK . This user ' s guide is intended to further explain and supplement that documentation . In addition to a detailed description of the capabilities , structure , and usage of ARPACK , this document is intended to provide a cursory overview of the Implicitly Restarted Arnoldi / Lanczos Method that this software is based upon . The goal is to provide some understanding of the underlying algorithm , expected behavior , additional references , and capabilities as well as limitations of the software . 1 . 7 Dependence on LAPACK and BLAS ARPACK is dependent upon a number of subroutines from LAPACK [ 1 ] and the BLAS [ 10 , 9 , 19 ] . The necessary routines are distributed along with the ARPACK software . Whenever possible , BLAS routines that have been optimized for the given machine should be used in place of the ones provided with ARPACK . A list of rou - tines required from these two sources is available in Chapter 5 . If local installations of BLAS and / or LAPACK are available then the corresponding ARPACK subdirectories may be deleted and the local installations may be pointed to instead . Care should be taken to verify consistency of the version dates of the local installations with the version dates of the BLAS and LAPACK routines provided with ARPACK . NOTE : The LAPACK library on your system MUST be the public release . The current release is version 2 . 0 . If you are not certain if the public release has been installed , we strongly recommend that you compile and link to the subset of LAPACK included with ARPACK . 1 . 8 Expected Performance ARPACK has been designed for straightforward adaptation to a variety of high per - - DRAFT - 31 July 96 1 . 9 . PARPACK 16 formance architectures including vector , super - scalar and parallel machines . It is intended to be portable and e(cid:14)cient across a wide range of computing platforms . Computationally intensive kernels are all expressed through BLAS operations and if the number k remains (cid:12)xed as n increases the performance will scale asymptotically to the Level 2 BLAS operation GEMV . Computational rates near maximum achievable peak are possible on multi - vector processors such as CRAY - C90 and on workstation clusters such as SGI Power Challenge . The package is written in the ANSI standard Fortran 77 language with one excep - tion . The use of include (cid:12)les is the only exception . These are associated soley with the trace debugging facility provided with ARPACK . Each of the ARPACK subrou - tines reference two include (cid:12)les for debugging and timing purposes ( see Appendix B ) . These references may be easily deleted if they are incompatible with your system . 1 . 9 PARPACK A parallel version of the ARPACK library is also available . The message passing layers currently supported are BLACS and MPI . Parallel ARPACK ( PARPACK ) is provided as an extension to the current ARPACK library . PARPACK has been installed on CRAY - T3D , Intel Delta and Paragon , IBM - SP2 , an SGI cluster and a network of Sun workstations . The package runs e(cid:14)ciently in each of these environments . More detailed information about Parallel ARPACK is available in the report by Maschho(cid:11) and Sorensen [ 25 ] . 1 . 10 Trouble Shooting and Problems An up to date list of known problems is available in pub / people / sorensen / ARPACK / Known _ Problems Any di(cid:14)culties with using the software should be reported to arpack @ caam . rice . edu 1 . 11 Research Funding of ARPACK Financial support for this work was provided in part by the National Science Founda - tion cooperative agreement CCR - 912008 , and by the ARPA contract number DAAL03 - 91 - C - 0047 ( administered by the U . S . Army Research O(cid:14)ce ) . - DRAFT - 31 July 96 Chapter 2 Getting Started with ARPACK This chapter will describe the basic structure of ARPACK and how to begin using it for computing a few eigenvalues and eigenvectors of a symmetric matrix . Di(cid:14)cult problems and generalized problems will require one to use a shift - invert strategy that is based upon the use of a ( sparse - direct ) matrix factorization . These more sophisticated modes of operation are described in the next chapter . Example driver routines have been constructed for each problem type , computational mode , data type and precision . These drivers may be used as templates to construct a code for a speci(cid:12)c application by substituting the appropriate data structures , ma - trix factorizations , solvers and matrix - vector products . An explanation of how to use these drivers as templates and how to modify them for your own use is given in Appendix A ( Templates and Driver Routines ) . Each of the various drivers has been provided to address a typical situation arising from signi(cid:12)cant applications of eigenvalue calculations . We begin with a description of the ARPACK directory structure . We then use one of the sample drivers to illustrate the use ARPACK in the simplest mode of operation . 2 . 1 Directory Structure and Contents Once the ARPACK software has been unbundled as described in Chapter 1 , a directory structure will have been created . The top level directory is named ARPACK . The directory structure is pictured in Figure 2 . 1 . The ARMAKES subdirectory contains sample (cid:12)les with machine speci(cid:12)c information needed during the building of the ARPACK library . The BLAS and LAPACK subdi - rectories contain the necessary codes from the respective software libraries . The DOCUMENTS subdirectory contains (cid:12)les that have example templates of how to invoke the di(cid:11)erent computational modes o(cid:11)ered by ARPACK . Example driver programs that illustrate all of the computational modes , data types and precisions may be found in the EXAMPLES directory . Programs for banded , complex , nonsymmetric , symmetric eigenvalue problems and singular value decomposition may be found in the directories 17 2 . 2 . GETTING STARTED 18 BAND , COMPLEX , NONSYM , SYM , SVD respectively . Look at the README (cid:12)les in each subdirectory for further information . The SRC subdirectory contains all the ARPACK source codes . The UTIL subdirectory contain the various utility routines needed for printing results and timing the execution of the ARPACK subroutines . The archived library libarpack < PLATFORM > . a is created upon completion of the installation instructions . Here , < PLATFORM > denotes the environment where the ARPACK library is built . All of the subroutines other than those in the EXAMPLES directory are compiled and archived into libarpack < PLATFORM > . a . The installer should be aware that the BLAS and LAPACK directories contain a subset of routines from these packages that will require an additional megabyte of memory once they are compiled and archived . If these packages are already available on your system you may delete the BLAS and LAPACK directories provided here and point to the ones that are already installed on your system . This is easily done by modifying the (cid:12)le ARmake . inc as described in the README (cid:12)le in the top level directory ARPACK . To get started , we recommend that the user enter the SIMPLE subdirectory and issue the commands make dssimp ; dssimp > output This will compile , link , and execute the dssimp program . dssimp is a sample driver for the reverse communication interface to the ARPACK routine dsaupd which (cid:12)nds a few eigenvalues and eigenvectors of a symmetric matrix . This chapter discusses the use of dssimp for computing eigenvalues and eigen - vectors of a symmetric matrix using the simplest computational mode . There are additional drivers available for all of the computational modes , data types , and pre - cisions . These additional driver programs are in the EXAMPLES subdirectories . Each of them is self - contained and may be compiled and executed in a similar manner as described in the README (cid:12)les . This dssimp driver should serve as template to enable a user to create program to use dsaupd on a speci(cid:12)c problem in the simplest computational mode . All of the driver programs in the various EXAMPLES subdirectories are intended to be used in this way . The simple programs have more extensive documentation to aid in the understanding and conversion but essentially the same principle and structure apply to all of the driver programs . 2 . 2 Getting Started The collection of driver programs mentioned above have been constructed to illustrate how to use ARPACK in a straightforward way to solve some of the most frequently occurring eigenvalue problems . The purpose of this section and the corresponding simple codes is to provide a means to get started with ARPACK as quickly as pos - sible . These codes may be used as templates that are easily altered to solve new - DRAFT - 31 July 96 CHAPTER 2 . GETTING STARTED WITH ARPACK 19 Figure 2 . 1 : The ARPACK directory structure . ARPACK - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - / / / | \ \ \ ARMAKES BLAS DOCUMENTS | LAPACK SRC UTIL | EXAMPLES - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - / / | \ \ \ SIMPLE BAND SVD SYM NONSYM COMPLEX Table 2 . 1 : List of the simple drivers illustrating the use of ARPACK . NAME PURPOSE [ d , s ] ssimp Real symmetric driver [ d , s ] nsimp Real non - symmetric driver [ z , c ] nsimp Complex ( Hermitian or general ) problems after a few straightforward changes . The available simple drivers are listed in Table 2 . 1 . These codes may be found in the EXAMPLES / SIMPLE directory . 2 . 3 An Example for a Symmetric Eigenvalue Problem In this section , the simple code dssimp is discussed . All of the other example drivers are similar in nature . This particular example program illustrates the simplest com - putational mode of using ARPACK in considerable detail . dssimp shows how to use ARPACK to (cid:12)nd a few eigenvalues (cid:21) and corresponding eigenvectors x for the standard eigenvalue problem : Ax = x(cid:21) where A is an n by n real symmetric matrix . The main points illustrated are : (cid:15) How to declare su(cid:14)cient memory to (cid:12)nd nev eigenvalues . dssimp is set up to (cid:12)nd nev eigenvalues of largest magnitude LM . This may be reset to any one of the additional options ( SM , LA , SA , BE ) to (cid:12)nd other eigenvalues of interest . - DRAFT - 31 July 96 2 . 3 . AN EXAMPLE FOR A SYMMETRIC EIGENVALUE PROBLEM 20 (cid:15) Illustration of the reverse communication interface needed to utilize the top level ARPACK routine dsaupd . This routine computes the quantities needed to construct the desired eigenvalues and the the corresponding eigenvectors . (cid:15) How to extract the desired eigenvalues and eigenvectors from the quantities computed with dsaupd by using the ARPACK routine dseupd . This dssimp program is a driver for the subroutine dsaupd and it is set up to solve the following problem : (cid:15) Solve Ax = x(cid:21) in regular mode . Regular mode only uses matrix vector products involving A : (cid:15) The matrix A for this example is derived from the central di(cid:11)erence discretiza - tion of the 2 - dimensional Laplacian on the unit square with zero Dirichlet boundary conditions . (cid:15) The goal is to compute nev eigenvalues of largest magnitude and corresponding eigenvectors . The only thing that must be supplied in order to use this routine on your problem is to change the array dimensions and to supply a means to compute the matrix - vector product w Av on request from dsaupd . The selection of which eigenvalues to compute may be altered by changing the parameter which . Once usage of dsaupd in the simplest mode is understood , you may wish to explore the other available options such as solving generalized eigenvalue problems using a shift - invert computational mode . Some of these additional modes are described in the latter sections of this chapter and also in the (cid:12)le ex - sym . doc in DOCUMENTS directory . 2 . 3 . 1 The Reverse Communication Interface The easiest way to describe the reverse communication interface is through the ex - ample code segment shown in Figure 2 . 2 . Once the storage has been declared and the input parameters initialized , the reverse communication loop ( Fig . 2 . 2 ) is entered and repeated calls to dsaupd are made . On return the parameter ido will indicate the action to be taken . In this simple example , the only action taken is a matrix - vector product ( see call av in the code segment of Figure 2 . 2 ) . The more sophisticated shift - invert computational modes require more complicated actions but the basic idea remains the same . - DRAFT - 31 July 96 CHAPTER 2 . GETTING STARTED WITH ARPACK 21 c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | M A I N L O O P ( Reverse communication loop ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c 10 continue c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Repeatedly call the routine DSAUPD and take | c | actions indicated by parameter IDO until | c | either convergence is indicated or maxitr | c | has been exceeded . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call dsaupd ( ido , bmat , n , which , nev , tol , resid , & ncv , v , ldv , iparam , ipntr , workd , workl , & lworkl , info ) c if ( ido . eq . - 1 . or . ido . eq . 1 ) then c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Perform matrix vector multiplication | c | y < - - - OP * x | c | The user should supply his / her own | c | matrix vector multiplication routine | c | here that takes workd ( ipntr ( 1 ) ) as | c | the input , and return the result to | c | workd ( ipntr ( 2 ) ) . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call av ( nx , workd ( ipntr ( 1 ) ) , workd ( ipntr ( 2 ) ) ) c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | L O O P B A C K to call DSAUPD again . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c go to 10 c end if Figure 2 . 2 : The reverse communication interface in example program dssimp . - DRAFT - 31 July 96 2 . 3 . AN EXAMPLE FOR A SYMMETRIC EIGENVALUE PROBLEM 22 Table 2 . 2 : Parameters for the top level ARPACK routines . ido Reverse communication (cid:13)ag . nev The number of requested eigenvalues to compute . ncv The number of Lanczos basis vectors to use through the course of the computation . bmat Indicates whether the problem is standard bmat = ` I ' or generalized ( bmat = ` G ' ) . which Speci(cid:12)es which eigenvalues of A are to be computed . tol Speci(cid:12)es the relative accuracy to which eigenvalues are to be computed . iparam Speci(cid:12)es the computational mode , number of IRAM iterations , the implicit shift strategy , and outputs various informational parameters upon completion of IRAM . 2 . 3 . 2 Post Processing for Eigenvalues and Eigenvectors If dsaupd indicates that convergence has taken place , then various steps may be taken to recover the results in a useful form . This is done through the subroutine dseupd and is illustrated in Figure 2 . 3 . 2 . 3 . 3 Setting up the problem To set up the problem , the user needs to specify the number of eigenvalues to compute , which eigenvalues are of interest , the number of basis vectors to use , and whether or not the problem is standard or generalized . These items are controlled with the parameters listed in Table 2 . 2 . The simple codes described in this chapter are set up to solve the standard eigen - value problem using only matrix - vector products w Av . Generalized eigenvalue problems require selection of another mode . These are addressed in Chapter 3 . The value of ncv must be at least nev + 1 : However , setting ncv > 2(cid:1)nev is recommended . The options available for which include ` LA ' and ` SA ' for the algebraically largest and smallest eigenvalues , ` LM ' and ` SM ' for the eigenvalues of largest or smallest magnitude , and ` BE ' for the simultaneous computation of the eigenvalues at both ends of the spectrum . For a given problem , some of these options may converge more rapidly than others due to the approximation properties of the IRLM as well as the distribution of the eigenvalues of A : Convergence behavior can be quite di(cid:11)erent for - DRAFT - 31 July 96 CHAPTER 2 . GETTING STARTED WITH ARPACK 23 c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | No fatal errors occurred . | c | Post - Process using DSEUPD . | c | | c | Computed eigenvalues may be extracted . | c | | c | Eigenvectors may be also computed now if | c | desired . ( indicated by rvec = . true . ) | c | | c | The routine DSEUPD is called to do this | c | post processing ( Other modes may require | c | more complicated post processing than | c | mode1 . ) | c | | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c rvec = . true . c call dseupd ( rvec , ' All ' , select , d , v , ldv , sigma , & bmat , n , which , nev , tol , resid , ncv , v , ldv , & iparam , ipntr , workd , workl , lworkl , ierr ) c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Eigenvalues are returned in the first column | c | of the two dimensional array D and the | c | corresponding eigenvectors are returned in | c | the first NCONV ( = IPARAM ( 5 ) ) columns of the | c | two dimensional array V if requested . | c | Otherwise , an orthogonal basis for the | c | invariant subspace corresponding to the | c | eigenvalues in D is returned in V . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c Figure 2 . 3 : Post Processing for Eigenvalues and Eigenvectors using desupd . - DRAFT - 31 July 96 2 . 3 . AN EXAMPLE FOR A SYMMETRIC EIGENVALUE PROBLEM 24 various settings of the which parameter . For example , if the matrix is inde(cid:12)nite then setting which = ` SM ' will require interior eigenvalues to be computed and the Lanczos process may require many steps before these are resolved . For a given ncv , the computational work required is proportional to n (cid:1) ncv 2 FLOPS . Setting nev and ncv for optimal performance is very much problem de - pendent . If possible , it is best to avoid setting nev in a way that will split clusters of eigenvalues . For example , if the the (cid:12)ve smallest eigenvalues are positive and on the order of 10 (cid:0)3 and the sixth smallest eigenvalue is on the order of 10 (cid:0)1 then it is better to ask for nev = 5 than for nev = 3 even if the three smallest are the only ones of interest . Setting the optimal value of ncv relative to nev is not completely understood . As with the choice of which , it depends upon the underlying approxima - tion properties of the IRLM as well as the distribution of the eigenvalues of A : As a rule of thumb , ncv (cid:21) 2 (cid:1) nev is reasonable . There are tradeo(cid:11)s due to the cost of the user supplied matrix - vector products and the cost of the implicit restart mechanism and the cost of maintaining the orthogonality of the Lanczos vectors . If the user sup - plied matrix - vector product is relatively cheap , then a smaller value of ncv may lead to more user matrix - vector products , but an overall decrease in computation time . Chapter 4 will discuss these issues in more detail . 2 . 3 . 4 Storage Declarations The program is set up so that the setting of the three parameters maxn , maxnev , maxncv will automatically declare all of the work space needed to run dsaupd on a given problem . The declarations allow a problem size of N (cid:20) maxn , computation of nev (cid:20) maxnev eigenvalues , and using at most ncv (cid:20) maxncv Lanczos basis vectors during the IRLM . The user may override the default settings used for the example problem by modifying maxn , maxnev and maxncv in the following parameter statement . integer maxn , maxnev , maxncv , ldv parameter ( maxn = 256 , maxnev = 10 , maxncv = 25 , ldv = maxn ) These parameters are used in the code segment listed in Figure 2 . 3 . 4 for declaring all of the output and work arrays needed by the ARPACK subroutines dsaupd and dseupd . 2 . 3 . 5 Stopping Criterion The stopping criterion is determined by the user is speci(cid:12)ed by the parameter tol . The default value for tol is machine precision (cid:15)M : There are several things to consider when setting this parameter . In absence of all other considerations , one should expect a computed eigenvalue (cid:21) c to satisfy j(cid:21)c (cid:0) (cid:21)tj (cid:20) tol (cid:1) j(cid:21)cj ; - DRAFT - 31 July 96 CHAPTER 2 . GETTING STARTED WITH ARPACK 25 c c % - - - - - - - - - - - - - - % c | Local Arrays | c % - - - - - - - - - - - - - - % c Double precision & v ( ldv , maxncv ) , workl ( maxncv * ( maxncv + 8 ) ) , & workd ( 3 * maxn ) , d ( maxncv , 2 ) , resid ( maxn ) , & ax ( maxn ) logical select ( 1 ) integer iparam ( 11 ) , ipntr ( 11 ) Figure 2 . 4 : Storage declarations needed for ARPACK subroutine dsaupd where (cid:21)t is the eigenvalue of A closet to (cid:21)c : Typically , the smaller the value of tol , the more work required to satisfy the stopping criterion . However , setting tol too large may cause eigenvalues to be missed when they are multiple or very tightly clustered . It is also possible to set tol so small that convergence never occurs . There may be complications when the matrix A is non - normal or when the eigenvalues of interest are clustered near the origin . Further details are provided in Chapter 4 . 2 . 3 . 6 Initial Parameter Settings The reverse communication (cid:13)ag is denoted by ido . This parameter must be initially set to 0 before the (cid:12)rst call to dsaupd . During the course of the IRLM , ido is used to indicate the action to be taken by the user when control is returned to the program calling dsaupd . Various algorithmic modes may be selected through the settings of the entries in the integer array iparam . The most important of these is the value of iparam ( 7 ) which speci(cid:12)es the computational mode to use . The selection in this simple example is iparam ( 7 ) = 1 indicating mode = 1 is to be used and this only requires matrix - vector products . Convergence can be greatly enhanced through the the use of the shift - invert computational modes provided . These additional modes are described in Chapter 3 . In addition , iparam ( 1 ) speci(cid:12)es the shift selection strategy to be used with the implicit restarting mechanism described in Chapter 4 . Setting iparam ( 1 ) = 1 as in the example will specify the so called exact shift strategy . Exact shifts are recommended unless the user has a very good reason based upon a - priori information and an expert knowledge of the underlying IRLM to specify an alternative . The maximum number of IRLM iterations allowed must be speci(cid:12)ed in iparam ( 3 ) . In specifying this parameter , the user should keep in mind that an IRLM iteration - DRAFT - 31 July 96 2 . 3 . AN EXAMPLE FOR A SYMMETRIC EIGENVALUE PROBLEM 26 include ' debug . h ' ndigit = - 3 logfil = 6 msgets = 0 msaitr = 0 msapps = 0 msaupd = 1 msaup2 = 0 mseigt = 0 mseupd = 0 Figure 2 . 5 : How to initiate the trace debugging capability in ARPACK . costs approximately ncv (cid:0) nev user supplied matrix - vector products . In addition , 4 (cid:1) n (cid:1) ncv (cid:1) ( ncv (cid:0) nev ) FLOPS are needed for the work associated with an IRLM iteration . The integer argument lworkl sets the length of the work array workl . Its value is set at ncv (cid:1) ( ncv + 8 ) : 2 . 3 . 7 Setting the Starting Vector The parameter info should be set to 0 on the initial call to dsaupd unless the user wants to supply the starting vector that initializes the IRLM . Normally , this default is a reasonable choice . However , if this eigenvalue calculation is one of a sequence of closely related problems then convergence may be accelerated if a suitable starting vector is speci(cid:12)ed . Typical choices in this situation might be to use the (cid:12)nal value of the starting vector from the previously converged eigenvalue calculation ( that vector will already be in the (cid:12)rst column of V ) or to construct a starting vector by taking a linear combination using the computed eigenvectors from the previously converged eigenvalue calculation . If the starting vector is to be supplied , then it should be placed in the array resid and info should be set to 1 on entry to dsaupd . On completion , the parameter info may contain the value 0 indicating the iteration was successful or it may contain a nonzero value indicating an error or a warning condition . The meaning of a nonzero value returned in info may be found in the header comments of the subroutine dsaupd . 2 . 3 . 8 Trace Debugging Capability ARPACK provides a means to trace the progress of the computation as it proceeds . Various levels of output may be speci(cid:12)ed from no output level = 0 to voluminous - DRAFT - 31 July 96 CHAPTER 2 . GETTING STARTED WITH ARPACK 27 level = 3 . The code segment listed in Figure 2 . 5 gives an example of the statements that may be used within the calling program to initiate and request this output . The include statement sets up the storage declarations that are solely associated with this trace debugging feature . The parameter ndigit speci(cid:12)es the number of decimal digits and the width of the output lines . A positive or negative value of ndigit speci(cid:12)es that 132 or 80 columns , respectively , are used during output . The parameter logfil speci(cid:12)es the logical unit number of the output (cid:12)le . The values of the remaining parameters indicate the output levels from the indicated routines . For example msaitr indicates the level of output requested from the subroutine dsaitr . The above con(cid:12)guration will give a breakdown of the number of matrix vector prod - ucts required , the total number of iterations , the number of re - orthogonalization steps and an estimate of the time spent in each routine and phase of the computation . Fig - ure 2 . 6 displays the output produced by the above settings . The user is encouraged to experiment with the other settings once some familiarity has been gained with the routines . See Appendix B for a detailed discussion of the Trace Debugging Capabili - ties . - DRAFT - 31 July 96 2 . 3 . AN EXAMPLE FOR A SYMMETRIC EIGENVALUE PROBLEM 28 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Symmetric implicit Arnoldi update code = = Version Number : 2 . 1 = = Version Date : 11 / 15 / 95 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Summary of timing statistics = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Total number update iterations = 8 Total number of OP * x operations = 125 Total number of B * x operations = 0 Total number of reorthogonalization steps = 125 Total number of iterative refinement steps = 0 Total number of restart steps = 0 Total time in user OP * x operation = 0 . 020002 Total time in user B * x operation = 0 . 000000 Total time in Arnoldi update routine = 0 . 210021 Total time in ssaup2 routine = 0 . 190019 Total time in basic Arnoldi iteration loop = 0 . 110011 Total time in reorthogonalization phase = 0 . 070007 Total time in ( re ) start vector generation = 0 . 000000 Total time in trid eigenvalue subproblem = 0 . 040004 Total time in getting the shifts = 0 . 000000 Total time in applying the shifts = 0 . 040004 Total time in convergence testing = 0 . 000000 Figure 2 . 6 : Output from a Debug session for dsaupd . - DRAFT - 31 July 96 Chapter 3 General Use of ARPACK This chapter will describe the complete structure of the reverse communication inter - face to the ARPACK codes . Numerous computational modes are available , including several shift - invert strategies designed to accelerate convergence . Two of the more sophisticated modes will be described in detail . The remaining ones are quite simi - lar in principle , but require slightly di(cid:11)erent tasks to be performed with the reverse communication interface . This chapter is structured as follows . The naming conventions used in ARPACK , and the data types and precisions available are described in x 3 . 1 . Spectral transforma - tions are discussed in x 3 . 2 . Spectral transformations are usually extremely e(cid:11)ective but there are a number of problem dependent issues that determine which one to use . In x 3 . 3 we describe the reverse communication interface needed to exercise the various shift - invert options . Each shift - invert option is speci(cid:12)ed as a computational mode and all of these are summarized in the remaining sections . There is a subsection for each problem type and hence these sections are quite similar and repetitive . Once the basic idea is understood , it is probably best to turn directly to the subsection that describes the problem setting that is most interesting to you . Perhaps the easiest way to rapidly become acquainted with the modes of ARPACK is to run the example driver routines ( see Appendix A ) that have been supplied for each of the modes . These may be used as templates and adapted to solve speci(cid:12)c problems . 3 . 1 Naming Conventions , Precisions and Types There are two user interface subroutines needed to use ARPACK . They are aupd for the implicitly restarted Arnoldi method and eupd for computing either an orthogo - nal basis for a selected invariant subspace or a set of eigenvectors after convergence of aupd . If a spectral transformation is used , eupd transforms the computed eigen - values for the problem Ax = Mx(cid:21) : Both aupd and eupd are available for several combination of problem type ( symmetric and nonsymmetric ) , data type ( real , com - 29 3 . 2 . SHIFT AND INVERT SPECTRAL TRANSFORMATION MODE 30 Table 3 . 1 : Available precisions and data types for ARPACK . First letter Precision Data Type s Single Real d Double Real c Single Complex z Double Complex plex ) , and precision ( single , double ) . The (cid:12)rst letter ( s , d , c , z ) denotes precision and data type . The second letter denotes whether the problem is symmetric ( s ) or nonsymmetric ( n ) . Table 3 . 1 lists the possibilities . Thus , dnaupd is the routine to use if the problem is a double precision nonsym - metric ( standard or generalized ) problem and dneupd is the post - processing routine to use in conjunction with dnaupd to recover eigenvalues and eigenvectors of the original problem upon convergence . For complex matrices one should use naupd and neupd with the (cid:12)rst letter either c or z regardless of whether the problem is Hermitian or non - Hermitian . Table 3 . 2 lists the double precision routines available . 3 . 2 Shift and Invert Spectral Transformation Mode The most general problem that may be solved with ARPACK is to compute a few selected eigenvalues and corresponding eigenvectors for Ax = Mx(cid:21) ( 3 . 2 . 1 ) where A and M are real or complex n (cid:2) n matrices . The shift and invert spectral transformation is used to enhance convergence to a desired portion of the spectrum . If ( x ; (cid:21) ) is a ( generalized ) eigen - pair for ( A ; M ) and (cid:27) 6 = (cid:21) then ( A (cid:0) (cid:27)M ) (cid:0)1 Mx = x(cid:18) where (cid:18) = 1 (cid:21) (cid:0) (cid:27) : ( 3 . 2 . 2 ) This transformation is e(cid:11)ective for (cid:12)nding eigenvalues near (cid:27) since the nev eigen - values (cid:18)j of C (cid:17) ( A (cid:0) (cid:27)M ) (cid:0)1 M that are largest in magnitude correspond to the nev eigenvalues (cid:21)j of the original problem that are nearest to the shift (cid:27) in absolute value . These transformed eigenvalues of largest magnitude are precisely the eigenval - ues that are easy to compute with a Krylov method . Once they are found , they may be transformed back to eigenvalues of the original problem . The direct relation is (cid:21)j = (cid:27) + 1 = (cid:18)j ; - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 31 Table 3 . 2 : Double Precision Top level routines in ARPACK subdirectory SRC . ROUTINE DESCRIPTION dsaupd Top level reverse communication interface to solve real double precision symmetric problems . dseupd Post processing routine used to compute eigenvectors associated with the computed eigenvalues . This requires output from a converged application of dsaupd . dnaupd Top level reverse communication interface to solve real double precision non - symmetric problems . dneupd Post processing routine used to compute eigenvectors and / or Schur vectors corresponding to the invariant subspace associated with the computed eigenvalues . This requires output from a converged application of dnaupd . znaupd Top level reverse communication interface to solve double precision complex arithmetic problems . This routine should be used for both Hermitian and Non - Hermitian problems . zneupd Post processing routine used to compute eigenvectors and / or Schur vectors corresponding to the invariant subspace associated with the computed eigenvalues in complex arithmetic . This requires output from a converged application of znaupd . - DRAFT - 31 July 96 3 . 2 . SHIFT AND INVERT SPECTRAL TRANSFORMATION MODE 32 and the eigenvector xj associated with (cid:18)j in the transformed problem is also an ( generalized ) eigenvector of the original problem corresponding to (cid:21)j : Usually , the IRAM will rapidly obtain good approximations to the eigenvalues of C of largest magnitude . However , to implement this transformation , one must provide a means to solve linear systems involving A (cid:0) (cid:27)M either with a matrix factorization or with an iterative method . In general , C will be non - Hermitian even if A and M are both Hermitian . How - ever , this is easily remedied . The assumption that M is Hermitian positive de(cid:12)nite implies that the bi - linear form < x ; y > (cid:17) x T My is an inner product . If M is positive semi - de(cid:12)nite and singular , then a semi - inner product results . It is easy to show that if A is Hermitian ( self - adjoint ) then so is C ( with respect to the inner product de(cid:12)ned by M ) . Therefore , symmetry will be preserved if we force the computed basis vectors to be orthogonal in this ( semi ) inner product . Implementing this M - orthogonality requires the user to also provide a matrix - vector product w Mv on request along with each application of C . In the following sections we shall discuss some of the more familiar transformations to the standard eigenproblem . However , when M is positive ( semi ) de(cid:12)nite , we recommend using the shift - invert spectral transformation with M - inner products if at all possible . This is a far more robust transformation when M is ill - conditioned or singular . With a little extra manipulation ( provided automatically in eupd ) the ( semi - ) inner product induced by M prevents corruption of the computed basis vectors by roundo(cid:11) - error associated with the presence of in(cid:12)nite eigenvalues . These very ill conditioned eigenvalues are generally associated with a singular or highly ill - conditioned M : A detailed discussion of this theory may be found in Chapter 4 . Shift - invert spectral transformations are very e(cid:11)ective and should even be used on standard problems ( M = I ) whenever possible . This is particularly true when interior eigenvalues are sought or when the desired eigenvalues are clustered . If one has a generalized problem ( M 6 = I ) , then one must provide a way to solve linear systems with either A , M or a linear combination of the two matrices in order to use ARPACK . If possible , the user should probably use a sparse direct method to factor the appropriate matrix . If an iterative method is used for the linear system solves , the accuracy of the solutions must be commensurate with the convergence tolerance used for ARPACK . Usually , a slightly more stringent tolerance must be required of the iterative linear system solves relative to the desired accuracy of the eigenvalue calculation . The main drawback with using the shift - invert spectral transformation is that the coe(cid:14)cient matrix A (cid:0) (cid:27)M is typically inde(cid:12)nite in the Hermitian case and has 0 in the interior of the convex hull of the spectrum in the non - Hermitian case . These are typically the most di(cid:14)cult situations for an iterative method ( and also with a sparse direct method in a parallel setting ) . The decision to whether use a spectral transformation on a standard eigevalue - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 33 problem ( M = I ) or to use one of the simple modes described in Chapter 2 is problem dependent . The simple modes have the advantage that one only need supply a matrix vector product w Av . However , this approach is usually only successful for problems where extremal non - clustered eigenvalues are sought . In non - Hermtian problems , extremal means eigenvalues near extreme points ( vertices ) of the convex hull of the spectrum of A . For Hermitian problems , extremal means eigenvalues at the left or right end point of the spectrum of A . The notion of non - clustered ( or well separated ) is di(cid:14)cult to de(cid:12)ne without going into considerable detail . A simplistic notion of a well - separated eigenvalue (cid:21)i for a Hermitian problem would be j(cid:21)i (cid:0) (cid:21)jj > (cid:28)j(cid:21)n (cid:0) (cid:21)1j for all j 6 = i with (cid:28) > > (cid:15)M . Unless a matrix vector product is quite di(cid:14)cult to code or extremely expensive computationally , it is probably worth trying to use the simple mode (cid:12)rst if you are seeking extremal eigenvalues . The remainder of this section discusses additional transformations that may be applied to convert a generalized eigenproblem to a standard eigenproblem . These are appropriate when M is well conditioned ( Hermitian or non - Hermitian ) . 3 . 2 . 1 M is Hermitian Positive De(cid:12)nite If M is Hermitian positive de(cid:12)nite and well conditioned ( kMk (cid:1) kM (cid:0)1 k is of modest size ) , then computing the Cholesky factorization M = LL T and converting equa - tion ( 3 . 2 . 1 ) to ( L (cid:0)1 AL (cid:0)T ) y = y(cid:21) where L T x = y provides a transformation to a standard eigenvalue problem . In this case , a request for a matrix vector product would be satis(cid:12)ed with the following three steps : 1 . Solve L T z = v for z ; 2 . Matrix - vector multiply z Az ; 3 . Solve Lw = z for w : Upon convergence , a computed eigenvector y for ( L (cid:0)1 AL (cid:0)T ) is converted to an eigenvector x of the original problem by solving the the triangular system L T x = y : This transformation is most appropriate when A is Hermitian , M is Hermitian positive de(cid:12)nite and extremal eigenvalues are sought . This is because L (cid:0)1 AL (cid:0)T will be Hermitian when A is . If A is symmetric positive de(cid:12)nite and the smallest eigenvalues are sought , then it would be best to reverse the roles of A and M in the above description and ask for the largest algebraic eigenvalues or those of largest magnitude . Upon convergence , a computed eigenvalue ^ (cid:21) would then be converted to an eigenvalue of the original problem by the relation (cid:21) 1 = ^ (cid:21) : - DRAFT - 31 July 96 3 . 3 . REVERSE COMMUNICATION STRUCTURE FOR SHIFT - INVERT 34 3 . 2 . 2 M is NOT Hermitian Positive Semi { De(cid:12)nite If neither A nor M is Hermitian positive semi de(cid:12)nite , then a direct transformation to standard form is required . One simple way to obtain a direct transformation of equation ( 3 . 2 . 1 ) to a standard eigenvalue problem Cx = x(cid:21) is to multiply on the left by M (cid:0)1 which results in C = M (cid:0)1 A : Of course , one should not perform this transformation explicitly since it will most likely convert a sparse problem into a dense one . If possible , one should obtain a direct factorization of M and when a matrix - vector product is involving C called for , it may be accomplished with the following two steps : 1 . Matrix - vector multiply z Av ; 2 . Solve : Mw = z : Several problem dependent issues may modify this strategy . If M is singular or if one is interested in eigenvalues near a point (cid:27) then a user may choose to work with C (cid:17) ( A (cid:0) (cid:27)M ) (cid:0)1 M but without using the M - inner products discussed previously . In this case the user will have to transform the converged eigenvalues (cid:18)j of C to eigenvalues (cid:21)j of the original problem . 3 . 3 Reverse Communication Structure for Shift - Invert The reverse communication interface routine for all problem types is aupd . If the eigenvalue problem ( 3 . 2 . 1 ) is a double precision non - symmetric one , then the subrou - tine to use is dnaupd . First the reverse communication loop structure will be described and then the details and nuances of the problem set up will be discussed . We shall use the symbol OP for the operator that is applied to vectors in the Arnoldi / Lanczos process and B will stand for the matrix to use in the weighted inner product de - scribed previously . For the shift - invert spectral transformation mode , OP denotes ( A (cid:0) (cid:27)M ) (cid:0)1 M and B denotes M . They will stand for di(cid:11)erent matrices in each of the various modes . The basic idea is to set up a loop that repeatedly calls aupd . On each return , one must either apply OP or B to a speci(cid:12)ed vector or exit the loop depending upon the value returned in the reverse communication parameter ido . 3 . 3 . 1 Shift and invert on a Generalized Eigen - problem The above code segments shown in Figures 3 . 1 { 3 . 2 illustrate the reverse communica - tion loop for dnaupd in shift - invert mode for a generalized nonsymmetric eigenvalue problem . This loop structure will be identical for the symmetric problem . The only change needed is to replace dnaupd with dsaupd . The loop structure is also identical for complex arithmetic subroutine znaupd . - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 35 c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Call a routine FAC to factor the matrix ( A - SIGMA * M ) . | c | into L * U . | c | | c | A routine MV is called repeatedly below to form z = Mv . | c | | c | A routine SOLVE is used repeatedly below to solve | c | ( A - SIGMA * M ) w = z using the single LU factorization | c | provided by FAC . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call fac ( ( A - SIGMA * M ) , L , U ) c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | M A I N L O O P ( Reverse communication ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c 10 continue c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Repeatedly call the routine DNAUPD and take | c | actions indicated by parameter IDO . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call dnaupd ( ido , bmat , n , which , nev , tol , resid , & ncv , v , ldv , iparam , ipntr , workd , workl , & lworkl , info ) if ( ido . eq . - 1 ) then c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Perform y < - - - OP * x = inv [ A - SIGMA * M ] * M * x | c | to force the starting vector into the | c | range of OP . | c | x = workd ( ipntr ( 1 ) ) | c | y = workd ( ipntr ( 2 ) ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call mv ( workd ( ipntr ( 1 ) ) , workd ( ipntr ( 2 ) ) ) c Figure 3 . 1 : Reverse communication interface for Shift - Invert . - DRAFT - 31 July 96 3 . 3 . REVERSE COMMUNICATION STRUCTURE FOR SHIFT - INVERT 36 call solve ( L , U , workd ( ipntr ( 2 ) ) ) c c % - - - - - L O O P B A C K to call DSAUPD again . - - - - - - - % c go to 10 c else if ( ido . eq . 1 ) then c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Perform y < - - OP * x = inv [ A - sigma * M ] * M * x | c | M * x has been saved in workd ( ipntr ( 3 ) ) . | c | M * x = workd ( ipntr ( 3 ) | c | y = workd ( ipntr ( 2 ) ) . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call dcopy ( n , workd ( ipntr ( 3 ) ) , 1 , workd ( ipntr ( 2 ) ) , 1 ) call solve ( L , U , workd ( ipntr ( 2 ) ) ) c c % - - - - - L O O P B A C K to call DSAUPD again . - - - - - - - % c go to 10 c else if ( ido . eq . 2 ) then c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Perform y < - - - M * x | c | x = workd ( ipntr ( 1 ) ) | c | y = workd ( ipntr ( 2 ) ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call mv ( workd ( ipntr ( 1 ) ) , workd ( ipntr ( 2 ) ) ) c c % - - - - - L O O P B A C K to call DSAUPD again . - - - - - - - % c go to 10 end if Figure 3 . 2 : Reverse communication interface for Shift - Invert contd . - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 37 In this example shown in Figures 3 . 1 { 3 . 2 , the matrix M is assumed to be sym - metric and positive semi - de(cid:12)nite . In the structure above , the user will have to supply some routine such as fac to obtain a matrix factorization of A (cid:0) (cid:27)M that may re - peatedly be used to solve linear systems . Moreover , a routine needs to be provided in place of mv to perform the matrix - vector product z = Mv and as well as a routine in place of solve to solve ( A (cid:0) (cid:27)M ) w = z the resulting linear systems using the previously computed factorization . When convergence has taken place ( indicated by ido = 99 ) , the reverse commu - nication loop will be exited . Then , post - processing using the ARPACK subroutine dneupd must be done to recover the eigenvalues and corresponding eigenvectors of the original problem . When operating in Shift - invert mode , the eigenvalue selection parameter which is normally set to which = ' LM ' . The routine dneupd is then used to convert the converged eigenvalues of OP to eigenvalues of the original problem ( 3 . 2 . 1 ) . Also , when M is singular or ill - conditioned , the routine dneupd takes steps to purify the eigenvectors and rid them of numerical corruption from eigenvectors corresponding to near - in(cid:12)nite eigenvalues . These procedures are done automatically by the routine dneupd when operating in any one of the computational modes described above and later in this chapter . The user may wish to construct alternative computational modes using spectral transformations that are not addressed by any of the modes speci(cid:12)ed in this chapter . The reverse communication interface will easily accommodate these modi(cid:12)cations . However , it will most likely be necessary to construct explicit transformations of the eigenvalues of OP to eigenvalues of the original problem in these situations . 3 . 4 Using the Computational Modes The problem set up is similar for all of the available computational modes . In the previous section , a detailed description of the reverse communication loop for a speci(cid:12)c mode ( Shift - Invert for a Real Non - symmetric Generalized Problem ) was given . To use this or any of the other modes listed below , the user is strongly urged to modify one of the driver routine templates as described in Appendix A . The (cid:12)rst thing to do is decide the nature of the eigenvalues to be computed and whether or not a spectral transformation is required to compute them . Then one must formulate an e(cid:14)cient means to implement the action of the operator OP on a vector in order to to accomplish the spectral transformation . Also , one must decide if the use of a weighted inner product is advantageous . The relation between the eigenvalues of OP and the eigenvalues of the original problem must also be understood in order to make the appropriate speci(cid:12)cation of which in order to recover eigenvalues of interest for the original problem . The user must specify the number of eigenvalues to compute , which eigenvalues are of interest , the number of basis vectors to use , and whether or not the problem is standard or generalized . These items are controlled with the parameters listed in Table 2 . 2 of Chapter 2 . - DRAFT - 31 July 96 3 . 4 . USING THE COMPUTATIONAL MODES 38 call dnaupd ( ido , bmat , n , which , nev , tol , resid , ncv , v , ldv , & iparam , ipntr , workd , workl , lworkl , info ) . Figure 3 . 3 : Calling the ARPACK subroutine dnaupd . Setting nev and ncv for optimal performance is very much problem dependent . If possible , it is best to avoid setting nev in a way that will split clusters of eigenvalues . As a rule of thumb , ncv (cid:21) 2 (cid:1) nev is reasonable . There are tradeo(cid:11)s due to the cost of the user supplied matrix - vector products and the cost of the implicit restart mechanism . If the user supplied matrix - vector product is relatively cheap then a smaller value of ncv may lead to more user matrix - vector products and IRA iterations but an overall decrease in computation time . Convergence behavior can be quite di(cid:11)erent for various settings of the which parameter . The Arnoldi process tends to converge most readily to extreme points of the convex hull of the spectrum . Implicit restarting can be e(cid:11)ective in focusing on and isolating a selected set of eigenvalues near these extremes . In principle , implicit restarting could isolate eigenvalues in the interior , but in practice this is di(cid:14)cult and usually unsuccessful . If one is interested in eigenvalues near a point (cid:27) that is in the interior of the convex hull of the spectrum , a shift - invert strategy is usually required for reasonable convergence . The call to dnaupd is listed in Figure 3 . 3 . The integer ido is the reverse com - munication (cid:13)ag that will specify a requested action on return from dnaupd . The character * 1 parameter bmat speci(cid:12)es if this is a standard bmat = ` I ' or a gener - alized bmat = ` G ' problem . The integer n speci(cid:12)es the dimension of the problem . The character * 2 parameter which speci(cid:12)es the nev eigenvalues to be computed . The options for which di(cid:11)er depending on whether a Hermitian or non - Hermitian eigenvalue problem is to be solved . Tables 3 . 3 { 3 . 4 list the di(cid:11)erent selections possi - ble . The speci(cid:12)cation of problem type will be described separately but the reverse communication interface and loop structure is the same for each type of the three basic modes regular , regular - inverse , shift - invert ( standard or generalized ) . There are some additional specialized modes for symmetric problems ( Buckling and Cayley ) and for real non - symmetric problems with complex shifts applied in real arithmetic . The user is encouraged to examine the sample driver routines for these modes . The integer nev indicates the number of eigenvalues to compute and tol speci(cid:12)es the accuracy requested . The integer array iparam has eleven entries . On input , iparam ( 1 ) should be set to 0 if the user wishes to supply shifts for implicit restarting or to 1 if the default exact - shift strategy is requested . The entry iparam ( 1 ) should be set to 1 unless the user has a great deal of knowledge about the spectrum and about the IRAM and underlying theory . The entry iparam ( 3 ) should be set to the maximum number of implicit restarts allowed . The cost of an implicit restart - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 39 call dsaupd ( ido , bmat , n , which , nev , tol , resid , ncv , v , & ldv , iparam , ipntr , workd , workl , lworkl , info ) Figure 3 . 4 : Calling the ARPACK subroutine dsaupd . Table 3 . 3 : The various settings for the argument which in saupd WHICH DESCRIPTION ` LA ' Largest algebraic eigenvalues . ` SA ' Smallest algebraic eigenvalues . ` LM ' Eigenvalues largest in magnitude . ` SM ' Eigenvalues smallest in magnitude . ` BE ' Compute nev eigenvalues , half from each end of the spectrum . When nev is odd , compute one more from the high end than from the low end . step ( major iteration ) is on the order of 4n (cid:1) ( ncv (cid:0) nev ) Flops for the dense matrix operations and ncv - nev matrix - vector products w Av with the matrix A : On output , iparam ( 3 ) will contain the number of implicit restarts taken during the computation . With respect to shift - invert modes , entry iparam ( 7 ) is very important . The remaining entries of iparam are either no longer referenced or are output parameters . The legitimate values for iparam ( 7 ) di(cid:11)er with each problem type and will be listed below for each of them . 3 . 5 Computational Modes for Real Symmetric Problems The reverse communication interface subroutine for symmetric eigenvalue problems is dsaupd . The subroutine is called as shown in Figure 3 . 4 . The argument which may be any one of the settings listed in Table 3 . 3 . The following is a list of the spectral transformation options for symmetric eigen - value problems . In the following list , the speci(cid:12)cation of OP and B are given for the various modes . Also , the iparam ( 7 ) and bmat settings are listed along with the name of the sample driver for the given mode . The sample drivers listed here may be found in the EXAMPLES / SYM subdirectory . - DRAFT - 31 July 96 3 . 6 . POST - PROCESSING FOR EIGENVECTORS USING DSEUPD 40 1 . Regular mode ( iparam ( 7 ) = 1 , bmat = ' I ' ) . Use driver dsdrv1 . ( a ) Solve Ax = x(cid:21) in regular mode . ( b ) OP = A and B = I : 2 . Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' I ' ) . Use driver dsdrv2 . ( a ) Solve Ax = x(cid:21) in shift - invert mode . ( b ) OP = ( A (cid:0) (cid:27)I ) (cid:0)1 and B = I : 3 . Regular inverse mode ( iparam ( 7 ) = 2 , bmat = ' G ' ) . Use driver dsdrv3 . ( a ) Solve Ax = Mx(cid:21) in regular inverse mode . ( b ) OP = M (cid:0)1 A and B = M : 4 . Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' G ' ) . Use driver dsdrv4 . ( a ) Solve Ax = Mx(cid:21) in shift - invert mode . ( b ) OP = ( A (cid:0) (cid:27)M ) (cid:0)1 M and B = M : 5 . Buckling mode ( iparam ( 7 ) = 4 , bmat = ' G ' ) . Use driver dsdrv5 . ( a ) Solve Kx = KGx(cid:21) in Buckling mode . ( b ) OP = ( K (cid:0) (cid:27)KG ) (cid:0)1 K and B = K : 6 . Cayley mode ( iparam ( 7 ) = 5 , bmat = ' G ' ) . Use driver dsdrv6 . ( a ) Solve Ax = Mx(cid:21) in Cayley mode . ( b ) OP = ( A (cid:0) (cid:27)M ) (cid:0)1 ( A + (cid:27)M ) and B = M : 3 . 6 Post - Processing for Eigenvectors Using dseupd On the (cid:12)nal return from dsaupd ( indicated by ido = 99 ) , the error (cid:13)ag info must be checked . If info = 0 then no fatal errors have occurred and it is time to post - process using dseupd to get eigenvalues of the original problem and the corresponding eigenvectors if desired . In the case shown here ( shift - invert and generalized ) , there are some subtleties to recovering eigenvectors when M is ill - conditioned . This process is called eigenvector puri(cid:12)cation . It prevents eigenvectors from being corrupted with noise due to the presence of eigenvectors corresponding to near in(cid:12)nite eigenvalues ( See Chapter 4 ) . These operations are completely transparent to the user . The general calling sequence for dseupd is shown in Figure 3 . 5 . The input parameters bmat , n (cid:1)(cid:1)(cid:1) info are precisely the same parameters that appear in the calling sequence of dsaupd . It is VERY IMPORTANT that none of these parameters are altered between the (cid:12)nal return from dsaupd and the subsequent call to dseupd . - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 41 c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | No fatal errors occurred . | c | Post - Process using DSEUPD . | c | | c | Computed eigenvalues may be extracted . | c | | c | Eigenvectors may also be computed now if | c | desired . ( indicated by rvec = . true . ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c rvec = . true . c call dseupd ( rvec , ' All ' , select , d , v , ldv , sigma , & bmat , n , which , nev , tol , resid , ncv , v , ldv , & iparam , ipntr , workd , workl , lworkl , ierr ) c Figure 3 . 5 : Post - Processing for Eigenvectors Using dseupd . There is negligible additional cost to obtain eigenvectors . An orthonormal ( Lanc - zos ) basis is always computed . In the above example , this basis is overwritten with the eigenvectors in the array v . Both basis sets may be obtained if desired but there is an additional storage cost of n (cid:1) nev if both are requested ( in this case a separate n by nev array z must be supplied ) . The approximate eigenvalues of the original problem are returned in ascending algebraic order in the array d . If it is desirable to retain the Lanczos basis in v and storage is an issue , the user may elect to call this routine once for each desired eigenvector and store it peripherally . There is also the option of computing a selected set of these vectors with a single call . The input parameters that must be speci(cid:12)ed are (cid:15) The logical variable rvec = . true . if eigenvectors are requested . false . if only eigenvalues are desired . (cid:15) The character * 1 parameter howmny that speci(cid:12)es how many eigenvectors are desired . howmny = ' A ' : compute nev eigenvectors ; howmny = ' S ' : compute some of the eigenvectors , speci(cid:12)ed by the logical array select . (cid:15) sigma should contain the value of the shift used if iparam ( 7 ) = 3 , 4 , 5 . It is not referenced if iparam ( 7 ) = 1 or 2 . - DRAFT - 31 July 96 3 . 7 . COMPUTATIONAL MODES FOR REAL NON - SYMMETRIC PROBLEMS42 call dnaupd ( ido , bmat , n , which , nev , tol , resid , ncv , v , ldv , & iparam , ipntr , workd , workl , lworkl , info ) Figure 3 . 6 : Calling the ARPACK subroutine dnaupd . Table 3 . 4 : The various settings for the argument which in naupd WHICH Description ` LM ' Eigenvalues of largest magnitude . ` SM ' Eigenvalues of smallest magnitude . ` LR ' Eigenvalues of largest real part . ` SR ' Eigenvalues of smallest real part . ` LI ' Eigenvalues of largest imaginary part . ` SI ' Eigenvalues of smallest imaginary part . 3 . 7 Computational Modes for Real Non - Symmetric Prob - lems The following subroutines are used to solve non - symmetric generalized eigenvalue problems in real arithmetic . These routines are appropriate when A is a general non - symmetric matrix and M is symmetric and positive semi - de(cid:12)nite . The reverse communication interface routine for the non - symmetric double precision eigenvalue problem is dnaupd . The routine is called as shown in Figure 3 . 6 . The speci(cid:12)cation of which nev eigenvalues is controlled by the character * 2 argument which . Table 3 . 4 lists the choices available . There are three di(cid:11)erent shift - invert modes for non - symmetric eigenvalue prob - lems . These modes are speci(cid:12)ed by setting the parameter entry iparam ( 7 ) = mode where mode = 1 , 2 , 3 , or 4 . In the following list , the speci(cid:12)cation of OP and B are given for the various modes . Also , the iparam ( 7 ) and bmat settings are listed along with the name of the sam - ple driver for the given mode . The sample drivers listed here may be found in the EXAMPLES / NONSYM subdirectory . 1 . Regular mode ( iparam ( 7 ) = 1 , bmat = ' I ' ) . Use driver dndrv1 . ( a ) Solve Ax = x(cid:21) in regular mode . - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 43 ( b ) OP = A and B = I : 2 . Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' I ' ) . Use driver dndrv2 with sigma a real shift . ( a ) Solve Ax = x(cid:21) in shift - invert mode . ( b ) OP = ( A (cid:0) (cid:27)I ) (cid:0)1 and B = I : 3 . Regular inverse mode ( iparam ( 7 ) = 2 , bmat = ' G ' ) . Use driver dndrv3 . ( a ) Solve Ax = Mx(cid:21) in regular inverse mode . ( b ) OP = M (cid:0)1 A and B = M : 4 . Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' G ' ) . Use driver dndrv4 with sigma a real shift . ( a ) Solve Ax = Mx(cid:21) in shift - invert mode . ( b ) OP = ( A (cid:0) (cid:27)M ) (cid:0)1 M and B = M : 5 . Complex Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' G ' ) . Use driver dndrv5 with sigma a complex shift . Must factor A (cid:0) (cid:27)M in complex arithmetic . ( a ) Solve Ax = Mx(cid:21) using complex shift in real arithmetic . ( b ) OP = Realf ( A (cid:0) (cid:27)M ) (cid:0)1 Mg and B = M : 6 . Complex Shift - invert mode ( iparam ( 7 ) = 4 , bmat = ' G ' ) . Use driver dndrv6 with sigma a complex shift . Must factor A (cid:0) (cid:27)M in complex arithmetic . ( a ) Solve Ax = Mx(cid:21) using complex shift in real arithmetic . ( b ) OP = Imagf ( A (cid:0) (cid:27)M ) (cid:0)1 Mg and B = M : Note that there are two shift - invert modes with complex shifts ( See dndrv5 and dndrv6 ) . Since (cid:27) is complex , these both require the factorization of the matrix A(cid:0)(cid:27)M in complex arithmetic even though both A and M are real . The only advantage of using this option instead of using the standard shift - invert mode in complex arithmetic with the routine znaupd is that all of the internal operations in the IRAM are executed in real arithmetic . This results in a factor of two savings in storage and a factor of four savings in arithmetic . There is additional post - processing that is somewhat more complicated than the other modes in order to get the eigenvalues and eigenvectors of the original problem . These modes are only recommended if storage is extremely critical . - DRAFT - 31 July 96 3 . 8 . POST - PROCESSING FOR EIGENVECTORS USING DNEUPD 44 c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | No fatal errors occurred . | c | Post - Process using DNEUPD . | c | | c | Computed eigenvalues may be extracted . | c | | c | Eigenvectors may also be computed now if | c | desired . ( indicated by rvec = . true . ) | c | | c | The real part of the eigenvalue is returned | c | in the first column of the two dimensional | c | array D , and the IMAGINARY part is returned | c | in the second column of D . The corresponding | c | eigenvectors are returned in the first NEV | c | columns of the two dimensional array V if | c | requested . Otherwise , an orthogonal basis | c | for the invariant subspace corresponding to | c | the eigenvalues in D is returned in V . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c rvec = . true . call dneupd ( rvec , ' A ' , select , d , d ( 1 , 2 ) , v , ldv , & sigmar , sigmai , workev , bmat , n , which , nev , tol , & resid , ncv , v , ldv , iparam , ipntr , workd , & workl , lworkl , ierr ) c Figure 3 . 7 : Post - Processing for Eigenvectors Using dneupd . 3 . 8 Post - Processing for Eigenvectors Using dneupd On the (cid:12)nal return from dnaupd ( indicated by ido = 99 ) , the error (cid:13)ag info must be checked . If info = 0 , then no fatal errors have occurred and it is time to post - process using dneupd to get eigenvalues of the original problem and the corresponding eigenvectors if desired . In the case shown here ( shift - invert and generalized ) , there are some subtleties to recovering eigenvectors when M is ill - conditioned . This process is called eigenvector puri(cid:12)cation . It prevents eigenvectors from being corrupted with noise due to the presence of eigenvectors corresponding to near in(cid:12)nite eigenvalues ( See Chapter 4 ) . These operations are completely transparent to the user . The general calling sequence for dseupd is shown in Figure 3 . 7 . The input parameters bmat , n (cid:1)(cid:1)(cid:1) info are precisely the same parameters that appear in the calling sequence of dnaupd . It is VERY IMPORTANT that none of these parameters are altered between the (cid:12)nal return from dsaupd and the subsequent call to dneupd . The approximate eigenvalues of the original problem are returned with real part - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 45 array dr and imaginary part in the array di . Since the problem is real , complex eigenvalues must come in complex conjugate pairs . There is negligible additional cost to obtain eigenvectors . An orthonormal ( Schur ) basis for the invariant subspace corresponding to the converged approximate eigenvalues is always computed . In the above example , this basis is overwritten with the eigenvectors in the array v . When the eigenvectors corresponding to a complex conjugate pair of eigenvaues are com - puted , the real and imaginary parts of the vector associated with the eigenvalue with positive imaginary part , are in columns j , and j + 1 , respectively . Both basis sets may be obtained if desired but there is an additional storage cost of n (cid:1) nev if both are requested ( in this case a separate n by nev array z must be supplied ) . In some cases it may be desirable to have both basis sets . The eigenvector basis will be very ill - conditioned if at least one of the computed eigenvalues is ill - conditioned . However , the corresponding Schur basis is always well - conditioned ( it is an orthogonal basis for the approximate invariant subspace ) . If it is desirable to retain the Schur basis in v and storage is an issue , the user may elect to call this routine once for each desired eigenvector and store it peripherally . There is also the option of computing a selected set of these vectors with a single call . The input parameters that must be speci(cid:12)ed are (cid:15) The logical variable rvec = . true . if eigenvectors are requested . false . if only eigenvalues are desired . (cid:15) The character * 1 parameter howmny speci(cid:12)es how many eigenvectors are de - sired . howmny = ' A ' : compute nev eigenvectors ; howmny = ' P ' : Compute nev Schur vectors ; howmny = ' S ' : compute some of the eigenvectors , speci(cid:12)ed by the logical array select . (cid:15) sigmar , sigmai should contain the real and imaginary portions , respectively , of the shift that was used if iparam ( 7 ) = 3 or 4 . Neither is referenced if iparam ( 7 ) = 1 or 2 . 3 . 9 Computational Modes for Complex Problems This section describes the solution of complex eigenvalue problems . The reverse com - munication interface subroutine for the double precision complex eigenvalue problem is znaupd . This routine is to be used for both Hermitian and non - Hermitian prob - lems . The routine is called as shown in Figure 3 . 8 . It should be noted that the calling sequences for znaupd and zneupd di(cid:11)er slightly from those of dnaupd and dneupd . The main di(cid:11)erence is that an additional work array rwork is required by znaupd and is not required bydnaupd . Occasionally , when using znaupd on a complex Hermitian problem , eigenvalues will be returned with small but non - zero imaginary part due the unavoidable round - o(cid:11) - DRAFT - 31 July 96 3 . 9 . COMPUTATIONAL MODES FOR COMPLEX PROBLEMS 46 call znaupd ( ido , bmat , n , which , nev , tol , resid , ncv , v , & ldv , iparam , ipntr , workd , workl , lworkl , rwork , info ) Figure 3 . 8 : Calling the ARPACK subroutine znaupd . errors . These should be ignored unless they are signi(cid:12)cant with respect to the eigenval - ues of largest magnitude that have been computed . There is very little computational penalty for using the non - Hermitian routines in this case . The only additional cost is to compute eigenvalues of a Hessenberg rather than a tridiagonal matrix . For the problem con(cid:12)gurations this software is designed to solve , the size of these matrices are small enough that the di(cid:11)erences in computational cost are negligible compared to the major O ( n ) work that is required . The integer ido is the reverse communication (cid:13)ag that speci(cid:12)es a requested ac - tion on return from dnaupd . The character * 1 parameter bmat speci(cid:12)es if this is a standard bmat = ' I ' or a generalized bmat = ' G ' problem . The integer n speci(cid:12)es the dimension of the problem . The character * 2 parameter which and has the same possible values as for subroutine dnaupd listed in Table 3 . 4 . There are three shift - invert modes for complex problems . These modes are speci - (cid:12)ed by setting the parameter entry iparam ( 7 ) = mode where mode = 1 , 2 , or 3 . In the following list , the speci(cid:12)cation of OP and B are given for the various modes . Also , the iparam ( 7 ) and bmat settings are listed along with the name of the sam - ple driver for the given mode . The sample drivers listed here may be found in the EXAMPLES / COMPLEX subdirectory . 1 . Regular mode ( iparam ( 7 ) = 1 , bmat = ' I ' ) . Use driver zndrv1 . ( a ) Solve Ax = x(cid:21) in regular mode . ( b ) OP = A and B = I : 2 . Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' I ' ) . Use driver zndrv2 . ( a ) Solve Ax = x(cid:21) in shift - invert mode . ( b ) OP = ( A (cid:0) (cid:27)I ) (cid:0)1 and B = I : 3 . Regular inverse mode ( iparam ( 7 ) = 2 , bmat = ' G ' ) . Use driver zndrv3 . ( a ) Solve Ax = Mx(cid:21) in regular inverse mode . ( b ) OP = M (cid:0)1 A and B = M : 4 . Shift - invert mode ( iparam ( 7 ) = 3 , bmat = ' G ' ) . Use driver zndrv4 . ( a ) Solve Ax = Mx(cid:21) in shift - invert mode . ( b ) OP = ( A (cid:0) (cid:27)M ) (cid:0)1 M and B = M : - DRAFT - 31 July 96 CHAPTER 3 . GENERAL USE OF ARPACK 47 c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | No fatal errors occurred . | c | Post - Process using CNEUPD . | c | | c | Computed eigenvalues may be extracted . | c | | c | Eigenvectors may also be computed now if | c | desired . ( indicated by rvec = . true . ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c rvec = . true . c call cneupd ( rvec , ' A ' , select , d , v , ldv , sigma , & workev , bmat , n , which , nev , tol , resid , ncv , v , & ldv , iparam , ipntr , workd , workl , lworkl , rwork , & ierr ) c Figure 3 . 9 : Post - Processing for Eigenvectors Using cneupd . 3 . 10 Post - Processing for Eigenvectors Using zneupd On the (cid:12)nal return from znaupd ( indicated by ido = 99 ) , the error (cid:13)ag info must be checked . If info = 0 , then no fatal errors have occurred and it is time to post - process using zneupd to get eigenvalues of the original problem and the corresponding eigenvectors if desired . In the case shown here ( shift - invert and generalized ) , there are some subtleties to recovering eigenvectors when M is ill - conditioned . This process is called eigenvector puri(cid:12)cation . It prevents eigenvectors from being corrupted with noise due to the presence of eigenvectors corresponding to near in(cid:12)nite eigenvalues ( See Chapter 4 ) . These operations are completely transparent to the user . The general calling sequence for dseupd is shown in Figure 3 . 9 . The input parameters bmat , n (cid:1)(cid:1)(cid:1) info are precisely the same parameters that appear in the calling sequence of znaupd . It is VERY IMPORTANT that none of these parameters are altered between the (cid:12)nal return from znaupd and the subsequent call to zneupd . There is negligible additional cost to obtain eigenvectors . An orthonormal ( Schur ) basis for the invariant subspace corresponding to the converged approximate eigen - values is always computed . In the above example , this basis is overwritten with the eigenvectors in the array v . Both basis sets may be obtained if desired but there is an additional storage cost of n (cid:1) nev if both are requested ( in this case a separate n by nev array z must be supplied ) . In some cases it may be very desirable to have both basis sets . The eigenvector basis will be very ill - conditioned if any of the com - puted eigenvalues is ill - conditioned . However , the corresponding Schur basis is always - DRAFT - 31 July 96 3 . 10 . POST - PROCESSING FOR EIGENVECTORS USING ZNEUPD 48 well - conditioned ( it is an orthonormal basis for the approximate invariant subspace ) . If it is desirable to retain the Schur basis in v and storage is an issue , the user may elect to call this routine once for each desired eigenvector and store it peripherally . There is also the option of computing a selected set of these vectors with a single call . The input parameters that must be speci(cid:12)ed are (cid:15) The logical variable rvec = . true . if eigenvectors are requested . false . if only eigenvalues are desired . (cid:15) The Character * 1 parameter howmny Speci(cid:12)es how many eigenvectors are de - sired howmny = ' A ' : compute nev eigenvectors ; howmny = ' P ' : Compute nev Schur vectors ; howmny = ' S ' : compute some of the eigenvectors , speci(cid:12)ed by the logical array select . (cid:15) sigma should contain the value of the ( complex ) shift that was used if iparam ( 7 ) = 3 . It is referenced if iparam ( 7 ) = 1 or 2 . - DRAFT - 31 July 96 Chapter 4 The Implicitly Restarted Arnoldi Method This chapter presents an overview of the theory of Krylov subspace projection and the underlying algorithms implemented in ARPACK . The basic Implicitly Restarted Arnoldi Method ( IRAM ) is quite simple in structure and is very closely related to the Implicitly Shifted QR - Algorithm for dense problems . This discussion is intended to give a broad overview of the theory and to develop a high level description of the algorithms . Speci(cid:12)c implementation details concerned with e(cid:14)ciency and numerical stability are treated in Chapter 5 . Further information may found in [ 38 , 23 , 39 , 20 , 21 , 27 ] . The basic iteration of the IRAM is outlined in Figure 4 . 1 for those familiar with Krylov subspace methods and basic dense eigenvalue methods . In the iteration shown , Hm is an m (cid:2) m upper Hessenberg matrix , V H m Vm = Im , and the residual vector fm is orthogonal to the columns of Vm . The remainder of this chapter will develop enough background to understand the origins , motivation , and expected behavior of this algorithm . The discussion begins with a very brief review of the structure of the algebraic eigenvalue problem and some basic numerical methods that either in(cid:13)uence or play a direct role in the IRA method . Overcomming the basic disadvantages of the simple power method motivates the in - troduction of Krylov subspaces along with the important projection idea and the related approximation properties . The Lanczos / Arnoldi factorization is introduced as a concrete way to construct an orthogonal basis for a Krylov subspace and provides a means to implement the projection numerically . Implicit restarting is introduced as an e(cid:14)cient way to overcome the often intractable storage and computational re - quirements in the original Lanczos / Arnoldi method . This new technique turns out to be a truncated form of the powerful implicitly shifted QR algorithm and hence the implementation issues and ultimate behavior is closely tied to that well understood method . Because of its reduced storage requirements , the technique is suitable for large scale eigenvalue problems . Implicit restarting provides a means to approximate 49 4 . 1 . STRUCTURE OF THE EIGENVALUE PROBLEM 50 Figure 4 . 1 : An Implicitly Restarted Arnoldi Iteration as Implemented by ARPACK . (cid:15) Start : Build a length m Arnoldi factorization AVm = VmHm + fme T m with the starting vector v1 : (cid:15) Iteration : Until convergence 1 . Compute the eigenvalues f(cid:21)j : j = 1 ; 2 ; (cid:1)(cid:1)(cid:1) ; mg of Hm . Sort these eigenvalues according to the user selection criterion into a wanted set f(cid:21)j : j = 1 ; 2 ; (cid:1)(cid:1)(cid:1) ; kg and an unwanted set f(cid:21)j : j = k + 1 ; k + 2 ; (cid:1)(cid:1)(cid:1) ; mg : 2 . Perform m(cid:0)k = p steps of the qr iteration with the unwanted eigenvalues f(cid:21)j : j = k + 1 ; k + 2 ; (cid:1)(cid:1)(cid:1) ; mg . as shifts to obtain HmQm = QmH + m : 3 . Restart : Postmultiply the length m Arnoldi factorization with the ma - trix Qk consisting of the leading k columns of Qm to obtain the length k Arnoldi factorization AVmQk = VmQkH + k + f + k e T k ; where H + k is the leading principal submatrix of order k for H + m : Set Vk VmQk : 4 . Extend the length k Arnoldi factorization to a length m factorization . a few eigenvalues with user speci(cid:12)ed properties in space proportional to n(cid:1)k where k is the number of eigenvalues sought . Generalized eigenvalue problems are discussed in some detail . They arise naturally in PDE applications and they have a number of subtleties with respect to numeri - cally stable implementation of spectral transformations . Spectral transformations are presented within the context of the generalized problem as a means to improve the performance of Krylov methods . 4 . 1 Structure of the Eigenvalue Problem A brief discussion of the mathematical structure of the eigenvalue problem is necessary to (cid:12)x notation and introduce ideas that lead to an understanding of the behavior , strengths and limitations of the algorithm . In this discussion , the real and complex number (cid:12)elds are denoted by R and C respectively . The standard n - dimensional real and complex vectors are denoted by R n and C n and the symbols R m(cid:2)n and C m(cid:2)n will denote the real and complex matrices m rows and n columns . Scalars are denoted by lower case Greek letters , vectors are denoted by lower case Latin letters and matrices by capital Latin letters . The transpose of a matrix A is denoted by A T and the conjugate - transpose by A H : The symbol , k (cid:1) k will denote the Euclidean or 2 - norm of a vector . The standard basis for C n is denoted by the set fejg n j = 1 : The set of numbers (cid:27) ( A ) (cid:17) f(cid:21) 2 C : rank ( A (cid:0) (cid:21)I ) < n ) g is called the spectrum of A . The elements of this discrete set are the eigenvalues of A and they may be - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 51 characterized as the n roots of the characteristic polynomial pA ( (cid:21) ) (cid:17) det ( (cid:21)I (cid:0) A ) . Corresponding to each distinct eigenvalue (cid:21) 2 (cid:27) ( A ) is at least one nonzero vector x such that Ax = x(cid:21) . This vector is called a right eigenvector of A corresponding to the eigenvalue (cid:21) . The pair ( x ; (cid:21) ) is called an eigenpair . A nonzero vector y such that y H A = (cid:21)y H is called a left eigenvector . The multiplicity na ( (cid:21) ) of (cid:21) as a root of the characteristic polynomial is the algebraic multiplicity and the dimension ng ( (cid:21) ) of Null ( (cid:21)I (cid:0)A ) is the geometric multiplicity of (cid:21) . A matrix is defective if ng ( (cid:21) ) < na ( (cid:21) ) and otherwise A is non - defective . The eigenvalue (cid:21) is simple if na ( (cid:21) ) = 1 : A subspace S of C n(cid:2)n is called an invariant subspace of A if AS (cid:26) S . It is straightforward to show if A 2 C n(cid:2)n , X 2 C n(cid:2)k and B 2 C k(cid:2)k satisfy AX = XB ; ( 4 . 1 . 1 ) then S (cid:17) Range ( X ) is an invariant subspace of A . Moreover , if X has full column rank k then the columns of X form a basis for this subspace and (cid:27) ( B ) (cid:26) (cid:27) ( A ) . If k = n then (cid:27) ( B ) = (cid:27) ( A ) and A is said to be similar to B under the similarity transformation X : A is diagonalizable if it is similar to a diagonal matrix and this property is equivalent to A being non - defective . Invariant subspaces are central to the methods developed here . Invariant sub - spaces generalize the notion of eigenvectors . If Ax = x(cid:21) then X = ( x ) , B = ( (cid:21) ) and S (cid:17) Range ( X ) = Span ( x ) is a one dimensional invariant subspace of A : More generally , if Axj = xj(cid:21)j for j = 1 ; 2 ; (cid:1)(cid:1)(cid:1) ; k and we put X = ( x1 ; x2 ; (cid:1)(cid:1)(cid:1) ; xk ) then S (cid:17) Range ( X ) is an invariant subspace of A and indeed AX = X(cid:3) where (cid:3) = diag ( (cid:21)1 ; (cid:21)2 ; (cid:1)(cid:1)(cid:1) ; (cid:21)k ) . If X = Q ^ R where Q unitary and ^ R is upper triangular ( the standard QR - factorization ) , then AQ = QR where R = ^ R(cid:3) ^ R (cid:0)1 is an upper tri - angular matrix with the eigenvalues (cid:21)j on its diagonal . A large condition number k ^ Rkk ^ R (cid:0)1 k of ^ R and hence of X will indicate these eigenvalues and this invariant subspace are sensitive to perturbations in A ( such as those introduced by roundo(cid:11) error in a (cid:12)nite precision computation ) . But this is not the whole story . Separation of eigenvalues and angles between invariant subspaces also come into play . In the symmetric ( Hermitian ) case invariant subspaces corresponding to distinct eigenvalues are orthogonal to each other and completely decouple the action of the matrix ( as an operator on C n . In the non - symmetric case such a decoupling is generally not possi - ble . The nature of the coupling is completely described by the Jordan canonicial form but this form is usually extremely sensitive to perturbations and hence unsuitable as the basis for a computational algorithm . The Schur decomposition does provide a means to express this coupling and pro - vides a foundation for the development of numerical algorithms . It states that every square matrix is unitarily similar to an upper triangular matrix . In other words , for any linear operator on C n , there is a unitary basis in which the operator has an upper triangular matrix representation . - DRAFT - 31 July 96 4 . 1 . STRUCTURE OF THE EIGENVALUE PROBLEM 52 Theorem 4 . 1 . 1 ( Schur Decomposition ) . Let A 2 C n(cid:2)n . Then there is a unitary matrix Q and an upper triangular matrix R such that AQ = QR : ( 4 . 1 . 2 ) The diagonal elements of R are the eigenvalues of A . From the Schur decomposition , the fundamental structure of Hermitian and normal matrices is easily exposed : Lemma 4 . 1 . 2 A matrix A 2 C n(cid:2)n is normal ( AA H = A H A ) if and only if A = Q(cid:3)Q H with Q 2 C n(cid:2)n unitary and (cid:3) 2 C n(cid:2)n diagonal . A matrix A 2 C n(cid:2)n is Hermitian ( A = A H ) if and only if A = Q(cid:3)Q H with Q 2 C n(cid:2)n unitary and (cid:3) 2 R n(cid:2)n diagonal . In either case , the diagonal entries of (cid:3) are the eigenvalues of A and the columns of Q are the corresponding eigenvectors . The columns of Q are called Schur vectors in general and these are eigenvectors of A if and only if A is normal . For purposes of algorithmic development this structure is fundamental . In fact , the well known Implicitly Shifted QR - Algorithm [ 12 , 13 ] is designed to produce a sequence of unitary similarity transformations Qj that iteratively reduce A to upper triangular form . This algorithm begins with an initial unitary similarity transformation V of A to the condensed form AV = VH where H is upper Hessenberg ( tridiagonal in case A = A H ) . The iteration is shown in Figure 4 . 2 . Figure 4 . 2 : Algorithm 1 : Implicitly Shifted QR - iteration . Input : ( A ; V ; H ) with AV = VH ; V H V = I , H upper Hessenberg ; For j = 1 ; 2 ; 3 ; : : : until convergence , ( a1 . 1 ) Select a shift (cid:22) (cid:22)j ( a1 . 2 ) Factor [ Q ; R ] = qr ( H (cid:0) (cid:22)I ) ; ( a1 . 3 ) H Q H HQ ; V VQ ; End For where Q is unitary and R is upper triangular ( i . e . the QR factorization of H(cid:0)(cid:22)I ) . It is easy to see that H is unitarily similar to A throughout the course of this iteration . The iteration is continued until the subdiagonal elements of H converge to zero , i . e . until a Schur decomposition has been ( approximately ) obtained . In the standard implicitly shifted QR - iteration , the unitary matrix Q is never actually formed . it is computed indirectly as a product of 2(cid:2)2 Givens or 3(cid:2) 3 Householder transformations through a \ bulge chase " process . The elegant details of an e(cid:14)cient and stable implementation would be too much of a digression here . They may be found in [ 14 ] . The convergence - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 53 behavior of this iteration is fascinating . The columns of V converge to Schur vectors at various rates . These rates are fundamentally linked to the simple power method and its rapidly convergent variant , inverse iteration [ 31 , 41 ] . Despite the extremely fast rate of convergence and the e(cid:14)cient use of storage , the implicitly shifted QR method is not suitable for large scale problems and it has proved to be extremely di(cid:14)cult to parallelize . Large scale problems are typically sparse or structured so that a matrix - vector product w Av may be computed with time and storage proportional to n rather than n 2 : A method based upon full similarity transformations quickly destroys this structure . Storage and operation counts per iteration become order n 2 : Hence , there is considerable motivation for methods that only require matrix - vector products with the original A : The power method provides a simple means to (cid:12)nd the dominant eigenvalue of a matrix without performing matrix factorizations and dense similarity transformations . It has the drawback that only one eigen - pair may be found and that convergence may be slow or non - existent . De(cid:13)ations schemes and / or block variants may be employed to overcome the (cid:12)rst problem and spectral transformations may be used to accelerate convergence and focus on selected eigenvalues . 4 . 2 Krylov Subspaces and Projection Methods The methods that underly the ARPACK software are derived from a class of algo - rithms called Krylov subspace projection methods . These methods are based upon the intricate structure of the sequence of vectors naturally produced by the power method . An examination of the behavior of the sequence of vectors produced by a power methods suggests that the successive vectors may contain considerable information along eigenvector directions corresponding to eigenvalues other than the one with largest magnitude . The expansion coe(cid:14)cients of the vectors in the sequence evolve in a very structured way . Therefore , linear combinations of the these vectors might well be devised to expose additional eigenvectors . A single vector power iteration simply ignores this additional information , but more sophisticated techniques may be employed to extract it . If one hopes to obtain additional information through various linear combinations of the power sequence , it is natural to formally consider the Krylov subspace Kk ( A ; v1 ) = Span fv1 ; Av1 ; A 2 v1 ; : : : ; A k(cid:0)1 v1g and to attempt to formulate the best possible approximations to eigenvectors from this subspace . It is reasonable to construct approximate eigenpairs from this subspace by im - posing a Galerkin condition : A vector x 2 Kk ( A ; v1 ) is called a Ritz vector with corresponding Ritz value (cid:18) if the Galerkin condition < w ; Ax(cid:0) x(cid:18) > = 0 ; for all w 2 Kk ( A ; v1 ) - DRAFT - 31 July 96 4 . 3 . THE ARNOLDI FACTORIZATION 54 is satis(cid:12)ed . There are some immediate consequences of this de(cid:12)nition : Let W be a matrix whose columns form an orthonormal basis for Kk (cid:17) Kk ( A ; v1 ) : Let P = WW H denote the related orthogonal projector onto Kk and de(cid:12)ne ^ A (cid:17) PAP = WBW H where B (cid:17) W H AW : It can be shown that Lemma 4 . 2 . 1 For the quantities de(cid:12)ned above : 1 . ( x ; (cid:18) ) is a Ritz - pair if and only if x = Ws with Bs = s(cid:18) . 2 . k ( I (cid:0) P ) AWk = k ( A (cid:0) ^ A ) Wk (cid:20) k ( A (cid:0) M ) Wk for all M 2 C n(cid:2)n such that MKk (cid:26) Kk . 3 . The Ritz - pairs ( x ; (cid:18) ) and the minimum value k ( I (cid:0) P ) AWk are independent of the choice of orthonormal basis W : These facts are actually valid for any k dimensional subspace S in place of Kk : Additional useful properties may be derived as consequences of the fact that every w 2 Kk is of the form w = (cid:30) ( A ) v1 for some polynomial (cid:30) of degree less than k . A thorough discussion is given by Saad in [ 35 ] and in his earlier papers . These facts have important algorithmic consequences . In particular , it may be shown that Kk is an invariant subspace for A if and only if v1 = Vs , where AV = VR with V H V = Ik and R is a k (cid:2) k upper triangular matrix . Also , Kk is an invariant subspace for A if v1 = Xs , where X 2 C n(cid:2)k and AX = X(cid:3) with (cid:3) diagonal . There is some algorithmic motivation to seek a convenient orthonormal basis V = WQ that will provide a means to successively construct these basis vectors . It is possible to construct a k (cid:2) k unitary Q using standard Householder transforma - tions such that v1 = Ve1 and H = Q H BQ is upper Hessenberg with non - negative subdiagonal elements . It is also possible to show that in this basis , AV = VH + fe T k ; where = (cid:13) ^ p ( A ) v1 : Here , V H f = 0 follows from the Galerkin condition and it turns out that ^ p ( (cid:21) ) = det ( (cid:21)I (cid:0) H ) . The (cid:12)rst observation shows that if it is possible to obtain a v1 as a linear combina - tion of k eigenvectors of A then f = 0 and V is an orthonormal basis for an invariant subspace of A and that the Ritz values (cid:27) ( H ) (cid:26) (cid:27) ( A ) and corresponding Ritz vectors are eigenpairs for A . The second observation leads to the Lanczos / Arnoldi process [ 2 , 18 ] . 4 . 3 The Arnoldi Factorization De(cid:12)nition : If A 2 C n(cid:2)n then a relation of the form AVk = VkHk + fke T k - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 55 where Vk 2 C n(cid:2)k has orthonormal columns , V H k fk = 0 and Hk 2 C k(cid:2)k is upper Hessenberg with non - negative subdiagonal elements is called a k - step Arnoldi Factor - ization of A : If A is Hermitian then Hk is real , symmetric and tridiagonal and the relation is called a k - step Lanczos Factorization of A : The columns of Vk are referred to as the Arnoldi vectors or Lanczos vectors , respectively . The development of this factorization has been purely through the consequences of the orthogonal projection imposed by the Galerkin conditions . A more straight - forward but less illuminating derivation is to simply truncate the reduction of A to Hessenberg form that precedes the implicitly shifted QR - iteration by equating the (cid:12)rst k columns on both sides of the complete reduction AV = VH : An alternative way to write this factorization is AVk = ( Vk ; vk + 1 ) Hk (cid:12)ke T k ! where (cid:12)k = kfkk and vk + 1 = 1 (cid:12)k fk : This factorization may be used to obtain approximate solutions to a linear system Ax = b if b = v1(cid:12)0 and this underlies the GMRES method [ 36 ] . However , the purpose here is to investigate the use of this factorization to obtain approximate eigenvalues and eigenvectors . The discussion of the previous section implies that Ritz pairs satisfying the Galerkin condition are immediately available from the eigenpairs of the small projected matrix Hk : If Hks = s(cid:18) then the vector x = Vks satis(cid:12)es kAx (cid:0) x(cid:18)k = k ( AVk (cid:0) VkHk ) sk = j(cid:12)ke T k sj : The number j(cid:12)ke T k sj is called the Ritz estimate for the the Ritz pair ( x ; (cid:18) ) as an approximate eigenpair for A : Observe that if ( x ; (cid:18) ) is a Ritz pair then (cid:18) = s H Hks = ( Vks ) H A ( Vks ) = x H Ax is a Rayleigh Quotient ( assuming ksk = 1 ) and the associated Rayleigh Quotient residual r ( x ) = Ax (cid:0) x(cid:18) satis(cid:12)es kr ( x ) k = j(cid:12)ke T k sj : When A is Hermitian , this relation may be used to provide computable rigorous bounds on the accuracy of the eigenvalues of Hk as approximations to eigenval - ues [ 30 ] of A : When A is non - Hermitian the possibility of non - normality precludes such bounds and one can only say that the Rayleigh Quotient residual is small if j(cid:12)ke T k sj is small without further information . However , in either case , if fk = 0 these the Ritz pairs become exact eigenpairs of A : The k - step factorization may be advanced one step at the cost of a ( sparse ) matrix - vector product involving A and two dense matrix vector products involving V T k and Vk : The explicit steps needed to form a k - Step Arnoldi Factorization are listed in - DRAFT - 31 July 96 4 . 3 . THE ARNOLDI FACTORIZATION 56 Algorithm 2 shown in Figure 4 . 3 . In exact arithmetic , the columns of Vj form an orthonormal basis for the Krylov subspace and Hj is the orthogonal projection of A onto this space . In (cid:12)nite precision arithmetic , care must be taken to assure that the computed vectors are orthogonal to working precision . The method proposed by Daniel , Gragg , Kaufman and Stewart ( DGKS ) in [ 7 ] provides an excellent way to construct a vector fj + 1 that is numerically orthogonal to Vj + 1 . It amounts to computing a correction c = V H j + 1 fj + 1 ; fj + 1 fj + 1 (cid:0) Vj + 1c ; h h + c ; just after Step ( a2 . 4 ) if necessary . A simple test is used to avoid this DGKS correction if it is not needed . Figure 4 . 3 : Algorithm 2 : The k - Step Arnoldi Factorization Input : ( A ; v1 ) Put v1 = v = kv1k ; w = Av1 ; (cid:11)1 = v H 1 w ; Put f1 w (cid:0) v1(cid:11)1 ; V1 ( v1 ) ; H1 ( (cid:11)1 ) ; For j = 1 ; 2 ; 3 ; : : : k - 1 , ( a2 . 1 ) (cid:12)j = kfjk ; vj + 1 fj = (cid:12)j ; ( a2 . 2 ) Vj + 1 ( Vj ; vj + 1 ) ; ^ Hj Hj (cid:12)je T j ! ; ( a2 . 3 ) z Avj + 1 ; ( a2 . 4 ) h V H j + 1 z ; fj + 1 z (cid:0) Vj + 1h ; ( a2 . 5 ) Hj + 1 ( ^ Hj ; h ) ; End For The dense matrix - vector products at Step ( a2 . 4 ) and also the correction may be accomplished using Level 2 BLAS . This is quite important for performance on vector , and parallel - vector supercomputers . The Level 2 BLAS operation GEMV is easily parallelized and vectorized and has a much better ratio of (cid:13)oating point computation to data movement [ 10 , 8 ] than the Level 1 BLAS operations . The information obtained through this process is completely determined by the choice of the starting vector . Eigen - information of interest may not appear until k gets very large . In this case it becomes intractable to maintain numerical orthogonality of the basis vectors Vk . Moreover , extensive storage will be required and repeatedly (cid:12)nding the eigensystem of Hk will become prohibitive at a cost of O ( k 3 ) (cid:13)ops . Failure to maintain orthogonality leads to several numerical di(cid:14)culties . In a certain sense , the computation ( or approximation ) of the projection indicated at Step ( a2 . 4 ) in a way that overcomes these di(cid:14)culties has been the main source of research activity in these Krylov subspace projection methods . The computational di(cid:14)culty stems from the fact that kfkk = 0 if and only if the columns of Vk span an invariant - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 57 subspace of A : When Vk \ nearly " spans such a subspace , kfkk should be small . Typically , in this situation , a loss of signi(cid:12)cant digits will take place at Step ( a2 . 4 ) through numerical cancellation unless special care is taken ( i . e . use of the DGKS correction ) . It is desirable for kfkk to become small because this indicates that the eigenvalues of Hk are the eigenvalues of a perturbed matrix that is near to A : This is easily seen from a re - arangement of the Arnoldi relation : ( A (cid:0) fkv H k ) Vk = VkHk where vk = Vkek . Hence , Range ( Vk ) is an invariant subspace for the perturbed matrix A + E with kEk = kfkv H k k = kfkk : Thus , the eigenvalues of Hk will be accurate approximations to the eigenvalues of A if the approximated eigenvalues are insensitive to perturbations ( i . e . well conditioned ) . However , this \ convergence " may well lead to loss of numerical orthogonality in the updated basis Vk + 1 unless care is taken to avoid this . Moreover , if subsequent Arnoldi vectors are not forced to be orthogonal to the converged ones , then components along these converged directions re - enter the basis via round - o(cid:11) e(cid:11)ects and quickly cause a spurious copy of the previously computed eigenvalue to appear repeatedly in the spectrum of the projected matrix Hk : The treatment of this basic di(cid:14)culty has occupied a number of renowned re - searchers [ 29 , 15 , 7 , 30 , 32 , 37 , 4 , 6 , 5 , 33 , 34 , 35 , 17 ] since the early 1970 ' s . Within this context , restarting has proven to have important consequences for the develop - ment of numerical software based upon Arnoldi ' s method and this will be explored in the following section . 4 . 4 Restarting the Arnoldi Method An unfortunate aspect of the Lanczos / Arnoldi process is that one cannot know in advance how many steps will be required before eigenvalues of interest are well ap - proximated by the Ritz values . This is particularly true when the problem has a wide range of eigenvalues but the eigenvalues of interest are clustered . Without a spectral transformation , many Lanczos steps are required to obtain the selected eigenvalues . In order to recover eigenvectors , one is obliged to store all of the Lanczos basis vectors ( usually on a peripheral device ) and to solve a very large tridiagonal eigenvalue prob - lems at each step . In the Arnoldi process that is used in the non - Hermitian case , not only do the basis vectors have to be stored , but the cost of the Hessenberg eigenvalue subproblem is O ( k 3 ) at the k - th step . Implicit Restarting A restarting alternative has been proposed by Saad based upon the polynomial ac - celeration scheme developed by Manteu(cid:11)el [ 24 ] for the iterative solution of linear - DRAFT - 31 July 96 4 . 4 . RESTARTING THE ARNOLDI METHOD 58 systems . Saad [ 34 ] proposed to restart the factorization with a vector that has been preconditioned so that it is more nearly in a k - dimensional invariant subspace of in - terest . This preconditioning takes the form of a polynomial applied to the starting vector that is constructed to damp unwanted components from the eigenvector ex - pansion . An iteration is de(cid:12)ned by a repeatly restarting until the current Arnoldi factorization contains the desired information . Saad ' s ideas were based on similar ones developed for the Lanczos process by Paige [ 29 ] , Cullum and Donath [ 5 ] , and Golub and Underwood [ 15 ] . It appears that Karush [ 17 ] proposed the (cid:12)rst example of a restarted iteration . The ARPACK software is based upon another approach to restarting that o(cid:11)ers a more e(cid:14)cient and numerically stable formulation . This approach called implicit restarting is a technique for combining the implicitly shifted QR mechanism with a k - step Arnoldi or Lanczos factorization to obtain a truncated form of the implic - itly shifted QR - iteration . The numerical di(cid:14)culties and storage problems normally associated with Arnoldi and Lanczos processes are avoided . The algorithm is capa - ble of computing a few ( k ) eigenvalues with user speci(cid:12)ed features such as largest real part or largest magnitude using 2nk + O ( k 2 ) storage . No auxiliary storage is re - quired . The computed Schur basis vectors for the desired k - dimensional eigen - space are numerically orthogonal to working precision . The suitability of this method for the development of mathematical software stems from this concise and automatic treatment of the primary di(cid:14)culties with the Arnoldi / Lanczos process . Implicit restarting provides a means to extract interesting information from large Krylov subspaces while avoiding the storage and numerical di(cid:14)culties associated with the standard approach . It does this by continually compressing the interesting infor - mation into a (cid:12)xed size k - dimensional subspace . This is accomplished through the implicitly shifted QR mechanism . An Arnoldi factorization of length m = k + p AVm = VmHm + fme T m ; ( 4 . 4 . 1 ) is compressed to a factorization of length k that retains the eigen - information of interest . This is accomplished using QR steps to apply p shifts implicitly . The (cid:12)rst stage of this shift process results in AV + m = V + m H + m + fme T m Q ; ( 4 . 4 . 2 ) where V + m = VmQ , H + m = Q H HmQ , and Q = Q1Q2 (cid:1)(cid:1)(cid:1)Qp , with Qj the orthogonal matrix associated with the shift (cid:22)j . It may be shown that the (cid:12)rst k (cid:0) 1 entries of the vector e T m Q are zero ( i . e . e T m Q = ( (cid:27)e T k ; ^ q H ) ) . Equating the (cid:12)rst k columns on both sides yields the updated k(cid:0)step Arnoldi factorization AV + k = V + k H + k + f + k e T k ; ( 4 . 4 . 3 ) with an updated residual of the form f + k = V + m ek + 1 ^ (cid:12)k + fm(cid:27) . Using this as a starting point it is possible to apply p additional steps of the Arnoldi process to return to the original m - step form . - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 59 Each of these shift cycles results in the implicit application of a polynomial in A of degree p to the starting vector . v1 ( A ) v1 with ( (cid:21) ) = p Y 1 ( (cid:21) (cid:0) (cid:22)j ) : ( 4 . 4 . 4 ) The roots of this polynomial are the shifts used in the QR process and these may be selected to (cid:12)lter unwanted information from the starting vector and hence from the Arnoldi factorization . Full details may be found in [ 38 ] . The choice of shifts and hence construction of the polynomial is motivated by the fact that if the starting vector v1 = P k j = 1 xj(cid:13)j where Axj = xj(cid:21)j , then fk = 0 , AVk = VkHk and thus Vk will provide an orthonormal basis for the invariant subspace S (cid:17) Range ( Vk ) : Moreover , (cid:27) ( Hk ) = f(cid:21)1 ; (cid:21)2 ; (cid:1)(cid:1)(cid:1) ; (cid:21)kg : Figure 4 . 4 : Algorithm 3 : An Implicitly Restarted Arnoldi Method ( IRAM ) . Input : ( A ; V ; H ; f ) with AVm = VmHm + fme T m , an m - Step Arnoldi Factorization ; For ` = 1 ; 2 ; 3 ; : : : until convergence ( a3 . 2 ) Compute (cid:27) ( Hm ) and select set of p shifts (cid:22)1 ; (cid:22)2 ; : : : (cid:22)p based upon (cid:27) ( Hm ) or perhaps other information ; ( a3 . 3 ) q T e T m ; ( a3 . 4 ) For j = 1 ; 2 ; : : : ; p , Factor [ Q ; R ] = qr ( Hm (cid:0) (cid:22)jI ) ; Hm Q H HmQ ; Vm VmQ ; q q H Q ; End For ( a3 . 5 ) fk vk + 1 ^ (cid:12)k + fm(cid:27)k ; Vk Vm ( 1 : n ; 1 : k ) ; Hk Hm ( 1 : k ; 1 : k ) ; ( a3 . 6 ) Beginning with the k - step Arnoldi factorization AVk = VkHk + fke T k , apply p additional steps of the Arnoldi process to obtain a new m - step Arnoldi factorization AVm = VmHm + fme T m . End For The repeated update of the starting vector v1 through implicit restarting is de - signed to enhance the components of this vector in the directions of the wanted eigenvectors and damp its components in the unwanted directions . If v1 has an ex - pansion as a linear combination of eigenvectors fxjg of A , the e(cid:11)ect of this polynomial restarting is illustrated as follows : v1 = n X j = 1 xj(cid:13)j ) ( A ) v1 = n X j = 1 xj ( (cid:21)j ) (cid:13)j : - DRAFT - 31 July 96 4 . 4 . RESTARTING THE ARNOLDI METHOD 60 If the same polynomial ( i . e . the same shifts ) were applied each time , then after ` iterations , the j - th original expansion coe(cid:14)cient would be essentially attenuated by a factor (cid:18) ( (cid:21)j ) ( (cid:21)1 ) (cid:19) ` ; where the eigenvalues have been ordered according decreasing values j ( (cid:21)j ) ) j . The leading k eigenvalues become dominant in this expansion and the remaining eigen - values become less and less signi(cid:12)cant as the iteration proceeds . Adaptive choices of shifts can further enhance the isolation of the wanted components in this expansion . Hence , the wanted eigenvalues are approximated increasingly well as the iteration proceeds . The basic iteration is listed in Figure 4 . 4 in Algorithm 3 and the diagrams in Figures 4 . 5 | 4 . 7 describe how this iteration proceeds schematically . In Algorithm 3 and in the discussion that follows , the notation M ( 1 : n ; 1 : k ) denotes the leading n (cid:2) k submatrix of M : Observe that if m = n then fm = 0 and this iteration is precisely the same as the Implicitly Shifted QR iteration . Even for m < n , the (cid:12)rst k columns of Vm and the Hessenberg submatrix Hm ( 1 : k ; 1 : k ) are mathematically equivalent to the matrices that would appear in the full Implicitly Shifted QR iteration using the same shifts (cid:22)j : In this sense , the Implicitly Restarted Arnoldi method may be viewed as a truncation of the Implicitly Shifted QR iteration . The fundamental di(cid:11)erence is that the standard Implicitly Shifted QR iteration selects shifts to drive subdiagonal elements of Hn to zero from the bottom up while the shift selection in the Implicitly Restarted Arnoldi method is made to drive subdiagonal elements of Hm to zero from the top down . Important implementation details concerning the de(cid:13)ation ( setting to zero ) of subdiagonal elements of Hm and the purging of unwanted but converged Ritz values are beyond the scope of this discussion . However , these details are extremely important to the success of this iteration in di(cid:14)cult cases . Complete details of these numerical re(cid:12)nements may be found in [ 23 , 20 ] . The above iteration can be used to apply any known polynomial restart . If the roots of the polynomial are not known there is an alternative implementation that only requires one to compute q1 = ( Hm ) e1 where is the desired degree p polynomial . A sequence of Householder transformations may developed to form a unitary matrix Q such that Qe1 = q1 and Hm Q H HmQ is upper Hessenberg . The details which follow standard developments for the Implicitly Shifted QR iteration will be omitted here . A shift selection strategy that has proved successful in practice and is used as the default in ARPACK is called the \ Exact Shift Strategy " . In this strategy , one computes (cid:27) ( Hm ) and sorts this into two disjoint sets (cid:10)w and (cid:10)u : The k Ritz values in the set (cid:10)w are regarded as approximations to the \ wanted " eigenvalues of A , and the p Ritz values in the set (cid:10)u are taken as the shifts (cid:22)j . An interesting consequence ( in exact arithmetic ) is that after Step ( a3 . 4 ) above , the spectrum of Hk in Step - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 61 + p k p p k k + p Figure 4 . 5 : The set of rectangles represents the matrix equation VmHm + fme T m of an Arnoldi factorization . The unshaded region on the right is a zero matrix of m (cid:0) 1 columns . + k p p k k + p Figure 4 . 6 : After performing m (cid:0) k implicitly shifted qr steps on Hm , the middle set of pictures illustrates VmQmH + m + fme T m Qm : The last p columns of fme T m Qm are nonzero because of the qr iteration . k k + k Figure 4 . 7 : An implicitly restarted length k Arnoldi factorization results after dis - carding the last m (cid:0) k columns . - DRAFT - 31 July 96 4 . 5 . THE GENERALIZED EIGENVALUE PROBLEM 62 ( a3 . 5 ) is (cid:27) ( Hk ) = (cid:10)w and the updated starting vector v1 is a particular linear com - bination of the k Ritz vectors associated with these Ritz values . In other words , the implicit restarting scheme with exact shifts provides a speci(cid:12)c selection of expansion coe(cid:14)cients (cid:13)j for a new starting vector as a linear combination of the current best estimates ( the Ritz vectors ) for wanted eigenvectors . This implicit scheme costs p rather than the k + p matrix - vector products the explicit scheme would require . Thus the exact shift strategy can be viewed both as a means to damp unwanted components from the starting vector and also as directly forcing the starting vector to be a linear combination of wanted eigenvectors . See [ 21 , 38 ] further information convergence of an IRAM and other possible shift strategies . 4 . 5 The Generalized Eigenvalue Problem A typical source of large scale eigenproblems is through a discrete form of a continuous problem . The resulting (cid:12)nite dimensional problems become large due to accuracy requirements and spatial dimensionality . Typically this takes the form Ax = (cid:21)Mx ; where A is a (cid:12)nite dimensional approximation to the continuous operator obtained either through (cid:12)nite di(cid:11)erence approximations on a spatial grid or through restriction of the contiuous operator to a (cid:12)nite dimensional subspace . In the latter \ (cid:12)nite ele - ment " case , the entries of M are inner products of the respective basis functions for the (cid:12)nite dimensional space and these basis functions are usually chosen so that few entries in a typical row of A or M are nonzero . In structures problems A is called the \ sti(cid:11)ness " matrix and M is called the \ mass " matrix . In chemistry and physics M is often referred to as the \ overlap " matrix . A nice feature of (cid:12)nite element approach to discretization is that boundary conditions are naturally incorporated into the discrete problem . Moreover , in the self - adjoint case , the Rayleigh principle is preserved from the continuous to the discrete problem . In particular , since Ritz values are Rayleigh quotients , this assures the smallest Ritz value is greater than the smallest eigenvalue of the original problem . Basis functions that provide sparsity are usually not orthogonal in the natural inner product and hence , M is usually not diagonal . Thus it is typical for large scale eigenproblems to arise as generalized rather than standard problems with M positive semi - de(cid:12)nite . The matrix A is generally symmetric when the underlying continuous operator is self - adjoint and non - symmetric otherwise . There are a number of ways to convert the generalized problem to standard form . There is always motivation to preserve symmetry when it is present . If M is positive de(cid:12)nite then factor M = LL T and the eigenvalues of ^ A (cid:17) L (cid:0)1 AL (cid:0)T are the eigenvalues of ( A ; M ) and the eigenvectors are obtained by solving L T x = ^ x where ^ x is an eigenvector of ^ A . This standard transformation is (cid:12)ne if one - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 63 wants the eigenvalues of largest magnitude and it preserves symmetry if A is sym - metric . However , when M is ill - conditioned this can be a dangerous transformation leading to numerical di(cid:14)culties . Since a matrix factorization will have to be done anyway , one may as well formulate a spectral transformation . 4 . 5 . 1 Structure of the Spectral Transformation The use of spectral transformations is closely related to the inverse power and inverse iteration techniques . They are typically designed to enhance convergence to eigenval - ues near a selected point (cid:27) in the complex plane . For example , if one were interested in computing the smallest eigenvalues of a symmetric positive de(cid:12)nite matrix then (cid:27) = 0 would be a reasonable choice . A convenient way to provide such a spectral transformation is to note that Ax = (cid:21)Mx ( ) ( A (cid:0) (cid:27)M ) x = ( (cid:21) (cid:0) (cid:27) ) Mx Thus ( A (cid:0) (cid:27)M ) (cid:0)1 Mx = x(cid:18) ; where (cid:18) = 1 (cid:21) (cid:0) (cid:27) : If A is symmetric then one can maintain symmetry in the Arnoldi / Lanczos process by taking the inner product to be < x ; y > = x T My : It is easy to verify that the operator ( A(cid:0)(cid:27)M ) (cid:0)1 M is symmetric with respect to this inner product if A is symmetric . In the Arnoldi / Lanczos process the matrix - vector product w Av is replaced by w ( A (cid:0) (cid:27)M ) (cid:0)1 Mv and the step h V T f is replaced by h V T ( Mf ) . If A is symmetric then the matrix H is symmetric and tridiagonal . Moreover , this process is well de(cid:12)ned even when M is singular and this can have important consequences even if A is nonsymmetric . We shall refer to this process as the M - Arnoldi process . If M is singular then the operator S (cid:17) ( A (cid:0) (cid:27)M ) (cid:0)1 M has a non - trivial null space and the bilinear function < x ; y > = x T My is a semi - inner product and kxkM (cid:17) p < x ; y > is a semi - norm . Since A (cid:0) (cid:27)M is assumed to be nonsingular , N (cid:17) Null ( S ) = Null ( M ) : Vectors in N are generalized eigenvectors corresponding to in(cid:12)nite eigenvalues . Typically , one is only interested in the (cid:12)nite eigenvalues of ( A ; M ) and these will correspond to the non - zero eigenvalues of S : The invariant sub - space corresponding to these non - zero eigenvalues is easily corrupted by components of vectors from N during the Arnoldi process . However , using the M - Arnoldi process with some re(cid:12)nements can provide a solution . In order to better understand the situation , it is convenient to note that since M is positive semi - de(cid:12)nite , there is an orthogonal matrix Q such that M = Q " D 0 0 0 # Q T - DRAFT - 31 July 96 4 . 5 . THE GENERALIZED EIGENVALUE PROBLEM 64 where D is a positive de(cid:12)nite diagonal matrix of order n , say . Thus ^ S (cid:17) Q T SQ = " S1 0 S2 0 # ; where S1 is a square matrix of order n and S2 is an m (cid:2) n matrix with the original A ; M being of order m + n . Observe now that a non - zero eigenvalue (cid:18) of ^ S satis(cid:12)es ^ Sx = x(cid:18) , i . e . " S1x1 S2x1 # = " x1(cid:18) x2(cid:18) # so that x2 = (cid:18) (cid:0)1 S2x1 must hold . Note also that for any eigenvector x H = ( x H 1 ; x H 2 ) , the leading vector x1 must be an eigenvector of S1 . Since ^ S is block triangular , (cid:27) ( ^ S ) = (cid:27) ( S1 ) [ (cid:27) ( 0m ) . Assuming S2 has full rank , it follows that if S1 has a zero eigenvalue then there is no corresponding eigenvector ( since S2x1 = 0 would be implied ) . Thus if zero is an eigenvalue of S1 with algebraic multiplicity mo then zero is an eigenvalue of ^ S of algebraic multiplicity m + mo and with geometric multiplicity m . Of course , since , S is similar to ^ S all of these statements hold for S as well . 4 . 5 . 2 Eigenvector / Null - Space Puri(cid:12)cation With these observations in hand , it is possible to see the virtue of using M - Arnoldi on S . After k - steps of M - Arnoldi , SV = VH + fe T k with V T MV = Ik ; V T Mf = 0 : Introducing the similarity transformation Q gives ^ S ^ V = ^ VH + ^ fe T k with ( Q ^ V ) T MQ ^ V = Ik ; ( Q ^ V ) T MQ ^ f = 0 ; where ^ V = Q T V and ^ f = Q T f . Partitioning ^ V T = [ V T 1 V T 2 ] and ^ f T = [ f T 1 f T 2 ] consistent with the blocking of ^ S gives S1V1 = V1H + f1e T k with V T 1 DV1 = Ik ; V T 1 Df1 = 0 : Moreover , the side condition S2V1 = V2H + f2e T k holds , so that in exact arithmetic a zero eigenvalue should not appear as a converged Ritz value of H . This argument shows that M - Arnoldi on S is at the same time doing D - Arnoldi on S1 while avoiding convergence to zero eigenvalues . Round - o(cid:11) error due to (cid:12)nite precision arithmetic will cloud the situation , as usual . It is clear that the goal is to prevent components in N from corrupting the vectors V : Thus to begin , the starting vector v1 should be of the form v1 = Sv : If a (cid:12)nal approximate eigenvector x has components in N they may be purged by replacing x Sx and then normalizing . To see the e(cid:11)ect of this , note that x = Q " x1 x2 # implies Sx = Q " S1x1 S2x1 # - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 65 and all components in N which are of the form Q " 0 p # will have been purged . This (cid:12)nal application of S may be done implicitly in two ways . One is to note that if x = Vs with Hs = s(cid:18) then Sx = VHs + fe T k s = x(cid:18) + fe T k s and the approximate eigenvector x is replaced with the improved approximation x ( x(cid:18) + fe T k s ) = (cid:28) where (cid:28) = kx(cid:18) + fe T k skM = q (cid:18) 2 + ( (cid:12)ke T k s ) 2 . This correction was originally suggested by Ericsson and Ruhe [ 11 ] as a mean of performing a formal step of the power method with S : The residual error of the computed Ritz vector with respect to the original problem is kAx (cid:0) Mx(cid:21)k = kMfk je T k sj j(cid:18)j 2 ( 4 . 5 . 1 ) where (cid:21) = (cid:27) + 1 = (cid:18) : Keeping in mind that under the spectral transformation j(cid:18)j is usually quite large , this estimate indicates even greater accuracy than expected from the usual estimate . This is the puri(cid:12)cation used in ARPACK . Another recent suggestion due to Meerbergen and Spence is to use implicit restart - ing with a zero shift [ 26 ] . Recall that implicit restarting with ` zero shifts is equivalent to starting the M - Arnoldi process with a starting vector of S ` v1 and all the resulting Ritz vectors will be multiplied by S ` as well . After applying the implicit shifts to H , the leading submatrix of order k (cid:0) ` will provide the updated Ritz values . No additional explicit matrix - vector products with S are required . The ability to apply ` zero shifts ( i . e . to multiply by S ` implicitly ) is very impor - tant when S1 has zero eigenvalues . If S1x1 = 0 then " S1 0 S2 0 # " x1 x2 # = " 0 S2x1 # 2 N : Thus , in order to completely eradicate components from N one must multiply by S ` where ` is equal to the dimension of the largest Jordan block corresponding to a zero eigenvalue of S1 . This may be incorporated into ARPACK at a future date . Spectral transformations were studied extensively by Ericsson and Ruhe [ 11 ] and the (cid:12)rst eigenvector puri(cid:12)cation strategy was developed in [ 28 ] . Shift and invert techniques play an essential role in the block Lanczos code developed by Grimes , Lewis , and Simon and the many nuances of this technique in practical applications are discussed thoroughly in [ 16 ] . The development presented here and the eigenvector puri(cid:12)cation through implicit restarting is due to Meerbergen and Spence [ 26 ] . 4 . 6 Stopping Criteria This section considers the important question of determining when a length m Arnoldi factorization has computed approximate eigenvalues of acceptable accuracy . - DRAFT - 31 July 96 4 . 6 . STOPPING CRITERIA 66 Let Hms = s(cid:18) where ksk = 1 and ^ x (cid:17) Vms : Then kA ^ x (cid:0) ^ x(cid:18)k = kAVms (cid:0) VmHmsk = kfmkje T m sj ; ( 4 . 6 . 1 ) suggests that the Ritz pair ( ^ x ; (cid:18) ) is a good approximation to an eigenpair of A if the last component of an eigenvector for Hm is small . If the upper Hessenberg matrix H is unreduced ( has no zero subdiagonal elements ) then standard results imply that je T m sj 6 = 0 : However , this quantity can be quite small even if all of the subdiagonal element of H are far from zero . Usually , this is how convergence takes place , but it is also possible for fm to become small . If the quantity kfmk is small enough , then all m eigenvalues of Hm are likely to be good approximations to m eigenvalues of A : In the Hermitian case , this estimate on the residual can be turned into a precise statement about the accuracy of the Ritz value (cid:18) as an approximation to the eigenvalue of A that is nearest to (cid:18) . However , an analogous statment in the non - Hermaitian case is not possible without further information concerning non - normalilty and defectiveness . We shall develop a crude but e(cid:11)ective assessment of accuracy based upon this estimate . Far more sophisticated analysis is available for the symmetric problem in [ 30 ] and in [ 35 ] for the non - symmetric case . It is easily shown that ( A + E ) ^ x = ^ x(cid:18) ; with E (cid:17) (cid:0) ( e T m s ) fm ^ x H : ( 4 . 6 . 2 ) Thus , the Ritz pair ( ^ x ; (cid:18) ) is exact eigenpair for a nearby problem whenever kfmk or je T m sj is small ( relative to kAk ) . The advantage of using the Ritz estimate kfmkje T m sj is to avoid explicit formation of the direct residual A ^ x(cid:0) ^ x(cid:18) when accessing the numerical accuracy of an approximate eigenpair . In the Hermitian case a small residual implies an accurate answer . However , in the non - Hermitian case , a small kEk does not necessarily imply that the Ritz pair ( ^ x ; (cid:18) ) is an accurate approximation to an eigenpair ( x ; (cid:21) ) of A : The following theorem indicates what accuracy might be expected of a Ritz value as an approximation to an eigenvalue of A : Theorem 4 . 6 . 1 Suppose that (cid:21) is a simple eigenvalue of A nearest the eigenvalue (cid:18) of A + E : Denote the left and right eigenvectors for (cid:21) by y and x , respectively , each of unit length . Then j(cid:21) (cid:0) (cid:18)j (cid:20) kEk jy H xj + O ( kEk 2 ) Proof : See Wilkinson [ page 68 ] [ 42 ] . The number jy H xj is the cosine of the angle between y and x and it determines the conditioning of (cid:21) . Thus , if y and x are nearly orthogonal , the eigenvalue (cid:21) is highly sensitive to perturbations in A but if they are nearly parallel then (cid:21) is insensitive to perturbations . For Hermitian matrices y = x so that jy H xj = 1 and (cid:18) will be an excellent approximation to (cid:21) . However , if the left and right eigenvectors are nearly orthogonal , then even if kEk (cid:25) (cid:15)MkAk , where (cid:15)M is machine precision , (cid:18) may - DRAFT - 31 July 96 CHAPTER 4 . THE IMPLICITLY RESTARTED ARNOLDI METHOD 67 contain few digits , if any , of accuracy . Roughly , as a rule of thumb , if jy H xj (cid:25) 10 (cid:0)d and (cid:15)M (cid:25) 10 (cid:0)t then the leading t (cid:0) d decimal digits of (cid:18) will agree with those of (cid:21) . The question of how close the Ritz vector ^ x is to x is complicated by the fact that an eigenvector is not an unique quantity . Any scaling of an eigenvector by a nonzero complex number is also an eigenvector . For this reason , it is better to estimate the positive angle ' between an eigenvector and its approximation . Theorem 4 . 6 . 2 Suppose that AQ = Q " (cid:21) r T 12 0 R22 # is a Schur form for A and let (cid:21) be a simple eigenvalue of A nearest the eigenvalue (cid:18) of A + E with corresponding eigenvectors x and ^ x respctively . If ' is the positive angle between x and ^ x then ' (cid:20) 2kEkF sep ( (cid:21) ; R22 ) + O ( kEk 2 F ) : Proof : See x 5 in [ 3 ] . The de(cid:12)nition of the quantity sep in this theorem is sep ( (cid:21) ; R22 ) (cid:17) min z6 = 0 k(cid:21)z H (cid:0) z H R22kF kzkF ; and the norm kEkF = ( trace E H E ) 1 2 is the Frobenius norm . This is a more re(cid:12)ned indicator of eigenvector sensitivity that accounts for non - normality as well as clustering of eigenvalues . Varah [ 40 ] shows that sep ( (cid:21) ; R22 ) (cid:20) min (cid:21)i6 = (cid:21) ; (cid:21)i2(cid:27) ( R22 ) j(cid:21) (cid:0) (cid:21)ij ; sep ( (cid:21) ; R22 ) (cid:20) kr12k jy H xj q 1 (cid:0) jy H xj 2 ; ( 4 . 6 . 3 ) where the latter bound is only de(cid:12)ned for nonzero r12 . Thus , the conditioning of the eigenvector problem depends upon both the distance to the other eigenvalues of A and the sensitivity of (cid:21) : Varah also notes that both upper bounds may be signi(cid:12)cant over estimates . Note that when A is symmetric , r12 = 0 and it may be shown that the (cid:12)rst bound is an equality . Multiple eigenvalues or clusters of eigenvalues cause further complications . The above estimates may be extended to these cases through the conditioning of invariant subspaces and angles between invariant subspaces . The conclusion we must draw is that the eigenvalues of a nonsymmetric matrix may be very sensitive to perturbations such as those introduced by round - o(cid:11) error . This sensitivity is intricately tied to the departure from normality of the given matrix . The classic example of a matrix with an extremely ill - conditioned eigensystem is Jm ( (cid:21) ) + (cid:15)eme T 1 where Jm ( (cid:21) ) is bi - diagonal with the number (cid:21) on the diagonal and all ones on the super - diagonal . The eigenvalues (cid:18)j of this perturbed Jordan matrix satisfy j(cid:18)j (cid:0) (cid:21)j = (cid:15) 1 m . This is quite contrary to the behavior of eigenvalues of normal - DRAFT - 31 July 96 4 . 6 . STOPPING CRITERIA 68 matrices . Without further knowledge of the nearness of a given matrix to being non - normal , we must be content with a stopping criterion that assures small backward error in the non - Hermaitian case . This strategy is used in ARPACK , where the Ritz pair ( ^ x ; (cid:18) ) is considered converged when kfmkje T m sj (cid:20) max ( (cid:15)MkHmk ; tol (cid:1) j(cid:18)j ) is satis(cid:12)ed . Since j(cid:18)j (cid:20) kHmk (cid:20) kAk , this implies that ( 4 . 6 . 2 ) is satis(cid:12)ed with kEk (cid:20) tolkAk and this test is invariant to scaling of A through multiplication by a nonzero scalar . The backward error is de(cid:12)ned as the smallest , in norm , perturbation (cid:1)A such that the Ritz pair is an eigenpair for A + (cid:1)A . The recent study [ 22 ] presents a thorough discussion of the many issues involved in determining stopping criteria for the nonsymmetric eigenvalue problem . In ARPACK we are more stringent than just asking for a small backward error relative to kAk . We instead ask for small backward error relative to the projected matrix Hm . - DRAFT - 31 July 96 Chapter 5 Computational Routines This chapter will discuss the implementation details of the main computational rou - tines of ARPACK . We (cid:12)rst give an outline of the code structure . This shows how the Implicitly Restarted Arnoldi / Lanczos Method that was described in Algorithm 3 of Chapter 4 is modularized . Each of the basic steps described in the algorithm de(cid:12)nes a subroutine module , i . e . a computational routine . The basic tasks and salient implementation details are presented here for each of these computational routines . ARPACK relies heavily upon a number of basic operations and algorithms pro - vided by the BLAS and LAPACK . These have contributed greatly to the robustness , accuracy , and computational performance of ARPACK . The most important of these with respect to performance is the BLAS subroutine gemv . For a (cid:12)xed number nev of requested eigenvalues and a (cid:12)xed length ncv Arnoldi basis , the computational cost scales linearly with n , the order of the matrix . The rate of execution ( in FLOPS ) for the IRA iteration is asymptotic to the rate of execution of gemv . In the outline of the implementation described in Figure 5 . 1 , Hj is a j (cid:2) j upper Hessenberg matrix , V H j BVj = Ij , and the residual vector fj is B - orthogonal to the columns of Vj . For each j , OPVj = VjHj + fje T j where OP and B are de(cid:12)ned with respect to one of the computational modes described in Chapter 3 . The integer k denotes the desired number of eigenvalue approximations and this may , at times , be greater than the users request for nev approximations . The integer m = ncv will be the largest size factorization constructed . An eigenvalue (cid:18) of Hj is called a Ritz value of OP and x = Vjs is called a Ritz vector when Hjs = s(cid:18) : The normalization ksk = 1 is assumed throughout . 69 70 Figure 5 . 1 : High level implementation of the IRAM / IRLM in ARPACK (cid:15) When entering XYaupd initially , perform some basic error checking and partition the internal workspace with respect to the input parameters . Set k = nev and m = ncv . (cid:15) Enter XYaup2 . Generate a random initial vector Vme1 = v1 by calling Xgetv0 , unless the initial vector is provided by the caller . (cid:15) Call XYaitr to compute the initial Arnoldi / Lanczos factorization OPVk = VkHk + fke T k of length k = nev : (cid:15) For iter = 1 ; : : : ; maxiter + 1 , 1 . Call XYaitr to extend the length k Arnoldi / Lanczos factorization to a length m factor - ization . Reverse communication is performed to compute matrix vector products with OP and possibly B . 2 . Compute the eigenvalues of Hm and the associated error bounds . Call [ c , d ] seigt for the symmetric eigenvalue problem or Xneigh otherwise . 3 . Call XYgets to partition the eigenvalues into two sets (cid:10)w and (cid:10)u . The k eigenvalues in the set (cid:10)w are the desired approximations while the remaining eigenvalues in the set (cid:10)u are to be used as shifts . 4 . Call XYconv to determine how many of the wanted Ritz values satisfy the convergence tolerance . 5 . Exit the loop if all k eigenvalues in (cid:10)w satisfy the convergence criterion , or iter = maxiter + 1 . 6 . Possibly increment k : Determine p = m(cid:0)k shifts f(cid:22)jg p j = 1 . If the exact shift strategy is used , the eigenvalues of (cid:10)u are used as shifts otherwise the p shifts are provided through a reverse communication interface . If p = 0 , exit the loop . 7 . Implicitly restart the Arnoldi / Lanczos factorization by calling XYapps . ( a ) Perform p steps of the implicitly shifted QR algorithm on Hm with f(cid:22)jg p j = 1 result - ing in HmQm = QmH + m where H + m and Qm are upper Hessenberg and orthogonal matrices , respectively . ( b ) Let Qk denote the matrix consisting of the (cid:12)rst k columns of Qm and H + k the leading principal submatrix of H + m of order k : Update V + k = VmQk to obtain the new length k Arnoldi factorization OPV + m = V + mH + k + f + k e T k ; ( See Algorithm 3 , Chap . 4 ) . (cid:15) End For (cid:15) Call XYeupd for computing Ritz and / or Schur vectors and for transforming the Ritz values of OP if a spectral transformation was used . - DRAFT - 31 July 96 CHAPTER 5 . COMPUTATIONAL ROUTINES 71 5 . 1 ARPACK subroutines Table 5 . 1 lists all the auxiliary subroutines of ARPACK . The naming convention is XY < mnemonic > The (cid:12)rst letter X is one of the letter s , d , c , z and denotes the data type as follows : s single precision real arithmetic , d double precision real arithmetic , c single precision complex arithmetic , z double precision complex arithmetic . If the second letter Y occurs , it is one of the letters s , n that denote the type of eigensystem as follows : n non - symmetric , s symmetric . For the subroutines listed in Table 5 . 1 that start with \ [ X1 , X2 ] " , only those data types are available . 5 . 1 . 1 XYaupd The top level subroutine XYaupd provides the reverse communication interface to the IRA or IRL iterations . The user directly calls subroutine XYaupd in one of the reverse communication modes to compute the eigenvalues of the linear operator de(cid:12)ned by OP required for the computational mode selected by the user . Every time an operation involving OP and / or B is needed , XYaupd prompts the user to provide the action of OP and / or B on a vector and then re - enter XYaupd . This is the reverse communication interface . During the initial call to subroutine XYaupd , error checking is performed on many of the input arguments . The workspace provided to XYaupd is also partitioned and various counters and pointers are initialized . 5 . 1 . 2 XYaup2 Subroutine XYaup2 implements Algorithm 2 ( see Figure 4 . 3 ) in Chapter 4 . The deci - sion to terminate the IRAM / IRLM is made in XYaup2 . The iteration is terminated either when the requested number of wanted Ritz values satisfy the convergence cri - terion or when the speci(cid:12)ed maximum number of iterations has been exceeded . For both situations XYaup2 is exited with a complete length m Arnoldi / Lanczos factor - ization and the number of Ritz values that satisfy the convergence criterion is stored . This allows the user to call XYeupd and compute the eigenvalues and eigenvectors or Schur vectors that have converged to within the requested tolerance . At step 6 , k may be increased for one of three reasons . The primary reason occurs when the exact shift strategy is used . In this case , the number of shifts to apply - DRAFT - 31 July 96 5 . 1 . ARPACK SUBROUTINES 72 Table 5 . 1 : Description of the auxiliary subroutines of ARPACK . ROUTINE DESCRIPTION XYaupd Top level subroutine that implements the IRAM . XYeupd This routine computes eigenvectors and / or Schur vectors for the computed eigenvalues . XYaup2 Intermediate level interface called by XYaupd that performs the iteration . Xgetv0 Initial vector generation subroutine . XYaitr Arnoldi factorization subroutine . Xneigh Compute Ritz values and error bounds subroutine for the non - symmetric and non - Hermitian eigenvalue problems . [ s , d ] seigt Compute Ritz values and error bounds subroutine for the symmetric eigenvalue problem . XYgets Sort the Ritz values and corresponding error bounds . [ s , d ] Yconv Determines which Ritz values satisfy the convergence criterion . XYapps Application of implicit shifts routine . Xortc Sorting routines for complex vectors . [ s , d ] ortr Sorting routine for real vectors . [ s , d ] laqrb Compute the eigenvalues and the last components of the Schur vectors of an upper Hessenberg matrix . [ s , d ] stqrb Compute the eigenvalues and the last components of the eigenvectors of a symmetric tridiagonal matrix . - DRAFT - 31 July 96 CHAPTER 5 . COMPUTATIONAL ROUTINES 73 is decreased by 1 for every wanted Ritz value in (cid:10)w that satis(cid:12)es the convergence criterion . Since p = m (cid:0) k this is most easily achieved by increasing the value of k . This scheme helps prevent stagnation of the IRAM / IRLM . If k is held (cid:12)xed at its original value of nev , the polynomial restarting becomes less and less e(cid:11)ective as as the number of converged wanted Ritz values approaches nev . The linear rate of convergence is related directly to the ratios j ( (cid:21)j ) j = j ( (cid:21)i ) j of the restart ( or (cid:12)lter ) polynomial evaluated at wanted eigenvalues (cid:21)i and unwanted eigenvalues (cid:21)j ( See ( 4 . 4 . 4 ) in Chapter 4 ) . These ratios become unfavorable for wanted eigenvalues (cid:21)i that are too close to the convex hull of the zero set of the (cid:12)lter polynomial . Increasing k arti(cid:12)cially increases the distance of the wanted eigenvalues to the zero set of the (cid:12)lter polynomial and as a consequence improves ( i . e . decreases ) these ratios and decreases the linear convergence factor . A check is performed so that k never exceeds ( ncv - nev ) / 2 . A second reason to increase k is when an unwanted Ritz value in (cid:10)u has converged to the point that it has a computed zero error estimate . The value of k is incremented for every such instance . This prevents attempting to implicitly shift with a converged unwanted Ritz value that is located in a leading submatrix of Hm that has split from active portion of the iteration . The third way k may be increased can only occur in [ s , d ] naup2 . Complex conju - gate pairs of Ritz values must be classi(cid:12)ed together either as members of the unwanted set (cid:10)u or of the wanted set (cid:10)w : If such a pair would have to be split between the two sets then the value of k is increased by 1 so that both are included in the wanted set (cid:10)w : If the user has decided to provide the shifts for implicit restarting via reverse communication , the only manner in which p may be decreased from m (cid:0) k is for second and third reasons given above . One example of shifts that the user may wish to provide is the set of roots of a Chebyshev polynomial of degree p that has been constructed to be small in magnitude over an elliptical region that ( approximately ) encloses the unwanted eigenvalues . Typically , an ellipse that encloses the set (cid:10)u but excludes the set (cid:10)w is constructed and the Chebyshev polynomial of degree p that is small on the ellipse is then speci(cid:12)ed [ 34 ] . 5 . 1 . 3 XYaitr Subroutine XYaitr is responsible for all the work associated with building the needed factorization . It implements Algorithm 2 of Chapter 4 using the classical Gram { Schmidt procedure with possible re - orthogonalization by the DGKS scheme . At each step j , a residual vector fj is computed that is numerically orthogonal to the columns of Vj : If kfjk (cid:20) sin ( (cid:25) = 4 ) kAVjejk ; a step of re - orthogonalization is performed in order to produce an updated residual ^ fj : If the angle between the successive residual vectors ^ fj and fj is greater than (cid:25) = 4 then the orthogonalization has been successful and fj is replaced by ^ fj and the last column of H is updated . Otherwise , another re - orthogonalization step is required . This is repeated at most one more time . If a - DRAFT - 31 July 96 5 . 1 . ARPACK SUBROUTINES 74 third re - orthogonalization is necessary , then the original AVjej lies in the numerical span of the columns of Vj . In the event that a third re - orthogonalization is necessary , special action must be taken . If this occurs , then it means that the component of the original AVjej that is orthogonal to the Range ( Vj ) is indistiguishable from roundo(cid:11) error . Numerically , the columns of Vj form a basis for an invariant subspace of A and consequently the corresponding subdiagonal element (cid:12)j is set to zero . In order to continue building the Arnoldi factorization to the desired length , an arbitrary nonzero vector vj + 1 must be generated that is orthogonal to the existing columns of Vj : This is accomplished by generating a random vector and orthogonalizing it against the columns of Vj to get the new basis vector vj + 1 . In the non - symmetric case , the j + 1 - st column of H and the new residual vector fj + 1 are obtained by applying the Gram - Schmidt procedure to orthogonalize Avj + 1 against the columns of ( Vj ; vj + 1 ) : 5 . 1 . 4 Xgetv0 The subroutine Xgetv0 is responsible for generating starting vectors . It is called upon to construct the initial Arnoldi / Lanczos vector when this option is requested . Xgetv0 is also called upon to generate a new basis vector when the re - orthogonalization scheme of XYaitr calls for this , i . e . when an invariant subspace is encountered early during the construction of the Arnoldi factorization . In the latter case , the vector that is returned by Xgetv0 is already orthogonalized against the existing set of basis vectors . In either case , if the ( shift - invert ) computational mode calls for it , the vector is also forced to be in the range of OP . The LAPACK subroutine Xlarnv is used to generate the random vectors . Subroutine Xgetv0 is called by XYaup2 and XYaitr . 5 . 1 . 5 Xneigh Subroutine [ s , d ] neigh calls the ARPACK subroutine [ s , d ] laqrb . This routine is a modi(cid:12)ed version of the LAPACK subroutine [ s , d ] lahqr for computing a real Schur form for an upper Hessenberg matrix . Subroutine [ s , d ] laqrb computes the upper quasi - triangular Schur matrix just as [ s , d ] lahqr does but it only computes the last components of the associated Schur vectors since these are all that is needed for the error estimates . The complex arithmetic subroutine [ c , z ] neigh computes the complete Schur decomposition of the projected matrix Hm using LAPACK subroutine [ c , z ] lahqr . The subroutine [ c , z ] neigh then calls the LAPACK subroutine [ c , z ] trevc to compute the eigenvectors of the upper quasi - triangular Schur matrix . However , just as in real arithmetic case , only the last components of these eigenvectors are needed for computing error estimates . - DRAFT - 31 July 96 CHAPTER 5 . COMPUTATIONAL ROUTINES 75 5 . 1 . 6 [ s , d ] seigt Subroutine [ s , d ] seigt calls the ARPACK subroutine [ s , d ] stqrb that computes the eigenvalues and last components of the corresponding eigenvectors of the real symmet - ric tridiagonal matrix . This is a modi(cid:12)cation of the LAPACK subroutine [ s , d ] stqr . [ s , d ] seigt performs the task equivalent to [ s , d ] neigh but takes advantage of sym - metry . 5 . 1 . 7 [ s , d ] Yconv Subroutine [ s , d ] Yconv declares that a Ritz value (cid:18) is an acceptable approximation to an eigenvalue of OP if kfmkje T m sj (cid:20) max ( (cid:15)MkHmk ; tol(cid:1)j(cid:18)j ) is satis(cid:12)ed . Subroutine [ c , z ] naup2 performs the checks directly within the code . The value of tol is de(cid:12)ned by the user and has a default of machine precision (cid:15)M . Since kOPx(cid:0)x(cid:18)k = kfmkje T m sj ; ARPACK avoids computation of the direct residual OPx (cid:0) x(cid:18) when accessing the numerical quality of the Ritz pair . CAUTION : Only for symmetric ( Hermitian ) eigenproblems may the user assume that a computed Ritz value is an accurate approximation to an eigenvalue of OP . As x 4 . 6 of Chapter 4 explained , determining whether IRAM computes accurate eigenvalues for non - symmetric ( non Hermitian ) eigenproblems depends on the sensitivity of the eigenproblem . Also , note that if OP is from a shift - invert spectral transformation , then the eigenvector puri(cid:12)cation step performed by XYeupd will most likely result in smaller residuals for the original problem than those obtained for OP ( See ( 4 . 5 . 1 ) in Chapter 4 ) . 5 . 1 . 8 XYapps Subroutine XYapps applies the shifts using an implicitly shifted QR mechanism on the projected matrix Hm : If a shift is complex , then [ s , d ] napps employs a double implicit shift application so that the complex conjugate of the shift is applied simul - taneously . This allows the implicit shift application to take place in real arithmetic . Finally , XYapps updates the current Arnoldi / Lanczos basis to obtain the new length k factorization and f + k : Subdiagonals of the Hessenberg matrices are set to zero if they satisfy the same criterion as used in a standard implementation of the QR algo - rithm . This amounts to checking if any subdiagonal of Hm is less than the product of machine precision and the sum of the two adjacent diagonal elements of Hm : 5 . 1 . 9 XYeupd The purpose of XYeupd is to obtain the requested eigenvalues and eigenvectors ( or Schur basis vectors ) for the original problem Ax = (cid:21)Mx from the information com - puted by XYaupd for the linear operator OP . Regardless of whether a spectral transfor - mation is used , the eigenvectors will remain unchanged on transforming back to the original problem . If a spectral transformation is used , then subroutine XYaupd will - DRAFT - 31 July 96 5 . 1 . ARPACK SUBROUTINES 76 Figure 5 . 2 : Outline of algorithm used by subroutine XYeupd to compute Schur vectors and possibly eigenvectors . 1 . Compute the partial Schur form HmQk = QkRk where the k converged wanted Ritz values computed by XYaupd are located on the diagonal of the upper triangular matrix Rk of order k : 2 . Compute the approximate Schur vectors of A by forming VmQk and placing in the (cid:12)rst k columns of Vm : Denote the matrix consisting of these (cid:12)rst k columns by Vk : 3 . If eigenvectors are desired , then ( a ) Compute the eigendecomposition RkSk = SkDk : ( b ) Compute the Ritz vectors by forming VkSk : compute eigenvalues of OP : Subroutine XYeupd maps them to those of Ax = (cid:21)Mx ex - cept in two cases . The exceptions occur when using [ s , d ] naupd with a complex shift (cid:27) with either of OP = Real ( ( A(cid:0)(cid:27)M ) (cid:0)1 M ) or OP = Imag ( ( A(cid:0)(cid:27)M ) (cid:0)1 M ) : Note that if (cid:27) is a real shift , [ s , d ] neupd can recover the eigenvalues since then OP real = (cid:22) OP real : Otherwise , the eigenvalues must be recovered by the user , preferabley by using the converged Ritz vectors and computing Rayleigh quotients with them for the original problem . We hope to automate this step in a future release . If eigenvectors are desired , an orthonormal basis for the invariant subspace corre - sponding to the converged Ritz values is (cid:12)rst computed . The vectors of this orthonor - mal basis are called approximate Schur vectors for A : Figure 5 . 2 outlines our strategy . Refer to Figure 5 . 2 for de(cid:12)nitions of the quantities discussed in the remainder of this section . For symmetric eigenvalue problems [ s , d ] seupd does not need Step 3 of Figure 5 . 2 since Schur vectors are also eigenvectors . Moreover , a special routine is not required to re - order the Schur form since Rk is a diagonal matrix of real eigenvalues . For real non - symmetric eigenvalue problems , [ s , d ] neupd uses the real Schur form . That is , Rk is an upper quasi - triangular matrix with 1 - by - 1 and 2 - by - 2 diagonal blocks ; each 2 - by - 2 diagonal block has its diagonal elements equal and its o(cid:11) - diagonal elements of opposite sign . Associated with each 2 - by - 2 diagonal block is a complex conjugate pair of eigenvalues . The real eigenvalues are stored on the diagonal of Rk : Similarly , Dk is a block diagonal matrix . When the eigenvalue is complex , the complex eigenvector associated with the eigenvalue with positive imaginary part is stored in two consecutive columns of Sk : The (cid:12)rst column holds the real part of the eigenvector and the second column holds the imaginary part . The eigenvector associated with the eigenvalue with negative imaginary part is simply the complex conjugate of the eigenvector associated with the positive imaginary part . The computed Ritz vectors are stored in the same manner . The computation of the partial Schur form needed at Step 1 is performed by (cid:12)rst calling the appropriate LAPACK subroutine that computes the full Schur decompo - sition of Hm : Another LAPACK subroutine , Xtrsen , re - orders the computed Schur - DRAFT - 31 July 96 CHAPTER 5 . COMPUTATIONAL ROUTINES 77 Table 5 . 2 : Description of the LAPACK computational routines used by ARPACK . ROUTINE DESCRIPTION Xtrsen Re - orders the Schur form of a matrix . [ s , d ] steqr Diagonalize a symmetric tridiagonal matrix . ctrevc Computes the eigenvectors of a matrix in upper triangular form . strevc Computes the eigenvectors of a matrix in upper quasi - triangular form . form to obtain Qk and Rk : The approximate Schur vectors are formed by comput - ing the QR factorization of Qk and then postmultiplying Vm with the factored form . This avoids the need for the additional storage that would be necessary if VmQk were computed directly . The appropriate LAPACK subroutines are used to compute and apply the QR factorization of Qk : The factored approach described above is extremely stable and e(cid:14)cient since Qk is a numerically orthogonal matrix . In exact arithmetic , there would be no need to perform the reordering ( or the sorting for the symmetric eigenvalue problem ) . In theory , the implicit restarting mechanism would obviate the need for this . However , computing in (cid:12)nite precision arithmetic ( as usual ) complicates the issue and make these (cid:12)nal reorderings manda - tory . See Chapter 5 in [ 20 ] and [ 23 ] for further information . When Ritz vectors are required , the LAPACK subroutine Xtrevc is called to com - pute the decomposition RkSk = SkDk : Since Sk is an upper quasi triangular matrix , the product VkSk is easily formed using the level 3 BLAS subroutine Xtrmm . 5 . 2 LAPACK routines used by ARPACK ARPACK uses a variety of LAPACK auxiliary and computational subroutines . An auxiliary routine is one that performs some basic computation and / or an unblocked form of an algorithm . On the other hand , a computational routine typically imple - ments the block version of the algorithm . For example , the computational subroutine Xhseqr determines the eigenvalues and Schur decomposition of an upper Hessenberg matrix using a multishift QR algorithm . The auxiliary routine Xlahqr implements the standard double shift form of the QR algorithm for determining the eigenvalues and Schur decomposition . For further details and information , see Chapter 2 and Appendices A and B in [ 1 ] . Tables 5 . 2 and 5 . 3 list all the LAPACK routines used by ARPACK . The current release of LAPACK used is version 2 . 0 . - DRAFT - 31 July 96 5 . 2 . LAPACK ROUTINES USED BY ARPACK 78 Table 5 . 3 : Description of the LAPACK auxiliary routines used by ARPACK . ROUTINE DESCRIPTION Xlahqr Computes the Schur decomposition of an upper Hessenberg matrix . Xgeqr2 Computes the QR factorization of a matrix . sorm2r Applies a real orthogonal matrix in factored form . cunm2r Applies a complex orthogonal matrix in factored form . Xlascl Scales a matrix stably . Xlanhs Compute various matrix norms of a Hessenberg matrix . Xlacpy Perform a matrix copy . Xlamch Determine various machine parameters . [ s , d ] labad Determines over - and under(cid:13)ow limits . [ s , d ] lapy2 Compute p x 2 + y 2 stably . Xlartg Generates a plane rotation . [ s , d ] larfg Generates a real elementary re(cid:13)ector . [ s , d ] larf Applies a real elementary re(cid:13)ector H to a real matrix . Xlaset Initialize a matrix . - DRAFT - 31 July 96 CHAPTER 5 . COMPUTATIONAL ROUTINES 79 Table 5 . 4 : Description of the Level three BLAS used by ARPACK . ROUTINE DESCRIPTION Xtrmm Matrix times an upper triangular matrix . Table 5 . 5 : Description of the Level two BLAS used by ARPACK . ROUTINE DESCRIPTION Xgemv Matrix vector product . [ d , s ] ger Rank one update to a real matrix . [ c , z ] geru Rank one update to a complex matrix . 5 . 3 BLAS routines used by ARPACK Tables 5 . 4 { 5 . 6 list all the BLAS subroutines called by ARPACK directly . We remark that there are other BLAS subroutines needed by ARPACK that are called by the LAPACK routines . - DRAFT - 31 July 96 Table 5 . 6 : Description of the Level one BLAS used by ARPACK . ROUTINE DESCRIPTION Xaxpy Compute a vector triad . Xscal Scale a vector . [ s , d ] dot Compute a real inner product . [ c , z ] dotc Compute a complex inner product . [ c , z ] sscal Scale a vector with a real constant . [ s , d ] nrm2 Computes the Euclidean norm of a real vector . [ sc , dz ] nrm2 Computes the Euclidean norm of a complex vector . Xcopy Copy one vector to another . Xswap Swap two vectors Appendix A Templates and Driver Routines In addition to the simple drivers described in Chapter 2 , a set of example drivers that demonstrate how to use ARPACK for solving both standard and generalized eigenvalue problems in various modes is also provided . These drivers can be found in the following subdirectories in the EXAMPLES directory . This directory is listed below . SYM Real symmetric eigenvalue problems . NONSYM Real non - symmetric eigenvalue problems . COMPLEX Complex eigenvalue problems . BAND Eigenvalue problems in which matrices are stored in LAPACK band form . SVD Singular value decomposition ( SVD ) problems . These drivers are intended to be used as templates for constructing an user interface to ARPACK ' s computational routines . Each driver illustrates how variables are declared and used , how the reverse communication communication interface is used within a particular computational mode , and how to check the accuracy of the computed results . This Appendix provides some guidance on deciding which driver to select and how to use it e(cid:11)ectively . In order to make the process of building an user ' s application code from these drivers e(cid:14)cient , we discuss the necessary steps to be followed in this process . These steps are may be summarized as follows : (cid:15) Selecting an appropriate driver . (cid:15) Identifying and constructing the linear operator OP and the matrix B used in a driver . (cid:15) Substituting the constructed the linear operator OP and the matrix B in the reverse communication interface . (cid:15) Modifying the problem dependent variables . 81 A . 1 . SYMMETRIC DRIVERS 82 Table A . 1 : The functionality of the symmetric drivers . DRIVER PROBLEM SOLVED dsdrv1 Standard eigenvalue problem ( bmat = ' I ' ) in the regular mode ( iparam ( 7 ) = 1 . ) dsdrv2 Standard eigenvalue problem ( bmat = ' I ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) dsdrv3 Generalized eigenvalue problem ( bmat = ' G ' ) in the regular inverse mode ( iparam ( 7 ) = 2 . ) dsdrv4 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) dsdrv5 Generalized eigenvalue problem ( bmat = ' G ' ) in the Buckling mode ( iparam ( 7 ) = 4 . ) dsdrv6 Generalized eigenvalue problem ( bmat = ' G ' ) in the Cayley mode ( iparam ( 7 ) = 5 . ) (cid:15) Checking the accuracy of the computed results . This procedure is discussed in xx A . 1 { A . 3 for the solution of symmetric , nonsymmetric and complex arithmetic eigenvalue problems with ARPACK . A . 1 Symmetric Drivers There are six drivers for the symmetric eigenvalue problem ( A = A T and M = M T ) . They are named in the form of XsdrvY , where the (cid:12)rst character X speci(cid:12)es the precision used as follows : s single precision d double precision . The last character Y is a number between 1 and 6 indicating the type of the problem to be solved and the mode to be used . Each number is associated with a unique combination of the bmat and iparam ( 7 ) variables . Table A . 1 lists the problem solved by each double precision driver . The (cid:12)rst four drivers are the most commonly used . The last two drivers use two special spectral transformations that may accelerate the convergence for particular problems . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 83 A . 1 . 1 Selecting a Symmetric Driver Several drivers may be used to solve the same problem . However , one driver may be more appropriate or may be easier to modify than the others . This decision typically depends upon the nature of the application and the portion of the spectrum to be computed . See x 3 . 2 of Chapter 3 for more discussion on the issues that should be considered when deciding to use a spectral transformation . Standard Mode Driver dsdrv1 solves the standard eigenvalue problem Ax = x(cid:21) : This mode only requires matrix vector products with A : It is appropriate for com - puting extremal , non - clustered eigenvalues . Shift - Invert Mode Driver dsdrv2 uses the shift - invert mode to (cid:12)nd eigenvalues closest to a shift (cid:27) . This is often used to compute interior eigenvalues or clustered extremal eigenvalues . For a discussion on shift - invert mode , see x 3 . 2 of Chapter 3 . To use dsdrv2 , the user is required to supply the action of w ( A (cid:0) (cid:27)I ) (cid:0)1 v : This is typically accomplished by factoring the matrix A (cid:0) (cid:27)I and then solving the resulting linear system . Generalized Eigenvalue Problem If the generalized eigenvalue problem Ax = (cid:21)Mx ; is to be solved , then one of the drivers dsdrv3 , dsdrv4 , dsdrv5 , dsdrv6 is used . We remark , that if either A or M may be factored , then the generalized eigenvalue problem may be converted to a standard eigenvalue problem as described inx 3 . 2 of Chapter 3 , Regular Inverse Mode Driver dsdrv3 uses the regular inverse mode to solve the generalized eigenvalue prob - lem . This mode should be used if M is symmetric and positive de(cid:12)nite but it is not feasible to compute a sparse direct Cholesky factorization M = LL T . It might also be - DRAFT - 31 July 96 A . 1 . SYMMETRIC DRIVERS 84 appropriate if M can be factored but there is reason to think that M is ill - conditioned . To use dsdrv3 the user must supply the action of w M (cid:0)1 Av and w Mv The action of M (cid:0)1 is typically done with an iterative solver such as pre - conditioned conjugate gradient . The use of M - inner products restores symmetry . If M can be factored then direct conversion to a standard problem is recommended . Shift - Invert Mode Driver dsdrv4 uses the shift - inverse mode to solve the generalized eigenvalue problem . Eigenvalues closest to a shift (cid:27) can be obtained by computing the eigenvalues (cid:18) of largest magnitude for ( A (cid:0) (cid:27)M ) (cid:0)1 Mx = x(cid:18) : The eigenvalue (cid:21) of the original problem and (cid:18) are related by (cid:21) = (cid:27) + 1 (cid:18) To use dsdrv4 , the user is required to supply the two matrix vector operations w ( A (cid:0) (cid:27)M ) (cid:0)1 v ; and w Mv where (cid:27) is the shift de(cid:12)ned by the user . Typically , the above matrix operation is performed by factoring A (cid:0) (cid:27)M and solving the resulting linear system . Buckling Mode Driver dsdrv5 implements the Buckling transformation . Eigenvalues closest to a shift (cid:27) can be obtained by computing the largest eigenvalues (cid:18) of OPx (cid:17) ( A (cid:0) (cid:27)M ) (cid:0)1 Ax = x(cid:18) : This mode assumes that A is a symmetric postive semi de(cid:12)nite matrix . Note that the operator OP is symmetric with respect to the semi - inner product de(cid:12)ned by A : The eigenvalue (cid:21) of the original problem and (cid:18) are related by (cid:21) = (cid:27)(cid:18) (cid:18) (cid:0) 1 Note that (cid:27) = 0 should not be used for this mode . The two operations w ( A (cid:0) (cid:27)M ) (cid:0)1 y and y Mv are required in order to use this driver . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 85 Table A . 2 : The operators OP and B . DRIVER OP B dsdrv1 A I dsdrv2 ( A (cid:0) (cid:27)I ) (cid:0)1 I dsdrv3 M (cid:0)1 A M dsdrv4 ( A (cid:0) (cid:27)M ) (cid:0)1 M M dsdrv5 ( A (cid:0) (cid:27)M ) (cid:0)1 A A dsdrv6 ( A (cid:0) (cid:27)M ) (cid:0)1 ( A + (cid:27)M ) M Cayley Transformation Mode Driver dsdrv6 implements the Cayley spectral transformation . Eigenvalues closest to a shift (cid:27) can be obtained by computing the largest eigenvalues (cid:18) of OPx (cid:17) ( A (cid:0) (cid:27)M ) (cid:0)1 ( A + (cid:27)M ) x = x(cid:18) : Note that OP is symmetric with respect to the ( semi ) inner product de(cid:12)ned by M : The eigenvalue (cid:21) of the original problem and (cid:18) are related by (cid:21) = (cid:27) (cid:18) 1 + (cid:18) 1 (cid:0) (cid:18) (cid:19) : Note that the transformation becomes ill - de(cid:12)ned as (cid:27) ! 0 since (cid:18) ! 1 . There is a limit but it would be better to use shift - invert mode with (cid:27) = 0 . It has slightly di(cid:11)erent properties that the standard shift and invert spectral transformation used by drivers dsdrv3 and dsdrv4 . To use this driver , the operations w ( A (cid:0) (cid:27)M ) (cid:0)1 y and y ( A + (cid:27)M ) v are required . A . 1 . 2 Identify OP and B for the Driver The next step is to identify the linear operator OP and matrix B associated with that driver . Eigenvalues of OP are computed by the computational routine dsaupd . These eigenvalues are converted to those of A or ( A ; M ) in the post - processing routine dseupd . The Lanczos vectors generated by dsaupd are orthogonal with respect to the inner product de(cid:12)ned by B . It is imperative that the operations OPv and Bv be computed correctly . Table A . 2 summarizes the operators OP and B de(cid:12)ned in each driver . - DRAFT - 31 July 96 A . 1 . SYMMETRIC DRIVERS 86 Because of the reverse communication interface in ARPACK , the construction of w OPv and w Bv is left completely to the user . This means that the user is free to choose any convenient data structure for the matrix representation . If the matrix is not available , their user is free to express the action of the matrix on a vector through a subroutine call or a code segment . A . 1 . 3 The Reverse Communication Interface The use of the reverse communication interface for the regular and shift - invert modes was illustrated in Chapter 2 and 3 , respectively . The most general structure of the reverse communication loop is presented in Figure A . 1 . The speci(cid:12)c actions to be taken within the loop varies with the drivers used . Each action in Figure A . 1 corresponds to an ido value returned from the call to dsaupd . These actions involve matrix vector operations such as w OPv and w Bv : The matrix vector operation must be performed on the correct portion of the work array workd . We discuss the details on how the matrix vector operation are performed in each driver below . Driver dsdrv1 Only the action w Av is taken in this driver . It is indicated by ido = 1 . The matrix vector multiplication w Av takes workd ( ipntr ( 1 ) ) as input , and the output is returned in the array workd ( ipntr ( 2 ) ) . Driver dsdrv2 Only the action w ( A (cid:0) (cid:27)I ) (cid:0)1 v is taken in this driver . It is also indicated by ido = - 1 or ido = 1 . The action requires that linear systems ( A (cid:0) (cid:27)I ) w = v be solved . The linear solve takes workd ( ipntr ( 1 ) ) ( righthand side ) as input , and the output ( solution ) is returned in the array workd ( ipntr ( 2 ) ) . Driver dsdrv3 All three actions listed in Figure A . 1 are taken here . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w M (cid:0)1 y where y = Av : When ido = - 1 , the starting vector is multiplied by OP = M (cid:0)1 A : This should occur only once . The matrix vector multiplication y Av takes workd ( ipntr ( 1 ) ) as the input . The intermediate vector y should overwrite workd ( ipntr ( 1 ) ) . It is also used as the right hand side of the of the linear system Mw = y : The solution of the linear system is returned in workd ( ipntr ( 2 ) . When ido = 2 , the action w Mv takes workd ( ipntr ( 1 ) ) as the input . The result is again returned in workd ( ipntr ( 2 ) ) . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 87 c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | M A I N L O O P ( Reverse communication loop ) | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c 10 continue c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | Repeatedly call the routine DSAUPD and take | c | actions indicated by parameter IDO until | c | either convergence is indicated or maxitr | c | has been exceeded . | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c call dsaupd ( ido , bmat , n , which , nev , tol , resid , & ncv , v , ldv , iparam , ipntr , workd , workl , & lworkl , info ) c if ( ido . eq . - 1 ) then c w OP * v c c % - - - - - L O O P B A C K to call DSAUPD again . - - - - - % c go to 10 c else if ( ido . eq . 1 ) then c w OP * v c c % - - - - - L O O P B A C K to call DSAUPD again . - - - - - % c go to 10 c else if ( ido . eq . 2 ) then c w B * v c c % - - - - - L O O P B A C K to call DSAUPD again . - - - - - % c go to 10 c end if Figure A . 1 : Reverse communication structure - DRAFT - 31 July 96 A . 1 . SYMMETRIC DRIVERS 88 Driver dsdrv4 All three actions listed in Figure A . 1 must be taken . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w ( A(cid:0)(cid:27)M ) (cid:0)1 Mv : When ido = - 1 , the starting vector is projected into the range of OP = ( A(cid:0)(cid:27)M ) (cid:0)1 M : This should occur only once . The matrix vector multiplication y Mv with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . The matrix vector multiplication y Mv is not needed when ido = 1 since it has already been com - puted and saved in workd ( ipntr ( 3 ) ) when ido = 2 . When ido = 1 , the linear system ( A (cid:0) (cid:27)M ) w = y uses workd ( ipntr ( 3 ) ) as the right hand side . The last action ( indicated by ido = 2 ) w Mx takes workd ( ipntr ( 1 ) ) as the input , and returns the result in workd ( ipntr ( 2 ) ) . Driver dsdrv5 The actions taken in this driver are similar to those in dsdrv4 but with di(cid:11)erent OP and B . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w ( A (cid:0) (cid:27)M ) (cid:0)1 Av : When ido = - 1 , the starting vector is projected into the range of OP = ( A (cid:0) (cid:27)M ) (cid:0)1 A : This should occur only once . The matrix vector multiplication y Av with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . This intermediate vector y is used as the right hand side in ( A (cid:0) (cid:27)M ) w = y : ( A . 1 . 1 ) The solution of ( A . 1 . 1 ) is returned in workd ( ipntr ( 2 ) ) . No matrix vector mul - tiplication y Av is needed when ido = 1 since it has been computed and saved in workd ( ipntr ( 3 ) ) when ido = 2 . The linear system of equation ( A . 1 . 1 ) simply uses workd ( ipntr ( 3 ) ) as the right hand side . The solution is returned in the array workd ( ipntr ( 2 ) ) . The action w Ax indicated by ido = 2 takes workd ( ipntr ( 1 ) ) as the input , and returns the result in workd ( ipntr ( 2 ) ) . Driver dsdrv6 The actions taken in this driver are similar to those in dsdrv4 but with di(cid:11)erent OP and B . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w ( A (cid:0) (cid:27)M ) (cid:0)1 ( A + (cid:27)M ) v : When ido = - 1 , the starting vector is projected into the range of OP = ( A(cid:0)(cid:27)M ) (cid:0)1 ( A + (cid:27)M ) : This should occur only once . The matrix vector multiplications y Mv and z Av with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . The vector b (cid:17) z + (cid:27)y is used as the right hand side of ( A (cid:0) (cid:27)M ) w = b : ( A . 1 . 2 ) The solution is returned in workd ( ipntr ( 2 ) ) . When ido = 1 , only the matrix vector multiplication z Av is needed since y Mv has been computed and saved in workd ( ipntr ( 3 ) ) when ido = 2 . The vector z is combined with workd ( ipntr ( 3 ) ) to - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 89 Table A . 3 : The eigenvalues of interest for symmetric eigenvalue problems . which EIGENVALUES ' LA ' Largest ( algebraic ) eigenvalues . ' SA ' Smallest ( algebraic ) eigenvalues . ' LM ' Largest eigenvalues in magnitude . ' SM ' Smallest eigenvalues in magnitude . ' BE ' Eigenvalue at both ends . When nev is odd , compute one more from the high end than from the low end . form the right hand side of ( A . 1 . 2 ) . The solution of equation ( A . 1 . 2 ) is returned in workd ( ipntr ( 2 ) ) . The matrix vector product w Mx indicated by ido = 2 takes workd ( ipntr ( 1 ) ) as the input , and returns the resulting matrix vector product in workd ( ipntr ( 2 ) ) . A . 1 . 4 Modify the problem dependent variables These variables include : n The dimension of the problem . nev The number of eigenvalues needed . ncv The length of the Arnoldi factorization . This represents the maximum number of Arnoldi vectors used . which The eigenvalues of interest . info Set to 0 for a randomly generated starting vector . If the user decides to use another starting vector , this value should be set to 1 , and the starting vector should be provided in the array resid . sigma The shift used if a spectral transformation is employed . The variable nev may be set to be a value larger than the number of eigenvalues desired to avoid splitting a eigenvalue cluster . The only restriction is that nev must be less than ncv . The initial choice of ncv is ncv = 2 (cid:1) nev is recommended . The user is encouraged to experiment with both nev and nev . The choices available for the input variable which is listed in Table A . 3 . We remark that when using a spectral - DRAFT - 31 July 96 A . 1 . SYMMETRIC DRIVERS 90 transformation is employed , only the selections ' LM ' , ' LA ' or ' SA ' should be used . Once the above variables are modi(cid:12)ed , the storage declarations integer maxn , maxnev , maxncv , ldv parameter ( maxn = 256 , maxnev = 10 , maxncv = 25 , ldv = maxn ) should be adjusted so that the conditions n (cid:20) maxn , nev (cid:20) maxnev , ncv (cid:20) maxncv , nev (cid:20) ncv + 1 are satis(cid:12)ed . Other Variables The following variables are also set in all drivers . Their usage is described in Chap - ter 2 . In most cases , they do not need to be changed . lworkl The size of the work array workl used by dsaupd . Must be set to at least ncv * ( ncv + 8 ) . tol The convergence criterion . The default is to set it to 0and a value of machine precision is used . It can be changed depending on the accuracy desired . Typically , the smaller this value the more work is required to satisfy the stopping criteria . However , setting this value too large may cause eigenvalues to be missed when there are multiple or clustered eigenvalue . ido The reverse communication (cid:13)ag . Must be set to 0 before entering dsaupd . bmat Designates whether a standard ( bmat = ' I ' ) or generalized eigenvalue ( bmat = ' G ' ) problem iparam ( 1 ) The shifting strategy used during the implicitly restarted portion of an IRLM . Unless the user has an expert understanding of an IRLM , an exact shifting strategy selected by setting iparam ( 1 ) = 1 should be used . iparam ( 3 ) Maximum number of IRLM iterations allowed . iparam ( 7 ) Indicates the algorithmic mode used with ARPACK . rvec Indicates whether eigenvectors are needed . If the eigenvectors are of interest , then rvec = . true . and set to . false . otherwise . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 91 A . 1 . 5 Postprocessing and Accuracy Checking Once the eigenvalues and eigenvectors have been extracted from the postprocessing routine dseupd , the user may check the accuracy of the result by computing the direct residuals kAx (cid:0) (cid:21)xk or kAx (cid:0) (cid:21)Mxk for standard or generalized eigenvalue problems , respectively . In order to compute the above quantities , the matrix vector product routines for Ax and Mx must be supplied , even if they are not used in the reverse communication loop . Residual checking is provided in all drivers . A . 2 Real Nonsymmetric Drivers There are six drivers for nonsymmetric eigenvalues problem . They are named in the form of XndrvY , where the (cid:12)rst character X speci(cid:12)es the precision used , s single precision d double precision and the last character Y is a number between 1 and 6 indicating the mode to be used . Each number is associated with a combination of bmat , iparam ( 7 ) and sigmai vari - ables used in that driver . Table A . 4 summarizes the features of the double precision drivers . The (cid:12)rst four drivers are the ones most commonly used . The last two drivers are used when the complex shift used in the shift - invert mode has a nonzero imagi - nary part . Either dndrv5 or dndrv6 may be modi(cid:12)ed to solve a standard eigenvalue problem in shift - invert mode with a complex shift . If the amount of storage used by complex arithmetic is not prohibitive , then the complex drivers of x A . 3 should be used instead . A procedure for modifying a nonsymmetric driver is outlined below . It is similar to the one used for the symmetric drivers . A . 2 . 1 Selecting a Non - symmetric Driver Several drivers may be used to solve the same problem . However , one driver may work better or may be easier to modify than the other depending on the nature of the application . The decision of what to use should be based on the type of problem to be solved and the part of the spectrum that is of interest . See x 3 . 2 of Chapter 3 for more discussion on the issues that should be considered when deciding to use a spectral transformation . Standard Mode For the standard eigenvalue problem , Ax = (cid:21)x ; the driver dndrv1 computes the eigenvalues of largest and smallest magnitude , real part or imaginary part . However , if the operation A (cid:0)1 x can be easily formed , using - DRAFT - 31 July 96 A . 2 . REAL NONSYMMETRIC DRIVERS 92 Table A . 4 : The functionality of the non - symmetric drivers . DRIVER PROBLEM SOLVED dndrv1 Standard eigenvalue problem ( bmat = ' I ' ) in the regular mode ( iparam ( 7 ) = 1 . ) No shift is needed in this driver . dndrv2 Standard eigenvalue problem ( bmat = ' I ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) The shift is real ( sigmai = 0 . 0 . ) dndrv3 Generalized eigenvalue problem ( bmat = ' G ' ) in the regular inverse mode ( iparam ( 7 ) = 2 . ) No shift is needed in this driver . dndrv4 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) with a real shift ( sigmai = 0 . 0 . ) dndrv5 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift invert mode ( iparam ( 7 ) = 3 . ) The shift has a nonzero imaginary part ( sigmai 6 = 0 . ) dndrv6 Solve a generalized eigenvalue problem ( bmat = ' G ' ) in a shift invert mode ( iparam ( 7 ) = 4 . ) The shift has a nonzero imaginary part ( sigmai 6 = 0 . ) - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 93 the shift - invert driver dndrv2 with zero shift is probably a more e(cid:11)ective way to compute eigenvalues of the smallest magnitude . Shift - Invert Mode Driver dndrv2 uses the shift - invert mode to (cid:12)nd eigenvalues closest to a real shift (cid:27) : This is often used to compute interior eigenvalues . To use dndrv2 , the user is required to supply the action of w ( A (cid:0) (cid:27)I ) (cid:0)1 v ; If the desired shift has a nonzero imaginary part , then dndrv5 or dndrv6 should be modi(cid:12)ed to solve the problem . For eigenvalue problems where the additional storage needed is not prohibitive , the complex shift - invert driver zndrv2 should be used . Generalized Nonsymmetric Eigenvalue Problem If the generalized eigenvalue problem Ax = (cid:21)Mx is to be solved , one can either convert it into a standard eigenvalue problem as de - scribed in x 3 . 2 of Chapter 3 or use dndrv3 , dndrv4 , dndrv5 , dndrv6 that are designed speci(cid:12)cally for the generalized problem . Regular Inverse Mode Driver dsdrv3 uses the regular inverse mode to solve the generalized eigenvalue prob - lem . This mode should be used if M is symmetric and positive de(cid:12)nite but it is not possible to factor into a Cholesky factorization M = LL T or if there is reason to think that M is ill - conditioned . To use dsdrv3 the user must supply the action of w M (cid:0)1 Av and w Mv The action of M (cid:0)1 is typically done with an iterative solver such as pre - conditioned conjugate gradient . If M can be factored then direct conversion to a standard problem is recommended . Spectral Transformations for Non - symmetric Eigenvalue Problems If interior eigenvalues are sought , then the shift - invert driver dndrv4 , dndrv5 or dndrv6 may be used . Driver dndrv4 can be used when the shift has a zero imag - inary part . Otherwise , either dndrv5 or dndrv6 should be used . To use these drivers , one is required to supply the action of w ( A (cid:0) (cid:27)M ) (cid:0)1 Mv : - DRAFT - 31 July 96 A . 2 . REAL NONSYMMETRIC DRIVERS 94 Table A . 5 : The operators OP and B . DRIVER OP B dndrv1 A I dndrv2 ( A (cid:0) (cid:27)I ) (cid:0)1 I dndrv3 M (cid:0)1 A M dndrv4 ( A (cid:0) (cid:27)M ) (cid:0)1 M M dndrv5 Real ( A (cid:0) (cid:27)M ) (cid:0)1 M M dndrv6 Imag ( A (cid:0) (cid:27)M ) (cid:0)1 M M Since sigma may have a nonzero imaginary part , a complex factorization routine or a complex iterative solver may be required . In that case , the vector w will in general be a complex vector . But only the real or imaginary part will be passed into dnaupd . A . 2 . 2 Identify OP and B for the Driver Once a driver is chosen , the next step is to identify OP and B associated with that driver . Eigenvalues of OP are computed by the computational routine dnaupd . These eigenvalues are converted to those of A or ( A ; M ) in the post - processing routine dseupd . The Arnoldi vectors generated by dnaupd are B - orthonormal . It is very important to construct the matrix vector operations w OPv and w Bv correctly . Table A . 5 summarizes the operators OP and B used by the drivers . The notation Real ( A ) and Real ( M ) is used to denote the real and imaginary parts of a complex matrix , respectively . Because of the reverse communication interface of ARPACK , the construction of w OPv and w Bv is left completely to the user . This means that the user is free to choose any convenient data structure for the matrix representation . If the matrix is not available , their user is free to express the action of the matrix on a vector through a subroutine call or a code segment . A . 2 . 3 The Reverse Communication Interface The basic structure of the reverse communication loop for the nonsymmetric drivers is similar to that for the symmetric driver with dsaupd replaced with dnaupd . See - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 95 Figure A . 1 . The actions taken in dndrv1 , dndrv2 , dndrv3 and dndrv4 are exactly the same as those in dsdrv1 dsdrv2 , dsdrv3 and dsdrv4 . For completeness , we repeat the discussion below . Since the operator OP de(cid:12)ned in dndrv5 and dndrv6 are unique for real nonsymmetric problems , the actions taken in these two drivers are completely di(cid:11)erent from dsdrv5 and dsdrv6 . Driver dndrv1 Only the action w Av is taken in this driver . It is indicated by ido = 1 . The matrix vector multiplication w Av takes workd ( ipntr ( 1 ) ) as input , and the output is returned in the array workd ( ipntr ( 2 ) ) . Driver dndrv2 Only the action w ( A (cid:0) (cid:27)I ) (cid:0)1 v is taken in this driver . It is indicated by ido = 1 . The action requires the solution of the linear system ( A(cid:0)(cid:27)I ) w = v : This is typically accomplished by factoring ( A (cid:0) (cid:27)I ) or the use of an iterative solver . Driver dndrv3 All three actions listed in Figure A . 1 are taken here . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w M (cid:0)1 Av . When ido = - 1 , the starting vector is projected into the range of OP = M (cid:0)1 A : This should occur only once . The matrix vector product y Av takes workd ( ipntr ( 1 ) ) as the input . The intermediate vector y should overwrite workd ( ipntr ( 1 ) ) . It is also used as the right hand side of the of the linear system Mw = y . The solution of the linear system should be returned in workd ( ipntr ( 2 ) ) . When ido = 2 , the action w Mv takes workd ( ipntr ( 1 ) ) as the input . The result is again returned in workd ( ipntr ( 2 ) ) . Driver dndrv4 All three actions listed in Figure A . 1 must be taken . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w ( A(cid:0)(cid:27)M ) (cid:0)1 Mv When ido = - 1 , the starting vector is projected into the range of OP = ( A(cid:0)(cid:27)M ) (cid:0)1 M : This should occur only once . The matrix vector multiplication y Mv with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . No matrix vector multiplication is needed when ido = 1 since y Mv has been computed and saved in workd ( ipntr ( 3 ) ) when ido = 2 . When ido = 1 , the linear system ( A (cid:0) (cid:27)M ) w = y uses workd ( ipntr ( 3 ) ) as the right hand side . The last action ( indicated by ido = 2 ) w Mx takes workd ( ipntr ( 1 ) ) as the input , and returns the matrix vector product in workd ( ipntr ( 2 ) ) . - DRAFT - 31 July 96 A . 2 . REAL NONSYMMETRIC DRIVERS 96 Driver dndrv5 All three actions listed in Figure A . 1 must be taken . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w Real ( A (cid:0) (cid:27)M ) (cid:0)1 Mv : When ido = - 1 , the starting vector is projected into the range of OP = Real ( A (cid:0) (cid:27)M ) (cid:0)1 M : This should occur only once . The matrix vector multiplication y Mv with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . The intermediate vector y is used as the right hand side of the complex linear system ( A (cid:0) (cid:27)M ) w = y ( A . 2 . 1 ) The real part of the solution must be returned in the array workd ( ipntr ( 2 ) ) . When ido = 1 , no matrix vector multiplication is needed since y Mv has been com - puted and saved in workd ( ipntr ( 3 ) ) when ido = 2 . The linear system ( A . 2 . 1 ) uses workd ( ipntr ( 3 ) ) as the right hand side , and the real part of the solution is re - turned in workd ( ipntr ( 2 ) ) . When ido = 2 , the matrix vector multiplication w Mx is performed on workd ( ipntr ( 1 ) ) , and the result is returned in the array workd ( ipntr ( 2 ) ) . Driver dndrv5 All three actions listed in Figure A . 1 must be taken . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w Imag ( A (cid:0) (cid:27)M ) (cid:0)1 Mv When ido = - 1 , the starting vector is projected into the range of OP = Imag ( A (cid:0) (cid:27)M ) (cid:0)1 M : This should occur only once . The matrix vector multiplication y Mv with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . The intermediate vector y is used as the right hand side of the complex linear system A . 2 . 1 . The imaginary part of the solution must be returned in the array workd ( ipntr ( 2 ) ) . When ido = 1 , no matrix vector multiplication is needed since y Mv has been computed and saved in workd ( ipntr ( 3 ) ) when ido = 2 . The linear system ( A . 2 . 1 ) uses workd ( ipntr ( 3 ) ) as the right hand side , and the imaginary part of the solution is re - turned in workd ( ipntr ( 2 ) ) . When ido = 2 , the matrix vector multiplication w Mx is performed on workd ( ipntr ( 1 ) ) , and the result is returned in workd ( ipntr ( 2 ) ) . A . 2 . 4 Modify the Problem Dependent Variables These variables include : n The dimension of the problem . nev The number of eigenvalues needed . ncv The length of the Arnoldi factorization . This represents the maximum number of Arnoldi vectors used . which The eigenvalues of interest . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 97 Table A . 6 : The eigenvalues of interest for non - symmetric eigenvalue problems . which EIGENVALUES ' LM ' Largest magnitude ' SM ' Smallest magnitude ' LR ' Largest real parts ' SR ' Smallest real parts ' LI ' Largest imaginary parts ' SI ' Smallest imaginary parts info Set to 0 for a randomly generated starting vector . If the user decides to use another starting vector , this value should be set to 1 , and the starting vector should be provided in the array resid . sigmar The real part of the shift used if a spectral transformation is employed . sigmai The imaginary part of the shift used if a spectral transformation is employed . The variable nev may be set to be a value larger than the number of eigenvalues desired to avoid splitting a eigenvalue cluster . The only restriction is that nev must be less than ncv . The initial choice of ncv is ncv = 2 (cid:1) nev is recommended . The user is encouraged to experiment with both nev and nev . The choices available for the input variable which is listed in Table A . 6 . We remark that when using a spectral transformation , the selection of which = ' SM ' should be avoided . Once the above variables are modi(cid:12)ed , the storage declarations integer maxn , maxnev , maxncv , ldv parameter ( maxn = 256 , maxnev = 10 , maxncv = 25 , ldv = maxn ) should be adjusted so that the conditions n (cid:20) maxn , nev (cid:20) maxnev , ncv (cid:20) maxncv , nev (cid:20) ncv + 2 are satis(cid:12)ed . We remark that the last condition on nev follows since we the complex conjugate pairs of eigenvalues are kept together . - DRAFT - 31 July 96 A . 2 . REAL NONSYMMETRIC DRIVERS 98 Other Variables The following variables are also set in all drivers . Their usage is described in Chap - ter 2 . In most cases , they do not need to be changed . lworkl The size of the work array workl used by dnaupd . Must be set to at least 3 * ncv * ( ncv + 6 ) . tol The convergence criterion . The default is to set it to 0 and a value of machine precision is used . It can be changed depending on the accuracy desired . Typically , the smaller this value the more work is required to satisfy the stopping criteria . However , setting this value too large may cause eigenvalues to be missed when there are multiple or clustered eigenvalue . ido The reverse communication (cid:13)ag . Must be set to 0 before entering dsaupd . bmat Designates whether a standard ( bmat = ' I ' ) or generalized eigenvalue ( bmat = ' G ' ) problem iparam ( 1 ) The shifting strategy used during the implicitly restarted portion of an IRLM . Unless the user has an expert understanding of an IRLM , an exact shifting strategy selected by setting iparam ( 1 ) = 1 should be used . iparam ( 3 ) Maximum number of IRLM iterations allowed . iparam ( 7 ) Indicates the algorithmic mode used with ARPACK . rvec Indicates whether eigenvectors are needed . If the eigenvectors are of interest , then rvec = . true . and set to . false . otherwise . A . 2 . 5 Postprocessing and Accuracy Checking The eigenvalues and eigenvectors of A and ( A ; M ) can be extracted with a call to dneupd when using drivers dndrv1 - dndrv4 . However , since the eigenvalues (cid:18) computed for OP by the drivers dndrv5 and dndrv6 are related to the eigenvalues (cid:21) of Ax = Mx(cid:21) by (cid:18) = 1 2 ( 1 (cid:21) (cid:0) (cid:27) + 1 (cid:21) + (cid:27) ) ; and (cid:18) = 1 2i ( 1 (cid:21) (cid:0) (cid:27) + 1 (cid:21) + (cid:27) ) ; respectively . These equations do not have a unique solution (cid:21) and it appears to be di(cid:14)cult to match the correct solution with a given eigenvector . Thus , the Rayleigh Quotient (cid:21) = x H Ax = ( x H Mx ) must be formed by the user to obtain the eigenvalue - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 99 Table A . 7 : The functionality of the complex arithmetic drivers . DRIVER PROBLEM SOLVED zndrv1 Standard eigenvalue problem ( bmat = ' I ' ) in the regular mode ( iparam ( 7 ) = 1 . ) zndrv2 Standard eigenvalue problem ( bmat = ' I ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) zndrv3 Generalized eigenvalue problem ( bmat = ' G ' ) in the regular inverse mode ( iparam ( 7 ) = 2 . ) zndrv4 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) corresponding to the eigenvector x : This will be done automatically in dneupd in a later release of ARPACK . Once the converged eigenvalues and eigenvectors have been obtained the user may check the accuracy of the results by computing the direct residuals kAx (cid:0) (cid:21)xk and kAx (cid:0) (cid:21)Mxk for a standard or generalized eigenvalue problems . Residual checking is provided in all drivers . A . 3 Complex Drivers There are four drivers for complex date type problems . They are named in the form of XndrvY , where the (cid:12)rst character X speci(cid:12)es the precision used as follows : c single precision complex , z double precision complex , and the last character Y is a number between 1 and 4 indicating the type of the problem to be solved and the mode to be used . Each number is associated with a unique combination bmat and iparam ( 7 ) value . Table A . 7 summarizes the features of each double precision complex arithmetic driver . The procedure for modifying a complex driver is similar to that is used for the (cid:12)rst four symmetric drivers . A . 3 . 1 Selecting a Complex Arithmetic Driver Several drivers may be used to solve the same problem . However , one driver may work better or may be easier to modify than the other depending on the nature of the application . The decision of what to use should be based on the type of problem to be solved and the part of the spectrum that is of interest . See x 3 . 2 of Chapter 3 - DRAFT - 31 July 96 A . 3 . COMPLEX DRIVERS 100 for more discussion on the issues that should be considered when deciding to use a spectral transformation . Standard Eigenvalue Problems For the standard eigenvalue problem , Ax = (cid:21)x ; the driver zndrv1 computes the eigenvalues of the largest and smallest magnitude , real part , or imaginary part . However , if the operation A (cid:0)1 v can be easily formed , using the shift - invert driver zndrv2 with zero shift is probably a more e(cid:11)ective way to compute eigenvalues of smallest magnitude . Shift and Invert Spectral Transformation Driver zndrv2 uses the shift - invert spectral transformation mode to (cid:12)nd eigenvalues closest to a shift (cid:27) : In order use zndrv2 , the user is required to supply action of w ( A (cid:0) (cid:27)I ) (cid:0)1 v : Generalized Eigenvalue Problems If the generalized eigenvalue problem Ax = (cid:21)Mx is to be solved , one can either convert it into a standard eigenvalue problem as de - scribed x 3 . 2 of Chapter 3 , or employ zndrv3 or zndrv4 that are designed speci(cid:12)cally for the generalized problem . Driver zndrv3 uses the regular inverse mode . It can be used to (cid:12)nd eigenvalues that are either largest or smallest in magnitude . If interior eigenvalues are sought , then the shift - invert driver zndrv4 should be used . The user is required to supply the action of w ( A (cid:0) (cid:27)M ) (cid:0)1 v ; where (cid:27) is the shift de(cid:12)ned by the user . A . 3 . 2 Identify OP and B for the Driver to be Modi(cid:12)ed Once a driver is chosen . The next step is to identify OP and B associated with that driver . Eigenvalues of OP are computed by the computational routine znaupd . These eigenvalues are converted to those of A or ( A ; M ) in the post - processing routine zneupd . The Arnoldi vectors generated by znaupd are B - orthonormal . It is very im - portant to construct the operation OPv and Bv correctly . The following list summarize the operator OP and B de(cid:12)ned in each driver . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 101 Table A . 8 : The operators OP and B . DRIVER OP B zndrv1 A I zndrv2 ( A (cid:0) (cid:27)I ) (cid:0)1 I zndrv3 M (cid:0)1 A M zndrv4 ( A (cid:0) (cid:27)M ) (cid:0)1 M M Because of the reverse communication interface of ARPACK , the construction of w OPv and w Bv is left completely to the user . This means that the user is free to choose any convenient data structure for the matrix representation . If the matrix is not available , their user is free to express the action of the matrix on a vector through a subroutine call or a code segment . A . 3 . 3 The Reverse Communication Interface The basic reverse communication loop for the complex driver is exactly the same as those used for the symmetric driver except that dsaupd is replaced by znaupd . ( Figure A . 1 . ) Actions to be taken within the loop vary from one driver to the other . Some drivers may take only one or two actions listed in Figure A . 1 . Each action corresponds to an ido value returned from the call to znaupd . These actions involve matrix vector operations such as w OPv and w Bv : The matrix vector operation must be performed correctly on the correct portion of the work array workd ( either workd ( ipntr ( 1 ) ) or workd ( ipntr ( 3 ) ) . ) The output should also be returned in the correct portion of workd ( either workd ( ipntr ( 2 ) ) or workd ( ipntr ( 1 ) ) ) before the loop goes back to the next call to znaupd . For completeness we restate the how the matrix vector operation are performed in each driver below . Driver zndrv1 Only the action w Av is taken in this driver . It is indicated by ido = 1 . The matrix vector multiplication w Av takes workd ( ipntr ( 1 ) ) as input , and the output is returned in the array workd ( ipntr ( 2 ) ) . Driver zndrv2 Only the action w ( A(cid:0)(cid:27)I ) (cid:0)1 v is taken in this driver . It is indicated by by ido = 1 also . The action requires the linear system ( A (cid:0) (cid:27)I ) w = v to be solve . This can - DRAFT - 31 July 96 A . 3 . COMPLEX DRIVERS 102 be done by factoring ( A (cid:0) (cid:27)I ) or the use of an iterative solver . The structure of the reverse communication loop is the same as that of dsdrv1 Driver zndrv3 All three actions listed in Figure A . 1 are taken here . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w M (cid:0)1 Av . When ido = - 1 , the starting vector is projected into the range of OP = M (cid:0)1 A : This should occur only once . The matrix vector multiplication y Av takes workd ( ipntr ( 1 ) ) as the input . The intermediate vector y should overwrite workd ( ipntr ( 1 ) ) . It is also used as the right hand side of the of the linear system Mw = y : The solution of the linear system should be returned in workd ( ipntr ( 2 ) . When ido = 2 , the action w Mv takes workd ( ipntr ( 1 ) ) as the input . The result is again returned in workd ( ipntr ( 2 ) ) . Driver zndrv4 All three actions listed in Figure A . 1 must be taken . The (cid:12)rst two actions ( indicated by ido = - 1 and ido = 1 ) involve the same matrix vector operation w ( A(cid:0)(cid:27)M ) (cid:0)1 Mv When ido = - 1 , the starting vector is projected into the range of OP = ( A(cid:0)(cid:27)M ) (cid:0)1 M : This should occur only once . The matrix vector multiplication y Mv with workd ( ipntr ( 1 ) ) as the input must be performed when ido = - 1 . No matrix vector multiplication is needed when ido = 1 since y Mv has been computed and saved in workd ( ipntr ( 3 ) ) when ido = 2 . When ido = 1 , the linear system ( A (cid:0) (cid:27)M ) w = y uses workd ( ipntr ( 3 ) ) as the right hand side . The last action ( indicated by ido = 2 ) w Mx takes workd ( ipntr ( 1 ) ) as the input , and returns the matrix vector product in workd ( ipntr ( 2 ) ) . A . 3 . 4 Modify the Problem Dependent Variables These variables include : n The dimension of the problem . nev The number of eigenvalues needed . ncv The length of the Arnoldi factorization . This represents the maximum number of Arnoldi vectors used . which The eigenvalues of interest . info Set to 0 for a randomly generated starting vector . If the user decides to use another starting vector , this value should be set to 1 , and the starting vector should be provided in the array resid . sigma The shift used if a spectral transformation is employed . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 103 Table A . 9 : The eigenvalues of interest for complex arithmetic eigenvalue problems . which EIGENVALUES ' LM ' Largest magnitude ' SM ' Smallest magnitude ' LR ' Largest real parts ' SR ' Smallest real parts ' LI ' Largest imaginary parts ' SI ' Smallest imaginary parts The variable nev may be set to be a value larger than the number of eigenvalues desired to avoid splitting a eigenvalue cluster . The only restriction is that nev must be less than ncv . The initial choice of ncv is ncv = 2 (cid:1) nev is recommended . The user is encouraged to experiment with both nev and nev . The choices available for the input variable which is listed in Table A . 9 . We remark that when using a spectral transformation , the selection of which = ' SM ' should be avoided . Once the above variables are modi(cid:12)ed , the storage declarations integer maxn , maxnev , maxncv , ldv parameter ( maxn = 256 , maxnev = 10 , maxncv = 25 , ldv = maxn ) should be adjusted so that the conditions n (cid:20) maxn , nev (cid:20) maxnev , ncv (cid:20) maxncv , nev (cid:20) ncv + 1 are satis(cid:12)ed . Other Variables The following variables are also set in all drivers . Their usage is described in Chap - ter 2 . In most cases , they do not need to be changed . lworkl The size of the work array workl used by znaupd . Must be set to at least 3 * ncv * ( ncv + 5 ) . tol The convergence criterion . The default is to set it to 0 and a value of machine precision is used . It can be changed depending on the accuracy desired . Typically , the smaller this value the more work is required to - DRAFT - 31 July 96 A . 4 . BAND DRIVERS 104 satisfy the stopping criteria . However , setting this value too large may cause eigenvalues to be missed when there are multiple or clustered eigenvalue . ido The reverse communication (cid:13)ag . Must be set to 0 before entering dsaupd . bmat Designates whether a standard ( bmat = ' I ' ) or generalized eigenvalue ( bmat = ' G ' ) problem iparam ( 1 ) The shifting strategy used during the implicitly restarted portion of an IRLM . Unless the user has an expert understanding of an IRLM , an exact shifting strategy selected by setting iparam ( 1 ) = 1 should be used . iparam ( 3 ) Maximum number of IRLM iterations allowed . iparam ( 7 ) Indicates the algorithmic mode used with ARPACK . rvec Indicates whether eigenvectors are needed . If the eigenvectors are of interest , then rvec = . true . and set to . false . otherwise . A . 3 . 5 Post - processing and Accuracy Checking Once the eigenvalues and eigenvectors have been extracted from the post - processing routine zneupd , the user may check the accuracy of the result by computing the direct residuals kAx (cid:0) (cid:21)xk and kAx(cid:0) (cid:21)Mxk for standard or generalized eigenvalue problems , respectively . A . 4 Band Drivers If the matrix A and M are stored in LAPACK band form , then one of the band drivers may be used . Band drivers are named in the form of XYbdrZ , where the (cid:12)rst character X speci(cid:12)es the precision and data type , s single precision d double precision c single precision complex z double precision complex the second character Y indicates the symmetry property of the problem , s symmetric problem n nonsymmetric problem - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 105 Table A . 10 : Band storage drivers for symmetric eigenvalue problems BAND DRIVER PROBLEM SOLVED dsbdr1 Standard eigenvalue problem ( bmat = ' I ' ) in the regular mode ( iparam ( 7 ) = 1 . ) dsbdr2 Standard eigenvalue problem ( bmat = ' I ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) dsbdr3 Generalized eigenvalue problem ( bmat = ' G ' ) in the regular inverse mode ( iparam ( 7 ) = 2 . ) dsbdr4 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) dsbdr5 Generalized eigenvalue problem ( bmat = ' G ' ) in the Buckling mode ( iparam ( 7 ) = 4 . ) dsbdr6 Generalized eigenvalue problem ( bmat = ' G ' ) in the Cayley mode ( iparam ( 7 ) = 5 . ) and the third character Z is a number between 1 and 6 indicating the type of the problem to be solved and the mode to be used . Each number is associated with a combination of bmat , iparam ( 7 ) and sigmai values used in that driver . Tables A . 10 | A . 12 list summarizes the the double precision band storage drivers . There are no special drivers for complex Hermitian problem . Complex Hermitian problems can be solved by using [ c , z ] ndrvZ . [ c , z ] nband . These drivers call the band eigenvalue computation routine XYband , where the (cid:12)rst character X ( s , d ) speci(cid:12)es the precision and data type as listed above , and the second character Y indicates the sym - metry property of the problem that can be solved with this routine . Since the reverse communication interface already implemented in these computational routines , users only need to provide the matrix and modify a few variables in these drivers to solve their own problem . A procedure for modifying these drivers is presented below . A . 4 . 1 Selecting a Band Storage Driver Several drivers may be used to solve the same problem . However , one driver may work better or may be easier to modify than the other depending on the nature of the application . The decision of what to use should be based on the type of problem to be solved and the part of the spectrum that is of interest . Typically , regular mode drivers can be used to (cid:12)nd extremal eigenvalues and shift - invert drivers are used to (cid:12)nd interior eigenvalues or extremal eigenvalues that are clustered . - DRAFT - 31 July 96 A . 4 . BAND DRIVERS 106 Table A . 11 : Band storage drivers for non - symmetric eigenvalue problems BAND DRIVER PROBLEM SOLVED dnbdr1 Standard eigenvalue problem ( bmat = ' I ' ) in the regular mode ( iparam ( 7 ) = 1 . ) dnbdr2 Standard eigenvalue problem ( bmat = ' I ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) dnbdr3 Generalized eigenvalue problem ( bmat = ' G ' ) in the regular inverse mode ( iparam ( 7 ) = 2 . ) dnbdr4 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) dnbdr5 Standard eigenvalue problem ( bmat = ' I ' ) in a shift invert mode ( iparam ( 7 ) = 4 . ) dnbdr6 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift invert mode ( iparam ( 7 ) = 4 . ) Table A . 12 : Band storage drivers for Complex arithmetic eigenvalue problems . BAND DRIVER PROBLEM SOLVED znbdr1 Standard eigenvalue problem ( bmat = ' I ' ) in the regular mode ( iparam ( 7 ) = 1 . ) znbdr2 Standard eigenvalue problem ( bmat = ' I ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) znbdr3 Generalized eigenvalue problem ( bmat = ' G ' ) in the regular inverse mode ( iparam ( 7 ) = 2 . ) znbdr4 Generalized eigenvalue problem ( bmat = ' G ' ) in a shift - invert mode ( iparam ( 7 ) = 3 . ) - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 107 A . 4 . 2 Store the matrix correctly The band routines assume the matrix A and M are stored in LAPACK band form . In the following we used AB and MB to denote A and B stored in band form . If the matrix A has kl subdiagonals and ku superdiagonals , then the ijth element of A aij is stored in AB ( kl + ku + 1 + i (cid:0) j ; j ) for max ( 1 ; j (cid:0) ku ) (cid:20) i (cid:20) min ( m ; j + kl ) . An example of a band matrix A with kl = 2 , ku = 1 is illustrated below . A = 0 B B B B B @ a11 a12 a21 a22 a23 a31 a32 a33 a34 a42 a43 a44 a45 a53 a54 a55 1 C C C C C A ! AB = 0 B B B B B B B @ (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) a12 a23 a34 a45 a11 a22 a33 a44 a55 a21 a32 a43 a54 (cid:3) a31 a42 a53 (cid:3) (cid:3) 1 C C C C C C C A The elements marked * in the matrix AB need not be set . A . 4 . 3 Modify problem dependent variables These variables include the following n The dimension of the problem . nev The number of eigenvalues needed . ncv The length of the Arnoldi factorization . which Part of the spectrum that is of interest . sigma Real shift used in dsbdr2 and dsbdr4 , or complex shift used in znbdr2 and znbdr4 . sigmar The real part of the shift used in a real nonsymmetric shift invert mode driver ( dnbdr2 , dnbdr4 , dnbdr5 , dnbdr6 . ) sigmai The imaginary part of the shift used in a real nonsymmetric shift invert mode driver ( dnbdr5 , dnbdr6 ) . It should be set to zero in dnbdr2 and dndrv4 . A . 4 . 4 Modify other variables if necessary The following variables are also set in all drivers . Their usage is described in Chapters 2 and 3 . In most cases , they do not need to be changed . lworkl Must be set to at least ncv * ncv + 3 * ncv . - DRAFT - 31 July 96 A . 5 . THE SINGULAR VALUE DECOMPOSITION 108 tol Usually set to zero . It can be changed depending on the accuracy desired . Typically , the smaller this value the more work is required to satisfy the stopping criteria . However , setting this value too large may cause eigenvalues to be missed when they are multiple or very tightly clustered . ido Must be set to 0 before entering dnaupd . info Usually set to 0 . In this case , a random starting vector is generated to start the Arnoldi iteration . If the user decides to use other starting vector , this value should be set to 1 , and the starting vector should be provided in the array resid . bmat Either ' I ' or ' G ' depending on the problem to be solved . This variable has been set appropriately in each driver . The user should not change its value . iparam ( 1 ) Usually set to 1 . This indicates that exact shift strategy is used in the computation . For a discussion on shift strategy see x 4 . 4 of Chapter 4 . iparam ( 3 ) Maximum iterations allow . It is set to 300 in all drivers . But it can be reset to any reasonable value . iparam ( 7 ) Indicate algorithmic mode . This variable has been set appropriately in each driver . The user should not change its value . rvec Indicate whether eigenvector is needed . It is set to . true . in all drivers . If no eigenvector is needed , this may be set to . false . A . 4 . 5 Accuracy checking Once the eigenvalues and eigenvectors have been obtained , the user may check the accuracy of the result by computing the direct residuals kAx(cid:0)(cid:21)xk ; and kAx(cid:0)(cid:21)Mxk ; for a standard and generalized eigenvalue problem , respectively . A . 5 The Singular Value Decomposition Every rectangular matrix A 2 R m(cid:2)n with m (cid:21) n may be factored into the form A = USV T ( A . 5 . 1 ) where U T U = V T V = In are matrices with orthonormal columns and the diagnoal matrix S = diag ( (cid:27)1 ; (cid:27)2 ; (cid:1)(cid:1)(cid:1) ; (cid:27)n ) . The numbers (cid:27)1 (cid:21) (cid:27)2 (cid:21) (cid:1)(cid:1)(cid:1) (cid:21) (cid:27)n (cid:21) 0 are called the singular values of A : The columns of U are the left singular vectors and the columns of V are the right singular vectors of A . This is the so - called \ short form " of the Singular Value Decompositon ( SVD ) of A . - DRAFT - 31 July 96 APPENDIX A . TEMPLATES AND DRIVER ROUTINES 109 Figure A . 2 : Compute w A T Av by Blocks Initialize w 0 ; For j = 1 ; 2 ; 3 ; : : : ` , C Aj ; % Read next block of A % z Cv ; w w + C T z ; End For The relationship ( A . 5 . 1 ) may be manipulated using orthogonality to reveal that A T A = VS 2 V T with U = AVS (cid:0)1 ; ( A . 5 . 2 ) if (cid:27)n > 0 . Thus selected singular values and the corresponding right singular vectors may be computed by (cid:12)nding eigenvalues and vectors for the n (cid:2) n matrix A T A : In many applications , one is iterested in computing a few ( say k ) of the largest singular values and corresponding vectors . If Uk , Vk denote the leading k - columns of U and V respectively , and if Sk denotes the leading principal submatrix of S then Ak (cid:17) UkSkV T k is the best rank - k approximation to A in both the 2 - norm and the Frobenius norm . Often a very small k will su(cid:14)ce to approximate important features of the original A or to approximately solve least squares problems involving A : This partial SVD may be computed e(cid:14)ciently using ARPACK subroutine saupd in mode = 1 with which = ' LA ' and taking OP = A T A and B = I : Of course , the action of w OPv should be computed with the steps 1 . Matrix - vector multiply z Av : 2 . Matrix - vector multiply w A T z : Also , note that if the matrix A is huge and must be stored on a peripheral device , then A may be read in by blocks to achieve the action of w OPv using the fact that OPv = ` X j = 1 A T j Ajv ; where A T = ( A T 1 ; A T 2 ; (cid:1)(cid:1)(cid:1) ; A T ` ) to obtain the loop shown in Figure A . 2 . The drivers illustrate how to compute the leading k terms of the SVD as just described . The left singular vectors are recoverd from the right singular vectors . As - DRAFT - 31 July 96 A . 5 . THE SINGULAR VALUE DECOMPOSITION 110 long as the largest singular values are not multiple or tightly clusterd , there should be no problem in obtaining numerically orthogonal left singular vectors from the computed right singular vectors . However , there is a way to get the both the left and right singular vectors directly . This is to de(cid:12)ne OP = 0 A A T 0 ! and utilize the fact that 0 A A T 0 ! U V ! = U V ! S to extract the columns of Uk from the (cid:12)rst m components of the converged eigenvec - tors of OP and the columns of Vk from the remaining n components . We only provide the (cid:12)rst approach in the ARPACK drivers . We also should mention that in case you have a matrix A with m < n then replace A with A T in the above discussion and reverse the roles of U and V . A . 5 . 1 The SVD Drivers The drivers for computing the singular value decomposition are of the form Xsvd . f where X denotes the precision and data type , s single precision d double precision . Of course , the SVD is de(cid:12)ned for complex matrices as well and it is a straight - forward matter to convert the real arithmetic driver to a corresponding complex arithmetic driver . These drivers may be easily modi(cid:12)ed to estimate the 2 - norm condition number (cid:20)2 ( A ) = (cid:27)1 (cid:27)n by setting which = ' BE ' . This will ask for a few of the smallest and a few of the largest singular values simultaneously . The condition number could then be estimated by taking the ratio of the largest and smallest singular values . Since these drivers are simply special cases of dsdrv1 , the parameter settings will not be described further . The only cautionary note is that the parameter which may be set to ' SA ' if desired but this is not recommended if it is expected that A will be nearly rank de(cid:12)cient . - DRAFT - 31 July 96 Appendix B Tracking the progress of ARPACK ARPACK provides a means to trace the progress of the computation as it proceeds . Various levels of output may be speci(cid:12)ed from no output , level = 0 , to voluminous , level = 3 . The following statements may be used within the calling program to initiate and request this output . include ' debug . h ' ndigit = - 3 logfil = 6 msgets = 0 msaitr = 0 msapps = 0 msaupd = 1 msaup2 = 0 mseigt = 0 mseupd = 0 The parameter logfil speci(cid:12)es the logical unit number of the output (cid:12)le . The parameter ndigit speci(cid:12)es the number of decimal digits and the width of the output lines . A positive value of ndigit speci(cid:12)es that 132 columns are used during output and a negative value speci(cid:12)es eighty columns are to be used . The values of the remaining parameters indicate the output levels from the indicated routines . For the above example , msaitr indicates the level of output requested for the subroutine ssaitr or dsaitr . The above con(cid:12)guration will give a breakdown of the number of matrix vector products required , the total number of iterations , the number of re - orthogonalization steps and an estimate of the time spent in each routine and phase of the computation . The output displayed by Table B . 1 is produced . The user is encouraged to experiment with the other settings once some familiarity has been gained with the routines . The include statement sets up the storage declarations that are solely associated with this trace debugging feature . debug . h has the following structure : 111 112 Table B . 1 : Sample output produced by dsaupd . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Symmetric implicit Arnoldi update code = = Version Number : 2 . 1 = = Version Date : 11 / 15 / 95 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Summary of timing statistics = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Total number update iterations = 8 Total number of OP * x operations = 125 Total number of B * x operations = 0 Total number of reorthogonalization steps = 125 Total number of iterative refinement steps = 0 Total number of restart steps = 0 Total time in user OP * x operation = 0 . 020002 Total time in user B * x operation = 0 . 000000 Total time in Arnoldi update routine = 0 . 210021 Total time in ssaup2 routine = 0 . 190019 Total time in basic Arnoldi iteration loop = 0 . 110011 Total time in reorthogonalization phase = 0 . 070007 Total time in ( re ) start vector generation = 0 . 000000 Total time in trid eigenvalue subproblem = 0 . 040004 Total time in getting the shifts = 0 . 000000 Total time in applying the shifts = 0 . 040004 Total time in convergence testing = 0 . 000000 - DRAFT - 31 July 96 APPENDIX B . TRACKING THE PROGRESS OF ARPACK 113 c c \ SCCS Information : @ ( # ) c FILE : debug . h SID : 2 . 3 DATE OF SID : 11 / 16 / 95 RELEASE : 2 c c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % c | See debug . doc for documentation | c % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - % integer logfil , ndigit , mgetv0 , & msaupd , msaup2 , msaitr , mseigt , msapps , msgets , mseupd , & mnaupd , mnaup2 , mnaitr , mneigh , mnapps , mngets , mneupd , & mcaupd , mcaup2 , mcaitr , mceigh , mcapps , mcgets , mceupd common / debug / & logfil , ndigit , mgetv0 , & msaupd , msaup2 , msaitr , mseigt , msapps , msgets , mseupd , & mnaupd , mnaup2 , mnaitr , mneigh , mnapps , mngets , mneupd , & mcaupd , mcaup2 , mcaitr , mceigh , mcapps , mcgets , mceupd The parameters msaupd , msaup2 , msaitr , mseigt , msapps , msgets , mseupd are for the symmetric codes , while mnaupd , mnaup2 , mnaitr , mneigh , mnapps , mngets , mneupd are for the nonsymmetric codes and , (cid:12)nally , mcaupd , mcaup2 , mcaitr , mceigh , mcapps , mcgets , mceupd are for the complex arithmetic codes . A comprehensive break down of each parameter is listed in Table B . 2 . - DRAFT - 31 July 96 114 Table B . 2 : Description of the message level settings for ARPACK . Routine Level Description mYaupd 1 Print the total number of iterations taken , the number of converged Ritz values , the Ritz values and corresponding Ritz estimates , and various timing statistics . mYaup2 1 Upon exit , print the number of converged Ritz values , the Ritz values and corresponding Ritz estimates . 2 Print the current iteration number , the length of the Arnoldi factorization extended , the B - norm of its residual vector . Print NEV and NP , the Ritz values and associated Ritz estimates at each iteration , and the B - norm of the residual of the compressed factorization . 3 Print the real and imaginary parts of all the Ritz values and associated Ritz estimates , NEV , NP , NUMCNV , NCONV . Print the shifts . If the exact shift strategy is used , also print the associated Ritz estimates of the shifts . mYaitr 1 Noti(cid:12)cation of a restart . 2 Print the number of Arnoldi vector being generated and the B - norm of the current residual . 3 Print the columns of the Hessenberg matrix as they are generated , reorthogonalization and iterative re(cid:12)nement information , the (cid:12)nal upper Hessenberg matrix of order K + NEV , and V T j Bfj = kfjkB : mYeigh 2 Print the last row of the Schur matrix for H , and the last row of the eigenvector matrix for H : 3 Print the entering upper Hessenberg matrix , the computed eigenvalues associated Ritz estimates . mYapps 1 Print information about where de(cid:13)ation occured . 2 Print sigmak , betak , order of the (cid:12)nal Hessenberg matrix , and the (cid:12)nal compressed upper Hessenberg matrix . 3 Print implicit application of shift number , real and imaginary part of the shift , and the indices of the submatrix that the shift is applied . mYeupd 1 Print the number of converged Ritz values , B - norm of the residual , all NCV Ritz values and error bounds . 2 Print the (cid:12)nal upper Hessenberg matrix computed by XYaupd . If Ritz vectors are requested , print real and imaginary parts of the eigenvalues and the last row of the Schur vectors as computed by XYeupd . 3 If Ritz vectors are requested , print the threshold eigenvalue used for re - ordering , number of eigenvalues to reorder and the number of converged Ritz values . - DRAFT - 31 July 96 Appendix C The XYaupd ARPACK Routines In this appendix we exhibit the headers of the three main computational routines dsaupd , dnaupd , and znaupd . Although these codes are nearly identical in structure and usage , there are a number of di(cid:11)erences that are problem dependent . Therefore , each is listed separately . Information on the calling sequence , input and output parameters , storage and data types may be found here . Also , error (cid:13)ags and warnings are listed . 115 C . 1 . D S AU P D 1 16 C . 1 DSAUPD c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c \ BeginDoc c c \ Name : dsaupd c c \ Description : c c Reverse communication interface for the Implicitly Restarted Arnoldi c Iteration . For symmetric problems this reduces to a variant of the Lanczos c method . This method has been designed to compute approximations to a c few eigenpairs of a linear operator OP that is real and symmetric c with respect to a real positive semi - definite symmetric matrix B , c i . e . c c B * OP = ( OP ' ) * B . c c Another way to express this condition is c c < x , OPy > = < OPx , y > where < z , w > = z ' Bw . c c In the standard eigenproblem B is the identity matrix . c ( A ' denotes transpose of A ) c c The computed approximate eigenvalues are called Ritz values and c the corresponding approximate eigenvectors are called Ritz vectors . c c dsaupd is usually called iteratively to solve one of the c following problems : c c Mode 1 : A * x = lambda * x , A symmetric c = = = > OP = A and B = I . c c Mode 2 : A * x = lambda * M * x , A symmetric , M symmetric positive definite c = = = > OP = inv [ M ] * A and B = M . c = = = > ( If M can be factored see remark 3 below ) c c Mode 3 : K * x = lambda * M * x , K symmetric , M symmetric positive semi - definite c = = = > OP = ( inv [ K - sigma * M ] ) * M and B = M . c = = = > Shift - and - Invert mode c c Mode 4 : K * x = lambda * KG * x , K symmetric positive semi - definite , c KG symmetric indefinite c = = = > OP = ( inv [ K - sigma * KG ] ) * K and B = K . c = = = > Buckling mode c c Mode 5 : A * x = lambda * M * x , A symmetric , M symmetric positive semi - definite c = = = > OP = inv [ A - sigma * M ] * [ A + sigma * M ] and B = M . c = = = > Cayley transformed mode c c NOTE : The action of w < - inv [ A - sigma * M ] * v or w < - inv [ M ] * v c should be accomplished either by a direct method c using a sparse matrix factorization and solving c c [ A - sigma * M ] * w = v or M * w = v , c c or through an iterative method for solving these c systems . If an iterative method is used , the c convergence test must be more stringent than c the accuracy requirements for the eigenvalue c approximations . c c \ Usage : c call dsaupd c ( IDO , BMAT , N , WHICH , NEV , TOL , RESID , NCV , V , LDV , IPARAM , c IPNTR , WORKD , WORKL , LWORKL , INFO ) c c \ Arguments c IDO Integer . ( INPUT / OUTPUT ) c Reverse communication flag . IDO must be zero on the first c call to dsaupd . IDO will be set internally to c indicate the type of operation to be performed . Control is c then given back to the calling routine which has the c responsibility to carry out the requested operation and call c dsaupd with the result . The operand is given in c WORKD ( IPNTR ( 1 ) ) , the result must be put in WORKD ( IPNTR ( 2 ) ) . c ( If Mode = 2 see remark 5 below ) c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c IDO = 0 : first call to the reverse communication interface c IDO = - 1 : compute Y = OP * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y . c This is for the initialization phase to force the c starting vector into the range of OP . c IDO = 1 : compute Y = OP * Z and Z = B * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y , c IPNTR ( 3 ) is the pointer into WORKD for Z . c IDO = 2 : compute Y = B * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y . c IDO = 3 : compute the IPARAM ( 8 ) shifts where c IPNTR ( 11 ) is the pointer into WORKL for c placing the shifts . See remark 6 below . c IDO = 99 : done c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c After the initialization phase , when the routine is used in c either the " shift - and - invert " mode or the Cayley transform c mode , the vector B * X is already available and does not c need to be recomputed in forming OP * X . c c BMAT Character * 1 . ( INPUT ) c BMAT specifies the type of the matrix B that defines the c semi - inner product for the operator OP . c B = ' I ' - > standard eigenvalue problem A * x = lambda * x c B = ' G ' - > generalized eigenvalue problem A * x = lambda * B * x c c N Integer . ( INPUT ) c Dimension of the eigenproblem . - D R A F T - 31 J u l y 96 A PPE N D I X C . T H E XYAU P D A R P A C K R O U T I N E S 117 c c WHICH Character * 2 . ( INPUT ) c Specify which of the Ritz values of OP to compute . c c ' LA ' - compute the NEV largest ( algebraic ) eigenvalues . c ' SA ' - compute the NEV smallest ( algebraic ) eigenvalues . c ' LM ' - compute the NEV largest ( in magnitude ) eigenvalues . c ' SM ' - compute the NEV smallest ( in magnitude ) eigenvalues . c ' BE ' - compute NEV eigenvalues , half from each end of the c spectrum . When NEV is odd , compute one more from the c high end than from the low end . c ( see remark 1 below ) c c NEV Integer . ( INPUT ) c Number of eigenvalues of OP to be computed . 0 < NEV < N . c c TOL Double precision scalar . ( INPUT ) c Stopping criterion : the relative accuracy of the Ritz value c is considered acceptable if BOUNDS ( I ) . LE . TOL * ABS ( RITZ ( I ) ) . c If TOL . LE . 0 . is passed a default is set : c DEFAULT = DLAMCH ( ' EPS ' ) ( machine precision as computed c by the LAPACK auxiliary subroutine DLAMCH ) . c c RESID Double precision array of length N . ( INPUT / OUTPUT ) c On INPUT : c If INFO . EQ . 0 , a random initial residual vector is used . c If INFO . NE . 0 , RESID contains the initial residual vector , c possibly from a previous run . c On OUTPUT : c RESID contains the final residual vector . c c NCV Integer . ( INPUT ) c Number of columns of the matrix V ( less than or equal to N ) . c This will indicate how many Lanczos vectors are generated c at each iteration . After the startup phase in which NEV c Lanczos vectors are generated , the algorithm generates c NCV - NEV Lanczos vectors at each subsequent update iteration . c Most of the cost in generating each Lanczos vector is in the c matrix - vector product OP * x . ( See remark 4 below ) . c c V Double precision N by NCV array . ( OUTPUT ) c The NCV columns of V contain the Lanczos basis vectors . c c LDV Integer . ( INPUT ) c Leading dimension of V exactly as declared in the calling c program . c c IPARAM Integer array of length 11 . ( INPUT / OUTPUT ) c IPARAM ( 1 ) = ISHIFT : method for selecting the implicit shifts . c The shifts selected at each iteration are used to restart c the Arnoldi iteration in an implicit fashion . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c ISHIFT = 0 : the shifts are provided by the user via c reverse communication . The NCV eigenvalues of c the current tridiagonal matrix T are returned in c the part of WORKL array corresponding to RITZ . c See remark 6 below . c ISHIFT = 1 : exact shifts with respect to the reduced c tridiagonal matrix T . This is equivalent to c restarting the iteration with a starting vector c that is a linear combination of Ritz vectors c associated with the " wanted " Ritz values . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c c IPARAM ( 2 ) = LEVEC c No longer referenced . See remark 2 below . c c IPARAM ( 3 ) = MXITER c On INPUT : maximum number of Arnoldi update iterations allowed . c On OUTPUT : actual number of Arnoldi update iterations taken . c c IPARAM ( 4 ) = NB : blocksize to be used in the recurrence . c The code currently works only for NB = 1 . c c IPARAM ( 5 ) = NCONV : number of " converged " Ritz values . c This represents the number of Ritz values that satisfy c the convergence criterion . c c IPARAM ( 6 ) = IUPD c No longer referenced . Implicit restarting is ALWAYS used . c c IPARAM ( 7 ) = MODE c On INPUT determines what type of eigenproblem is being solved . c Must be 1 , 2 , 3 , 4 , 5 ; See under \ Description of dsaupd for the c five modes available . c c IPARAM ( 8 ) = NP c When ido = 3 and the user provides shifts through reverse c communication ( IPARAM ( 1 ) = 0 ) , dsaupd returns NP , the number c of shifts the user is to provide . 0 < NP < = NCV - NEV . See Remark c 6 below . c c IPARAM ( 9 ) = NUMOP , IPARAM ( 10 ) = NUMOPB , IPARAM ( 11 ) = NUMREO , c OUTPUT : NUMOP = total number of OP * x operations , c NUMOPB = total number of B * x operations if BMAT = ' G ' , c NUMREO = total number of steps of re - orthogonalization . c c IPNTR Integer array of length 11 . ( OUTPUT ) c Pointer to mark the starting locations in the WORKD and WORKL c arrays for matrices / vectors used by the Lanczos iteration . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c IPNTR ( 1 ) : pointer to the current operand vector X in WORKD . c IPNTR ( 2 ) : pointer to the current result vector Y in WORKD . c IPNTR ( 3 ) : pointer to the vector B * X in WORKD when used in c the shift - and - invert mode . c IPNTR ( 4 ) : pointer to the next available location in WORKL c that is untouched by the program . c IPNTR ( 5 ) : pointer to the NCV by 2 tridiagonal matrix T in WORKL . c IPNTR ( 6 ) : pointer to the NCV RITZ values array in WORKL . c IPNTR ( 7 ) : pointer to the Ritz estimates in array WORKL associated - D R A F T - 31 J u l y 96 C . 1 . D S AU P D 1 18 c with the Ritz values located in RITZ in WORKL . c Note : IPNTR ( 8 : 10 ) is only referenced by dseupd . See Remark 2 . c IPNTR ( 8 ) : pointer to the NCV RITZ values of the original system . c IPNTR ( 9 ) : pointer to the NCV corresponding error bounds . c IPNTR ( 10 ) : pointer to the NCV by NCV matrix of eigenvectors c of the tridiagonal matrix T . Only referenced by c dseupd if RVEC = . TRUE . See Remarks . c Note : IPNTR ( 8 : 10 ) is only referenced by dseupd . See Remark 2 . c IPNTR ( 11 ) : pointer to the NP shifts in WORKL . See Remark 6 below . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c c WORKD Double precision work array of length 3 * N . ( REVERSE COMMUNICATION ) c Distributed array to be used in the basic Arnoldi iteration c for reverse communication . The user should not use WORKD c as temporary workspace during the iteration . Upon termination c WORKD ( 1 : N ) contains B * RESID ( 1 : N ) . If the Ritz vectors are desired c subroutine dseupd uses this output . c See Data Distribution Note below . c c WORKL Double precision work array of length LWORKL . ( OUTPUT / WORKSPACE ) c Private ( replicated ) array on each PE or array allocated on c the front end . See Data Distribution Note below . c c LWORKL Integer . ( INPUT ) c LWORKL must be at least NCV * * 2 + 8 * NCV . c c INFO Integer . ( INPUT / OUTPUT ) c If INFO . EQ . 0 , a randomly initial residual vector is used . c If INFO . NE . 0 , RESID contains the initial residual vector , c possibly from a previous run . c Error flag on output . c = 0 : Normal exit . c = 1 : Maximum number of iterations taken . c All possible eigenvalues of OP has been found . IPARAM ( 5 ) c returns the number of wanted converged Ritz values . c = 2 : No longer an informational error . Deprecated starting c with release 2 of ARPACK . c = 3 : No shifts could be applied during a cycle of the c Implicitly restarted Arnoldi iteration . One possibility c is to increase the size of NCV relative to NEV . c See remark 4 below . c = - 1 : N must be positive . c = - 2 : NEV must be positive . c = - 3 : NCV must be greater than NEV and less than or equal to N . c = - 4 : The maximum number of Arnoldi update iterations allowed c must be greater than zero . c = - 5 : WHICH must be one of ' LM ' , ' SM ' , ' LA ' , ' SA ' or ' BE ' . c = - 6 : BMAT must be one of ' I ' or ' G ' . c = - 7 : Length of private work array WORKL is not sufficient . c = - 8 : Error return from trid . eigenvalue calculation ; c Informatinal error from LAPACK routine dsteqr . c = - 9 : Starting vector is zero . c = - 10 : IPARAM ( 7 ) must be 1 , 2 , 3 , 4 , 5 . c = - 11 : IPARAM ( 7 ) = 1 and BMAT = ' G ' are incompatable . c = - 12 : IPARAM ( 1 ) must be equal to 0 or 1 . c = - 13 : NEV and WHICH = ' BE ' are incompatable . c = - 9999 : Could not build an Arnoldi factorization . c IPARAM ( 5 ) returns the size of the current Arnoldi c factorization . The user is advised to check that c enough workspace and array storage has been allocated . c c c \ Remarks c 1 . The converged Ritz values are always returned in ascending c algebraic order . The computed Ritz values are approximate c eigenvalues of OP . The selection of WHICH should be made c with this in mind when Mode = 3 , 4 , 5 . After convergence , c approximate eigenvalues of the original problem may be obtained c with the ARPACK subroutine dseupd . c c 2 . If the Ritz vectors corresponding to the converged Ritz values c are needed , the user must call dseupd immediately following completion c of dsaupd . This is new starting with version 2 . 1 of ARPACK . c c 3 . If M can be factored into a Cholesky factorization M = LL ' c then Mode = 2 should not be selected . Instead one should use c Mode = 1 with OP = inv ( L ) * A * inv ( L ' ) . Appropriate triangular c linear systems should be solved with L and L ' rather c than computing inverses . After convergence , an approximate c eigenvector z of the original problem is recovered by solving c L ' z = x where x is a Ritz vector of OP . c c 4 . At present there is no a - priori analysis to guide the selection c of NCV relative to NEV . The only formal requrement is that NCV > NEV . c However , it is recommended that NCV . ge . 2 * NEV . If many problems of c the same type are to be solved , one should experiment with increasing c NCV while keeping NEV fixed for a given test problem . This will c usually decrease the required number of OP * x operations but it c also increases the work and storage required to maintain the orthogonal c basis vectors . The optimal " cross - over " with respect to CPU time c is problem dependent and must be determined empirically . c c 5 . If IPARAM ( 7 ) = 2 then in the Reverse commuication interface the user c must do the following . When IDO = 1 , Y = OP * X is to be computed . c When IPARAM ( 7 ) = 2 OP = inv ( B ) * A . After computing A * X the user c must overwrite X with A * X . Y is then the solution to the linear set c of equations B * Y = A * X . c c 6 . When IPARAM ( 1 ) = 0 , and IDO = 3 , the user needs to provide the c NP = IPARAM ( 8 ) shifts in locations : c 1 WORKL ( IPNTR ( 11 ) ) c 2 WORKL ( IPNTR ( 11 ) + 1 ) c . c . c . c NP WORKL ( IPNTR ( 11 ) + NP - 1 ) . c c The eigenvalues of the current tridiagonal matrix are located in c WORKL ( IPNTR ( 6 ) ) through WORKL ( IPNTR ( 6 ) + NCV - 1 ) . They are in the c order defined by WHICH . The associated Ritz estimates are located in - D R A F T - 31 J u l y 96 A PPE N D I X C . T H E XYAU P D A R P A C K R O U T I N E S 119 c WORKL ( IPNTR ( 8 ) ) , WORKL ( IPNTR ( 8 ) + 1 ) , . . . , WORKL ( IPNTR ( 8 ) + NCV - 1 ) . c c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - C . 2 DNAUPD c \ BeginDoc c c \ Name : dnaupd c c \ Description : c Reverse communication interface for the Implicitly Restarted Arnoldi c iteration . This subroutine computes approximations to a few eigenpairs c of a linear operator " OP " with respect to a semi - inner product defined by c a symmetric positive semi - definite real matrix B . B may be the identity c matrix . NOTE : If the linear operator " OP " is real and symmetric c with respect to the real positive semi - definite symmetric matrix B , c i . e . B * OP = ( OP ' ) * B , then subroutine ssaupd should be used instead . c c The computed approximate eigenvalues are called Ritz values and c the corresponding approximate eigenvectors are called Ritz vectors . c c dnaupd is usually called iteratively to solve one of the c following problems : c c Mode 1 : A * x = lambda * x . c = = = > OP = A and B = I . c c Mode 2 : A * x = lambda * M * x , M symmetric positive definite c = = = > OP = inv [ M ] * A and B = M . c = = = > ( If M can be factored see remark 3 below ) c c Mode 3 : A * x = lambda * M * x , M symmetric semi - definite c = = = > OP = Real _ Part { inv [ A - sigma * M ] * M } and B = M . c = = = > shift - and - invert mode ( in real arithmetic ) c If OP * x = amu * x , then c amu = 1 / 2 * [ 1 / ( lambda - sigma ) + 1 / ( lambda - conjg ( sigma ) ) ] . c Note : If sigma is real , i . e . imaginary part of sigma is zero ; c Real _ Part { inv [ A - sigma * M ] * M } = = inv [ A - sigma * M ] * M c amu = = 1 / ( lambda - sigma ) . c c Mode 4 : A * x = lambda * M * x , M symmetric semi - definite c = = = > OP = Imaginary _ Part { inv [ A - sigma * M ] * M } and B = M . c = = = > shift - and - invert mode ( in real arithmetic ) c If OP * x = amu * x , then c amu = 1 / 2i * [ 1 / ( lambda - sigma ) - 1 / ( lambda - conjg ( sigma ) ) ] . c c Both mode 3 and 4 give the same enhancement to eigenvalues close to c the ( complex ) shift sigma . However , as lambda goes to infinity , c the operator OP in mode 4 dampens the eigenvalues more strongly than c does OP defined in mode 3 . c c NOTE : The action of w < - inv [ A - sigma * M ] * v or w < - inv [ M ] * v c should be accomplished either by a direct method c using a sparse matrix factorization and solving c c [ A - sigma * M ] * w = v or M * w = v , c c or through an iterative method for solving these c systems . If an iterative method is used , the c convergence test must be more stringent than c the accuracy requirements for the eigenvalue c approximations . c c \ Usage : c call dnaupd c ( IDO , BMAT , N , WHICH , NEV , TOL , RESID , NCV , V , LDV , IPARAM , c IPNTR , WORKD , WORKL , LWORKL , INFO ) c c \ Arguments c IDO Integer . ( INPUT / OUTPUT ) c Reverse communication flag . IDO must be zero on the first c call to dnaupd . IDO will be set internally to c indicate the type of operation to be performed . Control is c then given back to the calling routine which has the c responsibility to carry out the requested operation and call c dnaupd with the result . The operand is given in c WORKD ( IPNTR ( 1 ) ) , the result must be put in WORKD ( IPNTR ( 2 ) ) . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c IDO = 0 : first call to the reverse communication interface c IDO = - 1 : compute Y = OP * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y . c This is for the initialization phase to force the c starting vector into the range of OP . c IDO = 1 : compute Y = OP * Z and Z = B * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y , c IPNTR ( 3 ) is the pointer into WORKD for Z . c IDO = 2 : compute Y = B * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y . c IDO = 3 : compute the IPARAM ( 8 ) real and imaginary parts c of the shifts where INPTR ( 14 ) is the pointer c into WORKL for placing the shifts . See Remark c 5 below . c IDO = 4 : compute Z = OP * X c IDO = 99 : done c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c After the initialization phase , when the routine is used in c the " shift - and - invert " mode , the vector B * X is already c available and does not need to be recomputed in forming OP * X . c c BMAT Character * 1 . ( INPUT ) c BMAT specifies the type of the matrix B that defines the c semi - inner product for the operator OP . c BMAT = ' I ' - > standard eigenvalue problem A * x = lambda * x - D R A F T - 31 J u l y 96 C . 2 . D NAU P D 1 20 c BMAT = ' G ' - > generalized eigenvalue problem A * x = lambda * B * x c c N Integer . ( INPUT ) c Dimension of the eigenproblem . c c WHICH Character * 2 . ( INPUT ) c ' LM ' - > want the NEV eigenvalues of largest magnitude . c ' SM ' - > want the NEV eigenvalues of smallest magnitude . c ' LR ' - > want the NEV eigenvalues of largest real part . c ' SR ' - > want the NEV eigenvalues of smallest real part . c ' LI ' - > want the NEV eigenvalues of largest imaginary part . c ' SI ' - > want the NEV eigenvalues of smallest imaginary part . c c NEV Integer . ( INPUT ) c Number of eigenvalues of OP to be computed . 0 < NEV < N - 1 . c c TOL Double precision scalar . ( INPUT ) c Stopping criterion : the relative accuracy of the Ritz value c is considered acceptable if BOUNDS ( I ) . LE . TOL * ABS ( RITZ ( I ) ) c where ABS ( RITZ ( I ) ) is the magnitude when RITZ ( I ) is complex . c DEFAULT = DLAMCH ( ' EPS ' ) ( machine precision as computed c by the LAPACK auxiliary subroutine DLAMCH ) . c c RESID Double precision array of length N . ( INPUT / OUTPUT ) c On INPUT : c If INFO . EQ . 0 , a random initial residual vector is used . c If INFO . NE . 0 , RESID contains the initial residual vector , c possibly from a previous run . c On OUTPUT : c RESID contains the final residual vector . c c NCV Integer . ( INPUT ) c Number of columns of the matrix V . NCV must satisfy the two c inequalities 2 < = NCV - NEV and NCV < = N . c This will indicate how many Arnoldi vectors are generated c at each iteration . After the startup phase in which NEV c Arnoldi vectors are generated , the algorithm generates c approximately NCV - NEV Arnoldi vectors at each subsequent update c iteration . Most of the cost in generating each Arnoldi vector is c in the matrix - vector operation OP * x . c NOTE : 2 < = NCV - NEV in order that complex conjugate pairs of Ritz c values are kept together . ( See remark 4 below ) c c V Double precision array N by NCV . ( OUTPUT ) c Contains the final set of Arnoldi basis vectors . c c LDV Integer . ( INPUT ) c Leading dimension of V exactly as declared in the calling program . c c IPARAM Integer array of length 11 . ( INPUT / OUTPUT ) c IPARAM ( 1 ) = ISHIFT : method for selecting the implicit shifts . c The shifts selected at each iteration are used to restart c the Arnoldi iteration in an implicit fashion . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c ISHIFT = 0 : the shifts are provided by the user via c reverse communication . The real and imaginary c parts of the NCV eigenvalues of the Hessenberg c matrix H are returned in the part of the WORKL c array corresponding to RITZR and RITZI . See remark c 5 below . c ISHIFT = 1 : exact shifts with respect to the current c Hessenberg matrix H . This is equivalent to c restarting the iteration with a starting vector c that is a linear combination of approximate Schur c vectors associated with the " wanted " Ritz values . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c c IPARAM ( 2 ) = No longer referenced . c c IPARAM ( 3 ) = MXITER c On INPUT : maximum number of Arnoldi update iterations allowed . c On OUTPUT : actual number of Arnoldi update iterations taken . c c IPARAM ( 4 ) = NB : blocksize to be used in the recurrence . c The code currently works only for NB = 1 . c c IPARAM ( 5 ) = NCONV : number of " converged " Ritz values . c This represents the number of Ritz values that satisfy c the convergence criterion . c c IPARAM ( 6 ) = IUPD c No longer referenced . Implicit restarting is ALWAYS used . c c IPARAM ( 7 ) = MODE c On INPUT determines what type of eigenproblem is being solved . c Must be 1 , 2 , 3 , 4 ; See under \ Description of dnaupd for the c four modes available . c c IPARAM ( 8 ) = NP c When ido = 3 and the user provides shifts through reverse c communication ( IPARAM ( 1 ) = 0 ) , dnaupd returns NP , the number c of shifts the user is to provide . 0 < NP < = NCV - NEV . See Remark c 5 below . c c IPARAM ( 9 ) = NUMOP , IPARAM ( 10 ) = NUMOPB , IPARAM ( 11 ) = NUMREO , c OUTPUT : NUMOP = total number of OP * x operations , c NUMOPB = total number of B * x operations if BMAT = ' G ' , c NUMREO = total number of steps of re - orthogonalization . c c IPNTR Integer array of length 14 . ( OUTPUT ) c Pointer to mark the starting locations in the WORKD and WORKL c arrays for matrices / vectors used by the Arnoldi iteration . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c IPNTR ( 1 ) : pointer to the current operand vector X in WORKD . c IPNTR ( 2 ) : pointer to the current result vector Y in WORKD . c IPNTR ( 3 ) : pointer to the vector B * X in WORKD when used in c the shift - and - invert mode . c IPNTR ( 4 ) : pointer to the next available location in WORKL c that is untouched by the program . c IPNTR ( 5 ) : pointer to the NCV by NCV upper Hessenberg matrix - D R A F T - 31 J u l y 96 A PPE N D I X C . T H E XYAU P D A R P A C K R O U T I N E S 121 c H in WORKL . c IPNTR ( 6 ) : pointer to the real part of the ritz value array c RITZR in WORKL . c IPNTR ( 7 ) : pointer to the imaginary part of the ritz value array c RITZI in WORKL . c IPNTR ( 8 ) : pointer to the Ritz estimates in array WORKL associated c with the Ritz values located in RITZR and RITZI in WORKL . c c Note : IPNTR ( 9 : 13 ) is only referenced by dneupd . See Remark 2 below . c c IPNTR ( 9 ) : pointer to the real part of the NCV RITZ values of the c original system . c IPNTR ( 10 ) : pointer to the imaginary part of the NCV RITZ values of c the original system . c IPNTR ( 11 ) : pointer to the NCV corresponding error bounds . c IPNTR ( 12 ) : pointer to the NCV by NCV upper quasi - triangular c Schur matrix for H . c IPNTR ( 13 ) : pointer to the NCV by NCV matrix of eigenvectors c of the upper Hessenberg matrix H . Only referenced by c dneupd if RVEC = . TRUE . See Remark 2 below . c Note : IPNTR ( 9 : 13 ) is only referenced by dneupd . See Remark 2 below . c IPNTR ( 14 ) : pointer to the NP shifts in WORKL . See Remark 5 below . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c c WORKD Double precision work array of length 3 * N . ( REVERSE COMMUNICATION ) c Distributed array to be used in the basic Arnoldi iteration c for reverse communication . The user should not use WORKD c as temporary workspace during the iteration . Upon termination c WORKD ( 1 : N ) contains B * RESID ( 1 : N ) . If an invariant subspace c associated with the converged Ritz values is desired , see remark c 2 below , subroutine dneupd uses this output . c See Data Distribution Note below . c c WORKL Double precision work array of length LWORKL . ( OUTPUT / WORKSPACE ) c Private ( replicated ) array on each PE or array allocated on c the front end . See Data Distribution Note below . c c LWORKL Integer . ( INPUT ) c LWORKL must be at least 3 * NCV * * 2 + 6 * NCV . c c INFO Integer . ( INPUT / OUTPUT ) c If INFO . EQ . 0 , a randomly initial residual vector is used . c If INFO . NE . 0 , RESID contains the initial residual vector , c possibly from a previous run . c Error flag on output . c = 0 : Normal exit . c = 1 : Maximum number of iterations taken . c All possible eigenvalues of OP has been found . IPARAM ( 5 ) c returns the number of wanted converged Ritz values . c = 2 : No longer an informational error . Deprecated starting c with release 2 of ARPACK . c = 3 : No shifts could be applied during a cycle of the c Implicitly restarted Arnoldi iteration . One possibility c is to increase the size of NCV relative to NEV . c See remark 4 below . c = - 1 : N must be positive . c = - 2 : NEV must be positive . c = - 3 : NCV - NEV > = 2 and less than or equal to N . c = - 4 : The maximum number of Arnoldi update iteration c must be greater than zero . c = - 5 : WHICH must be one of ' LM ' , ' SM ' , ' LR ' , ' SR ' , ' LI ' , ' SI ' c = - 6 : BMAT must be one of ' I ' or ' G ' . c = - 7 : Length of private work array is not sufficient . c = - 8 : Error return from LAPACK eigenvalue calculation ; c = - 9 : Starting vector is zero . c = - 10 : IPARAM ( 7 ) must be 1 , 2 , 3 , 4 . c = - 11 : IPARAM ( 7 ) = 1 and BMAT = ' G ' are incompatable . c = - 12 : IPARAM ( 1 ) must be equal to 0 or 1 . c = - 9999 : Could not build an Arnoldi factorization . c IPARAM ( 5 ) returns the size of the current Arnoldi c factorization . c c \ Remarks c 1 . The computed Ritz values are approximate eigenvalues of OP . The c selection of WHICH should be made with this in mind when c Mode = 3 and 4 . After convergence , approximate eigenvalues of the c original problem may be obtained with the ARPACK subroutine dneupd . c c 2 . If a basis for the invariant subspace corresponding to the converged Ritz c values is needed , the user must call dneupd immediately following c completion of dnaupd . This is new starting with release 2 of ARPACK . c c 3 . If M can be factored into a Cholesky factorization M = LL ' c then Mode = 2 should not be selected . Instead one should use c Mode = 1 with OP = inv ( L ) * A * inv ( L ' ) . Appropriate triangular c linear systems should be solved with L and L ' rather c than computing inverses . After convergence , an approximate c eigenvector z of the original problem is recovered by solving c L ' z = x where x is a Ritz vector of OP . c c 4 . At present there is no a - priori analysis to guide the selection c of NCV relative to NEV . The only formal requrement is that NCV > NEV + 2 . c However , it is recommended that NCV . ge . 2 * NEV + 1 . If many problems of c the same type are to be solved , one should experiment with increasing c NCV while keeping NEV fixed for a given test problem . This will c usually decrease the required number of OP * x operations but it c also increases the work and storage required to maintain the orthogonal c basis vectors . The optimal " cross - over " with respect to CPU time c is problem dependent and must be determined empirically . c See Chapter 8 of Reference 2 for further information . c c 5 . When IPARAM ( 1 ) = 0 , and IDO = 3 , the user needs to provide the c NP = IPARAM ( 8 ) real and imaginary parts of the shifts in locations c real part imaginary part c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c 1 WORKL ( IPNTR ( 14 ) ) WORKL ( IPNTR ( 14 ) + NP ) c 2 WORKL ( IPNTR ( 14 ) + 1 ) WORKL ( IPNTR ( 14 ) + NP + 1 ) c . . c . . c . . - D R A F T - 31 J u l y 96 C . 3 . Z NAU P D 1 22 c NP WORKL ( IPNTR ( 14 ) + NP - 1 ) WORKL ( IPNTR ( 14 ) + 2 * NP - 1 ) . c c Only complex conjugate pairs of shifts may be applied and the pairs c must be placed in consecutive locations . The real part of the c eigenvalues of the current upper Hessenberg matrix are located in c WORKL ( IPNTR ( 6 ) ) through WORKL ( IPNTR ( 6 ) + NCV - 1 ) and the imaginary part c in WORKL ( IPNTR ( 7 ) ) through WORKL ( IPNTR ( 7 ) + NCV - 1 ) . They are ordered c according to the order defined by WHICH . The complex conjugate c pairs are kept together and the associated Ritz estimates are located in c WORKL ( IPNTR ( 8 ) ) , WORKL ( IPNTR ( 8 ) + 1 ) , . . . , WORKL ( IPNTR ( 8 ) + NCV - 1 ) . c c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - C . 3 ZNAUPD c \ BeginDoc c c \ Name : znaupd c c \ Description : c Reverse communication interface for the Implicitly Restarted Arnoldi c iteration . This is intended to be used to find a few eigenpairs of a c complex linear operator OP with respect to a semi - inner product defined c by a hermitian positive semi - definite real matrix B . B may be the identity c matrix . NOTE : if both OP and B are real , then dsaupd or dnaupd should c be used . c c c The computed approximate eigenvalues are called Ritz values and c the corresponding approximate eigenvectors are called Ritz vectors . c c znaupd is usually called iteratively to solve one of the c following problems : c c Mode 1 : A * x = lambda * x . c = = = > OP = A and B = I . c c Mode 2 : A * x = lambda * M * x , M symmetric positive definite c = = = > OP = inv [ M ] * A and B = M . c = = = > ( If M can be factored see remark 3 below ) c c Mode 3 : A * x = lambda * M * x , M symmetric semi - definite c = = = > OP = inv [ A - sigma * M ] * M and B = M . c = = = > shift - and - invert mode c If OP * x = amu * x , then lambda = sigma + 1 / amu . c c c NOTE : The action of w < - inv [ A - sigma * M ] * v or w < - inv [ M ] * v c should be accomplished either by a direct method c using a sparse matrix factorization and solving c c [ A - sigma * M ] * w = v or M * w = v , c c or through an iterative method for solving these c systems . If an iterative method is used , the c convergence test must be more stringent than c the accuracy requirements for the eigenvalue c approximations . c c \ Usage : c call znaupd c ( IDO , BMAT , N , WHICH , NEV , TOL , RESID , NCV , V , LDV , IPARAM , c IPNTR , WORKD , WORKL , LWORKL , RWORK , INFO ) c c \ Arguments c IDO Integer . ( INPUT / OUTPUT ) c Reverse communication flag . IDO must be zero on the first c call to znaupd . IDO will be set internally to c indicate the type of operation to be performed . Control is c then given back to the calling routine which has the c responsibility to carry out the requested operation and call c znaupd with the result . The operand is given in c WORKD ( IPNTR ( 1 ) ) , the result must be put in WORKD ( IPNTR ( 2 ) ) . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c IDO = 0 : first call to the reverse communication interface c IDO = - 1 : compute Y = OP * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y . c This is for the initialization phase to force the c starting vector into the range of OP . c IDO = 1 : compute Y = OP * Z and Z = B * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y , c IPNTR ( 3 ) is the pointer into WORKD for Z . c IDO = 2 : compute Y = M * X where c IPNTR ( 1 ) is the pointer into WORKD for X , c IPNTR ( 2 ) is the pointer into WORKD for Y . c IDO = 3 : compute and return the shifts in the first c NP locations of WORKL . c IDO = 4 : compute Z = OP * X c IDO = 99 : done c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c After the initialization phase , when the routine is used in c the " shift - and - invert " mode , the vector M * X is already c available and does not need to be recomputed in forming OP * X . c c BMAT Character * 1 . ( INPUT ) c BMAT specifies the type of the matrix B that defines the c semi - inner product for the operator OP . c BMAT = ' I ' - > standard eigenvalue problem A * x = lambda * x c BMAT = ' G ' - > generalized eigenvalue problem A * x = lambda * M * x c c N Integer . ( INPUT ) c Dimension of the eigenproblem . c c WHICH Character * 2 . ( INPUT ) c ' LM ' - > want the NEV eigenvalues of largest magnitude . - D R A F T - 31 J u l y 96 A PPE N D I X C . T H E XYAU P D A R P A C K R O U T I N E S 123 c ' SM ' - > want the NEV eigenvalues of smallest magnitude . c ' LR ' - > want the NEV eigenvalues of largest real part . c ' SR ' - > want the NEV eigenvalues of smallest real part . c ' LI ' - > want the NEV eigenvalues of largest imaginary part . c ' SI ' - > want the NEV eigenvalues of smallest imaginary part . c c NEV Integer . ( INPUT ) c Number of eigenvalues of OP to be computed . 0 < NEV < N - 1 . c c TOL Double precision scalar . ( INPUT ) c Stopping criteria : the relative accuracy of the Ritz value c is considered acceptable if BOUNDS ( I ) . LE . TOL * ABS ( RITZ ( I ) ) c where ABS ( RITZ ( I ) ) is the magnitude when RITZ ( I ) is complex . c DEFAULT = dlamch ( ' EPS ' ) ( machine precision as computed c by the LAPACK auxiliary subroutine dlamch ) . c c RESID Complex * 16 array of length N . ( INPUT / OUTPUT ) c On INPUT : c If INFO . EQ . 0 , a random initial residual vector is used . c If INFO . NE . 0 , RESID contains the initial residual vector , c possibly from a previous run . c On OUTPUT : c RESID contains the final residual vector . c c NCV Integer . ( INPUT ) c Number of columns of the matrix V . NCV must satisfy the two c inequalities 2 < = NCV - NEV and NCV < = N . c This will indicate how many Arnoldi vectors are generated c at each iteration . After the startup phase in which NEV c Arnoldi vectors are generated , the algorithm generates c approximately NCV - NEV Arnoldi vectors at each subsequent update c iteration . Most of the cost in generating each Arnoldi vector is c in the matrix - vector operation OP * x . c NOTE : 2 < = NCV - NEV in order that complex conjugate pairs of Ritz c values are kept together . ( See remark 4 below ) c c V Complex * 16 array N by NCV . ( OUTPUT ) c Contains the final set of Arnoldi basis vectors . c c LDV Integer . ( INPUT ) c Leading dimension of V exactly as declared in the calling program . c c IPARAM Integer array of length 11 . ( INPUT / OUTPUT ) c IPARAM ( 1 ) = ISHIFT : method for selecting the implicit shifts . c The shifts selected at each iteration are used to filter out c the components of the unwanted eigenvector . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c ISHIFT = 0 : the shifts are to be provided by the user via c reverse communication . The NCV eigenvalues of c the Hessenberg matrix H are returned in the part c of WORKL array corresponding to RITZ . c ISHIFT = 1 : exact shifts with respect to the current c Hessenberg matrix H . This is equivalent to c restarting the iteration from the beginning c after updating the starting vector with a linear c combination of Ritz vectors associated with the c " wanted " eigenvalues . c ISHIFT = 2 : other choice of internal shift to be defined . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c c IPARAM ( 2 ) = No longer referenced c c IPARAM ( 3 ) = MXITER c On INPUT : maximum number of Arnoldi update iterations allowed . c On OUTPUT : actual number of Arnoldi update iterations taken . c c IPARAM ( 4 ) = NB : blocksize to be used in the recurrence . c The code currently works only for NB = 1 . c c IPARAM ( 5 ) = NCONV : number of " converged " Ritz values . c This represents the number of Ritz values that satisfy c the convergence criterion . c c IPARAM ( 6 ) = IUPD c No longer referenced . Implicit restarting is ALWAYS used . c c IPARAM ( 7 ) = MODE c On INPUT determines what type of eigenproblem is being solved . c Must be 1 , 2 , 3 , 4 ; See under \ Description of znaupd for the c four modes available . c c IPARAM ( 8 ) = NP c When ido = 3 and the user provides shifts through reverse c communication ( IPARAM ( 1 ) = 0 ) , _ naupd returns NP , the number c of shifts the user is to provide . 0 < NP < NCV - NEV . c c IPARAM ( 9 ) = NUMOP , IPARAM ( 10 ) = NUMOPB , IPARAM ( 11 ) = NUMREO , c OUTPUT : NUMOP = total number of OP * x operations , c NUMOPB = total number of B * x operations if BMAT = ' G ' , c NUMREO = total number of steps of re - orthogonalization . c c IPNTR Integer array of length 14 . ( OUTPUT ) c Pointer to mark the starting locations in the WORKD and WORKL c arrays for matrices / vectors used by the Arnoldi iteration . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c IPNTR ( 1 ) : pointer to the current operand vector X in WORKD . c IPNTR ( 2 ) : pointer to the current result vector Y in WORKD . c IPNTR ( 3 ) : pointer to the vector B * X in WORKD when used in c the shift - and - invert mode . c IPNTR ( 4 ) : pointer to the next available location in WORKL c that is untouched by the program . c IPNTR ( 5 ) : pointer to the NCV by NCV upper Hessenberg c matrix H in WORKL . c IPNTR ( 6 ) : pointer to the ritz value array RITZ c IPNTR ( 7 ) : pointer to the ( projected ) ritz vector array Q c IPNTR ( 8 ) : pointer to the error BOUNDS array in WORKL . c Note : IPNTR ( 9 : 13 ) is only referenced by zneupd . See Remark 2 below . c IPNTR ( 9 ) : pointer to the NCV RITZ values of the c original system . c IPNTR ( 10 ) : Not Used - D R A F T - 31 J u l y 96 C . 3 . Z NAU P D 1 24 c IPNTR ( 11 ) : pointer to the NCV corresponding error bounds . c IPNTR ( 14 ) : pointer to the NP shifts in WORKL . See Remark 5 below . c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - c c WORKD Complex * 16 work array of length 3 * N . ( REVERSE COMMUNICATION ) c Distributed array to be used in the basic Arnoldi iteration c for reverse communication . The user should not use WORKD c as temporary workspace during the iteration ! ! ! ! ! ! ! ! ! ! c See Data Distribution Note below . c c WORKL Complex * 16 work array of length LWORKL . ( OUTPUT / WORKSPACE ) c Private ( replicated ) array on each PE or array allocated on c the front end . See Data Distribution Note below . c c LWORKL Integer . ( INPUT ) c LWORKL must be at least 3 * NCV * * 2 + 5 * NCV . c c RWORK Double precision work array of length NCV ( WORKSPACE ) c Private ( replicated ) array on each PE or array allocated on c the front end . c c c INFO Integer . ( INPUT / OUTPUT ) c If INFO . EQ . 0 , a randomly initial residual vector is used . c If INFO . NE . 0 , RESID contains the initial residual vector , c possibly from a previous run . c Error flag on output . c = 0 : Normal exit . c = 1 : Maximum number of iterations taken . c All possible eigenvalues of OP has been found . IPARAM ( 5 ) c returns the number of wanted converged Ritz values . c = 2 : No longer an informational error . Deprecated starting c with release 2 of ARPACK . c = 3 : No shifts could be applied during a cycle of the c Implicitly restarted Arnoldi iteration . One possibility c is to increase the size of NCV relative to NEV . c See remark 4 below . c = - 1 : N must be positive . c = - 2 : NEV must be positive . c = - 3 : NCV - NEV > = 2 and less than or equal to N . c = - 4 : The maximum number of Arnoldi update iteration c must be greater than zero . c = - 5 : WHICH must be one of ' LM ' , ' SM ' , ' LR ' , ' SR ' , ' LI ' , ' SI ' c = - 6 : BMAT must be one of ' I ' or ' G ' . c = - 7 : Length of private work array is not sufficient . c = - 8 : Error return from LAPACK eigenvalue calculation ; c = - 9 : Starting vector is zero . c = - 10 : IPARAM ( 7 ) must be 1 , 2 , 3 . c = - 11 : IPARAM ( 7 ) = 1 and BMAT = ' G ' are incompatable . c = - 12 : IPARAM ( 1 ) must be equal to 0 or 1 . c = - 9999 : Could not build an Arnoldi factorization . c User input error highly likely . Please c check actual array dimensions and layout . c IPARAM ( 5 ) returns the size of the current Arnoldi c factorization . c c \ Remarks c 1 . The computed Ritz values are approximate eigenvalues of OP . The c selection of WHICH should be made with this in mind when using c Mode = 3 . When operating in Mode = 3 setting WHICH = ' LM ' will c compute the NEV eigenvalues of the original problem that are c closest to the shift SIGMA . After convergence , approximate eigenvalues c of the original problem may be obtained with the ARPACK subroutine zneupd . c c 2 . If a basis for the invariant subspace corresponding to the converged Ritz c values is needed , the user must call zneupd immediately following c completion of znaupd . This is new starting with release 2 of ARPACK . c c 3 . If M can be factored into a Cholesky factorization M = LL ' c then Mode = 2 should not be selected . Instead one should use c Mode = 1 with OP = inv ( L ) * A * inv ( L ' ) . Appropriate triangular c linear systems should be solved with L and L ' rather c than computing inverses . After convergence , an approximate c eigenvector z of the original problem is recovered by solving c L ' z = x where x is a Ritz vector of OP . c c 4 . At present there is no a - priori analysis to guide the selection c of NCV relative to NEV . The only formal requrement is that NCV > NEV + 2 . c However , it is recommended that NCV . ge . 2 * NEV + 1 . If many problems of c the same type are to be solved , one should experiment with increasing c NCV while keeping NEV fixed for a given test problem . This will c usually decrease the required number of OP * x operations but it c also increases the work and storage required to maintain the orthogonal c basis vectors . The optimal " cross - over " with respect to CPU time c is problem dependent and must be determined empirically . c See Chapter 8 of Reference 2 for further information . c c 5 . When IPARAM ( 1 ) = 0 , and IDO = 3 , the user needs to provide the c NP = IPARAM ( 8 ) complex shifts in locations c WORKL ( IPNTR ( 14 ) ) , WORKL ( IPNTR ( 14 ) + 1 ) , . . . , WORKL ( IPNTR ( 14 ) + NP ) . c Eigenvalues of the current upper Hessenberg matrix are located in c WORKL ( IPNTR ( 6 ) ) through WORKL ( IPNTR ( 6 ) + NCV - 1 ) . They are ordered c according to the order defined by WHICH . The associated Ritz estimates c are located in WORKL ( IPNTR ( 8 ) ) , WORKL ( IPNTR ( 8 ) + 1 ) , . . . , c WORKL ( IPNTR ( 8 ) + NCV - 1 ) . c c - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - D R A F T - 31 J u l y 96 Bibliography [ 1 ] E . Anderson , Z . Bai , C . Bischof , J . Demmel , J . Dongarra , J . Du Croz , A . Green - baum , S . Hammarling , A . McKenney , S . Ostrouchov , and D . Sorensen . LAPACK Users ' Guide . SIAM , Philadelphia , PA , second edition , 1995 . [ 2 ] W . E . Arnoldi . The principle of minimized iterations in the solution of the matrix eigenvalue problem . Quart . J . Applied Mathematics , 9 : 17 { 29 , 1951 . [ 3 ] Z . Bai , J . Demmel , and A . Mckenney . On computing condition numbers for the nonsymmetric eigenproblem . ACM Transactions on Mathematical Software , 19 ( 2 ) : 202 { 223 , June 1993 . LAPACK Working Note . [ 4 ] J . Cullum . The simultaneous computation of a few of the algebraically largest and smallest eigenvalues of a large , symmetric , sparse matrix . BIT , 18 : 265 { 275 , 1978 . [ 5 ] J . Cullum and W . E . Donath . A block Lanczos algorithm for computing the q algebraically largest eigenvalues and a corresponding eigenspace for large , sparse symmetric matrices . In Proceedings of the 1974 IEEE Conference on Decision and Control , pages 505 { 509 , New York , 1974 . [ 6 ] J . Cullum and R . A . Willoughby . Computing eigenvalues of very large symmetric matrices | an implementation of a Lanczos algorithm with no reorthogonaliza - tion . Journal of Computational Physics , 434 : 329 { 358 , 1981 . [ 7 ] J . Daniel , W . B . Gragg , L . Kaufman , and G . W . Stewart . Reorthogonaliza - tion and stable algorithms for updating the Gram { Schmidt QR factorization . Mathematics of Computation , 30 : 772 { 795 , 1976 . [ 8 ] J . J . Dongarra , I . S . Du(cid:11) , D . C . Sorensen , and H . A . Van der Vorst . Solving Linear systems on Vector and shared memory computers . SIAM , Philadelphia , PA . , 1991 . [ 9 ] J . J . Dongarra , J . DuCroz , I . S . Du(cid:11) , and S . Hammarling . A set of level 3 basic linear algebra subprograms . ACM Transactions on Mathematical Software , 16 ( 1 ) : 1 { 17 , 1990 . 125 BIBLIOGRAPHY 126 [ 10 ] J . J . Dongarra , J . DuCroz , S . Hammarling , and R . J . Hanson . An extended set of Fortran basic linear algebra subprograms . ACM Trans . on Math . Software , 14 ( 1 ) : 1 { 17 , 1988 . [ 11 ] T . Ericsson and A . Ruhe . The spectral transformation Lanczos method for the numerical solution of large sparse generalized symmetric eigenvalue problems . Mathematics of Computation , 35 : 1251 { 1268 , October 1980 . [ 12 ] J . G . F . Francis . The QR transformation | part 1 . The Computer Journal , 4 : 265 { 271 , October 1961 . [ 13 ] J . G . F . Francis . The QR transformation | part 2 . The Computer Journal , 4 : 332 { 345 , January 1962 . [ 14 ] G . H . Golub and C . F . Van Loan . Matrix Computations . Johns Hopkins , Balti - more , second edition , 1989 . [ 15 ] G . H . Golub and R . Underwood . The block Lanczos method for computing eigenvalues . In J . R . Rice , editor , Mathematical Software III , pages 361 { 377 , New York , 1977 . Academic Press . [ 16 ] R . G . Grimes , J . G . Lewis , and H . D . Simon . A shifted block Lanczos algorithm for solving sparse symmetric generalized eigenproblems . SIAM J . Matrix Analysis and Applications , 15 ( 1 ) : 228 { 272 , January 1994 . [ 17 ] W . Karush . An iterative method for (cid:12)nding characteristics vectors of a symmetric matrix . Paci(cid:12)c J . Mathematics , 1 : 233 { 248 , 1951 . [ 18 ] C . Lanczos . An iteration method for the solution of the eigenvalue problem of linear di(cid:11)erential and integral operators . J . Research of the National Bureau of Standards , 45 ( 4 ) : 255 { 282 , October 1950 . Research Paper 2133 . [ 19 ] C . L . Lawson , R . J . Hanson , D . R . Kincaid , and F . T . Krogh . Basic linear algebra subprograms for Fortran usage . ACM Transactions on Mathematical Software , 5 ( 3 ) : 308 { 323 , 1979 . [ 20 ] R . B . Lehoucq . Analysis and Implementation of an Implicitly Restarted Itera - tion . PhD thesis , Rice University , Houston , Texas , May 1995 . Also available as Technical Report TR95 - 13 , Dept . of Computational and Applied Mathematics . [ 21 ] R . B . Lehoucq . Restarting an Arnoldi reduction . Preprint MCS - P591 - 0496 , Argonne National Laboratory , Argonne , IL , 1996 . [ 22 ] R . B . Lehoucq and J . A . Scott . An evaluation of software for computing eigen - values of sparse nonsymmetric matrices . Preprint MCS - P547 - 1195 , Argonne Na - tional Laboratory , Argonne , IL , 1995 . - DRAFT - 31 July 96 BIBLIOGRAPHY 127 [ 23 ] R . B . Lehoucq and D . C . Sorensen . De(cid:13)ation techniques for an implicitly restarted arnoldi iteration . SIAM J . Matrix Analysis and Applications , 1996 . To appear . [ 24 ] T . A . Manteu(cid:11)el . Adaptive procedure for estimating parameters for the nonsym - metric Tchebychev iteration . Numerische Mathematik , 31 : 183 { 208 , 1978 . [ 25 ] K . J . Maschho(cid:11) and D . C . Sorensen . A portable implementation of ARPACK for distributed memory parallel architectures . In Proceedings of the Copper Moun - tain Conference on Iterative Methods , April 9 { 13 , 1996 . , volume 1 , 1996 . [ 26 ] Karl Meerbergen and Alastair Spence . Implicitly restarted Arnoldi with puri(cid:12) - cation for the shift { invert transformation . Mathematics of Computation , 1996 . To appear . [ 27 ] R . B . Morgan . On restarting the Arnoldi method for large nonsymmetric eigen - value problems . Mathematics of Computation , 65 ( 215 ) : 1213 { 1230 , July 1996 . [ 28 ] B . Nour - Omid , B . N . Parlett , and Thomas Ericsson Paul S . Jensen . How to im - plement the spectral transformation . Mathematics of Computation , 48 ( 178 ) : 663 { 673 , April 1987 . [ 29 ] C . C . Paige . The computation of eigenvalues and eigenvectors of very large sparse matrices . PhD thesis , University of London , London , England , 1971 . [ 30 ] B . N . Parlett . The Symmetric Eigenvalue Problem . Prentice - Hall , Englewood Cli(cid:11)s , N . J . , 1980 . [ 31 ] B . N . Parlett and W . G . Poole . A geometric theory for the QR , LU , and power iterations . SIAM J . Numerical Analysis , 10 ( 2 ) : 389 { 412 , April 1973 . [ 32 ] B . N . Parlett and D . Scott . The Lanczos algorithm with selective orthogonaliza - tion . Mathematics of Computation , 33 : 217 { 238 , 1979 . [ 33 ] Y . Saad . Variations on Arnoldi ' s method for computing eigenelements of large unsymmetric matrices . Linear Algebra and Its Applications , 34 : 269 { 295 , 1980 . [ 34 ] Y . Saad . Chebyshev acceleration techniques for solving nonsymmetric eigenvalue problems . Mathematics of Computation , 42 : 567 { 588 , 1984 . [ 35 ] Y . Saad . Numerical Methods for Large Eigenvalue Problems . Halsted Press , 1992 . [ 36 ] Y . Saad and M . H . Schultz . GMRES : A generalized minimal residual algorithm for solving nonsymmetric linear systems . SIAM Journal on Scienti(cid:12)c and Sta - tistical Computing , 7 ( 3 ) : 856 { 869 , July 1986 . - DRAFT - 31 July 96 BIBLIOGRAPHY 128 [ 37 ] H . Simon . Analysis of the symmetric Lanczos algorithm with reorthogonalization methods . Linear Algebra and Its Applications , 61 : 101 { 131 , 1984 . [ 38 ] D . C . Sorensen . Implicit application of polynomial (cid:12)lters in a k - step Arnoldi method . SIAM J . Matrix Analysis and Applications , 13 ( 1 ) : 357 { 385 , January 1992 . [ 39 ] D . C . Sorensen . Implicitly restarted Arnoldi / Lanczos methods for large scale eigenvalue calculations . In D . E . Keyes , A . Sameh , and V . Venkatakrishnan , editors , Parallel Numerical Algorithms , Dordrecht , 1995 . Kluwer . To appear . [ 40 ] J . M . Varah . On the separation of two matrices . SIAM Journal on Numerical Analysis , 16 ( 2 ) : 216 { 222 , April 1979 . [ 41 ] D . S . Watkins and L . Elsner . Convergence of algorithms of decomposition type for the eigenvalue problem . Linear Algebra and Its Applications , 143 : 19 { 47 , 1991 . [ 42 ] J . H . Wilkinson . The Algebraic Eigenvalue Problem . Clarendon Press , Oxford , UK , 1965 . - DRAFT - 31 July 96