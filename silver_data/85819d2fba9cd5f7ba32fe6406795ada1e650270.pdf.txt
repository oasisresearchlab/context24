Fair Grading Algorithms for Randomized Exams Jiale Chen ∗ Jason Hartline † Onno Zoeter ‡ Abstract This paper studies grading algorithms for randomized exams . In a randomized exam , each student is asked a small number of random questions from a large question bank . The pre - dominant grading rule is simple averaging , i . e . , calculating grades by averaging scores on the questions each student is asked , which is fair ex - ante , over the randomized questions , but not fair ex - post , on the realized questions . The fair grading problem is to estimate the average grade of each student on the full question bank . The maximum - likelihood estimator for the Bradley - Terry - Luce model on the bipartite student - question graph is shown to be consistent with high probability when the number of questions asked to each student is at least the cubed - logarithm of the number of students . In an empirical study on exam data and in simulations , our algo - rithm based on the maximum - likelihood estimator signiﬁcantly outperforms simple averaging in prediction accuracy and ex - post fairness even with a small class and exam size . 1 Introduction A common approach for deterring cheating in online examinations is to assign students random questions from a large question bank . This random assignment of questions with heterogeneous diﬃculties leads to diﬀerent overall diﬃculties of the exam that each student faces . Unfortunately , the predominant grading rule – simple averaging – averages all question scores equally and results in an unfair grading of the students . This paper develops a grading algorithm that utilizes structural information of the exam results to infer student abilities and question diﬃculties . From these abilities and diﬃculties , fairer and more accurate grades can be estimated . This grading algorithm can also be used in the design of short exams that maintain a desired level of accuracy . During the COVID - 19 pandemic , learning management systems ( LMS ) like Blackboard , Moo - dle , Canvas by Instructure , and D2L have beneﬁted worldwide students and teachers in remote learning [ Raza et al . , 2021 ] . The current exam module in these systems includes four steps . In the ﬁrst step , the instructor provides a large question bank . In the second step , the system assigns each student an independent random subset of the questions . ( Assigning each student an indepen - dent random subset of the questions helps mitigate cheating . ) In the third step , students answer the questions . In the last step , the system grades each student proportionally to her accuracy on assigned questions , i . e . , by simple averaging . While randomizing questions and grading with simple averaging is ex - ante fair , it is not generally ex - post fair . When questions in the question bank have varying diﬃculties , then by random chance a student could be assigned more easy questions than average or more hard questions than average . Ex - post in the random assignment of questions to students , the simple averaging of scores on each question allows variation in question diﬃculties to manifest as ex - post unfairness in the ﬁnal grades . ∗ Department of Management Science and Engineering , Stanford University . Email : jialec @ stanford . edu . † Department of Computer Science , Northwestern University . Email : hartline @ northwestern . edu . ‡ Booking . com . Email : Onno . zoeter @ booking . com . 1 a r X i v : 2304 . 06254v1 [ s t a t . M L ] 13 A p r 2023 The aim of this paper is to understand grading algorithms that are fair and accurate . Given a bank of possible questions , a benchmark for both fairness and accuracy is the counterfactual grade that a student would get if the student was asked all of the questions in the question bank . Exams that ask fewer questions to the students may be inaccurate with respect to this benchmark and the inaccuracy may vary across students and this variation is unfair . This benchmark allows for both the comparison of grading algorithms and the design of randomized exams , i . e . , the method for deciding which questions are asked to which students . The grading algorithms developed in this paper are based on the Bradley - Terry - Luce model [ Bradley and Terry , 1952 ] on bipartite student - question graphs . This model is also studied in the psychology literature where it is known as the Rasch model [ Rasch , 1993 ] . This model views the student answering process as a noisy comparison between a parameter of the student and a parameter of the question . Speciﬁcally , there is a merit value vector u which describes the student abilities and question diﬃculties and is unknown to the instructor . The probability that student i answers question j correctly is deﬁned to be f ( u i − u j ) = exp ( u i ) exp ( u i ) + exp ( u j ) , where f ( x ) = 1 1 + exp ( − x ) , and u i , u j represents the merit value of student i and question j respec - tively . The paper develops a grading algorithm that is based on the maximum likelihood estimator u ∗ of the merit vector . Compared to simple averaging which only focuses on student in - degrees and out - degrees , our grading algorithm incorporates more structural information about the exam result and , as we show , reduces ex - post unfairness . Results . Our theoretical analysis considers a sequence of distributions over random question assignment graphs indexed by n and m by setting the number of students to n and number of questions in the question bank to m ≥ n and assigning d n , m random questions uniformly and independently to each student . The exam result can be represented by a directed graph , where an edge from a student to a question represents a correct answer and the opposite direction represents an incorrect answer . We prove that the maximum likelihood estimator exists and is unique within a strongly connected component ( Theorem 9 ) . Let α n , m = max 1 ≤ i , j ≤ n + m u i − u j be the largest diﬀerence between any pair of merits . We prove that if exp ( α n , m ) ( n + m ) log ( n + m ) nd n , m → 0 ( n , m → ∞ ) , then the probability that the exam result graph is strongly connected goes to 1 ( Theorem 10 ) . Thus , the existence and uniqueness of the MLE are guaranteed under the model . We also prove that if exp ( 2 ( α n , m + 1 ) ) ∆ n , m → 0 ( n , m → ∞ ) , ( 1 ) where ∆ n , m = (cid:114) m log 3 ( n + m ) nd n , m log 2 ( nm d n , m ) , then the MLEs are uniformly consistent , i . e . , (cid:107) u ∗ − u (cid:107) ∞ P −→ 0 ( Theorem 12 ) . These theoretical results complement the empirical and simulation results from the literature on the Rasch model with random missing data . Our analysis is similar to that of Han et al . [ 2020 ] which studies Erd¨os - R´enyi random graphs . Our empirical analysis considers a study of grading algorithms on both anonymous exam data and numerical simulations . The exam data set consists of 22 questions and 35 students with 2 all students answering all questions . From this data set , randomized exams with fewer than 22 questions can be empirically studied and grading algorithms can be compared . Our algorithm outperforms simple averaging when students are asked at least seven questions . We ﬁt the model parameters to this real - world dataset and run numerical simulations with the resulting generative model . With these simulations , we compare our algorithm and simple averaging on ex - post bias and ex - post error , two notion of ex - post unfairness . For example , when each of the 35 students answers a random 10 of the 22 questions , we ﬁnd that the expected maximum ex - post bias of simple averaging is about 100 times higher than that of our algorithm . The expected output of simple averaging has about 13 % expected deviation from the benchmark for the most unlucky student , which would probably lead to a diﬀerent letter grade for the students , while the deviation is only about 1 . 6 % for our algorithm . In the same setting , we found that our algorithm achieves a factor of 8 percent smaller ex - post error , which is a noisier concept of ex - post unfairness . After the decomposition of ex - post error into ex - post bias and variance , we found that our algorithm achieves a signiﬁcantly smaller ex - post bias with the cost of a slightly larger variance of the output , and in combination it reduces the ex - post error . We also evaluate a related simple problem of exam design via simulation in Section 5 . 6 . Given an inﬁnite question bank , we sample a ﬁxed number of active questions , then we create a randomized exam with ﬁve questions for each student drawn from this ﬁxed number of active questions . When there are only ﬁve active questions , our grading algorithm and simple averaging coincide as all students are asked all active questions . When there are an inﬁnite number of active questions the algorithms again coincide as no two students are asked the same question and our algorithm and simple averaging are the same . By simulation we consider the ex - post bias as a function of the number of active questions and ﬁnd that the optimal number of questions is about six to nine for maximum ex - post bias and about ten to ﬁfteen for average ex - post bias . Illustrative Example . Figure 1 illustrates the unfairness that can arise in simple averaging and the intuition for how our algorithm improves fairness . In the fair exam grading problem , the instructor ﬁrst assigns questions to students according to an undirected student - question bipartite graph , a . k . a . , the task assignment graph ( Figure 1 ( a ) ) . The exam result can be represented by a directed student - question bipartite graph , a . k . a . , the exam result graph ( Figure 1 ( b ) ) , where a directed edge from a student to a question represents a correct answer and an opposite direction represents an incorrect answer . Given the exam result graph , the instructor uses a grading algorithm to estimate the average accuracy of students on the whole question bank . We take student S2 as an example to see how simple averaging , as one speciﬁc grading rule , grade students ( Figure 1 ( c ) ) . Simple averaging observes that student S2 has one correct answer and one incorrect answer , in other words , the corresponding vertex has in - degree one and out - degree one . Thus simple averaging predicts that the probability of student S2 answering the remaining question Q3 correctly is 0 . 5 . The reason we believe 0 . 5 is not a good prediction is , in this exam , every student assigned question Q3 answers it correctly , including student S5 and S6 , who give incorrect answers to question Q2 . We can infer that Q3 is a relatively easy question . On the other hand , student S2 who can answer question Q2 correctly has a relatively higher ability among the class . Therefore , it is reasonable to believe that student S2 can give a correct answer to question Q3 and , thus , simple averaging underestimates her grade . We show how our algorithm analyze the missing edge between student S2 and question Q3 in this example ( Figure 1 ( d ) ) . Our algorithm ﬁnds that student S2 belongs to the strongly connected component { S1 , S2 , Q1 , Q2 } , while question Q3 belongs to { Q3 } and the missing edge goes across two comparable components . As a property of the graph , any directed path between student S2 and 3 question Q3 goes from the student to the question . Our grading rule takes it as a strong evidence of the S2’s ability higher than Q3’s diﬃculty and predicts that student S2 can answer question Q3 correctly with probability one . Q1 Q2 Q3 S1 S2 S3 S4 S5 S6 Question Student ( a ) Task Assignment Graph Q1 Q2 Q3 S1 S2 S3 S4 S5 S6 Question Student ( b ) Exam Result Graph Q1 Q2 Q3 S1 S2 S3 S4 S5 S6 Question Student . 5 ( c ) simple averaging Q1 Q2 Q3 S1 S2 S3 S4 S5 S6 Question Student 1 ( d ) Our method Figure 1 : A running example of the exam grading problem Related Work . The literature on peer grading also compares estimation from structural models and simple averaging . When peers are assigned to grade submissions , the quality of peer reviews can vary . Structural models can be used to estimate peer quality and calculate grades on the sub - missions that put higher weight on peers who give higher quality reviews . Alternatively , submission grades can be calculated by simply averaging the reviews of each peer . The literature has mixed results . De Alfaro and Shavlovsky [ 2014 ] propose an algorithm based on reputation that largely outperforms simple averaging on synthetic data , and is better on real - world data when student grading error is not random . Reily et al . [ 2009 ] and Hamer et al . [ 2005 ] also point out that sophis - ticated aggregation improves the accuracy compared to simple averaging and also helps to avoid rogue strategies including laziness and aggressive grading . On the other hand , Sajjadi et al . [ 2016 ] show that statistical and machine learning methods do not perform better than simple averaging on their dataset . In contrast our result that structural models outperform simple averaging is replicated on several data sets . We believe this diﬀerence with the peer grading literature is due to 4 diﬀerences in the degrees of the bipartite graphs considered . The exam grading graphs are higher degree than the peer - grading graphs . In psychometrics , item response theory ( IRT ) considers mathematical models that build rela - tionship between unobserved characteristics of respondents and items and observed outcomes of the responses . The Rasch model is a commonly used model of IRT that can be applied to psycho - metrics , educational research [ Rasch , 1993 ] , health sciences [ Bezruczko , 2005 ] , agriculture [ Moral and Rebollo , 2017 ] , and market research [ Bechtel , 1985 ] . Previous simulation studies showed that among diﬀerent item parameter estimation methods for the Rasch model , the joint maximum likeli - hood ( JML ) method and its variants provides one of the most eﬃcient estimates [ Robitzsch , 2021 ] , especially with missing data [ Waterbury , 2019 , Enders , 2010 ] . In our setting , randomly assignment of questions to students can be seen as a special case of missing data . With complete data , the condition for the consistency of the maximum likelihood estimators is analyzed [ Haberman , 1977 , 2004 ] . With missing data , though plenty of works on simulation exists , there is a lack of theoretical work that proves mathematically the consistency of the maximum likelihood estimators . The Rasch model can be regarded as a special case of the Bradley - Terry - Luce ( BTL ) model [ Bradley and Terry , 1952 ] for the pairwise comparison of respondents with items by restricting the comparison graph to a bipartite graph . For the BTL model with Erd¨os - R´enyi graph G ( n , p n ) , the maximum likelihood estimator ( MLE ) can be solved by an eﬃcient algorithm [ Zermelo , 1929 , Ford , 1957 , Hunter , 2004 ] , and is proved to be a consistent method in l ∞ norm when lim inf n →∞ p n > 0 [ Simons and Yao , 1999 , Yan et al . , 2012 ] , and recently when p n ≥ log n 3 n [ Han et al . , 2020 ] which is close to the theoretical lower bound of log nn , below which the comparison graph would be disconnected with positive probability and there is no unique MLE . In this paper , we follow the method of Han et al . [ 2020 ] to prove the consistency of the Rasch model with missing data , or BTL model with a sparse bipartite graph , when each vertex in the left part is assigned small number of random edges to the vertices in the right part . We also propose an extension of the algorithm that reasonably deals with the cases where the MLE does not exists . Fowler et al . [ 2022 ] recently studied unfairness detection of the simple averaging under the same randomized exam setting and argue that “the exams are reasonably fair” . They use certain IRT model to ﬁt exams based on their real - world data , and ﬁnd that the simple averaging gives grades that are strongly correlated with the students’ inferred abilities . They also simulate under the IRT model , over random assignment and the student answering process . The simulation shows that , if given any ﬁxed assignment we consider the absolute error of the students’ expected performance over their answering process , the average absolute error over diﬀerent assignments reaches a 5 - percentage bias . We ﬁnd similar results in our simulation , and design a method to reduce the corresponding error by a factor of ten . Our method solves one of their future directions by adjusting grades of the students based on their exam variant . All large - scale standardized tests including the Scholastic Aptitude Test ( SAT ) and Graduate Record Examination ( GRE ) are using item response theory ( IRT ) to generate score scales for alternative forms [ An and Yung , 2014 ] . This test equating process can be divided into two steps , linking and equating . Linking refers to how to estimate the IRT parameters of students and questions under the model ; and equating refers to how to adjust the raw grade of the students to adapt to diﬀerent overall diﬃculty levels in diﬀerent version of the exam , e . g . Lee and Lee [ 2018 ] . One of the most popular test equating processes is IRT true - score equating with nonequivalent - groups anchor test ( NEAT ) design . In the NEAT design , there are two test forms given to two population of students , where a set of common questions is contained in both forms . Linking performs by putting the estimated parameter of the common items onto the same scale through a linear transformation , since any linear transformation gives the same probability under the IRT 5 model . Equating performs by taking the estimated ability of the student from the second form and compute the expected number of accurate answers in the ﬁrst form as the adjusted grade . Since these large - scale standardized tests have a large population of students for each variant of the exam , the above test equating process works well . Our methods can be viewed as adapting the statistical framework of linking and equating to the administration of a single exam for a small population of students . In our randomized exam setting with small scale , however , every student receives a diﬀerent form of the exam , thus it is almost impossible to estimate the parameters for every form separately or to decide an anchor set of question and do the same linking . Our algorithm uses the concurrent linking that estimates all parameters at the same time based on the information in all forms . As for equating , we use a similar method of true - score equating , but compute on the whole question bank instead of one speciﬁc form . In the problem of fair allocation of indivisible items , Best - of - Both - Worlds ( BoBW ) fairness mechanisms ( e . g . , Aziz [ 2020 ] , Freeman et al . [ 2020 ] , Babaioﬀ et al . [ 2022 ] ) try to provide both ex - ante fairness and ex - post fairness to agents . An ex - ante fair mechanism is easy to be found . For example , giving all items to one random agent guarantees that every agent receives a 1 n fraction of the total value in expectation ( ex - ante proportionality ) . However , such a mechanism is clearly not ex - post fair . Likewise , simple averaging gives every student an unbiased grade ex - ante , but neglects the diﬀerent overall diﬃculty among students ex - post . We propose another grading rule that evaluates the diﬃculties of the questions and adjusts the grades according to them , which achieves better ex - post fairness of the students . 2 Model Consider a set of students S and a bank of questions Q . A merit vector u is used to describe the key property of the students and questions . Speciﬁcally , for any student i ∈ S , u i represents the ability of the student ; for any question j ∈ Q , u j represents the diﬃculty of the question . We put them in the same vector for convenience . The merit vector is unknown when the exam is designed . Denote w ij as the outcome of the answering process . Then w ij s are independent Bernoulli random variables , where w ij = 1 represents a correct answer , w ij = 0 represents an incorrect answer , and Pr [ w ij = 1 ] = 1 − Pr [ w ij = 0 ] = exp ( u i ) exp ( u i ) + exp ( u j ) = f ( u i − u j ) , where f ( x ) = 1 1 + exp ( − x ) . The goal of the exam design is to assign a small number of questions to each student ( task assignment graph ) , and based on the exam result ( exam result graph ) , give each student a grade ( grading rule ) that accurately estimates her performance over the whole question bank ( benchmark ) . We give a formal description of the task assignment graph , exam result graph , benchmark , and grading rule below . Deﬁnition 1 ( Task Assignment Graph ) . The task assignment graph G = ( S ∪ Q , E ) is an undirected bipartite graph , where the left part of the vertices represents the students and the right part represents the questions , and an edge between i ∈ S and j ∈ Q exists if and only if the instructor decides to assign question j to student i . Deﬁnition 2 ( Exam Result Graph ) . The exam result graph G (cid:48) = ( S ∪ Q , E (cid:48) ) is a directed bipartite graph constructed from the task assignment graph G . All directed edges are between students and questions . For any edge ( i , j ) ∈ G in the task assignment graph , where i ∈ S and j ∈ Q , if student i answers question j correctly in the exam , i . e . , we observe that w ij = 1 , there is an edge i → j in G (cid:48) ; if the answer is incorrect , i . e . , we observe that w ij = 0 , there is an edge j → i in G (cid:48) . For 6 other student - question pairs that do not occur in the task assignment graph G , there is also no edge between them in the exam result graph G (cid:48) . To evaluate diﬀerent exam designs and grading rules , we propose the following benchmark . Deﬁnition 3 ( Benchmark ) . In an ideal case where we know the distribution over the outcome of the answering processes w ij s , the instructor would measure the students’ performance by their expected accuracy on a random question in the bank . Formally , the benchmark for any student i ’s grade is opt i = E j ∼U ( Q ) [ w ij ] = 1 | Q | (cid:88) j ∈ Q f ( u i − u j ) . ( 2 ) The benchmark is an ideal way to grade the student if the instructor has complete information on all answering processes . On the other hand , when the instructor only observes one sample of each w ij involved in the exam , we will use a grading rule to grade the students . Deﬁnition 4 ( Grading Rule ) . In an exam , the instructor gives a grade for each student based on the exam result graph . A grading rule is a mapping g : G (cid:48) → R S from the exam result graph to the grades for each student . One interpretation of the grade is as an estimation of the benchmark , i . e . , students’ expected accuracy on a random question in the bank , which combines the two important criteria of fairness and accuracy . To evaluate the exam design , we compare the performance of the grading rule to the benchmark and aggregate the error among all students . Speciﬁcally , there are three stages of the exam design , before the randomization of the task assignment graph , after the randomization of the task assignment graph and before the student answering process , and after the student answering process . In each stage , we might care about the maximum or average unfairness among students . Deﬁnition 5 ( Ex - ante Bias ) . For a given algorithm alg , the ex - ante bias for student i is deﬁned as the mean square error of the algorithm’s expected performance compared to the benchmark , over a random family G of task assignment graphs , i . e . , ( E G ∼G E w [ alg i ] − opt i ) 2 . Deﬁnition 6 ( Ex - post Bias ) . For a given algorithm alg and a ﬁxed task assignment graph G , the ex - post bias for student i is deﬁned as the mean square error of the algorithm’s expected performance compared to the benchmark on G , i . e . , ( E w [ alg i ] − opt i ) 2 . Deﬁnition 7 ( Ex - post Error ) . For a given algorithm alg , a ﬁxed task assignment graph G , and a ﬁxed realization of the student answering process w , the ex - post error for student i is deﬁned as the mean square error of the algorithm’s performance compared to the benchmark on G and w , i . e . , ( alg i − opt i ) 2 . The diﬀerence between ex - ante bias , ex - post bias , and ex - post error is that ex - ante bias takes expectation over both random graphs and the noisy answering process , ex - post bias takes expecta - tion over the noisy answering process , while ex - post error directly measures the error . Thus ex - post error is harder than ex - post bias which is harder than ex - ante bias to achieve . Example 2 . 1 ( Simple Averaging ) . Simple averaging is a commonly used grading rule in exams . It calculates the average accuracy on the questions the student receives . Formally , given a exam result graph G (cid:48) , the simple averaging grades student i by avg i = deg + i deg − i + deg + i = (cid:80) j 1 ( i , j ) ∈ E (cid:48) (cid:80) j 1 ( i , j ) ∈ E , ( 3 ) where deg + and deg − represents the outdegree and indegree of the vertex in G (cid:48) , respectively . 7 Theorem 8 . The simple averaging is ex - ante fair over any family of bipartite graphs G that is symmetric with respect to the questions , i . e . , its ex - ante bias is 0 . Proof . ∀ i , E G ∼G E w [ avg i ] = E G ∼G E w (cid:34)(cid:80) j 1 ( i , j ) ∈ E (cid:48) (cid:80) j 1 ( i , j ) ∈ E (cid:35) = E G ∼G E w (cid:34)(cid:80) j w ij 1 ( i , j ) ∈ E (cid:80) j 1 ( i , j ) ∈ E (cid:35) = E G ∼G (cid:34)(cid:80) j E [ w ij ] 1 ( i , j ) ∈ E (cid:80) j 1 ( i , j ) ∈ E (cid:35) = (cid:88) j E [ w ij ] E G ∼G (cid:34) 1 ( i , j ) ∈ E (cid:80) j 1 ( i , j ) ∈ E (cid:35) = opt i ( 4 ) In other words , simple averaging can be seen as an ex - ante unbiased estimator of the benchmark . However , ex - post , i . e . , on one speciﬁc task assignment graph , simple averaging is unfair . Intuitively , some unlucky students might be assigned harder questions and receive a signiﬁcantly lower average grade than the benchmark , and the opposite happens to some lucky students . We will visualize this phenomenon in Figure 3 in Section 5 . 3 . 1 . Based on the above deﬁnitions , we now formalize the procedure and goal of the exam grading problem . i . The instructor chooses a task assignment graph G . ii . The students receive questions according to G and give their answer sheet back , thus the instructor receives the exam result graph G (cid:48) . iii . The instructor uses a grading rule g to grade the students based on G (cid:48) . iv . We want the grade g ( G (cid:48) ) to have a small maximum ( average ) ex - post bias or ex - post error . 3 Method In this section , we propose our method for the exam grading problem . According to our for - malization of the problem , any method contains two parts : generating the task assignment graph G , and choosing the grading rule g . We describe each of them respectively . 3 . 1 Task Assignment Graph For simplicity , we assume both the student set S and the question set Q is ﬁnite . To generate the task assignment graph , we sample m diﬀerent questions u . a . r . from the question bank , and independently assign each student d diﬀerent questions u . a . r . from those m questions . Algorithm 1 Task assignment graph generation Require : ﬁnite sets S and Q , question sample size 1 ≤ m ≤ | Q | , degree constraint 1 ≤ d ≤ m Ensure : a task assignment graph G = ( S ∪ Q , E ) ˜ Q ← a set of m questions sampled u . a . r . without replacement from Q for all i ∈ S do J ← a set of d questions sampled u . a . r . without replacement from ˜ Q E ← E ∪ { ( i , j ) | j ∈ J } 8 3 . 2 Grading Rule Recall that a grading rule maps from an exam result graph G (cid:48) to a vector of probabilities . In contrast with simple averaging which only considers the local information ( the in - degrees and out - degrees of the students ) , we use structural information of the exam result graph for analysis . Our grading rule is an aggregation of a prediction matrix h ∈ [ 0 , 1 ] S × Q , where h ij represents the algorithm’s prediction on the probability that student i answers correctly question j . The grade for student i will be the average of h ij s over all j ∈ Q , i . e . alg i = 1 | Q | (cid:80) j ∈ Q h ij . We use u (cid:32) v to represent the existence of a directed path in G (cid:48) that starts with u and ends with v , and u (cid:54) (cid:32) v for nonexistence . The algorithm classiﬁes the elements h ij s into four cases : existing edge ( i , j ) ∈ E , same component i (cid:32) j ∧ j (cid:32) i , comparable components i (cid:32) j ⊕ j (cid:32) i , and incomparable components i (cid:54) (cid:32) j ∧ j (cid:54) (cid:32) i . Existing Edge For ( i , j ) ∈ E , we observe w ij from the exam result graph G (cid:48) , hence h ij = w ij . Same Component For student i ∈ S and question j ∈ Q satisfy i (cid:32) j ∧ j (cid:32) i , they are in the same strongly connected component in G (cid:48) . We make all predictions in the component simultaneously , by inferring the student abilities and question diﬃculties from the structure of the component . Formally , denote V (cid:48) as the vertex set of the component . From Theorem 9 , the strong connectivity guarantees the existence of the maximum likelihood estimators ( MLEs ) u ∗ ∈ R V (cid:48) . We can use a minorization – maximization algorithm from Hunter [ 2004 ] to calculate the MLEs and set h ij = f ( u ∗ i − u ∗ j ) for any missing edge ( i , j ) between students and questions inside this component . Comparable Components W . l . o . g . , we assume i (cid:32) j and j (cid:54) (cid:32) i , thus every directed path between those two vertices starts with the student and ends with the question , showing strong evidence of a correct answer . In other words , considering the strongly connected components they belong to , the component that contains the student has a “higher level” in the condensation graph of G (cid:48) and can reach the component that contains the question , i . e . , they belong to comparable components in the condensation graph . In this case , we set h ij = 1 . Similarly , if j (cid:32) i and i (cid:54) (cid:32) j , we set h ij = 0 Incomparable Components For a student i and question j that satisfy i (cid:54) (cid:32) j ∧ j (cid:54) (cid:32) i , i . e . , they lie in incomparable components , we use the average of the predictions in the above three cases as the prediction for h ij . 4 Theory In this section , we show several properties of our algorithm . Recall that the Bradley - Terry - Luce model describes the outcome of pairwise comparisons as follows . In a comparison between subject i and subject j , subject i beats subject j with probability p ij = exp ( u i ) exp ( u i ) + exp ( u j ) = f ( u i − u j ) , where u = ( u 1 . . . , u n + m ) represents the merit parameters of n + m subjects and f ( x ) = 1 1 + exp ( − x ) . We consider the Bradley - Terry - Luce model under a family of random bipartite task assignment graphs B ( n , m , d n , m ) . Speciﬁcally , a task assignment graph G ( L ∪ R , E ) with n vertices in L and m 9 Algorithm 2 Grade Generation Require : an exam result graph G (cid:48) ( S ∪ Q , E (cid:48) ) Ensure : a grade vector g ∈ [ 0 , 1 ] S for students From the exam result graph G (cid:48) , we can get the task assignment graph G ( S ∩ Q , E ) . for all ( i , j ) ∈ E do (cid:46) Case 1 : Existing Edge h ij ← w ij . for all Strongly Connected Component ˜ G ( ˜ S ∪ ˜ Q , ˜ E ) do (cid:46) Case 2 : Same Component u ∗ ← the MLEs of the merit parameters of ˜ S ∪ ˜ Q . for all ( i , j ) ∈ ( ˜ S × ˜ Q ) \ ˜ E do h ij ← f ( u ∗ i − u ∗ j ) . for all ( i , j ) ∈ ( S × Q ) \ E ∧ i (cid:32) j ∧ j (cid:54) (cid:32) i do (cid:46) Case 3 : Comparable Component h ij ← 1 . for all ( i , j ) ∈ ( S × Q ) \ E ∧ j (cid:32) i ∧ i (cid:54) (cid:32) j do h ij ← 0 . for all ( i , j ) ∈ ( S × Q ) \ E ∧ i (cid:54) (cid:32) j ∧ j (cid:54) (cid:32) i do (cid:46) Case 4 : Incomparable Component h ij ← the average of the existing h i · in previous steps . for all i ∈ S do (cid:46) Grade Aggregation g i ← the average of h ij for all j s . vertices in R , where n ≤ m , is constructed by linking d n , m diﬀerent random vertices in R to each left vertex in L , i . e . , L is regular but R is not . Given a task assignment graph G , denote A as its adjacency matrix . For any two subjects i and j , the number of comparisons between them follows A ij ∈ { 0 , 1 } . We deﬁne A (cid:48) ij as the number of times that subject i beats subject j , thus A (cid:48) ij + A (cid:48) ji = A ij = A ji . In other words , A (cid:48) is the adjacency matrix of the exam result graph G (cid:48) . Based on the observation of G (cid:48) , the log - likelihood function is L ( u ) = (cid:88) 1 ≤ i (cid:54) = j ≤ n + m A (cid:48) ij log p ij = (cid:88) 1 ≤ i (cid:54) = j ≤ n + m A (cid:48) ij log f ( u i − u j ) . ( 5 ) Denote u ∗ = ( u ∗ 1 , u ∗ 1 , . . . , u ∗ n + m ) as the maximum likelihood estimators ( MLEs ) of u . Since L is additive invariant , w . l . o . g . we assume u 1 = 0 and set u ∗ 1 = 0 . Since ( log f ( x ) ) (cid:48) = 1 − f ( x ) the likelihood equation can be simpliﬁed to n + m (cid:88) j = 1 A (cid:48) ij = n + m (cid:88) j = 1 A ij f ( u ∗ i − u ∗ j ) , ∀ i . ( 6 ) 4 . 1 Existence and Uniqueness of the MLEs Zermelo [ 1929 ] and Ford [ 1957 ] gave a necessary and suﬃcient condition for the existence and uniqueness of the MLEs in ( 6 ) . Condition A . For every two nonempty sets that form a partition of the subjects , a subject in one set has beaten a subject in the other set at least once . To provide an intuitive understanding of Condition A , we show its equivalence to the strong connectivity of the exam result graph G (cid:48) . Then we state our theorem on when Condition A holds . 10 Theorem 9 . Condition A holds if and only if the exam result graph G (cid:48) is strongly connected . Proof . Condition A says that for any partition ( V 1 , V 2 ) of the vertices L ∪ R , there exists an edge from V 1 to V 2 and also an edge from V 2 to V 1 . If G (cid:48) is strongly connected , Condition A directly holds by the deﬁnition of strong connectivity . Otherwise , if G (cid:48) is not strongly connected , the condensation of G (cid:48) contains at least two SCCs . We pick one strongly connected component with no indegree as V 1 and the remaining vertices as V 2 , then there is no edge from V 2 to V 1 , i . e . , Condition A fails . Theorem 10 ( Existence and Uniqueness of MLEs ) . If exp ( α n , m ) ( n + m ) log ( n + m ) nd n , m → 0 ( n , m → ∞ ) , ( 7 ) where α n , m = max 1 ≤ i , j ≤ n + m u i − u j is the largest diﬀerence between all possible pairs of merits , then Pr [ Condition A is satisﬁed ] → 1 ( n , m → ∞ ) . To prove Theorem 10 , we analyze the edge expansion property ( Lemma 11 ) of the task assign - ment graph G and take a union bound on all valid subsets to bound the probability that G (cid:48) fails Condition A . Lemma 11 ( Edge Expansion ) . Under condition ( 7 ) , Pr (cid:20) ∀ S ⊂ V , s . t . | S | ≤ n + m 2 , | ∂S | | S | > nd n , m 2 ( n + m ) (cid:21) → 1 ( n , m → ∞ ) , where ∂S = { ( u , v ) ∈ E : u ∈ S , v ∈ V \ S } for the task assignment graph G ( V , E ) . Proof . Consider any subset of vertices S with size r ≤ n + m 2 . Denote X = S ∩ L , Y = S ∩ R , | X | = x , thus | Y | = r − x , | L \ X | = n − x , | R \ Y | = m + x − r . ∂S is a random variable that can be expressed as | ∂S | = (cid:88) u ∈ X (cid:88) v ∈ R \ Y A uv + (cid:88) u ∈ L \ X (cid:88) v ∈ Y A uv , where A is the adjacency matrix of the task assignment graph G . Recall that the task assignment graph G is generated by linking d n , m random diﬀerent vertices in R to each vertex in L . Thus for diﬀerent u 1 (cid:54) = u 2 ∈ L , A u 1 · is independent with A u 2 · , while for a ﬁxed u ∈ L , A u · is chosen randomly without replacement . Chernoﬀ bound applies under such conditions , i . e . , Pr (cid:20) | ∂S | ≤ 1 2 E [ | ∂S | ] (cid:21) ≤ exp (cid:18) − E [ | ∂S | ] 8 (cid:19) . Then we lower bound E [ | ∂S | ] by E [ | ∂S | ] = d n , m m ( | X | | R \ Y | + | L \ X | | Y | ) = d n , m m (cid:0) 2 x 2 + ( m − n − 2 r ) x + nr (cid:1) . For the case where m − n − 2 r ≤ 0 , i . e . , r ≥ m − n 2 , we have E [ | ∂S | ] = d n , m m (cid:0) 2 x 2 + ( m − n − 2 r ) x + nr (cid:1) ≥ d n , m m (cid:18) − ( m − n − 2 r ) 2 8 + nr (cid:19) = d n , m r m (cid:18) − 1 2 r − 1 8 ( m − n ) 2 r + 1 2 ( n + m ) (cid:19) ≥ d n , m r m (cid:18) − n + m 4 − 1 4 ( m − n ) 2 n + m + 1 2 ( n + m ) (cid:19) = nd n , m r n + m 11 For the case where m − n − 2 r > 0 , i . e . , r < m − n 2 , we have E [ | ∂S | ] = d n , m m (cid:0) 2 x 2 + ( m − n − 2 r ) x + nr (cid:1) ≥ nd n , m r m ≥ nd n , m r n + m . Thus for any ﬁxed set S with size r ≤ n + m 2 , Pr (cid:20) | ∂S | ≤ d n , m nr 2 ( n + m ) (cid:21) ≤ Pr (cid:20) | ∂S | ≤ 1 2 E [ | ∂S | ] (cid:21) ≤ exp (cid:18) − E [ | ∂S | ] 8 (cid:19) ≤ exp (cid:18) − nd n , m r 8 ( n + m ) (cid:19) . Finally , by union bound , Pr (cid:20) ∀ S ⊂ V , s . t . | S | ≤ n , | ∂S | | S | > nd n , m 2 ( n + m ) (cid:21) = 1 − Pr (cid:20) ∃ S ⊂ V , s . t . | S | ≤ n , | ∂S | | S | ≥ nd n , m 2 ( n + m ) (cid:21) ≥ 1 − ( n + m ) / 2 (cid:88) r = 1 (cid:18) n + m r (cid:19) exp (cid:18) − nd n , m r 8 ( n + m ) (cid:19) ≥ 1 − ( n + m ) / 2 (cid:88) r = 1 exp (cid:18) − nd n , m r 8 ( n + m ) + r log ( n + m ) (cid:19) ≥ 1 − ( n + m ) / 2 (cid:88) r = 1 exp (cid:18) − nd n , m r 16 ( n + m ) (cid:19) ≥ 1 − exp (cid:18) − nd n , m 16 ( n + m ) + log ( n + m ) (cid:19) ≥ 1 − exp (cid:18) − nd n , m 32 ( n + m ) (cid:19) The third - to - last inequality and the last inequality hold when d n , m > 32 ( n + m ) log ( n + m ) n . Note that condition ( 7 ) implies ( n + m ) log ( n + m ) nd n , m → 0 ( n , m → ∞ ) since α n , m ≥ 0 . Thus for large enough n and m , Pr (cid:20) ∀ S ⊂ V , s . t . | S | ≤ n , | ∂S | | S | > nd n , m 2 ( n + m ) (cid:21) ≥ 1 − exp (cid:18) − nd n , m 32 ( n + m ) (cid:19) → 1 ( n , m → ∞ ) . Proof of Theorem 10 . For an edge between vertex i and j in the task assignment graph G , i . e . A ij = 1 , the corresponding directed edge in the exam result graph G (cid:48) goes from i to j with probability Pr [ A (cid:48) ij = 1 ] = f ( u i − u j ) ≤ max 1 ≤ i , j ≤ n + m f ( u i − u j ) ≤ 1 1 + exp ( − α n , m ) ≤ 2 − exp ( − α n , m ) . By Lemma 11 , under condition ( 7 ) , Pr (cid:20) ∀ S ⊂ V , s . t . | S | ≤ n , | ∂S | | S | > nd n , m 2 ( n + m ) (cid:21) → 1 ( n , m → ∞ ) . 12 Now consider any subset of vertices S ⊂ V s . t . | S | = r ≤ n + m 2 . The probability that all edges between S and V \ S go in the same direction in G (cid:48) is no more than 2 (cid:0) 2 − exp ( − α n , m ) (cid:1) ndn , m 2 ( n + m ) . Thus by union bound , the probability that Condition A holds is at least 1 − 2 (cid:88) 1 ≤ r ≤ ( n + m ) / 2 (cid:18) n + m r (cid:19) (cid:18) 2 − exp ( − α n , m ) ndn , m 2 ( n + m ) (cid:19) ≥ 1 − 2   (cid:88) 0 ≤ r ≤ n + m (cid:18) n + m r (cid:19) (cid:18) 2 − exp ( − α n , m ) ndn , m 2 ( n + m ) (cid:19) − 1   ≥ 1 − 2 (cid:32)(cid:18) 1 + (cid:18) 2 − exp ( − α n , m ) ndn , m 2 ( n + m ) (cid:19)(cid:19) n + m − 1 (cid:33) , which converges to 1 when n , m → ∞ under condition ( 7 ) . 4 . 2 Uniform Consistency of the MLEs Based on condition ( 7 ) , Theorem 10 shows the existence and uniqueness of the MLEs . In this part , we give an outline of the proof for the uniform consistency of the MLEs ( Theorem 12 ) . Theorem 12 ( Uniform Consistency of MLEs ) . If exp ( 2 ( α n , m + 1 ) ) ∆ n , m → 0 ( n , m → ∞ ) , ( 8 ) where ∆ n , m = (cid:114) m log 3 ( n + m ) nd n , m log 2 ( nm d n , m ) , then the MLEs are uniformly consistent , i . e . , (cid:107) u ∗ − u (cid:107) ∞ P −→ 0 . Denote ε i = u ∗ i − u i as the estimation error of the maximum likelihood estimators . Since we assume u 1 = 0 and set u ∗ 1 = 0 , we have ε 1 = u ∗ 1 − u 1 = 0 . Consider the two subjects with the most negative estimation error and the most positive estimation error i = arg min i ε i ≤ ε 1 = 0 , i = arg max i ε i ≥ ε 1 = 0 , and their corresponding error ε = min i ε i , ε = max i ε i , then we have (cid:107) u ∗ − u (cid:107) ∞ = max { − ε , ε } ≤ ε − ε . The goal is to identify a speciﬁc number D , such that more than half ε i s are at most ε + D , and more than half ε i s are at least ε − D . Then at least one subject is on both sides , thus ε − ε is bounded by 2 D . To identify D , we check a sequence of increasing numbers { D k } K n , m k = 0 , and the two corresponding growing sets { B k } K n , m k = 0 and { B k } K n , m k = 0 that contains the subjects with estimation errors D k - close to ε and ε respectively . Under careful choice of K n , m and { D k } K n , m k = 0 , we will show that B K n , m and B K n , m both contain more than half subjects . The main diﬃculty is showing the growth of { B k } K n , m k = 0 and { B k } K n , m k = 0 . We prove this by considering the local growth of the sets , i . e . , N ( B k ) ∩ B k + 1 and N ( B k ) ∩ B k + 1 . By symmetry , we only consider B k . Lemma 13 analyzes the generation of the random task assignment graphs and shows a vertex expansion property that describes the growth of the neighborhoods N ( B k ) . Lemma 14 starts with any vertex i in B k , analyzes the ﬁrst order equations of the MLE to exclude the vertices that are in the neighborhoods N ( { i } ) and but are not in B k + 1 , and gives a lower bound on the size of N ( { i } ) ∩ B k + 1 . Finally , we jointly consider all vertices in B k and provide a lower bound on the size of N ( B k ) ∩ B k + 1 , which shows the growth rate of B k and ﬁnishes the proof . 13 Deﬁnition of Notations • K n , m = 2 (cid:108) log n log ( nm d n , m ) − 1 (cid:109) is the number of steps of the growth . • c n , m = exp ( − ( α n , m + 1 ) ) 4 is a lower bound on f (cid:48) ( x ) for | x | ≤ α n , m + 1 . • q n , m = c n , m log ( nm d n , m ) 5log n is a lower bound on the local growth rate | N ( { i } ) ∩ B k + 1 | | N ( { i } ) | of vertex i ∈ B k . • z n , m = (cid:113) 32 m log ( n + m ) nd n , m is the deviation used in the Chernoﬀ bound . • The sequence of numbers { D k } K n , m k = 0 is set to be D k = 4 k c n , m (cid:115) 2 m log ( n + m ) ( 1 − z n , m ) nd n , m for k = 0 , 1 , . . . , K n , m − 1 , D K n , m = 80 K n , m c 2 n , m (cid:115) 2 m log ( n + m ) ( 1 − z n , m ) nd n , m . • The two growing sets { B k } K n , m k = 0 and { B k } K n , m k = 0 which contains the subjects with estimation error D k - close to ε and ε respectively are deﬁned as B k = { j : ε j − ε ≤ D k } , B k = { j : ε − ε j ≤ D k } . Lemma 13 ( Vertex Expansion ) . Regarding the task assignment graph G ( L ∪ R , E ) ∼ B ( n , m , d n , m ) , for a ﬁxed subset of left vertices X ⊂ L with | X | ≤ n 2 , w . p . 1 − ( n + m ) − 4 | X | it holds that • If 1 ≤ | X | < m / d n , m , | N ( X ) | | X | > ( 1 − z n , m ) (cid:16) 1 − d n , m | X | m (cid:17) d n , m ; • If | X | ≥ m / d n , m , | N ( X ) | m > 1 − z n , m − e − 1 . For a ﬁxed subset of right vertices Y ⊂ R with | Y | ≤ m 2 , w . p . 1 − ( n + m ) − 4 | Y | it holds that • If 1 ≤ | Y | < m / d n , m , | N ( Y ) | | Y | > ( 1 − z n , m ) (cid:16) 1 − d n , m | Y | m (cid:17) nd n , m m ; • If | Y | ≥ m / d n , m , | N ( Y ) | n > 1 − z n , m − e − 1 . In above inequalities , z n , m = (cid:113) 32 m log ( n + m ) nd n , m as previously deﬁned . Proof . Before proving the vertex expansion property of the task assignment graph B ( n , m , d n , m ) , we ﬁrst bound the vertex degree by Chernoﬀ bound and union bound , ∀ i ∈ R , Pr (cid:20) ( 1 − z n , m ) nd n , m m ≤ | N ( { i } ) | ≤ ( 1 + z n , m ) nd n , m m (cid:21) ≥ 1 − ( n + m ) − 4 , ( 9 ) where z n , m is deﬁned above as z n , m = (cid:113) 32 m log ( n + m ) nd n , m → 0 when n , m → ∞ under condition ( 7 ) . We need to deﬁne another family of random bipartite graph ˜ B . Each graph in ˜ B ( n , m , d n , m ) contains n vertices in the left part , m vertices in the right part , and assigns d n , m random neighbors 14 to each vertex in the left part ( multi - edges are allowed ) . For any X ⊂ L , it’s easy to see that | N ( X ) | in G ∼ B ( n , m , d n , m ) stochastically dominates | N ( X ) | in G ∼ ˜ B ( n , m , d n , m ) . Thus it’s suﬃcient to prove the theorem under ˜ B ( n , m , d n , m ) . On the other hand , counting | N ( X ) | under ˜ B ( n , m , d n , m ) is the same random process as counting the number of non - empty bins after independently throwing d n , m | X | balls u . a . r . into m bins . By linearity of expectation over every bin , we know E [ | N ( X ) | ] = m (cid:32) 1 − (cid:18) 1 − 1 m (cid:19) d n , m | X | (cid:33) . We need several lower bounds of E [ | N ( X ) | ] here . With the fact of x 2 ≤ 1 − exp ( − x ) ≤ x , ∀ 0 ≤ x < 1 , we have E [ | N ( X ) | ] = m (cid:32) 1 − (cid:18) 1 − 1 m (cid:19) d n , m | X | (cid:33) ≥ m (cid:18) 1 − exp (cid:18) − d n , m | X | m (cid:19)(cid:19) ≥ d n , m | X | 2 . Therefore , using Azuma’s inequality , we can lower bound | N ( X ) | , i . e . , Pr [ | N ( X ) | ≤ ( 1 − z n , m ) E [ | N ( X ) | ] ] ≤ exp (cid:32) − z 2 n , m ( E [ | N ( X ) | ] ) 2 2 d n , m | X | (cid:33) = exp (cid:32) − z 2 n , m d n , m | X | 8 (cid:33) ≤ ( n + m ) − 4 | X | . Also , when | X | < m / d n , m , we have (cid:32) 1 − (cid:18) 1 − 1 m (cid:19) d n , m | X | (cid:33) ≥ d n , m | X | m (cid:18) 1 − d n , m | X | m (cid:19) , thus with probability 1 − ( n + m ) − 4 | X | , | N ( X ) | ≥ ( 1 − z n , m ) E [ | N ( X ) | ] ≥ ( 1 − z n , m ) d n , m | X | (cid:18) 1 − d n , m | X | m (cid:19) ; Similarly when | X | ≥ m / d n , m , we have (cid:32) 1 − (cid:18) 1 − 1 m (cid:19) d n , m | X | (cid:33) ≥ 1 − e − 1 , and | N ( X ) | ≥ ( 1 − z n , m ) E [ | N ( X ) | ] ≥ ( 1 − z n , m ) (cid:0) 1 − e − 1 (cid:1) m ≥ (cid:0) 1 − z n , m − e − 1 (cid:1) m . The proof for Y ⊂ R is almost the same except that it’s suﬃcient to use Chernoﬀ bound rather than Azuma’s inequality since the independence among the subjects in N ( Y ) . E [ | N ( Y ) | ] = n (cid:32) 1 − (cid:18) 1 − | Y | m (cid:19) d n , m (cid:33) ≥ n (cid:18) 1 − exp (cid:18) − d n , m | Y | m (cid:19)(cid:19) ≥ nd n , m | Y | 2 m . Using Chernoﬀ bound , we can lower bound | N ( Y ) | , i . e . , Pr [ | N ( Y ) | ≤ ( 1 − z n , m ) E [ | N ( Y ) | ] ] ≤ exp (cid:32) − z 2 n , m E [ | N ( Y ) | ] 2 (cid:33) = exp (cid:32) − z 2 n , m nd n , m | Y | 4 m (cid:33) ≤ ( n + m ) − 4 | Y | . 15 Thus when | Y | < m / d n , m , with probability 1 − ( n + m ) − 4 | Y | , | N ( Y ) | ≥ ( 1 − z n , m ) E [ | N ( Y ) | ] ≥ ( 1 − z n , m ) nd n , m | Y | m (cid:18) 1 − d n , m | Y | m (cid:19) ; when | Y | ≥ m / d n , m , with probability 1 − ( n + m ) − 4 | Y | , | N ( Y ) | ≥ ( 1 − z n , m ) E [ | N ( Y ) | ] ≥ ( 1 − z n , m ) (cid:0) 1 − e − 1 (cid:1) n ≥ (cid:0) 1 − z n , m − e − 1 (cid:1) n . Lemma 14 ( Local Growth of B k ) . For n and m large enough , k < K n , m and a ﬁxed subject i ∈ B k , it holds w . p . 1 − 2 ( n + m ) − 4 that • If k < K n , m − 1 , | N ( { i } ) ∩ B k + 1 | ≥ q n , m | N ( { i } ) | , where q n , m = c n , m log ( nm d n , m ) 5log n and c n , m = exp ( − ( α n , m + 1 ) ) 4 as previously deﬁned ; • If k = K n , m − 1 , | N ( { i } ) ∩ B k + 1 | ≥ 75 81 | N ( { i } ) | . Proof . Pick a subject i ∈ B k . For any task assignment graph G and its adjacency matrix A , the corresponding adjacency matrix A (cid:48) of the exam result graph is a random variable of A . Speciﬁcally , for any A ij = 1 , A (cid:48) ij s are independent Bernoulli random variables with probability f ( u i − u j ) to be 1 . In other words , E [ A (cid:48) ij ] = A ij f ( u i − u j ) . By Chernoﬀ bound , Pr   (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:88) j A (cid:48) ij − (cid:88) j A ij f ( u i − u j ) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ (cid:112) 2 | N ( { i } ) | log ( n + m )   ≤ 2 exp (cid:18) − 4 | N ( { i } ) | log ( n + m ) | N ( { i } ) | (cid:19) ≤ 2 ( n + m ) − 4 . Below we use the above inequality and some analysis of function f to count the number of subjects in N ( { i } ) ∩ B k + 1 . The fact we use about function f is f (cid:48) ( x ) = exp ( − x ) ( 1 + exp ( − x ) ) 2 ≤ 1 4 and f (cid:48) ( x ) ≥ exp ( − ( α n , m + 1 ) ) ( 1 + exp ( − ( α n , m + 1 ) ) ) 2 ≥ exp ( − ( α n , m + 1 ) ) 4 = c n , m , ∀ | x | ≤ α n , m + 1 . Thus for another subject j such that ε j ≤ ε i , by mean value theorem , we have f (cid:0) u ∗ i − u ∗ j (cid:1) − f ( u i − u j ) = f (cid:48) ( ξ ij ) ( ε i − ε j ) ≤ 1 4 ( ε i − ε ) ≤ D k 4 , where ξ ij ∈ (cid:104) u i − u j , u ∗ i − u ∗ j (cid:105) . Similarly , for a subject j with ε j > ε i + D k + 1 − D k , we have f ( u i − u j ) − f (cid:0) u ∗ i − u ∗ j (cid:1) = f (cid:48) ( ξ (cid:48) ij ) ( ε j − ε i ) ≥ c n , m ( D k + 1 − D k ) , 16 where ξ (cid:48) ij ∈ (cid:104) u ∗ i − u ∗ j , u i − u j (cid:105) . Since u i − u j − D K n , m ≤ u i − u j − ( ε j − ε i ) = u ∗ i − u ∗ j ≤ ξ (cid:48) ij ≤ u i − u j , and D K n , m → 0 as n , m → ∞ under condition ( 8 ) , | ξ (cid:48) ij | is bounded by α n , m + 1 when n and m is large enough , thus f (cid:48) ( ξ (cid:48) ij ) ≥ c n , m . Therefore , on the one hand , (cid:88) u ∗ j − u j > u ∗ i − u i A ij (cid:0) f ( u i − u j ) − f ( u ∗ i − u ∗ j ) (cid:1) = (cid:88) j A ij (cid:0) f ( u i − u j ) − f ( u ∗ i − u ∗ j ) (cid:1) − (cid:88) u ∗ j − u j ≤ u ∗ i − u i A ij (cid:0) f ( u i − u j ) − f ( u ∗ i − u ∗ j ) (cid:1) ≤ (cid:112) 2 N ( { i } ) log ( n + m ) + 1 4 D k (cid:88) u ∗ j − u j ≤ u ∗ i − u i A ij . ( 10 ) On the other hand , (cid:88) u ∗ j − u j > u ∗ i − u i A ij (cid:0) f ( u i − u j ) − f ( u ∗ i − u ∗ j ) (cid:1) ≥ (cid:88) u ∗ j − u j > u ∗ i − u i + D k + 1 − D k A ij (cid:0) f ( u i − u j ) − f ( u ∗ i − u ∗ j ) (cid:1) ≥ c n , m ( D k + 1 − D k ) (cid:88) u ∗ j − u j > u ∗ i − u i + D k + 1 − D k A ij . ( 11 ) Combining ( 10 ) and ( 11 ) , we have | N ( { i } ) ∩ B k + 1 | ≥ (cid:88) u ∗ j − u j ≤ u ∗ i − u i + D k + 1 − D k A ij ≥ c n , m ( D k + 1 − D k ) − (cid:113) 2 m log ( n + m ) ( 1 − z n , m ) nd n , m c n , m ( D k + 1 − D k ) + 14 D k | N ( { i } ) | . For k < K n , m − 1 , c n , m ( D k + 1 − D k ) − (cid:113) 2 m log ( n + m ) ( 1 − z n , m ) nd n , m c n , m ( D k + 1 − D k ) + 1 4 D k | N ( { i } ) | ≥ q n , m | N ( { i } ) | . For k = K n , m − 1 , c n , m ( D k + 1 − D k ) − (cid:113) 2 m log ( n + m ) ( 1 − z n , m ) nd n , m c n , m ( D k + 1 − D k ) + 14 D k | N ( { i } ) | ≥ 75 81 | N ( { i } ) | . Proof of Theorem 12 . Denote X k = B k ∩ L and Y k = B k ∩ R . We inductively prove the following fact , for n and m large enough , with probability 1 − ( n + m ) − 2 , • for 1 ≤ k ≤ K n , m − 2 , and k is odd , | X k | , | Y k | ≥ (cid:16) n m d n , m (cid:17) ( k − 1 ) / 2 ; 17 • for 1 ≤ k ≤ K n , m − 2 , and k is even , | X k | ≥ (cid:16) n m (cid:17) k / 2 d ( k − 1 ) / 2 n , m , | Y k | ≥ (cid:16) n m (cid:17) k / 2 − 1 d ( k − 1 ) / 2 n , m ; • for k = K n , m − 1 , | X k | , | Y k | ≥ m d n , m ; • for k = K n , m , | X k | > n 2 , | Y k | > m 2 . We will use the following fact , | Y k + 1 | ≥ | N ( X k ) ∩ B k + 1 | = | N ( X k ) | − | N ( X k ) ∩ B k + 1 | ≥ | N ( X k ) | − (cid:88) i ∈ X k | N ( { i } ) ∩ B k + 1 | = | N ( X k ) | − (cid:88) i ∈ X k (cid:0) | N ( { i } ) | − | N ( { i } ) ∩ B k + 1 | (cid:1) , ( 12 ) and similarly | X k + 1 | ≥ | N ( Y k ) ∩ B k + 1 | ≥ | N ( Y k ) | − (cid:88) i ∈ Y k (cid:0) | N ( { i } ) | − | N ( { i } ) ∩ B k + 1 | (cid:1) , to show the growth of X k and Y k respectively . From now on we only consider n and m large enough . Since i ∈ B 0 , w . l . o . g . we assume | X 0 | = 1 . if X 0 contains other subjects , we take a subset with size 1 . Then by fact ( 12 ) , ( 9 ) and Lemma 14 , we know with probability 1 − 4 ( n + m ) − 4 that | Y 1 | ≥ | N ( X 0 ) ∩ B k + 1 | ≥ q n , m | N ( X 0 ) | > 0 . For 1 < k ≤ K n , m − 2 , and odd k , we prove inductively . We assume | X k | = (cid:0) nm d n , m (cid:1) ( k − 1 ) / 2 . If X k is larger , we pick any subset with size (cid:0) nm d n , m (cid:1) ( k − 1 ) / 2 . Fact ( 12 ) show that | Y k + 1 | ≥ | N ( X k ) | − (cid:88) i ∈ X k (cid:0) | N ( { i } ) | − | N ( { i } ) ∩ B k + 1 | (cid:1) . By Lemma 13 and union bound over all subset of L with size (cid:0) nm d n , m (cid:1) ( k − 1 ) / 2 , it holds with proba - bility 1 − ( n + m ) − 3 | X k | that , | N ( X k ) | > ( 1 − z n , m ) (cid:18) 1 − d n , m | X k | m (cid:19) d n , m | X k | . By Lemma14 and union bound over all possible subject i ∈ X k , it holds with probability 1 − 2 ( n + m ) − 3 that , ∀ i ∈ X k , | N ( { i } ) ∩ B k + 1 | ≥ q n , m | N ( { i } ) | . 18 Therefore , with probability 1 − 3 ( n + m ) − 3 we have | Y k + 1 | ≥ | N ( X k ) | − (cid:88) i ∈ X k (cid:0) | N ( { i } ) | − | N ( { i } ) ∩ B k + 1 | (cid:1) ≥ | N ( X k ) | − ( 1 − q n , m ) (cid:88) i ∈ X k | N ( { i } ) | ≥ ( 1 − z n , m ) (cid:18) 1 − d n , m | X k | m (cid:19) d n , m | X k | − ( 1 − q n , m ) d n , m | X k | ≥ | X k | (cid:16) m n d n , m (cid:17) 1 / 2 (cid:32)(cid:16) n m (cid:17) 1 / 2 ( q n , m − z n , m ) d 1 / 2 n , m − ( 1 − z n , m ) (cid:0) nm (cid:1) 1 / 2 d 3 / 2 n , m | X k | m (cid:33) = | X k | (cid:16) m n d n , m (cid:17) 1 / 2 (cid:32)(cid:16) n m (cid:17) 1 / 2 ( q n , m − z n , m ) d 1 / 2 n , m − ( 1 − z n , m ) (cid:0) nm d n , m (cid:1) 3 / 2 | X k | n (cid:33) ≥ | X k | (cid:16) m n d n , m (cid:17) 1 / 2 (cid:18)(cid:16) n m (cid:17) 1 / 2 ( q n , m − z n , m ) d 1 / 2 n , m − 1 (cid:19) where the last inequality holds because we assume | X k | = (cid:0) nm d n , m (cid:1) ( k − 1 ) / 2 . Finally , under condition ( 8 ) , we have for large enough n and m , (cid:0) nm (cid:1) 1 / 2 ( q n , m − z n , m ) d 1 / 2 n , m − 1 ≥ (cid:0) nm (cid:1) 12 , thus | Y k + 1 | ≥ d 1 / 2 n , m | X k | . The same calculation applies to the case of 1 < k ≤ K n , m − 2 and even k . Similarly , we can prove for 1 < k ≤ K n , m − 2 , | X k + 1 | ≥ nm ( d n , m ) 1 / 2 | Y k | . Therefore , we ﬁnish the proof for all k < K n , m . Similarly for k = K n , m and large enough n and m , with probability 1 − 4 ( n + m ) − 3 , | Y K n , m | ≥ | N ( X K n , m − 1 ) | − (cid:88) i ∈ X Kn , m − 1 (cid:16) | N ( { i } ) | − | N ( { i } ) ∩ B K n , m | (cid:17) ≥ | N ( X K n , m − 1 ) | − (cid:18) 1 − 75 81 (cid:19) (cid:88) i ∈ X Kn , m − 1 | N ( { i } ) | ≥ ( 1 − z n , m − e − 1 ) m − 6 81 m > m 2 . The same proof applies for | X K n , m | . To summarize , with probability 1 − ( n + m ) − 2 , | X K n , m | > n / 2 and | Y K n , m | > m / 2 , thus | B K n , m | > ( n + m ) / 2 . By symmetry , | B K n , m | > ( n + m ) / 2 with probability 1 − ( n + m ) − 2 . Then with probability 1 − 2 ( n + m ) − 2 , at least one subject i ∈ B K n , m ∩ B K n , m lies in both B K n , m and B K n , m . By deﬁnition , subject i satisﬁes ε i − ε ≤ D K n , m and ε − ε i ≤ D K n , m , thus (cid:107) u ∗ − u (cid:107) ∞ ≤ ε − ε ≤ 2 D K n , m , which tends to 0 under condition ( 8 ) . Corollary 15 ( Rates ) . In the case where α n , m = O ( 1 ) , and d n , m = Ω (cid:16) m log 3 ( n + m ) n (cid:17) , with proba - bility 1 − 2 ( n + m ) − 2 , we have (cid:107) u ∗ − u (cid:107) ∞ = O (cid:32) log n log ( nm d n , m ) (cid:115) m log ( n + m ) nd n , m (cid:33) . 19 4 . 3 Analysis of Our Algorithm Our algorithm uses the MLEs to predict the student’s performance within the component . Based on the consistency of the MLEs , we show the bias of our algorithm when Condition A is satisﬁed . Theorem 16 . When Condition A is satisﬁed , the exam result graph is strongly connected . In this case , the MLE is unique and we have ( alg i − opt i ) 2 ≤ 1 4 (cid:107) u − u ∗ (cid:107) 2 ∞ . Proof . When the exam result graph is strongly connected , the algorithm calculates the MLEs u ∗ and gives student i a grade of alg i = 1 | Q | (cid:80) j ∈ Q f ( u ∗ i − u ∗ j ) , while the ground truth probability of answering a random question correctly is opt i = 1 | Q | (cid:80) j ∈ Q f ( u i − u j ) . Thus we have | alg i − opt i | = (cid:12) (cid:12) (cid:12)(cid:12)(cid:12)(cid:12) 1 | Q | (cid:88) j f ( u ∗ i − u ∗ j ) − 1 | Q | (cid:88) j f ( u i − u j ) (cid:12) (cid:12) (cid:12)(cid:12)(cid:12)(cid:12) ≤ 1 | Q | (cid:88) j (cid:12)(cid:12) f ( u ∗ i − u ∗ j ) − f ( u i − u j ) (cid:12)(cid:12) = 1 | Q | (cid:88) j (cid:12)(cid:12) f (cid:48) ( ξ ij ) (cid:12)(cid:12) | ε i − ε j | ≤ 2 n (cid:107) u − u ∗ (cid:107) ∞ (cid:88) j (cid:12)(cid:12) f (cid:48) ( ξ ij ) (cid:12)(cid:12) ≤ 1 2 (cid:107) u − u ∗ (cid:107) ∞ , ( 13 ) where the third - to - last equality is because of the mean value theorem , the next - to - last inequality is because | ε i − ε j | ≤ 2 (cid:107) u − u ∗ (cid:107) ∞ , and the last inequality is because | f (cid:48) ( x ) | ≤ 14 . Thus ( alg i − opt i ) 2 ≤ 14 (cid:107) u − u ∗ (cid:107) 2 ∞ . Next we discuss the performance of our algorithm on several extreme cases of the task assignment graph . For example , the extremely sparse cases when N ( { i } ) is mutually disjoint for each student i or each student receives only d = 1 question . Another example is that the task assignment graph is a complete bipartite graph . In all of the above cases , our algorithm gives the same grade as simple averaging . Theorem 17 . When the task assignment graph satisﬁes that N ( i ) is mutually disjoint for each student i or each student receives only d = 1 question , our algorithm gives the same grade as simple averaging . Proof . In both cases , the exam result graph satisﬁes that every SCC is a single point , thus the algorithm’s output totally relies on cross - component predictions . For each student , the comparable components for each student are exactly the questions that student receives . Thus the algorithm gives the same prediction as the student’s correctness on those questions . The prediction for remaining questions is the average accuracy on the assigned questions by the algorithm’s rule for incomparable components . Therefore , the algorithm’s grade for the student is exactly the same as simple averaging . 20 Theorem 18 . When the task assignment graph is a complete bipartite graph , our algorithm gives the same grade as simple averaging . Proof . In this case , the output of the algorithm only relies on existing edges . It directly follows that the algorithm gives the same grade as simple averaging . 5 Experiments 5 . 1 Real - World Data We use the anonymous answer sheets from a previously administered exam with | S | = 35 students and | Q | = 22 questions . The task assignment graph of the exam is a complete bipartite graph , i . e . , each student is assigned with all questions . The corresponding exam result graph happens to be strongly connected , thus we are able to infer student abilities and question diﬃculties ( Figure 2 ) . Below we study results from counterfactual subgraphs with real exam answers and from data generated according to the model with the inferred abilities and diﬃculties .              0 H U L W  9 D O X H                          )  U  D F  W L  R Q    R  I    '  D  W  D  6 W X G H Q W V  4 X H V W L R Q V Figure 2 : Empirical Cumulative Distribution of Merit Value . We analyze all students and questions under the Bradley - Terry - Luce model and show the empirical cumulative density function of inferred student abilities and question diﬃculties . The abilities ranges from - 1 . 486 to 1 . 149 while the diﬃculties ranges from - 3 . 090 to 2 . 099 . 5 . 2 Algorithms Simple Averaging The grade for student i is its average correctness on assigned questions . See the formal deﬁnition in Example 2 . 1 . Our Algorithm The grade for student i is an aggregation of the algorithm’s prediction on her performance on each question . All predictions can be classiﬁed into four cases , including existing edges ( keep the fact as prediction ) , same component ( maximum likelihood estimators ) , comparable components ( answer in line with the path direction ) and incomparable components ( heuristic as simple averaging ) . See the formal deﬁnition in Section 3 . 2 . 21 5 . 3 Ex - post Bias 5 . 3 . 1 Simulation 1 : A Visualization of Simple Averaging’s Ex - post Unfairness We compare the ex - post bias ( Deﬁnition 6 ) between our algorithm and simple averaging given a ﬁxed random task assignment graph . We use inferred parameters of all 35 students and 22 questions according to Figure 2 . The task assignment graph is generated by Algorithm 1 with the parameter m = 22 and d = 10 , i . e . each student is assigned 10 random questions from the whole question bank . The exam result graph is repeatedly generated according to the model . Figure 3 shows the performance of two algorithms . The left plot corresponds to our algorithm and the right plot corresponds to simple averaging . In each plot , there are 35 conﬁdence intervals , each corresponding to the diﬀerence between the student’s expected grade and her benchmark , i . e . E w [ alg i ] − opt i . The conﬁdence intervals in the left plot are signiﬁcantly closer to 0 , compared to the right plot , which visualizes the intuition that students are facing diﬀerent overall question diﬃculties under the random assignment and simple averaging fails to adjust their grades . Instead , our algorithm infers the question diﬃculties and the student abilities and adjusts their grades accordingly , largely reducing the ex - post bias .                        6 W X G H Q W  , Q G H [                                     2  X  U    *  U  D  G  H        %  H  Q  F  K  P  D  U  N ( a ) Ex - post Grade Deviation of Our Algorithm                        6 W X G H Q W  , Q G H [                                     $  Y J    *  U  D  G  H        %  H  Q  F  K  P  D  U  N ( b ) Ex - post Grade Deviation of Simple Averaging Figure 3 : A Visualization of the Ex - post Grade Deviation with Degree Constraint d = 10 5 . 3 . 2 Simulation 2 : The Eﬀect of the Degree Constraint We compare the expected maximum ex - post bias , i . e . , E G (cid:104) max i ∈ S ( E w [ alg i ] − opt i ) 2 (cid:105) and the expected average ex - post bias , i . e . , E G E i ∼U ( S ) (cid:104) ( E w [ alg i ] − opt i ) 2 (cid:105) between our algorithm and sim - ple averaging . We use inferred parameters of all 35 students and 22 questions according to Figure 2 . For each degree constraint d from 1 to 22 , we repeatedly generate task assignment graphs using al - gorithm Algorithm 1 with the other parameter m = 22 , i . e . each student is assigned d independent questions from the whole question bank . For each task assignment graph , the exam result graph is repeatedly generated according to the model . Figure 4 shows two algorithms’ expected maximum ex - post bias ( Figure 4 ( a ) ) and expected average ex - post bias ( Figure 4 ( b ) ) under diﬀerent degree constraints , where our algorithm ( blue curve ) outperforms simple averaging ( red curve ) on every degree constraint d . Our algorithm’s expected ex - post bias with the degree constraint d = 5 is close to simple averaging’s with the 22 degree constraint d = 20 , which means our algorithm can ask 15 fewer questions to each student to achieve the same grading accuracy as simple averaging . 0 5 10 15 20 Degree Constraint 0 . 00 0 . 05 0 . 10 0 . 15 0 . 20 E xp ec t e d M a x i m u m E x - po s t B i a s Ours Avg ( a ) Expected Maximum Ex - post Bias 0 5 10 15 20 Degree Constraint 0 . 00 0 . 01 0 . 02 0 . 03 0 . 04 0 . 05 0 . 06 E xp ec t e d A v e r a g e E x - po s t B i a s Ours Avg ( b ) Expected Average Ex - post Bias Figure 4 : Expected Aggregated Ex - post Bias v . s . Degree Constraint . The scale of expected average ex - post bias is about 4 times smaller than the scale of expected maximum ex - post bias . We emphasize that our algorithm does not only perform better in expectation over random graphs but also on each of them . If we zoom in on a speciﬁc degree constraint , we can see two algo - rithms’ maximum ex - post bias and average ex - post bias on every task assignment graph . Figure 5 shows the case with the degree constraint d = 10 . Figure 5 ( a ) corresponds to the maximum ex - post bias and Figure 5 ( b ) corresponds to the average ex - post bias . In each case , the left plot contains 100 points , corresponding to a diﬀerent task assignment graph , whose x - axis is the aggregated ex - post bias of simple averaging and whose y - axis is that of our algorithm ; the right plot is the histogram of the diﬀerence in the aggregated ex - post bias between our algorithm and simple averaging . The simulation results show that our algorithm has a negligible aggregated ex - post bias compared to simple averaging on every task assignment graph . 5 . 4 Ex - post Error and Bias - Variance Decomposition In this part , we are investigating the expected average ex - post error ( Deﬁnition 7 ) , i . e . , E G E i E w [ ( alg i − opt i ) 2 ] . Through bias - variance decomposition , we relate the ex - post error to the ex - post bias and the variance in the algorithm performance . Theorem 19 ( Bias - Variance Decomposition ) . E G E i E w [ ( alg i − opt i ) 2 ] = E G E i [ ( E w [ alg i ] − opt i ) 2 ] + E G E i E w [ ( alg i − E w [ alg i ] ) 2 ] . Proof . We prove a stronger argument of the decomposition for any ﬁxed student i and any ﬁxed task assignment graph G , ∀ i , G , E w [ ( alg i − opt i ) 2 ] = E w [ ( alg i − E w [ alg i ] + E w [ alg i ] − opt i ) 2 ] = ( E w [ alg i ] − opt i ) 2 + E w [ ( alg i − E w [ alg i ] ) 2 ] + 2 E w [ ( alg i − E w [ alg i ] ) ( E w [ alg i ] − opt i ) ] = ( E w [ alg i ] − opt i ) 2 + E w [ ( alg i − E w [ alg i ] ) 2 ] + 2 ( E w [ alg i ] − opt i ) E w [ ( alg i − E w [ alg i ] ) ] = ( E w [ alg i ] − opt i ) 2 + E w [ ( alg i − E w [ alg i ] ) 2 ] . 23 0 . 000 0 . 005 0 . 010 0 . 015 0 . 020 0 . 025 0 . 030 0 . 035 Maximum Ex - post Bias of Simple Averaging 0 . 000 0 . 005 0 . 010 0 . 015 0 . 020 0 . 025 0 . 030 0 . 035 M a x i m u m E x - p o s t B i a s o f O u r A l go r it h m 0 . 035 0 . 030 0 . 025 0 . 020 0 . 015 0 . 010 0 . 005 Difference in Maximum Ex - post Bias : Our Algorithm - Simple Averaging 0 . 0 2 . 5 5 . 0 7 . 5 10 . 0 12 . 5 15 . 0 17 . 5 20 . 0 ( a ) Expected Maximum Ex - post Bias : 2 . 43e - 4 for Our Algorithm and 1 . 80e - 2 for Simple Aver - aging 0 . 000 0 . 001 0 . 002 0 . 003 0 . 004 0 . 005 Average Ex - post Bias of Simple Averaging 0 . 000 0 . 001 0 . 002 0 . 003 0 . 004 0 . 005 A v e r a g e E x - po s t B i a s o f O u r A l go r it h m 0 . 0050 0 . 0045 0 . 0040 0 . 0035 0 . 0030 0 . 0025 0 . 0020 0 . 0015 Difference in Average Ex - post Bias : Our Algorithm - Simple Averaging 0 . 0 2 . 5 5 . 0 7 . 5 10 . 0 12 . 5 15 . 0 17 . 5 ( b ) Expected Average Ex - post Bias : 4 . 08e - 5 for Our Algorithm and 3 . 31e - 3 for Simple Averaging Figure 5 : Aggregated Ex - post Bias on Task Assignment Graphs with Degree Constraint d = 10 24 With the same setting in Section 5 . 3 . 1 , we show the expected average ex - post error of our algorithm and simple averaging in Table 1 . Our algorithm achieves a factor of 8 percent smaller ex - post error in total . But after the decomposition , we can see that our algorithm achieves a factor of 99 percent smaller ex - post bias with the cost of a factor of 10 percent larger variance . In practice , students will only take the exam once , so inevitably the variance of the algorithm would contribute to the total error . Our algorithm does not focus on how to reduce variance over the noisy answering process , instead , it focuses on the expected performance of the algorithm , i . e . , it makes the ex - post bias much closer to zero . To verify that our algorithm does not increase the variance too much , we also run the simulation under “the worst case” of our algorithm , i . e . , all students have the same abilities and all questions have the same diﬃculties . In this setting , our algorithm faces the risk of over - ﬁtting , while simple averaging works perfectly . In Table 2 , we can see that both algorithms achieve ex - post biases close to 0 , and our algorithm has a factor of 1 . 6 percent larger variance than simple averaging which is the main contribution to the diﬀerence in ex - post errors . Ex - post Bias Variance Ex - post Error Ours 0 . 00004 0 . 0188 0 . 0188 Avg 0 . 00331 0 . 0170 0 . 0203 Ours - Avg - 0 . 00327 0 . 0018 - 0 . 0015 Table 1 : Bias - Variance Decomposition in the setting of real - world parameters Ex - post Bias Variance Ex - post Error Ours 0 . 0000500 0 . 0254 0 . 0255 Avg 0 . 0000493 0 . 0250 0 . 0250 Ours - Avg 0 . 0000007 0 . 0004 0 . 0005 Table 2 : Bias - Variance Decomposition in the setting of all - the - same parameters 5 . 5 Real - World Data Experiment : Cross Validation We cannot repeat an exam in the real world and check the ex - post bias of the algorithms . Thus , we sample part of the data we have as a new exam result graph and use them to predict the students’ actual average on the data . We randomly split the real - world data into training data and test data . Speciﬁcally , for a ﬁxed student sample size d 1 and a degree constraint d 2 , in each repetition , we randomly sample d 1 students and randomly choose d 2 questions and corresponding answers for each student independently as the training data , use our algorithm ( Ours ) and simple averaging ( Avg ) to predict every student’s average accuracy on the whole question bank , and calculate the mean squared error . Formally , the mean squared error MSE is deﬁned as MSE = E X , ˜ S (cid:20) 1 | ˜ S | (cid:80) i ∈ ˜ S (cid:16) alg i − 1 | Q | (cid:80) j ∈ Q w ij (cid:17) 2 (cid:21) , where X is the training set given a ﬁxed degree d , ˜ S is the sampled student set , alg i is student i ’s grade given by the algorithm and w ij is the correctness of student i ’s answer to question j . This measurement is closer to ex - post error except that the answering process is not repeatedly drawn . 25 In Figure 6 ( a ) , we ﬁx the student sample size d 1 = 35 , i . e . , ˜ S = S and change the degree constraint d 2 from 1 to 22 and show the curve of the logarithm of MSE . Our algorithm performs better than simple averaging when the degree constraint d 2 is larger than 5 and has a factor of 16 % to 20 % smaller MSE compared to simple averaging when the degree constraint d 2 is larger than 10 . In Figure 6 ( b ) , we consider for every possible student sample size d 1 , what the smallest degree constraints d 2 is for our algorithm to perform better than simple averaging . It provides a reference for choosing the grading rule in diﬀerent situations . 0 . 0 2 . 5 5 . 0 7 . 5 10 . 0 12 . 5 15 . 0 17 . 5 20 . 0 Degree Constraint 8 7 6 5 4 3 2 L og a r it h m o f M S E Ours Avg ( a ) Logarithm of MSE v . s . Degree Constraint 5 10 15 20 25 30 35 Student Sample Size 6 7 8 9 10 11 12 13 T h r e s ho l d Compared to Avg ( b ) Threshold v . s . Student Sample Size Figure 6 : Cross Validation We also run the same cross - validation in numerical simulation . We assume two diﬀerent Normal prior distributions for student abilities and question diﬃculties , ﬁtted by the data in Figure 2 . For a ﬁxed student sample size d 1 and degree constraint d 2 , in every repetition , we ﬁrst draw d 1 i . i . d . student abilities and | Q | = 22 i . i . d . question diﬃculties from those two prior distributions . We use a complete task assignment graph to generate the exam result graph according to the model . Then we randomly choose d 2 questions and the corresponding answers of each student as the training set and use our algorithm and simple averaging to predict each student’s average accuracy over the whole question bank . Note that we do exact same things in the cross - validation , so when calculating the MSE , we compare the algorithms’ grades to the students’ average accuracy given by the exam result graph instead of the benchmark . From Figure 7 we observe that the simulation result is quite similar to that of the real - world cross - validation , which suggests that the numerical simulation results we have in Section 5 . 3 and Section 5 . 4 could be a good reference for the practical use of our algorithm . 5 . 6 The Eﬀect of the Question Sample Size ( Exam Design Problem ) We now consider the inﬁnite question bank and compare the expected maximum ex - post bias and the expected average ex - post bias between our algorithm and simple averaging . We sampled and ﬁxed | S | = 5 random students among the previous 35 students . The question diﬃculties are i . i . d . distributed according to the linear interpolation of the diﬃculties shown in Figure 2 . For each question sample size m , we repeatedly generate task assignment graphs using Algorithm 1 with the other parameter d = 5 . It can be expected that when m = d and m → ∞ , two algorithms should have the same performance . Figure 8 shows a consistantly smaller expected maximum ex - post bias ( Figure 8 ( a ) ) and expected average ex - post bias ( Figure 8 ( b ) ) of our algorithm ( blue curve ) than simple averaging ( red curve ) . As the question sample size grows , the expected aggregated ex - post 26 0 . 0 2 . 5 5 . 0 7 . 5 10 . 0 12 . 5 15 . 0 17 . 5 20 . 0 Degree Constraint 8 7 6 5 4 3 2 L og a r i t h m o f M S E Ours Avg ( a ) Logarithm of MSE v . s . Degree Constraint 5 10 15 20 25 30 35 Student Sample Size 6 8 10 12 14 16 T h r e s ho l d Compared to Avg ( b ) Threshold v . s . Student Sample Size Figure 7 : Simulated Cross Validation bias of our algorithm ﬁrst decreases and then increases . The turning point is about 6 - 9 for expected maximum ex - post bias and 10 - 15 for expected average ex - post bias . 10 20 30 40 50 Question Sample Size 0 . 0100 0 . 0125 0 . 0150 0 . 0175 0 . 0200 0 . 0225 0 . 0250 E xp ec t e d M a x i m u m E x - po s t B i a s Ours Avg ( a ) Expected Maximum Ex - post Bias 10 20 30 40 50 Question Sample Size 0 . 005 0 . 006 0 . 007 0 . 008 0 . 009 E xp ec t e d A v e r a g e E x - po s t B i a s Ours Avg ( b ) Expected Average Ex - post Bias Figure 8 : Expected Aggregated Ex - post Bias v . s . Question Sample Size 6 Conclusions We formulate and study the fair exam grading problem under the Bradley - Terry - Luce model . We propose an algorithm that is a generalization of the maximum likelihood estimation method . To theoretically validate our algorithm , we prove the existence , uniqueness , and uniform consistency of the maximum likelihood estimators under the Bradley - Terry - Luce model on sparse bipartite graphs . Our algorithm signiﬁcantly outperforms simple averaging in numerical simulation . On real - world data , our algorithm is better when the students are assigned a suﬃcient number of questions ( i . e . , on suﬃciently long exams ) . We provide guidelines for how to choose the grading rule given a certain number of students and a ﬁxed exam length . Our model in this paper mainly considers true - or - false questions , which can be extended to multiple - choice questions and to the case where it can be assumed that students would guess if 27 they cannot solve a question . Our model treats student abilities and question diﬃculties as one - dimensional , which can be extended to a multi - dimensional model that takes diﬀerent topics into account . Another potential extension of the model is to introduce diﬀerent groups of students , so each question might have diﬀerent diﬃculties for each group and we could ask for fairness across groups . Our method to treat missing edges across comparable components – which predicts 0 or 1 – needs to be improved , especially in the low - degree environment ( i . e . , short exam lengths where the exam result graph is unlikely to be strongly connected ) . Also , it would be important to provide a simple and clear explanation to students for practical use . References Xinming An and Yiu - Fai Yung . Item response theory : What it is and how you can use the irt procedure to apply it . SAS Institute Inc , 10 ( 4 ) : 364 – 2014 , 2014 . Haris Aziz . Simultaneously Achieving Ex - ante and Ex - post Fairness , June 2020 . Moshe Babaioﬀ , Tomer Ezra , and Uriel Feige . Best - of - Both - Worlds Fair - Share Allocations , March 2022 . Gordon G . Bechtel . Generalizing the Rasch Model for Consumer Rating Scales . Marketing Science , 4 ( 1 ) : 62 – 73 , February 1985 . ISSN 0732 - 2399 . doi : 10 . 1287 / mksc . 4 . 1 . 62 . Nikolaus Bezruczko . Rasch Measurement in Health Sciences . JAM Press , Maple Grove , Minn , 2005 . ISBN 978 - 0 - 9755351 - 2 - 7 978 - 0 - 9755351 - 3 - 4 . Ralph Allan Bradley and Milton E Terry . Rank analysis of incomplete block designs : I . the method of paired comparisons , 1952 . Luca De Alfaro and Michael Shavlovsky . Crowdgrader : A tool for crowdsourcing the evaluation of homework assignments . In Proceedings of the 45th ACM technical symposium on Computer science education , pages 415 – 420 , 2014 . Craig K . Enders . Applied Missing Data Analysis . Methodology in the Social Sciences . Guilford Press , New York , 2010 . ISBN 978 - 1 - 60623 - 639 - 0 . L . R . Ford . Solution of a Ranking Problem from Binary Comparisons . The American Mathematical Monthly , 64 ( 8 ) : 28 – 33 , 1957 . ISSN 0002 - 9890 . doi : 10 . 2307 / 2308513 . Max Fowler , David H . Smith , Chinedu Emeka , Matthew West , and Craig Zilles . Are We Fair ? Quantifying Score Impacts of Computer Science Exams with Randomized Question Pools . In Pro - ceedings of the 53rd ACM Technical Symposium on Computer Science Education V . 1 , SIGCSE 2022 , pages 647 – 653 , New York , NY , USA , February 2022 . Association for Computing Machinery . ISBN 978 - 1 - 4503 - 9070 - 5 . doi : 10 . 1145 / 3478431 . 3499388 . Rupert Freeman , Nisarg Shah , and Rohit Vaish . Best of Both Worlds : Ex - Ante and Ex - Post Fairness in Resource Allocation . In Proceedings of the 21st ACM Conference on Economics and Computation , EC ’20 , pages 21 – 22 , New York , NY , USA , July 2020 . Association for Computing Machinery . ISBN 978 - 1 - 4503 - 7975 - 5 . doi : 10 . 1145 / 3391403 . 3399537 . Shelby J . Haberman . Maximum Likelihood Estimates in Exponential Response Models . The Annals of Statistics , 5 ( 5 ) : 815 – 841 , September 1977 . ISSN 0090 - 5364 , 2168 - 8966 . doi : 10 . 1214 / aos / 1176343941 . 28 Shelby J . Haberman . Joint and Conditional Maximum Likelihood Estimation for the Rasch Model for Binary Responses . ETS Research Report Series , 2004 ( 1 ) : i – 63 , June 2004 . ISSN 23308516 . doi : 10 . 1002 / j . 2333 - 8504 . 2004 . tb01947 . x . John Hamer , Kenneth T . K . Ma , Hugh H . F . Kwong , Kenneth T . K , Ma Hugh , and H . F . Kwong . A Method of Automatic Grade Calibration in Peer Assessment . In Of Conferences in Research and Practice in Information Technology , Australian Computer Society , pages 67 – 72 , 2005 . Ruijian Han , Rougang Ye , Chunxi Tan , and Kani Chen . Asymptotic theory of sparse Bradley – Terry model . The Annals of Applied Probability , 30 ( 5 ) : 2491 – 2515 , October 2020 . ISSN 1050 - 5164 , 2168 - 8737 . doi : 10 . 1214 / 20 - AAP1564 . David R . Hunter . MM algorithms for generalized Bradley - Terry models . The Annals of Statistics , 32 ( 1 ) , February 2004 . ISSN 0090 - 5364 . doi : 10 . 1214 / aos / 1079120141 . Won - Chan Lee and Guemin Lee . IRT Linking and Equating . In The Wiley Handbook of Psychome - tric Testing , chapter 21 , pages 639 – 673 . John Wiley & Sons , Ltd , 2018 . ISBN 978 - 1 - 118 - 48977 - 2 . doi : 10 . 1002 / 9781118489772 . ch21 . Francisco J . Moral and Francisco J . Rebollo . Characterization of soil fertility using the Rasch model . Journal of soil science and plant nutrition , 17 ( 2 ) : 486 – 498 , June 2017 . ISSN 0718 - 9516 . doi : 10 . 4067 / S0718 - 95162017005000035 . Georg Rasch . Probabilistic Models for Some Intelligence and Attainment Tests . MESA Press , 5835 S , 1993 . ISBN 978 - 0 - 941938 - 05 - 1 . Syed A . Raza , Wasim Qazi , Komal Akram Khan , and Javeria Salam . Social Isolation and Ac - ceptance of the Learning Management System ( LMS ) in the time of COVID - 19 Pandemic : An Expansion of the UTAUT Model . Journal of Educational Computing Research , 59 ( 2 ) : 183 – 208 , April 2021 . ISSN 0735 - 6331 . doi : 10 . 1177 / 0735633120960421 . Ken Reily , Pam Finnerty , and Loren Terveen . Two peers are better than one : Aggregating peer reviews for computing assignments is surprisingly accurate . In GROUP’09 - Proceedings of the 2009 ACM SIGCHI International Conference on Supporting Group Work , pages 115 – 124 , January 2009 . doi : 10 . 1145 / 1531674 . 1531692 . Alexander Robitzsch . A Comprehensive Simulation Study of Estimation Methods for the Rasch Model . Stats , 4 ( 4 ) : 814 – 836 , December 2021 . ISSN 2571 - 905X . doi : 10 . 3390 / stats4040048 . Mehdi S . M . Sajjadi , Morteza Alamgir , and Ulrike von Luxburg . Peer Grading in a Course on Algorithms and Data Structures : Machine Learning Algorithms do not Improve over Simple Baselines , February 2016 . Gordon Simons and Yi - Ching Yao . Asymptotics when the number of parameters tends to inﬁnity in the Bradley - Terry model for paired comparisons . The Annals of Statistics , 27 ( 3 ) : 1041 – 1060 , June 1999 . ISSN 0090 - 5364 , 2168 - 8966 . doi : 10 . 1214 / aos / 1018031267 . Glenn Waterbury . Missing Data and the Rasch Model : The Eﬀects of Missing Data Mechanisms on Item Parameter Estimation . Journal of applied measurement , 20 : 1 – 12 , May 2019 . Ting Yan , Yaning Yang , and Jinfeng Xu . Sparse Paired Comparisons in the Bradley - Terry Model . Statistica Sinica , 22 ( 3 ) : 1305 – 1318 , 2012 . ISSN 1017 - 0405 . 29 E . Zermelo . Die Berechnung der Turnier - Ergebnisse als ein Maximumproblem der Wahrschein - lichkeitsrechnung . Mathematische Zeitschrift , 29 ( 1 ) : 436 – 460 , December 1929 . ISSN 0025 - 5874 , 1432 - 1823 . doi : 10 . 1007 / BF01180541 . 30