Increasing User Decision Accuracy using Suggestions Pearl Pu Human Computer Interaction Group ( HCI ) Ecole Polytechnique F´ed´erale de Lausanne ( EPFL ) Station 14 1015 Lausanne , Switzerland pearl . pu @ epﬂ . ch Paolo Viappiani Artiﬁcial Intelligence Laboratory ( LIA ) Ecole Polytechnique F´ed´erale de Lausanne ( EPFL ) Station 14 1015 Lausanne , Switzerland paolo . viappiani @ epﬂ . ch Boi Faltings Artiﬁcial Intelligence Laboratory ( LIA ) Ecole Polytechnique F´ed´erale de Lausanne ( EPFL ) Station 14 1015 Lausanne , Switzerland boi . faltings @ epﬂ . ch ABSTRACT The internet presents people with an increasingly bewilde - ring variety of choices . Online consumers have to rely on computerized search tools to ﬁnd the most preferred option in a reasonable amount of time . Recommender systems ad - dress this problem by searching for options based on a model of the user’s preferences . We consider example critiquing as a methodology for mixed - initiative recommender systems . In this technique , users vol - unteer their preferences as critiques on examples . It is thus important to stimulate their preference expression by selec - ting the proper examples , called suggestions . We describe the look - ahead principle for suggestions and describe sever - al suggestion strategies based on it . We compare them in si - mulations and , for the ﬁrst time , report a set of user studies which prove their effectiveness in increasing users’ decision accuracy by up to 75 % . Author Keywords Recommender systems , consumer decision support , exam - ple critiquing interfaces , user evaluation of interfaces . ACM Classiﬁcation Keywords H . 1 . 2 [ Models and Principles ] : User / Machine Systems - hu - man factors , software psychology ; H . 5 . 2 [ Information Interfaces and Presentation ] : User Inter - faces - evaluation / methodology , graphical user interfaces . INTRODUCTION People increasingly face the difﬁcult task of having to select the best option from a large set of multi - attribute alternatives , such as choosing an apartment to rent , a notebook computer to buy , or ﬁnancial products in which to invest . Knowledge - and utility - based recommender systems are tools that help people ﬁnd their most desired item based on a model of their Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . CHI 2006 , April 22 - 27 , 2006 , Montr´eal , Qu´ebec , Canada . Copyright 2006 ACM 1 - 59593 - 178 - 3 / 06 / 0004 . . . $ 5 . 00 . Initial preferences System shows K examples User revises the preference model by critiquing examples Userpicks the final choice Figure 1 . Example critiquing interaction . The dark box is the computer’s function , the other boxes show actions of the user . preferences [ 2 – 4 , 13 , 18 ] . For their performance , it is crucial that this preference model be as accurate as possible . This poses new challenges for human - computer interaction at the cognitive level that have been poorly addressed so far , but are key to the user success rate of such systems on e - commerce sites . Utility theory provides a solid mathematical foundation for recommendations [ 5 ] . However , it assumes complex prefe - rence models that cannot be obtained in e - commerce sce - narios because people are not willing to go through lengt - hy preference elicitation processes . Furthermore , they are usually not very familiar with the available products and their characteristics . Thus , their preferences are not well established , but constructed while learning about the availa - ble products [ 11 ] . To allow such construction to take place , users must be able to explore the space of possible options while building their preference model . A good way to do this is through a mixed - initiative system based on example critiquing ( see Figure 1 ) . Example criti - quing was ﬁrst introduced by [ 25 ] and works by showing k examples to a user in each interaction cycle . If the target item is not among the k examples , then a set of user critiques will be collected to reﬁne the existing model . Example critiquing allows users to express preferences in any order , on any cri - teria , and with any effort they are willing to expend [ 15 ] . It has been employed by a number of product search and re - commender tools [ 2 , 6 , 13 , 19 – 21 ] . CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 121 In an example critiquing interaction , user’s preferences are volunteered , not elicited : users are never forced to answer questions about preferences they might not be sure about . Thus , users will only state preferences that they actually ha - ve , and they can tailor the effort they spend on stating their preferences to the importance of the decision that they are making . RELATED WORK Example critiquing was ﬁrst proposed in [ 25 ] and has since been used in several recommender systems , such as Find - Me [ 2 ] , ATA [ 6 ] , SmartClient [ 13 ] , ExpertClerk [ 19 ] and the system of Shearin & Lieberman [ 20 ] . The ATA system [ 6 ] is particularly important , as it was the ﬁrst to incorporate the notion of suggestions , which is crucial to our work . Evaluating example critiquing interfaces has been an acti - ve area of research lately . Pu and Kumar [ 16 ] showed that example critiquing interfaces enable users to perform deci - sion tradeoff tasks more efﬁciently with considerably less errors than non - critiquing interfaces . More recently , Pu and Chen [ 17 ] showed that the implementation of tradeoff sup - port can increase users’ decision accuracy by up to 57 % . In dynamic critiquing [ 18 ] , a popular family of example critiquing interfaces , a metaphor of navigation through the product space is implemented ; the interface proposes pre - computed critiques ( simple and compound ) that can be se - lected by the users . McCarthy et al . [ 7 ] showed that users who applied more frequently compound critiques in a criti - quing interface were able to reduce interaction cycle from 22 to 6 . Several researchers [ 1 , 8 – 10 , 21 , 22 ] recognized the need to suggest diverse examples in recommender tools . In the con - text of case - based reasoning [ 9 , 22 ] , algorithms have been proposed to optimize both the similarity to the target ( i . e . the optimality ) and the diversity of the retrieval set . This ap - proach has been applied to recommender systems , and it has been shown in [ 8 ] that such techniques can reduce the length of the recommendation cycle by up to 76 % , compared to the pure similarity - based recommender . In [ 21 ] , diversity is used to implement system recommendations to the query show me more like this . Their adaptive search algorithm alternates between a strategy that favors similarity and one that favors diversity ( refocus ) . More recent work on diversity was motivated to compensa - te for users’ preference uncertainty [ 12 ] , where the utility function is parameterized over a probability distribution , or to cover different topic interests in collaborative ﬁltering re - commenders [ 24 ] . CONTRIBUTION OF THIS WORK In our approach , a preference model consists of a user’s stated preferred attribute values and their relative importan - ce . When preferences are inferred or constructed from a set of examples , human subjects have been found to favor out - comes based on the superiority of only one or few attributes . This phenomenon is known as the prominence effect [ 23 ] . However , a more rational behavior is to evaluate potential candidates based on as many attributes as a user may ha - ve using compensatory decision strategies [ 11 ] . Therefore , users should be guided to not only express more preferences , but also expand on the number of attributes for which pre - ferred values have been established . The latter , called prefe - rence enumeration , is thus an important measure of quality for a preference model . We have found that simply showing examples that are optimal for the current preference model may not be enough to overcome the prominence effect . As the experiments described in this paper show , users are not likely to increase attribute enumeration after interacting with optimal examples . This observation has led us to extend the example critiquing method to include both • candidate examples that are optimal for the preference model , and • suggested examples that are chosen to stimulate the ex - pression of preferences . In this paper , we take a deeper look at how suggestions should be generated and derive a family of new strategies , called model - based strategies . Our ﬁnal result is an evalua - tion of the impact of these strategies on decision accuracy through user studies . We deﬁne decision accuracy as the li - kelihood that a user ﬁnds the most preferred option when using the tool . However , to avoid the expense of using each of the dif - ferent possible suggestion strategies in a study with actual users , we ﬁrst carried out an evaluation based on simulated users . As the purpose of suggestions is to stimulate expressi - on of preference , we compare different suggestion strategies with respect to user’s preference enumeration , deﬁned as the number of preferences stated by the user . We also show in the experiments that this preference enumeration is indeed positively correlated with decision accuracy . The simulations compared 6 different strategies : three from our work , one based on random selection , the strategy pro - posed by Linden et al . [ 6 ] , and the diversity strategy as de - scribed by McSherry [ 9 ] . McSherry’s algorithm is a further development based on [ 22 ] . The comparison with a random strategy was included to rule out any strategy that would ha - ve extraordinarily poor performance , while the strategies of Linden and McSherry represent the strategies that are com - monly proposed in the literature . Results suggest that the model - based probabilistic strategy performs best , and it was consequently used in a study with real users . The study is a within - subject comparative user study whe - re 60 live and 40 recruited users compared two versions of example critiquing systems , one with and one without sug - gestion interfaces . Results indicate that users were able to state signiﬁcantly more preferences when using the sugge - stion interfaces ( up to 80 % accuracy ) . More importantly , the user study also indicates that a higher preference enume - ration leads to more accurate decisions . Among the 40 re - CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 122 cruited users , there is a correlation between the number of preference discovered by the suggestions and the decision accuracy ( p = 0 . 03 ) . A DEEPER LOOK AT SUGGESTIONS The problem faced when using a search tool is that the user has to learn how to state her preferences so that the tool can ﬁnd her most preferred option . We can assume that she is minimizing her own effort and will add preferences to the model only when she can expect them to have an impact on the solutions . This is the case when : • she can see several options that differ in a possible prefe - rence , and • these options are relevant , i . e . they could be reasonable choices , and • these options are not already optimal , so a new preference is required to make them optimal . In all other cases , stating an additional preference is irrele - vant . When all options would lead to the same evaluation , or when the preference only has an effect on options that would not be eligible anyway , stating it would only be wasted ef - fort . This leads us to the following look - ahead principle as a basis for suggestion strategies : Suggestions should be options that could become opti - mal when an additional preference is stated . As a simple example consider searching for a ﬂight between two cities A and B . Options are characterized by the attri - butes : < price , arrival time , departure airport > . For the departure airport , there is a city airport ( CTY ) which is very close to where the user lives and a big international air - port ( INT ) which takes several hours to reach . Assume that the user has three preferences in this order of importance : • the lowest price • arrive by 12 : 00 • depart from the city airport and that she initially only states a preference on the price . The other two preferences remain hidden . Finally , assume that the choice is among the following options : • f 1 : < 200 , 13 , INT > • f 2 : < 250 , 14 , INT > • f 3 : < 300 , 9 , INT > • f 4 : < 600 , 8 : 30 , INT > • f 5 : < 400 , 12 , CTY > • f 6 : < 400 , 16 : 30 , CTY > • f 7 : < 900 , 18 , CTY > • f 8 : < 280 , 15 , INT > According to the ﬁrst stated preference ( lowest price ) , the options are ordered f 1 (cid:194) f 2 (cid:194) f 8 (cid:194) f 3 (cid:194) f 5 = f 6 (cid:194) f 4 (cid:194) f 7 . Assume that the system shows the 2 most promising ones : f 1 and f 2 , the two with lowest price . Here f 1 already domi - nates f 2 ( f 1 is better in all respects ) according to the users hidden preferences , so she is unlikely to state any additional preference based on these examples . A strategy that generates suggestions according to diversity might pick f 7 as suggestion as it is most different from what is currently displayed . However , the user is likely to discard this option , because it is very expensive and arrives very late . A strategy that chooses examples with extreme values would show one of f 4 or f 7 . Neither of them is likely to be taken seriously by the user : f 4 is likely to leave at a very early and inconvenient hour , while f 7 arrives much too late to be useful . What makes f 7 a bad suggestion to show ? From the system point of view , where only the preference about the price is known , f 7 is not a great suggestion because for most of the possible hidden preferences , it is likely to be dominated by f 5 or f 6 . If the hidden preference is for the city airport , then f 5 dominates because it is cheaper . If the hidden preference is on arrival time , then only if the user requires an arrival later than 16 : 30 there is a chance that it will not be dominated by f 6 , which is otherwise signiﬁcantly cheaper . Without knowing the hidden preferences , good suggestions for this scenario would be f 3 , which has a reasonable arrival time without a signiﬁcantly higher price , f 5 or f 6 . These ex - amples differ from f 4 and f 7 in that they have a good chance of becoming optimal for a wide range of possible hidden preferences . PREFERENCE MODELING Since the suggestion strategies depend on the preference mo - del that is used in the recommender system , we deﬁne the preference model that we assume further in the discussion . We stress that these assumptions are only made for genera - ting suggestions . The preference model used in the recom - mender system could be more diverse or more speciﬁc as required by the application . Also , similar model - based sug - gestion strategies could be derived for other preference mo - dels . Given a ﬁxed set of n attributes A = { A 1 , . . , A n } , an option o is characterized by the values a 1 ( o ) , . . . , a n ( o ) that must be - long to the ﬁxed domains D 1 , . . , D n , which can be explicitly enumerated or can be intervals of continuous or discrete ele - ments . The user’s preferences are supposed to be independent and deﬁned on individual attributes : Deﬁnition 1 . A preference r is an order relation (cid:185) r of the values of an attribute a ; ∼ r expresses that two values are equally preferred . A preference model R is a set of pre - ferences { r 1 , . . , r m } . CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 123 If there can be preferences over a combination of attributes , such as the total travel time in a journey , we assume that the model includes additional attributes that model these com - binations . As a preference r always applies to the same at - tribute a z , we simplify the notation and apply (cid:185) r and ∼ r to the options directly : o 1 ≺ r o 2 iff a z ( o 1 ) ≺ r a z ( o 2 ) . We use ≺ r to indicate that (cid:185) r holds but not ∼ r . Depending on the formalism used for modeling preferences , there are different ways of combining the order relations given by the individual preferences r i in the user’s prefe - rence model R into a global order of the options . For exam - ple , each preference may be expressed by a number and the combination may be formed by summing the numbers cor - responding to each preference , or by taking their minimum or maximum . We can obtain suggestion strategies that are valid with most known preference modeling formalisms by using qualita - tive optimality criteria based on dominance and Pareto - optimality : Deﬁnition 2 . An option o is dominated by an option o (cid:48) with respect to R if and only if for all r i ∈ R , o (cid:185) r i o (cid:48) and at least one r j ∈ R , o ≺ r j o (cid:48) . We write o ≺ R o (cid:48) ( equivalently we can say that o (cid:48) dominates o and write o (cid:48) (cid:194) R o ) We also say that o is dominated ( without specifying o (cid:48) ) Note that we use the same symbol ≺ for both individual pre - ferences and sets of preferences . Deﬁnition 3 . An option o is Pareto - optimal ( PO ) if and only if it is not dominated by any other option . Pareto - optimality is the strongest concept that is applicable regardless of the preference modeling formalism used . Our techniques use the concept of dominating set : Deﬁnition 4 . The dominating set of an option o is the set of all options that dominate o : O + R ( o ) = { o (cid:48) ∈ O : o (cid:48) (cid:194) R o } . We will write O + ( o ) if it is clear from the context which is the set R of preferences we are considering . In our applications , users initially state only a subset R of their true preference model R . When a preference is added , dominated options with respect to R can become Pareto - optimal . The following observation is the basis for evalua - ting the likelihood that a dominated option will become Pareto - optimal : P ROPOSITION 1 . A dominated option o (cid:48) with respect to R becomes Pareto - optimal with respect to R ∪ r i ( a new preference r i is added ) , if and only if o (cid:48) is strictly better with respect to r i than all options that currently dominate it : o (cid:48) (cid:194) r i o , ∀ o ∈ O + R ( o (cid:48) ) . In general , the Pareto - optimal set increases when stating mo - re preferences , as the dominance relation becomes sparser . MODEL - BASED SUGGESTION STRATEGIES We propose 3 strategies that we call model - based suggesti - on strategies because they speciﬁcally choose examples to stimulate the expression of additional preferences based on the current preference model . They use Pareto - optimality to implement the principle stated in the introduction : suggesti - ons should not be optimal yet , but have a high likelihood of becoming optimal when an additional preference is added . An ideal suggestion is an option that is Pareto - optimal with respect to the full preference model R , but is dominated in R , the partial preference model . Following Proposition 1 , the probability of a dominated op - tion o becoming Pareto - optimal is equal to : p ( o ) = (cid:89) o + ∈ O + ( o ) p d ( o , o + ) ( 1 ) where p d is the probability that a new preference makes o escape the domination relation with a dominating option o + , i . e . if o is preferred over o + according to the new prefe - rence . Evaluating this probability exactly requires the proba - bility distribution of the possible preferences , generally not known . Therefore we propose several strategies based on in - creasingly detailed assumptions about these distributions . Counting strategy The simplest strategy , the counting strategy , is based on the assumption that p d is constant for all dominance relations . Thus , we assume : p ( o ) = (cid:89) o + ∈ O + ( o ) p d = p | O + ( o ) | d Since p d ≤ 1 , this probability is the largest for the smallest set O + ( o ) . Consequently , the best suggestions are those with the lowest value of the following counting metric : F C ( o ) = | O + ( o ) | ( 2 ) Probabilistic strategy The probabilistic strategy ﬁnds the best possible estimati - on of the probability that a particular solution will become Pareto - optimal . p d ( Equation 1 ) can be written as : p d ( o , o + ) = 1 − (cid:89) a i ∈ A u ( 1 − P a i δ i ( o , o + ) ≈ (cid:88) a i ∈ A u P a i δ i ( o , o + ) where o + ∈ O + ( o ) , the set of dominators of o , and δ i is an heuristic estimation of the probability that an hidden prefe - CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 124 rence on attribute a i make o better than o + according to that preference , hence escaping the dominance relation . As a heuristic we use a normalized difference for interval do - mains : the chances that a new preference will treat o 1 and o 2 differently is directly proportional to the difference between their values . For discrete attributes , it is sufﬁcient to check if the attributes take different values . If so , there will be equal chances that one is preferred over the other and δ = 0 . 5 . If the values are the same , the dominance relation cannot be broken by a preference on this attribute , so δ = 0 . Attribute strategy The attribute strategy considers the fact that for breaking the dominance relation with all options in the dominating set , there has to be one attribute where all dominating options have different values . To express this concept , we deﬁne the function diff : Deﬁnition 5 . For an attribute a i and a given option o 1 with dominating set O + , diff ( o 1 , a i , O + ) = 1 if : • interval domains : a i ( o 1 ) should be either greater than or smaller than the attribute values for a i of all options in O + • enumerated domains : a i ( o 1 ) should be different than the attribute values for a i for all options in O + and 0 otherwise . The reasoning is the following : for interval domains , we as - sume that preferences are continuous , i . e . the user is likely to prefer values to be larger or smaller than a certain threshold , or as large or as small as possible . This applies to attributes like price or travel time and ﬁts well with the majority of users . For enumerated domains , a new preference may break the dominance relation whenever the attribute has a different value . Then we count the number of attributes for which the - re are no preferences yet and where all dominating options have a different value : F A ( o ) = (cid:88) a i ∈ A u P a i diff ( a i , o , O + ( o ) ) ( 3 ) where A u is the set of attributes on which no preference has been expressed yet ; P a i is the probability that the user has an unstated preference on attribute a i . It chooses as suggestions those options with the largest value of this metric . The example continued Previously in the example , f 1 and f 2 are shown as candida - te optimal examples . We will now consider which options will be chosen by the strategies as suggestions , omitting the calculations . In the counting strategy , the ﬁrst suggestion will be f 8 ( which is not very interesting because it is very similar to the candidates ) followed by f 3 as the second . The attribu - te strategy selects f 6 as the best suggestion . Its dominators for price ( f 1 , f 2 , f 8 , f 3 ) all depart from a different airport and leave before ( external interval ) , so the diff is equal to 1 on both attributes . The attribute strategy cannot choose a second suggestion because all other options have the same values for diff on both attributes . The probabilistic strategy chooses f 6 and f 5 since they are both dominated by four op - tions ( f 1 , f 2 , f 8 and f 3 ) but have high chance of breaking this domination because they signiﬁcantly differ on the other at - tributes ( they leave from the other airport ; f 6 lands few hours after , f 5 before ) . Let’s assume now that the user has stated her preference about price and time . The candidates will now be f 1 and f 3 . The suggestions : the counting strategy will propose f 2 and f 5 ( dominated respectively only by f 1 and f 3 ) , the attribute will suggest f 5 ( different airport than its dominator , f 3 ) and the probabilistic will give f 5 and f 6 . All suggestion techni - ques show an example with the city airport , and the user is stimulated to state that as a preference . SIMULATED USER EXPERIMENTS 0 20 40 60 80 100 1 2 3 4 5 6 r un s w i t h p r e f e r en c e s s t a t ed > = x number of preferences stated randomdiversityextremescountingattribute probabilistic Figure 2 . Simulation results on a database of actual apartment offers . For each strategy , we compare the fraction of simulation runs that discover at least x pre - ferences . 100 runs , data - set with 6 attributes and prefe - rences . The suggestions strategies are heuristics , and it is not cle - ar which of them performs best . Since evaluations with live users can only be implemented with a speciﬁc design , we ﬁrst select the best suggestion strategy by simulating the in - teraction of a computer generated user with randomly ge - nerated preferences . In this way , we can compare the diffe - rent techniques and select the most promising one for further evaluation . This is followed by real user studies in the next section using the probabilistic suggestion strategy . In the simulations , users stated a randomly generated set of m preferences on different attributes of available options sto - red in a database . We are interested in whether the system obtains a complete model of the user’s preferences in order to test the objective of the strategies , which is to motivate the user to express as many preferences as possible . CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 125 0 20 40 60 80 100 0 1 2 3 4 5 6 7 8 r un s w i t h p r e f e r en c e s s t a t ed > = x number of preferences stated randomdiversityextremescountingattribute probabilistic Figure 3 . Simulation results for randomly generated pro - blems . For each strategy , we compare the fraction of si - mulation runs that discover at least x preferences . 100 runs , data - set with 8 attributes and preferences . The simulated interaction starts with the initial preference ( randomly chosen among the m preferences ) . K options are selected as suggestions according to one of the following strategies : random choice , suggestion of extrema , maximi - zation of diversity ( which we include for comparison purpo - ses ) and the three model - based suggestions that we propose ( counting , attribute and probabilistic ) . Maximization of di - versity consists of selecting the subset of the k most diver - se options , so that the diversity ( deﬁned as the sum of the difference on all attributes ) between each option is maximi - zed [ 9 ] . The simulated user behaves according to our model , stating a new preference whenever the suggestions contain an option that would become optimal if such a preference were added to the user model . The interaction continues until either the user model is complete or the simulated user states no further preference . Note that when the complete preference model is discovered the user ﬁnds the most wanted option . The results of the simulation for a catalog of student accom - modations ( 160 options , 10 attributes ) are summarized in Figure 2 . It shows the percentage of runs ( out of 100 ) that discover at least x out of the 6 preferences in the complete user model . We see that the suggestion strategies provide a marked increase in the number of preferences that are unco - vered , and , in particular , the model - based strategies perform best . In another test , we ran the same simulation for a catalog of 100 randomly generated options with 9 attributes and 9 pre - ferences ( one is the initial preference , and 8 are yet to be discovered ) . The results are shown in Figure 3 . We can see that random and extreme strategies now perform very poor - ly and model - based strategies appear much better . Also , the difference among the three model - based approaches is smal - ler : the counting strategy performs only slightly worse than the attribute and probabilistic strategies . This occurs because there is no correlation between the attributes . We investigated the impact of the number of preferences , the number of attributes and the size of the data set . Surprisin - gly we discovered that the number of attributes only slight - ly changes the results . Keeping the number of preferences constant at 6 , we varied the simulations on the number of attributes set to 6 , 9 , and 12 respectively . The fraction of runs ( with 100 total runs ) that discovered all the preferences va - ried for each strategy and simulation scenario by no more than 5 % . We were surprised by the fact that the strategy of generating extreme examples , as originally proposed by Linden [ 6 ] , performed so poorly and only outperformed the randomly selected suggestions by a narrow margin . This shows the importance of considering the preferences that are already known and those to be discovered in the design of suggesti - on strategies . The simulations show that the simulated user is much more likely to state new preferences using the probabilistic stra - tegy ( statistically signiﬁcant ) . Moreover , in the simulations the complete preference model was discovered up to 25 ti - mes more often with the probabilistic strategy than with ran - domly picked suggestions , up to 10 times more than using the extreme strategy , and 1 . 5 times more than the counting strategy . The probabilistic strategy has a better average per - formance than the attribute strategy . Among the three model - based strategies , the probabilistic strategy provides the best results . However , it also makes the most assumptions about the preferences the user is likely to state . When these assumptions are not satisﬁed , the perfor - mance is likely to degrade . On the other hand , the counting strategy is the most robust among our strategies as it ma - kes no assumptions whatsoever about the form of the user’s preferences , while still achieving a large gain over simpler strategies . In the actual user studies , we decided to use the probabilistic strategy . EXPERIMENTAL RESULTS : USER STUDY In the user study , we are particularly interested in verifying : Hypothesis 1 : using model - based suggestions ( at least the probabilistic strategy ) leads to more complete preference models . Hypothesis 2 : using model - based suggestions leads to mo - re accurate decisions . Hypothesis 3 : more complete preference models tend to gi - ve more accurate decisions , indicating that the reasoning underlying the model - based suggestions is correct . We performed user studies using FlatFinder , a web applica - tion for ﬁnding student housing that uses real offers from a university database that was updated daily . The tool used the probabilistic strategy , as it was determined to be the best in the experiments with the simulated user . We recruited stu - dent subjects who had an interest in ﬁnding housing and thus were quite motivated for the task . CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 126 We studied two settings : • in an unsupervised setting , we monitored user behavior on a publicly accessible example critiquing search tool for the listing . This allowed us to obtain data from over a hun - dred different users ; however , it was not possible to judge decision accuracy since we were not able to interview the users themselves . • in a supervised setting , we recruited 40 volunteer students use the tool under supervision . Here , we could determine decision accuracy because at the end we asked the sub - jects to carefully examine the entire database of offers to determine their target option . Thus , we could determine the switching rate and measure decision accuracy . Each apartment comprises 10 attributes : the type of ac - commodation ( room in a family house , room in a shared apartment , studio apartment , apartment ) , the rental price , the number of rooms , furnished ( yes or no ) , the bathroom ( priva - te or shared ) , the type of kitchen ( shared , private ) , the trans - portation available ( none , bus , subway , commuter train ) , the distance to the university and the distance to the town center . For numerical attributes , a preference consists of a relational operator ( less than , equal , greater than ) , a threshold value and an importance weight between 1 - 5 . For example , pri - ce less than 600 Francs with importance 4 indicates a rela - tively strong preference for an apartment below 600 Francs . For discrete attributes , a preference speciﬁes a preferred va - lue with a certain importance . Preferences are translated into numbers using standardized value functions and are combi - ned by summing the results . The options are ordered so that the highest value is the most preferred . The users stated a set of initial preferences and then ob - tained options by pressing the search button . Subsequent - ly , they went through a sequence of interaction cycles whe - re they could reﬁne their preferences by critiquing the dis - played examples . The system maintains their current set of preferences and the user could state additional preferences , change the reference value of existing preferences , or even remove one or more of the preferences . Finally , the process would ﬁnish with a user’s ﬁnal set of preferences , and a tar - get choice chosen by the user from the displayed examples . The search tool was made available in two versions : • C , only showing a set of 6 candidate apartments without suggestions , and • C + S , showing a set of 3 candidate apartments and 3 sug - gestions selected according to the probabilistic strategy We now describe the results of the two experiments . Online User Study FlatFinder has been hosted on the laboratory web - server and made accessible to students looking for apartments during the winter of 2004 - 2005 . For each user , it recorded anony - mously a log of the interactions for later analysis . We set up a tool C tool C + S number of critiquing cycles 2 . 89 3 . 00 number of initial preferences 2 . 39 2 . 23 number of ﬁnal preferences 3 . 04 3 . 69 increment 0 . 65 1 . 46 Table 1 . Average user behavior in the online experiment . Interaction Characteristics ( mean ) 1st 2nd group 1 Decision Accuracy 0 . 45 0 . 80 ( C ﬁrst ) Preference Enumeration 5 . 30 6 . 15 group 2 Decision Accuracy 0 . 72 0 . 67 ( C + S ﬁrst ) Preference Enumeration 5 . 44 4 . 50 Table 2 . Results of the supervised user study . Decision ac - curacy and preference enumeration ( the number of pre - ferences stated ) are higher when suggestions are provi - ded . behavior so that users were alternatively presented with the versions with ( C + S ) and without ( C ) suggestions . We col - lected logs from 63 active users who went through several cycles of preference revision . In the following , whenever we present a hypothesis compa - ring users of the same group , we show its statistical signiﬁ - cance using a paired student test . For all hypotheses compa - ring users of different groups , we use the unpaired student test to indicate statistical signiﬁcance . We ﬁrst considered the increase from initial preference enu - meration P I to ﬁnal preference enumeration P F . This incre - ment was on average 1 . 46 for the tool with suggestions C + S and only 0 . 64 for the tool C , showing the higher involve - ment of users when they see suggestions . This hypothesis was conﬁrmed with p = 0 . 002 , t = − 2 . 925 . It is interesting to see that in both groups the users interacted for a similar number of cycles ( average of 2 . 89 for C and 3 . 00 for C + S p = 0 . 42 ) , and that the number of initial prefe - rences is also close ( average of 2 . 39 for C and 2 . 23 for C + S p = 0 . 37 ) , meaning that the groups are relatively unbiased . The result of the test shows clearly that users are more likely to state preferences when suggestions are present , thus ve - rifying Hypothesis 1 . They also show that model - based sug - gestions are signiﬁcantly better than random ones . However , as this is an online experiment , we are not able to measu - re decision accuracy . Thus , we also conducted a supervised user study . Supervised User Study The supervised user study used the same tool as the online user study but users were followed during their interaction . To measure improvement of accuracy , we instructed all of users to identify her most preferred item after she searched the database using interface 1 . This choice was recorded and was called c 1 . Then the users were instructed to interact with CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 127 the database using interface 2 and indicate a new choice ( c 2 ) if the latter was an improvement on c 1 in their opinion . To evaluate whether the second choice was better than the initi - al one , we instructed the users to review all apartments ( 100 apartments in this case ) and tell us whether c 1 , c 2 , or a com - pletely different one truly seemed best . Thus , the experiment allowed us to measure decision accu - racy since we obtained the true target choice for each user . If users would stand by their ﬁrst choice , it would indicate that they had found their target choice without further help from the second interface . If users would stand by their se - cond choice , it would indicate that they had found their target choice with the help of the second interface . If users chose yet another item , it would indicate that they had not found their target choice even though they performed search with both interfaces . 40 ( 9 females ) subjects of 9 different nationalities , mostly undergraduate students , took part in the study . Most of them ( 27 out of 40 ) had searched for an apartment in the area be - fore and 26 out of 40 had used online tools to look for ac - commodations . Importantly , all subjects were motivated by the interest of ﬁnding a better apartment for themselves . To overcome bias due to learning and fatigue , we divided the users in two groups , who were asked to interact with the versions in different order . Group 1 used tool C ( interaction 1 ) and then C + S ( interaction 2 ) , while group 2 used the tools in the inverse order . Both groups then went through the entire list to ﬁnd the true most preferred option . For each version of the tool and each group , we recorded as decision accuracy as the fraction of subjects where the ﬁnal choice made using that interface was equal to the target option . For both groups , we refer to the accuracy of interface 1 as a 1 , and the accuracy of interface 2 as a 2 . We expected that the order of presenting the versions would be important : once they have realized their own preferences and found a satisfactory option , they are likely to be consi - stent with that ; therefore we would have expected a 2 > a 1 in both cases . However we would expect that average accura - cy would signiﬁcantly increase with suggestions , and so we would see a 2 > > a 1 in the ﬁrst group and a 2 only slightly higher than a 1 in group 2 . Decision Accuracy improves with suggestions Figures 4 and 5 show the variation of decision accuracy for the two groups . For group 1 , after interaction with tool C , the accuracy is on average only 45 % , but after interaction with C + S , the version with suggestions , it increases to 80 % . This con - ﬁrms the hypothesis that suggestions improve accuracy ( p = 0 . 00076 , t = − 2 . 6 ) . 10 of the 20 subjects in this group swit - ched to another choice between the two versions , and 8 of them reported that the new choice was better . Clearly , the 0 0 . 2 0 . 4 0 . 6 0 . 8 1 2 ) C + S 1 ) C A cc u r a cy Interaction User study - Group 1 Figure 4 . For group 1 , accuracy dramatically increa - sed when they used the version with suggestions ( C + S ) ( p = 0 . 00076 ) . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 2 ) C 1 ) C + S A cc u r a cy Interaction User study - Group 2 Figure 5 . For group 2 , accuracy was already very high when using the version with suggestions ( C + S ) . Further interaction with the tool C ( showing 6 candidates ) did not increase accuracy any further . ( p = 0 . 33 ) use of suggestions signiﬁcantly improved decision accuracy for this group . Users in group 2 used C + S directly and already achieved an average accuracy of 72 % . We would have expected that a consequent use of tool C would have a small positive effect on the accuracy , but in reality the accuracy decreased to 67 % . 10 subjects changed their ﬁnal choice using the tool without suggestions and 6 of them said that the newly chosen was only equally good as the one they originally chose . The fact that accuracy does not drop signiﬁcantly in this case is not surprising because users remember their preferences from using the tool with suggestions and will thus state them more accurately independently of the tool . We can conclude from this group that improved accuracy is not simply the result of performing the search a second time , but due to the provision of suggestions in the tool . Also , the closeness of the accuracy levels reached by both groups when using suggestions can be interpreted as conﬁrmation of its signiﬁcance . We also note that users needed less cycles ( and thus less ef - fort ) to make a decision with interface C + S ( average of 4 . 15 ) than interface C ( average of 5 . 92 ) . Interestingly , the price of the chosen apartment increased for the ﬁrst group ( average of 586 . 75 for C vs . 612 . 50 for C + S ; p = 0 . 04 , t = − 1 . 79 , statistically signiﬁcant ) whereas it de - CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 128 found 0 . 45 0 . 83 still not found 0 . 55 0 . 17 ∆ P < = 0 ∆ P > 0 Table 3 . For users who did not ﬁnd their target in the ﬁrst use of the tool , the table shows the fraction that did and did not ﬁnd their target in the next try , depending on whether the size of their preference model did or did not increase . creased for the second group ( average of 527 . 20 for C + S to 477 . 25 for C ; p = 0 . 18 , the decrease is not statically signiﬁ - cant ) . We believe that subjects in the ﬁrst group did not ﬁnd a good choice and thus paid a relatively high price to get an apartment with which they would feel comfortable . Condi - tioned by this high price they were then willing to spend even more as they discovered more interesting features through suggestions . On the other hand , subjects in group 2 already found a good choice in the ﬁrst use of the tool , and were un - willing to accept a high price when they did not ﬁnd a better choice in the second search without suggestions . Thus , we conclude that Hypothesis 2 is conﬁrmed : suggesti - ons indeed increase decision accuracy . Preference enumeration improves accuracy In this study , we notice that when suggestions are present , users state a higher number of preferences ( average of 5 . 8 preferences vs . only 4 . 8 without suggestions , p = 0 . 021 , t = 2 . 22 ) . Therefore , Hypothesis 1 is again conﬁrmed . To validate Hypothesis 3 , that a higher preference enumera - tion also leads to more accurate decisions , we can compare the average size of preference model for those users who found their target solution with the ﬁrst use of the tool and those who did not . In both groups , users who did ﬁnd their target in the ﬁrst try stated on average 5 . 56 preferences ( 5 . 56 in group 1 and 5 . 57 in group 2 ) while users who did not ﬁnd their target stated only an average of 4 . 88 preferences ( 5 . 09 in group 1 and 4 . 67 in group 2 ) . This shows that increased preference enumeration indeed improves accuracy , but this result was not statistically signiﬁcant ( p = 0 . 17 , t = − 0 . 959 overall ) . In fact , there is a chance that this correlation is due to some users being more informed and thus both making more accurate decisions and stating more preferences . As an evaluation that is independent of user’s a - priori know - ledge , we only considered those users who did not ﬁnd their target in the ﬁrst try . As a measure of correlation of pre - ference enumeration and accuracy , we considered how of - ten an increase in preference enumeration in the second try led to ﬁnding the most preferred option on the second try . Table 3 shows that among users whose preference model did not grow in size , only 45 % found their target . However , for those that increased their preference enumeration , 83 % found their target as a result . Again , we see a good conﬁr - mation that higher preference enumeration leads to a more accurate decision with real users ( p = 0 . 04 , t = 1 . 928 ) . > 0 0 . 23 0 . 14 0 . 38 0 0 . 62 0 . 71 0 . 62 < 0 0 . 15 0 . 14 0 . 00 ∆ a , ∆ P < 0 = 0 > 0 Table 4 . Variation of accuracy against variation of the number of stated preference P in the two steps of the user test . ( Marginalization : each column sums to 1 ) . Finally , a third conﬁrmation can be obtained by considering the inﬂuence that variations in the size of the preference mo - del have on decision accuracy , shown in Table 4 . Each co - lumn corresponds to users where the size of the preference model decreased , stayed the same , or increased , and shows the fraction for which the accuracy increased , stayed the sa - me or decreased ( note that when accuracy is 1 at the ﬁrst step , it cannot further increase ) . We can see that a signiﬁ - cant increase in accuracy occurs only when the size of the preference model increases ; in all other cases there are so - me random variations but no major increases . The statisti - cal test conﬁrms the hypothesis that an increase in prefe - rence enumeration causes an increase in accuracy at a level of p = 0 . 0322 , t = 1 . 928 . Thus , we conclude that hypothesis 3 is also validated by the user study : a more complete preference model indeed leads to more accurate decisions . CONCLUSIONS Search and recommender tools are an important part of computer usage today and present signiﬁcant new human - computer interaction challenges that have been insufﬁciently addressed thus far . Among them is the problem of obtaining accurate user preferences through interaction . Mixed - initiative systems such as example critiquing are a promising technology for efﬁciently eliciting accurate user preference models . Determining how to stimulate the user to state preferences on as many attributes as she may have is a key issue concerning such systems . We have developed a model for computing examples most suitable for stimula - ting preference expression and designed several suggestion strategies based on this model . The main principle is that suggestions should be options that are dominated under the current preference model but would no longer be dominated with the inclusion of additional preferences . In order to im - plement this principle with a minimum of assumptions about the user’s preference model , we deﬁned different strategies based on the concept of Pareto - optimality . We ﬁrst compared various suggestion strategies on simulati - ons and determined the one that seemed to be the most ef - fective . We conﬁrmed its strong performance with live user studies , where we observed that the quality of the preference model , as measured by the number of stated preferences , in - creased almost twice as much with suggestions as without . We followed this online user study by a supervised user stu - dy which also allowed us to measure decision accuracy . This study conﬁrmed that the use of suggestions almost doubled CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 129 decision accuracy and allowed the search tool to ﬁnd the most preferred option 80 % of the time . This should greatly strengthen the performance of recommendation and search tools in applications ranging from decision support to e - commerce . ACKNOWLEDGMENTS The authors thank Vincent Schickel - Zuber for signiﬁcant contribution in the development of the web based interface of FlatFinder and the anonymous reviewers for useful com - ments and suggestions . REFERENCES 1 . D . Bridge and A . Ferguson . Diverse Product Recommendations using an Expressive Language for Case Retrieval . In Advances in Case - Based Reasoning , Springer , 2002 2 . R . D . Burke , K . J . Hammond and B . C . Young . The FindMe approach to assisted browsing . IEEE Expert , 12 ( 4 ) , 1997 . 3 . R . Burke . Hybrid recommender systems : survey and experiments . User Modeling and User - Adapted Interaction , 12 , 4 ( 2002 ) , 331 - 370 . 4 . R . Burke , K . Hammond and E . Cooper . Knowledge - Based Navigation of Complex Information Spaces . In Proceedings of the 13th National Conference on Artiﬁcial Intelligence , AAAI press , 1996 , pp . 462 - 468 . 5 . R . L . Keeney and H . Raiffa . Decisions with Multiple Objectives : Preferences and Value Tradeoffs . New York : Wiley , 1976 . 6 . Greg Linden , Steve Hanks , and Neal Lesh . Interactive assessment of user preference models : The automated travel assistant . In Proceedings , User Modeling ’97 , 1997 . 7 . K . McCarthy , J . Reilly , L . McGinty and B . Smyth . Experiments in Dynamic Critiquing . In Proceedings of the 10th International Conference on Intelligent User Interfaces ( IUI’05 ) , New York : ACM Press , 2005 , pp . 175 - 182 . 8 . L . McGinty and B . Smyth . On the Role of Diversity in Conversational Recommender Systems . In Proceedings of the 5th International Conference on Case - Based Reasoning ( ICCBR’03 ) , 2003 , pp . 276 - 290 9 . David McSherry . Diversity - conscious retrieval . In ECCBR , pages 219 – 233 , 2002 . 10 . David McSherry . Similarity and Compromise . Proceedings of the 5th International Conference on Case - Based Reasoning , LNAI 2689 , Springer - Verlag , pp . 291 - 305 , 2003 11 . J . W . Payne , J . R . Bettman , and E . J . Johnson . The Adaptive Decision Maker . Cambridge Univ . Press , 1993 . 12 . R . Price and P . R . Messinger . Optimal Recommendation Sets : Covering Uncertainty over User Preferences . In Proceedings of the 20th National Conference on Artiﬁcial Intelligence ( AAAI’05 ) , 2005 , pp . 541 - 548 . 13 . Pearl Pu and Boi Faltings . Enriching buyers’ experiences : the smartclient approach . In SIGCHI conference on Human factors in computing systems , pages 289 – 296 . ACM Press New York , NY , USA , 2000 . 14 . Pearl Pu and Boi Faltings . Decision tradeoff using example - critiquing and constraint programming . Constraints : An International Journal , 9 ( 4 ) , 2004 . 15 . Pearl Pu , Boi Faltings and Marc Torrens , Effective Interaction Principles for Online Product Search Environments . In Proceedings of the IEEE / WIC / ACM International Joint Conference on Intelligent Agent Technology and Web Intelligence , 2004 , pp . 724 - 727 16 . Pearl Pu and P . Kumar , Evaluating Example - Based Search Tools . In Proceedings of the 5th ACM Conference on Electronic Commerce ( EC’04 ) , ACM Press , 2004 , pp . 208 - 217 . 17 . Pearl Pu and Li Chen , Integrating Tradeoff Support in Product Search Tools for E - Commerce Sites . In Proceeding of the 6th ACM Conference on Electronic Commerce ( EC’05 ) , ACM Press , 2005 , pp . 269 - 278 . 18 . James Reilly , Kevin McCarthy , Lorraine McGinty , and Barry Smyth . Dynamic critiquing . In ECCBR , pages 763 – 777 , 2004 . 19 . Hideo Shimazu . Expertclerk : Navigating shoppers buying process with the combination of asking and proposing . In Proceedings of the 17 International Joint Conference on Artiﬁcial Intelligence ( IJCAI’01 ) , volume 2 , pages 1443 – 1448 , 2001 . 20 . Sybil Shearin and Henry Lieberman . Intelligent proﬁling by example . In Intelligent User Interfaces , pages 145 – 151 , 2001 . 21 . Barry Smyth and Lorraine McGinty . The power of suggestion . In IJCAI , pages 127 – 132 , 2003 . 22 . B . Smyth , P . McClave . Similarity vs . Diversity . In Proceedings of the 4th International Conference on Case - Based Reasoning ( ICCBR’01 ) , Springer - Verlag , 2001 , pp . 347 - 361 . 23 . A . Tversky , S . Sattath , and P . Slovic . Contingent weighting in judgment and choice . Psychological Review , 95 : 371 – 384 , 1988 . 24 . C . N . Ziegler , S . M . McNee , J . A . Konstan , G . Lausen . Improving Recommendation Lists Through Topic Diversiﬁcation . In Proceedings of the 14th International World Wide Web Conference ( WWW’05 ) , 2005 , pp . 22 - 32 . 25 . M . D . Williams and F . T . Tou . RABBIT : An Interface for Database Access . In Proceedings of the ACM ’82 Conference , ACM Press , 1982 , pp . 83 - 87 . CHI 2006 Proceedings • Social Computing 1 April 22 - 27 , 2006 • Montréal , Québec , Canada 130