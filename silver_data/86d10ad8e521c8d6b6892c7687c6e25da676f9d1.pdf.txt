Draft version : February 7 , 2024 Correspondence should be addressed to Mark S Fox . Email : msf @ mie . utoronto . ca Copyright rests with the authors . This work is released under a Creative Commons Attribution License , version 4 . 0 . For details please see https : / / creativecommons . org / licenses / by / 4 . 0 / 1 A Maturity Model for Urban Dataset Meta - data Mark S Fox Urban Data Centre School of Cities University of Toronto msf @ mie . utoronto . ca Bart Gajderowicz Urban Data Centre School of Cities University of Toronto bartg @ mie . utoronto . ca Dishu Lyu Urban Data Centre School of Cities University of Toronto lester . lyu @ mie . utoronto . ca Draft version : February 7 , 2024 Abstract In the current environment of data generation and publication , there is an ever - growing number of datasets available for download . This growth precipitates an existing challenge : sourcing and integrating relevant datasets for analysis is becoming more complex . Despite efforts by open data platforms , obstacles remain , predominantly rooted in inadequate metadata , unsuitable data presentation , complications in pinpointing desired data , and data integration . This paper delves into the intricacies of dataset retrieval , emphasizing the pivotal role of metadata in aligning datasets with user queries . Through an exploration of existing literature , it underscores prevailing issues such as the identification of valuable metadata and the development of tools to maintain and annotate them effectively . The central contribution of this research is the proposition of a dataset metadata maturity model . Deriving inspiration from software engineering maturity models , this framework delineates a progression from rudimentary metadata documentation to advanced levels , aiding dataset creators in their documentation efforts . The model encompasses seven pivotal dimensions , spanning content to quality information , each stratified across six maturity levels to guide the optimal documentation of datasets , ensuring ease of discovery , relevance assessment , and comprehensive dataset understanding . This paper also incorporates the maturity model into a data cataloguing tool called CKAN through a custom plugin , CKANext - udc . The plugin introduces custom fields based on different maturity levels , allows for user interface customisation , and integrates with a graph database , converting catalogue data into a knowledge graph based on the Maturity Model ontology . 2 | A Maturity Model for Urban Dataset Meta - data Introduction The world is awash in data , but we cannot seem to find the data we need . Though open data platforms strive to make it easier to find relevant data , Ojo et al . ( 2016 ) observe that common obstacles to finding relevant data are “poor metadata , failure to pres ent data appropriately to different audiences and difficulty in locating data of interest . ” Kunze and Auer ( 2013 ) define the problem of dataset retrieval as determining the most relevant datasets according to a user query . This is part of the exploration phase of information seeking , which Koesten et al . ( 2017 ) define as determining “whether a se arch result , in our case a dataset , matches an information need . ” In understanding the process of exploration , it is important to distinguish between the direct examination of the contents of a dataset 1 versus the examination of its meta - data . Chapman et al . ( 2020 ) , in their survey of dataset search identify the following “open problems for meta - data” : 1 . identifying the meta - data that is of highest value to users with respect to datasets ; 2 . tools to automatically create and maintain that meta - data ; and 3 . automatic annotation of dataset with meta - data — linking them automatically to global ontologies Research has explored each of these problems . Regarding the first problem , Datasheets for Datasets ( Gebru et al . , 2021 ) suggest over 50 meta - data questions whose answers would enable a dataset consumer to determine the relevance of a dataset . Using Datasheets is a daunting task , requiring more information than the dataset cataloguer has available or is willing to provide . If the cataloguer is only willing to provide limited information , which is the most important to provide ? A second problem is that the answers to the Datasheets questions are textual . That is , they are in a natural language such as English , which must be read by the dataset consumer . Existing keyword - based search may help narrow down the target datasets , but with possibly poor precision and recall . In order to achieve higher levels of precision and recall , applied ontology methods have been used to construct vocabularies and ontologies to represent dataset meta - data . The most prominent is the Data Catalog Vocabulary - DCAT ( Albertoni et al . , 2020 ) and schema . org . Other relevant vocabularies / ontologies include PROV ( Lebo et al . , 2013 ) for provenance and DQV ( Albertoni & Isaac , 2016 ) for dataset quality . Regarding the second and third problems , Neumaier et al . ( 2017 ) automate the harvesting of meta - data descriptions of over 854K datasets from over 261 data portals and mapping them onto the DCAT . In addition , they add both provenance and quality meta - data . The difficulty in finding relevant datasets is exacerbated by the global growth of dataset repositories that would need to be searched . Open Data Portal Watch ( Neumaier et al . , 2017 ) collects meta - data from more than 260 repositories , focusing on government data . Noy et al . ( 2019 ) have developed Google Dataset Search ( GDS ) to address this problem . GDS crawls the web to extract the meta - data from various types of datasets , which is then transformed into a searchable knowledge graph . The problem addressed in this paper is how does the cataloguer of a dataset know what types of meta - data should be defined and selected from the myriad of dataset meta - data entities and attributes ? The dataset cataloguer may not be versed in the many relevant vocabularies , such as DCAT , schema . org , PROV and DQV . Datasheets specify over 50 questions requiring a considerable amount of detailed information . The DCAT vocabulary specifies 13 classes with over 70 properties , not including extensions for provenance , quality , etc . Consequently , dataset cataloguers face a bewildering number of meta - data entities and attributes to use to document their datasets . 1 Which falls into the area sensemaking ( Russell et al . , 1993 ) . Fox , Gajderowicz , Lyu | 3 In order to navigate the morass of potential entities and attributes that can be used to catalogue a dataset , our goal is to define a dataset meta - data maturity model that identifies and sequences the meta - data that should be provided by a dataset cataloguer . A maturity model , as defined in the software engineering Capability Maturity Model ( Paulk et al . , 1993 ) , specifies a sequence of levels of software development process capability starting with the base case , e . g . , “no maturity” , followed by levels of increasing maturity . Each step up the maturity “ladder” specifies a more enhanced process capability . In the context of dataset meta - data , the lowest level ( base case ) is having no meta - data specified . The question then is what to include in the next and subsequent maturity levels such that we balance the amount of effort required to catalogue a dataset with sufficient meta - data to discover and determine the suitability / relevance of a dataset and provide sufficient information on who and how it may be used . Our methodology for determining the dataset meta - data maturity model is to review the literature on dataset search behaviours to ascertain both the types of information searched for and the frequency of its search . Our proxy for the latter is how often a type of information appears in the search literature . We then review existing vocabularies relevant to the representation of dataset metadata . We extend the maturity model to include facets of frameworks such as FAIR ( Findable , Accessible , Interoperable , Retrievable ) and OCAP2 ( Ownership , Control , Access , Possession ) for indigenous data ( Mecredy et al . , 2018 ) . Dataset Meta - Data Requirements Requirements for dataset meta - data have emerged from a variety of sources . One source is based on the analysis of dataset search behaviours . Another from the analysis of meta - data gathered by dataset platforms . A third addresses concerns such as FAIRness , privacy and restrictions on use . A fourth reflects requirements specific to domains such as Indigenous and medical data . This section reviews many of these requirements . Requirements Based on Search Behaviour Koesten et al . ( 2017 ) studied information - seeking behaviour . The following are examples of search : “someone trying to find the number of schools in a given post code area would need to extract the answer from a larger dataset containing all entries for all schools in a country in 2016 . Someone studying how the number of schools across different regions has changed over time would need to process and aggregate several versions of the same data , published year after year . Finally , school data could be mixed with house prices statistics to understand how one aspect influences the other . ” Koesten et al . proposed a five - pillar model for how people seek information ( Table 1 ) . They also identified three categories of meta - data to describe a dataset : Relevance , Usability and Quality . Table 2 summarizes the meta - data of a dataset they found important . Table 1 . Information Seeking Stages . 2 https : / / fnigc . ca / ocap - training / 4 | A Maturity Model for Urban Dataset Meta - data Task → Search → Evaluate → Explore → Use goal or process oriented STRATEGIES : web search engines data portals asking people FOI request relevance 1 usability 2 quality 3 basic visual scan obvious errors summarizing statistics headers documentation metadata linking time series analysis summarising presenting exporting 1 : context , coverage , summary , original purpose , granularity , time frame 2 : labeling , documentation , licence , access , machine readability , language used , format , ability to share , format 3 : collection methods , provenance , consistency of formatting / labeling completeness , what’s been excluded Table 2 . Categories of Meta - data . Assess Information needed about Relevance context , coverage , original purpose , granularity , summary , time frame Usability labeling , documentation , license , access , machine readability , language used , format , schema , ability to share Quality collection methods , provenance , consistency of formatting / labeling , completeness , what has been excluded Kacprzak et al . ( 2019 ) conducted an extensive analysis of web portal search logs and written requests . Their findings identified a dataset’s topic area as important along with geospatial , temporal and dataset format properties , with geospatial and temporal at varying levels of granularity . An examination of the requests reproduced in their paper indicates the central role of domain expertise in the terms used in queries . These requests contain detailed descriptions of the topics where the terms are drawn from the d omain’s vocabulary . Chen et al . ( 2019 ) analysed almost 2 , 000 dataset queries from online communities Stack Overflow , Open Data Stack Exchange , Reddit , and data . gov . uk . Table 3 depicts the results of their analysis . It divides the analysis into two categories , Metadata , where the queries refer to information contained in meta - data , and Content , where the queries refer to information contained in the content of the dataset . Note that 94 % of the queries refer to the domain or topic of the dataset , 50 % refer to concepts and their properties in the dataset , 20 % refer to geospatial information , 16 % refer to the format of the dataset , and 10 % to temporal information . Table 3 . Analysis of Dataset Queries . Fox , Gajderowicz , Lyu | 5 Category Title % of Queries Example Query Metadata Name 3 . 54 % HUST - ASL Dataset Domain / Topic 94 . 45 % weather dataset with solar radiance and solar energy production Data Format 16 . 23 % jpg images for all Unicode characters Language 3 . 90 % annotated movie review dataset in German Accessibility 7 . 40 % open source handwritten English alphabets dataset Provenance 0 . 21 % FDA datasets about medicine name and the result has adverse events Statistics 2 . 98 % dataset contains at least 1000 examples of opinion articles Overall 96 . 05 % Content Concept 50 . 59 % dataset about people , include gender , ethnicity , name Geospatial 19 . 21 % judicial decisions in France Other Entities 0 . 41 % datasets with nutrition data for many commercial food products ( i . e . , Lucky Charms , Monster Energy , Nutella , etc . ) Temporal 9 . 35 % 2011 - 2013 MoT failure rates on passenger cars Other Numbers 1 . 59 % businesses that employ over 1000 people in Yorkshire region Overall 63 . 79 % Kacprzak et al . ( 2019 ) , in their analysis of query logs from four national open data platforms , identified the following meta - data attributes as relevant : • Geospatial • Temporal • Topic taxonomy • Price • License • Format • Size Chua et al . ( 2020 ) analysed the information - seeking behaviours of 21 people using open data portals . Spatial and temporal keywords dominated the search queries and were supplemented with format and source filters . Follow up interviews identified that dataset incompleteness and outdatedness as issues . 6 | A Maturity Model for Urban Dataset Meta - data Sharifpour et al . ( 2022 ) in their analysis of search behaviours based on different levels of domain expertise , discovered that expert users used more words and succeeded with shorter sessions , confirming one of the results of White et al . ( 2009 ) . They also observed that dataset search is more difficult due to “the data for relevance judgement is not readily accessible within the metadata of datasets” . Dataset Platform Meta - Data Requirements In this section , we review the meta - data requirements that have emerged in the literature either by reviewing dataset platforms , analysis or domain consensus . Assaf et al . ( 2015 ) proposed HDL , a harmonized dataset model that adopts and extends key properties of DCAT , Schema . org , CKAN , etc . Their analysis identifies eight information types to be encoded as meta - data : 1 . General Information such as title and description . 2 . Access Information such as the URL and license . 3 . Ownership information such as author and maintainer . 4 . Provenance information such as creation date and versioning . 5 . Geospatial information such as geographic coverage . 6 . Temporal information such as temporal span and granularity . 7 . Statistical information property distribution and number of entities . 8 . Quality information such as the quality of the data and meta - data Neumaiier et al . ( 2017 ) identified the following “extra keys” ( Table 4 ) in their analysis of over 749K CKAN datasets . They also add quality ( CQV ) and provenance ( PROV ) information to the dataset’s meta - data . Table 4 . Extra Keys . Extra key Portals Datasets Mapping spatial 29 315 , 652 dct : spatial harvest _ object . id 29 514 , 489 ? harvest _ source . id 28 486 , 388 ? harvest _ source _ title 28 486 , 287 ? guid 21 276 , 144 dct : identifier contact - email 17 272 , 208 dcat : contactPoint spatial - reference - system 16 263 , 012 ? metadata - date 15 265 , 373 dct : issued The DataCite project ( Rueda et al . , 2017 ) seeks to create an interoperable e - infrastructure for research data . It highlights the importance of unique , persistent identifiers in datasets for achieving an interoperable e - infrastructure . “Persistent identifiers allow dif ferent platforms to exchange Fox , Gajderowicz , Lyu | 7 information consistently and unambiguously and provide a reliable way to track citations and reuse . ” In addition is the adoption of a common set of meta - data properties , partitioned into mandatory , recommended and optional ( Table 5 ) . Table 5 . DataCite Meta - data Properties . Mandatory Recommended Optional Identifier Subject Language Creator Contributor Alternate Identifier Title Date Size Publisher Related Identifier Format Publication Year Description Version Resource Type Geolocation Rights Fenner et al . ( 2019 ) define a roadmap for data citation . They identify two types of meta - data that need to be represented . This first is citation meta - data . Table 6 lists the types of citation meta - data in the first column and the corresponding properties as found in the Dublin Core , Schema . org , DataCite and DATS ( Sansone et al . , 2017 ) . Table 6 . Citation Meta - data . Citation Meta - Data Dublin Core Schema . org DataCite DATS Dataset Identifier identifier @ id identifier identifier Title title name title title Creator creator author creator creator Data repository or archive publisher publisher publisher publisher Publication Date date datePublished publication Year date Version not available version version version Type type type resourceTypeGeneral type The second is discovery meta - data used to enable the discovery of relevant datasets ( Table 7 ) . Table 7 . Discovery Meta - data . Discovery Dublin Core Schema . org DataCite DATS 8 | A Maturity Model for Urban Dataset Meta - data Meta - Data Description description description description datatype is a dimension , isAbout Material Material Keywords subject keywords subject keywords License license license rights license Related Dataset isPartOf is VersionOf references isPartOf citation relatedIdentifier isPartOf Related Publication bibliographicCitation citation relatedIdentifier publication Chapman et al . ( 2020 ) state that repositories need to consider data provenance , annotations , quality , granularity of content , data schema , language , and temporal coverage . Thornton et al . ( 2021 ) analysed several Canadian open health data repositories regarding the richness of their meta - data . As part of their analysis they used meta - data defined in the Dataverse North meta - data best practices guide ( Cooper et al . , 2019 ) and Data Citation Roadmap ( Fenner et al . , 2019 ) . The following are the meta - data in the Dataverse North guide : • Title • Author • Description • Subject • Producer • Contact Name • Contact Affiliation • Contact Email Gebru et al . ( 2021 ) in their “Datasheets for Datasets” proposal defined 56 questions to document the provenance of machine learning datasets . These questions are divided into 7 categories : 1 . Motivation : Who created the dataset ? For what purpose ? Who funded it ? 2 . Composition : What is the dataset composed of ? Size ? Completeness ? 3 . Collection Process : How was the data collected ? When ? Ethical process ? 4 . Preprocessing / Cleaning / Labeling : Was any cleaning or labeling performed ? 5 . Uses : How has the data been used ? What can it be used for , or not ? 6 . Distribution : How and when will the dataset be distributed ? Any restrictions ? 7 . Maintenance : Who supports the dataset ? Will it be updated ? Will older versions be maintained ? Fox , Gajderowicz , Lyu | 9 Appendix 2 contains the complete list of questions for each category . Licensing Meta - Data We assume that the ultimate purpose for searching a dataset catalogue is to be able to use an identified dataset for some application . Hence , the user will have to know who the creator / owner of the data is , where it is located and any conditions of usage . To ascertain the meta - data required for the latter , we review a few licenses under which datasets are often published . The Creative Commons Organization has six types of licenses 3 that span the continuum from free use of the material for both commercial and non - commercial uses , to limitations on remixing , adapting , and building upon , and for commercial use . Across all these licenses is the requirement to give attribution to the creator of the material . The Open Knowledge Foundation has three types of licenses 4 that focus specifically on data . The licenses allow users of the data to : • share : To copy , distribute and use the database . • create : To produce works from the database . • adapt : To modify , transform and build upon the database . Similar to the Creative Commons license , attribution is required ( for two of the licenses ) for any public use of the data and its derivations . In both cases knowing the creator / owner and the license is important . FAIR Data Bahim et al . ( 2020 ) define a FAIR ( Findable , Accessible , I , Retrievable ) Data Maturity Model . The model partitions a set of FAIRness dataset data and meta - data indicators into Essential , Important and Useful . Details are provided in the next section . Use of Indigenous Data OCAP 5 ( Mecredy et al . , 2018 ) , developed by the First Nations Information Governance Centre 6 , is a set of principles “regarding the collection , use and disclosure of data or information regarding first nations . ” It focuses on protecting indigenous individual privacy rights as well as the collective rights of community . OCAP is an acronym for Ownership , Control , Access and Possession 7 : • Ownership : “The notion of ownership refers to the relationship of a First Nations community to its cultural knowledge / data / information . The principle states that a community or group owns information collectively in the same way that an individual owns their personal information . Ownership is distinct from stewardship . The stewardship or custodianship of data or information by an institution that is accountable to the group is a mechanism through which ownership may be maintained . This can be done with data - sharing agreements and other legal instruments . “ • Control : “The aspirations and inherent rights of First Nations to maintain and regain control of all aspects of their lives and institutions extend to information and data . The principle of ‘control’ asserts that First Nations people , their communities and their 3 https : / / creativecommons . org / about / cclicenses / 4 https : / / opendatacommons . org / licenses / 5 https : / / fnigc . ca / ocap - training / 6 https : / / fnigc . ca / 7 Reproduced from Module 1 of OCAP online training participant notes , developed by Algonquin College and FNIGC . 10 | A Maturity Model for Urban Dataset Meta - data representative bodies must control how information about them is collected , used and disclosed . The element of control extends to all aspects of information management , from collection of data to the use , disclosure , and ultimate destruction of data . “ • Access : First Nations must have access to information and data about themselves and their communities , regardless of where it is held . The principle also refers to the right of First Nations communities and organizations to manage and make decisions regarding who can access their collective information . “ • Possession : “While ‘ownership’ identifies the relationship between a people and their data , possession reflects the state of stewardship of data . First Nations possession puts data within First Nations jurisdiction and therefore , within First Nations control . Possession is the mechanism to assert and protect ownership and control . First Nations generally exercise little or no control over data that is in possession of others , particularly other governments . “ Possession of data is fundamentally necessary . It is nearly impossible to exert ownership , control and access without it . Dataset Metadata Vocabularies With the introduction of open data portals such as CKAN and Dataverse , interest in vocabularies for representing dataset meta - data has grown . In this section , we review vocabularies for dataset meta - data . VoID Vocabulary of Interlinked Datasets 8 ( Alexander et al . , 2011 ) is one of the early RDF vocabularies for dataset meta - data . It identifies Dublin Core Meta - Data terms to be used for datasets . Table 8 depicts the meta - data terms . The prefix “dct” denotes the namespace “http : / / purl . org / dc / terms / ” . Table 8 . Dublin Core Meta - Data terms for dataset meta - data . Term Purpose dct : title The name of the dataset . dct : description A textual description of the dataset . dcterms : creater An entity such as person organisation or service that is primarily responsible for creating the dataset . The creator should be described as an RDF resource , rather than just providing the name as literal . dct : publisher An entity such as a person organisation or service that is responsible for making the dataset available . The publisher should be described as an RDF resource , rather than just providing the name as a literal . dct : contributor An entity such as a person organisation or service that is responsible for making contributions to the dataset . The contributor should be described as an RDF resource , rather than just providing the name as a literal . dct : source A related resource from which the dataset is derived . The source should be described as an RDF resource rather than as literal . 8 https : / / www . w3 . org / TR / void / Fox , Gajderowicz , Lyu | 11 Term Purpose dct : date A point or period of time associated with an event in the life - cycle of the resource The value should be formatted and data - typed as an xsd : date . dct : created Date of creation of the dataset . The value should be formatted and data - typed as an xsd : date . dct : issued Date of formal issuance ( e . g . , publication ) of the dataset . The value should be formatted and data - typed as an xsd : date . dct : modified Date on which the dataset was changed . The value should be formatted and data - typed as an xsd : date . In addition , it provides properties for contact information , licensing , dataset domain categories , format , access information and statistics . Table 9 lists the statistics - related properties . The prefix “void” denotes the namespace “http : / / rdfs . org / ns / void # ” . Table 9 . VoID dataset statistics . Property Purpose void : triples The total number of triples contained in the dataset . void : entities The total number of entities that are described in the dataset . To be an entity in a dataset , a resource must have a URI , and the URI must match the dataset’s void : uriRegexPattern , if any . Authors of VoID files may impose arbitrary additional requirements , for example , they may consider any foaf : Document resources as not being entities . void : classes The total number of distinct classes in the dataset . In other words , the number of distinct class URIs occuring as objects of rdf : type triples in the dataset . void : properties The total number of distinct properties in the dataset . In other words , the number of distinct property URIs that occur in the predicate position of triples in the dataset . void : distinctSubjects The total number of distinct subjects in the dataset . In other words , the number of distinct URIs or blank nodes that occur in the subject position of triples in the dataset . void : distinctObjects The total number of distinct objects in the dataset . In other words , the number of distinct URIs , blank nodes , or literals that occur in the object position of triples in the dataset . void : documents If the dataset is published as a set of individual documents , such as RDF / XML documents or RDFa - annotated web pages , then this property indicates the total number of such documents . Non - RDF documents , such as web pages in HTML or images , are usually not included in this count . This property is intended for datasets where the total number of triples or entities is hard to determine . void : triples or void : entities should be preferred where practical . 12 | A Maturity Model for Urban Dataset Meta - data Figure 1 . DCAT3 Classes and Properties ( Albertoni et al . , 2023 ) . DCAT The Data Catalog Vocabulary ( DCAT ) 9 is a W3C RDF - based vocabulary that enables interoperability among data catalogues published on the Web . The vocabulary defines a set of meta - data terms for describing data catalogues and datasets . Figure 1 depicts the classes and properties in the version 3 ( working draft ) of DCAT . The dcat : Catalog class is used to define a web accessible catalogue composed of dcat : Resources of which dcat : Dataset and dcat : DataService are subclasses . A rich set of properties are provided to describe both . The prefix “dcat” denotes the namespace “http : / / www . w3 . org / ns / dcat # ” . 9 https : / / www . w3 . org / TR / vocab - dcat - 3 / Fox , Gajderowicz , Lyu | 13 DCAT - AP The DCAT - AP ( Van Nueffelen , 2021 ) provides a standard for the description of dataset meta - data , which is published by data portals across Europe . It identifies a required set of DCAT classes and properties and categorizes them as mandatory , recommended , and optional , which can be interpreted as a three - level maturity model . Table 10 , Table 11 , and Table 12 define the properties of the three categories , respectively . Table 10 . DCAT - AP Mandatory Dataset Properties . Property URI Range Usage note Card Description dct : description rdfs : Literal This property contains a free - text account of the Dataset . This property can be repeated for parallel language versions of the description . 1 . . n Title dct : title rdfs : Literal This property contains a name given to the Dataset . This property can be repeated for parallel language versions of the name . 1 . . n Table 11 . DCAT - AP Recommended Dataset Properties . Property URI Range Usage note Card contact point dcat : contactPoint vcard : Kind This property contains contact information that can be used for sending comments about the Dataset . 0 . . n dataset distribution dcat : distribution dcat : Distribution This property links the Dataset to an available Distribution . 0 . . n keyword / tag dcat : keyword rdfs : Literal This property contains a keyword or tag describing the Dataset . 0 . . n publisher dct : publisher foaf : Agent This property refers to an entity ( organisation ) responsible for making the Dataset available . 0 . . 1 spatial / geographical coverage dct : spatial dct : Location This property refers to a geographic region that is covered by the Dataset . 0 . . n 14 | A Maturity Model for Urban Dataset Meta - data Table 12 . DCAT - AP Optional Dataset Properties . Property URI Range Usage note Card access rights dct : accessRig hts dct : RightsStatement This property refers to information that indicates whether the Dataset is open data , has access restrictions or is not public . A controlled vocabulary with three members ( : public , : restricted , : non - public ) will be created and maintained by the Publications Office of the EU . 0 . . 1 creator dct : creator foaf : Agent This property refers to the entity primarily responsible for producing the dataset 0 . . 1 conforms to dct : conforms To dct : Standard This property refers to an implementing rule or other specification . 0 . . n documentation foaf : page foaf : Document This property refers to a page or document about this Dataset . 0 . . n frequency dct : accrualPe riodicity dct : Frequency This property refers to the frequency at which the Dataset is updated . 0 . . 1 has version dct : hasVersio n dcat : Dataset This property refers to a related Dataset that is a version , edition , or adaptation of the described Dataset . 0 . . n identifier dct : identifier rdfs : Literal This property contains the main identifier for the Dataset , e . g . the URI or other unique identifier in the context of the Catalogue . 0 . . n Property URI Range Usage note Card temporal coverage dct : temporal dct : PeriodOfTime This property refers to a temporal period that the Dataset covers . 0 . . n theme / catego ry dcat : theme , subproperty of dct : subject skos : Concept This property refers to a category of the Dataset . A Dataset may be associated with multiple themes . 0 . . n Fox , Gajderowicz , Lyu | 15 Property URI Range Usage note Card is referenced by dct : isReferenc edBy rdfs : Resource This property provides a link to a description of a relationship with another resource 0 . . n is version of dct : isVersion Of dcat : Dataset This property refers to a related Dataset of which the described Dataset is a version , edition , or adaptation . 0 . . n landing page dcat : landingPa ge foaf : Document This property refers to a web page that provides access to the Dataset , its Distributions and / or additional information . It is intended to point to a landing page at the original data provider , not to a page on a site of a third party , such as an aggregator . 0 . . n language dct : language dct : LinguisticSystem This property refers to a language of the Dataset . This property can be repeated if there are multiple languages in the Dataset . 0 . . n other identifier adms : identifie r adms : Identifier This property refers to a secondary identifier of the Dataset , such as MAST / ADS¹5 , DataCite ¹6 , DOI17 , EZID18 or W3ID19 . 0 . . n provenance dct : provenanc e dct : ProvenanceStatem ent This property contains a statement about the lineage of a Dataset . 0 . . n qualified attribution prov : qualified Attribution prov : Attribution This property refers to a link to an Agent having some form of responsibility for the resource 0 . . n qualified relation dcat : qualified Relation dcat : Relationship This property is about a related resource , such as a publication , that references , cites , or otherwise points to the dataset . 0 . . n related resource dct : relation rdfs : Resource This property refers to a related resource . 0 . . n release date dct : issued rdfs : Literal typed as xsd : date or xsd : dateTime This property contains the date of formal issuance ( e . g . , publication ) of the Dataset . 0 . . 1 sample adms : sample dcat : Distribution This property refers to a sample distribution of the dataset 0 . . n 16 | A Maturity Model for Urban Dataset Meta - data Property URI Range Usage note Card source dct : source dcat : Dataset This property refers to a related Dataset from which the described Dataset is derived . 0 . . n spatial resolution dcat : spatialRes olutionIn Meters xsd : decimal This property refers to the minimum spatial separation resolvable in a dataset , measured in meters . 0 . . n temporal resolution dcat : temporal Resolution xsd : duration This property refers to the minimum time period resolvable in the dataset . 0 . . n Type dct : type skos : Concept This property refers to the type of the Dataset . A controlled vocabulary for the values has not been established . 0 . . 1 update / modification date dct : modified rdfs : Literal typed as xsd : date or xsd : dateTime This property contains the most recent date on which the Dataset was changed or modified . 0 . . 1 version owl : versionInf o rdfs : Literal This property contains a version number or other version designation of the Dataset . 0 . . 1 version notes adms : version Notes rdfs : Literal This property contains a description of the differences between this version and a previous version of the Dataset . This property can be repeated for parallel language versions of the version notes . 0 . . n was generated by prov : wasGene ratedBy prov : Activity This property refers to an activity that generated , or provides the business context for , the creation of the dataset . 0 . . n Schema . org Schema . org contains a number of classes and properties relevant to documenting datasets . Google provides a guide 10 for developers to enable dataset discovery . It distinguishes between required schem . org properties 11 : A sample of the schema . org class definition sin given in Appendix A . • name – A descriptive name of a dataset ( e . g . , “Snow depth in Northern Hemisphere” ) • description – A short summary describing a dataset . 10 https : / / developers . google . com / search / docs / appearance / structured - data / dataset 11 https : / / github . com / ESIPFed / science - on - schema . org / blob / master / guides / Dataset . md Fox , Gajderowicz , Lyu | 17 And recommended schema . org properties : • url – Location of a page describing the dataset . • sameAs – Other URLs that can be used to access the dataset page . A link to a page that provides more information about the same dataset , usually in a different repository . • version – The version number or identifier for this dataset ( text or numeric ) . • isAccessibleForFree – Boolean ( true | false ) specifying if the dataset is accessible for free . • keywords – Keywords summarizing the dataset . • identifier – An identifier for the dataset , such as a DOI . ( text , URL , or PropertyValue ) . • variableMeasured – What does the dataset measure ? ( e . g . , temperature , pressure ) DQV Data Quality Vocabulary 12 is an extension of DCAT that focuses on “the quality of the data , how frequently is it updated , whether it accepts user corrections , persistence commitments etc . ” ( Albertoni & Isaac , 2016 ) . The following lists the core classes . The prefix “dqv” denotes th e namespace “http : / / www . w3 . org / ns / dqv # ” . • dqv : QualityAnnotation represents feedback and quality certificates given about the dataset or its distribution . • dct : Standard represents a standard the dataset or its distribution conforms to . • dqv : QualityPolicy represents a policy or agreement that is chiefly governed by data quality concerns . • dqv : QualityMeasurement represents a metric value providing quantitative or qualitative information about the dataset or distribution . • prov : Entity represents an entity involved in the provenance of the dataset or distribution . Figure 2 depicts the core classes and properties of DQV . 12 https : / / www . w3 . org / TR / vocab - dqv / 18 | A Maturity Model for Urban Dataset Meta - data Figure 2 . DQV Information Model ( from Albertoni & Isaac , 2016 ) FAIR Bahim et al . ( 2020 ) define a FAIR ( Findable , Accessible , Interoperable , Retrievable ) Data Maturity Model . The model partitions a set of FAIRness dataset data and meta - data indicators into Essential , Important and Useful . Table 13 , Table 14 , and Table 15 list the indicators for each partition . For the purposes of the Catalogue Meta - Date Maturity Model , few of the indicators refer directly to the types of information needed to identify a relevant dataset . Never the less , most of the indicators relevant whe n choosing amongst alternative datasets , i . e . , the more “fair” the dataset is , the easier it will be to use . In the tables , we identify in blue the indicators that are relevant to our maturity model . We identify in green indicators that are satisfied by the adoption of our maturity model . Table 13 . Essential FAIR Indicators . FAIR ID Indicator F1 RDA - F1 - 01M Metadata is identified by a persistent identifier F1 RDA - F1 - 01D Data is identified by a persistent identifier F1 RDA - F1 - 02M Metadata is identified by a globally unique identifier F1 RDA - F1 - 02D Data is identified by a globally unique identifier F2 RDA - F2 - 01M Rich metadata is provided to allow discovery F3 RDA - F3 - 01M Metadata includes the identifier for the data Fox , Gajderowicz , Lyu | 19 FAIR ID Indicator F4 RDA - F4 - 01M Metadata is offered in such a way that it can be harvested and indexed A1 RDA - A1 - 02M Metadata can be accessed manually ( i . e . , with human intervention ) A1 RDA - A1 - 02D Data can be accessed manually ( i . e . , with human intervention ) A1 RDA - A1 - 03M Metadata identifier resolves to a metadata record A1 RDA - A1 - 03D Data identifier resolves to a digital object A1 RDA - A1 - 04M Metadata is accessed through standardised protocol A1 RDA - A1 - 04D Data is accessible through standardised protocol A1 . 1 RDA - A1 . 1 - 01M Metadata is accessible through a free access protocol A2 RDA - A2 - 01M Metadata is guaranteed to remain available after data is no longer available R1 RDA - R1 - 01M Plurality of accurate and relevant attributes are provided to allow reuse R1 . 1 RDA - R1 . 1 - 01M Metadata includes information about the licence under which the data can be reused R1 . 3 RDA - R1 . 3 - 01M Metadata complies with a community standard R1 . 3 RDA - R1 . 3 - 01D Data complies with a community standard R1 . 3 RDA - R1 . 3 - 02M Metadata is expressed in compliance with a machine - understandable community standard Table 14 . Important FAIR Indicators . FAIR ID Indicator A1 RDA - A1 - 01M Metadata contains information to enable the user to get access to the data A1 RDA - A1 - 05D Data can be accessed automatically ( i . e . by a computer program ) A1 . 1 RDA - A1 . 1 - 01D Data is accessible through a free access protocol I1 RDA - I1 - 01M Metadata uses knowledge representation expressed in standardised format I1 RDA - I1 - 01D Data uses knowledge representation expressed in standardised format I1 RDA - I1 - 02M Metadata uses machine - understandable knowledge representation I1 RDA - I1 - 02D Data uses machine - understandable knowledge representation I2 RDA - I2 - 01M Metadata uses FAIR - compliant vocabularies 20 | A Maturity Model for Urban Dataset Meta - data FAIR ID Indicator I3 RDA - I3 - 01M Metadata includes references to other metadata I3 RDA - I3 - 03M Metadata includes qualified references to other metadata R1 . 1 RDA - R1 . 1 - 02M Metadata refers to a standard reuse licence R1 . 1 RDA - R1 . 1 - 03M Metadata refers to a machine - understandable reuse licence R1 . 2 RDA - R1 . 2 - 01M Metadata includes provenance information according to community - specific standards R1 . 3 RDA - R1 . 3 - 02D Data is expressed in compliance with a machine - understandable community standard Table 15 . Useful FAIR Indicators . FAIR ID Indicator A1 . 2 RDA - A1 . 2 - 01D Data is accessible through an access protocol that supports authentication and authorisation I2 RDA - I2 - 01D Data uses FAIR - compliant vocabularies I3 RDA - I3 - 01D Data includes references to other data I3 RDA - I3 - 02M Metadata includes references to other data I3 RDA - I3 - 02D Data includes qualified references to other data I3 RDA - I3 - 04M Metadata include qualified references to other data R1 . 2 RDA - R1 . 2 - 02M Metadata includes provenance information according to a cross - community language DDI Data Documentation Initiative ( DDI ) has developed standards for documenting social sciences datasets ( www . ddialliance . org ) . It provides a deeper dive into the properties describing the content of datasets and how they were generated . ODRL Open Digital Rights Language 13 ( Iannella & Villata , 2018 ) “is a policy expression language that provides a flexible and interoperable information model , vocabulary , and encoding mechanisms for representing statements about the usage of content and services . ” It “represents Policies that express Permissions , Prohibitions and Duties related to the usage of Asset resources . The Information Model ( Figure 3 ) explicitly expresses what is allowed and what is not allowed by the Policy , as well as other terms , requirements , and parties involved . ” 13 https : / / www . w3 . org / TR / odrl - model / Fox , Gajderowicz , Lyu | 21 Figure 3 . ODRL Information Model ( from Iannella & Villata ( 2018 ) ) . A Maturity Model for Dataset Meta - Data As identified in the previous section , there is a plethora of information that a dataset producer could provide . But as observed by Gebru et al . ( 2021 ) not all is available or may take a significant effort to provide . Given the various backgrounds of dataset providers , and their depth of knowledge of the dataset they wish to catalogue , our goal is to simplify the process while assuring that the most important meta - data is captured at the outset . Our method of simplifying the process is to define a maturity model that identifies and stratifies the meta - data that should be provided by a dataset producer . By following the steps of the maturity model , the probability of acquiring the most important meta - data from the dataset producer is increased . Secondly , by presenting the meta - data requirements in a stratified format , it limits the perceived size and complexity of the task for the dataset producer . Given the variety of information that can be used to document a dataset , we have chosen to categorize the meta - data properties for each maturity level . Similar to the categories identified in Assaf et al . ( 2015 ) , we define the following categories : 1 . Content such as title and description 2 . Access Information such as the URL and license . 3 . Ownership information such as author and maintainer . 4 . Provenance information such as creation date and versioning . 5 . Temporal / Geospatial information such as geographic coverage and temporal span and granularity . 22 | A Maturity Model for Urban Dataset Meta - data 6 . Statistical information property distribution and number of entities . 7 . Quality information . Both FAIRness principles and use of indigenous data guidance are spread throughout . Where appropriate DCAT properties and classes are used for compatibility . Based on DCAT , a dataset is a dcat : Dataset object . A specific version of the dataset is a dct : Distribution . These are related by the property : dct : distribution ( dctat : Dataset , dcat : Distribution ) . Depending on the domain of the property , it the data resource being catalogued is either dct : Dataset or the dcat : Distribution related to the dct : Dataset . The following prefixes are used in the model . Table 16 . Maturity Model Prefixes . Prefix URI adms http : / / www . w3 . org / ns / adms # cc http : / / creativecommons . org / ns # cudr http : / / data . urbandatacentre . ca / dc http : / / purl . org / dc / elements / 1 . 1 / dcat http : / / www . w3 . org / ns / dcat # dct http : / / purl . org / dc / terms / dqv http : / / www . w3 . org / ns / dqv # fair http : / / ontology . eil . utoronto . ca / fair # foaf http : / / xmlns . com / foaf / 0 . 1 / oa http : / / www . w3 . org / ns / oa # odrl http : / / www . w3 . org / ns / odrl / 2 / owl http : / / www . w3 . org / 2002 / 07 / owl # prov http : / / www . w3 . org / ns / prov # rdfs http : / / www . w3 . org / 2000 / 01 / rdf - schema # sc https : / / schema . org / skos http : / / www . w3 . org / 2004 / 02 / skos / core # vann http : / / purl . org / vocab / vann / vcard http : / / www . w3 . org / 2006 / vcard / ns # void http : / / rdfs . org / ns / void xsd http : / / www . w3 . org / 2001 / XMLSchema # Fox , Gajderowicz , Lyu | 23 Maturity Level 1 Maturity Level 1 is guided by our review of dataset search behaviours . The goal is to minimize the initial amount of information provided by the cataloguer to that which is most often used in searching for datasets . Hence level 1 is mostly focused on descriptions of what the dataset is about supplemented with temporal and geospatial information . Note that DCAT - AP’s mandatory attributes are a subset of level 1 . Table 17 . Dataset Maturity Level 1 Definition . Category Description Property Value Restriction Content Domain / Topic dcat : theme skos : Concept Title dct : title rdfs : Literal Description dct : description rdfs : Literal Keywords dcat : keyword rdfs : Literal Provenance Published date dct : issued xsd : datetime Temporal / Geospatial Time period data spans dct : temporal dct : PeriodOfTime Geospatial area data spans dct : spatial dct : Location Notes : • skos : Concept 14 : A SKOS concept can be viewed as an idea or notion ; a unit of thought . However , what constitutes a unit of thought is subjective , and this definition is meant to be suggestive , rather than restrictive . Maturity Level 2 Maturity Level 2 focuses primarily on access and includes the remaining attributes in the DCAT - AP recommended properties . Table 18 . Dataset Maturity Level 2 Definition . Category Description Property Value Restriction Content Unique identifier for the dataset . Often assigned by creator or publisher . dct : identifier rdfs : Literal Access Access Category : Open , Closed , Service accessCategory { open , closed , service } License dct : license dct : LicenseDocument Location of dataset : where it can be accessed dcat : accessURL rdfs : Resource 14 https : / / www . w3 . org / TR / skos - reference / # concepts 24 | A Maturity Model for Urban Dataset Meta - data Category Description Property Value Restriction What organization or community this is visible to dct : description rdfs : Literal Access service specification dcat : accessService dcat : DataService Ownership Owner dct : rightsHolder foaf : Agent Contact point dcat : contactPoint vcard : Kind Publisher dct : publisher foaf : Agent Creator dct : creator foaf : Agent Maturity Level 3 Maturity Level 3 focuses primarily on additional content and versioning information . It begins the incorporation of FAIR principles and expands on the temporal and geospatial resolution of the data . Table 19 . Dataset Maturity Level 3 Definition . Category Description Property Value Restriction Content Documentation dcat : landingPage foaf : Document Language dct : language dct : Linguistic System Data is identified by a persistent identifier fair : hasRDA _ F1 _ 01D xsd : boolean Data is identified by a globally unique identifier fair : hasRDA _ F1 _ 02D xsd : boolean Access Format ( file type if relevant ) dct : format dct : MediaTypeOrExtent URL for a downloadable file dcat : downloadURL rdfs : Resource Provenance Version of the dataset owl : versionInfo rdfs : Literal Version notes adms : versionNotes rdfs : Literal Link to dataset that it is a version of dct : isVersionOf dcat : Dataset Link to datasets that are versions of it dct : hasVersion dcat : Dataset Provenance of the data dct : provenance dct : ProvenanceStatement Fox , Gajderowicz , Lyu | 25 Category Description Property Value Restriction Provenance document location prov : wasQuotedFrom prov : Entity Temporal / Geospatial Temporal resolution dcat : temporalResolution xsd : duration Spatial resolution in meters dcat : spatialResolutionIn Meters xsd : decimal Spatial resolution in geographical regions : spatialResolutionInRegion sc : AdminstrativeArea Notes : • prov : wasQuotedFrom : A property of the dct : ProvenanceStatement object ( via the dct : provenance property ) . Maturity Level 4 Maturity level 4 focuses on whether the dataset contains data on individuals ( versus aggregate data ) . It also includes properties relevant to the identification of whether the dataset contains indigenous data , which may have stricter privacy rules . Table 20 . Dataset Maturity Level 4 Definition . Category Description Property Value Restriction Content Contains data about individuals containsIndividualData xsd : boolean Contains data about identifiable individuals containsIdentifiableIndividualData xsd : boolean Contains Indigenous Data containsIndigenousData xsd : boolean Access Limits on use ( e . g . , academic purposes – going beyond license ) odrl : hasPolicy odrl : Policy Ownership Indigenous community permission ( who gave permission ) indigenousRightsHolder foaf : Agent Temporal / Geospatial Indigenous communities from which data is derived spatialIndigenousCommunity ( sub - property of dct : spatial ) dct : Location Notes : 26 | A Maturity Model for Urban Dataset Meta - data • odrl : Policy 15 : A non - empty group of Permissions ( via the permission property ) and / or Prohibitions ( via the prohibition property ) and / or Duties ( via the obligation property ) . The Policy class is the parent class to the Set , Offer , and Agreement subclasses . For odrl : properties , the data resource being catalogued is assumed to be an instance of the odrl : Asset class . • containsIndividualData : A boolean value indicating whether the data holds individualized data ? If yes , the dataset is aggregated at the individual level . • containsIdentifiableIndividualData : Does the data hold identifiable individual data that can be used to uniquely identify an individual data was collected about ? If yes , the dataset is not anonymized . • containsIndigenousData : Does the data hold data about Indigenous communities ? If yes , the dataset should comply with OCAP principles ( Ownership , Control , Access , Possession ) . See https : / / fnigc . ca / ocap - training / for more information . Table 21 . IndigenousAgent Class Definition . ClassProperty Property Value Restriction IndigenousAgent rdfs : subClassOf foaf : Agent • IndigenousAgent : A subclass of foaf : Agent that is an Indigenous agent . • Table 22 . indigenousRightsHolder Property Definition . ClassProperty Property Value Restriction indigenousRightsHolder rdfs : subPropertyOf dct : rightsHolder • indigenousRightsHolder : An agent that has the rights to manage access rights to indigenous data . That person can be Indigenous themselves or a non - Indigenous agent that acts as the steward for access rights to the data . Table 23 . spatialIndigenousCommunity Property Definition . ClassProperty Property Value Restriction spatialindigenousCommunity rdfs : subPropertyOf dct : spatial • spatialIndigenousCommunity : A geospatial area occupied by or representative of an Indigenous community . Maturity Level 5 Maturity Level 5 focuses solely on capturing additional meta - data related to FAIR principles ( Findable , Accessible , Interoperable , Retrievable ) . 15 https : / / www . w3 . org / TR / odrl - model / # policy Fox , Gajderowicz , Lyu | 27 Table 24 . Dataset Maturity Level 5 Definition . Category Description Property Value Restriction Content Data complies with a community standard fair : hasRDA _ R1 _ 3 _ 01D xsd : boolean Data uses knowledge representation expressed in standardised format fair : hasRDA _ I1 _ 01D xsd : boolean Data uses machine - understandable knowledge representation fair : hasRDA _ I1 _ 02D xsd : boolean Data uses FAIR - compliant vocabularies fair : hasRDA _ I2 _ 01D xsd : boolean Data includes references to other data fair : hasRDA _ I3 _ 01D xsd : boolean Access Data is accessible through an access protocol that supports authentication and authorisation fair : hasRDA _ A1 _ 2 _ 01D xsd : boolean Data can be accessed manually ( i . e . , with human intervention ) fair : hasRDA _ A1 _ 02D xsd : boolean Data identifier resolves to a digital object fair : hasRDA _ A1 _ 03D xsd : boolean Data is accessible through standardised protocol fair : hasRDA _ A1 _ 04D xsd : boolean Data can be accessed automatically ( i . e . by a computer program ) fair : hasRDA _ A1 _ 05D xsd : boolean Data is accessible through a free access protocol fair : hasRDA _ A1 _ 1 _ 01D xsd : boolean Maturity Level 6 Maturity Level 6 provides basic statistics and data quality . The attributes are derived from VOID and DQV . Table 25 . Dataset Maturity Level 6 Definition . Category Description Property Value Restriction Statistical If tabular dataset , number of rows void : rows xsd : positiveInteger If tabular dataset , number of columns void : columns xsd : positiveInteger 28 | A Maturity Model for Urban Dataset Meta - data Category Description Property Value Restriction If tabular dataset , the number of filled - in data cells void : cells xsd : positiveInteger If RDF dataset , total number of triples void : triples xsd : postiveInteger If RDF dataset , total number of entities in the dataset void : classes xsd : postiveInteger if RDF dataset , total number of properties in the dataset void : properti es xsd : postiveInteger Quality Description of data quality . dqv : hasQualit yAnnotation dqv : QualityAnnota tion Metrics for data quality property , like completeness , accuracy , etc 16 dqv : inDimen sion dqv : Dimension Notes : • dvq : inDimension : Represents the dimensions a quality metric , certificate and annotation allow a measurement of . • dqv : QualityAnnotation 17 : Represents quality annotations , including ratings , quality certificates or feedback that can be associated to datasets or distributions . Quality annotations must have one oa : motivatedBy statement with an instance of oa : Motivation ( and skos : Concept ) that reflects a quality assessment purpose . This instance is defined as dqv : qualityAssessment . • dvq : Dimension 18 : Represents criteria relevant for assessing quality . Each quality dimension must have one or more metric to measure it . A dimension is linked with a category using the dqv : inCategory property . Implementation The Maturity Model has been implemented as CKAN 19 plugin , CKANext - udc 20 , to integrate the maturity model into the CKAN dataset cataloguing process . The plugin facilitates the inclusion of custom fields , allows for their reordering , and categorizes them into distinct maturity levels . It also allows for integration with a graph database to store each catalogue entry as a knowledge graph built on top of the ontology . The maturity model itself is defined as an ontology 21 and implemented in OWL . 16 https : / / www . w3 . org / TR / vocab - dqv / # examples 17 https : / / www . w3 . org / TR / vocab - dqv / # dqv : QualityAnnotation 18 https : / / www . w3 . org / TR / vocab - dqv / # dqv : Dimension 19 CKAN : https : / / docs . ckan . org / 20 CKAN Plugin : https : / / github . com / csse - uoft / ckanext - udc 21 Dataset Maturity Model Ontology : https : / / github . com / csse - uoft / maturity - model - ontology Fox , Gajderowicz , Lyu | 29 Figure 4 . CUDR Plugin ( CKANext - udc ) Architecture . The CKAN extension architecture , shown in Figure 4 , is developed as a CKAN plugin . The plugin interacts with the CKAN architecture by modifying how catalogue metadata is collected from the user , how it is displayed to the user for data entry and viewing , and how data is stored in the database . Data entry views allow for grouping and entering maturity model properties seamlessly in CKAN . First , the plugin refines the terminology by renaming “Dataset” to “Catalogue Entry” and “Resource” to “Dataset , ” a shift that is more in line with the maturity model ' s representation . Second , the maturity model is seamlessly integrated into both the edit and view pages of each catalogue entry . Third , the plugin introduces an advanced filter for improved search of the catalogue search . Beyond these template changes , the plugin adds more depth by overriding the default CKAN logic for managing data . For instance , when creating , updating , or deleting a catalogue entry , additional logic ensures that the knowledge graph is simultaneously updated based on the predefined mapping configuration between CKAN fields and the ontology . Lastly , the plugin enhances CKAN ' s foundational model by integrating the maturity model fields into CKAN’s default dataset metadata model . The new plugin and CKAN’s original model reside in the Postgres database . The plugin provides the ability to store catalogue data in a knowledge graph , as discussed below . By storing the metadata in both a knowledge graph and CKAN’s internal database allows the plugin to be backward compatible with previous versions of CKAN , to version 2 . 11 . The plug maintains all existing CKAN functionalities , including its API endpoint for importing and exporting catalogue data . Advanced users retain the ability to manage catalogue entries programmatically through CKAN’s Python interface and API - based scripts . Maturity Model Views A user can enter a new catalogue entry and its maturity levels properties , as shown in Figure 5 . Each maturity level can be completed either partially or entirely . The plugin computes and displays the maturity levels’ completion percentage for a catalogue entry . Maturity Model properties defined in the ontology are represented as text fields , date - time fields , or dropdown - select fields . Values in dropdown - select fields can either be entered manually or fetched from an ontology that defined the property , ensuring that the metadata aligns with imported ontologies . For example , the dataset file type in level 3 is represented as an instance of the class dct : MediaTypeOrExtent . As such , it may include any of the types in IANA 22 , including simple 22 Internet Assigned Numbers Authority ( IANA ) : https : / / www . iana . org / assignments / media - types / media - types . xhtml 30 | A Maturity Model for Urban Dataset Meta - data formats such as “json” and “csv” , application formats such as “pdf” and “vnd . ms - excel” , or complex formats , such as “ace + json” , “csvm + json” , “csv - schema” , and so on . The formats are displayed to a user during the data entry step as one of the possible options . Figure 5 . Maturity Model entry form , with six maturity levels and percentage of completed fields . Maturity Model View Configuration Administrators have the flexibility to adjust the plugin settings directly from the web interface , including the data entry screen and mapping between entry fields and the maturity model properties . CKAN provides several predefined dataset properties , such as “title , ” “tags , ” “notes , ” “author , ” and more . The Maturity Model used by the plugin is defined in a configuration file ( JSON format ) , as illustrated in Figure 6 , to organize the layout and properties when they are entered and displayed . Each maturity level tab , as shown in Figure 5 , has a configuration entry under the “maturity _ model” dictionary key . Each maturity level has a “title , ” “name , ” and an array Fox , Gajderowicz , Lyu | 31 of “fields " that specify the level’s properties . Existing CKAN properties that are also specified in the maturity model are mapped to the model’s ontology properties . If the property is a CKAN property , “ckanField” is used and the property name is the value in “ckanField” . If the maturity model introduced a new property , the configuration requires a “name” and “label” entry in the “fields” key . { " maturity _ model " : [ { " title " : " Maturity Level 1 ( Basic Information ) " , " name " : " maturity _ level _ 1 " , " fields " : [ { / / Maturity Model Property " name " : " theme " , " label " : " Domain / Topic " . . . } , { / / CKAN Property " ckanField " : " title " . . . } . . . } ] } Figure 6 . CKAN Maturity Model configuration for data entry . Users can search for catalogue entries using a text search field or a filter applicable to several key maturity model properties , as shown in Figure 7a . Search functionality utilizes CKAN’s built - in support for Apache Solr library 23 for indexing and searching text data . Results are shown in the view list screen . For catalogue entries that match a filter or search query , a side panel , shown in Figure 7b , displays an aggregate sum for indexed properties . The aggregate results are limited to the subset of results that match the original query . By utilizing the text search and filter search , the plugin allows us to how users of the catalogue search for datasets . For example , free text search provides insights into how users refer to or spell various maturity model properties . Filter search provides us with similar monitoring capabilities but on a catalogue property level . Storing Dataset Maturity Models in a Knowledge Graph All catalogue entries , and their maturity model data , are stored in Postgres by CKAN . There is also an option to configure the CKAN plugin to connect with a graph database . The graph database uses the Maturity Model ontology as its schema to store catalogue entries . To do this , one must supply the necessary mappings to the data present in the knowledge graph . As catalogue entries are updated or deleted , the plugin produces corresponding SPARQL queries based on these mappings , ensuring that the knowledge graph remains in sync with CKAN ' s database . An illustrative example of this mapping configuration utilizes a structure reminiscent of JSON - LD in Figure 8 . For dynamic elements , such as generating an UUID value , the syntax allows one to provide a JavaScript helper function 24 call , such as “ generate _ uuid ( ) , ” as demonstrated below . 23 Apache Solr library : https : / / solr . apache . org / 24 The plugin allows for custom helper functions to be defined in “ ckanext / udc / graph / mapping _ helpers . py “ 32 | A Maturity Model for Urban Dataset Meta - data a ) Filter Search Screen ( entry screen ) b ) Filter Aggregation ( side panel ) Figure 7 . Maturity Model search capability . { " mappings " : { " @ context " : { / / Define various namespaces that are used below . " xsd " : " http : / / www . w3 . org / 2001 / XMLSchema # " , " dcat " : " http : / / www . w3 . org / ns / dcat # " , " foaf " : " http : / / xmlns . com / foaf / 0 . 1 / " , " dct " : " http : / / purl . org / dc / terms / " } , / / The URI of the catalogue entry , values in the curly bracket { } / / will be evaluated at runtime . ` ckanField ` is a dictionary / / and ` ckanField . id ` is a unique id of this catalogue entry . " @ id " : " http : / / data . urbandatacentre . ca / catalogue / { ckanField . id } " , / / The RDF Type of the catalogue " @ type " : " http : / / data . urbandatacentre . ca / Catalogue " , / / Author name and email are mapped into a ` foaf : Agent ` instance . Contents in the / / curly bracket { } will be evaluated in the runtime . " dct : creator " : { " @ id " : " http : / / data . urbandatacentre . ca / creator / { generate _ uuid ( ) } " , " @ type " : " foaf : Agent " , " foaf : mbox " : " { ckanField . author _ email } " , " foaf : name " : " { ckanField . author } " } , / / title is mapped to ` dct : title ` " dct : title " : { " @ type " : " xsd : string " , " @ value " : " { ckanField . title } " } , / / Published Date is mapped to ` dct : issued ` " dct : issued " : { " @ type " : " xsd : date " , " @ value " : " { to _ date ( published _ date ) } " / / to _ date ( … ) is a helper function } } } Figure 8 . CKAN Maturity Model configuration for data entry . Fox , Gajderowicz , Lyu | 33 Evaluation Over a period of six months , a team of five cataloguers scanned the web for Canadian sourced urban - related datasets , both open and closed , primarily for the themes of “Transportation , ” “Housing , ” “Bylaws , ” and “Culture and Tourism” 25 . 747 datasets were catalogued of which 95 % were in the three themes excluding Bylaws . Figure 9 shows a word cloud of keywords associated with each catalogue entry . The keywords have a strong correlation with the selected themes . For each dataset , the cataloguers extracted as much information as available to complete the meta - data properties in maturity model . Figure 9 . Word cloud of catalogue keywords . The evaluation ascertains which dataset properties were most readily available , and rank maturity levels based on this availability . Towards this end , we first evaluate the completion rate of categories of information to give us a sense of what type of information is readily available to our cataloguers . Figure 10 shows the completion percentage for each of the seven categories of information . As was expected , in general , “C ontent ” and “A ccess ” related properties are most common , at about 80 % . Information about the location and times in the “Temp - Geo” , i . e . the temporal and geospatial coverage of the dataset , is available 58 % of the time . Properties related to the “O wnership ” of the dataset have a completion rate of 45 % . While “O wnership ” and “A ccess ” may be closely related from a licensing perspective , our focus during this study has been on open datasets . Hence , having access to the dataset may be more important than knowing the owner . This is reflected in the fact that “Access” properties are completed 30 - 35 % more often than “Ownership” properties . Properties indicating the " Quality ” of the dataset require some quality metric provided by the publisher . As can be seen , this information is rarely available at 24 % . The completion rate of “P rovenance ” is also low , at 18 % . This is due to the fact that provenance information is rarely provided , indicating that it may be considered as nonessential by dataset publishers . Finally , we note that “S tatistics ” category , indicating the size of the dataset , has the lowest completion rate at 10 % with a relatively high standard deviation of 20 , indicating this information is the most difficult to obtain . 25 Prior to cataloguing Canadian urban datasets , two studies were undertaken to ascertain data requirements for research in the themes of Transportation ( Pandya , 2023a ) and Housing ( Pandya , 2023b ) . 34 | A Maturity Model for Urban Dataset Meta - data Figure 10 . Percentage of Category Completion . Finally , our evaluation focuses on ascertaining , for each level of the maturity model , the percentage of meta - data properties that are available . The percentage of completed properties in each level is given in Figure 11 . Maturity Level 1 emphasizes the metadata predominantly employed for dataset searches . The completion rate for this level stands at an average of 92 % , accompanied by a standard deviation of 15 . Maturity Level 2 focuses on access and ownership meta - data . This level records a completion rate of 61 % and a standard deviation of 14 . Level 3 expands on content , provenance and temporal / geospatial information . It registered a 48 % completion rate and a standard deviation of 17 . Level 4 assesses the existence of data on individuals versus aggregates , any limits on use , and whether data pertinent to Indigenous communities is captured or not . Level 4 has a completion rate of 46 % an associated standard deviation of 16 % . It should be noted , however , that Indigenous - related properties are filled in at a rate of 9 % , while other properties are filled in at a rate of 83 % , averaging out to 46 % . Maturity Level 5 focuses on whether a dataset satisfies FAIR principles and has a high completion rate of 83 % , with an associated standard deviation of 30 . Maturity Level 6 is centred on the statistical and quality properties of the data , including the number of triples and concepts in triple stores or the row and column count in tabular datasets . The completion metric for this level is low at 13 % , with a high standard deviation relative to the mean at 16 . Figure 11 . Percentage of Maturity Level Completion . Fox , Gajderowicz , Lyu | 35 In accordance with our expectations , the properties of Maturity Level 1 were more readily available to cataloguers compared to those of Level 2 . The identification efforts for Level 3 and Level 4 are similar , prompting a hypothesis that their positions might be interchangeable . Obtaining Level 5 properties were easily obtainable by the curators through an examination of accompanying documentation or , if applicable , a cursory inspection of the dataset itself . Due to the importance of FAIR principles in finding accessible and usable datasets and the ease with which the properties were found , prompts the hypothesis that Level 5’s position should be moved higher in the maturity model . However , the high standard deviation indicates that this availability varied greatly , and further analysis is needed . Maturity Level 6 manifested the most minimal completion rate . This can be attributed , initially , to the bifurcation of the statistical properties in Level 6 into two dataset categories : triple store and tabular . Thus , a completion rate of 100 % would be contingent upon the existence of multimodal datasets encompassing both types . Furthermore , discerning this information mandates access to and enumeration of data points specific to their respective modes , a task that wasn ' t uniformly viable . Based on our evaluation , we note that the basic descriptive properties of datasets in Level 1 are , in fact , the easiest to identify and can used as the initial search criteria for datasets . FAIR properties of datasets in Level 5 are also easy to obtain as they require less effort and are often found in documentation . However , with a high standard deviation , completed information varied greatly . Descriptive properties at Level 3 are similarly obtainable to those in Level 4 . We again note that Level 4 has a uneven distribution amongst its properties , with 86 % completion for non - Indigenous properties and 9 % for Indigenous - related properties . This indicates that finding information about accessing the datasets and their provenance requires as much effort as identifying the dataset’s aggregation level and access limits , but not whether it captures data about Indigenous communities . Finally , the low completion score of Level 6 properties indicates that the dual nature of the properties requires a separation of modality categories , which are counted independently to better capture completion rates , and that description for the quality of the data is not readily available . Conclusion This paper highlights the challenges of finding relevant data despite the abundance of available data . It discusses the obstacles in finding data , such as poor metadata , inappropriate data presentation , and difficulty locating the desired data . We define the problem of dataset retrieval as determining the most relevant datasets based on user queries . The paper also emphasizes the issue of dataset creators needing to gain knowledge about the appropriate metadata to define and select for their datasets . The complexity of the task is exemplified by the extensive range of questions and properties specified in datasheets and the various vocabularies like DCAT , schema . org , PROV , and DQV . The survey of dataset search use cases identified open problems related to metadata , such as identifying valuable metadata for users , tools for creating and maintaining metadata , and automatic annotation and linkage of datasets to global ontologies . To address the challenge of documenting datasets , this paper proposes a dataset metadata maturity model . This model follows the concept of maturity models in software engineering and suggests a sequence of levels of metadata development capability . Here , the distinction is made between examining the contents of a dataset directly and examining its metadata , with the latter being the focus of this paper . The base case has no metadata , and subsequent levels are meant to define increasingly sophisticated metadata capabilities . The goal is to strike a balance between the effort required to document a dataset and the provision of sufficient metadata for discovery , determining relevance , and understanding dataset usage . The proposed dataset metadata maturity model serves as a guide for dataset creators in defining and selecting appropriate metadata . It considers various dimensions and maturity levels . The methodology involved reviewing the literature on dataset search behaviours and analyzing the frequency of information types searched for . Existing relevant vocabularies and frameworks like FAIR and OCAP are also taken into account . The maturity model consists of seven dimensions ; 36 | A Maturity Model for Urban Dataset Meta - data namely content , access information , ownership , provenance , temporal / geospatial information , statistical information , and quality information . These dimensions are further stratified into six maturity levels , with each level incorporating additional metadata elements . The Maturity Model has been incorporated into CKAN through a plugin named CKANext - udc . This plugin enhances the dataset cataloguing process by introducing custom fields categorized into different maturity levels and rearranging them on the user interface as needed . Moreover , it integrates with a graph database , storing each catalogue entry ' s maturity model data as a knowledge graph underpinned by the Maturity Model ontology . The ontology is executed in OWL , and the plugin adjusts the CKAN system in various ways , from data collection to presentation and storage . Notably , the terminology is adjusted to match the maturity model , enabling advanced filtering for better search . The plugin also modifies default CKAN logic , ensuring that when catalogue entries change , the knowledge graph is updated accordingly . All conventional CKAN features , including the API endpoint for data import and export , are preserved , and advanced users can still manage entries using CKAN ' s Python interface and API scripts . References Albertoni , R . & Isaac , A . ( 2016 ) . Data on the Web Best Practices : Data Quality Vocabulary : W3C Working Group Note 14 December 2016 . Retrieved from https : / / www . w3 . org / TR / vocab - dqv / Albertoni , R . , Browning , D . , Cox , S . , Beltran , A . G . , Perego , A . , and Winstanley , P . , ( 2023 ) , Data Catalog Vocabulary ( DCAT ) – Version 3 , W3C Working Draft 07 March 2023 . Retrieved from https : / / www . w3 . org / TR / vocab - dcat - 3 / Albertoni , R . and Isaac , A . , ( 2016 ) , Data on the Web Best Practices : Data Quality Vocabulary , W3C Working Group Note 15 December 2016 . Retrieved from https : / / www . w3 . org / TR / vocab - dqv / Assaf , A . , Troncy , R . , and Senart , A . HDL Towards a harmonized dataset model for open data portals . In PROFILES 2015 , 2 nd International Workshop on Dataset Profiling & Federated Search for Linked Data , Main conference ESWC15 , 31 May - 4 June 2015 , Portoroz , Slovenia . CEUR - WS . org Bahim , C . , et al . 2020 . The FAIR Data Maturity Model : An Approach to Harmonise FAIR Assessments . Data Science Journal , 19 : 41 , pp . 1 – 7 . Chapman , A . , Simperl , E . , Koesten , L . , Konstantinidis , G . , Ibáñez , L . D . , Kacprzak , E . , & Groth , P . ( 2020 ) . Dataset search : a survey . The VLDB Journal , 29 ( 1 ) , 251 - 272 . Chen , J . , Wang , X . , Cheng , G . , Kharlamov , E . , & Qu , Y . ( 2019 , November ) . Towards more usable dataset search : from query characterization to snippet generation . In Proceedings of the 28 th ACM International Conference on Information and Knowledge Management ( pp . 2445 - 2448 ) . Chiu , T . H . , Chen , H . L . , & Cline , E . ( 2023 ) . Metadata implementation and data discoverability : A survey on university libraries’ Dataverse portals . The Journal of Academic Librarianship , 49 ( 4 ) , 102722 . Chua , U . C . , Santiago , K . L . , Ona , I . B . M . , Peña , R . M . N . , Marasigan , G . Z . S . , Delos Reyes , P . G . A . , and Samson , B . P . V . ( 2020 ) , AsianChi’20 , ACM . Fox , Gajderowicz , Lyu | 37 Cooper A , Gagnon M , Leahey A , Paquette - Bigras E , Perrier L , Steeleworthy M , Taylor S . Dataverse North Metadata Best Practices Guide . 2019 . Retrieved from https : / / portagenetwork . ca / wp - content / uploads / 2019 / 04 / DVN - Metadata _ EN . pdf Elmqvist , N . ( 2011 , May ) . Embodied human - data interaction . In ACM CHI 2011 Workshop Embodied Interaction : Theory and Practice in HCI ( Vol . 1 , pp . 104 - 107 ) . Fenner , M . , Crosas , M . , Grethe , J . S . , Kennedy , D . , Hermjakob , H . , Rocca - Serra , P . , … & Clark , T . ( 2019 ) . A data citation roadmap for scholarly data repositories . Scientific data , 6 ( 1 ) , 1 - 9 . Gebru , T . , Morgenstern , J . , Vecchione , B . , Vaughan , J . W . , Wallach , H . , Iii , H . D . , & Crawford , K . ( 2021 ) . Datasheets for datasets . Communications of the ACM , 64 ( 12 ) , 86 - 92 . Hodgson , R . ( 2022 ) . “Quantities , Units , Dimensions and Types ( QUDT ) Sche – a – Version 2 . 1 . 21” . QUDT . org . Retrieved from https : / / www . qudt . org / doc / DOC _ SCHEMA - QUDT . html Iannella , R . , and Villata , S . ( 2018 ) , “ODRL Information Model 2 . 2” , W3C Recommendation 15 February 2018 . Retrieved from https : / / www . w3 . org / TR / odrl - model / Kacprzak , E . , Koesten , L . , Ibáñez , L . D . , Blount , T . , Tennison , J . , & Simperl , E . ( 2019 ) . Characterising dataset search — An analysis of search logs and data requests . Journal of Web Semantics , 55 , 37 - 55 . Koesten , L . M . , Kacprzak , E . , Tennison , J . F . , & Simperl , E . ( 2017 , May ) . The Trials and Tribulations of Working with Structured Data : - a Study on Information Seeking Behaviour . In Proceedings of the 2017 CHI conference on human factors in computing systems ( pp . 1277 - 1289 ) . Kunze , S . R . , & Auer , S . ( 2013 , September ) . Dataset retrieval . In 2013 IEEE Seventh International Conference on Semantic Computing ( pp . 1 - 8 ) . IEEE . Lebo , T . , Sahoo , S . , and McGuinness , D . ( 2013 ) . “PROV - O : The PROV Ontology – W3C Recommendation 30 April 2013” . Retrieved from https : / / www . w3 . org / TR / prov - o / Mecredy , G . , Sutherland , R . , & Jones , C . ( 2018 ) . First Nations data governance , privacy , and the importance of the OCAP® principles . International Journal of Population Data Science , 3 ( 4 ) . Neumaier , S . , Umbrich , J . , & Polleres , A . ( 2017 , January ) . Lifting data portals to the web of data . In Proceedings of the Workshop on Linked Data on the Web ( LDOW 2017 ) . https : / / ceur - ws . org / Vol - 1809 / Noy , N . , Burgess , M . , & Brickley , D . ( 2019 , May ) . Google Dataset Search : Building a search engine for datasets in an open Web ecosystem . In The World Wide Web Conference ( pp . 1365 - 1375 ) . Ojo , A . , Porwol , L . , Waqar , M . , Stasiewicz , A . , Osagie , E . , Hogan , M . , . . . & Zeleti , F . A . ( 2016 , October ) . Realizing the innovation potentials from open data : Stakeholders’ perspectives on the desired affordances of open data environment . In Working Conference on Virtual Enterprises ( pp . 48 - 59 ) . Springer , Cham . 38 | A Maturity Model for Urban Dataset Meta - data Osagie , E . , Waqar , M . , Adebayo , S . , Stasiewicz , A . , Porwol , L . , & Ojo , A . ( 2017 , June ) . Usability evaluation of an open data platform . In Proceedings of the 18 th annual international conference on digital government research ( pp . 495 - 504 ) . Pandya , M . ( 2023a ) . Transportation problems and data requirements : Report of the Transportation Panel . https : / / storage . googleapis . com / wzukusers / user - 12947767 / documents / c4609af45a0546deb1a4468616c808ad / UDC % 20Transportation % 20Panel % 20Report % 20v3 . pdf Pandya , M . ( 2023b ) . Affordable housing problems and data requirements : Report of the Affordable Housing Panel . https : / / storage . googleapis . com / wzukusers / user - 12947767 / documents / 32479acd560c4ed1be6d1f8a393d8846 / UDC % 20 - % 20Affordable % 20Housing % 20Panel % 20 Report % 20 - % 20v3 . pdf Paulk , M . C . , Curtis , B . , Chrissis , M . B . , & Weber , C . V . ( 1993 ) . Capability maturity model , version 1 . 1 . IEEE software , 10 ( 4 ) , 18 - 27 . Project Open Data : Retrieved from https : / / project - open - data . cio . gov / v1 . 1 / schema Rueda , L . , Fenner , M . , & Cruse , P . ( 2017 ) . Datacite : Lessons learned on persistent identifiers for research data . The International Journal of Digital Curation , 11 , 2 , pp . 39 – 47 . Russell , D . M . , Stefik , M . J . , Pirolli , P . , & Card , S . K . ( 1993 , May ) . The cost structure of sensemaking . In Proceedings of the INTERACT’93 and CHI’93 conference on Human factors in computing systems ( pp . 269 - 276 ) . Sansone , S . A . , Gonzalez - Beltran , A . , Rocca - Serra , P . , Alter , G . , Grethe , J . S . , Xu , H . , . . . & Ohno - Machado , L . ( 2017 ) . DATS , the data tag suite to enable discoverability of datasets . Scientific data , 4 ( 1 ) , 1 - 8 . Sharifpour , R . , Wu , M . , & Zhang , X . ( 2022 ) . Large - scale analysis of query logs to profile users for dataset search . Journal of Documentation . Thomas , W . , Gregory , A . , Gager , J . , Johnson , J . , and Wackerow , J . , ( 2014 ) , “Technical Document for DDI 3 . 2” , Data Documentation Initiative , Retrieved on 2 July 2016 from http : / / www . ddialliance . org / Specification / DDI - Lifecycle / 3 . 2 / XMLSchema / HighLevelDocumentation / DDI _ Part _ I _ TechnicalDocument . pdf Thornton , G . M . , & Shiri , A . ( 2021 ) . Challenges with organization , discoverability and access in Canadian open health data repositories . Journal of the Canadian Health Libraries Association / Journal de l ' Association des bibliothèques de la santé du Canada , 42 ( 1 ) . Van Nuffelen , B . ( 2022 ) ‘DCAT Application Profile for data portals in Europe Version 2 . 1 . 1’ . Retrieved on Accessed 22 May 2023 from https : / / github . com / SEMICeu / DCAT - AP / releases / tag / v2 . 1 . 1 White , R . W . , Dumais , S . T . and Teevan , J . ( 2009 ) , “Characterizing the influence of domain expertise on web search behavior ” , Proceedings of the Second ACM International Conference on Web Search and Data Mining , pp . 132 - 141 . Fox , Gajderowicz , Lyu | 39 Alexander , K . , Cyganiak , R . , Hausenblas , M . , and Zhao , J . ( 2016 ) , “Describing Linked Datasets with the VoID Vocabulary” , W3C Interest Group Note 03 March 2011 . Retrieved from https : / / www . w3 . org / TR / void / 40 | A Maturity Model for Urban Dataset Meta - data Appendix 1 : Schema . org Dataset Properties Figure 12 . Sample of schema . org Dataset Class Definition . Fox , Gajderowicz , Lyu | 41 Appendix 2 : Datasheets for Datasets Questions Category Question Motivation For what purpose was the dataset created ? Was there a specific task in mind ? Was there a specific gap that needed to be filled ? Who created the dataset ( for example , which team , research group ) and on behalf of which entity ( for example , company , institution , organization ) ? Who funded the creation of the dataset ? Composition What do the instances that comprise the dataset represent ( for example , documents , photos , people , countries ) ? Are there multiple types of instances ( for example , movies , users , and ratings ; people and interactions between them ; nodes and edges ) ? How many instances are there in total ( of each type , if appropriate ) ? Does the dataset contain all possible instances or is it a sample ( not necessarily random ) of instances from a larger set ? If the dataset is a sample , then what is the larger set ? Is the sample representative of the larger set ( for example , geographic coverage ) ? If so , please describe how this representativeness was validated / verified . If it is not representative of the larger set , please describe why not ( for example , to cover a more diverse range of instances , because instances were withheld or unavailable ) What data does each instance consist of ? “Raw” data ( for example , unprocessed text or images ) or features ? Is there a label or target associated with each instance ? Is any information missing from individual instances ? If so , please provide a description , explaining why this information is missing ( for example , because it was unavailable ) . This does not include intentionally removed information , but might include , for example , redacted text . Are relationships between individual instances made explicit ( for example , users’ movie ratings , social network links ) ? If so , please describe how these relationships are made explicit . Are there recommended data splits ( for example , training , development / validation , testing ) ? If so , please provide a description of these splits , explaining the rationale behind them . Are there any errors , sources of noise , or redundancies in the dataset ? Is the dataset self - contained , or does it link to or otherwise rely on external resources ( for example , websites , tweets , other datasets ) ? If it links to or relies on external resources , a ) are there guarantees that they will exist , and remain constant , over time ; b ) are there official archival versions of the complete dataset ( that is , including the external resources as they existed at the time the dataset was created ) ; c ) are there any restrictions ( for example , licenses , fees ) associated with any of the external resources that might apply to a dataset consumer ? Please provide descriptions of all external resources and any 42 | A Maturity Model for Urban Dataset Meta - data Category Question restrictions associated with them , as well as links or other access points , as appropriate . Does the dataset contain data that might be considered confidential ( for example , data that is protected by legal privilege or by doctor – patient confidentiality , data that includes the content of individuals’ non - public communications ) ? Does the dataset contain data that , if viewed directly , might be offensive , insulting , threatening , or might otherwise cause anxiety ? If so , please describe why . Does the dataset identify any subpopulations ( for example , by age , gender ) ? If so , please describe how these subpopulations are identified and provide a description of their respective distributions within the dataset . . Is it possible to identify individuals ( that is , one or more natural persons ) , either directly or indirectly ( that is , in combination with other data ) from the dataset ? Does the dataset contain data that might be considered sensitive in any way ( for example , data that reveals race or ethnic origins , sexual orientations , religious beliefs , political opinions or union memberships , or locations ; financial or health data ; biometric or genetic data ; forms of government identification , such as social security numbers ; criminal history ) ? Collection Process 21 . How was the data associated with each instance acquired ? Was the data directly observable ( for example , raw text , movie ratings ) , reported by subjects ( for example , survey responses ) , or indirectly inferred / derived from other data ( for example , part - of - speech tags , model - based guesses for age or language ) ? If the data was reported by subjects or indirectly inferred / derived from other data , was the data validated / verified ? If so , please describe how . 22 . What mechanisms or procedures were used to collect the data ( for example , hardware apparatuses or sensors , manual human curation , software programs , software APIs ) ? How were these mechanisms or procedures validated ? 23 . If the dataset is a sample from a larger set , what was the sampling strategy ( for example , deterministic , probabilistic with specific sampling probabilities ) ? 24 . Who was involved in the data collection process ( for example , students , crowdworkers , contractors ) and how were they compensated ( for example , how much were crowdworkers paid ) ? 25 . Over what timeframe was the data collected ? Does this timeframe match the creation timeframe of the data associated with the instances ( for example , recent crawl of old news articles ) ? If not , please describe the timeframe in which the data associated with the instances was created . 26 . Were any ethical review processes conducted ( for example , by an institutional review board ) ? If so , please provide a description of these review processes , including the outcomes , as well as a link or other access point to any supporting documentation . Fox , Gajderowicz , Lyu | 43 Category Question If the dataset does not relate to people , you may skip the remaining questions in this section . 27 . Did you collect the data from the individuals in question directly , or obtain it via third parties or other sources ( for example , websites ) ? 28 . Were the individuals in question notified about the data collection ? If so , please describe ( or show with screenshots or other information ) how notice was provided , and provide a link or other access point to , or otherwise reproduce , the exact language of the notification itself . 29 . Did the individuals in question consent to the collection and use of their data ? If so , please describe ( or show with screenshots or other information ) how consent was requested and provided , and provide a link or other access point to , or otherwise reproduce , the exact language to which the individuals consented . 30 . If consent was obtained , were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses ? If so , please provide a description , as well as a link or other access point to the mechanism ( if appropriate ) . 31 . Has an analysis of the potential impact of the dataset and its use on data subjects ( for example , a data protection impact analysis ) been conducted ? If so , please provide a description of this analysis , including the outcomes , as well as a link or other access point to any supporting documentation . Preprocessing / Cleaning / Labeling 33 . Was any preprocessing / cleaning / labeling of the data done ( for example , discretization or bucketing , tokenization , part - of - speech tagging , SIFT feature extraction , removal of instances , processing of missing values ) ? If so , please provide a description . If not , you may skip the remaining questions in this section . 34 . Was the “raw” data saved in addition to the preprocessed / cleaned / labeled data ( for example , to support unanticipated future uses ) ? If so , please provide a link or other access point to the “raw” data . 35 . Is the software that was used to preprocess / clean / label the data available ? If so , please provide a link or other access point . Uses 37 . Has the dataset been used for any tasks already ? If so , please provide a description . 38 . Is there a repository that links to any or all papers or systems that use the dataset ? If so , please provide a link or other access point . 39 . What ( other ) tasks could the dataset be used for ? 40 . Is there anything about the composition of the dataset or the way it was collected and preprocessed / cleaned / labeled that might impact future uses ? For example , is there anything that a dataset consumer might need to know to avoid uses that could result in unfair treatment of individuals or groups ( for example , stereotyping , quality of service issues ) or other risks or harms ( for 44 | A Maturity Model for Urban Dataset Meta - data Category Question example , legal risks , financial harms ) ? If so , please provide a description . Is there anything a dataset consumer could do to mitigate these risks or harms ? 41 . Are there tasks for which the dataset should not be used ? If so , please provide a description . Distribution 43 . Will the dataset be distributed to third parties outside of the entity ( for example , company , institution , organization ) on behalf of which the dataset was created ? If so , please provide a description . 44 . How will the dataset be distributed ( for example , tarball on website , API , GitHub ) ? Does the dataset have a digital object identifier ( DOI ) ? 45 . When will the dataset be distributed ? 46 . Will the dataset be distributed under a copyright or other intellectual property ( IP ) license , and / or under applicable terms of use ( ToU ) ? If so , please describe this license and / or ToU , and provide a link or other access point to , or otherwise reproduce , any relevant licensing terms or ToU , as well as any fees associated with these restrictions . 47 . Have any third parties imposed IP - based or other restrictions on the data associated with the instances ? If so , please describe these restrictions , and provide a link or other access point to , or otherwise reproduce , any relevant licensing terms , as well as any fees associated with these restrictions . 48 . Do any export controls or other regulatory restrictions apply to the dataset or to individual instances ? If so , please describe these restrictions , and provide a link or other access point to , or otherwise reproduce , any supporting documentation . Maintenance 50 . Who will be supporting / hosting / maintaining the dataset ? 51 . How can the owner / curator / manager of the dataset be contacted ( for example , email address ) ? 52 . Is there an erratum ? If so , please provide a link or other access point . 53 . Will the dataset be updated ( for example , to correct labeling errors , add new instances , delete instances ) ? If so , please describe how often , by whom , and how updates will be communicated to dataset consumers ( for example , mailing list , GitHub ) ? 54 . If the dataset relates to people , are there applicable limits on the retention of the data associated with the instances ( for example , were the individuals in question told that their data would be retained for a fixed period of time and then deleted ) ? If so , please describe these limits and explain how they will be enforced . 55 . Will older versions of the dataset continue to be supported / hosted / maintained ? If so , please describe how . If not , please describe how its obsolescence will be communicated to dataset consumers .