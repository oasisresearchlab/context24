Visualizing Topics with Multi - Word Expressions David M . Blei Department of Computer Science Princeton University Princeton , NJ 08540 , USA blei @ cs . princeton . edu John D . La ﬀ erty Computer Science Department Machine Learning Department Carnegie Mellon University Pittsburgh , PA 15213 , USA lafferty @ cs . cmu . edu July 6 , 2009 Abstract We describe a new method for visualizing topics , the distributions over terms that are automatically extracted from large text corpora using latent variable models . Our method ﬁnds signiﬁcant n - grams related to a topic , which are then used to help understand and interpret the underlying distribution . Compared with the usual visualization , which simply lists the most probable topical terms , the multi - word expressions provide a better intuitive impression for what a topic is “about . ” Our approach is based on a language model of arbitrary length expressions , for which we develop a new methodology based on nested permutation tests to ﬁnd signiﬁcant phrases . We show that this method outperforms the more standard use of χ 2 and likelihood ratio tests . We illustrate the topic presentations on corpora of scientiﬁc abstracts and news articles . 1 Introduction Topic models are hierarchical Bayesian models of document collections that explain an observed corpus with a small set of distributions over terms . When ﬁt to a corpus , these distributions tend to correspond to intuitive notions of the topics or themes that pervade the documents . Topic models have emerged as a powerful tool for unsupervised analysis of text . They have been extended for authorship [ 19 ] , citation [ 10 ] , and discourse segmentation [ 18 ] . Review articles of topic modeling provide further applications [ 21 ] . The idea behind topic modeling is to imagine a probabilistic process by which both a hidden thematic structure and observed collection of documents arises . Given the observed collection , one then “reverses” this process to determine the posterior distribution of the hidden thematic structure . Topic models build on and were inspired by techniques like latent semantic analysis ( LSA ) [ 2 ] and probabilistic latent semantic analysis ( pLSA ) [ 7 ] . However , LSA and pLSA do not embody generative probabilistic processes . By adopting a fully generative model , topic models such as latent Dirichlet allocation exhibit better generalization and are easily extendable [ 1 ] . Once they are ﬁt to a corpus , it is of interest to visualize the topics . These visualizations provide landmark descriptive statistics for understanding , exploring , and navigating through an otherwise unorganized collection of documents [ 11 ] . Typically , one visualizes each topic by simply listing the terms in order of decreasing probability . While a person can usually peruse these lists and intuit “meanings” of the topics , such visual - izations can be unsatisfying . Single terms are often part of indicative phrases , which are lost in a simple a r X i v : 0907 . 1013v1 [ s t a t . M L ] 6 J u l 2009 phase transitions , model , symmetry , point , quantum , systems , phase transition , phase diagram , system , order , ﬁeld , order , parameter , critical , two , transitions in , models , different , symmetry breaking , ﬁrst order , phenomena Annotated documents LDA topic # 11 Turbo topic # 11 phase , transitions , phases , transition , quantum , critical , symmetry , ﬁeld , point , model , order , diagram , systems , two , theory , system , study , breaking , spin , ﬁrst What is phase 11 transition 11 ? Why is there phase 11 transitions 11 ? These is are old 127 questions 127 people 170 have been asking 195 for many years 127 but get 153 few answers 127 We established 127 one general 11 theory 127 based 153 on game 153 theory 127 and topology 85 it provides 11 a basic 127 understanding 127 to phase 11 transitions 11 We proposed 11 a modern 127 deﬁnition 117 of phase 11 transition 11 based 153 on game 153 theory 127 and topology 85 of symmetry 11 group 184 which uniﬁed 135 Ehrenfests deﬁnition 117 A spontaneous 11 result 68 of this topological 85 phase 11 transition 11 theory 127 is the universal 14 equation 117 of coexistence 195 curve 195 in phase 11 diagram 11 it holds 153 both for classical 122 and quantum 11 phase 11 transition 11 This topological 85 phase 11 transition 11 theory 127 provides 11 a natural 117 generalization 117 of Landau 11 theory 127 of continuous 11 phase 11 transition 11 We developed 127 the holographic 68 topological 85 phase 11 action 68 of many body 127 system 11 to distinguish 11 diﬀerent 11 quantum 11 phases 11 Renormalization 68 group 184 transformation 135 was proved 117 to be a eﬃcient 122 tool 127 to study 11 the critical 11 phenomena 11 but its physical 127 meaning 11 is vague we ﬁnd that the renormalization 68 group 184 transformation 135 is actually 117 a game 153 process 153 between two 11 opposite 195 interaction 11 of the system 11 the universal 14 scaling 11 law 153 is a topological 85 constrain 68 of saddle 11 surface 170 around Nash 153 equilibrium 153 point 11 of the game 153 Further more we show 11 the quantum 11 phase 11 entanglement 11 reach 195 its maximal 184 point 11 at the critical 11 point 11 it is also the point 11 the elementary 127 excitations 11 or quasiparticles 11 transformed 135 into their antiparticles 195 so quantum 11 phase 11 transition 11 is a good 153 candidate 11 of qubit 86 We take 11 the BoseHubbard 11 model 11 as a main 127 example to show 11 the application 127 of this theory 127 the simple 153 applications 127 to plasmon 11 and Cooper 11 pair 195 theory 127 are also presented 127 In fact 127 game 153 theory 127 opens 11 a new 127 door 195 to many body 127 system 11 for the future 127 1 Figure 1 : An illustration of the turbo topics strategy . We ﬁrst estimate an LDA topic model ( under the word exchangeability assumption ) . We next annotate each word in the original corpus with its most likely posterior topic . This is illustrated at left in the subscript on each word and with topic 11 highlighted in yellow . We run a hypothesis testing procedure over the annotated corpus to identify signiﬁcant words that appear to the left or right of a word or phrase labeled with a given topic . This procedure is carried out recursively , until no more signiﬁcant phrases are found . At right we illustrate the original top words from topic 11 , and those ﬁnd by the turbo topics strategy . Phrases like “phase diagram , ” “symmetry breaking , ” and “ﬁrst order” are found by the procedure . More topics are illustrated in Figure 3 . unigram representation . An alternative is to ﬁt a more complicated model [ 4 ; 24 ; 25 ] , but then one loses the computational advantage and statistical simplicity of unigram topic modeling . In this paper we introduce a new method for visualizing unigram topic models . In our approach , the model is ﬁrst ﬁt as usual , and then the posterior distribution is used to annotate each word occurrence of the corpus with its most probable topic . With this annotated corpus , we carry out a statistical co - occurrence analysis to extract the most signiﬁcant n - grams for each topic . The resulting multi - term phrases are combined with the unigram lists to give a visualization that o ﬀ ers a better intuitive impression for what a topic is about . We call the resulting visualizations turbo topics , as suggested by the manner in which the method recycles the output of estimation to build a more powerful presentation of the model . As part of this procedure , we developed a new algorithm for ﬁnding multi - word expressions . Our method uses a back - o ﬀ language model deﬁned for arbitrary length expressions [ 8 ] , and recursively employs the distribution - free permutation test to ﬁnd signiﬁcant phrases . In contrast , previous methods of ﬁnding multi - word expressions rely on a test statistic derived from a multinomial contingency table and , in most cases , appeal to the asymptotic distribution of that statistic [ 9 ] . We show that the permutation test works better in small sample settings , such as when we restrict our attention to topical terms , and the back - o ﬀ model allows for ﬁnding multi - word phrases within a well - deﬁned language model . We describe turbo topics in Section 2 and our new method of ﬁnding multi - word expressions in Section 3 . In Section 4 , we evaluate on simulated data and illustrate improved topic visualization with two real - world corpora . 2 2 Turbo Topics We ﬁrst review latent Dirichlet allocation ( LDA ) , a commonly used building block for topic models [ 1 ] . We then describe our algorithm for ﬁnding multi - word expressions to visualize topics . Latent Dirichlet allocation . LDA models documents as arising from multiple topics , where a topic is deﬁned to be a distribution over a ﬁxed vocabulary of terms [ 1 ] . Speciﬁcally , LDA assumes that K topics are associated with a collection , and that each document exhibits these topics with di ﬀ erent proportions . This is often a natural assumption because documents tend to be heterogeneous . Each might combine a subset of themes that permeate the collection as a whole . LDA is a hidden variable model where the observed data are the words of each document and the hidden variables are the latent topical structure , i . e . , the topics themselves and how each document exhibits them . Given a collection , the posterior distribution of the hidden variables given the words of the documents provides a probabilistic decomposition of the documents into topics . The statistical assumptions underlying LDA can be understood by its probabilistic generative process , the random process that is assumed to have produced the observed data . Let K be a speciﬁed number of topics , V the size of the vocabulary , α a positive K - vector , and η a scalar . LDA assumes that the collection arises as follows . For each of the K topics draw a distribution over words , β k ∼ Dirichlet V ( η ) , where Dirichlet V denotes the Dirichlet distribution on the V − 1 dimensional probability simplex . For each document d draw a vector of topic proportions θ d ∼ Dirichlet K ( α ) . Finally , to select the i th word in the document , ﬁrst draw a topic assignment from the topic proportions , Z d , i | θ d ∼ Multinomial ( θ d ) and then draw the word from the chosen topic W d , i | z d , i ∼ Multinomial ( β z d , i ) . This process speciﬁes how the latent variables interact to produce the observed collection . Finding the posterior distribution of the hidden variables is akin to “reversing” this process given a corpus { (cid:126)w d } Dd = 1 . The posterior p ( β 1 : K , θ 1 : D , (cid:126) z 1 : D | (cid:126)w 1 : D , α , η ) provides a probabilistic decomposition of the corpus into its topics β 1 : K . Each document exhibits multiple topics via its topic proportions θ d ; the words of each document are assigned to speciﬁc topics z d , i . However , this posterior is intractable to compute ; the central computational problem in topic modeling is to approximate it . E ﬃ cient approximation algorithms include Markov chain Monte Carlo sampling [ 21 ] and variational methods [ 13 ; 1 ; 23 ] . Here we use mean - ﬁeld variational inference [ 1 ] , though our methods can be used with any algorithm for approximate inference . 3 Multi - word expressions for topic visualization . The topics in LDA are unigram distributions over words , and the LDA model is exchangeable at the word level . This means that if the words in the corpus were shu ﬄ ed within their documents then exactly the same inferences would result . Arguably , this is a reasonable assumption for topic modeling . When presented with a jumbled document , a human can often discern the thematic content of the text , even if he or she cannot reconstruct the detailed ﬂow of the presentation . Exchangeable word models like LDA are simpler and o ﬀ er computational advantages over more complex models that take word order into account [ 4 ; 24 ; 25 ] . Our goal is to enhance the interpretation of the model rather than the model itself , preserving the advantages of exchangeable modeling while attaining the expressive visualizations of n - gram modeling . Thus , our focus is on analyzing the posterior distribution of the topic structure of a corpus to determine phrases indicative of each of the topics . To do so , we ﬁrst use the posterior of the topic variables Z d , i to assign topics to words . Then , based on the original order of the words in the documents , we use the annotated words to ﬁnd the signiﬁcant topical n - grams that stem from them . Our strategy is as follows . 1 . Estimate an LDA topic model with K topics . This results in a posterior for topics , topic proportions , and per - word topic assignments . 2 . Using the posterior , annotate each word in the original corpus with a topic assignment . This yields an ordered sequence of word - topic pairs ( w 1 , z 1 ) , ( w 2 , z 2 ) , ( w 3 , z 3 ) , ( w 4 , z 4 ) , . . . 3 . Given a word or phrase w and topic z of interest , run a hypothesis testing procedure to identify words v that are likely to precede or follow w when it is labeled as belonging to topic z . 4 . Repeat step 3 until no signiﬁcant phrases are added . This is illustrated in Figure 1 . In step 2 , the sequence w 1 , w 2 , w 3 , . . . denotes the original text that comprises the corpus . This step annotates each word w i in the text with a topic assignment z i , unless the word was removed by pre - processing ( e . g . , a stop word ) . The topic assigned to the word is determined by the posterior , and is document speciﬁc . Thus , the word “ﬂy” in one document might be annotated by a topic about insects ; the same word in another topic might be annotated by a topic about airplanes . Topic models capture polysemy , in the sense that they can assign the same term to di ﬀ erent topics in di ﬀ erent document contexts [ 21 ] . Once the words are annotated with topic assignments , document boundaries are ignored . Step 3 results in bigrams ( w , v ) or ( v , w ) for a given topic . Note that v may or may not have been assigned topic z . For instance , consider a topic focused on movies , and consider the movie title “Sex in the City . ” The terms “the” and “and” are stop words , which are not assigned to any topic ; the term “city” may not be very relevant to the movies topic . However , if that topic assigns high probability to the term “sex , ” then our method will be able to identify the movie title because of the repeated context in which it appears . ( See Figure 3 . ) 3 Recursive Permutation Tests For Multi - Word Expressions A key component in turbo topics is the method for recursively identifying signiﬁcant n - grams in a sequence of words . We describe our novel solution to this problem , appropriate for the sparse settings that arise in topic models . 4 A language model . Consider a corpus of N words . Under an arbitrary language model , the log likelihood is log p ( w ) = (cid:80) Nn = 1 log p ( w n | w 1 , . . . , w n − 1 ) . ( 1 ) In parameterizing this model , we can consider two extremes . On one extreme , the fully parameterized model contains a conditional distribution of words given each possible history . However , this model is computationally intractable because it requires specifying O ( V N ) parameters . Moreover , it is statistically unreliable ; there will typically not be enough data to support maximum likelihood estimates . At the other extreme , the unigram model posits that each word is independent of its history , p ( w n | w 1 , . . . , w n − 1 ) = p ( w n ) . This model is e ﬃ cient to estimate , but cannot capture dependencies between words . We adopt a middle ground between these models that sparsely parameterizes the full model using word histories of varying lengths . For example , consider a model where all words follow a unigram distribution except for those words that follow the word “new . ” Among words following “new , ” some words , such as “house , ” essentially follow their unigram distribution , while others , such as “york” or “jersey , ” are endowed with “new” - speciﬁc probabilities . Our challenge is to determine which n - grams , such as “new york , ” should be given special probabilities p ( “new” ) p ( “york” | “new” ) and which should be modeled by products of their unigram probabilities . Then , to visualize the distribution , we order by probability the collection of n - grams represented in the model . Evaluating the likelihood in equation ( 1 ) requires a distribution over words conditioned on an arbitrary history of previous words . Denote a length n history by w 1 : n and let S w 1 : n be a set of words that are governed by history - speciﬁc probabilities . To continue the example , if the history is “new” then S “new” might be { “york” , “jersey” , “hampshire” } . The conditional distribution over words is p ( w n + 1 | w 1 : n ) =  π w n + 1 | w 1 : n if w n + 1 ∈ S w 1 : n γ w 1 : n p ( w n + 1 | w 2 : n ) otherwise . ( 2 ) The constant γ w 1 : n ensures that the distribution sums to one , γ w 1 : n = 1 − (cid:80) v ∈ S w 1 : n π v | u 1 − (cid:80) v ∈ S w 1 : n p ( v | w 2 : n ) . ( 3 ) This is a back - o ﬀ model with a sparsely represented set of conditional distributions . Note that if S w 1 : n = { } is empty , then w 1 : n is not endowed with a speciﬁc conditional distribution . In this case , γ w 1 : n = 1 and equation ( 2 ) gives that p ( w | w 1 : n ) = p ( w | w 2 : n ) . This type of model has been investigated in the speech recognition and language modeling literature [ 8 ; 20 ; 22 ] . Expanding the model with likelihood ratios . We now describe how we search through the space of sparsity patterns for the parameters of the language model . Finding a good set of parameters amounts to identifying the set S h for each word history h in a corpus . Beginning with a unigram model , where S h = { } for all histories , our approach is to greedily determine the words best governed by bigram probabilities . We then apply this procedure recursively to ﬁnd higher order dependencies . Consider a sparse bigram model , a model with word histories of at most one word , and consider a single pair of words u and v such that v (cid:60) S u . To determine whether to add a bigram parameter π v | u to the model , we compute the log likelihood ratio of the expanded model to the unexpanded model , i . e . , the log of the probability of the data under the expanded model divided by the probability of the data under the unexpanded model . The expanded model is the model with S u ← S u ∪ { v } and conditional probabilities following equation ( 2 ) . It 5 contains one new parameter π new v | u , and a di ﬀ erent estimate of the parameter π new v . All other parameters are identical in both models . For the likelihood ratio , the only probabilities that change between the two models are for the words that follow u and for all instances of v . The probability of instances of v following u change from their unigram probability π v to their bigram probability π new v | u ; the probability of other instances of v changes from π v to π new v . Words following u that are not in S u are governed by their unigram probabilities ; however , they are scaled di ﬀ erently in the expanded model . The scaling constant of equation ( 3 ) uses both π new v | u and π new v . Thus , the log likelihood ratio of the expanded model to the unexpanded model is LR u v = n u v log π new v | u + ( n v − n u v ) log π new v + (cid:80) v (cid:48) ∈ S cu / v n u v (cid:48) log ( π v (cid:48) γ new u ) ( 4 ) − n u v log π v − (cid:80) v (cid:48) ∈ S cu / v n u v (cid:48) log ( π v (cid:48) γ u ) . The ﬁrst two lines are the log likelihood under the expanded model ; the third line is the negative log likelihood under the unexpanded model . All parameters are computed as normalized counts [ 8 ] . A value of LR u v above zero indicates that the expanded model ﬁts the data better than the unigram model . This quantity is closely related to an entropy - based score [ 22 ] . For simplicity , we have described the likelihood ratio for expanding a unigram model to a sparse bigram model . This methodology can be generalized to word histories of arbitrary length , and the resulting likelihood ratios can be used to assess expansions beyond bigrams . In assessing such expansions , we compute the ratio of the log likelihoods for a model with history h and a model with expanded history h ∪ { v } . The unexpanded model’s back - o ﬀ probabilities are for words given the original history . Recursive permutation tests . With the likelihood ratio in hand , our next task is to develop an algorithm for building up a model from the unigram parameterization . Our algorithm adds parameters as needed by carrying out a sequence of hypothesis tests . Given a previous word u , consider the best candidate word that is not yet modeled as a bigram , v ∗ = arg max v (cid:60) S u LR u v . Suppose that LR u v ∗ is greater than zero . When is this signiﬁcant , and when it is an artifact of a small data sample ? We answer this question with a permutation test [ 16 ; 6 ] . The permutation test determines the signiﬁcance of a score , as in equation ( 4 ) , that measures the degree of dependence between two random variables . To decide whether a log likelihood ratio is positive , we shu ﬄ e the data in such a way as to remove the added dependence , but retaining the previously modeled dependencies . We then compute the same log likelihood ratio on the shu ﬄ ed data . A score computed from shu ﬄ ed data that is greater than the score we are testing is evidence that the true score is not signiﬁcant , because it arose in a data set where any such dependency has been removed by design . Repeating this process , the proportion of scores under shu ﬄ ed data greater than the quantity in question provides a p - value for its signiﬁcance . Many hypothesis tests rely on assumptions about the asymptotic distribution of the test statistic . The permutation test relies on no such asymptotic assumption , and is thus particularly suited to sparse data settings . In natural language processing , permutation tests have been used for word collocations in multinomial models [ 15 ] and for bilingual associations [ 14 ] . They have not been developed for the back - o ﬀ language models that we consider . 6 Returning to our task , recall that a positive likelihood ratio LR u v ∗ indicates that u and v ∗ are dependent in the joint distribution . To perform the test , we repeatedly shu ﬄ e all the words ( within and across documents ) , but retain the sequences of words that are currently modeled . This removes dependencies between u and terms that are not in S u , while retaining the other dependencies that are already assumed . In the permuted data , if there is a v such that LR permuted u v is greater than LR u v ∗ , then this is an indication that our likelihood ratio score is not signiﬁcant . We perform the following procedure to ﬁnd the set of words S u with which to endow special u - speciﬁc probabilities , 1 . Set v ∗ = arg max v (cid:60) S u LR u v . 2 . Sample M permutations of the data that respect the current estimate of S u . Compute p - value u v ∗ ≈ 1 M ( # scores > LR u v ∗ ) 3 . If p - value u v ∗ is less than the desired threshold then add u to S u and repeat . Intuitions and previous approaches . There are two primary di ﬀ erences between this approach and previ - ous approaches for ﬁnding phrases . First , by testing the maximum log likelihood ratio , we address the issue of ﬁnding multiple related collocations rooted in a single word . If we simultaneously tested each possible expansion , then the hypothesis tests would be dependent on each other . Traditional phrase ﬁnding algorithms are based on a multinomial contingency table and subsequent hypothesis test [ 9 ] . They test all collocations simultaneously , without accounting for the bias that this introduces . This point can be made more concrete with our running example . Suppose “new” occurs 10 , 000 times in the corpus , the word “york” follows it 6000 times , and the word “jersey” follows it 3 , 000 times . Once we take “york” into account , “new jersey” can occur at most 4000 times . By not accounting for the the instances of “new york” we see that 3000 out of 4000 is a strong signal of a bigram . Leaving in “new york , ” as we would if we simultaneously tested both words , we would ﬁnd that 3000 out of 10 , 000 is not as strong a signal . Second , and more importantly , our method is based on expanding the sparsity pattern of the parameters of the model in equation ( 2 ) . When a signiﬁcant word collocation is found , we expand the model to share fewer parameters ; but the resulting expanded model is still a valid model . We can thus apply the hypothesis test recursively . In traditional algorithms for ﬁnding collocations , there is no principled way to expand a model once a signiﬁcant pair of words is found . For example , suppose a traditional algorithm ﬁnds “new york” to be a signiﬁcant bigram . One can try to add “new york” to the vocabulary of the multinomial model . However , the resulting distribution , with probabilities for “new” , “york” and “new york” , will then have two ways of generating the bigram “new york . ” ( One way is to generate the two words independently ; the other is to generate the added bigram . ) It is not clear how to account for observed text with such a distribution . 4 Empirical Results We ﬁrst compare the permutation test for back - o ﬀ models with previous methods of ﬁnding signiﬁcant bigrams . We then demonstrate the full procedure for visualizing topics . 7 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 F - m ea s u r e size = 1e6 v = 6866 size = 1e5 v = 4600 size = 1e4 v = 2443 size = 1e3 v = 681 size = 1e6 v = 6866 size = 1e5 v = 4600 size = 1e4 v = 2443 size = 1e3 v = 681 size = 1e6 v = 6866 size = 1e5 v = 4600 size = 1e4 v = 2443 size = 1e3 v = 681 p - value = 0 . 1 p - value = 0 . 01 p - value = 0 . 001 Chi - squared test Likelihood ratio test I Permutation test I Likelihood ratio test II Permutation test II Figure 2 : The F - measure for simulated corpora of di ﬀ erent sizes ( 10 3 , 10 4 , 10 5 , and 10 6 words ) and for three di ﬀ erent p - values . Likelihood ratio test I is the method of [ 3 ] . Likelihood ratio test II is the back - o ﬀ model in Section 3 using the asymptotic distribution of the log likelihood ratio . Permutation test I is the multinomial model of [ 15 ] . Permutation test II is the procedure of Section 3 . All permutation tests used 1000 permutations . Methods relying on the asymptotic distribution of the test statistic perform better as more data is seen . Methods that employ the permutation test perform well on all data set sizes , and perform better than those methods relying on asymptotics . For this simulated data , the model of Section 3 performs as well as a simple multinomial model . However , it further allows for ﬁnding multi - word expressions within a proper language model . ( See Figure 3 ) . 4 . 1 Simulated bigrams We evaluate our method on simulated text data with known bigrams . The data are drawn sequentially from a Chinese restaurant process ( CRP ) [ 17 ] . The CRP is a distribution over a potentially inﬁnite vocabulary . To simulate N words , we draw each from a distribution where the probability of any previously seen word is proportional to the number of times it has been drawn , and the probability of a new word is proportional to a scaling parameter α . More formally , the n th word is drawn from the following distribution , p ( w n + 1 = v | w 1 : n ) ∝   n v if v exists ; α if v is a new word . We embellish the CRP to create a corpus with bigrams . When a new term is to be added to the vocabulary , it will be a collocation of two previously existing singleton terms with probability β . It will be a new singleton term with probability 1 − β . CRP - based distributions such as this one have been shown to match qualities of word frequencies found in natural language [ 5 ] . Simulating from this process yields a random corpus with a vocabulary containing both singletons and bigrams . However , an observed bigram is indistinguishable from a pair of singletons . Thus , using this corpus as input to a word collocation algorithm , we can compare the set of found bigrams to the true set of bigrams . We measure success with weighted precision and recall . Note that in these simulations we did not ﬁnd or produce phrases of more than two words , as our purpose is to compare to previous techniques . We compared several tests for bigram discovery . The χ 2 test . This is a classical test of independence for discrete variables . 8 obamabarackobamassencampaignsenatordemocraticillinoispresident presidential recentpoliticalspeechhufﬁngtonpoliticsmichellevoterssupporterscandidacychoice barack obama obamascampaign sen barack obama democratic the illinois senator michellerecentspeechchoicesen clinton david axelrod presidentcamp the hufﬁngton post endorsedseenattackspoliticalgave marriagestate in californiagaydecisioncourtlaw supreme court couplesrulingrightsequalitylegalto marrymarried samesex couples states gay marriage sexual orientation the california supreme court hillary clinton campaignbill clintonshes the clinton hillaryspresidentsen clinton mark penn politicssexismthe ﬁrst her campaign supportersmadeﬁghtcalledmrs clinton political hillary rodham clinton clintonhillaryclintonscampaignbillshespresidenthillaryssupporters penn politicssexismpoliticalrodhamdemocraticﬁrstsaysenmrspresidency californiamarriagegaycourtstatecouplessupremedecisionmarried samesex rightsmarrylawrulingstatesequalitylegallesbianequalappeals moviethe ﬁlm hollywooddirectorﬁrstcharacterdocumentarytheaterbestsex and the city hbosceneto make releasescreenactormadestars indiana jones seen ﬁlmmovieﬁlmsmovieshollywooddocumentarydirectorjonesscreen character cannesfestivalcitytheaterstarhbosceneactorplayedindiana un i g r a m t op i c s n - g r a m t op i c s modelpoint monte carlo simulations ﬁxed point resultslatticescalingnumericalising model two we study the models quantum monte carlo interactions numerical simulations simulationdimensionsanalyticalphasespin glass lattice qcd mass dirac operator chiral perturbation theory operatorsquarkslimitthetaquarkmevsimulations lattice spacing chiral symmetry breaking resultseffectssmallbaryon in the continuum limit physicalquenched phase transitionsmodel symmetrypointquantumsystems phase transition phase diagram systemorderﬁeld order parametercriticaltwo transitions in modelsdifferent symmetry breaking ﬁrst order phenomena phase transitionsphasestransitionquantumcriticalsymmetryﬁeldpoint model orderdiagramsystemstwotheorysystemstudybreakingspinﬁrst latticeqcdchiraltheorymassquarkﬁnitequenchedperturbation limit quarksresultspotentialstaggeredchemicalmassessimulationsthetacontinuumvolume mass star formationstarsmassesblack hole stellarstar black holes massivemsun solar masses stellar mass black hole mass the stellar young the mass timesmyrimf supermassive black holes massblackstarstellarstarsmassesholemassiveformation holes msunfunctionyoung supermassiveaccretionratesolarinitialgalacticcentral carlomonte simulationspointmodelresultsﬁxedcriticalstudy two lattice dimensionsscalingnumericalsimulationtransitionisingphase twodimensionaltemperature Hufﬁngton Post Physics arXiv Figure 3 : Standard unigram display of topics compared with turbo topics for two corpora , the Hu ﬃ ngton Post ( left ) , and physics arXiv ( right ) . Four topics are shown for each corpus , comparing the unigram visualization ( bottom ) with the turbo topic visualization ( top ) . The presentations that include the n - grams are more descriptive , uncovering n - grams such as “indiana jones” and “the california supreme court” in the case of the Hu ﬃ ngton Post , and “monte carlo simulations” and “chiral symmetry breaking” in the case of the physics abstracts . Likelihood ratio tests . Here , we obtain p - values from the asymptotic distribution of twice the likelihood ratio . We implemented a simple multinomial model [ 3 ] and the back - o ﬀ model in Section 3 . Permutation tests . As described above , these yield a distribution - free method of obtaining p - values . We employed a permutation test with both a simple multinomial model [ 15 ] and the back - o ﬀ model from Section 3 . ( A comparative study was not performed in [ 15 ] . ) Figure 2 illustrates the F - measure achieved by these tests for four simulated corpora of di ﬀ erent sizes and for three p - value thresholds . The corpora were created with parameters α = 1000 and β = 0 . 1 . The tests that rely on asymptotics improve performance as the corpus size increases . Permutation tests perform well on small and large corpora . The simple multinomial model is as e ﬀ ective as the model of Section 3 for this task , but the procedure presented here allows for recursive detection of word phrases . 4 . 2 Example topic visualizations We demonstrate turbo topics with two corpora . 1 First , we ﬁnd topics from each corpora using variational expectation maximization [ 1 ] . We then restrict our attention to contexts surrounding the words assigned to 1 Code can be found at http : / / www . cs . princeton . edu / ∼ blei / . 9 each topic , and use the recursive permutation tests of Section 2 to ﬁnd a set of back - o ﬀ models , one for each topic . To visualize , we consider the signiﬁcant phrases of each model , i . e . , those n - grams for which the algorithm chose to explicitly represent parameters . We order the n - grams by their probabilities . To aid in visualization , when an n - gram subsumes a shorter n - gram with lower probability , we incorporate the shorter n - gram’s mass into the longer n - grams probability . ( The shorter n - gram’s probability is determined by how often it occurs without being part of the longer n - gram . ) For example , if an expanded topic contains “The New York Mets” with high probability and “New York Mets” with lower probability , then we add the probability of the shorter phrase to the longer phrase . If a shorter phrase , such as “court , ” appears on its own with higher probability than a longer phrase , such as “supreme court , ” then both are considered . Our ﬁrst corpus contains articles from the Hu ﬃ ngton Post , an online news service . This corpus contains 4000 documents and has a vocabulary of 6500 terms . Second , we use the 2006 physics abstracts from arXiv . org , an online scientiﬁc preprint service . This corpus contains 50 , 000 documents and has a vocabulary of 17 , 000 terms . For both corpora , the vocabulary was obtained by removing stop words and infrequent terms ( appearing in fewer than 20 documents ) from the topic analysis . These terms were , however , considered in the phrase analysis . Figure 3 shows , for each collection , four of the original topics and the corresponding turbo topics . ( The news model contains 100 topics ; the physics model contains 200 topics . For both corpora , the number of permutations was 100 and the p - value threshold was 0 . 01 . ) Under the expanded view with bigrams and longer phrases , what the topic is “about” comes into sharper focus . For instance , while we see from the ordered list of unigrams that a topic is about movies , it may not be immediately apparent what “jones” and “city” refer to . In the expanded visualization , the phrases “indiana jones” and “sex in the city” provide a clearer indication why these terms appear with such high probability . Similarly , in a topic that concerns gay marriage , “the california supreme court” appears , o ﬀ ering a reﬁnement of the terms “court” and “supreme” which are separated in the standard probability - sorted unigram list . Similar e ﬀ ects are seen in the topics extracted from the corpus of physics abstracts . While one of the unigram topics assigns high weight to “black” and “holes , ” the phrases “black hole mass , ” “star formation , ” and “supermassive black holes” are more suggestive of how the topic is used . 5 Discussion Topic models are formulated and estimated based on the assumption of word - level exchangeability , which leads to relatively simple and computationally e ﬃ cient inference algorithms . This “bag of words” assumption is reasonable for identifying topics , but it becomes a handicap when interpreting them . The salient bigrams and phrases for a topical word provide an indication of the role it plays in the topic . We have developed a new procedure for determining the salient phrases for a topic . Our procedure preserves the simplicity of an exchangeable model while incorporating some of the context of richer models . Though we focused on topics derived from LDA , we emphasize that this procedure can be used for any topic model , provided there is a latent topic assignment variable for each word of the corpus . Other examples include author - topic models [ 19 ] and conditional topic models [ 12 ] . Moreover , although we focused on topic visualization , one can imagine other uses of the resulting phrases , e . g . , for information retrieval , that would not require a full generative model . In terms of statistical methodology , our results demonstrate that the use of permutation testing is appropriate and e ﬀ ective in this setting , where sparse statistics render tests based on asymptotic distributions less accurate . Although we have implemented a simple greedy strategy based on recursively applying the permutation test , 10 it would be of interest to investigate more computationally e ﬃ cient procedures for simultaneously testing and correcting for multiple hypotheses for expanding word phrases . Acknowledgments We thank Jason Eisner , Chris Genovese , Noah Smith , and Larry Wasserman for useful discussions about this work . References [ 1 ] D . Blei , A . Ng , and M . Jordan . Latent Dirichlet allocation . Journal of Machine Learning Research , 3 : 993 – 1022 , January 2003 . [ 2 ] S . Deerwester , S . Dumais , T . Landauer , G . Furnas , and R . Harshman . Indexing by latent semantic analysis . Journal of the American Society of Information Science , 41 ( 6 ) : 391 – 407 , 1990 . [ 3 ] T . Dunning . Accurate methods for the statistics of surprise and coincidence . Computational Linguistics , 19 ( 1 ) , 1993 . [ 4 ] M . Girolami and A . Kaban . Simplicial mixtures of Markov chains : Distributed modelling of dynamic user proﬁles . In Advances in Neural Information Procesing Systems 16 , pages 9 – 16 . MIT Press , 2004 . [ 5 ] S . Goldwater , T . Gri ﬃ ths , and M . Johnson . Interpolating between types and tokens by estimating power - law generators . In Advances in Neural Information Processing Systems 18 , 2006 . [ 6 ] P . Good . Permutation Tests : A Practical Guide to Resampling Methods for Testing Hypotheses . Springer , 2000 . [ 7 ] T . Hofmann . Probabilistic latent semantic analysis . In Uncertainty in Artiﬁcial Intelligence ( UAI ) , 1999 . [ 8 ] S . Katz . Estimation of probabilities from sparse data for the language model component of a speech recognizer . IEEE Transactions on Acoustics , Speech , and Signal Processing , 35 ( 3 ) , 1987 . [ 9 ] C . Manning and H . Schutze . Foundations of Statistical Natural Language Processing . The MIT Press , Cambridge , MA , 1999 . [ 10 ] A . McCallum , X . Wang , and A . Corrada - Emmanuel . Topic and role discovery in social networks . Journal of Artiﬁcial Intelligence Research , 30 : 249 – 272 , 2007 . [ 11 ] D . Mimno and A . McCallum . Organizing the OCA : Learning faceted subjects from a library of digital books . In Joint Conference on Digital Libraries , 2007 . [ 12 ] D . Mimno and A . McCallum . Topic models conditioned on arbitrary features with Dirichlet - multinomial regression . In Uncertainty in Artiﬁcial Intelligence , 2008 . [ 13 ] T . Minka and J . La ﬀ erty . Expectation - propagation for the generative aspect model . In Uncertainty in Artiﬁcial Intelligence ( UAI ) , 2002 . [ 14 ] R . Moore . On log - likelihood - ratios and the signiﬁcance of rare events . In Empirical Methods in Natural Language Processing , 2004 . 11 [ 15 ] T . Pedersen , M . Kayaalp , and R . Bruce . Signiﬁcant lexical relationships . In AAAI Conference on Artiﬁcial Intelligence , 1996 . [ 16 ] E . Pitman . Signiﬁcance tests which may be applied to samples from any population . Journal of the Royal Statistical Society , 4 ( 1 ) , 1937 . [ 17 ] J . Pitman . Combinatorial Stochastic Processes . Lecture Notes for St . Flour Summer School . Springer - Verlag , 2002 . [ 18 ] M . Purver , K . K¨ording , T . Gri ﬃ ths , and J . Tenenbaum . Unsupervised topic modelling for multi - party spoken discourse . In ACL , 2006 . [ 19 ] M . Rosen - Zvi , T . Gri ﬃ ths , M . Steyvers , and P . Smith . The author - topic model for authors and documents . In Proceedings of the 20th Conference on Uncertainty in Artiﬁcial Intelligence , pages 487 – 494 . AUAI Press , 2004 . [ 20 ] K . Seymore and R . Rosenfeld . Scalable back - o ﬀ language models . In International Conference on Spoken Language , 1996 . [ 21 ] M . Steyvers and T . Gri ﬃ ths . Probabilistic topic models . In T . Landauer , D . McNamara , S . Dennis , and W . Kintsch , editors , Latent Semantic Analysis : A Road to Meaning . Laurence Erlbaum , 2006 . [ 22 ] A . Stolcke . Entropy - based prining of backo ﬀ language models . volume Proc . DARPA Broadcast News Transcription and Understanding Workshop , 1998 . [ 23 ] Y . Teh , D . Newman , and M . Welling . A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation . In Neural Information Processing Systems , 2006 . [ 24 ] H . Wallach . Topic modeling : Beyond bag of words . In Proceedings of the 23rd International Conference on Machine Learning , 2006 . [ 25 ] X . Wang , A . McCallum , and X . Wei . Topical N - grams : Phrase and topic discovery , with an application to information retrieval . In International Conference on Data Mining , 2007 . 12