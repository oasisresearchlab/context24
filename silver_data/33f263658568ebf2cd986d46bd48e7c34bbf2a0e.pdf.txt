January 17 , 2023 1 / 20 One year of COVID - 19 vaccine misinformation on Twitter : Longitudinal study Francesco Pierri 1 , 2 , * , Matthew R . DeVerna 2 , Kai - Cheng Yang 2 , David Axelrod 2 , John Bryden 2 , Filippo Menczer 2 1 Dipartimento di Elettronica , Informazione e Bioingegneria , Politecnico di Milano , Italia 2 Observatory on Social Media , Indiana University , Bloomington , USA * francesco . pierri @ polimi . it Background Vaccinations play a critical role in mitigating the impact of COVID - 19 and other diseases . Past research has linked misinformation to increased hesitancy and lower vaccination rates . Gaps remain in our knowledge about the main drivers of vaccine misinformation on social media and effective ways to intervene . Objective Our longitudinal study has two primary objectives : ( i ) to investigate the patterns of prevalence and contagion of COVID - 19 vaccine misinformation on Twitter in 2021 ; and ( ii ) to identify the main spreaders of vaccine misinformation . Given our results , we also question what are the likely drivers of misinformation and its spread , providing insights for potential interventions . Methods We collected almost 300M English - language tweets related to COVID - 19 vaccines using a list of over 80 relevant keywords over a period of 12 months . We then extracted and labeled news articles at the source level , based on third - party lists of low - credibility and mainstream news sources , and measured the prevalence of different kinds of information . We also considered suspicious YouTube videos shared on Twitter . We focused our analysis of vaccine misinformation spreaders on verified and automated Twitter accounts . Results Our findings show a relatively low prevalence of low - credibility information compared to the entirety of mainstream news . However , the most popular low - credibility sources had reshare volumes comparable to many mainstream sources , and larger volumes than authoritative sources such as the U . S . Centers for Disease Control and Prevention and the World Health Organization . Throughout the year , we observed an increasing trend in the prevalence of low - credibility news about vaccines . We also observed a considerable amount of suspicious YouTube videos shared on Twitter . Tweets by a small group of about 800 “superspreaders” verified by Twitter accounted for approximately 35 % of all reshares of misinformation on an average day , with the top superspreader ( @ RobertKennedyJr ) responsible for over 13 % of retweets . Finally , low - credibility news and suspicious YouTube videos were more likely to be shared by automated accounts . January 17 , 2023 2 / 20 Conclusions The wide spread of misinformation around COVID - 19 vaccines on Twitter during 2021 shows that there was an audience for this type of content . Our findings are also consistent with the hypothesis that superspreaders are driven by financial incentives that allow them to profit from health misinformation . Despite high - profile cases of deplatformed misinformation superspreaders , our results show that in 2021 a few individuals still played an outsize role in the spread of low - credibility vaccine content . As a result , social media moderation efforts would be better served by focusing on reducing the online visibility of repeat - spreaders of harmful content , especially during public health crises . Introduction The global spread of the novel coronavirus ( SARS - CoV - 2 ) over the last two years affected the lives of most people around the world . As of December 2021 , over 330 million cases were detected and 5 . 5 million deaths were recorded due to the pandemic ( coronavirus . jhu . edu / map . html ) . In the United States , COVID - 19 was the third leading cause of death in 2020 according to the National Center for Health Statistics [ 1 ] . Despite their socio - economic repercussions [ 2 , 3 ] , non - pharmaceutical interventions such as social distancing , travel restrictions , and national lockdowns have proven to be effective at slowing the spread of the coronavirus [ 4 – 6 ] . As the pandemic evolved , pharmaceutical interventions , such as vaccinations and antiviral treatments , became increasingly important to manage the pandemic [ 7 , 8 ] . Less than a year into the pandemic , we witnessed the swift development of COVID - 19 vaccines , expedited by new mRNA technology [ 9 ] . Both Pfizer - BioNTech [ 10 ] and Moderna [ 11 ] vaccines , among others , obtained emergency authorizations in the United States and Europe by the end of 2020 , and governments began to distribute them to the public immediately . Mounting evidence shows that vaccines effectively prevent infections and severe hospitalizations , despite the emergence of new viral strains of the original SARS - CoV - 2 virus [ 12 , 13 ] . It was estimated that the United States vaccination program averted up to 140 , 000 deaths by May 2021 [ 14 ] and over 10 million hospitalizations by November 2021 [ 15 ] . The widespread adoption of vaccines is extremely important to reduce the impact of the highly contagious virus [ 16 ] . However , as of December 2021 when supplies were no longer limited , only 62 % of U . S . citizens had received two doses of COVID - 19 vaccines [ 17 ] . Unvaccinated or partially vaccinated individuals still face risks of infection and death that are much higher than those who completed their vaccination cycle [ 18 ] . The geographically uneven vaccination coverage of the population can also lead to localized outbreaks and hinder governmental efforts to mitigate the pandemic [ 19 ] . Worldwide , most people are in favor of vaccines and vaccination programs , but a proportion of individuals are hesitant about some or all vaccines . Vaccine hesitancy describes a spectrum of attitudes , ranging from people with small concerns to those who completely refuse all vaccines . Previous literature links vaccine hesitancy to several factors that include the political , cultural , and social background of individuals , as well as their personal experience , education , and information environment [ 20 ] . Ever since public discourse moved online , concerns have been raised about the spread of false claims regarding vaccines on social media , which may erode public trust in science and promote vaccine hesitancy or refusal [ 21 – 24 ] . January 17 , 2023 3 / 20 After the outbreak of the COVID - 19 pandemic , a massive amount of health - related misinformation — the so - called “infodemic” [ 25 ] — was observed on multiple social media platforms [ 26 – 29 ] , undermining public - health policies to contain the disease . Online misinformation included false claims and conspiracy theories about COVID - 19 vaccines , hindering the effectiveness of vaccination campaigns [ 30 , 31 ] . A few recent studies reveal a positive association between exposure to misinformation and vaccine hesitancy at the individual level [ 32 ] as well as a negative association between the prevalence of online vaccine misinformation and vaccine uptake rates at the population level [ 33 ] . Motivated by these findings , our work investigates the spread of COVID - 19 vaccine misinformation by analyzing almost 300 million English - language tweets shared during 2021 , when vaccination programs were launched in most countries around the world . There are a number of studies related to the present work . Yang et al . [ 29 ] carried out a comparative analysis of English - language COVID - 19 - related misinformation spreading on Twitter and Facebook during 2020 . They compared the prevalence of low - credibility sources on the two platforms , highlighting how verified pages and accounts earned a considerable amount of reshares when posting content originating from unreliable websites . Muric et al . [ 34 ] released a public dataset of Twitter accounts and messages , collected at the end of 2020 , which specifically focuses on anti - vaccine narratives . Preliminary analyses show that the online vaccine - hesitancy discourse was fueled by conservative - leaning individuals who shared a large amount of vaccine - related content from questionable sources . Sharma et al . [ 35 ] focused on identifying coordinated efforts to promote anti - vaccine narratives on Twitter during the first four months of the U . S . vaccination program . They also carried out a content - based analysis of the main misinformation narratives , finding that side effects were often mentioned along with COVID - 19 conspiracy theories . Our work makes two key contributions to existing research . First , we studied the prevalence of COVID - 19 vaccine misinformation originating from low - credibility websites and YouTube videos and compared it to information published on mainstream news websites . As described above , previous studies either analyze the spread of misinformation about COVID - 19 in general ( during 2020 ) or focus specifically on anti - vaccination messages and narratives . They also analyze a limited time window , whereas our data captures 12 months into the roll - out of COVID - 19 vaccination programs . Second , we uncovered the role and the contribution of important groups of vaccine misinformation spreaders , namely verified and automated accounts , whereas previous work either focuses on detecting users with a strong anti - vaccine stance or inauthentic coordinated behavior . Considering these contributions , we address two research questions . The first is : RQ1 : What were the patterns of prevalence and contagion of COVID - 19 vaccine misinformation on Twitter in 2021 ? Leveraging a dataset of millions of tweets , we identified misinformation at the domain level based on a list of low - credibility sources ( website domains ) compiled by professional fact - checkers and journalists—an approach that is widely adopted in the literature to study unreliable information at scale [ 36 – 40 ] . Additionally , we considered a set of mainstream and public health sources as a baseline for reliable information . We then compared the volume of vaccine misinformation against reliable news , identified temporal trends , and investigated the most shared sources . We also explored the prevalence of misinformation that originated on YouTube and was shared on Twitter [ 29 , 41 , 42 ] . Analogously to the role of virus superspreaders in pandemic outbreaks [ 43 ] , recent studies suggest that certain actors play an outsize role in disseminating misleading January 17 , 2023 4 / 20 Table 1 . Sample keywords employed to collect tweets about vaccines . covid19vaccine covidvaccine coronavirusvaccine vaccination covid19 pfizer pfizercovidvaccine oxfordvaccine getvaccinated covid19 moderna vaccine covid19 pfizer mrna vaccinate covax coronavirus moderna vax content [ 29 , 38 , 41 ] . For example , just 10 accounts were responsible for originating over 34 % of low - credibility content shared on Twitter during an eight - month period in 2020 [ 44 ] . To examine how vaccine misinformation was posted and amplified by various actors on social media , our work addresses a second research question : RQ2 : Who were the main spreaders of vaccine misinformation ? Specifically , we analyzed two types of accounts . First , we investigated the presence and characteristics of users who generated the most reshares of misinformation [ 44 , 45 ] , with a specific focus on the role of “verified” accounts . Twitter deems these accounts “authentic , notable , and active” ( see help . twitter . com / en / managing - your - account / about - twitter - verified - accounts ) . Second , we investigated the presence and role of social bots , i . e . , social media accounts controlled in part by algorithms . Previous studies showed that bots actively amplified low - credibility information in various contexts [ 37 , 46 , 47 ] . Our findings deepen our understanding of the ongoing pandemic and generate actionable knowledge for future health crises . Materials and methods Twitter data collection On January 4th , 2021 , we started a real - time collection of tweets about COVID - 19 vaccines using the Twitter application program interface ( API ) . The tweets were collected by matching relevant keywords through the POST statuses / filter v1 . 1 API endpoint ( developer . twitter . com / en / docs / twitter - api / v1 / tweets / filter - realtime / overview ) . This effort is part of our CoVaxxy project , which provides a public dashboard ( osome . iu . edu / tools / covaxxy ) to visualize the relationship between online ( mis ) information and COVID - 19 vaccine adoption in the United States [ 48 ] . To capture the online public discourse around COVID - 19 vaccines in English , we defined as complete a set as possible of English - language keywords related to the topic . Starting with covid and vaccine as our initial seeds , we employed a snowball sampling technique to identify co - occurring relevant keywords in December 2020 [ 48 , 49 ] . The resulting list contained almost 80 keywords . We show a few examples in Table 1 ; the full list can be accessed through the online repository associated with this project [ 50 ] . To validate the data collection procedure , we examined the coverage obtained by adding keywords one at a time , starting with the most common ones . Over 90 % of the tweets contain at least one of the three most common keywords : “vaccine , ” “vaccination , ” or “vaccinate . ” This indicates that the collected tweets are very relevant to the topic of vaccines . In this paper , we analyzed the data collected in the period from January 4th to December 31st , 2021 . This comprises 294 , 081 , 599 tweets shared by 19 , 581 , 249 unique users , containing 8 , 160 , 838 unique links ( URLs ) and 1 , 287 , 703 unique hashtags . January 17 , 2023 5 / 20 Fig 1 . Time series of the daily number of vaccine - related tweets shared between January 4th and December 31st , 2021 . The median daily number of tweets is 720 , 575 . Figure 1 shows the daily volume of vaccine tweets collected . To comply with Twitter’s terms of service , we are only able to share the tweet IDs with the public , accessible through a public repository [ 50 ] . One can “re - hydrate” the dataset by querying the Twitter API or using tools like Hydrator ( github . com / DocNow / hydrator ) or twarc ( twarc - project . readthedocs . io / en / latest ) . Identifying online misinformation We identified misinformation in our dataset using two approaches . Following a common method in the literature [ 36 – 40 ] , the first approach identified tweets sharing links to low - credibility websites that were labeled by journalists , fact - checkers , and media experts for repeatedly sharing false news , hoaxes , conspiracy theories , unsubstantiated claims , hyperpartisan propaganda , click - bait , and so on . Specifically , we employed the Iffy + Misinfo / Disinfo list of low - credibility sources ( available at iffy . news / iffy - plus and accessed in March 2022 ) . This list is mainly based on information provided by the Media Bias / Fact Check ( MBFC ) website ( mediabiasfactcheck . com ) , an independent organization that reviews and rates the reliability of news sources . Political leaning was not considered for determining inclusion in the Iffy + list . Instead , the list includes sites labeled by MBFC as having a “Very Low” or “Low” factual - reporting level and those classified as “Questionable” or “Conspiracy - Pseudoscience” sources . The 674 low - credibility sources in the Iffy + list also include fake - news websites flagged by BuzzFeed , FactCheck . org , PolitiFact , and Wikipedia . To expand our list of low - credibility sources , we also employed news reliability scores provided by NewsGuard [ 51 ] , a journalistic organization that routinely assessed the reliability of news websites based on multiple criteria . NewsGuard assigns news outlets a trust score in the range [ 0 , 100 ] . While it considers outlets with scores below 60 as “unreliable , ” we adopted a stricter definition and only considered outlets with a score less than or equal to 30 as low - credibility . This yielded a list of 1 , 181 websites , which we cannot disclose to the public since the NewsGuard data is proprietary . By combining the Iffy + list and the NewsGuard list , we obtained a total number of 1 , 718 low - credibility sources . We tested the reliability of this domain - based approach to identify misinformation through a qualitative approach similar to previous studies [ 37 , 52 ] . We randomly chose 50 low - credibility links in our dataset and manually coded them as either “factual , ” January 17 , 2023 6 / 20 Table 2 . List of URL shortening services considered in our analysis . bit . ly dlvr . it liicr . nl tinyurl . com goo . gl ift . tt ow . ly fxn . ws buff . ly back . ly amzn . to nyti . ms nyp . st dailysign . al j . mp wapo . st reut . rs drudge . tw shar . es sumo . ly rebrand . ly covfefe . bz trib . al yhoo . it t . co shr . lc po . st dld . bz bitly . com crfrm . us flip . it mf . tt wp . me voat . co zurl . co fw . to mol . im read . bi disq . us tmsnrt . rs usat . ly aje . io sc . mp gop . cm crwd . fr owl . li zpr . io scq . io trib . in “misinformation , ” or “unverified . ” Two authors independently visited the actual web page of each link and researched its content to determine if it was accurate . A link was coded as “factual” if all claims within the article were corroborated by other sources . The “unverified” label was utilized for links that could no longer be accessed ( e . g . , because the web page no longer exists ) . All other links were coded as “misinformation . ” In the event of coding disagreements , authors shared and discussed what they learned during their independent research to reach an agreement on a single label . At the end of this procedure , seven links were coded as “factual , ” 38 as “misinformation , ” four as “unverified , ” and a single article was excluded as it appeared to be a personal blog post . We also note that of the seven articles labeled as “factual , ” six were from state propaganda outlets with a selection bias ( e . g . , sputniknews . com or rt . com ) . As a second approach , we analyzed links to YouTube videos shared on Twitter that might contain misinformation . We extracted unique video identifiers from links shared in the collected tweets and queried the YouTube API for the video status using the Videos : list endpoint . In light of recent YouTube efforts to remove anti - vaccine videos according to their COVID - 19 policy [ 53 ] and their updated policy [ 54 ] , we considered videos to be suspicious if they were not publicly accessible . Previous research shows that inaccessible videos contain a high proportion of anti - vaccine content , such as the “Plandemic” conspiracy documentary [ 29 ] . The efficacy of this approach to identifying videos that contain anti - vaccine content is further supported in research that analyzed available videos shared by users that had also shared an inaccessible video [ 55 ] . The authors found that the majority of available videos tweeted by these users promulgated an anti - vaccine or anti - mandate stance . As some estimates suggest that it takes an average of 41 days for YouTube to remove videos that violate their terms [ 42 ] , we checked the statuses of videos in March 2022 , at least 2 months after the last video was posted on Twitter . Sources of reliable information We curated a list of reliable , mainstream sources of vaccine - related news as our baseline to interpret the prevalence of misinformation and characterized its spreading patterns [ 29 ] . In particular , we considered websites with a NewsGuard trust score higher than 80 , January 17 , 2023 7 / 20 resulting in a list of 2 , 765 sources . We also included the websites of two authoritative sources of COVID - 19 - related information , namely the U . S . Centers for Disease Control and Prevention ( cdc . gov , CDC ) and the World Health Organization ( who . int , WHO ) . In the rest of the paper , we use “low - credibility” and “mainstream” to refer to the two sets of sources . Link extraction Identifying low - and high - credibility links and YouTube links requires extracting the top - level domains from the URLs embedded in tweets and matching them against our lists of web domains . Shortened links occurred frequently in our dataset , therefore we identified the most prevalent link - shortening services ( the list can be found in Table 2 ) and obtained the original links through HTTP requests . Bot detection To measure the level of bot activity for different types of information , we employed BotometerLite ( accessible at rapidapi . com / OSoMe / api / botometer - pro ) , a publicly - available tool that can efficiently identify likely automated accounts on Twitter [ 56 ] . For each Twitter account , BotometerLite generates a bot score in the range [ 0 , 1 ] where a higher score indicates that the account is more likely to be automated . BotometerLite evaluates an account by inspecting the profile information that is embedded in each tweet . This enabled us to perform bot analysis at the level of tweets in our dataset . Ethical considerations This research is based on observations of public data with minimal risks to human subjects . It was deemed exempt from review by the Indiana University IRB ( protocol 1102004860 ) . Data collection and analysis are performed in compliance with the terms of service of Twitter . Results Prevalence and contagion of online misinformation To address RQ1 , we compared the prevalence of tweets that linked to domains in our lists of low - credibility and mainstream sources over time . We carried out a similar analysis for suspicious YouTube videos . As shown in panels A and B of Fig . 2 , we observed a significant increasing trend in the daily prevalence of low - credibility information over time and a significant opposite trend for mainstream news . This is further confirmed in panel C , which shows the daily ratio between the volumes of tweets linking to low - credibility and mainstream news . A significant increasing trend was observed , suggesting that the public discussion about vaccines on Twitter shifted over time from referencing trustworthy sources in favor of low - credibility sources . The peak in July corresponds to a time when the prevalence of mainstream news was particularly low ( panel B ) . During this period we also observed a burst of reshares for content originating from Children’s Health Defense , the most prominent source of vaccine misinformation ( further discussed below ) . During the entire period of analysis , we found that misinformation is generally less prevalent than mainstream news , as shown in panel A of Fig . 3 . However , we observed that low - credibility content tended to spread more through retweets compared to mainstream content , as shown in panel B of Fig . 3 . This indicated that while low - January 17 , 2023 8 / 20 Fig 2 . Timelines of prevalence of vaccine information on Twitter . We employ non - parametric Mann - Kendall tests for trends . Colored bands correspond to a 14 - day rolling average with 95 % C . I . ( A ) Daily number of vaccine tweets sharing links to news articles from low - credibility sources . There is a significant increasing trend ( P < . 001 ) . ( B ) Daily number of vaccine tweets sharing links to news articles from mainstream sources . There is a significant decreasing trend ( P < . 001 ) . ( C ) Ratio between the volumes of tweets sharing links to low - credibility and mainstream sources . There is a significant increasing trend ( P < . 001 ) . ( D ) Daily percentage of tweets sharing links to inaccessible YouTube videos , out of all tweets sharing links to YouTube . There is a significant decreasing trend ( P < . 001 ) . credibility vaccine content was less prevalent overall , it had a greater potential for contagion through the social network , suggesting that it might have only spread through a subsection of the population . We further report that the fraction of vaccine - related tweets linking to YouTube videos was very small ( daily median : 0 . 52 % ) . However , a non - negligible proportion of these posts ( daily median : 10 . 95 % ) shared links to inaccessible videos , with a larger prevalence in the first half of 2021 ( a peak of 45 % is observed in July ) , and a significant decreasing trend towards the end of the year ( see panel D of Fig . 2 ) . Most popular misinformation sources Looking at different sources of news about vaccines , panel A in Fig . 4 shows the 20 most shared websites . We note three unreliable sources in this ranking , namely childrenshealthdefense . org , thegatewaypundit . com , and zerohedge . com . The most popular low - credibility source was the website of the Children’s Health Defense ( CHD ) organization , an anti - vaccine group led by Robert F . Kennedy Jr . that became very popular during the pandemic as an alternative and natural medicine site [ 45 , 57 ] . This C D A B January 17 , 2023 9 / 20 Fig 3 . Comparisons between prevalence of tweets linking to mainstream and low - credibility sources . ( A ) Daily percentage of vaccine tweets and retweets that share links to low - credibility news sources ( median : 1 . 31 % ) and mainstream news sources ( median : 7 . 53 % ) . The distributions are statistically different according to a two - sided Mann - Whitney test ( P < . 001 ) . ( B ) Distributions of the proportion of tweets linking to low - credibility sources ( median : 89 . 19 % ) and mainstream sources ( median : 67 . 96 % ) that are retweets . The distributions are statistically different according to a two - sided Mann - Whitney test ( P < . 001 ) . source was banned from Facebook and Instagram for repeatedly violating their guidelines against spreading medical misinformation in August 2022 [ 58 ] . With around 0 . 30 % of all vaccine tweets , its prevalence was comparable to that of reputable sources such as washingtonpost . com and reuters . com , and roughly twice the prevalence of CDC links ( 0 . 16 % ) . As shown in panel B , CHD was much more widely shared than other low - credibility sources , most of which had less than 0 . 05 % of all shared tweets . CHD accounted for approximately 18 % of all tweets linking to low - credibility sources , whereas the aggregated 20 most shared sources generated around 61 % of all such tweets . Nevertheless , the total fraction of tweets sharing low - credibility news about vaccines accounted for only 1 . 5 % compared to approximately 7 . 8 % of tweets that linked to mainstream sources ( see panel C of Fig . 4 ) . Superspreaders of misinformation Recent work reveals that accounts who disseminated a disproportionate amount of low - credibility content—so - called “superspreaders”—played a central role in the digital misinformation crisis [ 29 , 38 , 41 , 44 , 45 ] . These contributions also show that “verified” accounts often act as superspreaders of unreliable information , therefore we further investigated the role of such accounts to address RQ2 . Figure 5 shows that over time , verified accounts represented around 15 % of those that posted vaccine content , but were consistently responsible for about 43 % of that content . When we focus on low - credibility content , verified accounts represented an even smaller proportion of accounts , less than 6 % . Still , they were responsible for approximately 34 % of retweets . These findings highlight a stunning concentration of impact and responsibility for the spread of vaccine misinformation among a small group of verified accounts . While there were substantially fewer verified accounts sharing low - credibility vaccine content ( 828 ) compared to those sharing vaccine content in general ( 98 , 612 ) , Figure 6 shows that verified accounts tended to receive more retweets when posting low - credibility content than general vaccine content . A B January 17 , 2023 10 / 20 Fig 4 . Top sources of vaccine content . ( A ) The top 20 news sources ranked by percentage of vaccine tweets . ( B ) The top 20 low - credibility news sources ranked by percentage of vaccine tweets . ( C ) Percentages of all vaccine tweets linking to low - credibility and mainstream news sources . Fig 5 . Comparisons between percentages of original posters who are verified accounts and of retweets earned by verified accounts , for different categories of vaccine content . Each data point is a daily proportion . The median daily proportions of verified accounts among posters of vaccine content , low - credibility news , and inaccessible YouTube videos are 15 . 4 % , 5 . 6 % , and 4 . 5 % , respectively . The median daily proportions of retweets earned by verified posters of vaccine content , low - credibility news , and inaccessible YouTube videos are 43 . 1 % , 34 . 2 % , and 13 . 2 % , respectively . All distributions are statistically different from each other according to two - sided Mann - Whitney tests ( P < 0 . 001 ) . In Fig . 7 we ranked the top 25 accounts by the number of retweets to their posts linking to low - credibility sources . 11 of these misinformation superspreaders were accounts that have been verified by Twitter , some of which are associated with A C B January 17 , 2023 11 / 20 Fig 6 . Distributions of the mean numbers of retweets earned by verified accounts when sharing vaccine content ( median 3 . 82 ) , low - credibility news ( median 9 . 43 ) , and links to inaccessible YouTube videos ( median 1 ) . We display the complementary cumulative distributions in the main plot because the distributions are broad . In fact , the box plots ( inset ) have many outliers . All distributions are significantly different from each others according to two - sided Mann - Whitney tests ( P < 0 . 001 ) . untrustworthy news sources ( e . g . , @ zerohedge , @ BreitbartNews , and @ OANN ) . The top superspreader , Robert Kennedy Jr . ( @ RobertKennedyJr ) , earned approximately 3 . 45 times the number of retweets of the second most - retweeted account ( @ zerohedge ) . Mr . Kennedy was identified as one of the pandemic’s “disinformation dozen” [ 41 , 45 ] . His influence fueled the high prevalence of links to childrenhealthdefense . org within our dataset ( as previously shown in Fig . 4 ) . His verified account had approximately 3 . 8 times more followers than the unverified @ ChildrensHD account ( 416 . 2k versus 109 . 8k , respectively as of April 24th , 2022 ) . Retweets of Mr . Kennedy’s tweets singularly accounted for 13 . 4 % of all retweets of low - credibility vaccine content . A robustness check removing this account from the data yielded consistent results for all analyses reported in this section . We also investigated the role of verified users in sharing suspicious videos from YouTube . As shown in Figs . 5 and 6 , we found that verified accounts do not play as central a role in spreading this content in contrast to content from low - credibility domains . Role of social bots To address RQ2 , we also inspected the role of likely automated accounts in spreading COVID - 19 vaccine misinformation . As mentioned in the Methods section , we employed BotometerLite [ 56 ] to calculate a bot score for all the accounts posting a tweet in our dataset . We did not observe notable temporal trends in the activity of likely bots over time , so we show in Fig . 8 the distributions of daily average bot scores for tweets sharing vaccine content , links to low - credibility sources , and inaccessible YouTube videos . We observed that tweets sharing links to low - credibility sources had significantly higher bot - activity levels than vaccine tweets overall . As for tweets sharing inaccessible YouTube videos , their daily average bot scores were even higher than those linking to low - credibility sources . This analysis was carried out at the tweet level , meaning that if a bot - like account tweeted more times , it made a larger contribution . We observed similar results when performing the analysis at the account level , by considering the contribution of each account once . January 17 , 2023 12 / 20 Fig 7 . Top 25 accounts ranked by the number of retweets earned when sharing links to low - credibility news websites . Colors indicate whether accounts are verified ( orange ) or not ( blue ) . Fig 8 . Comparison between the daily average bot score of tweets sharing different categories of vaccine content . The median daily average bot scores of accounts sharing vaccine content , low - credibility news , and inaccessible YouTube videos are 0 . 22 , 0 . 25 and 0 . 26 , respectively . All distributions are significantly different from each other according to two - sided Mann - Whitney tests ( P < 0 . 001 ) . Discussion We investigated COVID - 19 vaccine misinformation spreading on Twitter during 2021 following the roll - out of vaccination programs around the world . Leveraging a source - based labeling approach , we identified millions of tweets sharing links to low - credibility and mainstream news websites . While low - credibility information was generally less prevalent than mainstream content over the year , we observed an increasing trend in the reshares of unreliable news during the year , and an opposite , decreasing trend for reliable information . Our data mostly captures English - language conversations , which January 17 , 2023 13 / 20 could originate from different countries . However , our aggregate analysis does not disentangle the infodemic trends and peaks associated with different countries , as observed in prior work [ 28 ] . Focusing on specific news sources , we noticed three low - credibility websites with volumes of reshares comparable to reliable sources . Alarmingly , the most prominent source of vaccine misinformation , Children’s Health Defense , earned more than twice the number of tweets linking to the Centers for Disease Control and Prevention . Looking at users who earned the most retweets when sharing low - credibility news about vaccines , we observed the presence of many verified accounts . In particular , the verified user who earned the most retweets was Robert Kennedy Jr . , the founder of Children’s Health Defense . Given the increase in misinformation over time and the outsized role of a small group of verified users , we hypothesize that financial incentives may play an important role [ 57 , 59 ] . Low - credibility websites monetize visitors through donations , advertising , and merchandise . Our finding that vaccine misinformation tended to spread more through retweets compared to mainstream news suggests that misinformation content lends itself to such exploitation . Amplification by automated accounts may also have played a role in increasing levels of misinformation , as we found these accounts to be significantly more active at sharing low - credibility news and inaccessible YouTube videos compared to vaccine - related content overall . However , we did not find a trend of increased levels of automated sharing over time . There are a number of limitations to our study . The source - based approach to identify low - credibility information at scale is not perfect . Credible sources may occasionally report inaccuracies and low - credibility sources often publish a mixture of reliable and unreliable information . Our analysis based on a sample of articles suggests that approximately 76 % of articles from low - credibility sources do contain false or misleading content . While we cannot publicly disclose Newsguard ratings , they are available to researchers upon agreement , and this should ensure reproducibility . We elected to include Newsguard data because it is more comprehensive , up - to - date , and its methodology is better documented compared to other ratings like those from Iffy + Misinfo / Disinfo . Nevertheless , it would be possible to repeat our analysis using only free ratings from Iffy + Misinfo / Disinfo since , as the literature suggests , the ratings are highly correlated [ 60 , 61 ] . In fact , we observe a high overlap between our lists of top sources — for example , 17 of the top - 20 sources in Figure 4B are also present in the Iffy + Misinfo / Disinfo list . More importantly , over 86 % of the total number of low - credibility tweets identified with the merged list originate from websites contained in the Iffy + Misinfo / Disinfo list alone . This suggests that the results are robust with respect to the ratings source . Similar limitations exist with respect to labeling inaccessible YouTube videos as low - credibility . For example , some of these videos may be inaccessible due to restricted access or copyright violations . An uploader’s choice to restrict access to a video may serve as a way to circumvent content moderation policies or could be unrelated to anti - vaccination efforts . However , in the context of the vaccination discussion on Twitter , examinations of videos and their Twitter posters suggest that most inaccessible videos are likely anti - vaccination in their orientation [ 55 ] . In addition , not all accessible videos contain accurate information about vaccines . YouTube may fail to identify content that should be removed according to its own policies . As such , analyses of inaccessible videos should be treated more like lower - bound estimates . January 17 , 2023 14 / 20 Another limitation is that the Botometer algorithm we employ to detect automated accounts is not perfect and may not accurately classify social bots [ 56 ] . We investigated whether bot - like behavior , as identified by Botometer , is associated with suspicious activity on Twitter . We used Twitter’s Compliance API ( developer . twitter . com / en / docs / twitter - api / compliance / batch - compliance / introduction ) to check all accounts for suspension from the platform as of November 2022 . We observed a significant positive correlation between the BotometerLite score , binned into 40 equal intervals , and the proportion of accounts suspended ( Pearson’s R = 0 . 93 , P < 0 . 001 ) . This suggests that the classifier reliably reveals behaviors that eventually lead to suspension on the platform . Perhaps most importantly , Twitter users may not be very representative of the real - world population across a range of demographic groups [ 62 ] , although information circulating around Twitter can have a great influence over the news media agenda [ 63 ] . Further studies should consider multiple social media platforms simultaneously , especially those with upward adoption trends [ 64 ] . Despite these limitations , our findings help map the landscape of online vaccine misinformation and design intervention strategies to curb its spread . The presence of misinformation around COVID - 19 vaccines on Twitter shows that there was an audience for this type of content , which might reflect a deeper distrust of medicine , health professionals , and science [ 65 ] . In a context of widespread uncertainty such as the COVID - 19 pandemic , trust is critical for overcoming vaccine hesitancy , and recent research shows how online misinformation fueled vaccine hesitancy and refusal sentiment [ 24 , 33 ] . Our findings reveal the presence of a small number of main producers and repeat spreaders of low - credibility content . Given that these superspreaders played key roles in disseminating vaccine misinformation , a straightforward strategy could be to deplatform them [ 66 , 67 ] , as shown by recent studies in different contexts [ 67 – 69 ] — and as has been done by major platforms in notable cases such as Alex Jones [ 70 ] and Donald Trump ( blog . twitter . com / en _ us / topics / company / 2020 / suspension ) . While social media platforms have legal rights to regulate online conversations , the decisions to deplatform public figures should be made with caution . In fact , past interventions have sparked a vivid debate around free speech and caused many users to migrate to alternative platforms [ 67 , 69 ] . It is also unclear whether reducing the supply of false information and increasing the supply of accurate information can “cure” the problem of vaccine hesitancy [ 31 ] . An alternative path of action could be to reduce the financial incentives of those who profit from the spread of misinformation . Our results also show that vaccine misinformation is more viral than other kinds of information . Other effective approaches to reduce its spread include lowering the visibility of certain content ( “down - ranking” ) or not showing that content to users ( “shadow banning” ) , as well as adding warning labels to content that is potentially harmful or inaccurate [ 71 , 72 ] . Platforms should partner with policymakers and researchers in evaluating the impacts of such different interventions [ 73 ] . There are several interesting research questions that are outside the scope of the present work , but that could be addressed by future research . For instance , further investigations could address the impact of Twitter’s removal of users due to the January 6 th riots on the spread of misinformation in the following months . Other studies could investigate how the Children’s Health Defense organization shifted its anti - vaccination narratives from children to a broader COVID - 19 vaccination campaign and remained the most popular source for the anti - vaccination movement . Future work could also analyze exposure to low - credibility information , which is more difficult to measure compared to the sharing patterns quantified in this paper . This would allow answering the question of January 17 , 2023 15 / 20 whether the spread of low - credibility information was confined to a limited group of people or reached a wide audience . Finally , it is still unclear how governmental and societal changes might have affected conversations around vaccines during the COVID - 19 pandemic compared to the ( anti - ) vaccination debate in previous years . All in all , we believe our work provides actionable insights for addressing the online spread of vaccine misinformation . Such insights can be beneficial during the ongoing pandemic and future health crises . Acknowledgements This work is supported in part by the Italian Ministry of Education ( PRIN project HOPE ) , the EU Horizon 2020 ( grant 101016233 ) , the National Science Foundation ( grant ACI - 1548562 ) , Knight Foundation , and Craig Newmark Philanthropies . References 1 . Ahmad FB , Anderson RN . The Leading Causes of Death in the US for 2020 . JAMA . 2021 ; 325 ( 18 ) : 1829 – 1830 . 2 . Bonaccorsi G , Pierri F , Cinelli M , Flori A , Galeazzi A , Porcelli F , et al . Economic and social consequences of human mobility restrictions under COVID - 19 . Proceedings of the National Academy of Sciences . 2020 ; 117 ( 27 ) : 15530 – 15535 . 3 . Bonaccorsi G , Pierri F , Scotti F , Flori A , Manaresi F , Ceri S , et al . Socioeconomic differences and persistent segregation of Italian territories during COVID - 19 pandemic . Scientific Reports . 2021 ; 11 ( 1 ) : 1 – 15 . 4 . Chinazzi M , Davis JT , Ajelli M , Gioannini C , Litvinova M , Merler S , et al . The effect of travel restrictions on the spread of the 2019 novel coronavirus ( COVID - 19 ) outbreak . Science . 2020 ; 368 ( 6489 ) : 395 – 400 . 5 . Haug N , Geyrhofer L , Londei A , Dervic E , Desvars - Larrive A , Loreto V , et al . Ranking the effectiveness of worldwide COVID - 19 government interventions . Nature Human Behaviour . 2020 ; 4 ( 12 ) : 1303 – 1312 . 6 . Chang S , Pierson E , Koh PW , Gerardin J , Redbird B , Grusky D , et al . Mobility network models of COVID - 19 explain inequities and inform reopening . Nature . 2021 ; 589 ( 7840 ) : 82 – 87 . 7 . Le TT , Andreadakis Z , Kumar A , Roma´n RG , Tollefsen S , Saville M , et al . The COVID - 19 vaccine development landscape . Nat Rev Drug Discov . 2020 ; 19 ( 5 ) : 305 – 306 . 8 . Mitja ` O , Clotet B . Use of antiviral drugs to reduce COVID - 19 transmission . The Lancet Global Health . 2020 ; 8 ( 5 ) : e639 – e640 . 9 . Ball P . The lightning - fast quest for COVID vaccines – and what it means for other diseases . Nature . 2020 ; 589 : 16 – 18 . 10 . Food and Drug Administration . Pfizer - BioNTech COVID - 19 Vaccine EUA Letter of Authorization ; 2020 . https : / / www . fda . gov / media / 144412 / download ( Accessed January 2022 ) . January 17 , 2023 16 / 20 11 . Food and Drug Administration . Moderna COVID - 19 Vaccine EUA Letter of Authorization ; 2020 . https : / / www . fda . gov / media / 144636 / download ( Accessed January 2022 ) . 12 . Dagan N , Barda N , Kepten E , Miron O , Perchik S , Katz MA , et al . BNT162b2 mRNA Covid - 19 Vaccine in a Nationwide Mass Vaccination Setting . New England Journal of Medicine . 2021 ; 384 ( 15 ) : 1412 – 1423 . 13 . Lopez Bernal J , Andrews N , Gower C , Gallagher E , Simmons R , Thelwall S , et al . Effectiveness of Covid - 19 Vaccines against the B . 1 . 617 . 2 ( Delta ) Variant . New England Journal of Medicine . 2021 ; 385 ( 7 ) : 585 – 594 . 14 . Gupta S , Cantor J , Simon KI , Bento AI , Wing C , Whaley CM . Vaccinations Against COVID - 19 May Have Averted Up To 140 , 000 Deaths In The United States . Health Affairs . 2021 ; 40 ( 9 ) : 1465 – 1472 . 15 . Schneider EC , Shah A , Sah P , Moghadas SM , Vilches T , Galvani A . The U . S . COVID - 19 Vaccination Program at One Year : How Many Deaths and Hospitalizations Were Averted ? ; 2021 . Available from : https : / / www . commonwealthfund . org / publications / issue - briefs / 2021 / dec / us - covid - 19 - vaccination - program - one - year - how - many - deaths - and . 16 . Randolph HE , Barreiro LB . Herd Immunity : Understanding COVID - 19 . Immunity . 2020 ; 52 ( 5 ) : 737 – 741 . 17 . Mathieu E , Ritchie H , Ortiz - Ospina E , Roser M , Hasell J , Appel C , et al . A global database of COVID - 19 vaccinations . Nature Human Behaviour . 2021 ; 5 ( 7 ) : 947 – 953 . 18 . Johnson AG . COVID - 19 incidence and death rates among unvaccinated and fully vaccinated adults with and without booster doses during periods of Delta and Omicron variant emergence—25 US Jurisdictions , April 4 – December 25 , 2021 . MMWR Morbidity and Mortality Weekly Report . 2022 ; 71 . 19 . Bilal U , Mullachery PH , Schnake - Mahl A , Rollins H , McCulley E , Kolker J , et al . Heterogeneity in Spatial Inequities in COVID - 19 Vaccination across 16 Large US Cities . American Journal of Epidemiology . 2022 ; . 20 . MacDonald NE , et al . Vaccine hesitancy : Definition , scope and determinants . Vaccine . 2015 ; 33 ( 34 ) : 4161 – 4164 . 21 . Wilson SL , Wiysonge C . Social media and vaccine hesitancy . BMJ Global Health . 2020 ; 5 ( 10 ) : e004206 . 22 . Larson HJ . The biggest pandemic risk ? Viral misinformation . Nature . 2018 ; 562 ( 7726 ) : 309 – 310 . 23 . Burki T . Vaccine misinformation and social media . The Lancet Digital Health . 2019 ; 1 ( 6 ) : e258 – e259 . 24 . Rathje S , He JK , Roozenbeek J , Van Bavel JJ , van der Linden S . Social media behavior is associated with vaccine hesitancy . PNAS Nexus . 2022 ; 1 ( 4 ) : pgac207 . 25 . Zarocostas J . How to fight an infodemic . The Lancet . 2020 ; 395 ( 10225 ) : 676 . January 17 , 2023 17 / 20 26 . Chen E , Jiang J , Chang HCH , Muric G , Ferrara E , et al . Charting the information and misinformation landscape to characterize misinfodemics on social media : COVID - 19 infodemiology study at a planetary scale . JMIR Infodemiology . 2022 ; 2 ( 1 ) : e32378 . 27 . Cinelli M , Quattrociocchi W , Galeazzi A , Valensise CM , Brugnoli E , Schmidt AL , et al . The COVID - 19 social media infodemic . Scientific Reports . 2020 ; 10 ( 1 ) : 1 – 10 . 28 . Gallotti R , Valle F , Castaldo N , Sacco P , De Domenico M . Assessing the risks of ‘infodemics’ in response to COVID - 19 epidemics . Nature Human Behaviour . 2020 ; 4 : 1285 – 1293 . doi : 10 . 1038 / s41562 - 020 - 00994 - 6 . 29 . Yang KC , Pierri F , Hui PM , Axelrod D , Torres - Lugo C , Bryden J , et al . The COVID - 19 Infodemic : Twitter versus Facebook . Big Data & Society . 2021 ; 8 ( 1 ) : 20539517211013861 . 30 . Hotez P , Batista C , Ergonul O , Figueroa JP , Gilbert S , Gursel M , et al . Correcting COVID - 19 vaccine misinformation : Lancet commission on COVID - 19 vaccines and therapeutics task force members . EClinicalMedicine . 2021 ; 33 . 31 . Pertwee E , Simas C , Larson HJ . An epidemic of uncertainty : rumors , conspiracy theories and vaccine hesitancy . Nature Medicine . 2022 ; 28 ( 3 ) : 456 – 459 . 32 . Loomba S , de Figueiredo A , Piatek SJ , de Graaf K , Larson HJ . Measuring the impact of COVID - 19 vaccine misinformation on vaccination intent in the UK and USA . Nature Human Behaviour . 2021 ; 5 ( 3 ) : 337 – 348 . 33 . Pierri F , Perry BL , DeVerna MR , Yang KC , Flammini A , Menczer F , et al . Online misinformation is linked to early COVID - 19 vaccination hesitancy and refusal . Scientific Reports . 2022 ; 12 ( 1 ) : 1 – 7 . 34 . Muric G , Wu Y , Ferrara E , et al . COVID - 19 Vaccine Hesitancy on Social Media : Building a Public Twitter Data Set of Antivaccine Content , Vaccine Misinformation , and Conspiracies . JMIR Public Health and Surveillance . 2021 ; 7 ( 11 ) : e30642 . 35 . Sharma K , Zhang Y , Liu Y . COVID - 19 Vaccine Misinformation Campaigns and Social Media Narratives . Proceedings of the International AAAI Conference on Web and Social Media . 2022 ; 16 : 920 – 931 . 36 . Lazer D , Baum M , Benkler Y , Berinsky A , Greenhill K , et al . The science of fake news . Science . 2018 ; 359 ( 6380 ) : 1094 – 1096 . 37 . Shao C , Ciampaglia GL , Varol O , Yang KC , Flammini A , Menczer F . The spread of low - credibility content by social bots . Nature Communications . 2018 ; 9 : 4787 . 38 . Grinberg N , Joseph K , Friedland L , Swire - Thompson B , Lazer D . Fake news on Twitter during the 2016 U . S . presidential election . Science . 2019 ; 363 ( 6425 ) : 374 – 378 . 39 . Pennycook G , Rand DG . Fighting misinformation on social media using crowdsourced judgments of news source quality . Proceedings of the National Academy of Sciences . 2019 ; 116 ( 7 ) : 2521 – 2526 . 40 . Bovet A , Makse HA . Influence of fake news in Twitter during the 2016 US presidential election . Nature Communications . 2019 ; 10 ( 1 ) : 1 – 14 . January 17 , 2023 18 / 20 41 . Center for Countering Digital Hate . The Disinformation Dozen ; 2021 . https : / / www . counterhate . com / files / ugd / f4d9b9 b7cedc0553604720b7137f8663366ee5 . pdf ( Accessed January 2022 ) . 42 . Knuutila A , Herasimenka A , Au H , Bright J , Nielsen R , Howard PN . COVID - related misinformation on YouTube : The spread of misinformation videos on social media and the effectiveness of platform policies ; 2020 . Oxford , UK : Project on Computational Propaganda . 43 . Liu Y , Eggo RM , Kucharski AJ . Secondary attack rate and superspreading events for SARS - CoV - 2 . The Lancet . 2020 ; 395 ( 10227 ) : e47 . 44 . DeVerna MR , Aiyappa R , Pacheco D , Bryden J , Menczer F . Identification and characterization of misinformation superspreaders on social media . arXiv ; 2022 . 2207 . 09524 . Available from : https : / / arxiv . org / abs / 2207 . 09524 . 45 . Nogara G , Vishnuprasad PS , Cardoso F , Ayoub O , Giordano S , Luceri L . The Disinformation Dozen : An Exploratory Analysis of Covid - 19 Disinformation Proliferation on Twitter . In : 14th ACM Web Science Conference 2022 ; 2022 . p . 348 – 358 . 46 . Ferrara E , Varol O , Davis C , Menczer F , Flammini A . The rise of social bots . Communications of the ACM . 2016 ; 59 ( 7 ) : 96 – 104 . 47 . Broniatowski DA , Jamison AM , Qi S , AlKulaib L , Chen T , Benton A , et al . Weaponized health communication : Twitter bots and Russian trolls amplify the vaccine debate . American Journal of Public Health . 2018 ; 108 ( 10 ) : 1378 – 1384 . 48 . DeVerna M , Pierri F , Truong B , Bollenbacher J , Axelrod D , Loynes N , et al . CoVaxxy : A global collection of English Twitter posts about COVID - 19 vaccines . In : Proceedings of the International AAAI Conference on Web and Social Media . vol . 15 ; 2021 . p . 992 – 999 . 49 . Di Giovanni M , Pierri F , Torres - Lugo C , Brambilla M . VaccinEU : COVID - 19 vaccine conversations on Twitter in French , German and Italian . In : Proceedings of the International AAAI Conference on Web and Social Media . vol . 16 ; 2022 . p . 1236 – 1244 . 50 . DeVerna M , Pierri F , Truong BT , Bollenbacher J , Axelrod D , Loynes N , et al . . CoVaxxy Tweet IDs dataset , 10 . 5281 / zenodo . 4526494 ; 2021 . Zenodo . 51 . NewsGuard , Inc . Rating process and criteria ; 2021 . Internet Archive https : / / web . archive . org / web / 20200630151704 / https : / / www . newsguardtech . co m / ratings / ra process - criteria / ( Accessed September 2021 ) . 52 . Shao C , Hui PM , Wang L , Jiang X , Flammini A , Menczer F , et al . Anatomy of an online misinformation network . PLOS ONE . 2018 ; 13 ( 4 ) : e0196087 . 53 . YouTube . COVID - 19 medical misinformation policy ; 2020 . Available from : https : / / support . google . com / youtube / answer / 9891785 ? hl = en . 54 . YouTube . Managing harmful vaccine content on YouTube ; 2021 . Available from : https : / / blog . youtube / news - and - events / managing - harmful - vaccine - content - youtube / . January 17 , 2023 19 / 20 55 . Axelrod D , Harper B , Paolillo J . YouTube COVID - 19 Vaccine Misinformation on Twitter : Platform Interactions and Moderation Blind Spots . In : Proceedings of the Conference on Truth and Trust Online ; 2022 . Available from : https : / / truthandtrustonline . com / wp - content / uploads / 2022 / 10 / TTO _ 2022 _ paper _ 1 . pdf . 56 . Yang KC , Varol O , Hui PM , Menczer F . Scalable and generalizable social bot detection through data selection . Proceedings of the AAAI Conference on Artificial Intelligence . 2020 ; 34 ( 1 ) : 1096 – 1103 . 57 . Smith MR . How a Kennedy built an anti - vaccine juggernaut amid COVID - 19 ; 2021 . Available from : https : / / apnews . com / article / how - rfk - jr - built - anti - vaccine - juggernaut - amid - covid - 4997be1bcf591fe8b7f1f 58 . Frenkel S . Facebook and Instagram Remove Robert Kennedy Jr . ’s Nonprofit for Misinformation ; 2022 . Available from : https : / / www . nytimes . com / 2022 / 08 / 18 / technology / facebook - instagram - robert - kennedy - jr - misinformation . html . 59 . Manjoo F . Alex Jones and the Wellness - Conspiracy Industrial Complex ; 2022 . Available from : https : / / www . nytimes . com / 2022 / 08 / 11 / opinion / alex - jones - wellness - conspiracy . html . 60 . Broniatowski DA , Kerchner D , Farooq F , Huang X , Jamison AM , Dredze M , et al . Twitter and Facebook posts about COVID - 19 are less likely to spread misinformation compared to other health topics . PloS one . 2022 ; 17 ( 1 ) : e0261768 . 61 . Lin H , Lasser J , Lewandowsky S , Cole R , Gully A , Rand D , et al . High level of agreement across different news domain quality ratings . PsyArXiv . 2022 ; . 62 . Wojcik S , Hughes A . Sizing Up Twitter Users ; 2019 . Available from : https : / / www . pewresearch . org / internet / 2019 / 04 / 24 / sizing - up - twitter - users / . 63 . McGregor SC , Molyneux L . Twitter’s influence on news judgment : An experiment among journalists . Journalism . 2020 ; 21 ( 5 ) : 597 – 613 . 64 . Auxier B , Anderson M . Social Media Use in 2021 ; 2021 . Available from : https : / / www . pewresearch . org / internet / 2021 / 04 / 07 / social - media - use - in - 2021 / . 65 . Dub´e E , Laberge C , Guay M , Bramadat P , Roy R , Bettinger JA . Vaccine hesitancy : an overview . Human Vaccines & Immunotherapeutics . 2013 ; 9 ( 8 ) : 1763 – 1773 . 66 . Rogers R . Deplatforming : Following extreme Internet celebrities to Telegram and alternative social media . European Journal of Communication . 2020 ; 35 ( 3 ) : 213 – 229 . 67 . Jhaver S , Boylston C , Yang D , Bruckman A . Evaluating the effectiveness of deplatforming as a moderation strategy on Twitter . Proceedings of the ACM on Human - Computer Interaction . 2021 ; 5 ( CSCW2 ) : 1 – 30 . 68 . Chandrasekharan E , Pavalanathan U , Srinivasan A , Glynn A , Eisenstein J , Gilbert E . You can’t stay here : The efficacy of reddit’s 2015 ban examined through hate speech . Proceedings of the ACM on Human - Computer Interaction . 2017 ; 1 ( CSCW ) : 1 – 22 . January 17 , 2023 20 / 20 69 . Ali S , Saeed MH , Aldreabi E , Blackburn J , De Cristofaro E , Zannettou S , et al . Understanding the effect of deplatforming on social networks . In : 13th ACM Web Science Conference 2021 ; 2021 . p . 187 – 195 . 70 . Bilton N . The Downfall of Alex Jones Shows How the Internet Can Be Saved ; 2021 . Available from : https : / / www . vanityfair . com / news / 2019 / 04 / the - downfall - of - alex - jones - shows - how - the - internet - can - be - saved . 71 . Papakyriakopoulos O , Goodman E . The Impact of Twitter Labels on Misinformation Spread and User Engagement : Lessons from Trump’s Election Tweets . In : Proceedings of the ACM Web Conference 2022 ; 2022 . p . 2541 – 2551 . 72 . Zannettou S . ” I Won the Election ! ” : An Empirical Analysis of Soft Moderation Interventions on Twitter . In : Proceedings of the International AAAI Conference on Web and Social Media . vol . 15 ; 2021 . p . 865 – 876 . 73 . Pasquetto IV , Swire - Thompson B , Amazeen MA , Benevenuto F , Brashier NM , Bond RM , et al . Tackling misinformation : What researchers could do with social media data . The Harvard Kennedy School Misinformation Review . 2020 ; 1 ( 8 ) . doi : 10 . 37016 / mr - 2020 - 49 .