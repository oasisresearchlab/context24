NATURE . COM Discuss this article online at : go . nature . com / jyfnuh Redefine misconduct as distorted reporting To make misconduct more difficult , the scientific community should ensure that it is impossible to lie by omission , argues Daniele Fanelli . A gainst an epidemic of false , biased and falsified findings , the scientific community’s defences are weak . Only the most egregious cases of misconduct are discovered and punished . Subtler forms slip through the net , and there is no protection from publication bias . Delegates from around the world will discuss solutions to these problems at the 3rd World Conference on Research Integrity ( wcri2013 . org ) in Montreal , Canada , on 5 – 8 May . Common propos - als , debated in Nature and elsewhere , include improving mentorship and training , publishing negative results , reducing the pressure to publish , pre - registering studies , teaching ethics and ensuring harsh punishments . These are important but they overestimate the benefits of correct - ing scientists’ minds . We often forget that scientific knowledge is reliable not because scientists are more clever , objective or honest than other people , but because their claims are exposed to criticism and replication . The key to protecting science , therefore , is to strengthen self - correction . Publication , peer - review and misconduct investigations should focus less on what scientists do , and more on what they communicate . What is wrong with current approaches ? By defining misconduct in terms of behaviours , as all countries do at present , we have to rely on whistle - blowers to discover it , unless the fabrica - tion is so obvious as to be apparent from papers . It is rare for misconduct to have witnesses ; and surveys suggest that when people do know about a colleagues’ misbehaviour , they rarely report it . Investigators , then , face the arduous task of reconstructing what a scientist did , establish - ing that the behaviour deviated from accepted practices and determin - ing whether such deviation expressed an intention to deceive . Only the most clear - cut cases are ever exposed . Take the scandal of Diederik Stapel , the Dutch star psychologist who last year was revealed to have been fabricating papers for almost 20 years . How was this possible ? First , Stapel insisted on collecting data by himself , which kept away potential whistle - blowers . Second , researchers had no incentive to replicate his experiments , and when they did , they lacked sufficient information to explain discrepancies . This was mainly because , third , Stapel was free to omit from papers details that would have revealed lies and statistical flaws . In tackling these issues , a good start would be to redefine miscon - duct as distorted reporting : ‘any omission or misrepresentation of the information necessary and sufficient to evaluate the validity and signifi - cance of research , at the level appropriate to the context in which the research is communicated’ . Some might consider this too broad . But it is no more so than the definition of falsification used by the US Office of Science and Technology Policy : “manipulating research materials , equipment , or processes , or changing or omitting data or results such that the research is not accurately represented in the research record” . Unlike this definition , however , mine points unambiguously to misconduct whenever there is a mismatch between what was reported and what was done . Authors should be held accountable for what they write , and for recording what they did . But who decides what information is neces - sary and sufficient ? That would be experts in each field , who should prepare and update guidelines . This might seem daunting , but such guidelines are already being published for many biomedical tech - niques , thanks to initiatives such as the EQUATOR Network ( equa - tor - network . org ) or Minimum Information for Biological and Biomedical Investigations ( mibbi . sourceforge . net ) . The main task of journal editors and referees would then be to ensure that researchers comply with reporting requirements . They would point authors to the appropriate guidelines , perhaps before the study had started , and make sure that all the requisite details were included . If authors refused or were unable to comply , their paper ( or grant application or talk ) would be rejected . The publication would indicate which set or sets of guidelines were followed . By focusing on reporting practices , the com - munity would respect scientific autonomy but impose fairness . A scientist should be free to decide , for example , that ‘fishing’ for statistical significance is nec - essary . However , guidelines would require a list of every test used , allowing others to infer the risk of false positives . Carefully crafted guidelines could make fabrication and plagia - rism more difficult , by requiring the publication of verifiable details . And they could help to uncover questionable practices such as ghost authorship , exploiting subordinates , post hoc hypotheses or drop - ping outliers . Graduate students could , in addition to learning the guidelines , train by replicating published studies . Special research funds could be reserved for independent replications of unchallenged claims . The current defence against misconduct is prepared for the wrong sort of attack : the community tries to regulate research like any other profession , but it is different . The reliability of scientific ‘products’ is ensured not by individual practice , but by collective dialogue . ■ Daniele Fanelli is a research fellow at the University of Edinburgh , UK . e - mail : dfanelli @ exseed . ed . ac . uk FOCUS LESS ON WHAT SCIENTISTS DO AND MORE ON WHAT THEY COMMUNICATE . 1 4 F E B R UA RY 2 0 1 3 | V O L 4 9 4 | N AT U R E | 1 4 9 WORLD VIEW A personal take on events © 2013 Macmillan Publishers Limited . All rights reserved