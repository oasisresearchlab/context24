Software Product Lines for Development of Evolutionary Robots S√∂ren Nienaber University of L√ºbeck L√ºbeck , Germany nienaber @ iti . uni - luebeck . de Mohammad D . Soorati University of Southampton Southampton , UK m . soorati @ soton . ac . uk Arash Ghasemzadeh University of Guilan Rasht , Iran ghasemzadehh . arash @ gmail . com Javad Ghofrani University of L√ºbeck L√ºbeck , Germany javad . ghofrani @ gmail . com ABSTRACT Evolutionary Robotics utilizes evolutionary algorithms for train - ing robot controllers ( e . g . , neural networks ) and adapting robot morphologies for different environments in design and runtime . One of the main challenges in robotics is the lack of reusability as AI - based robot controllers have to be trained from scratch for any change in the environment or a new task specification that a robot should adapt to . Training Artificial Neural Networks can be computationally heavy , time - consuming , and hard to reuse due to their monolithic black - box nature . The building blocks of emerging behaviors from Artificial Neural Networks cannot be fully sepa - rated or reused . We address the issue of reusability and propose an incremental approach for applying the reusability of behaviors . We implemented an Evolutionary Robotics framework to form a product family of robots . This product family is used to show the feasibility of our method for handling variability in a domain . Our results can be used to demonstrate a sample binding between the software product lines and machine learning domains . KEYWORDS Evolutionary Robotics , Software Product Lines , Configuration , Mo - bile Robots , Primitive Behaviors ACM Reference Format : S√∂ren Nienaber , Mohammad D . Soorati , Arash Ghasemzadeh , and Javad Ghofrani . 2023 . Software Product Lines for Development of Evolutionary Robots . In 27th ACM International Systems and Software Product Line Con - ference - Volume B ( SPLC ‚Äô23 ) , August 28 - September 1 , 2023 , Tokyo , Japan . ACM , New York , NY , USA , 8 pages . https : / / doi . org / 10 . 1145 / 3579028 . 3609018 1 INTRODUCTION Inspired by the evolution of species , Evolutionary Robotics aims at building robots that are evolved over time to accomplish complex tasks . The concept of evolution is used for the morphology or the Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , topostonserversortoredistributetolists , requirespriorspecificpermission and / or a fee . Request permissions from permissions @ acm . org . SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan ¬© 2023 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 979 - 8 - 4007 - 0092 - 7 / 23 / 08 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3579028 . 3609018 controller of the robots to adapt to criteria such as environmen - tal conditions . In evolutionary robotics , instead of designing the controller of the robots to perform specific tasks in complicated en - vironments , a population of robot controllers ( i . e . , Artificial Neural Networks ( ANNs ) ) will be trained as the robots interact with the en - vironment over various generations to reach a certain level of fitness . Note that training the physical robots in real environments requires significantly more time and investment . Therefore , the preliminary studies are based on training the evolutionary robotic solutions in simulation [ 19 ] with consideration of the reality gap [ 36 ] . Using evo - lutionary algorithms , an ANN will be trained to perform expected tasks by reading the signals from environments through the robot sensors and generating control signals for the actuators of the robot . The tasks are mainly consisting of primitive behaviors such as moving towards the light source , turning around an obstacle , avoid - ing barriers such as walls and borders , and closing / opening the gripper [ 3 ] . The robots can be trained to perform a combination of those primitive behaviors ( e . g . , exploring the environment , finding objects , and pushing them to a certain region ) . However , the trained ANN is a monolithic black box . The functionality of ANNs is the result of the mixture of input values and weights . Therefore , any small change in the structure or values of an ANN affects the entire functionality of that network . Sculley et al . [ 31 ] mention this issue as CACE principle ‚Äì Changing Anything Changes Everything . De - spite efforts in modular controllers [ 14 ] , this issue makes it hard to extract separated modules from a trained ANN and build a product line of various behaviors . For any combination of primitive tasks , a completely new evolutionary process need to be established . Due to the monolithic structure of trained ANNs , it is complicated to apply the techniques of product line engineering ( PLE ) in this context . PLE is mainly applied in the development of modular hardware and software blocks for robotics [ 2 , 7 ‚Äì 9 ] , but applying PLE techniques is a challenge in ML - based systems [ 18 , 31 ] . In Evolutionary Robotics ( ER ) , robots evolve to increase their fitness values which highly depends on the fitness function design . The design of the fitness functions is still a manual and slow pro - cess . In earlier work , we have shown that fitness function design is still highly dependent on the designers‚Äô a priori knowledge of the domain [ 32 ] . We use the concept of feature - oriented software devel - opment [ 4 ] and evolution - based software product lines [ 23 , 24 ] to combine controllers that suites the task at hand . Feature - oriented software development is based on a separated development of fixed and variable functionalities , called features , and building a soft - ware product line through composing and reusing them . Another SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan S . Nienaber et al . inspiring concept is the separated development of the features in a software product line as subsystems , which evolve apart from each other based on the changes in requirements and architectures of those features . Similarly , our concept is based on a separated training ‚Äì instead of development ‚Äì of behaviors of robots and com - bining them for generating a product line of robot controllers . We show the feasibility of our method by implementing a prod - uct family of ANNs with different robotic behaviors . We show how various features can be selectively developed on a monolithic ML - based system . We map the different primitive behaviors of robots and the concept of features in the PLE . We can increase the ef - fectiveness of evolutionary robots and develop a family of robot controllers with various combinations of functionalities . Our ap - proach enables system designers to train and evolve each behavior while maintaining the flexibility to select , remove , or create new robot controllers by manipulating these features . Our main contribution in this paper is to propose a method of combining PLE with the evolutionary controller design of robots . PLE enables the development of a family of robotic systems with similar but different capabilities . With this , we try to achieve better accessibility and faster development processes for robotic controller design . For this purpose , we extended an existing open source platform ( developed by Matthias H√ºppi [ 20 ] ) to evolve a simulated vehicle‚Äôs controller that learns to drive on a track . This was done by adding different fitness functions for our behaviors as well as new training arenas . The rest of the paper is structured as follows . Section 2 con - tains the details of our approach . Section 3 describes the general experimental setup with implementation details and discusses the specifications of the examined behaviors . We show the results of our experiments in Experimental Results . In Section 5 we discuss the existing approaches in the literature and their differences from ours , and discuss the current issues and future work in Section 6 . Finally , Section 7 concludes the paper and answers the research questions . 2 METHODOLOGY The main idea of this paper is to create a software product line of evolutionary based control systems for mobile robots . First , we introduce the general model of a mobile robot according to Brait - enberg [ 6 ] illustrated in Figure 1 . The mobile robot is placed in an environment and can measure various values of the environ - ment with the built - in sensors ( e . g . , its distance to barriers , light intensity , acceleration , GPS , etc . ) . Note that the robot is a part of the environment . The output of the sensors will be processed by a controller . The controller is a program that generates output signals for controlling the actuators of the robot based on the inputs . In our experiments , the actuators are two motors ( left and right ) for controlling the robot wheels . Complex robotic systems can have more and different types of actuators . In the simplest form , the output signal can rotate the motor in a certain direction or stop it . If both motors are activated , the robot can move forward . In the case of steering to the right or left , the corresponding motor should be stopped , and the opposite motor should rotate . Using this simple mechanism the mobile robot can interact with the environment through different ‚Äúprimitive behaviors‚Äù [ 3 ] such M2 M1 Controller S1 S2 S3 S4 S5 Figure 1 : Structure of simple mobile robot as moving towards an object , a light source , or avoiding an object or a barrier . Descriptions of some of these behaviors are listed in Table 1 . Evolved behaviors for the robots are not limited to this list , especially if the robot has more than two actuators , such as moving arms or grippers . Table 1 : A selection of primitive robotic behaviors Behavior Description Wall Following The robot follows a wall as close as possible . Obstacle Avoidance Driving around a de - tected obstacle . Backtracking Retrace the steps taken by a robot . Homing The robot drives to a home base from any point . Exploration Visiting as much of the environment as possi - ble . In mainstream robotics , contrary to evolutionary robotics , the developers are responsible for the design of the robot controller . In evolutionary robotics , the main role of the developer is to define the fitness function that measures the quality of the performance of an expected task . The main challenge here is , that there is no general approach for defining a fitness function as it is highly dependent on the task . The evolution of the ANN - based controller begins with a generation of controllers with random values as weights of the ANN and measures the fitness . Usually , the ANNs that reach the best fitness values will be selected as the parents for the next generation . These iterations will continue till the robots reach a certain level of fitness . This process is illustrated in Fig . 2 . Considering each behavior that the robot evolves during the iteration as a " feature " in the PLE , we can create a product line of mobile robots with different combinations of primitive behaviors . This way , a controller of an ANN - based mobile robot ( and in general any robot ) can be illustrated with a set of primitive behaviors . This way , different configurations of the behaviors can be presented as a feature diagram . Fig . 3 shows the general structure of such feature diagram . This step represents the domain engineering of PLE . It can have more or less features depending on the use case and the Software Product Lines for Development of Evolutionary Robots SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan Stage 1 Stage 3 Stage 2 Stage 4 Start generating cars and evaluate them via fitness Predict direction with model Mutation and cross - over Select best cars from previous generation Next generation Figure 2 : Steps required for the development of solutions based on evolutionary algorithms . Behavior behaviorset 2 behaviorset 1 behavior behavior 6 Optional Mandatory Or And Alternative behavior 4 behavior 5 behavior 3 Figure 3 : Feature diagram representing the behaviors of the robots as selectable features structure of the robot . Instead of writing programs for individual behaviors , an environment with expected complexities and a fitness function should be described for each behavior . It is complicated to create an ANN - based control unit with a modular composition of behaviors [ 26 ] . For this purpose , a sequence of steps is planned . In each step , a new behavior can be developed and the resulting ANN can be used for adding new behaviors in the next step . As illustrated in Fig . 4 the mandatory behaviors ( e . g . , exploration ) will be evolved in the first step . At the beginning of this step , a population of initial ANNs is initialized . The defined fitness function for the first behavior measures the performance of the robots . Robots with the best fitness values will be selected for generating a new population . After many iterations , an ANN which is evolved to perform the expected task will be the outcome of the first step . This ANN can be reused for getting extended with further behavior in the next steps . The benefit of this step - by - step approach is also demonstrated in Fig . 4 . Evolving each behavior in a separate step allows us to add new behavior to the trained behavior selectively . This way , one behavior or a set of behaviors can be reused as a base for further behaviors in the evolution process of the controller product line . It is important to note that learned behaviors of a subsequent step cannot be extracted from the final set of behaviors . This is comparable with the software modules in the software product lines , which are not easily extractable from the final products . However , training each behavior happens separately and each of the illustrated behaviors in Fig 4 can be used without any dependency to other behavior . For example , behavior 2 can be used as a single product without behavior 1 . But after adding behavior 2 to the controller which is already trained on behavior 1 , it is not that simple to separate them . We implemented the application engineering phase [ 28 ] of the product line of the robot controller . 3 EXPERIMENTS To show that our approach is feasible , we planned an experiment with a simulation tool for ER [ 20 ] . Our extensions and the imple - mentation can be found on Github [ 25 ] . 3 . 1 Robotic Setup The robots are simulated in a square Pygame [ 27 ] environment that has different setups based on the behavior . The robot is a simple rectangular vehicle with two different types of sensors . Firstly , a light sensor that is mounted on top of the robot measures the light intensity . The other sensors are seven proximity sensors mounted around the robot , each with a different angle in the front - facing direction of the vehicle . An example of a similar robot can be seen in Fig . 1 . The robot controllers in our framework are represented by simple ANNs with one hidden layer . Each layer uses the softmax function 2 . 0 ( 1 + ùëí ‚àí 2 ùë• ) ‚àí 1 . 0 as the activation . This leads to the neural network predicting two values between - 1 and 1 . The first value is the ve - locity of the robot in the next time step . The velocity however is given to a non - weighted Rectified Linear Unit ( ùëöùëéùë• ( 0 , ùë• ) ) to pre - vent negative velocity . The second predicted value is the angular change of the robot in the next time step , which is subtracted from the current heading angle of the robot . 3 . 2 Examined Robotic Behaviors The robot can be trained on four different behaviors that can be trained in any configuration of enabled and disabled behaviors . SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan S . Nienaber et al . Evolution Environment Fitness Behavior 2 Evolution Environment Fitness Evolution Environment Fitness Behavior 1 ( B1 , B3 ) ( B1 , B2 ) Behavior 3 Reuse Figure 4 : Reusing the developed behaviors for creating new complex behaviors ( 1 ) The first behavior is exploration . The goal of this behavior is to explore the environment as much as possible , which is equal to the number of visited cells . The fitness for this behavior is also defined as the number of visited cells , such that the best robot has the most distinct cells visited . ( 2 ) As a second behavior the robot is trained on a homing task . In this task , robot should be able to reach a home base that is marked as a green square from a random starting location . To measure that we defined the best result as 0 . 1 √ó ( ùëë ‚àí ùëû ) , where ùëë is the distance of the robot from the middle point of the home base and q is the number of time steps the robot stayed in the quadrant of the environment that the home base is located in . If the robot reached the home base , the fitness is multiplied by 0 . 01 . ( 3 ) In the obstacle avoidance behavior the robot is supposed to learn to drivearound in the environment while avoiding any obstacles . Here the fitness is equal to the number of visited cells while also rewarding the robot for keeping its distance from any obstacles . ( 4 ) The last behavior is wall following , in which the robot is supposed to follow a wall in the environment without crash - ing into it while also staying close to it . For this , we defined the fitness as the sum of the driven distance , the survived time steps and the inverse of the minimum measured sensor distance . 3 . 3 Experimental setup The four different behaviors ( exploration , homing , wall following , obstacle avoidance ) were each trained in an individual setup with four individual arenas . The four training steps were independent from each other such that the fitness functions only considers the examined behavior . This was done to ensure that the behaviors can be added and deleted in any order . Figure 5 shows the four arenas of size 600x600 that are used in the training . Additionally , a light source with the origin in ( 75 , 75 ) is placed in each environment . The light intensity is calculated as the distance from the light source , normalized between 1 and 0 , such that at the source the intensity is 1 . 0 and on the opposite corner the intensity is 0 . In the first run the neural network weights are randomly initialized . In all following experiments the weights are initialized with the weights Figure 5 : Depiction of the four arenas used for training of the four behaviors . A ) shows an empty arena for exploration . B ) shows an empty arena with the green home base in the upper left corner . C ) is a circular track that is used for the wall following . This arena was directly taken from the original project [ 20 ] . D ) is an arena with five obstacles that the vehicle should avoid . of a previously trained configuration . All weights except the weights of the first car are mutated before the first generation . Then a generation is run for a given number of steps . If all vehicles crash by hitting either the walls , an obstacle or the home base , then the generation will be ended preemptively . A generation is also ended early if at least half of the robots crash and additional 250 time steps have run . After each generation the two best performing vehicles are taken and used as the parents for the next generation . Here a random number of genomes are exchanged between the two best robots to build a new vehicle for the next generation . After this the genomes of all vehicles except the one , which contains the original weights of the best robot , are mutated . This is repeated until Software Product Lines for Development of Evolutionary Robots SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan the maximum number of generations is reached . Each generation throughout all behaviors has a population size of 75 vehicles . In a first step the exploration behavior is trained as this behavior serves as the foundation for all further configurations . Exploration is trained on arena A ( seen in Figure 5 ) for 75 generations . The high number of generation was chosen as this is considered the mandatory behavior . Each generation has a running time of 1000 time steps , if not ended early . Additionally , the generations are started with a randomly chosen initial position and initial angle , to avoid the robot learning the best path from just one position . After this we trained the other three behaviors with the weights of the exploration as the initial weights . The second behaviors were trained for 50 generations . The homing behavior was trained also for 1000 time steps , however , the initial position was not chosen randomly but one position was chosen from a list of predefined initial positions . This allows that the chance for reaching the home base is higher , as there are no positions that spawn directly in the wall . Wall following is trained on a circle track ( See 5 C ) to ensure that the robot is always close to a wall that it can follow . The initial position is always in the top of the ring with a right facing angle and each generation has a length of 1000 time steps . The obstacle avoidance is trained in an arena with 5 obstacles . Again random initial positions and angles are chosen to again avoid the robot just learning one path . Here 10 , 000 time steps were chosen to give a higher chance of the robot encountering the obstacles . The training steps were trained with decreasing number of generations with each additionally behavior to not entirely erase the previously learned behavior as the mutation is limited . Again the original trained exploration , trained for 75 generations . The second behavior was trained for 50 generations , while the third behavior was trained for 20 generations . 4 EXPERIMENTAL RESULTS We focused on two separate experiments , first an experiment in which all training runs ended on training the homing behavior ( see Figure 6 ) . Both experiments were conducted with three runs each , all starting on the exploration behavior in the first training step . The first run was the configuration exploration directly followed by homing . The other two runs both were trained on the second be - havior before being trained on homing , wall following and obstacle avoidance respectively . The second experiment has a similar setup except that each training run ended on the wall following behavior as the last training step . The second experiment can be seen in Fig - ure 7 . Here again exploration was used as the first trained behavior . Then again one run with wall following as the second behavior and two experiments that were trained with either homing or obstacle avoidance before being trained on wall following . In each run we tracked the fitness of the final trained behavior and used this data to plot the median and best fitness over all generations . Thus , Figure 6 shows the fitness of the homing behavior in all runs and Figure 7 shows the fitness of the wall following behavior experiment for all runs . What can be seen when looking at the results is that in both experiments the fitness converges faster when trained with another behavior . For example in Figure 6 does the median fitness of the run with homing as the second behavior not reach the low median fitness values that the other two runs reach . This is also reflected in the best fitness , as both the minimum and maximum values of the two behavior configurations are higher than the other two runs . The same can be seen when looking at the median fitness of the wall following experiment . The run with wall following directly after exploration has higher median values throughout most of the monitored generations . The same holds for the best fitness even though the two behavior run is close in values to the run with the homing behavior as the second trained behavior . In this experi - ment the run with the obstacle avoidance as the second behavior converges slower than the other two runs . These observations are not necessarily expected as the ANN in the robot controller is mu - tated in every generation . This is in contrast to the refinement in ANN training using backpropagation , where this behavior would be expected . Further , it is important to note that the arenas change between the training step . 5 RELATED WORK PLE techniques have been extensively utilized in software engi - neering for managing feature variability and enhancing system modularity [ 11 , 12 ] . However , limited research has investigated the application of PLE techniques in handling the variability in the level of ANN , especially for introducing variability and reuse in the ER domain . Speaking of collaboration between software product lines and AI , there are two directions : I ) AI methods and models are considered as a supporting tool in various stages of software development from requirement engineering to testing . As an example , Ripon et al . [ 29 ] introduce the application of ML for automated feature extraction for developing software product lines . In the field of software product lines , there are various studies in this direction . AI methods have been used to facilitate the selection of features and control the validity of selected features [ 1 , 35 ] . II ) Application of software product line engineering for developing AI - based applica - tions is less investigated . Idowu et al . [ 21 ] perform a survey on tools and techniques for handling the asset ( e . g . Dataset , Models , Con - figurations , etc . ) for the development of machine learning models . Ballesteros and Fuentes [ 5 ] propose the application of transferred learning for dynamic software product lines . However , they use the gained knowledge from previous decision - making processes for making new decisions required for the new reconfiguration of the system . Ghamizi et al . [ 17 ] propose an automated framework for finding the best configuration for Deep Neural Network ( DNN ) architectures . Garcia et al . [ 16 ] focused on identifying , modeling , and managing variability within the domain of service robots . Along this work , Garcia et al . discuss the software variability in robotic software . Our automated approach for evolving robot controllers is similar to the functional incremental fitness functions where the robot‚Äôs fitness function changes over time but our method is based on a product line approach and does not need the designer‚Äôs intervention for the appropriate combination and timing of different fitness function placement . A similar concept of transferred learning ( TL ) which exists in the development of deep neural networks has many differences with our proposed methods . TL is mainly applied to image processing SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan S . Nienaber et al . Figure 6 : Upper : Median Fitness of three test runs that ended on homing behavior . Lower : Best Fitness of three test runs that ended on homing behavior . Both plots show the fitness of the homing behavior over 20 generations . and classification tasks in which a pre - trained network will be trained with new data . In that case , since the DNN is already able to recognize the basic concepts of image like lines and shapes , it learns faster , i . e . , with less data and iterations . However , this method is used mainly for single task operations and due to the huge computational power needed , is not possible to install on an mobile robot with an interactive environment . Reinforcement learning ( RL ) is another concept that is famous among robotic community for teaching the robot within an interac - tive environment [ 34 ] . However , according to our knowledge , there is no other studies which applies the PLE to the RL . This could be an extension as future work of our paper . Modular neural network architectures for robotics [ 10 ] is a well - established field of research in robotics . According to this concept , each behavior in the robotic system is connected to a separate ANN Figure 7 : Upper : Median Fitness of three test runs that ended on wall following behavior . Lower : Best Fitness of three test runs that ended on wall following behavior controller . This is similar to the concept of modular software ar - chitectures , where different functionalities or system components are implemented in a separate software module . These kinds of modular architectures require additional runtime complexities [ 31 ] . Additional mechanisms should be implemented to handle the col - laboration and synchronization between the modules and provide the runtime environment for parallel processing and scheduling of all those modules . As an example , our behaviors ( i . e . , wall following , exploration , obstacle avoidance , and homing ) can be implemented as separate modules . If all modules have access to the motors of the robot at the same time , it leads to conflicts between the gener - ated control signals by each module . For this reason , an additional arbiter is required to make decisions about activation of the best proper module for each situation . However , implementing such a decision - making mechanism is a challenging task . Software Product Lines for Development of Evolutionary Robots SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan 6 DISCUSSION The main objective of this paper is to combine the concepts of PLE and ER . Our proposed methodology is also an attempt to fill the gap between two domains of research and science . On one hand , to the best of our knowledge , no other studies has investigated the synergies between these two concepts . Therefore , various discus - sions will still be open due to the space limitations in this paper . On the other hand , we are aware that the proposed solution has many shortages . The discussions can be taken as a starting point for further research activities . The proposed case study in this pa - per is to demonstrate that our idea works and to make it easier to elaborate the idea . However , applying the idea to the domain of robotics ( not limited to mobile robots ) could still cause a lot of changes and challenges . Second discussion point in the paper is the evolution of the con - trol program . In this paper , we have only considered the evolution of the program on a fixed architecture of ANN . However , there are other evolutionary methods e . g . , NeuroEvolution of Augment - ing Topologies ( NEAT ) which are starting with a simple ANN and evolve the architecture of the ANN through evolution to find the optimal architectures [ 33 ] . The evolution of ANN architecture is out of the scope of this paper and will be considered in future studies . The robots that we have talked about in this paper are built based on an interactive paradigm of sense - act which is the simplest form of robot control systems . In this paradigm , there is no world model , and the environment is the model that robot interacts with it . More complex models exist which are also out of scope of this paper and should be discussed and investigated in a more detailed manner . Those paradigms consist of an step for planning which is supported by a priori knowledge from the environment . Although the definition of behavior of the robot is bypassed with evolutionary algorithms , the definition of fitness functions in a proper way , that fulfills the requirements of the desired behaviors , is still an open challenge [ 13 ] . As the experiments , presented in Section 4 , show the conver - gence of the learned behaviors improve with additional learned behaviors . Further , it is shown that this observation is independent of the order in which the behavior is trained . These findings are similar to previous findings [ 30 ] . Our approach however is just a proof of concept for showing a the usage of PLE ideas in ER . Thus , there are several limitations to our work . For example the behav - iors as well as the used fitness functions are basic designs . Here , improving the fitness functions would also improve the stability of the whole system . This could be addressed by taking other factors into account i . e . robot velocity or the angular change of the robot over time . Another point in which our approach is limited is the design of the arenas , as these were designed to have a simple way of learning the behavior . If now the arena complexity improves , there is a chance that the robots would not perform in the same way . Making the arenas more complex , also requires more complex robot systems that are able to process more data . One point of discussion is also the used neural network . We de - cided for a small neural network for two reasons . 1 ) The individual behaviors we wanted to train are primitive behaviors for which a large , complex model would quickly develop a bias towards the training data [ 15 ] . 2 ) A small model with few trainable parame - ters would lead to a faster overall convergence of the models in all training runs . There is however one downside of the choice of neural network . Due to the fixed size of the network , it can happen that the per - formance of the existing behaviors of the robot get weaker if the new behaviors are evolved . This problem is known as catastrophic forgetting [ 22 ] in literature . Regarding to this problem , the order of added behaviors to the robot , can also affect the already evolved behaviors too . 7 CONCLUSION Although the monolithic and non - modular architecture of ANN - based controllers of robots does not allow us to apply the concept of reuse , we introduced a method to apply the concept of PLE for reusing behaviors in the development of those robotic systems . Our intention was to introduce another aspect of robotics to the community of the software product lines while transferring the knowledge from this community to support the robotic experts to develop new robotic systems without " reinventing the wheel " for each new project . By treating different behaviors as features , we showcased the flexibility of our approach in training , selecting , and creating robot controllers with varying behaviors . Our concept extended an existing project for evolutionary robotics , demonstrat - ing the practicality and effectiveness of software product lines in the development of mobile robot controllers . We conducted some experiments using our implementation that focused on the training of the different behaviors . These experiments showed that train - ing the robot incrementally on multiple behaviors does increase the fitness of the last behavior . From these results a reusability of trained behaviors in the training of further behaviors can be seen . Future work on this could focus on further refining and optimizing the proposed methodology ( e . g the fitness function ) for broader applications in the field of evolutionary robotics . REFERENCES [ 1 ] Uzma Afzal , Tariq Mahmood , and Zubair Shaikh . 2016 . Intelligent software product line configurations : A literature review . Computer Standards & Interfaces 48 ( 2016 ) , 30 ‚Äì 48 . [ 2 ] Reem J Alattas , Sarosh Patel , and Tarek M Sobh . 2019 . Evolutionary modular robotics : Survey and analysis . Journal of Intelligent & Robotic Systems 95 ( 2019 ) , 815 ‚Äì 828 . [ 3 ] Tracy L Anderson and Max Donath . 1990 . Autonomous robots and emergent behavior : asetofprimitivebehaviorsformobilerobotcontrol . In EEEInternational WorkshoponIntelligentRobotsandSystems , TowardsaNewFrontierofApplications . IEEE , 723 ‚Äì 730 . [ 4 ] Sven Apel , Don Batory , Christian K√§stner , and Gunter Saake . 2016 . Feature - oriented software product lines . Springer . [ 5 ] Joaqu√≠n Ballesteros and Lidia Fuentes . 2021 . Transfer learning for multiobjec - tive optimization algorithms supporting dynamic software product lines . In Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B . 51 ‚Äì 59 . [ 6 ] Valentino Braitenberg . 1984 . Vehicles . [ 7 ] Davide Brugali . 2021 . Software Product Line Engineering for Robotics . Software Engineering for Robotics ( 2021 ) , 1 ‚Äì 28 . [ 8 ] Davide Brugali , Luca Gherardi , A Biziak , Andrea Luzzana , and Alexey Zakharov . 2012 . A reuse - oriented development process for component - based robotic sys - tems . In Simulation , Modeling , and Programming for Autonomous Robots : Third International Conference , SIMPAR 2012 , Tsukuba , Japan , November 5 - 8 , 2012 . Pro - ceedings 3 . Springer , 361 ‚Äì 374 . [ 9 ] Thomas Buchmann , Johannes Baumgartl , Dominik Henrich , and Bernhard West - fechtel . 2015 . Robots and their Variability ‚Äì A Societal Challenge and a Potential Solution . In 2015IEEE / ACM5thInternationalWorkshoponProductLineApproaches in Software Engineering . IEEE , 27 ‚Äì 30 . SPLC ‚Äô23 , August 28 - September 1 , 2023 , Tokyo , Japan S . Nienaber et al . [ 10 ] JL Buessler and JP Urban . 2003 . Modular neural architectures for robotics . Bio - logically inspired robot behavior engineering ( 2003 ) , 261 ‚Äì 298 . [ 11 ] Rafael Capilla , Jan Bosch , Kyo - Chul Kang , et al . 2013 . Systems and software variability management . Concepts Tools and Experiences 10 ( 2013 ) , 2517766 . [ 12 ] Lianping Chen , Muhammad Ali Babar , and Nour Ali . 2009 . Variability manage - ment in software product lines : a systematic review . In Proceedings of the 13th International Software Product Line Conference . Citeseer , 81 ‚Äì 90 . [ 13 ] Agoston E Eiben and James E Smith . 2015 . Introduction to evolutionary computing . Springer . [ 14 ] Kai Olav Ellefsen , Jean - Baptiste Mouret , and Jeff Clune . 2015 . Neural modularity helps organisms evolve to learn new skills without forgetting old skills . PLoS computational biology 11 , 4 ( 2015 ) , e1004128 . [ 15 ] Scott Fortmann - Roe . 2012 . Understanding the Bias - Variance Tradeoff . http : / / scott . fortmann - roe . com / docs / BiasVariance . html . [ 16 ] Sergio Garc√≠a , Daniel Str√ºber , Davide Brugali , Alessandro Di Fava , Philipp Schillinger , Patrizio Pelliccione , and Thorsten Berger . 2019 . Variability mod - eling of service robots : Experiences and challenges . In Proceedings of the 13th internationalworkshoponvariabilitymodellingofsoftware - intensivesystems . 1 ‚Äì 6 . [ 17 ] Salah Ghamizi , Maxime Cordy , Mike Papadakis , and Yves Le Traon . 2019 . Au - tomated search for configurations of deep neural network architectures . arXiv preprint arXiv : 1904 . 04612 ( 2019 ) . [ 18 ] Javad Ghofrani , Ehsan Kozegar , Anna Lena Fehlhaber , and Mohammad Divband Soorati . 2019 . Applying product line engineering concepts to deep neural net - works . In Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A . 72 ‚Äì 77 . [ 19 ] Inman Harvey 1 , Philip Husbands 1 , and Dave Cliff . 1993 . Issues in evolutionary robotics . In From Animals to Animats 2 : Proceedings of the Second International Conference on Simulation of Adaptive Behavior , Vol . 2 . MIT press , 364 . [ 20 ] Matthias H√ºppi . 2020 . Evolutionary - Car - AI . https : / / github . com / maede97 / Evolutionary - Car - AI . git . [ 21 ] Samuel Idowu , Daniel Str√ºber , and Thorsten Berger . 2022 . Asset management in machine learning : State - of - research and state - of - practice . Comput . Surveys 55 , 7 ( 2022 ) , 1 ‚Äì 35 . [ 22 ] James Kirkpatrick , Razvan Pascanu , Neil Rabinowitz , Joel Veness , Guillaume Desjardins , Andrei A Rusu , Kieran Milan , John Quan , Tiago Ramalho , Agnieszka Grabska - Barwinska , et al . 2017 . Overcoming catastrophic forgetting in neural networks . Proceedings of the national academy of sciences 114 , 13 ( 2017 ) , 3521 ‚Äì 3526 . [ 23 ] Lukas Linsbauer , Felix Schw√§gerl , Thorsten Berger , and Paul Gr√ºnbacher . 2021 . Conceptsofvariationcontrolsystems . JournalofSystemsandSoftware 171 ( 2021 ) , 110796 . [ 24 ] Ma√≠ra Marques , Jocelyn Simmonds , Pedro O Rossel , and Mar√≠a Cecilia Bastarrica . 2019 . Softwareproductlineevolution : Asystematicliteraturereview . Information and Software Technology 105 ( 2019 ) , 190 ‚Äì 208 . [ 25 ] S√∂ren Nienaber . 2023 . Evolutionary Robotics in Software Product Lines . https : / / github . com / rexolan0706 / EvoRobotics - in - SPL . git . [ 26 ] Stefano Nolfi , Josh Bongard , Phil Husbands , and Dario Floreano . 2016 . Evolu - tionary robotics . Springer handbook of robotics ( 2016 ) , 2035 ‚Äì 2068 . [ 27 ] PyGame Development team Pete Shinners . 2011 . PyGame . http : / / pygame . org / . [ 28 ] Klaus Pohl , G√ºnter B√∂ckle , and Frank Van Der Linden . 2005 . Software product line engineering . Vol . 10 . Springer . [ 29 ] Shamim Ripon , Fahim Shahrier Rasel , Ruhul Kabir Howlader , and Maheen Islam . 2020 . Automated Requirements Extraction and Product Configuration Veri - fication for Software Product Line . Automated Software Testing : Foundations , Applications and Challenges 15 ( 2020 ) , 27 ‚Äì 51 . [ 30 ] Claudio Rossi and A . Eiben . 2014 . Evolutionary Intelligence Simultaneous ver - sus incremental learning of multiple skills by modular robots . Evolutionary Intelligence 7 ( 06 2014 ) . https : / / doi . org / 10 . 1007 / s12065 - 014 - 0109 - 3 [ 31 ] David Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Diet - mar Ebner , Vinay Chaudhary , Michael Young , Jean - Francois Crespo , and Dan Dennison . 2015 . Hidden technical debt in machine learning systems . Advances in neural information processing systems 28 ( 2015 ) . [ 32 ] Mohammad Soorati and Heiko Hamann . 2015 . The Effect of Fitness Function Design on Performance in Evolutionary Robotics : The Influence of a Priori Knowledge . https : / / doi . org / 10 . 1145 / 2739480 . 2754676 [ 33 ] Kenneth O Stanley and Risto Miikkulainen . 2002 . Evolving neural networks through augmenting topologies . Evolutionary computation 10 , 2 ( 2002 ) , 99 ‚Äì 127 . [ 34 ] Lisa Torrey and Jude Shavlik . 2010 . Transfer learning . In Handbook of research on machine learning applications and trends : algorithms , methods , and techniques . IGI global , 242 ‚Äì 264 . [ 35 ] JanZacharias , MoritzvonZahn , JohannesChen , andOliverHinz . 2022 . Designing a feature selection method based on explainable artificial intelligence . Electronic Markets 32 , 4 ( 2022 ) , 2159 ‚Äì 2184 . [ 36 ] JuanCrist√≥balZagal , JavierRuiz - delSolar , andPaulVallejos . 2004 . Backtoreality : Crossing the reality gap in evolutionary robotics . IFAC Proceedings Volumes 37 , 8 ( 2004 ) , 834 ‚Äì 839 .