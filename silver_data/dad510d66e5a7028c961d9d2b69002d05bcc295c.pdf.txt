P r e p r i n t Studying writer - suggestion interaction A qualitative study to understand writer interaction with aligned / misaligned next - phrase suggestions ADVAIT BHAT , Indian Institute of Technology Bombay , India SAAKET AGASHE , VJTI , India NIHARIKA MOHILE , Indian Institute of Technology Bombay , India PARTH OBEROI , Indian Institute of Technology Bombay , India RAVI JANGIR , Indian Institute of Technology Bombay , India ANIRUDHA JOSHI , Indian Institute of Technology Bombay , India We present an exploratory qualitative study to understand how writers interact with next - phrase suggestions . While there has been some quantitative research on the effects of suggestion systems on writing , there has been little qualitative work to understand how writers interact with suggestion systems and how it affects their writing process—specifically for a non - native but English writer . We conducted a study where amateur writers were asked to write two movie reviews each , one without suggestions and one with . We found writers interact with next - phrase suggestions in various complex ways – writers are able to abstract multiple parts of the suggestions and incorporate them within their writing—even when they disagree with the suggestion as a whole . The suggestion system also had various effects on the writing processes – contributing to different aspects of the writing process in unique ways . We propose a model of writer - suggestion interaction for writing with GPT - 2 for a movie review writing task , followed by ways in which the model can be used for future research , along with outlining opportunities for research and design . CCS Concepts : • Human - centered computing → Empirical studies in collaborative and social computing . Additional Key Words and Phrases : Human - AI Collaboration , Writing research , Qualitative research , Text suggestion systems ACM Reference Format : Advait Bhat , Saaket Agashe , Niharika Mohile , Parth Oberoi , Ravi Jangir , and Anirudha Joshi . 2022 . Studying writer - suggestion interaction : A qualitative study to understand writer interaction with aligned / misaligned next - phrase suggestions . 1 , 1 ( August 2022 ) , 32 pages . 1 INTRODUCTION With the recent advent of transformer - based probabilistic language models [ 63 ] , text generation has become sophisticated and viable enough to be used in writing interfaces to provide synchronous next - phrase suggestions , as seen in popular products like Google Smart Compose [ 26 ] and LightKey [ 14 ] . As the writer types , the editor predicts an in - line phrase that the writer can select ( Fig . 1 ) . While there is rapid progress in natural language processing technologies that enable such interfaces , research in understanding writer interaction with such technologies and their effects is still emerging . Recent studies have shown that writing and communication are influenced by the presence and content of suggestion systems [ 17 ] — in terms of vocabulary use [ 18 ] , overall perceived sentiment [ 17 ] , and interpersonal perception [ 53 ] . The focus of these studies has been the writing product . Authors’ addresses : Advait Bhat , advaitmb @ gmail . com , Indian Institute of Technology Bombay , India ; Saaket Agashe , VJTI , Mumbai , India ; Niharika Mohile , Indian Institute of Technology Bombay , India ; Parth Oberoi , Indian Institute of Technology Bombay , India ; Ravi Jangir , Indian Institute of Technology Bombay , India ; Anirudha Joshi , Indian Institute of Technology Bombay , India , anirudha @ iitb . ac . in . 2022 . XXXX - XXXX / 2022 / 8 - ART $ 15 . 00 https : / / doi . org / , Vol . 1 , No . 1 , Article . Publication date : August 2022 . a r X i v : 2208 . 00636v1 [ c s . H C ] 1 A ug 2022 P r e p r i n t 2 Bhat , et al . Fig . 1 . Google Smart Compose’s in - line next phrase suggestions displayed in gray after user written text . While there has been recent research on how the writing process is affected by a suggestion system , it has primarily been done through a behavioural lens , hence not revealing the decisions writers make that lead to the observed behaviour [ 24 ] Writing research has long studied the writing process through a cognitive lens . Hayes’ ( 2012 ) Cognitive Process Writing Model , one of the most holistic cognitive models of writing , describes writing as a complex , non - sequential interaction between various cognitive writing processes [ 37 ] . Our paper uses this model as an analytical lens to qualitatively understand how writers interact with an in - line next - phrase suggestion system and compares writing with and without suggestions . Additionally , we study how misalignment between sentiment bias in the model and the writer’s opinion affects writer - suggestion interaction . We chose a movie review writing task and a suggestion system based on GTP - 2 fine - tuned on the IMDb movie reviews corpus . We quantify the writer’s opinion of the movie based on the star rating they give the movie before writing the review . Based on that , we calculate whether the writer and suggestion system are aligned or misaligned . For our study , we ask participants to watch two movies and then write a review for each , once with suggestions enabled and once without . We encouraged writers to express their personal opinions through their reviews and think aloud as they did so . Following that , we elicited retrospective protocols and analysed them with the think - aloud protocols through qualitative coding using a grounded approach . We found that writers took aid from suggestions , directly or indirectly , on various levels , such as proposing ( idea generation ) , translating ( language ) , and transcribing ( aid in typing ) . We also found ways and criteria based on which writers evaluated these suggestions before incorporating them into their text . Comparing the writing sessions with and without suggestions revealed various effects suggestions had on the writing process , such as a change in the writer’s overall plan , the role of misalignment , increased distraction , and increased use of genre - specific language . Based on our observations , we propose a model of writer - suggestion interaction in our study’s particular context . Finally , we discuss how suggestion systems can be framed and analysed through the lens of our model , followed by a discussion of possible directions for research and opportunities for the design of suggestion systems . 2 BACKGROUND Our research is motivated by a background spanning primarily two threads of research . These include theory and methods from writing research and work studying the effects of the presence and content of suggestion systems on the writing process and product . 2 . 1 Writing Research Research shows that the process of writing is a complex , non - sequential process , with writers involved in different cognitive processes such as generating ideas , evaluating their ideas , converting ideas to language , etc . , throughout the writing session . In a review paper , Donahue and Lillis [ 29 ] outline four types of models that have been the most influential in the contemporary study of writing . These include text - oriented , social practice , didactic , and ( socio ) cognitive models of writing . Donahue and Lillis suggest that while these models have a common goal of describing , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 3 writing , their ‘empirical objects of study’ differ . The empirical focus of the text - oriented models is the product or the output of writing and is primarily concerned with its linguistics [ 51 ] . Social practice models take an anthropological approach construing writing as a social practice in a social context . The didactic process model historically marked the first focal shift toward the writing process . First proposed by Janet Emig [ 30 ] , this model divides the writing process into distinct stages , such as pre - writing , planning , revising , etc . , and was primarily created for pedagogical reasons . The ( socio ) cognitive models focus on the individual writer in a social context . These form a spectrum : from models that focus more on the ‘social’ — construing writing as a social activity to models that focus more on the ‘cognitive’ — construing writing as an individual cognitive activity . The Hayes ( 2012 ) model is the cognitive end of the modern Socio - cognitive spectrum and tries to describe the cognitive processes an individual writer engages in during the process of writing [ 37 ] . The Hayes ( 2012 ) model is an evolution of the ‘cognitive process theory of writing’ [ 33 ] as first proposed by Hayes and Flower in 1981 . Unlike the ‘staged’ didactic process model , this model viewed writing as an interaction between the writer’s internal cognitive processes , the ‘task environment’ , and the writer’s long - term memory . Hayes and Flower used protocol analysis – based on the work of Ericsson and Simon – as a method to qualitatively study writing . Further studies tested , validated , and modified the model , which led to the evolution of Hayes’ Cognitive Process Model of Writing ( 2012 ) . Our paper aims to understand how individual writers interact with next - phrase suggestion systems . For this , our empirical object of study is the individual writer , and we view writing as a cognitive activity the writer engages in . To that end , the Hayes ( 2012 ) Cognitive Process Writing model acts as a suitable analytical lens for our research . We give a brief description of the model below . For a detailed description , refer to [ 38 ] Hayes’ cognitive process model of writing ( 2012 ) consists of 3 levels—the control , the pro - cess , and the resource level ( Figure ) . The control level includes components that direct or govern the activity of writing . The process level includes core writing processes and factors from the environment that influence the internal processes . The resource level includes crucial components for various human activities , including writing . 2 . 1 . 1 Control Level . The control level contains Motivation , Goal Setting , the current writing plan , and the writer’s writing schema . Motivation governs how engaged the writer would be in the process of writing — if the writer lacks the motive to write , writing does not happen . The writer decides the Goal of the text before composing - whether it is a journal entry , an essay , or a thesis report . The goal of the text may also be assigned to the writer ( like the writer is asked to write a movie review in our study ) . The goal of the text can change depending on the writing stage - during revision , for example , the goal of the text is to be an improvement over the previous draft with corrected errors , and during planning , the goal of the text is to be a plan for the writer which can be referred to later . Writers often come up with plans for their text after they have set their initial goals ( “I will start with an introduction and then make arguments” ) . These plans can have sub - goals that fulfil larger main goals . Depending upon its complexity , the writer may store this plan in their memory or write it down . These writing plans may also change mid - composition . Writing schemas represent the writer’s knowledge of writing and composition . The schema informs the writer ‘how to write’ and attributes the composed text should have — like writing strategy , genre , length , format , etc . ( “The review should start with a brief introduction” ) . Writers form such schemas through observation and experience , evolving throughout the writer’s lifetime . Writing schemas profoundly impact the writer’s style , plans , and habits . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 4 Bhat , et al . Fig . 2 . Cognitive Process Model of Writing by Hayes ( 2012 ) 2 . 1 . 2 Process Level . The process level consists of two sections : the internal writing processes and the external task environment . Writing processes constitute the Proposer , Translator , Transcriber , and Evaluator . The proposer is responsible for generating new ideas to be included in the text . The environment , collaborators , reference texts , writer’s memory and plans all help generate ideas . The translator converts the non - verbal , abstract ideas generated by the proposer into a string of coherent , understandable language . The transcriber uses the words and sentences ( grammatical strings ) generated by the translator and uses rules of the written form ( drawing letters , capitalisation , etc . ) and transcribing tools to turn it into a written form . The evaluator evaluates the outputs of all the above processes and decides whether they are adequate and appropriate . It may interrupt the process of text production at any stage — it can reject the idea proposed by the proposer , language translated by the translator , or the transcription done by the transcriber . Different configurations and sequences of these processes are used in different stages of writing for more ‘complex activities’ based on the writer’s goal . Planning what to write in a text , for example , is defined as a complex activity that makes use of these basic processes . Like planning , revision is a complex activity comprising the basic four writing processes— proposing , translating , transcribing , and evaluating . Task environment includes the writer’s social and physical sur - roundings . For example , the comments and suggestions that collaborators or critics might give are part of the social task environment . Similarly , transcribing technology , reference material , written plans , text written so far , etc . , become the physical task environment . Comments and suggestions given by collaborators are a part of the social task environment . The task environment of the writer , naturally , may influence how and what they write . In this study , we are interested in studying the , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 5 writer’s interaction with their task environment— i . e . the text editor enabled with next - phrase text suggestions . 2 . 1 . 3 Resource Level . The resource level includes components representing attention , long - term memory , working memory , and reading , which are more general - purpose mental resources . Atten - tion represents our ability to maintain focus , often referred to as executive function . Long term memory includes the writer’s repertoire of knowledge , including schemas , vocabulary , grammar , spelling , and facts . Working memory is temporary storage to handle information needed to complete tasks . The proposer , translator , transcriber , and evaluator use the working memory . Additionally , we define a Working Memory State ( WMS ) as an addition to the Hayes 2012 model in the context of writing with text suggestions . It represents the current composition state in the writer’s working memory when they encounter a suggestion . It may contain a partial or a complete proposal and a partial or a complete translation of the text the writer was planning to write when a suggestion appeared . The partial composition in the WMS may have different levels of completeness based on how much of the proposal and translation has been generated . For instance , a writer may have only generated a partial proposal when they encounter a suggestion , or they may have generated a complete proposal and a complete translation and is just about to transcribe it when they encounter a suggestion . The WMS helps us describe better the interactions and effects related to the suggestion system , as described in greater detail in the findings . Using the Hayes model as an analytical lens does not confine us to the concepts defined by the model . We also aim and expect to discover behaviours that cannot be explained by the Hayes model ( e . g . new cognitive processes specific to interacting with suggestions ) . Our analysis is not purely deductive or inductive . We use the Hayes Model only as a starting point for our analysis and perform inductive open coding on our data . 2 . 2 Writing Interfaces and Suggestion Systems Unlike traditional word processors , predictive text systems proactively suggest content to writers . Early ‘decoder’ text technologies aimed to save keystrokes with input devices ( such as the T9 keyboard ) where users had to press significantly fewer keys compared to the preceding multi - tap input technique [ 61 ] . These decoder technologies , however , did not predict what one would want to write next based on what they had written so far . Subsequent prediction technologies aimed to save keystrokes by predicting what the writer might write — if the suggestions were accurate , the writer would save the effort of typing the same . These technologies have evolved from completing a single word to suggesting next - phrases based on the preceding text . Contemporary predictive text services such as Google Smart Compose [ 26 ] , and LightKey [ 14 ] suggest a single but long phrase at a time , in - line with the text written so far ( like in Figure 1 ) . Our study focuses on such inline next - phrase suggestion systems . 2 . 2 . 1 Effects on Writing Product and Process . There has been a growing body of research on how predictive text systems affect writing . In a 2020 study , Arnold et al . suggest that using next - word text prediction in image annotation tasks can lead to users choosing more AI - suggested words , thus affecting their vocabulary usage . They also found that captions written with the help of suggestion systems were smaller in length and included fewer words [ 18 ] . A separate study found that positive sentiment bias in text prediction can lead to positively biased writing . Suggestion systems have also been interpreted as communication mediating technologies . Recent work by Hancock , Naaman , and Levy [ 36 ] explores and defines AI Mediated communication as “a mediated communication between people in which a computational agent operates on behalf of a communicator by modifying , augmenting , or generating messages to accomplish communication or interpersonal goals . ” A broader conception of AI - MC includes non - interpersonal communication and can accommodate , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 6 Bhat , et al . one - to - many communication tasks such as blog posts , reviews , etc . , which are more relevant to our research . Mieczkowski and Hancock et al . [ 36 ] provide preliminary evidence that positivity bias in Google Smart Replies can impact and undermine some dimensions of interpersonal perception , like social attraction . This research frames the writer as a communicator in the social context of interpersonal communication . Doing so , it primarily focuses on the effects of AI - augmented writing and communication on the written product and the receiver’s perception of the same . A study by Hohenstein et al . suggests that using AIMC can increase communication efficiency and the use of positive language . They also note that receivers evaluate senders negatively if they suspect the use of AI - augmented responses [ 39 ] . The work above essentially studies the effects of suggestions on the writing product and interpersonal perceptions based on that product - but leaves out its effects on the writing process . On the other side of the product - process distinction , Buschek et al . [ 24 ] study behavioural patterns of writers while using multiple - parallel next - phrase suggestions for writing emails . Their research gives us the first peek into the writing process with suggestions . They identify writers’ writing behaviours , such as focused typing , dense suggestion use , text navigation , etc . However , they cannot reveal the cognitive decision - making processes that lead to those behaviours . This motivates us to systematically study how users use such next - phrase predictive text suggestions in the process of writing . 2 . 2 . 2 Suggestions as writing prompts . Recent studies that capture the effects of suggestions on the writing product and process also provide preliminary evidence to suggest that writers perceive predictive text suggestions as prompts for writing . In a post - task survey , Buschek et al . found that many writers used text suggestions for inspiration and help when they felt stuck [ 24 ] . Arnold et al . [ 19 ] suggest that writers perceived next - word and next - phrase suggestions as prompts for ideas and language . These studies provide evidence that writers perceive phrase suggestions as not merely tools for writing fast but also tools that aid content generation . Work by Lehman et al . presents a conceptual analysis of autocomplete as a concept in the context of interfaces with generative capabilities that enable human - ai collaboration such as autocomplete , code completion , and layout generators [ 48 ] . They describe the role of autocomplete systems as ‘extending and completing user input’ and allude to such systems possibly taking the role of ‘inspiring the user’ to generate content . The studies mentioned above suggest that writers do , in fact , consciously interact with suggestions in ways that are not limited to improving writing efficiency . Recent preliminary qualitative work on the effects of text prediction also identifies the need for a systematic qualitative study to generate a model for writer interaction with text suggestions [ 22 ] . This brings us to the first of our research questions : How do writers interact with suggestions , and what governs these interactions ? Hayes and Flower’s work on studying the writing process is a promising starting point for research in writer interaction with text suggestions and the process of writing with predictive text . Feldman et al . ( 2020 ) propose that the cognitive process model for writing by Flower and Hayes can be used as a framework for studying both solo and collaborative writing [ 32 ] . While Feldman et al . use the original cognitive process model by Flower and Hayes [ 32 ] , the model has undergone several revisions based on findings of subsequent empirical studies . For our study , we use the 2012 revision of the model by Hayes [ 37 ] as a lens for understanding writer - suggestion interactions . In addition to understanding how writers interact with suggestions , we are also interested in understanding how the presence and the content of suggestions affect the writing process , compared to a writing process without suggestions . We know that interfaces mediating writing have various effects on the writing process . For example , C . Haas found that writers engaged in less planning before they began writing and did more low - level planning instead of high - level planning when using a word processor compared to pen and paper [ 35 ] . There is also evidence that word processors lead to higher quality expository essays [ 55 ] . Unlike traditional word processors , predictive text , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 7 systems proactively suggest content to writers . Thus , along with studying how writers interact with suggestions , we also aim to qualitatively compare writing with suggestions with writing without suggestions . This brings us to our second research question : How do suggestions , and the subsequent writer - suggestion interactions , affect the writing compared to writing without suggestions ? 2 . 3 Approaches to studying writing and suggestion interactions In 2003 , Perrin proposed Progression Analysis , a method for analysing the writing strategies of newsroom writers [ 56 ] . This method collects data from multiple sources such as unstructured interviews and observations , keystroke logs , and retrospective verbal protocols . Keystroke logs are a primary source of ’ground truth’ data , which is interpreted through retrospective verbal protocols . The unstructured interviews and observations provide a context of the environment , the participant’s background , writing motivation , and so on . There has been a similar interest in understanding writer interaction with Language models through approaches proposed by Lee et al . , where interaction logs and writing session replays can act as a ground truth that can be qualitatively or quantitatively studied and interpreted [ 47 ] . This approach differs from traditional HCI approaches , such as contextual inquiry , where writers are interviewed after the writing task [ 25 , 28 ] . Such approaches , however , may lend themselves to validity issues as users tend to post - rationalise their decisions after making them [ 20 ] , giving an accurate account of the activity in question . Qualitative writing research has used concurrent and retrospective protocol analysis—first introduced by Ericsson and Simon [ 31 ] — as a method for understanding the decisions made by writers and getting a peek into the writer’s cognitive processes . While retrospective protocols lend themselves to post - rationalisation , pairing them with concurrent protocols can help the researcher triangulate between the data to come up with better interpretations . Literature suggests that while the concurrent think - aloud method elicits more protocol segments and insight into the steps leading to the final decision , retrospective protocols provide more insight into the final decision [ 46 ] . Randsell suggests that concurrent protocols do not significantly affect the written product , as it does not reduce the syntactic complexity of the composition or the number of words written [ 59 ] . Concurrent think - aloud protocols , however , have limitations . If writers are prompted to verbalise their thoughts too often , their writing process can end up being slower than usual [ 59 ] . Thus , care needs to be taken by the researcher to find a balance between eliciting enough protocol statements while not letting the writer deviate from their usual writing process . As we want to study writer - suggestion interaction and its effects on the writing process from a cognitive lens , we collect concurrent and retrospective protocols from writers during a writing session and analyse them using a grounded approach . 2 . 4 Studying writer - suggestion misalignment with writer - suggestion interaction Text suggestions based on language models have been known to inherit biases and dominant ‘views’ from the text corpus used to train the language model . Multiple studies have found that such language models may exhibit stereotypical relations and even sentiment biases against certain groups of people , owing to the datasets these models are trained on [ 21 , 45 , 60 ] . For example , Hutchinson et al . show that in BERT— a large - scale language model by Google— phrases referencing persons with disabilities are associated with more negative sentiment words [ 41 ] . Arnold et al . studied how sentiment bias in text prediction affects the written product and found that positively biased suggestions can lead to more positive writing [ 17 ] . They call for studying not just how the presence but the content of the suggestions affects people who use them . Controlling the content of the produced suggestions by controlling the bias for comparing how a change may affect the writing process is therefore essential to our study . That said , a bias is inherently , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 8 Bhat , et al . normative—a writer may deem a suggestion generated by a language model as good or bad based on their normative framework or social values [ 23 ] . A suggestion that may be considered offensive by one writer or community may not be considered so by another . Our interest , therefore , lies in the alignment ( or lack thereof ) between the writer and suggestion system and how such misalignment affects writer - suggestion interaction . This brings us to our final research question : How does the degree of misalignment of opinion affect writer / suggestion system interactions ? 2 . 5 Working with Indian non - native English speakers While studying writing tasks , research often categorises writers and speakers of English as either L1 speakers who are also often native speakers ( typically people from the US , UK , or Australia ) or L2 speakers , whose country of origin is typically a non - English speaking country ( like China , Japan or Germany ) [ 66 ] . Existing research has compared the writing of first language speakers ( L1 ) against second language speakers ( L2 ) . One study on Dutch students showed that native Dutch ( L1 ) writers had longer lengths of the P - Bursts [ 27 ] ( the number of characters and the duration of a writing episode that is not interrupted by a significant pause ) as compared to writing in English ( L2 ) [ 49 ] . This finding is relevant as shorter P - bursts mean a higher probability of encountering a suggestion . Buschek et al . [ 24 ] , in a different study , observed that L2 speakers accepted and used more suggestions than L1 speakers . L2 speakers also found suggestions more helpful and perceived their influence on wording , content , and inspiration for using other phrases / words as ( slightly ) higher than their L1 counterparts . Researchers have observed L2 writers using reference materials as language repositories [ 57 ] , where they may note down potentially useful phrases from the text for later use [ 34 ] . Past research has also shown that L2 writers are more prone to ‘patchwriting’ , characterised by non - malicious or unintentional appropriation of text without explicitly citing it . Although not explicitly written by a ‘person’ , text generated by language models can still be appropriated by writers , especially L2 writers , in their writing . Our study is conducted in India , and since most of our participants are L2 speakers , we are motivated to answer our research questions in the context of Indian non - native English speakers , numbering 129 million according to the 2011 census [ 10 ] . However , it is important to mention that non - native English speakers in India may differ from non - native speakers in other non - English speaking countries . India is a region of immense diversity in language . Hence , English remains an official language for communication between states and is the language of choice for administrative services , law , and education . While all of our participants had a first language ( or mother tongue ) that was not English ( e . g . Marathi , Hindi , Assamese , etc . ) , they had completed their K - 12 schooling with English as the medium of instruction . We believe this differentiates Indian L2 English speakers and writers from L2 writers from other non - English speaking countries , and the findings should be interpreted as such . Thus , in summary , we intend to study three things . 1 . Indian non - native English writers , interaction with next - phrase suggestions , 2 . The qualitative differences between them writing with and without suggestions , and 3 . The effect of misalignment between the writer and the suggestion system on the same . Our research aims not to test or validate particular hypotheses or approaches for giving text suggestions but to collect systematic observations and construct knowledge inductively on the writer’s interactions with text suggestions using a grounded approach . We present observations that can act as a theoretical springboard for further empirical research . 3 METHOD To investigate our research questions , we developed two instances of suggestion systems - one instance fine - tuned on positive movie reviews and another on negative movie reviews . We asked participants to watch two movies and write two movie reviews — one review without suggestions and another with . We asked writers to rate the movies they watched before writing the review , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 9 and allotted the suggestion system such that we got a distribution of writers along an ‘alignment spectrum’ . We collected concurrent think - aloud protocols while the users wrote their reviews and retrospective think - aloud protocols after they had finished writing . We qualitatively analysed these with the screen recordings of the writers’ writing process . We use the Hayes Cognitive Process Model of writing ( 2012 ) as a theoretical framework to analyse our qualitative data [ 37 ] . Our primary goal was to create opportunities for diverse writer - suggestion interaction to capture how writers interacted with the suggestions and their content . We also wanted to observe instances where the writers had varying levels of misalignment with the suggestion system — to see if and how writers used these suggestions when they agreed with them and when they did not . We chose a movie review writing task for the same . A movie review task is appropriate for many reasons . Firstly , writing movie reviews involves expressing one’s opinion and arguing for it . While movie review writing may not be a usual task for most writers , it is analogous to other opinion expression and argumentation tasks that writers may engage in . Moreover , unlike other writing tasks such as creative story writing [ 28 ] , movie reviews have a star rating associated with them , giving us a linear scale of sentiment that may be used to create a variety of writer - suggestion misalignments . Secondly , countless movie reviews exist on the internet , along with available datasets [ 50 ] , giving us a rich resource to train a language model . Lastly , a movie watching and reviewing task is simple to assign and execute for participants . Since the task involves no travel and may be completed within the confines of the participant’s house , it was possible to conduct the study even during the pandemic and related lockdowns . We recruited amateur writers who agreed to write two movie reviews and think aloud as they did so . All writers were asked to write their first review without suggestions and the second with suggestions . In the with - suggestions condition , the writers were randomly assigned to a suggestion system trained on a corpus of movie reviews with a mean rating of either 2 . 5 or 8 . 5 ( the Corpus Rating ) [ 46 ] . Writers also rated each movie . Thus , this was a mixed design qualitative experiment . The within - subjects variable was the presence or absence of suggestions in the editor . The between - subjects variable was the degree of misalignment between the writer’s rating and the mean rating of the corpus , defined as the following . The Corpus Rating is a representative number calculated by averaging the ratings in the positive or negative review corpus , assuming the corpora have a uniform distribution . We acknowledge that this might not be the case , but use this as a representative number to calculate the misalignment score , which represents how misaligned the writer’s opinion is with the bias in the suggestion system . Here , DoM : degree of misalignment , WR : Writer Rating and Corpus Rating : Corpus Rating 𝐷𝑜𝑀 = 𝑊 𝑅 − 𝐶𝑜𝑟𝑝𝑢𝑠𝑅𝑎𝑡𝑖𝑛𝑔 In most cases , a degree of misalignment closer to 0 indicates that the writer’s opinion aligns with the mean rating of the corpus on which their suggestion system was trained . A negative value tells us that the writer’s opinion about that movie is worse than the mean rating , and a positive value tells us that the writer’s opinion is better . After the writer filled out an informed consent form , they were sent a link to their first movie . The writer was requested not to read any online reviews or view online ratings of the movie . We gave the writer about 24 hours to watch the movie . After the writer had watched the movie , we asked them to fill out a form where they had to rate the movie on a scale of 1 to 10 , where 1 represents that the writer did not like the movie at all , and 10 represents that they liked it very much . The writer was additionally asked to choose one among the following options to ensure that there was no misunderstanding about the scale : ( 1 ) I really liked the movie , ( 2 ) The movie was average , and ( 3 ) I did not like the movie . Next , we fixed a time with them for a review writing session . We conducted the two sessions over Zoom calls . The link to the assigned online text editor was sent to them at the start of each writing , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 10 Bhat , et al . Table 1 . The selected set of movies and their aggregate internet ratings Movie Name & Aggregate Internet Rating Loqueesha [ 8 ] 1 . 8 Future World [ 7 ] 2 . 5 Glitter [ 3 ] 3 . 2 Literally , Right Before Aaron [ 7 ] 4 . 3 The Last Shift [ 9 ] 5 . 5 Nothing [ 4 ] 6 . 1 Little Miss Sunshine [ 5 ] 8 . 1 Hunt for the Wilderpeople [ 6 ] 8 . 1 Secrets & Lies [ 2 ] 8 . 4 session . The writer was asked to share their screen . The sessions were recorded for analysis . In the with - suggestions condition , we first demonstrated the suggestions interface ( described below ) . The writer was then asked to practise writing a few sentences describing their day as a familiarisation task . After that , the writer was asked to write the movie review and think aloud as they did this . After the writing session , we shared the video recording of the session ( without audio ) with the writer and asked them to explain their writing process retrospectively . If the writer forgot what they had thought or if they contradicted themselves from what they said earlier , audio from that portion of the recording was played to trigger relevant memories . We collected concurrent and retrospective think - aloud protocols as our primary source of qualitative data . The concurrent protocols , retrospective protocols , and video recordings helped us triangulate the data to get a clear picture of the actions and decisions the writers were making and why they were doing so . During a pilot , we realised that writers often forgot to think aloud and needed nudges . This resulted in writers explaining themselves in the middle of their writing process , distracted the writers , and interrupted their flow . To counter this problem , we reframed the ‘think - aloud’ . We asked the writers to ‘talk to themselves’ while writing . We also explicitly asked them not to explain their decisions to us . This resulted in suitable protocols while minimising distraction from the writing process . The Institutional Review Board of our university approved our study . 3 . 1 Movie selection We chose 30 movies for our study as an initial set . We chose movies that were not widely released and ‘mainstream’ , to ensure that the writers had not watched the movie previously and their reviews were not affected . We also avoided polarising genres such as historical dramas , war , political movies , animated movies , and documentaries . We picked movies from those released between 1990 and 2021 . We rated the chosen movies based on ratings from three established sources : IMDb [ 12 ] , Rotten Tomatoes ( Critic and Audience scores ) [ 16 ] , and Letterboxd [ 13 ] . Ratings from all three sources were averaged on a scale of 1 to 10 and utilised for final rankings . Based on this rating , the movies were divided into three categories : Bad ( 1 - 3 ) , Neutral ( 4 - 7 ) , and Good ( 7 - 10 ) . We randomly chose three movies from each category , resulting in the nine movies listed in Table 1 . 3 . 2 Apparatus Our interface consists of a text editor capable of providing phrase and word completion suggestions both at the end of and in between text ( Figure ) . We built three versions of the text editor , one with , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 11 suggestions powered by a language model trained on an IMDB review corpus [ 50 ] with reviews with an average rating of 2 . 5 , the second with an average rating of 8 . 5 , and the third without suggestions . The design of the writing interface can be seen in ( Fig . 3 ) . The interface provided word complete as well as next - phrase suggestion capabilities . If the system’s most recently typed text without a space was deemed an incomplete word , the system completed the word followed by a phrase . Else , it only offered the phrase . The suggestion pops up as highlighted text near the top of the cursor when between text ( figure ) and in - line at the end ( Figure ) . Our study used an in - line single phrase suggestion system as most widely deployed suggestion systems like Google Smart Compose [ 26 ] use a similar interface for delivering suggestions . In our initial pilots , we deployed a suggestion interface where the writer had to press tab to select the whole suggestion . However , we received feedback that writers often wanted to select only the first few words in the sentence and had to delete the last few words after they ‘tabbed’ the suggestion . To resolve this issue , we designed the interface to select only a single word from the phrase when a writer pressed tab . To visually convey this interface behaviour , we highlighted the first word and added interpuncts ( · ) between words to represent this stepped approach to accepting a suggestion . ( Fig . 3 ) . Through our pilot , we also tested several wait times from when the writer stops writing to when the suggestion appears . We decided on 300ms as the optimum wait time before the suggestion appeared . Fig . 3 . The interface presented to participants , with end - of - text suggestions ( left ) and middle - of - text sugges - tions ( right ) The suggestion system takes in the last 50 words the user has written to compute the suggestion using the language model running in the back - end . We make almost all computations on the server side to maintain low latency . We have used a GPT2 [ 58 ] transformer model for text prediction . To bias the model for the specific task of writing movie reviews , we used a fine - tuned GPT2 model [ ? ] on an IMDb movie review corpus with polar ratings [ 50 ] . The IMDb movie reviews dataset consists of 25 , 000 examples each of positive and negative movie reviews . These reviews are polarised ; the positive reviews contain reviews with a star rating greater than 6 , and the negative reviews set consists of reviews with star ratings less than 5 . We fine - tuned each model for three training epochs and obtained a test perplexity score of 36 . 9713 for the positive model and 34 . 6978 for the negative model . We used the Hugging Face transformers library to train these models [ 11 ] . We used the beam search algorithm to generate the most likely next phrase . The motivation to use beam search comes from the fact that we need to generate a few word completions . While methods like Nucleus Sampling [ 40 ] produce more varied text , these methods are more relevant to tasks of arbitrating text generation where the goal is to produce paragraphs worth of human - like text . In these cases , beam search repeats its predictions over and over after a few initial words , and therefore using sampling methods creates more human - like text . However , since our goal is to find the most optimal next phrase , given a previous prompt , we opt to choose a sampled version of beam search , which generates multiple potential candidates based on the top - 5 beam scores and then samples from these candidates . Furthermore , modern systems like [ 26 ] use beam search to generate completions . Using beam search in our experiment aligns our system with existing mass deployed next phrase suggestion systems , thereby adding external validity . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 12 Bhat , et al . Table 2 . Comparing the positive and negative alignments of the system to the base GPT - 2 suggestions Sample from GPT - 2 base model I’ve been doing a lot of work on this blog over the last few years . One of the things that I’ve been working on is making sure that all of the posts that I make on this blog are written by people who have had the pleasure of writing for me in the past . Sample from IMDb fine - tuned model ( Corpus Rating = 8 . 5 ) I saw this movie at the Tribeca Film Festival , and it was one of the funniest movies I’ve ever seen . The acting was good , and the story line was funny . It was a lot of fun , and I recommend it to anyone who likes comedy . Sample from IMDb fine - tuned model ( Corpus Rating = 2 . 5 ) I don’t know where to begin with this movie , it’s a complete waste of time and money . I don’t know how anyone could make a movie like this . The confidence of beam search dictates the length of the suggestion . A beam search decoder maintains the probability score generated by the words added to the suggestion on every iteration . We empirically validate a threshold value , and new words stop being added when the probability score falls below this threshold value . We tuned the threshold value in a series of pilot tests by observing the Threshold value that does not create repetitions and aberrant words in the generations . To verify how well the model inherits the bias , we performed a sentiment validation using a pre - trained BERT Sentiment Classifier . We provided prompts from the test set , which contained five hundred samples of reviews from both the positive and negative sections of the set and used our fine - tuned models to generate phrase completions for these prompts . We then passed these completions through a BERT - Large model trained for sentiment classification on the IMDB dataset . The reported accuracy of this pre - trained classifier on the IMDB validation set is 90 % . We observed that 76 % of the generations from the positively biased model were classified as positive , while 78 % of the negatively biased model were classified as negative . The remaining generations in both cases , classified into the category opposite to their generator model , can be attributed to the fact that the model tries to maintain coherence . In some cases , it is impossible to generate an oppositely biased candidate . Sample text generations are shown below ( Table 2 ) . These examples demonstrate the bias embedded in the respective language models . For examples from the study , refer to the findings section . To verify the usefulness of our model in real - time phrase completions , we follow a metric similar to the one used by [ 26 ] . We use our model on a set of pilot study data where users were asked to write reviews without a completion model . For each word that the user writes , we compute the next phrase . For every consecutive word of the phrase completion that matches what the user actually wrote , we increment the usefulness count by 1 . We then add the user’s second word to the model input and repeat this process for subsequent words . We finally divide this count by the total number of words the user writes . Furthermore , we average this for five iterations of running phrase completion for each review . This score establishes how well the model can predict precisely what the user would have wanted to write . We obtain an average score of 0 . 3 for the positively biased GPT - 2 model and a score of 0 . 29 for the negatively biased GPT - 2 model . For a baseline comparison , the AWD - LSTM [ 52 ] model , fine - tuned on the entire IMDB corpus [ 50 ] , gave us a score of only 0 . 23 . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 13 Table 3 . Participant data on First Language , assigned movie , writer rating , system alignment , and the resulting degree of misalignment . ParticipantCode Mothertongue Assigned movie ( for with suggestions review ) WriterRating ( WR ) Corpus Rating for the system ( CorpusRating ) degree of misalignment ( DoM = WR - CorpusRating ) U1 Marathi Loqueesha 7 8 . 5 - 1 . 5 U2 Marathi Future World 1 8 . 5 - 7 . 5 U3 Hindi Secrets & Lies 9 2 . 5 6 . 5 U4 Hindi The Last Shift 8 2 . 5 5 . 5 U5 Malyalam Hunt for the Wilderpeople 9 8 . 5 0 . 5 U6 Telugu Glitter 5 2 . 5 2 . 5 U7 Marathi Secrets & Lies 8 8 . 5 - 0 . 5 U8 Assamese Future World 4 2 . 5 1 . 5 U9 Gujarati Loqueesha 5 8 . 5 - 3 . 5 U10 Gujarati Glitter 7 2 . 5 4 . 5 U11 Hindi Future World 6 2 . 5 3 . 5 U12 Hindi Loqueesha 1 8 . 5 - 7 . 5 U13 Marathi Little Miss Sunshine 8 8 . 5 - 0 . 5 U14 Hindi Future World 1 2 . 5 - 1 . 5 3 . 3 Participants We recruited participants who were university students or recent graduates , who had at least ten years of education in English and frequently watched English movies . All participants were reasonably fluent desktop typists and identified themselves as non - native English speakers— whose mother tongues were Marathi , Hindi , Malayalam , Telugu , Assamese , and Gujarati . Their K - 12 schooling , however , was completed with English as a medium of instruction . Fig . 4 . ( 1 ) Distribution of participant degrees of alignment , ( 2 ) Distribution of participant rating ( X axis ) and system rating ( Y axis ) Table 3 contains the coded names of the participants along with the two movies they watched , the rating they gave for each movie , the mean rating of the corpus on which their suggestion , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 14 Bhat , et al . system was trained in the “with - suggestions” condition and the degree of misalignment . Figure 4 shows the distribution of our participants across the alignment spectrum . 3 . 4 Data Analysis The study resulted in ( 14 users x 2 sessions = 28 sessions ) , each with concurrent and retrospective protocols . Four of the authors conducted coding and analysis of these protocols . Before coding , the recordings were transcribed automatically using OtterAi [ 15 ] and cleaned up manually . During coding , we referred to the recordings when necessary . We also wrote extensive memos to document observations and construct theories . We followed a three - phase strategy for coding and analysis . In the first phase , we created a codebook . To do this , first , we inductively open - coded eight writing sessions ( four with and four without suggestion ) of four participants . We then compared the transcripts of each writer’s with - suggestion session and without - suggestion session to polish our codes . This also told us how the writer’s suggestion process differed from their without - suggestion writing process , highlighted habits and practices that were inherent to that particular writer’s writing process and new practices and habits resulting from the suggestions . We also generated deductive codes based on Hayes 2012 [ 37 ] . Finally , we compared and merged these two sets of codes to create a unified codebook . Thus , at the end of the first phase of our analysis , we had a codebook consistent with existing literature and codes that we had found through our study , along with extensive memos . In the second phase , we coded 12 sessions using the codebook to validate or update the codes . We continued writing memos to create provisional theories and compare them against our previous memos . The third phase included validating our existing codes and memos through new evidence in the remaining eight sessions . After the first four users , the data collection and analysis was done iteratively . By the time we completed 14 users , we believed we had reached saturation along with having a diverse range of alignments and stopped further data collection . 4 FINDINGS We begin our findings by presenting a few examples of suggestions generated during the writing sessions of eight of our participants . We provide the text they had written just previously for context . The examples are presented in Table 4 as eight different writer - suggestion alignments , and each alignment led to uniquely different generations and interactions . For example , when U7 ( WR : 8 , DoM 0 . 5 ) was talking ( the pacing of the movie is a little slow ) of the movie being a little slow , the system ‘spun’ it positively and said ‘at times , but it’s a very good movie’ . Next , we report how suggestions contributed to the various writing processes as defined by Hayes ( 2012 ) [ 37 ] . We then describe how writers evaluated the suggestions they encountered for incorporating into their text and what factors governed this evaluation . Finally , we report some interesting effects that we observed . 4 . 1 Contribution of suggestions to the processes of composition We found that next - phrase suggestions contributed to the three writing processes of the Hayes model , namely the proposer , translator , and transcriber . Of these , the writers accepted any , all , or different combinations of suggestions . These ranged from suggestions exclusively contributing to only one process ( e . g . transcribing ) to suggestions contributing to all three processes for a given sentence ( e . g . writer tabbing through a complete sentence for which they had not generated either a proposal or a translation ) . They either accepted the contributions in the moment or ‘stored’ them for later use—in their mind or on their editor . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 15 Table 4 . Different writer - system alignments with examples of suggestions offered . ( Text styled ’bold’ is the suggested text , while the regular text is written by the writer . ) System ( Right ) vs Writer ( Down ) Positive Negative Positive U5 ( WR : 9 , DoM : 0 . 5 ) : This movie has all the makings of a classic U3 ( WR : 9 , DoM : 6 . 5 ) : . . the characters were decent . However , the movie was so bad that I . . Slightly Positive U7 ( WR : 8 , DoM : - 0 . 5 ) : the pacing of this movie is a little slow at times , but it’s a very good movie U10 ( WR : 7 , DoM : 4 . 5 ) : The lead singer is good , but the rest of the cast . . Slightly Negative U9 ( WR : 5 , DoM : - 4 ) : The acting is blunt and not very well done , but the writing is also pretty good . . U6 ( WR : 5 , DoM : 2 . 5 ) : . . . made me feel attentive all the time and I would not prefer the same . This movie is a waste of time and money . Negative U12 ( WR : 1 , DoM : - 7 . 5 ) : There wasn’t a single thing done right in the film , but that doesn’t stop it from U14 ( WR : 1 , DoM : - 1 . 5 ) : . . . directed by James Franco and is a terrible film . The acting is awful and the characters . . . 4 . 1 . 1 Contributions to the proposer . Writers often extracted a theme or a topic present in a sugges - tion and used it as an inspiration for new sentences . Here , instead of coming up with a proposal from scratch , they would pick up a theme from the suggestion and use that as a prompt to generate a proposal for their upcoming sentence . For example , U9 ( WR : 5 , DoM : - 3 . 5 ) was suggested “ . . . but the writing is also pretty good . " by the system . They rejected the specific opinion in the suggestion but picked up the theme — “writing of the film” and expressed their own opinion , “the writing of the film was weird” . U9 ( WR : 5 , DoM : - 3 . 5 ) later remarked : “I saw the term writing and [ thought might as well write about it ] ” . There were instances where writers liked the proposal and agreed with the opinion expressed in the suggestion . Yet , they translated it in their own language , without using the sentence structure or vocabulary from the suggestion , at times being more elaborate and nuanced and also expanding upon the suggestion . For example , U4 ( WR : 8 , DoM : 5 . 5 ) started a sentence with ‘The protagonists . . . ’ . The system then floated a suggestion - ‘were different from each other . ’ The writer agreed with the suggestion saying “makes sense to me” , but wanted to mention the protagonists’ names . Therefore , they continued writing the sentence ‘The protagonists , Dave Stanley and Jevon Williams , . . . ’ and then incorporated the opinion in the suggestion in their own argument while adding more detail as well as argumentation for why they had the opinion . They wrote ‘ . . . were very different from each other not just in skin colour but in every realm of life . ’ They then went on to describe how they were different from each other in detail . When asked whether they would’ve done the same if they hadn’t read the suggestion , they replied “No , had that not appeared , I would have probably gone on and given a general description of the characters . ” — which meant the emphasis on the ‘difference’ between the characters came about because of the suggestion . In some cases , suggestions triggered a completely unrelated train of thought that led to a new idea . The proposals thus generated were unrelated to the suggestion but were nonetheless an effect of the suggestion . For example , U3 ( WR : 9 , DoM : 6 . 5 ) stated : “the suggestion said ‘it’s not funny , it’s , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 16 Bhat , et al . not interesting’ and I think that ‘not funny’ part made me think of how the movie is not a comedy and it’s a drama” . In the examples above , the writers either did not have a proposal for the following sentence , or it was not completely formed in their minds when they encountered the suggestion . It is important to note that we did not observe any instances where writers abandoned the proposals in the WMS to use the new proposal based on the suggestion . Thus , while we have evidence that suggestions triggered new ideas or shaped existing ideas , we don’t have evidence where suggestions oblige writers to discard their ideas . On the other hand , we did observe writers abandoning their original translations to choose the translation from the suggestion . 4 . 1 . 2 Contributions to the translator . Writers often accepted the vocabulary , phrases , and sentence structures ( i . e . the translations of their proposals ) from the suggestions . Here , it wasn’t always necessary for the writer to agree with the idea expressed in the suggestion . For example , in the case of U3 ( WR : 9 , DoM : 6 . 5 ) , they got a suggestion saying ‘great acting , good storyline and a great cast’ . U3 picked up this sentence structure— of talking about the different features of the movie with a single adjective , and wrote ‘great acting , effective cinematography , beautiful music’ . Here , they did not necessarily pick up the opinion from the suggestion , nor did they write about the same topics - what they picked up was solely the presentation of the sentence . ( The effects of this particular sort of contribution are further talked about in § 5 . 3 . 4 ) We found several instances where the suggestions contributed to both the proposal and the translation . For example , U8 ( WR : 4 , DoM : 1 . 5 ) started their review with “I saw no point in the plot of this movie” . Subsequently , a suggestion appeared saying ‘The movie was boring’ . They then picked up the perceived opinion from the suggestion and presented it as a consequence of their previous sentence , writing ‘Thus , the movie got boring to watch’ . Here , the suggestion contributed to the proposal and led the writer to use the vocabulary inspired by the language used in the suggestion . This ‘carry - forward effect’ was quite common , where the suggestions contributed to the proposal and influenced the language used in the sentence . We found instances where writers abandoned their original translation and chose a translation provided by the suggestion . This contrasts with the observation we noted above that we did not find writers abandoning their proposals because of a suggestion . Writers abandoned their original translation because , in some cases , this saved their typing effort when the suggestion was ‘more or less faithful’ to their proposal and , in some cases , ‘the suggestion better expressed their proposal than their own translation’ . For example , U5 ( WR : 9 , DoM : 0 . 5 ) explained how they selected a suggestion that conveyed their intentions better than their original translation : “I was writing ‘it was warm and funny’ . [ . . . ] After writing ‘funny’ , I noticed the word ‘heartwarming’ in the suggestions and I thought that was better . [ So I selected ] ‘and heartwarming’ [ and later deleted ] ‘warm and’ ) thus changing their original translation from ‘warm and funny’ to ‘funny and heartwarming’ . 4 . 1 . 3 Contributions to the transcriber . The third kind of contribution was contribution to transcrip - tion . This is when the translation offered by the system is precisely the same as that in the WMS . In such cases , the writer pressed ‘tab’ to select the suggestion to save on the typing effort . In this case , the writer might ‘tab’ the whole sentence or parts of the sentence . Transcription level contributions also occurred in the form of word - completes . A writer would type out the first few letters of a word , and the suggestion would complete it . For example , U4 ( WR : 8 , DoM : 5 . 5 ) typed ‘per’ , and the system completed the word ‘perception’ . The suggestion exactly matched the writer’s intended translation , and hence , the contribution was only on a transcription level . The writer did not have to completely agree with the proposal suggested by the system , but just bits of its translation . They would also accept transcription level contributions when only a few , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 17 words , a single word , or part of a word matched . For example , U3 ( WR : 9 , DoM : 6 . 5 ) was talking about the plot , and had typed out ‘The movie follows the lives of a dysfunctional family that is . . . ’ when they got the suggestion , ‘ . . . trying to figure out what’s going on’ . U3 tabbed through ‘trying to figure out’ and then typed ‘how to be happy together . ’ U3 noted that they had the same translation in mind and used the suggestions to reduce typing effort . 4 . 1 . 4 Storing suggestions for later use . Sometimes , writers liked the suggestion but felt that it was in the wrong place . Here , they would ‘store’ this suggestion for later use , either by tabbing the suggestion and rearranging it at a later stage or by remembering the contents of the suggestion and using it in a ‘better’ place . For example , U2 ( WR : 1 , DoM : - 7 . 5 ) explained that they liked the suggestion , ‘I don’t want to give too much away’ , but still had some content to write before that . So they accepted the suggestion . Then they pressed enter and started writing their next sentence in a new paragraph . Once they had finished writing the review , they shifted the suggestion to the end of the review . U2 : “ . . . For me [ the suggestion ] was more of a concluding sentence . . . ” The new paragraph served as a reminder to do the rearrangement . In another example , U5 ( WR : 9 , DoM : 0 . 5 ) liked a suggestion , so they remembered it and retrieved it later when needed . U5 later remarked : “I was going to write ‘I recommend it’ but there was a suggestion like one - two sentences ago , which was ‘a must see for all’ so I just thought why not write this” . As discussed in the background , L2 writers have been known to use reference materials as language repositories [ 57 ] . Flowerdew and Li observed L2 writers identifying useful phrases from reference materials and writing them down in notebooks for future use [ 34 ] . The behaviour of ‘storing suggestions for later use’ we observed is analogous to the behaviour observed by Flowerdew and Li with L2 writers . This suggests that L2 writers may also consider suggestions are language repositories for borrowing phrases from and then storing these phrases for later use . 4 . 2 Evaluating suggestions Since the suggestions came from the system , writers hadn’t proposed , translated , or transcribed the suggested text themselves and had to evaluate them on several criteria . Writers also evaluated a suggestion at different levels of abstraction before incorporating it into their composition— as described in § 5 . 2 . For example , incorporating the core theme , while rejecting the vocabulary and sentence structure . Writers evaluated the suggestions independently or against the text they had written so far , or compared them to their WMS . Their beliefs about the system also governed how they evaluated the suggestions . At times , writers did not notice the suggestions . This section presents how writers evaluated the suggestions and the criteria they used . 4 . 2 . 1 Independent evaluation of suggestions . Writers did an “independent evaluation” of a sug - gestion when they encountered it at a time when they had no ready proposal or translation in their WMS . This independent evaluation involved no comparison to their text written so far , and looked at each suggestion as an independent piece of text to be evaluated . When writers evaluated suggestions independently , their writing schemas , their existing plans , and their opinions about the movie informed their evaluation of that suggestion . Following were the main criteria for suggestion evaluation . Misalignment : As expected , misalignments between the writer’s rating and the average cor - pus score increased the chances of writers rejecting suggestions . Writers could notice when the misalignment was huge . For example , U3 ( WR : 9 , DoM : 6 . 5 ) loved the movie ( rating it 9 ) but was assigned a system with Corpus Rating 2 . 5 ( degree of misalignment = 6 . 5 ) . U3 remarked , “Suggestions were continuously telling me it was a very bad movie . . . I was like no , it was not a really bad movie” . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 18 Bhat , et al . For some users , even a small misalignment led to several rejected suggestions . U8 ( WR : 4 , DoM : 1 . 5 ) had given the movie a rating of 4 ( degree of misalignment = 1 . 5 ) . This meant they disliked the movie , but the suggestion system was more negative than their opinion . At several encounters with the suggestion , U8 exclaimed aloud “Wow ! ” and rejected it . They explained in the retrospective narration , “ [ the suggestion was ] very blatant , and I didn’t want to be this blatant” . Thus , misalignment became an important criterion for evaluation . Misalignment also affected the writer’s perception of the suggestion system . We present findings related to that below . Besides the general misalignment , writers also disagreed with specific opinions or certain details in the suggestions . For example , U3 ( WR : 9 , DoM : 6 . 5 ) , while they were describing one of the locations from the movie , wrote ‘Its a place where’ , and were suggested ‘black people go to meet other black people . ’ To this , during their retrospective protocol , U3 exclaimed : “Why does it have to be specially ‘black people [ go to meet ] black people ? Why can’t [ it ] be ‘people go to meet other people ? ’ [ . . . ] It’s a place where two people as different as Dave and Jevon meet up . [ . . . ] I wanted the entire review to portray that they are very different people . But their skin colour is not what is dividing them . It’s actually the thing that connects them . ” Movie review schemas : Writers had schemas in their minds about what content was appropri - ate to put in a movie review , whether they were writing with suggestions or without . Suggestions going against this schema were rejected . For example , a common writing schema was to not give out spoilers in a movie review . When U3 ( WR : 9 , DoM : 6 . 5 ) got a suggestion saying ‘For example’ , they rejected it , with the following explanation : “I was like I’ll maybe give an example but I am like no I wouldn’t want that in a movie review which I would read . I don’t want spoilers to that degree so I didn’t write” . Writers had a schema , or a rough plan for the structure of their review . They utilised it to evaluate the position of the suggested text , independent of the text preceding it . For example , U5 ( WR : 9 , DoM : 0 . 5 ) was suggested ‘this is one of the few movies that I have . . . ’ at the beginning of the review , but they had a different plan . They rejected this suggestion saying “ [ I want to write ] a two - line plot summary of the movie . [ . . . ] that’s a good way to hook [ the ] audience in with a little bit of a story . ” However , as discussed above , even after rejecting a suggestion for their position , writers would ‘store the suggestion for later use’ — either in their memory or on the text editor . Factual accuracy and truth value : Often , suggestions were rejected because they were fac - tually inaccurate . This includes inaccurate details about the movie , wrong dates , and inaccurate references to the real world . For example , when suggested - ‘ the special effects were . . . ’ , U3 ( WR : 9 , DoM : 6 . 5 ) rejected the suggested text , saying “ . . . because there were no special effects” . In another instance , U6 ( WR : 5 , DoM : 2 . 5 ) rejected a suggestion - ‘ . . waste of ticket money’ , and explained that one could not watch the movie in the theatres as the world is in the middle of a pandemic : “ . . . it’s 2020 [ no movies are running in theatres right now ] . So you won’t really waste your money . ” 4 . 2 . 2 Evaluation with respect to text written so far . Writers also evaluated the suggestions for consistency and flow with respect to the text they had written so far . For example , when U5 ( WR : 9 , DoM : 0 . 5 ) described the movie’s plot in their first paragraph , the system suggested - ‘This is one of my favourite movies of all’ . Although U5 had liked the movie , they declined the suggestion stating , “That [ suggestion ] seemed too abrupt a change [ compared to the sentence I just completed ] . ” Conversely , writers accepted suggestions for the same reason . U5 ( WR : 9 , DoM : 0 . 5 ) , for instance , was just about to talk about the acting when they got a suggestion ‘The acting was top - notch’ . Since it fit in perfectly with what they had already written and what they were about to write , they accepted it , saying , “I felt this [ suggestion ] had a good flow with the previous [ text ] ) . ” 4 . 2 . 3 Evaluation with respect to the Working Memory State ( WMS ) . Writers often compared sug - gestions with the partial or complete composition in their working memory . ( U1 ( WR : 7 , DoM : - 1 . 5 ) , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 19 " I used to stop and think can I use this suggestion and integrate [ it ] into what I am thinking or not " . Writers either checked whether the suggested text was ’more or less’ compatible with their WMS and whether the suggestions provided an improvement over their WMS . For example , U5 ( WR : 9 , DoM : 0 . 5 ) got a suggestion ‘ . . . story is simple yet engaging’ . Here , they accepted the suggestion as the suggestion sufficiently expressed their proposal : “I was going to write something about the story being engaging in the next sentence . [ . . . ] and [ the suggestion ] was almost similar” . In the retrospective protocol , they then stated this as a general principle they used for accepting suggestions : “I was going to write something similar to [ the suggestion ] or if I was going to write that [ exactly ] then I would take the suggestion . [ . . . ] The basic meaning of the sentence should remain the same . ” Suggestions also helped users improve their WMS by providing alternatives , especially for their translations . For example , U5 ( WR : 9 , DoM : 0 . 5 ) remarked : So I thought , [ the word ] ’interaction’ again , but that didn’t feel right . Then [ the system ] suggested " adventure " and I thought it was better , [ so I accepted it ] . Our findings echoed the distinction that Hayes et al . make between ‘reading for comprehension’ vs ‘reading for evaluation’ [ 62 ] . Reading for comprehension , as defined by Hayes et al . , is the attempt to construct a “satisfactory internal representation of the meaning of the text” . Reading for evaluation usually encompasses several goals besides comprehension , such as fixing spelling or grammatical errors , vocabulary , and revision in general . We found the state of WMS paramount in deciding whether writers read for comprehension or evaluation . In cases where a proposal and translation both existed , writers were less likely to be affected by offered suggestions . ( U8 ( WR : 4 , DoM : 1 . 5 ) : . . . this point was there in my mind . I was like , I don’t want any influence . I want to type it out . ) . If the writer was in the process of forming a proposal / translation , reading suggestions would distract them , making them lose track of their thoughts . ( U4 ( WR : 8 , DoM : 5 . 5 ) : “I was trying to form the sentence , and then I looked up [ at the screen ] . That’s when the suggestion distracted me . ” ) To counter this problem , some writers deliberately ignored the suggestions . ( U8 : “I wasn’t reading [ the suggestions ] . . . If I had read them my flow would have been broken . ” ) On the other hand , if the writer did not have any proposal , they were more open , and in some cases , would even rely on the system for their next proposal and translation ( see § Effects ) . U3 ( WR : 9 , DoM : 6 . 5 ) : " Partly because [ . . . ] I didn’t know what to write . I didn’t know where to go after the first sentence and I was thinking , [ . . . ] what do I write , but then the suggestion showed up , and I’m like yeah , that option works . So then , I went with that because I didn’t have anything else in mind . . . like any definitive thing in mind . That’s why I did it . " 4 . 2 . 4 Evaluation influenced by the beliefs about the suggestion system . Writers had at least two beliefs about how the system worked , influencing how they evaluated the suggestions and how much they trusted them . A few writers believed ( wrongly ) that the suggestions reflected what most people on the internet thought about that specific movie . This belief made the suggestions seem grounded in reality and trustworthy . For example , U8 ( WR : 4 , DoM : 1 . 5 ) reasoned that they got all these negative suggestions because they wrote the name of the movie at the top , so the system searched Google ( which has access to several reviews of the movie ) and ’knew’ that it was a bad movie . Likewise , U6 ( WR : 5 , DoM : 2 . 5 ) echoed “I think it starts with a search for that keyword [ in this case , the title of the film ] and then suggests related sentences or something like that " ; Believing that many people have talked negatively about the movie may have influenced U6 into writing more negatively . ( “ [ . . . ] the suggestions were obviously related to how bad the movie was . And when I started writing about the movie , I did not think it was that bad of a movie . And when I was about to complete it , I found the reason why it was bad . ” ) These writers were more likely to believe the suggestions were true representations of other people’s opinions on that movie , and were thus more open to accepting them . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 20 Bhat , et al . On the other hand , some users ( partially correctly ) believed that the system would generate suggestions based on their initial few sentences . For example , U5 ( WR : 9 , DoM : 0 . 5 ) decided to ignore all suggestions ( except word - completes ) for their first two sentences while they established context for the movie and the review so that the system would be able to come up with ‘more accurate’ suggestions . ( U5 ( WR : 9 , DoM : 0 . 5 ) : I just started writing the review , right ? So then it’ll [ give me ] generic sentences . [ . . . ] Yeah , so my rationale was that the [ system ] probably doesn’t have any context for writing about [ movie reviews ] . So I thought I’ll ignore them for the first two lines where I’m talking about the movie . Because [ the suggestions ] won’t make sense anyway ) Mirroring the same expectation , U9 ( WR : 5 , DoM : - 3 . 5 ) was enraged when the system kept giving negative suggestions , even after they had written positively about the movie . Because of this , they deemed the system incompetent , and said , “The first , like this time it was fine , but later I was annoyed . Just read what I have written , [ mate ] ! ” As U9 trusted the system less , it led to a decrease in their openness to suggestions . U5 and U9 believed that the suggestion system would adapt to their writing by either making the suggestion more specific or more in line with their sentiment found the suggestions given enough context . These writers’ openness to suggestions decreased over time as the suggestions did not meet their expectations . 4 . 2 . 5 Missing suggestions . When writers were either focussed on their writing or were looking at their keyboard while typing , they often did not select a suggestion even if the suggestion exactly matched what they went on to transcribe manually . ( U9 ( WR : 5 , DoM : - 3 . 5 ) : “I didn’t see this [ suggestion ] . . . I wrote the same thing . If I had seen [ the suggestion ] , I would have accepted it” ) . Suggestions were also ephemeral— the system would generate a new suggestion as soon as the writer pressed a different key and suggestions would disappear when the writer pressed a backspace . Often , writers ‘lost’ these suggestions , with no possible way to retrieve them . 4 . 3 Effects on the writing process 4 . 3 . 1 The role of alignment . Without a suggestion system , writers found no reason to deviate from their original translation and the sentiment it conveyed - if they liked the movie , they wrote as much ; if they hated it , they wrote as such . However , the existence of suggestions led to changes in the criticality in the expression for many writers . We found that these changes depended heavily on the degree of misalignment with the corpus on which the system was trained . Aligned : In the case that the writer’s sentiment was exactly aligned to that of the system ( with DoM roughly from - 2 to 2 ) , we observed that writers did not realise that the system was biased . We told our participants during the debriefing about the bias in the system ( positive / negative ) . Most writers claimed that they did not notice a bias . ( U5 ( WR : 9 , DoM : 0 . 5 ) : “I didn’t notice any bias” ) . Only when told that the system had a bias did they realise in retrospect that the suggestions did seem to be too positive / negative . ( U5 ( WR : 9 , DoM : 0 . 5 ) : “Now that you say [ the system was biased ] , I notice there was nothing negative about the movie when [ the system ] suggested . ” ) . U14 ( WR : 1 , DoM : - 1 . 5 ) described their writing experience as “I felt like [ the system ] and I were having a conversation and both hating on the movie together” . When explicitly asked if they noticed that most suggestions were negative , they replied , “I didn’t think [ the system ] was biased , I thought [ it ] was because the system knew [ the movie ] was bad” . On the other hand , in cases where the alignment was not perfect , writers noticed that the system was biased . For example , U2 ( WR : 1 , DoM : - 7 . 5 ) , who was writing a critical review , mentioned noticing a bias : “Even if I was putting in negative views , it was coming out positively” Slightly Misaligned : As part of our distribution , a few writers were aligned with the system’s bias , but not quite as strongly ( degree of misalignment roughly between - 3 . 5 to - 0 . 5 and 0 . 5 to 3 . 5 ) . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 21 In these cases , it seems that the writers were persuaded to write more strongly than they originally intended to . U7 ( WR : 8 , DoM : - 0 . 5 ) , who liked the assigned movie and had a positively biased system , was initially critical of the film ( ‘the pacing of this movie is very slow [ . . . ] 2hrs 20 minutes is a bit much’ ) , despite liking it and giving it an 8 - star rating . However , the text suggested by the system reminded them that they were being too negative . While thinking aloud , U7 said : “I’m being too much of a downer” ) , and altered their writing after that to be less critical and more positive ( ‘the plotline is well fleshed - out , the story is very immersive and believable’ ) . As mentioned above , U6 ( WR : 5 , DoM : 2 . 5 ) was one of the writers who believed that the system’s suggestions were “reflective of the internet’s opinion on the movie” . U6 began their review with almost no criticism , writing a weakly positive review ( U6 : The movie was good but [ I initially thought ] it was a horror movie ) . While they did not particularly like the movie , they stated that “all movies are a type of art” , and felt it would be “rude” to begin the review with criticism . Midway , however , their sentiments changed , and they began writing more negatively . ( “And when I started writing about the movie , I did not think it was that bad of a movie . And when I was about to complete it , I found the reason why it was bad . ” ) . The constant negative suggestions convinced them to become more negative ( “I was convinced” ) , and that if there had been no suggestions at all , “ [ the review ] would have been more positive” But such misalignment did not affect everybody . U8 ( WR : 4 , DoM : 1 . 5 ) , who also believed the system was getting its information from the internet and received substantially negative suggestions , felt that they themselves were “not qualified to be so critical” , since they weren’t an expert in the field . U8 rejected many strongly negative suggestions such as “the movie is just boring” and modified them to statements such as “the movie did get boring to watch” . Thus U8 could retain control and did not get swayed by the misalignment . Completely Misaligned However , when the system and the writer were completely misaligned ( DoM roughly greater than 3 . 5 and lesser than - 3 . 5 ) , the suggestions did not particularly affect any writer’s sentiment— in most cases , it caused frustration with the system . U3 ( WR : 9 , DoM : 6 . 5 ) responded verbally to the system “No , it is not a bad movie ! ” . Most writers in this category dismissed such suggestions with a completely opposite sentiment . However , some did partially accept the sentence and flipped the sentiment of the sentence . U2 ( WR : 2 , DoM : - 7 . 5 ) was offered : “ . . made it all the more interesting” . They accepted most of the suggestion , but changed the last word to “tiresome” . U3 ( WR : 9 , DoM : 6 . 5 ) was almost about to accept the suggestion “this is one of the worst movies I have ever seen” and flip the sentiment , but realised that would result in a more positive sentiment than they intended ( “this is one of the best movies I’ve seen” ) , and settled on a toned down version to match their intent ( “it is a pretty good film” ) . While this was true for most writers , we found one interesting case where even suggestions with completely misaligned sentiment affected a writer’s strength of opinion . U9 ( WR : 5 , DoM : - 3 . 5 ) began the review with fairly neutral sentiment ( “The movie was okay - ish” ) . When the suggestion system repeatedly offered up positive suggestions , they ended up frustrated ( “ [ . . why doesn’t it read what I have written . . ] ” ) , and when given ( “this movie is very good” ) , they exclaimed ( “NO ! It is not a good movie ! ” ) and wrote down “this movie is not good . . . ” as a reaction to the suggestion , ending up with a decidedly negative sentence . This polarisation can be attributed to their reaction to the misalignment with the system . 4 . 3 . 2 Changes in plan due to suggestions . Suggestions often affected the writer’s plans . For ex - ample , in the without - suggestion condition , U3 ( WR : 9 , DoM : 6 . 5 ) expected to start the review by introducing the plot in the first paragraph , followed by their opinion on the movie—according to their schema for the structure of a movie review . ( U3 : “you can’t really begin a review by saying , " Oh this sucked " or like " This was good " , so [ I wanted to write ] an introduction just to sum up the , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 22 Bhat , et al . movie . ” ) . In their with - suggestion task , however , U3 was offered the suggestion “ this is one of the worst movies I have ever seen” right after their first clause , followed by “ the acting is terrible” . The writer evaluated based on ‘sentiment match’ , disagreed , and wrote “This is a pretty good movie” . They did not evaluate the suggestion for its position here , though they had explicitly stated that starting a movie review with opinions did not match their schema . U3 later realised that they had changed their intended structure for the review and mentioned , somewhat self - critically : “ It is now [ that ] I’m doing the thing which I probably would have done in the second sentence , which is actually explaining the plot” Other times , the participants willingly accepted this change in plan for reasons like saving time and effort . U5 ( WR : 9 , DoM : 0 . 5 ) , for example , accepted - ‘the acting was top - notch’ , because they felt it was “good enough to go with” . When probed about the change in plan , they said that they “would have written about the acting in the next few sentences anyway” . U5 reflected , “I would [ normally ] spend a little bit more time thinking about sentences , but here when it starts suggesting , I thought I would use those and try to incorporate the rest around it to save more time . ” 4 . 3 . 3 Distraction . When writing without suggestions , writers generated proposals and translations themselves , with minimal external influence on the proposer and the translator . The strategies they usually used to propose ideas were recounting movie details from their long - term memory ( U7 ( WR : 8 , DoM : - 0 . 5 ) : I was kinda just mentally going through the entire movie ) , creating a plan before writing ( U3 ( WR : 9 , DoM : 6 . 5 ) : Oh yeah , I’m thinking of where to begin . It’s a lot of facets to cover ) , or reading the text written so far ( U8 ( WR : 4 , DoM : 1 . 5 ) : S o whenever there’s a break in thought , I usually go back and re - read what I wrote ) . Similarly , writers used strategies like ’blurting’ to capture ideas quickly and then iterating and revising ( U8 : “I just typed to keep my thoughts going . Because if I stop typing , then it feels like a proper block . ” ) for translating their ideas into language . However , in the with - suggestions condition , constantly reading and evaluating suggestions led to higher cognitive load and distraction ( U4 ( WR : 8 , DoM : 5 . 5 ) : “I was trying to form the sentence . That’s when I looked up . And I saw the suggestion , and I got distracted . To be honest with you , I was kind of judging this suggestion . ” ) . Suggestions also hindered the writers’ proposal generation process . ( U8 : “I feel like if I’m thinking of something as I’m trying to form that thought , and I see something , which is completely different , I lose that thought which I was going with . ” ) Especially when the content of the suggestions was unrelated to the proposal . ( U8 : “the suggestions are in a totally different direction and that kind of threw my flow off” ) . To avoid this , U8 deliberately ignored the suggestions when coming up with proposals and translations . ( U8 : “ I didn’t want to compromise on the phrasing of it , I think , which is why I was like , kind of trying to ignore the suggestions . ” ) The persistent and distracting nature of suggestions tended to hurry U8 ( WR : 4 , DoM : 1 . 5 ) up . To avoid this , they would quickly develop translations and move on to the following sentence . They feared that the longer they took to form a sentence , the more chances there would be of accidentally reading and subsequently getting distracted by the suggestion . ( U8 : “ The fact that I was getting suggestions [ . . . ] that made me want to finish the point quickly and go to the next point . ” ) Due to this , it was difficult for a few writers to use an iterative approach to writing . ( U6 ( WR : 5 , DoM : 2 . 5 ) : How I write is like , I write whatever I get into my mind and then correct it . [ . . . ] I had an issue while thinking because I’ve been reading all these suggestions , and I couldn’t think straight because of the suggestions ) . As mentioned earlier , writers evaluated suggestions using various criteria ( currently typed text , the position of text , WMS , degree of misalignment , factual accuracy etc . ) . However , they may not use all criteria all the time . They may identify certain problems with a suggestion but miss others . This could be because they weren’t perchance used to evaluating suggestions that appeared so frequently , and got distracted . For example , when evaluating a suggestions , U1 ( WR : 7 , DoM : - 1 . 5 ) , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 23 Table 5 . Comparing U8 and U5’s without and with - suggestion tasks , and how suggestions influenced language . Outputs in without - suggestion trials were longer , more nuanced and structurally complex , while their with - suggestion trial outputs were shorter , single - noun - single - adjective sentences . Participants Without Suggestions WithSuggestions U8 ( WR : 7 . 5 ) The actors were phenomenal in their portrayal of the characters , it was truly brilliant acting and they were what really brought the film together . It really showed that the actors had a great understanding of their characters . All of them having such distinct personalities , this was another possible trainwreck in the sense of it becoming too much for the viewers , again was dealt with expertise . The dialogues really helped to fully realise these characters - it revealed their inner motivations , thoughts , insecurities . ( WR : 4 , DoM : 1 . 5 ) The acting was flat and the writing was terrible . U5 ( WR : 8 ) A nicely paced slice of life movie , it was a nice break amongst all the action , adventure , and sci - fi I’ve seen lately . It’s deeply grounded in reality and offers commentary on things like racism , which is sort of shown from the eyes of both Jevon and Stanley . Even though it was a slow - ish drama , the pacing was nice , and I did not feel bored while watching it . And being a slice of life movie just added to its simplicity . ( WR : 9 , DoM : 0 . 5 ) The acting is top notch and the story is simple yet engaging . explained : " Makes you think more , you are already thinking something and there are tonnes of words in front of you [ . . . ] can I use this suggestion and integrate [ it ] into what I am thinking or not . " 4 . 3 . 4 Increased use of Genre Specific Language . The system also caused an increase in the instances of typical ‘movie review language’ by offering suggestions with similar vocabulary and translation as movie reviews from its dataset . Though the language was different from their own , writers accepted these suggestions . For example , U5 ( WR : 9 , DoM : 0 . 5 ) and U9 ( WR : 5 , DoM : - 3 . 5 ) did not recommend watching the movie or not in their without - suggestion reviews . But in their with - suggestion review , U5 wrote “a must - see for all movie lovers” , after getting suggestions like “ I recommend it . . . ” and “ a must - see for all . . . ” . U5 also acknowledged that they wrote this because it was “classic movie - review language . ” Similarly , after getting “I recommend . . . ” suggestions from the system , U9 ( WR : 5 , DoM : - 3 . 5 ) ended up recommending that readers not watch the movie ( “Nonetheless , this is not a very good movie , and I wouldn’t really recommend it” ) . While many writers gave opinions on specific filmmaking elements in both their reviews , their sentences in the without - suggestion trials were longer , more nuanced , structurally complex , descriptive , personalised / localised in time , and with rationale . On the other hand , the suggestion system largely and frequently offered sentences that were single - noun - single - adjective ( “the acting was [ . . . ] ” , “the writing was [ . . . ] ” , “the story was [ . . . ] ” ) , and this language was adopted by most authors in the with - suggestion trials . See Table 5 . We found it interesting that two of our writers , U5 ( WR : 9 , DoM : 0 . 5 ) and U7 ( WR : 8 , DoM : - 0 . 5 ) ) , ended up with the exact same phrase in their reviews - “the acting was top - notch” , coming from a suggestion . Buschek’s ( 2021 ) findings corroborate our findings that corpus - specific wordings replaced participants’ own style of writing when they wrote with suggestions [ 24 ] . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 24 Bhat , et al . 5 DISCUSSION 5 . 1 A writer - suggestion interaction Model We found that writers interacted with inline next - phrase suggestions in various ways . They , directly and indirectly , used suggestions as aids for proposing , translating and transcribing . They also evaluated suggestions on several criteria before incorporating them into their writing . This use of suggestions affected their writing process in various unexpected ways . Past work on suggestion systems has conceptualised suggestions as ’transcription aids’ whose goal is improving writing speed and preventing errors . [ 44 ] This ’transcription - centric’ model of writer - suggestion interaction , as implied by past studies , assumes that writers have a concrete , translated proposal ready in mind when they encounter a suggestion , and the suggestion system merely helps them transcribe it . Our findings illustrate that is often not the case , as suggestions also affect the content of the writer’s composition in various ways . This calls for a more holistic conceptualisation of writer - suggestion interaction . The Hayes CPMW provides the most comprehensive model of the writing process through the cognitive processes of writing . The CPMW , through years of development , has also tried to accommodate and account for various factors that contribute to the writing process , such as collaborators , critics and transcription technologies . It , however , does not have a clear place for suggestion systems—which are neither passive transcription aids nor ‘collaborators or critics’ . [ 37 ] Our findings show that , at least in the context of our study , it is possible to look at writer - suggestion interaction as an interaction between the cognitive processes of writing and the suggestions generated by the language model . Based on our findings , we propose a model that builds upon the categories and concepts proposed by Hayes and articulates the findings of our study . The flow of information in the model starts when the writer encounters a suggestion . ( Fig 5 ) The model consists of 3 parts : the writer , the interface and the language model . Language Model : The language model ( LM ) sends suggestions to the interface ( arrow 1 ) based on the text written so far by the writer in the writing interface . The LM , which in this case is GPT - 2 , is trained on a particular corpus ( IMDb movie review ) and may be aligned with the writer’s intent to a lesser or greater extent . Interface : The interface is part of the task environment and consists of the text written so far and the suggestions presented through a specific interface design ( refer to apparatus for the design of our writing interface ) Writer : / / As we described in our findings , a suggestion may contribute new ideas to the proposer ( arrow 2 ) , vocabulary and sentence constructs to the translator ( arrow 3 ) , and reduce typing and spelling effort , thereby contributing to the transcriber ( arrow 4 ) . We also observed that a single suggestion might contribute to a combination of these processes . This process of suggestions contributing to the processes of writing may happen subconsciously , where the writer ( and the processes of writing ) may get ’influenced’ by the visible suggestion , or consciously , when a writer may aid their processes of writing with the help of a suggestion . We also define the writer’s ’working memory state’ as the state of their writing processes when they encounter and attend to a suggestion . This state may contain a partial or complete proposal , or a partial or complete translation . Our model also borrows the ’evaluator’ from the Hayes model , but evaluates the outcomes of the three writing processes along with the outcomes of the language model , i . e . the suggestions ( arrow 5 ) . Writers may evaluate the suggestions based on their writing schema and writing plans , as well as compare the suggestions with the text they have written so far ( arrow 9 ) . Writers also may compare their current ’working memory state’ with the suggested text ( arrow 10 ) , check for consistency and whether the suggestion improves the partial or complete composition they have in mind . Writers may be less open to suggestions if they already have a concrete composition in mind . Finally , the writers’ beliefs about how the suggestion system works may impact how open they are to the suggestions and how they evaluate , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 25 Fig . 5 . Our Writer - Suggestion Interaction model them ( arrow 11 ) . For example , a writer who thinks the suggestion system reflects the views of other writers on the internet may be more willing to accept it . 5 . 2 Using the model as a lens for analysis and further research The proposed model , to our knowledge , is the first attempt to articulate writer - suggestion interaction from a cognitive lens . It is derived from qualitative analysis of a specific type of writing task - movie reviews , with a particular language model - GPT - 2 , fine - tuned on a specific data - set - IMDb movie reviews , with a one - dimensional bias - positive and negative sentiment and using a particular suggestion interaction modality - single inline next - phrase suggestions . While not a definitive model of writer - suggestion interaction , it can still act as a theoretical starting point for further research in this area . Further research can happen in three directions . 1 . Testing and validating the concepts and relationships proposed by the model . 2 . Theoretically expanding and generalising the model through empirical research . 3 . Using the model as a lens for formulating research questions and interpreting qualitative and quantitative data . Lee et al . propose a tool to document the writing process and observe writer - suggestion interaction through interaction logging [ 47 ] . They suggest that their tool and the datasets generated can allow designers and researchers to analyse writer - suggestion interaction by generating writing process replays using the interaction logs . Our proposed model , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 26 Bhat , et al . can act as an analytical lens for interpreting this data , generating hypotheses , and providing vocabulary to articulate complex interactions . Similar to the approach proposed by Perrin et al . [ 56 ] , interaction logs can act as the ‘ground - truth’ of the writing process , and our proposed model can be used as a theoretical starting point for interpreting these logs . 5 . 3 Framing interaction with the writer as interaction with writing processes Our model conceptualises the written artefact composed with the aid of suggestions as the product of the interaction between the suggestions and the cognitive processes of writing . Hence , a suggestion system’s effects on the cognitive processes of writing would manifest in the written product . Prior work by Arnold et al . points out that the content of suggestions can affect the final written output . They show that a positive bias in the suggestion system skews the sentiment of the final written product positively [ 17 ] . However , it remains unclear whether this effect was on a language or idea level , i . e . on the translator or the proposer . Future studies can benefit from this distinction to measure where the sentiment shift is taking place by choosing appropriate analysis strategies and different units of analysis . For example , a comparison between topics suggested through the suggestions and the topic a writer has written about could measure a shift in ideas , i . e . the influence on the proposer . In contrast , a language - level analysis of sentiment ( as performed by [ 17 ] ) , vocabulary ( similar to [ 18 ] ) , sentence structure etc . , could be more suited for measuring the influence on the translator . Making a distinction between the cognitive processes can also help in designing writing aids specifically targeted to particular writing processes . In a 2016 study , Arnold et al . compared the impact of suggesting phrases vs words for writing restaurant reviews . They found that while phrases aided writers more with ideas ( what to say ) and language ( how to say it ) , writers reported that phrases provided them with more ideas than single - word suggestions [ 19 ] . In a separate study , Arnold et al . also observed that suggesting single words led to writers using vocabulary presented by the suggestions instead of coming up with words themselves [ 18 ] . Our findings echo this observation , with several participants attempting to align with genre - specific language and textual structure for the movie reviews . Studying how such design choices might aid or influence individual cognitive processes of writing can help develop design parameters that can be controlled to specifically aid the translator , proposer or transcriber . One such parameter could be the sampling strategy used for generating suggestions from the language model . In our study , we observed that some writers found the suggestions generic ; this echoes the findings of Arnold et al [ 17 ] . This could be because the suggestions were generated using beam search , which optimises for the most likely next word to construct a phrase . Different sampling strategies like nucleus or temperature sampling could be used and manipulated to generate more divergent suggestions that may be more helpful in generating proposals , while strategies like beam search could be used for aiding translation and transcription . Along with designing tools that can explicitly aid specific writing processes , the proposed model can be used to evaluate how well competing tools aid a single writing process while not influencing the other processes as much as possible . Future tools can allow writers to choose which cognitive process they want to support . When the writers find themselves short on proposals , they could ask for innovative ideas that differ from what they have been writing . Or , when they struggle to come up with suitable translations , writers could ask for suggestions more compliant with a particular style of writing ( e . g . movie reviews ) or simply alternative translations . Writers who have decided what they want to write could ask for fewer distractions and more transcription help . Providing writers with this choice and control can potentially make AI - enabled writing interfaces more transparent and explainable . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 27 5 . 4 The evaluator needs attention . In our model , we represent the evaluator as a cognitive process that , along with evaluating the outputs of the three processes of writing — i . e . proposer , translator and transcriber — also follows the same function for evaluating suggestions . The evaluator evaluates based on various evaluation criteria . These include comparing the Working memory state and the text written so far , writers’ writing plan and schema , and writers’ beliefs about how the suggestion system works . Unlike the other three processes of writing , the evaluator interrupts the cognitive processes to accept or reject their outputs . With suggestions in the picture , the evaluator has to do the same for the suggestions , along with comparing the outputs of the suggestion system and the cognitive processes to determine the best fit . While suggestions aid the proposer , the translator and the transcriber , they do not aid the evaluator . Instead , demand the writer to engage in more evaluation , which can lead to evaluator fatigue . Arnold et al . [ 17 ] suggest that writers often found next - word and next - phrase suggestions distracting , a phenomenon we also observed . A potential cause could be the increased load on the evaluator — when writers already have a semi - formed composition in their working memory and are compelled to evaluate it against the encountered suggestion or evaluate the suggestion by itself , thus forgetting their semi - formed compositions . Our observations echo results reported by Arnold et al . , where people who were going to write ‘mildly’ positive content ended up writing content that was ‘clearly’ positive [ 17 ] . We , too , observed this phenomenon where writers who were slightly misaligned with the suggestion system shifted their writing to conform with the suggestion sentiment . Our paper suggests that studying how writers evaluate suggestions can help understand the underlying mechanism and decision - making that occurs when such sentiment shift happens . Writers evaluated suggestions on one or more criteria but left out other potentially critical criteria due to evaluation fatigue . This may be one of the ways sentiment bias might have crept into their writing , where they might have evaluated the suggestions for , say , their position in the review , but overlooked if the suggestion’s sentiment exactly fit with theirs . A ( potentially ) more severe effect of evaluator fatigue could be writers evaluating suggestions less critically over their writing session and writers conforming with the suggestions to save evaluation effort . We also found that writers did not have a clear understanding of the functioning of the suggestion system . They came up with theories , which led to unclear or false beliefs . In literature , such theories have been defined as algorithmic folk theories [ 43 ] . These beliefs directly affected how writers evaluated the suggestions and how open they were to changing their compositions and direction while writing . Some writers ( Like U6 ) conformed to the suggestions despite the original misalignment because they thought the suggestions reflected the majority opinion on the internet about the specific movie being reviewed . They believed the AI had access to all the data on the internet and could query and source accurate and contextual data— in some ways like a search engine . This led to writers giving AI a sense of authority— perhaps because of their prior experience with and general perception of search engines like Google— making them more open to suggestions . A similar attitude of giving AI authority based on analogising its underlying functionality with other technologies ( a search engine in our case ) was noted by Kapania et al . [ 42 ] . Our study confirms these findings in the context of next - phrase suggestion systems , where such false beliefs about the suggestion system may persuade writers to be more open to the suggestions and potentially conform to the suggestions . We believe future systems should find ways to aid the evaluator along with the other three processes : by decreasing the evaluation load and providing relevant and correct information so that writers’ evaluation criteria are better informed . Future suggestion systems could have a language model that is personalised to the writer’s writing style based on their previous written content , and users could control how personalised they want their suggestions to be . A personalised model may need less evaluation from the writer’s end as most suggestions would , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 28 Bhat , et al . already comply with their writing style — i . e . the model would not generate texts which the writer would’ve rejected anyway . Further research could focus on whether personalisation decreases evaluator load and thus decreases evaluator fatigue . There could be several ways of informing the writer’s evaluation criteria to help them make better decisions . The goal would be to give writers relevant and correct information so that they are better equipped to evaluate these suggestions . To begin with , providing writers with an explanation of how the suggestion system functions may help them build an accurate mental model – avoiding the mal - effects of incorrect beliefs about the system . Writing interfaces could be better designed to accurately reflect how suggestions are generated . Informing writers of the capabilities and limitations of the language models can help them evaluate the suggestions generated by the model better . Solutions such as Model Cards proposed by Mitchell et al . [ 54 ] can be helpful . These model cards could be simplified and made more user - facing . Attention visualisation techniques such as BertViz [ 64 ] may be implemented in text editors to highlight words written by the writer that contributed to the generation of the suggestion . Future language models could explore novel architectures and training techniques such that the final output could cite its ‘sources’ —as to which sources from the dataset contributed how much to the generated text . Generation - specific source citing could be more helpful than simply describing the model’s training data . Each data source could get a score which reflects how much that source contributed to the generated text , which would help writers make a more informed evaluation based on the language and alignment prevalent in the sources . Along with making text generation transparent , helping the writers measure the impact the acceptance of a particular suggestion may have on how their overall composition can be perceived can also be useful . One way may be to give writers an overall sentiment score for their product . This score could be set to update as the text is written and when a suggestion is accepted , giving real - time feedback on how certain language choices impact overall sentiment . A Grammarly - like approach to evaluating the tone of a piece of text may be put in place to evaluate the tone and effects of individual suggestions . However , as noted by Winans , Grammarly does not indicate which words or phrases should be the focus of tone - based revisions [ 65 ] . We suggest that a writing interface inform the writer of the effect a particular suggestion can have on their product’s overall tone and sentiment before they accept the suggestion . 6 LIMITATIONS AND FUTURE WORK This study has several limitations . 6 . 0 . 1 Apparatus . Our goal was to design our text editor and suggestion system to reflect the design and functionality of mass deployed suggestion systems such as Google Smart Compose . However , based on our pilot study , we made a few design choices that differed from mass deployed systems . Instead of accepting the whole suggestion on tabbing , we limited the acceptance to one word per tab ( reasons for the same are described in the apparatus section ) . We acknowledge that interaction between writers and the suggestion system may change if tabbing leads to writers accepting the whole sentence , similar to Google Smart Compose . Secondly , we generated suggestions after the writer paused for 300ms , against generating suggestions only when the confidence value is very high — like in deployed systems . This decision helped us create more opportunities for observing writer suggestion interaction . However , we acknowledge that showing suggestions more often would have affected how writers interacted with suggestions , and our findings would’ve been slightly different if the suggestions weren’t as frequent . We came up with the design of our writing interface and suggestion system through a pilot test with a writing interface identical to google smart compose . Feedback from the same helped us to redesign the interface and suggestions into a slightly novel design . However , we could not empirically evaluate the usability of the new writing , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 29 interface and the suggestion system . Although , qualitative feedback about the new design was generally positive . 6 . 0 . 2 Issues with misalignment . We fine - tuned two GPT - 2 language model instances on positive and negative movie reviews . To calculate a representative misalignment score , we assumed that the positive and negative corpora had a uniform distribution allowing us to approximate the Corpus Rating to be 2 . 5 and 8 . 5 . This , however , may not be true , and the Corpus Rating values and the Degree of Misalignment scores should only be considered representative measures and not accurate ones . Secondly , due to limitations in time and budget , we could not consider an ‘unaligned’ condition , where writers would be given a suggestion system trained on the whole IMDb review corpus from ratings spanning from 1 - 10 . The behaviour of such a system would’ve differed from the biased suggestion systems . In our pilot studies , we observed that such a system adapted to the writer’s sentiment as the writer wrote the review and created higher chances of ‘aligned’ conditions . Future work could study unaligned writer suggestion conditions and expand , validate or contest our models and findings . 6 . 0 . 3 Writing task . We selected movie review writing as our writing task . We have stated the reasons for doing so in the method section . However , we acknowledge that writing movie reviews in itself are an uncommon and relatively benign writing task , with fewer implications for the writer . Other forms of writing in the real world can be more nuanced and sensitive , like writing personal emails or opinion pieces on political issues . The writer - suggestion misalignment in examples such as political pieces would also be multidimensional , unlike single - dimensional positive and negative sentiment . We call for further research using more multidimensional writer - suggestion alignments . 6 . 0 . 4 Methodological Limitations . As we have briefly discussed in the background , think - aloud protocol elicitation , if done at a high frequency , can change the way writers write and make them write content they usually might not have written . We ensured we did not interrupt the writer much and tried to ask them not to justify their decisions , only verbalise their thoughts . Despite our best efforts , some writers at times started justifying their decisions . However , this phenomenon was rare because we reframed think - aloud as ‘talk to yourself’ . Future studies should keep in mind these methodological observations while using think - aloud protocols . Secondly , while eliciting some of the retrospective protocols , we asked some writers ( like U4 ) questions such as ‘would you have done that if the suggestions weren’t there ? ’ While we showed the writers the recording of the writing session and played the concurrent protocols for reference when needed , such hypotheticals can run the risk of post - rationalisation , and we acknowledge that possible limitation . Finally , we did not conduct a systematic quantitative analysis of the writing product to validate our observations about genre - specific language . Future studies can conduct an in - depth quantitative analysis to find whether this effect is statistically significant . 6 . 0 . 5 Limitations of the Findings and the Proposed Model . We would finally like to acknowledge that our findings and the proposed model are a result of a qualitative analysis of a specific type of writing task - movie reviews , with a particular language model - GPT - 2 , fine - tuned on a specific data - set - IMDb movie reviews , with a one - dimensional bias - positive and negative sentiment and using a particular suggestion interaction modality - single inline next - phrase suggestions . Therefore , this paper’s findings cannot be generalised across different writing tasks , language models , biases and interaction modalities . Finally , we would like to remind the reader that this was a qualitative study , so the findings should be interpreted as provisional and contestable . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 30 Bhat , et al . 7 CONCLUSION We conducted a qualitative study with 14 writers who wrote two movie reviews each , one with a system that offered next - phrase suggestions and one that did not . In the with - suggestions condition , authors were randomly given a system with a corpus rating of 2 . 5 or 8 . 5 out of 10 . Writers had varying ratings before writing the review , thus resulting in a range of positive and negative alignments between the user intent and the system . Analysis of the think - aloud and retrospective protocols collected from the users gave us insights into how the suggestions affected the different parts of the writing process . Our findings suggest that writers use suggestions in multiple , nuanced ways , and even in cases when they don’t directly accept the suggestions . Writers took aid from suggestions , directly or indirectly , on various levels , such as proposing ( idea generation ) , translating ( language ) , and transcribing ( aid in typing ) . We also found various ways and criteria in which writers evaluated these suggestions and that writer - suggestion misalignment primarily impacted the evaluation process . The presence and content of the suggestions had several effects on the writing process , such as a change in the writer’s overall plan , the role of misalignment , increased distraction , and increased use of genre - specific language . We propose a model of writer - suggestion interaction in our study’s context , followed by ways in which the model can be used for future research , along with outlining opportunities for research and design . REFERENCES [ 1 ] ] lvwerra [ n . d . ] . LVWERRA / GPT2 - imdb · hugging face . https : / / huggingface . co / lvwerra / gpt2 - imdb [ 2 ] 1997 . Secrets & Lies . https : / / www . imdb . com / title / tt0117589 / ? ref _ = fn _ al _ tt _ 1 [ 3 ] 2001 . Glitter . https : / / www . imdb . com / title / tt0118589 / ? ref _ = fn _ al _ tt _ 1 [ 4 ] 2004 . Nothing . https : / / www . imdb . com / title / tt0298482 / ? ref _ = fn _ al _ tt _ 1 [ 5 ] 2006 . Little miss sunshine . https : / / www . imdb . com / title / tt0449059 / ? ref _ = nv _ sr _ srsg _ 0 [ 6 ] 2016 . Hunt for the Wilderpeople . https : / / www . imdb . com / title / tt4698684 / ? ref _ = nv _ sr _ srsg _ 0 [ 7 ] 2018 . Future world . https : / / www . imdb . com / title / tt5737536 / ? ref _ = nv _ sr _ srsg _ 0 [ 8 ] 2019 . Loqueesha . https : / / www . imdb . com / title / tt7620554 / ? ref _ = nv _ sr _ srsg _ 0 [ 9 ] 2020 . The last shift . https : / / www . imdb . com / title / tt10661180 / ? ref _ = nv _ sr _ srsg _ 0 [ 10 ] 2021 . 2011 census of India . https : / / en . wikipedia . org / wiki / 2011 _ Census _ of _ India # Census _ report [ 11 ] 2022 . Hugging Face Transformers . https : / / huggingface . co / [ 12 ] 2022 . IMDb . https : / / www . imdb . com / [ 13 ] 2022 . Letterboxd . https : / / letterboxd . com / [ 14 ] 2022 . LightKey . https : / / www . lightkey . io / [ 15 ] 2022 . Otter Voice Meeting notes . https : / / otter . ai / [ 16 ] 2022 . Rotten Tomatoes . https : / / www . rottentomatoes . com / [ 17 ] Kenneth C Arnold , Krysta Chauncey , and Krzysztof Z Gajos . 2018 . Sentiment Bias in Predictive Text Recommendations Results in Biased Writing . . In Graphics Interface . 42 – 49 . [ 18 ] Kenneth C Arnold , Krysta Chauncey , and Krzysztof Z Gajos . 2020 . Predictive text encourages predictable writing . In Proceedings of the 25th International Conference on Intelligent User Interfaces . 128 – 138 . [ 19 ] Kenneth C Arnold , Krzysztof Z Gajos , and Adam T Kalai . 2016 . On suggesting phrases vs . predicting words for mobile text composition . In Proceedings of the 29th Annual Symposium on User Interface Software and Technology . 603 – 608 . [ 20 ] Sandeep Athavale and Girish Dalvi . 2019 . Discovering strategies for design of purposeful games—a preliminary study . In Research into Design for a Connected World . Springer , 63 – 74 . [ 21 ] Christine Basta , Marta R Costa - Jussà , and Noe Casas . 2019 . Evaluating the underlying gender bias in contextualized word embeddings . arXiv preprint arXiv : 1904 . 08783 ( 2019 ) . [ 22 ] Advait Bhat , Saaket Agashe , and Anirudha Joshi . 2021 . How do people interact with biased text prediction models while writing ? . In Proceedings of the First Workshop on Bridging Human – Computer Interaction and Natural Language Processing . 116 – 121 . [ 23 ] Su Lin Blodgett , Solon Barocas , Hal Daumé III , and Hanna Wallach . 2020 . Language ( technology ) is power : A critical survey of " bias " in nlp . arXiv preprint arXiv : 2005 . 14050 ( 2020 ) . [ 24 ] Daniel Buschek , Martin Zürn , and Malin Eiband . 2021 . The impact of multiple parallel phrase suggestions on email input and composition behaviour of native and non - native english writers . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems . 1 – 13 . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t Studying writer - suggestion interaction 31 [ 25 ] Alex Calderwood , Vivian Qiu , Katy Ilonka Gero , and Lydia B Chilton . 2020 . How Novelists Use Generative Language Models : An Exploratory User Study . . In HAI - GEN + user2agent @ IUI . [ 26 ] Mia Xu Chen , Benjamin N Lee , Gagan Bansal , Yuan Cao , Shuyuan Zhang , Justin Lu , Jackie Tsay , Yinan Wang , Andrew M Dai , Zhifeng Chen , et al . 2019 . Gmail smart compose : Real - time assisted writing . In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . 2287 – 2295 . [ 27 ] N Ann Chenoweth and John R Hayes . 2001 . Fluency in writing : Generating text in L1 and L2 . Written communication 18 , 1 ( 2001 ) , 80 – 98 . [ 28 ] Elizabeth Clark , Anne Spencer Ross , Chenhao Tan , Yangfeng Ji , and Noah A Smith . 2018 . Creative writing with a machine in the loop : Case studies on slogans and stories . In 23rd International Conference on Intelligent User Interfaces . 329 – 340 . [ 29 ] Christiane Donahue and Theresa Lillis . 2014 . 4 Models of writing and text production . De Gruyter Mouton , 55 – 78 . https : / / doi . org / doi : 10 . 1515 / 9783110220674 . 55 [ 30 ] Janet Emig . 1971 . The composing processes of twelfth graders . ( 1971 ) . [ 31 ] K . A . Ericsson and H . A . Simon . 1992 . Protocol analysis : verbal reports as data . MIT Press . https : / / books . google . co . in / books ? id = VrhNzQEACAAJ [ 32 ] Molly Q . Feldman and Brian James McInnis . 2021 . How We Write with Crowds . Proc . ACM Hum . - Comput . Interact . 4 , CSCW3 , Article 229 ( jan 2021 ) , 31 pages . https : / / doi . org / 10 . 1145 / 3432928 [ 33 ] Linda Flower and John R . Hayes . 1981 . A Cognitive Process Theory of Writing . College Composition and Communication 32 , 4 ( 1981 ) , 365 – 387 . http : / / www . jstor . org / stable / 356600 [ 34 ] John Flowerdew and Yongyan Li . 2007 . Language re - use among Chinese apprentice scientists writing for publication . Applied linguistics 28 , 3 ( 2007 ) , 440 – 465 . [ 35 ] Christina Haas . 1989 . How the writing medium shapes the writing process : Effects of word processing on planning . Research in the Teaching of English ( 1989 ) , 181 – 207 . [ 36 ] Jeffrey T Hancock , Mor Naaman , and Karen Levy . 2020 . AI - mediated communication : Definition , research agenda , and ethical considerations . Journal of Computer - Mediated Communication 25 , 1 ( 2020 ) , 89 – 100 . [ 37 ] John R . Hayes . 2012 . Modeling and Remodeling Writing . Written Communication 29 , 3 ( 2012 ) , 369 – 388 . https : / / doi . org / 10 . 1177 / 0741088312451260 arXiv : https : / / doi . org / 10 . 1177 / 0741088312451260 [ 38 ] John R Hayes and Natalie G Olinghouse . 2015 . Can cognitive writing models inform the design of the common core state standards ? The elementary school journal 115 , 4 ( 2015 ) , 480 – 497 . [ 39 ] Jess Hohenstein , Dominic DiFranzo , Rene F Kizilcec , Zhila Aghajari , Hannah Mieczkowski , Karen Levy , Mor Naaman , Jeff Hancock , and Malte Jung . 2021 . Artificial intelligence in communication impacts language and social relationships . arXiv preprint arXiv : 2102 . 05756 ( 2021 ) . [ 40 ] Ari Holtzman , Jan Buys , Li Du , Maxwell Forbes , and Yejin Choi . 2019 . The Curious Case of Neural Text Degeneration . https : / / doi . org / 10 . 48550 / ARXIV . 1904 . 09751 [ 41 ] Ben Hutchinson , Vinodkumar Prabhakaran , Emily Denton , Kellie Webster , Yu Zhong , and Stephen Denuyl . 2020 . Social biases in NLP models as barriers for persons with disabilities . arXiv preprint arXiv : 2005 . 00813 ( 2020 ) . [ 42 ] Shivani Kapania , Oliver Siy , Gabe Clapper , Azhagu Meena SP , and Nithya Sambasivan . 2022 . ”Because AI is 100Attitudes and Sources of AI Authority in India . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 158 , 18 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517533 [ 43 ] Nadia Karizat , Dan Delmonaco , Motahhare Eslami , and Nazanin Andalibi . 2021 . Algorithmic Folk Theories and Identity : How TikTok Users Co - Produce Knowledge of Identity and Engage in Algorithmic Resistance . Proc . ACM Hum . - Comput . Interact . 5 , CSCW2 , Article 305 ( oct 2021 ) , 44 pages . https : / / doi . org / 10 . 1145 / 3476046 [ 44 ] Per Ola Kristensson and Keith Vertanen . 2014 . The inviscid text entry rate and its application as a grand goal for mobile text entry . In Proceedings of the 16th international conference on Human - computer interaction with mobile devices & services . 335 – 338 . [ 45 ] Keita Kurita , Nidhi Vyas , Ayush Pareek , Alan W Black , and Yulia Tsvetkov . 2019 . Measuring bias in contextualized word representations . arXiv preprint arXiv : 1906 . 07337 ( 2019 ) . [ 46 ] Hannu Kuusela and Pallab Paul . 2000 . A Comparison of Concurrent and Retrospective Verbal Protocol Analysis . The American Journal of Psychology 113 , 3 ( 2000 ) , 387 – 404 . http : / / www . jstor . org / stable / 1423365 [ 47 ] Mina Lee , Percy Liang , and Qian Yang . 2022 . Coauthor : Designing a human - ai collaborative writing dataset for exploring language model capabilities . In CHI Conference on Human Factors in Computing Systems . 1 – 19 . [ 48 ] Florian Lehmann and Daniel Buschek . 2020 . Examining Autocompletion as a Basic Concept for Interaction with Generative AI . i - com 19 , 3 ( 2020 ) , 251 – 264 . [ 49 ] Mariëlle Leijten , Eric Van Horenbeeck , and Luuk Van Waes . 2019 . Analysing keystroke logging data from a linguistic perspective . In Observing writing . Brill , 71 – 95 . , Vol . 1 , No . 1 , Article . Publication date : August 2022 . P r e p r i n t 32 Bhat , et al . [ 50 ] Andrew L . Maas , Raymond E . Daly , Peter T . Pham , Dan Huang , Andrew Y . Ng , and Christopher Potts . 2011 . Learning Word Vectors for Sentiment Analysis . In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies . Association for Computational Linguistics , Portland , Oregon , USA , 142 – 150 . http : / / www . aclweb . org / anthology / P11 - 1015 [ 51 ] Christian MIM Matthiessen and Michael Alexander Kirkwood Halliday . 2009 . Systemic functional grammar : A first step into the theory . [ 52 ] Stephen Merity , Nitish Shirish Keskar , and Richard Socher . 2017 . Regularizing and optimizing LSTM language models . arXiv preprint arXiv : 1708 . 02182 ( 2017 ) . [ 53 ] Hannah Mieczkowski , Jeffrey T Hancock , Mor Naaman , Malte Jung , and Jess Hohenstein . 2021 . AI - Mediated Commu - nication : Language Use and Interpersonal Effects in a Referential Communication Task . Proceedings of the ACM on Human - Computer Interaction 5 , CSCW1 ( 2021 ) , 1 – 14 . [ 54 ] Margaret Mitchell , Simone Wu , Andrew Zaldivar , Parker Barnes , Lucy Vasserman , Ben Hutchinson , Elena Spitzer , Inioluwa Deborah Raji , and Timnit Gebru . 2019 . Model cards for model reporting . In Proceedings of the conference on fairness , accountability , and transparency . 220 – 229 . [ 55 ] Ronald D Owston , Sharon Murphy , and Herbert H Wideman . 1992 . The effects of word processing on students’ writing quality and revision strategies . Research in the Teaching of English ( 1992 ) , 249 – 276 . [ 56 ] Daniel Perrin . 2003 . Progression analysis ( PA ) : investigating writing strategies at the workplace . Journal of Pragmatics 35 , 6 ( 2003 ) , 907 – 921 . [ 57 ] Lia Plakans and Atta Gebril . 2012 . A close investigation into source use in integrated second language writing tasks . Assessing Writing 17 , 1 ( 2012 ) , 18 – 34 . [ 58 ] Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , Ilya Sutskever , et al . 2019 . Language models are unsupervised multitask learners . OpenAI blog 1 , 8 ( 2019 ) , 9 . [ 59 ] Sarah Ransdell . 1995 . Generating thinking - aloud protocols : Impact on the narrative writing of college students . The American journal of psychology ( 1995 ) , 89 – 98 . [ 60 ] Emily Sheng , Kai - Wei Chang , Premkumar Natarajan , and Nanyun Peng . 2019 . The woman worked as a babysitter : On biases in language generation . arXiv preprint arXiv : 1909 . 01326 ( 2019 ) . [ 61 ] Miika Silfverberg , I Scott MacKenzie , and Panu Korhonen . 2000 . Predicting text entry speed on mobile phones . In Proceedings of the SIGCHI conference on Human factors in computing systems . 9 – 16 . [ 62 ] James F Stratman and Linda Carey . 1987 . 5 Cognitive processes in revision . Advances in Applied Psycholinguistics : Volume 2 , Reading , Writing , and Language Learning 2 ( 1987 ) , 176 . [ 63 ] Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . 2017 . Attention is all you need . In Advances in neural information processing systems . 5998 – 6008 . [ 64 ] Jesse Vig . 2019 . A multiscale visualization of attention in the transformer model . arXiv preprint arXiv : 1906 . 05714 ( 2019 ) . [ 65 ] Michael D . Winans . 2021 . Grammarly’s Tone Detector : Helping Students Write Pragmatically Ap - propriate Texts . RELC Journal 52 , 2 ( 2021 ) , 348 – 352 . https : / / doi . org / 10 . 1177 / 00336882211010506 arXiv : https : / / doi . org / 10 . 1177 / 00336882211010506 [ 66 ] Jun Zhao . 2017 . Native speaker advantage in academic writing ? Conjunctive realizations in EAP writing by four groups of writers . Ampersand 4 ( 2017 ) , 47 – 57 . https : / / doi . org / 10 . 1016 / j . amper . 2017 . 07 . 001 , Vol . 1 , No . 1 , Article . Publication date : August 2022 .