Report Posterior Cingulate Neurons Dynamically Signal Decisions to Disengage during Foraging Highlights d Foraging salience drives monkeys’ choices to switch strategies in two tasks d PCC neuronal activity during both tasks predicted strategy switches d PCC neurons signaled salience in both tasks more strongly in poor than rich contexts Authors David L . Barack , Steve W . C . Chang , Michael L . Platt Correspondence dbarack @ gmail . com In Brief Barack et al . report that foraging salience motivated strategic disengagement in two distinct tasks . Posterior cingulate neurons preferentially signaled salience and forecast divergent choices when reward rates were low , suggesting a role in the strategic control of behavior . Barack et al . , 2017 , Neuron 96 , 339 – 347 October 11 , 2017 ª 2017 Elsevier Inc . https : / / doi . org / 10 . 1016 / j . neuron . 2017 . 09 . 048 Neuron Report Posterior Cingulate Neurons Dynamically Signal Decisions to Disengage during Foraging David L . Barack , 1 , 5 , 6 , * Steve W . C . Chang , 2 , 3 and Michael L . Platt 4 1 Department of Philosophy and Center for Cognitive Neuroscience , Duke University , Durham , NC 27701 , USA 2 Department of Psychology , Yale University , New Haven , CT 06520 , USA 3 Department of Neuroscience , Yale University School of Medicine , New Haven , CT 06510 , USA 4 Departments of Neuroscience , Psychology , and Marketing , University of Pennsylvania , Philadelphia , PA 19104 , USA 5 Present address : Center for Science and Society and Departmentsof Philosophy , Neuroscience , and Economics , Columbia University , New York , NY 10027 , USA 6 Lead Contact * Correspondence : dbarack @ gmail . com https : / / doi . org / 10 . 1016 / j . neuron . 2017 . 09 . 048 SUMMARY Foraging for resources is a fundamental behavior balancing systematic search and strategic disen - gagement . The foraging behavior of primates is especially complex and requires long - term memory , value comparison , strategic planning , and decision - making . Here we provide evidence from two different foraging tasks that neurons in primate posterior cingulate cortex ( PCC ) signal decision salience dur - ing foraging to motivate disengagement from the current strategy . In our foraging tasks , salience re - fers to the difference between decision thresholds and the net harvested reward . Salience signals were stronger in poor foraging contexts than rich ones , suggesting low harvest rates recruit mecha - nisms in PCC that regulate strategic disengagement and exploration during foraging . INTRODUCTION Animals forage for a wide range of resources ( Stephens and Krebs , 1986 ) , making a series of sequential , non - exclusive , accept - or - reject decisions ( Stephens , 2008 ; Calhoun and Hay - den , 2015 ) . Hypothesized as a major selective pressure driving the expansion of neocortex in primates ( Milton , 1988 ; Genovesio et al . , 2014 ; DeCasien et al . , 2017 ) , foraging is a fundamental cognitive skill ( Newell , 1994 ; Hills et al . , 2010 ) applicable in a variety of domains , including search ( Cain et al . , 2012 ; Wolfe , 2013 ) , memory ( Hills et al . , 2015 ) , and social ( Hills and Pachur , 2012 ; Turrin et al . , 2017 ) and executive processing ( Payne et al . , 2007 ; Wilke et al . , 2009 ; Metcalfe and Jacobs , 2010 ; Payne and Duggan , 2011 ) . Despite widespread relevance , the neural circuits mediating foraging have only recently begun to be described ( Hayden et al . , 2011 ; Kolling et al . , 2012 ; Shenhav et al . , 2014 ) . The anterior and posterior cingulate cortices , strongly and reciprocally connected ( Heilbronner and Haber , 2014 ) , are both implicated in control ( Botvinick et al . , 2004 ; Pearson et al . , 2011 ) . During foraging , dorsal anterior cingulate cortex ( dACC ) carries signatures of reward - based computations ( Hayden et al . , 2011 ; Kolling et al . , 2012 ; Shenhav et al . , 2014 ) , but the role of the posterior cingulate cortex ( PCC ) remains unknown . Neuroimaging studies link PCC activity with value ( Kable and Glimcher , 2007 ; Knutson and Bossaerts , 2007 ) , strategy ( Wan et al . , 2015 ) , and change detection ( Summerﬁeld et al . , 2011 ; McGuire et al . , 2014 ) . PCC neurons signal rewards ( McCoy et al . , 2003 ) , risk ( McCoy and Platt , 2005 ) , task switches ( Hayden and Platt , 2010 ) , and exploratory decisions ( Pearson et al . , 2009 ) . In addition , microstimulation of PCC provokes preference rever - sals ( Hayden et al . , 2008 ) and inactivation impairs learning ( Heil - bronner and Platt , 2013 ) . This diverse array of observations may reﬂect computations that regulate foraging behavior . Here we show PCC neurons signal salience in motivating de - cisions to disengage during foraging . Salience refers to atten - tional capture by environmental events ( Treisman and Gelade , 1980 ; Gottlieb et al . , 1998 ) or decision outcomes ( Pearce and Hall , 1980 ; Esber and Haselgrove , 2011 ; Kahnt et al . , 2014 ) , and regulates stimulus processing ( Corbetta and Shulman , 2002 ) , learning ( Yu and Dayan , 2005 ) , and motivation ( Brom - berg - Martin et al . , 2010 ; Kahnt and Tobler , 2013 ) . PCC neurons are known to signal outcome salience , including reward size ( McCoy et al . , 2003 ) , omission ( McCoy et al . , 2003 ) , and variance ( McCoy and Platt , 2005 ) , as well as offer salience , the absolute difference of option values from a standard ( Heilbronner et al . , 2011 ) . Here we report that foraging salience , deﬁned as the abso - lute difference between experienced and threshold cumulative reward , regulated strategy in two separate foraging tasks involving distinct decisions to disengage . In the patch foraging task , monkeys chose between harvesting reward from a di - minishing source and disengaging to forage in a new one . In the traveling salesman task , a circular array of targets was baited unpredictably with large and small rewards . Monkeys developed routine circular patterns of target exploitation , known as a trapline in behavioral ecology ( Berger - Tal and Bar - David , 2015 ; cf . Freeman , 1968 after Darwin ) . In both tasks , PCC neurons forecast decisions to disengage and signaled foraging salience , with stronger signals in poor envi - ronments than rich ones . Our results suggest PCC neurons signal foraging salience to promote strategic disengagement and exploration . Neuron 96 , 339 – 347 , October 11 , 2017 ª 2017 Elsevier Inc . 339 RESULTS Travel Times and Foraging Salience Drive Patch - Leaving Decisions In the patch - leaving task , monkeys ( M . mulatta ) decided to har - vest reward from a depleting patch or to disengage and replenish it ( Figure 1A ) . They made a series of decisions to harvest a juice reward that decreased over time as it was repeatedly chosen ( initially 0 . 3 mL , decreasing in (cid:1) 0 . 02 mL steps ) or to reset the value of the patch , incurring a ‘‘travel time’’ that varied from patch to patch . Patch residence time increased as travel times increased ( Figure 1B ) , corroborating prior observations ( Hayden et al . , 2011 ) ( linear regression , p < 0 . 00001 , b = 1 . 40 ; Monkey L [ ML ] , p < 0 . 00001 , b = 1 . 11 ; Monkey R [ MR ] , p < 0 . 00001 , b = 1 . 50 ) . We considered three models of patch - leaving decisions : an optimal foraging model based on the marginal value theorem ( MVT ; Charnov , 1976 ) , a net foraging model based on survival analysis ( Fox , 2001 ) , and a salience model inspired by attentional learning theory ( Pearce and Hall , 1980 ) . The optimal foraging model set the decision variable to the difference between the current reward rate and the MVT - calculated optimal reward rate for departing a patch . The net foraging model captured the central tendencies of the decision to leave a patch by setting the leave threshold to the mean of the exponential reward intake function and setting the decision variable to the reward Fixation ( 0 . 4 - 0 . 8 sec ) TargetsOn Stay Leave Saccade Handling time delay ( 0 . 4 s ) Travel time delay ( 0 . 5 - 10 . 5 s ) Saccade Reward reduces by 0 . 02 mL ITI ( 1 s ) ITI ( 1 s ) Reward resets to 0 . 3 mL A B 2 4 6 8 10 20 40 60 80 100 120 Travel time ( sec ) T i m e i n p a t c h ( sec ) C Observed p ( Leave Patch ) Predicted p ( Leave Patch ) - 0 . 74 - 0 . 51 - 0 . 29 - 0 . 06 0 . 17 Net reward foraging model DV 0 . 2 0 . 4 0 . 6 0 . 8 P r ob a b ili t y o f l eav i ng p a t c h - 0 . 0050 . 018 0 . 041 0 . 064 0 . 087 Optimal foraging model DV 0 . 2 0 . 4 0 . 6 0 . 8 - 5 . 38 - 3 . 96 - 2 . 54 - 1 . 12 0 . 3 Salience foraging model DV 0 . 2 0 . 4 0 . 6 0 . 8 D Monkey R Monkey L Monkey L Monkey R Figure 1 . Patch Foraging Task Reveals Sensitivity of Monkeys to Salience during Foraging ( A ) Thepatch - leaving task . Monkeys ﬁxate on thecentral cross for 400 – 800 ms . Fixationthenextinguishesand targets appear . If monkeys choosethe smallblue rectangle ( stay inpatch option ) , thenasmall reward is delivered after abrief delay ( handling time ; 400ms ) followed by 1s intertrialinterval ( ITI ) and beginning of a newtrial . Rewardassociatedwiththestayinpatchoptionalsodecreasesbyasmallamount . Ifmonkeyschoosethelargegrayrectangle ( leavepatchoption ) , they mustwaitthroughatimeoutperiodcorrespondingtotheheightofthegraybar , anddonotreceivereward . Thisisfollowedby1sITIandbeginningofanewtrialin a new patch . At onset of a new patch , reward associated with the blue rectangle resets to a constant initial amount , locations of the blue and gray rectangles are swapped , and a new height for the gray bar , signaling the travel timeout to replenish the patch , is selected from a uniform distribution , which correlates with a delay ranging from 0 . 5 to 10 . 5 s . ( B ) Time in patch plotted as a function of travel time . As travel times grew , monkeys stayed longer in a patch . Total of 3 , 511 patches in 43 electrophysiology sessions across both monkeys . ( C ) Probabilityofleavingapatchversusthedecisionvariableforthreedifferentbehavioralmodels . Blackcircles : meanobservedprobabilityofleavingapatchfor the corresponding value of the decision variable . Red lines : predicted leave probability . All three plots display a logistic regression of leave or stay decisions against the decision variable . Left panel , net reward foraging model ; middle panel , optimal foraging model ; right panel , salience foraging model . ( D ) Recording locations for both monkeys . 340 Neuron 96 , 339 – 347 , October 11 , 2017 differential , the difference between the current net harvested reward computed over the whole patch and threshold net har - vested reward computed from the mean of the intake function . The salience foraging model set the decision variable to the product of the reward differential and weighted salience , the absolute value of the reward differential . The salience foraging model provided the best ﬁt to patch - leaving decisions ( Figure 1C ; mean AIC score ± SEM : net foraging model : 509 . 87 ± 28 . 88 ; ML , 400 . 50 ± 31 . 45 ; MR , 604 . 97 ± 36 . 73 ; optimal foraging model : 488 . 65 ± 28 . 50 ; ML , 373 . 23 ± 29 . 57 ; MR , 589 . 02 ± 35 . 46 ; salience foraging model : 398 . 75 ± 26 . 60 ; ML , 272 . 80 ± 21 . 27 ; MR , 508 . 27 ± 31 . 84 ; STAR Methods ) . Corroborating these ﬁts , response times were faster for more salient choices ( linear regression by day of response times versus salience ; ML , mean b = (cid:3) 0 . 022 ± 0 . 025 , Student’s t test , p > 0 . 39 , t ( 19 ) = (cid:3) 0 . 88 ; MR , mean b = (cid:3) 0 . 13 ± 0 . 0089 , Student’s t test , p < 1 3 10 (cid:3) 12 , t ( 22 ) = (cid:3) 14 . 94 ) . PCC Neurons Forecast Leave Decisions and Dynamically Signal Salience during Patch Foraging We recorded activity of 159 PCC neurons ( Figure 1D ; 96 in ML and 63 in MR ; individual monkey results in Figure S1 ) . Firing rates predicted patch - leaving decisions many seconds in advance by ramping up or down in the last 15 s in patch ( example cell , Fig - ure 2A ; patch exit epoch ; linear regression during patch exit epoch , p < 1 3 10 (cid:3) 20 , b = 0 . 20 ± 0 . 020 ) . Eighty - six ( 54 % ) of 159 cells showed a signiﬁcant increase or decrease in activity approaching patch exit ( linear regression during patch exit , p < 0 . 05 ) . This pattern is reminiscent of ramping of neuronal activity to a threshold observed for perceptual and foraging 11 13 15 17 A F i r i ng R a t e ( s p i kes / sec ) Cell L110412A1a 11 13 15 17 Low Reward Rate High Reward Rate - 12 - 9 - 6 - 3 0 Time Relative to Leave ( sec ) F i r i ng R a t e ( s p i kes / sec ) B C - 0 . 05 0 0 . 05 0 . 1 M ea n N o r m a li z e d F i r i ng R a t e n = 159 cells Low Reward Rate High Reward Rate - 12 - 9 - 6 - 3 0 Time Relative to Leave ( sec ) Cell L110412A1a - 12 - 9 - 6 - 3 0 Time Relative to Leave ( sec ) D - 4 - 2 Time x Reward Rate Coefficients - 3 - 2 - 1 0 1 2 S a li e n ce C o e ff i c i e n t s - 0 . 1 - 0 . 15 0 . 15 0 . 2 0 2 4 Figure 2 . PCC Neurons Predict Patch Departures Several Seconds in Advance ( A ) SamplecellPSTHstarting15sbeforepatchdeparture . Thiscellshowsamarkedincreaseinﬁring ( thickblackline ) duringthe15spatchexitwindow . Redline : linear ﬁt to ﬁring rate within the patch exit window . Black tickmarks : sample raster plots from 20 patches . ( B ) Same cell as in ( A ) , showing differences in ﬁring dynamics depending on environmental richness preceding decisions to leave a patch . Rich contexts ( red trace ) , reward rate Z score R 0 ; poor contexts ( blue trace ) , reward rate Z score < 0 . ( C ) Population plot for rich and poor environments , matching the pattern observed in the sample cell in ( B ) . n = 159 cells ( 96 from ML and 63 from MR ) . ( D ) Salience coefﬁcients plotted against the interaction of time and reward rate coefﬁcients . Later and lower reward rates resulted in stronger salience signaling . See also Figure S3 . See Figure S1 for individual monkey results . In all plots , thick lines , mean ; shading , ±1 SEM . Neuron 96 , 339 – 347 , October 11 , 2017 341 decisions ( Gold and Shadlen , 2007 ; Hayden et al . , 2011 ) but extended continuously across multiple actions . We focused the remaining analyses on this patch exit epoch . Because PCC neurons signal and causally facilitate learning in low - value contexts , but not high ones ( Heilbronner and Platt , 2013 ) , we next queried whether PCC neurons signal patch de - partures differently in distinct reward rate contexts . Reward rate was deﬁned as the net reward harvested in a patch divided by time spent harvesting . Poor environments presented low ( Z score < 0 ) reward rate decision contexts and rich environ - ments presented high ( Z score R 0 ) ones . An example neuron showed a signiﬁcant increase in ﬁring rate preceding the deci - sion to leave the patch in poor environments ( Figure 2B ; linear regression , p < 1 3 10 (cid:3) 23 ) , but not rich ones ( p > 0 . 4 ) . The slopes of these regressions differed signiﬁcantly ( ANCOVA , p < 1 3 10 (cid:3) 13 , F ( 1 , 596 ) = 62 . 57 ) . Environmental richness modulated this neuron’s ramping activity across patches ( linear regression of patch - by - patch slopes versus Z scored reward rate , p < 0 . 001 ) , a pattern seen in the slopes of 20 ( 13 % ) of 159 cells ( linear regression , p < 0 . 05 ) . This pattern was also evident in the average population activity ( Figure 2C ; linear regression ; poor , p < 1 3 10 (cid:3) 9 ; rich , p > 0 . 35 ; ANCOVA , p < 0 . 00005 , F ( 1 , 596 ) = 17 . 21 ) . The observation that ﬁring rates of PCC neurons predict im - pending patch departures prompts the question of whether PCC neurons also signal salience , and if so , whether salience signals vary with environmental richness . Rich environments may attenuate salience signaling because the current strategy remains proﬁtable . Combined with differences in ramping across contexts , the dependency of salience signaling on environ - mental richness predicts a three - way interaction during the patch exit epoch between time , reward rate , and salience . Spike counts in 50 ms bins were regressed against all three covariates and all interactions using a generalized linear model ( GLM ) with a log - linear link function and Poisson distributed noise . Of 159 neurons , 25 ( 16 % ) showed signiﬁcant interactions of all three covariates ( ML , 17 [ 18 % ] of 96 neurons ; MR , 8 [ 13 % ] of 63 neu - rons ; STAR Methods ) . To examine temporal dynamics , all spikes in a sliding boxcar ( 3 s width , 50 ms steps ) were regressed against reward rate , salience , and their interaction ( Figure S3A , cells sorted from negative [ top ] to positive [ bottom ] by the sum of the beta coefﬁcients ) . This analysis revealed a pattern of pos - itive and negative salience coefﬁcients over time , with some cells positively signaling foraging salience and others negatively , indi - cating PCC neurons do not store salience information between patch - leaving decisions . Context - dependent salience signaling also predicts stronger salience signals in poor environments . Coefﬁcients for salience were negatively correlated with coefﬁcients for the interaction of reward rate and time in patch ( Figure 2D ; linear regression , b = – 0 . 17 ± 0 . 042 , p < 0 . 0005 ) , conﬁrming this prediction . Finally , this context dependency predicts the inﬂuence of salience on ﬁring rates in poor patches should be larger than in rich ones . We regressed spike counts during the whole trial epoch ( 1 s before choice to 1 s after ) against salience for poor and rich patches separately . In rich environments , there was no population - level effect of salience ( linear regression , mean b = 0 . 098 ± 0 . 090 , Student’s t test , p > 0 . 27 , t ( 158 ) = 1 . 10 ) . By contrast , in poor environments , greater salience was accompa - nied by increased average ﬁring rates in the whole population ( mean b = 0 . 48 ± 0 . 18 , p < 0 . 01 , t ( 158 ) = 2 . 67 ) . The inﬂuence of salience was also larger in poor environments than in rich ones ( Student’s t test , mean Db = 0 . 38 ± 0 . 18 , p < 0 . 05 , t ( 158 ) = 2 . 16 ) . Monkeys Trapline Forage to Solve a Traveling Salesman Problem In our traveling salesman task , monkeys visually navigated through a circular array of six targets ( Figure 3A ) . Two targets were randomly baited on each trial , one with large and one with small reward . Monkeys spontaneously developed traplines , deﬁned as a set sequence of choices . They typically chose tar - gets in the same sequence across days , tracing a circle , the most efﬁcient route ( the daily dominant pattern , DDP ; ML , same DDP across 24 of 30 sessions ; MR , same DDP across all 14 sessions ; Figure 3B ; STAR Methods ) . Though monkeys usually chose targets in the same order , they occasionally diverged from this routine , providing an opportunity to investigate changes in foraging strategy in a second task . Across all recording days , mean proportion of diverge trials was high : 0 . 21 ± 0 . 017 of all trials ( ML , 0 . 22 ± 0 . 025 ; MR , 0 . 18 ± 0 . 0078 ) . To capture these divergences , the three foraging models used in the patch foraging task were ﬁt to monkeys’ choices on the traveling salesman task ( STAR Methods ) . Choices were coded as decisions to stay on the trapline or diverge from it , excluding trials in which monkeys started with an off - trapline choice . Again , the salience foraging model pro - vided the best ﬁt to decisions to diverge ( Figure 3C ; mean AIC score ± SEM : net foraging model ( 3 10 3 ) : 1 . 80 ± 0 . 21 ; ML , 1 . 86 ± 0 . 29 ; MR , 1 . 66 ± 0 . 26 ; optimal foraging model ( 3 10 4 ) : 3 . 12 ± 0 . 22 ; ML , 3 . 01 ± 0 . 26 ; MR , 3 . 34 ± 0 . 44 ; salience foraging model ( 3 10 3 ) : 1 . 73 ± 0 . 21 ; ML , 1 . 80 ± 0 . 29 ; MR , 1 . 58 ± 0 . 26 ; STAR Methods ) . Corroborating these ﬁts , response times were faster for more salient choices ( linear regression by day of response times versus salience ; ML , mean b = (cid:3) 0 . 058 ± 0 . 013 , Student’s t test , p < 0 . 0005 , t ( 29 ) = (cid:3) 4 . 49 ; MR , mean b = (cid:3) 0 . 039 ± 0 . 0090 , Student’s t test , p < 0 . 001 , t ( 13 ) = (cid:3) 4 . 28 ) . PCC Neurons Predict Path Divergences and Dynamically Signal Salience during Traplining We predicted that the patterns of neural activity observed in PCC during patch foraging also would be evident during traplining . To test this hypothesis , we recorded spiking activity of 124 new neurons in the same two monkeys ( Figure 1D ; 84 in ML and 40 in MR ; individual monkey results in Figure S2 ) . Firing rates pre - dicted when monkeys would diverge from traplines . In our pop - ulation , 59 ( 48 % ) of 124 neurons signaled choices on which mon - keys diverged from traplines ( linear regression on spike counts during anticipation epoch from 250 ms before choice saccade to 250 ms hold ﬁxation after , p < 0 . 05 ; STAR Methods ) , and 54 ( 44 % ) of 124 neurons predicted decisions to diverge from trap - lines one choice in advance ( linear regression on average ﬁring rates during anticipation epoch , p < 0 . 05 ) . Forty - four ( 35 % ) of 124 neurons signaled diverge decisions in both conditions . PCC neurons forecast divergences from traplines with phasic responses , as illustrated by the example cell ( Figure 4A ) and population response ( Figure 4B ) . To quantify this difference , 342 Neuron 96 , 339 – 347 , October 11 , 2017 mean ﬁring rate in a 1 s epoch before divergence was compared to the mean ﬁring rate before the last non - diverge choice . Of 124 neurons , 59 ( 48 % ) ﬁred more preceding diverge choices than preceding non - diverge choices ( Student’s t test , p < 0 . 05 ) . An example neuron ( Figure 4A ) showed higher ﬁring rates on choices immediately prior to diverging ( Student’s t test , p < 1 3 10 (cid:3) 9 , t ( 288 ) = 6 . 58 ) . This same pattern characterized the population response ( Figure 4B ) , with higher ﬁring rates prior to decisions to diverge compared to non - diverge ( Student’s t test , p < 1 3 10 (cid:3) 8 , t ( 38 ) = 8 . 01 ) . Akin to the differences in patch - leave signaling in PCC neurons , this predictive signaling for path divergences differed in rich environments compared to poor . After sorting rich ( reward rate Z score R 0 ) and poor ( reward rate Z score < 0 ) environ - ments , the same sample neuron showed differences in predic - tive signaling across contexts ( Figure 4C ) , with higher ﬁring rates in poor environments ( linear regression of mean ﬁring rates by trial versus Z scored reward rate , p < 0 . 005 ) . The activity of 19 of 124 cells ( 15 % ) was correlated with reward rate ( linear regression , p < 0 . 05 ) . Elevated activity in poor compared to rich environments was also observed in the population pre - ceding decisions to diverge ( Figure 4D ; linear regression , p < 0 . 05 ) . We next explored whether PCC neurons signal foraging salience during trapline foraging and if such signals depend on environmental richness . The dependency of salience signaling on environmental richness predicts a three - way inter - action preceding a diverge decision between time , reward rate , and salience . PCC neurons signaled the interaction between all three covariates , albeit more weakly than during patch foraging : of 124 PCC neurons , 13 ( 10 % ) signaled the interaction of all three covariates ( GLM , spikes sorted in 50 ms bins from ﬁrst choice in trial to diverge choice and regressed against time before diverge , reward rate , salience , and all interactions , Bon - ferroni corrected ; ML , 9 ( 11 % ) of 84 neurons ; MR , 4 ( 10 % ) of 40 neurons ; STAR Methods ) . A sliding boxcar plot ( Figure S3B ) revealed a much noisier but similar pattern of positive and nega - tive salience coefﬁcients as observed in the patch - leaving task ( Figure S3A ) . Such context - dependent signaling also predicts a negative correlation between beta weights for salience and for the interac - tion of reward rate and time . Regression of the salience coefﬁ - cients against coefﬁcients for the interaction of reward rate with time revealed a signiﬁcant negative correlation ( Figure 4E ; linear regression , b = – 0 . 078 ± 0 . 021 , p < 0 . 0005 ; ML , b = – 0 . 12 ± 0 . 030 , p < 0 . 0005 ; MR , b = – 0 . 012 ± 0 . 023 , p > 0 . 5 , but with one outlier removed , b = – 0 . 087 ± 0 . 045 , p = 0 . 0612 ) . Finally , this context dependency predicts the strength of salience coding in poor environments should be larger than in rich ones . After sorting decisions by rich and poor contexts , A Fixation ( 0 . 4 - 0 . 8 s ) TargetsOn Choice B Monkey L Monkey R 2 3 4 5 6 1 1 2 3 4 5 6 DDP for 24 / 30 sessions 50 trials sample eye traces . DDP for 14 / 14 sessions 50 trials sample eye traces . C - 0 . 8 - 0 . 6 - 0 . 4 - 0 . 2 0 Net reward foraging model DV 0 . 2 0 . 4 0 . 6 0 . 8 P r ob a b ili t y o f d i ve r g i ng Observed p ( Divergence ) Predicted p ( Divergence ) 0 . 2 Optimal foraging model DV 0 . 2 0 . 4 0 . 6 0 . 8 P r ob a b ili t y o f d i v e r g i ng Salience foraging model DV 0 . 2 0 . 4 0 . 6 0 . 8 P r ob a b ili t y o f d i ve r g i ng - 25 . 4 - 21 . 2 - 16 . 9 - 12 . 7 - 8 . 4 - 3 . 2 - 2 . 5 - 1 . 9 - 1 . 2 - 0 . 5 Figure 3 . Monkeys Spontaneously Diverged from Traplines in a Traveling Salesman Task ( A ) Traveling salesman task . Monkeys ﬁxate on the central cross for 400 – 800 ms . Fixation extinguishes and targets appear . Monkeys are free to select targets in any pattern , but must select all six targets to advance to the next trial . Two targets were baited , one with a small reward and one with a large reward ( small and large juice drops , respectively ) . ( B ) Sample eye traces from 50 trials each for ML ( top ) and MR ( bottom ) . Left panel shows eye traces ; right panel lists the typical order in which targets were selected ( daily dominant pattern ; DDP ) for each monkey . ( C ) Probability of diverging from trapline versus the decision variable for three different behavioral models , the same models as ﬁt to the patch - leaving task choices . Same conventions as Figure 1C . Neuron 96 , 339 – 347 , October 11 , 2017 343 we regressed spike counts during the whole choice epoch ( 250 ms before choice to 500 ms after choice ) against salience . Just as in the patch foraging task , in rich environments there was no population - level effect of salience ( linear regression , mean b = 0 . 12 ± 0 . 075 , Student’s t test , p > 0 . 1 , t ( 121 ) = 1 . 57 ) , while one was observed in poor environments ( mean b = 0 . 23 ± 0 . 084 , p < 0 . 01 , t ( 122 ) = 2 . 77 ) . While the inﬂuence of salience was greater in poor than rich contexts , this difference was not statistically signiﬁcant ( Student’s t test , mean Db = 0 . 12 ± 0 . 098 , p > 0 . 2 , t ( 121 ) = 1 . 18 ) . C D A B - 2 - 1 . 5 - 1 - 0 . 5 0 0 . 5 1 Time Relative to Divergent Choice ( s ) F i r i ng R a t e ( s p i kes / sec ) D - 1ND - 1 DivergeNon - Diverge Cell L010414A1b 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 M ea n M odu l a t i on o f F i r i ng R a t e - 2 - 1 . 5 - 1 - 0 . 5 0 0 . 5 1 Time Relative to Divergent Choice ( s ) D - 1 ND - 1 DivergeNon - Diverge n = 124 cells E - 6 - 4 - 2 0 2 4 6 8 - 1 . 5 - 1 - 0 . 5 0 0 . 5 1 S a li e n ce C o e ff i c i e n t - 2 - 1 . 5 - 1 - 0 . 5 0 0 . 5 1 Time Relative to Divergent Choice ( s ) 0 0 . 2 0 . 4 0 . 6 M ea n M odu l a t i on o f F i r i ng R a t e D - 1 Low Reward Rate High Reward Rate n = 124 cells - 0 . 2 0 . 8 - 2 - 1 . 5 - 1 - 0 . 5 0 0 . 5 1 F i r i ng R a t e ( s p i kes / sec ) Low Reward Rate High Reward Rate Cell L010414A1b D - 1 - 0 . 1 10 20 30 40 10 20 30 40 50 Time Relative to Divergent Choice ( s ) Figure 4 . PCC Neurons Predict Trapline Divergences in Advance ( A ) SamplecellPSTHshowingelevatedactivityduringtheinter - choiceintervalofdivergetrials ( purpletrace ) comparedtonon - divergetrials ( orangetrace ) . D - 1 , mean time of choice before diverge choice ; ND - 1 , mean time of choice before last non - diverge choice . Tick marks , sample raster plots from 20 trials in each condition . ( B ) Population plot for diverge ( purple trace ) and non - diverge ( orange trace ) trials . Same conventions as ( A ) . ( C ) Samecellasin ( A ) , showingdifferencesinﬁringdynamicsdependingonenvironmentalrichnessprecedingdivergences . Richcontexts ( redtrace ) , rewardrate Z score R 0 ; poor contexts ( blue trace ) , reward rate Z score < 0 . Activity was elevated prior to diverge decisions in poor environments only . ( D ) Population plot for rich ( red trace ) and poor ( blue trace ) environments . ( E ) Saliencecoefﬁcientsplottedagainsttime 3 rewardratecoefﬁcients . Laterandlowerrewardratesresultedinstrongersaliencesignaling , matchingobservations prior to leaving a patch ( Figure 2D ) . See also Figure S3 . In ( B ) and ( D ) , n = 124 cells ( 84 from ML and 40 from MR ) . See Figure S2 for individual monkey results . In all plots , thick lines , mean ; shading , ±1 SEM . 344 Neuron 96 , 339 – 347 , October 11 , 2017 DISCUSSION In both tasks , the salience foraging model best described behavior . Conceptually , salience reﬂects the occurrence of sta - tistically improbable environmental events that are relevant to an animal . Foraging requires tracking the environment in order to detect and adapt to changes in the quality , spatial location , and abundance of resources . Foraging salience provides an efﬁcient way to track the need to change behavior . We hypoth - esize that the salience model best described behavior because , unlike the optimal or net foraging models , it captures factors that inﬂuence orienting ( Simion and Shimojo , 2007 ) and atten - tion ( Orquin and Mueller Loose , 2013 ) . Salience generally plays an important role in allocating attention ( Gottlieb et al . , 1998 ) to motivate behavior ( Bromberg - Martin et al . , 2010 ) or to learn ( Pearce and Hall , 1980 ) , and can be thought of as an increase in signal gain ( Reynolds and Heeger , 2009 ) to enable faster and more accurate stimulus processing . In the best - ﬁt model , foraging salience similarly serves as a multiplicative gain on cu - mulative harvest . Possible cognitive roles for foraging salience signals in PCC include motivating disengagement , computing the value of alternative options , and tracking choice difﬁculty . First , salience signals may reﬂect integration of environmental information with the goal of optimizing rewards by motivating disengagement . Several neuroimaging studies of environmental change detec - tion have reported activity in PCC reﬂecting integration of envi - ronmental signals ( Summerﬁeld et al . , 2011 ; McGuire et al . , 2014 ) , and PCC neurons signal behavioral goals ( Dean et al . , 2004 ) , option values ( McCoy et al . , 2003 ) , reward uncertainty ( McCoy and Platt , 2005 ) , decision strategies ( Pearson et al . , 2009 ) , and decision salience ( Heilbronner et al . , 2011 ) . In our study , PCC neurons signaled foraging salience and the interac - tion of salience with elapsed time and reward rate , a synthesis of multiple sources of evidence that can be used to adapt behavior to the environment . Salience signals in PCC were also stronger in poor foraging contexts , suggesting control sig - nals are ampliﬁed when strategic changes in behavior are favored . Second , the observed signals may reﬂect the value of searching for alternatives , similar to activity in dACC ( Kolling et al . , 2012 ) . In support of this , as the cumulative reward approaches the threshold for leaving , salience decreases and the value of disengaging increases in both tasks . Third , signals observed in PCC may reﬂect choice difﬁculty . Recent debate regarding dACC activity during foraging has explicitly con - trasted the value of search with choice difﬁculty ( Shenhav et al . , 2014 ) . As the agent approaches the threshold net reward for disengaging , salience decreases , making the decision more difﬁcult . Given our experimental design , we are unable to distin - guish between these possibilities . Foraging salience signals may be computed locally within PCC , though imaging studies have failed to identify other types of salience signals ( Litt et al . , 2011 ; Kahnt and Tobler , 2013 ; Kahnt et al . , 2014 ) . Failure to ﬁnd salience signals in PCC in fMRI studies may reﬂect variation in the sign of salience signals across the population and across time within the same neuron ( Figure S3 ) . Salience signals may also be sent to PCC from other areas . PCC is preferentially innervated by projections from locus coeruleus ( LC ) and expresses a greater proportion of noradren - ergic receptors than other cingulate regions ( Bozkurt et al . , 2005 ) . LC contributes to change detection ( Nassar et al . , 2012 ) , exploration ( Jepma and Nieuwenhuis , 2011 ) , and outcome salience ( Aston - Jones and Cohen , 2005 ) for orienting attention ( Corbetta et al . , 2008 ) and learning ( Sara and Bouret , 2012 ) , potentially a source of salience signals in PCC . Alterna - tively , salience signals have been observed in cortical areas con - nected with PCC , including lateral prefrontal cortex ( Kobayashi et al . , 2006 ) , posterior parietal cortex ( Kahnt et al . , 2014 ) , anterior cingulate cortex ( Litt et al . , 2011 ; Kahnt et al . , 2014 ) , orbitofrontal cortex ( Ogawa et al . , 2013 ) and temporoparietal junction ( Kahnt et al . , 2014 ) . PCC may integrate information from some or all of these areas to compute foraging salience to adapt behavior to the current environment ( Pearson et al . , 2011 ) . The framework of disengagement decisions covers many cognitive behaviors that evolve over multiple actions and involve many types of resources , both external and internal ( Hills et al . , 2008 ) . Foraging presents a powerful approach for studying how decisions unfold over multiple actions , and may be the foun - dation upon which more complex strategic decisions are built ( Pearson et al . , 2014 ) , a view supported by ﬁnding a common set of neural computations regulating disengagement decisions in patch leaving and traplining . STAR + METHODS Detailed methods are provided in the online version of this paper and include the following : d KEY RESOURCES TABLE d CONTACT FOR REAGENT AND RESOURCE SHARING d EXPERIMENTAL MODEL AND SUBJECT DETAILS d METHOD DETAILS B Patch Leaving Task Behavioral Modeling B Traveling Salesman Task Behavioral Modeling d QUANTIFICATION AND STATISTICAL ANALYSIS B Patch Leaving Task Neural Analysis B Traveling Salesman Task Neural Analysis SUPPLEMENTAL INFORMATION Supplemental Information includes three ﬁgures and can be found with this article online at https : / / doi . org / 10 . 1016 / j . neuron . 2017 . 09 . 048 . AUTHOR CONTRIBUTIONS D . L . B . and M . L . P . designed the experiments ; D . L . B . collected and analyzed the data ; S . W . C . C . supervised data collection during the ﬁrst task ; and D . L . B . , S . W . C . C . , and M . L . P . prepared and revised the manuscript . ACKNOWLEDGMENTS This work was supported by the National Eye Institute of the NIH ( R01 EY013496 to M . L . P . ) and an Incubator Award from the Duke Institute for Brain Sciences . We thank Ben Hayden for designing the patch foraging task ; Jean - Franc¸oisGarie´pyforassistanceindesigning thetravelingsalesman task ; John Pearson , Geoff Adams , Nick DeWind , and Greg Jensen for technical help ; Monica Carlson for animal husbandry ; and numerous commenters for helpful feedback . Neuron 96 , 339 – 347 , October 11 , 2017 345 Received : June 19 , 2017 Revised : August 30 , 2017 Accepted : September 26 , 2017 Published : October 11 , 2017 REFERENCES Akaike , H . ( 1974 ) . Anewlookatthestatistical modelidentiﬁcation . IEEETrans . Automat . Contr . 19 , 716 – 723 . Aljadeff , J . , Lansdell , B . J . , Fairhall , A . L . , and Kleinfeld , D . ( 2016 ) . Analysis of neuronal spike trains , deconstructed . Neuron 91 , 221 – 259 . Aston - Jones , G . , and Cohen , J . D . ( 2005 ) . An integrative theory of locus coeru - leus - norepinephrine function : adaptive gain and optimal performance . Annu . Rev . Neurosci . 28 , 403 – 450 . Berger - Tal , O . , and Bar - David , S . ( 2015 ) . Recursive movement patterns : re - view and synthesis across species . Ecosphere 6 , 149 . Botvinick , M . M . , Cohen , J . D . , and Carter , C . S . ( 2004 ) . Conﬂict monitoring and anterior cingulate cortex : an update . Trends Cogn . Sci . 8 , 539 – 546 . Bozkurt , A . , Zilles , K . , Schleicher , A . , Kamper , L . , Arigita , E . S . , Uylings , H . B . M . , and Ko¨tter , R . ( 2005 ) . Distributions of transmitter receptors in the macaque cingulate cortex . Neuroimage 25 , 219 – 229 . Brainard , D . H . ( 1997 ) . The psychophysics toolbox . Spat . Vis . 10 , 433 – 436 . Bromberg - Martin , E . S . , Matsumoto , M . , andHikosaka , O . ( 2010 ) . Dopamine in motivational control : rewarding , aversive , and alerting . Neuron 68 , 815 – 834 . Busemeyer , J . R . , andTownsend , J . T . ( 1993 ) . Decisionﬁeldtheory : adynamic - cognitive approach to decision making in an uncertain environment . Psychol . Rev . 100 , 432 – 459 . Cain , M . S . , Vul , E . , Clark , K . , and Mitroff , S . R . ( 2012 ) . A bayesian optimal foraging model of human visual search . Psychol . Sci . 23 , 1047 – 1054 . Calhoun , A . J . , and Hayden , B . Y . ( 2015 ) . The foraging brain . Curr . Opin . Behav . Sci . 5 , 24 – 31 . Charnov , E . L . ( 1976 ) . Optimal foraging , the marginal value theorem . Theor . Popul . Biol . 9 , 129 – 136 . Corbetta , M . , andShulman , G . L . ( 2002 ) . Controlofgoal - directedandstimulus - driven attention in the brain . Nat . Rev . Neurosci . 3 , 201 – 215 . Corbetta , M . , Patel , G . , and Shulman , G . L . ( 2008 ) . The reorienting system of the human brain : from environment to theory of mind . Neuron 58 , 306 – 324 . Cornelissen , F . W . , Peters , E . M . , and Palmer , J . ( 2002 ) . The Eyelink Toolbox : eye tracking with MATLAB and the Psychophysics Toolbox . Behav . Res . Methods Instrum . Comput . 34 , 613 – 617 . Dayan , P . , and Abbott , L . F . ( 2001 ) . Theoretical Neuroscience ( Cambridge , Massachusetts : MIT Press ) . Dean , H . L . , Crowley , J . C . , and Platt , M . L . ( 2004 ) . Visual and saccade - related activity in macaque posterior cingulate cortex . J . Neurophysiol . 92 , 3056 – 3068 . DeCasien , A . R . , Williams , S . A . , and Higham , J . P . ( 2017 ) . Primate brain size is predicted by diet but not sociality . Nat Ecol Evol 1 , 112 . Esber , G . R . , and Haselgrove , M . ( 2011 ) . Reconciling the inﬂuence of predic - tiveness and uncertainty on stimulus salience : a model of attention in associa - tive learning . Proc . Biol . Sci . 278 , 2553 – 2561 . Fox , G . ( 2001 ) . Failure - time analysis . In Design and Analysis of Ecological Experiments , S . M . Scheiner and J . Gurevitch , eds . ( Oxford University Press ) , pp . 235 – 266 . Freeman , R . ( 1968 ) . Charles Darwin on the routes of male humble bees . In Bulletin of the British Museum ( British Museum ) , pp . 177 – 189 . Genovesio , A . , Wise , S . P . , and Passingham , R . E . ( 2014 ) . Prefrontal - parietal function : from foraging to foresight . Trends Cogn . Sci . 18 , 72 – 81 . Gold , J . I . , and Shadlen , M . N . ( 2007 ) . The neural basis of decision making . Annu . Rev . Neurosci . 30 , 535 – 574 . Gottlieb , J . P . , Kusunoki , M . , and Goldberg , M . E . ( 1998 ) . The representation of visual salience in monkey parietal cortex . Nature 391 , 481 – 484 . Hamming , R . W . ( 1950 ) . Error detecting and error correcting codes . Bell Syst . Tech . J . 29 , 147 – 160 . Hayden , B . Y . , and Platt , M . L . ( 2010 ) . Neurons in anterior cingulate cortex multiplex information about reward and action . J . Neurosci . 30 , 3339 – 3346 . Hayden , B . Y . , Nair , A . C . , McCoy , A . N . , and Platt , M . L . ( 2008 ) . Posterior cingu - late cortex mediates outcome - contingent allocation of behavior . Neuron 60 , 19 – 25 . Hayden , B . Y . , Pearson , J . M . , andPlatt , M . L . ( 2011 ) . Neuronalbasisofsequen - tial foraging decisions in a patchy environment . Nat . Neurosci . 14 , 933 – 939 . Heilbronner , S . R . , andHaber , S . N . ( 2014 ) . Frontalcortical andsubcorticalpro - jections provide a basis for segmenting the cingulum bundle : implications for neuroimaging and psychiatric disorders . J . Neurosci . 34 , 10041 – 10054 . Heilbronner , S . R . , and Platt , M . L . ( 2013 ) . Causal evidence of performance monitoring by neurons in posterior cingulate cortex during learning . Neuron 80 , 1384 – 1391 . Heilbronner , S . R . , Hayden , B . Y . , and Platt , M . L . ( 2011 ) . Decision salience sig - nals in posterior cingulate cortex . Front . Neurosci . 5 , 55 . Hills , T . T . , and Pachur , T . ( 2012 ) . Dynamic search and working memory in so - cial recall . J . Exp . Psychol . Learn . Mem . Cogn . 38 , 218 – 228 . Hills , T . T . , Todd , P . M . , and Goldstone , R . L . ( 2008 ) . Search in external and in - ternal spaces : evidence for generalized cognitive search processes . Psychol . Sci . 19 , 802 – 808 . Hills , T . T . , Todd , P . M . , and Goldstone , R . L . ( 2010 ) . The central executive as a search process : priming exploration and exploitation across domains . J . Exp . Psychol . Gen . 139 , 590 – 609 . Hills , T . T . , Todd , P . M . , and Jones , M . N . ( 2015 ) . Foraging in semantic ﬁelds : how we search through memory . Top . Cogn . Sci . 7 , 513 – 534 . Houston , A . I . , and McNamara , J . M . ( 1999 ) . Models of Adaptive Behaviour : An Approach Based on State ( Cambridge University Press ) . Jepma , M . , andNieuwenhuis , S . ( 2011 ) . Pupildiameterpredictschangesinthe exploration - exploitation trade - off : evidence for the adaptive gain theory . J . Cogn . Neurosci . 23 , 1587 – 1596 . Kable , J . W . , and Glimcher , P . W . ( 2007 ) . The neural correlates of subjective value during intertemporal choice . Nat . Neurosci . 10 , 1625 – 1633 . Kacelnik , A . , Vasconcelos , M . , Monteiro , T . , and Aw , J . ( 2011 ) . Darwin’s ‘‘tug - of - war’’ vs . starlings’‘‘horse - racing’’ : how adaptations for sequential encoun - ters drive simultaneous choice . Behav . Ecol . Sociobiol . 65 , 547 – 558 . Kahnt , T . , and Tobler , P . N . ( 2013 ) . Salience signals intheright temporoparietal junction facilitate value - based decisions . J . Neurosci . 33 , 863 – 869 . Kahnt , T . , Park , S . Q . , Haynes , J . - D . , and Tobler , P . N . ( 2014 ) . Disentangling neural representations of value and salience in the human brain . Proc . Natl . Acad . Sci . USA 111 , 5000 – 5005 . Knutson , B . , and Bossaerts , P . ( 2007 ) . Neural antecedents of ﬁnancial deci - sions . J . Neurosci . 27 , 8174 – 8177 . Kobayashi , S . , Nomoto , K . , Watanabe , M . , Hikosaka , O . , Schultz , W . , and Sakagami , M . ( 2006 ) . Inﬂuencesofrewardingandaversiveoutcomesonactiv - ity in macaque lateral prefrontal cortex . Neuron 51 , 861 – 870 . Kolling , N . , Behrens , T . E . J . , Mars , R . B . , and Rushworth , M . F . S . ( 2012 ) . Neural mechanisms of foraging . Science 336 , 95 – 98 . Krajbich , I . , and Rangel , A . ( 2011 ) . Multialternative drift - diffusion model pre - dicts the relationship between visual ﬁxations and choice in value - based deci - sions . Proc . Natl . Acad . Sci . USA 108 , 13852 – 13857 . Litt , A . , Plassmann , H . , Shiv , B . , and Rangel , A . ( 2011 ) . Dissociating valuation and saliency signals during decision - making . Cereb . Cortex 21 , 95 – 102 . Mackintosh , N . J . ( 1975 ) . A theory of attention : variations in the associablity of stimuli with reinforcement . Psychol . Rev . 82 , 276 – 298 . McCoy , A . N . , and Platt , M . L . ( 2005 ) . Risk - sensitive neurons in macaque pos - terior cingulate cortex . Nat . Neurosci . 8 , 1220 – 1227 . McCoy , A . N . , Crowley , J . C . , Haghighian , G . , Dean , H . L . , andPlatt , M . L . ( 2003 ) . Saccade reward signals in posterior cingulate cortex . Neuron 40 , 1031 – 1040 . 346 Neuron 96 , 339 – 347 , October 11 , 2017 McGuire , J . T . , Nassar , M . R . , Gold , J . I . , and Kable , J . W . ( 2014 ) . Functionally dissociable inﬂuences on learning rate in a dynamic environment . Neuron 84 , 870 – 881 . Metcalfe , J . , and Jacobs , W . J . ( 2010 ) . People’s study time allocation and its relation to animal foraging . Behav . Processes 83 , 213 – 221 . Milton , K . ( 1988 ) . Foraging behaviour and the evolution of primate intelligence . In Machiavellian Intelligence : Social Expertise and the Evolution of Intellect in Monkeys , Apes , and Humans , A . W . R . W . Byrne , ed . ( New York : Clarendon Press / Oxford University Press ) , pp . 285 – 305 . Nassar , M . R . , Rumsey , K . M . , Wilson , R . C . , Parikh , K . , Heasly , B . , andGold , J . I . ( 2012 ) . Rational regulation of learning dynamics by pupil - linked arousal sys - tems . Nat . Neurosci . 15 , 1040 – 1046 . Newell , A . ( 1994 ) . Uniﬁed Theories of Cognition ( Harvard University Press ) . Ogawa , M . , van der Meer , M . A . , Esber , G . R . , Cerri , D . H . , Stalnaker , T . A . , and Schoenbaum , G . ( 2013 ) . Risk - responsive orbitofrontal neurons track acquired salience . Neuron 77 , 251 – 258 . Orquin , J . L . , and Mueller Loose , S . ( 2013 ) . Attention and choice : a review on eye movements in decision making . Acta Psychol . ( Amst . ) 144 , 190 – 206 . Payne , S . J . , and Duggan , G . B . ( 2011 ) . Giving up problem solving . Mem . Cognit . 39 , 902 – 913 . Payne , S . J . , Duggan , G . B . , andNeth , H . ( 2007 ) . Discretionarytaskinterleaving : heuristics for time allocation in cognitive foraging . J . Exp . Psychol . Gen . 136 , 370 – 388 . Pearce , J . M . , and Hall , G . ( 1980 ) . A model for Pavlovian learning : variations in the effectiveness of conditioned but not of unconditioned stimuli . Psychol . Rev . 87 , 532 – 552 . Pearson , J . M . , Hayden , B . Y . , Raghavachari , S . , and Platt , M . L . ( 2009 ) . Neuronsinposteriorcingulatecortexsignalexploratorydecisionsinadynamic multioption choice task . Curr . Biol . 19 , 1532 – 1537 . Pearson , J . M . , Heilbronner , S . R . , Barack , D . L . , Hayden , B . Y . , and Platt , M . L . ( 2011 ) . Posterior cingulate cortex : adapting behavior to a changing world . Trends Cogn . Sci . 15 , 143 – 151 . Pearson , J . M . , Watson , K . K . , and Platt , M . L . ( 2014 ) . Decisionmaking : theneu - roethological turn . Neuron 82 , 950 – 965 . Reynolds , J . H . , and Heeger , D . J . ( 2009 ) . The normalization model of attention . Neuron 61 , 168 – 185 . Sara , S . J . , andBouret , S . ( 2012 ) . Orientingandreorienting : thelocuscoeruleus mediates cognition through arousal . Neuron 76 , 130 – 141 . Shenhav , A . , Straccia , M . A . , Cohen , J . D . , and Botvinick , M . M . ( 2014 ) . Anterior cingulate engagement in a foraging context reﬂects choice difﬁculty , not foraging value . Nat . Neurosci . 17 , 1249 – 1254 . Simion , C . , and Shimojo , S . ( 2007 ) . Interruptingthecascade : orientingcontrib - utes to decision making even in the absence of visual stimulation . Percept . Psychophys . 69 , 591 – 595 . Stephens , D . W . ( 2008 ) . Decision ecology : foraging and the ecology of animal decision making . Cogn . Affect . Behav . Neurosci . 8 , 475 – 484 . Stephens , D . W . , and Krebs , J . R . ( 1986 ) . Foraging Theory ( Princeton , NJ : Princeton University Press ) . Summerﬁeld , C . , Behrens , T . E . , and Koechlin , E . ( 2011 ) . Perceptual classiﬁca - tion in a rapidly changing environment . Neuron 71 , 725 – 736 . Treisman , A . M . , and Gelade , G . ( 1980 ) . A feature - integration theory of atten - tion . Cognit . Psychol . 12 , 97 – 136 . Turrin , C . , Fagan , N . A . , Monte , O . D . , and Chang , S . W . C . ( 2017 ) . Social resource foraging is guided by the principles of the Marginal Value Theorem . Sci . Rep . 7 , 11274 . Wan , X . , Cheng , K . , and Tanaka , K . ( 2015 ) . Neural encoding of opposing strat - egy values in anterior and posterior cingulate cortex . Nat . Neurosci . 18 , 752 – 759 . Wilke , A . , Hutchinson , J . M . , Todd , P . M . , and Czienskowski , U . ( 2009 ) . Fishing for the right words : decision rules for human foraging behavior in internal search tasks . Cogn . Sci . 33 , 497 – 529 . Wolfe , J . M . ( 2013 ) . When is it time to move to the next raspberry bush ? Foraging rules in human visual search . J . Vis . 13 , 10 . Yu , A . J . , and Dayan , P . ( 2005 ) . Uncertainty , neuromodulation , and attention . Neuron 46 , 681 – 692 . Neuron 96 , 339 – 347 , October 11 , 2017 347 STAR + METHODS KEY RESOURCES TABLE CONTACT FOR REAGENT AND RESOURCE SHARING Further information and requests for resources and reagents should be directed to and will be fulﬁlled by the Lead Contact , David L . Barack ( dbarack @ gmail . com ) . EXPERIMENTAL MODEL AND SUBJECT DETAILS Two mature ( aged (cid:1) 6 - 9 years ) male rhesus macaques ( M . mulatta ) participated . Monkeys were single housed in cages in a colony room with other monkeys , allowing auditory and visual contact . Monkeys received daily enrichment and biannual health check - ups . As of the beginning of the ﬁrst task , one of the monkeys had been used on two previous experiments for both recording and inac - tivation in PCC ( ML ) and one was naive ( MR ) . After initial behavioral training , a head - restraint prosthesis ( titanium ; Crist Instruments ) and recording chamber ( acrylic ; Crist Instru - ments ) permitting access to PCC were implanted using standard aseptic surgical techniques . All surgeries were performed in accor - dance with protocols approved by the Duke University institutional animal care and use committee and were in accord with the Public Health Service Guide to the Care and Use of Laboratory Animals . Monkeys were anesthetized using isoﬂourane , received analgesics and antibiotics after surgery , and permitted a month to heal before any recordings were performed . METHOD DETAILS Two monkeys were trained on both tasks , ﬁrst the patch leaving task , followed by neural recordings , and then the traveling salesman task , followed by neural recordings . Neural recordings began once a stable pattern of behavior emerged , within two weeks of onset of training for both tasks . For the patch leaving task , we regarded behavior as stabilized when a signiﬁcant inﬂuence of travel time on total time in patch emerged ( cf . Houston and McNamara , 1999 ) . For the traveling salesman task , we regarded behavior as stable when monkeys exhibited the same pattern of choices ( a trapline ) over the course of ﬁve behavioral sessions . During training and recording , monkeys’ access to ﬂuid was controlled outside of experimental sessions . Custom software written in MATLAB ( MathWorks , Natick , MA , USA ) using Psychtoolbox ( Brainard , 1997 ) controlled stimulus presentation , reward delivery , and recorded all task and behavioral events . Horizontal and vertical eye traces were sampled at 1000 Hz by an infrared eye - moni - toring camera system ( SR Research , Osgoode , ON ) and recorded using the Eyelink toolbox ( Cornelissen et al . , 2002 ) . Solenoid valves controlled juice delivery . All data were analyzed using custom software written in MATLAB . Patch Leaving Task Behavioral Modeling This task simulates a patch - leaving problem by presenting the animal with a two - alternative forced choice decision between continuing to forage at a depleting resource and waiting to replenish the resource ( Hayden et al . , 2011 ; Figure 1A ) . To begin the trial , the animal ﬁxated ( ±0 . 5 (cid:4) ) on a centrally presented cross for a random ﬁxation time drawn from a uniform distribution ( 400 – 800 ms ) . If the animal prematurely shifted his gaze from the ﬁxation cross before exhausting this time , the ﬁxation clock resets to zero . If the animal exhausted the ﬁxation time , the ﬁxation cross was extinguished and the targets , a small blue rectangle and a large gray rect - angle , one each on the left and right side of the screen , were presented . The animal could make a choice by aligning gaze with a target and holding it there for 250 ms . The animal was free to peruse the options , glancing back and forth without penalty or registration of choice , so long as the choice ﬁxation period was not exhausted . If the monkey selected the blue rectangle , he was permitted to freely look about while the rectangle shrank at 65 pixels / s until it disappeared . This shrink time simulated the ‘handling time’ for the food item , and was constant across all trials and reward sizes . At the end of this handling time period , the animal received a squirt of juice , followed by a 1 s intertrial interval ( ITI ) and the reappear - ance of the ﬁxation cross . The reward size for the ﬁrst trial in patch was always (cid:1) 0 . 30 mL of juice . As the animal continued to select REAGENT or RESOURCE SOURCE IDENTIFIER Experimental Models : Organisms / Strains Rhesus macaque ( M . mulatta ) N / A NCBI Taxon : 9544 Software and Algorithms MATLAB MathWorks SCR : 001622 e1 Neuron 96 , 339 – 347 . e1 – e5 , October 11 , 2017 the blue rectangle ( ‘stay in patch’ decision ) , the amount of juice associated with that choice dropped each trial by (cid:1) 0 . 02 ± ε mL of juice ( where ε is a random term with mean = 0 . 002 mL and sd = 0 . 0001 mL ) . After a series of stay in patch decisions , the animal typi - cally decided to select the gray rectangle ( ‘leave patch’ decision ) . After selecting that option , the monkey was free to look about while the gray rectangle shrank also at 65 pixels / s . The height of the gray rectangle signaled the time - out penalty for leaving the patch ( the ‘travel time’ ) , and did not vary so long as the animal continued to stay in the patch . Once the monkey chose to leave , the gray bar shrank , which was followed by a 1 s ITI and the reappearance of the ﬁxation cross ; no juice was delivered for this choice . On the ﬁrst trial in the ‘new patch’ , three changes occurred . First , the juice reward associated with the blue rectangle was reset to its full amount , 0 . 30 mL . Second , the height of the gray bar was selected randomly from the distribution of 0 . 5 – 10 . 5 s . Third , the locations of the targets were switched . To avoid changes in behavior due to satiety , each session was limited to one hour . Behavioral data were analyzed with three foraging models using custom software in MATLAB . The three foraging models were constructed on the basis of the best - ﬁt distribution for cumulative reward intake . The foraging threshold was computed from the mean of the exponential gain function for foraging in a patch , which reﬂected the reward encounter rate . This exponential gain func - tion was computed from the experiment - deﬁned sequence of rewards and the experiment - deﬁned trial event times ( inter - trial inter - val = 1 s ; handling time = 0 . 4 s ; target acquisition ﬁxation time = 0 . 25 ms ; mean ﬁxation time = 0 . 6 s ; and time for reward delivery for each trial in patch ) and empirically measured response time means , which varied daily . We then modeled the reward gain function g ( t ) over all reward harvesting choices in a patch as an exponential survival curve g ð t Þ = 1 (cid:3) e (cid:3) l 0 T for ﬁt reward encounter rate l 0 and cumulative time in patch T using maximum likelihood estimation . In order to ﬁt this exponential , all rewards were normalized by the maximum possible net reward . Like other value - based decisions ( Busemeyer and Townsend , 1993 ; Krajbich and Rangel , 2011 ) , foraging decisions can be modeled as the integration of a decision variable to a threshold ( Kacelnik et al . , 2011 ; Calhoun and Hayden , 2015 ) . In our task , we considered two different approaches to model the decision threshold , one based on foraging theory ( Stephens and Krebs , 1986 ) and the other based on survival analysis ( Fox , 2001 ) using the mean of the maximum entropy distribution for encountered rewards , the exponential gain function . First we developed a foraging theory model inspired by the marginal value theorem ( MVT ; Charnov , 1976 ) . We computed the average reward rate from the Gamma - distributed patch residence times and exponential gain function ( Stephens and Krebs , 1986 ) : R ð b t Þ = l g ð b t Þ 1 + l b t for average reward rate R ð b t Þ , patch encounter rate l , estimated patch residence time b t , and reward gain function g ð b t Þ . Rate - maxi - mizing patch residence times b t were found using maximum likelihood estimation and the fmincon function in MATLAB . The MVT pre - dicts that advanced knowledge of a longer travel time to the next patch will increase the time spent foraging in the current patch , whereas knowledge of a shorter travel time will decrease foraging time ( Stephens and Krebs , 1986 ; Houston and McNamara , 1999 ) , as we conﬁrm in Figure 1 . We incorporated this inﬂuence of travel time by computing the threshold for each i th patch separately as though drawn from a set of patches with mean travel time t i = ( 1 / l ) ( Stephens and Krebs , 1986 ) . The decision variable for this model was the difference between net received reward and the MVT - computed optimal foraging threshold . For the optimal foraging model , the decision variable D V was equal to the reward rate computed from the rate maximizing foraging time b t minus the current within patch reward rate D V = R ð b t Þ (cid:3) R ð t Þ for optimal reward rate R ð b t Þ and actual current reward rate R ( t ) . Second , we developed a net foraging model based on the cyclical nature of patch - based foraging and the mean net reward har - vested from a patch . Patch foraging is characterized by a renewal cycle ( Houston and McNamara , 1999 ) : the animal makes an iter - ated series of decisions ( begin foraging in patch – stay in patch – stay in patch – stay in patch – leave patch – begin foraging in patch etc . ) . Each such cycle can be modeled as lasting a certain amount of time . These patch residence times are modeled as a survival process ( Fox , 2001 ) using the net reward harvested so far in a patch , computed with the exponential gain function above ( Houston and McNamara , 1999 ) . A leave threshold was calculated from the mean of the exponential gain function g ( t ) for rewards harvested from a patch . To capture the inﬂuence of travel time on time in patch , this threshold was modulated by an additive gain term computed from the Z scored travel time for each patch . For the net foraging model , the decision variable D V on trial t was the reward differential , deﬁned as the difference between net received reward and threshold net reward for leaving D V t = X t (cid:3) 1 i = 1 R i ! (cid:3) T j for trials in patch 1 through t – 1 , rewards R , and threshold T for patch with travel time j . Neuron 96 , 339 – 347 . e1 – e5 , October 11 , 2017 e2 Third , we developed a salience foraging model also based on the mean net reward harvested in a patch but that included a salience term . Salience plays a key role in attentional learning models ( Esber and Haselgrove , 2011 ) . In these models , the associability of a conditioned stimulus ( CS ) is the degree to which the CS can be associated with an unconditioned stimulus ( US ) ( Mackintosh , 1975 ; Pearce and Hall , 1980 ; Esber and Haselgrove , 2011 ) . This associability can be deﬁned in terms of its salience , the absolute value of the difference on the previous trial of the intensity of the US and the CS predicted strength ( Mackintosh , 1975 ; Pearce and Hall , 1980 ) . A similar sort of rule can be adopted for decision - making . The value of the current offer can be compared to a stan - dard , and the absolute value of the difference of the offer value from the standard represents the salience of the offer ( Heilbronner et al . , 2011 ) . The salience model computes the same decision variable as the net foraging model , but then multiplicatively scales this decision variable based on salience . Salience was deﬁned as the absolute value of the difference between net received reward and the mean net reward computed from the exponential distribution . Salience was multiplied by the value of the net offered reward minus the de - cision threshold and weighted by a coefﬁcient ﬁt to the choice data ( MLE ) . The decision variable D V for this model was the reward differential times the weighted salience D V t = b s (cid:2)(cid:2)(cid:2)(cid:2)(cid:2) X t (cid:3) 1 i = 1 R i ! (cid:3) T j (cid:2)(cid:2)(cid:2)(cid:2)(cid:2) X t (cid:3) 1 i = 1 R i ! (cid:3) T j ! for salience coefﬁcient b s and other variables as above . Despite containing more parameters , the salience foraging model was the best ﬁt model even after correcting for the number of parameters ( as reported in the results ) . In Figures 1C and 3C , we computed the probability of choosing to leave a patch for these foraging models using a sigmoidal choice function with a single decision variable . The observed choice behavior was ﬁt with the net foraging model , optimal foraging model , and the salience foraging model using the respective decision variables . For all three models , a standard sigmoidal choice function was used to calculate the probability of choosing the leave option : p L = e D V = s 1 + e D V = s for the probability of choosing the leave option p L , value difference D V as deﬁned for each model above , and constant s ﬁt using MLE . Both s and b s were simultaneously ﬁt using MLE for the salience foraging model . Traveling Salesman Task Behavioral Modeling In our traveling salesman task , monkeys foraged through a visual array of six targets by sequentially aligning gaze with them ( Fig - ure 3A ) . On every trial , one of six targets delivered a large reward ( (cid:1) 0 . 2 mL ) , one delivered a small reward half the size of the large one ( (cid:1) 0 . 1 mL ) , and the remaining four delivered no rewards . After aligning gaze ( ±0 . 5 (cid:4) ) with a ﬁxation cross for 500 – 1000 ms , the target array was presented . Monkeys selected a target by directing their gaze on to it and holding ﬁxation for 250 ms ( ±0 . 5 (cid:4) from edge of target ; targets were 60 pixels in width ) . While the locations of the targets were always the same , the identities of the rewarded tar - gets varied pseudo - randomly from trial to trial . Monkeys were free to choose the targets in any order , but they had to select every target before being allowed to advance to the next trial , mimicking traplining problems in natural foraging . After completing the array , a 1000 ms inter - trial interval was imposed , and then a new ﬁxation cross appeared on the screen . Our model - based analysis of behavior in the traveling salesman task computed cumulative rewards and reward rates . Cumulative rewards were equal to the total reward harvested during a trial , and cumulative reward rates divided that net reward by the cumulative elapsed time between choices . The total reward harvested at choice n within a trial was the sum of the rewards received from the previous choices 1 : n - 1 in that trial . The elapsed time at choice n was the sumof the choice ﬁxation times ( 250 ms ) for previous choices 1 : n - 1 and the variable response times of the monkey for all choices 1 : n . Response times were calculated from the end of saccade for the last decision to end of saccade for the current decision . For each day’s run , we determined the daily dominant pattern by assessing the similarity between every possible pair of trials on a given day by computing the pair’s Hamming score ( Hamming , 1950 ) . To compute the similarity between two trials , each trial’s pattern of choices by target number was ﬁrst coded as a digit string ( e . g . , 1 , 2 , 4 , 5 , 6 , 3 ) . The Hamming distance D i , i 0 between two strings i , i 0 of equal length is equal to the sum of the number of differences d between each entry in the string , D i ; i 0 = X n d ð x n ; y n Þ for strings x , y of length n . We computed D i , i’ for every pair of trials , and then , for each unique pattern of choices , computed the average Hamming distance D i ; i 0 . Larger D i , i’ correspond to strings with more differences . The daily dominant pattern corresponded to the pattern with the minimum D i ; i 0 . We analyzed the choices made in the traveling salesman task as decisions to continue on the trapline , as deﬁned by the daily domi - nant pattern , or to diverge from it . We made two adjustments to accommodate this analysis . First , we excluded trials where the mon - keys diverged at the very beginning of foraging , that is , trials where the ﬁrst choice diverged from the DDP , because this behavior was not inﬂuenced by the reward harvested over the course of the trial . Second , we ﬁt 30 different exponential gain functions , one for each e3 Neuron 96 , 339 – 347 . e1 – e5 , October 11 , 2017 possible sequence of experienced rewards during a trial ( not counting zeros as unique ) . To compute the different foraging thresholds for each choice in a trial , we used the mean lambda from the set of gain functions that were consistent with the sequence of rewards the monkey had experienced leading up to that choice number in the trial . We ﬁt the same set of models from the patch - leaving task analysis to the behavioral data from the traveling salesman task , and models were compared using the same method as well . QUANTIFICATION AND STATISTICAL ANALYSIS The outcomes of statistical tests are detailed in the Results , and included the use of Student’s t test , linear regression , ANCOVA to compare ramp - ups during the patch leaving task , and a generalized linear model ( GLM ) . Signiﬁcance was set at a = 0 . 05 , and multiple comparisons were always Bonferroni corrected . Results reported are mean ± standard error of the mean . For individual cell results , n was set to the number of patches ( patch leaving tasks ) or number of diverge and non - diverge trials ( traveling salesman task ) . For population results , n was the number of recorded cells . Behavioral models were compared using log - likelihoods . All zero probabilities were rectiﬁed to very small probabilities ( 1x10 (cid:3) 15 ) . We then took the sum of the logs of these probabilities for model comparison . Models were compared using the Akaike Information Criterion ( AIC ) ( Akaike , 1974 ) , a measure of goodness - of - ﬁt that penalizes models possessing more parameters . AIC is deﬁned as AIC = (cid:3) 2LL + 2k for the log - likelihood of the data given the model , LL , and the number of free parameters in the model , k . Neuronal ﬁring rates often show non - linearities ( Dayan and Abbott , 2001 ) , which can be captured using a GLM ( Aljadeff et al . , 2016 ) . All regressions on neuronal ﬁring rates were performed using a GLM with a log - linear link function , Poisson distributed noise , and dispersion estimated from the data , and all reported results utilized Bonferroni corrected p values . The use of this GLM effectively models neuronal responses as an exponential function of a linear combination of the input variables . GLMs were run using the glmﬁt function in MATLAB . Patch Leaving Task Neural Analysis Analysis of neural recordings focused on the whole trial epoch , a two - second - wide window ranging from one second before choice to one second after , and a patch exit epoch , from 15 s before the acquisition of the leave target to that acquisition time . Peri - stimulus time histograms ( PSTHs ) were computed to depict neuronal activity at the patch - level , corresponding to analyses time - locked to patch exits . For these patch - level PSTHs , data were aggregated into 50 ms bins and convolved with a Gaussian of mean 0 and stan - dard deviation 125 ms . Neuronal ﬁring rates were also modeled during the patch exit window , the last 15 s in a patch . The activity of each cell for each patch was retained , and the ﬁring rates were treated as a time series of binned spike counts in 50 ms bins . We ﬁrst regressed the mean ﬁring rate in each bin against time before patch exit . Next , we ran the same regression for each patch separately , regressing the binned ﬁring rates against time . We then correlated those regression slopes with the Z scored reward rates from the leave trials . A similar regression was performed for the population after normalizing the activity of each cell by subtracting the mean activity and then dividing by that mean . To investigate the dynamics of neuronal activity around the time of patch exit , these spike counts were regressed against reward rate , time before exiting the patch , salience , and all 2 - way and the 3 - way interactions . Due to vari - ability in the timing of task events and response times ( both ﬁxation acquisition and choice ) , all three covariates were decorrelated ( time X reward rate : mean R 2 = 0 . 14 ± 0 . 0079 ; time X salience : mean R 2 = 0 . 14 ± 0 . 011 ; reward rate X salience : mean R 2 = 0 . 30 ± 0 . 013 ) . To compare neural coding of salience in rich and poor foraging environments , whole trial epoch spike counts for those trials in the patch exit window were regressed against salience . Patches were ﬁrst sorted into poor ( reward rate Z score < 0 ) and rich ( Z score R 0 ) ones , and spike counts regressed separately for each . Patch reward rates were computed by summing the reward received in a patch and divided by the elapsed time in patch , though choosing an instantaneous reward rate , equal to the most recent reward before the current choice divided by the elapsed time since that reward , yielded similar ﬁndings . Traveling Salesman Task Neural Analysis We analyzed neuronal ﬁring rates during the traveling salesman task for two different epochs : ﬁrst , a 1000 ms epoch in 50 ms bins preceding either diverge or non - diverge decisions , to compare the two types of decision ; second , a time series of spike counts in 50 ms bins from the start of a trial up to the choice to diverge . For PSTHs , data were binned in 50 ms bins and convolved with a Gaussian of mean 0 and standard deviation of 75 ms . Divergent and non - divergent choices were analyzed as follows . Only choices corresponding to the ﬁrst divergent choice in a trial were counted as divergent . Furthermore , because we were interested in exploring the processes that resulted in diverging from a trapline while the trapline was being executed , divergent choices that occurred on the ﬁrst choice in a trial were excluded . Such trials begin with a divergence before reward rates or other returns were possible during a trial and hence cannot reﬂect the inﬂuence of those variables . Non - divergent choice neural activity was drawn from the ﬁfth choice on trials that matched the daily dominant pattern . The ﬁfth choice corresponds to the point in the trial where there are two targets left , as well as to the last point in the trial at which the monkey could still diverge . Neuron 96 , 339 – 347 . e1 – e5 , October 11 , 2017 e4 To compare diverge decisions to non - diverge decisions , the mean ﬁring rate in a 1 s epoch on every non - excluded trial preceding the decision was analyzed . The two groups were compared using a Student’s t test . We then split the diverge group into poor ( reward rate Z score < 0 ) and rich ( reward rate Z score R 0 ) environments , and compared the ﬁring rates during choices of each type to the ﬁring rate on non - diverge choices . To assess neural coding of diverge decisions across reward rates , we linearly regressed the mean ﬁring rate on diverge trials during this 1 s epoch against Z scored reward rate . A similar regression was performed for the population after normalizing the activity of each cell by subtracting the mean activity and then dividing by that mean . A GLM was used to determine the inﬂuence of salience on decisions to diverge . All the spikes from the onset of the trial up to the decision to diverge were sorted into 50 ms bins and then regressed against reward rate , time before divergence , salience , and all 2 - way and the 3 - way interactions . As with the patch leaving task , time , reward rate , and salience were decorrelated ( time X reward rate : R 2 = 0 . 063 ± 0 . 0048 ; time X salience : R 2 = 0 . 020 ± 0 . 0057 ; reward rate X salience : R 2 = 0 . 15 ± 0 . 0050 ) . Computed coefﬁcients from this regression for salience and for the interaction of reward rate and time were subsequently regressed against each other . 9 neurons for which fewer than 5 % of trials were diverge trials ( all from monkey L ) were excluded from this analysis . To examine differences in the strength of salience signaling for diverge trials in high and low reward rate contexts , spike counts from the whole choice epoch , from 250 ms before the end of a choice saccade to 500 ms after ( covering a 250 ms hold ﬁxation period to register a choice and a 250 ms post - choice period ) , were regressed against salience . Diverge trials were sorted into poor ( reward rate Z score < 0 ) and rich ( reward rate Z score R 0 ) environments , and spike counts regressed separately for each . The reward rate was calculated by summing the rewards over the whole trial and dividing by the elapsed trial time , though choosing an instantaneous reward rate , equal to the most recent reward divided by the elapsed time from receipt of that reward to the current choice , yielded similar ﬁndings . Two cells were excluded from this analysis because there were too few spikes on diverge choices yielding coefﬁ - cients in excess of 100 , both from monkey L . e5 Neuron 96 , 339 – 347 . e1 – e5 , October 11 , 2017