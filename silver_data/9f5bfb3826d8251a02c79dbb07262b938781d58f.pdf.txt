Designing and assessing a community - engaged digital enablement program : a Case Study Ben Stein ben . s . stein @ gmail . com University of Pittsburgh United States Jacob Biehl biehl @ pitt . edu University of Pittsburgh United States Rosta Farzan rfarzan @ pitt . edu University of Pittsburgh United States ABSTRACT Over the last decade , in acknowledgment of a growing chal - lenge of digital divide , researchers have been partnering with community organizations to explore community - engaged methods to empower under - served communities as they respond to new challenges in a digitally - dominated world . These community - engaged methods show great promise , en - abling localized interventions which honor the lived real - ity of participants , but their highly customized nature also presents new challenges in measurement and assessment for the research community . In this work , we present a case study of a 12 - session workshop series focused on digital en - ablement and describe challenges of applying traditional evaluation methods in understanding the value of the pro - gram . As a response to these challenges , we propose a frame - work for assessment of similar programs that enables us to better understand the ways in which our participants created digital capital and will support cross - study comparison and evaluation in future work . CCS CONCEPTS • Human - centered computing → Ethnographic studies ; • Gen - eral and reference → Design . KEYWORDS digital capital , community - collaborative research , informal educa - tion ACM Reference Format : Ben Stein , Jacob Biehl , and Rosta Farzan . 2023 . Designing and assessing a community - engaged digital enablement program : a Case Study . In The 11th International Conference on Communities and Technologies ( C & T ) ( C & T ’23 ) , May 29 – June 02 , 2023 , Lahti , Finland . ACM , New York , NY , USA , 12 pages . https : / / doi . org / 10 . 1145 / 3593743 . 3593764 1 INTRODUCTION Digitaltransformationisreshapingprocessesandexperiencesacrossamultitudeofsocietalactivities . Transitions were accelerated by the COVID - 19 pandemic , especially in the diverse end - user sectors Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , topostonserversortoredistributetolists , requirespriorspecificpermission and / or a fee . Request permissions from permissions @ acm . org . C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland © 2023 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 979 - 8 - 4007 - 0758 - 2 / 23 / 05 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3593743 . 3593764 of education , patient - facing medical services , and government so - cial services . These transitions have been creating long - lasting and far - reaching digital divides [ 6 , 8 , 13 , 27 , 32 ] . Opportunity gaps in online instruction further divides in academic preparedness and competition for a future of work that highly relies on technical skills [ 6 , 27 ] these divides further limit an already limited ‘digital capital’ in under - served communities— “‘a set of internalized abili - ties and aptitudes’ ( digital competencies ) as well as ‘externalized resources’ ( digital technology ) that can be historically accumulated and transferred from one arena to another” [ 36 ] . Many academic institutions , corporations , and community - based organizations have initiated programs and activities to build digital capital in under - served communities impacted by digital divides [ 38 , 41 ] . These efforts require conforming to the needs , cultural norms , and engagement practices of all involved stakeholders , mak - ing each program a unique effort . They necessitate a customized approach that prioritizes community needs over traditional aca - demic measurement . This in turn limits the ability for stakeholders to share insights , methods , and results that can be replicated and compared across initiatives . As noted by Cooper and colleagues , the academic community “has yet to establish a cohesive , system - atic understanding of the challenges , benefits and commitments of community - collaborative approaches to research . ” [ 10 ] Our work is situated within these tensions . This work is , in part , a case study examining a community - based 12 - session digital skills development program for high - school students in an under - served community . The program was executed by university faculty and graduate students , and members of several community - based organizations . We contribute programmatic insights into how stake - holders coordinated , collaborated , and iteratively reached common ground to design and conduct the program . The goals of these workshops are to understanding how researchers and community members can work together towards enabling community’s digital capital , beyond just developing digital skills among the participants . Towards that , our effort has a unique element of connecting youth skill development to the needs of the local small businesses in their community . Following the conclusion of the workshop , we iteratively devel - oped and employed methods to evaluate and assess the outcomes of the workshops . We describe methodological challenges encoun - tered in assessment of a program focusing on enablement rather than skill development . We argue that our practiced and proposed methods to measure and describe outcomes are deeply situated within the specific challenges of community engaged work . We believe these methods contribute to the development of assessment techniques that can be effectively replicated . More broadly , this 96 C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Stein et al . work aims to contribute pathways for the research community to engage in scholarship to build more equitable digital capital . 2 RELATED WORK Our work is situated at the intersection of a case study of a com - munity digital skill development program and methodological ap - proaches in evaluating such programs . In both dimensions of the work , we aim to prioritize the learning , engagement , and satisfac - tion of our youth participants . Thus , we draw from two primary areas of research . First , we review the opportunities and challenges associated with community - collaborative research , with emphasis on the obstacles to typical measurement in these arenas . Second , we consider findings from other practitioners seeking to conduct science - oriented education in informal settings to identify common challenges and adaptations which have arisen as a result . 2 . 1 Community - Collaborative Research Participatory design ( PD ) [ 40 ] has steadily gained academic atten - tion over the last 30 years as a method to design for , and alongside participants . It specifically engages with how designers of experi - ences can perform work in a way that is ethical , and sensitive to the context in which the designs will operate . PD has been conducted across a wide variety of disciplines , from healthcare [ 4 , 9 , 33 , 45 ] to architecture [ 28 ] , for users from the very young [ 12 , 23 ] to the very old [ 31 ] , and to empower education in both formal [ 2 , 24 , 30 ] and informal [ 7 , 17 , 42 ] environments . These methods often are utilized to yield more locally - effective designs and redistribute power tradi - tionally held by designers to those who will use the product of the design process . Review of participatory design literature reveals a common theme perhaps best described in Irani and colleagues’ seminal work : “It is not that PD works because of an inherent supe - riority to other methods . It works ( when it works ) because it takes advantage of cultural logics and practices particular to the location in which it emerged . ” [ 22 ] . Community - Collaborative Research ( CCR ) , and other highly in - terrelated approaches including community - based participatory research [ 44 ] , or participatory action research [ 1 ] can be thought of as an instantiation of PD in which research ( rather than de - sign ) is conducted in partnership with a specific community . With roots in Lewin’s “action research” [ 26 ] , CCR shares many power - distribution implications of PD , as it is principally concerned with equalizing power “ . . . by sharing ownership , responsibility , and decision - making” [ 39 ] . CCR moves the paradigm of PD outside of its historical origins in the workplace , resulting in dynamics of relationships , responsibility , and authority that are quite different than the ones typically confronted in PD [ 25 ] . The co - construction of the relationship , rapport , and trust be - tween researchers and community stakeholders is a methodological challenge in CCR . This may involve addressing differences in lan - guage , culture , race , ability , and other factors which , left unattended , can create power distance and impede trust between researchers and the communities . In their efforts to earn trust , researchers must take on a gamut of roles , from “friendly outsider” [ 10 , 47 ] to “confi - dant , advocate , interloper , invader , and collaborator” [ 25 ] . This trust has been found to be a critical component of the group dynamics that lead to successful long - term CCR partnerships [ 5 , 46 ] . Measurement also presents methodological challenges to CCR . As research shifts from being done “on” communities to “for , with , and by” them [ 11 ] , there has been an increasing need to re - examine how community - collaborative research is evaluated . This has re - sulted in a number of critical innovations , including the practice of defining and measuring success in collaboration with community stakeholders [ 3 , 29 ] . There is ample prior work which argues that , like design , evaluation must be sensitive to the context in which it is to be conducted . This includes adapting to dynamic community challenges and employing mechanisms to adapt in - situ [ 10 , 20 , 45 ] . These dynamic approaches complicate measurement when dis - seminating results depends on common , reproducible measurement techniques . A 2020 meta - analysis [ 29 ] notes that , despite dozens of measures appearing in recent literature , it is challenging for practitioners to identify the right ones for a given research context . They write that “ . . . it is important to highlight the inherent tension between a researcher - driven approach to selecting established and validated metrics and a community - driven process of developing and / or adopting metrics that may be more trusted , relevant , and useful in the local setting . ” These challenges around measurement in community - engaged scenarios appear in our own work and inform our proposed solution ( Section 5 ) . 2 . 2 Measurement in Informal Science Education Typical research evaluation requires traditional rigor and rigid control of the experimental environment in order to isolate effects and identify relationships or causal links . Learning increasingly takes place across a variety of formal and informal ( i . e . outside the formal classroom [ 18 ] ) venues . In informal science education ( ISE ) , such tight control can be disruptive to learning , impractical to establish , and potentially alienating to learners who engage in such experiences on a voluntary basis . Without the social constraints of the formal classroom , practitioners have been forced to adopt context - specific alternative methods of data collection and analysis “in the field” [ 15 , 16 , 19 , 21 ] . In addition to pedagogical and practical considerations , ISE prac - titioners acknowledge that evaluation can carry implicit assump - tions about the equity of participants that reproduce and reinforce undesirable power dynamics between dominant and non - dominant communities . Garibay and Teasdale [ 17 ] explore this in detail , not - ing that rigid conceptualizations of assessment can result in the silencing of voices in non - dominant communities , the projection of goals onto these communities that are not endorsed by them , and assessments that are not culturally valid . We sought to conduct a community - engaged informal educa - tion program over multiple visits and evaluate its effectiveness while seeking to evaluate it in a locally - sensitive but generally - interpretable way , confronting issues of power , research design , and rigor over the course of the study . 3 METHODOLOGY To explore a community - engaged approach to design and execute a program to support the creation of digital capital , we conducted a se - ries of workshops designed to teach youth participants foundational digital skills , including basic web development , website design , and social media management and analytics . The program consisted of 97 Designing and assessing a community - engaged digital enablement program : a Case Study C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland twelve 90 - minute sessions and ran from August through October 2021 . All participants enrolled at will and with parental consent . Approval was received by the University of Pittsburgh’s IRB . 3 . 1 Community Organization Partnership This research was conducted in Pittsburgh , PA , a mid - size city in the American Rust Belt . The project was executed as a partner - ship between the researchers from the University of Pittsburgh and Ozanam , Inc . 1 , , a non - profit community organization based in Pittsburgh’s Hill District . Ozanam serves neighborhood youth both after school and during the summer by offering educational pro - gramming , athletic training , academic support , and social events . They are “committed to making a difference the lives of the youth [ they ] serve . ” They contributed facilities where sessions were held , connections with local Black - owned business owners ( some of whom participated in program sessions as guest speakers ) , and met regularly with the university team to discuss the curriculum and workshop plans . 3 . 2 Program Design Prior to the start of the program , the researchers and representa - tives from the community partner organization ( collectively , the “project team” ) conducted meetings to discuss schedules , logistics , and learning objectives for the program . The broad intent of the partnership was to empower youth with knowledge of information and computing technologies ( ICTs ) and encourage and enable them to leverage this knowledge for the benefit of their communities . Thus , the project involved recruiting local youth to participate in an educational program aimed at ICTs and paid internships in local Black - owned businesses at the conclusion of the program . We also established that prior knowledge of computing technologies would not be assumed during the program and participants would not be expected to work outside of the sessions . 3 . 2 . 1 Assessing Community Needs . Ozanam facilitated introducing the researchers to the owners of four small Black - owned businesses local to their neighborhood . These businesses had expressed in - terest in receiving technical help from program participants . The researchers visited each business for 30 - 40 minutes , spent time with and interviewed the owners to understand the nature of their businesses , and discussed with their owner about their use of tech - nology in their daily routines . The issue of web and social media presence was most dominant during these discussions , as all the owners expressed their desire for improvement in this area . We observed that only one business had active social media accounts , and two of the owners mentioned a desire to drive traffic to their existing websites . We also noted that three of four businesses had used a website - building tool ( e . g . Wix 2 , GoDaddy 3 , and Wordpress 4 ) to develop their current websites without access to a web developer . Throughout these meetings and discussion , the project team identified support for both Web and Social Media presence as an important need for the these businesses . 1 https : / / www . ozanaminc . org / 2 https : / / www . wix . com / 3 https : / / www . godaddy . com / websites / website - builder 4 https : / / wordpress . com / website - builder / 3 . 3 Curriculum Given the identified community need , the project team discussed various potential learning objectives and agreed to focus the cur - riculum on social media and website - oriented skills to directly address the needs of the local businesses . Our intents with these learning objectives were both to provide opportunities for partici - pants to create and improve the social and technical components of their digital capital , particularly in direct connection to the needs voiced by the local businesses as an evidence of community digital enablement . The final curriculum was informed by our initial plan but it was dynamically designed as we responded to participants’ observed needs during the program and the feedback they provided through session reflection measures . Ultimately , participants were intro - duced to the basic concepts of a variety of digital skills , including website design and creation , the roles and syntax of HTML and CSS , requirements gathering , social media analytics , and usability testing . More specifically , we designed every session to include ( 1 ) technical skill development ( e . g . learning basics of HTML and CSS , setting up laptop and internet connections , or learning to use website development platforms ) ; ( 2 ) collaborative activities to develop connection among the participants ( e . g . creating a name and logo for our program , or providing feedback on each others’ websites ) ; ( 3 ) community - oriented discussions ( e . g . discussion on local business participants frequented , what are the issued within the community or school you care about , or how to support your favorite local business ) . A brief overview of the final curriculum appears in Table ? ? . 3 . 4 Participants Our participants were middle and high school students aged 13 - 17 . Participants were paid by the community partner organization for their participation . All participants were given a laptop by the uni - versity running Microsoft Windows 10 for use during the program . Participants who successfully completed the program were per - mitted to keep their laptops , while participants who did not were asked to return them . Participants who successfully completed the program were eligible for a paid internship in local businesses at its conclusion . 3 . 5 Data collection Over the course of the program , we collected both qualitative and quantitative data in order to understand participants’ experiences and engagement with the program . 3 . 5 . 1 Pre - session questions . Each session began with a small num - ber of questions ( typically two to three ) related to the technical learning goals of that session . The web - based survey tool Mentime - ter 5 was used to display questions and collect response data . All the responses were associated with a consistent anonymous ID composed of the participant’s initials and the day and month of their birth ( e . g . BF0815 ) . In the case of sessions focusing on foster - ing technical knowledge , these questions were used to determine participants’ prior knowledge about that technical concept . Other sessions covered more subjective ideas ( for example , how a website 5 https : / / www . mentimeter . com 98 C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Stein et al . might be best organized to provide information ) . Questions for these sessions did not assess knowledge but focused participants’ attention on the topic at hand , encourage reflection , and assess their prior understanding of the concepts . 3 . 5 . 2 Post - session questions . Sessions concluded with a similarly small number of reflection questions ( also administered via Men - timeter ) that prompted students to reflect on that day’s session and provide feedback . Sessions 1 - 9 used the same two questions for this purpose ( “Tell us ( at least ) two things you liked from the session today” and “Tell us ( at least ) two things you wish we could’ve spent more time on or that you think we could do better” ) . However , due to saturation of responses , we modulated these and occasion - ally presented additional questions as the program progressed . For example , in Session 7 , we asked participants directly about their motivations for their continued participation in the course . In Ses - sion 11 , we replaced these questions with a version more aimed at understanding learning success ( “What was most confusing part of what we learned about analytics today ? ” ) . 3 . 5 . 3 Entry and exit questionnaire . Participants present at the first and last sessions completed a 5 - point Likert - style questioionnaire that measured three constructs : comfort with and interest in in - formation technology skills [ 14 ] , technical knowledge [ 43 ] , and attachment to community [ 34 , 35 ] . Additionally , the entry ques - tionnaire asked about the participant’s demographics , family size , and the methods by which they most commonly communicate with friends . The exit questionnaire added a section designed to capture the participant’s reflections on the program , including satisfaction , memorable moments , social dynamics , and the extent to which the participant shared their experiences outside the program . The exit questionnaire repeated all knowledge - based questions which ap - peared in pre - session data collection activities ( described in Section 3 . 5 . 1 ) to capture participants’ learning progress . 3 . 5 . 4 Participant websites . As part of their participation in the program , each participant created a website . Participants were en - couraged to personalize their sites , focusing them on a topic about which they were passionate . Multiple sessions included time dedi - cated to development of the sites . Participants represented a variety of topics important to them in their personal sites , including a family recipe book or a repository of information about various “World’s Worst” destinations . Figure 1 presents one of the partici - pants’ website that was designed for a hypothetical T - shirt store with the goal to promote a message of peace through design and sales of clothing . At the conclusion of program , we downloaded a complete version of each site for qualitative analysis . 3 . 5 . 5 Artifacts created during class . In addition to the website arti - facts , some sessions involved activities in which participants wrote responses or drew sketches on paper . For example , in the second session , we asked participants to design and draw the homepage of a website about a topic that relevant to a problem in their neighbor - hood ( e . g . Figure ? ? - the initial sketch of Shirt For Peace website ) . In the fifth session , participants were asked to write down the name of a local business that was important to them and the reasons for this importance ( e . g . Figure ? ? ) . These artifacts were also collected for qualitative analysis . Figure 1 : A website co - developed by two participants and designed to sell t - shirts with anti - gun - violence messages . 4 ANALYSIS Community - based informal learning programs , such as the pro - gram described above , tend to ask what have become a very familiar series of questions : To what extent was our program engaging and empowering ? Did our participants attain the learning objectives we set for each session ? Did we create lasting change ? In our analysis , we reflect on two major challenges with this established assess - ment approach : ( 1 ) answering these questions can be challenging if we relied solely on traditional measurements , and ( 2 ) these ques - tions are often designed as research objectives by the researchers as opposed to participatory methods of assessment engaging the community partners . In Section 4 . 1 , we describe insights distilled using traditional descriptive approaches . In Section 4 . 2 , we iden - tify data sparsity as a key limitation of the utility of traditional approaches , elaborate on the specifics of the data missing , describe how it limits typical analysis , and explore the factors which caused it . In Section 5 , we propose a solution in the form of a flexible ana - lytical lens designed to accommodate the inevitably complex data that is common in ever - changing and complex community - driven participatory contexts . 4 . 1 Formal and Descriptive Analysis 4 . 1 . 1 Demographics and Attendance . We had a total of 15 unique participants who attended at least 2 sessions . Of these , 2 did not complete the entry demographic questionnaire . Of the remaining 13 , 6 were male and 7 were female . 4 participants were under the age of 15 , 3 were 15 , and 6 were older than 15 . All participants who responded to the question about ethnicity identified as “Black . ” Five participants indicated that they lived with a single parent and 6 lived with two parents . Five did not live with any siblings , and 6 had at least one sibling . Additional demographic information is available in Appendix ? ? . The entry questionnaire also asked participants about how they most commonly stayed in contact with their friends . Of the 11 who responded , 9 reported using phones , texting , or social media to stay 99 Designing and assessing a community - engaged digital enablement program : a Case Study C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland in touch , and 5 indicated that they communicated in person during social events ( e . g . basketball practice ) . 4 . 1 . 2 Entry and exit questionnaire instruments . Both questionnaires contained Likert - style questions designed to assess three constructs : self - reported comfort with and interest in ICT skills , self - reported technical knowledge , and attachment to community . Twelve partic - ipants completed the entry questionnaire , ten completed the exit questionnaire , and a total of seven completed both instruments . Given the nature of the data in terms of quantity and sparsity , we do not test or report on any statistical differences . In Figure ? ? , we present per - participant mean values for each construct as measured by the entry and exit questionnaires . As described in Section 3 . 5 . 3 , the exit questionnaire contained all eight knowledge - based pre - session questions from the program’s duration in order to assess participants’ knowledge growth . The median score across 10 participants was 3 out of 8 ( mean 3 . 4 ) . We also computed a per - participant change score which compared each participant’s change in score from the pre - session questions to the exit questionnaire ( i . e . describing the number of questions the par - ticipant answered incorrectly on a pre - session quiz and correctly in the exit questionnaire ) . The median per - participant change in score was 1 ( mean 0 . 4 ) . Overall , broad , conceptual questions ( e . g . the roles of HTML and CSS in rendering a webpage ) were answered correctly more often during the exit questionnaire . Questions about specific code syntax were answered incorrectly by most participants . 4 . 1 . 3 Post - program reflections . The exit questionnaire asked par - ticipants to reflect on their experiences and outcomes . Quantitative components were designed to measure satisfaction with the course and outcomes related to participation , while qualitative items asked participants to elaborate on program - related experiences that were particularly positive or negative . All questions are presented in the Appendix ? ? . Ten participants completed this instrument . The average of all five program satisfaction - related questions was 3 . 78 on a scale from 1 - 5 . Measures designed to capture social bonds formed between participants present a degree of social bonding happening as a result of participating in the workshops . Three of ten participants indicated that they had made a new friend as a result of participation , and nine indicated that they were more com - fortable with their co - participants than they were at the beginning . Two participants indicated that they know the names of most of the other participants . Measures for self - assessed efficacy were broadly positive . Eight participants indicated that they were more comfortable providing computer - related help to people around them , and nine indicated that they were more able to help with website - creation - related tasks than they were at the start of the program . Eight participants indicated that they felt able to assist local businesses ( both generally and with regard to specific businesses owned by community mem - bers who appeared as guest speakers during the program ) using the skills they had learned through program participation . When asked about their favorite skill developed during the pro - gram , variants of “learning to create a website” were dominant , with eight of ten participants naming the skill in response . When asked for reasoning , five cited the importance of the skill ( three specifically connected the skill to career goals ) . Participants were also asked if they had shared their experiences in the program with anyone outside of it , and if so , how they had felt while doing so . Five participants indicated that they had , with three of these indi - cating that they felt pride , a sense of accomplishment , and enjoying receiving approval from family members . We asked two questions related to particularly positive or nega - tive experiences during the program . No participant reported nega - tive experiences . When asked if anything had happened that had made them feel especially happy , eight participants responded af - firmatively . Of these , five gave additional detail : one described excitement about publishing their website , one indicated that they enjoyed sharing their site with the class and receiving praise , one enjoyed working with classmates , one enjoyed being able to choose the topic of their website , and the last described excitement about creating a website to attain their goal to address a social issue . 4 . 2 CCR Challenges and Data Sparsity As we described in Section 4 . 1 , we observed a number of positive outcomes as a result of the program . However , we also observed that the data presented in Section 4 . 1 may appear somewhat surface - level and lack the deep insights necessary to understand the op - portunities and challenges of the program with respect to our goal of digital empowerment and cultivation of digital capacity among our participants and their communities . In particular , we observed there were major challenges related to the community - collaborative approach to this research that led to a pattern of sparsity in the data we collected over the 12 sessions . This sparsity has an impact on both qualitative and quantita - tive methods and results . In qualitative research , typical collection methods tend to begin from the assumption that all participants engage in roughly the same activities and in - depth qualitative ob - servations are recorded for each participant from which to draw insights . Quantitative analysis methods leverage statistical tech - niques to compare observations and capture effects . In many cases , this structure works well , enabling clear and systemic observation to satisfy the assumptions of particular analysis methods and to understand the factors of interest and insights from the data . How - ever , we argue that this paradigm does not fit well in all contexts , particularly for small community - collaborative research projects . Below , we explore this argument across several dimensions . 4 . 2 . 1 Attendance . Similar to other informal learning programs , the youth who participated in our program did so in an extracurricular fashion , adding an additional responsibility on top of their formal education and other obligations , including gainful employment . Many of our participants were also student athletes who engaged in weekend sporting events . While we devoted multiple conversations with our community partners and participants to selecting an ideal meeting time and scheduled our sessions on Sunday mornings to avoid as many conflicts as possible , conflicts were inevitable . The net result of these dynamics was an effect on attendance . Over the course of the 12 sessions , we had a total of 18 unique participants . 9 participants attended at least 7 sessions , and 13 attended more than 4 . We chose not to strictly enforce attendance for continued partic - ipation and encouraged any level of participation that worked with their schedule and in cases allowing them to remotely participate . In all sessions , a few of the participants arrived late . To ensure 100 C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Stein et al . that pre - session data was not influenced by session content and discussion , we administered pre - session questions in the first 5 to 10 minutes of each session . When participants arrived after the ses - sion began , we chose not to ask them to complete the pre - session questions in order to allow them to participate with others in the ongoing activities and support their engagement with the session materials as much as possible . Similarly , we did not strictly enforce completing end - of - session questions before departing . While we followed best research practices in designing for con - sistent data collection and regular attendance , we also designed for supporting our participants throughout the program . We believe that this flexibility is essential in not discouraging youth continued participation and to communicate the priorities of the program as their learning and satisfaction as opposed to research data collection . For example , it may seem natural to address issues of attendance through stricter policies or explicit solicitation of punctuality from the participants . However , we made a deliberate decision to foster partial participation rather than attempt to enforce full participa - tion to maximize the benefit of the program to as many participants as possible . As a result , our data does not match typical research data and requires new methods of analysis due to the challenges we discuss in Section 4 . 2 . 4 . 2 . 2 Power and culture distance . We confronted the reality that there is significant cultural and power distance between ourselves as researchers and the youth who participated . The university re - searchers conducting these sessions included a middle - class White cisgender man in his thirties pursuing a graduate degree , a White cisgender female professor in her forties , and a White cisgender male professor in his forties . All of our youth participants identified as Black and were between the ages of 13 and 17 , and were all in middle or high school . In our case , differences in racial identity , age , educational attainment , and socioeconomic status make the inherent power dynamics of the research overt . As Harrington and colleagues point out , these dynamics can occur even between re - searchers and participants whose identities overlap [ 20 ] . To reduce this sense of power differences , we chose to not act as teachers and adults enforcing rules but as adults being there to help them learn what they are interested in learning and to build a program together . For example , we observed some participants using their mobile phones during early sessions , at the expense of their partici - pation in the day’s activities . Rather than insisting that participants ignore their phones for the duration of the 90 - minute class , we instead suggested a compromise in which the instructor gave par - ticipants a short “phone break” after every 15 minutes of instruction . Compromises like these are , in our view , essential for maximizing a sense of comfort and belonging to the learning space . In fact , as we evidence in Section 4 . 1 , all our participants indicated a strong sense of comfort during these sessions . However , the challenge of missing data is partially related to these decisions . 4 . 2 . 3 Dynamic iteration before and during the program . The collab - orative nature of the work also created challenges . Typical grant - supported research often has a timeline established reflecting ex - tensive preparation during the grant application process , time to fully define and fine - tune research activities and data collection . Commonly , these processes take place on a scale of months . In order to best serve our community partner and the youth , it was necessary to adhere to a much faster - pace and dynamic timeline defined by our community’s constraints . This required us to begin the educational programming mere weeks after funds were awarded to satisfy participants’ school schedule . Furthermore , we intentionally minimized constraints on participants recruitment in terms of age , or educational level and supported recruitment to be performed in parallel with the program design . This meant that , in some cases , we were planning activities and program structure for participants without yet knowing much about the participants ages , educational backgrounds , or interests and planning the data collection for an environment which we did not yet fully understand much less have full research control over . The net result of this approach had benefits and drawbacks . Its dynamic and reflexive nature maximized our chances of meeting the expectations of our community partner and of our participants , as we devoted repeated effort to increase engagement and produce positive outcomes . We argue that this benefit paid off in the form of the strong program satisfaction ( see Section 4 . 1 . 3 ) . However , this agile approach also impacted our ability to collect structured data , as we continued to update our curriculum , activities , and understanding of our participants in situ . Rigid control necessary for typical structured data collection would have significantly and negatively affected the program’s success , making it necessary to collect data where and when possible and to avoid fixation on uniform participation across all participants and activities . 5 DISCUSSION : A NEW LENS While qualitative research methods are often suitable and sufficient to draw insight from small numbers of participants , they still tend to rely on a density of data to find patterns and insights . The sparsity of data described above , created by unique challenges of responsive and dynamic community - engaged research , made a small sample size , functionally , even smaller . This tension points to the need for a sustainable model of analysis for non - conventional community programs , particularly those engaging marginalized communities . Traditional methods make assumptions about data richness , data collection techniques , planning time , environmental control , and curriculum rigidity that do not hold in all cases . Insisting on adher - ence to classical methods in such cases can result in the incomplete reporting of data , missed insights , and inappropriate interpretation . To best provide interventions that are localized , we must modu - larize our methods of analysis and embrace a flexible perspective that allows us to report any data we gather while still enabling comparison across studies through a shared framework . To address the challenges , we propose the G oals , A ttitudes , M otivations , and B ehaviors Le ns ( GAMBLe ) for analysis of com - munity engaged informal learning programs . The goal of the model is to enable multi - dimensional understanding of how participants engage in a short - term program while accommodating challenges in data collection , differences in the lived experiences of researchers and community participants , and the need for flexibility inherent to the delivery of such a program . Our proposed framework can server as a summative and forma - tive evaluation framework , as the components of the lens , described in Table 1 , serve three purposes : ( 1 ) they provide the foundation 101 Designing and assessing a community - engaged digital enablement program : a Case Study C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Component Description Example Goals Objectives conceptually related to the program content and influenced by the participant “I want to build a website . ” Attitudes opinions , values , or beliefs held by participants and ex - pressed either directly or indirectly through engagement in the program “My opinion is important because I could some - day make a difference in my community or school” Motivations Reasoning given by the participant to describe why they have a goal or attitude , or why they engage in a behavior “I want to help people who are struggling with issues of mental health . ” Behaviors Actions performed by the participant and recorded in data Un - prompted collaboration with a classmate Table 1 : Overview of the GAMBLe model coding strategy , enabling us to structure and understand the data we collected ; ( 2 ) they can translate to design recommendations for future practitioners who seek to develop community - driven STEM related informal programs , and ( 3 ) they guide and inform participants - driven data collection strategies for future studies with similar goals . We associate each component with specific meth - ods of data collection and sense - making , and these relationships can help to ensure that each component of participation is being adequately observed for analysis . 5 . 1 Definition of GAMBLe Components 5 . 1 . 1 Goals . We define the observations of the goal component as objectives declared by a participant related to the content of the program - in this case , digital skills and small businesses . In our case , we found that goals were most accessible when we directly inquired about them . For example , in the reflection questions admin - istered during the penultimate session , we asked participants what they wanted to do during the final session . Multiple participants expressed a desire to spend time working on their personal sites , which we classified as a goal . We also observed that our recurring end - of - session reflection questions allowed us to collect data on the goal component . For example , in response to questions of “Tell us ( at least ) two things you liked from the session today” and “Tell us ( at least ) two things you wish we could’ve spent more time on or that you think we could do better” ) : many students expressed a desire to learn more technical details in these questions , to spend more time working on their websites , or to have more interaction and collaboration with other participants during the sessions . 5 . 1 . 2 Attitudes . Attitudes are opinions , values , or beliefs held by participants that were expressed either directly or indirectly through engagement in the program . In our context , most attitudes we observed were fairly directly related to the domains explicitly en - gaged by the curriculum ( primarily technology and its relationship to small businesses ) . However , we were able to capture additional attitude through entry and exit survey questions which specifically prompted an opinion . For example , the measure we used to assess connection to local community contained questions asking about how the participant saw themselves in relationship to their local political environment ( e . g . “There are plenty of ways for young people like me to have a say in what our city government does . ” ) . We also observed expressions of attitude in the websites devel - oped by our participants over the course of the program . Examples of that include this sentence on one of the participant’s websites : “Webelievethatpoliceviolencecanbe preventedbybringingawareness to the issue and helping save lives . ” Other attitudes were expressed more implicitly . For example , one participant focused her website on her family’s recipes and included her grandmother’s recipes , possibly suggesting an interest in that portion of her family history . 5 . 1 . 3 Behaviors . We define behaviors as actions performed by a participant in connection with their participation in the program . They range from simple patterns in attendance , to level of class par - ticipation , to interactions with other participants . In our program , our primary avenues for the observation of behaviors were observ - ing participants in each workshop session and studying the artifacts they produced during sessions ; i . e . by reviewing the websites which participants created at regular intervals during the course of the program as well as identifying which participants invested time outside the classroom . We also reviewed their responses to in - class discussion prompts ( e . g . discussing how the learned skills might benefit local businesses , their contributions to an activity in which participants designed a team logo , etc . ) when identifying behaviors . We note that careful observation of unprompted behavior was especially useful . For example , while we presented the creation of a personalized website to our participants as an individual activity , two of our participants chose to collaborate heavily throughout the process , ultimately yielding one of the most fully - developed sites created during the program . Observation of this behavior can support us in understanding of the participants goals and motiva - tions as well as to inform design of future programs in terms of providing explicit opportunities for collaboration and to prompt participants who choose to collaborate to reflect on the process . 5 . 1 . 4 Motivations . The motivations component describes a par - ticipant’s reasons for pursuing a goal , holding an attitude , or en - gaging in a behavior ( as defined by the other model components ) . Under this definition , a motivation only appears in support of an observation of another component . For example , in week 7’s ses - sion reflection questions , we asked participants “What are some of the motivations that bring you back to class each week ? ” One participant responded “I want to create a website to stop hate crime and gun violence . ” Note that , under our proposed model , this state - ment allows us to observe both a goal and a motivation . The goal 102 C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Stein et al . is course - content related as described in Section 5 . 1 . 1 : " . . . to create a website . . . " The motivation for the goal is given by the rest of the sentence : “ . . . to stop hate crime and gun violence . ” We note that the line between goals and motivations can be difficult to distinguish and care must be applied when attempting to observe each component . While we observed multiple instances of motivations being related to goals , we did not prompt participants to disclose motivations related to behaviors or attitudes . 5 . 2 Application and Use of GAMBLe Having developed and defined GAMBLe , we applied it to our case study to gain new insights and to understands its utility . The first author compiled all data collected from program participants , in - cluding all administered measures , digitizations of artifacts created by the participants , and observations recorded during sessions into a central repository . We then applied each component of the lens in multiple iterations through each participant’s data until all meaning - ful observations were assigned to a lens component . We organized and visualized this labelled data using Miro 6 , a virtual collaboration application . Examples of such coding for two of the participants is presented in Figure 2 and 3 . This process yielded a summary of each participant’s data which grants a view into the nature of their engagement and participation in the program . Below , we explore three sample analyses grounded in the proposed GAMBLe model to demonstrate its usefulness in identifying themes , comparing and differentiating the experiences , and identifying insights . Figure 2 : Participant 13’s data , coded according the GAMBLe model . In this figure , each piece of data generated by the par - ticipant is represented by a dark gray rectangle with white text inside the bounds of the light gray box . Colored shapes outside the bounds of the box are coded observations based on the model . Each combination of color and shape repre - sents a component of the model ( e . g . Behaviors are coded with blue parallelograms ) . A high - resolution PDF of this fig - ure is available in the supplement to this document . 6 https : / / miro . com Figure 3 : Participant 9’s data , coded according the GAMBLe model . A high - resolution PDF of this figure is available in the supplement to this document . Figure 2 shows Participant 13 ( P13 ) ’s coded data . P13 was an active participant in the program , attending 9 of 12 sessions . Our model accommodates the variety of rich data that they generated and allowing us to identify themes which occur both in different GAMBLe components and across the longitude of their attendance . For example , we identified a strong theme in their data in which they voiced the Goal “create a website” and the Motivation “stop gun violence and hate crime” across multiple modalities of data collection . Their enthusiasm for the program was also apparent , as they were one of the few participants who exhibited the behavior “extracurricular participation” by reporting that they worked on the website outside of normal program meetings . When we apply the same lens to P9 ( Figure 3 ) , we see an inter - esting mixture of commonalities and differences . Both participants voiced a Goal related to creating a website . P13 spoke multiple times about “creating” a website , while P9 stated the goal in terms of “learning how to” create a website . However , while P13’s Moti - vation was related to a social cause , P9’s was more personal : they wanted to develop a skill for the purposes of a future business that they plan to one day have . Additionally , while both exhibited an Attitude that we described as “Technical interest” , P9’s was more specific . They mention enjoying learning about how to perform common web development tasks like changing the color of text and “learning different coding styles . ” In contrast , P13 mentioned enjoying the process of creating their website , but did not engage with specific learning goals on the same level as P9 . In this case , the model allows us to align participants with similar goals but tease apart their differing motivations . It also allows us to identify interests that they share but more closely observe how the interests were expressed differently . 103 Designing and assessing a community - engaged digital enablement program : a Case Study C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Using the same lens , we observe that Participant 3 differ from the previous two participants in that there is no evidence of a par - ticular goal related to the content of the course . They never voiced an objective like “ [ I want ] to learn how businesses operate” ( P5 ) or “I would be excited to help make [ the website of a guest speaker’s local business ] ” ( P8 ) . In this case , our decision to ask explicitly about participants’ motivation in Session 7 was especially fruitful . In response to the question “What are some of the motivations that bring you back to class each week ? ” , their reply was simple : “money and the computer . ” The difference between this extrinsic motiva - tion and the intrinsic motivation of the previous two participants allows us to better understand the breadth of engagement styles in our program in a way that would not have been obvious without specifically evaluating motivation . Indeed , this participant arguably created the most complete and advance website of all participants . The theme of the website reflected the same observation in terms of motivation and goal . The site was focused on a less social or personal matter and instead highlighted “the worst places in the world” . While these example applications of the lens are as individual as the participants who generated the underlying data , by reviewing complete codings for all participants , we are able to identify com - mon manifestations of each component and gain insight into the ultimate impact of the workshops . In terms of behaviors , we most commonly observed behaviors to learn more technical skills related to website development ( 7 participants ) , high level of investment in personal websites ( 5 participants ) , and enjoying or seeking out collaborative work with classmates ( 4 participants ) . Less common but interesting behaviors were participants who worked on their websites outside of normal session meetings ( 3 participants ) , elec - tive collaboration ( 2 participants ) , and sharing information from the program with individuals outside it ( 3 participants ) . In terms of attitudes , we observed a diverse set of attitudes , in - cluding high or increased belief in personal technical efficacy ( 8 participants ) , belief in the unique value and insight that youth can offer ( 6 participants ) , belief in the relevance of computing tech - nology to future endeavors ( 5 participants ) , and interest in the technical aspects of website creation beyond general knowledge ( 4 participants ) . The most common goal among our participants , by far , was to learn to make websites ( either a specific one , or websites in general ) with 7 participants expressing this intent on at least one occasion during the program . Motivations for this goal ( and for participation in the program in general ) , however , were more divided , with some participants citing value to a future career ( 4 participants ) , some indicating an intent to use the skill for a specific purpose ( e . g . addressing public health issues or societal problems ) ( 3 participants ) , and others citing reasons of self - expression ( 2 par - ticipants ) . Additionally , one participant cited the extrinsic rewards of the program - payment for participation and a computer - as motivation for continued attendance . 5 . 3 Value of GAMBLe In addition to the producing insights about our program’s value , we propose that GAMBLe has value for addressing the challenges we describe in Section 4 . 2 ; specifically support for assessment of infor - mal learning programs in a manner that is more consistent with the sharing of control necessary for ethical community - collaborative research , and for understanding how digital capital was ( and was not ) created by participants who engaged with the workshops . First , it addresses the challenges we identified by supporting sensemaking of qualitative data in dynamic environments inher - ent to community - engaged work , where participants , resources , needs , and agendas are always in flux . By dividing an individual’s participation into modular components with specific utilities , we are better able to make use of any moment of connection to the program , be it through verbal engagement in class , a long - term collaboration with a classmate , a note written on a worksheet , or an artifact created over many weeks . It does so by building a holistic description of each participant without insistence on comparing participants to one another , especially in cases where participants engaged through different avenues or in different amounts . Second , it attempts to realize a key goal in the evaluation of community - collaborative research : returning control of assessment to the engaged community rather than leaving it in the hands of researchers . As we noted in Section 4 , we often seek to evaluate community - collaborative research in order to understand questions of learning , of success , and of meaningful change . We align these , at a fundamental level , with what GAMBLe seeks to describe . Learning can be identified through changes in attitudes or behaviors . Success can be observed through the setting , pursuit , and achievement of goals . Meaningful change can be seen throughout , as the compo - nents capturing each participant’s engagement evolve over time . By creating opportunities for participants to tell us their goals and mo - tivations and to express their behaviors and attitudes broadly , we place control in the hands of each participant individually , allowing them final say - at a personal level - on what they believe and value in the program , what they wish to do as they participate , and why . Properly executed , this approach promotes a more personalized experience with increased agency for participants . It is our hope that such an approach will lead to greater engagement , more ethical research , and more fruitful collaboration . Finally , we argue that the components of GAMBLe allow us to observe , the different avenues our participants took toward creating their digital capital through engagement . We saw some participants prioritizing the practice of digital skills through the behavior of extracurricular work on their websites and the goal of learning at a more technical level how such sites are made . We saw others value the social support component of digital capital by express - ing the attitude of enjoying in - class collaboration . We also heard participants cite access to digital equipment as a key motivation for their participation . In our view , these are all valid and valuable steps toward the creation of digital capital as conceptualized by Ragnedda [ 37 ] , and they were each expressed through different components of GAMBLe . 6 IMPLICATIONS AND FUTURE WORK When refined by future discussions , replications , and debate within the community of researchers who work in this space , we believe that the GAMBLe schema will confer multiple benefits , including contributions to program design , data collection strategies , and the sharing of results . 104 C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Stein et al . 6 . 1 Implications for Digital Capital Programs As described in Section 5 . 2 , application of the lens enables us to better understand the nature of a participant’s engagement with the program while designing the program to focus as much as pos - sible on the needs of the participants rather than the researchers . It further provides us with insights to improve future programs by designing them with some of the goals , attitudes , motivations , and behaviors we observed . While we expect these to vary by partici - pant population , geographical location , culture , and other factors , we believe that iteration on the program supported by continu - ous application of the GAMBLe lens will improve it significantly , making it more engaging and accessible to a diverse population . Similar to many other forms of capital , development of digital capital is highly embedded in individuals’ and communities local context as it is the structure of social , community , and local network influence individuals access to tangible and intangible resources and ways to mobilize the accumulated capital . We argue that the GAMBLe’s nature as a flexible lens allows researchers to observe the localized ways that participants create digital capital through participation on their own terms . This , we assert , may form the foundation of new interventions that yield new paths to the acqui - sition of digital capital which are sensitive to the lived experiences of participants while supporting their growth . 6 . 2 Implications for Data Collection Methods In Section 5 . 1 , we describe methods by which we were able to observe each component of the GAMBLe model in our data . How - ever , it is important to note that we developed the model after data collection occurred . We propose that practitioners who find merit in the model should consider it when designing data collection procedures , offering opportunities for participants to express each component in order to best understand how they engage . We argue that the consideration of the model will make it possi - ble to incorporate collection measures that target a specific model component into the program activities . For example , designing ac - tivities to allow participants to express their attitudes or include discussions on what is important to them to reflect on goals and motivations . In the context of our study , we observed that the rel - atively unstructured and personal nature of the website creation task yielded insights into attitudes , motivations , and behaviors that might otherwise have been difficult to obtain with direct measure - ment and could be disruptive and cumbersome for the participants . Last , after complete coding of our data , we found that of the four model components , goals were observed with the least fidelity . All participants who articulated a goal indicated , in some fashion , the objective of learning to create websites . Besides this general goal , data for a participant did not reveal other clear goals for their par - ticipation in the course . Upon reflection , we suspect that this is due to the research team providing inadequate opportunities for partic - ipants to reflect on diverse set of personal goals for participation at a more granular level . Early in the program , we foregrounded the skill of website creation through activities and discussion of upcoming course material , and we believe that doing so before providing participants opportunities to tell us their own desires for the workshop towards digital enablement may have caused them to adopt a goal we prescribed rather than cultivate their own . This observation leads us to suggest that the collection of data for each component , including goals , be considered carefully and conducted with intention . Although it is valuable to understand what our participants value ( through their attitudes ) and want to ultimately accomplish ( through observation of their motivations ) it is the participant’s goals that most directly relate to curriculum planning , as these capture a participant’s direct desires for the result of learning and participation . In this case , inadequately understand - ing the goals of our participants may have limited our ability to provide in - class activities and learning objectives that aligned with their desires , impacting engagement ( and indirectly , the success of the program at fostering digital capital ) for some individuals . 6 . 3 A Framework for Community - Based Programs A significant portion of any shared model’s contribution is its role as a shared reference point in collaboration . It is our belief that , with refinement and discussion from the academic community ( and the participants who aid us in our work ) , the GAMBLe model will en - able sharing of results , techniques for data collection , and program design across boundaries of culture , geographical location , disci - pline , and more . We view the GAMBLe framework as one model within the ecology of informal learning assessment tools which also needs to be evaluated within this ecology . We urge interested readers to provide feedback , as it is our goal to develop a durable , flexible , and powerful model to support communication , collabora - tion , the sharing of findings , and the refinement of methods . We note that while general measures are of great value to re - searchers , they are significantly less so to the partners with whom we perform community - engaged research , and they must not be al - lowed to eclipse our responsibility to design for the contexts , goals , and people with whom we perform this work . We echo the senti - ment expressed by Luger and colleagues : “Although our goal is to point partnerships toward valid and reliable common measures that can be used across settings , we do not suggests that partnerships rely solely on these measures for evaluation purposes” [ 29 ] . 7 CONCLUSION In this work , we demonstrate a new assessment methodology pre - sented through the lens of a case study . In our case study , we con - ducted a short - term program designed to support the cultivation of digital capital in a local community through the teaching and prac - tice of digital skills , including website development , social media management , and web analytics . The challenges we encountered as a result of committing as fully as possible to community - engaged research led us to develop a new lens which supports the evaluation of similar programs and allows us to better understand how our participants chose their own paths to the creation of digital capital . ACKNOWLEDGMENTS This research was supported by the Richard King Mellon Foun - dation . We would like to thank our community partner , Ozanam , Inc , the owners of the local businesses in the Hill district neighbor - hood of Pittsburgh , as well as our workshop participants , for their partnership and for making this research happen . 105 Designing and assessing a community - engaged digital enablement program : a Case Study C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland REFERENCES [ 1 ] Fran Baum , Colin MacDougall , and Danielle Smith . 2006 . Participatory action research . Journal of epidemiology and community health 60 , 10 ( 2006 ) , 854 . [ 2 ] Claus Bossen , Christian Dindler , and Ole Sejer Iversen . 2010 . User gains and PD aims : assessment from a participatory design project . In Proceedings of the 11th Biennial Participatory Design Conference . 141 – 150 . [ 3 ] Tone Bratteteig and Ina Wagner . 2016 . What is a participatory design result ? . In Proceedings of the 14th Participatory Design Conference : Full papers - Volume 1 . 141 – 150 . [ 4 ] Kathryn L Braun , Tung T Nguyen , Sora Park Tanjasiri , Janis Campbell , Sue P Heiney , Heather M Brandt , Selina A Smith , Daniel S Blumenthal , Margaret Hargreaves , Kathryn Coe , et al . 2012 . Operationalization of community - based participatory research principles : assessment of the national cancer institute’s community network programs . American journal of public health 102 , 6 ( 2012 ) , 1195 – 1203 . [ 5 ] Barbara L Brush , Graciela Mentz , Megan Jensen , Brianna Jacobs , Kate M Say - lor , Zachary Rowe , Barbara A Israel , and Laurie Lachance . 2020 . Success in long - standing community - based participatory research ( CBPR ) partnerships : A scoping literature review . Health Education & Behavior 47 , 4 ( 2020 ) , 556 – 568 . [ 6 ] US Census Bureau . 2020 . Schooling During the COVID - 19 Pandemic . https : / / www . census . gov / library / stories / 2020 / 08 / schooling - during - the - covid - 19 - pandemic . html https : / / www . census . gov / library / stories / 2020 / 08 / schooling - during - the - covid - 19 - pandemic . html . [ 7 ] Luigina Ciolfi , Gabriela Avram , Laura Maye , Nick Dulake , Mark T . Marshall , Dick van Dijk , and Fiona McDermott . 2016 . Articulating Co - Design in Museums : Reflections on Two Participatory Processes . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work and Social Computing ( San Francisco , California , USA ) ( CSCW ’16 ) . Association for Computing Machinery , New York , NY , USA , 13 – 25 . https : / / doi . org / 10 . 1145 / 2818048 . 2819967 [ 8 ] Laura Cook and Danny Zschomler . 2020 . Child and family social work in the context of COVID - 19 : current practice issues and innovations : Research Briefing . Technical Report . Centre for Research on the Child and Family ( CRCF ) , Norwich . https : / / ueaeprints . uea . ac . uk / id / eprint / 75973 / [ 9 ] ChrisMCoombe , AmyJSchulz , LelloGuluma , AlexJAllenIII , CarolGray , Wilma Brakefield - Caldwell , J Ricardo Guzman , Toby C Lewis , Angela G Reyes , Zachary Rowe , et al . 2020 . Enhancing capacity of community – academic partnerships to achieve health equity : results from the CBPR partnership academy . Health promotion practice 21 , 4 ( 2020 ) , 552 – 563 . [ 10 ] Ned Cooper , Tiffanie Horne , Gillian R Hayes , Courtney Heldreth , Michal Lahav , Jess Holbrook , and Lauren Wilcox . 2022 . A Systematic Review and Thematic Analysis of Community - Collaborative Approaches to Computing Research . In CHI Conference on Human Factors in Computing Systems . ACM , New Orleans LA USA , 1 – 18 . https : / / doi . org / 10 . 1145 / 3491102 . 3517716 [ 11 ] Carl DiSalvo , Andrew Clement , and Volkmar Pipek . 2012 . Communities : Partici - patory Design for , with and by communities . In Routledge international handbook of participatory design . Routledge , 202 – 230 . [ 12 ] Allison Druin , Jerry A . Fails , and Mona Leigh Guha . 2014 . Including Children in Technology Design Processes : Techniques and Practices . In CHI ’14 Extended Ab - stracts on Human Factors in Computing Systems ( Toronto , Ontario , Canada ) ( CHI EA ’14 ) . Association for Computing Machinery , New York , NY , USA , 1021 – 1022 . https : / / doi . org / 10 . 1145 / 2559206 . 2567819 [ 13 ] ForresterResearch . 2020 . EnteringtheNewNormal : Fiveshiftswillchangebusiness and technology foreever . Technical Report . [ 14 ] Anna Victoria Forssen , Barbara M Moskal , and Alka R Harriger . 2011 . Measuring the impact of a high school intervention on students’ attitudes in information technology : Validation and use of an attitude survey . In 2011 ASEE Annual Con - ference & Exposition . 22 – 1053 . [ 15 ] Alice Fu , Archana Kannan , Richard Shavelson , Lisa Peterson , and Amy Kurpius . 2016 . Room for Rigor : Designs and Methods in Informal Science Education Evaluation . VisitorStudies 19 ( Jan . 2016 ) , 12 – 38 . https : / / doi . org / 10 . 1080 / 10645578 . 2016 . 1144025 [ 16 ] AliceC . Fu , ArchanaKannan , andRichardJ . Shavelson . 2019 . DirectandUnobtru - sive Measures of Informal STEM Education Outcomes : Direct and Unobtrusive Measures of Informal STEM Education Outcomes . New Directions for Evaluation 2019 , 161 ( March 2019 ) , 35 – 57 . https : / / doi . org / 10 . 1002 / ev . 20348 [ 17 ] CeciliaGaribayandRebeccaM . Teasdale . 2019 . EquityandEvaluationinInformal STEM Education : Equity and Evaluation in Informal STEM Education . New DirectionsforEvaluation 2019 , 161 ( March2019 ) , 87 – 106 . https : / / doi . org / 10 . 1002 / ev . 20352 [ 18 ] Brian L Gerber , Anne ML Cavallo , and Edmund A Marek . 2001 . Relationships among informal learning environments , teaching procedures and scientific rea - soning ability . International Journal of Science Education 23 , 5 ( 2001 ) , 535 – 549 . [ 19 ] AnnGrandandAnaMargaridaSardo . 2017 . WhatWorksintheField ? Evaluating Informal Science Events . Frontiers in Communication 2 ( 2017 ) . https : / / www . frontiersin . org / article / 10 . 3389 / fcomm . 2017 . 00022 [ 20 ] Christina Harrington , Sheena Erete , and Anne Marie Piper . 2019 . Deconstructing Community - Based Collaborative Design : Towards More Equitable Participatory Design Engagements . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( Nov . 2019 ) , 1 – 25 . https : / / doi . org / 10 . 1145 / 3359318 [ 21 ] Jennifer Idema and Patricia G . Patrick . 2019 . Experiential learning theory : identi - fying the impact of an Ocean Science Festival on family members and defining characteristics of successful activities . International Journal of Science Education , Part B 9 , 3 ( July 2019 ) , 214 – 232 . https : / / doi . org / 10 . 1080 / 21548455 . 2019 . 1614238 [ 22 ] Lilly Irani , Janet Vertesi , Paul Dourish , Kavita Philip , and Rebecca E Grinter . 2010 . Postcolonial computing : a lens on design and development . In Proceedings of the SIGCHI conference on human factors in computing systems . 1311 – 1320 . [ 23 ] Ole Sejer Iversen , Rachel Charlotte Smith , and Christian Dindler . 2017 . Child as Protagonist : Expanding the Role of Children in Participatory Design . In Pro - ceedings of the 2017 Conference on Interaction Design and Children ( Stanford , California , USA ) ( IDC ’17 ) . Association for Computing Machinery , New York , NY , USA , 27 – 37 . https : / / doi . org / 10 . 1145 / 3078072 . 3079725 [ 24 ] BethKolko , AlexisHope , BrookSattler , KateMacCorkle , andBehzodSirjani . 2012 . Hackademia : building functional rather than accredited engineers . In Proceedings of the 12th Participatory Design Conference : Research Papers - Volume 1 . 129 – 138 . [ 25 ] Christopher A . Le Dantec and Sarah Fox . 2015 . Strangers at the Gate : Gaining Access , Building Rapport , and Co - Constructing Community - Based Research . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing . ACM , Vancouver BC Canada , 1348 – 1358 . https : / / doi . org / 10 . 1145 / 2675133 . 2675147 [ 26 ] Kurt Lewin et al . 1946 . Action research and minority problems . Journal of social issues 2 , 4 ( 1946 ) , 34 – 46 . [ 27 ] Mark Lieberman . 2020 . A Third of K - 12 Students Aren’t Adequately Connected for Remote Learning , Report Says . Education Week ( June 2020 ) . https : / / www . edweek . org / technology / a - third - of - k - 12 - students - arent - adequately - connected - for - remote - learning - report - says / 2020 / 06 [ 28 ] Rachael Luck . 2018 . Participatory design in architectural practice : Changing practices in future making in uncertain times . Design Studies 59 ( 2018 ) , 139 – 157 . [ 29 ] Tana M . Luger , Alison B . Hamilton , and Gala True . 2020 . Measuring Community - Engaged Research Contexts , Processes , and Outcomes : A Mapping Review . The MilbankQuarterly 98 , 2 ( 2020 ) , 493 – 553 . https : / / doi . org / 10 . 1111 / 1468 - 0009 . 12458 _ eprint : https : / / onlinelibrary . wiley . com / doi / pdf / 10 . 1111 / 1468 - 0009 . 12458 . [ 30 ] Mark Lynch , Edward P Zovinka , Lening Zhang , Jenna L Hruska , and Angela Lee . 2005 . Rural Outreach Chemistry for Kids ( ROCK ) : The program and its evaluation . Journal of Higher Education Outreach and Engagement 10 , 3 ( 2005 ) , 125 – 141 . [ 31 ] Sebastian Merkel and Alexander Kucharski . 2019 . Participatory design in geron - technology : A systematic literature review . The Gerontologist 59 , 1 ( 2019 ) , e16 – e25 . [ 32 ] Faye Mishna , Elizabeth Milne , Marion Bogo , and Luana F . Pereira . 2020 . Re - sponding to COVID - 19 : New Trends in Social Workers’ Use of Information and Communication Technology . Clinical Social Work Journal ( Nov . 2020 ) . https : / / doi . org / 10 . 1007 / s10615 - 020 - 00780 - x [ 33 ] Elsa M Orellano - Colón , Yolanda González - Laboy , and Amarelis De Jesús Rosario . 2017 . Creation of the Quebrada Arriba Community and Academic Partnership : An effective coalition for addressing health disparities in older Puerto Ricans . Puerto Rico health sciences journal 36 , 2 ( 2017 ) , 107 . [ 34 ] Emily J Ozer and Marieka Schotland . 2011 . Psychological empowerment among urban youth : Measure development and relationship to psychosocial functioning . Health Education & Behavior 38 , 4 ( 2011 ) , 348 – 356 . [ 35 ] N Andrew Peterson , Christina Hamme Peterson , Lynn Agre , Brian D Christens , and Cory Michael Morton . 2011 . Measuring youth empowerment : Validation of a sociopolitical control scale for youth in an urban community context . Journal of Community Psychology 39 , 5 ( 2011 ) , 592 – 605 . [ 36 ] Massimo Ragnedda . 2018 . Conceptualizing digital capital . Telematics and Infor - matics 35 , 8 ( 2018 ) , 2366 – 2375 . [ 37 ] Massimo Ragnedda and Maria Laura Ruiu . 2020 . Digital capital : A Bourdieusian perspective on the digital divide . Emerald Group Publishing . [ 38 ] Elisabeth Roberts , David Beel , Lorna Philip , and Leanne Townsend . 2017 . Rural resilience in a digital society . , 355 – 359 pages . [ 39 ] CarolynLeungRubin , NathanAllukian , XingyueWang , SujataGhosh , Chien - Chi Huang , Jacy Wang , Doug Brugge , John B Wong , Shirley Mark , Sherry Dong , et al . 2014 . “We make the path by walking it” : building an academic community partnership with Boston Chinatown . Progress in community health partnerships : research , education , and action 8 , 3 ( 2014 ) , 353 . [ 40 ] Douglas Schuler and Aki Namioka . 1993 . Participatory design : Principles and practices . CRC Press . [ 41 ] Lisa J Servon and Marla K Nelson . 2001 . Community technology centers : Nar - rowing the digital divide in low - income , urban communities . Journal of urban affairs 23 , 3 - 4 ( 2001 ) , 279 – 290 . [ 42 ] GustavTaxén . 2004 . IntroducingParticipatoryDesigninMuseums . In Proceedings of the Eighth Conference on Participatory Design : Artful Integration : Interweaving Media , Materials and Practices - Volume 1 ( Toronto , Ontario , Canada ) ( PDC 04 ) . Association for Computing Machinery , New York , NY , USA , 204 – 213 . https : / / doi . org / 10 . 1145 / 1011870 . 1011894 106 C & T ’23 , May 29 – June 02 , 2023 , Lahti , Finland Stein et al . [ 43 ] Alexander JAM Van Deursen , Ellen J Helsper , and Rebecca Eynon . 2016 . Develop - mentandvalidationoftheInternetSkillsScale ( ISS ) . Information , Communication & Society 19 , 6 ( 2016 ) , 804 – 823 . [ 44 ] Meera Viswanathan , Alice Ammerman , Eugenia Eng , Gerald Garlehner , Kath - leen N Lohr , Derek Griffith , Scott Rhodes , Carmen Samuel - Hodge , Siobhan Maty , Linda Lux , et al . 2004 . Community - based participatory research : Assessing the evidence : Summary . AHRQ evidence report summaries ( 2004 ) . [ 45 ] Nina Wallerstein . 1999 . Power between evaluator and community : research relationships within New Mexico’s healthier communities . Social Science & Medicine 49 , 1 ( July 1999 ) , 39 – 53 . https : / / doi . org / 10 . 1016 / S0277 - 9536 ( 99 ) 00073 - 8 [ 46 ] Nina Wallerstein , John Oetzel , Bonnie Duran , Greg Tafoya , Lorenda Belone , and Rebecca Rae . 2008 . What predicts outcomes in CBPR . Community - based participatory research for health : From process to outcomes 2 ( 2008 ) , 371 – 92 . [ 47 ] Marisol Wong - Villacres , Aakash Gautam , Deborah Tatar , and Betsy DiSalvo . 2021 . Reflections on Assets - Based Design : A Journey Towards A Collective of Assets - Based Thinkers . Proceedings of the ACM on Human - Computer Interaction 5 , CSCW2 ( Oct . 2021 ) , 1 – 32 . https : / / doi . org / 10 . 1145 / 3479545 107