INTRODUCTION For nearly 30 years , the study of how human judgment deviates from normative theories of decision making ( i . e . , the study of “human judg - ment bias” ) was one of the most heavily re - searched and widely cited areas in psychology ( e . g . , Hogarth , 1987 ; Kahneman , Slovic , & Tversky , 1982 ; Nisbett & Ross , 1980 ) . This re - search indicates that humans handle complex situations by simplifying and by applying a limit - ed set of heuristics , or rules of thumb , that only approximate the kinds of information and processes specified by normative theories . Al - though this research indicated that these approximations were often adequate and greatly increased our capacity to process large quantities of ambiguous information , their use sometimes led to significant and systematic deviations from the prescripts of normative theories . Recently , however , a number of decision - making researchers , particularly those working in more applied areas such as training and decision support , have voiced a concern about the generality of this research . Speciﬁcally , they claim that demonstrations of human judgment bias have involved conditions that are too ster - ile and too contrived to generalize to real world situations ( Cannon - Bowers , Salas , & Pruitt , 1996 ) . Rather , they argue , if the results are to be applied with any conﬁdence , what is needed is the study of decision making under more realistic conditions , i . e . , the study of naturalis - tic decision making ( NDM ) . Interest in NDM has increased , as indicated by the publication of two books ( Klein , Orasanu , Calderwood , & Zsambok , 1993 ; Zsambok & Klein , 1997 ) and a special issue of Human Factors , “Decision Making in Complex Environments” ( Salas & Cannon - Bowers , 1996 ) , devoted to this topic . Some studies in more naturalistic contexts have yielded results similar to those from clas - sical decision - making research . Ashton and Ashton ( 1988 ; 1990 ) , for example , found that Information Order and Outcome Framing : An Assessment of Judgment Bias in a Naturalistic Decision - Making Context Bruce M . Perrin , Barbara J . Barnett , and Larry Walrath , The Boeing Company , St . Louis , Missouri , and Jeffrey D . Grossman , Space and Naval Warfare Systems Center , San Diego , California Findings that decision makers can come to different conclusions depending on the order in which they receive information have been termed the “information order bias . ” When trained , experienced individuals exhibit similar behaviors ; however , it has been argued that this result is not a bias , but rather , a pattern - matching process . This study provides a critical examination of this claim . It also assesses both experts’ susceptibility to an outcome framing bias and the effects of varying task loads on judgment . Using a simulation of state - of - the - art ship defen - sive systems operated by experienced , active - duty U . S . Navy officers , we found no evidence of a framing bias , while task load had a minor , but systematic effect . The order in which information was received had a signiﬁcant impact , with the effect being consistent with a judgment bias . Nonetheless , we note that pattern - matching processes , similar to those that produce inferential and reconstructive effects on memory , could also explain our results . Actual or potential applications of this research include decision support system interfaces or training programs that might be developed to reduce judgment bias . Address correspondence to Bruce Perrin , The Boeing Company , Mailcode : S034 - 3065 , P . O . Box 516 , St . Louis , MO 63166 - 0516 ; bruce . m . perrin @ boeing . com . HUMAN FACTORS , Vol . 43 , No . 2 , Summer 2001 , pp . 227 – 238 . Copyright © 2001 , Human Factors and Ergonomics Society . All rights reserved . at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from 228 Summer 2001 – Human Factors professional auditors were more inﬂuenced by negative than by positive information and were affected by how they received information , all at once or one piece at a time . Similarly , Adel - man , Tolcott , and Bresnick ( 1993 ) found that information presented all at once had a differ - ent effect on U . S . Army air defense operators’ judgments than did the same information pre - sented over a period of time . When conﬂicting information was presented over time , that study found that the operators were more heavily affected by evidence introduced later ( i . e . , a recency effect ) . Entin and his colleagues ( Entin , 1992 ; Entin , Serfaty , & Forester , 1989 ) also found a recency effect in the judgments of mil - itary intelligence analysts when evidence was presented over time and was conﬂicting . On the other hand , when evidence was ambiguous , but essentially neutral , Tolcott , Marvin , and Lehner ( 1989 ) revealed that Army intelligence analysts showed a primacy effect . Their participants perceived that their initial hypotheses were strengthened by this neutral information . Additionally , their participants showed a confirmation bias , overemphasizing information consistent with their initial hypothe - ses , while discounting information inconsistent with it . Consistent with the NDM argument , how - ever , the observed effects in these studies were often not large . Ashton and Ashton ( 1990 ) , for example , noted that their “effects do not always reach conventional statistical significance lev - els” ( p . 15 ) . Likewise , Adelman et al . ( 1993 ) reported that their order effects explained less than 10 % of the variance in probability esti - mates . Results from these studies also suggest that the ﬁndings may be more characteristic of less experienced participants . Tolcott et al . ( 1989 ) , for example , found a trend for over - conﬁdence to increase as experience decreased . Similarly , Adelman et al . ( 1993 ) found that the observed order effects were less pronounced in ofﬁcers than enlisted men . Finally , the tasks used in these studies were only rough approximations of their partici - pants’ true jobs . All of the studies used paper - and - pencil versions of the task . In some cases , information was given as a probability , and often the evidence was contained in short writ - ten statements or involved only simple events occurring in isolation . In short , one is left with the impression that if the experimental situa - tion had been closer to the actual task , and experienced personnel had been given the information and tools they routinely used , per - haps no evidence of judgment bias would have been found . Indeed , Adelman et al . ( 1993 ) argued that their “case would be considerably stronger . . . if the results were obtained using actual air defense simulators” ( p . 367 ) . Subsequently , Adelman and his colleagues ( Adelman , Bresnick , Black , Marvin , & Sak , 1996 ) conducted the same study using air defense simulators . The effect of information order , rather than being removed , however , was strengthened , with significant differences that were as much as ﬁve - fold among the treat - ment groups . Although such a result seems to be strong evidence that judgment bias can occur in more naturalistic decision contexts , the authors argued that perhaps the same evi - dence , when presented in different orders , might indicate different conclusions . In other words , the experts’ decisions were the result of a pattern - matching process , in which a pattern is based on both the sequence and the content of the information . A key difference between this pattern - matching explanation and an information order bias is whether inconsistent information is handled by reinterpreting it or by discounting it . The pattern - matching hypothesis specifies that earlier information is reinterpreted in light of the latter information , so that all evidence is taken into account in the final judgment . An information order bias , on the other hand , results from discounting or undervaluing inconsistent information . Unfortunately , data on whether participants’ discounted or reinter - preted inconsistent evidence are not available in the Adelman et al . ( 1996 ) study . In the current study , we sought to replicate the information order effect in a more natural - istic decision context , similar to that used in the Adelman et al . ( 1996 ) study . To distinguish between an information order bias , which pre - dicts a discounting of inconsistent evidence , and the pattern - matching hypothesis , which does not , we collected data on the evidence used and the weight decision makers gave to it . Six pieces of information , three supporting each of at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from two possible conclusions , were used in our treat - ments , while all other information was held as close to neutral as possible . If the inconsistent evidence tended to be under - represented and undervalued in the ﬁnal judgment , an informa - tion order bias would be indicated . On the other hand , if nominally inconsistent informa - tion tended to be reinterpreted , and both this evidence and conﬁrming information are cited with relatively equal frequency , a pattern - matching process would be implied . We also assessed the possible effects of the decision frame of reference . Outcomes are generally perceived as positive or negative rela - tive to a neutral reference , so that varying the frame of reference can affect whether a given outcome is perceived to be a gain or a loss . Because the value function for losses is gener - ally found to be steeper than that for gains ( that is , losses loom larger than equivalent gains ) , shifts in reference can change the value attached to particular outcomes . The frame of reference for outcomes has been demonstrated to have substantial effects on evaluating deci - sion options in academic studies ( e . g . , Tversky & Kahneman , 1981 ) . Additionally , we manipulated the task load under which these judgment tasks were to occur . Studies of judgment bias in academic settings apparently do not require any substan - tial task loading for positive demonstrations . In fact , problems in these settings generally have involved no task load beyond the necessi - ty of making a decision in an unfamiliar area . Research has suggested , however , that increased task loads may increase judgment bias . Knapp and Tolbert ( 1985 ) , for example , have postu - lated an increased reliance on heuristics under conditions of high task load , with a resulting decline in the optimality of performance . For example , using the imposition of time limits on task performance , Sheridan ( 1981 ) demon - strated a narrowing attention , resulting in the tendency to treat all data sources as if they were equally reliable . For the current study , we used a domain similar to that used in the Adelman et al . ( 1996 ) research . U . S . Navy Tactical Action Ofﬁcers ( TAOs ) are responsible for identifying and determining the intent of unidentiﬁed air - craft that could possibly pose a threat to their ships . Using a simulation of the latest decision support system , we had active - duty U . S . Navy ofﬁcers assess the type ( military or civil ) and the intent ( hostile or friendly ) of unknown aircraft . The simulation used familiar displays and included the decision support features to which the participants were accustomed ( e . g . , the aircraft’s speed , altitude , and distance from the ship , as well as information about the sur - rounding area such as shorelines and traffic lanes used by commercial aircraft ) . Additional information on the aircraft was provided through a verbal communications network . The content of these messages was also typical of actual reports ( i . e . , they supported a classiﬁca - tion or a particular intent , but were seldom conclusive ) . Finally , there were numerous air - craft to observe and multiple reports on each to evaluate and integrate . Overall , we provided a reasonably naturalistic environment in which the effects of information order and outcome frame could be tested under conditions of varying task loads . METHOD Participants Participants for the study were 16 active - duty U . S . Navy personnel . We surveyed our participants on relevant qualifications , which included experience in the Persian Gulf and in combat . On average , they had over 10 years of experience in the Navy and nearly two years ( 20 . 9 months ) of active duty as a TAO . All of them had exposure to other responsibilities in a ship’s Combat Information Center ( CIC ) , and most had also worked as part of a ship’s anti - air warfare team in a role other than that of TAO . This level of training and experience is comparable to that reported by Adelman et al . ( 1996 ) , whose participants had averaged 1 . 9 years of experience in their respective jobs . Procedure Data collection was carried out at the Naval Command , Control , and Ocean Surveillance Center , Research , Development , Test , and Evaluation Division simulation facility in San Diego , California , and on the simulation sys - tem installed at the Boeing Company in St . Louis , Missouri . In these facilities , we had the B IAS IN N ATURALISTIC D ECISION M AKING 229 at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from 230 Summer 2001 – Human Factors ability to collect data from as many as ﬁve par - ticipants simultaneously . Each person per - formed the task independently ; there was no interaction among the individuals during the scenarios . Each experimental session contained the following three phases . Familiarization . During this phase , the objectives of the experiment were described to the participants , as were the support materials , response forms , and the simulation . The ex - periment was described as a study of the in - formation TAOs use to evaluate unidentified aircraft . All of the judgments required of the par - ticipants were described , and examples of com - pleted response forms were shown . Participants were then given a packet of background mate - rials to read and study , including a description of recent developments in the Persian Gulf , the setting for the test scenarios . Participants also had access to detailed maps , although the geo - graphical features needed to understand the scenarios ( e . g . , air lanes that are designated for commercial air traffic ) were also provided on the simulation displays . Participants were allowed to study these materials for as long as they wished prior to beginning the experiment and were given continuous access to them dur - ing the study . Training . To ensure familiarity with the required judgments , we provided a 6 - min training scenario ; no data relevant to our exper - imental predictions were collected from this scenario . The participants first read the situa - tion update , which gave the current position of the ship and described the position of any air - craft present at the start of the scenario . During this scenario , the participants queried the sim - ulation for information and manipulated the displays as they would on the job . Prerecorded tapes that were synchronized to the scenario provided communications from other areas of the ship ( e . g . , radio communications reports ) . At the midpoint and end of the scenario , we administered the appropriate instruments to familiarize the participants with the data col - lection techniques . Test . The participants then began the test phase , which included five or six scenarios , depending on time constraints . Each scenario lasted approximately 18 min . Participants ﬁrst reviewed the situation update for the scenario ; then the scenario was run with the prerecorded communications tape . During the scenario , the participants were free to query the simulation as they deemed appropriate . After each 3 - min interval in the scenario , the simulation paused and assessments were obtained on selected air - craft , resulting in six periodic assessments . Final judgments on classiﬁcation of the aircraft and the evidence used to make this decision were collected at the conclusion of each scenario . Design The experimental design used in this study crossed manipulations of outcome frame , task load , and information order in a 2 × 2 × 3 design . The sequence in which participants received the task load and information order treatments was counterbalanced . Outcome frame , however , was always treated as a between - subjects factor , because it did not seem feasible to induce different frames of ref - erence for the same participant . Our manipula - tion of each of the factors is described below . Outcome framing . Two points of reference for outcomes for the scenarios in the current study are : ( a ) how appropriate actions might serve to gain strategic position or tactical advantage , and ( b ) how errors might result in the loss of U . S . , allied , and neutral assets or lives . Differing outcome frames were estab - lished by varying the importance attached to potential strategic gains vs . physical loss in the background materials reviewed by each partic - ipant . More explicit manipulations of frame such as labeling displays to emphasize loss or gain or requiring our participants to report expected losses or gains from their actions were considered but rejected . Maintaining a naturalistic context was an overriding objec - tive , which would be violated by altering the task in these ways . Under this manipulation of frame , the losses avoided are the same as the gains achieved , and , similarly , the losses incurred are identical to the gains not realized . If losses seem large compared to the equivalent gains , participants under the loss frame will view a threatening situation as more serious ( the potential loss is greater ) than the same situa - tion viewed under the gains frame . Task load . The manipulation of task load had two levels and was varied among scenarios . at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from B IAS IN N ATURALISTIC D ECISION M AKING 231 The manipulation involved variation in the dif - ficulty of the primary task of classifying and determining the intent of aircraft , rather than any physical stressors , such as noise and fatigue , or any psychological stressors , such as concern about evaluation by superiors . Speciﬁcally , we manipulated task load by varying : ( a ) the num - ber of previously identified aircraft and ships in the vicinity , ( b ) the number of unidentiﬁed , possibly threatening aircraft , ( c ) the amount of display clutter ( noise in the signal ) , and ( d ) the number of communications that the partici - pant had to monitor . None of the additional communications used in the high task load condition were relevant to the experimental conditions . Table 1 summarizes the range of values for these factors under the low and high task load conditions . Information order . Five different evidence patterns were developed : three treatment orders and two orders used as controls . In the first treatment pattern , three pieces of infor - mation that imply that an aircraft is civil were followed by three pieces of information that indicate that the aircraft is military ( the civil - then - military sequence ) . The second pattern was just the reverse of the ﬁrst ; that is , the mil - itary evidence was presented ﬁrst , followed by the civil information ( the military - then - civil sequence ) . In both of these patterns , the evi - dence was spread over the 18 - min scenario , with one piece of information appearing dur - ing each of the six 3 - min blocks . Finally , the third pattern mixed the evidence over time so that one military and one civil cue were pre - sented in each of the first , third , and fifth blocks of the six 3 - min blocks of a scenario ( the mixed sequence ) . These manipulations result in the same evi - dence being presented over the course of a sce - nario , with only the order of the information being varied . Two other patterns were added as control conditions . If the participants’ ﬁnal classiﬁcations tended to be based on informa - tion presented later in a sequence of conﬂicting evidence , the cues recalled might be a result of forgetting rather than of an information order effect ; that is , the participants might have sim - ply forgotten the inconsistent information because it was presented early in the scenario . To differentiate forgetting from an information order effect , we added one control pattern in which all cues suggested that the aircraft was civil ( civil only sequence ) and a second pattern in which all cues were military ( military only sequence ) . In both control patterns , the civil and military cues that were used in the infor - mation order treatments were presented in the first three time blocks . These pieces of infor - mation were then followed by three additional cues supporting the same conclusion in the last three time blocks . To effectively implement these treatments , the authors had to identify evidence that is interchangeable in order and that is commonly observed , so that the recurrence of a cue would seem plausible . The cues selected to indicate that an aircraft was civil were : ( a ) The aircraft was within a ﬂight lane designated for commercial air traffic , ( b ) the aircraft identi - fied itself as a commercial flight in an inter - cepted radio communication to a nearby airport , and ( c ) emissions from a commercial weather or course radar were detected in the same direction as the aircraft . The three military cues were : ( a ) Emissions from a military radar were detected in the same direction as the aircraft , ( b ) the aircraft deviat - ed slightly from the commercial ﬂight lane , and ( c ) the aircraft failed to respond verbally to warnings on International Air Distress ( IAD ) and Military Air Distress ( MAD ) frequencies to stay clear of the ship . Although these cues suggest the aircraft is either civil or military , they are subject to various ambiguities , and thus , varying interpretations . TABLE 1 : Factors Varied under Low and High Task Load Conditions Low Task Load High Task Load Number of aircraft , ships already identiﬁed 6 – 10 13 – 16 Number of aircraft not identiﬁed , possible threats 2 – 4 4 – 6 Number of instances of display clutter 4 – 7 9 – 12 Number of communications received 43 58 at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from Aircraft exhibiting these cues in the five pat - terns described previously were incorporated into three low task load and three high task load scenarios . To increase the realism of the scenarios , many of the surface details of these aircraft were varied , such as the commercial flight lane the aircraft was following or the exact type of commercial or military radar detected . A number of other features , such as aircraft altitude and airspeed , were held approx - imately constant at neutral values . To assure the realism of the resulting scenarios , active - duty navy personnel reviewed them ﬁrst in text form , then later in the simulation , before they were shown to any of our participants . They judged the scenarios to be realistic and repre - sentative of operational situations . Dependent Measures and Analysis Periodic assessments . After each 3 - min time block , participants expressed their degree of belief that a given aircraft was military or civil / commercial by placing a check mark along a line with anchors of “definitely mili - tary” and “definitely civil . ” Similarly , the par - ticipant assessed the threat posed by the aircraft by marking along a line anchored with “definitely a threat” and “definitely not a threat . ” An area for comments about classiﬁca - tion and intent was also provided . At each periodic assessment , data on four to six air - craft were obtained . Because reports by TAOs occur frequently in operational settings , and the time needed to collect these judgements was only about 15 to 30 s , pausing the simula - tion should not have detracted from the realism of the decision context . Because of limitations in the availability of qualiﬁed personnel , how - ever , it was not possible to test this assumption by adding a group that provided only final judgments , with no pauses in the scenarios . An analysis of variance ( ANOVA ) was used to assess the differences among the ﬁnal periodic assessments resulting from the three conflict - ing patterns of evidence . Final judgments . Participants also provided : ( a ) a ﬁnal , dichotomous classiﬁcation , military or civil , of the aircraft in the treatment condi - tion , ( b ) a description of the aircraft’s mission ( optional ) , ( c ) a listing of all the evidence , sup - porting and contradictory , that they could recall , ( d ) an assessment of the strength of support or contradiction of each piece of evi - dence , and ( e ) a subjective assessment of workload using a variation of the modified Cooper - Harper scale ( Wierwille & Casali , 1983 ) . The optional area ( describing the air - craft’s mission ) was not used by any of the par - ticipants . Ten blank spaces were provided for the participants to list the cues they recalled . Each of these spaces was followed by a line with endpoints labeled “very strongly support - ed” and “very strongly contradicted , ” which the participants used to indicate the degree to which the recalled evidence supported or con - tradicted their conclusion . Differences in the frequency of recall were assessed using a Chi - square test . Differences in the assessed strength of support or contradiction of each piece of evidence , including neutral informa - tion , were tested using an ANOVA . We also examined the nature of any information recalled but not presented during the scenario ( i . e . , recall errors ) . RESULTS To determine if the manipulation of task load in the present study was effective , the authors analyzed the subjective workload assessments , based on the modified Cooper - Harper ratings , collected at the end of each scenario . Significantly higher mean ratings were found for the high task load scenarios , compared with the low task load scenarios ( means of 5 . 3 vs . 6 . 7 ; t ( 74 ) = 1 . 98 ; p = . 025 ) . The present study’s manipulations appear to have created situations that differed in the per - ceived level of workload . Using data from the final periodic assess - ment , when the accumulated evidence on each aircraft was the same , and only the order of presentation varied , the main effect of infor - mation order was statistically signiﬁcant ; F ( 2 , 64 ) = 7 . 103 , p < . 001 . Main effects for the other factors ( task load and outcome frame ) and the two - and three - way interactions did not reach statistical significance . Tests of the pair - wise differences among the three informa - tion order means were conducted using Scheffé’s F - test . These tests indicated that the judgments following the military - then - civil 232 Summer 2001 – Human Factors at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from B IAS IN N ATURALISTIC D ECISION M AKING 233 sequence shifted significantly toward the civil end of the scale , compared with the other two treatments ; F ( 1 , 46 ) = 16 . 65 , p < . 001 , vs . civil - then - military sequence ; F ( 1 , 54 ) = 17 . 68 , p < . 001 vs . mixed - evidence sequence . The difference between the civil - then - military and mixed sequences was not significant . Mean judgments on the aircraft’s classification at each time step are depicted in Figure 1 , illus - trating a recency effect . Ratings of the intent of the aircraft followed a similar pattern . Analysis of the recall data from the three conﬂicting information orders revealed signiﬁ - cant support for the information order bias . In order to be considered indicative of an infor - mation order bias , participants needed to have recalled more information that supported their final classification than that contradicted it , without regard to which hypothesis they adopted . The Chi - square test was statistically signiﬁcant ; χ 2 ( 2 ) = 79 . 99 , p = . 0001 , and the results are illustrated in Figure 2 . Participants recalled more civil information than military when their final classification was civil and more military information than civil when their final classification was military . In all cases , identical information was presented , with only the order of presentation varying . Since our participants tended to classify the aircraft consistently with recent data , it was possible that the differences in recall frequency noted previously were a result of forgetting rather than a judgment bias . To evaluate this possibility , we analyzed the evidence recalled as a function of when in the scenario it was presented : early , late , or dispersed . This analy - sis , unlike those described in the previous paragraphs , included the evidence recalled from the military only and civil only sequences , as well as the conflicting patterns . So , for example , in the civil - then - military and civil only sequences , the same civil information is provided early ( during the first three time steps ) ; in the military - then - civil information order , this evidence is provided late ( in the last three time steps ) ; while in the mixed sequence , Average Rating Time 1 Time 2 Time 3 Time 4 Time 5 Time 6 Civil - Military Mixed Military - Civil Time Definitely Military Definitely Civil Neutral Figure 1 . Classiﬁcation judgments vary as a function of the order in which information is presented . at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from this evidence is dispersed throughout the sce - nario . Results of these analyses are presented in Figure 3 . For both ﬁnal classiﬁcations , the amount of information recalled did not vary signiﬁcantly as a function of when it occurred ; civil : χ 2 ( 6 ) = 6 . 34 , p = . 386 ; military : χ 2 ( 6 ) = 2 . 59 , p = . 865 . When evidence was presented early , par - ticipants remembered approximately the same proportion of it as when it was presented late , provided that this evidence supported their ﬁnal conclusion . Although a signiﬁcantly smaller proportion of the disconfirming evidence was recalled , participants did recall some inconsistent cues . In these cases , however , the evidence was rated as relatively unimportant , compared with the same information when it conﬁrmed their ﬁnal judgment . Figure 4 depicts the results of this analysis . The same civil information was more conclusive when it supported the final judg - ment than when it contradicted it ; F ( 1 , 84 ) = 6 . 99 , p = . 01 . The importance attached to mil - itary information showed the same pattern ; it was weighted more heavily when it supported the final judgment than when it contradicted that judgment ; F ( 1 , 63 ) = 6 . 24 , p = . 015 . A number of pieces of evidence about the air - craft were selected to be approximately neutral ; that is , outside the context of a given situation , 234 Summer 2001 – Human Factors 0 10 20 30 40 50 60 70 80 90 100 Civil Evidence MilitaryEvidence P e r ce n t a g e R eca ll e d Civil Military Final Judgment Figure 2 . Percentage of civil or military evidence recalled as a function of ﬁnal classiﬁcation . 0 20 40 60 80 100 Dispersed Late Early P e r c e n t a g e R eca ll e d Recall of Civil Evidence Recall of Military Evidence ( When Final Judgment is Civil ) ( When Final Judgment is Military ) Figure 3 . Percentage of recall as a function of where in the sequence information is presented . at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from B IAS IN N ATURALISTIC D ECISION M AKING 235 Navy TAOs would rate this information as being no more characteristic of a military aircraft than of a civil one . From these neutral data , our participants recalled only altitude and air - speed with any regularity . Interestingly , they indicated that the same airspeeds and altitudes supported their ﬁnal conclusion , whether that conclusion was civil or military . As illustrated in Figure 5 , these cues supported a civil con - clusion when participants’ ﬁnal classiﬁcations were civil and a military conclusion when their final classifications were military ; F ( 1 , 34 ) = 59 . 917 , p = . 0001 . Analysis of recall errors also supported the conclusion that our participants showed an information order bias . In nine of the 129 air - craft evaluated , or about 7 % , 10 recall errors occurred . Most of the errors involved evidence that could be attributed to another aircraft in the same scenario . In one case , however , infor - mation was reported that had never occurred anywhere in the scenario . Of the 10 errors , nine - 40 - 30 - 20 - 10 0 10 20 30 40 Civil Evidence Military Evidence S t r e ng t h o f S uppo r t o r C on t r a d i c t i on f o r F i n a l J udg m e n t Strongly Supports Civil Strongly Supports Military Civil Military Final Judgment Figure 4 . Identical evidence is weighted differently based on the ﬁnal judgment . - 40 0 40 S t r e ng t h o f S uppo r t f o r a C i v il o r M ili t a r y J udg m e n t Strongly Supports Military Strongly Supports Civil Civil Military Final Judgment Figure 5 . Participants interpreted identical airspeeds and altitudes to support their ﬁnal judgment , whether the judgment was military or civil . at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from 236 Summer 2001 – Human Factors were consistent with the participant’s ﬁnal clas - siﬁcation of the aircraft , indicative of an infor - mation order bias . Additionally , for the single error that involved disconﬁrming evidence , the participant rated it as an extremely weak con - tradiction , again indicative of this bias . DISCUSSION Overall , our results indicated that experts can be significantly influenced by the order in which they receive information , and in such situations , they may fail to recall inconsistent information or attach little importance to it if it is recalled . But before discussing these con - clusions , we will consider the lack of effect of task load and outcome framing . Across both judgments of classiﬁcation and intent , no effect involving outcome frame was signiﬁcant . Several reasons for this result might be cited , including the possibility that experi - enced decision makers are not influenced by outcome frame . Equally likely , however , is the possibility that our manipulation did not ﬁrmly establish different outcome frames of reference . To clearly link outcomes to different frames , it would have been necessary to alter basic features of the simulation ( e . g . , supplementing the dis - plays with probabilities of damage or casualties as a result of misclassiﬁcation ) . Explicit manip - ulations of this type were considered but rejected as violating the central objective of maintaining a more naturalistic context . In general , it appears that manipulating frame of reference will be problematic in naturalistic decision contexts unless well - established con - cepts for the relevant gains and losses already exist . No such concepts existed within this domain . Task load , on the other hand , varies natural - ly in this domain , and , as noted previously , our manipulation produced signiﬁcant differences in our participants’ perceived workloads . We also found that high task loads reduced the overall amount of information processed . Using an arcsin transformation of proportions ( Winer , 1962 ) , we observed more missing data in high vs . low task load scenarios ; F ( 1 , 597 ) = 7 . 34 , p = . 005 . Similarly , we observed a smaller percentage of data recalled under high vs . low task load ; F ( 1 , 127 ) = 3 . 79 , p = . 05 . Why , then , did task load not show any sig - niﬁcant main effects or interactions with infor - mation order ? Simply , it appears that under high task load , participants directed their attention to potentially threatening aircraft , whereas under low task load , no such focusing of attention occurred . For example , under high task load , participants more frequently recalled that an aircraft had departed a military base than if a similar aircraft had departed a civil airﬁeld . Under low task load , these differences disappeared . Because the aircraft used in our information order treatments were all threaten - ing , variation in task load did not affect the information to which the participant attended . Information on other aircraft , however , was lost under high task load , producing the signif - icant differences noted , and potentially impact - ing subsequent judgments on these aircraft . For those aircraft in the information order treatments , where attention was apparently focused , the order in which trained and experi - enced participants received evidence strongly affected their judgments , similar to the results of the Adelman et al . ( 1996 ) study . However , the possibility that these differences resulted from reinterpreting nominally inconsistent infor - mation can be largely ruled out . Indeed , rather than being reinterpreted , inconsistent evidence in the current study was recalled less frequently and given less weight than when that same evi - dence conﬁrmed a judgment . Additionally , we found no support for interpreting these differ - ences in recall as a function of forgetting . These findings may imply that experts employ different processes to reconcile con - flicting information , depending on circum - stances . In some cases , experts may reinterpret seemingly inconsistent cues , so that all of the evidence fits a known pattern ; in other cases , they may be required to adopt simplifying heuristics that explain away certain apparent inconsistencies . It seems possible , however , to characterize these results as the outcome of a single , pattern - matching process . Extensive bodies of research on schema theory ( Bartlett , 1932 ) and related research on scripts ( Schank & Abelson , 1977 ) , natural language categories ( Rosch , 1973 ) , and prototypes ( Anderson , 1991 ) , show errors in encoding and reconstruct - ing events from memory that are markedly at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from B IAS IN N ATURALISTIC D ECISION M AKING 237 similar to our ﬁndings . Speciﬁcally , these theo - ries hold that during encoding and recall , details of an event may be altered , omitted , or created to complete a pattern when the original obser - vations do not fully match the corresponding schema , script , or prototype . For cases in which adopting a speciﬁc inter - pretation of a cue can achieve consistency with a schema , reinterpretations would presumably occur . Consistent with this expectation , neutral cues on airspeed and altitude in the current study were interpreted as support for the par - ticipants’ conclusions , without regard to which conclusion they adopted . When conﬂicts among cues are irreconcilable , as they probably were for the evidence varied in our information order treatment , encoding and reconstruction of the events might involve the omission of some inconsistent information or a change in the emphasis attached to other data . These effects were found . Additionally , recall errors that supported the accepted conclusion , albeit at a very low frequency , also occurred , consistent with the interpretation that our participants reconstructed their observations to be more consistent with an expected pattern or schema . Results from traditional judgment research on the information order effect can also be interpreted as a schema - matching process . A belief - adjustment model , built on ﬁndings from a number of previous studies ( Hogarth & Einhorn , 1992 ) , may represent a framework for assessing the opposing pressures to main - tain a given schema or to shift to a new one . Influences that cause individuals to maintain an initial schema would yield a primacy effect in group behavior , whereas factors that pro - duce shifts to a new schema would yield a recency effect in group behavior . The belief - adjustment model bases these primacy / recency predictions on five factors , including whether the series of evidence is short or long , and , if short , whether the evi - dence is simple or complex . These last two fac - tors are crucial to predicting the type of order effect for the current study , with recency more strongly indicated if the sequence is short and complex . In other words , all other things being equal , a relatively short sequence of complex information could be expected to produce less pressure to change schema , compared with a longer sequence or a sequence composed of more clearly inconsistent evidence . Unfortunately , research in more naturalistic settings makes these predictions difficult to test . Neither measure used in the belief - adjust - ment model ( i . e . , the length of the sequence and the complexity of evidence ) appears to have any direct counterpart in either the current problem domain or most studies in naturalistic contexts . Our participants had continuous access to graphical displays and to dozens of characteristics of the aircraft , as well as to spe - cific reports and observations over scenarios that lasted about 20 min and involved numer - ous aircraft . While such a situation may seem long and complex to a naive observer , it is not clear that it was so for our participants . Overall , interest in decision making in more naturalistic contexts has created a concern about generalizing the findings of traditional judgement research to decision making on the job , and thus , has stimulated new research . The expectation for this work has been that experts , performing in more naturalistic con - texts , will demonstrate less so - called “judg - ment bias” and will recognize patterns in what appear to the naive observer to be complex and conflicting events . Clearly , many studies have demonstrated this result . Other studies have not , yielding behavior that parallels the results from traditional judgment bias research . It is possible to reconcile these differences , however , if we postulate that observations are encoded and reconstructed around conceptual structures like schema , scripts , or prototypes . Then , apparent conflicts that can be resolved by employing familiar reinterpretations of evi - dence are resolved in this manner . More perva - sive conflicts in information , which can be created even for experts , may be resolved by omissions , changes in emphasis , or , in rare cases , creation of data during encoding or reconstruction that are consistent with the accepted schema . What this line of research reveals is less a need for additional studies of overall decision - making behavior than a need for evaluations of the factors underlying the selection of patterns / schema and the persis - tence with which they are held . The factors used in models from traditional judgment research seem quite inadequate to this task at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from 238 Summer 2001 – Human Factors when they are applied to decision making in more naturalistic contexts . ACKNOWLEDGMENTS The authors dedicate this paper to the mem - ory of Larry Walrath , who lost his battle with cancer in December of 2000 . Larry was a col - league , mentor , and friend to many within the human factors community . This research was supported by contract N660001 - 91 - C - 6020 from Space and Naval Warfare Systems Center , San Diego , California . The authors express their gratitude to Stanley Collyer and Willard Vaughan ( Ofﬁce of Naval Research Code 34 ) for their support of this work . REFERENCES Adelman , L . , Bresnick , T . , Black , P . K . , Marvin , F . F . , & Sak , S . G . ( 1996 ) . Research with Patriot Air Defense ofﬁcers : Examining information order effects . Human Factors , 38 , 250 – 261 . Adelman , L . , Tolcott , M . A . , & Bresnick , T . A . ( 1993 ) . Examining the effect of information order on expert judgment . Organizational Behavior and Human Decision Processes , 56 , 348 – 369 . Anderson , M . R . ( 1991 ) . The adaptive nature of human categoriza - tion . Psychological Review , 98 , 409 – 429 . Ashton , A . H . , & Ashton , R . H . ( 1988 ) . Sequential belief revision in auditing . The Accounting Review , 63 , 623 – 641 . Ashton , R . H . , & Ashton , A . H . ( 1990 ) . Evidence responsiveness in professional judgment : Effects of positive versus negative evidence and presentation mode . Organizational Behavior and Human Decision Processes , 46 , 1 – 19 . Bartlett , F . C . ( 1932 ) . Remembering : A study in experimental and social psychology . New York : Cambridge University Press . Cannon - Bowers , J . A . , Salas , E . , & Pruitt , J . S . ( 1996 ) . Establishing the boundaries of a paradigm for decision - making research . Human Factors , 38 , 193 – 205 . Entin , E . E . ( 1992 ) . Inertia and adaptation in the sequential pro - cessing of information . In Proceedings of the psychology in the Department of Defense 13th symposium , 193 – 197 . Colorado Springs , CO : Department of Behavioral Sciences and Leadership , U . S . Air Force Academy . Entin , E . E . , Serfaty , D . , & Forester , J . ( 1989 ) . Sequential process - ing of information from multiple sources . In Proceedings of the system , man , and cybernetics society , ( pp . 91 – 100 ) . New York : IEEE Press . Hogarth , R . M . ( 1987 ) . Judgment and choice ( 2nd ed . ) . New York : Wiley - Interscience . Hogarth , R . M . , & Einhorn , H . J . ( 1992 ) . Order effects in belief updating : The belief - adjustment model . Cognitive Psychology , 24 , 1 – 55 . Kahneman , D . , Slovic , P . , & Tversky , A . ( 1982 ) . Judgment under uncertainty : Heuristics and biases . New York : Cambridge University Press . Klein , G . A . , Orasanu , J . , Calderwood , R . , & Zsambok , C . E . ( 1993 ) . Decision making in action : Models and methods . Norwood , NJ : Ablex . Knapp , B . G . , & Tolbert , C . A . ( 1985 ) . Insights on information absorption and transmission rates in C 2 I settings ( ARI Research Note 85 - 93 ) . Alexandria , VA : U . S . Army Research Institute for the Behavioral and Social Sciences . Nisbett , R . E . , & Ross , L . ( 1980 ) . Human inference : Strategies and shortcomings of social judgment . Englewood Cliffs , NJ : Prentice - Hall . Rosch , E . ( 1973 ) . On the internal structure of perceptual and semantic categories . In T . E . Moore ( Ed . ) , Cognitive develop - ment and the acquisition of language ( pp . 111 – 144 ) . New York : Academic Press . Salas , E . & Cannon - Bowers , J . A . ( Eds . ) . ( 1996 ) . Decision making in complex environments [ Special issue ] . Human Factors , 38 ( 2 ) . Schank , R . C . , & Abelson , R . ( 1977 ) . Scripts , plans , goals , and understanding . Mahwah , NJ : Erlbaum . Sheridan , T . ( 1981 ) . Understanding human error and aiding human diagnostic behavior in nuclear power plants . In J . Rasmussen & W . Rouse ( Eds . ) , Human detection and diagno - sis of system failures ( pp . 19 – 35 ) . New York : Plenum Press . Tolcott , M . A . , Marvin , F . F . , & Lehner , P . E . ( 1989 ) . Expert deci - sion making in evolving situations . IEEE Transactions on Systems , Man , and Cybernetics , 19 , 606 – 615 . Tversky , A . , & Kahneman , D . ( 1981 ) . The framing of decisions and the psychology of choice . Science , 211 , 453 – 458 . Wierwille , W . W . , & Casali , J . G . ( 1983 ) . A validated rating scale for global mental workload measurement applications . In Proceedings of the Human Factors Society 27th Annual Meeting , 129 – 133 . Santa Monica : Human Factors Society . Winer , B . F . ( 1962 ) . Statistical principles in experimental design . New York : McGraw - Hill . Zsambok , C . E . , & Klein , G . ( 1997 ) . Naturalistic decision making . Mahwah , NJ : Erlbaum . Bruce M . Perrin is an associate technical fellow in Boeing’s Instructional and Technical Data Systems Division , St . Louis , Missouri . He received his Ph . D . in industrial / organizational psychology from Kansas State University in 1983 . Barbara J . Barnett is a team lead in Boeing’s Instructional and Technical Data Systems Division , St . Louis , Missouri . She received her Ph . D . in engi - neering psychology from the University of Illinois at Urbana - Champaign in 1989 . Larry Walrath was a member of the Human Systems Integration Group at Boeing , Phantom Works , St . Louis , Missouri . He received his Ph . D . in psychology from the University of California at Santa Barbara in 1971 . Jeffrey D . Grossman is the head of the Simulation and Human - Systems Technology Division at the Space and Naval Warfare Systems Center in San Diego , California . He received an M . P . A . from the University of Southern California in 1973 . Date received : June 10 , 1999 Date accepted : November 17 , 2000 at UNIV CALIFORNIA SAN DIEGO on August 24 , 2015 hfs . sagepub . com Downloaded from