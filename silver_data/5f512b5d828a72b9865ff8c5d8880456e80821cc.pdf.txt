JuLY / auGuST 2013 1541 - 1672 / 13 / $ 31 . 00 © 2013 IEEE 67 Published by the IEEE Computer Society A I A N D E D U C A T I O N Editor : Judy Kay , University of Sydney , judy . kay @ sydney . edu . au Simulated Learners learners : to provide an environment in which hu - man teachers can practice , to embed simulated learners as part of the learning environment , and to provide an environment for exploring and test - ing learning system design issues . 1 The second of these roles has been much investigated in artifi cial intelligence in education ( AIED ) , with the develop - ment of a wide variety of “pedagogical agents . ” 2 In contrast , the fi rst and third roles for simulated learners haven’t been nearly as well explored . The main research touching on the fi rst role is the de - velopment of “teachable agents” in a reciprocal learning context , 3 but otherwise there has been little work . Surprisingly , there hasn’t been much work on the third role , either—at least , until re - cently when there has been renewed interest in us - ing simulated learners to test systems at various stages in the learning system lifecycle , and to har - ness the power of computational modeling to shed light on learning design issues . Because simulated learners will play an increas - ingly important role in the design of learning en - vironments in the coming years , here we take a closer look at current research for simulated learn - ers in all three roles , and examine some of the main issues affecting simulated learners going forward . Simulated Learners : State of the Art The fi rst role for simulated learners discussed by VanLehn and his colleagues is to provide a prac - tice environment for teachers . The Betty’s Brain research project has exactly this aim : a human teacher instructs a “teachable agent . ” 3 But , the hu - man teacher is , in fact , actually a student , and the instruction is a pedagogical strategy called “recip - rocal learning” meant to help the student learn through the act of teaching . The agent represents what it’s taught in a concept map , and can ques - tion the student based on qualitative inferences in its knowledge base . Such questions help the ( hu - man ) student clarify his or her own thinking . Betty’s Brain , in fact , fi ts better under the “peda - gogical agents” category than under the “practice for teachers” category . There’s really no other sig - nifi cant work on using simulated learners to help teachers to practice , a research goal that perhaps should be resurrected . The second role for simulated learners is as “pedagogical agents” incorporated into the learn - ing environment to provide novel opportunities for learning . The fi rst such pedagogical agent was Tak - Wai Chan’s “learning companion , ” meant to be a friendly collaborative “peer” helping the learner as he or she solved problems . 4 The learn - ing companion can converse with the student in a mixed - initiative style and in general provide sup - port through the learning process . In subsequent research stretching over years , Chan and his col - leagues explored many aspects of the learning companion approach . Esma Aimeur and Claude Frasson created a “disturbing agent” which , rather than assisting a learner as the learning companion does , chal - lenges the learner . 5 This disturbing agent presents itself as a learner at a comparable level to the hu - man learner and proposes solutions , suggestions , or counter - examples that are deliberately incor - rect . By forcing the learner to reconcile differences with the disturbing agent and , if necessary , to de - fend his or her position , this approach can enhance learning , as suggested by cognitive dissonance the - ory . Learner confi dence can even be enhanced , at least for strong learners , but the strategy is ineffec - tive for weak students . Arthur Graesser and his colleagues developed AutoTutor , 6 where students learn through a nat - ural language conversation with an “animated tutor” . AutoTutor allows a variety of dialogue S imulated learners are an increasingly impor - tant aspect of advanced learning environ - ments . In their landmark paper , Kurt VanLehn and his colleagues delineated three roles for simulated Gord McCalla and John Champaign IS - 28 - 04 - Education . indd 67 16 / 10 / 13 7 : 03 PM 68 www . computer . org / intelligent IEEE INTELLIGENT SYSTEMS patterns and performs natural lan - guage processing using latent seman - tic analysis . This approach works best in environments where high pre - cision or sophisticated interactions aren’t needed , where learners will ac - cept literal replies , and where there’s low - to - medium shared knowledge between the learner and tutor . Many systems have been built based on the AutoTutor approach , since they can be inexpensively developed , require minimal knowledge engineering , and have been shown to improve students learning by about one letter grade , 0 . 8 sigma . In addition to allowing various pedagogical styles , simulated agents can also be part of the domain itself . Lewis Johnson and his team 7 for ex - ample , have built a series of immer - sion environments in which military officers can practice interacting with simulated villagers . The villagers are animated , converse in their own nat - ural language , and behave as they would in various theatres where the military officers might be deployed . The officers are accompanied by their own troops , also simulated . Vari - ous scenarios can be played out in these environments that help the of - ficer learn appropriate social and linguistic conventions prior to be - ing deployed . This is an example of pedagogical agents that aren’t exactly simulated learners ( although they do evolve appropriately during the inter - action ) , but are essential to the do - main itself and to the social learning required . Many educational games also make use of such artificial agents incorporated as part of the domain it - self . Not strictly speaking simulated learners , such agents still share many of the same design requirements of simulated learners , and fruitful in - teraction between those working on such agents and on simulated learners is ongoing . In other work , Lewis Johnson and his colleagues summarize the moti - vations , capabilities , and technical issues of pedagogical agents . 2 They discuss the ways that pedagogical agents can increase the “bandwidth” of communication between the sys - tem and the student , by using tech - niques such as demonstrating actions , gesturing , and incorporating emotion in the interactions . Technical con - siderations discussed include how to incorporate the agent in the system interface and how to determine the agent’s behavior in an adaptive and personalized manner . The third role for simulated learn - ers is for testing system design issues . The original paper by Van Lehn and his co - authors 1 drew extensively from Stellan Ohlsson and his colleagues’ research on learners in the subtrac - tion domain , 8 in which a simulated model of a learner accurately pre - dicted the effects of various teaching interventions , later confirmed with real learners . This research showed the potential of modeling to shed in - sight into pedagogical and other is - sues . Surprisingly , there hasn’t been much follow - up work in the interven - ing years on simulated learners in this third role , at least until recently . Benjamin MacLaren and Kenneth Koedinger’s work on SimStudent 9 cre - ated a machine - learning agent that learns cognitive skills by observ - ing demonstrations . It does this by generating explanations of observed problem - solving steps , then inducing rules , drawing on Anderson’s ACT - R theory . SimStudent has been used to study skill acquisition and both ma - chine and human learning . It assists with system testing and development by letting authors create a tutor by teaching SimStudent how to solve problems . Over the subsequent years , SimStudent ( through several itera - tions ) has evolved into a sophisticated model of skill acquisition in a number of domains . 10 More recently , John Champaign 11 used simulated learners to explore learning environments at the initial stages of system design . In particu - lar , he was interested in determining the effect of various pedagogical in - terventions in a learning environment built on the principles of the ecologi - cal approach architecture . 12 The eco - logical approach demands that a huge amount of data about the learners be collected as they use the system , which then is analyzed for patterns that can be used to make various ped - agogical decisions . But there’s a cold - start problem—during initial system design , there are no learners—hence , the need for simulated learners . Using relatively simple simulated learners , Champaign evaluated three different kinds of interventions , and was able to eliminate many ineffective strate - gies while zeroing in on approaches that might work better . This sets the stage for subsequent system building and evaluation with real learners . Graham Erickson and his co - investigators also were interested in exploring the use of simulation in the early stages of design , only in this work they simulated the entire learn - ing environment as well as the learn - ers . 13 The environment was simulated using the ecological approach archi - tecture ( in this case , to emulate an in - telligent tutoring system ) . The learn - ers were simulated by drawing data from human subject studies done for other purposes ( “study reuse” ) . The resulting simulation was used to com - pare various approaches to recom - mending learning objects to learners . Further studies of other pedagogical issues are ongoing . It’s fair to say that the third role for simulated learners is on the cusp of major research activity . In fact , there was a Simulated Learners workshop IS - 28 - 04 - Education . indd 68 16 / 10 / 13 7 : 03 PM JuLY / auGuST 2013 www . computer . org / intelligent 69 at the 2013 International AIED Con - ference , where many of the papers ex - plored simulated learners in the sense of the third role . Issues in Using Simulated Learners There are many interesting issues fac - ing simulated learner research . The first is how much cognitive fidelity is required in the simulation model . No - buru Matsuda and his colleagues’ ef - forts in SimStudent have been to build a simulated learner with cognitive fi - delity , at least matching the needs of the cognitive tutoring paradigm in skill - acquisition domains . 10 But , cog - nitive fidelity isn’t needed for every goal where simulated learners are be - ing used . For system load testing it doesn’t matter at all , for example . In general , the degree and type of cogni - tive fidelity is dependent on the situa - tion : only enough cognitive fidelity is needed for the simulation’s purposes . If building pedagogical agents , there only needs to be sufficient realism to be convincing to learners in a partic - ular domain . If doing system testing , the simulated learners only need to manifest the range of behaviors that are important to the questions the simulation is attempting to answer . A second issue is where in the sys - tem lifecycle simulated learners can be used . The answer is likely : “any - where . ” Simulated learners can be used during initial analysis and design phases to explore possible re - quirements for the learning environ - ment . If a skeletal simulation of a learning environment can be built and tested on fairly simple simulated learners , then much can be learned about what’s possible , what’s useful , and what’s likely not worth pursuing in the design of the actual learning environment . 11 , 13 Later in the system life cycle , simulated learners can be created to explore specific issues , and to do initial testing of the learning en - vironment . Still later , when the learn - ing environment has been deployed , detailed learner models can be ex - tracted from the behavior of real learners as they interact with the en - vironment , and these models can in - form the creation of simulated learn - ers that can be used to do further , more refined exploration of specific issues . Over time , through successive iterations of human subject test - ing followed by system redesign , the simulated learners can become ever more sophisticated , even as the learn - ing environment itself becomes more adaptive . Research will continue to provide new and interesting kinds of agents to enhance the kinds of pedagogical interactions that will be possible in a learning environment . Adding such agents is particularly urgent when the learning domain itself is social , as in military training environments 7 where learners must acquire social and political skills . But , even in do - mains with content that’s decidedly not social ( for example , mathematics , physics , and programming ) there’s a need for learners to socially inter - act when confronted with a learning impasse or a motivational issue . Al - though systems such as iHelp 14 can bring real learners together to pro - vide “peer help” in such contexts , simulated learners can also be useful when there aren’t enough peers over - all , or when no peer is around who is ready , willing , or able to help . Simulated learners are usually embedded in “closed” learning envi - ronments , such as intelligent tutoring systems where the learner is fully im - mersed in the system without outside influences . Can they still be created for more open learning environments where learners have electronic ac - cess to many people ( through chat rooms , e - mail , and social media ) and access to vast amounts of infor - mation ( through the Web ) ? Build - ing simulated learners for more open learning environments , with conse - quently reduced control of learners and less predictability in their behav - ior , will prove a challenge . Never - theless , research in educational data mining and learning analytics is in - creasingly providing methods that allow the discovery of patterns of be - havior manifested by large numbers of learners interacting with complex learning systems and interacting with each other , which is the first step to successful simulation . It’s unlikely that there will ulti - mately be one super high - fidelity population of simulated learners to be used in all the different ways sim - ulated learners can be used for all learning environments . This would be solving an AI - complete problem . However , the three different roles of simulated learners discussed by Van Lehn and his co - authors might dove - tail nicely , as simulated learners de - veloped for system testing eventually become sophisticated enough to form the basis of pedagogical agents , and as pedagogical agents take on more roles in a learning environment , and hence can be used for testing a wider range of issues . Moreover , empirical evidence from other research in AIED ( and in learn - ing science , cognitive science , and education ) about learners and learn - ing that isn’t explicitly about simu - lation can feed into the mix , adding even more sophistication to simu - lated learners’ design . It’s likely that a nice synergy will occur between insights gathered through the em - pirical evaluation of learners and at - tempts to model the learners through simulation . Insight gathered from empirical evidence of how learn - ers behave could feed a simulation that then allows predictions of as - yet IS - 28 - 04 - Education . indd 69 16 / 10 / 13 7 : 03 PM 70 www . computer . org / intelligent IEEE INTELLIGENT SYSTEMS undiscovered aspects of learner be - havior , as was the case in Ohlsson and his colleagues’ research . 8 This sets up a positive feedback loop be - tween simulation modeling and em - pirical evaluation that can be quite powerful , and that might eventu - ally allow deep insights into human intelligence to emerge . The learn - ing application is a microcosm of the full AI problem : it provides the right “forcing functions” for explor - ing intelligence . 15 Building a learn - ing environment is tractable in that it’s domain - and purpose - limited , but the problems that must be solved are realistic in having to deal with a messy , but representative , world of incomplete , inconsistent , highly con - textualized , and constantly changing learners . S imulated learners will become an increasingly important part of the design and deployment of ad - vanced learning environments . Ped - agogical agents will continue to be an important tool for expanding the sophistication of learning envi - ronments with new and interesting uses , and evermore realism in their interactions . Research will certainly continue on pedagogical agents , to - wards perhaps the ultimate learning companion , the “primer” envisaged by Neal Stephenson in his book The Diamond Age . 16 In fact , this was the topic of a research workshop hosted by H . Chad Lane at the Institute for Creative Technologies in Califor - nia in 2008 . Such a lifelong learning companion continues to be discussed among AIED and other advanced learning technology researchers , and there have been workshops on lifelong user modeling at the 2009 and 2013 User Modeling , Adapta - tion , and Personalization ( UMAP ) conferences . A more modest goal for pedagogical agents may well be to deploy them in the first role for sim - ulated learners : helping teachers to practice . So , this first role will likely be much better explored going for - ward , in lock step with work on the second role . But , perhaps the most activity in the use of simulated learners ( and simulation more generally ) will be in the third role . Analogous to the role of wind tunnels in aeronautic engi - neering , simulation will provide the means to explore various options more cost effectively than having to build a real learning environment with real learners . Learning environ - ments are simply too expensive to build if every new component—and every adjustment of an old compo - nent—must be tested with human subjects . This is especially true in an age where learning environments are increasingly intended to be used by many thousands of learners ( as in Massive Open Online Courses ) . Be - fore releasing them to the wild , the designers of such environments must be able to test their systems with re - alistic loads and with a much wider diversity of behavior than small - scale human subject evaluations can pro - vide . Simulation will be one obvious way of exploring this large and di - verse space relatively inexpensively . Further , with the vast amount of data being collected from real learn - ers , through many design and test - ing iterations , the simulation can be increasingly well informed over time . Perhaps the most exciting role for simulated learners , however , is as an aid to scientific exploration of the is - sues of learning and its support . Sim - ulation modeling is a way of being precise about assumptions , and then making detailed predictions about the effect of these assumptions that can be empirically tested through evalua - tions that yield new insights and even more refined simulation models , in a powerful feedback loop . References 1 . K . VanLehn , S . Ohlsson , and R . Nason , “Applications of Simulated Students : An Exploration , ” Int’l J . Artificial Intelligence in Education , vol . 5 , no . 2 , 1996 , pp . 135 – 175 . 2 . W . L . Johnson , J . Rickel , and J . Lester , “Animated Pedagogical Agents : Face - to - Face Interaction in Interactive Learn - ing Environments , ” Int’l J . Artificial Intelligence in Education , vol . 11 , no . 1 , 2000 , pp . 47 – 78 . 3 . K . Leelawong and G . Biswas , “Design - ing Learning by Teaching Agents : The Betty’s Brain System , ” Int’l J . Artificial Intelligence in Education , vol . 18 , no . 3 , 2008 , pp . 181 – 208 . 4 . T . W . Chan , “Learning Companion Sys - tems , ” Intelligent Tutoring Systems : At the Crossroads of Artificial Intelligence and Education , C . Frasson and G . Gauthier , eds . , Ablex , 1990 , pp . 6 – 33 . 5 . E . Aimeur and C . Frasson , “Analyzing a New Learning Strategy According to Different Knowledge Levels , ” Comput - ers and Education , vol . 27 , no . 2 , 1996 , pp . 115 – 127 . 6 . A . Graesser et al . , “AutoTutor : An Intel - ligent Tutoring System with Mixed - Initiative Dialogue , ” IEEE Trans . Education , vol . 48 , no . 4 , 2005 , pp . 612 – 618 . 7 . W . L . Johnson and A . Valente , “Tacti - cal Language and Culture Training Systems : Using Artificial Intelligence to Teach Foreign Languages and Cultures , ” Proc . 20th Nat’l Conf . Innovative Applications of Artificial Intelligence , vol . 3 , AAAI Press , 2008 , pp . 1632 – 1639 . 8 . S . Ohlsson et al . , “The Cognitive Complexity of Doing and Learning Arithmetic , ” J . Research in Mathemat - ics Education , vol . 23 , no . 5 , 1992 , pp . 441 – 467 . 9 . B . MacLaren and K . Koedinger , “When and Why Does Mastery Learning IS - 28 - 04 - Education . indd 70 16 / 10 / 13 7 : 03 PM JuLY / auGuST 2013 www . computer . org / intelligent 71 Work : Instructional Experiments with ACT - R ‘SimStudents’ , ” Proc . Int’l Conf . Intelligent Tutoring Systems , Springer - Verlag , 2002 , pp . 355 – 366 . 10 . N . Matsuda et al . , “Predicting Students’ Performance with SimStudent that Learns Cognitive Skills from Observa - tion , ” Proc . Int’l Conf . Artificial Intel - ligence in Education , IoS Press , 2007 , pp . 467 – 476 . 11 . J . Champaign , “Peer - Based Intelligent Tutoring Systems : A Corpus - Oriented Approach , ” doctoral thesis , School of Computer Science , Univ . of Water - loo , Canada , 2012 ; http : / / hdl . handle . net / 10012 / 6721 . 12 . G . I . McCalla , “The Ecological Ap - proach to the Design of E - Learning Environments : Purpose - Based Cap - ture and Use of Information about Learners , ” J . Interactive Media in Education , vol . 1 , 2004 ; www - jime . open . ac . uk / 2004 / 1 . 13 . G . Erickson et al . , “Using the Ecologi - cal Approach to Create Simulations of Learning Environments , ” Proc . Int’l Conf . Artificial Intelligence in Educa - tion , LNCS 7926 , 2013 , pp . 411 – 420 . 14 . J . E . Greer et al . , “Integrating Cogni - tive Tools for Peer Help : The Intelligent IntraNet Peer Help - Desk Project , ” Computers as Cognitive Tools : The Next Generation , S . Lajoie , ed . , Law - rence Erlbaum , 2000 , pp . 69 – 96 . 15 . J . S . Brown , “Toward a New Epistemol - ogy for Learning , ” Intelligent Tutoring Systems : At the Crossroad of Artificial Intelligence and Education , C . Frasson and G . Gauthier , eds . , 1990 , pp . 266 – 282 . 16 . N . Stephenson , The Diamond Age : Or , a Young Lady’s Illustrated Primer , Bantam Spectra , 1995 . Gord McCalla is a computer scientist and professor in the ARIES Lab , Department of Computer Science , University of Saskatch - ewan , Saskatoon , Canada . Contact him at mccalla @ cs . usask . ca . John Champaign is a postdoctoral re - search fellow at the Massachusetts Institute of Technology . Contact him at jchampai @ mit . edu . Selected CS articles and columns are also available for free at http : / / ComputingNow . computer . org . stay connected . Keep up with the latest IEEE Computer Society publications and activities wherever you are . | IEEE Computer Society | Computing Now | facebook . com / IEEEComputerSociety | facebook . com / ComputingNow | @ ComputerSociety | @ ComputingNow | youtube . com / ieeecomputersociety IS - 28 - 04 - Education . indd 71 16 / 10 / 13 7 : 03 PM