HAL Id : tel - 01687719 https : / / tel . archives - ouvertes . fr / tel - 01687719 Submitted on 18 Jan 2018 HAL is a multi - disciplinary open access archive for the deposit and dissemination of sci - entific research documents , whether they are pub - lished or not . The documents may come from teaching and research institutions in France or abroad , or from public or private research centers . L’archive ouverte pluridisciplinaire HAL , est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche , publiés ou non , émanant des établissements d’enseignement et de recherche français ou étrangers , des laboratoires publics ou privés . Recherche d’information clinomique dans le Dossier Patient Informatisé : modélisation , implantation et évaluation . Chloé Cabot To cite this version : Chloé Cabot . Recherche d’information clinomique dans le Dossier Patient Informatisé : modélisation , implantation et évaluation . . Traitement du texte et du document . Normandie Université , 2017 . Français . ￿NNT : 2017NORMR041￿ . ￿tel - 01687719￿ THÈSE Pour obtenir le diplôme de doctorat Spécialité informatique Préparée au sein de l’Université Rouen Normandie Recherche d’information clinomique au sein du Dossier Patient Informatisé : modélisation , implantation et évaluation Présentée et soutenue par Chloé CABOT Thèse dirigée par : Pr . Stéfan Darmoni , LITIS EA4108 , Université de Rouen Normandie Dr . Lina Soualmia , LITIS EA4108 , Université de Rouen Normandie Thèse soutenue publiquement le 21 décembre 2017 devant le jury composé de M . Stéfan Darmoni PUPH , Université Rouen Normandie Directeur de thèse Mme Lorraine Goeuriot MCU , Université Grenoble Alpes Examinateur Mme Marie - Christine Jaulent DR , LIMICS Inserm U1142 Rapporteur Mme Lina Soualmia MCU , HDR , Université Rouen Normandie Codirectrice de thèse M . Laurent Vercouter PU , INSA Rouen Normandie Examinateur M . Pierre Zweigenbaum DR , LIMSI CNRS UPR3251 Rapporteur ii Résumé Les objectifs de cette thèse s’inscrivent dans la large problématique de recherche d’in - formation dans les données issues du Dossier Patient Informatisé ( DPI ) . Les aspects abordés dans cette problématique sont multiples : d’une part la mise en œuvre d’une recherche d’information clinomique au sein du DPI et d’autre part la recherche d’in - formation au sein de données non structurées issues du DPI . Dans un premier temps , l’un des objectifs de cette thèse est d’intégrer au sein du DPI des informations dépassant le cadre de la médecine pour intégrer des données , in - formations et connaissances provenant de la biologie moléculaire ; les données omiques , issues de la génomique , protéomique ou encore métabolomique . L’intégration de ce type de données permet d’améliorer les systèmes d’information en santé , leur interopérabi - lité ainsi que le traitement et l’exploitation des données à des ﬁns cliniques . Un enjeu important est d’assurer l’intégration de données hétérogènes , grâce à des recherches sur les modèles conceptuels de données , sur les ontologies et serveurs terminologiques et sur les entrepôts sémantiques . L’intégration de ces données et leur interprétation selon un même modèle de données conceptuel sont un verrou important . Enﬁn , il est important d’intégrer recherche clinique et recherche fondamentale aﬁn d’assurer une continuité des connaissances entre recherche et pratique clinique et aﬁn d’appréhender la problématique de personnalisation des soins . Cette thèse aboutit ainsi à la concep - tion et au développement d’un modèle générique des données omiques exploité dans une application prototype de recherche et visualisation dans les données omiques et cliniques d’un échantillon de 2 000 patients . Le second objectif de ma thèse est l’indexation multi terminologique de docu - ments médicaux à travers le développement de l’outil Extracteur de Concepts Multi - Terminologique ( ECMT ) . Il exploite les terminologies intégrées au portail terminolo - gique Health Terminology / Ontology Portal ( HeTOP ) pour identiﬁer des concepts dans des documents non structurés . Ainsi , à partir d’un document rédigé par un humain , et donc porteur potentiellement d’erreurs de frappe , d’orthographe ou de grammaire , l’enjeu est d’identiﬁer des concepts et ainsi structurer l’information contenue dans le document . Pour la recherche d’information médicale , l’indexation présente un inté - rêt incontournable pour la recherche dans les documents non structurés , comme les comptes - rendus de séjour ou d’examens . Cette thèse propose plusieurs méthodes et leur évaluation suivant deux axes : l’indexation de textes médicaux à l’aide de plusieurs terminologies et le traitement du langage naturel dans les textes médicaux narratifs . Mots - clés : Recherche d’information , Dossiers patients informatisés , Modélisation , Extraction d’information , Vocabulaires contrôlés , Traitement du langage naturel iii iv Abstract The aim of this thesis is part of the broad issue of information retrieval in Electronic Health Records ( EHRs ) . The aspects tackled in this topic are numerous : on the one hand clinomics information retrieval within EHRs and secondly information retrieval within unstructured data from EHRs . As a ﬁrst step , one of the objectives is to integrate in EHRs information beyond the scope of medicine to integrate data , information and knowledge from molecular biology ; omic data from genomics , proteomics or metabolomics . The integration of this type of data improves health information systems , their interoperability and the processing and exploitation of data for clinical purposes . An important challenge is to ensure the integration of heterogeneous data , through research on conceptual models of data , ontology and terminology servers , and semantic data warehouses . The integration of this data and their interpretation into a conceptual data model is an important challenge . Finally , it is important to integrate clinical research and fundamental research in order to ensure continuity of knowledge between research and clinical practice and to understand personalized medicine challenges . This thesis thus leads to the design and development of a generic model of omics data exploited in a prototype application for information retrieval and visualization in omic and clinical data within a sample of 2 , 000 patients . The second objective of this thesis is the multi - terminological indexing of medi - cal documents through the development of the Extracting Concepts with Multiple Terminologies tool ( ECMT ) . It uses terminologies embedded in the Health Termino - logy / Ontology Portal ( HeTOP ) to identify concepts in unstructured documents . From a document written by a human , and therefore potentially showing typing errors , spel - ling or grammar mistakes , the challenge is to identify concepts and thus structure the information contained in the text . In health information retrieval , indexing is of great interest for information retrieval in unstructured documents , such as reports and me - dical notes . This thesis proposes several methods and their evaluation along two axes : the indexing of medical texts using several terminologies and the processing of natural language in narrative medical notes . Keywords : Information Retrieval , Electronic Health Records , Modelling , Information Extraction , Controlled Vocabularies , Natural Language Processing v vi Remerciements Tout d’abord , je tiens à remercier le Professeur Stéfan Darmoni pour la conﬁance qu’il m’a témoignée , sa disponibilité et sa bonne humeur au quotidien . Je voudrais également vivement remercier le Docteur Lina Soualmia pour son aide précieuse et ses nombreux conseils tout au long de cette thèse . Leur soutien m’a été indispensable pour avancer pendant ces trois années . J’adresse également mes sincères remerciements aux membres du jury le Professeur Laurent Vercouter et les Docteurs Lorraine Goeuriot , Marie - Christine Jaulent et Pierre Zweigenbaum pour avoir accepté d’évaluer ce travail . Je tiens aussi à remercier toute l’équipe CISMeF qui m’a accueillie il y a cinq ans pour la sympathie qu’ils m’ont témoignée . Un grand merci à Julien pour son aide indéfectible depuis mon master , à Badisse , Benoît , Nicolas , Ivan , Catherine , Gaétan et Tayeb pour leurs conseils avisés , à Sandrine , Quentin , Arthur , Matthieu et enﬁn Adila et Romain qui m’ont supportée à leurs côtés . Je remercie également l’équipe du LITIS pour avoir accueilli ces recherches . Un merci tout particulier à Alexis , Amandine , Chadi , Mélissa , Adrien , Johann , Raphaël , Laura et Alexandre pour leur amitié , leurs rires et nos discussions tardives . Enﬁn , je voudrais remercier ma famille pour leur soutien et leurs encouragements et en particulier ma mère , qui a su me guider jusqu’ici et mes soeurs , Marion , pourtant bien occupée par les nouveaux membres de la famille , et Cyrielle , qui m’a accompagnée – parfois littéralement – dans mes pérégrinations . Pour terminer , merci à tous ceux , humains ou presque , qui m’ont aidé à mener à bien ce travail et se reconnaîtront dans ces quelques lignes . vii viii Table des matières Table des matières ix Liste des ﬁgures xiii Liste des tableaux xv Liste des acronymes xvii 1 Introduction 1 1 . 1 Préambule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . 2 Contexte de recherche . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1 . 2 . 1 Projet PlaIR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1 . 2 . 2 Projet RIDoPI . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1 . 3 Contexte de travail . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1 . 3 . 1 L’équipe TIBS . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1 . 3 . 2 L’informatique biomédicale . . . . . . . . . . . . . . . . . . . . . 4 1 . 3 . 3 La recherche translationnelle . . . . . . . . . . . . . . . . . . . . 5 1 . 4 Objectifs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1 . 5 Organisation du mémoire . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2 La recherche d’information en santé 9 2 . 1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2 . 1 . 1 L’information en santé . . . . . . . . . . . . . . . . . . . . . . . 11 2 . 1 . 2 La recherche d’information dans le domaine de la santé . . . . . 12 2 . 2 Les ressources en santé et sciences biomédicales . . . . . . . . . . . . . 13 2 . 2 . 1 Ressources bibliographiques . . . . . . . . . . . . . . . . . . . . 14 2 . 2 . 2 Contenus en texte intégral . . . . . . . . . . . . . . . . . . . . . 15 2 . 2 . 3 Bases de données . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2 . 2 . 4 Agrégations de ressources . . . . . . . . . . . . . . . . . . . . . 17 2 . 3 La représentation des données en santé . . . . . . . . . . . . . . . . . . 17 2 . 3 . 1 Représentation des connaissances et vocabulaires contrôlés . . . 18 2 . 3 . 2 Données cliniques et Dossiers Patients Informatisés . . . . . . . 26 ix TABLE DES MATIÈRES 2 . 3 . 3 Données biologiques et recherche translationnelle . . . . . . . . 31 2 . 4 Entrepôts de données et plateformes de recherche biomédicales . . . . . 32 2 . 4 . 1 Plateformes et entrepôts de données cliniques . . . . . . . . . . 33 2 . 4 . 2 Plateformes et entrepôts de recherche translationnelle . . . . . . 34 2 . 4 . 3 Comparaison des plateformes existantes . . . . . . . . . . . . . 36 2 . 5 L’indexation de textes médicaux . . . . . . . . . . . . . . . . . . . . . . 38 2 . 5 . 1 Concepts , bases et déﬁnitions . . . . . . . . . . . . . . . . . . . 38 2 . 5 . 2 L’extraction de termes cliniques dans des textes médicaux . . . 40 2 . 5 . 3 Détection des modiﬁcateurs . . . . . . . . . . . . . . . . . . . . 42 2 . 5 . 4 Outils d’indexation existants . . . . . . . . . . . . . . . . . . . . 44 2 . 6 La recherche d’information en santé . . . . . . . . . . . . . . . . . . . . 46 2 . 6 . 1 Concepts , bases et déﬁnitions . . . . . . . . . . . . . . . . . . . 46 2 . 6 . 2 Historique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 2 . 6 . 3 Modèles de recherche d’information . . . . . . . . . . . . . . . . 48 2 . 6 . 4 La reformulation de requête . . . . . . . . . . . . . . . . . . . . 56 2 . 7 Évaluation des systèmes de recherche d’information en santé . . . . . . 58 2 . 7 . 1 Métriques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 2 . 7 . 2 Campagnes de test et évaluation . . . . . . . . . . . . . . . . . . 60 2 . 8 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 3 Modélisation de données omiques et cliniques pour le Dossier Patient Informatisé 63 3 . 1 L’intégration de données hétérogènes . . . . . . . . . . . . . . . . . . . 64 3 . 2 Le projet RAVEL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 3 . 2 . 1 Le modèle de données RAVEL . . . . . . . . . . . . . . . . . . . 66 3 . 2 . 2 Données cliniques . . . . . . . . . . . . . . . . . . . . . . . . . . 67 3 . 3 Collecte de données omiques . . . . . . . . . . . . . . . . . . . . . . . . 68 3 . 3 . 1 Bases de connaissances . . . . . . . . . . . . . . . . . . . . . . . 68 3 . 3 . 2 Données expérimentales . . . . . . . . . . . . . . . . . . . . . . 69 3 . 4 Recensement des types de données omiques . . . . . . . . . . . . . . . . 70 3 . 4 . 1 Les diﬀérents types de données omiques . . . . . . . . . . . . . . 70 3 . 4 . 2 Niveaux d’interprétation des données omiques . . . . . . . . . . 71 3 . 5 Modèle de données omiques . . . . . . . . . . . . . . . . . . . . . . . . 74 3 . 5 . 1 Gestion des études omiques . . . . . . . . . . . . . . . . . . . . 74 3 . 5 . 2 Gestion des données d’expression et de quantiﬁcation . . . . . . 75 3 . 5 . 3 Gestion des données de variants . . . . . . . . . . . . . . . . . . 75 3 . 6 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 x TABLE DES MATIÈRES 4 Recherche d’information dans les données cliniques et omiques au sein du Dossier Patient Informatisé 79 4 . 1 Intégration de données cliniques et omiques . . . . . . . . . . . . . . . 80 4 . 1 . 1 Choix des ressources à intégrer . . . . . . . . . . . . . . . . . . 80 4 . 1 . 2 Intégration de terminologies et ontologies au sein du méta - modèle 3M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 1 . 3 Données de référence . . . . . . . . . . . . . . . . . . . . . . . . 82 4 . 1 . 4 Données expérimentales . . . . . . . . . . . . . . . . . . . . . . 85 4 . 1 . 5 Lien avec les données cliniques . . . . . . . . . . . . . . . . . . . 87 4 . 2 Recherche d’information clinomique . . . . . . . . . . . . . . . . . . . . 87 4 . 2 . 1 Moteur de recherche CISMeF . . . . . . . . . . . . . . . . . . . 87 4 . 2 . 2 Requête dans les données omiques . . . . . . . . . . . . . . . . . 90 4 . 3 Résultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 4 . 3 . 1 Comparatif face aux solutions existantes : i2b2 et tranSMART . 93 4 . 3 . 2 Cas clinique RAVEL en rhumatologie : polyarthrite rhumatoïde 98 4 . 4 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 5 Indexation multi - terminologique de documents biomédicaux 103 5 . 1 Le serveur multi - terminologique HeTOP . . . . . . . . . . . . . . . . . 104 5 . 1 . 1 Un serveur multiterminologique et interlingue . . . . . . . . . . 104 5 . 1 . 2 Terminologies et ontologies disponibles . . . . . . . . . . . . . . 106 5 . 2 L’Extracteur de Concepts Multi - Terminologique ( ECMT ) . . . . . . . . 107 5 . 2 . 1 Détection des concepts . . . . . . . . . . . . . . . . . . . . . . . 107 5 . 2 . 2 Exploitation des réseaux sémantiques . . . . . . . . . . . . . . . 109 5 . 3 Évaluation de l’indexation au sein des corpus MEDLINE et EMEA . . 112 5 . 3 . 1 Description des tâches . . . . . . . . . . . . . . . . . . . . . . . 112 5 . 3 . 2 Sources de données . . . . . . . . . . . . . . . . . . . . . . . . . 113 5 . 3 . 3 Résultats CLEF e - Health 2015 . . . . . . . . . . . . . . . . . . . 114 5 . 3 . 4 Résultats CLEF e - Health 2016 . . . . . . . . . . . . . . . . . . . 116 5 . 3 . 5 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 5 . 4 Évaluation de la couverture terminologique au sein du corpus LiSSa . . 120 5 . 4 . 1 Le corpus LiSSa . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 5 . 4 . 2 Création du gold standard . . . . . . . . . . . . . . . . . . . . . 121 5 . 4 . 3 Annotation manuelle . . . . . . . . . . . . . . . . . . . . . . . . 121 5 . 4 . 4 Évaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 5 . 5 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 6 Indexation de textes libres dans les documents médicaux 131 6 . 1 Indexation appliquée aux textes libres médicaux . . . . . . . . . . . . . 132 6 . 1 . 1 L’indexation de textes médicaux narratifs . . . . . . . . . . . . 132 xi TABLE DES MATIÈRES 6 . 1 . 2 La reconnaissance partielle de texte : mesures de similarité . . . 133 6 . 1 . 3 L’approche phonétique . . . . . . . . . . . . . . . . . . . . . . . 138 6 . 2 Sources de données . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 6 . 2 . 1 Le corpus français CépiDC . . . . . . . . . . . . . . . . . . . . . 141 6 . 2 . 2 Le corpus anglais CDC . . . . . . . . . . . . . . . . . . . . . . . 142 6 . 2 . 3 Dictionnaires . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143 6 . 3 Extraction d’information dans des textes libres médicaux à l’aide de la CIM - 10 : CIM - IND . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 6 . 3 . 1 Pré - traitements . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 6 . 3 . 2 Sélection des candidats . . . . . . . . . . . . . . . . . . . . . . . 145 6 . 3 . 3 Classement des candidats . . . . . . . . . . . . . . . . . . . . . 146 6 . 4 Application aux corpus CépiDC et CDC . . . . . . . . . . . . . . . . . 147 6 . 4 . 1 Compétition CLEF eHealth 2016 . . . . . . . . . . . . . . . . . 147 6 . 4 . 2 Compétition CLEF eHealth 2017 . . . . . . . . . . . . . . . . . 149 6 . 4 . 3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 6 . 5 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 7 Conclusion et perspectives 155 Liste des publications 159 A Annexes I A . 1 Figures annexes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . I A . 2 Tableaux annexes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . III Bibliographie V xii Liste des ﬁgures 1 . 1 Organisation générale de la Plateforme d’Indexation Régionale . . . . . . 3 2 . 1 Structure du descripteur Osteoarthritis dans le MeSH version 2016 : descripteur , concepts et termes . . . . . . . . . . . . . . . . . . . . . . . 19 2 . 2 La notion de concept au sein du Metathesaurus® UMLS ( adapté de Kleinsorge et Willis [ 2008 ] ) . . . . . . . . . . . . . . . . . . . . . . . 21 2 . 3 Exemple de structure d’un concept avec C0018681 Headache ( adapté de Kleinsorge et Willis [ 2008 ] ) . . . . . . . . . . . . . . . . . . . . . . . 22 2 . 4 Répartition des catégories de concepts dans l’ontologie SNOMED CT . . 26 2 . 5 Hiérarchie du concept Pneumonie virale . . . . . . . . . . . . . . . . . . 27 2 . 6 Répartition des termes dans les trois ontologies de la Gene Ontology . . 27 2 . 7 Les principales sciences omiques et leurs méthodes d’étude . . . . . . . . 31 2 . 8 Processus général de la recherche documentaire . . . . . . . . . . . . . . 47 2 . 9 Représentation vectorielle de l’espace de documents . . . . . . . . . . . . 51 2 . 10 Un arbre de dépendance entre termes . . . . . . . . . . . . . . . . . . . 54 3 . 1 Modèle physique des données RAVEL . . . . . . . . . . . . . . . . . . . 67 3 . 2 Exemple de ﬁchier de données issu de la base de données TGCA . . . . . 69 3 . 3 Modèle logique des données omiques . . . . . . . . . . . . . . . . . . . . 76 4 . 1 Processus d’intégration des données externes . . . . . . . . . . . . . . . . 83 4 . 2 Capture d’écran de la page de description d’une pathologie OMIM : le cancer du sein . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 4 . 4 Traitement des données omiques expérimentales . . . . . . . . . . . . . . 86 4 . 5 Intégration des données omiques expérimentales . . . . . . . . . . . . . . 87 4 . 6 Représentation en arbre de la requête stay ( patient ( birthDate = 1937 - 01 - 01 AND gender = " M " ) AND entryDate = 2010 - 03 - 10 ) . . . . . . . . . . . . . 88 4 . 7 Capture d’écran du prototype RAVEL . . . . . . . . . . . . . . . . . . . 91 4 . 8 Détail concernant le gène SAGE1 depuis l’interface de visualisation des données omiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 4 . 9 Détail concernant l’étude « miRNA Analysis of TCGA GBM Samples »de - puis l’interface de visualisation des données omiques . . . . . . . . . . . 93 xiii LISTE DES FIGURES 4 . 10 Interface du workbench i2b2 . . . . . . . . . . . . . . . . . . . . . . . . . 94 4 . 11 Interface du client web tranSMART . . . . . . . . . . . . . . . . . . . . 95 5 . 1 L’interface utilisateur de l’ECMT et ses options . . . . . . . . . . . . . . 110 5 . 2 Exemple du traitement de la phrase « Cholestases intrahépatiques ﬁbro - gènes familiales et anomalies héréditaires du métabolisme hépatocytaire des acides biliaires » avec l’ECMT et l’option de priorisation activée . . 110 5 . 3 Exemple du traitement de la phrase « Cholestases intrahépatiques ﬁbro - gènes familiales et anomalies héréditaires du métabolisme hépatocytaire des acides biliaires » avec l’ECMT et l’option de priorisation désactivée . 111 5 . 4 Fichier d’annotation au format BRAT contenant des entités extraites par l’ECMT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 5 . 5 Interface de l’outil d’annotation manuelle LiSSa . . . . . . . . . . . . . . 122 5 . 6 Représentation graphique de la couverture terminologique des 32 termi - nologies et ontologies analysées dans le corpus LiSSa . . . . . . . . . . . 124 6 . 1 Extraits de certiﬁcats de décès en français dans le corpus CépiDC . . . . 143 6 . 2 Extraits de certiﬁcats de décès en anglais dans le corpus CDC . . . . . . 143 6 . 3 Modèle de données physique du système CIM - IND . . . . . . . . . . . . 146 A . 1 Le modèle physique du système d’information CISMeF . . . . . . . . . II xiv Liste des tableaux 2 . 1 Métriques générales de la version 2016AB du Metathesaurus® UMLS . . 21 2 . 2 Métriques générales de la version 2016AB du Metathesaurus® UMLS par langue ( seules les langues représentant plus de 2 % du Metathesaurus® sont ici détaillées ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2 . 3 Exemples de catégories incluses dans la CIM10 . . . . . . . . . . . . . . 24 2 . 4 Barrières à l’adoption , au déploiement et à l’utilisation des DPI ( adapté de Archer et al . [ 2011 ] ) . . . . . . . . . . . . . . . . . . . . . . . . . . 30 3 . 1 Les diﬀérents types de données en sciences omiques . . . . . . . . . . . . 70 3 . 2 Les diﬀérents types de niveaux d’interprétation des données omiques . . 72 3 . 3 Description du niveau d’interprétation 3 pour les principaux types de données omiques sélectionnés pour concevoir le modèle de données . . . 74 4 . 1 Exemples de requêtes omiques . . . . . . . . . . . . . . . . . . . . . . . 89 4 . 2 Analyse fonctionnelle des outils RAVEL et i2b2 v1 . 7 . 06 . . . . . . . . . . 96 4 . 3 Analyse fonctionnelle des outils RAVEL et tranSMART v16 . 2 . . . . . . 97 4 . 4 Réponse au cas d’usage PR RAVEL . . . . . . . . . . . . . . . . . . . . 100 5 . 1 Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités . . . . . . . . . 115 5 . 2 Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités normalisées . . 115 5 . 3 Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités . . . . . . . 116 5 . 4 Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités normalisées . 116 5 . 5 Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités . . . . . . . . . 117 5 . 6 Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités normalisées . . 117 5 . 7 Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités . . . . . . . 118 xv LISTE DES TABLEAUX 5 . 8 Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités normalisées . 118 5 . 9 Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 2 ( EMEA ) - Normalisation . . . . . . . . . . . . . . . 118 5 . 10 Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 2 ( MEDLINE ) - Normalisation . . . . . . . . . . . . . 119 5 . 11 Comparatif des résultats CLEF eHealth 2015 et 2016 ( série 2 ) obtenus avec l’ECMT dans la tâche de reconnaissance d’entités sur le corpus MEDLINE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 5 . 12 Comparatif des résultats CLEF eHealth 2015 et 2016 ( série 2 ) obtenus avec l’ECMT dans la tâche de reconnaissance d’entités sur le corpus EMEA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 5 . 13 Couverture terminologique dans le corpus LiSSa pour chaque catégorie de documents : titres , résumés , mots - clés . . . . . . . . . . . . . . . . . . 126 5 . 14 Couverture terminologique par concepts distincts dans le corpus LiSSa pour chaque catégorie de documents : titres , résumés , mots - clés . . . . . 127 5 . 15 Résultats de l’évaluation de l’indexation automatique réalisée par l’ECMT contre le gold standard . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 6 . 1 Comparaison des méthodes de similarité sur le corpus CépiDC . . . . . . 148 6 . 2 Résultats de CIM - IND sur le corpus CépiDC - CLEF eHealth 2016 . . . 148 6 . 3 Résultats du challenge CLEF eHealth 2016 par équipe pour la tâche de codage CIM10 sur le corpus CépiDC ( de Névéol et al . [ 2016 ] ) . . . . . 148 6 . 4 Résultats de CIM - IND pour chaque jeu de données français CépiDC et anglais CDC - CLEF eHealth 2017 . . . . . . . . . . . . . . . . . . . . . 149 6 . 5 Résultats du challenge CLEF eHealth 2017 par équipe pour la tâche de codage CIM10 sur le jeu de données brut CépiDC français ( de Névéol et al . [ 2017 ] ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 6 . 6 Résultats du challenge CLEF eHealth 2017 par équipe pour la tâche de codage CIM10 sur le jeu de données aligné CépiDC français ( de Névéol et al . [ 2017 ] ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 6 . 7 Résultats du challenge CLEF eHealth 2017 par équipe pour la tâche de codage CIM10 sur le jeu de données CDC anglais ( de Névéol et al . [ 2017 ] ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152 A . 1 Les principales terminologies et ontologies ( n = 32 ) disponibles dans le portail HeTOP ( nombre de termes en français total n = 653 , 392 ) . . . III xvi Liste des acronymes ADICAP Association pour le Développement de l’Informatique en Cytologie et en Anatomie Pathologiques . III , 126 , 127 ANR Agence Nationale de la Recherche . 4 , 156 ANSI American National Standards Institute . 27 ATC Anatomical Therapeutic Chemical classiﬁcation . III , 106 , 116 , 123 , 126 , 127 , 129 ATIH Agence Technique de l’Information sur l’Hospitalisation . 23 , 106 AUI Atom Unique Identiﬁer . 20 BNCI Base Nationale des Cas d’Intoxications . III , 126 , 127 caBIG cancer Biomedical Informatics Grid . 33 CAC Champ Aléatoire Conditionnel . 39 – 42 caTRIP Cancer Translational Research Information Platform . 33 CCAM Classiﬁcation Commune des Actes Médicaux . III , 44 , 68 , 105 , 106 , 116 , 126 , 127 CDP C Page Dossier Patient . 67 CGH Comparative Genomic Hybridization . 70 , 71 , 87 , 91 CIF Classiﬁcation Internationale du Fonctionnement , du handicap et de la santé . III , 126 , 127 CIM10 Classiﬁcation Internationale des Maladies , 10 e révision . III , 22 , 23 , 32 , 36 , 44 , 61 , 68 , 87 , 90 , 97 , 101 , 105 , 106 , 109 , 112 , 116 , 126 , 127 , 129 , 141 – 146 , 149 , 150 , 152 , 153 CISMeF Catalogue et Index des Sites Médicaux de langue Française . III , 126 , 127 CLADIMED CLAssiﬁcation des DIspositifs MÉDicaux . III , 126 , 127 CNV Copy Number Variation . 71 CUI Concept Unique Identiﬁer . 20 , 109 , 112 – 115 , 117 , 120 DPI Dossier Patient Informatisé . 2 , 4 – 7 , 25 – 28 , 31 , 32 , 37 , 61 , 66 , 76 , 90 , 93 , 94 , 98 , 101 , 107 , 155 , 157 xvii Liste des acronymes DSM - IV Diagnostic and Statistical Manual of Mental Disorders , 4th Edition , Text Revision . III , 126 , 127 ECMT Extracteur de Concepts Multi Terminologique . 7 , 104 , 105 , 107 – 109 , 112 , 114 – 116 , 119 , 121 – 123 , 129 , 153 , 156 FMA Foundational Model of Anatomy . III , 106 , 116 , 126 , 127 GEO Gene Expression Omnibus . 73 GO Gene Ontology . III , 24 , 68 , 126 , 127 GWAS Genome - Wide Association Study . 33 HeTOP Health Terminology / Ontology Portal . 4 , 80 , 81 , 84 , 100 , 104 – 107 , 109 , 117 , 120 , 156 , 157 HGVS Human Genome Variation Society . 71 HL7 Health Level - 7 . 27 HL7 - CCOW HL7 Clinical Context Object Workgroup . 27 HL7 - CDA HL7 Clinical Document Architecture . 27 HL7 - RIM HL7 Reference Information Model . 27 , 32 HPO Human Phenotype Ontology . III , 106 , 109 , 116 , 126 , 127 HRDO Human Rare Diseases Ontology . III , 123 , 126 , 127 i2b2 Informatics for Integrating Biology and the Bedside . 32 , 33 , 80 , 93 – 95 , 101 ICD - O International Classiﬁcation of Diseases for Oncology . III , 126 , 127 ICNP International Classiﬁcation for Nursing Practice . III , 109 , 126 , 127 ICPC - 2 International Classiﬁcation for Patient Safety . III , 116 , 126 , 127 IDF Inverse Document Frequency . 47 , 51 , 53 , 85 indel Insertion - Délétion . 30 ISO Organisation internationale de normalisation . 27 LiSSa Littérature Scientiﬁque en Santé . 13 , 14 , 104 , 120 , 121 , 129 , 157 LOH Loss Of Heterozygosity . 31 LOINC Logical Observation Identiﬁers Names and Codes . III , 36 , 97 , 106 , 126 , 127 LPP Liste des Produits et des Prestations . III , 126 , 127 LUI Lexical ( term ) Unique Identiﬁer . 20 MedDRA MEDical Dictionary for Regulatory Activities terminologies . III , 106 , 123 , 125 – 128 xviii Liste des acronymes MEDLINE Medical Literature Analysis and Retrieval System Online . 11 , 13 , 16 , 43 MeSH Medical Subject Headings . III , 17 – 19 , 43 , 44 , 61 , 90 , 95 , 97 , 105 , 106 , 108 , 109 , 112 , 116 , 123 , 125 – 129 MVS Machine à vecteurs de support . 40 , 42 , 43 NCBI National Center for Biotechnology Information . 15 , 16 , 68 , 69 , 75 , 81 , 82 , 84 , 91 , 97 , 100 NCIt National Cancer Institute thesaurus . III , 106 , 109 , 112 , 116 , 123 , 125 – 128 NGS Next Generation Sequencing . 30 NIH National Institutes of Health . 16 , 69 NLM National Library of Medicine . 11 , 13 , 14 , 16 , 17 , 19 , 43 OMIM Online Mendelian Inheritance in Man . III , 69 , 75 , 76 , 81 , 84 , 100 , 116 , 126 , 127 OMS Organisation mondiale de la Santé . 106 PHARMA Racines des médicaments . III , 116 , 126 , 127 PlaIR Plateforme d’Indexation Régionale . 2 , 3 , 7 , 156 PMSI Programme de Médicalisation des Systèmes d’Information . 68 RAVEL Retrieval And Visualization in ELectronic health records . 4 , 64 , 66 , 67 , 75 , 76 , 80 , 82 , 87 , 90 , 91 , 98 , 101 , 156 RDF Resource Description Framework . 17 RI Recherche d’Information . 4 , 5 , 10 , 11 , 13 , 16 , 17 , 37 , 45 – 49 , 51 – 58 , 60 , 61 , 100 , 107 , 133 RIDoPI Recherche d’Information dans le Dossier Patient Informatisé . 2 , 4 SIH Système d’Information Hospitalier . 27 SNOMED CT Systematized Nomenclature of Medicine Clinical Terms . IV , 23 , 24 , 32 , 41 , 44 , 61 , 90 , 100 , 106 , 123 , 125 – 128 SNOMED Int . Systematized Nomenclature of Medicine . IV , 109 , 116 , 123 , 126 , 127 SNP Single Nucleotid Polymorphism . 71 , 74 , 75 , 91 SNV Single Nucleotide Variation . 30 SOC Système d’Organisation des Connaissances . 17 , 21 , 37 , 61 SRI Système de Recherche d’Information . 57 – 59 , 155 SUI String Unique Identiﬁer . 20 , 21 SV Structural Variant . 71 xix Liste des acronymes SYNODOS SYstème de Normalisation et d’Organisation de Données médicales tex - tuelles pour l’Observation en Santé . IV , 126 , 127 TAL Traitement Automatique de la Langue . 35 , 37 , 39 TecSAN Technologies pour la Santé . 4 , 156 TF - IDF Term Frequency - Inverse Document Frequency . 50 , 51 , 136 TGCA The Genome Cancer Atlas . 69 , 73 , 87 TSP Thésaurus Santé Publique . IV , 123 , 125 – 129 UCUM The Uniﬁed Code for Units of Measure . IV , 126 , 127 UMLS Uniﬁed Medical Language System . 19 – 21 , 23 , 24 , 37 , 41 , 42 , 44 , 56 , 61 , 106 , 107 , 112 , 113 , 115 , 118 – 120 , 129 WHO - ART Adverse Reactions Terminology . 129 XML eXtensible Markup Language . 17 , 27 , 68 , 82 , 83 , 85 , 107 , 108 , 114 XSD XML Schema Deﬁnition . 85 xx Chapitre 1 Introduction Sommaire 1 . 1 Préambule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . 2 Contexte de recherche . . . . . . . . . . . . . . . . . . . . . 2 1 . 2 . 1 Projet PlaIR . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1 . 2 . 2 Projet RIDoPI . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1 . 3 Contexte de travail . . . . . . . . . . . . . . . . . . . . . . . 3 1 . 3 . 1 L’équipe TIBS . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1 . 3 . 2 L’informatique biomédicale . . . . . . . . . . . . . . . . . . . 4 1 . 3 . 3 La recherche translationnelle . . . . . . . . . . . . . . . . . . 5 1 . 4 Objectifs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1 . 5 Organisation du mémoire . . . . . . . . . . . . . . . . . . . . 7 1 . 1 Préambule L’utilisation de données issues de la pratique clinique et de la recherche est un déﬁ majeur dans le domaine de la santé . Dans le domaine numérique , l’intégration de don - nées omiques et de données cliniques dans le Dossier Patient Informatisé ( DPI ) , mais également dans des portails de ressources terminologiques peut permettre le dévelop - pement de nouveaux tests et thérapies , mais également de comprendre les maladies génétiques complexes , voire des cancers . L’objectif de cette thèse est de proposer un modèle permettant l’intégration de ce type de données complexes , de les intégrer dans le DPI et d’en évaluer l’eﬃcacité dans le contexte de la recherche d’information à grande échelle . 1 CHAPITRE 1 . INTRODUCTION 1 . 2 Contexte de recherche Les travaux présentés dans la suite de cette section portent sur l’ingénierie des connaissances , et plus particulièrement sur la gestion des vocabulaires contrôlés pour le stockage et l’organisation des connaissances et leur exploitation dans l’indexation de documents et la recherche d’information . Dans ce contexte , plusieurs projets ont été conduits et se poursuivent aujourd’hui . Deux projets sont détaillés ici , les projets Plateforme d’Indexation Régionale ( PlaIR ) et Recherche d’Information dans le Dossier Patient Informatisé ( RIDoPI ) , qui sont à l’origine de cette thèse . 1 . 2 . 1 Projet PlaIR PlaIR ( Plateforme d’Indexation Régionale ) 1 est un projet de recherche coﬁnancé par l’Union Européenne et la région Haute - Normandie ( FEDER pour Fonds Européens DÉveloppement Régional ) . Coordonné par l’équipe « DocApp » ( Document et Appren - tissage ) du LITIS , PlaIR I s’est déroulé de 2009 à 2012 et avait pour but de mutualiser un ensemble de ressources documentaires numériques et numérisées et les bibliothèques logicielles d’analyse automatique ou semi - automatique de ces ressources pour constituer une plateforme d’indexation et de recherche d’information multi - domaines et multi - usages ( voir Figure 1 . 1 ) . Le premier axe du projet consistait en la reconnaissance de caractères imprimés sur des journaux anciens numérisés et en l’élaboration d’une plateforme de visualisation de ces documents . Le second axe avait pour but de réaliser une plateforme pour aider à l’indexation en multi - terminologies et en multi - disciplines . Il s’agissait donc d’étendre le modèle multi - terminologique conçu lors du projet Inter - opérabilité Sémantique des Terminologies dans les Systèmes d’Information de Santé Français ( InterSTIS ) et consolidé par l’équipe Traitement de l’Information en Biologie Santé ( TIBS ) pour assurer ses fonctionnalités et sa validité à d’autres domaines que celui de la Santé et plus précisément pour le Droit du Transport et les Sciences de l’ingénieur . Ces travaux du passage de la mono - terminologie à la multi - terminologie sont décrits dans la thèse de Julien Grosjean [ Grosjean , 2014 ] . Dans PlaIR II , l’objectif est d’améliorer quantitativement et qualitativement le portail de ressources terminologiques largement développé pendant le projet PlaIR I . Le principal axe est d’intégrer dans ce portail des informations dépassant la médecine pour intégrer des données , informations et connaissances provenant de la biologie , ce que nous résumons par les données « omiques » ( génomique , protéomique , métabolomique , etc . ) . 1 . http : / / plair . projets . litislab . fr 2 CHAPITRE 1 . INTRODUCTION Figure 1 . 1 – Organisation générale de la Plateforme d’Indexation Régionale . 1 . 2 . 2 Projet RIDoPI Depuis 2011 , l’équipe TIBS s’intéresse à la problématique de la Recherche d’Infor - mation ( RI ) dans le DPI dans le cadre du projet RIDoPI . Ce projet a initié un programme de recherche Technologies pour la Santé ( TecSAN ) de l’Agence Nationale de la Recherche ( ANR ) ( 2012 – 2015 ) : le projet Retrieval And Visualization in ELectronic health records ( RAVEL ) . Son objectif est de rechercher et d’implémenter des méthodes d’indexation dans le but d’enrichir sémantiquement les données structurées et non structurées au sein du DPI , aﬁn d’optimiser la RI et la visualisation des données cliniques [ Thiessard et al . , 2012 ] . Ce projet réunit des partenaires académiques et industriels . L’équipe TIBS a été en particulier responsable du modèle de données et de la RI . 1 . 3 Contexte de travail Dans cette section , je présente l’équipe TIBS , ses travaux de recherche , ainsi que les problématiques et objectifs de mes travaux de thèse . 3 CHAPITRE 1 . INTRODUCTION 1 . 3 . 1 L’équipe TIBS L’équipe TIBS ( Traitement de l’Information en Biologie Santé , dirigée par le Pr T . Lecroq ) est une équipe de recherche rattachée au laboratoire LITIS ( Laboratoire d’Informatique , du Traitement de l’Information et des Systèmes , EA 4108 , dirigé par le Pr T . Paquet ) . Le LITIS est le laboratoire de recherche dans le domaine des Sciences et Technologies de l’Information et de la Communication en Haute - Normandie . Le laboratoire a une démarche pluri - disciplinaire , associant l’informatique , les mathématiques , le traitement du signal , la reconnaissance des formes et des images de la médecine . Ses travaux de recherche sont structurés autour de trois axes : l’axe Combinatoire et Algorithmes , l’axe Interaction et systèmes complexes et l’axe Traitement des masses de données . Depuis janvier 2014 , le LITIS fait partie de la fédération NormaSTIC , fédération CNRS 3638 avec le Groupe de REcherche en Informatique , Image , Automatique et Instrumentation de Caen ( GREYC ) . L’un des thèmes généraux des travaux de TIBS est l’ingénierie des connaissances en santé . Par exemple , CISMeF est un projet qui vise à recenser et indexer les res - sources ( documents , sites , etc . ) de qualité en santé disponibles sur l’Internet en langue française [ Darmoni et al . , 2001 ] . L’outil Doc’CISMeF initialement développé en 2000 permet de rechercher lesdites ressources . Les travaux de l’équipe s’articulent également autour des terminologies et ontologies de santé , avec le portail Health Terminology / Ontology Portal ( HeTOP ) qui propose un accès centralisé multilingue aux principales terminologies de santé [ Grosjean et al . , 2011 ] . Depuis 2011 , l’équipe travaille autour d’un nouvel axe de recherche en informatique biomédicale qui porte sur la RI et la visualisation des données dans le DPI . Ma thèse s’inscrit dans cette contribution . 1 . 3 . 2 L’informatique biomédicale De nombreuses déﬁnitions de l’informatique biomédicale se concentrent sur les don - nées , l’information et les connaissances , mais ne fournissent pas une déﬁnition adéquate de ces termes . L’informatique biomédicale peut être déﬁnie comme la science de l’in - formation appliquée ou étudiée dans le contexte de la biomédecine [ Bernstam et al . , 2010 ] . L’American Medical Informatics Association ( AMIA ) donne une déﬁnition plus précise du domaine de l’informatique biomédicale : « L’informatique biomédicale est un domaine interdisciplinaire qui étudie et poursuit l’utilisation eﬃcace des données , des informations et des connaissances biomédicales pour la recherche scientiﬁque , la ré - solution de problèmes et la prise de décision , motivée par des eﬀorts visant à améliorer la santé humaine . » . Ses activités sont ainsi multiples : — le développement de théories , méthodes et processus pour la production , le sto - 4 CHAPITRE 1 . INTRODUCTION ckage , la récupération , l’utilisation et le partage de données , d’informations et de connaissances biomédicales ; — l’utilisation des connaissances et technologies de l’informatique , de la commu - nication et plus largement des sciences de l’information et leur application en biomédecine ; — l’étude , la modélisation , la simulation et l’expérimentation à travers le spectre des molécules aux populations , en traitant une variété de systèmes biologiques , et reliant recherche , pratiques fondamentales et cliniques et systèmes de soins de santé . Ses caractéristiques placent ainsi l’informatique biomédicale à l’interface de la re - cherche translationnelle . 1 . 3 . 3 La recherche translationnelle La médecine translationnelle est une discipline qui se développe rapidement , axée sur les technologies et les découvertes en laboratoire et leur traduction dans la pratique clinique . Il existe ici aussi de nombreuses déﬁnitions de la médecine translationnelle . L’Institut national de la santé américain ( NIH ) considère ainsi que « pour améliorer la santé humaine , les découvertes scientiﬁques doivent être traduites en applications pratiques . Ces découvertes commencent généralement « à la paillasse » avec la recherche fondamentale - dans laquelle les scientiﬁques étudient la maladie au niveau moléculaire ou cellulaire - puis progressent vers le niveau clinique , ou le « chevet » du patient déﬁnissant ainsi la recherche translationnelle comme la recherche de la paillasse au chevet » [ Zerhouni , 2003 ] . Plus succinctement , la médecine translationnelle peut être décrite comme la transition de la recherche expérimentale in vitro à l’application chez l’être humain [ Wehling , 2015 ] . Cette transition , ou traduction , nécessite de coordonner et exécuter diverses étapes impliquées dans l’extraction d’informations signiﬁcatives à partir de données cliniques et expérimentales accumulées de manière ordonnée et semi - automatique : — la gestion des données haut débit comme le transfert de données , le stockage de données , le contrôle d’accès et la gestion des données ; — la mise en place d’une infrastructure évolutive ; — l’analyse de données multidimensionnelles à grande échelle pour l’extraction de connaissances concrètes pour le développement d’applications en biotechnologie et en biomédecine . 5 CHAPITRE 1 . INTRODUCTION 1 . 4 Objectifs L’un des premiers objectifs de ma thèse est l’intégration au sein du DPI d’infor - mations dépassant le cadre de la médecine pour intégrer des données , informations et connaissances provenant de la biologie moléculaire ; les données omiques , issues de la génomique , protéomique , métabolomique . L’intégration de ce type de données permet d’améliorer les systèmes d’information en santé , leur interopérabilité ainsi que le trai - tement et l’exploitation des données à des ﬁns cliniques . La modélisation des dossiers , l’exploration des codages et de nouveaux modes de saisies , la sémantique des infor - mations stockées sont alors des éléments essentiels . Un enjeu important est d’assurer l’intégration de données hétérogènes , grâce à des recherches sur les modèles concep - tuels de données , sur les ontologies et serveurs terminologiques et sur les entrepôts sémantiques . En France , il n’existe pas de plateforme permettant d’uniﬁer des données médicales ( cliniques , biologie ou d’imagerie ) de sources hétérogènes et l’utilisation des données du dossier patient . L’intégration de ces données et leur interprétation selon un même modèle de données conceptuel sont un verrou important . L’interconnexion de systèmes d’information et le partage d’information au travers de services web peuvent aider à la transmission ou la non - redondance d’information . Enﬁn , il est important d’intégrer recherche clinique et recherche fondamentale aﬁn d’assurer une continuité des connaissances entre recherche et pratique clinique et aﬁn d’appréhender la problé - matique de personnalisation des soins . De nouveaux modèles pour la représentation et l’intégration de connaissances issues à la fois de la médecine et de la biologie mo - léculaire au sein des dossiers patients sont nécessaires , ainsi que des outils dédiés à la recherche et la visualisation d’information des données cliniques et omiques . Le second objectif de ma thèse est l’indexation multi - terminologique de documents médicaux . Notre équipe développe l’outil Extracteur de Concepts Multi Terminologique ( ECMT ) . Il exploite les terminologies intégrées au portail de PlaIR pour identiﬁer des concepts dans des documents non structurés . Ainsi , à partir d’un document rédigé par un humain , et donc porteur potentiellement d’erreurs , de frappe , d’orthographe ou de grammaire , cet outil va identiﬁer des concepts et ainsi structurer l’information contenue dans le document . Pour la recherche d’information médicale , l’indexation présente un intérêt incontournable pour la recherche dans les documents non structurés , comme les comptes - rendus de séjour ou d’examens . Il s’agit donc d’une part d’évaluer l’apport de cet outil à la recherche d’information dans les documents médicaux non structurés contenus dans les DPI et dans un second temps d’améliorer et d’enrichir l’indexation grâce à l’exploitation des réseaux sémantiques et relations inter terminologiques . Les textes médicaux issus de la pratique clinique ayant pour caractéristique de comporter généralement des erreurs qui sont un frein à une indexation eﬃcace , cette problématique doit également être abordée . 6 CHAPITRE 1 . INTRODUCTION 1 . 5 Organisation du mémoire Ce mémoire s’organise en sept chapitres . Les deux premiers chapitres sont consacrés au contexte de travail , aux objectifs et à l’état de l’art et déﬁnitions liés à la recherche d’information en santé . Les deux chapitres suivants présentent les méthodes et modèles utilisés ou conçus ainsi que leur réalisation pour aboutir à une solution d’intégration et de recherche clinomique dans les DPI . Les cinquième et sixième chapitres présentent les travaux réalisés s’intéressant à l’indexation multi - terminologiques de documents médicaux . Le dernier chapitre propose une conclusion de cette thèse et ses perspectives . 7 CHAPITRE 1 . INTRODUCTION 8 Chapitre 2 La recherche d’information en santé Sommaire 2 . 1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2 . 1 . 1 L’information en santé . . . . . . . . . . . . . . . . . . . . . . 11 2 . 1 . 2 La recherche d’information dans le domaine de la santé . . . 12 2 . 2 Les ressources en santé et sciences biomédicales . . . . . . 13 2 . 2 . 1 Ressources bibliographiques . . . . . . . . . . . . . . . . . . . 14 2 . 2 . 2 Contenus en texte intégral . . . . . . . . . . . . . . . . . . . . 15 2 . 2 . 3 Bases de données . . . . . . . . . . . . . . . . . . . . . . . . . 16 2 . 2 . 4 Agrégations de ressources . . . . . . . . . . . . . . . . . . . . 17 2 . 3 La représentation des données en santé . . . . . . . . . . . 17 2 . 3 . 1 Représentation des connaissances et vocabulaires contrôlés . . 18 2 . 3 . 2 Données cliniques et Dossiers Patients Informatisés . . . . . . 26 2 . 3 . 3 Données biologiques et recherche translationnelle . . . . . . . 31 2 . 4 Entrepôts de données et plateformes de recherche biomé - dicales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 2 . 4 . 1 Plateformes et entrepôts de données cliniques . . . . . . . . . 33 2 . 4 . 2 Plateformes et entrepôts de recherche translationnelle . . . . 34 2 . 4 . 3 Comparaison des plateformes existantes . . . . . . . . . . . . 36 2 . 5 L’indexation de textes médicaux . . . . . . . . . . . . . . . 38 2 . 5 . 1 Concepts , bases et déﬁnitions . . . . . . . . . . . . . . . . . . 38 2 . 5 . 2 L’extraction de termes cliniques dans des textes médicaux . . 40 2 . 5 . 3 Détection des modiﬁcateurs . . . . . . . . . . . . . . . . . . . 42 2 . 5 . 4 Outils d’indexation existants . . . . . . . . . . . . . . . . . . 44 2 . 6 La recherche d’information en santé . . . . . . . . . . . . . 46 2 . 6 . 1 Concepts , bases et déﬁnitions . . . . . . . . . . . . . . . . . . 46 2 . 6 . 2 Historique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 2 . 6 . 3 Modèles de recherche d’information . . . . . . . . . . . . . . . 48 9 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2 . 6 . 4 La reformulation de requête . . . . . . . . . . . . . . . . . . . 56 2 . 7 Évaluation des systèmes de recherche d’information en santé . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 2 . 7 . 1 Métriques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 2 . 7 . 2 Campagnes de test et évaluation . . . . . . . . . . . . . . . . 60 2 . 8 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 10 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2 . 1 Introduction Cette section introduit le domaine d’application de l’informatique médicale . Il vise à contextualiser la revue de la littérature et montrer pourquoi l’informatique médi - cale est un environnement où la RI a un impact considérable . L’informatique médicale est une discipline à l’interface des sciences de l’information , de l’informatique et de la médecine . Elle traite avec des ressources , appareils et méthodes indispensables à l’ac - quisition , le stockage , la recherche et l’utilisation d’informatique en médecine clinique et en biologie . Un volume important de ces informations est conservé dans des formats non structurés , notamment en langage naturel . Le langage naturel est répandu pour plusieurs raisons . Les dossiers patients électroniques en sont à leurs balbutiements dans de nombreux pays et ceux ayant implémenté ces projets ont toujours à numériser un volume considérable de données . De plus , alors que les dossiers patients électroniques ont été adoptés suivant diﬀérents standards , l’interopérabilité entre ces projets reste une question ouverte . Puis , les professionnels médicaux ont développé des mécanismes de langage naturel sophistiqués et eﬃcients pour communiquer entre eux , par exemple , l’usage intensif d’abréviations et de notations courtes personnalisées . Ainsi , ils peuvent être réticents à remplacer ces usages par l’information structurée nécessaire au traite - ment automatisé . Le décalage sémantique entre les données médicales brutes , comme les dossiers patients , les données biologiques et la façon dont un humain ( un clinicien par exemple ) interprète ces données est un problème majeur en informatique médi - cale [ Patel et al . , 2007 ] . L’ambiguïté du langage naturel ampliﬁe ce problème . Les terminologies et ontologies standardisées visent à résoudre cette question en apportant un point de référence sémantique primordial pour l’intégration de données hétérogènes issues de multiples sources . L’accès opportun et pertinent à l’information est essentiel pour le processus de soins . Le déﬁ de gérer cette information implique impérativement un traitement sémantique . 2 . 1 . 1 L’information en santé « L’information » est un concept diﬃcile à déﬁnir qui peut être vu de diﬀérentes façons . Il est fréquent de voir sa déﬁnition à travers la comparaison aux concepts de « donnée » et « connaissance » . Les données consistent en des observations ou mesures réalisées sur l’environnement . L’information représente les données agrégées et organisées décrivant une situation spéciﬁque . La connaissance représente les éléments appris à partir des données et de l’information , cumulés et intégrés au cours du temps , et qui peuvent être appliqués à des faits nouveaux . Aujourd’hui , nous sommes entrés dans l’ère de la société de l’information [ Webs - ter , 2014 ] . Jamais auparavant une quantité si importante d’information ne fut créée et partagée . Une étude publiée en 2003 estimait que le stockage de nouvelles données 11 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ avait augmenté de 30 % par an en 1999 et 2002 [ Lyman et Varian , 2003 ] . De fait , l’in - formation est au cœur de notre société et est revenue une ressource indispensable dans chacune de ses sphères . Dans le domaine de la santé , l’information joue un rôle crucial dans les activités professionnelles et les comportements des patients . Deux études de 1966 et 1973 prédisaient que les professionnels de santé passaient environ un tiers de leur temps à gérer et utiliser de l’information [ Jydstrup et Gross , 1966 ; Mamlin et Baker , 1973 ] . Selon Hersh [ Hersh , 2008 ] , il est probable que le temps dédié à la gestion de l’information dans le domaine de la santé soit aussi important , sinon plus , de nos jours . 2 . 1 . 2 La recherche d’information dans le domaine de la santé Probablement pour les mêmes raisons qui ont fait évoluer le domaine de la RI en général au cours des dernières années , la recherche et l’intérêt pour l’application des techniques de ce champ au domaine spéciﬁque de la santé et de la biomédecine ont également connu un réel essor . Le Web et ses applications ont profondément modiﬁé la disponibilité et la facilité d’accès à l’information sur la santé , non seulement pour les professionnels de la santé , mais aussi pour les patients . Pour les professionnels de la santé , les applications oﬀrant un accès facile à des connaissances validées et à jour sur la santé sont d’une grande importance pour la diﬀusion des connaissances et ont le potentiel d’inﬂuer sur la qualité des soins prodigués . D’un autre côté , le Web a ouvert l’accès aux patients , à leur famille et à leur entourage , à des informations sur la santé , à améliorer leurs connaissances et à changer leurs relations avec les professionnels de la santé . Selon Adam Bosworth [ Bosworth , 2007 ] , dans un bon système de santé , les patients devraient avoir accès à l’information la plus pertinente possible , ainsi qu’à des services personnalisés de soutien et devraient être capables d’apprendre et d’éduquer ceux souﬀrant de maux similaires . Pour les professionnels , une des principales et plus anciennes applications en RI est Medical Literature Analysis and Retrieval System Online ( MEDLINE ) de la National Library of Medicine ( NLM ) aux États - Unis qui donne accès à la littérature anglophone de recherche biomédicale . Pour les patients , l’information sur la santé est disponible par diﬀérents services et avec une qualité dif - férente . Le contrôle et l’accès aux informations sur la santé par les patients restent un sujet sensible , ayant ouvert diverses initiatives gouvernementales partout dans le monde avec l’émergence du domaine de la e - santé . Ce domaine peut être déﬁni comme un domaine émergent à l’intersection de l’informatique médicale et de la santé publique dédié aux services de santé et à l’information fournis via Internet et les technologies qui lui sont liées [ Boogerd et al . , 2015 ] . Certaines des principales sociétés privées dans le domaine de la RI , comme Google , Microsoft et Apple ont intensiﬁé leurs in - vestissements dans ce domaine dans le courant des années 2000 . Google a lancé en mai 2008 un service intitulé Google Health visant à agréger les données des dossiers 12 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ patients . Ce service , faiblement utilisé , est déﬁnitivement fermé en janvier 2013 . Micro - soft a également lancé en octobre 2007 un service intitulé Microsoft HealthVault aux États - Unis qui est étendu aux utilisateurs du Royaume - Uni en 2010 . Globalement , le domaine de la e - santé axé sur le patient consiste à donner aux patients plus de pouvoir pour gérer leur santé . Cela peut être fait en leur donnant accès à leurs données de santé , en facilitant l’accès aux informations nécessaires ou encore en fournissant des outils en ligne qui permettent des conseils personnalisés et d’autres approches . Depuis le début des années 2010 , le développement des objets connectés , et dans le domaine de la santé , des capteurs biométriques , intégrés à des objets du quotidien a donné nais - sance à de nombreuses applications de suivi de données biométriques à destination des patients . Apple Health ( depuis septembre 2014 ) ou Google Fit ( depuis octobre 2014 ) propose l’agrégation de ces données . Ces outils permettent le partage de données de santé entre utilisateurs , mais aussi avec des professionnels de santé . Des initiatives ont également été entreprises dans le champ de la recherche clinique ( Apple CareKit , Apple ResearchKit ) avec le soutien de diverses institutions et entreprises ( University of Ro - chester , Sage Bionetworks , Duke University , University of Cape Town , Johns Hopkins University ) . Le développement récent de ces outils et leur adoption induit ainsi un développement important des données de santé personnelles , s’ajoutant aux données et ressources disponibles en sciences biomédicales . 2 . 2 Les ressources en santé et sciences biomédicales Les informations de santé textuelles peuvent être classées en deux parties : les in - formations spéciﬁques aux patients et les informations fondées sur les connaissances [ Fagan , 2003 ; Hersh , 2008 ] . Le premier type concerne des patients individuels et son but est d’informer les professionnels de la santé de l’état de santé d’un patient . Il com - prend généralement le dossier médical du patient qui peut contenir des données struc - turées ou non ( par exemple : résultats de laboratoire , signes vitaux ) ou du texte libre ( comptes - rendus ) . Le deuxième type de classiﬁcation est lié à l’information dérivée et organisée à partir de la recherche observationnelle et expérimentale . Cette information fournit aux professionnels de santé les connaissances acquises dans d’autres situations aﬁn qu’elle puisse être appliquée à des patients individuels ou utilisée pour eﬀectuer d’autres recherches . À l’instar des autres types d’information scientiﬁque , l’information basée sur le savoir peut être subdivisée en informations primaires ( résultats directs des recherches originales qui ﬁgurent dans des articles , revues ou autres sources ) et des in - formations secondaires ( examens , condensations , monographies , documents de revue , directives cliniques , informations sur la santé sur les pages Web et autres sources ) . Une autre façon de classer l’information basée sur le savoir est de la diviser en quatre sous - catégories : bibliographique , texte intégral , bases de données et agrégations [ Fagan , 13 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2003 ; Hersh , 2008 ] . Chaque sous - catégorie est décrite ci - après ainsi que certains de ses principaux exemples . 2 . 2 . 1 Ressources bibliographiques Les ressources bibliographiques en santé sont composées de bases de données biblio - graphiques , de catalogues en ligne et de registres spécialisés . La distinction entre ces sous - catégories est devenue ﬂoue , car , par exemple , les bases de données de référence de la littérature ont commencé à fournir des liens vers la littérature référencée , en se rapprochant des catalogues Web . On peut citer PubMed , Literatura Latino Ameri - cana em Ciências da Saúde ( LILACS ) ( pour le portugais et l’espagnol ) et Littérature Scientiﬁque en Santé ( LiSSa ) ( équivalent pour le français ) , développé au sein de notre équipe . Bases de données de référence de la littérature Ces bases de données cataloguent des livres et des périodiques et sont les bases de données originales de RI depuis les années 1960 , conçues pour guider le chercheur plutôt que fournir directement les ressources . MEDLINE est probablement la base bibliogra - phique la plus connue , issue de la National Library of Medicine ( NLM ) . Dans sa version 2016 , elle contient 24 358 442 références à des articles de 5 623 revues dans le domaine de la biomédecine et de la santé . Au cours de l’année 2016 , 1 140 078 références ont été ajoutées . MEDLINE est disponible gratuitement via PubMed 1 et une recherche génère une liste de citations ( incluant les auteurs , le titre , la source et souvent un résumé ) pour les articles de revues , une indication de disponibilité de texte intégral électronique ( généralement via PubMed Central 2 ) ou un lien vers le site Web de l’éditeur ou tout autre fournisseur de texte intégral . La recherche peut également être réalisée à l’aide de la passerelle NLM 3 , une interface Web qui intègre plusieurs systèmes de recherche NLM . D’autres sites donnent également accès à MEDLINE , certains gratuitement et d’autres pour certains frais ( généralement en fournissant des services à valeur ajoutée ) . Outre MEDLINE , la NLM dispose de nombreuses autres bases de données et de res - sources électroniques . Leurs bases de données bibliographiques sont organisées en trois catégories : les citations aux revues et autres périodiques depuis 1966 ( accessibles par le biais de PubMed qui est composé de MEDLINE , de citations en cours de MEDLINE et de citations fournies par l’éditeur ) , de citations de livres , de journaux et de matériel au - diovisuel disponible auprès de LOCATORplus 4 ) et des citations aux articles de revues avant 1966 et des résumés de réunions scientiﬁques ( accessibles via la passerelle NLM ) . 1 . http : / / pubmed . gov 2 . http : / / www . pubmedcentral . nih . gov 3 . http : / / gateway . nlm . nih . gov 4 . http : / / locatorplus . gov 14 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Outre la NLM , il existe d’autres producteurs de bases de données bibliographiques , tant publiques que privées comme le National Cancer Institute ( NCI ) . Certaines de ces bases de données bibliographiques ont tendance à être plus ciblées sur des ressources ou domaines spéciﬁques comme la CINAHL ( Cumulative Index of Nursing and Allied Health Literature ) - la principale base de données non - NLM pour le domaine des soins inﬁrmiers . En France , le Département d’Informatique et d’Informations Médicales du Centre Hospitalier Universitaire de Rouen ( D2IM ) développe la base de données bi - bliographique LiSSa 5 contenant plus de 850 000 articles en français [ Griffon et al . , 2016 ] . Catalogues Web Les catalogues Web sont des pages Web qui contiennent des liens vers d’autres pages et sites et partagent de nombreuses fonctionnalités avec des bases de données bibliogra - phiques traditionnelles . Le nombre de ces catalogues augmente [ Fagan , 2003 ] . On peut citer par exemple Doc’CISMeF 6 et HONSelect 7 . Le CHU de Rouen développe , depuis 1995 , un catalogue de ressources internet ( CISMeF – Catalogue et Index de Sites Médi - caux Francophones ) dont une des principales priorités est l’enseignement et l’éducation des professionnels de santé et des apprenants ( les étudiants en médecine ) , notamment grâce au recensement de documents pédagogiques . L’outil associé , Doc’CISMeF , per - met d’eﬀectuer des recherches dans ce catalogue de ressources , et oﬀre des possibilités d’interrogation plus étendues [ Darmoni et al . , 2001 ] . Registres spécialisés Les registres spécialisés diﬀèrent des bases de données de référence de la littérature parce qu’ils intègrent des ressources plus diverses . Ce type de ressource d’informa - tion peut se chevaucher avec des bases de données de référence de la littérature et des catalogues Web , mais , en général , il pointe vers des ressources d’informations plus diversiﬁées . On peut citer par exemple le registre de pratiques cliniques de l’ICH ( In - ternational Council for Harmonisation ) 8 . 2 . 2 . 2 Contenus en texte intégral Cette sous - catégorie contient des versions en ligne de la version complète des pério - diques , des livres et des sites Web . À l’origine , les bases de données en texte intégral étaient principalement des versions en ligne de revues et elles n’ont commencé à in - clure des livres qu’avec la baisse du prix des ordinateurs et la croissance du Web . 5 . http : / / www . lissa . fr 6 . http : / / doccismef . chu - rouen . fr / dc / 7 . http : / / www . hon . ch / HONselect / 8 . http : / / www . ich . org / products / guidelines . html 15 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ La plupart des périodiques sont aujourd’hui publiés électroniquement . Certains sont diﬀusés en ligne par l’entreprise responsable de la version imprimée ( par exemple El - sevier ) , d’autres sont exclusivement présents en ligne . Les versions électroniques sont généralement renforcées par des fonctionnalités supplémentaires comme un accès fa - cilité , la fourniture de données supplémentaires telles que des chiﬀres , des tableaux , des données brutes et des images ou des liens bibliographiques . Seuls certains éditeurs permettent un accès libre et gratuit à leurs revues . Certaines approches très visibles comprennent BiomedCentral ( BMC ) 9 , Public Library of Science ( PLOS ) 10 et Pub - Med Central ( PMC ) 11 . Les manuels éducatifs dans le domaine de la santé sont publiés aussi de plus en plus sur le Web . Ces versions électroniques permettent plusieurs fonc - tionnalités supplémentaires sur les versions imprimées : elles sont dotées d’images de haute qualité , de contenus multimédias , de liens vers d’autres ressources , de questions d’auto - évaluation interactives et d’un accès plus facile aux mises à jour . 2 . 2 . 3 Bases de données Cette catégorie comprend des bases de données et d’autres catalogues d’informa - tions spéciﬁques . Ce type d’information est habituellement stocké dans des systèmes de gestion de base de données et contient plusieurs types de ressources comme des images ( de radiologie , pathologie et d’autres domaines ) , des données de biologie moléculaire ( séquençage de gène , caractérisation de protéine et d’autres ) et des références ( qui re - lient la littérature scientiﬁque ) . La nature dynamique des bases de données Web les rend plus appropriées à un certain type de contenu . Les images , un élément important de la pratique de la santé , de l’éducation et de la recherche font partie de ces types . Il existe plusieurs bases de données sur les images de santé disponibles sur le Web . L’un des plus célèbres est le Visible Human Project 12 , qui consiste en des représentations tridimensionnelles de corps mâles et femelles normaux construits à partir de sections anatomiques . La génomique étudie le matériel génétique dans les organismes vivants et ses recherches ont évolué rapidement ces dernières années . L’un de ses principaux mo - teurs a été le Human Genome Project , dirigé par le National Human Genome Research Institute lié à l’organisme National Institutes of Health ( NIH ) [ Lander et al . , 2001 ] . Ce projet s’est achevé en avril 2003 avec la production d’une version de la séquence du génome humain qui est disponible gratuitement dans des bases de données publiques 13 . Plusieurs bases de données sur la génomique sont disponibles sur le Web . On peut no - ter principalement celles publiées par le National Center for Biotechnology Information ( NCBI ) aux États - Unis ainsi que celles publiées par l’institut de bio - informatique eu - 9 . http : / / www . biomedcentral . com 10 . http : / / www . plos . org 11 . http : / / pubmedcentral . gov 12 . http : / / www . nlm . nih . gov / research / visible / visible _ human . html 13 . https : / / genome . ucsc . edu / 16 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ ropéen EMBL - EBI . Les ressources NCBI sont liées entre elles , ainsi que PubMed via le système Entrez NCBI 14 . Certaines bases de données recensent des données cliniques comme la base Cancer Genome Atlas 15 qui recense les données de biologie moléculaire collectées chez des cohortes de patients atteints de divers cancers ou encore des données liées aux essais cliniques 16 . On peut noter également les bases de données de citations dans la littérature scien - tiﬁque , impliquée dans l’évaluation de la recherche comme le Science Citation Index ( SCI ) et le Social Sciences Citation Index ( SSCI ) de Thomson Reuters , disponible sur le service Web of Science 17 . 2 . 2 . 4 Agrégations de ressources Cette dernière catégorie comprend les agrégations des trois premières catégories pour tous les types d’utilisateurs , des patients aux professionnels de la santé et aux scientiﬁques . La distinction entre cette catégorie et certains des contenus ci - dessus avec plusieurs liens est ﬂoue , mais , généralement , les agrégations ont une plus grande variété d’informations qui répondent aux divers besoins de leurs utilisateurs . Il s’agit , par exemple , de sites Web qui collectent plusieurs types de contenus pour générer une ressource cohérente . L’une des plus importantes ressources agrégées d’information est MedlinePlus , un service de la NLM et du National Institutes of Health ( NIH ) mis à jour quotidiennement . Il regroupe des informations provenant de ces entités et d’autres sources de conﬁance sur plus de 750 pathologies . Il donne également accès à des recherches MEDLINE préformulées explorant des articles de revues médicales , des informations sur les médicaments , une encyclopédie illustrée , un dictionnaire médical , des liens vers des essais cliniques , des didacticiels interactifs et des actualités sur la santé . L’information en santé est ainsi multiple et conséquente . Son organisation et sa représentation s’avèrent une problématique à part entière détaillée ci - après . 2 . 3 La représentation des données en santé Le domaine de la RI met à proﬁt la disponibilité de structures de données bien dé - ﬁnies qui peuvent être utilisés dans les processus d’indexation et de RI . L’information sur la santé est de par sa nature très précise et détaillée [ Fagan , 2003 ] . L’organisa - tion de ces connaissances est l’une des plus anciennes applications de la classiﬁcation , débutée avec les descriptions formelles d’Aristote dans le domaine de la biologie . La 14 . http : / / www . ncbi . nlm . nih . gov / Entrez / 15 . https : / / cancergenome . nih . gov / 16 . https : / / clinicaltrials . gov / 17 . http : / / scientific . thomson . com / products / wos / 17 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ représentation des concepts en santé est plus exigeante que dans de nombreux do - maines , en raison de ses niveaux de précision , de complexité , de connaissance implicite et d’ampleur des applications . Parallèlement , c’est aussi un domaine riche dans lequel plusieurs systèmes de représentation sont aujourd’hui disponibles . Les Systèmes d’Or - ganisation des Connaissances ( SOC ) en santé peuvent être classés en trois catégories avec un degré de formalisme croissant : terminologies , thésaurus et ontologies [ Vanops - tal et al . , 2011 ] . Une terminologie est une liste de termes , qui sont des représentations des concepts utilisés dans un domaine spéciﬁque . Lorsque des relations simples entre des termes diﬀérents sont spéciﬁées , on parle alors de thésaurus . Les relations sont typiquement de trois types : hiérarchiques ( les termes sont plus larges ou plus étroits ) , synonymiques ou associatives ( termes avec des relations qui ne sont ni hiérarchiques ni synonymiques ) . Enﬁn , les ontologies sont la représentation la plus formelle faisant in - tervenir des descriptions logiques dans la déﬁnition des termes . Les ontologies doivent également présenter une cohérence interne et des sémantiques exploitables de façon automatisée [ Gruber , 1993 , 1995 ] . Les SOC en santé décrits dans cette section peuvent être utilisés dans plusieurs domaines de la recherche en informatique médicale , tels que la RI , l’indexation , le traitement du langage naturel , l’interopérabilité sémantique ou encore les systèmes d’aide à la décision . Dans les processus de RI , ils peuvent être utilisés dans le processus d’indexation qu’elle soit manuelle ou automatique et dans le processus de recherche lui - même ( par exemple les relations entre concepts peuvent être utilisées pour améliorer l’expression des besoins d’information de la requête ) . 2 . 3 . 1 Représentation des connaissances et vocabulaires contrô - lés Cette section décrit le thésaurus de la NLM qui permet d’indexer la plupart des bases de données de la NLM , suivi d’autres SOC majeurs dans le domaine de la santé . Medical Subject Headings thesaurus Le Medical Subject Headings ( MeSH ) est le thésaurus de la NLM utilisé pour in - dexer la plupart des bases de données NLM [ Coletti et Bleich , 2001 ] . Il propose des ensembles de termes nommés descripteurs qui sont organisés à la fois en struc - ture alphabétique et hiérarchique et qui permettent la recherche à diﬀérents niveaux de spéciﬁcité . Les données Medical Subject Headings ( MeSH ) peuvent être téléchar - gées librement sur le site de la NLM , au format eXtensible Markup Language ( XML ) ou Resource Description Framework ( RDF ) 18 . Les hiérarchies organisant les descrip - teurs sont également appelées arbres . Chaque descripteur apparaît dans au moins un 18 . https : / / www . nlm . nih . gov / mesh / download _ mesh . html 18 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ - Osteoarthritis [ C05 . 799 . 613 ] [ Descripteur ] - Osteoarthritis [ Concept préféré ] - Osteoarthrosis [ Terme préféré ] - Arthritis , Degenerative [ Terme ] - Osteoarthrosis Deformans [ Terme ] - Osteoarthrosis Deformans [ Concept plus restreint ] - Osteoarthrosis Deformans [ Terme préféré ] Figure 2 . 1 – Structure du descripteur Osteoarthritis dans le MeSH version 2016 : descripteur , concepts et termes . arbre et peut apparaître dans autant d’arbres que nécessaire . Le MeSH est structuré en trois niveaux : descripteur , concept et terme . Un descripteur peut être constitué d’une classe de concepts , qui correspondent à une classe de termes qui sont synonymes les uns des autres . La ﬁgure 2 . 1 donne un exemple d’organisation autour du descrip - teur Osteoarthritis ( arthrose ) . Au niveau hiérarchique le plus élevé , on retrouve des concepts généraux comme Anatomie ou Maladies mentales . Les concepts plus spéci - ﬁques comme Cheville ou Trouble du comportement sont retrouvés dans la hiérarchie de treize niveaux . Dans sa version 2017 , le MeSH comporte 27 883 descripteurs et plus de 87 000 termes permettant de retrouver le concept le plus approprié . Par exemple Vitamine C est un terme correspondant à Acide Ascorbique . De plus , 232 000 concepts supplémentaires sont disponibles , ciblant principalement les maladies , médicaments et molécules . Chaque concept a un terme préféré qui est aussi le nom du concept et chaque des - cripteur a un concept préféré . Le nom du descripteur correspond au terme préféré du concept préféré . De plus , MeSH a deux types de relations : hiérarchique et associa - tive 19 . Le premier type est une composante cruciale d’un thésaurus et est représenté par l’arborescence MeSH qui représente des niveaux distincts de spéciﬁcité ( termes plus généraux ou plus spéciﬁques ) . Les descripteurs MeSH sont organisés en 16 catégories qui peuvent être explorées à travers le navigateur MeSH Browser . Les relations asso - ciatives sont souvent représentées par la référence croisée « see related » ( voir aussi ) . Elles peuvent être utilisées pour ajouter ou suggérer des termes à une recherche spéci - ﬁque , pour signaler dans le thésaurus l’existence d’autres descripteurs qui peuvent être plus appropriés ou pour souligner les distinctions faites dans le thésaurus ou dans la structure hiérarchique du thésaurus . Outre l’existence de descripteurs , le MeSH a d’autres types de vocabulaires : qua - liﬁcatifs ( ou sous - titres ) , balises de contrôle , types de publication et concepts supplé - mentaires . Les qualiﬁcatifs peuvent être rattachés aux descripteurs aﬁn de limiter la portée d’un terme ( par exemple pharmacothérapie , diagnostic , étiologie , chirurgie ) . Par exemple , une « déﬁcience en monoamine oxydase » est récupérée par le descrip - teur Monoamine Oxydase combiné avec le qualiﬁcatif Déﬁcient ( « Monoamine oxy - 19 . http : / / www . nlm . nih . gov / mesh / meshrels . html 19 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ dase / Déﬁcient » ) . Il existe des règles limitant la saisie de certains qualiﬁcatifs ( les qua - liﬁcatifs admissibles sont mentionnés dans le champ Qualiﬁcateurs Admissibles pour chaque terme ) . Les balises de contrôle sont une classe spéciale de descripteurs MeSH qui doivent être considérés systématiquement pour chaque article , d’où leur nom , et représentent des caractéristiques telles que les espèces , le sexe , l’âge humain , les pé - riodes historiques et la grossesse . Les types de publication décrivent l’élément qui est indexé au lieu de son sujet . Il comporte trois grandes catégories : les composants de la publication ( par exemple , résumé ) , les formats de publication ( conférences , articles ) , les caractéristiques de l’étude ( par exemple , essai clinique , méta - analyse ) . Les ﬁches descriptives supplémentaires permettent l’indexation des articles avec des descripteurs provenant d’autres thésaurus . Uniﬁed Medical Language System Le système Uniﬁed Medical Language System ( UMLS ) intègre et distribue des ter - minologies , classiﬁcations et standards et leurs ressources associées . Ce projet a été initié par la NLM , en 1986 , du fait de son directeur , Donald Lindberg [ Lindberg et al . , 1993 ] . Ce projet visait à réduire les obstacles à l’utilisation des machines dans le domaine de la santé et plus particulièrement à la récupération eﬃcace des informations exploitables par machine [ Humphreys et al . , 1998 ; Lindberg et al . , 1993 ] . Deux de ces barrières sont la variété des façons d’exprimer un même concept dans diﬀérents vocabulaires et la diﬀusion d’informations utiles parmi les diﬀérents systèmes et leur interopérabilité . De fait , le domaine de l’informatique médicale se caractérise par une grande diversité de vocabulaires développés pour des applications spéciﬁques ( systèmes épidémiologiques , systèmes d’aide à la décision , documentation d’indexation , codes de facturation et procédures ) . L’absence d’un langage commun freinait l’interopérabilité des applications qui utilisaient ces vocabulaires et était une motivation pour le dévelop - pement de l’UMLS . L’UMLS se compose de trois sources de connaissances qui peuvent être utilisées séparément ou ensemble . L’un est le Metathesaurus® qui propose plus d’un million de concepts biomédicaux à partir de plus de 100 sources ( y compris le MeSH ) , le deuxième est le Semantic Network® avec 135 types sémantiques et 54 re - lations sémantiques entre les types , le dernier est le SPECIALIST Lexicon® dans le domaine du traitement automatique de la langue [ Kleinsorge et Willis , 2008 ] . L’uti - lisation de ces sources de connaissances peut être très diverse ( par exemple : recherche d’information , traitement du langage naturel , indexation automatisée , construction de thésaurus , dossiers patients informatisés et autres ) . Chaque source de connaissances est décrite plus en détail dans cette section . L’UMLS est disponible sous licence libre au téléchargement 20 . 20 . https : / / www . nlm . nih . gov / research / umls / licensedcontent / umlsknowledgesources . html 20 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ S0011232 Adrenal Gland Diseases S0011231 Adrenal Gland Disease S0000441 Disease of adrenal gland S0481705 Disease of adrenal gland , NOS S0220090 Disease , adrenal gland S0044801 Gland Disease , Adrenal S0226798 SURRENALE , MALADIES ( Français ) S0860744 Disorder of adrenal gland , unspeciﬁed S0217833 Unspeciﬁed disorder of adrenal glands S0225481 ADRENAL DISORDER S0627685 DISORDER ADRENAL ( NOS ) S0632950 Disorder of adrenal gland S0354509 Adrenal Gland Disorders C o n ce p t C 0001621 A d r e n a l G l a n d D i s ea s e s Term adrenal disease gland L0001621 Term adrenal disorder gland , unspeciﬁedL0041793 Term adrenal disorder L0161347 Term adrenal disorder gland L0181041 Term L0162317 Figure 2 . 2 – La notion de concept au sein du Metathesaurus® UMLS ( adapté de Klein - sorge et Willis [ 2008 ] ) . Tableau 2 . 1 – Métriques générales de la version 2016AB du Metathesaurus® UMLS . Concepts 3 436 707 Nombre de noms de concepts ( AUI ) 13 369 382 Nombre de noms de concepts distincts ( SUI ) 11 287 976 Nombre de noms de concepts distincts normalisés ( LUI ) 10 291 037 Nombre de sources distinctes intégrées dans le Metathesaurus® 154 Nombre de langages 25 Le Metathesaurus® UMLS Le Metathesaurus® est le composant le plus impor - tant de l’UMLS . C’est un thésaurus biomédical organisé par concepts , ou signiﬁcations auquel sont associés des synonymes dans près de 200 autres vocabulaires . Le Metathe - saurus® identiﬁe également les relations entre concepts . Les statistiques concernant les données intégrées dans la dernière version du Metathesaurus® UMLS ( version 2016AB ) ainsi que les diﬀérentes langues gérées sont indiquées dans les tableaux 2 . 1 et 2 . 2 . Dans le Metathesaurus® les termes synonymes sont regroupés en un concept avec un identi - ﬁant unique , le Concept Unique Identiﬁer ( CUI ) ( 2 . 2 ) . Chaque terme , identiﬁé par un identiﬁant unique , le Lexical ( term ) Unique Identiﬁer ( LUI ) , est un nom normalisé et peut comporter plusieurs chaînes ( identiﬁées par un String Unique Identiﬁer ( SUI ) ) , qui représentent les variantes lexicales dans les vocabulaires sources . Chaque chaîne est associée à un ou plusieurs atomes ( identiﬁés par un Atom Unique Identiﬁer ( AUI ) ) qui représentent le nom du concept dans la source . La ﬁgure 2 . 3 donne l’exemple de la structure du concept Headache ( CUI : C0018681 ) . Si deux termes diﬀérents ont des signiﬁcations diﬀérentes ( par exemple le froid ) , on leur attribue le même identiﬁant LUI qui reste associé à diﬀérents CUI ( par exemple température froide , rhume , sensation de froid ) . Le même mécanisme peut être reproduit 21 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Concept C0018681 Headache T e r m e L0290366 cephalgia head pain A0418053 HEAD PAIN CEPHALGIA ( DxP ) S0375902 HEAD PAIN CEPHALGIA A1641293 Cranial Pain ( MeSH ) S1680378 Cranial Pain A1412439 headaches ( BI ) S1459113 headaches A2882187 Headache ( SNOMED ) A0066000 Headache ( MeSH ) S0046854 Headache L1406212 cranial pain L0018681 headache T e r m e d i s t i n c t T e r m e d i s t i n c t T e r m e d i s t i n c t T e r m e d i s t i n c t T e r m e T e r m e Figure 2 . 3 – Exemple de structure d’un concept avec C0018681 Headache ( adapté de Klein - sorge et Willis [ 2008 ] ) . Tableau 2 . 2 – Métriques générales de la version 2016AB du Metathesaurus® UMLS par langue ( seules les langues représentant plus de 2 % du Metathesaurus® sont ici détaillées ) . Langue Nombre de termes ( SUI ) Nombre de ressources % du Metathesaurus® Anglais 9 417 453 129 70 . 44 % Espagnol 1 366 172 9 10 . 22 % Français 406 771 9 3 . 04 % Portugais 340 009 5 2 . 54 % Japonais 314 810 2 2 . 35 % Néerlandais 280 191 7 2 . 1 % avec des chaînes et des concepts . Le Metathesaurus® est distribué en deux formats : Original Release Format et Rich Release Format ( RRF ) . L’accès au Metathesaurus® peut être eﬀectué via le service UMLS Knowledge Service ou le navigateur RRF . Semantic Network® Le Semantic Network® est une ontologie de haut niveau dans le domaine de la santé [ Chen et al . , 2006 ] , composée de 135 types sémantiques , qui peuvent être assignés aux concepts du Metathesaurus® et 54 relations sémantiques , un ensemble de relations associées aux types sémantiques . Les types sémantiques sont les nœuds du réseau et les relations sont les arcs . Il est fourni dans un format de table relationnelle et dans un format d’enregistrement unitaire . Les types sémantiques sont organisés en deux hiérarchies : Entité et Évènement et sa portée actuelle est très large , permettant la catégorisation sémantique d’une large gamme de SOC . Chaque concept du Metathesaurus® est associé à au moins un type sémantique ( le type le plus 22 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ spéciﬁque disponible dans la hiérarchie ) . Au lieu d’ajouter des types sémantiques au réseau pour englober un objet dans les catégories les plus appropriées , les concepts qui n’appartiennent pas à un niveau de granularité doivent être associés à un type d’un niveau supérieur . Par exemple , le type sémantique Objet fabriqué a deux nœuds enfants : Dispositif médical et Dispositif de recherche . Si un objet n’est ni un dispositif médical ni un dispositif de recherche , il est simplement aﬀecté au type plus général Objet fabriqué . Les relations sémantiques peuvent être hiérarchiques ou associatives . Le lien is a ( est un ) est le lien principal dans le réseau qui établit la hiérarchie des types et des relations ( par exemple , l’animal est un organisme ) . L’ensemble des associations sont regroupées en cinq grandes catégories : « physiquement liées à » , « liées spatialement à » , « temporellement liées à » , « fonctionnellement liées à » et « conceptuellement liés à » . Dans la mesure du possible , les relations sont déﬁnies entre les types sémantiques de plus haut niveau et , en général , sont héritées par tous les descendants de ces types . Les relations ne s’appliquent pas nécessairement à toutes les instances de concepts qui ont été aﬀectées aux types sémantiques qui sont les nœuds de ce lien . Si cela n’a aucun sens , l’héritage des relations peut également être bloqué à un seul ou à tous les descendants des types sémantiques qui sont des liens . SPECIALIST LEXICON SPECIALIST LEXICON a deux composantes princi - pales : le lexique et ses outils . Le lexique est un lexique anglais général de mots communs qui comprend de nombreux termes biomédicaux et a été développé pour le support du traitement automatique de la langue . Les outils sont des programmes qui traitent les termes . Les entrées du SPECIALIST LEXICON enregistrent la syntaxe , la morphologie ( inﬂexion , dérivation et composition ) et l’orthographe de chaque terme . Les éléments lexicaux peuvent être composés de plus d’un terme s’il s’agit d’une expansion d’acro - nymes et d’abréviations généralement utilisés . La Classiﬁcation Internationale des Maladies - 10 e révision La Classiﬁcation Internationale des Maladies , 10e révision ( CIM10 ) est une liste de classiﬁcation médicale de l’Organisation mondiale de la santé ( OMS ) . Elle contient des codes pour les maladies , les signes et les symptômes , les découvertes anormales , les plaintes , les circonstances sociales et les causes externes de blessures ou de maladies . La table analytique comporte vingt - deux chapitres depuis 2006 , du fait de sa plus récente mise à jour ; elle en comptait vingt et un auparavant . Chaque chapitre est divisé en catégories aﬀectées d’un code à trois caractères , par exemple : asthme J45 ( voir Tableau 2 . 3 ) . La majorité des catégories propose un niveau de détail supplémentaire ou sous - catégorie dont le code est précisé par un quatrième caractère séparé des trois premiers par un point ( par exemple : asthme allergique J45 . 0 ) . Le nombre de codes utilisables de la CIM10 incluant les extensions de circonstances et de lieux du chapitre 23 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Tableau 2 . 3 – Exemples de catégories incluses dans la CIM10 . Code de la catégorie Nom de la catégorie Exemples de maladies J11 grippe , virus non identiﬁé grippe J00 rhinopharyngite aiguë [ rhume banal ] rhume J98 autres troubles respiratoires emphysème compensateur J93 pneumothorax pneumothorax spontané XX est de 16 800 . L’OMS fournit des informations détaillées en ligne et met à disposition un ensemble de documents . La version internationale de la CIM10 ne doit pas être confondue avec les modiﬁcations nationales de la CIM10 qui comportent souvent beaucoup plus de détails et ont parfois des sections distinctes pour les procédures . La Modiﬁcation clinique de la CIM10 aux États - Unis ( ICD - 10 - CM ) , par exemple , comporte environ 68 000 codes . Les États - Unis disposent également du Système de codiﬁcation des procédures ( ICD - 10 - PCS ) et un système de codage qui contient 76 000 codes de procédure qui ne sont pas utilisés par d’autres pays . En France , l’Agence Technique de l’Information sur l’Hospitalisation ( ATIH ) édite chaque année une version actualisée complète du volume 1 ( Table analytique ) de la CIM10 en collaboration avec l’OMS . Ce document intègre les mises à jour de l’OMS et les extensions et modiﬁcations réalisées par l’ATIH . Cette version comporte 17 300 codes utilisables . Après des versions alpha et bêta soumises au public dès juillet 2011 pour la première puis mai 2012 pour la seconde , la version consolidée de la CIM - 11 , version ontologique de la CIM , doit être soumise à l’Assemblée mondiale de la santé dès mai 2018 pour sa commercialisation oﬃcielle . Systematized Nomenclature of Medicine Clinical Terms La Systematized Nomenclature of Medicine Clinical Terms ( SNOMED CT ) , en français Nomenclature Systématisée de la Médecine - Termes cliniques , est une on - tologie incluse dans l’UMLS . Il s’agit d’une collection de termes médicaux couvrant une large gamme de concepts , y compris dont les pathologies , procédures , organismes , structures corporelles et produits pharmaceutiques [ Spackman , 2008 ] . La SNOMED CT est l’une des plus importantes ontologies spéciﬁques au domaine de la santé , avec environ 326 734 concepts , 1 299 729 termes et 1 672 322 relations . La SNOMED CT uti - lise les logiques de description comme une représentation formelle sous - jacente , de sorte qu’il s’agit strictement d’une représentation symbolique des connaissances [ Frixione et Lieto , 2012 ] . Les concepts de SNOMED CT sont représentés comme des nœuds dans un graphe acyclique . Chaque concept possède un identiﬁant unique et un certain nombre de des - criptions alternatives pour ce concept . Les concepts peuvent être divisés en plusieurs catégories de haut niveau dont la répartition se trouve dans la Figure 2 . 4 . Les concepts 24 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ de SNOMED CT peuvent être déﬁnis en termes de relations avec d’autres concepts . La relation la plus fondamentale est l’héritage , ou parent - enfant . Ainsi , les concepts sont organisés en une hiérarchie héréditaire . Par exemple , la Figure 2 . 5 montre le concept Pneumonie virale comme un enfant de Pneumonie infectieuse . En plus des héritages , un certain nombre d’autres relations peuvent être déﬁnies entre les concepts . La ﬁgure montre que le concept Pneumonie virale a une relation agent causal avec le concept Virus . La SNOMED CT couvre un large éventail de connaissances médicales dans une seule ressource autonome , alors que l’UMLS est en fait un conglomérat de ressources diﬀérentes , chacune avec une couverture variable . En outre , la SNOMED CT a un processus rigoureux de contrôle qualité supervisé par l’Organisation internationale de développement de la santé . La SNOMED CT permet la construction d’expressions post - coordonnées . La post - coordination permet aux utilisateurs de spéciﬁer un nouveau concept en combinant plusieurs concepts SNOMED CT . Par exemple , une expression pour décrire un acide aminé hydrophile essentiel pourrait être composée des concepts acide aminé hydro - phile et acide aminé essentiel . À leur tour , ils peuvent être composés avec d’autres concepts qualiﬁant la nature d’un acide aminé . Dans cette approche , un raisonneur peut être utilisé pour déterminer la relation entre les expressions construites à la volée et les classes de l’ontologie de base , c’est - à - dire que les expressions peuvent être clas - sées et placées à l’emplacement correct dans la hiérarchie des concepts [ Dhombres et al . , 2015 ; Karlsson et al . , 2014 ] . L’utilisation d’expressions post - coordonnées dans les systèmes d’information nécessite de préciser les relations exactes entre les expres - sions post - coordonnées et le contenu SNOMED CT existant ainsi que de respecter les contraintes déﬁnies par le modèle de la SNOMED CT . Gene Ontology Le projet Gene Ontology ( GO ) est un eﬀort collaboratif pour répondre à la nécessité d’une description cohérente des produits génétiques dans les bases de données . Fondée en 1998 , le projet a commencé comme une collaboration entre trois bases de données d’organismes modèles , FlyBase ( Drosophila ) , la base de données génomique Saccha - romyces ( SGD ) et la base de données du génome de souris ( MGD ) . Le projet GO a développé trois ontologies structurées qui décrivent les produits génétiques en termes de processus biologiques , de composants cellulaires et de fonctions moléculaires associés de manière indépendante des espèces . Leur répartition est décrite dans la Figure 2 . 6 . L’utilisation des termes GO en collaboration avec des bases de données facilite des requêtes uniformes dans tous les domaines . Les vocabulaires contrôlés sont structurés aﬁn qu’ils puissent être interrogés à diﬀérents niveaux . Par exemple , les utilisateurs peuvent demander à trouver tous les gènes dans le génome de la souris qui sont im - 25 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Maladies 22 % Autres 4 % Entités observables 3 % Qualiﬁcatifs 7 % Produits 8 % Substances 9 % Structures anatomiques 10 % Organismes 10 % Observations 11 % Procédures 16 % Figure 2 . 4 – Répartition des catégories de concepts dans l’ontologie SNOMED CT . pliqués dans la transduction du signal , ou de zoomer sur toutes les tyrosine kinases réceptrices qui ont été annotées . Cette structure permet également aux annotateurs d’attribuer des propriétés aux gènes ou aux produits de gènes à diﬀérents niveaux , en fonction des connaissances sur cette entité . 2 . 3 . 2 Données cliniques et Dossiers Patients Informatisés Déﬁnitions Depuis l’émergence du concept d’un dossier de santé interopérable , exhaustif et axé sur le patient dans les années 90 , les diﬀérentes acceptions d’un tel dossier ont toujours été motivées par l’idée de soutenir les soins de santé et de maintenir , respectivement , améliorer , sa qualité [ Waegemann , 2002 ] . Bien que cette idée de base ait perduré , les éléments spéciﬁques contenus ou le nom qui a été donné à ces diﬀérents concepts ont souvent changé avec le temps [ Waegemann , 2003 ] . À l’heure actuelle en France , le terme DPI est largement utilisé . Il décrit le concept d’une collecte globale et transversale des données sur la santé et les soins de santé d’un patient . Il comprend donc des données qui ne sont pas seulement particulièrement pertinentes pour le traitement médical d’un sujet , mais aussi pour la santé d’un sujet en général . Le patient est considéré comme un partenaire actif dans son traitement en accédant , en ajoutant et en gérant les données liées à la santé , en soutenant ainsi les soins [ Ball et al . , 2007 ] . Indépendamment de 26 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Pneumonie virale Pneumonie infectieuse Maladie infectieuse Agent infectieux Virus Pneumonie Maladie du poumon agent causal agent causal Figure 2 . 5 – Hiérarchie du concept Pneumonie virale . processus biologique { 29548 } 66 % fonction moléculaire { 10885 } 25 % composant cellulaire { 4092 } 9 % Figure 2 . 6 – Répartition des termes dans les trois ontologies de la Gene Ontology . la revendication d’améliorer la qualité et de soutenir les soins de santé , de nouveaux déﬁs ont surgi avec le temps et qui devront être abordés par des DPI modernes . On peut notamment mentionner le coût qui est devenu un facteur critique dans les soins de santé et , par conséquent , a également une forte inﬂuence sur le développement des DPI [ Iakovidis , 1998 ] . Un autre problème concernant les DPI est la nécessité d’une interopérabilité sur un plan technique , syntaxique [ Griffon , 2013 ] mais aussi sémantique [ Mary , 2017 ] . Cette interopérabilité peut se concevoir à diﬀérentes échelles , non seulement à l’échelle nationale entre les diﬀérents acteurs de santé , mais aussi transfrontalière avec la mobilité professionnelle et privée croissante au sein de l’Union Européenne [ Hoerbst et Ammenwerth , 2010 ] . Enﬁn , la conﬁdentialité et la sécurité des données contenues dans les DPI demeurent une préoccupation constante . 27 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Caractéristiques des DPI Contenu Les DPI visent à regrouper toute information clinique , voire administra - tive , permettant la prise en charge du patient . Ces informations peuvent inclure : les informations personnelles , les actes médicaux et hospitalisations , les antécédents per - sonnels et familiaux , la liste des professionnels de santé impliqués dans le suivi , les allergies , les données de surveillance collectées par le patient , les recommandations , les vaccinations , les prescriptions , les notes cliniques et enﬁn les résultats d’examen biolo - gique ou d’imagerie [ Archer et al . , 2011 ] . Les informations fournies par les praticiens devraient employer un vocabulaire facile d’accès pour les non - praticiens . Parallèlement , les informations saisies par les patients peuvent ne pas être aussi complètes , précises et organisées que les données échangées entre les acteurs de soins de santé . Le contenu doit être important , compréhensible et crédible pour les patients et leurs soignants et ap - proprié pour l’accès au Web par des personnes autorisées par un patient . L’expérience des médecins a montré que les listes de maladies et diagnostics , les notes cliniques , les médicaments et les données sur les allergies et les résultats des tests de laboratoire et de diagnostic peuvent être partagés avec les patients [ Halamka et al . , 2008 ] . Architecture L’interopérabilité entre les systèmes est essentielle pour le partage des données entre les diﬀérents acteurs : patient , hôpital , médecin traitant et autres pra - ticiens et les laboratoires . Depuis les années 90 , des eﬀorts de standardisation ont été entrepris , notamment avec le développement de la version 3 de Health Level - 7 ( HL7 ) Stolyar et al . [ 2005 ] . HL7 est un ensemble de normes et spéciﬁcations techniques pour les échanges informatisés de données cliniques , ﬁnancières et administratives entre les Système d’Information Hospitalier ( SIH ) . Ces spéciﬁcations sont intégrées au corpus des normes formelles américaines ( American National Standards Institute ( ANSI ) ) et internationales ( Organisation internationale de normalisation ( ISO ) ) . HL7 développe des standards conceptuels ( HL7 Reference Information Model ( HL7 - RIM ) ) , des stan - dards de documents ( HL7 Clinical Document Architecture ( HL7 - CDA ) ) , des standards concernant les applications ( HL7 Clinical Context Object Workgroup ( HL7 - CCOW ) ) et enﬁn des standards concernant les échanges d’information ( HL7 v2 . x puis HL7 v3 . 0 ) . Initialement américaines , ces spéciﬁcations s’exportent et tendent à devenir un stan - dard international . Elles déﬁnissent structure et rôle des messages pour permettre une communication eﬃcace des données liées au système de santé . Par exemple , HL7 - RIM propose une représentation du domaine clinique HL7 et identiﬁe le cycle de vie des mes - sages ou de groupes de messages . C’est un modèle partagé entre tous les domaines HL7 . HL7 - CDA est un standard XML spéciﬁant la structure et la sémantique des documents cliniques pour leur échange entre systèmes . 28 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Conﬁdentialité et sécurité Les deux tiers des patients adultes s’inquiètent de la vie privée et de la sécurité de leurs informations sur la santé , mais la plupart de ceux qui utilisent des DPI ne s’inquiètent pas des implications pour la vie privée [ California HealthCare Foundation , 2010 ] . Avantages et limites à l’utilisation des DPI Avantages De nombreux travaux ont étudié les bénéﬁces des DPI en considérant les résultats cliniques , organisationnels et sociétaux . Les résultats cliniques comprennent l’amélioration de la qualité des soins , une réduction des erreurs médicales et d’autres améliorations dans les indicateurs qui décrivent la pertinence des soins . Les résultats organisationnels , d’autre part , ont inclus des éléments tels que la performance ﬁnan - cière et opérationnelle , ainsi que la satisfaction chez les patients et les cliniciens qui utilisent les DPI . Enﬁn , les résultats au niveau sociétal comprennent l’amélioration de la recherche et l’amélioration de la santé de la population . Au niveau clinique , les travaux sont particulièrement axés sur la qualité des soins et la sécurité des patients . Les DPI ont été empiriquement liés à une adhésion accrue aux directives cliniques et recommandations [ Dexter et al . , 2009 ] . Un autre bénéﬁce moins tangible associé aux DPI est la capacité améliorée à mener des recherches . Le fait de disposer de données sur les patients stockées électroniquement augmente la disponibilité des données ce qui rend possible et facilite de nombreuses tâches en recherche clinique . Limites L’adoption des DPI présente de nombreux obstacles perçus et réels . Tout comme pour toute nouvelle technologie , l’échec peut souvent être lié à une faible im - plication des acteurs lors des phases de planiﬁcation , de la conception et de la mise en œuvre . Le manque de conﬁance est un autre obstacle , de même que les mauvaises connaissances en informatique ou une accessibilité inadéquate . Le DPI idéal semble être celui qui donne accès à la totalité ou à la plupart des informations cliniques du patient [ Detmer et al . , 2008 ; Tang et al . , 2006 ] . Cela nécessite que l’information du patient soit intégrée à travers des réseaux interopérables qui recueillent des informations pro - venant d’installations qui ont traité le patient . Ces DPI sont intégrés au système de santé . Il existe un certain nombre d’obstacles techniques et non techniques à la réussite de la mise en œuvre de ces DPI idéaux présentés dans le Tableau 2 . 4 [ Archer et al . , 2011 ] . Aujourd’hui , les DPI n’incluent pas de manière standardisée des données clino - miques comme des données de séquençage ou d’expression protéique . Ces données sont pourtant centrales en recherche translationnelle . 29 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Tableau 2 . 4 – Barrières à l’adoption , au déploiement et à l’utilisation des DPI ( adapté de Archer et al . [ 2011 ] ) . Limites Implications Systèmes d’information de santé — Équilibre entre l’autonomie du médecin et du patient — Manque de formation technologique , d’intérêt ou de capacité des médecins — Résistance au changement — Portée du travail et des responsabilités des prestataires de soins de santé — Rémunération et incitation des médecins — Préoccupations du fournisseur concernant les risques de responsabilité Conﬁance des acteurs — Préserver la conﬁdentialité des informations médicales Normes techniques pour l’in - teropérabilité des systèmes — Normes d’échange de données — Normes minimales de déﬁnition de données dans les spécialisations spéciﬁques de fournis - seur — Normes de sécurité et de conﬁdentialité — Certiﬁcation des produits de technologie de l’information sur la santé Manque d’adoption par les praticiens , les institutions — En Europe et en Amérique du Nord Manque d’infrastructures de technologie de l’information — Manque de ressources prenant en charge l’in - tégration du système — Étendue des systèmes non compatibles exis - tants — Besoin de médiation des réseaux , structures organisationnelles pour soutenir l’intégration — Services en ligne limités chez les fournisseurs de soins de santé et les institutions Fracture numérique — Considérations relatives à la situation scolaire et socioéconomique — Connaissances en santé — Besoins spéciaux : limitations visuelles , cogni - tives ou physiques — Ressources ﬁnancières 30 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Cellule Chromosomes ADN ARN Protéines Glucides Lipides Acidesaminés Génomique Transcriptomique Protéomique Métabolomique Séquençage d ' ADN Micro - arrays Séquençage d ' ARN Micro - arrays Micro - arrays Spectrométrie de masse Spectrométrie de masse Figure 2 . 7 – Les principales sciences omiques et leurs méthodes d’étude . 2 . 3 . 3 Données biologiques et recherche translationnelle Ainsi , depuis le séquençage du génome humain en 2001 , les technologies de sé - quençage haut débit ou Next Generation Sequencing ( NGS ) sont devenues peu à peu accessibles et remplacent progressivement dans les laboratoires les techniques basées sur les puces [ Ng et al . , 2010 ] . Alors que le séquençage du génome humain avait pris 13 ans et coûté plusieurs milliards de dollars , aujourd’hui un laboratoire peut séquen - cer un génome complet en une semaine pour quelques milliers de dollars , et bientôt pour moins de 1000 dollars [ Fernald et al . , 2011 ] . Les techniques NGS se distinguent également sur des points clés : quantité de matériel biologique de départ nécessaire , personnel requis et taux d’erreurs moindre . Elles sont aujourd’hui utilisées pour ré - pondre à de nombreuses questions biologiques à l’échelle d’un génome : détermination de variations génomiques ( DNA - Seq ) , inventaire de transcrits et analyse de leur expres - sion ( RNA - Seq ) , interaction ADN - protéines ou encore modiﬁcations de la chromatine pour la régulation de l’expression des gènes ( ChIP - Seq / Méthyl - Seq ) . Le développement de ces méthodes a permis l’essor de nouvelles disciplines dédiées à l’étude de composants biologiques tels que les gènes avec la génomique , les protéines avec la protéomique , les métabolites avec la métabolomique . Par analogie avec le mot génome , leur nom est formé du suﬃxe - omique , un néologisme désignant un ensemble , une collection : l’ ome ( voir Figure 2 . 7 ) . Ainsi la gén omique signiﬁe l’étude du génome , l’ensemble du matériel génétique d’un individu . L’étude du génome fournit les clés de la compréhension de fonctions biologiques de l’individu grâce à l’étude de certaines anomalies : Single Nucleotide Variation ( SNV ) , Insertion - Délétion ( indel ) , translocations , changement de ploïdie , perte d’hétérozygotie 31 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ ( Loss Of Heterozygosity ( LOH ) ) . L’analyse des séquences peut oﬀrir des possibilités supplémentaires pour le diagnostic , et par extension pour la génomique personnelle qui vise à identiﬁer les caractéristiques génétiques d’un individu , évaluer ses risques de développer une maladie , et adapter les soins à ces caractéristiques . D’autres disciplines - omiques peuvent révéler une grande utilité dans le domaine de la santé . Par exemple , l’épigénomique informe sur les états d’activités physiologiques ou pathologiques dans la cellule . Des modiﬁcations pathogènes peuvent être la marque de certains cancers ou pathologies . La masse de données omiques générée par l’utilisation croissante de ces méthodes ouvre ainsi de nouvelles voies dans la recherche d’applications biomédicales . En ef - fet , ces nouvelles techniques peuvent être utilisées dans la démarche clinique , notam - ment pour élaborer des tests diagnostiques . Elles peuvent être également utiles dans la prise en charge du patient , grâce à l’élaboration de nouvelles thérapies ( pharmacogéno - mique ) . En recherche clinique , l’analyse des séquences permet de comprendre certaines pathologies , en particulier les maladies génétiques complexes ou encore certains can - cers [ Sarkar et al . , 2011 ] . Enﬁn , l’intégration des données omiques aux données du patient peut également répondre à de nombreuses questions épidémiologiques . De nou - velles thérapies et de nouvelles méthodes de prévention sont actuellement discutées et développées . Ces approches innovantes ne peuvent être poursuivies sans gérer les vastes quantités de données générées dans les laboratoires dans les domaines tels que la génomique fonctionnelle ou la protéomique . Dans cet environnement , le DPI , des systèmes d’aide à la décision ou encore des techniques de traitement du signal peuvent être intégrés pour élargir le champ de l’information . La recherche translationnelle est la discipline émergente qui vise à créer cet espace d’information commun qui pourrait mener à la découverte de nouvelles méthodes thé - rapeutiques et de diagnostic [ Sarkar et al . , 2011 ] , à l’interface de la biologie et la médecine . L’utilisation des connaissances produites par la recherche scientiﬁque dans le domaine de la santé est l’objectif principal de la médecine translationnelle . En ef - fet , la médecine translationnelle s’intéresse à l’application de résultats de recherche en biologie , et en particulier des résultats des études omiques ( et on parlera alors de bio - informatique translationnelle ) , dans le but de faire converger la recherche et le patient . Dans ce but , le développement de plateformes visant à la gestion et à l’exploitation des données produites est indispensable . 2 . 4 Entrepôts de données et plateformes de recherche biomédicales Actuellement , peu de systèmes d’information hospitaliers permettent d’intégrer ces données aux données cliniques au sein des DPI [ Aronson et Rehm , 2015 ] . En re - 32 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ vanche , depuis 2010 , plusieurs projets de plateformes de recherche translationnelle ont été initiés , visant à la réutilisation des données biomédicales et à l’exploitation des connaissances fondamentales . En Europe par exemple , le projet EHR4CR combine et développe plusieurs composants techniques précédemment isolés pour développer une plateforme pour réutiliser les données des DPI pour soutenir la recherche médicale [ De Moor et al . , 2015 ] . 2 . 4 . 1 Plateformes et entrepôts de données cliniques STRIDE ( Stanford Translational Research Integrated Database Environ - ment ) STRIDE est un projet mené par l’université de Stanford dont le but est de créer une plateforme standard supportant la recherche clinique translationnelle . Il com - porte trois volets : une base de données cliniques , basée sur le standard HL7 - RIM , un modèle sémantique basé sur des terminologies et ontologies ( SNOMED CT , CIM10 et RxNorm , une terminologie américaine des médicaments disponibles sur le marché nord - américain ) et un framework permettant le développement d’applications dédiées à la recherche . Cependant , actuellement aucun projet de déploiement extérieur à l’Uni - versité de Stanford n’est prévu et selon les connaissances actuelles , les types de données omiques ne sont pas pris en charge [ Iyer et al . , 2014 ; Lowe et al . , 2009 ] . Slim - Prim Slim - Prim ( Scientiﬁc Laboratory Information Management – Patient - care Research Information Management , Université du Tennessee [ Viangteeravat et al . , 2009 ] ) est un système permettant de collecter , archiver et distribuer des don - nées de recherche et des données cliniques . Bien que Slim - Prim permette la gestion de données de type micro - arrays , cette plateforme ne gère pas les données de séquences et autres données biomoléculaires . i2b2 : informatics for integrating biology and the bedside La plateforme Informatics for Integrating Biology and the Bedside ( i2b2 ) a été développée à l’origine au sein du Partners Healthcare System , un vaste système de santé intégré basé à Boston [ Murphy et al . , 2006 ] . La première version du code d’i2b2 a été publiée publiquement en 2007 [ Kohane , 2011 ] . Depuis sa création , plus de 200 articles ont été publiés à l’aide de données dérivées des systèmes i2b2 . Un objectif majeur de i2b2 est de créer un moyen rentable et eﬃcace d’identiﬁer les patients pour de nombreux types de recherche clinique et translationnelle . i2b2 permet de développer des applications dédiées à la recherche clinique dans le champ génomique grâce à une architecture modulaire [ Miyoshi et al . , 2013 ] et donc d’eﬀectuer des recherches portant à la fois sur des données cliniques et des données génomiques [ Murphy et al . , 2017 ] . Chaque module est appelé cellule et chaque cellule peut communiquer avec les autres à travers de services Web . Les modules principaux gèrent le stockage des données ou encore la gestion des ontologies . 33 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Bien qu’i2b2 soit un outil puissant pour gérer et exploiter des données cliniques pour les ﬁns de la recherche clinique [ Johnson et al . , 2014 ] , il n’oﬀre pas la possibilité de fouiller les données d’un seul patient . 2 . 4 . 2 Plateformes et entrepôts de recherche translationnelle En sciences translationnelles , plusieurs plateformes sont dédiées au stockage , à la gestion et à l’exploitation de données cliniques et biomoléculaires . BRISK : Biology - Related Information Storage Kit La plateforme BRISK [ Tan et al . , 2011 ] est un assemblage de trois applications Web open source oﬀrant une pla - teforme cohérente d’intégration et de gestion des données . Il a d’abord été développé pour fournir une solution de partage de données pour les chercheurs du consortium AllerGen ( The Allergy , Genes and Environment Network ) . BRISK peut traiter les in - formations cliniques du phénotype et de la mutation somatique ( polymorphismes à un seul nucléotide ) . Il fournit aux chercheurs des capacités d’analyse des études d’associa - tion ( Genome - Wide Association Study ( GWAS ) ) à l’échelle du génome . Cette solution comprend également une application orientée laboratoire qui gère l’échantillon phy - sique , le sujet et les données de conteneur . caTRIP : Cancer Translational Research Information Platform La plate - forme Cancer Translational Research Information Platform ( caTRIP ) [ McConnell et al . , 2008 ] a été développée en tant que composant du projet cancer Biomedical In - formatics Grid ( caBIG ) au début des années 2000 pour permettre aux utilisateurs de faire une requête sur la grille caBIG . caBIG était un programme américain du National Cancer Institute . Son objectif était de développer un réseau open source aux États - Unis pour des échanges sécurisés sur la recherche sur le cancer . Les objectifs de caTRIP sont de permettre aux médecins de trouver des patients avec des proﬁls similaires , d’ana - lyser leurs résultats et de trouver des informations sur les traitements réussis dans la grille de données caBIG . Le système interopère avec plusieurs applications caBIG , y compris ( i ) le registre des tumeurs , un système clinique utilisé pour collecter des don - nées , ( ii ) le système d’extraction d’informations textuelles sur le cancer utilisant des terminologies contrôlées , ( iii ) le caTissue CORE , un dépôt de banque de tissus , ( iv ) le Cancer Annotation Engine et ( v ) le caIntegrator , un outil de stockage , d’interrogation et d’analyse de données . cBio Cancer Genomics Portal Développé au Memorial Sloan - Kettering Cancer Center ( MSKCC ) , le portail cBio Cancer Genomics [ Cerami et al . , 2012 ] est une plateforme open source conçue pour faciliter l’accès des chercheurs aux ensembles de données générés par les grands projets de génomique du cancer , comme The Cancer 34 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Genome Atlas 21 et le Consortium international du génome du cancer 22 . Il intègre les données cliniques désidentiﬁées , telles que la description du phénotype , la survie ou les intervalles de survie sans maladie , avec des données omiques à haut débit ( ADN , ARN messager - mNRA et protéines ) . De plus , les images de pathologie peuvent être consul - tées grâce à la visualisation numérique des archives de diapositives 23 . Des fonction - nalités avancées de visualisation , d’analyse et d’exportation sont fournies . La version en ligne publique stocke principalement des ensembles de données à grande échelle sur la génomique du cancer , tandis qu’une instance privée du portail peut être conﬁgurée localement par des groupes de recherche disposés à importer leurs propres ensembles de données de recherche . G - DOC Georgetown Database of Cancer Développé au Lombardi Comprehen - sive Cancer Center à l’Université de Georgetown , la base de données de Georgetown sur le cancer ( G - DOC ) [ Madhavan et al . , 2011 ] est une plateforme de recherche trans - lationnelle . G - DOC intègre les caractéristiques des patients ( par exemple , la démo - graphie , les données de recherche clinique structurée ) et les données sur les résultats cliniques avec quatre données omiques majeures à haut débit ( ADN , ARNm , microARN et métabolites ) dans un environnement uniﬁé . La plateforme contient un large éven - tail d’outils de bioinformatique et de biologie des systèmes dédiés à l’analyse et à la visualisation des données . iCOD : Integrated Clinical Omics Database La plateforme iCOD [ Shimokawa et al . , 2010 ] a été développée pour combiner des informations cliniques et moléculaires complètes des patients aﬁn de fournir une compréhension holistique des maladies . iCOD peut gérer les données omiques comme les proﬁls d’expression génique et les informa - tions cliniques hétérogènes telles que les phénotypes détaillés , les images de radiologie ou les résultats des tests de laboratoire . Des visualisations intégrées sont fournies pour résumer l’interrelation des données cliniques et omiques et pour représenter des voies plausibles . iDASH : Integrating Data for Analysis , anonymization and SHaring iDASH [ Ohno - Machado et al . , 2012 ] est développé par le National Center for Biomedical Computing . Cette plateforme fournit aux chercheurs américains une infrastructure in - formatique pour l’intégration des données et l’analyse des données . iDASH distribue également des outils et des algorithmes , axés sur le partage de données de façon sécu - ritaire . 21 . http : / / cancergenome . nih . gov / 22 . http : / / icgc . org / 23 . http : / / cancer . digitalslidearchive . net / 35 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ tranSMART Cette plateforme a d’abord été développée comme une plateforme de collaboration pour les entreprises pharmaceutiques par un consortium privé avant d’être diﬀusée dans la communauté open source ( la Fondation tranSMART est maintenant chargée de la maintenance et du développement ) [ Szalma et al . , 2010 ] . La plateforme est basée sur le modèle de données open source i2b2 . Il est conçu pour aider les scienti - ﬁques à développer et à aﬃner les hypothèses de recherche en étudiant les corrélations entre les données phénotypiques et omiques . tranSMART peut gérer les données struc - turées à partir d’essais cliniques ( démographie , résultats , résultats de laboratoire et phénotypes cliniques ) et des données alignées sur les biomarqueurs , tels que les proﬁls d’expression des gènes , les génotypes , les métabolomites et les données protéomiques . Il fournit aux chercheurs des outils d’analyse capables de générer des statistiques des - criptives et analytiques avancées . 2 . 4 . 3 Comparaison des plateformes existantes Gestion des données cliniques BRISK et le portail cBio Cancer Genomics se concentrent principalement sur l’ex - ploration des données omiques . Dans ces plateformes , les données cliniques sont re - cueillies et stockées pour permettre la catégorisation des échantillons et eﬀectuer des analyses spéciﬁques ( par exemple , type de pathologie pour une analyse de GWAS dans BRISK et des intervalles sans maladie pour une analyse de survie dans le portail cBio ) . CaTRIP , G - DOC , iCOD , iDASH et tranSMART se concentrent sur l’exploration des données cliniques . iDASH fournit de nombreux outils d’analyse d’image et de Traite - ment Automatique de la Langue ( TAL ) , et gère les documents en utilisant MIDAS 24 , une solution open source . Dans tranSMART , les données phénotypiques sont stockées en utilisant le modèle de données i2b2 constitué d’un schéma en étoile dérivé de paires de valeurs d’entité . G - DOC et iCOD utilisent leur propre format de base de données . Gestion des données omiques En ce qui concerne les données omiques , chaque plateforme supporte un ensemble de données spéciﬁques , en fonction des objectifs initiaux de la plateforme et des besoins des chercheurs qui conduisent le projet . G - DOC prend en charge quatre types de données omiques : ARN messagers , microARN , variation de nombre de copies et spectrométrie de masse de métabolites . En tant que plateforme de recherche translationnelle initiale - ment destinée au domaine du développement de médicaments , tranSMART prend en charge de multiples ensembles de données omiques utiles aux entreprises pharmaceu - tiques : proﬁls d’expression des gènes , génotypes , proﬁls de protéines sériques , données 24 . http : / / midasplatform . org / 36 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ métabolomiques et protéomiques . La plateforme BRISK est axée sur l’étude d’associa - tion GWAS : les polymorphismes à un seul nucléotide sont les seules données omiques supportées . Le portail CBio supporte un large éventail d’ensemble de données omiques produites par des études à grande échelle : données de mutations , modiﬁcations du nombre de copies , modiﬁcations de l’expression de l’ARNm par micro - arrays , valeurs de méthylation de l’ADN et protéines et niveaux de phosphoprotéines . iCOD comprend des données omiques moléculaires telles que l’hybridation génomique comparative et les proﬁls d’expression génique . Outils de visualisation et d’analyse Les fonctionnalités d’analyse fournies par le portail CBio Cancer Genomics , G - DOC , iCOD , iDASH et tranSMART s’appuient principalement sur un outil tiers , comme le logiciel statistique R , intégré directement dans les plateformes . Ils fournissent des scripts prêts à l’emploi mettant en œuvre les principaux tests et outils d’analyse utilisés par les chercheurs ( y compris - mais non limités - au test t et à l’analyse en composantes principales ) . De plus , des outils de visualisation multiples sont fournis , via des logiciels tiers ( par exemple , Integrative Genome Viewer ) ou des développements internes . En plus des outils d’analyse , la plupart des systèmes implémentent des fonctionnalités d’exportation compatibles avec le logiciel SASÕ , R ou Microsoft Excel , permettant une analyse avancée par des experts statisticiens . Interopérabilité La plupart des plateformes ne fournissent aucun support pour les terminologies et les ontologies standards . Seuls iDASH et caTRIP ont été conçus pour supporter native - ment un ensemble limité de terminologies . tranSMART gère actuellement l’utilisation de terminologies ( par exemple la CIM10 ou Logical Observation Identiﬁers Names and Codes ( LOINC ) 25 ) . i2b2 permet d’aligner des terminologies deux à deux à l’aide d’ex - pression régulières . Un environnement collaboratif et sécurisé est également fourni par chaque plateforme , à l’exception de iCOD ( information non disponible ) . Cela permet aux chercheurs de partager et de travailler de manière sélective sur les ensembles de données stockés , ce qui pourrait accélérer le processus de recherche . De manière surpre - nante , aucune des plateformes ne peut être intégrée dans un cadre global : des formats standard tels que CDISC ODM ou HL7 CDA ne sont pas traités comme format d’entrée et les sorties ne sont pas toujours compatibles avec les pipelines existants d’analyse de bioinformatique . Les développements et déploiements liés à ces plateformes demandent donc des eﬀorts importants . 25 . https : / / loinc . org 37 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2 . 5 L’indexation de textes médicaux Les données biomédicales , et en particulier les DPI comprennent des informations textuelles , non structurées , comme détaillé dans la partie 2 . 3 . 2 . Leur exploitation au sein d’outils de RI , et plus largement dans des entrepôts de données nécessite un trai - tement particulier . La plupart des plateformes , comme i2b2 , proposent une recherche plein texte pour accéder à l’information contenue dans des textes médicaux . Cepen - dant , lorsque le nombre de documents se multiplie ou que le nombre de termes de la recherche est important , il est avantageux d’utiliser les techniques d’indexation de documents . L’indexation dans le domaine biomédical implique la réalisation d’un certain nombre de tâches indispensables telles que l’identiﬁcation de termes médicaux , l’identiﬁcation d’attributs tels que la négation , l’incertitude , la sévérité , l’identiﬁcation des relations entre les entités et la mise en correspondance des termes du document aux concepts dans des SOC spéciﬁques au domaine . Le processus entier dépend d’un certain nombre de processus fondamentaux de TAL tels que la tokenisation et l’analyse syntaxique . Il existe également une forte dépendance vis - à - vis des ressources spéciﬁques au domaine telles que les dictionnaires médicaux et les SOC tels que l’UMLS . 2 . 5 . 1 Concepts , bases et déﬁnitions L’objectif de l’indexation dans le domaine médical est de convertir un document non structuré en information structurée de sorte que l’information puisse ensuite être analysée , agrégée , extraite et traitée de façon automatique . Un texte médical contient un grand nombre de termes variés : noms de maladies , noms de médicaments , procédures médicales , dispositifs médicaux , résultats de labo - ratoire , mesures du corps du patient , etc . De plus , chacun de ces termes médicaux ou entités cliniques comporte un certain nombre de modiﬁcateurs qui leur sont attachés . Par exemple , une maladie peut être chronique , aiguë , légère , atypique , idiopathique , etc . De même , un nom de médicament peut être accompagné d’informations supplémen - taires telles que la fréquence , l’itinéraire ou la quantité de la dose d’administration . La forme d’un texte médical n’est pas standardisée . Classiquement , le compte - rendu présente quelques paragraphes de long . Les phrases peuvent être des phrases courtes ou de longues phrases composées . La plupart du texte est narratif sans l’utilisation de constructions stylisées . Par exemple , les phénomènes tels que les doubles négatifs ( non inconnus ) sont relativement rares . Les documents contiennent des données structurées et non structurées . L’en - tête et le bas du document peuvent contenir des informa - tions sur les patients , sur les médecins et les hôpitaux , sur l’heure et sur la date dans un format structuré . Le corps du document peut également contenir une composante structurée sous la forme d’une liste de diagnostics , d’antécédents , d’allergies connues , 38 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ etc . Cependant , une grande partie du corps des documents est non structurée . Les médecins décrivent le patient , son état , le diagnostic ou les résultats d’une procédure en texte libre . La plupart des documents sont généralement subdivisés en sections . Les textes médicaux ( comptes - rendus de procédures ou de séjours hospitaliers , lettres de liaison ) posent ainsi de nombreux déﬁs à tout outil d’indexation : — structure de documents non standard : les textes médicaux n’ont pas de structure standardisée . Ils peuvent être divisés en sections , mais il n’y a pas de standardi - sation sur le type de sections ou leurs en - têtes ou contenus qui vont varier d’une institution à l’autre , voire d’un médecin à l’autre ; — technicité du langage : les documents médicaux contiennent un grand nombre de termes médicaux et de vocabulaire spécialisé . Les outils d’indexation généra - listes vont ainsi obtenir des résultats peu satisfaisants . Cet aspect concerne par exemple un grand nombre d’actes thérapeutiques ( par exemple : la décompression intralabyrinthique par abord des fenêtres , sans laser ) ; — grammaire et syntaxe : souvent , des phrases incomplètes ou des phrases anor - malement courtes sont utilisées , semblables à la prise de notes . Par exemple : « Début de ﬁèvre le 26 / 12 bien tolérée sans point d’appel infectieux . Appétit discrètement altéré » ; — abréviations : le domaine médical connaît une abondance d’abréviations . Souvent , la même abréviation peut être non médicale ou médicale ou peut s’étendre à des termes diﬀérents dans des spécialités médicales diﬀérentes selon le contexte et l’intention de l’auteur . Les abréviations sont ainsi diﬃciles à normaliser , classer ou résoudre ; — polysémie et synonymie : un seul terme médical peut représenter deux idées dif - férentes basées sur le contexte . C’est ce qu’on appelle la polysémie . Par exemple , inﬂammation peut se référer à un problème de peau , un problème de niveau cel - lulaire , une activité non médicale , etc . En outre , un concept unique peut être exprimé à travers de nombreux mots diﬀérents . C’est ce qu’on appelle la synony - mie ; — erreurs de transcription : la plupart des rapports sont dictés par des médecins et dactylographiés par des tiers . Ceci introduit un large éventail d’erreurs de transcription . Les mots inaudibles sont laissés en blanc . Les homophones tels qu’ antérieur ( avant ) , intérieur ( à l’intérieur ) créent de la confusion ; des mots épelés de façon similaire sont confondus . Le processus de transcription introduit également un large éventail d’erreurs d’orthographe ou grammaticales . 39 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2 . 5 . 2 L’extraction de termes cliniques dans des textes médi - caux L’extraction de termes cliniques est la tâche la plus fondamentale dans l’extraction d’information dans le domaine médical . Elle implique l’extraction de termes médicaux et de phrases à partir de documents . Les termes médicaux peuvent inclure des noms de maladies , des procédures , des dispositifs médicaux , des noms de médicament , etc . Les termes cliniques peuvent être des unités à un ou plusieurs mots qui se produisent soit de façon contiguë ou non . L’extraction des termes a été largement étudiée et explorée dans la littérature . Un certain nombre d’approches basées sur l’utilisation d’outils statistiques , de règles ou de linguistiques ont été explorées . Méthodes statistiques Les méthodes statistiques s’avèrent un choix robuste et généralisable pour de nom - breuses tâches de TAL . Elles dépendent fortement de l’obtention de données d’appren - tissage . Les modèles de Markov cachés , les systèmes MaxEnt , les champs aléatoires conditionnels sont des modèles courants utilisés pour l’extraction de termes cliniques . Modèles de Markov cachés Les travaux sur les modèles de Markov cachés tel que ceux de Collier et al . [ 2000 ] utilisent la génération d’un modèle de séquence pour la détection des termes cliniques dans le texte . Les probabilités de transition entre types de termes sont utilisées pour prédire la probabilité d’apparition d’un terme suivant son type . Modèle de Markov de maximum d’entropie Finkel et al . [ 2005 , 2004 ] ; Saha et al . [ 2009 ] utilisent une méthode basée sur un modèle de Markov de maximum d’en - tropie . Cette méthode permet d’utiliser une plus grande variété de fonctionnalités . Les caractéristiques linguistiques telles que la nature grammaticale jouent également un rôle . Les approches basées sur le lexique sont également utilisées pour créer des fonctionnalités supplémentaires . Champs aléatoires conditionnels Depuis l’introduction des Champ Aléatoire Condi - tionnel ( CAC ) [ Lafferty et al . , 2001 ] , ils ont été un choix populaire pour les tâches d’annotation de textes . Les CAC ont été utilisés pour l’extraction de termes cliniques dans de nombreux travaux [ Bodnari et al . , 2013 ; Grouin , 2014 ; McDonald et Per - eira , 2005 ; Settles , 2004 ; Tang et al . , 2014 ] . Les caractéristiques utilisées par les modèles de Markov de maximum d’entropie sont également appropriées par les CAC . Un certain nombre de caractéristiques orthographiques telles que la casse , la présence de ponctuation , etc . , sont également exploitées pour fournir des indices supplémentaires . Les CAC surmontent le problème du biais des annotations rencontré par les modèles 40 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ de Markov de maximum d’entropie et ont été théoriquement et empiriquement prouvés être plus robustes et plus précis dans les tâches d’annotation . Machine à vecteurs de support Les classiﬁeurs à Machine à vecteurs de support ( MVS ) ont également été utilisés dans des tâches d’extraction de termes cliniques dans les travaux de Doan et Xu [ 2010 ] et Saha et al . [ 2009 ] . Par la suite , les MVS ont été modiﬁées pour des tâches d’annotations sous la forme de classiﬁeurs MVS structurés utilisés dans les travaux de Cogley et al . [ 2013 ] et Yamamoto et al . [ 2003 ] . Des résultats comparables sont également obtenus avec des classiﬁeurs MVS non structurés . Combinaison et comparaison des approches Un certain nombre de travaux tentent de combiner plusieurs modèles statistiques entre eux ou avec des approches à base de règles , soit dans un pipeline , soit dans une architecture parallèle combinée pour la majorité . Dehghan [ 2013 ] post traite la sortie du CAC pour corriger les erreurs d’identiﬁcation des limites . Wang et Patrick [ 2009 ] combinent les résultats de CAC et de modèles de Markov de maximum d’entropie à l’aide du vote à la majorité . Ils tentent aussi d’utiliser le CAC pour l’identiﬁcation de termes en post - traitant ensuite les résultats par un système de Markov de maximum d’entropie pour la classiﬁcation de type de termes . Korkontzelos et al . [ 2015 ] utilisent la combinaison d’un modèle de Markov de maximum d’entropie et un perceptron pour agréger les prédictions is - sues d’une part de dictionnaires et d’autre part de systèmes d’indexation . Des études comparatives telles que celles réalisées par Abacha et Zweigenbaum [ 2011 ] révèlent que les systèmes statistiques tels que le CAC obtiennent de meilleurs résultats que les méthodes purement basées sur des règles . De plus , le CAC surpasse également la combinaison d’un système de règle pour l’extraction de termes suivie d’un classiﬁeur MVS pour la classiﬁcation du type de terme . Méthodes basées sur des règles Un certain nombre de méthodes basées sur l’utilisation de règles ont également été proposées pour la reconnaissance de termes cliniques dans des textes médicaux . Les méthodes se répartissent en deux catégories : les approches basées sur la linguistique et les approches basées sur les vocabulaires contrôlés . Approches linguistiques Les approches basées sur la langue s’appuient générale - ment sur l’analyse syntaxique . L’analyse syntaxique est réalisée en utilisant un certain nombre de règles supervisées pour identiﬁer les termes . Proux et al . [ 1998 ] eﬀectuent un certain nombre d’étapes de ﬁltrage fondées sur des règles pour identiﬁer des enti - tés cliniques . Wilbur et al . [ 1999 ] eﬀectuent la segmentation des phrases en utilisant des méthodes basées sur des règles . Ils implémentent également une approche en deux 41 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ étapes où un système basé sur des règles est suivi d’un classiﬁeur qui identiﬁe le type de terme . De même , Rebholz - Schuhmann et al . [ 2006 ] utilisent un certain nombre d’étapes de ﬁltrage utilisant à la fois des principes basés sur des règles et des principes statistiques . Jimeno et al . [ 2008 ] incluent un modèle statistique dans le système basé sur des règles en utilisant la fréquence des mots et le nombre de cooccurrences . Approches basées sur des vocabulaires contrôlés Les approches basées sur les terminologies et ontologies mettent à proﬁt l’utilisation des connaissances médicales avec notamment l’UMLS , la SNOMED CT pour identiﬁer les termes médicaux et caractériser leur type . Par exemple Fan et al . [ 2013 ] utilisent l’ontologie SNOMED CT . De même MetaMap [ Aronson et Lang , 2010 ; Mork et al . , 2017 ] est un outil basé sur des règles exploitant le réseau sémantique de l’UMLS . Ces outils sont détaillés dans la section 2 . 5 . 4 . Méthodes génériques appliquées au domaine médical Malgré ses spéciﬁcités , la tâche d’extraction de termes cliniques présente une étroite similarité avec la même tâche appliquée dans le domaine général et n’exploitant pas de vocabulaire spéciﬁque . Les points communs [ Bikel et al . , 1999 ] incluent la personne , les adresses et les noms d’organisation . Leur identiﬁcation est une première étape im - portante dans le domaine de l’extraction de l’information [ Nadeau et Sekine , 2007 ] . La reconnaissance de termes a été un domaine largement étudié et expérimenté . Les approches fondées sur des règles , l’analyse syntaxique , l’utilisation de lexiques fondés sur le Web , l’utilisation d’outils statistiques tels que les CAC [ McCallum et Li , 2003 ; Tkachenko et Simanovsky , 2012 ] , modèles de Markov cachés Zhou et Su [ 2001 ] et modèles de Markov de maximum d’entropie [ Bender et al . , 2003 ] ont été explorés pour la reconnaissance de termes . Ratinov et Roth [ 2009 ] discutent de diﬀérents déﬁs de conception pour la reconnaissance de termes en utilisant la représentation d’entités nommées , des schémas d’annotations , de modèles et d’ensembles de caractéristiques , qui se révèlent pertinents pour l’extraction de termes cliniques . Spasić et al . [ 2015 ] discutent de l’importance d’une ontologie de domaine pour améliorer les résultats de la reconnaissance de termes lorsqu’il s’agit d’un domaine cible spéciﬁque . 2 . 5 . 3 Détection des modiﬁcateurs Les modiﬁcateurs sont des termes qui fournissent des informations vitales supplé - mentaires sur les entités . Un modiﬁcateur peut annuler , quantiﬁer ou décrire une entité . Le rôle sémantique d’une entité dans une phrase ne peut être découvert qu’après la combinaison avec ses modiﬁcateurs ( par exemple : « ﬁèvre augmentée » ) . Plusieurs approches sont également possibles ici : basées sur l’utilisation de règles ou d’outils statistiques . 42 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Approches basées sur des règles Un sous - problème important de la détection des modiﬁcateurs est le problème de la détection de la négation ( « absence de » , « pas de » ) , qui a été largement étudié dans la littérature . Un système de détection de négation basé sur des règles simples , mais populaire est l’algorithme NegEx proposé par Chapman et al . [ 2001 ] qui utilise un lexique de 35 phrases de négation utilisées pour la détection de la négation avec une fenêtre contextuelle de 5 mots pour détecter l’entité négative . Ceci est étendu par Harkema et al . [ 2009 ] où , avec des termes déclencheurs , une deuxième liste de termes est utilisée . Cet algorithme a également été exploré pour la langue française , avec de bons résultats [ Deléger et Grouin , 2012 ; Garcelon et al . , 2014 ] . Dans le contexte de la négation , des entités cliniques Patrick et al . [ 2006 ] mentionnent une importante classiﬁcation des négations . Certaines négations sont incluses comme des entités cliniques dans l’UMLS , tandis que d’autres sont des cas de négation classiques dans lesquels la réponse à la négation est disjointe de l’expression de l’entité clinique . Les méthodes basées sur des règles qui dépendent fortement de l’analyse lexicale et linguistique dominent ainsi les eﬀorts de détection de négation . De nombreuses idées peuvent être reprises pour identiﬁer d’autres catégories de modiﬁcateurs . Par exemple , une approche d’analyse de syntaxe telle que celle de Gindl et al . [ 2008 ] peut être utilisé pour détecter la portée de toute phrase modiﬁcatrice . Approches statistiques Uzuner et al . [ 2011 ] ainsi que de Bruijn et al . [ 2011 ] ont proposé une approche basée sur un classiﬁeur MVS et une gamme de fonctions lexicales et syntaxiques pour la classiﬁcation d’assertions . Clark et al . [ 2011 ] divisent la tâche de détection de modiﬁcateur en deux étapes : la détection de déclencheurs et la détection du cadre du déclencheur . Ils modèlent chacune de ces étapes en tant que tâches d’annotation en utilisant des CAC . Approches basées sur l’analyse de dépendance Sohn et al . [ 2012 ] démontrent l’utilité de l’analyse de dépendance pour la détection de négation par une approche basée sur les règles où les motifs créés manuellement sur l’arborescence de l’analyse de dépendance sont utilisés pour identiﬁer les cas de né - gation . L’utilisation de l’analyse de dépendance avec des classiﬁeurs a été largement implémentée avec la conception de classiﬁeurs spécialisés qui mesurent la similarité des arbres . Les noyaux de convolution [ Collins et Duffy , 2001 ; Moschitti , 2004 ] sont une telle approche . Sidorov et al . [ 2012 ] utilisent des fonctionnalités basées sur l’ana - lyse de dépendance jointes à un classiﬁeur pour la tâche d’idenditiﬁcation de l’auteur . 43 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2 . 5 . 4 Outils d’indexation existants Application à la langue anglaise MTI : Medical Text Indexer Développé par la NLM , MTI est un logiciel d’indexa - tion automatique adapté au MeSH . MTI recommande des termes MeSH appropriés à chaque citation MEDLINE en utilisant le titre et le résumé comme entrée [ Aronson et Lang , 2010 ; Mork et al . , 2014 ] . MTI se compose de deux composants princi - paux : MetaMap et le module de citations associées à PubMed . MetaMap extrait les concepts biomédicaux du titre et du résumé , puis les aligne aux termes MeSH corres - pondants , tandis que le module RPC tente de trouver des citations MEDLINE simi - laires à l’aide d’un algorithme des k - voisins modiﬁé nommé PubMed Related Articles ( PRA ) [ Lin et Wilbur , 2007 ] . Les termes MeSH de ces citations similaires sont en - suite extraits et combinés avec les termes MeSH par MetaMap . Après quelques étapes de post - traitement , telles que l’application de règles d’indexation , une liste classiﬁée de termes MeSH est proposée . Depuis 2012 , l’usage de MTI par les indexeurs de la NLM ainsi que via son interface Web , MeSH On Demand , a été multiplié par 5 [ Mork et al . , 2017 ] . Open Biomedical Annotator Le National Center for Biomedical Ontology ( NCBO ) développe un système d’accès automatique et basé sur les ontologies aux ressources biomédicales en ligne [ Shah et al . , 2009b ] . Le processus d’indexation est réalisé par le traitement des métadonnées textuelles de diverses ressources telles que les jeux de données ArrayExpress pour les annoter et les indexer avec des concepts d’ontologies appropriées . Cette indexation nécessite l’utilisation d’un outil de reconnaissance de concepts pour identiﬁer les concepts d’ontologie dans les métadonnées textuelles de la ressource . Cet outil permet d’obtenir une meilleure précision que MetaMap pour la plupart des ressources et dictionnaires testés , au prix d’un rappel moindre , avec un temps d’exécution amélioré [ Shah et al . , 2009a ] . Système BioASQ Ce système adopte une approche de classiﬁcation à plat grâce à un classiﬁeur MVS binaire pour chaque annotation dans les données d’apprentissage [ Tsoumakas et al . , 2013 ] . Le système utilise un méta modèle ( appelé MetaLabeler [ Tang et al . , 2009 ] ) pour prédire le nombre d’étiquettes d’une instance de test . Pen - dant la prédiction , tous les classiﬁeurs MVS sont interrogés et les étiquettes sont triées en fonction de la valeur de conﬁance correspondante . Enﬁn , le système prédit les n pre - mières étiquettes . Bien que l’approche proposée soit relativement simple , elle nécessite une grande puissance de calcul et un stockage important . Open Biomedical Annotator Open Biomedical Annotator est basé sur Mgrep [ Dai , 2008 ] . Ce service a accès à un grand dictionnaire de termes biomédicaux issus 44 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ de l’UMLS et des ontologies NCBO [ Musen et al . , 2012 ] . Il s’appuie également sur la structure hiérarchique des ontologies et leurs alignements pour étendre les annotations . Le service est disponible comme un service Web REST pour créer des annotations à partir d’ontologies personnalisées [ Jonquet et al . , 2009 ; Shah et al . , 2009a ] . PoNeDI PoNeDI propose une approche pour l’indexation des documents biomédi - caux avec le MeSH et la SNOMED CT qui vise à surmonter la limitation de la corres - pondance partielle . Cette approche propose de restreindre le processus de racinisation à l’étape du prétraitement . L’étape de l’extraction des descripteurs repose essentielle - ment sur le modèle possibiliste et combine des méthodes sémantiques et statistiques pour calculer un score estimant la pertinence d’un descripteur dans un document . Les connaissances fournies par l’UMLS sont utilisées pour le ﬁltrage . La méthode de ﬁl - trage vise à ne conserver que des descripteurs pertinents . Les expériences menées sur la collection OHSUMED en anglais ont montré de très bons résultats en comparaison avec le baseline ( + 26 . 37 % ) ainsi que les documents de CISMeF en français [ Chebil et al . , 2015 , 2016 ] . Application à la langue française FMTI FMTI est un outil d’indexation automatique attribuant des descripteurs MeSH au texte médical en français [ Pereira et al . , 2008 ] . Il repose sur une approche multi - terminologie impliquant quatre terminologies médicales importantes et les alignements entre elles . Une fois que le texte a été normalisé , les mots vides supprimés , et chaque mot lemmatisé , le groupe de mots obtenu est mis en correspondance indépendamment de l’ordre des mots contre tous les termes MeSH , CIM10 , SNOMED CT , Classiﬁcation Commune des Actes Médicaux ( CCAM ) et TUV qui ont été traités en de la même façon . Les termes de candidats obtenus sont limités au ( x ) terme ( s ) MeSH sémantique - ment les plus proches en utilisant des relations interconcept obtenues en alignant les terminologies . En conséquence , la liste ﬁnale des termes d’indexation se compose de termes MeSH obtenus directement et les termes MeSH obtenus indirectement à l’aide des relations inter terminologiques . Peregrine Peregrine Hettne et al . [ 2010 ] est un logiciel open source développé par le centre médical de l’Université Erasmus aux Pays - Bas . Il supprime les mots vides et détecte la phrase la plus longue possible pour la faire correspondre à un concept . Il utilise l’outil Lexical Variant Generator de l’UMLS pour réduire l’expression avant la correspondance . Peregrine peut trouver des concepts partiellement superposés , mais il ne peut pas détecter les concepts imbriqués ( il ne renvoie que le concept correspondant au terme le plus long ) . Peregrine n’est pas dédié spéciﬁquement au français , mais a obtenu les meilleurs résultats lors de la campagne de test 2016 CLEF e - Health dédiée à 45 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ l’extraction d’information dans des textes cliniques francophones [ Névéol et al . , 2016 ; Van Mulligen et al . , 2016 ] . 2 . 6 La recherche d’information en santé En RI , l’index d’un document peut être utilisé dans le processus de recherche . Cette partie décrit les concepts de base de la RI en santé et présente les diﬀérents modèles de RI . 2 . 6 . 1 Concepts , bases et déﬁnitions La RI est un domaine large et varié , tel que le chercheur en RI Gerard Salton l’indi - quait dans sa déﬁnition générale originale dans les années 1960 : « Information retrieval is a ﬁeld concerned with the structure , analysis , organisation , storage , searching and retrieval of information . » [ Salton , 1968 ] . Cependant , dans ce manuscrit , nous adoptons une conception standard de la RI : un utilisateur ayant un besoin d’information , exprimé à l’aide d’une requête , obtenant une liste triée de documents non structurés , dans l’ordre décroissant d’une mesure de pertinence à sa requête ( voir Figure 2 . 8 ) . Les caractéristiques importantes sont ici doubles : les données ( documents et requêtes ) ne sont pas structurées et il y a une certaine mesure de pertinence ( ou d’incertitude ) du document à une requête . Cette estimation de la pertinence est naturellement incertaine . Ainsi le domaine de la RI a développé un large corpus de connaissances autour de modèles qui traitent de l’incer - titude . Ces modèles peuvent être considérés comme inférentiels de diverses manières : par exemple , l’inférence incertaine qu’un document donné est pertinent pour une des - cription de requête ou pour inférer des termes d’expansion de requête pour augmenter la requête d’origine . Le principe du classement des probabilités [ Robertson , 1977 ] et le principe de l’incertitude logique [ Van Rijsbergen , 1986 ] sont deux exemples qui illustrent l’inférence incertaine centrée sur la RI . Ensuite , la représentation de l’information en RI est spéciﬁque au contexte . Par représentation , nous entendons à la fois la façon dont l’information est stockée , par exemple dans un index , et comment ces derniers sont utilisés par un modèle de re - cherche , par exemple en inférant des termes apparentés pour l’expansion de la requête . La RI est spéciﬁque au contexte parce que la représentation est dérivée des données et , par conséquent , reﬂète étroitement les données spéciﬁques étant récupérées . Si la représentation est directement dérivée des données , il y a moins de risque d’incompa - tibilité entre les concepteurs du modèle et les utilisateurs des données . La dérivation de la représentation à partir des données rend également le système relativement léger , plutôt que d’avoir un processus complexe et souvent sujet à l’erreur où les concepteurs construisent manuellement le modèle de domaine . Beaucoup de techniques en RI sont 46 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Besoin d ' information Formulation de la requête Requête Documents Indexation Documents indexés Correspondance Documents trouvés Retour de l ' utilisateur Figure 2 . 8 – Processus général de la recherche documentaire . généralement applicables , plutôt que spéciﬁques au domaine , et peuvent donc être ap - pliquées à n’importe quel domaine . En revanche , l’ontologie peut devoir être adaptée ou ne pas convenir à un domaine autre que celui pour lequel elle a été initialement conçue . Enﬁn , les modèles RI s’appuient généralement sur des statistiques basées sur les mots et sont donc spéciﬁquement conçus pour fonctionner avec des données non structurées . Comme les données médicales sont hétérogènes et qu’elles existent en grande partie sous forme de texte libre , les modèles adaptés aux données non structurées sont natu - rellement applicables . Les approches de RI ont leurs limites . Le principal problème de la recherche sémantique ( et en particulier la recherche sémantique des données médicales ) est que les modèles RI dépendent des termes comme représentation des documents et des requêtes . L’utilisation d’une représentation à base de termes rend le modèle sensible aux problèmes d’écart sémantique du vocabulaire et de l’inadéquation de granularité . Les modèles RI sont généralement basés sur des statistiques tirées des collections uti - lisées pour la recherche , généralement aucun recours n’est fait à des sources externes ( exception faite de certains modèles RI qui tirent des statistiques supplémentaires de corpus externes [ Diaz et Metzler , 2006 ; Zhu et Carterette , 2012 ] ) . L’utilisation de sources externes est très pertinente pour les systèmes de RI médicaux parce que les dossiers médicaux et similaires sont généralement rédigés avec des descriptions de haut niveau qui supposent une connaissance de fond substantielle qui n’est pas explicite . 2 . 6 . 2 Historique Les premiers systèmes de RI apparaissent avec les Sumériens , au début du troisième millénaire av . J . - C . , alors qu’ils construisent des zones de stockage et de classiﬁcation de matériaux manuscrits ( inscriptions cunéiformes , un des systèmes d’écriture les plus anciens ) pour supporter le travail de groupes sociaux variés [ Valentine , 2012 ] . L’avè - 47 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ nement du papier et de la presse imprimée a amené le développement de systèmes pour stocker , gérer et récupérer l’information . En 1945 , Vannevar Bush critique le caractère artiﬁciel des systèmes d’indexation contemporains . Il théorise un système fonctionnant par association à la manière de l’esprit humain et mécanisé aﬁn qu’il puisse être uti - lisé avec rapidité et souplesse [ Bush , 1945 ] . C’est la première conception d’un système de RI automatisé . Le terme de RI fut inventé un peu plus tard , en 1950 , par Calvin Mooers [ Mooers , 1950 ] . Depuis la ﬁn des années 1950 , le domaine de la RI a évo - lué au rythme de nombreux travaux : les travaux de Luhn [ Luhn , 1957 ] , le système SMART créé par G . Salton et ses étudiants dans le cadre desquels ont été développés des concepts importants comme le modèle d’espace vectoriel et la réinjection de perti - nence [ Salton , 1971 ] , le modèle Cranﬁeld [ Cleverdon , 1967 ] , le développement de l’Inverse Document Frequency ( IDF ) [ Jones , 1972 ] et les modèles probabilistes par Robertson [ Robertson et Jones , 1976 ] et Croft [ Croft et Harper , 1979 ; Turtle et Croft , 1991 ] . En 1992 s’initie la conférence Text REtrieval ( TREC ) qui fournit l’infrastructure nécessaire à une évaluation à grande échelle et permit l’amélioration de l’existant et l’émergence de nouveaux modèles . Dans les années 1990 , avec le dévelop - pement du Web , le domaine de la RI s’est élargi . L’intérêt accru pour le grand public ainsi que l’augmentation de l’information disponible et des besoins des utilisateurs ont contribué à l’émergence de nouveaux domaines hors du champ de la simple recherche documentaire parmi lesquels la recherche de questions , la recherche multilingue , la détection et le suivi des sujets , la synthèse , la recherche multimédia . Malgré les développements récents et nombreux , la RI est loin d’être un « problème résolu » [ Callan et al . , 2007 ] . D’un côté , l’information est produite à un volume plus important que jamais et de plus , les façons dont les gens produisent , recherchent , gèrent et utilisent l’information évoluent rapidement . 2 . 6 . 3 Modèles de recherche d’information Ayant donné une déﬁnition générale de la RI , dont ses avantages et limitations , nous allons maintenant considérer les modèles de RI . Les modèles qui ont été développés pour la tâche de RI sont le modèle booléen et des modèles statistiques incluant le modèle d’espace vectoriel et le modèle probabiliste . Le modèle booléen Le modèle booléen est le modèle historique en RI . Ce modèle est basé sur la logique booléenne et la théorie des ensembles : à la fois les documents à rechercher et la requête de l’utilisateur sont conçus à partir d’un même ensemble de termes . La recherche est donc basée sur les documents contenant ou non les termes de la requête . Par exemple , la requête contenant l’unique terme santé déﬁnit l’ensemble de documents indexés avec 48 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ le terme santé . Les termes d’une requête peuvent être mis en correspondance avec les ensembles de documents contenant ces termes et combinés pour créer de nouveaux ensembles de documents en utilisant les opérateurs logiques ; le produit logique AND , la somme logique OR et la diﬀérence logique NOT . Une requête combinant deux termes à l’aide de l’opérateur AND produira un ensemble de documents inférieur ou égal aux ensembles de documents de chacun des termes de la requête , c’est - à - dire leur intersec - tion . Une requête combinant deux termes avec l’opérateur OR produira un ensemble de documents supérieur ou égal aux ensembles de documents de chacun des termes de la requête , c’est - à - dire leur union . Ce modèle a plusieurs avantages expliquant son usage répandu . Il est aisé à implé - menter et eﬃcace [ Frakes et Baeza - Yates , 1992 ] . De ce fait , c’est le modèle stan - dard utilisé à grande échelle par les systèmes de RI opérationnels ainsi que de nombreux services en ligne . Il permet également aux utilisateurs d’exprimer des contraintes struc - turelles et conceptuelles pour décrire des caractéristiques linguistiques ( des synonymes avec l’opérateur OR par exemple ) [ Marcus , 1991 ] . La logique booléenne permet une expression suﬃsante et claire et s’avère particulièrement eﬃcace si la requête néces - site une sélection exhaustive . De plus , l’approche booléenne permet d’appliquer des techniques de modiﬁcations de la requête ( expansion ou limitation ) . Enﬁn , le modèle booléen est particulièrement eﬃcace dans les phases ﬁnales de la RI , car les relations et concepts peuvent être représentés de façon exacte . Il présente également plusieurs limites , intrinsèquement liées à la nature même des opérateurs booléens . Les utilisateurs peuvent avoir des diﬃcultés à formuler une requête en utilisant des opérateurs booléens pour plusieurs raisons . D’abord , la dif - férence conceptuelle entre la déﬁnition booléenne des termes and , or , not et leurs signiﬁcations en langage naturel . L’opération A AND B sera alors comprise et utilisée comme une somme entre les ensembles de documents correspondants , plutôt que leur intersection . De la même façon , le OR logique sera confondu avec un ou exclusif , plus proche de son sens dans la langue parlée . Ainsi , des erreurs dans la construction des requêtes seront liées à ce décalage . De plus , la construction de requête nécessite à l’uti - lisateur d’être familier avec les concepts de priorités , et de groupes déﬁnis à l’aide de parenthèses . Enﬁn , l’utilisateur doit également gérer les nombreuses façons de struc - turer une requête , du fait des possibilités combinatoires augmentant avec le nombre de concepts utilisés [ Lancaster , 1993 ] . Ensuite , seuls les documents satisfaisant une requête de façon exacte sont récupérés . L’opérateur AND ne distinguera pas le cas où aucun terme n’est retrouvé du cas où seul un des termes est retrouvé . Ainsi peu de do - cuments seront retrouvés lorsque la requête combine plus de trois ou quatre termes . De la même façon , l’opérateur OR aura souvent l’inconvénient de produire un trop grand nombre de résultats . Il est ainsi diﬃcile de contrôler le nombre de documents retrou - vés et les utilisateurs seront souvent confrontés à un résultat de recherche soit négatif , 49 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ ou un nombre de résultats trop important . Enﬁn , le modèle booléen ne fournit aucun système de classement par pertinence des résultats retrouvés [ Belkin et Croft , 1992 ] . Le modèle booléen étendu Plusieurs méthodes ont été développées pour étendre le modèle booléen aﬁn de résoudre les problèmes mentionnés notamment l’introduction d’une pondération des termes de la requête ainsi qu’un système de classement des résultats [ Fox et al . , 1992 ; Fox et Sharan , 1986 ; Sachs , 1976 ; Salton et al . , 1983 ] . La méthode P - norm développée par Salton et al . [ 1983 ] permet d’associer aux termes de la requête et des documents des poids calculés en utilisant des statistiques de fréquence de terme avec les procédures de normalisation appropriées . Ces poids normalisés peuvent être utilisés pour classer les documents dans l’ordre de la distance décroissante par rapport au point ( 0 , 0 , . . . , 0 ) pour une requête OR , et dans l’ordre de la distance croissante du point ( 1 , 1 , . . . , 1 ) pour une requête AND . De plus , les opérateurs booléens se voient associer un coeﬃcient P pour indiquer le degré de rigueur de l’opé - rateur ( de 1 pour le moins strict à l’inﬁni pour le plus strict , c’est - à - dire le cas booléen ) . La norme P utilise une mesure basée sur la distance et le coeﬃcient P détermine le degré d’exponentiation à utiliser . L’exponentiation est un calcul coûteux , en particulier pour les valeurs P supérieures à un . Dans la théorie de la correspondance approximative ( fuzzy match ) , un élément a un degré variable d’appartenance à un ensemble au lieu du choix d’appartenance binaire traditionnel . Le poids d’un terme d’index pour un document donné reﬂète le degré auquel ce terme décrit le contenu d’un document . Par conséquent , ce poids reﬂète le degré d’appartenance du document dans l’ensemble approximatif associé au terme en question . Le degré d’appartenance à l’union et l’intersection de deux ensembles approximatifs est égal au maximum et au minimum , respectivement , des degrés d’ap - partenance des éléments des deux ensembles . Dans le modèle « Mixed Min and Max » développé par Fox et Sharan [ 1986 ] , les opérateurs booléens sont adoucis en consi - dérant la similitude de la requête - document comme une combinaison linéaire des poids minimum et maximum des documents . Le modèle vectoriel Le modèle vectoriel est un modèle algébrique pour représenter des documents tex - tuels ( ou d’autres objets d’une manière générale ) comme des vecteurs d’identiﬁants , et dans notre cas d’index de termes . Il est utilisé aussi bien dans la RI , dans l’indexation ainsi que dans les systèmes de classements . Il apparaît pour la première fois dans le système de RI SMART dans les années 1960 [ Salton , 1971 ] . Les documents et les requêtes sont représentés comme des vecteurs dans un espace euclidien à plusieurs dimensions . Chaque dimension correspond à un terme distinct 50 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ Terme 1 Terme 3 Terme 2 Document 1 Document 2 Requête Figure 2 . 9 – Représentation vectorielle de l’espace de documents . ( voir Figure 2 . 9 ) . . Si un terme apparaît dans le document , sa valeur associée dans le vecteur est non nulle . Diﬀérentes manières de traiter ces valeurs existent , aussi connues sous le terme de poids . L’une des méthodes les plus connues est la méthode Term Frequency - Inverse Document Frequency ( TF - IDF ) . La déﬁnition du terme dépend de son application . Les termes sont généralement des mots , mot - clés ou des groupes nominaux . Si l’on choisit des mots comme termes , la dimension du vecteur est le nombre de mots contenus dans le vocabulaire , c’est - à - dire , le nombre de mots distincts du corpus . Les opérations sur les vecteurs peuvent être utilisées pour comparer les documents avec des requêtes . Si la représentation de l’index d’un document est un vecteur (cid:126) d = ( d 1 , d 2 , . . . , d m ) dans lequel chaque terme d k ( 1 ≤ k ≤ m ) est associé à un terme index , et si la requête est un vecteur similaire (cid:126) q = ( q 1 , q 2 , . . . , q m ) dans lequel les composants sont associés avec les mêmes termes , alors leur degré de correspondance est donné par leur similarité . Classiquement on pourra utiliser le simple produit scalaire entre les deux vecteurs , ou encore la mesure de l’angle qu’ils forment , donnée par la relation ( 2 . 1 ) : score ( (cid:126) d , (cid:126) q ) = P mk = 1 d k × q k qP mk = 1 ( d k ) 2 × P mk = 1 ( q k ) 2 ( 2 . 1 ) score ( (cid:126) d , (cid:126) q ) = P m k = 1 d k × q k 12 ( P mk = 1 ( d k ) 2 + P mk = 1 ( q k ) 2 ) ( 2 . 2 ) score ( (cid:126) d , (cid:126) q ) = P mk = 1 d k × q k P m k = 1 ( d k ) 2 + P m k = 1 ( q k ) 2 − P m k = 1 d k × q k ( 2 . 3 ) 51 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ score ( (cid:126) d , (cid:126) q ) = P mk = 1 d k × q k min ( P mk = 1 d k , P mk = 1 q k ) ( 2 . 4 ) D’autres mesures existent telles que le coeﬃcient de Dice ( 2 . 2 ) , la mesure de Jaccard ( 2 . 3 ) , ainsi que la mesure de recouvrement ( 2 . 4 ) . La principale limite du modèle vectoriel est qu’il ne déﬁnit pas les valeurs des composants du vecteur . Le problème de l’assignation de valeurs appropriées aux com - posants du vecteur est appelé pondération des termes . Les premières expérimentations de Salton [ Salton , 1971 ; Salton et Yang , 1973 ] ont montré que la pondération des termes n’est pas un problème trivial . Ils ont suggéré une mesure appelée TF - IDF , une combinaison de la fréquence du terme T F , c’est - à - dire le nombre d’occurrences d’un terme dans un document , et IDF , la fréquence inverse de document , c’est - à - dire , le nombre de documents qui contiennent le terme . De nombreux algorithmes modernes sont des versions de cette méthode , la méthode originale de Salton obtenant des ré - sultats contrastés , dans certains cas , moins bons qu’une pondération par la seule fré - quence inverse de document . Moins le terme apparaît dans un document , plus le terme est discriminant entre les documents et , par conséquent , plus il est utile dans la RI . La fréquence du document inversé IDF est calculée par la relation ( 2 . 5 ) idf i = log N n i ( 2 . 5 ) Où idf i est la fréquence du document inverse pour le terme i , N le nombre total de documents dans la collection et n i le nombre de documents qui contiennent le terme i . Le modèle probabiliste Le modèle probabiliste est basé sur le principe de classement probabiliste . Bien que l’idée d’introduire un classement par les probabilités de pertinence ait été formulée initialement par Maron et Kuhns , c’est Stephen Robertson qui établit le principe de classement probabiliste en 1977 [ Robertson , 1977 ] : Un système qui retourne pour chaque requête une liste de documents dans l’ordre décroissant de la probabilité que le document soit utile à l’utilisateur ayant soumis la requête , en supposant que ces probabilités soient estimées aussi exactement que possible à partir de toute l’information disponible , aura la meilleure performance possible sur la base de cette information . Le principe tient ainsi compte du fait qu’il existe une incertitude dans la représenta - tion des besoins d’information et des documents . Il peut y avoir une variété de sources de preuves qui sont utilisées par les méthodes probabilistes , et la plus courante est la répartition statistique des termes dans les documents pertinents et non pertinents . Déﬁnissons une expérience pour laquelle nous prenons un document de la collection au hasard . Si nous connaissons le nombre de documents pertinents dans la collection , 52 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ par exemple 100 documents sont pertinents et nous connaissons le nombre total de documents dans la collection , par exemple 1 , alors ce quotient déﬁnit la probabilité de pertinence P ( R = 1 ) = 100 / 1000000 = 0 , 0001 . Supposons en outre que P ( D k ) est la probabilité qu’un document contienne le terme k avec l’espace échantillon [ 0 , 1 ] , ( 0 = le document ne contient pas de terme k , 1 = le document contient le terme k ) , puis nous utiliserons P ( R , D k ) pour désigner la distribution de probabilité conjointe avec les résultats ( 0 , 0 ) , ( 0 , 1 ) , ( 1 , 0 ) et ( 1 , 1 ) et nous utiliserons P ( R | D k ) pour désigner la distribution de probabilité conditionnelle avec les résultats 0 , 1 . Ainsi , P ( R = 1 | D k = 1 ) est la probabilité de pertinence si l’on considère les documents qui contiennent le terme k . Approche classique Stephen Robertson et Karen Spärck - Jones ont fondé leur ap - proche sur ce principe [ Robertson et Jones , 1976 ] . Ils ont suggéré de classer les documents par P ( R | D ) , c’est - à - dire la probabilité de pertinence R étant donnée la description de contenu du document D . Notons que D est ici un vecteur de com - posantes binaires , chaque composante représentant typiquement un terme . Dans le modèle probabiliste , la probabilité P ( R | D ) doit être interprétée comme suit : il peut y avoir plusieurs , par exemple 10 , documents qui sont représentés par le même D . Si 9 d’entre eux sont pertinents , alors P ( R | D ) = 0 , 9 . En pratique , la règle de Bayes ( 2 . 6 ) sur les probabilités de probabilité P ( R | D ) / P ( R | D ) est utilisée , où R désigne la non - pertinence . Les probabilités permettent d’ignorer P ( D ) dans le calcul tout en four - nissant un classement par la probabilité de pertinence . En outre , l’indépendance entre les termes est supposée . P ( R | D ) P ( R | D ) = P ( D | R ) P ( R ) P ( D | R ) P ( R ) = Q k P ( D k | R ) P ( R ) Q k P ( D k | R ) P ( R ) ( 2 . 6 ) Maron et Kuhns [ 1960 ] suggèrent en 1960 que la probabilité P ( R ) pourrait être déﬁnie par les statistiques d’usage d’un document . Cette idée est à l’origine du classe - ment par popularité , très utilisée aujourd’hui sur le Web [ Joachims et al . , 2005 ] . L’exploitation complète de cette approche nécessite deux éléments : des exemples de documents pertinents et de longues requêtes . Des documents pertinents sont nécessaires pour calculer P ( Dk | R ) , c’est - à - dire la probabilité que le document contienne le terme k étant donné la pertinence . Des requêtes longues sont nécessaires , car cette approche ne distingue que présence et absence d’un terme dans les documents , et ainsi , le nombre de valeurs distinctes pour un document est restreint pour des requêtes courtes . L’une des applications de cette approche est la méthode BM25 , mise en pratique initialement dans le système de RI Okapi dans les années 90 [ Robertson et Walker , 1994 ] . La méthode BM25 utilise la fréquence du terme dans le document , la fréquence du terme dans le corpus et la longueur du document pour estimer la pertinence . Étant donné une requête Q , contenant les termes q 1 , . . . , q n , la fonction de classement d’un 53 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ x1 x2 x4 x5 x1x3 x6 x7 Figure 2 . 10 – Un arbre de dépendance entre termes . document D est donnée dans l’équation ( 2 . 7 ) . RSV ( D , Q ) = X q ∈ Q tf q , D ( k 1 + 1 ) tf q , D + k 1 (cid:16) 1 − b + b | D | | D avg | (cid:17) log | C | − d f q + 0 , 5 d fq + 0 , 5 ( 2 . 7 ) La fraction à gauche est la composante de pondération de termes , où tf q , D est la fréquence du terme t dans le document D , | D | est la longueur du document et | D avg | est la longueur moyenne du document . La fraction de droite correspond à l’IDF , où | C | est le nombre de documents dans la collection et d f q est le nombre de documents contenant le terme q . BM25 a deux paramètres libres , b et k 1 , qui contrôlent respectivement l’eﬀet de la fréquence des termes et de la longueur du document . Cet algorithme de pondération est aujourd’hui toujours couramment utilisé [ Sparck Jones et al . , 2000 ] . Réseaux bayésiens Turtle et Croft [ Turtle et Croft , 1989 , 1991 ] ont introduit en RI l’utilisation de réseaux bayésiens [ Jensen et Jensen , 2001 ] . Conceptuellement , les réseaux bayésiens reposent sur des graphes orientés pour indiquer les dépendances probabilistes entre les variables ( voir Figure 2 . 10 ) , et ont conduit au développement d’algorithmes sophistiqués . Turtle et Croft ont utilisé un réseau pour mieux modeler les dépendances complexes entre un document et les besoins d’information d’un utilisateur . Le modèle se décompose en deux parties : un réseau représentant la collection de documents et un réseau de requêtes . Le réseau de documents est vaste , mais peut être prétraité : il lie les documents aux termes et concepts . Les concepts sont une extension des termes apparaissant dans le document . Le réseau de requêtes est relativement petit , mais un nouveau réseau doit être construit chaque fois qu’une requête arrive , puis relié au réseau de documents . Le réseau de requêtes fait correspondre les termes de la requête à des sous - expressions ( construites à l’aide de versions probabilistes des opérateurs AND et OR ) correspondant aux besoins d’information de l’utilisateur . Le résultat est un réseau probabiliste ﬂexible qui peut généraliser divers modèles booléens et probabilistes plus simples . Le système a permis une RI eﬃcace à grande 54 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ échelle , et a été la base du système de recherche de texte InQuery , construit à l’Uni - versité du Massachusetts [ Callan et al . , 1992 ] . Ce système s’est très bien comporté dans les évaluations de TREC et a été vendu commercialement pendant un certain temps . Cependant , le modèle utilisait encore diverses approximations et hypothèses d’indépendance pour rendre possible l’estimation des paramètres et le calcul [ Callan et al . , 1995 ] . Modèles de langue Les modèles de langue ont été appliqués à la RI par un certain nombre de chercheurs à la ﬁn des années 1990 [ Hiemstra et Kraaij , 1998 ; Ponte et Croft , 1998 ] . Ils proviennent de modèles probabilistes de langue développés pour les systèmes automatiques de reconnaissance vocale au début des années 80 . Pour chaque document d’une collection , un modèle statistique en deux étapes déﬁnit la probabilité de générer la demande de l’utilisateur . Les documents sont classés selon cette probabilité . Si une requête est saisie , le système utilise d’abord le modèle de formulation de requêtes pour déterminer pour chaque mot de la requête les termes qui ont pu le générer . Il en résulte une requête structurée qui représente toutes les requêtes qui ont généré la demande . Dans la deuxième étape , le système utilise le modèle de correspondance de chaque document pour calculer la probabilité que le document ait généré l’une des requêtes représentées par la requête structurée . Les deux parties ont des objectifs qui sont similaires aux deux parties des modèles de reconnaissance vocale . Les deux modélisent le signal observé , respectivement la demande de l’utilisateur et l’onde sonore . La requête structurée qui représente toutes les requêtes qui ont pu générer la demande peut être comparée à un réseau de mots dans la reconnaissance vocale [ Ephraim et Rabiner , 1990 ] . Dans le modèle de vraisemblance de la requête , un modèle de langage séparé est associé à chaque document d’une collection . Les documents sont classés en fonction de la probabilité de la requête Q dans le modèle de langue du document P ( Q | M d ) . Généralement , le modèle Unigram est utilisé à cette ﬁn . Le manque de données est un problème majeur dans la construction des modèles de langue . La plupart des séquences de mots possibles ne seront pas observées lors de la phase d’apprentissage . Une solution consiste à faire l’hypothèse que la probabilité d’un mot dépend uniquement des n mots précédents , hypothèse appliquée dans les modèles n - gram . Le modèle possibiliste Le modèle possibiliste est une théorie de l’incertitude dédiée au traitement des informations incomplètes . Dans une large mesure , il est comparable à la théorie des probabilités . Il diﬀère de ce dernier par l’utilisation d’une paire de fonctions , les mesures de possibilité et de nécessité , au lieu d’une seule . En outre , il n’est pas additif et a un sens sur les structures ordinales . Le nom « Theory of Possibility » a été inventé par Zadeh et al . [ 1978 ] , qui a été inspiré par un article de Gaines 55 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ et Kohout [ 1975 ] . De l’avis de Zadeh , les distributions de possibilités étaient censées fournir une sémantique graduelle aux énoncés en langage naturel . Il peut être considéré soit comme une version non numérique de la théorie des probabilités , soit comme un cadre de raisonnement avec des probabilités extrêmes , soit comme une simple approche du raisonnement avec des probabilités imprécises [ Dubois et Prade , 1998 ] . 2 . 6 . 4 La reformulation de requête Souvent , les termes de la requête sont liés à des termes utilisés pour indexer des documents , mais qui ne font pas partie de l’index du document . Cela motive le déve - loppement de techniques d’expansion des requêtes . Ces méthodes sont utilisées pour améliorer la précision des résultats de recherche avec des termes de requête alternatifs ou supplémentaires ( synonymes ou autres relations sémantiques ) . Cette technique est très utilisée , probablement en raison du grand nombre de représentations de concepts de santé disponibles . Les premiers travaux importants dans ce domaine ont été eﬀectués par Voorhees [ 1994 ] , qui a étudié si la RI pouvait être améliorée en élargissant les requêtes avec les sy - nonymes de WordNet . Les résultats ont montré qu’il est très diﬃcile de sélectionner au - tomatiquement des termes d’expansion appropriés . Des termes , choisis manuellement , ont cependant réussi à améliorer les résultats . Les résultats de Voorhees ont également montré que la performance en RI basée sur le concept dépend fortement du modèle de domaine spéciﬁque ou de l’ontologie utilisée . Les applications générales ( celles qui utilisent WordNet ou Open Directory ) ont du mal à surpasser les systèmes basés sur des mots - clés [ Egozi et al . , 2011 ; Ravindran et Gauch , 2004 ; Voorhees , 1994 ] . En conséquence , l’expansion de requête s’est initialement peu développée . Cependant , les applications biomédicales ( qui utilisent des ontologies spéciﬁques à ce domaine ) se sont constamment améliorées [ Koopman et al . , 2011 ; Liu et Chu , 2007 ; Zhou et al . , 2007 ] . Après la méthode d’expansion des requêtes de Voorhees , les modèles suivants ont tenté d’améliorer le modèle de requête avec des représentations basées sur des concepts . Cela a été fait dans le but de résoudre le décalage sémantique . Les termes de requête sont normalisés à des concepts , la motivation étant qu’un concept encapsule toutes les variantes lexicales d’un même terme en une seule entité . Au moment de la recherche , peu importe la variante de terme utilisée , car chaque variante du terme correspondra au même concept global . Zhong et Huang [ 2006 ] ont appliqué avec succès cette ap - proche à la recherche de données génomiques , bien qu’ils aient limité les concepts pour représenter des variantes lexicales de noms de gènes dans les données dans le volet Ge - nomics du challenge TREC . Sur la base de ce travail initial , des tentatives ultérieures ont été faites pour utiliser des concepts dans des modèles de langage probabilistes . Trieschnigg [ 2010 ] ; Trieschnigg et al . [ 2010 ] ont construit un modèle de langage de requêtes comme une distribution de probabilité sur des concepts . Ces approches 56 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ ont démontré des améliorations statistiquement signiﬁcatives dans la RI , mais avec des gains limités et souvent une approche très spéciﬁque à la tâche à accomplir ( par exemple , seulement applicable à la recherche de données génomiques ) . La littérature fait référence à un facteur de réussite critique , à savoir les approches qui combinent les statistiques basées sur le corpus et les connaissances du domaine . Ce fut la découverte de Stokes et al . [ 2009 ] , qui a mené une enquête approfondie sur les critères nécessaires à une expansion réussie des requêtes . Bien que spéciﬁque au domaine de la génomique , un certain nombre de leurs résultats peuvent être généralisés à la RI médicale . Les méthodes qui combinent les statistiques basées sur le corpus et les connaissances du domaine ont été les plus eﬃcaces . Un certain nombre de pistes ont été explorées exploitant davantage de méthodes axées sur les données dans le cadre d’une approche fondée sur des concepts . Les concepts peuvent être intégrés dans des modèles de lan - gage probabilistes pour créer une représentation basée sur le concept de la requête . Il s’agit d’une pré récupération eﬀectuée et donc indépendante du contenu du document récupéré . Meij et al . [ 2010 ] et Trieschnigg [ 2010 ] ont étendu ce travail en utilisant le retour de l’utilisateur pour générer un modèle de requête basé sur des concepts mis à jour . Leurs résultats ont montré que l’intégration des statistiques basées sur le corpus avec la connaissance du domaine était la composante clé pour l’expansion réussie des requêtes . Liu et Chu [ 2007 ] ont constaté que les requêtes médicales pouvaient être adaptées à un certain nombre de scénarios diﬀérents , par exemple les traitements , le diagnostic , les symptômes . L’UMLS fournit les connaissances de domaine pertinentes sur ces scéna - rios globaux . Les méthodes standard d’extension de requêtes statistiques peuvent être appliquées , mais ﬁltrées sur la base de concepts correspondant à ces scénarios médicaux spéciﬁques . Cette heuristique combinée statistique et ontologique a surpassé à la fois une approche statique pure et une approche purement ontologique . Zhou et al . [ 2007 ] a franchi une étape supplémentaire en intégrant des types sémantiques . En utilisant des concepts , des types sémantiques et des statistiques de corpus , ils ont pu dériver les relations implicites entre les concepts , et les utiliser pour l’expansion des requêtes . Cette approche s’est révélée la plus eﬃcace lors du volet Genomics du challenge TREC 2006 [ Zhou et al . , 2006 ] . Les travaux décrits sont principalement centrés sur le do - maine de la génomique , qui est un scénario de recherche très précis . Les requêtes sont fournies sous la forme « Gène ( 1 . . n ) Processus biologique ( 1 . . m ) » et la tâche est de retourner des informations pertinentes sur les gènes spéciﬁques . Par conséquent , un certain nombre de méthodes sont spéciﬁques à ce domaine et ne peuvent pas être ap - pliquées à d’autres scénarios . Cependant , ils soulignent que les approches couronnées de succès utilisent généralement à la fois les connaissances du domaine et les méthodes statistiques , basées sur les données . 57 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ 2 . 7 Évaluation des systèmes de recherche d’infor - mation en santé L’objectif principal de l’évaluation des Système de Recherche d’Information ( SRI ) est de mesurer la façon dont un besoin d’information d’un utilisateur est satisfait par une liste de documents renvoyés pour une requête spéciﬁque . Il existe une longue his - toire d’évaluation empirique en RI et des évaluations robustes des SRI sont enracinées dans la communauté RI [ Cleverdon , 1991 ] . Cette partie passe en revue certains des travaux connexes dans l’évaluation . 2 . 7 . 1 Métriques L’évaluation en RI repose sur des mesures statistiques de l’eﬃcacité du système de RI . La plupart des mesures sont conçues pour quantiﬁer deux éléments : la précision et le rappel [ Manning et al . , 2008 ] . La précision est la mesure du nombre de docu - ments pertinents récupérés par le SRI parmi tous les documents , ou plus formellement ( équation 2 . 8 ) : precision SRI = | D rel ∩ D ret | | D ret | ( 2 . 8 ) où D ret représente l’ensemble des documents récupérés par les SRI et D rel l’ensemble des documents pertinents . Parallèlement , le rappel est la mesure du nombre de documents pertinents récupérés parmi tous les documents pertinents ( équation 2 . 9 ) : rappel SRI = | D rel ∩ D ret | | D rel | ( 2 . 9 ) En RI médicale , il existe diﬀérents cas d’utilisation nécessitant soit la maximisa - tion de la précision , soit du rappel . Un scénario commun où les deux sont nécessaires est le cas de la recherche de patients éligibles à l’inclusion dans les essais cliniques [ Voorhees et Hersh , 2012 ] . Les essais cliniques sont conduits pour le développement de nouveaux médicaments ou procédures médicales . Trouver des patients satisfaisants aux critères pour mener un essai clinique peut être vu essentiellement comme un pro - blème de RI - les critères d’inclusion d’essai clinique étant le besoin d’information et les dossiers des patients étant le corpus de documents . Pour un besoin d’information concernant la recherche de patients atteints d’une maladie rare , il est très important que le SRI renvoie tous les documents pertinents ( rappel maximal ) . Dans ce cas , l’uti - lisateur préférerait inclure de nombreux patients non pertinents que manquer l’un des rares patients pertinents dans son groupe . Inversement , pour une maladie commune , où il ya un grand nombre de patients pertinents , la précision est importante . Les utilisa - 58 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ teurs du SRI n’ont pas besoin de tous les documents pertinents , mais ils ne souhaitent pas lire des documents non pertinents . La précision et le rappel sont incorporés dans un certain nombre de mesures d’évaluation standard . La précision à certaines positions de classement - par exemple la précision à 10 - mesure le nombre de documents pertinents jusqu’à la position de rang stipulée . Étant donnée une position de rang n , la précision @ n est ( équation 2 . 10 ) : precision @ n = P ni = 1 rel ( d i ) n ( 2 . 10 ) où rel ( d i ) représente une fonction , telle que rel ( d i ) = 1 si le document d i est pertinent et rel ( d i ) = 0 sinon . Cette mesure serait la plus appropriée lorsque la maximisation de la précision est importante , par exemple dans le cas de la recherche de maladies ou de maladies cou - rantes . Le rappel peut également être mesuré à des positions de classement spéciﬁques ( équation 2 . 11 ) : rappel @ n = P ni = 1 rel ( d i ) R ( 2 . 11 ) où R représente le nombre total de documents pertinents . La position de rang n est souvent déﬁnie sur le nombre total de documents renvoyés . Plutôt que de disposer de deux mesures distinctes pour la précision et le rappel , il est intéressant d’avoir une mesure qui englobe les deux composantes . La précision moyenne ( AP ) permet ceci et est calculée comme suit ( équation 2 . 12 ) : AP = 1 R N X n = 1 P @ n ( 2 . 12 ) où R représente le nombre de documents pertinents et N le nombre de documents renvoyés . On peut également calculer la précision moyenne à travers l’ensemble des requêtes Q , mesure appelée Mean Average Precision ( MAP ) : MAP = P q ∈ Q AP ( q ) Q | ( 2 . 13 ) La MAP est une mesure largement utilisée dans l’évaluation de la RI ( équation 2 . 13 ) . Cependant , elle s’appuie sur l’hypothèse de l’exhaustivité : tous les documents perti - nents au sein d’une collection d’essais ont été identiﬁés [ Cleverdon , 1991 ] . Lorsque cette hypothèse n’est pas vériﬁée ( c’est - à - dire qu’un nombre important de documents pertinents ne sont pas évalués ) , les mesures d’évaluation standard décrites ci - dessus ne sont pas robustes . Pour faire face à cette situation , Buckley et Voorhees [ 2004 ] ont présenté la mesure d’évaluation bpref qui est conçue pour traiter des informa - 59 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ tions incomplètes ( équation 2 . 14 ) . Cette mesure ne considère que les documents qui sont explicitement évalués , alors que d’autres mesures supposent généralement que les documents non jugés sont sans pertinence . bpref est calculé comme suit : bpref = 1 | R | X r ∈ R 1 − | ∀ n ( n ∈ ¯ R ∧ n < r ) | | R | ! ( 2 . 14 ) où r représente un document dans l’ensemble des documents pertinents noté R , n est un document non pertinent dans l’ensemble de documents non pertinents ¯ R , tel que n se produit avant r dans la liste classée . Les documents qui n’ont pas été évalués en fonction de leur pertinence n’aﬀectent donc pas la mesure . 2 . 7 . 2 Campagnes de test et évaluation Conférence Text REtrieval ( TREC ) La méthodologie d’évaluation et les mesures décrites dans la partie précédente sont au cœur de la campagne d’évaluation de la Conférence Text REtrieval ( TREC ) [ Voo - rhees et Harman , 2005 ] . TREC vise à fournir une plateforme commune pour évaluer les SRI en développant des collections d’évaluation . Une collection de test est composée d’un corpus de documents , d’un ensemble de requêtes ( souvent appelées rubriques ) et d’un ensemble de jugements de pertinence fournis par des utilisateurs experts . Le corpus documentaire et les requêtes associées sont mis à la disposition des équipes participant à la campagne . Les équipes utilisent la méthode qu’elles ont élaborée pour exécuter les requêtes et soumettent leurs résultats , sous la forme d’une liste classée de docu - ments , aux organisateurs du TREC . Les organisateurs évaluent ensuite la contribution de chaque équipe en fonction des jugements de pertinence . Les premières collections de test comportaient un petit nombre de documents . Par exemple , les collections d’articles ACM ( CACM ) ne contiennent que 3 024 documents . De petites collections de docu - ments peuvent être évaluées complètement par des juges experts . Toutefois , à mesure que les collections de documents se sont développées - la collection ClueWeb contient 1 , 2 milliard de documents Web - il est devenu impossible d’évaluer tous les documents . Pour faire face à cette question , TREC a utilisé des techniques de mise en commun pour sélectionner un sous - ensemble approprié de documents pour évaluation par des experts . Le regroupement se fait en prenant un échantillon de documents pour chaque requête de chaque équipe participante . Ces documents sont fusionnés en un ensemble unique ( appelé le pool ) , qui est ensuite fourni aux évaluateurs experts . Si des systèmes suﬃsamment divers contribuent au pool , un sous - ensemble représentatif du document sera évalué et les jugements de pertinence ne devraient pas favoriser un système par - ticulier . TREC est organisé en sous - déﬁs distincts , appelés Tracks , qui se concentrent 60 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ sur des applications de RI particulières ( par exemple le Web Track est spéciﬁque à la recherche de documents Web ) . En 2011 , TREC a lancé le MedTrack ( Medical Records Track ) , conçu pour « encourager la recherche sur la technologie permettant de récupé - rer les dossiers de santé électroniques sur la base du contenu sémantique des champs de texte libre » [ Voorhees et Hersh , 2012 ] . La collection de documents utilisée dans TREC MedTrack comprenait 100 866 documents issus de dossiers cliniques désidenti - ﬁés provenant d’hôpitaux américains . Les thèmes et jugements de pertinence ont été créés par les médecins , les sujets reﬂétant les types de requêtes qui pourraient être utilisés pour identiﬁer les patients admissibles à l’inclusion dans les essais cliniques . Conference and Labs of the Evaluation Forum ( CLEF ) La conférence CLEF se compose d’une conférence indépendante évaluée par des pairs sur un large éventail de questions dans les domaines de l’évaluation de l’accès à l’information multilingue et multimodale et d’un ensemble de laboratoires et d’ateliers conçus pour tester diﬀérents aspects des systèmes de recherche d’information mono et inter langues . Elle propose plusieurs campagnes d’évaluation de la recherche d’in - formation , en particulier basées sur l’expérimentation et les tâches partagées : CLEF Labs , TREC , NTCIR , FIRE , MediaEval , RomIP , SemEval , TAC . L’une de ces cam - pagnes , CLEF eHealth , est dédiée au développement de méthodes de traitement et de ressources dans un contexte multilingue pour enrichir le texte libre numérisé dans le domaine de la santé . La campagne propose plusieurs tâches liées aux problématiques de recherche d’information et d’extraction d’information dans le domaine de la santé . En 2016 , trois tâches ont été étudiées : l’extraction de l’information de transfert liée aux changements de soins inﬁrmiers australiens , l’extraction de l’information dans des corpus cliniques francophones et enﬁn la recherche d’information multilingue axée sur le patient en tenant compte des variations de requête [ Kelly et al . , 2016 ] . Campagnes de test i2b2 La vaste adoption de la plateforme i2b2 permet l’organisation annuelle de cam - pagnes de test dédiées particulièrement aux tâches d’extraction de l’information dans les documents cliniques . Des corpus spéciﬁques sont diﬀusés et leur annotation est évaluée de façon indépendante . Par exemple , la campagne 2012 se concentrait sur les relations temporelles dans les comptes - rendus cliniques . Un corpus de résumés de dé - charge annotés avec des informations temporelles , utilisés pour le développement et l’évaluation de systèmes de raisonnement temporel était fourni . L’évaluation portait sur l’annotation ( 1 ) d’événements cliniquement signiﬁcatifs , y compris les concepts cli - niques tels que les problèmes , les tests , les traitements et les services cliniques , ainsi que les événements pertinents pour l’historique clinique du patient , tels que les ad - missions , les transferts entre les départements , etc . ( 2 ) les expressions temporelles , en 61 CHAPITRE 2 . LA RECHERCHE D’INFORMATION EN SANTÉ se référant aux phrases de dates , heures , durées ou fréquences dans le texte clinique et ( 3 ) les relations temporelles , entre les événements cliniques et les expressions tem - porelles [ Sun et al . , 2013 ] . La campagne 2016 se concentrait sur les problématiques de dé - identiﬁcation des textes et comptes - rendus cliniques ainsi que l’annotation de termes psychiatriques . 2 . 8 Synthèse Dans cette partie , nous avons déﬁni la notion d’information en santé et décrit les ressources disponibles ainsi que leurs représentations dans diﬀérents SOC . Plusieurs de ces SOC seront exploités plus loin dans cette thèse , à la fois dans la modélisation de données pour l’intégration de données clinomiques dans les DPI et dans l’indexation de textes médicaux à l’aide de vocabulaires contrôlés : l’UMLS , la CIM10 , la SNOMED CT et le MeSH pour citer les principaux ou encore la Gene Ontology plus spéciﬁque à la problématique de gestion des données clinomiques . L’organisation des données au sein des DPI et d’entrepôts de données dédiés à la recherche clinique et translationnelle a également été abordée . Les systèmes disponibles et décrits ici ont pour point commun de proposer uniquement des fonctionnalités sur des cohortes de patients tandis que la solution développée dans le cadre de cette thèse permet la manipulation de données cliniques et omiques à l’échelle d’un ou plusieurs patients . Enﬁn , nous avons décrit les diﬀérents méthodes et modèles d’indexation et de re - cherche d’information applicables au domaine de la santé . Dans cette thèse , nous nous concentrerons sur l’indexation à l’aide de vocabulaires contrôlés appliquée à des textes médicaux . La structuration de ces informations est en eﬀet un verrou important pour une RI eﬃcace , dans les DPI mais aussi d’autres textes comme des certiﬁcats de décès exploités ici . L’organisation des connaissances est ainsi centrale dans cette thèse . 62 Chapitre 3 Modélisation de données omiques et cliniques pour le Dossier Patient Informatisé Sommaire 3 . 1 L’intégration de données hétérogènes . . . . . . . . . . . . 64 3 . 2 Le projet RAVEL . . . . . . . . . . . . . . . . . . . . . . . . 66 3 . 2 . 1 Le modèle de données RAVEL . . . . . . . . . . . . . . . . . 66 3 . 2 . 2 Données cliniques . . . . . . . . . . . . . . . . . . . . . . . . . 67 3 . 3 Collecte de données omiques . . . . . . . . . . . . . . . . . . 68 3 . 3 . 1 Bases de connaissances . . . . . . . . . . . . . . . . . . . . . . 68 3 . 3 . 2 Données expérimentales . . . . . . . . . . . . . . . . . . . . . 69 3 . 4 Recensement des types de données omiques . . . . . . . . 70 3 . 4 . 1 Les diﬀérents types de données omiques . . . . . . . . . . . . 70 3 . 4 . 2 Niveaux d’interprétation des données omiques . . . . . . . . . 71 3 . 5 Modèle de données omiques . . . . . . . . . . . . . . . . . . 74 3 . 5 . 1 Gestion des études omiques . . . . . . . . . . . . . . . . . . . 74 3 . 5 . 2 Gestion des données d’expression et de quantiﬁcation . . . . 75 3 . 5 . 3 Gestion des données de variants . . . . . . . . . . . . . . . . . 75 3 . 6 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 63 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Dans ce chapitre , il s’agit de présenter les diﬀérentes étapes ayant permis la concep - tion d’un modèle générique des données cliniques et omiques . Le développement de la partie clinique du modèle réalisé par l’équipe du D2IM du CHU de Rouen s’est déroulé dans le cadre du projet RAVEL . Le développement de la partie omique dont j’avais la tâche a nécessité plusieurs étapes décrites ici : d’abord le recensement et l’identiﬁ - cation des diﬀérents types de données omiques , ensuite la collecte de données auprès de divers acteurs et enﬁn la modélisation de ces données . La conception de ce modèle implique ainsi la coordonnation de types de données hétérogènes : les données cliniques et administratives du patient , essentiellement textuelles et numériques , et des données de biologie moléculaire . 3 . 1 L’intégration de données hétérogènes L’intégration de données hétérogènes est une problématique grandissante avec l’ex - pansion rapide des connaissances biomédicales , la réduction des coûts informatiques et la diﬀusion de l’accès à Internet . Aujourd’hui , les bases de données mondiales contiennent des données biomédicales allant des résultats cliniques d’un patient in - dividuel à la structure génétique de notre espèce . Beaucoup de ces systèmes sont ac - cessibles via Internet . Dans l’ensemble , ces données englobent de l’information et des connaissances qui peuvent améliorer considérablement la recherche fondamentale , les soins aux patients et la santé publique . Cependant , le volume et la disponibilité excep - tionnels de ces données ont augmenté grâce à un processus largement décentralisé qui a permis aux organisations de répondre à des besoins de données spéciﬁques ou locaux sans les obliger à coordonner et à normaliser leurs implémentations de base de données . Ce processus a abouti à une mosaïque hétérogène de sources de données , rendant leur accès et leur agrégation diﬃciles d’un point de vue pratique [ Hamid et al . , 2009 ] . Ainsi , de plus en plus , l’analyse de données exige l’utilisation de données générées et gérées par des tiers . La variété des données utilisées , autant que l’échelle des données analysées , peut ainsi s’avérer un facteur limitant dans les eﬀorts d’analyse des données . Avec l’avènement du traitement de données de masse en sciences , les données peuvent provenir à des échelles signiﬁcatives à partir d’une seule machine ( comme les séquen - ceurs haut débit ) ou peuvent être réparties entre scientiﬁques dans un projet distribué à grande échelle . Dans ces cas , de plus en plus les communautés développent des vo - cabulaires contrôlés ou des ontologies et des normes de métadonnées pour les eﬀorts d’intégration de données . La possibilité de fédérer des données dans des ensembles de données , des catalogues et des domaines peut fournir aux utilisateurs la possibilité de trouver , d’accéder , d’intégrer et d’analyser des combinaisons d’ensembles de données en fonction de leurs besoins . Plusieurs grandes étapes nécessaires à l’intégration de données hétérogènes peuvent 64 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES être identiﬁées : la découverte et la collecte des données , l’intégration des données à proprement parler et leur validation [ Hendler , 2014 ] . La découverte de données per - tinentes à un projet est la première étape réelle . La recherche de données est complexe , même dans un entrepôt , mais à l’extérieur d’un entrepôt , et sur le Web , elle est encore plus diﬃcile . Plusieurs approches explorent la façon dont divers types de métadonnées peuvent être utilisées pour faciliter l’exploration des données comme la recherche fa - cettée ou l’utilisation de métadonnées plus précises voire spéciﬁques au domaine . Par exemple , pour les données de recherche scientiﬁque , la Research Data Alliance 1 a créé un certain nombre de groupes de travail qui explorent le développement de normes de métadonnées pour des domaines scientiﬁques spéciﬁques . D’autres approches ont exploré l’extraction de métadonnées à partir de descriptions de données ou de données structurées sur des pages Web [ Cafarella et al . , 2011 ] . L’intégration de données peut s’envisager sous plusieurs formes . Le schéma relation - nel traditionnel centré autour du concept d’une table ( ou relation ) qui se compose de lignes et de colonnes ( attributs ) . Le modèle relationnel est une méthode bien connue et robuste de représentation des données , mais l’une de ses principales critiques est que la modélisation d’objets structurés , de hiérarchies , tel que les entités biologiques , n’est pas immédiatement intuitive pour quiconque , à l’exception des concepteurs [ Stein , 2003 ] . L’utilisation de données semi - structurées libère de la structure rigide du modèle de données relationnelles [ Achard et al . , 2001 ] . Les données semi - structurées sont essen - tiellement des données avec une série d’étiquettes et de valeurs associées . XML est un format recommandé par le WWW Consortium pour l’échange de données sur le Web et est parfaitement adapté pour décrire les données semi - structurées [ Abiteboul et al . , 2000 ] . En termes de représentation des données et connaissances , l’utilisation d’onto - logies présente l’avantage supplémentaire de faciliter l’interaction entre les chercheurs dans diﬀérents domaines du savoir et de permettre l’interopérabilité entre les bases de données et les programmes , qui sont essentiels au travail collaboratif en sciences [ Bodenreider , 2008 ] . Enﬁn , La validation des données vise à mettre en évidence certains des problèmes largement rencontrés lors de l’intégration de données hétérogènes : les données man - quantes , les données saisies incorrectement ou d’autres problèmes communs de " données sales " . Souvent , l’intégration des données permet de mettre en évidence ces problèmes qui n’étaient pas visibles lorsque les données étaient étudiées individuellement [ Hend - ler , 2014 ] . 1 . https : / / rd - alliance . org / 65 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES 3 . 2 Le projet RAVEL Aujourd’hui , avec le développement des DPI , la quantité de données cliniques aug - mente constamment et ces données deviennent ﬁnalement accessibles aux patients . Les DPI contiennent une grande variété de données cliniques hétérogènes qui présentent dif - férentes valeurs d’information et décisionnelles pour les professionnels de la santé : elles sont utilisées de diﬀérentes façons et dans diﬀérentes situations . En outre , une grande quantité de données sont encore enregistrées sous forme de documents non structurés et narratifs , bien que ces données contiennent des informations cruciales dans un pro - cessus de soins de santé plus eﬃcace , telles que des notes cliniques , des observations , des rapports récapitulatifs pour n’en nommer que quelques - uns . La simple accumula - tion de données cliniques dans les DPI , ainsi que leur diversité , entraîne le risque de débordement d’information tant pour les praticiens de la santé que pour les patients . En outre , on estime que jusqu’à 50 % de l’information clinique nécessaire pour décrire le séjour hospitalier des patients n’est disponible que dans des documents descriptifs non structurés dans les dossiers des patients [ Turchin et al . , 2006 ] . Ainsi , l’évolution des dossiers des patients vers le DPI entraîne des paradoxes : les données sont exhaustives , mais peu exploitées et ne proposent pas de présentation structurée et hiérarchisée , ce qui freine le processus décisionnel par les médecins . Il est donc essentiel de fournir des outils de recherche et de visualisation robustes et eﬃcaces pour les données DPI . Dans ce cadre , le projet RAVEL étudie et met en œuvre : ( i ) les méthodes d’indexation les plus récentes aﬁn d’enrichir les données des DPI sémantiquement structurées et non structurées . Cet enrichissement sera utile pour ( ii ) l’optimisation de la récupération de l’information , et ( iii ) la visualisation des données des patients . 3 . 2 . 1 Le modèle de données RAVEL L’utilisation d’un DPI est devenue une pratique courante dans tous les hôpitaux . Les modèles de ces DPI varient d’un hôpital à l’autre , mais ils sont le plus souvent complexes . À titre d’exemple , le DPI du CHU de Rouen contient plus de 100 entités . Le modèle de données RAVEL décrit comment sont représentées les données cliniques dans la base de données . Il s’appuie sur une base de données relationnelle aﬁn de stocker les données cliniques . Il est basé sur un modèle conceptuel générique [ Dirieh Dibad , 2012 ] compact , optimisé pour la recherche d’information . Il est composé de onze entités dans lesquelles sont réparties les informations concernant les séjours , analyses et actes médicaux , prescriptions et informations civiles . La Figure 3 . 1 représente ces entités et leurs attributs et relations . Ce modèle de données RAVEL est intégré au méta modèle utilisé dans le système d’information CISMeF ( voir la section 4 . 1 . 2 ) . L’équipe CISMeF a conçu un modèle logique générique de données pouvant encapsuler n’importe quel modèle . Ce modèle se 66 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Figure 3 . 1 – Modèle physique des données RAVEL . compose en deux parties : d’une part le « modèle » pour déﬁnir un modèle conceptuel de données et d’autre part l’instance du modèle pour stocker les données elles - mêmes . Dans le système d’information CISMeF , ce méta modèle intègre l’ensemble des ressources terminologiques et des documents indexés . 3 . 2 . 2 Données cliniques Actuellement , le CHU de Rouen utilise le logiciel C Page Dossier Patient ( CDP ) pour la gestion des dossiers patients informatisés ( environ 1 800 000 ) . Parmi ces dossiers , 2 021 ont d’abord été sélectionnés selon des critères médicaux ( spécialités et complexité ) puis dé - indentiﬁés pour être intégrés à RAVEL . Ces dossiers comportent les données concernant ( i ) le patient ( âge , sexe ) , ( ii ) les séjours , ( iii ) les actes médicaux , ( iv ) les analyses biologiques / imagerie , ( v ) les prescriptions . La volumétrie est de 182 000 séjours , 284 000 actes , 286 0000 analyses biologiques , 152 000 comptes - rendus pour 2 021 patients . 67 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Chaque dossier est codé par des terminologies médicales comme la CIM10 ou la CCAM grâce au codage Programme de Médicalisation des Systèmes d’Information ( PMSI ) , réalisé manuellement par des experts ( le plus souvent des médecins ) après chaque hospitalisation . Le but de ce programme est à l’origine de la facturation des actes et du suivi des patients ( visée socio - économique ) . 3 . 3 Collecte de données omiques 3 . 3 . 1 Bases de connaissances Aﬁn de disposer d’informations de référence pour décrire des données omiques ex - périmentales , plusieurs bases de données internationales ont été utilisées et certaines de leurs informations intégrées au modèle de données omiques . Gènes : NCBI Gene , Gene Ontology Pour la description des gènes , la banque Gene du NCBI a été utilisée [ Maglott et al . , 2007 ] . Cette base de données recueille des informations validées sur les gènes non prédits de diverses espèces , dont l’homme . Ces informations sont exhaustives , on trouve notamment le nom du gène , ses coordonnées sur le génome , son type ( codant , pseudogènes . . . ) ou encore un résumé descriptif . L’intégralité des données est accessible sous forme d’un ﬁchier binaire , convertible en XML , et est mise à jour quotidiennement . Ces informations ont été complétées des annotations issues de la GO associées aux gènes , déjà intégrées dans le système d’information de CISMeF . La GO est un projet bioinformatique destiné à structurer la description des gènes et des produits géniques dans le cadre d’une ontologie commune à toutes les espèces [ The Gene Ontology Consortium , 2008 ] . Protéines : Uniprot K / B Ensuite , concernant les protéines , la banque UniprotKB [ UniProt Consortium , 2013 ] a été utilisée aﬁn de servir de référence en particulier aux analyses d’expression protéique . Cette base de données comporte une collection d’informations fonctionnelles sur les protéines telles que le nom et la description de la protéine , sa fonction ou encore sa localisation cellulaire . UniprotKB comporte deux sections : l’une , UniprotKB / Swiss - Prot , est manuellement annotée et supervisée , l’autre UniprotKB / TrEMBL n’est pas supervisée et uniquement annotée . Seule UniprotKB / Swiss - Prot a été utilisée dans notre modèle de données . L’intégralité des données d’UniprotKB est accessible par un ﬁchier XML et est mise à jour régulièrement ( environ tous les mois ) . 68 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES barcode chromosome start stop num . mark seg . mean TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 554267 72533855 6384 0 . 0456 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 72550247 72568008 2 1 . 2471 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 72602596 74674719 93 0 . 0994 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 74693651 74877529 20 - 0 . 3621 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 74885003 74952060 7 - 0 . 6845 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 74961517 75110250 10 - 0 . 3235 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 75148401 116948645 3057 0 . 0836 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 116950995 117008722 5 - 0 . 4321 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 117014630 150816179 803 0 . 0395 TCGA - 02 - 0001 - 01C - 01D - 0185 - 02 1 150823072 150848508 4 - 1 . 5222 Figure 3 . 2 – Exemple de ﬁchier de données issu de la base de données TGCA . Phénotypes : OMIM Enﬁn , les ressources du catalogue Online Mendelian Inheritance in Man ( OMIM ) ont également été intégrées dans le but de disposer d’informations de référence concer - nant les maladies génétiques [ Hamosh et al . , 2005 ] . Les données de description de gènes incluses dans le catalogue OMIM n’ont pas été utilisées puisque redondantes avec la base NCBI Gene , seules les données correspondant à la description des phénotypes ont été considérées . Elles complètent les données d’Orphanet , une base de données concer - nant les maladies orphelines , également intégrée au système d’information CISMeF . 3 . 3 . 2 Données expérimentales Pour appuyer la modélisation des données omiques , j’ai préalablement collecté di - vers types de données expérimentales , aﬁn de les étudier et par la suite de peupler la base de données . The Genome Cancer Atlas Les données issues du portail The Genome Cancer Atlas ( TGCA ) ont été principa - lement utilisées . Le portail TGCA est un projet débuté en 2005 dont l’objectif est de cataloguer les mutations génétiques responsables de cancers , en utilisant les techniques d’analyse omiques et la bioinformatique . Le projet , supervisé par le NIH américain , a la particularité de proposer des cohortes de patients importantes ainsi qu’une grande diversité d’études omiques et de techniques diﬀérentes couvrant 33 types de cancers et représentant plus de 2 pétabytes de données . Les données sont disponibles au format texte tabulé ( voir Figure 3 . 2 ) . Variations génétiques Dans le cadre de la collaboration avec plusieurs laboratoires de recherche , plusieurs jeux de données omiques ont été obtenus . Le laboratoire INSERM U918 Génétique 69 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Tableau 3 . 1 – Les diﬀérents types de données en sciences omiques . Type de données Technologie utilisée Analyse du nombre de copies Altération du nombre de copies pour une région segmentée par échantillon Méthylation de l’ADN Valeurs beta calculées pour une région génomique par échan - tillon Expression : exon Signal d’expression normalisé par exon par échantillon Expression : gène Signal d’expression normalisé par gène par échantillon Expression : miRNA Signal d’expression normalisé par miRNA par échantillon Expression : jonction Signal d’expression normalisé par jonction par échantillon Expression : transcrit Signal d’expression normalisé par transcrit par échantillon Expression : protéine Signal d’expression normalisé par protéine par échantillon Gènes de fusion Signal d’expression normalisé par protéine par échantillon Variants Variants validés par échantillon et Clinique des proliférations Lyphoïdes du Centre H . Becquerel , dirigé par le Pr . F . Jardin , nous a fourni les données d’analyse Comparative Genomic Hybridization ( CGH ) de 20 patients . L’équipe du Dr . D . Campion ( INSERM 614 Génétique du cancer et des maladies neuropsychiatriques , dirigé par le Pr . T . Frébourg ) nous a permis d’utiliser les données de séquençage d’exomes de 120 patients atteints de la maladie d’Alzheimer . 3 . 4 Recensement des types de données omiques Préalablement à la conception du modèle de données omiques , il a été nécessaire de réaliser une revue exhaustive des diﬀérents types de données que devait prendre en charge le modèle de données . Une vue d’ensemble de ces diﬀérents types de données s’avère en eﬀet nécessaire aﬁn de développer un modèle générique et ﬂexible , seule solution nous semblant adaptée à l’hétérogénéité des données omiques . 3 . 4 . 1 Les diﬀérents types de données omiques Les sciences omiques ciblent diﬀérents objectifs et génèrent ainsi diﬀérents types de données . Il peut s’agir de détection de variants ou d’analyse d’expression de seg - ments génomiques tels que des gènes , exons ou encore de protéines . Aﬁn de cerner les diﬀérentes données générées par les scientiﬁques ainsi que leurs besoins , j’ai été ame - née à rencontrer plusieurs acteurs de la recherche utilisant couramment les techniques d’analyse omique en laboratoire . 70 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Données quantitatives Dans le cas de données de quantiﬁcation , il s’agit dans la plupart des cas d’une valeur numérique , représentant le taux d’expression d’une entité ( sonde , gène , pro - téine , exon . . . ) ou encore le taux de méthylation de l’ADN . Ces valeurs peuvent être déterminées par des technologies de puces à ADN ou de séquençage . Chacune de ces entités peut présenter des caractéristiques diﬀérentes . Globalement , on peut discriminer ( i ) les gènes , ( ii ) les protéines et ( iii ) les segments caractérisés prin - cipalement par leur localisation sur le génome ( variants structuraux , exons , transcrits , variants d’épissage ) . Ces types sont décrits dans le Tableau 3 . 1 . Variants génétiques Les variants tels que les Single Nucleotid Polymorphism ( SNP ) et petites insertions délétions ( indels ) mais également les variants structuraux ou Structural Variant ( SV ) peuvent être représentés par des chaînes de caractères formalisées . La nomenclature Human Genome Variation Society ( HGVS ) permet en eﬀet de nommer les diﬀérents types de variations en fonction de leur localisation . Ces variants peuvent être identiﬁés par des techniques de puces à ADN ou également de séquençage . Les variants structuraux peuvent être de plus caractérisés par la valeur d’un signal correspondant à l’analyse de sondes réparties sur le génome par la technique de CGH . Cette valeur représentera par exemple la délétion ou l’insertion d’un segment . Les variants du nombre de copies ou Copy Number Variation ( CNV ) seront également caractérisés par une valeur numérique représentant le nombre de copies . 3 . 4 . 2 Niveaux d’interprétation des données omiques L’une des problématiques importantes pour la conception du modèle de données est de sélectionner les informations pertinentes dans le cadre déﬁni par l’intégration avec des données cliniques . En eﬀet , les sciences omiques génèrent des volumes de données très importants et ces données doivent être traitées et interprétées pour être exploitables à l’échelle d’un patient ou d’un groupe de patients . J’ai ainsi réalisé une catégorisation des données omiques en quatre niveaux d’interprétation , des données brutes aux données recoupées et interprétées en régions d’intérêt . Ces niveaux sont décrits sur le Tableau 3 . 2 . Les données brutes ( niveau 1 ) correspondent aux données non normalisées . Pour un séquençage , ce niveau correspond aux données brutes sorties du séquenceur . Elles peuvent être accessibles par des ﬁchiers textes ou binaires , dont le format dépendra fréquemment du matériel utilisé . Le plus souvent , le volume de données est très impor - tant ( jusqu’à plusieurs giga - octets pour une analyse ) et ces données ne peuvent être interprétées manuellement . 71 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Type Description Exemple 1 Données brutes Données non normalisées — Fichier BAM ( données de séquences ) — Fichier CEL Aﬀymetrix ( données de microarrays ) 2 Données traitées Données normalisées pour un échantillon — Signal d’une sonde ou d’un groupe de sondes par échan - tillon — Ampliﬁcation / délétion d’une sonde dans un échantillon — Mutation supposée pour un échantillon 3 Données inter - prétées Données agrégées pour un échan - tillon — Signal d’expression d’un gène pour un échantillon — Ampliﬁcation / délétion d’une région segmentée dans un échantillon — Mutation validée pour un échantillon 4 Régions d’inté - rêt Associations quantiﬁées et croisées entre diﬀérents types d’échantillons . Associations basées sur : — Anomalies moléculaires — Caractéristiques de l’échan - tillon — Variables cliniques — Une région génomique est ampliﬁée dans 10 % des gliomes . Tableau 3 . 2 – Les diﬀérents types de niveaux d’interprétation des données omiques . 72 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Les données traitées ( niveau 2 ) correspondent aux données normalisées par une méthode statistique comme la LOWESS par exemple . Il s’agit du signal d’une sonde ou d’un groupe de sondes pour une analyse d’expression , ou encore d’un variant supposé pour un échantillon . Ces données sont accessibles par des ﬁchiers textes sur des banques de dépôt comme Gene Expression Omnibus ( GEO ) ou ArrayExpress . Le volume de données est réduit , mais reste important . Pour une analyse d’expression de gènes , le ﬁchier de résultats concernant un seul échantillon peut aller jusqu’à une centaine de mega - octets . L’interprétation manuelle reste délicate , l’information concernant des sondes ou des variants non validés . Les données interprétées ( niveau 3 ) regroupent des données qui ont été agrégées pour un échantillon . Par exemple , pour l’analyse d’expression de gènes , il s’agira du signal d’expression d’un gène , les signaux des sondes correspondant à ce gène ayant été agrégés ou encore d’un variant validé . Ce type de données est disponible en ﬁchier texte , le plus souvent tabulé . Cependant , il n’existe pas de standard établi . Le volume de données est dans ce cas réduit , un ﬁchier de résultats pour une analyse d’expression peut représenter de quelques kilo - octets jusqu’à 1 Mo , selon le nombre de gènes analysés . Ce niveau de données n’est pas accessible dans les banques de dépôt ArrayExpress et GEO , qui ne proposent que des données de niveau 1 et 2 . Peu de banques de données proposent ces données interprétées . Le portail TGCA oﬀre les données recueillies dans une vingtaine d’études impliquant jusqu’à plusieurs centaines de patients . Les tech - niques utilisées sont variées et couvrent tous les types de données vus précédemment . Dans ce cas , on dispose d’informations validées et exploitables . Ce niveau de données paraît donc pertinent à intégrer dans un dossier médical . Le Tableau 3 . 3 présente pour chaque type de données l’information de niveau 3 correspondante . Enﬁn , les données interprétées et agrégées correspondent au niveau d’interprétation le plus élevé ( niveau 4 ) . Il s’agit de réaliser des associations quantiﬁées et croisées entre diﬀérents types d’échantillons aﬁn d’isoler une région d’intérêt . Cette interprétation approfondie des données omiques nécessite une expertise biostatistique et biologique humaine pointue . L’aboutissement à ce niveau d’interprétation est notamment l’un des buts de la plateforme tranSMART . Très peu de ressources sont disponibles de façon standardisée et formalisée . De plus , de telles données ne s’appliquent plus à l’échelle du patient , mais à celle du phénotype , il n’est donc pas adapté à l’intégration avec des données cliniques . Cependant , les régions d’intérêt isolées représentent une information pertinente , notamment à des ﬁns de diagnostic ou de recherche . Ainsi , le développement du modèle de données omiques est basé sur les données omiques de niveau 3 . En eﬀet , elles semblent les plus adaptées à ﬁgurer dans un dossier médical . Elles présentent directement une information exploitable telle qu’un variant validé ou la délétion d’un segment génomique . Elles sont donc les plus pertinentes , à 73 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES la fois pour la visualisation dans le dossier médical et pour la recherche d’information . Type de données Niveau 3 : Description Variants structuraux Altération d’une région segmentée par échantillon Analyse du nombre de copies Altération du nombre de copies pour une région segmentée par échantillon Méthylation de l’ADN Valeurs bêta calculées pour une ré - gion génomique par échantillon Expression : exon Signal d’expression normalisé par exon par échantillon Expression : gène Signal d’expression normalisé par gène par échantillon Expression : miRNA Signal d’expression normalisé par miRNA par échantillon Expression : jonction Signal d’expression normalisé par jonction par échantillon Expression : transcrit Signal d’expression normalisé par transcrit par échantillon Expression : protéine Signal d’expression normalisé par protéine par échantillon Variants ( SNP , indels ) Variants validés par échantillon Tableau 3 . 3 – Description du niveau d’interprétation 3 pour les principaux types de données omiques sélectionnés pour concevoir le modèle de données . 3 . 5 Modèle de données omiques Le modèle de données omiques se compose de trois parties principales ( voir Figure 3 . 3 ) gérant ( i ) les informations concernant l’étude réalisée et le laboratoire responsable , ( ii ) les données de variants de type SNP / indels et ( iii ) les données d’expression ou globalement de quantiﬁcation [ Cabot et al . , 2014 ] . 3 . 5 . 1 Gestion des études omiques Cette partie gère les informations concernant l’étude omique réalisée . L’entité OMI _ LAB regroupe les informations concernant le ( ou les ) laboratoire ( s ) ayant conduit l’étude . Ensuite , les informations concernant les responsables de l’étude sont représentées par l’entité OMI _ SUBMITTER . Les données liées à l’étude telles que son nom , l’équipement 74 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES utilisé ou le protocole sont représentées par l’entité OMI _ STUDY . Dans certains cas , en particulier si l’étude porte sur une analyse d’expression , les valeurs numériques obte - nues peuvent être décrites par une unité de mesure . Cette information correspond alors à l’entité OMI _ UNITS , accompagnée de sa signiﬁcation . 3 . 5 . 2 Gestion des données d’expression et de quantiﬁcation L’objet de l’analyse quantitative peut être de trois types : ( i ) un gène , ( ii ) , une pro - téine , ( iii ) tout segment caractérisé par une position de début et de ﬁn . Ces informations sont représentées respectivement par les entités GENE , PROTEIN et OMI _ SEGMENT . L’entité GENE représente les données de l’intégralité des gènes et des microARN identiﬁés chez l’Homme , issues de la base de données Gene du NCBI . Chaque gène est associé à ses annotations GO , ainsi qu’aux maladies références dans OMIM qui lui sont liées . De la même manière , l’entité PROTEIN contient les informations concer - nant l’intégralité des protéines isolées chez l’Homme , issues de la base de données UniprotKB / Swissprot . Chaque entrée est également liée aux annotations GO et aux maladies OMIM ou Orphanet associées . Pour chaque analyse d’expression de gènes ou de protéines , les données utilisées sont donc issues de ces deux bases de données exhaustives et supervisées , régulièrement mises à jour , aﬁn de garantir d’une part la qualité des données et d’autre part d’accélérer l’intégration de données expérimentales . En eﬀet , la disponibilité des données de gènes et de protéines dans notre base de données permet d’éviter l’intégration progressive de ces informations , au fur et à mesure de l’intégration de données expérimentales . L’entité SEGMENT est générique et peut représenter les données d’exons , de transcrits ou encore de variants de structure ( larges insertions et délétions ) . Chaque segment est lié au ( x ) entité ( s ) GENE correspondante ( s ) , selon les positions de début et de ﬁn , et du chromosome . Chaque segment est ainsi également associé aux protéines correspon - dantes , aux termes GO du ( des ) gène ( s ) ainsi qu’aux données de pathologies OMIM ou Orphanet associées au ( x ) gène ( s ) . La valeur numérique associée à chaque segment , gène , ou protéine analysés est stockée dans la table OMI _ QUANTIF . Chaque entrée est accompagnée de clés étrangères liant l’étude et le patient ( modèle RAVEL ) concernés . Les données stockées sont la valeur brute obtenue lors de l’analyse ainsi que la valeur normalisée , l’interprétation de cette valeur ( une délétion ou insertion par exemple dans le cas d’une analyse de variants structuraux ) et enﬁn éventuellement un commentaire . 3 . 5 . 3 Gestion des données de variants Les informations concernant les variants de type SNP et indels sont représentées par l’entité OMI _ VAR . Ces données comportent notamment les informations telles que le 75 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES S e qu e n ce va r i a n t s C li n i ca l d a t a S t ud y i n f o r m a t i on E x p r ess i on d a t a f o r g e n es , ex on s , s p li ce j un c t i on s , m i RNA , p r o t e i n s C op y nu m b e r r es u l t s & L O H DNA - m e t h y l a t i on RDF _ RESOURCE DM _ PAT DM _ PAT _ LASTNAME DM _ PAT _ FIRSTNAME DM _ BIRTH _ PAT DM _ SEX _ PAT RDF _ RESOURCE GENE ORIGIN _ ID GEN _ SYMBOL GEN _ ALIAS GEN _ FULLNAME GEN _ PROT _ NAME GEN _ PROT _ ALIAS GEN _ STATUS GEN _ TYPE GEN _ SUMMARY GEN _ MIM T _ DESC _ GO _ TERM _ RDF _ RES PROTEIN _ RDF _ RESOURCE GEN _ CHROM GEN _ START GEN _ END GEN _ STRAND MIM _ PHENO _ RDF _ RESOURCE RDF _ RESOURCE PROTEIN ORIGIN _ ID PRO _ ACC PRO _ ALTECNUMBER PRO _ ALTFULLNAME PRO _ ALTSHORTNAME PRO _ RECECNUMBER PRO _ RECFULLNAME PRO _ RECSHORTNAME PRO _ FUNCTION PRO _ MIM T _ DESC _ ORPHA _ DISEASE T _ DESC _ GO _ TERM _ RDF _ RES GENE _ RDF _ RESOURCE MIM _ PHENO _ RDF _ RESOURCE n , 1 n , 1 1 , n 1 , 1 1 , n OMI _ STUDY OMI _ GENOTYPE _ STATUS RDF _ RESOURCE OMI _ VAR _ DET DM _ PAT OMI _ VAR n , 1 n , 1 1 , n RDF _ RESOURCE OMI _ STUDY OMI _ STD _ TITLE OMI _ STD _ PROTOCOL OMI _ STD _ EQUIPMENT OMI _ STD _ DESC OMI _ STD _ SAMPLE OMI _ STD _ TYPE OMI _ STD _ DATE OMI _ STUDY _ HAS _ UNIT 1 , n OMI _ SEG _ BUILD RDF _ RESOURCE OMI _ SEGMENT OMI _ SEG _ START OMI _ GENE OMI _ SEG _ END OMI _ SEG _ TYPE OMI _ SEG _ NAME OMI _ SEG _ HAS _ NM OMI _ SEG _ LENGTH OMI _ SEG _ CHR 1 , n RDF _ RESOURCE OMI _ QUANTIF DM _ PAT OMI _ STUDY OMI _ QUANTIF _ COMMENT OMI _ QUANTIF _ RAW _ COUNTS OMI _ QUANTIF _ INTERP OMI _ SEGMENT _ RDF _ RES OMI _ QUANTIF _ VAL GENE PROTEIN RDF _ RESOURCE OMI _ VAR OMI _ VAR _ REF _ BUILD OMI _ VAR _ SYST _ NAME OMI _ VAR _ SYST _ NAME _ PROT OMI _ VAR _ REGION _ NAME GENE OMI _ VAR _ DBSNP OMI _ VAR _ VAR _ POS OMI _ VAR _ REGION _ TYPE OMI _ VAR _ BASE _ REF OMI _ VAR _ BASE _ MUT OMI _ VAR _ CODON _ REF OMI _ VAR _ CODON _ MUT OMI _ VAR _ HGVS _ NAME OMI _ VAR _ NEW _ VAR _ NAME OMI _ VAR _ NM _ ACC OMI _ VAR _ CAT RDF _ RESOURCE OMI _ GENE _ HAS _ SEGMENT OMI _ SEG OMI _ GENE n , 1 1 , n n , 1 1 , n RDF _ RESOURCE OMI _ UNITS OMI _ UNIT OMI _ UNIT _ MEAN OMI _ VAR _ INDEL _ LENGTH OMI _ VAR _ INDEL _ CIGAR OMI _ STD _ SOURCE RDF _ RESOURCE OMI _ SUBMITTER OMI _ SUB _ FIRSTNAME OMI _ SUB _ TEAM OMI _ SUB _ RDF _ RES OMI _ SUB _ LASTNAME OMI _ SUB _ MAIL OMI _ SUB _ PHONE RDF _ RESOURCE OMI _ LAB OMI _ LAB _ REF OMI _ LAB _ NAME HAS _ CITY HAS _ COUNTRY OMI _ LAB _ MAIL OMI _ LAB _ PHONE OMI _ LAB _ ADDRESS RDF _ RESOURCE OMI _ STUDY _ HAS _ SUBMITTER OMI _ STUDY OMI _ SUBMITTER RDF _ RESOURCE OMI _ STUDY _ HAS _ LAB OMI _ STUDY OMI _ LAB 1 , n 1 , n 1 , n Modèle de donnéescliniques Figure 3 . 3 – Modèle logique des données omiques . nom de la variation selon les diﬀérentes conventions , sa localisation , la base de référence et la base mutée dans le cas d’un SNP . Ces informations sont reliées à plusieurs autres entités . D’une part une association est faite avec le patient grâce à la table d’association OMI _ PAT _ HAS _ VAR , cette association fait alors le lien avec le modèle RAVEL des données cliniques . Pour chaque entité , une association est également existante avec l’étude . Ainsi , une même variation apparaissant chez plusieurs patients ne sera stockée qu’une seule fois , évitant toute redondance des données de variations . Enﬁn , chaque variation est également reliée au gène correspondant . Cette associa - tion permet de relier chaque variation non seulement au gène , mais également aux maladies OMIM ou Orphanet référencées pour ce gène , ou encore ses annotations GO . 3 . 6 Synthèse La conception et le développement d’un système de recherche d’information et de visualisation des données omiques et cliniques au sein d’un DPI nécessite en premier lieu un modèle de données générique gérant à la fois des données cliniques et omiques . 76 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES Le premier objectif de ce travail débuté dans le cadre de mon mémoire de master a ainsi été le recensement et l’identiﬁcation des diﬀérents types de données omiques à modéliser . Ce recensement des données et la compréhension des diﬀérentes étapes de leur analyse a mené à une classiﬁcation des types de données omiques . Ce recense - ment a également permis d’identiﬁer des acteurs clés pour d’une part regrouper des informations et connaissances servant l’exploitation ultérieure des données et d’autre part mettre au point des jeux de données expérimentales en vue de leur utilisation dans l’application prototype . Ce travail m’a permis d’aboutir à un modèle de données omiques générique , compact et évolutif capable de gérer la vaste majorité des don - nées expérimentales aujourd’hui utilisés en recherche clinique et les informations de référence produites par la communauté scientiﬁque qui leur sont liées . 77 CHAPITRE 3 . MODÉLISATION DE DONNÉES OMIQUES 78 Chapitre 4 Recherche d’information dans les données cliniques et omiques au sein du Dossier Patient Informatisé Sommaire 4 . 1 Intégration de données cliniques et omiques . . . . . . . . 80 4 . 1 . 1 Choix des ressources à intégrer . . . . . . . . . . . . . . . . . 80 4 . 1 . 2 Intégration de terminologies et ontologies au sein du méta - modèle 3M . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 1 . 3 Données de référence . . . . . . . . . . . . . . . . . . . . . . . 82 4 . 1 . 4 Données expérimentales . . . . . . . . . . . . . . . . . . . . . 85 4 . 1 . 5 Lien avec les données cliniques . . . . . . . . . . . . . . . . . 87 4 . 2 Recherche d’information clinomique . . . . . . . . . . . . . 87 4 . 2 . 1 Moteur de recherche CISMeF . . . . . . . . . . . . . . . . . . 87 4 . 2 . 2 Requête dans les données omiques . . . . . . . . . . . . . . . 90 4 . 3 Résultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 4 . 3 . 1 Comparatif face aux solutions existantes : i2b2 et tranSMART 93 4 . 3 . 2 Cas clinique RAVEL en rhumatologie : polyarthrite rhumatoïde 98 4 . 4 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 79 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Ce chapitre présente les développements réalisés pour la conception d’une applica - tion prototype permettant la visualisation de données cliniques et omiques et la mise au point d’un outil de recherche dans ces données . On peut distinguer trois grandes par - ties . Tout d’abord , le premier objectif est l’intégration des données de référence et des données expérimentales sur la base du modèle de données conçu décrit dans le chapitre précédent . La seconde étape est la conception de vues permettant la visualisation des données omiques dans l’application prototype et l’adaptation du moteur de recherche existant pour les données cliniques pour permettre l’interrogation conjointe des don - nées cliniques et omiques , à l’échelle d’un ou plusieurs patients . Enﬁn , l’évaluation de notre solution est réalisée selon deux axes : l’analyse comparative avec les plateformes de référence que sont i2b2 et TranSMART et l’évaluation de la partie clinique de notre système dans le cadre du projet RAVEL à travers un cas d’usage . 4 . 1 Intégration de données cliniques et omiques 4 . 1 . 1 Choix des ressources à intégrer Le modèle de données développé est ainsi en partie basé sur l’intégration de don - nées de références externes , concernant les gènes et protéines ainsi que les pathologies associées . L’intégration de ces données externes a plusieurs objectifs . D’une part , la disponi - bilité en local de l’ensemble des gènes et protéines permet d’éviter l’interrogation de serveurs distants lors du traitement de données omiques expérimentales . D’autre part , l’accessibilité de ces données peut se révéler utile pour la recherche d’information . Enﬁn , ces données sont ainsi également accessibles sur le portail HeTOP développé par l’équipe , qui met à disposition un grand nombre de terminologies de santé dans plusieurs langues , et ce , dans plusieurs buts : aider à l’indexation ( codage , annotation ) , accéder à des ressources bibliographiques , enseigner / apprendre la médecine ou encore réaliser des audits de terminologies . Ce portail est décrit dans la section 5 . 1 . 1 . 4 . 1 . 2 Intégration de terminologies et ontologies au sein du méta - modèle 3M Le méta - modèle 3M L’interopérabilité sémantique au sein du système d’information CISMeF repose sur un modèle uniﬁé de vocabulaires nommé méta - modèle 3M développé dans le cadre de la thèse de Julien Grosjean [ Grosjean , 2014 ] . Le méta - modèle 3M est un modèle commun à tous les termes , quelle que soit la terminologie à laquelle ils appartiennent . Il peut être considéré comme un méta - modèle ou une ontologie supérieure conçue pour 80 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE supporter une interopérabilité sémantique générale entre les terminologies qui le com - posent . Le méta - modèle 3M fournit des propriétés d’alignement telles que celles déﬁnies dans le langage de la ressource considérée . Le méta - modèle est fondamentalement mul - tilingue car les termes préférés , les synonymes ou d’autres attributs textuels peuvent être déﬁnis par un code de langue ( « en » pour l’anglais , « fr » pour le français , etc . ) . Chaque terminologie incluse dans HeTOP est un enrichissement du méta - modèle 3M . Chaque enrichissement déﬁnit ses propres spécialisations de Descriptor . Les terminolo - gies incluses dans ce modèle sont mises en œuvre sous forme d’ontologies OWL légères . Le passage d’une représentation ontologique à une terminologique est basé sur un pro - cessus de réiﬁcation . De cette façon , les ontologies formelles sont « dégradées » pour s’adapter à ce modèle . Cette méthode permet de conserver les données d’origine d’une ontologie et d’enrichir le serveur avec des ressources terminologiques de santé . L’ap - proche conceptuelle utilisée dans le modèle permet l’intégration de toute langue tout en maintenant les relations entre les concepts . Méthode d’intégration Le modèle physique de données CISMeF se compose ainsi de deux parties : le « modèle » pour déﬁnir un modèle conceptuel de données et d’autre part l’instance du modèle pour stocker les données elle - mêmes ( voir la ﬁgure A . 1 en annexe ) . La partie « modèle » se compose de quatre tables préﬁxées de « MODEL » , en bas de la ﬁgure . Les entités sont stockées dans la table TB _ MODEL , les attributs dans la table TB _ - MODEL _ DATATYPE _ PROPERTY et les associations entre entités dans la table TB _ MODEL _ - DATATYPE _ PROPERTY . La table TB _ MODEL _ INHERITANCE permet de gérer les relations d’héritage . Les cinq tables TB _ OBJECT , TB _ OBJECT _ PROPERTY , TB _ DATATYPE _ PROPERTY , TB _ HIERARCHY et TB _ INDEXING permettent de gérer les objets concrets ainsi que leurs attributs et relations . Pour intégrer des terminologies dans le système d’information CISMeF , trois étapes sont nécessaires : ( i ) concevoir un modèle générique de termi - nologie dans lequel chaque terminologie peut être intégré , ( ii ) concevoir un processus capable d’intégrer des terminologies dans la base de données implémentant le modèle et ( iii ) ) construire et intégrer les relations sémantiques intra et inter - terminologie . Un modèle générique est disponible aﬁn de tenir compte de toutes les terminologies dans une structure globale . Ensuite , un modèle de chaque terminologie est conçu comme une spécialisation du méta - modèle . Avec les modèles spéciﬁques , le travail consiste à développer un analyseur pour chaque terminologie : l’entrée est la donnée d’origine ( ou les données originales normalisées ) et la sortie est un ﬁchier OWL dans le cas d’une ontologie ou un ﬁchier RDF / XML dans le cas d’une terminologie , cas appliqué ici pour l’intégration des bases NCBI Gene , Uniprot Swissprot KB et OMIM . Comme les don - nées peuvent être dans diﬀérents formats et structures , dans certains cas , des processus supplémentaires doivent être eﬀectués ( bases de données temporaires , ﬁchiers , etc . ) . 81 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE La phase ﬁnale est l’intégration des ﬁchiers OWL ou RDF / XML dans le modèle physique . Un parseur générique a été développé pour insérer directement chaque ter - minologie dans la base de données , capable de reconnaître les classes descriptrices , les déﬁnitions , les synonymes , les relations aﬁn de l’insérer très facilement dans la base de données . Implémentation du modèle de données omiques Préalablement à l’intégration de données dans le modèle décrit , Le modèle de don - nées omiques a dû être implémenté au sein du méta modèle CISMeF , en lien avec le modèle de données RAVEL . J’ai pour cela déﬁni le modèle conceptuel des données omiques dans la partie « modèle générique » du méta - modèle 3M . 4 . 1 . 3 Données de référence Le modèle de données développé s’appuie ainsi sur l’intégration de données de réfé - rences externes , concernant les gènes et protéines ainsi que les pathologies associées aﬁn de faciliter l’interrogation des données et la recherche d’information . L’intégration de ces données dans le système d’information du D2IM du CHU de Rouen fait donc appel aux étapes décrites précédemment : la création d’un modèle conceptuel des données , la création d’un parseur des données sources et enﬁn l’intégration en base de données . NCBI Gene Le NCBI met à disposition l’ensemble des données de la base Gene sur son serveur FTP , mises à jour quotidiennement , sous la forme d’un ﬁchier binaire . xgs . La première étape du traitement ( voir Figure 4 . 1 ) consiste à convertir ce ﬁchier en un ﬁchier XML exploitable , contenant uniquement les gènes identiﬁés chez Homo sapiens . Pour cela , il est traité avec un script bash , fourni par le NCBI . Le ﬁchier XML obtenu contient l’intégralité des gènes et microARN identiﬁés chez l’Homme et représente environ 9 Go . La seconde étape consiste à parser ce ﬁchier XML aﬁn d’insérer les données dans la base de données grâce au parseur Java P1 . Pour cela , la classe ParseurGene . java a été développée . Cette classe extrait les informations correspondantes au modèle de données établi en analysant les balises du document XML et réalise l’insertion en base de données . Aﬁn de suivre les mises à jour eﬀectuées chaque jour par le NCBI , le parseur P1 a été modiﬁé aﬁn qu’il soit exécutable en ligne de commande . L’ensemble des processus ( téléchargement du ﬁchier source , conversion et analyse ) est ainsi exécuté grâce à un script bash , dont le lancement est programmé quotidiennement . 82 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE RDF _ RESOURCE : VARCHAR PROTEIN ORIGIN _ ID : VARCHAR PRO _ ACC : VARCHAR PRO _ ALTECNUMBER : VARCHAR PRO _ ALTFULLNAME : VARCHAR PRO _ ALTSHORTNAME : VARCHAR PRO _ RECECNUMBER : VARCHAR PRO _ RECFULLNAME : VARCHAR PRO _ RECSHORTNAME : VARCHAR PRO _ FUNCTION : VARCHAR PRO _ MIM : VARCHAR T _ DESC _ ORPHA _ DISEASE : VARCHAR ( FK ) T _ DESC _ GO _ TERM _ RDF _ RES : VARCHAR ( FK ) GENE _ RDF _ RESOURCE : VARCHAR ( FK ) MIM _ PHENO _ RDF _ RESOURCE : VARCHAR ( FK ) RDF _ RESOURCE : VARCHAR OMIM _ PHENOTYPE ORIGIN _ ID : VARCHAR MIM _ TITLE : VARCHAR MIM _ ALIAS : VARCHAR MIM _ DESCRIPTION : VARCHAR MIM _ INHERITANCE : VARCHAR MIM _ MOL _ BASIS : VARCHAR MIM _ LAB _ ABNORM : VARCHAR MIM _ NEOPLASIA : VARCHAR T _ DESC _ ORPHA _ DISEASE : VARCHAR ( FK ) GENE _ RDF _ RESOURCE : VARCHAR ( FK ) PROTEIN _ RDF _ RES : VARCHAR ( FK ) T _ DESC _ HPO : VARCHAR ( FK ) n , 1 RDF _ RESOURCE : VARCHAR GENE ORIGIN _ ID : VARCHAR GEN _ SYMBOL : VARCHAR GEN _ ALIAS : VARCHAR GEN _ FULLNAME : VARCHAR GEN _ PROT _ NAME : VARCHAR GEN _ PROT _ ALIAS : VARCHAR GEN _ STATUS : VARCHAR GEN _ TYPE : VARCHAR GEN _ SUMMARY : VARCHAR GEN _ MIM : VARCHAR T _ DESC _ GO _ TERM _ RDF _ RES : VARCHAR ( FK ) PROTEIN _ RDF _ RESOURCE : VARCHAR ( FK ) GEN _ CHROM : VARCHAR GEN _ START : VARCHAR GEN _ END : VARCHAR GEN _ STRAND : VARCHAR MIM _ PHENO _ RDF _ RESOURCE : VARCHAR ( FK ) Base de données gene _ homo _ sapiens . xgs gene _ homo _ sapiens . xml Conversion XGS vers XML P a r s e u r P 1 24h P a r s e u r G e n e . j a v a xgs2xml . sh protein _ homo _ sapiens . xml Parseur P1 ParseurUniprot . java removed . txt P a r s e u r P 1 omim . txt P a r s e u r O M I M . j a v a 1 mois 1 2 3 1 , 1 Figure 4 . 1 – Processus d’intégration des données externes . UniprotKB Uniprot met à disposition l’intégralité de sa base UniprotKB / Swissprot sous la forme d’un ﬁchier XML d’environ 800 Mo et les données obsolètes sont mises à dispo - sition par un ﬁchier texte . Leur traitement est décrit sur la Figure 4 . 1 . L’analyse des deux ﬁchiers source , ﬁchier de données XML et ﬁchier texte contenant les données obsolètes , est réalisée par une classe Java ParseurUniprot du parseur P1 qui extrait les données sélectionnées dans le modèle de données et les insère en base de données . Les données déclarées obsolètes sont supprimées . Uniprot met à jour le ﬁchier de données sources de manière irrégulière , environ une fois par mois . Ainsi la mise à jour des données ne peut pas être ici automatisée et doit être réalisée manuellement . 83 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 2 – Capture d’écran de la page de description d’une pathologie OMIM : le cancer du sein . OMIM OMIM met à disposition ses données sous la forme d’un ﬁchier texte non structuré ou d’une API . L’accès par l’API étant limité à dix enregistrements , le ﬁchier texte non structuré a dû être utilisé . Les données concernant les gènes ayant déjà été importées de la base Gene du NCBI , seules les données concernant les pathologies ont été traitées . Certaines entrées combinant description d’un gène et d’une pathologie ont également été traitées . L’analyse des données est réalisée par la classe Java ParseurOMIM ( voir Figure 4 . 1 ) . Les données étant non structurées , le traitement des données repose principalement sur des expressions régulières ciblant les informations correspondant au modèle de données . Les données extraites sont ensuite insérées en base de données . La fréquence des mises à jour n’est pas communiquée par OMIM , elles doivent donc être lancées manuellement . Les données intégrées ont été mises à disposition sur le portail HeTOP ( voir Fi - gure 4 . 2 ) en libre accès . On peut ainsi retrouver grâce au moteur de recherche les informations concernant les gènes , protéines et pathologies OMIM intégrées ainsi que les données associées qui étaient déjà présentes sur le portail ( annotations GO , maladies Orphanet et description des phénotypes grâce à la terminologie HPO ) . La ﬁgure 4 . 2 84 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE montre les informations extraites des données d’OMIM et disponibles dans la base de données : nom du phénotype , alias de la maladie , description , mode de transcription , base moléculaire et type de la tumeur dans le cas d’un cancer . L’onglet Relations visible en haut de la page répertorie les diﬀérentes relations avec les autres terminologies et ontologies disponibles . Ici , il s’agit du gène et de la protéine liés ainsi que des maladies Orphanet correspondantes . 4 . 1 . 4 Données expérimentales L’intégration de données expérimentales lève une nouvelle problématique liée à la structuration des données . D’une part , les ﬁchiers de données décrivant une étude sont standardisés et adoptent le format IDF , correspondant à un ﬁchier texte tabulé struc - turé ( voir Figure 4 . 3b ) . Les diﬀérents champs ( nom de l’étude , nom des responsables , objet de l’étude ) sont constants . D’autre part , les résultats expérimentaux sont pré - sentés le plus souvent dans des ﬁchiers texte tabulés ( voir Figure 4 . 3a ) . Un ﬁchier correspond à un échantillon , conformément au niveau d’interprétation 3 choisi . Ces ﬁchiers sont peu structurés et inconstants d’un type d’étude à l’autre , en fonction de la nature de l’analyse , de la technique utilisée voire du laboratoire impliqué . L’intégration de ces données a donc nécessité l’élaboration d’un format intermé - diaire . Pour cela , j’ai choisi de concevoir un document XML Schema Deﬁnition ( XSD ) permettant de déﬁnir la structure et le type de contenu d’un document XML et de vériﬁer la validité de ce document . Ainsi le schéma XSD conçu déﬁnit de manière exhaustive les diﬀérents champs nécessaires à la description de toute étude omique expérimentale , quelle que soit la technique utilisée ou la nature de l’expérience ( voir Figure 4 . 3c ) . Il permet de réunir en un ﬁchier unique et standard les informations concernant l’étude issues du ﬁchier IDF ainsi que les résultats expérimentaux issues des multiples ﬁchiers de résultats . Le processus d’intégration des données se déroule en deux étapes . Tout d’abord , les diﬀérents ﬁchiers comportant les informations annexes à l’expérience et les résultats expérimentaux sont traités en Python aﬁn de les convertir en un ﬁchier XML unique répondant au schéma XSD élaboré ( voir Figure 4 . 3d ) . Ensuite , ce ﬁchier XML est traité en Java , via une classe dédiée dans le parseur P1 , aﬁn d’en extraire les infor - mations et d’insérer les données dans la base de données . Le traitement en Java peut inclure certaines étapes d’annotation , aﬁn par exemple de déterminer les gènes présents sur un segment génomique dans le cadre de l’analyse de CNV . Ces étapes sont décrites sur la Figure 4 . 5 . La conversion en XML des données expérimentales nécessite de développer un script Python ( ou tout autre langage de programmation adapté au traitement de ﬁchiers ) spé - ciﬁque à chaque format de ﬁchier de résultats expérimentaux . Cependant un module Python dédié au traitement des ﬁchiers IDF a été développé , les formats de ces ﬁ - 85 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE ( a ) Fichier de résultats non traité . ( b ) Fichier IDF . ( c ) Schéma XSD . ( d ) Exemple de sortie XML . Figure 4 . 4 – Traitement des données omiques expérimentales . ( a ) Extrait d’un ﬁchier texte tabulé de résultats d’analyse d’expression de protéines avant traitement pour un échantillon . ( b ) Extrait du ﬁchier IDF décrivant les paramètres de l’étude . ( c ) Extrait du schéma XSD déﬁni pour la conversion des données en XML . ( d ) Extrait du ﬁchier XML obtenu après traitement , comportant à la fois les données de l’étude issues du ﬁchier IDF et les résultats expérimentaux . 86 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE chiers étant constants d’une étude à l’autre . L’intégration d’un nouveau type d’étude omique ne demande ainsi que le développement d’un script de traitement des ﬁchiers de résultats expérimentaux . Fichiers de résultats Base de données Fichier XML unique 1 1 Script python 1 2 Parseur P1 Figure 4 . 5 – Intégration des données omiques expérimentales . 4 . 1 . 5 Lien avec les données cliniques Préalablement à l’intégration des données , il a été nécessaire d’établir une méthode aﬁn d’associer les patients présents dans la base de données RAVEL et les ﬁchiers de résultats omiques expérimentaux à disposition . En eﬀet , les données omiques récoltées n’étaient pas liées à des données cliniques disponibles . Il a donc fallu relier les données cliniques déjà présentes dans RAVEL avec les données omiques réunies . Pour cela , la classiﬁcation CIM10 a été utilisée . Chaque patient dont les données sont intégrées à RAVEL est associé à plusieurs codes CIM10 , en fonction des pathologies diagnostiquées . À partir de ces codes , les patients dont les pathologies correspondaient aux pathologies pour lesquelles des données omiques étaient disponibles ont été sélectionnés . Ainsi , la cohérence entre les données de RAVEL et les données omiques issues du portail TGCA ou fournies par les laboratoires contactés a été préservée . Le processus d’intégration a été utilisé pour intégrer avec succès 7 études omiques dont 5 études issues du projet « Glioblastoma » de la base de données TGCA , et 2 études dont les données ont été obtenues par collaboration . Ces études portent sur ( i ) l’analyse de méthylation de l’ADN , ( ii ) analyse CGH , ( iii ) analyse de CNV , ( iv ) analyse de l’expression des gènes , ( v ) analyse de l’expression de protéines , ( vi ) analyse des miRNA et ( vii ) l’analyse d’un exome . Au total les données de 527 patients ont été intégrées dans notre base de données cliniques et omiques . 4 . 2 Recherche d’information clinomique 4 . 2 . 1 Moteur de recherche CISMeF Par rapport à l’existant , le moteur de recherche utilisé dans RAVEL a été conçu à la fois comme le plus générique possible et avec une forte contrainte en terme de temps 87 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 6 – Représentation en arbre de la requête stay ( patient ( birthDate = 1937 - 01 - 01 AND gender = " M " ) AND entryDate = 2010 - 03 - 10 ) . de réponse . Cet outil s’appuie sur les travaux précédents de l’équipe CISMeF sur la RI documentaire , dans le cadre desquels a été créé un moteur sémantique pour retrouver un type d’objet unique : les ressources web . Ce moteur de recherche permet la recherche d’information sur des données structurées , essentiellement numériques , mais aussi par - fois symboliques ( comme le genre ) , mais aussi sur des données non structurées ( issues essentiellement des diﬀérents comptes - rendus d’un DPI ) . Ce moteur est générique , car il permet de rechercher n’importe quelles données stockées dans la base de données . Ce moteur de recherche se base sur un langage de requêtes dédié qui présente trois caractéristiques importantes : ( i ) il est orienté objet , ( ii ) il est ﬂexible et évolutif et ( iii ) il a des capacités d’interrogation complète , c’est - à - dire que toutes les données incluses dans la base de données sont interrogeables . Le moteur de recherche a été conçu pour être générique , rapide , multilingue et aligné avec de multiples terminologies . Il utilise un langage d’interrogation spéciﬁque visant à faciliter la recherche d’information . Le langage est composé d’unités syntaxiques , respectant la syntaxe suivante : ENTITÉ ( CLAUSE _ CONTRAINTES ) où : — ENTITÉ correspond à une entité du modèle conceptuel — CLAUSE _ CONTRAINTES correspond aux contraintes appliquées à cette entité , construite en utilisant des attributs ou des objets liés ( voir Tableau 4 . 1 ) . Plus de détails sont disponibles sur le langage d’interrogation dans [ Lelong et al . , 2016 ] . Dans le modèle actuel , trois ENTITÉS principales sont modélisées à trois niveaux : le niveau du patient , le niveau du séjour , et le niveau le plus bas ( comme l’analyse biolo - gique ou l’analyse omique ) . Par exemple , les requêtes patient ( ) et medicalUnit ( ) re - tournent respectivement tous les patients et toutes les unités médicales contenues dans la base données . La clause de contrainte CLAUSE _ CONTRAINTES permet d’appliquer des contraintes à l’entité spéciﬁée . C’est une expression booléenne , ainsi les opérateurs boo - léens AND , OR , NOT et les parenthèses sont utilisées pour construire des liens logiques 88 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE entre contraintes uniques . Cette clause de contrainte peut être construite en utilisant les attributs de l’entité spéciﬁée . Par exemple , la requête suivante patient ( birthDate = 1937 - 01 - 01 AND gender = ’M’ ) utilise deux attributs birthDate et gender de l’entité patient et retournera tous les patients masculins , nés le 01 / 01 / 1937 . Les opérateurs booléens , parenthèses et comparateurs sont déﬁnis explicitement dans la grammaire du langage alors que les entités sont déduites automatiquement par auto - complétion à partir du modèle de données omiques . Le moteur de recherche permet d’interpréter les requêtes pour extraire les données correspondantes de la base de données . Le processus d’interprétation contient trois étapes : ( i ) le parsing de la requête , ( ii ) sa représentation sous la forme d’un arbre ( voir Figure 4 . 6 ) et ( iii ) la construction de la requête SQL correspondant à l’arbre généré , le modèle de données étant intégré dans une base de données relationnelle . Diﬀérentes données peuvent être extraites : ( i ) données symbo - liques ( absence , présence ) , ( ii ) données numériques ( avec les opérateurs > , < et = ) et ( iii ) données chronologiques . Requête en langage naturel Traduction dans le langage d’interrogation Les patients de l’étude 12 ayant une expression de HRNR supérieure à 3 patient ( study ( id = " OMI _ STUDY _ 12 " ) AND quantification ( gene ( geneSymbol = " HRNR " ) AND numericValue > 3 ) Patients ayant des variations faux - sens sur HOMER1 et un taux de glucose sanguin supérieur à 1 , 1g / L patient ( study ( id = " OMI _ STUDY _ 1 " ) AND variant ( gene ( geneSymbol = " HOMER1 " ) AND variantCategory = " Missense " ) AND bioTest ( bioResultEXECode ( label = " Glucose " ) AND numericValue > 1 . 1 ) ) Tous les segments génomiques délétés dans l’étude 10 quantification ( interpretation = " deletion " AND study ( id = " OMI _ STUDY _ 10 " ) ) Tous les variants faux sens sur le gène HRNR sans l’étude 1 variant ( study ( id = ”OMI _ STUDY _ 1” ) AND gene ( geneSymbol = ”HRNR” ) AND variantCategory = ”Missense” ) Tableau 4 . 1 – Exemples de requêtes omiques . 89 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE 4 . 2 . 2 Requête dans les données omiques Description Le moteur de recherche a été adapté pour permettre aux utilisateurs d’interroger à la fois données cliniques et données omiques ( variant , gène , protéine ou segment génomique ) . Des mots - clés ont été déﬁnis pour interroger chaque entité du modèle omique conceptuel et élaborer des contraintes . Le temps de réponse moyen pour un patient est inférieur à deux secondes , ce qui est considéré comme satisfaisant pour un clinicien ou un chercheur . Pour n patients , le temps de réponse moyen est inférieur à dix secondes . Il est possible de réaliser la RI simultanément sur les données cliniques et omiques dans la même requête . Par exemple , les patients qui ont des variations faux - sens sur le gène HOMER1 et un taux de glucose sanguin supérieur à 1 , 1g / L peuvent être extraits . Chaque entité du modèle de données omiques conceptuel est interrogeable . Les requêtes sont réalisables à plusieurs échelles : au niveau du patient , du séjour ou de l’étude expérimentales . Les variants et régions génomiques peuvent également être extraits . Interrogation sémantique des données Le système fourni permet ainsi d’interroger les données cliniques et omiques dans un ou plusieurs DPI . Plusieurs types de données omiques peuvent être récupérés : données d’expression ( gènes , protéines , miARN ) , variantes génomiques , variantes de numéros de copies , hybridation génomique comparative et données de méthylation d’ADN . Les terminologies et les ontologies telles que SNOMED CT , MeSH , CIM10 utilisées comme références dans l’interface utilisateur graphique peuvent être utilisées pour créer des requêtes . Par exemple , tous les patients ayant des variantes génomiques sur des gènes annotés avec le terme Gene Ontology GO : 0042246 Récupération tissulaire peuvent être récupérés avec la requête patient ( variant ( gene ( GOterm ( label = " tissue rege - neration " ) ) ) ) . Visualisation des résultats Les données omiques expérimentales sont consultables dans un onglet réservé du prototype RAVEL qui regroupe l’intégralité des diﬀérents types de données ( voir Fi - gure 4 . 7 ) . Chaque analyse est représentée dans un cadre propre , les résultats appa - raissant dans un tableau au sein de ce cadre . Si l’analyse considérée est une analyse quantitative ( analyse d’expression , de méthylation . . . ) , les informations aﬃchées sont : ( i ) l’entité analysée ( gène , protéine , segment analysé ) , ( ii ) la valeur obtenue , normali - sée , ( iii ) l’interprétation de cette valeur ( « délétion » , « sous - expression » . . . ) , ( iv ) un commentaire ( facultatif ) , ( v ) la date de la mesure et ( vi ) un lien vers l’étude aﬀérente . 90 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 7 – Capture d’écran du prototype RAVEL . Si l’analyse considérée concerne un variant ( SNP ou indel ) , les informations aﬃchées sont : ( i ) le nom du variant , ( ii ) le nom du variant en accord avec la nomenclature HGVS si disponible , ( iii ) le gène , ( iv ) le type de région , ( v ) la position du variant , ( vi ) la catégorie du variant , ( vii ) le codon de référence , ( viii ) le codon muté , ( ix ) un lien vers la base de données dbSNP répertoriant les SNP présents chez diﬀérentes espèces dont l’Homme [ Sherry et al . , 2001 ] , ( x ) un lien vers le Genome Browser de l’UCSC permettant d’explorer le génome , ( xi ) un lien vers la base de données de génomes eucaryotes Ensembl , ( xii ) la date de l’analyse , et ( xiii ) un lien vers l’étude aﬀérente . La Figure 4 . 7 présente la vue principale des données omiques au sein de l’applica - tion RAVEL développée par l’équipe CISMeF . Les données sont présentées au sein d’un composant en « accordéon » , chaque onglet étant dédié à un type d’analyse omique . Ici on peut observer chez ce patient ces résultats de ( i ) analyse miARN , ( ii ) expression protéique , ( iii ) CGH , ( iv ) analyse de méthylation de l’ADN , ( v ) expression génique et ( vi ) analyse d’exome . Le détail de chaque entité analysée ( gène , protéine , miARN , segment génomique ) peut être consulté dans l’interface . Chacune des entités bénéﬁcie des données de réfé - rences agrégées depuis NCBI Gene et Uniprot KB . La Figure 4 . 8 présente les infor - mations concernant le gène SAGE1 issues de la base de données NCBI Gene . Toutes les 91 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 8 – Détail concernant le gène SAGE1 depuis l’interface de visualisation des données omiques . informations de référence importées depuis NCBI Gene sont consultables directement au sein de l’application . Ces informations incluent les informations générales concer - nant le gène ( nom , alias , position , fonction ) ainsi que les relations ( annotations GO , protéines associées , pathologies associées ) et ressources liées . Les données concernant les études omiques sont consultables également depuis le prototype RIDoPI dans une fenêtre dédiée . Ces informations incluent notamment ( i ) la date de l’étude , ( ii ) le titre de l’étude , ( iii ) sa description , ( iv ) l’équipement utilisé , ( v ) le protocole utilisé , ( vi ) la source des données , ( vii ) le type de l’étude ( expression de gènes , analyse de variants . . . ) et ( viii ) si applicable , la version d’assemblage du génome utilisée . L’utilisateur a ainsi la possibilité de consulter la source des données qu’il visualise , notamment de s’informer sur le moyen d’obtention des échantillons analysés ou encore le protocole utilisé pour le traitement des données . Il peut également de cette façon obtenir les données brutes associées aux données disponibles , aﬁn par exemple de les réutiliser ou eﬀectuer un nouveau traitement de ces données brutes . De plus , une vue globale des données de l’étude est possible à travers diﬀérents graphes . La Figure 4 . 9 montre les informations concernant l’étude « miRNA Analy - sis of TCGA GBM Samples » portant sur 54 patients atteints d’un glioblastome dont les résultats omiques ont été publiés par le TCGA . Toutes les informations apparais - sant dans le ﬁchier idf fourni ( voir Figure 4 . 3b ) sont stockées en base de données et sont consultables directement au sein de l’application , incluant notamment le titre de l’étude , sa description et le protocole utilisé . Ces données regroupent le nombre de patients , les caractéristiques démographiques de la cohorte ( âge , genre , origine eth - 92 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 9 – Détail concernant l’étude « miRNA Analysis of TCGA GBM Samples » depuis l’interface de visualisation des données omiques . nique . . . ) . Elles sont représentées à partir d’histogrammes et de diagrammes circulaires , aﬁn de pouvoir rapidement appréhender les caractéristiques de l’étude . 4 . 3 Résultats 4 . 3 . 1 Comparatif face aux solutions existantes : i2b2 et tranS - MART i2b2 Aﬁn d’étudier les solutions existantes dédiées à la gestion et l’exploitation des don - nées issues des DPI , j’ai procédé à l’installation des systèmes i2b2 et tranSMART . D’une part , j’ai étudié leur architecture serveur et d’autre part les logiciels clients ainsi que les fonctionnalités proposées . i2b2 est une plateforme libre développée aux États - Unis et dédiée à la recherche translationnelle . Cette plateforme est implémentée dans plusieurs pays ( [ Takai - Igarashi et al . , 2011 ] et [ Ganslandt et al . , 2011 ] ) et est devenue un standard de facto . i2b2 stocke les données dans un entrepôt de données Oracle centré sur l’exploitation de données structurées . L’architecture fonctionnelle de cet outil écrit en Java propose une organisation en modules ( hive ) , chaque module assurant une fonction spéciﬁque au sein de l’applicatif . Bien que cette modularité facilite l’utilisation des données des DPI pour les chercheurs , elle complexiﬁe le déploiement et la maintenabilité du système . Ces modules incluent ( i ) des outils de traitement automatique de la langue pour l’in - 93 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 10 – Interface du workbench i2b2 . dexation et l’extraction de concepts basés sur des ontologies médicales , ( ii ) des outils de recherche d’information pour sélectionner des patients sur des données codées et structurées , ( iii ) des outils graphiques pour réaliser des analyses statistiques sur les résultats de la sélection [ Murphy et al . , 2006 ] . La plateforme propose l’exploitation des données soit à partir d’un logiciel client fonctionnant sous Windows soit d’une interface web , les deux outils proposant des in - terfaces similaires ( voir Figure 4 . 10 ) . L’interface permet de construire des requêtes en sélectionnant les concepts issus de terminologies ou d’ontologies médicales . Ces concepts recouvrent des données démographiques , diagnostiques , de prescriptions ou encore de tests médicaux . L’outil de construction des requêtes permet d’inclure plu - sieurs concepts et gère également l’exclusion de concepts , la fréquence d’apparition de concepts ainsi que des interrogations dans le temps . Ces fonctionnalités sont détaillées dans le tableau 4 . 2 La requête réalisée renvoie ensuite une cohorte de patients anonymisée correspon - dant aux concepts sélectionnés . Il est alors possible de visualiser ces données sous forme graphique , principalement par des représentations de type histogramme , ou d’exporter les données vers le format Excel . Le modèle i2b2 permet ainsi d’intégrer des données médicales diverses aﬁn de pouvoir faire des interrogations multicritères dans le temps [ Murphy et al . , 2006 ] . 94 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Figure 4 . 11 – Interface du client web tranSMART . Bien qu’i2b2 soit un outil puissant pour gérer des données cliniques , il concentre ses eﬀorts en particulier sur la problématique de la recherche de cohortes . Il ne permet pas la visualisation des données à l’échelle d’un seul patient et donc la visualisation des données d’un DPI [ Murphy et al . , 2017 ] . De plus , son déploiement demande des ressources importantes , en terme de déploiement , de maintenance ainsi qu’en terme de formation à son utilisation [ Takai - Igarashi et al . , 2011 ] . tranSMART tranSMART [ Scheufele et al . , 2014 ; Szalma et al . , 2010 ] est une plateforme libre de recherche translationnelle , développée par l’entreprise pharmaceutique Johnson & Johnson et supportée par une communauté croissante de développeurs . Le modèle de données de tranSMART ( version 1 . 2 ) est basé sur le modèle i2b2 . La plateforme est développée en Java et repose sur plusieurs dépendances comme le logiciel R pour les analyses statistiques . La plate - forme tranSMART permet d’intégrer des données à partir d’une variété de sources de données . Les types de données qui peuvent être intégrées dans tranSMART comprennent des données cliniques au niveau du patient ou de l’étude ( démographie , diagnostic , médicaments , résultats de laboratoire ) , des données omiques ( génotypage , expression de gènes , expression des protéines ) , les résultats de l’étude , ainsi que les des - cripteurs d’étude sous forme de métadonnées . Les données peuvent provenir de sources publiques ( par exemple , TCGA , GEO ) , ou à partir de sources internes ( par exemple , es - 95 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE RAVEL i2b2 1 . 7 . 06 Portée 1 à n patients n patients Contraintes numériques - Par rapport à une valeur ﬁxe - Par rapport à une borne de référence - Gestion des unités de mesure (cid:88) (cid:88) (cid:55) (cid:88) (cid:88) (cid:88) Contraintes chronologiques - Par rapport à une date ﬁxe - Par rapport à un intervalle de temps - Entre deux évènements (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) Contraintes textuelles (cid:88) (cid:88) Recherche plein texte dans les comptes - rendus (cid:88) (cid:88) Détection du nombre d’occurences d’un évènement (cid:55) (cid:88) Données obtenues en sortie Toute entité du modèle conceptuel Set de patients Données cliniques gérées - Données patient - Séjours - Unités médicales - Analyses biologiques - Actes médicaux - Prescriptions - Compte - rendus (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) Données omiques gérées - Variants : • SNV / SNP • MNP • Variants du nombre de copies • Indels • Inversions , substitutions - Analyse d’expression : • Protéines • Gènes • micro - ARN • Exons - Analyse de méthylation de l’ADN (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:55) (cid:55) (cid:55) (cid:55) Terminologies prises en charge > 50 Gene Ontology , HOM - UCARE , Human Phenotype Ontology , ICD 10 , ICD 9 , LOINC , MedDRA , MeSH , NDFRT , RADLEX , RxNORM , SNOMEDCF + CT Prise en charge de l’explosion (cid:88) (cid:88) Tableau 4 . 2 – Analyse fonctionnelle des outils RAVEL et i2b2 v1 . 7 . 06 . 96 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE RAVEL tranSMART v16 . 2 Portée 1 à n patients n patients Recherche possible par : - Étude - Objectif de l’étude - Type de biomarqueur - Type d’analyse - Technologie employée - Matériel utilisé - Domaine thérapeuthique (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:55) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) Contraintes textuelles (cid:88) (cid:88) Données obtenues en sortie Toute entité du modèle conceptuel Ensemble de données Visualisation des données cliniques 1 et n patients (cid:55) Visualisation des données omiques 1 et n patients n patients Données omiques gérées - Variants : • SNV / SNP • MNP • Variants du nombre de copies • Indels • Inversions , substitutions - Analyse d’expression : • Protéines • Gènes • micro - ARN • Exons - Analyse de méthylation de l’ADN (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) Terminologies prises en charge > 50 MeSH , NCBI Gene , CIM10 , LOINC Prise en charge de l’explosion (cid:88) (cid:88) Fonctionnalités d’analyse (cid:55) aCGH Survival Analysis , Box Plot with ANOVs , Correlation Analysis , Forest Plos , Group Test for RNASes , Heatmaps , IC50 Dose Response Curvs , Line Graps , Logistic Regressios , PCs , Scatter Plot with Linear Regressios , Survival Analysis , Fisher test Tableau 4 . 3 – Analyse fonctionnelle des outils RAVEL et tranSMART v16 . 2 . 97 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE sais cliniques institutionnels , etc . ) . Le contenu de référence introduit dans tranSMART peut être propriétaire ( par exemple , GeneGo , Ingenuity ) ou disponible ouvertement ( par exemple , Entrez , MeSH ) . En outre , les sources de données d’origine peuvent être stockées sous forme de ﬁchiers et accessibles pour l’exportation via l’interface utilisateur pour les futurs workﬂows de recherche . L’interface web permet d’explorer les données phénotypiques de groupes de patients , de conduire des méta - analyses et de valider ou rechercher des hypothèses . Les outils d’analyse statistique disponibles permettent de réaliser des analyses pointues sur les données disponibles . L’explorateur de jeu de données est le principal point d’accès pour les données d’étude ( voir Figure 4 . 11 ) . Dans l’explorateur de jeu de données , l’uti - lisateur parcourt des données de manière hiérarchique . En utilisant le glisser - déposer , l’utilisateur peut exécuter une variété dd’analyses et statistiques . L’utilisateur peut spéciﬁer une cohorte de patients , choisir une modalité d’analyse disponible et déﬁnir les paramètres pertinents . Une fois les sélections eﬀectuées , les résultats sont retournés à l’utilisateur et présentés de manière graphique . L’utilisateur peut continuer à explorer davantage les données en modiﬁant les détails de la cohorte ou les paramètres de l’ana - lyse ou en exécutant d’autres analyses . Ainsi , l’utilisateur peut générer une hypothèse dans tranSMART en utilisant un ensemble de données et ensuite tester cette hypothèse sur un ensemble de données diﬀérent . Les résultats générés peuvent être sauvegardés ou exportés . Aucune connaissance des langages de script statistiques n’est nécessaire pour analyser les données . Ces fonctionnalités sont détaillées dans le tableau 4 . 3 . La plateforme tranSMART est ainsi dédiée en particulier à l’exploration analytique d’ensemble de données omiques plutôt qu’à la visualisation et la récupération d’in - formation dans les données des DPI . Elle ne permet aucun accès aux données d’un seul patient , ni en visualisation ni en recherche d’information au contraire de la solu - tion RAVEL . En revanche , elle propose des fonctionnalités d’analyse statistiques des données puissantes et aisée d’accès qui ne sont pas disponible dans notre application . 4 . 3 . 2 Cas clinique RAVEL en rhumatologie : polyarthrite rhu - matoïde Objectifs du cas d’usage La polyarthrite rhumatoïde ( PR ) est une maladie inﬂammatoire auto - immune à prédominance synoviale ( articulation ) . Elle évolue par poussées et peut entraîner des lésions articulaires graves . C’est la plus fréquente des rhumatismes inﬂammatoires chro - niques , avec une prévalence entre 0 . 4 et 0 . 8 % en France . La présentation initiale de la maladie est hétérogène , le diagnostic peut parfois s’avérer diﬃcile avec un laps de temps avant la découverte de la maladie . À l’inverse , un diagnostic de PR peut être remis en cause après plusieurs échecs thérapeutiques 98 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE par exemple : Le clinicien aimerait alors avoir un résumé des éléments objectifs ayant conduit à ce diagnostic pour éventuellement l’inﬁrmer . Une fois le diagnostic établi , le patient est régulièrement suivi , en consultation pour les cas les moins graves , en hôpital de jour pour les cas plus sévères où le traitement doit être administré en injection . La majorité du suivi se fait via un formulaire spéciﬁque . Il arrive parfois qu’un patient doive être hospitalisé en service traditionnel ( forme grave , échec thérapeutique , eﬀet indésirable grave ) où les formulaires ne sont pas uti - lisés . Il s’agit de retrouver dans le dossier les éléments permettant de vériﬁer la réalité du diagnostic de PR ( remise en cause du diagnostic après plusieurs échecs thérapeutiques par exemple ) : — Les traitements : leurs eﬀets indésirables , et en particulier le nombre de polynu - cléaires neutrophiles ( PNN ) . Pouvoir diﬀérentier : — nne neutropénie brutale et inhabituelle ( Neutropénie : Taux bas , inférieur à 1 500 par mm3 , de PNN - ( granulocytes , type de globules blancs ) ; — une neutropénie cyclique . — Évolution de variables biologiques marqueurs de l’inﬂammation : CRP , VS , FR , Anti - CCP ; — Évolution du DAS - 28 ( score d’activité de la maladie ) ; — Évolution des atteintes articulaires . Éléments de recherche Les éléments à rechercher dans ce cas d’usage sont les suivants : 1 . Quelles sont les articulations gonﬂées pour chaque visite ? 2 . Quelles sont les articulations douloureuses pour chaque visite ? 3 . Quelles sont les articulations gonﬂées et douleurs pour chaque visite ? 4 . Combien de grosses articulations sont atteintes à chaque visite ? 5 . Combien de petites articulations ? 6 . Sérologies RF ( valeur + normal ou pas ? ) 7 . ACPA ( valeur + normal ou pas ? ) 8 . VS ( valeur + normal ou pas ? ) 9 . CRP ( valeur + normal ou pas ? ) 10 . Durée des symptômes 11 . Traitements ( switch ineﬃcacité ou EIM ) 12 . DAS - 28 13 . PNN 99 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE Tableau 4 . 4 – Réponse au cas d’usage PR RAVEL . Élement Nombre de réponses Temps d’exécution 1 112 3 . 17s 2 6659 1 . 14s 3 76 0 , 37s 4 34 entrées 0 . 89s 5 17 entrées 34 . 55s 6 17 entrées 39 . 52s 8 8 entrées 4 . 12s 9 11 entrées 1 . 52s 13 5 entrées 1 . 47s Résultats RAVEL a permis d’obtenir les éléments concernant les articulations ( 1 - 5 ) , la séro - logie RF ( 6 ) , la VS ( 8 ) , la CRP ( 9 ) ainsi que le PNN ( 13 ) . Les éléments concernant les articulations ont nécessité d’utiliser la SNOMED CT . En eﬀet , la caractéristique de l’articulation , petite ou grosse , n’étant pas codée dans les questionnaires mais seule - ment l’articulation elle - même , il a été nécessaire de parcourir les concepts ascendants pour déterminer la caractéristique de l’articulation touchée . Ceci explique un temps de réponse plus important pour ces éléments . Les valeurs de tests biologiques comme le taux de CRP ont pû être recherchées en un temps satisfaisant . Plusieurs éléments n’ont pas pu être retrouvés . Les valeurs ACPA n’ont pû être intégrées dans la terminologie locale et n’ont donc pas pû être récupérée . Les éléments de questionnaires comme la durée des symptômes ou la valeur DAS - 28 étaient présents dans des champs de texte libre de questionnaires et n’ont pû être directement interrogés . 4 . 4 Synthèse Dans ce chapitre , nous avons vu en premier lieu l’intégration des données de réfé - rences issues des bases de connaissances NCBI Gene , Uniprot SwissprotKB et OMIM . Ces données mises à jour régulièrement ont été intégrées au système d’information du D2IM du CHU de Rouen et sont ainsi accessibles d’une part au public via le portail terminologique HeTOP et d’autre part pour notre application de RI dans les données cliniques et omiques . L’intégration de données expérimentales a nécessité l’intégration de jeux de données de natures , de formats , et de sources diverses . Au total , neuf études ont été intégrées couvrant les types de données omiques utilisés en recherche clinique : des données d’expression de gènes , protéines , exons et microARN , des variants géné - tiques , et enﬁn des analyses de méthylation de l’ADN . Par la suite , en m’appuyant sur 100 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE les travaux réalisés pour les données cliniques dans le cadre du projet RAVEL et sur le moteur réalisés par l’équipe du D2IM du CHU de Rouen , j’ai adapté le moteur de recherche existant aux données omiques pour aboutir à un outil permettant de requêter à la fois des données cliniques et omiques , à l’échelle d’un ou plusieurs patients . Une interface graphique a également été conçue pour la visualisation des données omiques . Enﬁn , l’évaluation de ce travail face aux plateformes i2b2 et TranSMART a été réali - sée . L’évaluation de la partie clinique de notre solution à travers un cas d’usage mis au point dans le cadre du projet RAVEL a également été décrite . Ce travail a fait l’objet de plusieurs communications [ Cabot et al . , 2016a , 2015 ] Plusieurs points peuvent être discutés . Tout d’abord , l’intégration de multiples sources de données omiques expérimentales a permis de valider la pertinence du modèle de données omiques développé . Cependant , il n’a pas été possible dans le cadre de cette thèse de disposer d’un jeu de données cliniques et omiques d’un nombre suﬃsant de pa - tients . Notre prototype se base donc aujourd’hui sur des données cliniques et omiques décorrélées : les données cliniques provenant de DPI du CHU de Rouen et les données omiques provenant de sources diverses récoltées sur des patients diﬀérents . Bien qu’une certaine cohérence ait pu être conservée en s’appuyant sur les codes diagnostic CIM10 pour lier les données entre elles , cette décorrélation est un frein important à l’évaluation du système . L’évaluation du système en situation réelle , par l’équipe d’un laboratoire sur ces propres données par exemple , n’a ainsi pas pu être eﬀectuée et des points im - portants comme l’ergonomie , la pertinence des vues proposées ou l’apprentissage de l’écriture des requêtes ne sont pas évalués . Le prototype réalisé permet néanmoins de démontrer la validation technique du système et son évaluation complète reste une perspective forte de ce travail . Enﬁn , face à l’existant , notre solution conserve l’avantage de proposer au sein d’un système unique de permettre l’interrogation conjointe de données cliniques et données omiques à l’échelle d’un ou plusieurs patients . Ses fonctionnalités sont ainsi étendues : il peut être utilisé dans le cadre de la pratique clinique comme dans le cadre de la recherche clinique pour la création de cohortes et plus largement en santé publique et épidémiologie . L’utilisation d’un système unique permet d’une part de concentrer les eﬀorts de développement et de maintenance , mais aussi du point de vue de l’utilisateur d’avoir accès à ces fonctionnalités multiples sans devoir maîtriser plusieurs systèmes . Enﬁn , ce choix favorise également la non - redondance des informations et la continuité des connaissances entre recherche et pratique clinique indispensable à la personnalisa - tion des soins . 101 CHAPITRE 4 . RECHERCHE D’INFORMATION CLINOMIQUE 102 Chapitre 5 Indexation multi - terminologique de documents biomédicaux Sommaire 5 . 1 Le serveur multi - terminologique HeTOP . . . . . . . . . . 104 5 . 1 . 1 Un serveur multiterminologique et interlingue . . . . . . . . . 104 5 . 1 . 2 Terminologies et ontologies disponibles . . . . . . . . . . . . . 106 5 . 2 L’Extracteur de Concepts Multi - Terminologique ( ECMT ) 107 5 . 2 . 1 Détection des concepts . . . . . . . . . . . . . . . . . . . . . . 107 5 . 2 . 2 Exploitation des réseaux sémantiques . . . . . . . . . . . . . 109 5 . 3 Évaluation de l’indexation au sein des corpus MEDLINE et EMEA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 5 . 3 . 1 Description des tâches . . . . . . . . . . . . . . . . . . . . . . 112 5 . 3 . 2 Sources de données . . . . . . . . . . . . . . . . . . . . . . . . 113 5 . 3 . 3 Résultats CLEF e - Health 2015 . . . . . . . . . . . . . . . . . 114 5 . 3 . 4 Résultats CLEF e - Health 2016 . . . . . . . . . . . . . . . . . 116 5 . 3 . 5 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 5 . 4 Évaluation de la couverture terminologique au sein du corpus LiSSa . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 5 . 4 . 1 Le corpus LiSSa . . . . . . . . . . . . . . . . . . . . . . . . . 121 5 . 4 . 2 Création du gold standard . . . . . . . . . . . . . . . . . . . . 121 5 . 4 . 3 Annotation manuelle . . . . . . . . . . . . . . . . . . . . . . . 121 5 . 4 . 4 Évaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 5 . 5 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 103 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Dans ce chapitre , il s’agit de traiter l’indexation multi - terminologique de documents biomédicaux . L’équipe du D2IM du CHU de Rouen développe l’ECMT . Il exploite les terminologies intégrées au portail HeTOP développé dans le cadre du projet PlaIR . L’utilisation de multiples terminologies pour l’indexation pose des problématiques spé - ciﬁques . Ce chapitre présente une méthode de priorisation des indexations visant à traiter la problématique du bruit induit par la multi - terminologie . Il présente enﬁn deux évaluations . En eﬀet , l’outil ECMT a été évalué à deux reprises dans le cadre de la campagne de test CLEF eHealth . Une évaluation de la couverture terminologique au sein d’un corpus issu de la base de données en français LiSSa est également présentée . 5 . 1 Le serveur multi - terminologique HeTOP Il y a un intérêt croissant aujourd’hui , non seulement pour développer et maintenir des terminologies de soins de santé , mais aussi pour les rendre interopérables dans les systèmes d’information fournissant des services aux applications [ Soualmia et Dar - moni , 2005 ] . Un « serveur de terminologie » est un outil qui gère et donne accès à plusieurs terminologies [ Burgun et al . , 1997 ] . De nombreux serveurs terminologiques ont déjà été développés , principalement en anglais [ Brown et al . , 2007 ; Burgun et al . , 1997 ; Gambarte et al . , 2007 ; Komatsoulis et al . , 2008 ; Navas et al . , 2007 ] . L’objec - tif principal d’un serveur multi - terminologique et multilingue est de créer une base de données terminologique permettant de rechercher des concepts et des termes parmi des ressources terminologiques et les parcourir dynamiquement . De telles données peuvent être utilisées pour ( i ) indexer les ressources manuellement ou automatiquement , ( ii ) permettre la recherche d’information à partir de plusieurs terminologies , ( iii ) évaluer l’intégrité des données terminologiques et ( iv ) fournir des ressources éducatives . 5 . 1 . 1 Un serveur multiterminologique et interlingue Les données biomédicales se développent constamment , en particulier avec les nou - velles technologies et les médias Internet . Par conséquent , il devient obligatoire d’in - dexer et annoter ces données avec des vocabulaires contrôlés et structurés aﬁn de stocker et rechercher ces informations avec des méthodes intelligentes . Un aspect clé de l’interopérabilité sémantique pour les données dans les sciences de la vie est l’utili - sation de terminologies ou d’ontologies comme dénominateur commun pour structurer les données et les rendre interopérables [ Bodenreider et Stevens , 2006 ; Rubin et al . , 2008 ] . Les terminologies et ontologies sont des classiﬁcations qui décrivent la connaissance d’un domaine spéciﬁque avec des concepts et des relations entre eux . Les ontologies sont plus complexes que les terminologies , car elles peuvent déﬁnir des règles et des fonctions pour inférer et structurer les connaissances . Étant donné que les ter - minologies et ontologies sont couramment utilisées dans les systèmes d’information et 104 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE spéciﬁquement en santé , il est diﬃcile de les gérer et de les consulter au sein d’une même application . En eﬀet , de nombreuses terminologies et ontologies ont été créées au cours de la dernière décennie à des ﬁns diﬀérentes : l’indexation et l’annotation de documents , l’organisation des connaissances , l’inférence des faits , etc . Certaines termi - nologies et ontologies ( par exemple MeSH , CIM10 , CCAM ) sont couramment utilisées quotidiennement dans les hôpitaux ou dans les laboratoires de recherche et sont très utiles pour la recherche d’information . Les terminologies et ontologies ne sont pas tou - jours bien structurées ou déﬁnies en raison d’un manque de standardisation ou de mise en forme . En outre , la sémantique et l’interopérabilité syntaxique entre terminologies et ontologies sont un grand déﬁ pour permettre l’interconnexion entre les systèmes et les connaissances . Plusieurs outils ont été créés pour stocker , rechercher et utiliser plusieurs terminologies et ontologies en même temps : parmi eux , l’UMLS ( Uniﬁed Me - dical Language System ) décrit dans la section 2 . 3 . 1 , le service de recherche d’ontologies EBI [ Côté et al . , 2010 ] , le NCBO BioPortal [ Rubin et al . , 2006 ] et le portail HeTOP [ Grosjean et al . , 2011 ] . HeTOP ( Health Terminology Ontology Portal ) est un portail de ressources termi - nologiques et ontologiques développé au sein de l’équipe CISMeF ( LITIS EA 4108 - TIBS ) dans le cadre de la thèse de Julien Grosjean [ Grosjean , 2014 ] . Il héberge 69 terminologies et ontologies dans plusieurs langues . La plupart des terminologies et on - tologies sont des références nationales ou internationales telles que le MeSH , la CIM10 ou la CCAM . Ces terminologies et ontologies sont régulièrement mises à jour et sont accessibles via un site Web 1 et un service Web . HeTOP a été conçu comme un portail multi - terminologique de référence et un portail interlingue pour aider les libraires , les traducteurs , les étudiants et les professionnels de la santé à récupérer des ressources et des connaissances dans une grande variété de domaines médicaux complexes . Il ne faut pas confondre interlinguisme ( en anglais cross - lingual ) qui désigne le fait de passer d’une langue à une autre en conservant le sens ( au maximum ) avec le multilinguisme qui correspond au fait de gérer plusieurs langues dans un système donné . Ainsi , He - TOP est à la fois interlingue , car il permet de passer d’une langue à une autre via les concepts , mais il est également multilingue , car il propose de rechercher des termes dans plusieurs langues à la fois . L’interface graphique oﬀerte par le site web est traduite com - plètement ou partiellement en 12 langues . À l’instar de la NCBO , CISMeF développe des outils et des services supplémentaires pour utiliser et exploiter ces ressources dans HeTOP : ( i ) l’ECMT 2 eﬀectue l’indexation des documents , identiﬁant les concepts de terminologies et ontologies présents dans un texte [ Cabot et al . , 2016b ; Pereira et al . , 2008 ; Soualmia et al . , 2015 ] , ( ii ) InfoRoute 3 , qui est un service d’info - bouton permettant d’accéder à de nombreux portails à partir d’une requête simple [ Darmoni 1 . www . hetop . org 2 . http : / / ecmt . chu - rouen . fr / 3 . http : / / inforoute . chu - rouen . fr / 105 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE et al . , 2008 ] , en eﬀectuant une extension sémantique basée sur les terminologies et ontologies , ( iii ) MT @ HeTOP 4 est un service basé à la traduction et l’alignement de termes , ( iv ) Doc’CISMeF 5 [ Darmoni et al . , 2001 ] qui est un moteur de recherche de ressources Web de qualité concernant la santé manuellement ou automatiquement mis à jour par les documentalistes de CISMeF avec le MeSH et d’autres terminologies et ontologies de référence . 5 . 1 . 2 Terminologies et ontologies disponibles Le portail HeTOP gère 69 terminologies en français et en anglais , totalement ou entièrement traduites en français , alignées par des relations sémantiques . Dans sa der - nière version , le système de gestion de base de données relationnelle est remplacé par le système d’analyse Inﬁnispan pour permettre un traitement rapide des entrées . Les prin - cipaux objectifs sont l’optimisation des temps de réponse et la dissociation du moteur de recherche d’un système de gestion de bases de données propriétaires . La solution NoSQL Inﬁnispan permet la distribution et la récupération des données à partir de plusieurs serveurs . Certaines de ces ressources sont issues du Métathésaurus UMLS . À ce jour , les principales ressources disponibles sont : — CIM10 dans les versions Organisation mondiale de la Santé ( OMS ) et ATIH , pour les diagnostics ; — CCAM , pour les actes médicaux ; — Medline Plus ; — MeSH , incluant les concepts supplémentaires ; — SNOMED CT et la version internationale ; — Anatomical Therapeutic Chemical classiﬁcation ( ATC ) , pour les médicaments ; — MEDical Dictionary for Regulatory Activities terminologies ( MedDRA ) ; — MedDRA — Foundational Model of Anatomy ( FMA ) — Human Phenotype Ontology ( HPO ) — LOINC — National Cancer Institute thesaurus ( NCIt ) Le Tableau A . 1 contient leur volumétrie . Chaque concept de ces ressources , lorsqu’il est disponible dans l’UMLS , possède un identiﬁcateur unique de concept . C’est le cas par exemple pour la CIM10 et non pour la CCAM . 4 . http : / / cispro . chu - rouen . fr / MT _ EHTOP / 5 . http : / / doccismef . chu - rouen . fr 106 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE 5 . 2 L’Extracteur de Concepts Multi - Terminologique ( ECMT ) Dans le cadre des travaux liés à l’évaluation des systèmes d’information sur la santé et la recherche et l’indexation de l’information dans le DPI [ Cabot et al . , 2016a ; Le - long et al . , 2016 ] , un outil nommé ECMT est développé par le D2IM du CHU de Rouen . Il a été utilisé dans plusieurs projets subventionnés par l’Agence Nationale de la Recherche [ Dupuch et al . , 2013 ; Thiessard et al . , 2012 ] . Pour évaluer les perfor - mances de l’ECMT , notre équipe a participé pour la première fois à la compétition CLEF eHealth en 2015 [ Goeuriot et al . , 2015 ] , puis en 2016 [ Kelly et al . , 2016 ] . La principale motivation de cette participation est d’améliorer les fonctionnalités de l’outil . La tâche de reconnaissance d’entités cliniques est retenue [ Névéol et al . , 2016 , 2015 ] . Elle vise à identiﬁer automatiquement les entités cliniques pertinentes dans des textes médicaux en français . L’ECMT utilise le traitement du langage naturel , la re - cherche de motifs et exploite plusieurs terminologies et ontologies pour réaliser cette reconnaissance . 5 . 2 . 1 Détection des concepts L’ECMT est développé pour extraire des textes en entrée une liste des concepts de santé candidats des 69 terminologies et ontologies incluses dans HeTOP . L’extrac - tion est eﬀectuée au niveau de la phrase du texte . Un service Web SOAP et REST permet de fournir une réponse en XML pour chaque concept qui contient : l’indice du premier et du dernier mot qui a conduit à identiﬁer le concept médical dans la liste ﬁnale , l’identiﬁant et son type sémantique si le concept de santé est inclus dans le Métathesaurus UMLS et la spécialité médicale du concept . Ces derniers sont basés sur des liens sémantiques manuels entre les spécialités médicales générales ( par exemple , la dermatologie , l’oncologie , etc . ) et les terminologies et ontologies incluses dans HeTOP . L’ECMT s’appuie sur l’algorithme du sac de mots et également la reconnaissance de motifs pour analyser des résumés de décharge , des rapports de procédures ou des résul - tats de laboratoire qui contiennent des données symboliques ( présence ou absence ) , des données numériques et des unités de mesure . La méthode du sac de mots a été dévelop - pée principalement pour la RI et elle a été adaptée pour l’indexation , c’est - à - dire que seul le plus grand ensemble de mots qui correspond à un concept est extrait , même si les sous - ensembles proposent d’autres concepts . Cette méthode est considérée comme étant plus précise et évite le bruit . Le texte en entrée est normalisé et chaque phrase est traitée séparément pour extraire les concepts . L’ECMT dispose également d’une interface conviviale ( ﬁgure 1 ) accessible après authentiﬁcation 6 . Plusieurs options sont 6 . http : / / ecmt . chu - rouen . fr / 107 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE disponibles pour paramétrer l’indexation du texte : — c : catégorisation . Si c = Vrai , les spécialités médicales ainsi que le type sémantique du concept sont inclus dans la réponse ( valeur par défaut : Vrai ) . — r : restriction . Si r = Vrai , la recherche s’arrête quand un concept correspondant à un maximum de mots est trouvé ( valeur par défaut : Vrai ) . Par exemple , pour « cardiopathie hypertensive » , si r = Vrai , seul le concept hypertension artérielle est retourné . Si r = Faux , la méthode retourne les concepts hypertension artérielle et maladie cardiaque . — sn : réseau sémantique . Si sn = Vrai les concepts alignés aux concepts trouvés dans le texte sont inclus dans la réponse ( valeur par défaut : Faux ) . — e : exclusions . Il s’agit d’une chaîne de caractères contenant les identiﬁants des concepts à exclure de la réponse ( une spécialité médicale , un type sémantique , un ancêtre , etc . ) . Par exemple , e = CIS _ MT _ 8 , UML _ ST _ T060 , MSH _ D _ C retourne uniquement les concepts qui ne sont pas des chirurgies ( CIS _ MT _ 8 ) , ni des procé - dures de diagnostic ( UML _ ST _ T060 ) ou des maladies MeSH ( MSH _ D _ C ) . Par défaut , toutes les catégories sont retournées . Si un ancêtre est utilisé pour l’exclusion , tous ces descendants sont exclus de la réponse . — f : ﬁltres . De la même façon que pour les exclusions , il s’agit d’une chaîne de caractères contenant les identiﬁants des concepts à conserver uniquement dans la réponse . — a : ancêtres . Si a = Vrai , l’ECMT retourne les ancêtres de chaque concept trouvé dans sa réponse ( valeur par défaut : Faux ) . — d : descendants . Si d = Vrai , l’ECMT retourne également les descendants de chaque concept trouvé dans sa réponse ( valeur par défaut : Faux ) . — at : synonymes . Si at = Vrai , les synonymes de chaque concept trouvé sont inclus dans la réponse ( valeur par défaut : Vrai ) . La réponse du service Web est un ﬁchier XML qui sérialise la sortie de l’annotation du texte . Les champs suivants le composent : — < cis - sentences > : le texte en entrée ; — < timemillis > : temps d’exécution en millisecondes ; — < cis - sentence > : une phrase ; — < idsentence > : l’identiﬁant de la phrase ; — < position > : indice de début de la phrase dans le texte ; — < start > : indice de début de l’indexation ; — < end > : indice de ﬁn de l’indexation ; — < idterm > : identiﬁant d’origine du concept ; 108 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE — < offset > : indice des termes composant le concept ; — < ter > : identiﬁant de la terminologie du concept ; — < umlscui > : CUI ; — < matchterms > : termes ayant permis d’identiﬁer le concept ; — < cis : term > : libellé préféré du concept ; — < cis : label > : libellé ; — < lang > : langage du libellé ; — < cis : altterms > : liste des synonymes du concept ; — < cis : altterm > : synonyme du concept ; — < cis : categorization > : liste de spécialités médicales ou types sémantiques du concept ; — < cis : category > : spécialité médicale ou type sémantique du concept ; — < cis : descendants > : liste des descendants du concept ; — < cis : descendant > : descendant du concept ; — < cis : ancestors > : liste des ancêtres du concept ; — < cis : ancestor > : ancêtre du concept ; — < cis : relateds > : liste des concepts reliés sémantiquement au concept trouvé ; — < cis : related > : concept relié sémantiquement au concept trouvé ; — < relationLabel > : libellé de la relation . 5 . 2 . 2 Exploitation des réseaux sémantiques Une nouvelle option nommée prioritisation a été ajoutée depuis 2015 . Elle traite le problème spéciﬁque lié au bruit généré par l’indexation multi - terminologique . Si cette option est activée , l’ECMT renvoie uniquement le concept le plus ﬁable , selon son type sémantique ( valeur par défaut : Faux ) . Lorsque n termes identiques provenant de plusieurs terminologies sont récupérés , les types sémantiques liés à ces termes sont déterminés et le plus important est déterminé à l’aide d’opérations ensemblistes . Ensuite , le terme le plus pertinent est conservé en fonc - tion d’une classiﬁcation des ressources HeTOP conçues manuellement pour chaque type sémantique disponible dans l’UMLS . Par exemple , l’indexation du terme « asthme » avec l’ECMT génère sept concepts récupérés dans sept ressources diﬀérentes : Syste - matized Nomenclature of Medicine ( SNOMED Int . ) , NCIt , MeSH , Medline Plus , HPO , CIM10 et International Classiﬁcation for Nursing Practice ( ICNP ) . Avec l’option de priorisation activée , un seul concept est récupéré selon le type sémantique correspon - dant au concept asthme dans l’UMLS ( maladie T47 dans ce cas ) qui est un concept 109 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Figure 5 . 1 – L’interface utilisateur de l’ECMT et ses options . Figure 5 . 2 – Exemple du traitement de la phrase « Cholestases intrahépatiques ﬁbrogènes familiales et anomalies héréditaires du métabolisme hépatocytaire des acides biliaires » avec l’ECMT et l’option de priorisation activée . 110 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Figure 5 . 3 – Exemple du traitement de la phrase « Cholestases intrahépatiques ﬁbrogènes familiales et anomalies héréditaires du métabolisme hépatocytaire des acides biliaires » avec l’ECMT et l’option de priorisation désactivée . 111 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE MeSH . Si aucun concept MeSH ne pouvait être récupéré pour un concept de maladie T47 , un concept NCIT devrait être priorisé et récupéré , et ainsi de suite . Cette option permet donc de conserver le concept de la terminologie la plus pertinente pour le type sémantique considéré . Les résultats de cette option sont illustrés dans les Figure 5 . 2 ( priorisation ac - tivée ) et 5 . 3 ( priorisation désactivée ) . Elles donnent un exemple de traitement de la phrase « Cholestases intrahépatiques ﬁbrogènes familiales et anomalies héréditaires du métabolisme hépatocytaire des acides biliaires » avec toutes les options par dé - faut de l’ECMT et l’option de priorisation activée . L’ECMT extrait les termes MeSH acides et sels biliaires ( CUI C0005391 ) , cholestase intrahépatique ( CUI C0008372 ) , le terme CIM10 E70 - E90 anomalies du métabolisme et le terme NCIt héréditaire ( CUI C0439660 ) . L’utilisateur peut également visualiser les termes et catégories synonymes . 5 . 3 Évaluation de l’indexation au sein des corpus MEDLINE et EMEA Les performances de l’ECMT ont été évaluées à l’occasion des éditions 2015 et 2016 de la compétition CLEF eHealth [ Cabot et al . , 2016b ; Soualmia et al . , 2015 ] dans les tâches correspondantes à l’extraction d’information dans des textes médicaux . L’édition 2015 a permis de dresser un premier état des lieux des performances de cet outil puisqu’il s’agissait de sa première évaluation dans le cadre d’une compétition internationale . L’édition 2016 a permis d’évaluer les progrès réalisés dans la reconnais - sance d’entités et plus particulièrement , dans la gestion des spéciﬁcités de l’indexation multi - terminologique . 5 . 3 . 1 Description des tâches Reconnaissance d’entités nommées La tâche de la reconnaissance d’entité nom - mée consiste à analyser des documents texte aﬁn de marquer les dix types d’entités d’intérêt clinique déﬁnis dans la compétition ( voir la section 2 . 1 ) . Deux sous - tâches sont possibles : ( i ) reconnaissance des entités simples ( extraction du concept et des indices du texte correspondant ) et ( ii ) reconnaissance des entités normalisées ( extraction du concept et de son CUI et des indices du texte correspondant ) . Normalisation des entités La tâche de normalisation des entités consiste à identi - ﬁer pour chaque entité d’intérêt extraite le CUI UMLS correspondant . 112 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE 5 . 3 . 2 Sources de données Le corpus QUAERO Le corpus QUAERO a été développé en tant que ressource pour la reconnaissance et la normalisation des entités nommées en 2013 [ Neveol et al . , 2014 ] dans le cadre du déﬁ 2013 de CLEF - ER , dans le but de créer un ensemble standard d’entités nor - malisées pour l’analyse des textes biomédicaux en français . Une sélection des titres issus de la base MEDLINE et de ﬁches descriptives de médicaments issues de l’Agence Européenne du Médicament ( EMEA ) utilisés dans le déﬁ CLEF - ER 2013 ont été sé - lectionnés pour l’établissement d’un gold standard . Des annotations sont fournies dans le format BRAT 7 et le processus d’annotation a été guidé par les concepts de l’UMLS . Dix types d’entités cliniques qui sont des groupes sémantiques UMLS ont été annotées : Anatomie , chimie et drogues , dispositifs , troubles , zones géographiques , êtres vivants , objets , phénomènes , physiologie , procédures . Les annotations ont été faites de manière globale , de sorte que les entités imbriquées ont été considérées , et ainsi une entité peut correspondre à plusieurs CUI UMLS . En particulier , ( i ) si une mention peut se référer à plus d’un groupe sémantique , tous les groupes sémantiques pertinents devraient être annotés . Par exemple , la mention « récidive » dans la phrase « prévention des récidives » devrait être annotée avec le groupe Maladie ( CUI C2825055 ) et le groupe Phénomène ( CUI C0034897 ) , ( ii ) si une mention peut se référer à plus d’un concept UMLS dans le même groupe sémantique , tous les concepts pertinents devraient être annotés . Par exemple , la mention « obsessionnels » dans la phrase « patients obsessionnels » devrait être annotée avec les CUI C0564408 et C0338831 ( groupe Trouble ) et ( iii ) les entités imbriquées devraient être annotées . Par exemple , dans l’expression « infarctus du myo - carde » , la mention « myocarde » devrait être annotée avec le groupe Anatomie ( CUI C0027061 ) et la mention « Infarctus du myocarde » devrait être annotée avec le groupe Trouble ( CUI C0027051 ) . L’outil d’évaluation BRATEval L’outil d’évaluation BRATEval eﬀectue une comparaison par paire des jeux d’an - notations obtenus sur un même ensemble de documents . Les jeux annotés doivent être formatés dans le format d’annotation de BRAT 8 . La version actuelle de l’outil a été testée sur les annotations réalisées avec Brat v1 . 3 . L’outil n’a besoin que du ﬁchier jar brateval . jar pour fonctionner , qui est inclus dans le ﬁchier de distribution , et aucune autre bibliothèque n’est requise . La performance du système a été évaluée par les mesures habituelles de l’extraction d’information : précision , rappel et mesure F1 pour la reconnaissance d’entités et la normalisation des entités telles qu’elles ont été 7 . http : / / brat . nlplab . org / standoff . html 8 . http : / / brat . nlplab . org / standoff . html 113 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE déﬁnies dans la section 2 . 7 . Les mesures de la performance ont été calculées au niveau du document et sur l’en - semble du corpus . La performance du système est obtenue en comparant les sorties du système concerné aux annotations standard de référence sur le jeu de données de test à l’aide de BRATEval . Pour la reconnaissance d’entités , une correspondance exacte ( exact match ) a été comptée lorsque le type d’entité et les indices fournis correspon - daient à la référence . Pour la reconnaissance d’entités normalisées , une correspondance exacte a été comptée lorsque le type d’entité , les indices fournis et les CUI du système correspondaient à la référence . Pour la tâche de normalisation , les correspondances ont été comptées pour chaque CUI fourni avec une entité . En conséquence , si le système ou la référence fournissait plusieurs CUI pour une entité , un crédit partiel a été attribué au système évalué pour chaque CUI commun avec la référence . 5 . 3 . 3 Résultats CLEF e - Health 2015 Pour chaque jeu de données MEDLINE et EMEA , le service Web de l’ECMT est exécuté avec les options restriction , catégorisation , réseau sémantique activées pour les tâches de reconnaissance d’entités et de reconnaissance d’entités normalisées . Pour satisfaire les conditions d’évaluation de la tâche , la sortie de l’ECMT est convertie du format XML en format BRAT . La Figure 5 . 4 est un exemple de ﬁchier d’annotation obtenu lors de l’indexation de la phrase « L’ hyperplasie médullosurrénalienne : une étiologie rare de l’ hypertension artérielle – rapport d’ un cas » . T1 DISO 3 35 hyperplasie médullosurrénalienne # 1 AnnotatorNotes T1 C0020507 T2 DISO 63 86 hypertension artérielle # 2 AnnotatorNotes T2 C0020538 T3 ANAT 76 86 artérielle # 3 AnnotatorNotes T3 C0003842 Figure 5 . 4 – Fichier d’annotation au format BRAT contenant des entités extraites par l’ECMT . Les résultats obtenus par l’ECMT pour chacun des jeu de données EMEA et MED - LINE pour les tâches de reconnaissance d’entités et de reconnaissances d’entités nor - malisées sont présentés dans les tableaux 5 . 1 , 5 . 2 , 5 . 3 et 5 . 4 . Les résultats obtenus dans cette première évaluation ne sont pas satisfaisants , en particulier pour le corpus EMEA où nous obtenons pour la reconnaissance d’entités une précision de 0 , 0040 et un rappel de 0 , 0022 en exact match et une précision de 0 , 4345 et un rappel de 0 , 2986 en inexact match . Pour la reconnaissance d’entités normalisées , nous obtenons en exact match une précision de 0 , 0044 et un rappel de 0 , 0024 et en inexact match une précision de 0 , 2305 et un rappel de 0 , 1440 . 114 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 1 – Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT 0 , 0040 0 , 0022 0 , 0028 0 , 4345 0 , 2986 0 , 3539 Moyenne 0 , 30912 0 , 3284 0 , 3108 0 , 4815 0 , 5198 0 , 4880 Médiane 0 , 2117 0 , 1835 0 , 2242 0 , 5767 0 , 5500 0 , 5538 Tableau 5 . 2 – Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités normalisées . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT 0 , 0044 0 , 0024 0 , 0031 0 , 2305 0 , 1440 0 , 1773 Moyenne 0 , 2854 0 , 2738 0 , 2792 0 , 4245 0 , 43218 0 , 4230 Médiane 0 , 0044 0 , 0071 0 , 0047 0 , 4234 0 , 5817 0 , 4901 Dans le corpus MEDLINE , pour la reconnaissance d’entités nous obtenons une pré - cision de 0 , 2284 et un rappel de 0 , 1335 en exact match , une précision de 0 , 7091 et un rappel de 0 , 6366 en inexact match . Pour la reconnaissance d’entités normalisées , nous obtenons une précision de 0 , 2953 et un rappel de 0 , 1861 en exact match , une précision de 0 , 5003 et un rappel de 0 , 3638 en inexact match . Les mauvais résultats obtenus pour le corpus MEDLINE peuvent être expliqués par les duplicats existants dans les termi - nologies et ontologies utilisées qui diminuent la précision et par les concepts issus de ressources non incluses dans l’UMLS et pour lesquelles aucun CUI ni groupe séman - tique n’est disponible , induisant une augmentation du bruit . En outre , les résultats en correspondance exacte , par rapport aux résultats en correspondance inexacte , pour - raient s’expliquer par de légères diﬀérences de termes utilisés . Le gold standard utilise des libellés UMLS tandis que l’ECMT utilise les libellés préférés de la terminologie d’origine . Cela entraîne des diﬀérences mineures entre le gold standard et l’ECMT . Par exemple , le gold standard peut considérer le libellé douleur tandis que l’ECMT fournira le libellé douleurs . Enﬁn , comme aucun traitement spéciﬁque n’a été eﬀectué pour extraire des entités qui se chevauchent , les entités imbriquées ne sont pas identi - ﬁées . L’ECMT identiﬁe alors des concepts plus précis que ceux présents dans le gold standard , mais ces concepts ne doivent pas être considérés comme du bruit . Les résultats obtenus pour le corpus EMEA sont proches de zéro . Ceci peut s’ex - pliquer par la présence de caractères spéciaux dans ces textes comme « µ » qui ne sont pas traités correctement par l’ECMT . De plus , les multiples sauts de ligne présents 115 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 3 – Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT 0 , 2284 0 , 1335 0 , 1685 0 , 7091 0 , 6366 0 , 6709 Moyenne 0 , 3549 0 , 4974 0 , 3958 0 , 5232 0 , 7240 0 , 5755 Médiane 0 , 3878 0 , 5937 0 , 4537 0 , 5872 0 , 7897 0 , 6655 Tableau 5 . 4 – Résultats obtenus lors de la compétition CLEF eHealth 2015 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités normalisées . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT 0 , 2953 0 , 1861 0 , 2283 0 , 5003 0 , 3638 0 , 4213 Moyenne 0 , 3213 0 , 4238 0 , 3363 0 , 4280 0 , 5052 0 , 4523 Médiane 0 , 2953 0 , 4033 0 , 2283 0 , 5003 0 , 5735 0 , 4213 dans ces documents provoquent un décalage des indices ce qui entraîne les résultats constatés en correspondance exacte car l’ECMT traite chaque saut de ligne comme un espace . 5 . 3 . 4 Résultats CLEF e - Health 2016 La seconde évaluation de l’ECMT a été eﬀectuée lors de la compétition CLEF eHealth 2016 dans la tâche d’extraction d’entités cliniques dans des textes cliniques . Pour chaque jeu de documents MEDLINE et EMEA , le service Web ECMT a été exécuté avec les options suivantes : restriction , catégorisation , réseau sémantique , priorisation activées . Deux séries ont été réalisées : ( i ) la série 1 utilise 13 termi - nologies et ontologies : ATC , CCAM , International Classiﬁcation for Patient Safety ( ICPC - 2 ) , FMA , HPO , CIM10 , Medline Plus , MeSH , NCIt , OMIM , HPO , Racines des médicaments ( PHARMA ) , SNOMED Int . et ( ii ) la série 2 utilise 7 terminologies et ontologies : ATC , CCAM , CIM10 , Medline Plus , MeSH , PHARMA , SNOMED Int . . Les résultats obtenus lors de cette compétition sont présentés dans les tableaux 5 . 5 , 5 . 6 , 5 . 7 , 5 . 8 pour la phase 1 de reconnaissances d’entités et de reconnaissance d’entités normalisées , et dans les tableaux 5 . 9 et 5 . 10 pour la phase 2 de normalisation . Phase 1 : Reconnaissance d’entités simples et reconnaissance d’entités nor - malisées Les résultats obtenus pour la phase 1 sont plutôt satisfaisants , en particulier dans la reconnaissance d’entités simples avec les résultats suivants : en correspondance exacte , nous obtenons une précision de 0 , 5381 et un rappel de 0 , 3784 ( série 1 ) avec le corpus EMEA et une précision de 0 , 6407 et un rappel de 0 , 4375 ( série 2 ) avec le corpus 116 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 5 – Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT - S1 0 , 5381 0 , 3784 0 , 4443 0 , 6490 0 , 4869 0 , 5564 ECMT - S2 0 , 5998 0 , 3285 0 , 4245 0 , 7175 0 , 4118 0 , 5233 Moyenne 0 , 5250 0 , 4114 0 , 4350 0 , 6377 0 , 5141 0 , 5423 Médiane 0 , 5998 0 , 3784 0 , 4443 0 , 7175 0 , 4808 0 , 5564 Tableau 5 . 6 – Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( EMEA ) - Reconnaissance d’entités normalisées . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT - S1 0 , 3800 0 , 2687 0 , 3148 0 , 4005 0 , 2842 0 , 3324 ECMT - S2 0 , 3885 0 , 2120 0 , 2743 0 , 4132 0 , 2270 0 , 2930 Moyenne 0 , 4762 0 , 3215 0 , 3761 0 , 4968 0 , 4341 0 , 4405 Médiane 0 , 4466 0 , 2687 0 , 3148 0 , 4666 0 , 2842 0 , 3324 MEDLINE . En correspondance inexacte , nous obtenons une précision de 0 , 649 et un rappel de 0 , 4869 ( série 1 ) avec le corpus EMEA et une précision de 0 , 7668 et un rappel de 0 , 5865 ( série 2 ) avec le corpus MEDLINE . Pour la reconnaissance d’entités normalisées , en correspondance exacte , nous obte - nons une précision de 0 , 38 et un rappel de 0 , 2687 ( série 1 ) avec le corpus EMEA et une précision de 0 , 4776 et un rappel de 0 , 3271 ( série 2 ) avec le corpus MEDLINE . En correspondance inexacte , nous obtenons une précision de 0 , 4005 et un rappel de 0 , 2842 ( série 1 ) avec le corpus EMEA et une précision de 0 , 4974 et un rappel de 0 , 3412 ( série 2 ) avec le corpus MEDLINE . Phase 2 : Normalisation Les résultats obtenus pour la phase 2 sont également plutôt satisfaisants . Les résultats obtenus sont les suivants : dans l’évaluation en cor - respondance exacte , nous obtenons une précision de 0 , 6044 et un rappel de 0 , 4626 ( série 2 ) avec le corpus EMEA et une précision de 0 , 5936 et un rappel de 0 , 515 ( série 1 ) avec le corpus MEDLINE . En correspondance inexacte , nous obtenons une précision de 0 , 605 et un rappel de 0 , 463 ( série 2 ) avec le corpus EMEA et une précision de 0 , 5938 et un rappel de 0 , 5153 ( série 1 ) avec le corpus MEDLINE . Dans cette phase , comme dans la phase 1 , la plupart des erreurs dans les CUI identiﬁés sont dues à des diﬀérences entre nos données et le gold standard . Comme nous avons utilisé jusqu’à 13 terminologies de diverses sources et que le portail HeTOP ne permet pas le suivi de versions , la plupart de ces erreurs sont liées aux sources de données et peuvent également être liées aux alignements entre ces sources ( et leurs 117 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 7 – Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT - S1 0 , 5399 0 , 4758 0 , 5058 0 , 6580 0 , 6492 0 , 6536 ECMT - S2 0 , 6407 0 , 4375 0 , 5199 0 , 7668 0 , 5865 0 , 6646 Moyenne 0 , 5030 0 , 4264 0 , 4455 0 , 6387 0 , 5707 0 , 5859 Médiane 0 , 6166 0 , 4375 0 , 4981 0 , 7394 0 , 5682 0 , 6422 Tableau 5 . 8 – Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 1 ( MEDLINE ) - Reconnaissance d’entités normalisées . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT - S1 0 , 4024 0 , 3562 0 , 3779 0 , 4203 0 , 3719 0 , 3946 ECMT - S2 0 , 4776 0 , 3271 0 , 3883 0 , 4974 0 , 3412 0 , 4047 Moyenne 0 , 5006 0 , 3760 0 , 4287 0 , 5181 0 , 4757 0 , 4917 Médiane 0 , 4927 0 , 3826 0 , 4308 0 , 5060 0 , 3917 0 , 4416 diﬀérentes versions ) et l’UMLS . 5 . 3 . 5 Discussion Par rapport aux résultats obtenus en 2015 , les résultats obtenus en 2016 sont amé - liorés , en particulier dans la reconnaissance d’entités simples . Pour le jeu MEDLINE , la précision en reconnaissance exacte des entités a été améliorée de 280 % et le rappel est amélioré par plus de trois fois ( voir Tableau 5 . 11 ) . Le traitement des caractères spéciaux dans les documents et les décalages ayant été corrigés , les documents EMEA ont pu être traités en correspondance exacte et améliorés en correspondance inexacte puisque la mesure F1 était de 0 , 35390 en 2015 et 0 , 5564 ( série 1 ) et 0 , 5233 ( série 2 ) en 2016 ( voir Tableau 5 . 12 ) . L’indexation avec plusieurs terminologies conduit à des termes dupliqués dans les Tableau 5 . 9 – Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 2 ( EMEA ) - Normalisation . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT - S1 0 , 5669 0 , 4753 0 , 5170 0 , 5674 0 , 4757 0 , 5175 ECMT - S2 0 , 6044 0 , 4626 0 , 5240 0 , 605 0 , 4630 0 , 5246 Moyenne 0 , 5507 0 , 4729 0 , 5073 0 , 5511 0 , 4732 0 , 5077 Médiane 0 , 5669 0 , 4753 0 , 5170 0 , 5674 0 , 4757 0 , 5175 118 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 10 – Résultats obtenus lors de la compétition CLEF eHealth 2016 avec l’ECMT - QUAERO Phase 2 ( MEDLINE ) - Normalisation . exact match inexact match Précision Rappel F1 Précision Rappel F1 ECMT - S1 0 , 5936 0 , 5150 0 , 5515 0 , 5938 0 , 5153 0 , 5518 ECMT - S2 0 , 5972 0 , 4676 0 , 5245 0 , 5975 0 , 4682 0 , 5250 Moyenne 0 , 5551 0 , 4854 0 , 5167 0 , 5553 0 , 4857 0 , 5170 Médiane 0 , 5936 0 , 4736 0 , 5245 0 , 5938 0 , 4736 0 , 5250 Tableau 5 . 11 – Comparatif des résultats CLEF eHealth 2015 et 2016 ( série 2 ) obtenus avec l’ECMT dans la tâche de reconnaissance d’entités sur le corpus MEDLINE . Tâche Précision Rappel F1 2015 entités , exact match 0 , 22840 0 , 13350 0 , 16850 entités , inexact match 0 , 70910 0 , 63660 0 , 67090 entités normalisées , exact match 0 , 29530 0 , 18610 0 , 22830 entités normalisées , inexact match 0 , 50030 0 , 36380 0 , 42130 2016 entités , exact match 0 , 6407 0 , 4375 0 , 5199 entités , inexact match 0 , 7668 0 , 5865 0 , 6646 entités normalisées , exact match 0 , 4776 0 , 3271 0 , 3883 entités normalisées , inexact match 0 , 4974 0 , 3412 0 , 4047 résultats d’indexation qui diminuent la précision . Ce fait explique les diﬀérences qui peuvent être observées entre les séries 1 ( 13 terminologies ) et 2 ( sept terminologies ) . Par rapport à l’année dernière , cette question a été prise en compte et une nouvelle option a été ajoutée dans l’ECMT . Cette option priorisation permet de conserver uniquement les termes les plus pertinents lorsque plusieurs terminologies ajoutent un même terme dans la sortie et donc réduisent le bruit . Ce classement repose sur l’utilisa - tion des types sémantiques . Pour chaque type sémantique , une liste des terminologies les plus pertinentes à retenir a été conçue manuellement . Cependant , à la date de la compétition , seulement 29 types sémantiques sur plus de 128 sont pris en charge . Le bruit introduit en utilisant des terminologies multiples pourrait alors être encore plus réduit dans le futur . En revanche , certaines erreurs dans les résultats de correspondance exacte ( par rapport aux résultats de correspondance inexacts ) subsistent . Les erreurs introduites par l’utilisation de ressources non UMLS restent présentes bien que non quantiﬁées . 119 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 12 – Comparatif des résultats CLEF eHealth 2015 et 2016 ( série 2 ) obtenus avec l’ECMT dans la tâche de reconnaissance d’entités sur le corpus EMEA . Tâche Précision Rappel F1 2015 entités , exact match 0 . 00400 0 . 00220 0 . 00280 entités , inexact match 0 . 43450 0 . 29860 0 . 35390 entités normalisées , exact match 0 . 00440 0 . 00240 0 . 00310 entités normalisées , inexact match 0 . 23050 0 . 14400 0 . 17730 2016 entités , exact match 0 , 5998 0 , 3285 0 , 4245 entités , inexact match 0 , 7175 0 , 4118 0 , 5233 entités normalisées , exact match 0 , 3885 0 , 2120 0 , 2743 entités normalisées , inexact match 0 , 4132 0 , 2270 0 , 2930 5 . 4 Évaluation de la couverture terminologique au sein du corpus LiSSa Plusieurs outils d’indexation sont disponibles en langue anglaise comme il a été décrit dans la section 2 . 5 . 2 ainsi que des terminologies et ontologies de référence dans le domaine de la santé , notamment l’UMLS . Les textes francophones ne bénéﬁcient pas de ces divers outils et ressources . Le français est légèrement représenté dans l’UMLS [ Névéol et al . , 2014 ] . Dans la version 2016AA , le thésaurus UMLS français gère 9 res - sources , tandis que 128 ressources sont disponibles en anglais , fournissant un concept français pour 85 685 CUI . Seulement 3 . 11 % des termes UMLS en anglais sont dis - ponibles en français et , si chaque terme en anglais a une moyenne de 2 synonymes , seulement 1 , 54 synonymes sont disponibles pour chaque terme en français . En janvier 2017 , HeTOP dispose de 363 936 CUI en français grâce à des traductions locales ou nationales . L’objectif de la présente évaluation est d’analyser la performance de ces ressources en français sur un corpus d’articles médicaux . Ceci devrait aider à réduire ( i ) le nombre de terminologies utilisées dans l’indexation automatique , ( ii ) le bruit gé - néré en utilisant plusieurs terminologies , en particulier avec certains types spéciﬁques de concepts et ( iii ) le nombre de concepts redondants . Dans la première phase de cette étude , on analyse la couverture de 32 terminologies disponibles dans le portail He - TOP sur le corpus médical de la base de données bibliographique LiSSa [ Griffon et al . , 2014 ] . Ensuite , dans la deuxième phase de cette étude , les résultats d’indexation automatique des cinq principales terminologies sont évalués par rapport à une norme aurifère annotée manuellement aﬁn d’évaluer l’indexation automatique et d’évaluer plus précisément la performance de ces cinq terminologies . 120 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE 5 . 4 . 1 Le corpus LiSSa Le corpus de la base de données bibliographiques LiSSa 9 vise à agréger l’ensemble de la littérature médicale en français . Les données de PubMed , d’Elsevier - Masson et de la revue Exercer sont disponibles , permettant la mise à disposition d’une base de données bibliographique riche de 832 446 références . Concernant les données postérieures à 2000 , LiSSa regroupe 265 195 références , dont 81 239 avec le résumé en français et 209 610 avec un lien vers le texte intégral ( dont 15 838 en accès gratuit ) . LiSSa dispose d’outils de ﬁltre et d’export . Aﬁn de déterminer la couverture terminologique de ce corpus , 50000 articles ont été choisis au hasard et chaque titre , résumé et ensemble de mots clés d’auteur ont été indexés à l’aide de l’outil ECMT . 5 . 4 . 2 Création du gold standard Un jeu de données de 300 documents a été développé avec 100 titres , 100 résumés et 100 ensembles de mots - clés d’auteur . Les documents ont été choisis au hasard dans le corpus de LiSSa puis je les ai revus manuellement pour éviter les données non pertinentes ( titres vides , tronqués , etc . ) . 5 . 4 . 3 Annotation manuelle L’objectif de la tâche d’annotation manuelle était de fournir une ressource aussi complète que possible . Pour compléter cette tâche , un outil Web intuitif a été développé pour supporter la réalisation d’annotations structurées riches . Il inclut un support spéciﬁque pour l’édition d’annotations : l’outil peut suggérer des concepts avec une fonction de complétion automatique répondant à l’entrée donnée . La vériﬁcation des contraintes liée à la terminologie d’indexation est entièrement intégrée dans l’interface d’annotation et les retours d’information sont immédiats , avec des eﬀets visuels clair mettant en évidence les annotations . Le gold standard a été annoté manuellement par quatre spécialistes ( BT , CL , LS , GK ) et un médecin ( NG ) avec les cinq terminologies obtenant la meilleure couverture du corpus déterminées lors de la première phase de l’évaluation . Cette tâche demande qu’une méthodologie spéciﬁque soit utilisée pour réduire le biais inter - expert . Ici , les annotations ont été eﬀectuées selon le point de vue d’un documentaliste , c’est - à - dire en annotant uniquement les principaux concepts pertinents selon l’information contenue dans le texte . La Figure 5 . 5 montre l’outil d’annotation avec le texte original fourni aux anno - tateurs avec des annotations mises en évidence et les annotations produites . 9 . http : / / www . lissa . fr 121 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Figure 5 . 5 – Interface de l’outil d’annotation manuelle LiSSa . 5 . 4 . 4 Évaluation Outil d’évaluation Un outil d’évaluation dédié a été développé pour calculer les comparaisons par paires entre les annotations manuelles du gold standard et les annotations issues de l’indexation automatique . Deux concepts sont considérés comme correspondants ( vrais positifs ) lorsque les concepts extraits sont identiques et que leurs positions dans le texte original coïncident . L’outil calcule les vrais positifs , les faux négatifs et les faux positifs , ainsi que la précision , le rappel et la mesure F1 comme décrit dans la section 2 . 7 . 1 . Évaluation de la couverture terminologique Dans cette tâche , 32 terminologies ont été sélectionnées parmi les 69 disponibles étant jugées les plus pertinentes pour cette tâche en tant que terminologies de réfé - rence utilisées au niveau national ou international . Ces ressources sont décrites dans le tableau A . 1 en annexe . La langue source de ces ressources varie : 13 terminologies sont publiées à l’origine en français alors que 19 ont été totalement ou partiellement traduites . Pour cette évaluation , un client ECMT spéciﬁque a été développé pour gérer la quantité de données à analyser . Chaque concept identiﬁé dans un document et ses métadonnées ( le type de concept , l’identiﬁant original , la terminologie ) a été stocké pour une analyse ultérieure . Préalablement à l’analyse de la couverture , les termes d’indexation qui présentaient les fréquences d’occurrence les plus élevées dans tout le 122 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE corpus ont été revus manuellement pour détecter les erreurs d’indexation fréquentes . Ils ont été exclus de l’indexation dans les cas pertinents . Le nombre de toutes les occurrences des concepts identiﬁées dans chaque termino - logie est déterminé pour chaque catégorie de document : titres , résumés et ensembles de mots - clés . Les résultats sont détaillés dans le tableau 5 . 13 et la Figure 5 . 6 . Des concepts distincts ( c’est - à - dire comptés une seule fois ) identiﬁés dans chaque termino - logie ont également été déterminés pour chaque catégorie de documents . Les résultats sont détaillés dans le tableau 5 . 14 . Les cinq terminologies dont sont issus le plus de termes d’indexation dans chaque catégorie de document , NCIt , SNOMED CT , SNOMED Int . , MeSH et Thésaurus Santé Publique ( TSP ) sont toujours les mêmes pour chaque groupe . Le thésaurus NCIt ob - tient la meilleure couverture dans toutes les catégories de documents , tandis que le thésaurus français de santé publique TSP est la seule ressource française à apparaître dans le premier tiers du classement des ressources . Des ressources plus spécialisées telles que Human Rare Diseases Ontology ( HRDO ) ( maladies rares ) ou ATC ( théra - peutique chimique ) obtiennent une couverture plus faible qu’attendu , ces ressources proposant un vocabulaire important bien que plus spécialisé . Les cinq premières ter - minologies donnant la meilleure couverture du corpus représentent ainsi 65 % à 70 % de l’ensemble des termes d’indexation identiﬁés . Cependant , certaines ressources plus restreintes publiées en français réalisent une bonne couverture du corpus malgré un nombre de termes d’indexation en français limités . Ces ressources telles que le thésau - rus CISMeF [ Douyère et al . , 2004 ] ou la classiﬁcation Q - Codes [ Jamoulle , 2013 ] sont en fait développées spéciﬁquement pour les informations cliniques et non cliniques dans les notes cliniques et pour compléter des terminologies plus importantes telles que MeSH ou SNOMED CT . La couverture déterminée uniquement pour des concepts distincts souligne une ré - currence élevée dans toutes les terminologies et toutes les catégories de documents , en particulier dans les résumés , par nature plus longs . Pour les titres , chaque concept a une fréquence moyenne de 11 , 92 . Pour les résumés , chaque concept a une fréquence moyenne de 75 , 76 . Pour les mots - clés , chaque concept a une fréquence moyenne de 10 , 62 . Évaluation des performances Le gold standard a été indexé avec l’ECMT avec chacune des cinq terminologies les mieux classées : MeSH , NCIt , TSP , SNOMED CT et MedDRA . SNOMED Int . a été écarté au proﬁt de MedDRA car elle est maintenant incluse dans SNOMED CT . Les options d’indexation automatique ont été déﬁnies pour récupérer les concepts les plus larges aﬁn de minimiser les concepts de haut niveau et de correspondre à la méthodologie adoptée lors de l’annotation manuelle . Cela permet de récupérer unique - 123 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE F r e n c h t e r m s Indexing terms ADICAP ADICAP ADICAP ADICAP ADICAP ADICAP ADICAPADICAP BNCI BNCI BNCI BNCI BNCI BNCI BNCIBNCI CCAM CCAM CCAM CCAM CCAM CCAM CCAMCCAM ICF ICF ICF ICF ICF ICF ICFICF ICD - O ICD - O ICD - O ICD - O ICD - O ICD - O ICD - O ICD - O CISMEF CISMEF CISMEF CISMEF CISMEF CISMEF CISMEFCISMEF ICPC - 2 ICPC - 2 ICPC - 2 ICPC - 2 ICPC - 2 ICPC - 2 ICPC - 2 ICPC - 2 CLADIMED CLADIMED CLADIMED CLADIMED CLADIMED CLADIMED CLADIMEDCLADIMED DSM - IV DSM - IV DSM - IV DSM - IV DSM - IV DSM - IV DSM - IV DSM - IV FMA FMA FMA FMA FMA FMA FMAFMA Genes & Proteins Genes & Proteins Genes & Proteins Genes & Proteins Genes & Proteins Genes & Proteins Genes & Proteins Genes & Proteins GO GO GO GO GO GO GOGO HPO HPO HPO HPO HPO HPO HPOHPO HRDO HRDO HRDO HRDO HRDO HRDO HRDOHRDO ICD - 10 ICD - 10 ICD - 10 ICD - 10 ICD - 10 ICD - 10 ICD - 10 ICD - 10 ICNP ICNP ICNP ICNP ICNP ICNP ICNPICNP LOINC LOINC LOINC LOINC LOINC LOINC LOINCLOINC LPP LPP LPP LPP LPP LPP LPPLPP MedDRA MedDRA MedDRA MedDRA MedDRA MedDRA MedDRAMedDRA Medline Plus Medline Plus Medline Plus Medline Plus Medline Plus Medline Plus Medline Plus Medline Plus MeSH MeSH MeSH MeSH MeSH MeSH MeSHMeSH NCIt NCIt NCIt NCIt NCIt NCIt NCItNCIt OMIM OMIM OMIM OMIM OMIM OMIM OMIMOMIM PASCAL PASCAL PASCAL PASCAL PASCAL PASCAL PASCALPASCAL PHARMA PHARMA PHARMA PHARMA PHARMA PHARMA PHARMAPHARMA Q - Codes Q - Codes Q - Codes Q - Codes Q - Codes Q - Codes Q - Codes Q - Codes SNOMED CT SNOMED CT SNOMED CT SNOMED CT SNOMED CT SNOMED CT SNOMED CT SNOMED CT SNOMED Int . SNOMED Int . SNOMED Int . SNOMED Int . SNOMED Int . SNOMED Int . SNOMED Int . SNOMED Int . SYNODOS SYNODOS SYNODOS SYNODOS SYNODOS SYNODOS SYNODOSSYNODOS TSP TSP TSP TSP TSP TSP TSPTSP UCUM UCUM UCUM UCUM UCUM UCUM UCUMUCUM 200 400 1000 2000 4000 10000 20000 40000 100000 100 1000 10000 100000 1000000 10000000 Figure 5 . 6 – Représentation graphique de la couverture terminologique des 32 terminologies et ontologies analysées dans le corpus LiSSa . 124 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE ment le concept le plus précis aﬁn d’éviter d’introduire du bruit . Par exemple , le texte « Hypertension cardiaque » ne sera annoté qu’avec le concept hypertension artérielle , à l’exclusion du concept de maladie cardiaque plus large . Ensuite , l’outil d’évaluation a été exécuté sur les résultats d’indexation automatique et les annotations manuelles . La performance a été évaluée pour chaque terminologie et chaque catégorie de documents . Les résultats sont présentés dans le tableau 5 . 15 . Dans les titres , MeSH réalise les meilleures performances avec une précision de 43 , 49 % et un rappel de 54 , 93 % . MedDRA est en seconde position avec une précision de 73 , 47 % et un rappel de 33 , 33 % . TSP donne une précision de 36 , 64 % et un rappel de 31 , 48 % . SNOMED CT et NCIt atteignent une performance beaucoup plus faible avec moins de 30 % de précision et un rappel comparable à ceux de TSP et de MedDRA . Selon l’analyse de couverture par concept distincts , chaque concept NCIt a une fréquence moyenne de 20 , 73 et SNOMED CT 11 , 93 dans les titres . Ces résultats attestent que NCIt et SNOMED CT contiennent de nombreux concepts redondants et non spéciﬁques qui introduisent du bruit dans l’indexation automatique . Dans les mots - clés , la performance est nettement meilleure pour chaque terminolo - gie , car les mots - clés contiennent , par déﬁnition , beaucoup moins d’informations non spéciﬁques que les titres et surtout les résumés . MeSH réalise les meilleures perfor - mances avec une précision de 66 . 80 % et un rappel de 55 . 71 % . MedDRA suit avec une précision de 78 , 89 % et un rappel de 39 , 66 % . TSP , NCIt et SNOMED CT atteignent des performances similaires avec une mesure F de 45 ± 2 % . Dans les résumés , l’indexation automatique donne de mauvais résultats avec chaque terminologie . Seul MeSH et MedDRA atteignent une mesure F1 supérieure à 20 % . Pour chaque terminologie , le rappel est similaire aux autres catégories de documents . Cepen - dant , la précision accuse une chute très importante , en particulier NCIt et SNOMED CT donnant moins de 10 % de précision . Cela doit être comparé aux résultats de la couverture lors de la phase 1 montrant une fréquence de concept moyenne de 75 , 76 dans les résumés . Ces résultats valident que les résumés d’indexation entraînent un niveau élevé de bruit par rapport aux titres et aux mots clés . 125 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 13 – Couverture terminologique dans le corpus LiSSa pour chaque catégorie de documents : titres , résumés , mots - clés . Titres Résumés Mots - clés Terminologie Concepts Terminologie Concepts Terminologie Concepts NCIt 150 224 NCIt 2 040 356 NCIt 52 423 MeSH 106 170 SNOMED CT 1 543 456 MeSH 50 937 SNOMED Int . 96 771 MeSH 1 238 133 TSP 47 237 SNOMED CT 95 409 TSP 1 089 331 SNOMED Int . 45 879 TSP 84 989 SNOMED Int . 827 714 SNOMED CT 36 771 MedDRA 45 164 LOINC 502 964 MedDRA 25 802 LOINC 36 483 MedDRA 395 434 LOINC 15 491 FMA 24 300 FMA 182 398 ICNP 13 585 ICNP 24 244 ICNP 161 341 FMA 8 819 CIM10 14 022 CLADIMED 87 924 HPO 7 633 HPO 10 493 CIM10 86 977 Medline Plus 7 260 ATC 9 903 HPO 79 312 CIM10 6 133 HRDO 9 612 HRDO 75 779 BNCI 3 746 CISMeF 7 961 Medline Plus 70 071 HRDO 3 553 Medline Plus 7 300 CISMeF 66 754 CISMeF 3 288 BNCI 5 141 PHARMA 49 571 CLADIMED 2 886 CLADIMED 4 934 Q - Codes 41 975 ATC 2 815 PHARMA 3 976 BNCI 41 245 CIF 2 485 ADICAP 3 875 CIF 22 757 GO 1 877 Q - Codes 3 166 ADICAP 20 408 ICPC - 2 1 331 GO 2 720 ICPC - 2 18 979 ADICAP 1 254 ICPC - 2 2 079 GO 18 624 Q - Codes 1 191 CIF 1 820 SYNODOS 16 665 PHARMA 1 052 ICD - O 1 784 OMIM 13 147 PASCAL 721 SYNODOS 1 221 ICD - O 9 299 ICD - O 381 PASCAL 744 PASCAL 3 735 SYNODOS 331 CCAM 282 DSM - IV 2 740 DSM - IV 151 DSM - IV 176 CCAM 2 499 CCAM 98 UCUM 50 Genes & Pro - teins 870 UCUM 18 OMIM 36 UCUM 333 OMIM 12 LPP 0 LPP 26 LPP 0 Genes & Pro - teins 0 ATC 0 Genes & Pro - teins 0 Total 755 049 Total 8 710 817 Total 345 160 126 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 14 – Couverture terminologique par concepts distincts dans le corpus LiSSa pour chaque catégorie de documents : titres , résumés , mots - clés . Titres Résumés Mots - clés Terminologie Concepts Terminologie Concepts Terminologie Concepts MeSH 11 324 MedDRA 19 281 MeSH 5 908 SNOMED Int . 10 396 SNOMED Int . 17 968 SNOMED Int . 4 290 MedDRA 8 644 MeSH 17 353 NCIt 4 249 SNOMED CT 7 996 SNOMED CT 17 192 MedDRA 4 024 NCIt 7 247 NCIt 12 683 SNOMED CT 3 491 TSP 3 617 TSP 5 799 TSP 2 801 LOINC 1 822 FMA 3 903 LOINC 1 012 FMA 1 815 LOINC 3 372 FMA 935 CIM10 1 758 HPO 2 997 CIM10 870 HPO 1 488 CIM10 2 812 HPO 823 ATC 1 332 HRDO 2 622 ICNP 712 HRDO 1 196 Q - Codes 2 488 HRDO 640 ICNP 944 ADICAP 1 069 ATC 562 PHARMA 835 CLADIMED 773 PHARMA 378 ADICAP 652 Medline Plus 683 Medline Plus 352 Medline Plus 443 OMIM 669 ADICAP 272 BNCI 353 ICNP 519 BNCI 228 CLADIMED 339 BNCI 484 CLADIMED 225 ICD - O 190 CIF 415 ICPC - 2 114 CIF 181 ICD - O 337 CIF 101 GO 168 GO 284 GO 97 ICPC - 2 163 ICPC - 2 276 ICD - O 94 CISMeF 98 SYNODOS 208 CISMeF 89 SYNODOS 72 CCAM 192 Q - Codes 84 Q - Codes 66 PHARMA 162 SYNODOS 41 CCAM 61 DSM - IV 138 DSM - IV 32 DSM - IV 38 Genes & Pro - teins 122 CCAM 27 PASCAL 34 CISMeF 119 PASCAL 24 OMIM 19 PASCAL 44 OMIM 7 UCUM 2 UCUM 5 UCUM 3 Genes & Pro - teins 0 LPP 3 PHARMA 0 LPP 0 ATC 0 Genes & Pro - teins 0 Total 63 293 Total 114 982 Total 32 485 127 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE Tableau 5 . 15 – Résultats de l’évaluation de l’indexation automatique réalisée par l’ECMT contre le gold standard . Terminologie Précision Rappel F1 Résumés MeSH 12 , 47 % 59 , 30 % 20 , 61 % NCIt 5 , 77 % 41 , 99 % 10 , 15 % TSP 11 , 08 % 37 , 56 % 17 , 11 % MedDRA 20 , 93 % 32 , 58 % 25 , 49 % SNOMED CT 6 , 24 % 32 , 26 % 10 , 45 % Titres MeSH 43 , 49 % 54 , 93 % 4 8 , 55 % NCIt 25 , 53 % 34 , 04 % 29 , 17 % TSP 36 , 64 % 31 , 48 % 33 , 86 % MedDRA 73 , 47 % 33 , 33 % 45 , 86 % SNOMED CT 26 , 30 % 27 , 95 % 27 , 10 % Mots - clés MeSH 66 , 80 % 55 , 71 % 60 , 75 % NCIt 59 , 81 % 34 , 53 % 43 , 78 % TSP 72 , 11 % 31 , 36 % 43 , 71 % MedDRA 78 , 89 % 39 , 66 % 52 , 79 % SNOMED CT 62 , 62 % 38 , 17 % 47 , 43 % Ensemble des résumés , titres et mots - clés MeSH 19 , 45 % 57 , 19 % 29 , 03 % NCIt 9 , 44 % 38 , 08 % 15 , 13 % TSP 16 , 97 % 34 , 73 % 22 , 80 % MedDRA 37 , 06 % 35 , 24 % 36 , 13 % SNOMED CT 10 , 84 % 33 , 00 % 16 , 32 % 128 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE 5 . 5 Synthèse L’indexation multi - terminologique de documents biomédicaux présente des problé - matiques particulières traitées dans ce chapitre . Nous avons tout d’abord présenté l’outil ECMT qui permet d’identiﬁer dans un texte des termes dans de multiples ter - minologies . L’utilisation de plusieurs terminologies spéciﬁques à un domaine pour l’in - dexation d’un texte médical présente des avantages . Elle peut permettre une meilleure identiﬁcation de termes spécialisés comme des actes thérapeutiques ou des spécialités pharmaceutiques . De plus , la sélection de terminologies correspondant à une problé - matique précise plutôt que l’utilisation d’une terminologie plus généraliste permet de cibler eﬃcacement les termes d’intérêt . Par exemple , pour l’indexation d’un corpus dans le but d’identiﬁer des eﬀets indésirables de médicaments , le choix de travailler avec les terminologies CIM10 , Adverse Reactions Terminology ( WHO - ART ) et Racines des médicaments ou l’ATC serait intéressant . La multi - terminologie présente également l’inconvénient important d’augmenter considérablement le bruit , proportionnellement au nombre de ressources utilisées . Le nombre de termes identiques identiﬁés dans des terminologies diﬀérentes peut ainsi devenir considérable . Nous avons donc proposé une méthode permettant de prioriser l’identiﬁcation d’un terme dans la terminologie la plus pertinente en fonction de son type sémantique . Cette méthode permet de réduire considérablement le nombre de termes identiﬁés sans aﬀecter le rappel du système . Parallèlement , l’outil ECMT a été évalué à plusieurs reprises dans le cadre des campagnes CLEF eHealth 2015 et 2016 . Notre première participation en 2015 , préa - lablement au développement de la méthode de priorisation , a permis de dresser un premier état des lieux et d’identiﬁer plus précisément les points à travailler . Notre par - ticipation en 2016 a démontré les progrès réalisés avec une amélioration importante de la mesure F1 du système , en particulier pour la reconnaissance exacte . Dans un second temps , une large étude de la couverture terminologique au sein d’un corpus d’articles biomédicaux en français issus de la base bibliographique LiSSa a été réalisée . Ce projet a permis d’une part de quantiﬁer l’apport de chaque terminologie dans l’indexation du corpus et d’autre part de conduire une évaluation de l’ECMT contre un gold standard annoté manuellement par notre équipe . Cette dernière évaluation a permis de conduire une évaluation multi - terminologique dans le sens où chaque terminologie choisie a servi à l’annotation , les campagnes de test CLEF eHealth portant elles uniquement sur les terminologies UMLS . Cette évaluation a conﬁrmé l’intérêt du MeSH mais aussi de thésaurus comme TSP . Malgré le travail réalisé , plusieurs aspects peuvent encore être améliorés dans le processus d’indexation . En particulier , s’agissant de l’indexation de textes médicaux , le traitement des erreurs du langage naturel est un point indispensable à traiter . En eﬀet , l’ECMT réalise une reconnaissance exacte entre le texte et les termes . Ainsi , un texte mal orthographié , porteur d’un nombre conséquent d’abréviations , ce qui est 129 CHAPITRE 5 . INDEXATION MULTI - TERMINOLOGIQUE l’une des caractéristiques des textes comme les comptes - rendus ou les courriers , ne sera pas indexé de façon satisfaisante . Cette problématique fait l’objet du chapitre suivant . 130 Chapitre 6 Indexation de textes libres dans les documents médicaux Sommaire 6 . 1 Indexation appliquée aux textes libres médicaux . . . . . 132 6 . 1 . 1 L’indexation de textes médicaux narratifs . . . . . . . . . . . 132 6 . 1 . 2 La reconnaissance partielle de texte : mesures de similarité . 133 6 . 1 . 3 L’approche phonétique . . . . . . . . . . . . . . . . . . . . . . 138 6 . 2 Sources de données . . . . . . . . . . . . . . . . . . . . . . . 141 6 . 2 . 1 Le corpus français CépiDC . . . . . . . . . . . . . . . . . . . 141 6 . 2 . 2 Le corpus anglais CDC . . . . . . . . . . . . . . . . . . . . . 142 6 . 2 . 3 Dictionnaires . . . . . . . . . . . . . . . . . . . . . . . . . . . 143 6 . 3 Extraction d’information dans des textes libres médicaux à l’aide de la CIM - 10 : CIM - IND . . . . . . . . . . . . . . . 144 6 . 3 . 1 Pré - traitements . . . . . . . . . . . . . . . . . . . . . . . . . . 145 6 . 3 . 2 Sélection des candidats . . . . . . . . . . . . . . . . . . . . . 145 6 . 3 . 3 Classement des candidats . . . . . . . . . . . . . . . . . . . . 146 6 . 4 Application aux corpus CépiDC et CDC . . . . . . . . . . 147 6 . 4 . 1 Compétition CLEF eHealth 2016 . . . . . . . . . . . . . . . . 147 6 . 4 . 2 Compétition CLEF eHealth 2017 . . . . . . . . . . . . . . . . 149 6 . 4 . 3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 6 . 5 Synthèse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 131 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Dans ce chapitre , je présenterai en premier lieu les problématiques liées à l’indexa - tion de textes médicaux narratifs comme des comptes - rendus . Nous verrons par la suite les sources et la description des données ayant été utilisées pour la conception d’une méthode d’indexation gérant le langage naturel et ses erreurs . Enﬁn , nous verrons l’évaluation de cette méthode dans les campagnes de test CLEF eHealth 2016 et 2017 . 6 . 1 Indexation appliquée aux textes libres médi - caux 6 . 1 . 1 L’indexation de textes médicaux narratifs La reconnaissance d’entités a été largement étudiée au cours de la dernière décennie dans le domaine biomédical ainsi que d’autres tels que les médias sociaux [ Derczynski et al . , 2015 ] ou la reconnaissance vocale [ Ma et al . , 2016 ] . À mesure que l’utilisation des services d’indexation s’est développée , des algorithmes de pointe ont amélioré la re - connaissance d’entités dans le texte médical formel pour l’anglais [ Mork et al . , 2017 ] . Cependant , les algorithmes ont du mal à s’adapter au texte libre , car ils sont conçus pour des textes formels et sont basés sur des fonctionnalités présentes dans des textes bien formés tels que des articles biomédicaux . Dans de nombreuses applications in - formatiques impliquant l’enregistrement et le traitement de données personnelles , il est nécessaire de permettre des variations dans l’orthographe des mots , causées par exemple par des erreurs de transcription . Le texte libre dans les comptes - rendus ou courriers médicaux comprend des erreurs d’orthographe , une utilisation incorrecte de la ponctuation , de la grammaire et de la capitalisation [ Lai et al . , 2015 ] . Dans d’autres langues , le texte libre peut également présenter une utilisation incorrecte des marques diacritiques . Dans les rapports médicaux , le texte est généralement composé de phrases courtes ou incomplètes , semblables à la prise de notes , avec une utilisation substantielle d’abréviations ambiguës . Habituellement , les comptes - rendus cliniques sont créés avec précipitation sans relecture laissant place à un grand nombre d’erreurs . Ces erreurs ne doivent pas seulement être reliées à la complexité de la langue , mais aussi aux carac - téristiques du domaine médical . Siklósi et al . ont constaté que les types d’erreurs les plus fréquentes sont les erreurs d’orthographe , les erreurs grammaticales , les phrases tronquées et les abréviations non standardisées [ Siklósi et al . , 2016 ] . En eﬀet , par opposition au texte formel , les abréviations sont rarement déﬁnies dans les rapports médicaux . Malgré les eﬀorts déployés dans l’indexation , même dans le domaine biomé - dical , l’extraction de l’information dans les notes cliniques doit encore faire face à ces déﬁs Menasalvas et Gonzalo - Martin [ 2016 ] . Pour traiter cette problématique et plus particulièrement celle de la variabilité du texte libre , il apparaît nécessaire d’uti - liser des méthodes du traitement automatique de la langue liées à la reconnaissance 132 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES partielle de texte , qui peuvent être combinées à des méthodes statistiques décrites dans la section 2 . 5 . 2 . 6 . 1 . 2 La reconnaissance partielle de texte : mesures de simi - larité Les mesures de similarité de texte jouent un rôle important dans la recherche et les applications liées aux textes dans des tâches telles que la RI , la classiﬁcation des textes , le regroupement de documents , la détection des thèmes , les systèmes de ques - tions / réponses , la traduction automatique , la synthèse de textes et d’autres . La simi - larité entre les mots est une partie fondamentale de la similarité du texte qui peut ensuite être utilisée pour déterminer des similarité de phrases , de paragraphes ou de documents . Les mots peuvent être similaires au niveau lexical ou au niveau sémantique . Lexicalement , les mots sont similaires s’ils ont une séquence de caractères similaire . Sé - mantiquement , les mots sont semblables s’ils ont le même sens , sont utilisés de la même manière ou dans le même contexte . La similarité lexicale est introduite par diﬀérents algorithmes basés sur les chaînes de caractères , la similarité sémantique est introduite à travers des algorithmes basés sur le corpus ou les connaissances . Les mesures basées sur les chaînes de caractères fonctionnent sur des séquences de chaînes et la compo - sition des caractères . Une mesure de similarité entre deux chaînes de caractères est une mesure appréciant la similarité ou la dissemblance ( distance ) entre deux chaînes de texte pour une correspondance ou une comparaison approximative des chaînes . La similarité basée sur le corpus est une mesure de similarité sémantique qui détermine la similarité entre les mots en fonction de l’information obtenue à partir de grands corpus . La similarité fondée sur la connaissance est une mesure de similarité sémantique qui détermine le degré de similarité entre les mots en utilisant des informations dérivées des réseaux sémantiques . Mesures de similarité lexicales Les mesures de similarité lexicales se basent sur les séquences de chaînes de carac - tères et leur composition en caractères . Une métrique de chaîne est une mesure qui détermine la similarité ou la dissemblance ( distance ) entre deux chaînes de caractères pour une correspondance ou une comparaison approximative des chaînes . Mesures basées sur les caractères Longest Common SubString ( LCS ) L’algorithme de la sous - chaîne commune la plus longue considère que la similarité entre deux chaînes est basée sur la longueur de la chaîne contiguë de caractères qui existe dans les deux chaînes . 133 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Damerau - Levenshtein Damerau - Levenshtein déﬁnit la distance entre deux chaînes en comptant le nombre minimal d’opérations nécessaires pour transformer une chaîne en l’autre , où une opération est déﬁnie comme une insertion , une suppression ou une substitution d’un seul caractère ou une transposition de deux caractères adjacents [ Hall et Dowling , 1980 ; Levenshtein , 1966 ; Peterson , 1980 ] . Jaro Jaro est basé sur le nombre et l’ordre des caractères communs entre deux chaînes . Il prend en compte les écarts d’orthographe typiques [ Jaro , 1995 , 2012 ] . Jaro - Winkler Jaro - Winkler est une extension de la distance de Jaro . Elle utilise une échelle de préﬁxe qui donne des valeurs plus favorables aux chaînes qui correspondent dès le début à une longueur de préﬁxe déﬁnie [ Winkler , 1990 ] . Needleman - Wunsch L’algorithme Needleman - Wunsch est un exemple de program - mation dynamique et a été la première application de programmation dynamique à la comparaison des séquences biologiques . Il eﬀectue un alignement global pour trou - ver le meilleur alignement sur l’ensemble des deux séquences . Il est approprié lorsque les deux séquences sont de longueur similaire , avec un degré signiﬁcatif de similarité [ Needleman et Wunsch , 1970 ] . Smith - Waterman Smith - Waterman est un autre exemple de programmation dyna - mique . Cet algorithme eﬀectue un alignement local pour trouver le meilleur alignement sur le domaine conservé de deux séquences . Il est utile pour des séquences dissemblables qui sont suspectées de contenir des régions de similarité ou des motifs de séquence si - milaires dans leur contexte de séquence plus large [ Smith et Waterman , 1981 ] . N - gram N - gram est une sous - séquence de n éléments à partir d’une séquence de texte donnée . Les algorithmes de similarité N - gram comparent les n - gram de chaque caractère ou mot de deux chaînes de caractères . La distance est calculée en divisant le nombre de n - gram similaires par le nombre maximal de n - gram [ Barrón - Cedeño et al . , 2010 ] . Mesures basées sur les termes Distance de bloc La distance de bloc est également connue sous le nom de distance de Manhattan , la distance de valeur absolue ou la distance L1 . Cet algorithme calcule la distance qui serait parcourue pour passer d’un point de données à l’autre si un chemin de grille est suivi . La distance de bloc entre deux éléments est la somme des diﬀérences de leurs composants correspondants [ Krause , 1973 ] . 134 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Similarité des cosinus La similarité des cosinus est une mesure de la similarité entre deux vecteurs d’un espace de produit interne qui mesure le cosinus de l’angle entre eux . Coeﬃcient de Dice Le coeﬃcient de Dice est déﬁni comme le double du nombre de termes communs dans les chaînes comparées divisé par le nombre total de termes dans les deux chaînes [ Dice , 1945 ] . Distance euclidienne La distance euclidienne ou la distance L2 est la racine carrée de la somme des diﬀérences carrées entre les éléments correspondants des deux vecteurs . Distance de Jaccard La similarité de Jaccard est calculée comme le nombre de termes partagés sur le nombre de tous les termes uniques dans les deux chaînes [ Jac - card , 1901 ] . Coeﬃcient de correspondance Le coeﬃcient de correspondance est une approche basée sur un vecteur très simple qui compte simplement le nombre de termes et dimen - sions similaires , sur lesquels les deux vecteurs sont non nuls . Coeﬃcient de chevauchement Le coeﬃcient de chevauchement est similaire au coeﬃcient de Dice , mais considère deux chaînes comme correspondantes si l’une est un sous - ensemble de l’autre . Mesures de similarité sémantiques basées sur le corpus La similarité basée sur le corpus est une mesure de similarité sémantique qui dé - termine la similarité entre les mots en fonction de l’information obtenue à partir de grands corpus . Un corpus est une grande collection de textes écrits ou parus qui est utilisée pour la recherche linguistique . Hyperspace Analogue to Language ( HAL ) Hyperspace Analogue to Language ( HAL ) [ Lund et Burgess , 1996 ; Lund et al . , 1995 ] crée un espace sémantique à partir de cooccurrences de mots . Une matrice mot par mot est formée avec chaque élément matriciel étant la force d’association entre le mot représenté par la ligne et le mot représenté par la colonne . L’utilisateur de l’algorithme a alors la possibilité d’abandonner les colonnes d’entropie faible de la matrice . Au fur et à mesure que le texte est analysé , un mot - clé est placé au début d’une fenêtre de dix mots qui enregistre les mots voisins comptés comme cooccurrents . Les valeurs de matrice sont accumulées en pondérant la cooccurrence inversement proportionnelle à la distance par rapport au mot - clé . On pense que les mots proches voisins reﬂètent davantage la sémantique du 135 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES mot - clé et sont donc plus élevés . HAL enregistre également l’information de l’ordre des mots en traitant la cooccurrence diﬀéremment selon que le mot voisin est apparu avant ou après le mot - clé . L’analyse sémantique latente ( LSA ) L’analyse sémantique latente ( LSA ) [ Lan - dauer et Dumais , 1997 ] est la technique de similarité basée sur le corpus la plus po - pulaire . LSA suppose que les mots qui ont une signiﬁcation proche se produiront dans des textes similaires . Une matrice contenant des nombres de mots par paragraphe ( les lignes représentent des mots uniques et des colonnes représentent chaque paragraphe ) est construite à partir d’un grand texte et une technique mathématique appelée dé - composition de valeur singulière ( SVD ) est utilisée pour réduire le nombre de colonnes tout en préservant la structure de similarité entre les lignes . Les mots sont ensuite com - parés en prenant le cosinus de l’angle entre les deux vecteurs formés par deux lignes quelconques . L’analyse sémantique latente généralisée ( GLSA ) L’analyse sémantique la - tente généralisée ( GLSA ) [ Matveeva et al . , 2005 ] étend l’approche LSA en se concen - trant sur les vecteurs de termes au lieu de la double représentation terme / document . GLSA requiert une mesure de l’association sémantique entre les termes et une méthode de réduction de la dimension . L’approche GLSA peut combiner toute mesure de simi - larité sur l’espace des termes avec n’importe quelle méthode appropriée de réduction de la dimension . La matrice traditionnelle document / terme est utilisée dans la dernière étape pour fournir les poids dans la combinaison linéaire des vecteurs de termes . L’analyse sémantique explicite ( ESA ) L’analyse sémantique explicite ( ESA ) [ Gabrilovich et Markovitch , 2007 ] est une mesure utilisée pour calculer la relation sémantique entre deux textes arbitraires . La technique basée sur Wikipedia représente les termes ( ou les textes ) en tant que vecteurs à haute dimension . Chaque entrée vec - torielle présente le poids TF - IDF entre le terme et un article Wikipédia . La relation sémantique entre deux termes ( ou textes ) est exprimée par la mesure du cosinus entre les vecteurs correspondants . Cross - Language Explicit Semantic Analysis ( CL - ESA ) CL - ESA [ Potthast et al . , 2008 ] est une généralisation multilingue de l’ESA . CL - ESA exploite une collection de référence multilingue alignée sur le document telle que Wikipedia pour représenter un document en tant que vecteur concept indépendant de la langue . La relation de deux documents dans diﬀérentes langues est évaluée par la similarité du cosinus entre les représentations vectorielles correspondantes . 136 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Google Distance La distance Google Distance ( NGD ) normalisée [ Cilibrasi et Vi - tanyi , 2007 ] est une mesure de similarité sémantique dérivée du nombre de résultats renvoyés par le moteur de recherche Google pour un ensemble donné de mots - clés . Les mots - clés ayant les mêmes signiﬁcations ou similaires en langage naturel ont tendance à être proches dans des unités de Google distance , alors que les mots ayant des si - gniﬁcations diﬀérentes ont tendance à être plus éloignés . Plus précisément , la distance NGD entre deux termes de recherche x et y est : NGD ( x , y ) = max ( log f ( x ) , log f ( y ) ) − log f ( x , y ) log M − min ( log f ( x ) , log f ( y ) ) ( 6 . 1 ) où M représente le nombre total de pages Web recherchées par Google ; f ( x ) et f ( y ) sont le nombre de résultats pour les termes de recherche x et y , respectivement ; et f ( x , y ) est le nombre de pages Web sur lesquelles x et y se produisent . Si les deux termes de recherche x et y ne se produisent jamais ensemble sur la même page Web , mais se produisent séparément , la distance NGD standard entre eux est inﬁnie . Si les deux termes se produisent toujours ensemble , leur NGD est nul ou équivalent au coeﬃcient entre x 2 et y 2 . Combinaison et comparaison des approches Une méthode pour mesurer la similarité sémantique entre les phrases ou les textes très courts , basée sur l’information sémantique et l’ordre des mots , a été présentée dans Li et al . [ 2006 ] . Tout d’abord , la similarité sémantique découle d’une base de connaissances lexicale et d’un corpus . Deuxièmement , la méthode proposée considère l’impact de l’ordre des mots sur la signiﬁcation de la phrase . La similarité de l’ordre des mots mesure le nombre de mots diﬀérents ainsi que le nombre de paires de mots dans un ordre diﬀérent . Les auteurs de Islam et Inkpen [ 2008 ] ont présenté une méthode nommée Semantic Text Similarity ( STS ) . Cette méthode détermine la similarité de deux textes à partir d’une combinaison d’informations sémantiques et syntaxiques . Ils ont considéré deux fonctions obligatoires ( similarité de chaîne et distance sémantique ) et une fonction facultative ( similarité d’ordre des mots communs ) . La méthode STS a obtenu un très bon coeﬃcient de corrélation de Pearson pour les séries de données de 30 phrases et a surpassé les résultats obtenus dans Li et al . [ 2006 ] . Les auteurs de Ag - garwal et al . [ 2012 ] ont présenté une approche qui combine la mesure de la relation sémantique basée sur le corpus sur toute la phrase avec les scores de similarité séman - tique basés sur la connaissance qui ont été obtenus pour les mots relevant des mêmes rôles syntaxiques dans les deux phrases . Tous les scores en tant que caractéristiques ont été alimentés par des modèles d’apprentissage , comme la régression linéaire , et des modèles de sacs de mots pour obtenir un seul score donnant le degré de similarité entre les phrases . Cette approche a montré une amélioration signiﬁcative dans le calcul de la 137 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES similarité sémantique entre les phrases en combinant la mesure de similarité fondée sur la connaissance et la mesure de similarité basée sur le corpus contre la mesure basée sur le corpus prise seule . Une corrélation prometteuse entre les résultats de similarité manuelle et automatique a été obtenue dans Buscaldi et al . [ 2012 ] en combinant deux modules . Le premier module calcule la similarité entre les phrases en utilisant la similarité n - gram , et le second module calcule la similarité entre les concepts dans les deux phrases en utilisant une mesure de similarité de concept et WordNet . Un système nommé UKP avec des résultats de corrélation raisonnables a été introduit dans Bär et al . [ 2012 ] , il a utilisé un modèle simple de régression linéaire basé sur des données d’apprentissage , pour combiner plusieurs mesures de similarité de texte . Ces mesures étaient la similarité des chaînes de caractères , la similarité sémantique , les mécanismes d’expansion du texte et les mesures liées à la structure et au style . Les modèles ﬁnaux de l’UKP se composaient d’une combinaison log - linéaire d’environ 20 caractéristiques , sur les 300 caractéristiques possibles mises en œuvre . 6 . 1 . 3 L’approche phonétique La correspondance phonétique est utilisée pour identiﬁer les chaînes qui peuvent être de prononciation similaire , quelle que soit leur orthographe . Une application ty - pique est l’identiﬁcation de noms propres . Par exemple , un opérateur téléphonique reçoit verbalement un nom , en suppose l’orthographe ( ou il lui est fourni une ortho - graphe , qui peut être incorrecte ) , et utilise son hypothèse pour interroger une base de données de noms . Le système de correspondance phonétique doit alors trouver dans la base de données les chaînes les plus susceptibles d’être identiques ou similaires à celles de la requête . Comme il n’existe aucun moyen ﬁable de déterminer automatiquement la prononciation d’une chaîne , cette correspondance doit être inexacte . La plupart des algorithmes existants et qui sont décrits ci - après ont été conçus pour la langue anglaise . Par conséquent , l’application de leurs règles aux mots d’autres langues peut ne pas don - ner un résultat exploitable . Un certain nombre d’algorithmes ont été développés pour l’appariement des mots , c’est - à - dire qui tentent d’identiﬁer les variations d’orthographe du mot , dont l’un des plus connus est l’algorithme de Soundex . À l’heure actuelle , il existe un certain nombre d’algorithmes phonétiques utilisant diﬀérents degrés de com - plexité pour surmonter ces variations . La sélection suivante de techniques illustre la gamme actuelle d’approches du problème sous leur forme plus générale , car beaucoup de ces algorithmes peuvent et ont été modiﬁés pour produire des correspondances plus précises pour des applications plus spécialisées . Russell Soundex L’algorithme Soundex est conçu principalement pour être utilisé avec des noms en anglais . Il a été breveté par Robert C . Russell et Margaret King Odell 138 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES en 1918 1 et 1922 2 . L’algorithme convertit chaque nom en un code à quatre caractères , qui peut être utilisé pour identiﬁer des noms équivalents , et qui est déterminé comme suit : 1 . Conserver la première lettre du nom et enlever toutes les occurrences de a , e , h , i , o , u , w , y dans d’autres positions . 2 . Aﬀecter les chiﬀres suivants aux lettres restantes après la première : — b , f , p , v ← 1 — l ← 4 — c , g , j , k , q , s , x , z ← 2 — m , n ← 5 — d , t ← 3 — r ← 6 3 . Si deux ou plusieurs lettres avec le même code étaient adjacentes dans le nom d’origine ( avant l’étape 1 ) , les omettre tous sauf le premier 4 . Convertir en forme « lettre , chiﬀre , chiﬀre , chiﬀre » en ajoutant des zéros à gauche ( s’il y a moins de trois chiﬀres ) , ou en enlevant les chiﬀres les plus à droite , s’il y en a plus de trois . Par exemple , les noms propres Euler , Gauss , Hilbert , Knuth et Lloyd reçoivent les codes respectifs E460 , G200 , H416 , K530 , L300 . Bien que le Soundex soit plus pré - cis que d’utiliser uniquement des similarités de caractères entre les noms , l’algorithme n’est pas idéal . Par exemple , « reynold » et « renauld » sont tous deux réduits à r543 , mais , plus communément , Soundex fait l’erreur de transformer des chaînes de sonorité dissemblables telles que « catherine » et « cotroneo » vers le même code et de trans - former des chaînes de sons similaires en diﬀérents codes . Il n’y a pas de classement des correspondance : les chaînes sont similaires ou non similaires . Pour les noms communs , il se révèlera plus eﬃcace pour reconnaître le début d’un mot , par exemple dans des fonction d’auto - complétion . Metaphone Cette technique a été développée par Lawrence Philips pour faire cor - respondre des mots qui se ressemblent et se basent sur les règles classiques de la pro - nonciation anglaise . Metaphone ignore les voyelles après la première lettre et réduit l’alphabet restant à seize sons consonnes , bien que les voyelles soient conservées lors - qu’elles sont la première lettre . Les lettres en double ne sont pas ajoutées au code . Zero est utilisé pour représenter le « th » , et « X » est utilisé pour le son « sh » . Les seize sons de consonnes sont : B X S K J T F H L M N P R Ø W Y . Il est plus précis que 1 . US patent 1261167 , R . C . Russell , 1918 - 04 - 02 2 . US patent 1435663 , R . C . Russell , 1922 - 11 - 14 139 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES le soundex car il prend en compte les règles de base de la prononciation anglaise . Me - taphone est disponible comme en standard dans de nombreux systèmes . L’algorithme produit des clés en sortie . Les sonorités similaires des mots partagent les mêmes clés et sont de longueurs diﬀérentes . Double Metaphone Le Double Metaphone est la deuxième génération de l’algo - rithme Metaphone [ Philips , 2000 ] . Il est conçu principalement pour coder les noms anglais américains tout en tenant compte du fait que de tels mots peuvent avoir plus d’une prononciation acceptable . Double Metaphone peut calculer un encodage primaire et secondaire pour un mot ou un nom donné pour indiquer à la fois la prononciation la plus probable ainsi qu’une prononciation alternative optionnelle ( d’où le « double » dans le nom ) . DM essaie de tenir compte d’une multitude d’irrégularités en anglais , mais aussi dans les langues slave , germanique , celtique , grecque , française , italienne , espagnole , chinoise et d’autres langues . Bien que puissant , DM a ses limites et ses in - convénients . DM a été conçu pour rechercher des listes de noms propres plutôt que de grandes quantités de texte . L’encodage peut ne pas correspondre à des mots mal orthographiés qui modiﬁent sérieusement la structure phonétique du mot . Malgré ses limites , l’algorithme de DM , qui est libre , est toujours un système d’encodage phoné - tique ﬂexible et puissant aujourd’hui , en particulier dans une approche multilingue . Caverphone 2 . 0 L’algorithme de correspondance phonétique Caverphone [ Hood , 2004 ] a été créé par David Hood dans le projet Caversham à l’Université d’Otago en Nouvelle - Zélande en 2002 , révisé dans une version 2 en 2004 . Il a été créé pour aider à la correspondance des données dans des listes électorales établies entre la ﬁn du 19ème siècle et le début du 20ème siècle , où le nom ne devait être que sous une « forme communément reconnaissable » . L’algorithme est destiné à s’appliquer à ces noms qui ne pouvaient pas être facilement comparables entre les listes électorales , après que les correspondances exactes ont été retirées du groupe de correspondances potentielles . Caverphone 2 . 0 considère plus eﬃcacement les cas présentant des voyelles initiales diﬀérentes et tolère mieux les consonnes post - vocaliques que Métaphone . La sensibilité de Caverphone 2 . 0 aux faux positifs se situe entre Metaphone et Soundex ( tendant à être similaire à Metaphone ) . Parmi ces algorithmes , l’algorithme DM est donc un choix intéressant pour un système multilingue puisqu’il permet la prise en compte de multiples langages . Il a donc été sélectionné pour la suite de mes travaux . 140 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES 6 . 2 Sources de données Dans le cadre de la campagne CLEF eHealth 2016 , un des deux tâches proposées impliquait l’indexation de certiﬁcats de décès , rédigés à la main par des médecins , avec la CIM10 . Ses données décrites dans cette partie ont servi de base à la conception d’une méthode prenant en compte les irrégularités dans les textes médicaux rédigés à la main . 6 . 2 . 1 Le corpus français CépiDC Depuis 1968 , le laboratoire CépiDC de l’Institut National de la Santé Et de la Recherche Médicale ( INSERM ) , se consacre à l’élaboration annuelle des statistiques nationales sur les causes des décès en association avec l’Institut national français de la statistique et des études économiques ( Insee ) , la diﬀusion des données et les études et recherches sur les causes médicales du décès . Ces statistiques sont construites à partir d’informations provenant de certiﬁcats de décès . L’équipe CépiDC gère une base de données contenant plus de 18 000 000 dossiers de décès Pavillon et Laurent [ 2003 ] . À partir de ces données , des jeux de données ont été conçus dans le cadre des challenges CLEF eHealth 2016 et 2017 . Ce challenge se concentre sur la reconnaissance de l’entité nommée dans les certiﬁcats de décès en français et en anglais ( en 2017 ) . Alors que les certiﬁcats de décès sont des documents normalisés remplis par les médecins pour signaler la mort d’un patient , ils présentent habituellement des erreurs d’orthographe ou de frappe , des abréviations et , en français , un texte non accentué ou un mélange de casse . Dans l’édition 2016 , un jeu de données a été utilisé dans le but d’indexer les certiﬁcats de décès à l’aide de la CIM10 . Dans l’édition 2017 , deux jeux de données ont été fournis . La tâche de ce challenge consiste à extraire les codes CIM10 des textes bruts du certiﬁcat de décès . Cette tâche d’extraction d’information repose sur le texte fourni pour extraire les codes CIM10 des certiﬁcats , ligne par ligne . Corpus CépiDC - CLEF eHealth 2017 Deux jeux de données sont fournis . Le premier ensemble de données s’appelle « da - taset aligné » et le second s’appelle « dataset brut » . Dataset aligné L’ensemble de données comprend 31 690 certiﬁcats de décès traités par CépiDC en 2014 totalisant 91 962 lignes . Les annotations dans le corpus CépiDC se composent de codes CIM10 et ont été attribuées par ligne de texte . L’ensemble de données est fourni dans un ﬁchier CSV . Chaque ligne contient douze champs d’infor - mation associés à une ligne brute de texte à partir d’un certiﬁcat de décès d’origine comme suit : — DocID : l’identiﬁant du certiﬁcat de décès ; 141 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES — YearCoded : année de traitement du certiﬁcat de décès ; — Gender : genre de la personne décédée ; — Age : âge au moment de la mort , arrondi ; — LocationOfDeath : lieu du décès ; — LineID : numéro de la ligne au sein du certiﬁcat de décès ; — RawText : text brut saisi dans le certiﬁcat de décès ; — IntType : intervalle de temps durant lequel le patient a souﬀert de la cause codée , selon les catégories suivantes : minutes , heures , jours , mois , années ; — IntValue : intervalle de temps durant lequel le patient a souﬀert de la cause codée ; — CauseRank : rang du code CIM10 ; — StandardText : entrée du dictionnaire ou extrait du texte auant permis de déter - miner le code CIM10 ; — ICD10 : code CIM10 code associé à la ligne de texte . La sortie comprend les 9 champs de saisie plus deux champs de texte ( CauseRank et StandardText ) utilisés pour indiquer la preuve supportant le code CIM10 fourni dans le douzième et dernier champ . Dataset brut Les données de 31 683 certiﬁcats de décès sont distribuées dans trois ﬁchiers CSV . Le premier ﬁchier inclut les champs suivants : DocID , YearCoded , LineID , RawText , IntType , IntValue . Le deuxième ﬁchier inclut les champs suivants : DocID , YearCoded , Gender , PrimCauseCode , Age , LocationOfDeath . Le troisième ﬁchier in - clut les champs suivants : DocID , YearCoded , LineID . Corpus CépiDC - CLEF eHealth 2016 L’ensemble de données comprend 65 843 certiﬁcats de décès traités par CépiDC au cours de la période 2006 - 2012 . Le corpus est fourni au format CSV et chaque ligne contient douze champs d’information associés à une ligne brute de texte à partir d’un certiﬁcat de décès d’origine . La sortie comprend les 9 champs de saisie plus deux champs de texte utilisés pour signaler les éléments de preuve mettant en évidence le code CIM10 fourni dans le douzième et dernier champ . Le dixième champ doit contenir l’extrait du texte original ayant permis la prédiction du code CIM10 . 6 . 2 . 2 Le corpus anglais CDC Ce corpus a été utilisé dans le cadre du challenge CLEF eHealth 2017 et mis au point par l’institut CDC américain . Les données de 6 665 certiﬁcats de décès sont distribuées parmi trois ﬁchiers CSV . Le premier ﬁchier inclut les champs suivants : 142 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES DocID , YearCoded , LineID , RawText , IntType , IntValue . Le deuxième ﬁchier inclut les champs suivants : DocID , YearCoded , Gender , PrimCauseCode , Age , LocationOf - Death . Le troisième ﬁchier inclut les champs suivants : DocID , YearCoded , LineID . La Figure 6 . 1 donne un exemple de documents fournis dans le corpus français CépiDC . Le septième champ contient le texte à annoter , le onzième l’entrée du diction - naire ICD10 correspondant au texte et au dernier champ le code ICD10 correspondant . De même , la Figure 6 . 2 donne un exemple de documents fournis dans le corpus anglais CDC . 64185 ; 2013 ; 2 ; 85 ; 2 ; 5 ; SYNDROME DE GLISEMENT AVEC GRABATISATION DEPUIS OCTOBRE 2012 ; 4 ; 3 ; 6 - 1 ; syndrome glissement ; R453 64185 ; 2013 ; 2 ; 85 ; 2 ; 5 ; SYNDROME DE GLISEMENT AVEC GRABATISATION DEPUIS OCTOBRE 2012 ; 4 ; 3 ; 6 - 1 ; grabatisation ; R263 79317 ; 2013 ; 2 ; 85 ; 2 ; 6 ; héùorragie digestive basse sur surdosage en AVK ; 3 ; 5 ; 6 - 3 ; hémorragie digestive basse ; K921 79317 ; 2013 ; 2 ; 85 ; 2 ; 6 ; héùorragie digestive basse sur surdosage en AVK ; 3 ; 5 ; 6 - 3 ; surdosage avk ; X44 64370 ; 2013 ; 1 ; 80 ; 2 ; 5 ; ABCES CERVICAL . LARYNGECTOMIE TOTALE . ATCD D’IDM . ; NULL ; NULL ; ; laryngectomie totale ; Z900 64370 ; 2013 ; 1 ; 80 ; 2 ; 5 ; ABCES CERVICAL . LARYNGECTOMIE TOTALE . ATCD D’IDM . ; NULL ; NULL ; ; abcès cervical ; L021 64370 ; 2013 ; 1 ; 80 ; 2 ; 5 ; ABCES CERVICAL . LARYNGECTOMIE TOTALE . ATCD D’IDM . ; NULL ; NULL ; ; antécédent infarctus myocarde ; I258 Figure 6 . 1 – Extraits de certiﬁcats de décès en français dans le corpus CépiDC . 13496 ; 2015 ; ; ; ; 6 ; Senile dementia of Alzheimer’s type ASHD ; ; ; ; senile dementia ; F03 13496 ; 2015 ; ; ; ; 6 ; Senile dementia of Alzheimer’s type ASHD ; ; ; ; alzheimer ; G309 13496 ; 2015 ; ; ; ; 6 ; Senile dementia of Alzheimer’s type ASHD ; ; ; ; ashd ; I251 16915 ; 2015 ; ; ; ; 2 ; HEALTHCAREASSOCIATED PNEUMONIA ; ; ; ; healthcare - associated pneumonia ; J189 Figure 6 . 2 – Extraits de certiﬁcats de décès en anglais dans le corpus CDC . 6 . 2 . 3 Dictionnaires Dictionnaires orthographiques Le corpus français de CépiDC comprend six versions d’un dictionnaire CIM10 orga - nisé manuellement , développé à CépiDC correspondant aux années : 2006 - 2010 , 2011 , 2012 , 2013 , 2014 et 2015 . En 2017 , le corpus CDC anglais comprend un dictionnaire 143 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES CIM10 organisé manuellement , développé par la CDC fournissant 170 285 entrées . Ces ressources ont été utilisées pour créer des dictionnaires d’orthographe . De plus , les données d’apprentissage ont été utilisées pour compléter ces dictionnaires . Traitement des dictionnaires Pour chaque langue , les versions du dictionnaire ont été fusionnées si nécessaire . Chaque terme de la CIM10 a été séparé en mots et les doublons ont été supprimés . Les deux listes de mots uniques obtenues ont fourni un dictionnaire d’orthographe pour chaque langue . Ensuite , un dictionnaire supplémentaire a été produit à partir de chaque jeu de données d’apprentissage en extrayant le code CIM10 et les combinaisons de termes . Le nombre de fois qu’un code CIM10 a été utilisé dans le corpus de formation a également été déterminé . Pour des termes ambigus , c’est - à - dire des termes qui correspondent à plus d’un code CIM10 , le terme le plus utilisé a été conservé . Chaque dictionnaire supplémentaire a été fusionné avec les dictionnaires fournis dans le corpus correspon - dant . Si un terme était présent dans le dictionnaire additionnel et un dictionnaire de corpus , mais les codes correspondants étaient diﬀérents , le code du dictionnaire sup - plémentaire a été supprimé pour éviter d’introduire une ambiguïté entre les versions du dictionnaire . Ce traitement a permis de compléter les dictionnaires fournis en par - ticulier par quelques abréviations manquantes . 6 . 3 Extraction d’information dans des textes libres médicaux à l’aide de la CIM - 10 : CIM - IND CIM - IND est conçu pour faire correspondre les termes CIM10 au texte fourni en entrée dans la version correspondante de la CIM10 . L’extraction est eﬀectuée au niveau de la phrase du texte en utilisant des techniques de traitement du langage naturel . Le système est construit en utilisant des extensions Python et Python / C et fournit une réponse au format CSV pour chaque concept identiﬁé avec : ( i ) le texte d’entrée , ( ii ) le décalage du premier et du dernier mot contenu dans le concept de santé , ( iii ) l’identiﬁant CIM10 et ( iv ) le terme CIM10 . CIM - IND eﬀectue trois étapes principales pour identiﬁer les termes de la CIM10 : une étape de prétraitement , la sélection des candidats et le classement des candidats . 144 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES 6 . 3 . 1 Pré - traitements Normalisation Plusieurs étapes de prétraitement sont eﬀectuées , y compris le ﬁltrage des mots vide ( en utilisant les listes de mots d’arrêt NLTK par défaut pour le français et l’anglais Bird et al . [ 2009 ] ) et le ﬁltrage élision ( en supprimant les articles abrégés qui sont contractés avec des termes ) . La casse des mots n’est pas prise en compte . Les diacritiques dans les textes français sont conservés et Unicode est utilisé pour assurer la correspondance . Correction orthographique La vériﬁcation orthographique est eﬀectuée avec la bibliothèque Enchant en utilisant le dictionnaire construit manuellement comme décrit dans la section 6 . 2 . 3 . 6 . 3 . 2 Sélection des candidats Une méthode basée sur l’algorithme de codage phonétique Double Metaphone ( DM ) [ Philips , 2000 ] est utilisée pour réaliser une première recherche de termes approxima - tive . Tout d’abord , CIM - IND calcule l’encodage DM pour chaque mot inclus dans la phrase normalisée . Ensuite les candidats dont le terme CIM10 présente un encodage DM correspondant sont récupérés . Cette étape fournit rapidement une liste de candidats pertinents de la CIM10 et permet d’eﬀectuer des traitements coûteux sur un ensemble réduit de termes dans la phase suivante . De cette façon , le système repose sur une base de données pour stocker le codage DM précalculé pour chaque mot disponible dans chaque dictionnaire de la version CIM10 . Cette base de données est implémentée avec le système MySQL et son modèle est décrit dans la ﬁgure 6 . 3 . Il permet la gestion de versions des terminologies intégrées . Par exemple , dans la ﬁgure 6 . 1 , les lignes 1 - 2 contiennent le mot mal orthographié « glisement » ( pour « glissement » ) et les lignes 3 - 4 contiennent le mot mal orthogra - phié « héúorragie » ( pour « hémorragie » ) . La première erreur est correctement traitée par l’algorithme DM qui fournit le même encodage à la fois pour le mot mal orthogra - phié et le mot correct . Cependant , la deuxième erreur n’est pas correctement traitée . Comme l’erreur modiﬁe profondément la phonétique du mot , l’algorithme DM donne un encodage diﬀérent de celui du mot correct . Cela met en évidence l’importance de procéder à une vériﬁcation orthographique du texte normalisé pour éviter les mots les plus mal orthographiés avant l’encodage phonétique et ainsi assurer une liste de candidats correcte . 145 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES word VARCHAR ( 128 ) id _ word INT ( 11 ) words dm _ key VARCHAR ( 128 ) dw _ id _ word INT ( 11 ) dw _ id INT ( 11 ) dictionary _ words dw _ id _ entry INT ( 11 ) entry VARCHAR ( 128 ) id _ entry INT ( 11 ) dictionary icd10 _ code VARCHAR ( 45 ) dv _ id _ entry INT ( 11 ) dv _ id INT ( 11 ) dictionary _ version dv _ id _ version INT ( 11 ) date VARCHAR ( 45 ) id _ version INT ( 11 ) version position INT ( 11 ) n = 23182 n = 4 n = 188352 n = 617807 n = 535437 Figure 6 . 3 – Modèle de données physique du système CIM - IND . 6 . 3 . 3 Classement des candidats Enﬁn , un algorithme de score de distance pondéré ( WDS ) a été développé pour classer la liste des termes candidats . L’algorithme WDS renvoie un score de similarité de 0 à 100 pour chaque candidat , 100 représentant une correspondance parfaite . Le terme le plus probable ayant le score le plus élevé est conservé en tant que terme correspondant à la CIM10 . Comme un seul ou plusieurs termes CIM10 peuvent être présents dans une phrase , deux cas sont considérés . Tout d’abord , si la longueur de la chaîne du candidat s 1 est semblable à la longueur de la chaîne s 2 ( c . - à - d . qu’un seul terme CIM10 est attendu ) , deux scores sont calculés : ( i ) un score de base ( BS ) et ( ii ) un score d’ensemble ( SeS ) . Le BS est calculé en déterminant la distance de Levenshtein entre les séquences s 1 et s 2 échelonnée de 0 à 100 . Le SeS détermine tous les caractères alphanumériques dans chaque chaîne et les traite comme un ensemble . Ensuite , deux chaînes de caractères sont construites en concaténant , d’une part , l’intersection triée et , d’autre part , le reste trié . Ensuite , la distance de ces chaînes est calculée en contrôlant les correspondances partielles non ordonnées . Sinon , si l’une des séquences est au moins 1 , 5 fois plus longue que l’autre , deux scores partiels sont calculés : ( i ) un score de base partiel ( PBS ) et ( ii ) un score d’en - semble partiel ( PSeS ) . Le PBS renvoie la distance de la sous - chaîne la plus similaire sous la forme d’un nombre entre 0 et 100 . Tout d’abord , chaque bloc représentant une séquence de caractères correspondants dans une chaîne est déterminé . Ensuite , la meilleure reconnaissance partielle sera l’alignement contenant au moins un de ces blocs . 146 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Le PSeS calcule le PBS pour chaque chaîne créée à partir de l’intersection triée et le reste trié de s 1 et s 2 . Pour s’assurer que seuls les résultats complets peuvent retourner une correspondance parfaite , les scores partiels sont mis à l’échelle en fonction de la longueur de s 1 et s 2 . Tous les scores d’ensemble sont mis à l’échelle de 0 , 95 . Enﬁn , le score WDS est déterminé comme le maximum de ces scores . 6 . 4 Application aux corpus CépiDC et CDC Le système CIM - IND a été évalué lors des éditions 2016 [ Cabot et al . , 2016b ; Kelly et al . , 2016 ; Névéol et al . , 2016 ] et 2017 [ Cabot et al . , 2017 ; Goeuriot et al . , 2017 ; Névéol et al . , 2017 ] de la compétition CLEF eHealth . Ces deux éditions ont proposé une tâche d’extraction des causes de décès dans les certiﬁcats de décès fournis par les corpus CépiDC et CDC telles que codées par la CIM - 10 . 6 . 4 . 1 Compétition CLEF eHealth 2016 Résultats préliminaires et comparaison des méthodes de similarité Préalablement à l’évaluation lors de la compétition , plusieurs méthodes ont été éva - luées sur le jeu d’apprentissage fourni . L’analyse du jeu d’apprentissage a été eﬀectuée à l’aide de quatre méthodes : ( i ) tout d’abord avec l’ECMT , ( ii ) une méthode combi - nant correction orthographique et reconnaissance exacte du texte , ( iii ) une méthode combinant correction orthographique et reconnaissance partielle à l’aide de la distance de Levenshtein , et enﬁn ( iv ) une méthode combinant la correction orthographique du texte et la reconnaissance partielle déterminée par les distances de Levenshtein et l’al - gorithme LCS . Les résultats obtenus sont présentés dans le Tableau 6 . 1 . Résultats de la compétition CLEF eHealth 2016 CIM - IND analyse l’ensemble des données de test CépiDC et produit les résultats au format CSV . Les résultats tels qu’évalués par l’organisation de la compétition sont présentés dans le tableau 6 . 2 . Dans ce jeu de données , une précision de 0 , 6964 et un rappel de 0 , 6634 sont obtenus . Le nombre de termes retrouvés est satisfaisant , mais en comparaison des résultats obtenus par d’autres équipes participant à la compétition , le taux d’erreur est élevé ( Tableau 6 . 3 ) . Dans cette version préliminaire de CIM - IND , seules les distances de Levenshtein et de sous - chaîne commune la plus longue étaient utilisées pour classer les candidats . Ces deux mesures aboutissent ainsi à un nombre important d’erreurs , mettant en évidence la nécessité de travailler à une combinaison de méthode de distances plus complète et adaptée avec le score WDS . 147 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Tableau 6 . 1 – Comparaison des méthodes de similarité sur le corpus CépiDC . Méthode ECMT Correction orthographique et reconnaissance exacte Correction orthographique et distance de Levenshtein Correction orthographique et distances de Levenshtein et LCS Précision 0 , 69 0 , 64 0 , 79 0 , 78 Rappel 0 , 23 0 , 62 0 , 48 0 , 59 F1 0 , 34 0 , 63 0 , 60 0 , 67 Temps d’exécu - tion par ligne 40ms 70ms 100ms 100ms Tableau 6 . 2 – Résultats de CIM - IND sur le corpus CépiDC - CLEF eHealth 2016 . TP FP FN Précision Rappel F1 CIM - IND 72192 31480 36626 0 , 6964 0 , 6634 0 , 6795 Moyenne 0 , 7878 0 , 6636 0 , 7185 Médiane 0 , 8110 0 , 6554 0 , 6997 Tableau 6 . 3 – Résultats du challenge CLEF eHealth 2016 par équipe pour la tâche de codage CIM10 sur le corpus CépiDC ( de Névéol et al . [ 2016 ] ) . Équipe Précision Rappel F1 Erasmus - run2 0 , 886 0 , 813 0 , 848 Erasmus - run1 0 , 890 0 , 803 0 , 844 ERIC - ECSTRA - run2 0 , 882 0 , 655 0 , 752 ERIC - ECSTRA - run1 0 , 811 0 , 615 0 , 700 CIM - IND 0 , 696 0 , 663 0 , 680 LIMSI - run1 0 , 765 0 , 569 0 , 652 BITEM - run1 0 , 585 0 , 526 0 , 554 Moyenne 0 , 788 0 , 664 0 , 719 Médiane 0 , 811 0 , 655 0 , 700 148 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES 6 . 4 . 2 Compétition CLEF eHealth 2017 L’évaluation a été eﬀectuée par les organisateurs pour deux cas : ( i ) pour tous les codes CIM10 , l’évaluation principale et ( ii ) pour les codes CIM10 traitant d’un type particulier de décès , appelés « causes externes » ou décès violents Névéol et al . [ 2017 ] . Tableau 6 . 4 – Résultats de CIM - IND pour chaque jeu de données français CépiDC et anglais CDC - CLEF eHealth 2017 . Toutes causes Causes externes Jeu de données Précision Rappel F1 Précision Rappel F1 Français - Jeu de don - nées brut CépiDC 0 , 8568 0 , 6886 0 , 7636 0 , 5670 0 , 4310 0 , 4897 Français - Jeu de don - nées aligné CépiDC 0 , 8346 0 , 7751 0 , 8038 0 , 5343 0 , 4717 0 , 5011 Anglais - Jeu de données CDC 0 , 8393 0 , 7827 0 , 8100 0 , 4261 0 , 3889 0 , 4066 Résultats sur le corpus français CépiDC CIM - IND a été exécuté sur les deux jeux de test français et une exécution a été soumise pour chacun de ces jeux de données . Le Tableau 6 . 4 montre les résultats obtenus sur les jeux de données brut et aligné . Les résultats obtenus par chaque équipe participante dans le challenge sont présentés dans les tableaux 6 . 5 et 6 . 6 . Sur le jeu de données brutes , CIM - IND a obtenu une précision de 0 , 8568 et un rappel de 0 , 6886 ( F 1 = 0 , 7636 ) pour tous les codes CIM10 . En ce qui concerne uniquement les codes CIM10 correspondant à des causes externes ( c’est - à - dire des décès violents ) , CIM - IND a réalisé une performance inférieure substantielle avec une précision de 0 , 567 et un rappel de 0 , 431 ( F 1 = 0 , 4897 ) . Sur le jeu de données aligné , CIM - IND a atteint une précision de 0 , 8346 et un rappel de 0 , 7751 ( F 1 = 0 , 8038 ) pour tous les codes CIM10 . En ce qui concerne uniquement les codes CIM10 correspondant à des causes externes , CIM - IND a de nouveau réalisé une performance inférieure avec une précision de 0 , 5343 et un rappel de 0 , 4717 ( F 1 = 0 , 5011 ) . Étant donné que la principale diﬀérence entre ces deux jeux de données était liée au formatage , il était attendu d’obtenir des résultats similaires . Cependant , remarqua - blement , le jeu de données alignées obtient un rappel plus élevé que le jeu de données brutes . Ensuite , il convient de noter que les performances sont considérablement infé - rieures en ce qui concerne uniquement les codes CIM10 liés aux causes externes pour les deux jeux de test . Dans ce corpus , les résultats de CIM - IND sont considérablement meilleurs que le score moyen et médian de toutes les séries soumises . 149 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Tableau 6 . 5 – Résultats du challenge CLEF eHealth 2017 par équipe pour la tâche de codage CIM10 sur le jeu de données brut CépiDC français ( de Névéol et al . [ 2017 ] ) . Toutes causes Causes externes Équipe Précision Rappel F1 Précision Rappel F1 E ss a i s o ﬃ c i e l s CIM - IND 0 , 857 0 , 689 0 , 764 0 , 567 0 , 431 0 , 490 LITL - run2 0 , 666 0 , 414 0 , 510 0 , 443 0 , 367 0 , 401 LIRMM - run1 0 , 541 0 , 480 0 , 509 0 , 443 0 , 367 0 , 401 LIRMM - run2 0 , 540 0 , 480 0 , 508 0 , 560 0 , 283 0 , 376 LITL - run1 0 , 651 0 , 404 0 , 499 0 , 538 0 , 277 0 , 365 TUC - MI - run2 0 , 044 0 , 026 0 , 033 0 , 010 0 , 004 0 , 005 TUC - MI - run1 0 , 025 0 , 015 0 , 019 0 , 006 0 , 005 0 , 005 Moyenne 0 , 475 0 , 358 0 , 406 0 , 367 0 , 247 0 , 292 Médiane 0 , 541 0 , 414 0 , 508 0 , 443 0 , 283 0 , 376 E ss a i s n o n o ﬃ c i e l s LIMSI - run2 0 , 872 0 , 784 0 , 825 0 , 700 0 , 594 0 , 643 LIMSI - run1 0 , 883 0 , 760 0 , 817 0 , 709 0 , 559 0 , 625 TUC - MI - run1 - corr . 0 , 883 0 , 539 0 , 669 0 , 780 0 , 290 0 , 423 TUC - MI - run2 - corr . 0 , 882 0 , 536 0 , 667 0 , 767 0 , 283 0 , 414 UNIPD - run1 0 , 629 0 , 468 0 , 537 0 , 350 0 , 381 0 , 365 UNIPD - run2 0 , 518 0 , 384 0 , 441 0 , 362 0 , 251 0 , 296 Mondeca - run1 0 , 375 0 , 131 0 , 194 0 , 335 0 , 228 0 , 271 Résultats sur le corpus anglais CDC Une série a été soumise pour le jeu de données CDC anglais . Le Tableau 6 . 4 présente les résultats obtenus sur ce jeu de données . Les résultats obtenus par chaque équipe participante dans le challenge sont présentés dans le tableau 6 . 7 . CIM - IND a obtenu une précision de 0 , 8393 et un rappel de 0 , 7827 ( F 1 = 0 , 8100 ) pour tous les codes CIM10 . En ce qui concerne uniquement les codes CIM10 corres - pondant à des causes externes , CIM - IND a atteint une performance inférieure avec une précision de 0 , 4261 et un rappel de 0 , 3889 ( F 1 = 0 , 4066 ) . En ce qui concerne tous les codes CIM10 , ces résultats sont légèrement meilleurs que les résultats obtenus avec le jeu de données brutes français , mais remarquablement similaires à ceux obtenus avec le jeu de données alignées . Encore une fois , il existe une baisse signiﬁcative de la performance concernant uniquement les codes CIM10 liés aux causes externes . Dans ce cas , les résultats sont inférieurs à ceux obtenus sur les deux jeux de données français , à la fois pour la précision et le rappel . Dans ce corpus , selon les deux évaluations , nos résultats sont supérieurs au score moyen et médian de toutes les séries soumises lors de la compétition . 150 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Tableau 6 . 6 – Résultats du challenge CLEF eHealth 2017 par équipe pour la tâche de codage CIM10 sur le jeu de données aligné CépiDC français ( de Névéol et al . [ 2017 ] ) . Toutes causes Causes externes Équipe Précision Rappel F1 Précision Rappel F1 E ss a i s o ﬃ c i e l s SIBM - run1 0 , 835 0 , 775 0 , 804 0 , 534 0 , 472 0 , 501 WBI - run1 0 , 780 0 , 751 0 , 765 0 , 740 0 , 318 0 , 445 TUC - MI - run2 0 , 874 0 , 611 0 , 719 0 , 412 0 , 403 0 , 407 LITL - run1 0 , 612 0 , 550 0 , 579 0 , 412 0 , 403 0 , 407 LIRMM - run1 0 , 506 0 , 530 0 , 518 0 , 482 0 , 348 0 , 404 LIRMM - run2 0 , 505 0 , 530 0 , 517 0 , 534 0 , 275 0 , 363 LITL - run2 0 , 646 0 , 402 0 , 495 0 , 709 0 , 151 0 , 249 TUC - MI - run1 0 , 426 0 , 297 0 , 350 0 , 218 0 , 119 0 , 154 Moyenne 0 , 648 0 , 555 0 , 593 0 , 505 0 , 311 0 , 366 Médiane 0 , 629 0 , 540 0 , 548 0 , 508 0 , 333 0 , 406 E ss a i s n o n o ﬃ c i e l s LIMSI - run2 0 , 854 0 , 881 0 , 867 0 , 630 0 , 674 0 , 651 LIMSI - run1 0 , 865 0 , 865 0 , 865 0 , 640 0 , 636 0 , 638 TUC - MI - run1 - corr . 0 , 875 0 , 614 0 , 722 0 , 748 0 , 323 0 , 452 UNIPD - run1 0 , 604 0 , 517 0 , 557 0 , 320 0 , 402 0 , 356 UNIPD - run2 0 , 488 0 , 418 0 , 451 0 , 376 0 , 265 0 , 311 6 . 4 . 3 Discussion Le développement de CIM - IND a débuté pour faire face aux diﬃcultés d’indexation des textes libres médicaux avec l’ECMT et explorer les diﬀérentes solutions permet - tant de traiter eﬃcacement les insconsistences du texte libre . En 2016 , le système a été évalué dans la tâche CLEF eHealth correspondante , uniquement sur un corpus fran - çais et a obtenu un score F1 de 0 , 6795 , ce qui était légèrement inférieur à la moyenne des résultats Cabot et al . [ 2016b ] . Ces premiers résultats ont démontré la nécessité d’apporter diverses améliorations concernant notamment le classement des candidats et le traitement des fautes d’orthographe et autres erreurs lexicales . Les résultats ob - tenus en 2017 mettant en œuvre le score WDS ont démontré ces améliorations avec une augmentation de 12 % du score F1 dans le jeu de données brutes français et une augmentation de 18 % du score F1 dans le jeu de données alignées français . En outre , cette deuxième évaluation a démontré que CIM - IND obtient des résultats satisfaisants à la fois en français et en anglais , avec des résultats supérieurs à la moyenne dans les deux langues . Cependant , certains aspects de nos résultats devraient être approfondis . Bien que CIM - IND ait obtenu des résultats satisfaisants , certaines erreurs liées à la désambiguï - sation ou aux fautes d’orthographe demeurent . En particulier , les fautes d’orthographe signiﬁcatives sur des mots qui ne font pas partie du dictionnaire d’orthographe en - 151 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES Tableau 6 . 7 – Résultats du challenge CLEF eHealth 2017 par équipe pour la tâche de codage CIM10 sur le jeu de données CDC anglais ( de Névéol et al . [ 2017 ] ) . Toutes causes Causes externes Équipe Précision Rappel F1 Précision Rappel F1 E ss a i s o ﬃ c i e l s KFU - run1 0 , 893 0 , 811 0 , 850 0 , 584 0 , 357 0 , 443 KFU - run2 0 , 891 0 , 812 0 , 850 0 , 631 0 , 325 0 , 429 TUC - MI - run1 0 , 940 0 , 725 0 , 819 0 , 426 0 , 389 0 , 407 CIM - IND 0 , 839 0 , 783 0 , 810 0 , 233 0 , 524 0 , 323 TUC - MI - run2 0 , 929 0 , 717 0 , 809 0 , 232 0 , 524 0 , 322 WBI - run1 0 , 616 0 , 606 0 , 611 0 , 880 0 , 175 0 , 291 WBI - run2 0 , 616 0 , 606 0 , 611 1 , 00 0 , 159 0 , 274 LIRMM - run1 0 , 691 0 , 514 0 , 589 0 , 168 0 , 262 0 , 205 LIRMM - run2 0 , 646 0 , 527 0 , 580 0 , 292 0 , 111 0 , 161 Unipd - run1 0 , 496 0 , 442 0 , 468 0 , 246 0 , 119 0 , 160 UNSW - run1 0 , 401 0 , 352 0 , 375 0 , 246 0 , 119 0 , 160 Unipd - run2 0 , 382 0 , 341 0 , 360 0 , 279 0 , 095 0 , 142 UNSW - run2 0 , 371 0 , 328 0 , 348 0 , 043 0 , 310 0 , 076 Mondeca - run1 format invalide format invalide Moyenne 0 , 670 0 , 582 0 , 622 0 , 405 0 , 267 0 , 261 Médiane 0 , 646 0 , 606 0 , 611 0 , 279 0 , 262 0 , 274 N o n o ﬃ c i e l LIMSI - run2 0 , 899 0 , 801 0 , 847 0 , 723 0 , 373 0 , 492 LIMSI - run1 0 , 909 0 , 765 0 , 831 0 , 837 0 , 325 0 , 469 Mondeca - run1 0 , 691 0 , 309 0 , 427 0 , 042 0 , 056 0 , 048 traîneraient un encodage phonétique incorrect , et donc une liste incorrecte de termes candidats . En anglais , les résultats pourraient être légèrement améliorés avec une ter - minologie plus complète ou un jeu d’apprentissage plus large pour couvrir certains termes manquants , en particulier les abréviations . En outre , la baisse de performance concernant les codes CIM10 liés aux causes externes devrait être étudiée et semble af - fecter toutes les séries soumises lors de la compétition . Les causes externes présentent un contexte spéciﬁque et souvent une terminologie spéciﬁque liée aux accidents , aux décès violents ou aux surdoses induites par le traitement . Ils apparaissent plus rare - ment dans les jeux d’apprentissage . En fait , seules 2 440 lignes dans le jeu de données français ( 110 869 lignes ) et 313 lignes dans le le d’apprentissage anglais ( 39 333 lignes ) semblent être liées à des causes externes ( codes CIM10 V01 à Y98 ) . Cela peut expliquer dans une certaine mesure la performance réduite . En outre , dans certains cas , les codes CIM10 associés à une ligne donnée utilisent le contexte fourni dans d’autres lignes du même certiﬁcat de décès . CIM - IND traite chaque ligne de manière indépendante et n’a pas pu annoter correctement ces lignes . Enﬁn , il faut noter que la combinaison de 152 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES méthodes statistiques à l’approche actuelle pourrait s’avérer une voie d’amélioration de ces résultats . 6 . 5 Synthèse Dans ce chapitre nous avons abordé la problématique d’indexation de textes nar - ratifs , rédigés à la main , et la prise en compte des erreurs de langage qu’ils peuvent comporter . Pour répondre à cette problématique , j’ai conçu une méthode basée sur la reconnaissance phonétique du texte et mis au point un score de similarité permet - tant de sélectionner le meilleur terme candidat . Elle permet d’identiﬁer dans un texte porteur d’erreur des termes dans une terminologie choisie . Ici , la CIM10 a été choi - sie dans le cadre de la compétition CLEF eHealth mais cette méthode est adaptable pour d’autres terminologies et doit être à court terme utilisée dans notre outil multi - terminologique ECMT . Cette méthode a été évaluée dans le cadre des éditions 2016 et 2017 CLEF eHealth avec de très bons résultats en français et en anglais . Par la suite , l’un des axes d’amélioration de cette méthode devrait se concentrer sur le traitement des abréviations . En eﬀet , là encore , les textes comme les comptes - rendus posent un déﬁ spéciﬁque . Alors que les abréviations sont usuellement déﬁnies dans des articles médicaux , elles ne le sont que très rarement dans un compte - rendu médical où elles peuvent de plus se révéler nombreuses . La résolution de ces abréviations qui peuvent s’avérer ambiguës est donc un développement futur important . 153 CHAPITRE 6 . INDEXATION DE TEXTES LIBRES 154 Chapitre 7 Conclusion et perspectives Les objectifs de cette thèse s’inscrivent ainsi dans la large problématique de re - cherche d’information dans les données issues du DPI . Les aspects abordés dans cette problématique ont été multiples : d’une part la mise en œuvre d’une recherche d’infor - mation clinomique au sein du DPI , à travers la modélisation de données hétérogènes et multidisciplinaires , l’intégration de données , informations et connaissances provenant de la biologie moléculaire et le développement d’outils d’interrogation et de visualistion et d’autre part la recherche d’information au sein de données non structurées issues du DPI à travers l’indexation de textes médicaux narratifs à l’aide de réseaux sémantiques . L’un des premiers objectifs fut le recensement et l’étude des SRI disponibles en santé . On peut retenir en particulier dans cette conclusion le projet américain i2b2 1 faisant référence dans le domaine de l’exploitation des données cliniques contenues dans les dossiers patients informatisés , ainsi que le projet dérivé tranSMART 2 dédié à la réutilisation des données omiques . Bien que partageant une partie de leur modèle de données , ces deux solutions ciblent des besoins très diﬀérents . i2b2 se concentre sur l’exploitation des données contenues dans des entrepôts de données cliniques pour la création de cohortes de patients et plus largement pour répondre à des problématiques de recherche clinique . Sa portée est donc réservée à une approche multi - patients et n’autorise pas l’exploration des données d’un patient individuel . tranSMART propose lui également une approche multi - patients et plus spéciﬁquement la fouille de données clinomique pour leur réutilisation en recherche fondamentale . Il s’inscrit ainsi pleine - ment dans une optique de recherche translationnelle . Dans la première partie de cette thèse , nous avons ainsi exploré une approche diﬀérente . L’objectif principal était ainsi la réalisation d’un système de recherche d’information intégrant données cliniques et données omiques mais également combinant à la fois une approche multi - patients , dé - diée aux problématiques de recherche clinique et de santé publique , et une approche mono - patient , plus proche de la pratique clinique . La combinaison de ces deux ap - 1 . http : / / www . i2b2 . org 2 . http : / / transmartfoundation . org 155 CHAPITRE 7 . CONCLUSION ET PERSPECTIVES proches peut être argumentée . Un système unique permet de lever plusieurs verrous : l’uniﬁcation des données médicales , cliniques , biologiques ou d’imagerie pour la trans - mission et la non - redondance des informations et la continuité des connaissances entre recherche et pratique clinique indispensable à la personnalisation des soins . Certains avantages peuvent être signalés en termes de formation nécessaire aux utilisateurs . La réalisation de ce système a fait intervenir plusieurs étapes . Tout d’abord le recensement et la formalisation des diﬀérents types de données omiques et la sélection des données pertinente à intégrer . Cette étape a abouti à la conception d’un modèle de données conceptuel générique des données omiques , étendant le modèle de données cliniques mis en œuvre dans le projet ANR TecSAN RAVEL . Ce modèle de données permet de gérer un grand nombre des types de données existants en biologie moléculaire : variants structuraux , variants du nombre de copies , variants SNP et insertions / délétions , don - nées d’expression de gènes , exons , miRNA , jonctions , transcrits et protéines , données de méthylation de l’ADN . Ce modèle a été validé par l’intégration de données issues de sources diverses et hétérogènes : le portail américain The Genome Cancer Atlas et les laboratoires de recherche en oncologie INSERM U918 et U614 . Cette partie a nécessité le développement d’outils logiciels assurant l’extraction , le traitement , l’intégration et la validation des données . Dans le cadre de ce travail , j’ai également été amenée à inté - grer de nouvelles données dans le portail terminologique HeTOP : la base de données NCBI Gene , la base de données Uniprot / Swissprot et enﬁn la base de données Online Mendelian Inheritance in Man ( OMIM ) . Ces données viennent enrichir le portail ter - minologique de données HeTOP développé dans le cadre du projet PlaIR concernant respectivement les gènes , protéines et maladies génétiques humaines . Le moteur de recherche développé dans le cadre du projet RAVEL pour les données cliniques a été adapté au modèle de données omiques aﬁn de permettre la recherche d’information à la fois dans les données cliniques et dans les données omiques . Enﬁn , une interface de visualisation des données intégrées a été développée et intégrée au prototype de Dossier Patient informatisé . Ce prototype permet la visualisation et l’interrogation des don - nées omiques intégrées ainsi que des données cliniques issues de 2 000 dossiers patients informatisés du Centre Hospitalier Universitaire de Rouen . Ce démonstrateur exploite les données intégrées dans le portail terminologique HeTOP . Dans la seconde partie de cette thèse , je me suis intéressée à l’indexation et la recherche d’information dans les documents médicaux tels que les comptes - rendus mé - dicaux . Dans ce cadre , j’ai participé en 2015 au challenge CLEF E - Health , en par - ticulier à la tâche consacrée à l’extraction d’information dans des textes cliniques . Ce challenge nous a permis d’évaluer l’outil ECMT qui permet d’indexer des textes à partir des terminologies exploitées dans le portail terminologique HeTOP . Suite à cette première évaluation , j’ai réalisé plusieurs tâches visant à optimiser l’extraction des concepts , notamment en concevant une méthode adressant la problématique de 156 CHAPITRE 7 . CONCLUSION ET PERSPECTIVES duplication des concepts propre à l’indexation multi - terminologique . Parallèlement , plusieurs corpus ont été analysés en collaboration avec la Cité des Sciences et l’Uni - versité Nice Sophia Antipolis . Ce travail a été évalué dans le cadre de l’édition 2016 du challenge CLEF eHealth . Ce challenge a amené le développement d’une méthode d’indexation spéciﬁque à la classiﬁcation internationale des maladies appliquée au trai - tement de certiﬁcats de décès . Cet outil implémente le suivi des diﬀérentes versions d’une terminologie ainsi que le traitement des erreurs du langage naturel . L’évalua - tion de l’indexation multi - terminologique d’un corpus d’articles biomédicaux issus de la base de données bibliographique LiSSa 3 a été réalisée pour évaluer l’apport des dif - férentes terminologies disponibles en français dans le portail terminologique HeTOP . Cette évaluation s’est déroulée en deux phases , la première nous permettant d’étudier quantitativement l’apport de chaque terminologie dans l’indexation des documents , la seconde nous permettant d’évaluer qualitativement l’indexation multi - terminologique et l’apport de chaque ressource . Cette évaluation a fait appel à un gold standard an - noté manuellement par l’équipe et au développement de l’outil d’annotation nécessaire à cette tâche . Par la suite , plusieurs perspectives peuvent être envisagées pour approfondir le tra - vail eﬀectué pendant cette thèse . L’intégration de données cliniques et omiques et leur exploitation au sein d’un système de recherche d’information au sein du DPI sont ap - pelées à évoluer , d’une part à travers les progrès accomplis dans les disciplines liées à la biologie moléculaire , tant d’un point de vue des connaissances fondamentales ac - quises que des progrès techniques , et d’autre part à travers l’évolution des ressources nécessaires à leur exploitation . Les problématiques de disponibilité , conﬁdentialité et sécurité des données restent aujourd’hui un frein important à l’accomplissement de cet objectif et à la mise en production et la diﬀusion d’un tel système au sein des sys - tèmes d’information hospitaliers . La problématique de recherche d’information dans les données non structurées telles que les comptes - rendus médicaux contenus dans les DPI peut être approfondie tant dans les possibilités oﬀertes par la linguistique et le traitement automatisé du langage que par les approches statistiques . Les compétitions organisées régulièrement dans ce domaine ont montré une grande diversité dans les approches possibles , mais aussi une certaine maturité des outils proposés . De tels ou - tils oﬀrent des perspectives intéressantes dans de multiples applications à la recherche d’information . En particulier , les travaux de cette thèse autour de l’ECMT ont permis une valorisation de cet outil auprès de la société Alicante en l’intégrant dans sa suite logicielle et l’installant dans un hôpîtal lillois , nous a permis un retour sur de nou - veaux cas d’usage qui devraient permettre la poursuite des travaux sur la recherche d’information et l’extraction de concepts . 3 . http : / / www . lissa . fr 157 CHAPITRE 7 . CONCLUSION ET PERSPECTIVES 158 Liste des publications Cabot , C . , L . F . Soualmia et S . J . Darmoni . 2017 ( submitted ) , «SIBM at CLEF eHealth Evaluation Lab 2017 : Multilingual Information Extraction with CIM - IND» , dans CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2017 ) . URL http : / / ceur - ws . org / Vol - 1609 / 16090047 . pdf . Cabot , C . , L . F . Soualmia , J . Grosjean , N . Griffon et S . J . Darmoni . 2017 , «Evaluation of the Terminology Coverage in the French Corpus LiSSa» , Studies in health technology and informatics , vol . 235 , p . 126 – 130 . Cabot , C . , L . F . Soualmia , B . Dahamna et S . J . Darmoni . 2016a , «SIBM at CLEF eHealth Evaluation Lab 2016 : Extracting Concepts in French Medical Texts with ECMT and CIMIND» , dans CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2016 ) , vol . 1609 , p . 47 – 60 . URL http : / / ceur - ws . org / Vol - 1609 / 16090047 . pdf . Cabot , C . , R . Lelong , J . Grosjean , L . F . Soualmia et S . J . Darmoni . 2016b , «Retrieving Clinical and Omic Data from Electronic Health Records» , Studies in health technology and informatics , vol . 221 , p . 115 – 115 . Cabot , C . , L . F . Soualmia , B . Dahamna et S . J . Darmoni . 2016c , «ECMT : In - dexation multi - terminologique de documents biomédicaux» , dans 1er Forum Franco - Québécois d’Innovation en Santé , Polytechnique Montréal . Cabot , C . , L . F . Soualmia et S . J . Darmoni . 2016d , «Recherche d’information dans les données cliniques et omiques au sein du Dossier Patient Informatisé» , Jour - née Plateforme d’Indexation 2 . 0 . Lelong , R . , C . Cabot , L . F . Soualmia et S . J . Darmoni . 2016 , «Semantic Search Engine to Query into Electronic Health Records with a Multiple - Layer Query Lan - guage» , dans MEDIR workshop . URL http : / / medir2016 . imag . fr / data / MEDIR _ 2016 _ paper _ 8 . pdf . Cabot , C . , L . F . Soualmia et S . J . Darmoni . 2015a , «Intégration de données cliniques et omiques pour la recherche d’information dans le Dossier Patient Infor - 159 LISTE DES PUBLICATIONS matisé» , dans Actes des 26èmes Journées Francophones d’Ingénierie des Connais - sances ( IC ) , associées à la Plateforme de l’Association Française pour l’Intelligence Artiﬁcielle , Rennes , France , p . 183 – 193 . URL https : / / hal . archives - ouvertes . fr / hal - 01179292 / . Cabot , C . , L . F . Soualmia , J . Grosjean , R . Lelong et S . J . Dar - moni . 2015b , «Integrating and Retrieving Clinical and Omic Data in Elec - tronic Health Records» , dans 7th International Workshop on Knowledge Re - presentation for Health Care ( KRH4C ) and 8th International Workshop on Process - oriented Information Systems in Healthcare ( ProHealth ) , p . 154 – 159 . URL https : / / www . researchgate . net / profile / Lina _ Soualmia / publication / 280066101 _ Integrating _ and _ Retrieving _ Clinical _ and _ Omic _ Data _ in _ Electronic _ Health _ Records / links / 55a7a47408aeceb8cad65695 . pdf . Soualmia , L . F . , C . Cabot , B . Dahamna et S . J . Darmoni . 2015 , «SIBM at CLEF e - Health Evaluation Lab 2015» , dans CEUR - WS Working Notes of the Confe - rence and Labs of the Evaluation Forum ( CLEF 2015 ) , vol . 1391 . Lelong , R . , C . Cabot , T . Merabti , J . Grosjean , N . Griffon , B . Dahamna , P . Massari et S . Darmoni . 2015 , «Information Retrieval in Electronic Health Re - cords Using a Multiple Layer Query Language» , dans Journées Recherche en Image - rie et Technologies pour la Santé 2015 , pp 128 - 129 . Cabot , C . , L . F . Soualmia , J . Grosjean , R . Lelong et S . J . Darmoni . 2015 , «Integrating and retrieving clinical and omic data in electronic health records» , 15 ans du Master de Bioinformatique de l’Université de Rouen . Cabot , C . , J . Grosjean , R . Lelong , A . Lefebvre , T . Lecroq , L . F . Soualmia et S . J . Darmoni . 2014a , «Omic Data Modelling for Information Retrieval» , dans IWBBIO , Citeseer , p . 415 – 424 . Cabot , C . , M . Mary , C . Saad , A . Renaux , A . Bertrand , A . Velt , A . Le - febvre , C . Bérard , N . Vergne et H . Dauchel . 2014b , «GC - VC / DGE : a user - friendly web application for Going over Concordance across results from NGS bioinformatics analytic pipelines» , dans ECCB 2014 , Strasbourg , France . Cabot , C . , M . Mary , C . Saad , A . Renaux , A . Bertrand , A . Velt , A . Le - febvre , C . Bérard , N . Vergne et H . Dauchel . 2014c , «GC - VC / DGE : a user - friendly web application for Going over Concordance across results from NGS bioinformatics analytic pipelines» , 3ème Journée Scientiﬁque de l’IRIB . Coutant , S . , C . Cabot , A . Lefebvre , M . Léonard , E . Prieur - Gaston , D . Campion , T . Lecroq et H . Dauchel . 2012 , «EVA : Exome Variation Analy - 160 LISTE DES PUBLICATIONS zer , an eﬃcient and versatile tool for ﬁltering strategies in medical genomics» , BMC bioinformatics , vol . 13 , n o Suppl 14 , p . S9 . 161 LISTE DES PUBLICATIONS 162 Annexe A Annexes A . 1 Figures annexes I ANNEXE A . ANNEXES Figure A . 1 – Le modèle physique du système d’information CISMeF II ANNEXE A . ANNEXES A . 2 Tableaux annexes Tableau A . 1 – Les principales terminologies et ontologies ( n = 32 ) disponibles dans le portail HeTOP ( nombre de termes en français total n = 653 , 392 ) Terminologie Version Termes en français % des termes en français ADICAP NA 9 , 189 1 , 34 % ATC 2014 6 , 005 0 , 88 % BNCI 2011 786 0 , 11 % CCAM v43 10 , 138 1 , 48 % CIF 2001 1 , 496 0 , 22 % ICD - O 1 , 595 0 , 23 % CISMeF 2016 129 0 , 02 % ICPC - 2 5 . 0 745 0 , 11 % CLADIMED v10 5 , 136 0 , 75 % DSM - IV IV 590 0 , 09 % FMA 2009 16 , 429 2 , 39 % Genes & Proteins 2017 612 0 , 09 % GO 2011 600 0 , 09 % HPO 2014 11 , 136 1 , 62 % HRDO 2013 10 , 689 1 , 56 % CIM10 10 19 , 615 2 , 86 % ICNP 2011 2 , 814 0 , 41 % LOINC 2 . 38 58 , 587 8 , 54 % LPP 236A 5 , 072 0 , 74 % MedDRA v18 . 1 68 , 139 9 , 93 % Medline Plus 2009 848 0 , 12 % MeSH 2016 94 , 106 13 , 71 % NCIt 2012 60 , 924 8 , 88 % OMIM 2015 7 , 276 1 , 06 % PASCAL 2015 6 , 022 0 , 88 % PHARMA 2016 35 , 327 5 , 15 % Q - Codes 2 . 4 188 0 , 03 % III ANNEXE A . ANNEXES SNOMED CT 2010 137 , 878 20 , 09 % SNOMED Int . 3 . 5 106 , 266 15 , 49 % SYNODOS 2015 382 0 , 06 % TSP 4 7 , 145 1 , 04 % UCUM 1 . 9 346 0 , 05 % IV Bibliographie Abacha , A . B . et P . Zweigenbaum . 2011 , «Medical entity recognition : a compa - rison of semantic and statistical methods» , dans Proceedings of BioNLP Workshop , Association for Computational Linguistics , p . 56 – 64 . 41 Abiteboul , S . , P . Buneman et D . Suciu . 2000 , Data on the Web : from relations to semistructured data and XML , Morgan Kaufmann . 65 Achard , F . , G . Vaysseix et E . Barillot . 2001 , «XML , bioinformatics and data integration . » , Bioinformatics , vol . 17 , n o 2 , p . 115 – 125 . 65 Aggarwal , N . , K . Asooja et P . Buitelaar . 2012 , «DERI & UPM : pushing corpus based relatedness to similarity : shared task system description» , dans Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume Pro - ceedings of the main conference and the shared task , and Volume Proceedings of the Sixth International Workshop on Semantic Evaluation , Association for Computatio - nal Linguistics , p . 643 – 647 . 137 Archer , N . , U . Fevrier - Thomas , C . Lokker , K . A . McKibbon et S . E . Straus . 2011 , «Personal health records : a scoping review» , Journal of the American Medical Informatics Association , vol . 18 , n o 4 , p . 515 – 522 . xv , 28 , 29 , 30 Aronson , A . R . et F . - M . Lang . 2010 , «An overview of MetaMap : historical perspec - tive and recent advances» , Journal of the American Medical Informatics Association , vol . 17 , n o 3 , p . 229 – 236 . 42 , 44 Aronson , S . J . et H . L . Rehm . 2015 , «Building the foundation for genomics in precision medicine . » , Nature , vol . 526 , n o 7573 , p . 336 – 342 . 32 Ball , M . J . , N . C . Smith et R . S . Bakalar . 2007 , «Personal health records : empowering consumers» , J Healthc Inf Manag , vol . 21 , p . 77 . 26 Bär , D . , C . Biemann , I . Gurevych et T . Zesch . 2012 , «UKP : computing se - mantic textual similarity by combining multiple content similarity measures» , dans V BIBLIOGRAPHIE Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume Proceedings of the main conference and the shared task , and Volume Procee - dings of the Sixth International Workshop on Semantic Evaluation , Association for Computational Linguistics , p . 435 – 440 . 138 Barrón - Cedeño , A . , P . Rosso , E . Agirre et G . Labaka . 2010 , «Plagiarism de - tection across distant language pairs» , dans Proceedings of the 23rd International Conference on Computational Linguistics , Association for Computational Linguis - tics , p . 37 – 45 . 134 Belkin , N . J . et W . B . Croft . 1992 , «Information ﬁltering and information retrie - val : two sides of the same coin ? » , Communications of the ACM , vol . 35 , n o 12 , p . 29 – 38 . 50 Bender , O . , F . J . Och et H . Ney . 2003 , «Maximum entropy models for named entity recognition» , dans Proceedings of the seventh conference on Natural language learning at HLT - NAACL 2003 , Association for Computational Linguistics , Morristown , NJ , USA , p . 148 – 151 . 42 Bernstam , E . V . , J . W . Smith et T . R . Johnson . 2010 , «What is biomedical informatics ? » , Journal of biomedical informatics , vol . 43 , n o 1 , p . 104 – 110 . 4 Bikel , D . M . , R . Schwartz et R . M . Weischedel . 1999 , «An Algorithm that Learns What’s in a Name» , Machine learning , vol . 34 , n o 1 - 3 , p . 211 – 231 . 42 Bird , S . , E . Klein et E . Loper . 2009 , Natural Language Processing with Python , O’Reilly Media , Inc . 145 Bodenreider , O . 2008 , «Biomedical ontologies in action : role in knowledge mana - gement , data integration and decision support . » , Yearbook of medical informatics , p . 67 – 79 . 65 Bodenreider , O . et R . Stevens . 2006 , «Bio - ontologies : current trends and future directions» , Brieﬁngs in bioinformatics , vol . 7 , n o 3 , p . 256 – 274 . 104 Bodnari , A . , L . Deleger et T . Lavergne . 2013 , «A Supervised Named - Entity Extraction System for Medical Text . » , CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2014 ) , vol . 1179 . 40 Boogerd , E . A . , T . Arts , L . J . Engelen et T . H . van de Belt . 2015 , «“What Is eHealth” : Time for An Update ? » , JMIR Research Protocols , vol . 4 , n o 1 , p . e29 . 12 VI BIBLIOGRAPHIE Bosworth , A . 2007 , «Putting Health into the patient’s Hands - Consumerism and Health care» , dans The American Medical Informatics Association AMIA Spring Congress Informatics Across the Spectrum , Opening Plenary Session and Keynote Address , Orlando , Florida . 12 Brown , S . H . , C . S . Husser , D . Wahner - Roedler , S . Bailey , L . Nugent , K . Porter , B . A . Bauer et P . L . Elkin . 2007 , «Using SNOMED CT as a refe - rence terminology to cross map two highly pre - coordinated classiﬁcation systems . » , Studies in health technology and informatics , vol . 129 , n o Pt 1 , p . 636 – 639 . 104 de Bruijn , B . , C . Cherry , S . Kiritchenko , J . Martin et X . Zhu . 2011 , «Machine - learned solutions for three stages of clinical information extraction : the state of the art at i2b2 2010 . » , Journal of the American Medical Informatics Asso - ciation : JAMIA , vol . 18 , n o 5 , p . 557 – 562 . 43 Buckley , C . et E . M . Voorhees . 2004 , «Retrieval evaluation with incomplete infor - mation» , dans Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 25 – 32 . 59 Burgun , A . , P . Denier , O . Bodenreider , G . Botti , D . Delamarre et al . . 1997 , «A Web terminology server using UMLS for the description of medical procedures . » , Journal of the American Medical Informatics Association , vol . 4 , n o 5 , p . 356 – 363 . 104 Buscaldi , D . , R . Tournier , N . Aussenac - Gilles et J . Mothe . 2012 , «IRIT : textual similarity combining conceptual similarity with an n - gram comparison me - thod» , dans Proceedings of the First Joint Conference on Lexical and Computatio - nal Semantics - Volume Proceedings of the main conference and the shared task , and Volume Proceedings of the Sixth International Workshop on Semantic Evaluation , Association for Computational Linguistics , p . 552 – 556 . 138 Bush , V . 1945 , «As We May Think» , The Atlantic Monthly . 48 Cabot , C . , J . Grosjean , R . Lelong , A . Lefebvre , T . Lecroq , L . F . Soual - mia et S . J . Darmoni . 2014 , «Omic Data Modelling for Information Retrieval» , dans Proceedings of the 2nd International Work - Conference on Bioinformatics and Biomedical Engineering , IWBBIO , p . 415 – 424 . 74 Cabot , C . , R . Lelong , J . Grosjean , L . F . Soualmia et S . J . Darmoni . 2016a , «Retrieving Clinical and Omic Data from Electronic Health Records» , Stud Health Technol Inform , vol . 221 , p . 115 . 101 , 107 Cabot , C . , L . F . Soualmia , B . Dahamna et S . J . Darmoni . 2016b , «SIBM at CLEF eHealth Evaluation Lab 2016 : Extracting Concepts in French Medical Texts VII BIBLIOGRAPHIE with ECMT and CIMIND» , dans CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum CLEF , p . 47 – 60 . 105 , 112 , 147 , 151 Cabot , C . , L . F . Soualmia et S . J . Darmoni . 2015 , «Intégration de données cli - niques et omiques pour la recherche d’information dans le Dossier Patient Informa - tisé» , dans Actes des 26èmes Journées Francophones d’Ingénierie des Connaissances ( IC ) , associées à la Plateforme de l’Association Française pour l’Intelligence Artiﬁ - cielle , Rennes , France , p . 183 – 193 . 101 Cabot , C . , L . F . Soualmia et S . J . Darmoni . 2017 , «SIBM at CLEF eHealth Evaluation Lab 2017 : Multilingual Information Extraction with CIM - IND» , dans CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2017 ) . 147 Cafarella , M . J . , A . Halevy et J . Madhavan . 2011 , «Structured data on the web» , Communications of the ACM , vol . 54 , n o 2 , p . 72 – 79 . 65 California HealthCare Foundation . 2010 , «Consumers and health information technology : a national survey» , URL http : / / www . chcf . org / publications / 2010 / 04 / consumers - and - health - information - technology - a - national - survey . 29 Callan , J . , J . Allan , C . L . A . Clarke , S . Dumais , D . A . Evans , M . Sander - son et C . Zhai . 2007 , «Meeting of the MINDS : an information retrieval research agenda» , ACM SIGIR Forum , vol . 41 , n o 2 , p . 25 – 34 . 48 Callan , J . P . , W . B . Croft et J . Broglio . 1995 , «TREC and TIPSTER expe - riments with inquery» , Information Processing & Management , vol . 31 , n o 3 , p . 327 – 343 . 55 Callan , J . P . , W . B . Croft et S . M . Harding . 1992 , «The INQUERY Retrieval System» , dans Proceedings of the 3rd international conference on database and expert systems applications , édité par Springer , Springer , Vienna , p . 78 – 83 . 55 Cerami , E . , J . Gao , U . Dogrusoz , B . E . Gross , S . O . Sumer et al . . 2012 , «The cBio Cancer Genomics Portal : An Open Platform for Exploring Multidimensional Cancer Genomics Data» , Cancer Discovery , vol . 2 , n o 5 , p . 401 – 404 . 34 Chapman , W . W . , W . Bridewell , P . Hanbury , G . F . Cooper et B . G . Bu - chanan . 2001 , «A simple algorithm for identifying negated ﬁndings and diseases in discharge summaries . » , Journal of biomedical informatics , vol . 34 , n o 5 , p . 301 – 310 . 43 Chebil , W . , L . F . Soualmia , M . N . Omri et S . J . Darmoni . 2015 , «Biomedical Concepts Extraction based on Possibilistic Network and Vector Space Model» , dans Conference on Artiﬁcial Intelligence in Medicine in Europe , Springer , p . 227 – 231 . 45 VIII BIBLIOGRAPHIE Chebil , W . , L . F . Soualmia , M . N . Omri et S . J . Darmoni . 2016 , «Indexing biomedical documents with a possibilistic network» , JASIST , vol . 67 , n o 4 , p . 928 – 941 . 45 Chen , H . , S . S . Fuller , C . Friedman et W . Hersh . 2006 , Medical Informatics : Knowledge Management and Data Mining in Biomedicine , Springer Science & Busi - ness Media . 22 Cilibrasi , R . L . et P . M . B . Vitanyi . 2007 , «The Google Similarity Distance» , IEEE Transactions on Knowledge and Data Engineering , vol . 19 , n o 3 , p . 370 – 383 . 137 Clark , C . , J . Aberdeen , M . Coarr , D . Tresner - Kirsch , B . Wellner , A . Yeh et L . Hirschman . 2011 , «MITRE system for clinical assertion status classiﬁcation . » , Journal of the American Medical Informatics Association : JAMIA , vol . 18 , n o 5 , p . 563 – 567 . 43 Cleverdon , C . 1967 , «The Cranﬁeld Tests on Index Language Devices» , Aslib pro - ceedings , vol . 19 , n o 6 , p . 173 – 194 . 48 Cleverdon , C . W . 1991 , «The signiﬁcance of the Cranﬁeld tests on index languages» , dans Proceedings of the 14th annual international ACM SIGIR conference on Re - search and development in information retrieval , ACM , p . 3 – 12 . 58 , 59 Cogley , J . , N . Stokes et J . Carthy . 2013 , «Medical Disorder Recognition with Structural Support Vector Machines . » , CLEF ( Working Notes ) . 41 Coletti , M . H . et H . L . Bleich . 2001 , «Medical Subject Headings Used to Search the Biomedical Literature» , Journal of the American Medical Informatics Associa - tion , vol . 8 , n o 4 , p . 317 – 323 . 18 Collier , N . , C . Nobata et J . - i . Tsujii . 2000 , «Extracting the names of genes and gene products with a hidden Markov model» , dans Proceedings of the 18th conference on Computational linguistics , Association for Computational Linguistics , Morris - town , NJ , USA , p . 201 – 207 . 40 Collins , M . et N . Duffy . 2001 , «New ranking algorithms for parsing and tagging» , dans Proceedings of the 40th annual meeting on association for computational lin - guistics , Association for Computational Linguistics , p . 263 – 270 . 43 Côté , R . , F . Reisinger , L . Martens , H . Barsnes , J . A . Vizcaino et H . Herm - jakob . 2010 , «The Ontology Lookup Service : bigger and better . » , Nucleic Acids Research , vol . 38 , p . W155 – 60 . 105 IX BIBLIOGRAPHIE Croft , W . B . et D . J . Harper . 1979 , «Using Probabilistic Models of Document Retrieval Without Relevance Information» , Journal of documentation , vol . 35 , n o 4 , p . 285 – 295 . 48 Dai , M . 2008 , «An Eﬃcient Solution for Mapping Free Text to Ontology Terms» , dans AMIA Summit on Translational Bioinformatics . 44 Darmoni , S . J . , S . Pereira , A . Névéol , P . Massari , B . Dahamna , C . Letord , G . Kerdelhué , J . Piot , A . Derville et B . Thirion . 2008 , «French Infobutton : an academic and business perspective . » , dans AMIA Annual Symposium Proceedings , p . 920 . 105 Darmoni , S . J . , B . Thirion , J . P . Leroy , M . Douyère , B . Lacoste et al . . 2001 , «Doc’CISMEF : a search tool based on " encapsulated " MeSH thesaurus» , Studies in health technology and informatics , vol . 84 , n o Pt 1 , p . 314 – 318 . 4 , 15 , 106 De Moor , G . , M . Sundgren , D . Kalra , A . Schmidt , M . Dugas et al . . 2015 , «Using electronic health records for clinical research : the case of the EHR4CR project . » , Journal of biomedical informatics , vol . 53 , p . 162 – 173 . 33 Dehghan , A . 2013 , Boundary adjustment of events in clinical named entity recogni - tion , vol . abs / 1308 . 1004 , CoRR . 41 Deléger , L . et C . Grouin . 2012 , «Detecting negation of medical problems in French clinical notes» , dans Proceedings of the 2nd ACM SIGHIT International Health In - formatics Symposium , ACM , New York , New York , USA , p . 697 – 702 . 43 Derczynski , L . , D . Maynard , G . Rizzo , M . van Erp , G . Gorrell , R . Troncy , J . Petrak et K . Bontcheva . 2015 , «Analysis of named entity recognition and linking for tweets» , Information Processing & Management , vol . 51 , n o 2 , p . 32 – 49 . 132 Detmer , D . , M . Bloomrosen , B . Raymond et P . Tang . 2008 , «Integrated Per - sonal Health Records : Transformative Tools for Consumer - Centric Care» , BMC Medical Informatics and Decision Making , vol . 8 , n o 1 , p . 45 . 29 Dexter , P . R . , S . Perkins , J . M . Overhage , K . Maharry , R . B . Kohler et C . J . McDonald . 2009 , «A Computerized Reminder System to Increase the Use of Preventive Care for Hospitalized Patients» , N Engl J Med , vol . 345 , n o 13 , p . 965 – 970 . 29 Dhombres , F . , R . Winnenburg , J . T . Case et O . Bodenreider . 2015 , «Ex - tending the coverage of phenotypes in SNOMED CT through post - coordination . » , Studies in health technology and informatics , vol . 216 , p . 795 – 799 . 25 X BIBLIOGRAPHIE Diaz , F . et D . Metzler . 2006 , «Improving the estimation of relevance models using large external corpora» , dans Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 154 – 161 . 47 Dice , L . R . 1945 , «Measures of the Amount of Ecologic Association Between Species» , Ecology , vol . 26 , n o 3 , p . 297 – 302 . 135 Dirieh Dibad , A . - D . 2012 , Recherche d’Information Multi Terminologique au sein d’un Dossier Patient Informatisé , thèse de doctorat , Université de Rouen . 66 Doan , S . et H . Xu . 2010 , «Recognizing Medication related Entities in Hospital Di - scharge Summaries using Support Vector Machine . » , Proceedings of COLING . Inter - national Conference on Computational Linguistics , vol . 2010 , p . 259 – 266 . 41 Douyère , M . , L . F . Soualmia , A . Neveol , A . Rogozan , B . Dahamna , J . - P . Leroy , B . Thirion et S . J . Darmoni . 2004 , «Enhancing the MeSH thesaurus to retrieve French online health resources in a quality - controlled gateway» , Health Information and Libraries Journal , vol . 21 , n o 4 , p . 253 – 261 . 123 Dubois , D . et H . Prade . 1998 , «Possibility theory : qualitative and quantitative aspects» , dans Quantiﬁed representation of uncertainty and imprecision , Springer , p . 169 – 226 . 56 Dupuch , M . , F . Segond , A . Bittar , L . Dini et L . F . Soualmia . 2013 , «Separate the grain from the chaﬀ : make the best use of language and knowledge technolo - gies to model textual medical data extracted from electronic health records» , dans Proceedings of the 6th Language Technology Conference . 107 Egozi , O . , S . Markovitch et E . Gabrilovich . 2011 , «Concept - Based Information Retrieval Using Explicit Semantic Analysis» , ACM Transactions on Information Sys - tems ( TOIS ) , vol . 29 , n o 2 , p . 8 – 34 . 56 Ephraim , Y . et L . R . Rabiner . 1990 , «On the relations between modeling ap - proaches for speech recognition» , IEEE Transactions on Information Theory , vol . 36 , p . 372 – 380 . 55 Fagan , L . M . 2003 , Medical Informatics : Computer Applications in Health Care and Biomedicine , Health Informatics . 13 , 15 , 17 Fan , J . , N . Sood et Y . Huang . 2013 , «Disorder concept identiﬁcation from clini - cal notes an experience with the ShARe / CLEF 2013 challenge» , dans CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2016 ) . 42 XI BIBLIOGRAPHIE Fernald , G . H . , E . Capriotti , R . Daneshjou , K . J . Karczewski et R . B . Alt - man . 2011 , «Bioinformatics challenges for personalized medicine» , Bioinformatics , vol . 27 , n o 13 , p . 1741 – 1748 . 31 Finkel , J . , S . Dingare , C . D . Manning , M . Nissim , B . Alex et C . Grover . 2005 , «Exploring the boundaries : gene and protein identiﬁcation in biomedical text . » , BMC bioinformatics , vol . 6 Suppl 1 , n o Suppl 1 , p . S5 . 40 Finkel , J . , S . Dingare , H . Nguyen , M . Nissim , C . Manning et G . Sinclair . 2004 , «Exploiting context for biomedical entity recognition : from syntax to the web» , , p . 88 – 91 . 40 Fox , E . A . , S . Betrabet , M . Koushik et W . C . Lee . 1992 , «Extended Boolean Models . » , . 50 Fox , E . A . et S . Sharan . 1986 , « A Comparison of Two Methods For Soft Boolean Operator Interpretation In Information Retrieval» , cahier de recherche . 50 Frakes , W . B . et R . Baeza - Yates . 1992 , Information Retrieval : Data Structures and Algorithms , Prentice - Hall , Inc . 49 Frixione , M . et A . Lieto . 2012 , «Representing concepts in formal ontologies . Com - positionality vs . typicality eﬀects» , Logic and Logical Philosophy , vol . 21 , n o 4 , p . 391 – 414 . 24 Gabrilovich , E . et S . Markovitch . 2007 , «Computing semantic relatedness using wikipedia - based explicit semantic analysis . » , IJcAI , vol . 7 , p . 1606 – 1611 . 136 Gaines , B . R . et T . L . Kohout . 1975 , «Possible automata» , dans Proc . Int . Symp . Multiple - Valued logics , Citeseer , Bloomington , IN , p . 183 – 196 . 55 Gambarte , M . L . , A . L . Osornio , M . Martinez , G . Reynoso , D . Luna et F . G . B . de Quiros . 2007 , «A practical approach to advanced terminology services in health information systems . » , Studies in health technology and informatics , vol . 129 , n o Pt 1 , p . 621 – 625 . 104 Ganslandt , T . , S . Mate , K . Helbing , U . Sax et H . U . Prokosch . 2011 , «Un - locking Data for Clinical Research – The German i2b2 Experience» , Applied clinical informatics , vol . 2 , n o 1 , p . 116 . 93 Garcelon , N . , R . Salomon et A . Burgun . 2014 , «Enrichissement sémantique associé à la détection de la négation et des antécédents familiaux dans un entrepôt de données hospitalier . » , dans JFIM , p . 83 – 93 . 43 XII BIBLIOGRAPHIE Gindl , S . , K . Kaiser et S . Miksch . 2008 , «Syntactical negation detection in clinical practice guidelines . » , Studies in health technology and informatics , vol . 136 , p . 187 – 192 . 43 Goeuriot , L . , L . Kelly , H . Suominen , L . Hanlen , A . Neveol , C . Grouin , J . Palotti et G . Zuccon . 2015 , «Overview of the CLEF eHealth Evaluation Lab 2015» , dans Experimental IR Meets Multilinguality , Multimodality , and Interaction , Springer , Cham , Cham , p . 429 – 443 . 107 Goeuriot , L . , L . Kelly , H . Suominen , A . Neveol , A . Robert , E . Kanoulas , R . Spijker , J . Palotti et G . Zuccon . 2017 , «CLEF 2017 eHealth Evaluation Lab Overview» , dans CLEF - 8th Conference and Labs of the Evaluation Forum , Lecture Notes in Computer Science LNCS , Springer . 147 Griffon , N . 2013 , Modélisation , création et évaluation de ﬂux de terminologies et de terminologies d’interface : application à la production d’examens complémentaires de biologie et d’imagerie médicale . , thèse de doctorat , Université de Rouen . 27 Griffon , N . , M . Schuers et S . J . Darmoni . 2016 , «LiSSa : An alternative in French to browse health scientiﬁc literature ? » , Presse medicale ( Paris , France : 1983 ) , vol . 45 , n o 11 , p . 955 – 956 . 15 Griffon , N . , M . Schuers , L . F . Soualmia , J . Grosjean , G . Kerdelhué , I . Kergourlay , B . Dahamna et S . J . Darmoni . 2014 , «A Search Engine to Access PubMed Monolingual Subsets : Proof of Concept and Evaluation in French» , Journal of Medical Internet Research , vol . 16 , n o 12 , p . e271 . 120 Grosjean , J . 2014 , Modélisation , réalisation et évaluation d’un portail multi - terminologique multi - discipline , multi - lingue ( 3M ) dans le cadre de la Plateforme d’Indexation Régionale ( PlaIR ) , thèse de doctorat , Université de Rouen . 2 , 80 , 105 Grosjean , J . , T . Merabti , B . Dahamna , I . Kergourlay , B . Thirion , L . F . Soualmia et S . J . Darmoni . 2011 , «Health multi - terminology portal : a semantic added - value for patient safety . » , Studies in health technology and informatics , vol . 166 , p . 129 – 138 . 4 , 105 Grouin , C . 2014 , «Biomedical entity extraction using machine - learning based ap - proaches» , dans Proceedings of LREC 2014 , p . 611 . 40 Gruber , T . R . 1993 , «A translation approach to portable ontology speciﬁcations» , Knowledge acquisition , vol . 5 , p . 199 – 220 . 18 Gruber , T . R . 1995 , «Toward principles for the design of ontologies used for know - ledge sharing ? » , International journal of human - computer studies , vol . 43 , n o 5 - 6 , p . 907 – 928 . 18 XIII BIBLIOGRAPHIE Halamka , J . D . , K . D . Mandl et P . C . Tang . 2008 , «Early Experiences with Personal Health Records» , Journal of the American Medical Informatics Association , vol . 15 , n o 1 , p . 1 – 7 . 28 Hall , P . A . V . et G . R . Dowling . 1980 , «Approximate String Matching» , ACM computing surveys ( CSUR ) , vol . 12 , n o 4 , p . 381 – 402 . 134 Hamid , J . S . , P . Hu , N . M . Roslin , V . Ling , C . M . T . Greenwood et J . Beyene . 2009 , «Data integration in genetics and genomics : methods and chal - lenges . » , Human genomics and proteomics : HGP , vol . 2009 , n o 2 , p . 1 – 13 . 64 Hamosh , A . , A . F . Scott , J . S . Amberger , C . A . Bocchini et V . A . McKusick . 2005 , «Online Mendelian Inheritance in Man ( OMIM ) , a knowledgebase of human genes and genetic disorders . » , Nucleic Acids Research , vol . 33 , n o Database issue , p . D514 – 7 . 69 Harkema , H . , J . N . Dowling , T . Thornblade et W . W . Chapman . 2009 , «ConText : an algorithm for determining negation , experiencer , and temporal status from clinical reports . » , Journal of biomedical informatics , vol . 42 , n o 5 , p . 839 – 851 . 43 Hendler , J . 2014 , «Data Integration for Heterogenous Datasets . » , Big data , vol . 2 , n o 4 , p . 205 – 215 . 65 Hersh , W . 2008 , Information Retrieval : A Health and Biomedical Perspective , Health Informatics , Springer Science & Business Media , New York , NY . 12 , 13 , 14 Hettne , K . M . , E . M . van Mulligen , M . J . Schuemie , B . J . Schijvenaars et J . A . Kors . 2010 , «Rewriting and suppressing UMLS terms for improved biomedical term identiﬁcation» , Journal of biomedical semantics , vol . 1 , n o 1 , p . 5 . 45 Hiemstra , D . et W . Kraaij . 1998 , «Twenty - One in ad - hoc and CLIR» , dans Pro - ceedings of TREC - 7 , Proc . of TREC - 7 , p . 500 – 540 . 55 Hoerbst , A . et E . Ammenwerth . 2010 , «Electronic health records» , Methods of Information in Medicine , vol . 49 , p . 320 – 336 . 27 Hood , D . 2004 , «Caverphone revisited» , Technical Paper CTP150804 . 140 Humphreys , B . L . , D . A . Lindberg , H . M . Schoolman et G . O . Barnett . 1998 , «The Uniﬁed Medical Language System : an informatics research collaboration . » , Journal of the American Medical Informatics Association , vol . 5 , n o 1 , p . 1 – 11 . 20 Iakovidis , I . 1998 , «Towards personal health record : current situation , obstacles and trends in implementation of electronic healthcare record in Europe» , International Journal of Medical Informatics , vol . 52 , n o 1 , p . 105 – 115 . 27 XIV BIBLIOGRAPHIE Islam , A . et D . Inkpen . 2008 , «Semantic text similarity using corpus - based word similarity and string similarity» , ACM Transactions on Knowledge Discovery from Data ( TKDD ) , vol . 2 , n o 2 , p . 10 – 25 . 137 Iyer , S . V . , R . Harpaz , P . LePendu , A . Bauer - Mehren et N . H . Shah . 2014 , «Mining clinical text for signals of adverse drug - drug interactions . » , Journal of the American Medical Informatics Association : JAMIA , vol . 21 , n o 2 , p . 353 – 362 . 33 Jaccard , P . 1901 , «Etude comparative de la distribution ﬂorale dans une portion des Alpes et des Jura» , Bull Soc Vaudoise Sci Nat , vol . 37 , p . 547 – 579 . 135 Jamoulle , M . 2013 , «Using the International Classiﬁcation for Primary Care ( ICPC ) and the Core Content Classiﬁcation for General Practice ( 3CGP ) to classify confe - rence abstracts» , Rev Port Med Geral Fam , vol . 29 , n o 5 , p . 66 – 67 . 123 Jaro , M . A . 1995 , «Probabilistic linkage of large public health data ﬁles» , Statistics in medicine , vol . 14 , n o 5 - 7 , p . 491 – 498 . 134 Jaro , M . A . 2012 , «Advances in Record - Linkage Methodology as Applied to Matching the 1985 Census of Tampa , Florida» , Journal of the American Statistical Association , vol . 84 , n o 406 , p . 414 – 420 . 134 Jensen , F . V . et F . B . Jensen . 2001 , Bayesian Networks and Decision Graphs , Springer . 54 Jimeno , A . , E . Jimenez - Ruiz , V . Lee , S . Gaudan , R . Berlanga et D . Rebholz - Schuhmann . 2008 , «Assessment of disease named entity recognition on a corpus of annotated sentences . » , BMC bioinformatics , vol . 9 Suppl 3 , n o Suppl 3 , p . S3 . 42 Joachims , T . , L . Granka , B . Pan , H . Hembrooke et G . Gay . 2005 , «Accura - tely interpreting clickthrough data as implicit feedback» , dans Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 154 – 161 . 53 Johnson , E . K . , S . Broder - Fingert , P . Tanpowpong , J . Bickel , J . R . Light - dale et C . P . Nelson . 2014 , «Use of the i2b2 research query tool to conduct a matched case – control clinical research study : advantages , disadvantages and metho - dological considerations» , BMC medical research methodology , vol . 14 , n o 1 , p . 16 . 34 Jones , K . S . 1972 , «A Statistical Interpretation of Term Speciﬁcity and Its Applica - tion in Retrieval» , Journal of documentation , vol . 28 , n o 1 , p . 11 – 21 . 48 Jonquet , C . , N . Shah et M . Musen . 2009 , «The Open Biomedical Annotator» , dans Summit on translational bioinformatics , p . 56 – 60 . 45 XV BIBLIOGRAPHIE Jydstrup , R . A . et M . J . Gross . 1966 , «Cost of information handling in hospitals . » , Health services research , vol . 1 , n o 3 , p . 235 – 271 . 12 Karlsson , D . , M . Nyström et R . Cornet . 2014 , «Does SNOMED CT post - coordination scale ? » , Studies in health technology and informatics , vol . 205 , p . 1048 – 1052 . 25 Kelly , L . , L . Goeuriot , H . Suominen , A . Neveol , J . Palotti et G . Zuccon . 2016 , «Overview of the CLEF eHealth Evaluation Lab 2016» , dans Experimental IR Meets Multilinguality , Multimodality , and Interaction , Springer , Cham , p . 255 – 266 . 61 , 107 , 147 Kleinsorge , R . et J . Willis . 2008 , «Uniﬁed Medical Language System ( UMLS ) Basics» , National Library of Medicine . xiii , 20 , 21 , 22 Kohane , I . S . 2011 , «Using electronic health records to drive discovery in disease genomics» , Nature Reviews Genetics , vol . 12 , n o 6 , p . 417 – 428 . 33 Komatsoulis , G . A . , D . B . Warzel , F . W . Hartel , K . Shanbhag , R . Chilu - kuri et al . . 2008 , «caCORE version 3 : Implementation of a model driven , service - oriented architecture for semantic interoperability . » , Journal of biomedical informa - tics , vol . 41 , n o 1 , p . 106 – 123 . 104 Koopman , B . , P . D . Bruza , L . Sitbon et M . Lawley . 2011 , «Towards semantic search and inference in electronic medical records : an approach using concept - based information retrieval» , The Australasian medical journal , vol . 5 , p . 482 . 56 Korkontzelos , I . , D . Piliouras , A . W . Dowsey et S . Ananiadou . 2015 , «Boos - ting drug named entity recognition using an aggregate classiﬁer . » , Artiﬁcial Intelli - gence in Medicine , vol . 65 , n o 2 , p . 145 – 153 . 41 Krause , E . F . 1973 , «Taxicab geometry» , The Mathematics Teacher . 134 Lafferty , J . , A . McCallum et F . Pereira . 2001 , «Conditional random ﬁelds : Probabilistic models for segmenting and labeling sequence data» , dans ICML ’01 Proceedings of the Eighteenth International Conference on Machine Learning , p . 282 – 289 . 40 Lai , K . H . , M . Topaz , F . R . Goss et L . Zhou . 2015 , «Automated misspelling detec - tion and correction in clinical free - text records . » , Journal of biomedical informatics , vol . 55 , p . 188 – 195 . 132 Lancaster , F . W . W . A . J . 1993 , Information Retrieval Today . Revised , Retitled , and Expanded Edition . , Information Resources Press . 49 XVI BIBLIOGRAPHIE Landauer , T . K . et S . T . Dumais . 1997 , «A solution to Plato’s problem : The latent semantic analysis theory of acquisition , induction , and representation of knowledge . » , Psychological review , vol . 104 , n o 2 , p . 211 – 240 . 136 Lander , E . S . , L . M . Linton , B . Birren , C . Nusbaum , M . C . Zody et al . . 2001 , «Initial sequencing and analysis of the human genome . » , Nature , vol . 409 , n o 6822 , p . 860 – 921 . 16 Lelong , R . , C . Cabot et L . F . Soualmia . 2016 , «Semantic Search Engine to Query into Electronic Health Records with a Multiple - Layer Query Language» , dans Proceedings of the 2nd SIGIR workshop on Medical Information Retrieval ( MedIR ) . 88 , 107 Levenshtein , V . I . 1966 , «Binary codes capable of correcting deletions , insertions , and reversals» , dans Soviet physics doklady , p . 707 – 710 . 134 Li , Y . , D . McLean , Z . A . Bandar , J . D . O’shea et K . Crockett . 2006 , «Sen - tence similarity based on semantic nets and corpus statistics» , IEEE Transactions on Knowledge and Data Engineering , vol . 18 , n o 8 , p . 1138 – 1150 . 137 Lin , J . et W . J . Wilbur . 2007 , «PubMed related articles : a probabilistic topic - based model for content similarity» , BMC bioinformatics , vol . 8 , n o 1 , p . 423 . 44 Lindberg , D . A . , B . L . Humphreys et A . T . McCray . 1993 , «The Uniﬁed Medical Language System . » , Methods of Information in Medicine , vol . 32 , n o 4 , p . 281 – 291 . 20 Liu , Z . et W . W . Chu . 2007 , «Knowledge - based query expansion to support scenario - speciﬁc retrieval of medical free text» , Information Retrieval , vol . 10 , n o 2 , p . 173 – 202 . 56 , 57 Lowe , H . J . , T . A . Ferris , P . M . Hernandez et S . C . Weber . 2009 , «STRIDE – An integrated standards - based translational research informatics platform . » , dans AMIA Annual Symposium Proceedings , American Medical Informatics Association , p . 391 – 395 . 33 Luhn , H . P . 1957 , «A statistical approach to mechanized encoding and searching of literary information» , IBM Journal of Research and Development . 48 Lund , K . et C . Burgess . 1996 , «Producing high - dimensional semantic spaces from lexical co - occurrence» , Behavior Research Methods , Instruments , & Computers , vol . 28 , n o 2 , p . 203 – 208 . 135 XVII BIBLIOGRAPHIE Lund , K . , C . Burgess et R . A . Atchley . 1995 , «Semantic and associative priming in high - dimensional semantic space» , dans Proceedings of the 17th annual conference of the Cognitive Science Society , p . 660 – 665 . 135 Lyman , P . et H . R . Varian . 2003 , «How Much Information» , URL http : / / groups . ischool . berkeley . edu / archive / how - much - info - 2003 / . 12 Ma , Y . , J . - j . Kim , B . Bigot et T . M . Khan . 2016 , «Feature - enriched word embed - dings for named entity recognition in open - domain conversations» , dans 2016 IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , IEEE , p . 6055 – 6059 . 132 Madhavan , S . , Y . Gusev , M . Harris , D . M . Tanenbaum , R . Gauba et al . . 2011 , «G - DOC : A Systems Medicine Platform for Personalized Oncology» , Neoplasia , vol . 13 , n o 9 , p . 771 – 783 . 35 Maglott , D . , J . Ostell , K . D . Pruitt et T . Tatusova . 2007 , «Entrez Gene : gene - centered information at NCBI» , Nucleic Acids Research , vol . 35 , p . D26 – D31 . 68 Mamlin , J . J . et D . H . Baker . 1973 , «Combined time - motion and work sampling study in a general medicine clinic . » , Medical care , vol . 11 , n o 5 , p . 449 – 456 . 12 Manning , C . D . , P . Raghavan et H . Schütze . 2008 , Introduction to information retrieval , Cambridge University Press . 58 Marcus , R . S . 1991 , «Computer and Human Understanding in Intelligent Retrieval Assistance . » , Proceedings of the ASIS Annual Meeting , vol . 28 , p . 49 – 59 . 49 Maron , M . E . et J . L . Kuhns . 1960 , «On Relevance , Probabilistic Indexing and Information Retrieval» , Journal of the ACM ( JACM ) , vol . 7 , n o 3 , p . 216 – 244 . 53 Mary , M . 2017 , Interopérabilité sémantique pour les données de diagnostic in vitro : représentation des connaissances et alignement , thèse de doctorat , Université de Rouen Normandie . 27 Matveeva , I . , G . A . Levow , A . Farahat et C . Royer . 2005 , Generalized latent semantic analysis for term representation , Proc . of RANLP . 136 McCallum , A . et W . Li . 2003 , «Early results for named entity recognition with conditional random ﬁelds , feature induction and web - enhanced lexicons» , dans Pro - ceedings of the seventh conference on Natural language learning at HLT - NAACL 2003 , Association for Computational Linguistics , p . 188 – 191 . 42 XVIII BIBLIOGRAPHIE McConnell , P . , R . C . Dash , R . Chilukuri , R . Pietrobon , K . Johnson , R . Annechiarico et A . J . Cuticchia . 2008 , «The cancer translational research informatics platform» , BMC Medical Informatics and Decision Making , vol . 8 , n o 1 , p . 60 . 34 McDonald , R . et F . Pereira . 2005 , «Identifying gene and protein mentions in text using conditional random ﬁelds . » , BMC bioinformatics , vol . 6 Suppl 1 , n o Suppl 1 , p . S6 . 40 Meij , E . , D . Trieschnigg , M . de Rijke et W . Kraaij . 2010 , «Conceptual lan - guage models for domain - speciﬁc retrieval» , Information Processing & Management , vol . 46 , n o 4 , p . 448 – 469 . 57 Menasalvas , E . et C . Gonzalo - Martin . 2016 , «Challenges of Medical Text and Image Processing : Machine Learning Approaches» , dans Machine Learning for Health Informatics , Springer International Publishing , Cham , p . 221 – 242 . 132 Miyoshi , N . S . B . , D . G . Pinheiro , W . A . Silva Jr et J . C . Felipe . 2013 , «Computational framework to support integration of biomolecular and clinical data within a translational approach» , BMC bioinformatics , vol . 14 , p . 180 . 33 Mooers , C . S . 1950 , «Coding , Information Retrieval , and the Rapid Selector» , Ame - rican Documentation . 48 Mork , J . , A . Aronson et D . Demner Fushman . 2017 , «12 years on - Is the NLM medical text indexer still useful and relevant ? » , Journal of biomedical semantics , vol . 8 , n o 1 , p . 8 . 42 , 44 , 132 Mork , J . G . , D . Demner - Fushman et S . Schmidt . 2014 , «Recent Enhancements to the NLM Medical Text Indexer . » , CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2014 ) , p . 1328 – 1336 . 44 Moschitti , A . 2004 , «A study on convolution kernels for shallow semantic parsing» , dans the 42nd Annual Meeting , Association for Computational Linguistics , Morris - town , NJ , USA , p . 335 – es . 43 Murphy , S . N . , P . Avillach , R . Bellazzi , L . Phillips , M . Gabetta , A . Eran , M . T . McDuffie et I . S . Kohane . 2017 , «Combining clinical and genomics queries using i2b2 - Three methods . » , PloS one , vol . 12 , n o 4 , p . e0172 187 . 33 , 95 Murphy , S . N . , M . E . Mendis , D . A . Berkowitz , I . Kohane et H . C . Chueh . 2006 , «Integration of clinical and genetic data in the i2b2 architecture . » , dans AMIA Annual Symposium Proceedings , American Medical Informatics Association , p . 1040 . 33 , 94 XIX BIBLIOGRAPHIE Musen , M . A . , N . F . Noy , N . H . Shah , P . L . Whetzel , C . G . Chute , M . - A . Story et B . Smith . 2012 , «The National Center for Biomedical Ontology» , Journal of the American Medical Informatics Association , vol . 19 , n o 2 , p . 190 – 195 . 45 Nadeau , D . et S . Sekine . 2007 , «A survey of named entity recognition and classiﬁ - cation» , Lingvisticae Investigationes , vol . 30 , n o 1 , p . 3 – 26 . 42 Navas , H . , A . L . Osornio , A . Baum , A . Gomez , D . Luna et F . G . B . de Quiros . 2007 , «Creation and evaluation of a terminology server for the interactive coding of discharge summaries . » , Studies in health technology and informatics , vol . 129 , n o Pt 1 , p . 650 – 654 . 104 Needleman , S . B . et C . D . Wunsch . 1970 , «A general method applicable to the search for similarities in the amino acid sequence of two proteins» , Journal of mole - cular biology , vol . 48 , n o 3 , p . 443 – 453 . 134 Névéol , A . , R . N . Anderson , K . B . Cohen et C . Grouin . 2017 , «CLEF eHealth 2017 Multilingual Information Extraction task overview : ICD10 coding of death certiﬁcates in English and French» , CLEF 2017 Evaluation Forum . xvi , 147 , 149 , 150 , 151 , 152 Névéol , A . , L . Goeuriot et L . Kelly . 2016 , «Clinical information extraction at the CLEF eHealth evaluation lab 2016» , dans Proceedings of the CLEF 2015 Evaluation Labs and Workshop : Online Working Notes . xvi , 46 , 107 , 147 , 148 Névéol , A . , J . Grosjean , S . J . Darmoni et P . Zweigenbaum . 2014 , «Language Resources for French in the Biomedical Domain . » , LREC . 120 Neveol , A . , C . Grouin , J . Leixa , S . Rosset et P . Zweigenbaum . 2014 , «The Quaero French medical corpus : A ressource for medical entity recognition and nor - malization» , dans Bio text - mining workshop ( BioTextM 2014 ) . 113 Névéol , A . , C . Grouin et X . Tannier . 2015 , «CLEF eHealth Evaluation Lab 2015 Task 1b : Clinical Named Entity Recognition . » , CLEF 2015 Working Notes . 107 Ng , S . B . , K . J . Buckingham , C . Lee , A . W . Bigham , H . K . Tabor et al . . 2010 , «Exome sequencing identiﬁes the cause of a mendelian disorder . » , Nature genetics , vol . 42 , n o 1 , p . 30 – 35 . 31 Ohno - Machado , L . , V . Bafna , A . A . Boxwala , B . E . Chapman , W . W . Chap - man et al . . 2012 , «iDASH : integrating data for analysis , anonymization , and sha - ring» , Journal of the American Medical Informatics Association , vol . 19 , n o 2 , p . 196 – 201 . 35 XX BIBLIOGRAPHIE Patel , C . , J . Cimino , J . Dolby , A . Fokoue , A . Kalyanpur , A . Kershenbaum , L . Ma , E . Schonberg et K . Srinivas . 2007 , «Matching Patient Records to Cli - nical Trials Using Ontologies» , dans The Semantic Web , Springer Berlin Heidelberg , p . 816 – 829 . 11 Patrick , J . , Y . Wang et P . Budd . 2006 , «Automatic mapping clinical notes to medical terminologies» , Australasian language technology workshop . 43 Pavillon , G . et F . Laurent . 2003 , «Certiﬁcation et codiﬁcation des causes médicales de décès» , Bulletin épidémiologique hebdomadaire . 141 Pereira , S . , A . Névéol , G . Kerdelhué et E . Serrot . 2008 , «Using multi - terminology indexing for the assignment of MeSH descriptors to health resources in a French online catalogue . » , dans AMIA Annual Symposium Proceedings , p . 586 . 45 , 105 Peterson , J . L . 1980 , «Computer programs for detecting and correcting spelling errors» , Communications of the ACM , vol . 23 , n o 12 , p . 676 – 687 . 134 Philips , L . 2000 , «The double metaphone search algorithm» , C / C + + Users Journal , vol . 18 , n o 6 , p . 38 – 43 . 140 , 145 Ponte , J . M . et W . B . Croft . 1998 , «A language modeling approach to information retrieval» , dans Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 275 – 281 . 55 Potthast , M . , B . Stein et M . Anderka . 2008 , «A Wikipedia - based multilingual retrieval model» , Advances in Information Retrieval , p . 522 – 530 . 136 Proux , D . , F . Rechenmann , L . Julliard , V . Pillet et B . Jacq . 1998 , «Detec - ting Gene Symbols and Names in Biological Texts : A First Step toward Pertinent Information Extraction . » , Genome informatics . Workshop on Genome Informatics , vol . 9 , p . 72 – 80 . 41 Ratinov , L . et D . Roth . 2009 , «Design challenges and misconceptions in named entity recognition» , dans Proceedings of the Thirteenth Conference on Computational Natural Language Learning , p . 147 – 155 . 42 Ravindran , D . et S . Gauch . 2004 , «Exploiting hierarchical relationships in concep - tual search» , dans Proceedings of the thirteenth ACM international conference on Information and knowledge management , ACM , p . 238 – 239 . 56 Rebholz - Schuhmann , D . , H . Kirsch , S . Gaudan , M . Arregui et G . Nena - dic . 2006 , «Annotation and disambiguation of semantic types in biomedical text : a XXI BIBLIOGRAPHIE cascaded approach to named entity recognition» , dans Proceedings of the th Work - shop on NLP and XML Multi - Dimensional Markup in Natural Language Processing , Association for Computational Linguistics , p . 11 – 18 . 42 Robertson , S . E . 1977 , «The Probability Ranking Principle in IR» , Journal of do - cumentation , vol . 33 , n o 4 , p . 294 – 304 . 46 , 52 Robertson , S . E . et K . S . Jones . 1976 , «Relevance weighting of search terms» , Journal of the Association for Information Science and Technology , vol . 27 , n o 3 , p . 129 – 146 . 48 , 53 Robertson , S . E . et S . Walker . 1994 , Some simple eﬀective approximations to the 2 - Poisson model for probabilistic weighted retrieval , Springer - Verlag New York , Inc . 53 Rubin , D . D . L . , S . E . Lewis , C . J . Mungall , S . Misra , M . Westerfield et al . . 2006 , «National Center for Biomedical Ontology : Advancing Biomedicine through Structured Organization of Scientiﬁc Knowledge» , www . liebertpub . com , vol . 10 , n o 2 , p . 185 – 198 . 105 Rubin , D . L . , N . H . Shah et N . F . Noy . 2008 , «Biomedical ontologies : a functional perspective» , Brieﬁngs in bioinformatics , vol . 9 , n o 1 , p . 75 – 90 . 104 Sachs , W . M . 1976 , «An approach to associative retrieval through the theory of fuzzy sets» , Journal of the Association for Information Science and Technology , vol . 27 , n o 2 , p . 85 – 87 . 50 Saha , S . K . , S . Sarkar et P . Mitra . 2009 , «Feature selection techniques for maxi - mum entropy based biomedical named entity recognition» , Journal of biomedical informatics , vol . 42 , n o 5 , p . 905 – 911 . 40 , 41 Salton , G . 1968 , Automatic information organization and retrieval , McGraw - Hill . 46 Salton , G . 1971 , The SMART Retrieval System—Experiments in Automatic Docu - ment Processing , Prentice - Hall , Inc . 48 , 50 , 52 Salton , G . , E . A . Fox et H . Wu . 1983 , «Extended Boolean information retrieval» , Communications of the ACM , vol . 26 , n o 11 , p . 1022 – 1036 . 50 Salton , G . et C . S . Yang . 1973 , «On The Speciﬁcation Of Term Values In Automatic Indexing» , Journal of documentation , vol . 29 , n o 4 , p . 351 – 372 . 52 Sarkar , I . N . , A . J . Butte , Y . A . Lussier , P . Tarczy - Hornoch et L . Ohno - Machado . 2011 , «Translational bioinformatics : linking knowledge across biological and clinical realms . » , Journal of the American Medical Informatics Association : JAMIA , vol . 18 , n o 4 , p . 354 – 357 . 32 XXII BIBLIOGRAPHIE Scheufele , E . , D . Aronzon , R . Coopersmith , M . T . McDuffie , M . Kapoor , C . A . Uhrich , J . E . Avitabile , J . Liu , D . Housman et M . B . Palchuk . 2014 , «tranSMART : An Open Source Knowledge Management and High Content Data Analytics Platform . » , AMIA Joint Summits on Translational Science proceedings . AMIA Joint Summits on Translational Science , vol . 2014 , p . 96 – 101 . 95 Settles , B . 2004 , «Biomedical named entity recognition using conditional random ﬁelds and rich feature sets» , dans Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications , Association for Computational Linguistics , p . 104 – 107 . 40 Shah , N . H . , N . Bhatia , C . Jonquet , D . Rubin , A . P . Chiang et M . A . Mu - sen . 2009a , «Comparison of concept recognizers for building the Open Biomedical Annotator» , BMC bioinformatics , vol . 10 , n o 9 , p . S14 . 44 , 45 Shah , N . H . , C . Jonquet , A . P . Chiang , A . J . Butte , R . Chen et M . A . Musen . 2009b , «Ontology - driven indexing of public datasets for translational bio - informatics» , BMC bioinformatics , vol . 10 , n o 2 , p . S1 . 44 Sherry , S . T . , M . H . Ward , M . Kholodov , J . Baker , L . Phan , E . M . Smi - gielski et K . Sirotkin . 2001 , «dbSNP : the NCBI database of genetic variation» , Nucleic Acids Research , vol . 29 , n o 1 , p . 308 – 311 . 91 Shimokawa , K . , K . Mogushi , S . Shoji , A . Hiraishi , K . Ido , H . Mizushima et H . Tanaka . 2010 , «iCOD : an integrated clinical omics database based on the systems - pathology view of disease» , BMC Genomics , vol . 11 , n o 4 , p . S19 . 35 Sidorov , G . , F . Velasquez , E . Stamatatos , A . Gelbukh et L . Chanona - Hernández . 2012 , «Syntactic Dependency - Based N - grams as Classiﬁcation Fea - tures» , dans Advances in Computational Intelligence , Springer , Berlin , Heidelberg , p . 1 – 11 . 43 Siklósi , B . , A . Novák et G . Prószéky . 2016 , «Context - aware correction of spelling errors in Hungarian medical documents» , Computer Speech & Language , vol . 35 , p . 219 – 233 . 132 Smith , T . F . et M . S . Waterman . 1981 , «Identiﬁcation of common molecular sub - sequences» , Journal of molecular biology , vol . 147 , n o 1 , p . 195 – 197 . 134 Sohn , S . , S . Wu et C . G . Chute . 2012 , «Dependency Parser - based Negation De - tection in Clinical Narratives . » , AMIA Joint Summits on Translational Science pro - ceedings . AMIA Joint Summits on Translational Science , vol . 2012 , p . 1 – 8 . 43 XXIII BIBLIOGRAPHIE Soualmia , L . F . , C . Cabot , B . Dahamna et S . J . Darmoni . 2015 , «SIBM at CLEF e - Health Evaluation Lab 2015» , dans Proceedings of the CLEF 2015 Evalua - tion Labs and Workshop : Online Working Notes . 105 , 112 Soualmia , L . F . et S . J . Darmoni . 2005 , «Combining diﬀerent standards and dif - ferent approaches for health information retrieval in a quality - controlled gateway» , International Journal of Medical Informatics , vol . 74 , n o 2 - 4 , p . 141 – 150 . 104 Spackman , K . 2008 , «SNOMED clinical terms basics» , cahier de recherche . 24 Sparck Jones , K . , S . Walker et S . E . Robertson . 2000 , «A probabilistic model of information retrieval : development and comparative experiments» , Information Processing & Management , vol . 36 , n o 6 , p . 809 – 840 . 54 Spasić , I . , B . Zhao , C . B . Jones et K . Button . 2015 , «KneeTex : an ontology - driven system for information extraction from MRI reports . » , Journal of biomedical semantics , vol . 6 , n o 1 , p . 34 . 42 Stein , L . D . 2003 , «Integrating biological databases . » , Nature Reviews Genetics , vol . 4 , n o 5 , p . 337 – 345 . 65 Stokes , N . , Y . Li , L . Cavedon et J . Zobel . 2009 , «Exploring criteria for successful query expansion in the genomic domain» , Information Retrieval , vol . 12 , n o 1 , p . 17 – 50 . 57 Stolyar , A . , W . B . Lober , D . R . Drozd et J . Sibley . 2005 , «Feasibility of data exchange with a Patient - centered Health Record . » , dans AMIA Annual Symposium Proceedings , American Medical Informatics Association , p . 1123 . 28 Sun , W . , A . Rumshisky et Ö . Uzuner . 2013 , «Evaluating temporal relations in clinical text : 2012 i2b2 Challenge» , Journal of the American Medical Informatics Association , vol . 20 , n o 5 , p . 806 – 813 . 62 Szalma , S . , V . Koka , T . Khasanova et E . D . Perakslis . 2010 , «Eﬀective know - ledge management in translational medicine» , Journal of Translational Medicine , vol . 8 , n o 1 , p . 68 . 36 , 95 Takai - Igarashi , T . , R . Akasaka , K . Suzuki , T . Furukawa , M . Yoshida et al . . 2011 , «On experiences of i2b2 ( Informatics for integrating biology and the bedside ) database with Japanese clinical patients’ data» , Bioinformation , vol . 6 , n o 2 , p . 86 – 90 . 93 , 95 Tan , A . , B . Tripp et D . Daley . 2011 , «BRISK—research - oriented storage kit for biology - related data» , Bioinformatics , vol . 27 , n o 17 , p . 2422 – 2425 . 34 XXIV BIBLIOGRAPHIE Tang , B . , H . Cao , X . Wang , Q . Chen et H . Xu . 2014 , «Evaluating word repre - sentation features in biomedical named entity recognition tasks . » , BioMed research international , vol . 2014 , n o 2 , p . 240 403 – 6 . 40 Tang , L . , S . Rajan et V . K . Narayanan . 2009 , «Large scale multi - label classi - ﬁcation via metalabeler» , dans Proceedings of the 18th international conference on World wide web , ACM , p . 211 – 220 . 44 Tang , P . C . , J . S . Ash , D . W . Bates , J . M . Overhage et D . Z . Sands . 2006 , «Personal Health Records : Deﬁnitions , Beneﬁts , and Strategies for Overcoming Bar - riers to Adoption» , Journal of the American Medical Informatics Association , vol . 13 , n o 2 , p . 121 – 126 . 29 The Gene Ontology Consortium . 2008 , «The Gene Ontology project in 2008» , Nucleic Acids Research , vol . 36 , p . D440 – D444 . 68 Thiessard , F . , F . Mougin , G . Diallo , V . Jouhet , S . Cossin et al . . 2012 , «RA - VEL : retrieval and visualization in ELectronic health records . » , Studies in health technology and informatics , vol . 180 , p . 194 – 198 . 3 , 107 Tkachenko , M . et A . Simanovsky . 2012 , «Named entity recognition : Exploring features . » , dans KONVENS , p . 118 – 127 . 42 Trieschnigg , D . 2010 , Proof of concept : concept - based biomedical information retrie - val , thèse de doctorat , Centre for Telematics and Information Technology , University of Twente , Enschede , The Netherlands . 56 , 57 Trieschnigg , D . , D . Hiemstra , F . de Jong et W . Kraaij . 2010 , «A cross - lingual framework for monolingual biomedical information retrieval» , dans Proceedings of the 19th ACM international conference , ACM , p . 169 – 178 . 56 Tsoumakas , G . , M . Laliotis , N . Markantonatos et I . Vlahavas . 2013 , «Large - scale semantic indexing of biomedical publications at bioasq» , dans BioASQ Work - shop . 44 Turchin , A . , N . S . Kolatkar , R . W . Grant , E . C . Makhni , M . L . Pen - dergrass et J . S . Einbinder . 2006 , «Using Regular Expressions to Abstract Blood Pressure and Treatment Intensiﬁcation Information from the Text of Phy - sician Notes» , Journal of the American Medical Informatics Association , vol . 13 , n o 6 , p . 691 – 695 . 66 Turtle , H . et W . B . Croft . 1989 , «Inference networks for document retrieval» , dans Proceedings of the 13th annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 1 – 24 . 54 XXV BIBLIOGRAPHIE Turtle , H . et W . B . Croft . 1991 , «Evaluation of an inference network - based re - trieval model» , ACM Transactions on Information Systems ( TOIS ) , vol . 9 , n o 3 , p . 187 – 222 . 48 , 54 UniProt Consortium . 2013 , «Update on activities at the Universal Protein Resource ( UniProt ) in 2013 . » , Nucleic Acids Research , vol . 41 , n o Database issue , p . D43 – 7 . 68 Uzuner , Ö . , B . R . South , S . Shen et S . L . DuVall . 2011 , «2010 i2b2 / VA challenge on concepts , assertions , and relations in clinical text . » , Journal of the American Medical Informatics Association : JAMIA , vol . 18 , n o 5 , p . 552 – 556 . 43 Valentine , P . M . 2012 , A Social History of Books and Libraries from Cuneiform to Bytes , Scarecrow Press . 47 Van Mulligen , E . , Z . Afzal , S . A . Akhondi , D . Vo et J . A . Kors . 2016 , «Erasmus MC at CLEF eHealth 2016 : Concept recognition and coding in French texts» , dans CEUR - WS Working Notes of the Conference and Labs of the Evaluation Forum ( CLEF 2016 ) . 46 Van Rijsbergen , C . J . 1986 , «A non - classical logic for information retrieval» , The computer journal , vol . 29 , n o 6 , p . 481 – 485 . 46 Vanopstal , K . , R . Vander Stichele , G . Laureys et J . Buysschaert . 2011 , «Vocabularies and retrieval tools in biomedicine : disentangling the terminological knot . » , Journal of medical systems , vol . 35 , n o 4 , p . 527 – 543 . 18 Viangteeravat , T . , I . M . Brooks , E . J . Smith , N . Furlotte , S . Vuthipada - don , R . Reynolds et C . S . McDonald . 2009 , «Slim - prim : a biomedical informa - tics database to promote translational research . » , Perspectives in health information management , vol . 6 , p . 6 . 33 Voorhees , E . M . 1994 , «Query Expansion using Lexical - Semantic Relations» , dans SIGIR ’94 , Springer London , p . 61 – 69 . 56 Voorhees , E . M . et D . K . Harman . 2005 , «TREC : Experiment and evaluation in information retrieval» , Cambridge : MIT press . 60 Voorhees , E . M . et W . R . Hersh . 2012 , «Overview of the TREC 2012 Medical Records Track . » , NIST Special Publication . 58 , 61 Waegemann , C . P . 2002 , Status report 2002 : electronic health records , Medical Re - cords Institute , Chicago , Illinois . 26 XXVI BIBLIOGRAPHIE Waegemann , C . P . 2003 , «Ehr vs . cpr vs . emr» , Healthcare Informatics online , vol . 1 , p . 1 – 4 . 26 Wang , Y . et J . Patrick . 2009 , «Cascading classiﬁers for named entity recognition in clinical notes» , dans Proceedings of the workshop on biomedical information ex - traction , Association for Computational Linguistics , p . 42 – 49 . 41 Webster , F . 2014 , Theories of the Information Society , Routledge . 11 Wehling , M . 2015 , Principles of Translational Science in Medicine , Academic Press . 5 Wilbur , W . J . , G . F . Hazard , G . Divita , J . G . Mork , A . R . Aronson et A . C . Browne . 1999 , «Analysis of biomedical text for chemical names : a comparison of three methods . » , dans Proceedings of the AMIA Symposium , American Medical Informatics Association , p . 176 – 180 . 41 Winkler , W . E . 1990 , «String Comparator Metrics and Enhanced Decision Rules in the Fellegi - Sunter Model of Record Linkage . » , dans Proceedings of the Section on Survey Research , p . 354 – 359 . 134 Yamamoto , K . , T . Kudo , A . Konagaya et Y . Matsumoto . 2003 , «Protein name tagging for biomedical annotation in text» , dans the ACL 2003 workshop , Association for Computational Linguistics , p . 65 – 72 . 41 Zadeh , L . , C . Negoita et H . Zimmermann . 1978 , «Fuzzy sets as a basis for a theory of possibility» , Fuzzy sets and systems , vol . 1 , n o 3 - 28 , p . 61 – 72 . 55 Zerhouni , E . 2003 , «The NIH Roadmap» , Science , vol . 302 , n o 5642 , p . 63 – 72 . 5 Zhong , M . et X . Huang . 2006 , «Concept - based biomedical text retrieval» , dans Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 723 – 724 . 56 Zhou , G . et J . Su . 2001 , «Named entity recognition using an HMM - based chunk tagger» , dans Proceedings of the 40th annual meeting on association for computatio - nal linguistics , Association for Computational Linguistics , Morristown , NJ , USA , p . 473 – 480 . 42 Zhou , W . , T . Y . Clement , V . I . Torvik et N . R . Smalheiser . 2006 , «A Concept - Based Framework for Passage Retrieval at Genomics . » , NIST Special Publication , vol . 8 . 57 Zhou , W . , C . Yu , N . Smalheiser , V . Torvik et J . Hong . 2007 , «Knowledge - intensive conceptual retrieval and passage extraction of biomedical literature» , dans XXVII BIBLIOGRAPHIE Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval , ACM , p . 655 – 662 . 56 , 57 Zhu , D . et B . Carterette . 2012 , «Combining multi - level evidence for medical record retrieval» , dans Proceedings of the 2012 international workshop on Smart health and wellbeing , ACM , p . 49 – 56 . 47 XXVIII Recherche d ' information clinomique dans le Dossier Patient Informatisé : modélisation , implantation et évaluation Les objectifs de cette thèse s ' inscrivent dans la large problématique de recherche d ' information dans les données issues du Dossier Patient Informatisé ( DPI ) . Les aspects abordés dans cette problématique sont multiples : d ' une part la mise en œuvre d ' une recherche d ' information clinomique au sein du DPI et d ' autre part la recherche d ' information au sein de données non structurées issues du DPI . Dans un premier temps , l ' un des objectifs de cette thèse est d ' intégrer au sein du DPI des informations dépassant le cadre de la médecine pour intégrer des données , informations et connaissances provenant de la biologie moléculaire ; les données omiques , issues de la génomique , protéomique ou encore métabolomique . L ' intégration de ce type de données permet d ' améliorer les systèmes d ' information en santé , leur interopérabilité ainsi que le traitement et l ' exploitation des données à des fins cliniques . Un enjeu important est d ' assurer l ' intégration de données hétérogènes , grâce à des recherches sur les modèles conceptuels de données , sur les ontologies et serveurs terminologiques et sur les entrepôts sémantiques . L ' intégration de ces données et leur interprétation selon un même modèle de données conceptuel sont un verrou important . Enfin , il est important d ' intégrer recherche clinique et recherche fondamentale afin d ' assurer une continuité des connaissances entre recherche et pratique clinique et afin d ' appréhender la problématique de personnalisation des soins . Cette thèse aboutit ainsi à la conception et au développement d ' un modèle générique des données omiques exploité dans une application prototype de recherche et visualisation dans les données omiques et cliniques d ' un échantillon de 2 000 patients . Le second objectif de ma thèse est l ' indexation multi terminologique de documents médicaux à travers le développement de l ' outil Extracteur de Concepts Multi - Terminologique ( ECMT ) . Il exploite les terminologies intégrées au portail terminologique Health Terminology / Ontology Portal ( HeTOP ) pour identifier des concepts dans des documents non structurés . Ainsi , à partir d ' un document rédigé par un humain , et donc porteur potentiellement d ' erreurs de frappe , d ' orthographe ou de grammaire , l ' enjeu est d ' identifier des concepts et ainsi structurer l ' information contenue dans le document . Pour la recherche d ' information médicale , l ' indexation présente un intérêt incontournable pour la recherche dans les documents non structurés , comme les comptes - rendus de séjour ou d ' examens . Cette thèse propose plusieurs méthodes et leur évaluation suivant deux axes : l ' indexation de textes médicaux à l ' aide de plusieurs terminologies et le traitement du langage naturel dans les textes médicaux narratifs . Mots - clés : Recherche d ' information , Dossiers patients informatisés , Modélisation , Extraction d ' information , Vocabulaires contrôlés , Traitement du langage naturel Clinomics Information Retrieval in Electronic Health Records : Modelling , Implantation and Evaluation The aim of this thesis is part of the broad issue of information retrieval in Electronic Health Records ( EHRs ) . The aspects tackled in this topic are numerous : on the one hand clinomics information retrieval within EHRs and secondly information retrieval within unstructured data from EHRs . As a first step , one of the objectives is to integrate in EHRs information beyond the scope of medicine to integrate data , information and knowledge from molecular biology ; omic data from genomics , proteomics or metabolomics . The integration of this type of data improves health information systems , their interoperability and the processing and exploitation of data for clinical purposes . An important challenge is to ensure the integration of heterogeneous data , through research on conceptual models of data , ontology and terminology servers , and semantic data warehouses . The integration of this data and their interpretation into a conceptual data model is an important challenge . Finally , it is important to integrate clinical research and fundamental research in order to ensure continuity of knowledge between research and clinical practice and to understand personalized medicine challenges . This thesis thus leads to the design and development of a generic model of omics data exploited in a prototype application for information retrieval and visualization in omic and clinical data within a sample of 2 , 000 patients . The second objective of this thesis is the multi - terminological indexing of medical documents through the development of the Extracting Concepts with Multiple Terminologies tool ( ECMT ) . It uses terminologies embedded in the Health Terminology / Ontology Portal ( HeTOP ) to identify concepts in unstructured documents . From a document written by a human , and therefore potentially showing typing errors , spelling or grammar mistakes , the challenge is to identify concepts and thus structure the information contained in the text . In health information retrieval , indexing is of great interest for information retrieval in unstructured documents , such as reports and medical notes . This thesis proposes several methods and their evaluation along two axes : the indexing of medical texts using several terminologies and the processing of natural language in narrative medical notes . Keywords : Information Retrieval , Electronic Health Records , Modelling , Information Extraction , Controlled Vocabularies , Natural Language Processing