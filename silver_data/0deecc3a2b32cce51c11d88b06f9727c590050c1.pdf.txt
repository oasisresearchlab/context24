Aggregating Life Tags for Opportunistic Crowdsensing with Mobile and Smartglasses Users Adrian Aiordăchioae MintViz Lab | MANSiD Center Ștefan cel Mare University of Suceava(cid:13) Suceava 720229 , Romania adrian . aiordachioae2 @ student . usv . ro Daniel Furtună Ștefan cel Mare University of Suceava Suceava 720229 , Romania daniel . furtuna @ student . usv . ro Radu - Daniel Vatavu MintViz Lab | MANSiD Center Ștefan cel Mare University of Suceava Suceava 720229 , Romania(cid:13) radu . vatavu @ usm . ro ABSTRACT We discuss in this work the opportunity of employing lifelogging devices , applications , and systems , such as systems that collect , process , and store video using mobile and wearable cameras , in order to run queries about objects and concepts of interest from everyday life . The outcome is an instance of “opportunistic mobile crowdsensing , ” which we implement with lifelogging technology , mobile video cameras , and camera glasses . We describe the implementation of our concept that builds on top of Life - Tags , a wearable system for abstracting life in the form of clouds of concepts automatically extracted from videos captured by lifeloggers . We show how Life - Tags can be extended with a mobile application and cloud - based services , the Firebase Realtime Database and Cloud Storage , toward integrated lifelogging and mobile crowdsensing , where the life tags of mobile and wearable users are queries for potential matches regarding specific objects and concepts of interest . We conclude with implications for the future integration of lifelogging technology , mobile and wearable computing , and crowdsensing . CCS CONCEPTS • Human - centered computing ~ Human computer interaction ( HCI ) ; Interactive systems and tools ; Ubiquitous and mobile devices ; • Software and its engineering . KEYWORDS Smartglasses ; Smart wearables ; Mobile devices ; Prototype ; Mobile crowdsensing ; Life - Tags ; Participatory sensing . 1 INTRODUCTION Lifelogging applications enable automatic and passive collection of personal data , e . g . , first - person images and video , GPS Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from Permissions @ acm . org . GoodTechs ' 20 , September 14 – 16 , 2020 , Antwerp , Belgium ©2020 Copyright is held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 978 - 1 - 4503 - 7559 - 7 / 20 / 09… $ 15 . 00 https : / / doi . org / 10 . 1145 / 3411170 . 3411237 coordinates of journeys , and physiological measurements , among others , that are stored as memory aids to offer support for reliving past moments [ 1 - 4 ] . Several commercial products and applications are available for lifelogging in the form of clip - on wearable cameras [ 5 - 11 ] , while recent research has explored new representations and visualizations for video and image - based lifelogs , such as clouds of tags automatically extracted from first - person , eye - level video [ 12 ] . In most cases where such systems are worn and active in public places , the information from the lifelogs they collect contains sensible information , such as regarding bystanders , which can generate complaints and opposition toward the wearers of such systems [ 13 - 15 ] . However , this information can equally be useful to the bystanders unwillingly caught on camera that could effectively use the lifelog collected by a third party for their own benefit . Given that video lifelog processing can be automated in the cloud , having many mobile and wearable video camera users collecting data and acting as crowdsensing workers represents an opportunity for performing everyday visual search tasks more effectively , for example visual tasks that represent challenges for people with low vision [ 16 ] . Inspired by the practice of mobile crowdsensing [ 17 - 23 ] , recent prototypes for camera - based smartglasses , such as LifeTags [ 12 ] and CueSee [ 16 ] , designed to assist users by abstracting their life and improving the performance of visual search , respectively , we introduce in this paper the concept and opportunity of employing lifelogging applications , such as those running on mobile and wearable video camera devices , to enable queries about objects and concepts of interest . These queries could be answered effectively by means of opportunistic mobile crowdsensing . This way , the lifelog would be useful not just to the wearer of such technology , but also to the larger community , including remote users and bystanders . Our practical contributions are as follows : 1 . We introduce the idea of using lifelogging applications to implement queries about objects of interest from everyday life that could be answered in real - time 2 by means of opportunistic crowdsensing implemented with video camera - based devices . 2 . We describe an implementation of our concept by starting from the Life - Tags system of Aiordăchioae and Vatavu [ 12 ] , 2 By “real - time , ” we mean a short interval of time in the order of seconds between the moment when the question is posed , e . g . , Where is the fruit section in this supermarket ? to the moment when results return from the cloud . which we extend with cloud resources and services , i . e . , the Firebase Realtime Database [ 24 ] , Firebase Cloud Storage [ 25 ] , Google Cloud Vision [ 26 ] , and a Node . js application . In our prototype , the tag clouds of many users are queried for potential matches of objects and concepts of interest . 3 . We present preliminary results about our system and conclude with implications for future integration of lifelogging , mobile and wearable computing , and mobile crowdsensing . 2 RELATED WORK We are witnessing a growth of mobile and wearable devices [ 27 , 28 ] that rely on embedded sensors for novel sensing applications . In this section , we discuss two instances of such applications represented by lifelogging and mobile crowdsensing . 2 . 1 Lifelogging Lifelogging is the process by which users record and store various aspects of their daily life [ 29 ] , such as in the form of snapshots and videos captured by wearable cameras . Lifelogging systems are usually constituted of several components responsible for collecting , storing , analyzing , querying , presenting , and sharing data . Among the most relevant prototypes from the scientific literature , we note SenseCam [ 30 ] , EyeTap [ 31 ] , DejaView [ 32 ] , and InSense [ 33 ] . Several commercial products are available for lifelogging enthusiasts including MeCam [ 6 ] , Narrative Clip 2 [ 7 ] , SnapCam [ 8 ] , and Google Clips [ 9 ] . Unlike clip - on video cameras , smartglasses can record video from the first - person and eye - level perspective [ 10 , 11 ] . Preliminary work on lifelogging applications has focused on monitoring various aspects of life , such as food - logging [ 34 ] , computer usage [ 1 ] , sleep patterns [ 35 ] , wordometer systems [ 36 ] , vehicular lifelogging [ 37 , 38 ] , thing - logging for the Internet - of - Things [ 39 ] , and applications that collect data for the purpose of evaluating the quality of life [ 40 ] . For example Zini et al . [ 40 ] proposed a system to monitor four distinct aspects of life quality , such as activities , sleep , fatigue , and mood . For people with severe memory problems , lifelogging applications provide memory support , referred as “memory prosthesis , ” by enabling users to relive recent experiences with the help of the lifelog [ 2 - 4 ] . 2 . 2 Mobile crowdsensing Ganti et al . [ 17 ] introduced the term “mobile crowdsensing” ( MCS ) to denote a general paradigm for mobile phone - based sensing in the context of crowdsourcing . Systems that build on this approach utilize sensors and communications interfaces embedded in mobile devices , e . g . , cameras , microphones , GPS and inertial measurement units . However , in order to operate effectively and attain the goal for which they were designed , MCS systems require the participation of a large number of users . Practical applications for mobile crowdsensing are useful for communities to collectively acquire data from which to extract information to analyze , estimate , and predict events of interest . For example , such systems have frequently addressed smart cities [ 18 - 20 ] . The Leelou Private Eye [ 20 ] is a crowd - sourced scanning network based on smartglasses that locates missing persons and warns about people with a criminal history . Jigsaw [ 19 ] is a floor plan reconstruction system that leverages crowdsensed data . Mobile crowdsensing systems have practical applications for people with visual impairments to help identifying objects with the support of remote assistants [ 21 ] or computer vision analysis [ 22 , 23 ] . For example , VizWiz [ 21 ] is a mobile application that enables people who are blind to solve visual problems in near real - time with the participation of human workers ; TapTapSee [ 22 ] is an application designed for people with visual impairments that employs computer vision [ 41 ] to identify objects ; and VizMap [ 23 ] employs computer vision and crowdsourcing to collect visual information about the environment ( posters , signs , exit doors , etc . ) from videos taken on - site by volunteers . These videos are then employed to build a 3D point cloud representation of the environment for localization and navigation . 2 . 3 Summary and contribution In this work , we demonstrate the opportunity of a new concept by combining two existing technologies : lifelogging and mobile crowdsourcing . The outcome is an instance of opportunistic mobile crowdsensing , where data collected by mobile and wearable camera devices is used to perform queries regarding everyday objects and concepts of interest . Our approach is to start from an existing prototype [ 12 ] , originally designed for single - user operation , and show how it can be extended with cloud services toward multi - user opportunistic crowdsensing . We demonstrate the concept with a functional prototype , for which we present engineering details and preliminary evaluation results , while we leave in - depth evaluation for future work . 3 LIFE - TAGS Life - Tags [ 12 ] is a wearable prototype designed to automatically capture snapshots using a camera glasses and to summarize life with word clouds . Life - Tags focuses on the concept of abstracting life by providing users with executive summaries of what their visual experiences were like , as recorded from the first - person , eye - level perspective of the smartglasses rather than with a list of snapshots and videos as in conventional lifelogging applications . Using Life - Tags , life experiences are stored for future consultation . Users can also choose to select synthetic parts of the lifelog , e . g . , a cloud of concepts , to share data on social networks , or other systems for rendering ambient media [ 42 , 43 ] , without affecting the privacy of bystanders . Life - Tags was demonstrated with a camera - based glasses featuring a full - HD micro video camera , Wi - Fi operation , and a 90˚ field of view [ 44 ] . Snapshots are captured using an Android application on a smartphone and , are periodically offloaded to a desktop PC , from where they are sent to Clarifai [ 45 ] , a third - party service for the automatic description of images ; see Figure 1 for a JSON - formatted response for a photograph captured in a park on a cloudy day . The Life - Tags visualization application presents users with snapshots and video montages corresponding to the identified tags [ 46 ] ; see Figure 2 , left for examples of snapshots captured by Life - Tags during a walk in the park and the corresponding tag clouds . The work that introduced Life - Tags [ 12 ] focused on single - user applications and on practical aspects regarding the storage and the optimal frequency at which to record data . In this work , we employ Life - Tags as the starting point for our multi - user mobile and wearable opportunistic crowdsensing system . The next section presents the technical details of our implementation . 4 TOWARD AN EXTENSION OF LIFE - TAGS FOR CROWDSENSING To extend the functionality of Life - Tags and implement our concept , we designed a mobile crowdsensing system to foster community queries about objects of interest . Our system falls into the category of opportunistic mobile systems because lifelogs are captured passively . Figure 3 shows snapshots from two scenarios , an university campus and a supermarket . The software architecture of our system consists of a server , a backend component , and a user interface . On the client side , we employed standard web technology , such as HTML , CSS , Javascript , the Google Maps library [ 48 ] , the Firebase Realtime Database [ 24 ] and the Firebase Cloud Storage [ 25 ] . The Firebase Realtime Database is used to share query - related information , e . g . , user “X” is looking for object “Y , ” between many crowdsensing workers in real - time . We used the Firebase Cloud Storage to implement high - scalability storage for the images automatically captured by the crowdsensing devices when the specified objects were identified . The Google Maps SDK [ 48 ] was employed to display the location where a specific object was found via the navigator . geolocation functionality available in modern web browsers . The client runs in Figure 1 . Example of a JSON message used by Life - Tags [ 12 ] containing concepts detected during a walk in the park . Figure 2 : Examples of snapshots captured by Life - Tags [ 12 ] in the park ( left ) and supermarket ( right ) . The images at the bottom show two tag clouds generated by Life - Tags . â Figure 3 : Examples of snapshots captured by our mobile and wearable crowdsensing system . a web browser , captures images and stores them into the Firebase Cloud Storage , from where they are processed by the Google Cloud Vision API and the response is saved in the Firebase Database as a list of objects with corresponding GPS coordinates . On the server side , a Node . js application running on Cloud Functions for Firebase is responsible for the management of the queries , sending video frames from crowdsensing workers to the Google Cloud Vision API [ 26 ] , parsing the results , and returning matches to the client that generated the request ; see Figure 4 . We performed a preliminary evaluation of our system using the DevTools panel in Google Chrome . Figure 5 shows results regarding the upload time of images to the Firebase Storage ( less than one second ) , while receiving results from the Google Cloud Vision API takes less than one second as well . Of course , request - response times are influenced by the speed of the Internet connection , the available bandwidth , and the size of the data that is transmitted . We monitored the performance with up to twenty users simulated in the web browser to see how the application responds . Our preliminary results showed that the average request - response time did not exceed one second . 5 CONCLUSION AND FUTURE WORK In this work , we contributed the idea of abstracting everyday life for a community of users in the form of concepts automatically extracted from video captured by the cameras embedded in mobile and wearable devices . We showed how a mobile crowdsensing system could be implemented as the evolution of a life abstracting system , Life - Tags [ 12 ] , toward crowdsourcing queries and identification of objects and concepts of interest inside a community , and addressing practical aspects from scaling single - user applications [ 12 ] to multi - user systems . It is interesting to look at the implications of the concept that we demonstrated . On one hand , we present an alternative use for lifelog data , converting it from a private resource to a public one for the benefit of the community . This perspective enables Figure 5 . Examples of request - response times for our technical implementation . Figure 4 . Block sequence diagram for our opportunistic mobile and wearable crowdsensing system . bystanders , which are regularly impacted negatively by video recording cameras in public places [ 13 - 15 ] , to benefit from data collected by users of mobile and wearable camera devices . On the other hand , we showed how mobile crowdsensing can employ large amounts of data collected by lifelogging enthusiasts for the purpose of increasing the performance of crowdworkers . We believe that further investigation of the connections and mutual benefits resulting from integrated lifelogging and mobile and wearable crowdsensing technology will reveal new opportunities for new applications . For example , interesting future work will focus on using crowdsourcing similarity criteria [ 49 ] , integration with smart environment software architecture [ 50 , 51 ] and with systems designed for mass - computer interaction [ 52 ] , and on deploying the system in real - world scenarios to understand technical performance and social acceptability [ 53 ] . Applications for people with low vision to improve visual search are another direction for further examination and exploitation of our concept . ACKNOWLEDGMENTS This work was supported by a grant of Ministry of Research and Innovation , CNCS - UEFISCDI , PN - III - P1 - 1 . 1 - TE - 2016 - 2173 ( TE141 / 2018 ) , within PNCDI III . REFERENCES [ 1 ] Hinbarji Z . , Albatal R . , O’Connor N . , and Gurrin C . 2016 . LoggerMan , a Comprehensive Logging and Visualization Tool to Capture Computer Usage , 9517 . Springer , Cham . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 27674 - 8 _ 31 [ 2 ] Abdullah Al Mahmud , Jeffrey Braun , and Jean - Bernard Martens . 2010 . Designing to Capture and Share Life Experiences for Persons with Aphasia . In Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services ( MobileHCI ’10 ) . ACM , New York , NY , USA , 391 – 392 . https : / / doi . org / 10 . 1145 / 1851600 . 1851680 [ 3 ] E . Berry , N . Kapur , L . Williams , S . Hodges , P . Watson , G . Smyth , J . Srinivasan , R . Smith , B . Wilson , and K . Wood . 2007 . The use of a wearable camera , SenseCam , as a pictorial diary to improve autobiographical memory in a patient with limbic encephalitis : A preliminary report . Neuropsychol . Rehabil . 17 , 4 – 5 , 582 – 601 . https : / / doi . org / 10 . 1080 / 09602010601029780 [ 4 ] Gary Stix . 2011 . Photographic Memory : Wearable Cam Could Help Patients Stave Off Effects of Impaired Recall . Scientific American . https : / / www . scientificamerican . com / article / photographic - memory - wearable / [ 5 ] Phil Hall . 2019 . Best action camera 2019 : 10 cameras for the GoPro generation . https : / / www . techradar . com / news / best - actioncamera [ 6 ] MeCam . 2019 . High definition video camera | Best life logging device | Mini video camera - MeCam . Retrieved March , 2020 from https : / / mecam . me / products / mecam - hd [ 7 ] Narrative . 2019 . The World’s Most Wearable HD Video Camera | Narrative Clip 2 . http : / / getnarrative . com / [ 8 ] SnapCam . 2019 . iON USA | SnapCam . Retrieved March , 2020 from https : / / usa . ioncamera . com / snapcam / [ 9 ] Google Clips . 2019 . Google Clips Specifications . https : / / support . google . com / googleclips / answer / 7545447 ? hl = en [ 10 ] RedShed . 2018 . The 8 Best Spy Glasses of 2018 . Retrieved March , 2020 from https : / / redshed . co . uk / tech - reviews / best - spyglasses / [ 11 ] Snap . 2019 . Spectacles by Snapchat | Your HandsFree Camera . Retrieved March , 2020 from https : / / www . spectacles . com [ 12 ] Adrian Aiordachioae , Radu - Daniel Vatavu . 2019 . Life - Tags : A Smartglasses - based System for Recording and Abstracting Life with Tag Clouds . Proc . ACM Hum . - Comput . Interact . 3 , EICS , Article 15 ( June 2019 ) , 22 pages . https : / / doi . org / 10 . 1145 / 3331157 [ 13 ] Marion Koelle , Swamy Ananthanarayan , Simon Czupalla , Wilko Heuten , and Susanne Boll . 2018 . Your smart glasses’ camera bothers me ! exploring opt - in and opt - out gestures for privacy mediation . In Proceedings of the 10th Nordic Conference on Human - Computer Interaction ( NordiCHI ’18 ) . ACM , New York , NY , USA , 473 – 481 . https : / / doi . org / 10 . 1145 / 3240167 . 3240174 [ 14 ] Shilin Zhu , Chi Zhang , and Xinyu Zhang . 2017 . Automating Visual Privacy Protection Using a Smart LED . In Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking ( MobiCom ’17 ) . ACM , New York , NY , USA , 329 – 342 . https : / / doi . org / 10 . 1145 / 3117811 . 3117820 [ 15 ] Marion Koelle , Swamy Ananthanarayan , Simon Czupalla , Wilko Heuten , and Susanne Boll . 2018 . Your smart glasses’ camera bothers me ! exploring opt - in and opt - out gestures for privacy mediation . In Proceedings of the 10th Nordic Conference on Human - Computer Interaction ( NordiCHI ’18 ) . ACM , New York , NY , USA , 473 – 481 . https : / / doi . org / 10 . 1145 / 3240167 . 3240174 [ 16 ] Yuhang Zhao , Sarit Szpiro , Jonathan Knighten , Shiri Azenkot . 2016 . CueSee : exploring visual cues for people with low vision to facilitate a visual search task . In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing ( UbiComp ’16 ) , ACM , New York , NY , USA , 73 – 84 . https : / / doi . org / 10 . 1145 / 2971648 . 2971730 [ 17 ] R . K . Ganti , F . Ye , H . Lei . 2011 . Mobile crowdsensing : current state and future challenges . IEEE Communications Magazine , 49 ( 11 ) , 32 - 39 . http : / / dx . doi . org / 10 . 1109 / MCOM . 2011 . 6069707 [ 18 ] Haggai Roitman , Jonathan Mamou , Sameep Mehta , Aharon Satt , L . V . Subramaniam . 2012 . Harnessing the crowds for smart city sensing . In Proceedings of the 1st International Workshop on Multimodal crowd sensing ( CrowdSens ’12 ) , 17 – 18 . https : / / doi . org / 10 . 1145 / 2390034 . 2390043 [ 19 ] Ruipeng Gao , Mingmin Zhao , Tao Ye , Fan Ye , Yizhou Wang , Kaigui Bian , Tao Wang , Xiaoming Li . 2014 . Jigsaw : indoor floor plan reconstruction via mobile crowdsensing . In Proc . of the 20th Annual International Conference on Mobile Computing and Networking , 249 – 260 . https : / / doi . org / 10 . 1145 / 2639108 . 2639134 [ 20 ] Leelou Private Eye - Home . Retrieved March , 2020 from https : / / leelouprivateeye . com / index . php / en / [ 21 ] Jeffrey P . Bigham , Chandrika Jayant , Hanjie Ji , Greg Little , Andrew Miller , Robert C . Miller , Robin Miller , Aubrey Tatarowicz , Brandyn White , Samual White , Tom Yeh . 2010 . VizWiz : nearly real - time answers to visual questions . In Proceedings of the 23nd annual ACM symposium on User interface software and technology ( UIST ’10 ) , 333 – 342 . https : / / doi . org / 10 . 1145 / 1866029 . 1866080 [ 22 ] TapTapSee - Blind and Visually Impaired Assistive Technology - powered by CloudSight . ai Image Recognition API . Retrieved March , 2020 from https : / / taptapseeapp . com / [ 23 ] Cole Gleason , Anhong Guo , Gierad Laput , Kris Kitani , Jeffrey P . Bigham . 2016 . VizMap : Accessible Visual Information Through Crowdsourced Map Reconstruction . In Proc . of the 18th International ACM SIGACCESS Conference on Computers and Accessibility ( ASSETS ’16 ) , 273 – 274 . https : / / doi . org / 10 . 1145 / 2982142 . 2982200 [ 24 ] Firebase Realtime Database . Retrieved from https : / / firebase . google . com / docs / database [ 25 ] Cloud Storage : Object Storage . Google Cloud . Retrieved March , 2020 from https : / / cloud . google . com / storage [ 26 ] Vision AI | Derive Image Insights via ML | Cloud Vision API . Retrieved March , 2020 from https : / / cloud . google . com / vision [ 27 ] Gartner Says Global Smartphone Sales Will Grow 3 % in 2020 . https : / / www . gartner . com / en / newsroom / press - releases / 2020 - 01 - 28 - gartner - says - worldwide - smartphone - sales - will - grow - 3 - - [ 28 ] Gartner Says Global End - User Spending on Wearable Devices to Total $ 52 Billion in 2020 . Retrieved March , 2020 https : / / www . gartner . com / en / newsroom / press - releases / 2019 - 10 - 30 - gartner - says - global - end - user - spending - on - wearable - dev [ 29 ] Cathal Gurrin , Alan F . Smeaton , and Aiden R . Doherty . 2014 . LifeLogging : Personal Big Data . Found . Trends Inf . Retr . 8 , 1 ( June 2014 ) , 1 – 125 . https : / / doi . org / 10 . 1561 / 1500000033 [ 30 ] Steve Hodges , Lyndsay Williams , Emma Berry , Shahram Izadi , James Srinivasan , Alex Butler , Gavin Smyth , Narinder Kapur , and Ken Wood . 2006 . SenseCam : A Retrospective Memory Aid . In Proceedings of the 8th International Conference on Ubiquitous Computing ( UbiComp’06 ) . Springer - Verlag , Berlin , Heidelberg , 177 – 193 . https : / / doi . org / 10 . 1007 / 11853565 _ 11 [ 31 ] Steve Mann , James Fung , and Eric Moncrieff . 1999 . EyeTap Technology for Wireless Electronic News Gathering . SIGMOBILE Mob . Comput . Commun . Rev . 3 , 4 ( Oct . 1999 ) , 19 – 26 . https : / / doi . org / 10 . 1145 / 584039 . 584044 [ 32 ] Dirk de Jager , Alex L . Wood , Geoff V . Merrett , Bashir M . Al - Hashimi , Kieron O’Hara , Nigel R . Shadbolt , and Wendy Hall . 2011 . A Low - power , Distributed , Pervasive Healthcare System for Supporting Memory . In Proceedings of the First ACM MobiHoc Workshop on Pervasive Wireless Healthcare ( MobileHealth ’11 ) . https : / / doi . org / 10 . 1145 / 2007036 . 2007043 [ 33 ] Mark Blum , Alex ( Sandy ) Pentland , and Gerhard Troster . 2006 . InSense : Interest - Based Life Logging . IEEE MultiMedia 13 , 4 ( Oct . 2006 ) , 40 – 48 . https : / / doi . org / 10 . 1109 / MMUL . 2006 . 87 [ 34 ] Keigo Kitamura , Toshihiko Yamasaki , and Kiyoharu Aizawa . 2008 . Food Log by Analyzing Food Images . In Proceedings of the 16th ACM International Conference on Multimedia ( MM ’08 ) . ACM , New York , NY , USA , 999 – 1000 . https : / / doi . org / 10 . 1145 / 1459359 . 1459548 [ 35 ] Vangelis Metsis , Dimitrios Kosmopoulos , Vassilis Athitsos , and Fillia Makedon . 2014 . Non - invasive Analysis of Sleep Patterns via Multimodal Sensor Input . Personal and Ubiquitous Computing 18 , 1 ( Jan . 2014 ) , 19 – 26 . https : / / doi . org / 10 . 1007 / s00779 - 012 - 0623 - 1 [ 36 ] Olivier Augereau , Charles Lima Sanches , Koichi Kise , and Kai Kunze . 2018 . Wordometer Systems for Everyday Life . Proc . ACM Interact . Mob . Wearable Ubiquitous Technol . 1 , 4 , Article 123 ( Jan . 2018 ) , 21 pages . https : / / doi . org / 10 . 1145 / 3161601 [ 37 ] Adrian Aiordăchioae , Radu - Daniel Vatavu , and Dorin - Mircea Popovici . 2019 . A Design Space for Vehicular LifeLogging to Support Creation of Digital Content in Connected Cars . In Proceedings of the 11th ACM SIGCHI Symposium on Engineering Interactive Computing Systems ( EICS ’19 ) , Article 9 , 1 - 6 . https : / / doi . org / 10 . 1145 / 3319499 . 3328234 [ 38 ] Joshua McVeigh - Schultz , Jennifer Stein , Jacob Boyle , Emily Duff , Jeff Watson , Avimaan Syam , Amanda Tasse , Simon Wiscombe , and Scott Fisher . 2012 . Vehicular Lifelogging : New Contexts and Methodologies for Human - car Interaction . In CHI ’12 Extended Abstracts on Human Factors in Computing Systems ( CHI EA ’12 ) . https : / / doi . org / 10 . 1145 / 2212776 . 2212800 [ 39 ] Jim Gemmell . 2014 . Life - logging , Thing - logging and the Internet of Things . In Proceedings of the 2014 Workshop on Physical Analytics ( WPA ’14 ) . ACM , New York , NY , USA , 17 – 17 . https : / / doi . org / 10 . 1145 / 2611264 . 2611276 [ 40 ] Floriano Zini , Martin Reinstadler , and Francesco Ricci . 2015 . Life - logs Aggregation for Quality of Life Monitoring . In Proceedings of the 5th International Conference on Digital Health 2015 ( DH ’15 ) . ACM , New York , NY , USA , 131 – 132 . https : / / doi . org / 10 . 1145 / 2750511 . 2750531 [ 41 ] CloudSight Image Recognition API . https : / / cloudsight . ai [ 42 ] Bogdan Pogorelc , Artur Lugmayr , Bjorn Stockleben , Radu - Daniel Vatavu , Nina Tahmasebi , Estefania Serral , Emilija Stojmenova , Bojan Imperl , Thomas Risse , Gideon Zenz , Matjaz Gams . 2013 . Ambient Bloom : New Business , Content , Design and Models to Increase the Semantic Ambient Media Experience . Multimedia Tools and Appl . 66 , 7 – 32 . https : / / doi . org / 10 . 1007 / s11042 - 012 - 1228 - 4 [ 43 ] Radu - Daniel Vatavu . 2012 . Presence bubbles : supporting and enhancing human - human interaction with ambient media . Multimedia Tools and Applications 58 , 2 ( May 2012 ) , 371 – 383 . https : / / doi . org / 10 . 1007 / s11042 - 010 - 0674 - 0 [ 44 ] Eyeglasses Hidden WiFi camera . Spy Shop Round Rock . https : / / spyshoproundrock . com / product / cameras / eyeglasses - hidden - wifi - camera [ 45 ] Clarifai . Enterprise AI Powered Computer Vision Technology Solutions | Clarifai . https : / / www . clarifai . com [ 46 ] WordCloud 1 . 0 . 0 . 3 . https : / / nuget . org / packages / WordCloud / [ 47 ] Liting Zhou , Zaher Hinbarji , Duc - Tien Dang - Nguyen , Cathal Gurrin . 2018 . LIFER : An Interactive Lifelog Retrieval System . In Proceedings of the 2018 ACM Workshop on The Lifelog Search Challenge ( LSC ’18 ) . ACM , New York , NY , USA , 9 – 14 . https : / / doi . org / 10 . 1145 / 3210539 . 3210542 [ 48 ] Google Maps Platform Documentation . Retrieved March , 2020 from https : / / developers . google . com / maps / documentation [ 49 ] Abdullah X . Ali , Meredith Ringel Morris , Jacob O . Wobbrock . 2018 . Crowdsourcing Similarity Judgments for Agreement Analysis in End - User Elicitation Studies . UIST ’18 , 177 – 188 . https : / / doi . org / 10 . 1145 / 3242587 . 3242621 [ 50 ] Ovidiu - Andrei Schipor , Radu - Daniel Vatavu , Wenjun Wu . 2019 . SAPIENS : Towards Software Architecture to Support Peripheral Interaction in Smart Environments . Proc . ACM Hum . - Comput . Interact . 3 , EICS , Article 11 ( June 2019 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3331153 [ 51 ] Ovidiu - Andrei Schipor , Radu - Daniel Vatavu , Jean Vanderdonckt . 2019 . Euphoria : A Scalable , Event - Driven Architecture for Designing Interactions Across Heterogeneous Devices in Smart Environments Information and Software Technology 109 . Elsevier , 43 - 59 . https : / / doi . org / 10 . 1016 / j . infsof . 2019 . 01 . 006 [ 52 ] Jean - Yves Lionel Lawson , Jean Vanderdonckt , Radu - Daniel Vatavu . 2018 . Mass - Computer Interaction for Thousands of Users and Beyond . In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems ( CHI EA ’18 ) . Association for Computing Machinery , New York , NY , USA , Paper LBW032 , 1 – 6 . https : / / doi . org / 10 . 1145 / 3170427 . 3188465 [ 53 ] Marion Koelle , Swamy Ananthanarayan , Susanne Boll . 2020 . Social Acceptability in HCI : A Survey of Methods , Measures , and Design Strategies . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems ( CHI ’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 19 . https : / / doi . org / 10 . 1145 / 3313831 . 3376162