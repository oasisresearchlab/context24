Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change William L . Hamilton , Jure Leskovec , Dan Jurafsky Department of Computer Science , Stanford University , Stanford CA , 94305 wleif , jure , jurafsky @ stanford . edu Abstract Understanding how words change their meanings over time is key to models of language and cultural evolution , but his - torical data on meaning is scarce , mak - ing theories hard to develop and test . Word embeddings show promise as a di - achronic tool , but have not been carefully evaluated . We develop a robust method - ology for quantifying semantic change by evaluating word embeddings ( PPMI , SVD , word2vec ) against known historical changes . We then use this methodology to reveal statistical laws of semantic evo - lution . Using six historical corpora span - ning four languages and two centuries , we propose two quantitative laws of seman - tic change : ( i ) the law of conformity —the rate of semantic change scales with an in - verse power - law of word frequency ; ( ii ) the law of innovation —independent of fre - quency , words that are more polysemous have higher rates of semantic change . 1 Introduction Shifts in word meaning exhibit systematic regu - larities ( Br´eal , 1897 ; Ullmann , 1962 ) . The rate of semantic change , for example , is higher in some words than others ( Blank , 1999 ) — com - pare the stable semantic history of cat ( from Proto - Germanic kattuz , “cat” ) to the varied meanings of English cast : “to mould” , “a collection of actors’ , “a hardened bandage” , etc . ( all from Old Norse kasta , “to throw” , Simpson et al . , 1989 ) . Various hypotheses have been offered about such regularities in semantic change , such as an in - creasing subjectiﬁcation of meaning , or the gram - maticalization of inferences ( e . g . , Geeraerts , 1997 ; Blank , 1999 ; Traugott and Dasher , 2001 ) . But many core questions about semantic change remain unanswered . One is the role of fre - quency . Frequency plays a key role in other lin - guistic changes , associated sometimes with faster change—sound changes like lenition occur in more frequent words—and sometimes with slower change—high frequency words are more resistant to morphological regularization ( Bybee , 2007 ; Pagel et al . , 2007 ; Lieberman et al . , 2007 ) . What is the role of word frequency in meaning change ? Another unanswered question is the relationship between semantic change and polysemy . Words gain senses over time as they semantically drift ( Br´eal , 1897 ; Wilkins , 1993 ; Hopper and Trau - gott , 2003 ) , and polysemous words 1 occur in more diverse contexts , affecting lexical access speed ( Adelman et al . , 2006 ) and rates of L2 learning ( Crossley et al . , 2010 ) . But we don’t know whether the diverse contextual use of pol - ysemous words makes them more or less likely to undergo change ( Geeraerts , 1997 ; Winter et al . , 2014 ; Xu et al . , 2015 ) . Furthermore , poly - semy is strongly correlated with frequency—high frequency words have more senses ( Zipf , 1945 ; ˙Ilgen and Karaoglan , 2007 ) —so understanding how polysemy relates to semantic change requires controling for word frequency . Answering these questions requires new meth - ods that can go beyond the case - studies of a few words ( often followed over widely different time - periods ) that are our most common diachronic data ( Br´eal , 1897 ; Ullmann , 1962 ; Blank , 1999 ; Hopper and Traugott , 2003 ; Traugott and Dasher , 2001 ) . One promising avenue is the use of distri - butional semantics , in which words are embedded in vector spaces according to their co - occurrence relationships ( Bullinaria and Levy , 2007 ; Turney and Pantel , 2010 ) , and the embeddings of words 1 We use ‘polysemy’ here to refer to related senses as well as rarer cases of accidental homonymy . a r X i v : 1605 . 09096v6 [ c s . C L ] 25 O c t 2018 Figure 1 : Two - dimensional visualization of semantic change in English using SGNS vectors . 2 a , The word gay shifted from meaning “cheerful” or “frolicsome” to referring to homosexuality . b , In the early 20th century broadcast referred to “casting out seeds” ; with the rise of television and radio its meaning shifted to “transmitting signals” . c , Awful underwent a process of pejoration , as it shifted from meaning “full of awe” to meaning “terrible or appalling” ( Simpson et al . , 1989 ) . are then compared across time - periods . This new direction has been effectively demonstrated in a number of case - studies ( Sagi et al . , 2011 ; Wijaya and Yeniterzi , 2011 ; Gulordava and Baroni , 2011 ; Jatowt and Duh , 2014 ) and used to perform large - scale linguistic change - point detection ( Kulkarni et al . , 2014 ) as well as to test a few speciﬁc hy - potheses , such as whether English synonyms tend to change meaning in similar ways ( Xu and Kemp , 2015 ) . However , these works employ widely dif - ferent embedding approaches and test their ap - proaches only on English . In this work , we develop a robust methodol - ogy for quantifying semantic change using embed - dings by comparing state - of - the - art approaches ( PPMI , SVD , word2vec ) on novel benchmarks . We then apply this methodology in a large - scale cross - linguistic analysis using 6 corpora spanning 200 years and 4 languages ( English , German , French , and Chinese ) . Based on this analysis , we propose two statistical laws relating frequency and polysemy to semantic change : • The law of conformity : Rates of semantic change scale with a negative power of word frequency . • The law of innovation : After controlling for frequency , polysemous words have signiﬁ - cantly higher rates of semantic change . 2 Diachronic embedding methods The following sections outline how we construct diachronic ( historical ) word embeddings , by ﬁrst constructing embeddings in each time - period and then aligning them over time , and the metrics that 2 Appendix B details the visualization method . we use to quantify semantic change . All of the learned embeddings and the code we used to ana - lyze them are made publicly available . 3 2 . 1 Embedding algorithms We use three methods to construct word em - beddings within each time - period : PPMI , SVD , and SGNS ( i . e . , word2vec ) . 4 These distributional methods represent each word w i by a vector w i that captures information about its co - occurrence statistics . These methods operationalize the ‘dis - tributional hypothesis’ that word semantics are im - plicit in co - occurrence relationships ( Harris , 1954 ; Firth , 1957 ) . The semantic similarity / distance be - tween two words is approximated by the cosine similarity / distance between their vectors ( Turney and Pantel , 2010 ) . 2 . 1 . 1 PPMI In the PPMI representations , the vector embedding for word w i ∈ V contains the positive point - wise mutual information ( PPMI ) values between w i and a large set of pre - speciﬁed ‘context’ words . The word vectors correspond to the rows of the matrix M PPMI ∈ R | V | × | V C | with entries given by M PPMI i , j = max (cid:26) log (cid:18) ˆ p ( w i , c j ) ˆ p ( w ) ˆ p ( c j ) (cid:19) − α , 0 (cid:27) , ( 1 ) where c j ∈ V C is a context word and α > 0 is a negative prior , which provides a smooth - ing bias ( Levy et al . , 2015 ) . The ˆ p correspond to the smoothed empirical probabilities of word 3 http : / / nlp . stanford . edu / projects / histwords 4 Synchronic applications of these three methods are re - viewed in detail in Levy et al . ( 2015 ) . Name Language Description Tokens Years E NG A LL English Google books ( all genres ) 8 . 5 × 10 11 1800 - 1999 E NG F IC English Fiction from Google books 7 . 5 × 10 10 1800 - 1999 COHA English Genre - balanced sample 4 . 1 × 10 8 1810 - 2009 F RE A LL French Google books ( all genres ) 1 . 9 × 10 11 1800 - 1999 G ER A LL German Google books ( all genres ) 4 . 3 × 10 10 1800 - 1999 C HI A LL Chinese Google books ( all genres ) 6 . 0 × 10 10 1950 - 1999 Table 1 : Six large historical datasets from various languages and sources are used . ( co - ) occurrences within ﬁxed - size sliding win - dows of text . Clipping the PPMI values above zero ensures they remain ﬁnite and has been shown to dramatically improve results ( Bullinaria and Levy , 2007 ; Levy et al . , 2015 ) ; intuitively , this clipping ensures that the representations emphasize posi - tive word - word correlations over negative ones . 2 . 1 . 2 SVD SVD embeddings correspond to low - dimensional approximations of the PPMI embeddings learned via singular value decomposition ( Levy et al . , 2015 ) . The vector embedding for word w i is given by w SVD i = ( UΣ γ ) i , ( 2 ) where M PPMI = UΣV (cid:62) is the truncated singular value decomposition of M PPMI and γ ∈ [ 0 , 1 ] is an eigenvalue weighting parameter . Setting γ < 1 has been shown to dramatically improve embed - ding qualities ( Turney and Pantel , 2010 ; Bulli - naria and Levy , 2012 ) . This SVD approach can be viewed as a generalization of Latent Seman - tic Analysis ( Landauer and Dumais , 1997 ) , where the term - document matrix is replaced with M PPMI . Compared to PPMI , SVD representations can be more robust , as the dimensionality reduction acts as a form of regularization . 2 . 1 . 3 Skip - gram with negative sampling SGNS ‘word2vec’ embeddings are optimized to predict co - occurrence relationships using an ap - proximate objective known as ‘skip - gram with negative sampling’ ( Mikolov et al . , 2013 ) . In SGNS , each word w i is represented by two dense , low - dimensional vectors : a word vector ( w SGNS i ) and context vector ( c SGNS i ) . These embeddings are optimized via stochastic gradient descent so that ˆ p ( c i | w i ) ∝ exp ( w SGNS i · c SGNS j ) , ( 3 ) where p ( c i | w i ) is the empirical probability of see - ing context word c i within a ﬁxed - length window of text , given that this window contains w i . The SGNS optimization avoids computing the normal - izing constant in ( 3 ) by randomly drawing ‘neg - ative’ context words , c n , for each target word and ensuring that exp ( w SGNS i · c SGNS n ) is small for these examples . SGNS has the beneﬁt of allowing incremental initialization during learning , where the embed - dings for time t are initialized with the embed - dings from time t − ∆ ( Kim et al . , 2014 ) . 2 . 2 Datasets , pre - processing , and hyperparameters We trained models on the 6 datasets described in Table 1 , taken from Google N - Grams ( Lin et al . , 2012 ) and the COHA corpus ( Davies , 2010 ) . The Google N - Gram datasets are extremely large ( comprising ≈ 6 % of all books ever published ) , but they also contain many corpus artifacts due , e . g . , to shifting sampling biases over time ( Pechenick et al . , 2015 ) . In contrast , the COHA corpus was carefully selected to be genre - balanced and rep - resentative of American English over the last 200 years , though as a result it is two orders of mag - nitude smaller . The COHA corpus also contains pre - extracted word lemmas , which we used to val - idate that our results hold at both the lemma and raw token levels . All the datasets were aggregated to the granularity of decades . 5 We follow the recommendations of Levy et al . ( 2015 ) in setting the hyperparameters for the em - bedding methods , though preliminary experiments were used to tune key settings . For all methods , we used symmetric context windows of size 4 ( on each side ) . For SGNS and SVD , we use embed - dings of size 300 . See Appendix A for further im - plementation and pre - processing details . 5 The 2000s decade of the Google data was discarded due to shifts in the sampling methodology ( Michel et al . , 2011 ) . 2 . 3 Aligning historical embeddings In order to compare word vectors from differ - ent time - periods we must ensure that the vectors are aligned to the same coordinate axes . Ex - plicit PPMI vectors are naturally aligned , as each column simply corresponds to a context word . Low - dimensional embeddings will not be natu - rally aligned due to the non - unique nature of the SVD and the stochastic nature of SGNS . In par - ticular , both these methods may result in arbi - trary orthogonal transformations , which do not af - fect pairwise cosine - similarities within - years but will preclude comparison of the same word across time . Previous work circumvented this problem by either avoiding low - dimensional embeddings ( e . g . , Gulordava and Baroni , 2011 ; Jatowt and Duh , 2014 ) or by performing heuristic local align - ments per word ( Kulkarni et al . , 2014 ) . We use orthogonal Procrustes to align the learned low - dimensional embeddings . Deﬁning W ( t ) ∈ R d × | V | as the matrix of word embeddings learned at year t , we align across time - periods while preserving cosine similarities by optimizing : R ( t ) = arg min Q (cid:62) Q = I (cid:107) QW ( t ) − W ( t + 1 ) (cid:107) F , ( 4 ) with R ( t ) ∈ R d × d . The solution corresponds to the best rotational alignment and can be ob - tained efﬁciently using an application of SVD ( Sch¨onemann , 1966 ) . 2 . 4 Time - series from historical embeddings Diachronic word embeddings can be used in two ways to quantify semantic change : ( i ) we can mea - sure changes in pair - wise word similarities over time , or ( ii ) we can measure how an individual word’s embedding shifts over time . Pair - wise similarity time - series Measuring how the cosine - similarity between pairs of words changes over time allows us to test hypotheses about speciﬁc linguistic or cultural shifts in a con - trolled manner . We quantify shifts by computing the similarity time - series s ( t ) ( w i , w j ) = cos - sim ( w ( t ) i , w ( t ) j ) ( 5 ) between two words w i and w j over a time - period ( t , . . . , t + ∆ ) . We then measure the Spearman correlation ( ρ ) of this series against time , which allows us to assess the magnitude and signiﬁ - cance of pairwise similarity shifts ; since the Spear - man correlation is non - parametric , this measure essentially detects whether the similarity series in - creased / decreased over time in a signiﬁcant man - ner , regardless of the ‘shape’ of this curve . 6 Measuring semantic displacement After aligning the embeddings for individual time - periods , we can use the aligned word vectors to compute the semantic displacement that a word has undergone during a certain time - period . In particular , we can directly compute the cosine - distance between a word’s representation for different time - periods , i . e . cos - dist ( w t , w t + ∆ ) , as a measure of semantic change . We can also use this measure to quantify ‘rates’ of semantic change for different words by looking at the displacement between consecutive time - points . 3 Comparison of different approaches We compare the different distributional ap - proaches on a set of benchmarks designed to test their scientiﬁc utility . We evaluate both their syn - chronic accuracy ( i . e . , ability to capture word sim - ilarity within individual time - periods ) and their di - achronic validity ( i . e . , ability to quantify semantic changes over time ) . 3 . 1 Synchronic Accuracy We evaluated the synchronic ( within - time - period ) accuracy of the methods using a standard modern benchmark and the 1990s portion of the E NG A LL data . On Bruni et al . ( 2012 ) ’s MEN similarity task of matching human judgments of word similari - ties , SVD performed best ( ρ = 0 . 739 ) , followed by PPMI ( ρ = 0 . 687 ) and SGNS ( ρ = 0 . 649 ) . These results echo the ﬁndings of Levy et al . ( 2015 ) , who found SVD to perform best on sim - ilarity tasks while SGNS performed best on anal - ogy tasks ( which are not the focus of this work ) . 3 . 2 Diachronic Validity We evaluate the diachronic validity of the methods on two historical semantic tasks : detecting known shifts and discovering shifts from data . For both these tasks , we performed detailed evaluations on a small set of examples ( 28 known shifts and the top - 10 “discovered” shifts by each method ) . Us - ing these reasonably - sized evaluation sets allowed the authors to evaluate each case rigorously using existing literature and historical corpora . 6 Other metrics or change - point detection approaches , e . g . mean shifts ( Kulkarni et al . , 2014 ) could also be used . Word Moving towards Moving away Shift start Source gay homosexual , lesbian happy , showy ca 1950 ( Kulkarni et al . , 2014 ) fatal illness , lethal fate , inevitable < 1800 ( Jatowt and Duh , 2014 ) awful disgusting , mess impressive , majestic < 1800 ( Simpson et al . , 1989 ) nice pleasant , lovely reﬁned , dainty ca 1890 ( Wijaya and Yeniterzi , 2011 ) broadcast transmit , radio scatter , seed ca 1920 ( Jeffers and Lehiste , 1979 ) monitor display , screen — ca 1930 ( Simpson et al . , 1989 ) record tape , album — ca 1920 ( Kulkarni et al . , 2014 ) guy fellow , man — ca 1850 ( Wijaya and Yeniterzi , 2011 ) call phone , message — ca 1890 ( Simpson et al . , 1989 ) Table 2 : Set of attested historical shifts used to evaluate the methods . The examples are taken from previous works on semantic change and from the Oxford English Dictionary ( OED ) , e . g . using ‘obsolete’ tags . The shift start points were estimated using attestation dates in the OED . The ﬁrst six examples are words that shifted dramatically in meaning while the remaining four are words that acquired new meanings ( while potentially also keeping their old ones ) . Detecting known shifts . First , we tested whether the methods capture known historical shifts in meaning . The goal in this task is for the methods to correctly capture whether pairs of words moved closer or further apart in semantic space during a pre - determined time - period . We use a set of independently attested shifts as an evaluation set ( Table 2 ) . For comparison , we eval - uated the methods on both the large ( but messy ) E NG A LL data and the smaller ( but clean ) COHA data . On this task , all the methods performed almost perfectly in terms of capturing the correct directionality of the shifts ( i . e . , the pairwise similarity series have the correct sign on their Spearman correlation with time ) , but there were some differences in whether the methods deemed the shifts statistically signiﬁcant at the p < 0 . 05 level . 7 Overall , SGNS performed the best on the full English data , but its performance dropped signiﬁcantly on the smaller COHA dataset , where SVD performed best . PPMI was noticeably worse than the other two approaches ( Table 3 ) . Discovering shifts from data . We tested whether the methods discover reasonable shifts by examining the top - 10 words that changed the most from the 1900s to the 1990s according to the semantic displacement metric introduced in Section 2 . 4 ( limiting our analysis to words with relative frequencies above 10 − 5 in both decades ) . We used the E NG F IC data as the most - changed list for E NG A LL was dominated by scientiﬁc terms due to changes in the corpus sample . Table 4 shows the top - 10 words discovered by each method . These shifts were judged by the authors as being either clearly genuine , borderline , or clearly corpus artifacts . SGNS performed by 7 All subsequent signiﬁcance tests are at p < 0 . 05 . Method Corpus % Correct % Sig . PPMI E NG A LL 77 . 1 51 . 9 COHA 85 . 7 52 . 4 SVD E NG A LL 92 . 6 81 . 5 COHA 95 . 8 62 . 5 SGNS E NG A LL 100 . 0 88 . 9 COHA 87 . 5 50 . 0 Table 3 : Performance on detection task , i . e . ability to cap - ture the attested shifts from Table 2 . SGNS performs the best on the E NG A LL corpus , whereas SVD performs the best on COHA . Note : These results use an improved and corrected experimental protocol compared to earlier versions of this work . The general trends are consistent , but the ab - solute numbers for all methods are lower . See the Appendix for details , and please use these revised numbers for future comparisons . far the best on this task , with 70 % of its top - 10 list corresponding to genuine semantic shifts , followed by 40 % for SVD , and 10 % for PPMI . However , a large portion of the discovered words for PPMI ( and less so SVD ) correspond to bor - derline cases , e . g . know , that have not necessarily shifted signiﬁcantly in meaning but that occur in different contexts due to global genre / discourse shifts . The poor quality of the nearest neighbors generated by the PPMI algorithm—which are skewed by PPMI’s sensitivity to rare events—also made it difﬁcult to assess the quality of its discov - ered shifts . SVD was the most sensitive to corpus artifacts ( e . g . , co - occurrences due to cover pages and advertisements ) , but it still captured a number of genuine semantic shifts . We opted for this small evaluation set and re - lied on detailed expert judgments to minimize am - biguity ; each potential shift was analyzed in detail by consulting consulting existing literature ( espe - cially the OED ; Simpson et al . , 1989 ) and all dis - agreements were discussed . Table 5 details representative example shifts in Method Top - 10 words that changed from 1900s to 1990s PPMI know , got , would , decided , think , stop , remember , started , must , wanted SVD harry , headed , calls , gay , wherever , male , actually , special , cover , naturally SGNS wanting , gay , check , starting , major , actually , touching , harry , headed , romance Table 4 : Top - 10 English words with the highest semantic displacement values between the 1900s and 1990s . Bolded entries correspond to real semantic shifts , as deemed by examining the literature and their nearest neighbors ; for example , headed shifted from primarily referring to the “top of a body / entity” to referring to “a direction of travel . ” Underlined entries are borderline cases that are largely due to global genre / discourse shifts ; for example , male has not changed in meaning , but its usage in discussions of “gender equality” is relatively new . Finally , unmarked entries are clear corpus artifacts ; for example , special , cover , and romance are artifacts from the covers of ﬁction books occasionally including advertisements etc . Word Language Nearest - neighbors in 1900s Nearest - neighbors in 1990s wanting English lacking , deﬁcient , lacked , lack , needed wanted , something , wishing , anything , anybody asile French refuge , asiles , hospice , vieillards , in - ﬁrmerie demandeurs , refuge , hospice , visas , ad - mission widerstand German scheiterte , volt , stromst¨arke , leisten , brechen opposition , verfolgung , nationalsozialis - tische , nationalsozialismus , kollaboration Table 5 : Example words that changed dramatically in meaning in three languages , discovered using SGNS embeddings . The examples were selected from the top - 10 most - changed lists between 1900s and 1990s as in Table 4 . In English , wanting underwent subjectiﬁcation and shifted from meaning “lacking” to referring to subjective ”desire” , as in “the education system is wanting” ( 1900s ) vs . ”I’ve been wanting to tell you” ( 1990s ) . In French asile ( “asylum” ) shifted from primarily referring to “hospitals , or inﬁrmaries” to also referring to “asylum seekers , or refugees” . Finally , in German Widerstand ( “resistance” ) gained a formal meaning as referring to the local German resistance to Nazism during World War II . English , French , and German . Chinese lacks suf - ﬁcient historical data for this task , as only years 1950 - 1999 are usable ; however , we do still see some signiﬁcant changes for Chinese in this short time - period , such as 病 毒 ( “virus” ) moving closer to 电 脑 ( “computer” , ρ = 0 . 89 ) . 3 . 3 Methodological recommendations PPMI is clearly worse than the other two meth - ods ; it performs poorly on all the benchmark tasks , is extremely sensitive to rare events , and is prone to false discoveries from global genre shifts . Be - tween SVD and SGNS the results are somewhat equivocal , as both perform best on two out of the four tasks ( synchronic accuracy , E NG A LL detec - tion , COHA detection , discovery ) . Overall , SVD performs best on the synchronic accuracy task and has higher average accuracy on the ‘detection’ task , while SGNS performs best on the ‘discov - ery’ task . These results suggest that both these methods are reasonable choices for studies of se - mantic change but that they each have their own tradeoffs : SVD is more sensitive , as it performs well on detection tasks even when using a small dataset , but this sensitivity also results in false dis - coveries due to corpus artifacts . In contrast , SGNS is robust to corpus artifacts in the discovery task , but it is not sensitive enough to perform well on the detection task with a small dataset . Qualitatively , we found SGNS to be most useful for discovering new shifts and visualizing changes ( e . g . , Figure 1 ) , while SVD was most effective for detecting subtle shifts in usage . 4 Statistical laws of semantic change We now show how diachronic embeddings can be used in a large - scale cross - linguistic analysis to re - veal statistical laws that relate frequency and pol - ysemy to semantic change . In particular , we ana - lyze how a word’s rate of semantic change , ∆ ( t ) ( w i ) = cos - dist ( w ( t ) i , w ( t + 1 ) i ) ( 6 ) depends on its frequency , f ( t ) ( w i ) and a measure of its polysemy , d ( t ) ( w i ) ( deﬁned in Section 4 . 4 ) . 4 . 1 Setup We present results using SGNS embeddings . Us - ing all four languages and all four conditions for English ( E NG A LL , E NG F IC , and COHA with and without lemmatization ) , we performed regression analysis on rates of semantic change , ∆ ( t ) ( w i ) ; thus , we examined one data - point per word for each pair of consecutive decades and analyzed how a word’s frequency and polysemy at time t correlate with its degree of semantic displacement over the next decade . To ensure the robustness of Top - 10 most polysemous yet , always , even , little , called , also , sometimes , great , still , quite Top - 10 least polysemous photocopying , retrieval , thirties , mom , sweater , forties , seventeenth , ﬁfteenth , holster , postage Table 6 : The top - 10 most and least polysemous words in the E NG F IC data . Words like yet , even , and still are used in many diverse ways and are highly polysemous . In contrast , words like photocopying , postage , and holster tend to be used in very speciﬁc well - clustered contexts , corresponding to a single sense ; for example , mail and letter are both very likely to occur in the context of postage and are also likely to co - occur with each other , independent of postage . Figure 2 : Higher frequency words have lower rates of change ( a ) , while polysemous words have higher rates of change ( b ) . The plots show robust linear regression ﬁts ( Huber , 2011 ) with 95 % CIs on the 2000s decade of the COHA lemma data . our results , we analyzed only non - stop words that occurred more than 500 times in both decades con - tributing to a change ( lower - frequency words tend to lack sufﬁcient co - occurrence data across years ) . We also log - transformed the semantic displace - ment scores and normalized the scores to have zero mean and unit variance ; we denote these nor - malized scores by ˜∆ ( t ) ( w i ) . Though SGNS and SVD embeddings per - formed similarly in our evaluation tasks , we opted to use the SGNS embeddings since they provide a better estimate of the relationship between fre - quency and semantic change . With SVD embed - dings the effect of frequency is confounded by the fact that high frequency words have less ﬁnite - sample variance in their co - occurrence estimates , which makes the word vectors of high frequency words appear more stable between corpora , re - gardless of any real semantic change . The SGNS embeddings do not suffer from this issue because they are initialized with the embeddings of the pre - vious decade . 8 We performed our analysis using a linear mixed model with random intercepts per word and ﬁxed 8 In fact , the SGNS embeddings may even be biased in the other direction , since higher frequency words undergo more SGD updates “away” from this initialization . effects per decade ; i . e . , we ﬁt β f , β d , and β t s . t . ˜∆ ( t ) ( w i ) = β f log (cid:16) f ( t ) ( w i ) (cid:17) + β d log (cid:16) d ( t ) ( w i ) (cid:17) + β t + z w i + (cid:15) ( t ) w i ∀ w i ∈ V , t ∈ { t 0 , . . . , t n } , ( 7 ) where z w i ∼ N ( 0 , σ w i ) is the random intercept for word w i and (cid:15) ( t ) w i ∈ N ( 0 , σ ) is an error term . β f , β d and β t correspond to the ﬁxed effects for frequency , polysemy and the decade t , respec - tively 9 . Intuitively , this model estimates the effects of frequency and polysemy on semantic change , while controlling for temporal trends and correct - ing for the fact that measurements on same word will be correlated across time . We ﬁt ( 7 ) using the standard restricted maximum likelihood algorithm ( McCulloch and Neuhaus , 2001 ; Appendix C ) . 4 . 2 Overview of results We ﬁnd that , across languages , rates of semantic change obey a scaling relation of the form ∆ ( w i ) ∝ f ( w i ) β f × d ( w i ) β d , ( 8 ) with β f < 0 and β d > 0 . This ﬁnding implies that frequent words change at slower rates while pol - ysemous words change faster , and that both these relations scale as power laws . 9 Note that time is treated as a categorical variable , as each decade has its own ﬁxed effect . 4 . 3 Law of conformity : Frequently used words change at slower rates Using the model in equation ( 7 ) , we found that the logarithm of a word’s frequency , log ( f ( w i ) ) , has a signiﬁcant and substantial negative effect on rates of semantic change in all settings ( Figures 2a and 3a ) . Given the use of log - transforms in pre - processing the data this implies rates of semantic change are proportional to a negative power ( β f ) of frequency , i . e . ∆ ( w i ) ∝ f ( w i ) β f , ( 9 ) with β f ∈ [ − 1 . 24 , − 0 . 30 ] across lan - guages / datasets . 4 . 4 Law of innovation : Polysemous words change at faster rates There is a common hypothesis in the linguistic lit - erature that “words become semantically extended by being used in diverse contexts” ( Winter et al . , 2014 ) , an idea that dates back to the writings of Br´eal ( 1897 ) . We tested this notion by examining the relationship between polysemy and semantic change in our data . Quantifying polysemy Measuring word polysemy is a difﬁcult and fraught task , as even “ground truth” dictionaries differ in the number of senses they assign to words ( Simpson et al . , 1989 ; Fellbaum , 1998 ) . We cir - cumvent this issue by measuring a word’s contex - tual diversity as a proxy for its polysemousness . The intuition behind our measure is that words that occur in many distinct , unrelated contexts will tend to be highly polysemous . This view of pol - ysemy also ﬁts with previous work on semantic change , which emphasizes the role of contextual diversity ( Br´eal , 1897 ; Winter et al . , 2014 ) . We measure a word’s contextual diversity , and thus polysemy , by examining its neighborhood in an empirical co - occurrence network . We con - struct empirical co - occurrence networks for the top - 10 , 000 non - stop words of each language using the PPMI measure deﬁned in Section 2 . In these networks words are connected to each other if they co - occur more than one would expect by chance ( after smoothing ) . The polysemy of a word is then measured as its local clustering coefﬁcient within this network ( Watts and Strogatz , 1998 ) : d ( w i ) = − (cid:80) c i , c j ∈ N PPMI ( w i ) I { PPMI ( c i , c j ) > 0 } | N PPMI ( w i ) | ( | N PPMI ( w i ) | − 1 ) , ( 10 ) where N PPMI ( w i ) = { w j : PPMI ( w i , w j ) > 0 } . This measure counts the proportion of w i ’s neigh - bors that are also neighbors of each other . Accord - ing to this measure , a word will have a high clus - tering coefﬁcient ( and thus a low polysemy score ) if the words that it co - occurs with also tend to co - occur with each other . Polysemous words that are contextually diverse will have low clustering co - efﬁcients , since they appear in disjointed or unre - lated contexts . Variants of this measure are often used in word - sense discrimination and correlate with , e . g . , num - ber of senses in WordNet ( Dorow and Widdows , 2003 ; Ferret , 2004 ) . However , we found that it was slightly biased towards rating contextually diverse discourse function words ( e . g . , also ) as highly polysemous , which needs to be taken into account when interpreting our results . We opted to use this measure , despite this bias , because it has the strong beneﬁt of being clearly interpretable : it simply measures the extent to which a word ap - pears in diverse textual contexts . Table 6 gives ex - amples of the least and most polysemous words in the E NG F IC data , according to this score . As expected , this measure has signiﬁcant intrin - sic positive correlation with frequency . Across datasets , we found Pearson correlations in the range 0 . 45 < r < 0 . 8 ( all p < 0 . 05 ) , conﬁrm - ing frequent words tend to be used in a greater di - versity of contexts . As a consequence of this high correlation , we interpret the effect of this measure only after controlling for frequency ( this control is naturally captured in equation ( 7 ) ) . Polysemy and semantic change After ﬁtting the model in equation ( 7 ) , we found that the logarithm of the polysemy score exhibits a strong positive effect on rates of semantic change , throughout all four languages ( Figure 3b ) . As with frequency , the relation takes the form of a power law ∆ ( w i ) ∝ d ( w i ) β d , ( 11 ) with a language / corpus dependent scaling constant in β d ∈ [ 0 . 08 , 0 . 53 ] . The distribution of polysemy scores varies substantially across languages , so the Figure 3 : a , The estimated linear effect of log - frequency ( ˆ β f ) is signiﬁcantly negative across all languages . From the COHA data , we also see that the result holds regardless of whether lemmatization is used . b , Analogous trends hold for the linear effect of the polysemy score ( ˆ β d ) , which is signiﬁcantly positive across all conditions . The magnitudes of ˆ β f and ˆ β d vary signiﬁcantly across languages , indicating language - speciﬁc variation within the general scaling trends . 95 % CIs are shown . large range for this constant is not surprising . 10 Note that this relationship between polysemy and semantic change is a complete reversal from what one would expect according to d ( w i ) ’s pos - itive correlation with frequency ; i . e . , since fre - quency and polysemy are highly positively cor - related , one would expect them to have similar effects on semantic change , but we found that the effect of polysemy completely reversed after controlling for frequency . Figure 2b shows the relationship of polysemy with rates of semantic change in the COHA lemma data after regress - ing out effect of frequency ( using the method of Graham , 2003 ) . 5 Discussion We show how distributional methods can reveal statistical laws of semantic change and offer a ro - bust methodology for future work in this area . Our work builds upon a wealth of previous research on quantitative approaches to semantic change , including prior work with distributional methods ( Sagi et al . , 2011 ; Wijaya and Yeniterzi , 2011 ; Gulordava and Baroni , 2011 ; Jatowt and Duh , 2014 ; Kulkarni et al . , 2014 ; Xu and Kemp , 2015 ) , as well as recent work on detecting the emergence of novel word senses ( Lau et al . , 2012 ; Mitra et al . , 2014 ; Cook et al . , 2014 ; Mitra et al . , 2015 ; Frermann and Lapata , 2016 ) . We extend these lines of work by rigorously comparing dif - ferent approaches to quantifying semantic change and by using these methods to propose new statis - tical laws of semantic change . The two statistical laws we propose have strong implications for future work in historical seman - 10 For example , the E NG A LL polysemy scores have an ex - cess kurtosis that is 25 % larger than G ER A LL . tics . The law of conformity —frequent words change more slowly—clariﬁes frequency’s role in semantic change . Future studies of semantic change must account for frequency’s conforming effect : when examining the interaction between some linguistic process and semantic change , the law of conformity should serve as a null model in which the interaction is driven primarily by under - lying frequency effects . The law of innovation —polysemous words change more quickly—quantiﬁes the central role polysemy plays in semantic change , an issue that has concerned linguists for more than 100 years ( Br´eal , 1897 ) . Previous works argued that seman - tic change leads to polysemy ( Wilkins , 1993 ; Hop - per and Traugott , 2003 ) . However , our results show that polysemous words change faster , which suggests that polysemy may actually lead to se - mantic change . These empirical statistical laws also lend them - selves to various causal mechanisms . The law of conformity might be a consequence of learn - ing : perhaps people are more likely to use rare words mistakenly in novel ways , a mechanism for - malizable by Bayesian models of word learning and corresponding to the biological notion of ge - netic drift ( Reali and Grifﬁths , 2010 ) . Or per - haps a sociocultural conformity bias makes people less likely to accept novel innovations of common words , a mechanism analogous to the biological process of purifying selection ( Boyd and Richer - son , 1988 ; Pagel et al . , 2007 ) . Moreover , such mechanisms may also be partially responsible for the law of innovation . Highly polysemous words tend to have more rare senses ( Kilgarriff , 2004 ) , and rare senses may be unstable by the law of con - formity . While our results cannot conﬁrm such causal links , they nonetheless highlight a new role for frequency and polysemy in language change and the importance of distributional models in his - torical research . Acknowledgments The authors thank D . Friedman , R . Sosic , C . Man - ning , V . Prabhakaran , and S . Todd for their helpful comments and discussions . We also thank S . Tsut - sui for catching a typo in equation ( 4 ) , which is present in previous versions , and Astrid van Agge - len for catching transcription errors in previous versions of Tables 2 and 3 . We are also indebted to our anonymous reviewers . W . H . was supported by an NSERC PGS - D grant and the SAP Stanford Graduate Fellowship . W . H . , D . J . , and J . L . were supported by the Stanford Data Science Initiative , and NSF Awards IIS - 1514268 , IIS - 1149837 , and IIS - 1159679 . References James S . Adelman , Gordon D . A . Brown , and Jos ´ e F . Quesada . 2006 . Contextual diversity , not word fre - quency , determines word - naming and lexical deci - sion times . Psychol . Sci . , 17 ( 9 ) : 814 – 823 . Steven Bird , Ewan Klein , and Edward Loper . 2009 . Natural language processing with Python . O’Reilly Media , Inc . Andreas Blank . 1999 . Why do new meanings occur ? A cognitive typology of the motivations for lexical semantic change . In Peter Koch and Andreas Blank , editors , Historical Semantics and Cognition . Walter de Gruyter , Berlin , Germany . Robert Boyd and Peter J Richerson . 1988 . Culture and the Evolutionary Process . University of Chicago Press , Chicago , IL . Elia Bruni , Gemma Boleda , Marco Baroni , and Nam - Khanh Tran . 2012 . Distributional semantics in tech - nicolor . In Proc . ACL , pages 136 – 145 . Michel Br´eal . 1897 . Essai de S´emantique : Science des signiﬁcations . Hachette , Paris , France . John A . Bullinaria and Joseph P . Levy . 2007 . Ex - tracting semantic representations from word co - occurrence statistics : A computational study . Behav . Res . Methods , 39 ( 3 ) : 510 – 526 . John A . Bullinaria and Joseph P . Levy . 2012 . Ex - tracting semantic representations from word co - occurrence statistics : stop - lists , stemming , and SVD . Behav . Res . Methods , 44 ( 3 ) : 890 – 907 . J . L . Bybee . 2007 . Frequency of Use And the Organi - zation of Language . Oxford University Press , New York City , NY . Paul Cook , Jey Han Lau , Diana McCarthy , and Timo - thy Baldwin . 2014 . Novel Word - sense Identiﬁca - tion . In Proc . COLING , pages 1624 – 1635 . Scott Crossley , Tom Salsbury , and Danielle McNa - mara . 2010 . The development of polysemy and frequency use in english second language speakers . Language Learning , 60 ( 3 ) : 573 – 605 . Mark Davies . 2010 . The Corpus of Historical American English : 400 million words , 1810 - 2009 . http : / / corpus . byu . edu / coha / . Beate Dorow and Dominic Widdows . 2003 . Discov - ering corpus - speciﬁc word senses . In Proc . EACL , pages 79 – 82 . Christiane Fellbaum . 1998 . WordNet . Wiley Online Library . Olivier Ferret . 2004 . Discovering word senses from a network of lexical cooccurrences . In Proc . COL - ING , page 1326 . J . R . Firth . 1957 . A Synopsis of Linguistic Theory , 1930 - 1955 . In Studies in Linguistic Analysis . Spe - cial volume of the Philological Society . Basil Black - well , Oxford , UK . Lea Frermann and Mirella Lapata . 2016 . A Bayesian Model of Diachronic Meaning Change . Trans . ACL , 4 : 31 – 45 . Dirk Geeraerts . 1997 . Diachronic Prototype Se - mantics : A Contribution to Historical Lexicology . Clarendon Press , Oxford , UK . Michael H . Graham . 2003 . Confronting multi - collinearity in ecological multiple regression . Ecol - ogy , 84 ( 11 ) : 2809 – 2815 . Kristina Gulordava and Marco Baroni . 2011 . A dis - tributional similarity approach to the detection of semantic change in the Google Books Ngram cor - pus . In Proc . GEMS 2011 Workshop on Geometri - cal Models of Natural Language Semantics , pages 67 – 71 . Association for Computational Linguistics . Zellig S . Harris . 1954 . Distributional structure . Word , 10 : 146 – 162 . Paul J . Hopper and Elizabeth Closs Traugott . 2003 . Grammaticalization . Cambridge University Press , Cambridge , UK . Peter J Huber . 2011 . Robust statistics . Springer . Adam Jatowt and Kevin Duh . 2014 . A framework for analyzing semantic change of words across time . In Proc . ACM / IEEE - CS Conf . on Digital Libraries , pages 229 – 238 . IEEE Press . R . Jeffers and Ilse Lehiste . 1979 . Principles and Meth - ods for Historical Linguistics . MIT Press , Cam - bridge , MA . Adam Kilgarriff . 2004 . How dominant is the common - est sense of a word ? In Text , Speech and Dialogue , pages 103 – 111 . Springer . Yoon Kim , Yi - I . Chiu , Kentaro Hanaki , Darshan Hegde , and Slav Petrov . 2014 . Temporal analysis of language through neural language models . arXiv preprint arXiv : 1405 . 3515 . Vivek Kulkarni , Rami Al - Rfou , Bryan Perozzi , and Steven Skiena . 2014 . Statistically signiﬁcant de - tection of linguistic change . In Proc . WWW , pages 625 – 635 . Thomas K . Landauer and Susan T . Dumais . 1997 . A solution to Plato’s problem : The latent semantic analysis theory of acquisition , induction , and repre - sentation of knowledge . Psychol . Rev . , 104 ( 2 ) : 211 . Jey Han Lau , Paul Cook , Diana McCarthy , David New - man , and Timothy Baldwin . 2012 . Word sense in - duction for novel sense detection . In Proc . EACL , pages 591 – 601 . Omer Levy , Yoav Goldberg , and Ido Dagan . 2015 . Im - proving distributional similarity with lessons learned from word embeddings . Trans . ACL , 3 . Erez Lieberman , Jean - Baptiste Michel , Joe Jackson , Tina Tang , and Martin A . Nowak . 2007 . Quantify - ing the evolutionary dynamics of language . Nature , 449 ( 7163 ) : 713 – 716 . Yuri Lin , Jean - Baptiste Michel , Erez Lieberman Aiden , Jon Orwant , Will Brockman , and Slav Petrov . 2012 . Syntactic annotations for the google books ngram corpus . In Proc . ACL , System Demonstrations , pages 169 – 174 . Charles E McCulloch and John M Neuhaus . 2001 . Generalized linear mixed models . Wiley - Interscience , Hoboken , NJ . Jean - Baptiste Michel , Yuan Kui Shen , Aviva Presser Aiden , Adrian Veres , Matthew K . Gray , Joseph P . Pickett , Dale Hoiberg , Dan Clancy , Peter Norvig , Jon Orwant , and others . 2011 . Quantitative analysis of culture using millions of digitized books . Sci - ence , 331 ( 6014 ) : 176 – 182 . Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S . Cor - rado , and Jeff Dean . 2013 . Distributed representa - tions of words and phrases and their compositional - ity . In Advances in Neural Information Processing Systems , pages 3111 – 3119 . Sunny Mitra , Ritwik Mitra , Martin Riedl , Chris Bie - mann , Animesh Mukherjee , and Pawan Goyal . 2014 . That’s sick dude ! : Automatic identiﬁcation of word sense change across different timescales . In Proc . ACL . Sunny Mitra , Ritwik Mitra , Suman Kalyan Maity , Martin Riedl , Chris Biemann , Pawan Goyal , and Animesh Mukherjee . 2015 . An automatic ap - proach to identify word sense changes in text media across timescales . Natural Language Engineering , 21 ( 05 ) : 773 – 798 . Mark Pagel , Quentin D . Atkinson , and Andrew Meade . 2007 . Frequency of word - use predicts rates of lexical evolution throughout Indo - European history . Nature , 449 ( 7163 ) : 717 – 720 . Eitan Adam Pechenick , Christopher M . Danforth , and Peter Sheridan Dodds . 2015 . Characterizing the Google Books corpus : Strong limits to inferences of socio - cultural and linguistic evolution . PLoS ONE , 10 ( 10 ) . F . Reali and T . L . Grifﬁths . 2010 . Words as alle - les : connecting language evolution with Bayesian learners to models of genetic drift . Proc . R . Soc . B , 277 ( 1680 ) : 429 – 436 . Eyal Sagi , Stefan Kaufmann , and Brady Clark . 2011 . Tracing semantic change with latent semantic analy - sis . In Kathryn Allan and Justyna A . Robinson , edi - tors , Current Methods in Historical Semantics , page 161 . De Gruyter Mouton , Berlin , Germany . Peter H Sch ¨ onemann . 1966 . A generalized solution of the orthogonal Procrustes problem . Psychometrika , 31 ( 1 ) : 1 – 10 . J . S . Seabold and J . Perktold . 2010 . Statsmodels : Econometric and statistical modeling with python . In Proc . 9th Python in Science Conference . John Andrew Simpson , Edmund SC Weiner , et al . 1989 . The Oxford English Dictionary , volume 2 . Clarendon Press Oxford , Oxford , UK . Elizabeth Closs Traugott and Richard B Dasher . 2001 . Regularity in Semantic Change . Cambridge Univer - sity Press , Cambridge , UK . Peter D . Turney and Patrick Pantel . 2010 . From fre - quency to meaning : Vector space models of seman - tics . J . Artif . Intell . Res . , 37 ( 1 ) : 141 – 188 . S . Ullmann . 1962 . Semantics : An Introduction to the Science of Meaning . Barnes & Noble , New York City , NY . Laurens Van der Maaten and Geoffrey Hinton . 2008 . Visualizing data using t - SNE . Journal of Machine Learning Research , 9 ( 2579 - 2605 ) : 85 . Duncan J Watts and Steven H Strogatz . 1998 . Col - lective dynamics of ‘small - world’networks . Nature , 393 ( 6684 ) : 440 – 442 . Derry Tanti Wijaya and Reyyan Yeniterzi . 2011 . Un - derstanding semantic change of words over cen - turies . In Proc . Workshop on Detecting and Exploit - ing Cultural Diversity on the Social Web , pages 35 – 40 . ACM . David P Wilkins . 1993 . From part to person : Natu - ral tendencies of semantic change and the search for cognates . Cognitive Anthropology Research Group at the Max Planck Institute for Psycholinguistics . B . Winter , Graham Thompson , and Matthias Urban . 2014 . Cognitive Factors Motivating The Evolution Of Word Meanings : Evidence From Corpora , Be - havioral Data And Encyclopedic Network Structure . In Proc . EVOLANG , pages 353 – 360 . Yang Xu and Charles Kemp . 2015 . A computational evaluation of two laws of semantic change . In Proc . Annual Conf . of the Cognitive Science Society . Yang Xu , Terry Regier , and Barbara C . Malt . 2015 . Historical Semantic Chaining and Efﬁcient Commu - nication : The Case of Container Names . Cognitive Science . George Kingsley Zipf . 1945 . The meaning - frequency relationship of words . J . Gen . Psychol . , 33 ( 2 ) : 251 – 256 . Bahar ˙Ilgen and Bahar Karaoglan . 2007 . Investiga - tion of Zipf’s ‘law - of - meaning’on Turkish corpora . In International Symposium on Computer and Infor - mation Sciences , pages 1 – 6 . IEEE . A Hyperparameter and pre - processing details For all datasets , words were lowercased and stripped of punctuation . For the Google datasets we built models using the top - 100000 words by their average frequency over the entire histori - cal time - periods , and we used the top - 50000 for COHA . During model learning we also discarded all words within a year that occurred below a cer - tain threshold ( 500 for the Google data , 100 for the COHA data ) . For all methods , we used the hyperparameters recommended in Levy et al . ( 2015 ) . For the con - text word distributions in all methods , we used context distribution smoothing with a smoothing parameter of 0 . 75 . Note that for SGNS this cor - responds to smoothing the unigram negative sam - pling distribution . For both , SGNS and PPMI , we set the negative sample prior α = log ( 5 ) , while we set this value to α = 0 for SVD , as this improved results . When using SGNS on the Google data , we also subsampled , with words being random re - moved with probability p r ( w i ) = 1 − (cid:113) 10 − 5 f ( w i ) , as recommended by Levy et al . ( 2015 ) and Mikolov et al . ( 2013 ) . Furthermore , to improve the com - putational efﬁciency of SGNS ( which works with text streams and not co - occurrence counts ) , we downsampled the larger years in the Google N - Gram data to have at most 10 9 tokens . No such subsampling was performed on the COHA data . For all methods , we deﬁned the context set to simply be the same vocabulary as the target words , as is standard in most word vector applications ( Levy et al . , 2015 ) . However , we found that the PPMI method beneﬁted substantially from larger contexts ( similar results were found in Bullinaria and Levy , 2007 ) , so we did not remove any low - frequency words per year from the context for that method . The other embedding approaches did not appear to beneﬁt from the inclusion of these low - frequency terms , so they were dropped for compu - tational efﬁciency . For SGNS , we used the implementation pro - vided in Levy et al . ( 2015 ) . The implementations for PPMI and SVD are released with the code package associated with this work . B Visualization algorithm To visualize semantic change for a word w i in two dimensions we employed the following procedure , which relies on the t - SNE embedding method ( Van der Maaten and Hinton , 2008 ) as a subrou - tine : 1 . Find the union of the word w i ’s k nearest neighbors over all necessary time - points . 2 . Compute the t - SNE embedding of these words on the most recent ( i . e . , the modern ) time - point . 3 . For each of the previous time - points , hold all embeddings ﬁxed , except for the target word’s ( i . e . , the embedding for w i ) , and op - timize a new t - SNE embedding only for the target word . We found that initializing the embedding for the target word to be the cen - troid of its k (cid:48) - nearest neighbors in a time - point was highly effective . Thus , in this procedure the background words are always shown in their “modern” positions , which makes sense given that these are the current mean - ings of these words . This approximation is neces - sary , since in reality all words are moving . C Regression analysis details In addition to the pre - processing mentioned in the main text , we also normalized the contextual di - versity scores d ( w i ) within years by subtracting the yearly median . This was necessary because there was substantial changes in the median con - textual diversity scores over years due to changes in corpus sample sizes etc . We removed stop words using the available lists in Python’s NLTK package ( Bird et al . , 2009 ) . We follow Kim et al . ( 2014 ) and allow a buffer period for the historical word vectors to initialize ; we use a buffer period of four decades from the ﬁrst usable decade and only measure changes after this period . When analyzing the effects of frequency and contextual diversity , the model contained ﬁxed ef - fects for these features and for time along with random effects for word identity . We opted not to control for POS tags in the presented results , as contextual diversity is co - linear with these tags ( e . g . , adverbs are more contextual diverse than nouns ) , and the goal was to demonstrate the main effect of contextual diversity across all word types . To ﬁt the linear mixed models , we used the Python statsmodels package with re - stricted maximum likelihood estimation ( REML ) ( Seabold and Perktold , 2010 ) . All mentioned signiﬁcance scores were computed according to Wald’s z - tests . D Revisions to the methodology for “detecting known shifts” ( Table 3 ) The methodology for “detecting known shifts” has been improved to correct for certain issues , most prominently : • In earlier versions , the inclusion / exclusion of word pairs in particular time points based on frequency cutoffs was unnecessarily strict and not properly detailed . In the previous versions , we used the same cutoffs as for the analysis in Section 4 ( i . e . , frequencies had to be above 10 − 5 ) , but this was not clear in the text . In this revised version , we compute co - sine similarities for pairs of words in a time period if both are above the minimum count for the embedding construction ( 100 occur - rences for COHA and 500 for the E NG A LL corpus ) . This results in lower scores over - all but is more reﬂective of how downstream users make use of our embeddings and re - ﬂects the exact results one obtains by run - ning our off - the - shelf embeddings ( available on the project website ) through the evalua - tion . For time points where one of the words in a pair is below the threshold , we simply discard these time points from the Spearman correlation . • In earlier versions , Spearman correlations were computed for pairs with less than 5 time points . However , we now require at least 5 time points to have a minimum amount of ro - bustness . • In earlier versions , the SGNS model used the incorrect date for the start of the shift for the word gay . A script for replicating the numbers in Table 3 , using this revised methodology , is now available in the Github repo associated with this work . Note also that not all pairs in Table 2 are actually used for evaluation in all settings ( e . g . , for COHA , due to not having enough samples ) .