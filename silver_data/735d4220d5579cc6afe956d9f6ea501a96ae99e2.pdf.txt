Contributed Article On the momentum term in gradient descent learning algorithms Ning Qian 1 Center for Neurobiology and Behavior , Columbia University , 722 W . 168th Street , New York , NY 10032 , USA Received 4 November 1997 ; revised 6 August 1998 ; accepted 6 August 1998 Abstract A momentum term is usually included in the simulations of connectionist learning algorithms . Although it is well known that such a term greatly improves the speed of learning , there have been few rigorous studies of its mechanisms . In this paper , I show that in the limit of continuous time , the momentum parameter is analogous to the mass of Newtonian particles that move through a viscous medium in a conservative force ﬁeld . The behavior of the system near a local minimum is equivalent to a set of coupled and damped harmonic oscillators . The momentum term improves the speed of convergence by bringing some eigen components of the system closer to critical damping . Similar results can be obtained for the discrete time case used in computer simulations . In particular , I derive the bounds for convergence on learning - rate and momentum parameters , and demonstrate that the momentum term can increase the range of learning rate over which the system converges . The optimal condition for convergence is also analyzed . q 1999 Elsevier Science Ltd . All rights reserved . Keywords : Momentum ; Gradient descent learning algorithm ; Damped harmonic oscillator ; Critical damping ; Learning rate ; Speed of convergence 1 . Introduction Connectionist neural network models have been success - fully applied to a wide range of problems ( Rumelhart and McClelland , 1986 ; McClelland and Rumelhart , 1986 ; Anderson et al . , 1990 ; Churchland and Sejnowski , 1992 ) . Although there are many different varieties of learning algo - rithms available , the majority of them—including the popular back - propagation learning algorithm—are of the gradient descent type . For a given network architecture , one usually starts with an error function which is parame - terized by the weights ( the connection strengths between units ) in the network . The gradient of the error function with respect to each weight is then computed and the weights are modiﬁed along the downhill direction of the gradient in order to reduce the error . Let E ( w ) be the error function , where w is a vector representing all the weights in the network , the simplest gradient descent algorithm , known as the steepest descent , modiﬁes the weights at time step t according to : D w t ¼ ¹ e = w E ( w t ) ( 1 ) where = w represents the gradient operator with respect to the weights , and e is a small positive number known as the learning rate . It is well known that such a learning scheme can be very slow . The inclusion of a momentum term has been found to increase the rate of convergence dramatically ( Rumelhart et al . , 1986 ) . With this method , Eq . ( 1 ) takes the form : D w t ¼ ¹ e = w E ( w ) þ p D w t ¹ 1 ( 2 ) where p is the momentum parameter . That is , the modiﬁca - tion of the weight vector at the current time step depends on both the current gradient and the weight change of the pre - vious step . Intuitively , the rationale for the use of the momentum term is that the steepest descent is particularly slow when there is a long and narrow valley in the error function surface . In this situation , the direction of the gradient is almost perpendicular to the long axis of the valley . The system thus oscillates back and forth in the direction of the short axis , and only moves very slowly along the long axis of the valley . The momentum term helps average out the oscillation along the short axis while at the same time adds up contributions along the long axis ( Rumelhart et al . , 1986 ) . Other methods have also been proposed for improving the speed of convergence of gradient descent learning algo - rithms . For example , the conjugate gradient method has been shown to be superior to the steepest descent in most 0893 – 6080 / 99 / $ - see front matter q 1999 Elsevier Science Ltd . All rights reserved . PII : S0893 - 6080 ( 98 ) 00116 - 6 1 Tel . : þ 1 - 212 - 543 - 5213 ; Fax : þ 1 - 212 - 543 - 5161 ; E - mail : nq6 @ columbia . edu Neural Networks 12 ( 1999 ) 145 – 151 PERGAMON NeuralNetworks applications ( Press et al . , 1992 ) . However , the conjugate method requires more storage of intermediate results than the momentum method , and is non - local in the sense that the information needed to update a weight is not all contained in the pre - and post - synaptic units of the weight . This makes the algorithm less biologically plausible and harder to implement on hardware . In addition , the conjugate gradient method is less robust than the momentum method when the error surface is relatively ﬂat , and when it is very different from a quadratic form in most parts of the parameter space ( unpublished observations ) . Perhaps for these reasons , the momentum method appears to be dominant in the connec - tionist learning literature . In this paper , I attempt to mathe - matically analyze the effect of the momentum term on the speed of learning . I will ﬁrst demonstrate an analogy between the momentum term in gradient descent and the mass of Newtonian particles in a conservative force ﬁeld . This analogy will help us understand how the momentum term achieves its effect in the continuous time case . I will then examine the discrete time case used in computer simu - lations . Unlike the continuous time case , the discrete system is not guaranteed to converge to a minimum . I will derive the bounds for convergence on e and p , and demonstrate that the momentum term can increase the range of e over which the system converges . When p is close to one , e can be nearly doubled . The optimal condition for fastest conver - gence to a minimum is also analyzed . 2 . Physical analogy Consider the continuous version of the steepest descent d w d t ¼ ¹ e = w E ( w ) ( 3 ) where w is a continuous function of time instead of indexed by discrete time steps . Compare this equation with the Newtonian equation for a point mass m moving in a viscous medium with friction coefﬁcient m under the inﬂu - ence of a conservative force ﬁeld with potential energy E ( w ) : m d 2 w d t 2 þ m d w d t ¼ ¹ = w E ( w ) ( 4 ) where w is the coordinate vector of the particle . It is clear that Eq . ( 3 ) can be viewed as the special case of Eq . ( 4 ) for a massless particle . The above comparison between the steepest descent and the Newtonian equation prompts us to examine if the mass term in Eq . ( 4 ) could play some role in gradient descent . It turns out that Eq . ( 4 ) is equivalent to the continuous version of the momentum method speciﬁed by Eq . ( 2 ) . To demonstrate , we discretize Eq . ( 4 ) to obtain : m w t þ D t þ w t ¹ D t ¹ 2 w t D t 2 þ m w t þ D t ¹ w t D t ¼ ¹ = w E ( w ) ( 5 ) After rearrangements , we have : w t þ D t ¹ w t ¼ ¹ ( D t ) 2 m þ mD t = w E ( w ) þ m m þ mD t ( w t ¹ w t ¹ D t ) : ( 6 ) This equation is identical to Eq . ( 2 ) if we let the learning rate e and the momentum p be related to the friction coefﬁcient m and mass m according to : e ¼ ( D t ) 2 m þ mD t , ( 7 ) p ¼ m m þ mD t : ( 8 ) Therefore , the steepest descent with a momentum term is equivalent to a Newtonian particle moving through a viscous medium under the inﬂuence of a conservative force ﬁeld . Note that p ¼ 0 implies m ¼ 0 and vice versa according to Eq . ( 8 ) . Thus , the momentum parameter plays the role of mass . 3 . Stability and convergence analyses 3 . 1 . Continuous time case The analogy between the momentum method and the Newtonian mechanics discussed in the previous section also establishes that the momentum method is stable in the continuous time case and is guaranteed to converge to a local minimum for any positive m and m ( or equivalently , e and p ) . This is because the total energy of the system E T ¼ 12 m d w T d t d w d t þ E ( w ) ( 9 ) is a Liapunov function that monotonically decreases due to the presence of friction . Without the momentum term the potential energy E ( w ) is the error function being minimized . With the momentum term the total energy E T is the new error function . The two error functions become identical towards the end of training because at the ﬁnal equilibrium state the weight vector w will cease to change ( or equiva - lently the velocity of the particle will become zero ) . How does the momentum term speed up the convergence of the system to a local minimum ? To understand this , we expand the potential energy in Eq . ( 4 ) around a minimum at w 0 to obtain : m d 2 w d t 2 þ m d w d t < ¹ H ( w ¹ w 0 ) ( 10 ) where H ( the Hessian ) is a symmetric and positive deﬁnite matrix with the elements : h i , j ¼ ] 2 E ( w ) ] w i ] w j l w 0 ( 11 ) and the ﬁrst order derivatives of E ( w ) are omitted because 146 N . Qian / Neural Networks 12 ( 1999 ) 145 – 151 they vanish at the minimum . Eq . ( 10 ) represents a set of coupled and damped harmonic oscillators , with all the oscil - lators having the same mass m and damping coefﬁcient m . The coupling between them is determined by the H matrix . Without loss of generality , we let w 0 ¼ 0 in the following discussion ( w 0 can always be eliminated with the substitu - tion ( w ¹ w 0 ) ! w ) . Since H is symmetric and positive deﬁnite , it can always be diagonalized with an orthogonal matrix Q through a similarity transformation : H ¼ QKQ T , QQ T ¼ I ( 12 ) where K is a diagonal matrix with positive entries : K ¼ k 1 k 2 ] k n 0 BBBBB @ 1 CCCCCA ( k i . 0 ) , ( 13 ) k i s are the eigenvalues of H , and n is the number of oscilla - tors ( or equivalently , the number of weights ) . Using the transformation : w 9 ¼ Q T w , ( 14 ) Eq . ( 10 ) can now be written as a set of uncoupled and damped oscillators : m d 2 w 9 d t 2 þ m d w 9 d t ¼ ¹ K w 9 ( 15 ) We can now consider each oscillator separately . The i th oscillator is governed by : m d 2 w 9 i d t 2 þ m d w 9 i d t ¼ ¹ k i w 9 i ( 16 ) with k i as the spring constant . Under the special case of no momentum term , which is equivalent to setting m ¼ 0 , the solution of Eq . ( 16 ) is simply : w 9 i ( t ) ¼ ce l i , 0 t ( 17 ) where c is a constant and l i , 0 ¼ ¹ k i m : ( 18 ) Obviously , different w 9 i will converge at a different rate determined by k i , and the one corresponding to the smallest k i will have the slowest speed . Since w is a linear combina - tion of w 9 , the convergence of w will be limited by the smallest k i in the system . To see how the momentum term helps speed up the con - vergence , note that when m (cid:222) 0 , the general solution of Eq . ( 16 ) becomes : w 9 i ( t ) ¼ c 1 e l i , 1 t þ c 2 e l i , 2 t ( 19 ) where c 1 and c 2 are constants , and the eigenvalues l i , 1 and l i , 2 are given by : l i , 12 (cid:8) (cid:9) ¼ ¹ m 2 m 6 (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) m m m 4 m ¹ k i m (cid:18) (cid:19) : s ( 20 ) Since m , m and k i are all positive , the real parts of the two eigenvalues are always negative so that the convergence of the system is ensured . For a given w 9 i , the speed of its convergence is determined by the magnitudes of the real parts of the eigenvalues , with larger magnitudes correspond - ing to faster convergence . It is easy to show that l Re l i , 1 l # l Re l i , 2 l , ( 21 ) and the equality holds when the square root in Eq . ( 20 ) is zero or imaginary . Therefore , the speed of convergence of w 9 i is limited by l Re l i , 1 l . To see the effect of the momentum term , we need to compare l Re l i , 1 l with l Re l i , 0 l ¼ l l i , 0 l ¼ k i = m : The following result , which is proved in Appendix A , provides the condition under which the momentum term improves the speed of convergence . Result 1 : For positive m , m and k i , the inequality l Re l i , 1 l . Re l i , 0 l ( 22 ) holds , and therefore the momentum term improves conver - gence , if and only if k i , m 2 2 m ( 23 ) That is , given m and m , for those k i s satisfying Inequality ( 23 ) , the momentum term improves the convergence of the corresponding w 9 i s . The convergence of the remaining w 9 i s is not improved or slowed down . Therefore , to achieve an overall improvement , m and m should be chosen such that Inequality ( 23 ) is satisﬁed for the majority of k i s . To quantify the degree of improvement , we deﬁne a positive parameter a according to : l Re l i , 1 l ; a l Re l i , 0 l ¼ a k i m : ( 24 ) Obviously , an a larger than 1 indicates improvement of convergence , and larger a means greater improvement . We prove the following result in Appendix A . Result 2 . a reaches the maximum value of 2 , and therefore the momentum term is most effective , when k i ¼ m 2 4 m : ( 25 ) More speciﬁcally , a increases monotonically from 1 to 2 when k i increases from a very small value to m 2 / 4m . It then decreases monotonically from 2 to 1 when k i increases from m 2 / 4m to m 2 / 2m . Finally , when k i is larger than m 2 / 2m , a is smaller than 1 and decreases monotonically to 0 . Thus , given m and m , the best convergence improvements 147 N . Qian / Neural Networks 12 ( 1999 ) 145 – 151 are for those w 9 i s whose k i s are near the value speciﬁed by Eq . ( 25 ) , at the middle of the range allowed by Inequality ( 23 ) . Eq . ( 25 ) is known as the critical damping condition for damped harmonic oscillators in physics ( Kleppner and Kolenkow , 1973 ) . Smaller k i s correspond to the so - called heavy damping condition where a relatively weak spring slowly pulls the oscillator , without oscillation along the way , to its equilibrium condition through a very viscous medium . Larger k i s correspond to the light damping condi - tion where a strong spring quickly pulls the oscillator to its equilibrium position , overshoots , and oscillates back and forth , through a relatively less viscous medium , resulting in an overall slow settlement . The critical damping condi - tion is right at the interface between these two cases , and it allows the fastest return of the oscillator to its equilibrium position . It is thus not surprising that the critical damping condition provides the best convergence improvement for the gradient descent learning algorithm . When k i is small , a ﬁrst order expansion of Eq . ( 19 ) shows that l i , 1 < l i , 0 at this limit . That is , small k i is similar to the no momentum case . Therefore , without the momentum term the system behaves like heavy damping . The momentum term speeds up learning by bringing some eigen components of the system closer to the critical damping . 3 . 2 . Discrete case While the above results of the continuous case give a clear physical picture of the effect of the momentum term , computer simulations are necessarily discrete . We investi - gate how the momentum term works in the discrete case in this section . Eq . ( 6 ) near a local minimum becomes : w t þ 1 ¼ [ ( 1 þ p ) I ¹ e H ] w t ¹ p w t ¹ 1 : ( 26 ) Similar to the continuous case , this set of equations can be decoupled by diagonalizing H using Eqs . ( 12 ) – ( 14 ) to obtain : w 9 t þ 1 ¼ [ ( 1 þ p ) I ¹ e H ] w 9 t ¹ p w 9 t ¹ 1 : ( 27 ) We can now consider each of the equations separately , with the i th equation given by : w 9 i , t þ 1 ¼ [ 1 þ p ¹ e k i ] w 9 i , t ¹ pw 9 i , t ¹ 1 : ( 28 ) Supplying the dummy equation w 9 i , t ¼ w 9 i , t , we can rewrite the equation in matrix form : w 9 i , t w 9 i , t þ 1 ! ¼ A w 9 i , t ¹ 1 w 9 i , t ! ¼ A t w 9 i , 0 w 9 i , 1 ! , ( 29 ) where the matrix A is given by : A ¼ 0 1 ¹ p 1 þ p ¹ e k i ! : ( 30 ) The convergence of w 9 i is determined by the eigenvalues of matrix A : l i , 12 (cid:8) (cid:9) ¼ 1 þ p ¹ e k i 6 (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p ¹ e k i ) 2 ¹ 4 p p 2 : ( 31 ) To ensure convergence , we require l l i , 1 l , 1 and l l i , 2 l , 1 , or equivalently : Max ( l l i , 1 l , l l i , 2 l ) , 1 : ( 32 ) We prove the following result in Appendix A . Result 3 : Max ( l l i , 1 l , l l i , 2 l ) , 1 , and therefore the system described by Eq . ( 28 ) converges , if and only if ¹ 1 , p , 1 and 0 , e k i , 2 þ 2 p . Fig . 1 . Using Eq . ( 31 ) , Max ( l l i , 1 l , l l i , 1 l ) is plotted as a function of p and e k i . The shaded area has values less than 1 , and therefore corresponds to the parameter range for convergence . It has the triangular shape predicted by Result 3 . 148 N . Qian / Neural Networks 12 ( 1999 ) 145 – 151 A graphical demonstration of this result is shown in Fig . 1 . Without the momentum term ( p ¼ 0 ) , the condition for convergence of w 9 i becomes 0 , e k i , 2 . When positive p is used , the range of learning rate e that ensures convergence clearly increases with p . Since p can be almost as large as 1 , the parameter range of convergence can be nearly doubled . It is interesting to note that in most simulations of connec - tionist learning algorithms , the p values were indeed chosen to be close to 1 , typically around 0 . 9 ( for examples see Rumelhart et al . , 1986 ; Qian and Sejnowski , 1988 , 1989 ) . Also note that unlike the continuous case , the system is not guaranteed to converge for any positive values of e , p and k i . Similar to the continuous case , we are also interested in ﬁnding out how the rate of convergence is affected by the momentum term . It is easy to show from Eq . ( 28 ) that with - out the momentum term ( p ¼ 0 ) , the convergence speed of w 9 i is determined by : l i , 0 ¼ 1 ¹ e k i ( 33 ) Obviously , if both l l i , 1 l and l l i , 2 l are smaller than l l i , 0 l then the momentum term speeds up the convergence of w 9 i ; if one of them is larger than l l i , 0 l , then the convergence is slowed down . To avoid tedious calculations with compli - cated inequalities , we consider the special case of small e typically used in simulations , and expand l in Eq . ( 31 ) to obtain : l i , 12 (cid:8) (cid:9) < 1 ¹ e k i 1 ¹ p , p 1 þ e k i 1 ¹ p (cid:18) (cid:19) : 8 > > > < > > > : ( 34 ) Both are positive for small e k i . For ¹ 1 , p , 0 , we have l i , 1 . l i , 0 and therefore the momentum term slows down the convergence for negative p . On the other hand , for 0 , p , 1 , we have l i , 1 , l i , 0 . We will also have l i , 2 , l i , 0 if p , 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k i p . Therefore , when 0 , p , 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k i p , the momentum term speeds up convergence . It is easy to see from Eq . ( 34 ) that when p increases , l i , 1 decreases while l i , 2 increases . The best convergence speed is achieved when l i , 1 ¼ l i , 2 . Using the original Eq . ( 31 ) we ﬁnd that the best p value is given by p ¼ 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k i p (cid:16) (cid:17) 2 ( 35 ) for small e k i , and the corresponding eigenvalues are l i , 12 (cid:8) (cid:9) ¼ 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k i p , l i , 0 : ( 36 ) One might argue that if e k i is not restricted to be small then the best convergence speed could be achieved by excluding the momentum term ( p ¼ 0 ) , and by setting e k i ¼ 1 so that l i , 0 ¼ 0 . The problem is that there are n ( the number of weights in the network ) k i s for a given local minimum and they can be of very different magnitudes . To ensure convergence for all w 9 i s , e has to be smaller than 2 = Max ( k i ) . This results in small e k i for most k i s . We have shown above that the momentum term can not only increase the speed of convergence for small e k i , but can also nearly double the parameter range for convergence . 4 . Discussion In this paper we demonstrated an equivalence between the momentum parameter in the gradient descent learning algorithms and the mass of Newtonian particles that move through a viscous medium under a conservative force ﬁeld . The behavior of gradient descent near a local minimum is equivalent to a set of coupled and damped harmonic oscil - lators . Within a reasonable parameter range , the momentum term can improve the speed of convergence for most eigen components in the system by bringing them closer to critical damping . For the discrete time case , the momentum term provides the additional beneﬁt of nearly doubling the para - meter range over which the system converges . The optimal choice of the momentum and learning - rate parameters for the i th eigen component ( w 9 i ) in both the continuous and discrete time cases ( see Eqs . ( 23 ) and ( 35 ) ) depends on the value of k i , which characterizes the i th canonical dimension of the error surface . Since for a given local minimum the k i s characterizing the minimum can cover a wide range of values , it is impossible to make the near optimal choice for all w 9 i s at the same time . One strategy might be to use different momentums and learning rates for different weights ( w i ) in the network , resulting in momentum and learning rate matrices . This approach has been found to speed up training ( Jacobs , 1988 ) . However , it may be limited by the fact that each w i is a linear combina - tion of all w 9 i . The convergence of each w i , therefore , depends on all k i s , and no single optimal set of parameters can be chosen for w i . Obviously , one should ﬁrst decouple the weights by rotat - ing w into the eigenspace of the Hessian H ( see Eq . ( 14 ) ) and then use Eq . ( 25 ) or Eq . ( 35 ) to determine the optimal training parameters for each eigencomponent separately . However , this is practically impossible to do because of the huge size of H for networks with large numbers of weights . Diagonal approximation of H , which neglects all off - diagonal terms , has been found to be adequate in the Optimal Brain Damage ( OBD ) algorithm for removing unimportant weights ( LeCun et al . , 1990 ) . Under this approximation , we have k i ¼ h i , i , Q ¼ I , and the weights are still left coupled . It is an empirical question whether the k i s so determined can be used effectively in Eq . ( 25 ) or Eq . ( 35 ) for choosing training parameters . An afﬁrmative answer would allow an integration of these equations into the OBD algorithm to improve the rate of convergence with - out much extra computational cost . An alternative approach for speeding up training would be to use a single set of momentum and learning - rate para - meters for all the weights in the network , but to let them step through ordered sets of values over time during training . A 149 N . Qian / Neural Networks 12 ( 1999 ) 145 – 151 few iterations at each parameter set would quickly converge those w 9 i components in all w i s whose k i s approximately satisfy the optimal condition . Different w 9 i components would be converged at different times . Acknowledgements The author is supported by NIH grant # MH54125 and a Sloan Research Fellowship . Appendix A Proof of Results 1 and 2 First , consider the case when 0 , k i # m 2 4 m : ( A1 ) Under this condition , both l i , 1 and l i , 2 of Eq . ( 20 ) are negative real numbers . It is easy to show that : ¹ l i , 1 . ¹ l i , 0 ( A2 ) and therefore Inequality ( 22 ) holds . According to the deﬁni - tion of a in Eq . ( 24 ) , we have m 2 m ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) m m m 4 m ¹ k i m (cid:18) (cid:19) s ¼ a k i m : ( A3 ) Since it is straightforward to verify that m 2 m ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) m m m 4 m ¹ k i m (cid:18) (cid:19) s . k i m ( A4 ) and m 2 m ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) m m m 4 m ¹ k i m (cid:18) (cid:19) s # 2 k i m ( A5 ) we have 1 , a # 2 : ( A6 ) Rearranging Eq . ( A3 ) to obtain : mk i m 2 a 2 ¹ a þ 1 ¼ 0 ( A7 ) we see that when k i ! 0 , a ! 1 ; and when k i ¼ m 2 = 4 m , a ¼ 2 . To demonstrate that a increases mono - tonically for k i in the interval ( 0 , m 2 = 4 m ] , note that ] a ] k i ¼ a 2 mk i m 2 ¹ 2 a mk i . 0 ( A8 ) because m 2 ¹ 2 a mk i $ m 2 ¹ 4 mk i . 0 : ( A9 ) Next consider the case when m 2 4 m , k i , m 2 2 m ( A10 ) Under this condition , both l i , 1 and l i , 2 are complex with negative real parts equal to ( ¹ m = 2 m ) . Therefore , l Re l i , 2 l ¼ l Re l i , 1 l ¼ m 2 m . k i m ¼ l l i , 0 l ( A11 ) and therefore Inequality ( 22 ) holds . According to the deﬁni - tion of a in Eq . ( 24 ) , we have m 2 m ¼ a k i m ( A12 ) Obviously , a decreases monotonically from 2 to 1 for k i in the interval [ m 2 = 4 m , m 2 = 2 m ] . The above considerations establish the sufﬁcient condi - tion for Result 1 . To prove the necessary condition , we ﬁnally consider the remaining case k i $ m 2 2 m ( A13 ) Again , both l i , 1 and l i , 2 are complex with a negative real part equal to ( ¹ m = 2 m ) . Therefore , l Re l i , 2 l ¼ l Re l i , 1 l ¼ m 2 m , k i m ¼ l l i , 0 l ( A14 ) and Inequality ( 22 ) does not hold . Eq . ( A12 ) remains valid here and it indicates that a decreases monotonically from 1 to 0 for k i in the interval [ m 2 = 2 m , ‘ ) . Appendix B Proof of Result 3 For clarity we drop the subscript i for l and k . We system - atically examine the magnitudes of l 1 and l 2 under all possible conditions . We ﬁrst show that the condition e k i . 0 is required for convergence . Assume e k i # 0 . Then , l 1 ¼ 1 þ p þ l e k l þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p þ l e k l ) 2 ¹ 4 p p 2 $ 1 þ p þ l e k l þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p ) 2 ¹ 4 p p 2 ¼ 1 þ p þ l e k l þ l 1 ¹ p l 2 $ 1 ð A15 Þ The last step is obvious by considering p , 1 and p $ 1 separately . Thus , the convergence of the system requires e k i . 0 . This means the learning rate e should be positive because by deﬁnition k i is always positive . Let D ; ( 1 þ p ¹ e k ) 2 ¹ 4 p ( A16 ) in Eq . ( 31 ) . It can be shown that D $ 0 when p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 or p $ ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , and that D , 0 when ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , p , ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 . We consider these cases of D $ 0 and D , 0 separately . I . D $ 0 Under this condition , l 1 , 2 are real . We further divide this 150 N . Qian / Neural Networks 12 ( 1999 ) 145 – 151 case into two sub - cases corresponding to the two conditions that ensure D $ 0 . A . p $ ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 Under this condition , we have 1 þ p ¹ e k $ 1 þ ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 ¹ e k ¼ 2 þ 2 (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p . 0 . This implies that l 1 , 2 . 0 and l 1 $ l 2 . The convergence of the system requires l 1 ¼ 1 þ p ¹ e k þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p ¹ e k ) 2 ¹ 4 p p 2 , 1 , ( A17 ) which reduces to : (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p ¹ e k ) 2 ¹ 4 p q , 1 ¹ p þ e k : ( A18 ) However , the right - hand side 1 ¹ p þ e k # 1 ¹ ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 þ e k ¼ ¹ 2 (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p # 0 while the left side is greater or equal to zero . This contradiction leads to the conclusion that : If p $ ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , the system diverges . B . p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 We further divide this subcase into two for the purpose of proof . a . 1 þ p ¹ e k $ 0 Under these conditions we also have l 1 , 2 . 0 and l 1 $ l 2 . Eq . ( A17 ) gives the stability condition , which leads to the requirements e k . 0 , which is already stated , and 1 ¹ p þ e k . 0 , which is satisﬁed because 1 ¹ p þ e k $ 1 ¹ ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 þ e k ¼ 2 (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p . 0 . We con - clude that : if p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 and 1 þ p ¹ e k $ 0 and e k . 0 , the system converges . It can be shown that these conditions also imply j p j , 1 . First , p $ e k ¹ 1 . ¹ 1 . To show p , 1 , assume the opposite that p $ 1 . Then ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 $ p $ 1 . This leads to e k $ 4 . Using this result , ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 $ p becomes (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ¹ 1 $ (cid:129)(cid:129)(cid:129) p p , or e k $ 1 þ p þ 2 (cid:129)(cid:129)(cid:129) p p . This contradicts the assumption e k , 1 þ p . Therefore , p # 1 . The results can be summarized as : If p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , j p j , 1 , and 0 , e k # 1 þ p , the system converges . b . 1 þ p ¹ e k # 0 In this case , l 1 , 2 # 0 and j l 2 j $ j l 1 j . Stability now requires : l 2 ¼ 1 þ p ¹ e k ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p ¹ e k ) 2 ¹ 4 p p 2 . ¹ 1 ( A19 ) which reduces to (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) ( 1 þ p ¹ e k ) 2 ¹ 4 p q , 3 þ p ¹ e k : ( A20 ) This is turn leads to the requirements 3 þ p ¹ e k . 0 and 2 þ 2 p ¹ e k . 0 . We conclude that if p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , 1 þ p ¹ e k # 0 , 3 þ p ¹ e k . 0 and 2 þ 2 p ¹ e k . 0 , the sys - tem converges . Similar to the case above , the conditions also imply l p l , 1 . To see this , ﬁrst note that 1 þ p # e k , 2 þ 2 p , or p . ¹ 1 . To show p , 1 , assume the opposite p $ 1 . Then e k $ 1 þ p $ 2 . Consequently , p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 implies (cid:129)(cid:129)(cid:129) p p # (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ¹ 1 . Combining this with e k , 3 þ p gives p , 1 , a contradiction . Therefore , p , 1 . Because the condition 3 þ p ¹ e k . 0 is contained in the condition 2 þ 2 p ¹ e k . 0 when l p l , 1 , we can simplify the convergence requirements to : If p # ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , j p j , 1 and 1 þ p # e k , 2 þ 2 p , the system converges . II . D # 0 This occurs when ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , p , ( 1 þ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 . Both l 1 and l 2 are complex in this case . Eq . ( 31 ) becomes : l 1 , 2 ¼ 1 þ p ¹ e k 6 i (cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129)(cid:129) 4 p ¹ ( 1 þ p ¹ e k ) 2 p 2 : ( A21 ) Stability requires that l l 1 , 2 l ¼ (cid:129)(cid:129)(cid:129) p p , 1 , or p , 1 . We con - clude that if ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , p , 1 , the system converges . For p to have a solution , we require ( 1 ¹ (cid:129)(cid:129)(cid:129)(cid:129)(cid:129) e k p ) 2 , 1 , or 0 , e k , 4 . Combining all of the above cases together , we arrive at the conclusion that if l p l , 1 and 0 , e k , 2 þ 2 p the sys - tem converges . Since we have exhaustively considered all possible cases in the above derivations , this is not only the sufﬁcient condition but also the necessary condition for convergence . References Anderson , J . A . , Pellionisz , A . , & Rosenﬁeld , E . ( Eds . ) , ( 1990 ) . Neuro - computing 2 : directions for research . Cambridge , MA : MIT Press . Churchland , P . S . , & Sejnowski , T . J . ( 1992 ) . The computational brain . Cambridge , MA : MIT Press . Jacobs , R . A . ( 1988 ) . Increased rates of convergence through learning rate adaptation . Neural Networks , 1 , 295 – 307 . Kleppner , D . , & Kolenkow , R . J . ( 1973 ) . An introduction to mechanics . New York : McGraw - Hill . LeCun , Y . , Denker , J . S . , & Solla , S . A . ( 1990 ) . Optimal brain damage . In D . S . Touretzky ( Ed . ) , Advances in neural information processing systems 2 ( NIPS * 89 ) ( pp . 598 – 605 ) . Denver , CO : Morgan Kaufman . McClelland , J . L . , & Rumelhart , D . E . ( 1986 ) . Parallel distributed proces - sing ( Vol . 2 ) . Cambridge , MA : MIT Press . Press , W . H . , Teukolsky , S . A . , Vetterling , W . T . , & Flannery , B . P . ( 1992 ) . Numerical recipes in C . Cambridge , UK : Cambridge University Press . Qian , N . , & Sejnowski , T . J . ( 1988 ) . Predicting the secondary structure of globular proteins using neural network models . J . Mol . Biol . , 202 , 865 – 884 . Qian , N . , & Sejnowski , T . J . ( 1989 ) . Learning to solve random - dot stereo - grams of dense and transparent surfaces with recurrent backpropaga - tion . In D . S . Touretzky , G . E . Hinton , & T . J . Sejnowski ( Eds . ) , Proceedings of the 1988 Connectionist Models Summer School ( pp . 435 – 443 ) . San Mateo , CA : Morgan Kaufmann . Rumelhart , D . E . , & McClelland , J . L . ( 1986 ) . Parallel distributed proces - sing ( Vol . 1 ) . Cambridge , MA : MIT Press . Rumelhart , D . E . , Hinton , G . E . , & Williams , R . J . ( 1986 ) . Learning internal representations by error propagation . In D . E . Rumelhart , & J . L . McClelland ( Eds . ) , Parallel distributed processing ( Vol . 1 , pp . 318 – 362 ) . Cambridge , MA : MIT Press . 151 N . Qian / Neural Networks 12 ( 1999 ) 145 – 151