Interdisciplinary Journal of Problem - Based Learning Volume 3 Issue 1 Special Issue on the Efficacy of Problem - based Learning Article 4 Published online : 3 - 24 - 2009 When is PBL More Effective ? A Meta - synthesis of Meta - analyses Comparing PBL to Conventional Classrooms Johannes Strobel Purdue University , Indiana , USA , strobelj @ missouri . edu Angela van Barneveld Concordia University , Montreal , Canada IJPBL is Published in Open Access Format through the Generous Support of the Teaching Academy at Purdue University , the School of Education at Indiana University , and the Educational Technology program at the University of South Carolina . This document has been made available through Purdue e - Pubs , a service of the Purdue University Libraries . Please contact epubs @ purdue . edu for additional information . This is an Open Access journal . This means that it uses a funding model that does not charge readers or their institutions for access . Readers may freely read , download , copy , distribute , print , search , or link to the full texts of articles . This journal is covered under the CC BY - NC - ND license . Recommended Citation Strobel , J . , & van Barneveld , A . ( 2009 ) . When is PBL More Effective ? A Meta - synthesis of Meta - analyses Comparing PBL to Conventional Classrooms . Interdisciplinary Journal of Problem - Based Learning , 3 ( 1 ) . Available at : http : / / dx . doi . org / 10 . 7771 / 1541 - 5015 . 1046 Keywords : Eﬀectiveness , meta - synthesis , PBL http : / / dx . doi . org / 10 . 7771 / 1541 - 5015 . 1046 When is PBL More Eff ective ? 45 • volume 3 , no . 1 ( Spring 2009 ) & Mitchell , 1993 ; Vernon & Blake , 1993 ; Kalaian , Mullan , & Kasim , 1999 ; Dochy , Segers , Van den Bossche , & Gijbels , 2003 ; Newman , 2003 ; Gijbels , Dochy , Van den Bossche , & Segers , 2005 ) . Although defi ning PBL similarly , these studies were not consistent in their fi nd - ings , particularly because of diff erences in defi ning eff ectiveness of learning , and how eff ectiveness was measured . Purpose The purpose of this study was to synthesize the diff erent meta - analyses , compare and contrast diff erent conceptualizations of learning and how it was measured , and identify common and generalizable fi ndings across the meta - analyses with regard to the eff ec - tiveness of PBL . Our research questions were : 1 . How do diff erences in ( a ) the defi nition of learning and ( b ) the measurement of learning contribute to the inconclusiveness of the diff erent meta - analyses with regard to the eff ectiveness of PBL ? 2 . Taking the diff erences into consideration , what generalizable value statements about the eff ectiveness of PBL can be made and are supported by the majority of meta - analyses ? What is Problem - based Learning ? PBL in its current form originated as a response to low enrollments and general dissatis - faction with medical education ( Barrows , 1996 ) . Since its origin , PBL has been used in a variety of disciplines and educational levels ( see Savery [ 2006 ] for a history ; see Savery & Duff y [ 1996 ] for an introduction ; see Hung , Jonassen & Liu [ 2007 ] for a summary of the research ) . As Barrows ( 1996 ) noted , PBL has taken on a myriad of defi nitions , pushed in part by institutions wanting to refi ne their particular approach . Maudlsey ( 1999 ) cautioned us not to assume that those making use of the term , problem - based learning were all referring to the same concept , especially since the use of problems as a teaching strategy does not necessarily constitute a PBL - oriented instructional methodology . One of Barrows’ most recent defi nitions ( 2002 ) identifi ed the following key compo - nents of PBL : Ill - structured problems are presented as unresolved so that students will generate • not only multiple thoughts about the cause of the problem , but multiple thoughts on how to solve it . A student - centered approach in which students determine what they need to learn . • It is up to the learners to derive the key issues of the problems they face , defi ne their knowledge gaps , and pursue and acquire the missing knowledge . The Interdisciplinary Journal of Problem - based Learning • 46 Johannes Strobel and Angela van Barneveld Teachers act as facilitators and tutors , asking students the kinds of meta - cognitive • questions they want students to ask themselves . In subsequent sessions , guidance is faded . Authenticity forms the basis of problem selection , embodied by alignment to • professional or ‘real world’ practice . For our study , we were guided by the defi nition of problem - based learning put forth by Barrows , as described above , and by Savery ( 2006 ) who indicated that it is “an instructional ( and curricular ) learner - centered approach that empowers learners to con - duct research , integrate theory and practice , and apply knowledge and skills to develop a viable solution to a defi ned problem” ( p . 9 ) . In contrast to PBL , we considered traditional learning approaches to be large - class , instructor - driven , lecture - based deliveries within a curriculum , which compartmentalized the content ( e . g . , in medicine , the instruction would be broken down into pharmacology , anatomy etc . ) ( Barrows , 2002 ) . Methodology To answer our research questions about how the diff erences in the defi nitions and measurements of learning contribute to the inconclusiveness about the eff ectiveness of PBL , we conducted a meta - synthesis ( Bair , 1999 ) of existing meta - analyses . The goal was to determine which generalizable value statements about the eff ectiveness of PBL were supported by the majority of meta - analyses . A meta - synthesis is a qualitative methodology that uses both qualitative and quan - titative studies as data or unit of analysis . It is primarily “concerned with understanding and describing key points and themes contained within a research literature on a given topic” ( Bair , 1999 , p . 4 ) . Since we gave emphasis to the interpretation of data and to the understanding of the diff erences in the conceptualizations of what constitutes eff ective - ness in PBL , we opted not to do a meta - meta - analysis , which would have meant quanti - tatively synthesizing all eff ect sizes into a single one ( see Spitzer , 1991 , for an introduction to meta - meta - analysis ) . Rather , we chose a meta - synthesis approach because it allowed us to represent and account for diff erences in the conceptualizations and measurements of PBL eff ectiveness due to the qualitative orientation of the approach . According to Walsh and Downe ( 2005 ) , the steps of meta - synthesis include ( a ) search for articles , ( b ) make decision on inclusion , ( c ) appraise studies , ( d ) analyze studies includ - ing “translation” of diff erent conceptualizations and comparisons , and fi nally ( e ) synthesize fi ndings . While meta - syntheses are traditionally used to synthesize qualitative research fi ndings exclusively , Bair ( 1999 ) expanded the use to include the qualitative comparison of quantitative , qualitative , and mixed - method studies . When is PBL More Eff ective ? 47 • volume 3 , no . 1 ( Spring 2009 ) Sample and process of selection Our unit of analysis was a meta - analysis or systematic review . A meta - analysis is a process of quantitatively synthesizing research results by using various statistical methods to retrieve , select , and combine eff ect sizes and results from previously separate but related studies ( see Bernard , Abrami , Lou , & Borokhovski , 2004 , for a methodological discussion ) . Meta - analysis uses eff ect size as a metric for judging the magnitude of the standardized diff erence between a treatment and control condition in a large set of studies and may also be used to judge the magnitude of the relationship ( r 2 or R 2 ) between measured variables in a large set of studies ( see Leandro , 2005 , for more details ) . Four research databases , ERIC , PubMEd , PsychInfo , and Web of Science were searched using the terms problem - based learning ( in a variety of diff erent forms ) , PBL , and meta - analysis . The date parameter was set to include studies since 1992 ( the fi rst recorded meta - analysis for PBL that met the date parameter appeared in 1993 ) . Twenty - fi ve records that met these three broad search parameters were selected for an initial review . Abstracts were reviewed to ensure that articles met the additional criteria for inclusion , which were ( 1 ) a meta - analysis or a systematic literature review ( general term for studies that provide overviews of primary studies that used explicit and reproducible methods [ Greenhalgh , 1997 ] ) that assessed multiple studies and either calculated or reported eff ect sizes , ( 2 ) contained comparisons of the eff ectiveness of PBL versus traditional learning approaches , or ( 3 ) focused on individual outcome measures rather than program evaluation . This fi rst review of the 25 selected records resulted in eight studies that met the inclusion criteria— four meta - analyses and four systematic reviews . Then , the reference sections of those eight studies were reviewed in search of meta - analytical studies that may have been missed in the database searches . This resulted in fi nding two additional meta - analyses . Out of these ten studies , we excluded Norman and Schmidt ( 2000 ) , because it was a response to an existing meta - analysis without providing new data or newly analyzing existing data , and Smits , Verbeek , and De Buisonje ( 2002 ) , because the study did not compare traditional instruction to PBL - oriented training . The total number of studies included in this paper was eight meta - analyses and systematic reviews . The research base on the eff ectiveness of PBL is particularly rich and strong in the fi eld of medicine . Similarly well developed is assessment in the fi eld of medicine , which allows comparisons of diff erent instructional interventions on situated and standardized test environments . Not surprisingly , the meta - analyses dealing with PBL draw heavily from primary studies conducted in medicine , but contain studies from other domains ( e . g . , economy , computer science ) to warrant a rather generalizable statement on the eff ectiveness of PBL . The Interdisciplinary Journal of Problem - based Learning • 48 Johannes Strobel and Angela van Barneveld Analysis We looked for the reported quantitative fi ndings and the narrative description of results in the meta - analytic studies and synthesized , qualitatively , the fi ndings that assessed ef - fectiveness of PBL versus traditional approaches . Instead of predefi ning codes of eff ectiveness , we used an open - coding approach ( Denzin & Lincoln , 2005 ) whereby the selected codes were derived from the research stud - ies . We focused on the narrative reports of the fi ndings to evoke the codes . In alignment with our research questions , we sought categories that coded the conceptual defi nitions of learning linked to the measurement strategies and outcome patterns used to determine eff ectiveness of the teaching and learning approach . We focused on the interpretation of narrative and qualitative reporting to support our meta - synthesis approach . Two ad - ditional coding categories emerged . One addressed overall satisfaction with the learning experience , and the other included patient management , a mix of knowledge and skills beyond basic science knowledge and in - situ clinical performance . We created a correlation matrix that captured the measures of eff ectiveness and modifying variables reported in each study and the specifi c orientation of eff ect sizes ( positive or negative ) of each vari - able . After all the measures were identifi ed , we grouped them into categories based on similarity of measurement intent . To assist with the categorization , we made use of Dochy et al . ’s ( 2003 ) defi nitions that knowledge tests measured “the knowledge from facts and the meaning of concepts and principles” ( p . 537 ) and skill tests measured “to what extent students can apply their knowledge” ( p . 537 ) . We excluded data from our coding strategy if only one study reported results , and if results focused on program evaluation rather than individual learning outcomes . Finally , we looked for overall patterns in measures that tended to favor PBL , indicated by a positive eff ect size , and those that tended to favor traditional approaches to learning / teaching , indicated by a negative eff ect size . Details on meta - analysis and systematic reports With regard to defi nitions of PBL , the reported meta - analyses consistently employed a defi nition of PBL in congruence with Barrows ( 1996 ) and Savery ( 2006 ) , which guided the conceptual framework of this paper as well . Summarized here is an overview of each of the eight meta - analyses selected for this paper , describing the research questions , the selection criteria that the researchers employed , and the fi ndings . All of the meta - analyses included additional research ques - tions , which were not pertinent to our particular investigation , for example , the cost of PBL compared to traditional classrooms . We summarized only the research revolving around the eff ectiveness of PBL as a learning strategy compared to the traditional class - room approach . When is PBL More Eff ective ? 49 • volume 3 , no . 1 ( Spring 2009 ) Albanese and Mitchell ( 1993 ) focused on the English - language international litera - ture from 1972 to 1992 to gain insight into the eff ectiveness of PBL within the domain of medical education . They reviewed ten studies that provided data on outcome measures of basic science knowledge , measured by the National Board of Medicine Exam ( NBME 1 ) , and seven studies that reported outcome measures of clinical knowledge and perfor - mance ( NBME 2 ) . NBME 1 assesses understanding and application of important concepts of the sciences basic to the practice of medicine , with special emphasis on principles and mechanisms underlying health , disease , and modes of therapy . NBME 2 assesses applica - tion of medical knowledge , skills , and understanding of clinical science essential for the provision of patient care under supervision and includes emphasis on health promotion and disease prevention . Research questions by Albanese and Mitchell ( 1993 ) included : Do PBL students develop the cognitive scaff olding necessary to easily assimilate new basic sciences in - formation ? To what extent are PBL students exposed to an adequate range of content ? Does faculty dislike PBL because of the concentrated time commitment required ? Results of assessments of basic science knowledge indicated an overall negative eff ect size ( ES ) , meaning that students engaged in the traditional classroom learning approach tended to perform better on the standardized tests ( NBME 1 ) . The authors augmented the results with two additional points . The fi rst was that standardized examinations “have been criticized for providing only a measure of the examinee’s ability to recognize the correct answer from a limited list of potentially correct answers and of being heavily oriented toward recall” ( p . 56 ) . The second point was that , although the ES favored the traditional approach and the expectation was that PBL students would not perform as well in the area of basic science knowledge assessments , this assumption was “not always true” ( p . 57 ) . However , the authors took this tendency as evidence of support for inadequate cognitive scaff olding development on the part of PBL students , as well as support for the idea that PBL students may not have adequate exposure to a range of content . Interest - ingly , though , the results also indicated that PBL graduates did perceive that they were disadvantaged relative to their traditional learning counterparts . However , they viewed themselves as better prepared in self - directed learning skills , problem - solving , information gathering , and self - evaluation techniques . Results also indicated that the rates at which PBL graduates were selected for their fi rst choice residency positions were higher than for traditional program graduates . Vernon and Blake ( 1993 ) focused on 22 studies within the period from 1970 to 1992 . Their study selection parameters included all identifi able research on health - related educational programs that contained signifi cant PBL emphasis . That is , the studies used quantitative methods , provided data that compared PBL with more traditional educational methods , and measured outcomes that were of an evaluative nature . They excluded stud - ies that were only descriptive or provided no comparison of the two learning approaches , The Interdisciplinary Journal of Problem - based Learning • 50 Johannes Strobel and Angela van Barneveld PBL and traditional . The purpose of their research was to summarize all available data that compared PBL with more traditional education methods , to analyze variations via meta - analytic techniques , and to review perceived strengths and weaknesses of research in this fi eld . The results indicated that , in terms of academic achievement ( knowledge tests ) , the results for standardized NBME 1 assessment outcomes showed signifi cant trends favoring students engaged in the traditional learning approach . For clinical knowledge and per - formance outcomes ( NBME 2 ) , results slightly favored the PBL students , while assessment outcomes of clinical performance ( observation - based supervisor ratings ) signifi cantly favored the PBL students . Berkson ( 1993 ) did a narrative review of 10 pre - 1992 studies , seeking evidence of the eff ectiveness of the PBL curriculum in medical education . Her research questions included : Does PBL teach problem solving better than traditional schools ? Does PBL im - part knowledge better than traditional schools ? Does PBL enhance motivation to learn medical science better than traditional schools ? Does PBL promote self - directed learning ( SDL ) skills better than traditional schools ? Berkson’s review indicated that there was no evidence to suggest that a PBL approach taught problem solving better than the traditional approach . Results did not demonstrate an advantage of one approach over the other for imparting knowledge . However , results indicated that students and faculty favored PBL . In addition , academic achievement and knowledge assessment favored the traditional approach , while clinical assessments favored PBL . With regard to academic process , PBL students placed more emphasis on meaning ( understanding ) rather than reproduction ( memory ) , which was the opposite pattern from students engaged in traditional learning methods . Berkson concluded that it was unlikely students will suff er detrimental conse - quences from participation in PBL programs . Kalaian , Mullan , and Kasim ( 1999 ) focused on medical education studies from 1970 to 1997—22 studies on NBME 1 outcome measures , and 9 studies on NBME 2 outcome measures . The purpose of the research was to examine outcomes from primary research comparing impact of PBL and traditional curricula on NBME 1 and NBME 2 . The set of primary studies reviewed included studies examined by previous reviews , augmented through online searches for studies within the 1970 to 1997 time parameter , and manual searches of medical education journals published in 1997 . The exclusion criteria eliminated studies that did not provide data needed to compute ES for PBL and traditional learning approaches , as well as studies that examined only specifi c subtests of the NBME , rather than the overall NBME . The researchers found negative ES for NBME 1 , and positive ES for NBME 2 , which was consistent with previous fi ndings that traditional learning approaches tended to produce better results for basic science knowledge , while PBL tended to produce better results for clinical knowledge and skills . Colliver ( 2000 ) reviewed the medical education literature , starting with three reviews published in 1993 ( Albanese & Mitchell ; Vernon & Blake ; Berkson ) and included studies When is PBL More Eff ective ? 51 • volume 3 , no . 1 ( Spring 2009 ) published from 1992 to 1998 comparing PBL to the traditional curriculum . The purpose was to focus on the credibility of claims about ties between PBL intervention and edu - cational outcomes , particularly achievement ( knowledge and skills ) , and on eff ect sizes of the intervention on said outcomes . As a study selection strategy , Colliver’s search was limited to those articles that involved a comparison of curriculum tracks or schools . Where eff ect sizes were not provided , Colliver calculated them himself . Results indicated that there was no convincing evidence that PBL improved the knowledge base and clinical performance , at least not to the extent that may be expected for a PBL curricular inter - vention . Colliver acknowledged that PBL may provide a more challenging , motivating and enjoyable approach to medical education , as noted in the earlier research fi ndings on student and faculty satisfaction and motivation , but claimed that its educational ef - fectiveness , compared to traditional methods , remained to be seen . Dochy , Segers , Van den Bossche , and Gijbels ( 2003 ) reviewed 43 studies , where 33 of them measured knowledge eff ects and 25 of them measured application of knowl - edge eff ects . Their study selection criteria stipulated that the work had to be empirical . Although nonempirical literature and literature reviews were selected as sources of relevant research , this literature was not included in the analysis . The characteristics of the learn - ing environment had to fi t the core model of PBL . The dependent variables used in the study had to comprise an operationalization of the knowledge or skills ( i . e . , knowledge application ) of the students . The subjects of study had to be students in tertiary educa - tion . Also , the study had to be conducted in a real - life classroom or programmatic setting rather than under more controlled laboratory conditions . Research questions were : What are the eff ects of PBL on knowledge and skills ? What are the moderators on the eff ects of PBL ? Results indicated that assessment methods that focus more on recognition ( e . g . , NBME 1 ) , showed signifi cant negative eff ects for almost all knowledge and favored the traditional learning approach . Assessment methods that focused more on application of knowledge ( e . g . , NBME II ) showed larger eff ects for PBL versus traditional learning environ - ments . Researchers stated that the better an instrument was able to evaluate students’ skills , the larger the ascertained eff ects of PBL . Newman ( 2003 ) selected studies cited in the following papers which provided evi - dence of the eff ectiveness of PBL : Albanese and Mitchell ( 1993 ) ; Vernon and Blake ( 1993 ) ; Berkson ( 1993 ) ; Smits , Verbeek , and De Buisonje ( 2002a ) ; and Van Den Bossche , Gijbels , and Dochy ( 2000 ) . The fi nal count was12 studies with extractable data in the medical education domain . The minimum criteria for study selection consisted of only including participants in postschool education programs . Study designs had to be controlled tri - als ; studies that used only qualitative approaches were excluded . The minimum meth - odological inclusion criteria across all study designs were the objective measurement of student performance and behavior or other outcomes . The minimum inclusion criteria for interventions consisted of a cumulative integrated curriculum , learning via simula - The Interdisciplinary Journal of Problem - based Learning • 52 Johannes Strobel and Angela van Barneveld tion formats that allowed free enquiry ( i . e . , not problem solving learning ) , small groups with either faculty or peer tutoring , and an explicit framework implemented in tutorials . Research questions included : Does PBL result in increased participant performance when compared to other non - PBL teaching and learning strategies ? Does an authentic PBL cur - riculum deliver a greater improvement in performance than “hybrid” curricula ? Results indicated that knowledge related outcomes favored the traditional learning environment . Also consistent with previous fi ndings , study approaches and student satisfaction tended to favor PBL . However , improvements in applied practice returned mixed results , whereas previous studies reported better outcomes in a PBL environment . Gijbels , Dochy , Van den Bossche , and Segers ( 2005 ) reviewed 40 studies that were published between 1976 and 2000 . Study selection parameters stipulated that each study had to be empirical . Second , the characteristics of the problem - based learning environ - ment had to fi t the previously described core model of PBL ( Barrows , 1996 ) . Third , each study had to include some course or curriculum comparison between a PBL environment and a more traditional educational setting . Fourth , the study subjects had to be students in higher education . Finally , each study had to be conducted in a real - life classroom or programmatic setting rather than under more controlled laboratory conditions . The re - search question was : What are the eff ects of PBL when the assessment of its main goals focuses , respectively , on ( 1 ) understanding concepts , ( 2 ) understanding principles that link concepts , and ( 3 ) linking of concepts and principles to conditions and procedures for application ? Results indicated that PBL students performed better at knowledge levels that emphasized principles ( understanding the link between concepts ) and application knowledge structures . The eff ect size of PBL interventions was larger when the assess - ment strategy focused on the understanding of principles that link concepts . Most studies reported positive outcomes of the traditional classroom approach on conceptual knowl - Figure 1 . Map of learning outcomes . When is PBL More Eff ective ? 53 • volume 3 , no . 1 ( Spring 2009 ) edge assessment , but when weighted average ES was taken in to account , PBL students performed at least as well as students in a traditional environment . This demonstrated the potential infl uence of the assessment strategy and tool on outcome measures . The authors stated that the better the capacity of an instrument to evaluate the application of knowledge by the student , the greater the ascertained eff ect of PBL . In summary , the fi rst general tendency of noted in the research was that traditional learning approaches tended to produce better outcomes on assessment of basic science knowledge but , according to Albanese and Mitchell ( 1993 ) , not always . A second trend noted was that a PBL approach tended to produce better outcomes for clinical knowl - edge and skills . Interestingly , more recent research studies revealed that the assessment strategy and tool infl uence outcome measures . Results and Discussion We grouped and collapsed the data and established four high - level categories based on the assessment of learning outcomes . These four categories included : Non - performance , non - skill - oriented , non - knowledge - based assessment • Knowledge assessment • Performance or skill - based assessment • Mixed knowledge and skill - based assessment • A map of eff ectiveness measures is shown in Figure 1 . A detailed correlation matrix can be found in the appendix . Trends in eff ect sizes were reported as overall tendencies based on the data , where the ( + ) symbol indicates that eff ect sizes favored PBL , while the ( - ) symbol indicates that eff ect sizes favored the traditional teaching and learning approach . In the category coded as Non - performance , non - skill , and non - knowledge - based , which included student and faculty satisfaction measures , as well as successful assignment of fi rst choice of residency , all the reported eff ect sizes favored PBL . For the Knowledge assessment category , measures of short - term knowledge acquisition and retention returned mixed results , but tended to favor traditional learning approaches . With assessments delivered immediately post - course ( Albanese & Mitchell , 1993 ; Dochy et al . , 2003 ) , outcomes of knowledge measures such as NBME 1 ( assesses understanding and application of important concepts of the sciences basic to the practice of medicine ) , multiple choice questions , progress assessments using 250 True / False questions favored the traditional learning approach ( Newman , 2003 , who only discusses NBME 1 ) . However , outcomes of knowledge measures that focused more on recall over recognition , such as free recall , where students were asked to write down everything they remembered on a topic , and short answer , which allowed for elaboration of answers , favored PBL ( reported by all other systematic reviews which discussed both NBME 1 and 2 ) . The Interdisciplinary Journal of Problem - based Learning • 54 Johannes Strobel and Angela van Barneveld Knowledge assessment that focused on long - term knowledge retention , described by Albanese and Mitchell ( 1993 ) as a comparison of immediate post - course results and results of the same test applied after a period of between 12 weeks to 2 years , returned eff ect sizes that consistently favored PBL . Dochy et al . ( 2003 ) looked only at whether a retention period existed and compared knowledge outcomes on the basis of retention period or no retention period . Long - term knowledge retention favored PBL . The Performance or skill - based assessment category included observations with clini - cal ratings ( formative assessment by supervisor during and at the end of performance ) and case analysis measures . Clinical ratings favored PBL . The case analysis sub - category , which included measures from the NBME 2 ( assesses application of medical knowledge , skills , and understanding of clinical science ) , patient simulations , and elaborated assess - ments such as essay questions and case studies , also favored PBL . The fi nal category , Mixed knowledge and skill , captured results that required both knowledge and skill for performance—oral examinations and the USMLE 3 ( assesses application of medical knowledge and understanding of biomedical and clinical science essential for the unsupervised practice of medicine , with emphasis on patient manage - ment ) . The outcomes in this category favored PBL . Specifi cally , to answer our fi rst research question of how diff erences in ( a ) the defi ni - tion of learning , and ( b ) the measurement of learning contribute to the inconclusiveness of the diff erent meta - analyses with regard to the eff ectiveness of PBL , the discrepancy in reported results on the eff ectiveness of PBL for knowledge retention seemed to stem particularly from the diff erences in seeing learning as long - term ( PBL favorable ) and short - term retention of knowledge ( traditional teaching methods favorable ) . Addition - ally , conceptualizations and consequently measurements of learning , which focused on the performance and were skill - oriented , indicate that PBL students outperformed traditionally taught students . The focus on short - term learning gains as a measurement of PBL seem a particular mismatch considering that learning within an authentic context is a key criterion of the defi nition of PBL ( Barrows , 2002 ) . Overall , students and staff indicated greater satisfaction with the PBL approach to learning . Standardized tests that measured knowledge of basic science focusing on short - term acquisition and retention ( primarily the medical board exams in their diff erent ver - sions ) favored the traditional approach across all studies . However , when the method used to assess basic science knowledge required a level of elaboration beyond multiple - choice or true / false questions , results signifi cantly favored the PBL approach . Standardized tests and other assessment methods that evaluated skill - oriented application of knowledge , mixed knowledge and long - term retention of knowledge , skills , and clinical performance signifi cantly favored PBL . As to our second research question , several value statements can be made about the eff ectiveness of PBL that were supported by the majority of the meta - analyses reviewed : When is PBL More Eff ective ? 55 • volume 3 , no . 1 ( Spring 2009 ) PBL instruction was eff ective when it came to long - term retention and performance im - provement . PBL students were overall slightly underperforming when it came to short - term retention . Ultimately , the goal of instruction should be performance improvement and long - term retention . Therefore , preference should be given to instructional strategies that focus on students’ performance in authentic situations and their long - term knowl - edge retention , and not on their performance on tests aimed at short - term retention of knowledge . Conclusion Instruction is often designed based on the assumption that learning is “a similar process in all individuals and for all tasks and thus many people feel a common instructional ap - proach should suffi ce” ( Clark 2000 , p . 31 ) . PBL is not the only successful strategy to achieve eff ective learning of ill - structured and complex domains . The results of these qualitatively synthesizing meta - analyses of PBL for preparation for the workplace indicate , however , that PBL is signifi cantly more eff ective than traditional instruction to train competent and skilled practitioners and to promote long - term retention of knowledge and skills acquired during the learning experience or training session . Future directions The vast majority of research on the eff ectiveness of PBL has been conducted in the training of professionals in the fi eld of medicine . Similarly solid research base is needed in other disciplines and contexts such as K - 12 education , history , or engineering , to ( a ) expand the use of PBL in the learning environment and ( b ) to more clearly defi ne the boundaries of its use . Since the evidence suggests that PBL works in particular contexts , especially for workplace learning with a focus on skills and long - term retention , the focus should shift from researching eff ectiveness of PBL versus traditional learning , and should refocus on studying the diff erences in eff ectiveness of support structures to fi nd optimal scaff olding , coaching , and modeling strategies for successful facilitation of PBL . Acknowledgements The authors want to thank the three anonymous reviewers for their feedback . The Interdisciplinary Journal of Problem - based Learning • 56 Johannes Strobel and Angela van Barneveld References Albanese , M . A . , & Mitchell , S . ( 1993 ) . Problem - based learning : A review of literature on its outcomes and implementation issues . Academic Medicine , 68 , 52 - 81 . Bair , C . R . ( 1999 ) . Meta - Synthesis : A new research methodology . Paper presented at the An - nual Meeting of the Association for the Study of Higher Education , November 18 - 21 , San Antonio , Texas , 26p ( ERIC document no . ED 473 866 ) . Barrows , H . S . ( 1986 ) . A taxonomy of problem - based learning methods . Medical Education , 20 ( 6 ) , 481 - 486 . Barrows , H . S . ( 1996 ) . Problem - based learning in medicine and beyond : A brief overview . New directions for teaching and learning , ( 68 ) , 3 - 12 . Barrows , H . S . ( 2002 ) . Is it Truly Possible to Have Such a Thing as dPBL ? Distance Education , 23 ( 1 ) , 119 - 122 . Berkson , L . ( 1993 ) . Problem - based Learning : Have the expectations been met ? Academic Medicine , 68 ( 10 ) , S79 - S88 . Bernard , R . M . , Abrami , P . C . , Lou , Y . & Borokhovski , E . ( 2004 ) . A methodological morass ? How we can improve the quality of quantitative research in distance education . Distance Education , 25 ( 2 ) , 175 - 198 . Clark , R . C . ( 2000 ) . Four Architectures of Instruction . Performance Improvement , 39 ( 10 ) , 31 - 38 . Colliver , J . A . ( 2000 ) . Eff ectiveness of problem - based learning curricula : Research and theory . Academic Medicine , 75 ( 3 ) , 259 - 266 . Denzin , N . K . & Lincoln , Y . S . ( Eds . ) ( 2005 ) The SAGE Handbook of Qualitative Research . Thousand Oaks , Sage . Dochy , Filip , Segers , Mien , Van den Bossche , Piet , & Gijbels , David ( 2003 ) . Eff ects of problem - based learning : a meta - analysis . Learning and Instruction , 13 , 533 – 568 . Gijbels , David , Dochy , Filip , Van den Bossche , Piet , & Segers , Mien ( 2005 ) . Eff ects of Problem - Based Learning : A Meta - Analysis from the Angle of Assessment . Review of Educational Research , 75 ( 1 ) , 27 - 61 . Greenhalgh , T . ( 1997 ) How to read a paper : Papers that summarise other papers ( systematic reviews and meta - analyses ) , British Medical Journal , 315 , 672 - 675 Hung , W . , Jonassen , D . H . , & Liu , R . ( 2007 ) . Problem - based learning . In J . M . Spector , J . G . van Merriënboer , M . D . , Merrill , & M . Driscoll ( Eds . ) , Handbook of research on educational com - munications and technology ( pp . 1503 - 1581 ) . 3rd Ed . Mahwah , NJ : Lawrence Erlbaum Associates . Kalaian , Hripsime A . , Mullan , Particia B . , & Kasim , Rafa M . ( 1999 ) . What can studies of problem - based learning tell us ? Synthesizing and modeling PBL eff ects on National Board of Medical Examination performance : Hierarchical Linear Modeling meta - analytic approach . Advances in Health Sciences Education , 4 , 209 - 221 . Kirschner , Paul A . , Sweller , John , & Clark , Richard E . ( 2006 ) . Why minimal guidance during instruction does not work : An analysis of the failure of constructivist , discovery , problem - based , experiential , and inquiry - based teaching . Educational Psychologist , 41 ( 2 ) , 75 - 86 . Correspondence concerning this article should be addressed to Johannes Strobel , Purdue University , Armstrong Hall , 701 West Stadium Avenue , West Lafayette , IN 47907 - 2045 . The Interdisciplinary Journal of Problem - based Learning • 58 Johannes Strobel and Angela van Barneveld Appendix Correlation Matrix