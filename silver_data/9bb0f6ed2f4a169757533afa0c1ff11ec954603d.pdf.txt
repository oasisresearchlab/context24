Lettersmith : Scaffolding Written Professional Communication Among College Students Julie Hui juliehui @ umich . edu School of Information , University of Michigan Ann Arbor , Michigan , USA Michelle Sprouse sprouse @ umich . edu English and Education , University of Michigan Ann Arbor , Michigan , USA ABSTRACT Professional writing is critical for job search and performance , but many – especially those without work experience – struggle to write well . We introduce an instructional approach called ‘scaf - folded annotation’ as a way to guide students in creating initial drafts of professional writing , like client emails and cover letters . We studied the implementation of scaffolded annotation in a digital plat - form called Lettersmith . First , we performed a quasi - experimental study and found that students applying scaffolded annotation in Lettersmith were more likely to include key components of pro - fessional writing . We also interviewed instructors and students who used Lettersmith and found that scaffolded annotation helped students in guiding structure , content , and tone . Instructors found the approach useful for articulating writing task expectations , pin - pointing student gaps in understanding , and scaling instructional support for early - stage drafting . We provide implications for writ - ing instruction and HCI researchers developing writing support tools . KEYWORDS Writing , Scaffolding , Annotation , Modeling , Reflection , Learning , Workplace Communication ACM Reference Format : Julie Hui and Michelle Sprouse . 2023 . Lettersmith : Scaffolding Written Pro - fessional Communication Among College Students . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( CHI ’23 ) , April 23 – 28 , 2023 , Hamburg , Germany . ACM , New York , NY , USA , 17 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3581029 1 INTRODUCTION Communication skills are ranked at the top of the list of attributes sought by corporate recruiters [ 9 ] with employers ranking the abil - ity to write well just as high or more highly than any technical or quantitative skills [ 44 ] . However , the landscape of communication is changing dramatically as new technologies enable communica - tion independent of a writer’s actual writing skills [ 1 ] . For instance , what if you received an impressive job application written by an AI system , how would you feel ? Our position is that writing tools This work is licensed under a Creative Commons Attribution - NoDerivs International 4 . 0 License . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 9421 - 5 / 23 / 04 . https : / / doi . org / 10 . 1145 / 3544548 . 3581029 should be for assistance rather than the replacement of commu - nication , especially in high - stakes contexts like job seeking and relationship development . While such automatic writing support tools may be especially useful for some situations ( e . g . summarizing long discussions [ 103 ] ) , it may be misleading or confusing if used as a representation of human ability . Yet , writing in general is hard to learn because it requires a range of socio - cognitive functions to effectively plan , monitor , and review one’s own writing [ 6 , 17 , 47 ] . Employers express that professional writing skills are one of the hardest to teach , with reports stating that only 26 . 2 % of college graduates write at a level deemed “pro - ficient” [ 27 ] . Another report estimated that American companies spend $ 3 . 1 billion annually on up - skilling employee writing ability and re - doing work as a result of communication errors [ 69 ] . Pro - fessional writing in particular is challenging because it involves a wide range of requirements , from knowing how to structure communication to knowledge about appropriate tone [ 10 ] . Professional writing skills are expected to be taught in college - level courses in order to prepare students for the working world . Yet , prior research finds that knowledge of how to communicate in a formal context is often learned from one’s family and upbringing [ 51 ] . Related research has also uncovered workplace biases that show how people in power are more likely to respond to individuals who sound like them [ 22 ] , emphasizing just how serious gaps in writing proficiency may be on long - term career trajectories . Writing instruction scholars express that greater instructor transparency can reduce barriers to these “unwritten” expectations , particularly for underserved students [ 32 , 98 ] . We emphasize that our goal is not to force students to lose their personal style of writing but to help them understand and adopt global standards of clear commu - nication in the workplace , such as how to elaborate on personal experience in cover letters , construct manageable help requests in emails , and succinctly detail findings in project reports . In order to address the challenge of preparing students for writ - ing in the workplace , we introduce an approach to writing instruc - tion called scaffolded annotation and evaluate its application through a digital platform called Lettersmith [ 3 , 49 ] . Scaffolded annotation leverages learning sciences principles [ 13 , 31 ] to break down expert knowledge into manageable tasks , thus helping students learn to identify and apply best practices of professional writing on their own . In this study , we address the following questions : • RQ1 : What is the effect of scaffolded annotation on students’ professional writing task outcomes ? • RQ2 : To what extent does scaffolded annotation influence students’ professional writing ? • RQ3 : To what extent does scaffolded annotation influence instructors’ teaching of professional writing ? CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse In order to address these questions , we build on prior work on the Lettersmith platform , which has already demonstrated its ability to improve writer confidence and overall writing quality , even when the tool is removed [ 49 ] . In this study , we introduce ‘scaffolded annotation’ as an instructional approach that combines using model texts [ 28 , 35 ] and annotations [ 53 ] to enhance student writing performance . Specifically , we evaluate the application of scaffolded annotation via a digital platform , Lettersmith [ 3 ] , in a large midwestern university in courses teaching professional writ - ing . First , we performed a quasi - experimental study to evaluate the differences in writing outcomes for when students did and did not use Lettersmith to draft a client - facing email . Experimental results show that students were 36 . 43 % more likely to include key components of this type of professional writing when drafting with the Lettersmith tool ( RQ1 ) . Second , we interviewed 19 students and 11 instructors in order to understand how scaffolded annotation influenced their writing and teaching practices respectively . The interview results revealed that scaffolded annotation helped stu - dents with writing structure , content , tone , and reflection ( RQ2 ) . For instructors , scaffolded annotation helped them clarify writing task expectations , pinpoint where students had gaps in understanding , and scale instructional support for early - stage drafting ( RQ3 ) . 2 RELATED WORK 2 . 1 Expectations of Professional Writing We define professional writing as any written communication per - formed in a workplace context or in the pursuit of work . Profes - sional writing often serves as a bridge into careers , especially given that job applications , networking , and day - to - day work are increas - ingly being conducted online . Yet , professional writing follows practices unique to workplaces that are not always found in other forms of writing . Unlike other contexts , like narrative and academic writing , professional communication often involves hierarchy , in that communication is often between superiors and subordinates , employees and clients , and / or peers [ 10 , 45 ] . It is typically strategic and requires careful control of a ‘professional’ tone , which is often both loosely defined yet also follows a broadly – but not universally – shared set of beliefs within a specific field or organization about what and how to communicate [ 10 ] . Finally , it is often expected to be concise and efficient , which requires balancing between in - cluding necessary information without being too wordy . While other forms of writing and communication might share similar attributes , employers repeatedly express that the writing taught in an academic setting does not meet the standards of workplace writ - ing [ 27 ] , and that significant improvements are needed in higher education writing instruction . Accessible and structured approaches to writing instruction are necessary for the task of teaching professional writing . However , there are limited platforms that support professional writing at the moment , and they are largely focused on recommending con - nections [ 48 , 67 ] , organizing team discussions [ 103 ] , or facilitating social networking ( e . g . , LinkedIn [ 4 ] ) . While these platforms pro - vide places for professional writing to happen , they do little to facilitate the process of writing , such as guiding content and struc - ture . Those that do , focus on word and sentence level guidance , like pointing out grammar mistakes or edits to make a sentence for succinct ( e . g . , Grammarly [ 2 ] ) . We address this gap in the need for professional writing support tools by building on learning sciences constructs of writing guidance and applying it to the context of professional communication . 2 . 2 Writing Support Tools The majority of existing writing support tools focus on maximiz - ing the quality and efficiency of the written output , but do little to guide the cognitive processes of learning how to write . In an evaluation of 44 writing support tools , Strobl et al . found that the majority of writing tools primarily support writing at the micro - level like spelling and grammar mistakes [ 85 ] . HCI researchers have also developed platforms to coordinate writing , like managing and engaging crowds [ 14 , 70 ] in writing of stories [ 58 ] , news arti - cles [ 7 ] , and Wikipedia articles [ 55 ] . Others have developed tools for machine - in - the loop collaborative writing , such as machine - generated sentence and phrasing suggestions [ 12 , 29 , 30 , 42 ] and text evaluation [ 59 , 102 ] . Tools that focus on supporting the cognitive process of writing have often focused on providing feedback . Peer feedback systems [ 63 , 64 , 80 ] have been shown to guide peers through providing feed - back comparable to the instructor . Automated Writing Evaluation ( AWE ) systems provide students with automatic feedback [ 97 ] so that they can make changes in the moment . However , reviews of automatic feedback systems have not been shown to be particularly effective—outside of being able to provide feedback more quickly than a live instructor [ 82 ] . While feedback is useful for improving writing through iterations , it only occurs after learners create their initial draft . We see an opportunity to support the cognitive pro - cesses of writing in learners’ initial process of drafting when they may have trouble planning and getting started . Recent advances in writing instruction tools have started to sup - port writing structure and organization by demonstrating the use of machine learning in guiding how to write an argumentative essay [ 92 , 94 ] and evaluating whether a learner has succeeded or failed at particular rhetorical moves [ 93 , 95 , 96 ] . While machine learning tools can help scale writing guidance , their suggestions are gener - ated from a large library of general input and not necessarily cus - tomizable to individual instructors’ preferences . Learning sciences scholars emphasize the importance of dialogue and context - specific modeling in developing student self - regulation skills of complex tasks [ 71 , 90 ] . Our work may not incorporate machine learning at the moment , but we explore how a writing support tool can both scale instruction while providing agency in how instructors teach specific assignments . 2 . 3 Theoretically Motivated Approaches to Writing Instruction HCI and writing education researchers argue that in order for computer - based writing tools to be effective , they must support the cognitive processes of writing [ 8 , 45 , 45 , 49 ] . This work applies prin - ciples from social cognitive theory and cognitive apprenticeship to motivate our approach . Social cognitive theory was first introduced by Albert Bandura to express that learning occurs in a social context in which people are shaped by what they observe and experience [ 13 ] . While colleges and universities are tasked with preparing Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Figure 1 : Table outlining the differences between scaffolded annotation and existing writing instruction approaches of model texts and annotation . students for communicating in the working world , professional writing is challenging to teach in the classroom because so much of it is learned through context - specific observation and different from the type of writing students typically encounter in a college setting . Therefore , scholars have suggested using cognitive apprenticeship as a way to teach complex skills in classroom settings . Building on the principles of social cognitive theory , cognitive apprentice - ship was introduced as a set of instructional approaches to make thinking visible for complex tasks [ 31 ] . Strategies of cognitive ap - prenticeship include modeling , coaching , feedback , and reflection , which emphasize the importance of learning by observing others and reflecting on one’s own practice . Writing researchers and practitioners have applied these learning sciences approaches to the field of writing through the pedagogical tools of model texts and annotations . Instructors use model texts — texts written by a specific writer in a specific situation used to exemplify a genre—to illustrate what content to include and how to organize text elements [ 28 , 35 ] . Model texts , which build on the cognitive apprenticeship practice of modeling [ 31 ] , provide examples that students can read and use to construct their own writing in ways that go beyond following general best practices [ 36 ] . Students may learn about form and organization from analyzing model texts in certain genres [ 86 , 87 ] . For instance , students can compare multiple written examples in a given genre to uncover the “rhetorical moves” writers make in deciding what content to include [ 50 , 86 ] and “how they say it” [ 50 ] . Model texts [ 28 , 87 , 88 ] build students’ knowledge of that genre and help students transfer that knowledge to new tasks [ 38 ] . Having learners view others’ annotations builds on the cognitive apprenticeship practice of modeling and coaching by making vis - ible others’ interpretations of text . Annotation—“a note added to text” [ 53 , p . 12 ] —has been used to support expert [ 52 ] and student analysis [ 19 , 33 , 66 ] of model texts . Having students annotate often results in richer discussions and engagement with readings [ 18 , 89 ] . Recently , advances in annotation interfaces have introduced new ways of sharing annotations . For instance , platforms that facilitate social annotation ( e . g . , Perusall [ 5 ] ) allow students to view and respond to peer annotations , which has been shown to foster a stronger sense of community in the classroom [ 54 ] . Scholars who study annotations find that annotated material improves recall [ 39 , 101 ] , while reducing unnecessary summarizing and increas - ing critical reflection in reading responses [ 100 , 101 ] . As digital technologies make it easier to share annotations , scholars suggest that making annotations visible to others can help limit the cog - nitive burden on novice writers [ 46 , 56 , 57 ] . For example , shared frameworks of annotations may help learners identify and apply rhetorical moves in model texts more quickly [ 61 , 76 , 78 ] . Our study focuses on the potential of using shared annotations to support student learning of professional writing . 2 . 3 . 1 Introducing ‘Scaffolded Annotation’ . We introduce ‘scaffolded annotation’ as an instructional approach that combines the benefits of model texts [ 28 , 35 ] and annotation [ 53 ] . Similar to model texts , scaffolded annotation builds on principles from social cognitive theory and cognitive apprenticeship by emphasizing the importance of learning from others ( Table 1 ) . Unlike just model texts , scaffolded annotation breaks down these texts into key components and shows how they are instantiated across multiple models . Similar to prior uses of annotations , scaffolded annotation allows for making others’ thinking visible by showing the annotator’s reasoning behind the text . Unlike prior uses of annotation , scaffolded annotation provides a shared list of annotations curated by the instructor to help identify key takeaways and reduce cognitive load on learners . We define the features of scaffolded annotation as the following : • Annotated model texts that break down examples into man - ageable components • Shared annotations curated by instructors that outline key components of the writing task • Annotating one’s own drafts , which supports reflection and can be used as examples for others CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse Figure 2 : Screenshot of the Lettersmith interface for how to write a cover letter . Lettersmith includes shared annotations ( A : ‘Checklist’ ) , annotated model texts ( B : ‘Examples’ ) , and space to draft and annotate one’s own writing with the checklist items ( C ) . The Checklist and Examples change depending on the instructor and writing genre . Following principles of scaffolding [ 75 ] , scaffolded annotation is meant to provide initial support when students are first drafting in a new genre—a stage of writing less supported among writing support tools—with the goal that students will eventually be able to write independently without the tool in place [ 31 , 75 ] . We suggest that ‘scaffolded annotation’ is particularly useful for guiding highly structured types of writing like cover letters , reports , and certain emails given that these types of texts follow generally agreed - upon practices , depending on the field or industry . We describe the role scaffolded annotations play in influencing student professional writing in the following sections . 3 DESIGN OF LETTERSMITH While prior work outlined how each individual feature in Letter - smith was motivated by learning science principles [ 49 ] , in this study we seek to articulate an explanation for why this combina - tion of features is particularly supportive for professional writing among novices . We argue that each of the described features of Lettersmith is likely useful on its own , but together contribute a unique approach to teaching professional writing through what we call ‘scaffolded annotation . ’ Lettersmith incorporates the practices of scaffolded annotation in the following ways ( Figure 2 ) : A ) Shared annotations in a ‘Checklist’ curated by the instructor ( left ) , B ) An - notated model texts that serve as ‘Examples’ ( right ) , and C ) Open space for annotating one’s own drafts ( center ) . Instructors are also able to see how students annotate their drafts to inform one - on - one feedback ( not shown ) . In using Lettersmith , students refer to the shared annotations ( A ) to determine the key elements of the writing genre . Then they review how these elements are applied in annotated model texts ( B ) . Both the shared annotations and annotated model texts are chosen by the instructor for their specific assignments and not hard - coded by the platform . Therefore , two instructors both teaching how to write cover letters might decide to teach with different content . This ability to customize guidance addressed instructors’ preference for control over how they taught writing within a genre . What one instructor considered important to include in a writing task may not match that of other instructors . 3 . 1 Prior Work on the Design of Lettersmith We borrow from traditions in system design where there is a tra - jectory of scholarship that discusses the initial system design in one study and further evaluation in later work ( e . g . [ 16 , 20 ] ) . Letter - smith’s design , presented in earlier work [ 49 ] was informed by user interviews and principles of cognitive apprenticeship [ 31 ] . To sum - marize , Lettersmith builds on the cognitive apprenticeship practice of coaching by breaking down and describing the type of content to be included in the writing task [ 31 , 41 ] . Lettersmith was also motivated by the practice of modeling , which has been shown to increase learning of complex tasks by showing how others perform similar work [ 31 , 37 ] . The opportunity to draft and annotate one’s own work was informed by the practice of reflection , which encour - ages novices to reflect on their practice and supports knowledge retention [ 31 ] . Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Prior work on the design of Lettersmith evaluated the efficacy of the tool in supporting novice entrepreneurs in crafting introduc - tory help requests to organizations , mentors , and users to request conversations and access resources . In this prior study , researchers performed a within - subjects experiment and determined that Letter - smith both increased the overall quality of emails produced and the likelihood that students would send them [ 49 ] . This prior work also showed that student writing stayed at a higher quality even after the tool was removed . We add to this prior work by 1 ) introducing the concept of scaffolded annotation , 2 ) performing a quasi - experiment in a classroom setting to determine how scaffolded annotation influ - ences writing outcomes on a more granular level , and 3 ) performing interviews with both instructors and students who used Lettersmith to understand how scaffolded annotation influenced their practice . 4 QUASI - EXPERIMENTAL STUDY To answer RQ1 ( What is the effect of scaffolded annotation on stu - dents’ professional writing task outcomes ? ) , we followed a two - year quasi - experimental design by comparing student writing between two consecutive years of a client - based project course where one course used Lettersmith and the other did not . We describe how classes were relatively balanced based on pre - existing demograph - ics . 4 . 1 Quasi - Experimental Methods 4 . 1 . 1 Participant Demographics . For the purposes of evaluating dif - ferences between the two class instances studied , we were provided aggregate demographic data pulled from the central student data warehouse , which is outlined in Figure 3 . Access to this anonymized data is covered by the university IRB policy on education tools . Stu - dents in both classes were predominantly seniors in college , and primarily majoring in Information . The average ACT score reported was 30 for both classes , indicating a similar level of academic prepa - ration . In addition , there was a similar percentage of first - gen and non first - gen students in each course . There were more females than males in both years . The student data warehouse only collects students’ birth sex in a binary ( either Male or Female ) format and so we report using these labels but acknowledge that this does not depict students’ full gender identities . Given persistent correlations between birth sex and grade outcomes in various domains , we continue to consider this variable in research projects while simul - taneously advocating for improved data collection practices . Finally , both classes had a similar racial demographic makeup , with the majority of students being White , followed by Asian , and less than 10 % of Black , Hispanic , and two or more race and ethnicity . Given these demographics , we believe that there were few significant demographic differences between the classes . 4 . 1 . 2 Approach . The instructor and course assignments were kept consistent between the two course years , but Lettersmith was only adopted in the second year . In the course without Lettersmith , the in - structor gave a presentation on professional communication styles and preferences as guidance on how to communicate with clients . In the following year , the instructors gave this same presentation in addition to introducing Lettersmith as a supplementary tool . Unlike a true experiment , which allows for controlling all the factors of the treatment and control group , we emphasize that a quasi - experiment does not allow for controlling all factors [ 23 ] . This comparison between non - randomized groups is common in education research ( e . g . , [ 40 , 73 ] ) , given the limited ability to control who is in each class , who teaches each class , and the amount of time instructors have for introducing an intervention . In our case , we had to compare classes across years because the participating instructor was only teaching one section each year . Therefore , we believe the most salient features , as captured in Figure 3 , were sufficiently similar between consecutive years of the same course , rather than two different courses within the same year . Both courses were taught in person . In Lettersmith , the instructor defined the following key elements of an introductory client email . This made up the shared annotations in the ‘Checklist . ’ The instructor also provided two examples of an introductory client email with the key elements annotated in each each example . This made up the annotated model texts in the ‘Examples . ’ The instructor then encouraged students to tag their own writing with each element of the shared annotations : • Greeting - Formally , write a professional greeting and state the names of your addressees . • Personal and Team Introduction - Share your name and the names of your group members . • Course Introduction - Share information about the course that you are enrolled in and your school . • Connection to Client - Provide a statement on why you are interested / excited about their organization and / or project . • Meeting Scheduling - State your interest in meeting with your client and the timeline in which you would like to meet . Indicate times and dates that you would like to meet ; addi - tionally , state your flexibility to meet your client’s schedule . Inquire about meeting mode ( in - person or virtual ) . • Meeting Purpose - State the purpose of the meeting . • Appreciative Closing - State your thanks for their engagement with the school , sharing the project , and that you are looking forward to your meeting . • Sign - off - Sign your message with the name of the sender and all the other team members . Thus , we hypothesize that emails drafted with Lettersmith will be more likely to include all of the key elements : • H1 : Students drafting in Lettersmith are more likely to in - clude a Greeting . • H2 : Students drafting in Lettersmith are more likely to in - clude a Personal and Team Introduction . • H3 : Students drafting in Lettersmith are more likely to in - clude a Course Introduction . • H4 : Students drafting in Lettersmith are more likely to in - clude a Connection to the Client . • H5 : Students drafting in Lettersmith are more likely to in - clude Meeting Scheduling . • H6 : Students drafting in Lettersmith are more likely to in - clude a Meeting Purpose . • H7 : Students drafting in Lettersmith are more likely to in - clude an Appreciative Closing . • H8 : Students drafting in Lettersmith are more likely to in - clude a Sign - off . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse Figure 3 : Student demographics in each class . Following IRB approval , we collected and anonymized introduc - tory emails sent by students in each course and coded whether each email included the above elements . This led to a dataset where each email was assigned a present ( 1 ) or absent ( 0 ) value for each element , where the independent variable was whether Lettersmith was present and the dependent variable was whether each element of introductory client emails was present or absent in each student email . Forty students sent introductory emails in year one , while fifty students sent introductory emails in year two . Only a subset of the entire class in each year produced emails because students worked in groups where one group member drafted email commu - nication with the clients . We analyzed the first email each student sent to their clients . We only implemented this analysis within one course given the significant labor on the instructors to compile the student emails from each year . We then performed a Pearson Chi - squared test of independence to determine whether students in the second year were more likely to include key elements of introductory client emails when drafting in Lettersmith . 4 . 2 Quasi - Experimental Results Overall , 40 students produced email drafts in year 1 , and 50 pro - duced drafts in year 2 . In year 2 , when Lettersmith was introduced , students on average annotated their emails with 7 . 74 items from the Checklist . Supporting H2 - H6 , students were more likely to include a Personal and Team Introduction , Course Introduction , Connection to Client , Meeting Scheduling , and Meeting Purpose when drafting in Lettersmith ( Figure 4 ) . Contrary to H1 , H7 , and H8 , there was not a statistically significant relationship between using Lettersmith and the likelihood students would include a Greeting , Appreciative Closing , and Sign - off . This was because even without Lettersmith , the vast majority of students already knew to include a greeting , appreciative closing , and sign - off in their emails . Figure 4 shows the contingency tables for each variable . Support - ing H2 , there was a statistically significant relationship between using Lettersmith and likelihood students would introduce them - selves and their team , X2 ( 1 ) = 32 . 22 , p < 0 . 001 , r = 0 . 624 , indicating that those drafting in Lettersmith would be more likely to include Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Figure 4 : Relationships between use of Lettersmith and presence of each element of an introductory client email . Elements marked with an asterisk * were found to have a statistically significant relationship . a personal and team introduction . Supporting H3 , there was a sta - tistically significant relationship between using Lettersmith and the likelihood that students would introduce the course , X2 ( 1 ) = 43 . 99 , p < 0 . 001 , r = 0 . 723 , indicating that students using Lettersmith were more likely to include a course introduction . Supporting H4 , there was a statistically significant relationship between using Let - tersmith and the likelihood students would include a connection to the client , X2 ( 1 ) = 57 . 24 , p < 0 . 001 , r = 0 . 820 , demonstrating that Lettersmith use increased the likelihood students would include a connection to the client in their email . Supporting H5 , there was a statistically significant relationship between using Lettersmith and likelihood students would include meeting scheduling details , X2 ( 1 ) = 27 . 38 , p < 0 . 001 , r = 0 . 575 , such that those drafting in Lettersmith were more likely to include a plan for meeting scheduling . Support - ing H6 , there was a statistically significant relationship between using Lettersmith and the likelihood students would include a meet - ing purpose , X2 ( 1 ) = 11 . 92 , p < 0 . 001 , r = 0 . 266 with students drafting in Lettersmith being more likely to include a meeting purpose . Stu - dents were significantly more likely to include these key elements of an introductory client email when drafting in Lettersmith com - pared to students not drafting in Lettersmith . No other results were significant , indicating that those drafting in Lettersmith were no more likely to include greetings , appreciative closings , or sign - offs than those not drafting in Lettersmith . Figure 5 shows a comparison of an example introductory client email written without using Lettersmith ( top ) and an example writ - ten with Lettersmith ( bottom ) . Emails written without Lettersmith were on average 129 words long , while emails written with Letter - smith were on average 230 words long . This additional length comes as the result of the emails written using Lettersmith being more likely to include key elements of a Personal and Team Introduction , Course Introduction , Connection to Client , Meeting Scheduling , and Meeting Purpose . While shorter emails are generally preferred , this is only the case if they included the necessary information needed for the receiver to respond . In this context , clients receiving student emails sometimes had little to no background information about the project . Sometimes the client had forgotten that they signed up to be a client for a class project , and sometimes the per - son in charge of engaging with the students has not been briefed about the university engagement at all . Therefore , while the email using Lettersmith is longer , it includes all the relevant information CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse Figure 5 : Comparing an example client email written without Lettersmith ( Top ) to an example client email written with Lettersmith ( Bottom ) . to establish a knowledgeable connection , highlighting how context is critical to the way professional writing is taught . In summary , we found that students who were exposed to the practices of scaffolded annotation via Lettersmith were more likely to include key components of professional writing . In the case of professional client emails , students were already skilled at including common parts of general emails , like a greeting and appreciative closing , but were more likely to miss content specific to client com - munication , like introducing oneself and the purpose for requesting a meeting . This suggests that scaffolded annotation was particularly useful for guiding what content to include for types of professional writing that are somewhat novel to students . 5 INTERVIEWS To answer RQ2 ( How does scaffolded annotation influence students’ professional writing ? ) and RQ3 ( How does scaffolded annotation in - fluence instructors’ teaching of professional writing ? ) , we performed interviews with instructors and students to better understand their experiences with using the tool and subsequently how the features of scaffolded annotation supported their respective practices . 5 . 1 Interview Methods 5 . 1 . 1 Recruitment . We introduced Lettersmith [ 3 ] , a publicly avail - able free platform , in seven courses between 2018 - 2022 . We re - cruited instructors to adopt Lettersmith if their course included assignments with professional writing . Courses that adopted Letter - smith included a client - based project course , a career preparation course , an entrepreneurship course , an introduction to writing course , and two technical communications courses . Class sizes ranged from 28 to 368 students , with a mean size of 160 students . Prior to using Lettersmith , instructors shared rubrics and / or presen - tations with general writing expectations of structure and content , while some also shared model texts ( e . g . example cover letters ) . However , prior to using Lettersmith , no instructors had imple - mented strategies of ‘scaffolded annotation’ by explicitly connect - ing how the model texts implemented each specific rubric item at the sentence level . Students had minimal experience communicat - ing with clients and employers as these courses were meant to be taken as an introduction to professional engagement . In this study , instructor quotes are designated with a “T” and student quotes are designated with an “S . ” Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany 5 . 1 . 2 Participant Demographics and Data Collection . We inter - viewed 11 instructors ( 8 female , 3 male ) and 19 students ( 13 female , 5 male , 1 non - binary ) from seven different courses ( Figure 6 ) . Some courses were taught by more than one instructor . Two instructors ( T8 , T9 ) were in the process of adopting , but had not deployed the tool in their classes at the time of the interview . Instructors were recruited to be interviewed via direct email , while students were recruited via the class - wide email lists and were compensated $ 20 for a 30 min interview . Instructor interviews lasted 30 min to 1 hour , in which we asked about their experience using Lettersmith , student challenges with professional written communication , and how Lettersmith impacted student writing . For student interviews , we asked questions about how they used Lettersmith for the writing assignment and whether or not they found the platform useful . 5 . 1 . 3 Analysis . Through our interviews , we aimed to further un - derstand why we see an improvement in student professional writing through the use of Lettersmith as observed in the quasi - experiment . Our final two research questions outline how enacting scaffolded annotation in Lettersmith impacted student performance ( RQ2 ) and instructor practice ( RQ3 ) . To answer each research ques - tion , we followed a grounded theory approach [ 43 , 83 , 84 ] in which both authors reviewed the transcripts together and collaboratively performed open coding to categorize the data into discrete parts . Open coding to address RQ2 ( How does scaffolded annotation influ - ence students’ professional writing ? ) , involved analyzing student and instructor interview data by identifying all instances where student writing performance was mentioned . This included data around students’ writing strengths and struggles before and after using Lettersmith , students’ impressions of Lettersmith , and how they used the platform . While student interview data was useful for understanding how they evaluate their own skills , we also in - cluded instructor data in this analysis because it provided another perspective on student writing ability . Following this initial round of open coding , we then performed axial coding to identify higher - level patterns of how scaffolded annotation played a role in student writing ability . This involved reviewing student and instructor data to identify places where annotated model texts , shared annotations , and annotating one’s own draft were mentioned and triangulating where these practices may have had an influence on student per - formance . Final themes that emerged from axial coding included descriptions of how Lettersmith supported students’ writing struc - ture and content , identifying appropriate tone , and reflection in the writing process . To answer RQ3 ( How does scaffolded annotation influence in - structors’ teaching of professional writing ? ) , we also followed grounded theory analysis by having both authors work together to open code instances where instructor practice was discussed . While students sometimes described how instructors used Lettersmith , the majority of student interview data focused on their own writing experiences and less on evaluating instructor practice . Therefore , we focused our analysis of RQ3 mainly on instructor interview data . This round of open coding identified instances where instruc - tors discussed experiences teaching professional writing , changes to their teaching practice as a result of Lettersmith , and impres - sions of Lettersmith . We then performed axial coding to identify how scaffolded annotation played a role in their teaching practice . Axial coding led to higher level themes of how scaffolded annota - tion helped them demonstrate writing expectations , pinpoint gaps in student knowledge , and guide students’ writing of first drafts . Findings are structured according to each research question ( RQ2 - section 5 . 2 . 1 ; RQ3 - section 5 . 2 . 2 ) . 5 . 2 Interview Findings Our semi - structured interviews uncovered ways scaffolded annota - tion in Lettersmith supported students’ professional writing . Stu - dents found scaffolded annotation useful for learning structure and content in a new genre , identifying language to express appropriate professional tone , and reflecting on their own writing . Instructors found that using Lettersmith helped them articulate writing task expectations , pinpoint where students had gaps in their under - standing , and scale instructional support for early - stage drafting . We describe how the features of scaffolded annotation—the use of annotated model texts , shared annotations , and annoting one’s own drafts —facilitated these outcomes for instructors and students . 5 . 2 . 1 Scaffolded Annotation to Aid Student Performance . Students found that shared annotations were useful for identifying what content to include , while the annotated model texts were useful for determining the structure of this content and how to convey an appropriate professional tone . Furthermore , being asked to annotate one’s own draft with shared annotations helped students reflect on their writing . This combination of guidance was found to be particularly useful for supporting early stage drafting in a new genre . Supporting Structure and Content : By viewing annotated model texts , students were able to see examples of how to struc - ture their drafts , like how to word a professional connection or a meeting schedule . For instance , S5 explained that when drafting an email to a client , using Lettersmith prompted her to include a more detailed agenda and search for resources online in preparation for the meeting . If we didn’t have Lettersmith and had these examples , we probably wouldn’t have wrote an email similar to this , we probably would have just said , ‘Hi , we’d love to meet’ and not really like have the full agenda . . . It kind of made us like have to become more prepared for the meeting as well . For one of the examples [ on Lettersmith ] , it caused us to kind of look at different websites where we could find resources to analyze customer data . So , it definitely made us more prepared . - S5 Furthermore , students found that viewing the shared annotations helped illustrate what the instructor believed to be the most impor - tant components to include in their draft . Students expressed that prior to using Lettersmith , getting started was the most difficult part . When you have a blank canvas , I think students don’t know like where to start . . . If you can kind of see how someone like worded something , like how did some - one ask for a meeting and how did they introduce a time . If you can read how they worded that , it’s much more helpful . - S14 CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse Figure 6 : Classes that used Lettersmith from which interview participants were recruited . Students liked that Lettersmith broke down examples into un - derstandable components that they could use as inspiration in their own work . Confirming students’ concerns , instructors described students having trouble determining what to include . For instance , students sometimes provided too much or not enough detail . In a technical communication course , the instructor described how students would start their reports far too broadly and be unclear about their specific contribution . They tend to start their essays with ‘Since the dawn of time , blah blah blah , in society today , etc . , etc . " Techni - cal writing and memos are supposed to be extremely to the point . You are supposed to open with an orga - nizational problem . So , they need some help sorting out the layers between the big issue of climate change and the actual tiny quarter of climate change they’re intervening in . - T9 Others instructors shared similar sentiments . T8 , a technical communication instructor , expressed that students felt the need to include detail on every single task they performed in a project , which made the reports too lengthy and lacking a cohesive narrative . One student expressed that by viewing the shared annotations in Lettersmith , they were guided through the process of including only the key parts of their draft , items they otherwise might have forgotten to include if they were just provided with a single example . Another student expressed that being asked to annotate their own writing helped them both identify all the necessary parts and check that they had it covered in their own work . Since we kind of had a baseline to start with , it made me feel like oh , most of the things are already included in here . . . So that was kind of nice because then we’re not sitting there like wondering like am I missing anything ? And at the point where you can like click - check to make sure you have every part of the email that they wanted us to have was helpful because it’s kind of like a double check before we sent it . - S11 By “click - check” S11 was referring to using shared annotations in their draft where they completed the items on the Checklist . This step - by - step process helped guide students in managing level of detail and structure , two core challenges mentioned by instructors . As on instructor expressed , “if you can’t come up with a reason that this is here—if there’s no tag that you can give it—then maybe it doesn’t belong . ” Asking students to primarily include these key elements while showing examples of each could help them include the most important information in an appropriate number of words . The ability to be concise is also critical for developing a cohesive and engaging narrative . Identifying Appropriate Tone : Both students and instructors agreed that capturing the right tone was one of the most challeng - ing aspects of professional writing . Instructors of project - based courses , where students had to interact with clients , were partic - ularly concerned about tone because the way students presented themselves influenced the clients’ relationship with the instructor and university more broadly . Students were particularly concerned about making a positive impression on potential employers . We found that Lettersmith helped guide tone by suggesting example ways of wording introductions and requests via the annotated model texts . Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany I just like frantically message all my friends , like can you read this ? . . . Is the tone weird ? Like , I’m always afraid that I’m coming off as too demanding or too cold . I’m very exclamation point heavy , saying like , hey nice to meet you ! I’m so excited do this ! And then like you sound like a two - year - old . - S4 Other students expressed similar concerns . For instance , some students noted that their instructors asked them to be polite , but they were unsure what polite looked like , whether that meant being extra formal or somewhat casual . Students understood that employ - ers were looking for candidates that “fit the culture” but were not always sure what that looked like in written communication , thus creating the fear that the language they used might not be appro - priate . T1 shared that prior to introducing Lettersmith , students would adopt a very informal tone when contacting clients for the first time . [ Lettersmith ] helps them establish that the first meet - ing wasn’t ‘Hey client , it’s me , bro . ’ You know , it sets them up for success . It’s fine if that evolves into dif - ferent types of communication , but just having the first email go out from a student , not from us , and have it be something that’s appropriate , even if it’s an easygoing client , I think [ the students ] feel more like they’re professionals and the client feels more confident . I think that’s making a difference in that relationship . - T1 For instance , a “polite ask” or an “appreciative closing” were two common tone - based Checklist items with corresponding examples that instructors used . T6 shared that “in the end , they will forge their own relationship and develop their own tone , ” but a formal tone would start off a professional relationship on the right foot . Other instructors commented that providing guidance through annotated model texts , while ultimately letting students create their own draft , helped provide enough structure while allowing students to keep their personal writing style . While some students complained about the formal language that instructors required , instructors felt that it was most appropriate to start out the communication formally and have the client or employer dictate whether to transition to informal language . Encouraging Reflection : Our findings also illustrated how shared annotations and having students annotate their own drafts helped students reflect on their own writing in order to meet the expectations of the writing task . These practices was particularly helpful for students who did not approach professional writing in a particularly strategic way . I’m not very super organized , like I like do things as they come . . . I’m like , oh , this should be in here and I’ll like put it in there . And I’ll be like , wait , this should be in here too , I’ll put it in there . - S4 S4 describes adding content depending on what seems to be missing at the moment , rather than strategically choosing what in - formation to include and in what order beforehand . Yet , in following this haphazard approach to writing , students are more likely to for - get key elements . After using Lettersmith , some students described being motivated to review their own work and iterate after seeing the models of others’ writing . For instance , T11 noted that asking her students to annotate their draft helped them assess whether they had at least attempted each key element of that writing genre . With the [ Lettersmith shared annotation ] function , they can see clearly , ‘wow [ I ] didn’t include a topic with a summary of [ my ] skill . ’ So that’s going to help them to see the structure of their paragraph more explicitly . . . [ It helps them ] segment their paragraph writing into smaller , smaller , smaller ideas , and then they can see how they do with each idea . - T11 With ‘segment their paragraph writing into smaller , smaller , smaller ideas , ’ T11 is referring to how Lettermith helps students break down a larger piece of writing into more manageable tasks at the sentence level . Similarly , T7 expressed the same belief , stat - ing that Lettersmith could help students “de - familiarize their own documents” to “help them turn a critical eye to their own writing . ” By this , T7 meant that the shared annotations would help students take a step back and review whether their work included the key components . Overall , scaffolded annotations helped students iden - tify key components and provided different examples of how to accomplish them in their own writing—a combination of supports that students found particularly useful for getting started . 5 . 2 . 2 Scaffolded Annotation in Informing Instructor Practice . We foundthatimplementingscaffolded annotation inLettermsithhelped instructors clarify their teaching material , identify where students had misunderstandings , and reduce teaching load during early - stage writing instruction . Demonstrating Writing Expectations : Instructors expressed that the process of creating their shared annotations and applying them to model texts helped them outline and demonstrate expec - tations of the writing task more clearly . Their prior instructional material typically consisted of a rubric and sometimes an example , which combined was not enough for students to perform at the de - sired level . For instance , as demonstrated in the quasi - experimental study , without Lettersmith , students were significantly more likely to not include key components of an introductory client email , like a personal introduction and way of connection . Instructors found that enacting scaffolded annotation helped them reflect on their own expectations and more clearly articulate them to students . Prior to using Lettersmith , T7’s cover letter guidance was a relatively short instruction list asking students to include “relevant content , ” a “block - style paragraph structure , ” and “professional and friendly language in a business letter format . ” T7 explains how setting up the Lettersmith environment for teaching cover letters made her expectations more clear for herself—and for her students . I think using Lettersmith has definitely improved my approach to teaching cover letters , because it has forced me to really think about all of these different components and defining them in really clear terms . Normally I think I would obviously say you know , this is a cover letter format , these are essentially the pieces of information that you need to have included , but I had never actually asked students to go through and identify those pieces [ in ] examples and then present their [ drafts ] having identified how they’ve connected CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse those pieces in the example . I think that explicit con - nection and having them go through the action of identifying those things , that’s going to result in a much better understanding of how the cover letter works as a genre . - T7 We found that having the instructor provide annotated model texts helped demonstrate to students how they could make sense of their own writing . Another instructor expressed that Lettersmith pushed them to perform “modeling that I hadn’t done in other classes” ( T1 ) . While a ‘good’ model text or annotation is subjective to the instructor , instructors expressed the desire to maintain con - trol over these items in order to teach students what they felt were appropriate communication practices for their particular field ( e . g . engineering , UX design ) . Pinpointing Gaps in Learner Knowledge : Providing shared annotations helped guide students in annotating their own work , whichsurfacedgapsinstudent understanding . Afterstudentsdrafted their writing in Lettersmith , they were asked to annotate their own draft , which helped instructors pinpoint where students failed to understand certain concepts . T10 expressed that prior to using Lettersmith , he had spent significant class time teaching concepts without seeing improvements in students’ writing – “I started to be like , why are all my students writing these really mediocre para - graphs after we’ve had this conversation in class ? ” He then decided to implement Lettersmith and once students annotated their own work , T10 was able to identify what part of his instruction was confusing : One of the things that I found really useful was that I could look at what students were tagging and try to kind of understand how each of them was grasping those individual concepts about writing . So , for exam - ple , I had one student who was continuously tagging what was actually the main argument of their writing as context , and so we were able to have a conversation . It really helped me get into kind of the thinking on a sort of one - on - one basis with some of the students . . . I could look at [ their writing ] and say all right , there’s a fundamental misconception . - T10 He then used this information to structure follow - up meetings with students , citing that “they were able to have a conversation more about using those terms and those concepts . ” After using Let - tersmith paired with instructor follow - up , he found that “there was an immediate across - the - board improvement of student work once we implemented it . ” Similarly , T11 expressed that having students annotate helped her determine where students faced specific mis - understandings in the writing assignment , which in turn informed iterations in her teaching approach . I could see whether they understood the components that we talked about , for example , if they need to add a ‘goal’ for seeking this job , whether they understand what is a ‘goal , ’ and that they [ annotated ] the cor - rect content and know that they understood what we talked about in class . So , that’s kind of an efficient way for me to assess students’ initial performance before we can go to the higher level rhetorical strategies , like how they can make the argument more persuasive . - T11 Similarly , T7 , a technical communications instructor , expressed that seeing students’ annotations helped her identify that students did not understand the concept of a “Why me” statement—one of their shared annotations . She was able to reference that particular item as a common mistake in order to guide clarification conversa - tions with students : Somethingthattheywouldoftenmisunderstandabouttheperspectiveofthereaderistheywouldoftenfo - cus on I want this job because it’s really good for me . They would articulate that in different ways rather than thinking about the reader’s perspective . And so it was a lot of coaching them through their ‘Why me’ statement being both I’m really passionate about this and also , I would bring this to this company environ - ment , this is what I have to offer you . - T7 In this case , the instructor realized that guidance she was giv - ing might not have been sufficiently clear and that she needed to emphasize the importance of writing for the reader . Another in - structor shared a similar sentiment , describing how students would often annotate personal opinions rather than facts as descriptions of prior experience . For instance , instead of sharing concrete skills learned or tasks accomplished , students would make vague state - ments about how they “learned a lot . ” Seeing that students failed to write and annotate sufficient descriptions of prior work helped inform more targeted instruction of that particular element . Scaling Instruction of First Drafts : Instructors also found that using Letteresmith helped save them time in the long run by scaling instruction of writing first drafts in a new genre . Instructors expressed that much of their time prior to using Lettersmith was spent repeating the same basic instructions to students , despite pro - viding a rubric . With Lettersmith , students are required to annotate their drafts with the shared annotations , so that first drafts were less likely to make basic mistakes—an effect we observed through the quasi - experiment . T1 , who teaches a project - based course of about 180 students de - scribed that he does not have enough time to review every instance of client communication , especially in the beginning when students are first setting up the relationships all at once . He expressed that using Lettersmith allowed him to scale his writing guidance by em - bedding his repeated set of instructions in annotated model texts and having students annotate their own work following his guidelines . When a class is that size , there’s just too many . And we have four different sections that all meet . So it’s really hard to keep track of what’s going on in the class . In this case , we don’t have to do any of that . If you complete your Lettersmith assignment , you have to tag what you think a greeting is and you have to tag the connection to the project or your interest in working with the client or whatever it is . We can just define those pieces and they can move forward . And they do it on their own time . - T1 Of course , direct instruction is often most helpful for student learning . But , because T1 did not have time to provide direct instruc - tion to all his students to begin with , he was able to supplement Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany some of that instruction with the platform . Instructors who did have more time for direct instruction were able to use the insights garnered from Lettersmith to clarify student misunderstandings and focus on more complex rhetorical processes . Overall , our interview findings provide reasoning for why stu - dents using Lettersmith were more likely to include key elements of professional writing , an effect we saw from the quasi - experiment . Instructors were able to articulate expectations of professional writ - ing more clearly , which helped students better understand how to apply the appropriate writing practices to their own work . In addi - tion to the changes in instructional practice , drafting in Lettersmith helped students address challenges with enacting best practices of structure , content , and tone . 6 DISCUSSION This work answers calls from within the HCI community to identify tools and approaches that better support the cognitive processes of writing [ 45 ] . First , we found through a quasi - experimental study of a client - based project course that students using Lettersmith were more likely to include key components of the writing task com - pared to students who did not have access to the platform . Many of the instructors were motivated to use Lettersmith because they hoped it would help them scale instruction while reducing time spent reiterating best practices . For instance , instructors teaching project - based courses expressed frustration that students would often forget to include items like a course description or a meeting agenda in emails to new clients , despite in - class reminders . While some research on education support tools express that technology can introduce a “transactional distance” between instructors and students that can ultimately impede learning [ 68 ] , our interview data uncovered how scaffolded annotation helped instructors iden - tify students’ points of confusion , which informed more fruitful follow - up conversations and targeted lessons . Instructors expressed that they spent less time repeatedly pointing out the same basic mistakes and more time addresing more complex rhetorical moves . Second , we found through interviews that the features of scaf - folded annotation helped students writing task outcomes . By com - paring their own writing to that of the annotated model texts , stu - dents could determine whether they were covering similar content and level of detail . While some skills are more easily addressed , other skills like tone and structure have long been notoriously chal - lenging to teach [ 24 – 26 ] . Current solutions in HCI include using AI to suggest phrasing [ 12 , 29 , 30 , 42 ] and perform text evaluation [ 59 ] , but there is little evidence showing whether these interventions improve student understanding of the writing process or ability to write effectively outside of AI - supported contexts . Our interview data show that students using Lettersmith are more aware of these strategies and that instructors report an improvement in student writing quality . In particular , having students annotate their own work helped them reflect on the key components of the writing assignment . These findings provide additional insight to prior work on Letter - smith [ 49 ] by demonstrating similar results in real - world classroom adoption where instructors led the use of the tool . Students pointed to the annotated model texts and shared annotations as the most useful features of Lettersmith given that they provided guidance around what was expected and how to enact them . This aligns with the initial motivating principles from social cognitive theory and cognitive apprenticeship , which describes how context - relevant examples can improve learning of complex tasks while decreasing cognitive load [ 81 ] . 6 . 1 Scaffolded Annotation as an Instructional Approach for Early - Stage Writing Scaffolded annotation applies learning sciences principles from so - cial cognitive theory and cognitive apprenticeship to help teach the conceptually complex task of writing . Specifically , we build on writing pedagogies of using ‘model texts , ’ which emphasize the importance of learning from others as motivated by social cogni - tive theory , and ‘annotations , ’ which emphasizes the importance of making thinking visible as motivated by cognitive apprenticeship . Scaffolded annotation involves the following unique practices of 1 ) Annotated model texts that break down examples into understand - able and manageable components , 2 ) Shared annotations curated by instructors that outline key components of the writing task , and 3 ) Annotating one’s own drafts which encourage student reflection and can serve as models for others . Our findings demonstrate how the combination of these prac - tices is particularly helpful for guiding students who were first learning to write in new types of professional genres ( e . g . client emails , cover letters ) . Lettersmith helped translate the writing task “into smaller , smaller , smaller ideas , ” as one instructor described . This process of breaking complex tasks into more manageable steps is at the core of scaffolding and has been shown to increase learning and retention [ 75 ] . Furthermore , our data show how encouraging students to apply shared annotations to their own work enforces reflection . Reflection involves encouraging the learner to evaluate their performance by comparing their work to expert models and identifying opportunities for improvement [ 79 ] . Students expressed that seeing examples of writing helped them understand key ele - ments and determine whether they had met genre expectations in their own work . Approaches to writing instruction have reflected different episte - mologies based on how much guidance should be given to students [ 34 ] . In this case , instructors are encouraged to provide significant modeling and guidance to learners so that they understand what exemplary writing looks like in order to apply those practices them - selves . Opposing views argue that writing instruction should be hands - off , allowing students to write on their own with little inter - vention in order to learn through practice . While the latter allows for greater exploration and creativity , Lettersmith aligns with the former approach given the highly structured nature of professional writing [ 10 , 25 ] and the importance of learning from others in work - place contexts [ 65 ] . We find that scaffolded annotation increases transparency of teacher expectations , which has been shown to improve learning outcomes [ 32 , 99 ] and decrease attrition at the introductory level , particularly for underserved students [ 98 , 99 ] —a population we hope to support in future work . We also believe that the affordances of a digital tool , in this case Lettersmith , make scaffolded annotation possible . Through Letter - smith , students can browse annotated model texts regularly updated by the instructor , while instructors can examine how students apply CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse shared annotations in real time . Our interview data show that this allows students to leverage these practices to improve their writing structure , content , and tone , while allowing instructors to pinpoint student misunderstanding and inform targeted feedback . 6 . 2 Design Implications for Writing Support Tools Researchers should not only question what technology could do to advance writing production , but how such tools support writers themselves . While prior work has outlined advances in writing tools , like using AI to produce written documents , we believe re - search on supporting a writer’s growth should be equally important given the critical role individually - produced writing plays in online professional ( and personal ) relationship development . How might we create a hybrid future that leverages advances in AI technologies and writing pedagogy for writer skill development ? 6 . 2 . 1 Scaffold Rather than Perform Writing Tasks . Our focus is less on how technology can efficiently create well - written docu - ments and more on how technology can support writers themselves . Prior work on writing support tools in HCI have outlined myr - iad new ways AI [ 12 , 29 , 30 , 42 , 59 , 94 ] and crowd - based tools [ 7 , 14 , 55 , 58 , 70 ] are able to produce written products . While these innovations are novel , they do not necessarily address our particu - lar focus of centering the writer and improving their performance . Supporting writers is critical considering that people build new relationships and access socio - economic opportunities based on personally - written messages online . We suggest leveraging learn - ing and cognitive science principles to develop writing support tools that support the cognitive processes of writing . This might include designing supports for learning from others [ 13 ] , reflection [ 31 ] , sensemaking [ 21 , 77 ] , and just - in - time teaching [ 72 ] — each of which has been shown to support learner skill development of complex tasks . We introduced scaffolded annotation as one way to foster learning from others and reflection in the writing process . For instance , having students annotate their own work contrasts with writing instruction tools leveraging AI to automatically label student content for them . Rather than analyzing machine - generated annotations of one’s own text [ 93 – 95 ] , we encourage students to analyze instructor - annotated model texts and annotate their own work as part of the reflection process . While Lettersmith does not currently apply AI , we see opportunities for using these tools to help teach writers , rather than replacing them . For instance , AI could be used to enhance intelligent tutors for writing by providing just - in - time teaching when an instructor is not readily available . 6 . 2 . 2 Support Context Flexibility and Awarehess . Professional writ - ing is often hierarchical , highly structured , requires careful control of “professional” tone [ 11 , 45 ] . The boundaries of each of these attributes are unique to the context and industry , making learning professional writing a highly dynamic process [ 15 , 74 , 91 ] . For in - stance , the language for applying to a job at a small tech startup company is likely to be significantly different from the language used to apply to a large marketing company . Such variability re - quires writing tools that allow for flexibility depending on context for both the student and the instructor . For students , AI tools could support writers in making sense of model texts by automatically highlighting patterns in writing styles or helping evaluate the ac - curacy of student self - annotations on their own writing . However , machine - generated guidance informed by outdated training data could suggest communication practices that lead to negative ram - ifications on students’ careers . Thus , live instructor engagement in how these tools are implemented may continue to be necessary . With enough annotated model texts , AI could learn from exam - ples curated by expert writers ( instructors ) to surface annotation themes , such as categories of annotations and common tags . 6 . 2 . 3 Structure Evaluation from Peers and Experts . One of the ways technology has significantly advanced writing support is through feedback and reflection . For instance , AI platforms have been intro - duced to help evaluate whether a learner has succeeded or failed at particular rhetorical moves [ 93 , 95 , 96 ] . Similarly , other researchers have developed platforms that coordinate feedback between peers [ 60 , 62 ] . We highlight the importance of advancing this work and suggest further opportunities to structure such interactions be - tween writers and evaluators . As we have shown , Lettersmith uses shared annotations to help instructors to observe how students make sense of their work . Future work could implement human - in - the - loop feedback where AI tools produce initial suggestions , while instructors or peers could tag or comment on what they agree or disagree with depending on the context . This in turn would improve the algorithm for machine - generated evaluations depending on the situation . We believe humans are still a critical part of the feed - back process because nuances of professional writing are highly dependent on the context . Overall , we highlight these implications as opportunities for HCI researchers and designers to consider how to support people learning professional writing . While machine - generated content will definitely change the nature of communication in the future of work , developing the cognitive processes behind writing will continue to be a much needed skillset . Through this study , we pro - vide one approach to enhancing writing instruction via scaffolded annotation , and hope to continue testing on this approach in other contexts . 7 LIMITATIONS While we now have a greater understanding of how Lettersmith can support professional writing in a university setting , it is unclear whether these findings could scale to other contexts . For instance , we wonder whether such a platform could be useful in workforce development centers where job seekers seek guidance from em - ployment counselors . We also wonder how issues of digital literacy and access might influence the efficacy of Lettersmith . In addition , given the initial quasi - experimental approach , we were unable to randomize groups . However , this is not uncommon in education research [ 40 , 73 ] as setting up a true experiment is challenging in a classroom context and introduces ethical considerations when withholding a potentially positive intervention . Furthermore , be - cause the control group did not use a digital tool , some of the effects we observed may be due to the usage of a novel tool that may not replicate after continuous usage . However , since we encourage in - structors to use Lettersmith only in the early stages of learning a new genre , we believe the value of the intervention will persist . Finally , while our prior work demonstrates evidence of learning Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany through a within - subjects experiment among novice entrepreneurs [ 49 ] , we plan to perform future studies to see if we see similar learning effects long - term and in additional contexts . 8 CONCLUSION Employers have long called for improvements to teaching profes - sional writing in a college setting . We introduce the instructional approach of ‘scaffolded annotation’ and evaluate its use in the digital platform Lettersmith . Lettersmith guides students through the process of drafting professional writing via the scaffolded an - notation practices of 1 ) Annotated model texts that break down examples into manageable components , 2 ) Shared annotations cu - rated by instructors that outline key components of the writing task , and 3 ) Annotating one’s own drafts to encourage reflection and serve as models for others . Through a quasi - experiment of 90 students in a project - based course , we found that students drafting in Lettersmith were more likely to include key elements of introduc - tory client emails . Interviews with instructors and students who used Lettersmith described how applying scaffolded annotation helped clarify instructor expectations , guide tone , identify where students had misunderstandings , as well as encourage students to reflect on whether they met genre expectations . ACKNOWLEDGMENTS We would like to thank the University of Michigan Center for Aca - demic Innovation for funding this work and their team for continu - ing to improve Lettersmith . In particular , we thank Cait Hayward and Holly Derry for their support in the research process . We also thank Umang Bhojani and Charlotte Parent for helping with data collection . We thank John Chung , Soyoung Lee , Kentaro Toyama , Sarita Schoenebeck , and Mark Ackerman for their critical feedback on earlier drafts . Finally , we thank the students who participated in this study . REFERENCES [ 1 ] [ n . d . ] . ChatGPT . https : / / openai . com / blog / chatgpt / . Accessed : 2022 - 12 - 06 . [ 2 ] [ n . d . ] . Grammarly . https : / / www . grammarly . com / . Accessed : 2022 - 09 - 10 . [ 3 ] [ n . d . ] . Lettersmith . https : / / lettersmith . io / . Accessed : 2022 - 09 - 10 . [ 4 ] [ n . d . ] . LinkedIn . https : / / www . linkedin . com / . Accessed : 2022 - 09 - 10 . [ 5 ] [ n . d . ] . Perusall . https : / / www . perusall . com / . Accessed : 2022 - 09 - 10 . [ 6 ] LindaAdler - KassnerandElizabethWardle . 2015 . Namingwhatweknow : Thresh - old concepts of writing studies . University Press of Colorado . [ 7 ] Elena Agapie , Jaime Teevan , and Andrés Monroy - Hernández . 2015 . Crowd - sourcing in the field : A case study using local crowds for event reporting . In Third AAAI Conference on Human Computation and Crowdsourcing . [ 8 ] Laura K Allen , Matthew E Jacovina , and Danielle S McNamara . 2016 . Computer - Based Writing Instruction . Grantee Submission ( 2016 ) . [ 9 ] R Alsop . 2002 . Playing well with others . The Wall Street Journal 11 ( 2002 ) . [ 10 ] Paul A Argenti . 1996 . Corporate communication as a discipline : toward a definition . Management communication quarterly 10 , 1 ( 1996 ) , 73 – 97 . [ 11 ] Paul A Argenti and Janis Forman . 2002 . The power of corporate communication : Crafting the voice and image of your business . McGraw Hill Professional . [ 12 ] Kenneth C Arnold , Krzysztof Z Gajos , and Adam T Kalai . 2016 . On suggesting phrases vs . predicting words for mobile text composition . In Proceedings of the 29th Annual Symposium on User Interface Software and Technology . 603 – 608 . [ 13 ] Albert Bandura . 2001 . Social cognitive theory : An agentic perspective . Annual review of psychology 52 , 1 ( 2001 ) , 1 – 26 . [ 14 ] Michael S Bernstein , Greg Little , Robert C Miller , Björn Hartmann , Mark S Ackerman , David R Karger , David Crowell , and Katrina Panovich . 2010 . Soylent : a word processor with a crowd inside . In Proceedings of the 23nd annual ACM symposium on User interface software and technology . 313 – 322 . [ 15 ] Douglas Biber and Susan Conrad . 2009 . Registers , Genres , and Styles : Funda - mental Varieties of Language . ( 2009 ) , 1 – 28 . [ 16 ] Jeffrey P Bigham , Chandrika Jayant , Hanjie Ji , Greg Little , Andrew Miller , Robert C Miller , Robin Miller , Aubrey Tatarowicz , Brandyn White , Samual White , et al . 2010 . Vizwiz : nearly real - time answers to visual questions . In Proceedings of the 23nd annual ACM symposium on User interface software and technology . 333 – 342 . [ 17 ] Deborah Brandt . 2011 . Literacy as involvement : The acts of writers , readers , and texts . SIU Press . [ 18 ] AJ Brush , David Bargeron , Jonathan Grudin , Alan Borning , and Anoop Gupta . 2002 . Supportinginteractionoutsideofclass : anchoreddiscussionsvs . discussion boards . ( 2002 ) . [ 19 ] Mike Bunn . 2011 . How to read like a writer . Writing spaces : Readings on writing 2 ( 2011 ) , 71 – 86 . [ 20 ] Michele A Burton , Erin Brady , Robin Brewer , Callie Neylan , Jeffrey P Bigham , and Amy Hurst . 2012 . Crowdsourcing subjective fashion advice using VizWiz : challenges and opportunities . In Proceedings of the 14th international ACM SIGACCESS conference on Computers and accessibility . 135 – 142 . [ 21 ] Kirsten R Butcher and Tamara Sumner . 2011 . Self - directed learning and the sensemaking paradox . Human – Computer Interaction 26 , 1 - 2 ( 2011 ) , 123 – 159 . [ 22 ] Jessica McCrory Calarco . 2011 . “I need help ! ” Social class and children’s help - seeking in elementary school . American Sociological Review 76 , 6 ( 2011 ) , 862 – 882 . [ 23 ] Donald T Campbell and Julian C Stanley . 2015 . Experimental and quasi - experimental designs for research . Ravenio books . [ 24 ] Kim Sydow Campbell . 2012 . Just - in - case and just - in - time use of a video lecture - tutorial to teach students to manage tone in professional writing . Journal of Organizational Behavior Education 5 ( 2012 ) , 135 – 144 . [ 25 ] Kim Sydow Campbell . 2016 . Flipping to teach the conceptual foundations of successful workplace writing . Business and Professional Communication Quarterly 79 , 1 ( 2016 ) , 54 – 67 . [ 26 ] Kim Sydow Campbell , Kathryn Riley , and Frank Parker . 1990 . You - perspective : Insightsfromspeechacttheory . JournalofTechnicalWritingandCommunication 20 , 2 ( 1990 ) , 189 – 199 . [ 27 ] Jill Casner - Lotto and Linda Barrington . 2006 . Are they really ready to work ? Employers’ perspectives on the basic knowledge and applied skills of new entrants to the 21st century US workforce . ERIC . [ 28 ] Davida H Charney and Richard A Carlson . 1995 . Learning to write in a genre : What student writers take from model texts . Research in the Teaching of English ( 1995 ) , 88 – 125 . [ 29 ] John Joon Young Chung , Wooseok Kim , Kang Min Yoo , Hwaran Lee , Eytan Adar , and Minsuk Chang . 2022 . TaleBrush : Sketching Stories with Generative Pretrained Language Models . In CHI Conference on Human Factors in Computing Systems . 1 – 19 . [ 30 ] Elizabeth Clark , Anne Spencer Ross , Chenhao Tan , Yangfeng Ji , and Noah A Smith . 2018 . Creative writing with a machine in the loop : Case studies on slogans and stories . In 23rd International Conference on Intelligent User Interfaces . 329 – 340 . [ 31 ] Allan Collins , John Seely Brown , and Susan E Newman . 2006 . Cognitive appren - ticeship . Vol . 291 . Citeseer . [ 32 ] David E Copeland , MA Winkelmes , and KRIS Gunawan . 2018 . Helping students byusingtransparentwritingassignments . Integratingwritingintothepsychology course : Strategies for promoting student success ( 2018 ) , 26 – 37 . [ 33 ] Marcel Cornis - Pope and Ann Woodlief . 2003 . The rereading / rewriting process : Theory and collaborative , on - line pedagogy . Intertexts : Reading Pedagogy in College Writing Classrooms , edited by Marguerite Helmers , Lawrence Erlbaum ( 2003 ) . [ 34 ] Marion Crowhurst . 1990 . Teaching and learning the writing of persua - sive / argumentative discourse . Canadian Journal of Education / Revue canadienne de l’éducation ( 1990 ) , 348 – 359 . [ 35 ] Beverly Derewianka . 1990 . Exploring how texts work . Heinemann . [ 36 ] Sara Doan . 2021 . Teaching Workplace Genre Ecologies and Pedagogical Goals Through Résumés and Cover Letters . Business and Professional Communication Quarterly 84 , 4 ( 2021 ) , 294 – 317 . [ 37 ] Shayan Doroudi , Ece Kamar , Emma Brunskill , and Eric Horvitz . 2016 . Toward a learning science for complex crowdsourcing tasks . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems . 2623 – 2634 . [ 38 ] DanaLynnDriscoll , JosephPaszek , GwenGorzelsky , CarolLHayes , andEdmund Jones . 2020 . Genre knowledge and writing development : Results from the writing transfer project . Written Communication 37 , 1 ( 2020 ) , 69 – 103 . [ 39 ] Robert L Fowler and Anne S Barker . 1974 . Effectiveness of highlighting for retention of text material . Journal of Applied Psychology 59 , 3 ( 1974 ) , 358 . [ 40 ] Erin Marie Furtak , Tina Seidel , Heidi Iverson , and Derek C Briggs . 2012 . Exper - imental and quasi - experimental studies of inquiry - based science teaching : A meta - analysis . Review of educational research 82 , 3 ( 2012 ) , 300 – 329 . [ 41 ] Atul Gawande . 2010 . Checklist manifesto , the ( HB ) . Penguin Books India . [ 42 ] Katy Ilonka Gero , Vivian Liu , and Lydia Chilton . 2022 . Sparks : Inspiration for science writing using language models . In Designing Interactive Systems Conference . 1002 – 1019 . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Hui and Sprouse [ 43 ] Barney G Glaser and Anselm L Strauss . 2017 . The discovery of grounded theory : Strategies for qualitative research . Aldine . [ 44 ] F Elizabeth Gray , Lisa Emerson , and Bruce MacKay . 2005 . Meeting the demands oftheworkplace : Sciencestudentsandwrittenskills . Journalofscienceeducation and technology 14 , 4 ( 2005 ) , 425 – 435 . [ 45 ] Nick Greer , Jaime Teevan , and Shamsi T Iqbal . 2016 . An introduction to techno - logical support for writing . In ACM Conference on Human Factors in Computing Systems , Vol . 12 . [ 46 ] Lee W Gregg and Erwin R Steinberg . 2016 . Cognitive processes in writing . Routledge . [ 47 ] Alice S Horning , Deborah - Lee Gollnitz , and Cynthia R Haller . 2017 . What is college reading ? WAC Clearinghouse . [ 48 ] Damon Horowitz and Sepandar D Kamvar . 2010 . The anatomy of a large - scale social search engine . In Proceedings of the 19th international conference on World wide web . 431 – 440 . [ 49 ] Julie S Hui , Darren Gergle , and Elizabeth M Gerber . 2018 . Introassist : A tool to support writing introductory help requests . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . 1 – 13 . [ 50 ] Ken Hyland . 2015 . Teaching and researching writing . Routledge . [ 51 ] Anthony Abraham Jack . 2016 . ( No ) harm in asking : Class , acquired cultural capital , and academic engagement at an elite university . Sociology of Education 89 , 1 ( 2016 ) , 1 – 19 . [ 52 ] Tristan E Johnson , Thomas N Archibald , and Gershon Tenenbaum . 2010 . Indi - vidual and team annotation effects on students’ reading comprehension , critical thinking , and meta - cognitive skills . Computers in human behavior 26 , 6 ( 2010 ) , 1496 – 1507 . [ 53 ] Remi H Kalir and Antero Garcia . 2021 . Annotation . MIT Press . [ 54 ] NancyKaplanandYoramChisik . 2005 . Readingalonetogether : creatingsociable digital library books . In Proceedings of the 2005 conference on Interaction design and children . 88 – 94 . [ 55 ] Harmanpreet Kaur , Alex C Williams , Anne Loomis Thompson , Walter S Lasecki , Shamsi T Iqbal , and Jaime Teevan . 2018 . Creating better action plans for writ - ing tasks via vocabulary - based planning . Proceedings of the ACM on Human - Computer Interaction 2 , CSCW ( 2018 ) , 1 – 22 . [ 56 ] Ronald T Kellogg . 1996 . A model of working memory in writing . ( 1996 ) . [ 57 ] Ronald T Kellogg and Alison P Whiteford . 2009 . Training advanced writing skills : The case for deliberate practice . Educational Psychologist 44 , 4 ( 2009 ) , 250 – 266 . [ 58 ] Joy Kim , Justin Cheng , and Michael S Bernstein . 2014 . Ensemble : exploring complementary strengths of leaders and crowds in creative collaboration . In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing . 745 – 755 . [ 59 ] Simon Knight , Antonette Shibani , Sophie Abel , Andrew Gibson , and Philippa Ryan . 2020 . AcaWriter : A learning analytics tool for formative feedback on academic writing . Journal of Writing Research ( 2020 ) . [ 60 ] Yasmine Kotturi , Anson Kahng , Ariel Procaccia , and Chinmay Kulkarni . 2020 . Hirepeer : Impartial peer - assessed hiring at scale in expert crowdsourcing mar - kets . In Proceedings of the AAAI Conference on Artificial Intelligence , Vol . 34 . 2577 – 2584 . [ 61 ] Alex Kuhn , Brenna McNally , Shannon Schmoll , Clara Cahill , Wan - Tzu Lo , Chris Quintana , and Ibrahim Delen . 2012 . How students find , evaluate and utilize peer - collected annotated multimedia data in science inquiry with zydeco . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems . 3061 – 3070 . [ 62 ] Chinmay E Kulkarni , Michael S Bernstein , and Scott R Klemmer . 2015 . Peer - Studio : rapid peer feedback emphasizes revision and improves performance . In Proceedings of the second ( 2015 ) ACM conference on learning @ scale . 75 – 84 . [ 63 ] AngelaLaflen . 2020 . UsingElireviewasastrategyforfeedbackinonlinecourses . Assessing writing 46 ( 2020 ) , 100486 . [ 64 ] Sandra Tsui Eu Lam . 2021 . A web - based feedback platform for peer and teacher feedback on writing : An Activity Theory perspective . Computers and Composi - tion 62 ( 2021 ) , 102666 . [ 65 ] Jean Lave and Etienne Wenger . 1991 . Situated learning : Legitimate peripheral participation . Cambridge university press . [ 66 ] Amanda Licastro . 2019 . The past , present , and future of social annotation . In Digital reading and writing in composition studies . Routledge , 87 – 104 . [ 67 ] David W McDonald and Mark S Ackerman . 2000 . Expertise recommender : a flexible recommendation system and architecture . In Proceedings of the 2000 ACM conference on Computer supported cooperative work . 231 – 240 . [ 68 ] Michael Grahame Moore . 2013 . Theory of transactional distance . In Handbook of distance education . Routledge , 84 – 103 . [ 69 ] Schools National Commission on Writing for America’s Families and Colleges . 2004 . Writing : A ticket to work . . . or a ticket out : A survey of business leaders . College Board ( 2004 ) . [ 70 ] Michael Nebeling , Alexandra To , Anhong Guo , Adrian A de Freitas , Jaime Teevan , Steven P Dow , and Jeffrey P Bigham . 2016 . WearWrite : Crowd - assisted writing from smartwatches . In Proceedings of the 2016 CHI conference on human factors in computing systems . 3834 – 3846 . [ 71 ] David J Nicol and Debra Macfarlane - Dick . 2006 . Formative assessment and self - regulated learning : A model and seven principles of good feedback practice . Studies in higher education 31 , 2 ( 2006 ) , 199 – 218 . [ 72 ] GregorMNovak , EvelynTPatterson , AndrewDGavrin , andWolfgangChristian . 1999 . Just in time teaching . [ 73 ] Daniel J Peterson . 2016 . The flipped classroom improves student achievement and course satisfaction in a statistics course : A quasi - experimental study . Teach - ing of psychology 43 , 1 ( 2016 ) , 10 – 15 . [ 74 ] Mya Poe , Neal Lerner , and Jennifer Craig . 2010 . Learning to communicate in science and engineering : Case studies from MIT . MIT Press . [ 75 ] Brian J Reiser and Iris Tabak . 2014 . Scaffolding . In The Cambridge Handbook of the Learning Sciences , Second Edition . Cambridge University Press , 44 – 62 . [ 76 ] C . Rose - Wainstock . [ n . d . ] . Socialannotationinthewritingclassroom . Literacies and Language Education : Research and Practice ( [ n . d . ] ) . [ 77 ] Daniel M Russell , Mark J Stefik , Peter Pirolli , and Stuart K Card . 1993 . The cost structure of sensemaking . In Proceedings of the INTERACT’93 and CHI’93 conference on Human factors in computing systems . 269 – 276 . [ 78 ] Mariolina Rizzi Salvatori and Patricia Donahue . 2012 . Tracing the moves : How students read . Reader 62 ( 2012 ) , 80 . [ 79 ] Donald A Schön . 2017 . The reflective practitioner : How professionals think in action . Routledge . [ 80 ] Christian Schunn . 2016 . Writing to learn and learning to write through SWoRD . In Adaptive educational technologies for literacy instruction . Routledge , 243 – 260 . [ 81 ] Valerie J Shute . 2008 . Focus on formative feedback . Review of educational research 78 , 1 ( 2008 ) , 153 – 189 . [ 82 ] Marie Stevenson and Aek Phakiti . 2014 . The effects of computer - generated feedback on the quality of writing . Assessing Writing 19 ( 2014 ) , 51 – 65 . [ 83 ] AnselmStraussandJulietCorbin . 1998 . Basicsofqualitativeresearchtechniques . ( 1998 ) . [ 84 ] Anselm Strauss and Juliet M Corbin . 1997 . Grounded theory in practice . Sage . [ 85 ] Carola Strobl , Emilie Ailhaud , Kalliopi Benetos , Ann Devitt , Otto Kruse , Antje Proske , andChristianRapp . 2019 . Digitalsupportforacademicwriting : Areview of technologies and pedagogies . Computers & education 131 ( 2019 ) , 33 – 48 . [ 86 ] John M Swales and John Swales . 1990 . Genre analysis : English in academic and research settings . Cambridge university press . [ 87 ] Christine Tardy . 2009 . Building genre knowledge . Parlor Press LLC . [ 88 ] Christine M Tardy , Bruna Sommer - Farias , and Jeroen Gevers . 2020 . Teaching and researching genre knowledge : Toward an enhanced theoretical framework . Written Communication 37 , 3 ( 2020 ) , 287 – 321 . [ 89 ] Jakko Van der Pol , Wilfried Admiraal , and P Robert - Jan Simons . 2006 . The affordance of anchored discussion for the collaborative processing of academic texts . International Journal of Computer - Supported Collaborative Learning 1 , 3 ( 2006 ) , 339 – 357 . [ 90 ] Lev Semenovich Vygotsky and Michael Cole . 1978 . Mind in society : Development of higher psychological processes . Harvard university press . [ 91 ] Barbara E Walvoord and Lucille P McCarthy . 1990 . Thinking and Writing in College : A Naturalistic Study of Students in Four Disciplines . ( 1990 ) . [ 92 ] Thiemo Wambsganss , Tobias Kueng , Matthias Soellner , and Jan Marco Leimeis - ter . 2021 . ArgueTutor : An adaptive dialog - based learning system for argu - mentation skills . In Proceedings of the 2021 CHI conference on human factors in computing systems . 1 – 13 . [ 93 ] Thiemo Wambsganss and Christina Niklaus . 2022 . Modeling Persuasive Dis - course to Adaptively Support Students’ Argumentative Writing . In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) . 8748 – 8760 . [ 94 ] Thiemo Wambsganss , Christina Niklaus , Matthias Cetto , Matthias Söllner , Siegfried Handschuh , and Jan Marco Leimeister . 2020 . AL : an adaptive learn - ing support system for argumentation skills . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . 1 – 14 . [ 95 ] Thiemo Wambsganss , Christina Niklaus , Matthias Söllner , Siegfried Handschuh , and Jan Marco Leimeister . 2021 . Supporting cognitive and emotional empathic writing of students . arXiv preprint arXiv : 2105 . 14815 ( 2021 ) . [ 96 ] Thiemo Wambsganss , Matthias Söllner , Kenneth R Koedinger , and Jan Marco Leimeister . 2022 . AdaptiveEmpathyLearningSupportinPeerReviewScenarios . In CHI Conference on Human Factors in Computing Systems . 1 – 17 . [ 97 ] Denise Whitelock , Alison Twiner , John TE Richardson , Debora Field , and Stephen Pulman . 2015 . OpenEssayist : a supply and demand learning analyt - ics tool for drafting academic essays . In Proceedings of the fifth international conference on learning analytics and knowledge . 208 – 212 . [ 98 ] Mary - AnnWinkelmes . 2015 . Equityofaccessandequityofexperienceinhigher education . In The National Teaching & Learning Forum , Vol . 24 . Wiley Online Library , 1 – 4 . [ 99 ] Mary - Ann Winkelmes , Matthew Bernacki , Jeffrey Butler , Michelle Zochowski , Jennifer Golanics , and Kathryn Harriss Weavil . 2016 . A teaching intervention that increases underserved college students’ success . Peer Review 18 , 1 / 2 ( 2016 ) , 31 – 36 . [ 100 ] Joanna Wolfe . 2008 . Annotations and the collaborative digital library : Effects of analignedannotationinterfaceonstudentargumentationandreadingstrategies . Lettersmith : Scaffolding Written Professional Communication Among College Students CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany International Journal of Computer - Supported Collaborative Learning 3 , 2 ( 2008 ) , 141 – 164 . [ 101 ] Joanna L Wolfe . 2000 . Effects of annotations on student readers and writers . In Proceedings of the fifth ACM conference on Digital libraries . 19 – 26 . [ 102 ] Shaomei Wu , Lindsay Reynolds , Xian Li , and Francisco Guzmán . 2019 . Design andevaluationofasocialmediawritingsupporttoolforpeoplewithdyslexia . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . 1 – 14 . [ 103 ] Amy X Zhang and Justin Cranshaw . 2018 . Making sense of group chat through collaborative tagging and summarization . Proceedings of the ACM on Human - Computer Interaction 2 , CSCW ( 2018 ) , 1 – 27 .