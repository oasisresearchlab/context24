Tapping into the Natural Language System with Artificial Languages when Learning Programming Elisa Madeleine Hartmann Chemnitz University of Technology Chemnitz , Saxony , Germany Annabelle Bergum Graduate School of Computer Science , Saarland University , Saarland Informatics Campus Saarbr√ºcken , Germany Dominik Gorgosch Chemnitz University of Technology Chemnitz , Saxony , Germany Norman Peitek Saarland University , Saarland Informatics Campus Saarbr√ºcken , Germany Sven Apel Saarland University , Saarland Informatics Campus Saarbr√ºcken , Germany Janet Siegmund Chemnitz University of Technology Chemnitz , Saxony , Germany ABSTRACT Background : In times when the ability to program is becoming increasingly important , it is still difficult to teach students to be - come successful programmers . One remarkable aspect are recent findings from neuro - imaging studies , which suggest a consistent role of language competency of novice programmers when they learn programming . Thus , for effectively teaching programming , it might be beneficial to draw from linguistic research , especially from foreign language acquisition . Objective : The goal of this study is to investigate the feasibility of this idea , such that we can enhance learning programming by activating language learning mechanisms . Method : To this end , we conducted an empirical study , in which we taught one group of students an artificial language , while an - other group received an introduction into Git as control condition , before we taught both groups basic programming knowledge in a programming course . Result : We observed that the training of the artificial language can be easily integrated into our curriculum . Furthermore , we observed that language learning strategies were activated and that partici - pants perceived similarities between learning the artificial language and the programming language . However , within the context of our study , we did not find a significant benefit for programming competency when students learned an artificial language first . Conclusion : Our study lays the methodological foundation to ex - plore the use of natural language acquisition research and expand this field step by step . We report our experience here to guide re - search and to open up the possibilities from the field of linguistic research to improve programming acquisition . KEYWORDS Program Comprehension , Learning to Program , Artificial Language , Artificial Grammar , Brocanto , Empirical Research , Artificial Gram - mar Learning 1 INTRODUCTION Learning to program is difficult [ 25 ] . At universities , students have been failing their programming courses for decades [ 4 , 5 , 45 , 50 ] , and even for those who pass their courses , it is unclear what pro - gramming skills they have actually developed [ 23 , 24 , 27 , 46 , 49 ] . The problem is that , despite decades of research and dedicated re - search communities , we still do not know how to effectively teach programming [ 4 , 5 , 23 , 27 , 46 , 49 ] . In recent neuro - imaging studies on programming , researchers have identified consistent activation of brain areas related to lan - guage processing [ 19 , 22 , 32 , 36 , 43 ] , indicating a closeness of pro - gramming and language processing . This appears reasonable , as there are similarities between the process of learning a program - ming language and the process of learning a natural language : In both cases , learners need to develop an understanding of the rules and structure of a language , as well as the ability to use it to communicate and accomplish specific tasks . Few studies already observed a similarity , for example , in the acquisition of syntax and semantics [ 42 , 48 ] . Thus , it seems opportune to employ a language learning lens to programming . This way , we can tap into the widely explored field of natural language learning . A typical way to study language learning uses artificial gram - mars and languages [ 12 , 15 , 20 , 21 , 29 , 30 , 37 , 38 ] . The advantage compared to using natural languages is that , in an artificial lan - guage , the impact of an already learned language can be reduced . In addition , artificial languages are much smaller than natural lan - guages , so they can be learned in a short time ( e . g . , within a few hours ) . Neuro - imaging studies based on artificial languages show an involvement in activation of typical language processing areas [ 34 ] , demonstrating that artificial languages are a valid substitute for studying natural languages . We take advantage of this connection and draw on this expe - rience for a better understanding and training of programming . Our first goal is to evaluate whether the approach of building on artificial grammars and languages can be transferred to program - ming experiments . Specifically , we evaluate whether we can train language learning aspects with an artificial language before stu - dents start learning programming , such that learning programming becomes easier . Our goal is to activate language learning strate - gies by learning the artificial language . As the chosen language consists of syntactical constructs , apart from semantic activation , we investigate the transfer from the language learning strategies to syntactical constructs as i . e . if - conditions . Therefore , our focus does not yet lie on programming competencies , but on the learn - ing process itself , which should be simplified . With the results of a r X i v : 2402 . 01657v1 [ c s . C Y ] 12 J a n 2024 Elisa Madeleine Hartmann , Annabelle Bergum , Dominik Gorgosch , Norman Peitek , Sven Apel , and Janet Siegmund this study we will be able to make additional assumptions on the learning process and its link to program comprehension . We expect that training strategies used to learn artificial lan - guages taken from the repertoire of language learning strategies have a positive effect on learning programming . These strategies in - clude the transfer of pattern templates of already known structures to a new language [ 39 , 40 ] . An example is inversion in German , which describes a change in the word order of a main clause when , for example , a temporal adverb is inserted ahead : In a simple main sentence , the verb follows the noun , for example : ‚ÄùDie Katze ( noun ) ist ( verb ) schwarz ( adjective ) . ‚Äù ( ‚ÄúThe cat ( noun ) is ( verb ) black ( ad - jective ) . ‚Äù ) . With an added temporal adverb , the noun and verb swap positions : ‚ÄùHeute ( adverb ) ist ( verb ) die Katze ( noun ) schwarz ( ad - jective ) . ‚Äù ( ‚ÄúToday ( adverb ) is ( verb ) the cat ( noun ) black ( adjective ) . ‚Äù ) . That a transfer takes place can be observed in the fact that this specialty in syntax often causes problems for English - speaking learners of German , who form the sentence according to English syntax without active verb displacement by adding the temporal adverb without changing anything in the rest of the syntax ( e . g . , ‚ÄúThe cat is black‚Äù vs . ‚ÄúToday , the cat is black‚Äù ) [ 35 ] . These so - called interferences illustrate that knowledge of a native or already ac - quired language transfer to a ( new ) foreign language ( and vice versa ) . It also demonstrates that consistent or similar structures can be acquired with less effort . This has also been observed when programmers learn a new programming language , such that natural language transfer concepts also come into play when learning a new programming language and learning to program , including observable interference [ 42 , 48 ] . This might also apply when learning programming is preceded by learning an artificial language , such that areas in the brain related to language processing might adapt to processing a programming language . This adaptability is an inherent property of the brain to adapt to new tasks : For example , the fusiform face area is involved in face recognition , but also has adapted in bird experts to recognize birds , and in car experts to recognize cars ( but not vice versa ) [ 16 ] . Just like the fusiform face area can adapt to other tasks , the language processing area ( s ) are active during programming . Thus , tapping into the language system might help in learning programming . To evaluate the feasibility of teaching an artificial language as a vehicle for transfer to train beginner programmers , we explore the experiment design landscape . As a first step , we developed a programming course for beginner programmers that starts with learning the artificial language Brocanto before learning program - ming . Brocanto is used in linguistic neuroscience studies , and has proved successful in natural language learning studies [ 3 , 8 , 15 , 29 ‚Äì 31 ] . It is structurally adapted to natural languages and consists of nominal phrases connected by verb phrases , both of which are constructed with pseudowords . Notably , Brocanto is also similar to programming languages , in that it has a restricted syntax and a fixed set of keywords . To evaluate the effect of learning Brocanto on learning programming , we conducted a study , in which one group learned Brocanto before programming ( Brocanto group ) , and a control group received an introduction to Git before program - ming ( Git group ) . All students from the Brocanto group successfully learned it within one hour . Additionally , we asked the students after the course whether they recall using specific strategies in learning the artificial language , and students mentioned that they oriented themselves along certain aspects of the language ( from single words to phrase structure forming markers ) . Despite hints that language learning strategies were activated in the Brocanto group , there was no statistically significant difference regarding programming learning within the context of our study . However , our study spanned only one week , and an effect might be observable only at a later point . For further assessment , we take a look at the results of programming tasks from the first semester course Algorithms and Programming after the first semester to get an extended impression . Nevertheless , our experiment design provides a framework for conducting further programming learning studies that are facilitated by language learning , and the statements of the participants motivate us to further explore this experimental landscape . Based on the results , we describe a road map to continue this line of work by formulating 11 conjectures that are promising for future research . In summary , we make the following contributions : ‚Ä¢ An experiment design using an artificial language to improve learning programming ‚Ä¢ 11 conjectures to guide future research ‚Ä¢ A replication package containing all information to replicate and adapt our study 2 BROCANTO In this section , we provide an overview of Brocanto , its use cases , and how we used it in our study . We start by discussing why it is a suitable artificial language in the context of programming learning . 2 . 1 Motivation In experiments on natural languages , artificial languages have proven to be valid substitutes for natural languages [ 30 , 31 ] . As we put the natural language ( learning ) into focus in this study , we decided against a treatment with another programming language . Therefore , it would have been a study on transfer . For the same reason , we also did not choose to contradict syntax exercises with Python , so called ‚ÄôDrill tasks‚Äô as we wanted to implicitly activate learning mechanisms that are used in natural language learning . Our goal is to evaluate whether learning an artificial language can act as a transfer medium of concepts from a natural language to a programming language . This way , we tap into the language system to make programming learning easier . It is reasonable to believe that this is possible , because artificial grammars , much like pro - gramming languages , have strict structure rules and are typically fast to learn ( i . e . , within a few hours ) [ 20 , 21 , 30 ] . Brocanto consists of universal principles of natural languages , such as ( pseudo ) words , phrases , and syntax rules , which also count for programming languages . Thus , Brocanto can act as a bridge element between natural languages and programming languages . Additionally , Brocanto supports transfer , so that knowledge from a known natural language is applied in learning Brocanto [ 47 ] . This can be seen in phrase structure rules and finite - state gram - mar , which are language learning methods that are active in the acquisition of an artificial language [ 37 , 38 ] . First , the phrase structure rules method describes that language learning entails breaking down a language‚Äôs constituent parts , also known as syntactic categories , into its phrases . Since Brocanto has Tapping into the Natural Language System with Artificial Languages when Learning Programming a phrase structure grammar , a transfer of this knowledge of natural languages can be applied to learning Brocanto . In other words , when learning Brocanto , students decompose Brocanto sentences in substructures as part of the learning process , which also happens during processing natural languages [ 37 , 38 ] . Second , the finite state grammar focuses on the probability of transition of individual elements , which increases with an increas - ing similarity between languages . For example , Brooks and Vokey found that , with similarity - based learning , students apply grammat - ical knowledge to a new set of letters ( from artificial grammars ) [ 6 ] . Thus , what is similar is also more easily transferred between lan - guages . Both learning strategies have been observed in studies with Brocanto , making it particularly suitable for our experiment . 2 . 2 Definition With its different nominal and verb phrase formations , Brocanto allows the definition of main clauses with a subject - verb - [ object ] structure . Formally , Brocanto is defined as : ‚Ä¢ Start symbol S ‚Ä¢ S : = NP ‚ó¶ VP | NP ‚ó¶ VP ‚ó¶ NP ‚ñ∑ Sentence ‚Ä¢ NP : = d ‚ó¶ N | D ‚ó¶ M ‚ó¶ N ‚ñ∑ Nominal Phrase ‚Ä¢ VP : = v | v ‚ó¶ m ‚ñ∑ Verb Phrase ‚Ä¢ N : = gum | trul | plox | tok ‚ñ∑ Noun ‚Ä¢ v : = pel | prez | glif | rix ‚ñ∑ Verb ‚Ä¢ M : = b√∂ke | f√ºne ‚ñ∑ Adjective ‚Ä¢ m : = n√∂ri | r√ºfi ‚ñ∑ Adverb , Verb - Suffix ( Conjugation ) ‚Ä¢ d : = aaf ‚ñ∑ Definite Article , Pronoun ‚Ä¢ D : = aak ‚ñ∑ Definite Article , Pronoun The nominal phrase ( NP ) consists of a determiner ( D , d ) , option - ally an adjective ( M ) , and a noun ( N ) . Thus , a nominal phrase can be written formally as ( dN or DMN ) . Verb phrases ( VP ) consist of a verb ( v ) , and optionally an adverb or verb - suffix ( m ) , and can be written as v or vm . Thus , the sentence aaf plox prez aak b√∂ke trul is correct according to Brocanto syntax , but aaf plox prez b√∂ke trul is not , because prez b√∂ke trul does not follow the construction of nominal phrases , as b√∂ke trul does not have a determiner ( aaf or aak ) . The standard protocol to teach artificial languages is to confront participants with grammatically correct and incorrect sentences [ 20 , 37 , 38 ] . There are three different types of grammatical violations that have proved successful for learning Brocanto [ 29 , 31 ] : Phrase order violations , determiner - noun agreement violations , and word category repetitions . Phrase order violation . The valid phrase order of a sentence is violated when the order of phrases does not conform to NP + VP or NP + VP + NP . For example , if the verb phrase is put at the begin - ning of a sentence , the phrase order is violated ( see Table 1 for an example ) . Determiner - noun agreement violation . Brocanto distinguishes be - tween two determiners : one that can form the nominal phrase with the noun alone ( d ) and another that can form the nominal phrase only with the addition of an adjective ( D + M ) . The determiner D must be followed by an adjective M before the noun N . The deter - miner d can only be followed by a noun N . Ignoring this rule and adding an adjective M to the determiner d leads to an agreement violation ( cf . Table 1 ) . Word category repetition . Since Brocanto has fixed word cate - gories , each word can be assigned a concrete position within a phrase ; within phrases , word categories cannot repeat . If two nouns occur in one nominal phrase , the structure of that phrase is violated ; it does not matter at which position the word category repetition is placed ( cf . Table 1 ) . We use these three kinds of violations in our experiment . 2 . 3 Adaptation For our experiment , we adapted Brocanto to fit within the time frame of our study , as the full version takes several hours to learn . The stimulus material that we created followed the treatment according to Opitz 2011 [ 29 ] included all pseudowords from Brocanto . The pilot showed that in the context of our short treatment , using sentences with all possible 14 pseudowords leads to cognitive overload . So we adapted the material to Opitz [ 30 ] , in which the procedure more closely matched our time period . Specifically , we restricted the sentence length to 5 to 8 words and shortened the set of Brocanto ‚Äôs pseudowords . From the 14 pseudowords , we included 9 in our study ( 3x N , 2x v , 1x M , 1x m , 1x d , 1x D ; cf . Fig . 1 ) . 3 EXPERIMENT DESIGN Having introduced Brocanto , we present the design of our study . Details of questionnaires , course material , and data are available at the project‚Äôs Web site 1 . 3 . 1 Research Question To guide our experiment design , we pose the following research questions : RQ _ 1 Can we feasibly integrate artificial language learning into our curriculum ? RQ _ 2 Does learning the artificial language Brocanto benefit learn - ing how to program in a beginner programming course compared to learning Git ? To measure a possible effect of learning Brocanto on learning pro - gramming , we follow a between - subjects design . The independent variable is the treatment each group receives : One group learns Brocanto , the other group gets an introduction to Git as control , so that not only the extra time students spend with learning something ( new ) affects programming learning . To operationalize programming skill , we conduct programming tests at the beginning ( pretest ) and end ( posttest ) of the course and measure the number of correct answers in each test . To control for programming experience and knowledge , we divide the participants into two comparable groups based on a questionnaire applied before the study . We explain the details of the tests and questionnaire next . 3 . 2 Task and Material This section explains the questionnaires , tests , and material in the order in which they appeared in our study , which was run over one week . 1 https : / / github . com / brains - on - code / Tapping - into - the - Natural - Language - System - Using - Artificial - Languages - when - Learning - Programming Elisa Madeleine Hartmann , Annabelle Bergum , Dominik Gorgosch , Norman Peitek , Sven Apel , and Janet Siegmund NP NP 2 ( opt . ) VP N : gum | trul | plox v : pel | prez M : f√ºne m : r√ºfi d : aaf D : aak Figure 1 : Brocanto Transition Diagram / Automat Table 1 : Violation Overview Violation Structure Example Brocanto Example Natural Language Example No Violation NP + VP + NP aak f√ºne trul prez aaf plox My black cat makes the noise . Phrase order violations NP + NP + VP aak f√ºne trul aaf plox prez My black cat the noise makes . Determiner - noun agreement violations d + M + N + v + d + N aaf f√ºne trul prez aaf plox My the black cat makes the noise . Word category repetitions D + N + M + N + v + d + N aak plox f√ºne trul prez aaf plox My noise black cat makes the noise . Pretest . The first day of the study included an introduction round to welcome participants and to assess previous programming experi - ence . Then , students completed an adapted version of an established programming experience questionnaire [ 44 ] and a test to assess existing programming skills [ 1 ] . The pretest by Ahadi and others provided us with an extended assessment of students‚Äô experience by using an applied variable swap to evaluate whether basic pro - gramming concepts are already known . It consists of 8 tasks , each of which can either be solved correctly ( 1 point ) , or incorrectly ( 0 points ) , leading to a maximum of 8 points in this test . The results from the questionnaire and pretest were the basis to create two comparable groups regarding programming skill . On the next day , the two groups individually received their treatment in Brocanto or an introduction to Git . Treatment Brocanto . For the treatment , we created 60 correct sentences and 60 incorrect sentences , 20 of each of the three types of violation ( cf . Section 2 . 2 ) . For teaching Brocanto , we followed standard procedure with three types of blocks that were repeated : Learning , testing , and distractor ( see Figure 1 for an overview ) [ 20 , 21 , 31 ] . In the learning block , participants see 10 correct sentences , each for 7 seconds , and are instructed to deduct the underlying grammar rules . Between each of the 10 sentences , a fixation cross was shown for 2 seconds in the center of the screen . In the test block , participants see 10 sentences , each for 7 seconds . 5 of the sentences are correct , and 5 incorrect , containing any of the three violations , ( cf . Section 2 ) , in random order . Of the correct sentences , around half were already shown in the learning block , and the other half were entirely new . The sentences with violations were new to the participants , and no violated versions of the sentences shown in the learning block . Due to Brocanto‚Äôs limited repertoire of words and phrases , sentences that were shown in correct form in the learning block may appear in violated form in one of the test blocks . Because of the violations , the sentences are not comparable . Participants were instructed to intuitively decide as fast as possible whether the sentence was correct or incorrect by pressing the right ( correct ) or left ( incorrect ) arrow key . After each decision , participants immediately received feedback for 1 second . If participants did not respond within the 7 seconds , the decision was logged as incorrect and participants could proceed by pressing the space bar . The purpose of the distractor block was to inhibit memorization of grammar rules and correct / incorrect sentences , so participants still deduct them in subsequent blocks . To this end , the distractor block contained a forced key choice , in which participants saw one of two colored geometrical shapes . For a red square , participants should press y , followed by space , and for a yellow circle , n , followed by space . These three blocks were repeated five times , summarized into one cycle . The experiment consisted of 3 cycles . After each cycle , participants could take a short break ( e . g . , loosen their hands ) and continue by pressing the space bar . The two geometrical shapes that participants had to react to in the distractor block did not change . Since it is easy to remember the two key choices , the distractor block might no longer distract properly towards the end of the experiment . For this reason , the instruction on how to react was omitted in the last 3 cycles . The participants had to react from memory with the correct key choice when seeing the respective geometric shape . They were not informed beforehand that the instruction would be omitted at the end . The active confusion was to support that they had to fall back on implicit learning that was trained in the experiment in the last test blocks . Participants completed a short warm - up cycle of the same setting consisting of 4 combinations of an artificial grammar of letters to familiarize themselves with the experiment setting . Control Git . Participants received a brief introduction to version control systems and the advantages of Git over clouds or local version control systems . Afterward , we taught the basic concepts and commands of Git ( e . g . , push , pull , commit ) . We showed them Tapping into the Natural Language System with Artificial Languages when Learning Programming aak f√ºne trul prez aaf f√ºne 5x R e s t Learning Test Distractor F ee db ac I n s t r u c ti o I n s t r u c ti o aak f√ºne trul pel aak f√ºne aak f√ºne trul prez aaf f√ºne 5x 7s 3s R e s t 7s 1s Learning Test Distractor F ee db ac I n s t r u c ti on I n s t r u c ti on I n s t r u c ti on 1s 10x 10x aak f√ºne trul pel aak f√ºne aak f√ºne trul prez aaf f√ºne 5x aak f√ºne trul prez aaf f√ºne 5x R e s t Learning Test Distractor F ee db ac I n s t r u c ti o I n s t r u c ti o aak f√ºne trul pel aak f√ºne aak f√ºne trul prez aaf f√ºne 5x 7s 3s R e s t 7s 1s Learning Test Distractor F ee db ac I n s t r u c ti on I n s t r u c ti on I n s t r u c ti on 1s 10x 10x aak f√ºne trul pel aak f√ºne aak f√ºne trul prez aaf f√ºne 5x aak f√ºne trul prez aaf f√ºne 5x R e s t Learning Test Distractor F ee db ac I n s t r u c ti o I n s t r u c ti o aak f√ºne trul pel aak f√ºne aak f√ºne trul prez aaf f√ºne 5x 7s 3s R e s t 7s 1s Learning Block Test Block Distractor F ee db ac I n s t r u c ti on I n s t r u c ti on I n s t r u c ti on 1s 10x 10x aak f√ºne trul pel aak f√ºne trul aak f√ºne trul prez aaf f√ºne gum 5x 5x Figure 2 : Illustration of one experiment cycle Day 1 I n t r o d u c t i o n [ GraÔ¨Åk zu Verlauf Vorkurs : 2d ~ 4hours ( 10 - 14 : 30 , incl . 30min Mittagspause ) + 1d 1h + Posttest ] P r e t e s t & E xp e r i e n ce Day 2 I n s t r u c t i o n T r ea t m e n t o r I n t r o d u c t i o n Day 3 C o u r s e C o n t e n t C o u r s e C o n t e n d 10am - 2 : 30pm C o u r s e C o n t e n t C o u r s e C o n t e n t Day 2 Day 1 Day 4 Day 3 Day 5 P o s tt e s t & P r og . T a s k I n t e r v i e w s C ou r s e C on t e n t C ou r s e C on t e n t C ou r s e C on t e n t C ou r s e C on t e n t C ou r s e C on t e n t B r o ca n t o o r G it I n s t r u c ti on s I n t r odu c ti on Figure 3 : Procedure of Programming Course how to create new projects , add content , and create new branches with GitHub Desktop . During the creation of the new branches , we explained potential merge conflicts . After this introduction , the participants were able to create a new project , clone a project , and use the standard Git - commands . The participants did not practice programming commands in the process . Programming Instructions . The remaining days , both groups met again in the same room and received programming training in Python , covering basic aspects , such as variables , data types , and control structures , adapted from a course of Xie and others [ 51 ] . This included intermediate programming assignments to asses whether the concepts were understood . Posttest . On the last day of the programming course , a posttest was administered . It consisted of two parts : First , the pretest was repeated , but with different variable values . Second , participants solved a programming task , which was to compute the average of all numbers between 1 and 100 that were multiples of 5 and print the result . The solutions were categorized into correct ( 2 points ) , conceptually mostly correct ( 1 point ) , and incorrect ( 0 points ) . Interviews . Within two weeks of the study , we conducted retro - spective voluntary interviews with 4 participants from the course . Of these , 3 belonged to the Brocanto group and 1 to the Git group . With the interviews , we gain detailed insights into possible ap - plied strategies of the students in learning the artificial language as well as programming by having them reflect on the experiment , the Git introduction , and the course assignments . The interviews lasted about 30 minutes . The participants received a small expense allowance . The two course instructors each interviewed one partic - ipant together in a semi - structured interview . In general , partici - pants were encouraged to reflect freely on topics . Open questions about possible problems in programming , repeating the tasks in the experiment and Git , and whether the treatment was helpful or hindering for learning programming provided the frames for reflec - tion . The interview was digitally recorded and the recording was transcribed and anonymized in a further step for data protection and analysis reasons . Elisa Madeleine Hartmann , Annabelle Bergum , Dominik Gorgosch , Norman Peitek , Sven Apel , and Janet Siegmund Table 2 : Pretest , exercises per programming construct and the posttest , as well as the posttest programming task and its percentage correctness divided by test and control group . The programming posttest is presented on a scale between 0 and 2 . Exercise Scores Posttests Scores Parti - cipant Pretest Data types Variables Arithmetic Print Logical Conditionals Loops Overall Program - ming AaP PG1 88 100 88 86 71 95 60 81 100 2 - PG2 63 100 100 100 100 85 100 89 100 2 42 PG3 0 100 96 81 71 90 68 66 69 0 - PG4 63 100 92 89 57 90 92 57 88 2 41 PG5 100 100 100 100 100 100 100 15 * 100 2 11 Mean 63 100 95 91 80 92 84 73 91 1 . 6 31 . 3 PB1 31 100 96 100 100 85 100 81 100 2 - PB2 38 100 96 94 100 85 96 78 88 2 - PB3 0 100 100 94 71 80 100 88 100 2 - PB4 75 100 100 97 100 95 100 98 75 2 - PB5 94 100 100 100 100 95 96 100 81 2 - PB6 94 100 96 97 100 95 100 99 100 2 28 PB7 25 100 96 100 71 85 100 63 75 1 - PB8 100 92 88 - + - + 100 96 85 100 2 34 Mean 57 99 97 97 92 90 99 87 90 1 . 9 31 * Did not solve all tasks regarding loops due to illness and is not included in this mean . + Did not attend these assignments . - Cancelled the semester course . 3 . 3 Participants To investigate our research question , we need participants inter - ested in programming , but with no to little prior experience with programming . Thus , we were looking for students enrolled in their first semes - ter at the Computer Science department from the first author . Via information events , flyers , and the Web site of the computer science department , we offered a voluntary pre - course for first - year stu - dents , in which basics of programming are taught . The experiments were part of this programming course . The researchers conducting the programming course were not involved in the courses that students completed in first semester . Despite extensive advertising of the course , we received fewer registrations than planned . Ad - ditionally , we excluded students who indicated at least medium programming experience . Since the students had not yet started their studies at that time , we were not able to contact all first se - mester students . We also could not reach any further participants after the course had started . With the interviews conducted after the course , we gathered more qualitative information to counter the small sample size . In the end , 20 students participated in the study . We divided them into two balanced groups according to their prior programming experience and age , to ensure that both groups have comparable prerequisites for learning programming ( cf . Table 3 ) . 11 participants ( 8 men ; 3 women , mean age 22 years ) were in the Brocanto group , and 9 participants ( 8 men , 1 woman , mean age 21 years ) were in the control group . According to the pretest , both groups are comparable regarding their programming competency ( Brocanto group : 4 . 56 ¬± 3 . 05 ; Git group : 5 . 0 ¬± 3 . 08 ) . In the end , however , 5 participants from the control group and 8 from the Brocanto group took part in Table 3 : Group division according to pretest Group Age Gender Group Age Gender Treatment 19 m Control 22 m Treatment 25 m Control 18 m Treatment 28 m Control 18 m Treatment 18 m Control 18 m Treatment 32 w Control 24 m Treatment 21 m Control 29 m Treatment 18 w Control 18 m Treatment 18 m Control 18 m Treatment 19 m Control 20 w Treatment 19 m Treatment 22 w the posttest . Of these , 3 students of the control group completed the Algorithms and Programming course , and 2 students of the treatment group . 3 . 4 Procedure We show an overview of the study in Figure 3 . All 20 participants came to the same room , were greeted , and the details of the course were explained , after which the pretest and questionnaire were administered . On the next day , the Brocanto group and Git group met in different rooms and learned Brocanto or Git . The remaining days covered the introduction to programming , and the last day concluded with the posttest , after which the participants left . We conducted the interviews in the subsequent weeks . Six months after Tapping into the Natural Language System with Artificial Languages when Learning Programming                                                            3  H  U  F  H Q  W  D J H    R  I   F  R  U U  H  F  W   D Q  V  Z  H  U  V  & \ F O H    & \ F O H    & \ F O H    3 %   3 %   3 %   3 %   3 %   3 %   3 %   3 %   P H D Q Figure 4 : Correctness of the Brocanto group in the test blocks . Note that the y - axis starts at 35 . the experiment , we obtained the points that students achieved in their mandatory Algorithms and Programming course . 3 . 5 Deviations One of the participants mistakenly joined the Brocanto group on the treatment day . That is why the number of participants is not per - fectly balanced to 10 students per group ; nevertheless , the groups havecomparableprogrammingcompetencyaccordingtothepretest . Furthermore , several participants dropped out because the course was too easy for them . This considerably reduces the power of our experiment . 4 RESULTS 4 . 1 Learning Brocanto First , we evaluate whether participants learned Brocanto . In Fig - ure 4 , we show the performance of the Brocanto group in the test blocks , in which they decided whether a sentence was correct or not . Correctness generally increases , so we can assume that the pro - ficiency in Brocanto has increased . Although not perfectly correct , these numbers are in line with typical studies , so we can conclude that students successfully learned Brocanto [ 29 , 31 ] . 4 . 2 Programming Competency We evaluated the correctness of the programming tasks manually and generated descriptive and inferential statistics using the Python library Pandas . In Table 2 and Figure 5 , we show an overview of the correctness for the pretest , intermediate assignments in the course , and the posttest . The correctness is comparable across all tasks , but for completeness , we conducted a significance test . Since the assumptions for an ANOVA are not met ( i . e . , normal distribu - tion ) , we use the Kruskal - Wallis test as non - parametric alternative . As expected with these comparable correctness scores and small sample size , none of the differences are significant . However , it is interesting to note that the Brocanto group performed better on the assignments of loops and conditionals . In both assignments , the Brocanto group has an about 14 % higher correctness rate . This is an avenue for future work , either because learning these constructs is more closely linked to language learning strategies , or because these appear at the end of a course , hinting at a delayed effect of learning Brocanto . Thus , we can provide an answer to RQ _ 2 , that learning Brocanto does not have an immediate positive effect on learning program - ming . However , keeping in mind the small time frame of our obser - vation , we might observe an effect at a later time . Forthisreason , wetookalookattheresultsofthepost - programming tasks of their first - semester course . In the semester course Algo - rithms and Programming , a total of 5 students , who also attended our course , continuously submitted at least 4 of the 7 programming tasks . The 3 participants from the control group scored 42 ( PG2 ) , 41 ( PG4 ) , and 11 ( PG5 ) out of a total of 50 points , and the 2 participants from the Brocanto group scored 28 ( PB6 ) and 34 ( PB8 ) points . To make a proper assumption on the long - term effect of the treatment , this data sample is too small . Nevertheless , the interview data pro - vides us with some interesting insights , which we discuss in section 5 and which motivates us to pursue this line of research further . Additionally , we can answer RQ _ 1 positively , so we could feasibly integrate learning Brocanto into our curriculum . Our results indicate that considering Language Learning in a beginner programming course is justified . The observation that students were all able to learn Brocanto suggests that there are " universal " learning strategies that students possess at least in the context of Language Learning . We hope that , in the future , recruiting more students for this or a similar course and including more long - term data will evaluate the ( long - term ) effects of beginning programming by learning an artificial language . Next , we discuss our findings and insights from the interviews and derive conjectures for future research . 5 DISCUSSION While our study did not show a significant improvement in pro - gramming learning , it has demonstrated that the experiment setup works well . The reason for the lacking significance could be the short time period between treatment and posttest . To observe the long - term development of the students , we obtained the scores from the pro - gramming tasks in the course Algorithms and Programming , but due to a high drop out rate , we cannot draw sound conclusions from these data . Against this background , we start the discussion by highlighting the feasibility of our approach and follow with learning strategies and possible consequences for learning programming . Further on , we explore whether transfer occurred . Finally , we discuss further insights that we gained from the study , that is , whether implicit or explicit teaching approaches affect learning strategies and the different levels of programming languages vs . natural languages . 5 . 1 Does Learning Brocanto Help in Learning Programming ? In the interview , we asked participants how learning Brocanto or Git affected them in learning programming . In general , participants considered learning Brocanto neither helpful nor harmful : ‚ÄúI don‚Äôt know if it really helped or not . I‚Äôm not sure about that . ‚Äù 2 ( PB1 ) , or 2 All statements are translated to English . Elisa Madeleine Hartmann , Annabelle Bergum , Dominik Gorgosch , Norman Peitek , Sven Apel , and Janet Siegmund  3 U H W H V W  3 R V W W H V W                    3  H  U  F  H Q  W  D J H    R  I   F  R  U U  H  F  W   D Q  V  Z  H  U  V  ' D W D W \ S H V  9 D U L D E O H V  $ U L W K P H W L F  3 U L Q W  / R J L F D O  & R Q G L W L R Q D O  / R R S V                    3  H  U  F  H Q  W  D J H    R  I   F  R  U U  H  F  W   D Q  V  Z  H  U  V  J U R X S  % U R F D Q W R  * L W Figure 5 : Results of the pretest and posttest ( left ) , as well as the intermediate assignments ( right ) . ‚ÄúSo hindering in no way . To what extent it was helpful , I don‚Äôt think I can judge that well , but it was definitely interesting . ‚Äù ( PB5 ) . For the git group we observe similar statements : ‚ÄúBut I don‚Äôt think it helped in the course in particular , because we didn‚Äôt do anything with Git and we only got a small introduction to Git . ‚Äù ( PG5 ) . In general , participants agreed that learning an artificial language was a good idea to prepare them for learning programming . For ex - ample , PB3 explains that they would perform better in a repetition of this experiment at a later time , because ‚Äúthen it would already be something familiar in a certain way , with this way of thinking , I say‚Äù ( PB3 ) . When asked what is meant by ‚Äúthis way of thinking‚Äù , PB3 specifies : ‚Äúso just this principle of looking at this [ syntax ] and learning it as fast as you can‚Äù ( PB3 ) . This way of thinking is also mentioned by PB5 , who describes a ‚Äúcapacity for abstraction‚Äù ( PB5 ) , where one ‚Äúfirst basically gets the idea of learning some grammar that doesn‚Äôt directly serve to a language that you would converse with or something , but that is a bit more abstract and still under - stand the rules . ‚Äù ( PB5 ) . This statement suggests that participants apply abstraction , which is one ( language ) learning strategy [ 17 ] . Thus , there are hints of reactivation of learning strategies and that the participants assume , even 2 weeks after the implementation of the treatment , that they would perform better if they were to do it again . Thus , learning has taken place , and there is evidence that these structures could be used again . Learning Brocanto activates ( language ) learning strategies , so it might help in learning programming . 5 . 2 Strategies in Learning Brocanto and Python There are indications of a systematic learning process of Brocanto , such as the identification of structures and / or phrases of Brocanto sentences . We observed four levels of abstraction : orientation , rec - ognizing sentence structure , recognizing phrase structures , and recognizing words . We discuss these based on the interview data . 5 . 2 . 1 Orientation . PB1 generally points out that , when starting to learn the grammar , they have to ‚Äúorient themselves first‚Äù ( PB1 ) , and PB3 mentioned that they ‚Äú [ . . . ] was looking at that and just really focused on looking at that and reading through it a couple of times , kind of lightly whispering to myself like that‚Äù . Thus , participants start with a general orientation phase , which is typical in learning languages to recognize structures [ 7 ] . 5 . 2 . 2 Recognizing Sentence Structure . Not only the analysis of the syntax rules occurred , but also the division of sentences into ‚Äúbe - ginning‚Äù , ‚Äúmiddle‚Äù , and the part ‚Äúfollowing‚Äù the middle , which is in line with research on artificial grammar learning [ 37 , 38 ] . PB5 explains : ‚Äúthe [ words ] [ . . . ] were always either at the beginning or after this part in the middle with such a word [ consisting of ] four letters [ . . . ] prez I think and there was another that was relatively similar to that . And then there were two words that could then come directly after it and again two that then came partly as the third , whereby the one in the middle was sometimes also omitted . ‚Äù ( PB5 ) . 5 . 2 . 3 Recognizing Phrase Structure . PB3 describes an identification of phrase structures : ‚Äúyou have in some places often such a three - word constructs or so , I don‚Äôt know whether there was a rhythm , but there were just many sentences that then so always started with three words and then almost all sentences with these three words in the program or whatever . And those words that were in those groups , I kind of didn‚Äôt memorize that well . ‚Äù ( PB3 ) . This is interesting linguistically , since in language learning , phrase - like sections of words , so - called chunks , can be used for orientation at the syntax level , assuming specifically three - element chunks [ 13 , 28 , 33 ] . In a similar line , PB5 speaks of ‚Äúcertain word combinations , [ . . . ] which then stood one after the other relatively frequently . ‚Äù ( PB5 ) . From this , patterns seem to have been derived : ‚ÄúSo that somehow gave the impression that they somehow belonged together or could somehow occur in a certain order . ‚Äù ( PB5 ) . 5 . 2 . 4 Recognizing Words . We observed a frequency effect that is also known from language learning : The frequency of occurrence ( of a word or construct ) increases the speed of its processing and recognition [ 2 , 11 ] . Typically , words that appear more often are easier learned , as PB5 noted : ‚Äú [ B ] ecause you saw them the most . So they [ . . . ] were even always there and so that was the most frequent repetition . The rest I think changed more than the ones at the be - ginning . ‚Äù ( PB5 ) . Interestingly , PB3 was better able to remember rare words : ‚Äú [ I remember two words from artificial language , ] Because they were rare , f√ºme , I don‚Äôt know how rare , but plox was rare . And the other words , the gummen ( gum ) I think there were more frequent . ‚Äù ( PB3 ) . In other words , the interruption of patterns by rarer words guided the structuring of syntax for extracting syntax rules . Thus , participants apply typical language learning strategies to learn Brocanto . Next , we discuss whether these strategies also come into play when learning Python . 5 . 2 . 5 Language Learning Strategies When Learning Python . In the interviews , we found several hints that these strategies actually Tapping into the Natural Language System with Artificial Languages when Learning Programming play a role . First , there is a general orientation phase at the syntax level , because ‚Äúone has just recognized relatively quickly , with for or with a for - loop , what belongs in the range , and that it is just such a construct , which then probably also recognizes the IDE , so because of aha , so a for - loop and so . ‚Äù ( PB3 ) . PB3 explains the orientation here to the span from the beginning of the for - loop to the end . Again , we see an orientation to markers in the code . Similar to dividing sentences into ‚Äúbeginning‚Äù , ‚Äúmiddle‚Äù , and ‚Äúfol - lowing‚Äù while learning Brocanto , participants use Python markers as orientation to break down the parts into individual structures , as PB3 describes : ‚ÄúAnd also relatively logical ( is ) the indentation after if and for [ . . . ] . I like that because first of all you see it directly and secondly , that‚Äôs how I work too , when I make notes [ . . . ] or something , then I just write how much of what belongs under what else , and then I move that in . That‚Äôs logical and simple . ‚Äù ( PB3 ) The statement ‚Äúsee it directly‚Äù refers to the graphical division of the individual parts of if - conditions and for - loops in Python . In Brocanto , this part must be opened up through recognizing sentence struc - tures ( i . e . , the second identified abstraction level ) . The indentation in Python makes this division visible , which facilitates learning ; thus , a strategy does not have to applied explicitly , but is provided by the indentation . PB3 describes this : ‚Äú [ Patterns are ] the sequences , how you have to write it , for example , [ . . . ] the loops . Especially that you have to indent and not use parentheses . And with print , for example , that always has to go in the parenthesis , about that order‚Äù ( PB1 ) . Thus , indentation helps to identify sentence or phrase structures . We also note that Python is seen here in comparison to other programming languages that require parentheses instead of inden - tation . The parentheses of individual structures seem less help - ful for orientation in the code and structuring of the individual programming constructs . Thus , in a programming language other than Python that would not follow this known pattern , structuring strategies might play a more important role . Thus , activating these strategies might be more important in programming languages without indentation . We capture this observation in the following conjecture : Language learning strategies are used in learning programming . 5 . 3 Transfer Transfer describes that knowledge or skills from one domain are applied to a new domain . We found that transfer occurred from a programming language to Python and from a natural language to Python , but not from Brocanto to Python . 5 . 3 . 1 Programming Language ‚Üí Python . The interview data sug - gests that a transfer between programming languages takes place , providingfurtherempiricalsupportforrecentstudiesby Shrestha [ 41 , 42 ] and Tshukudu [ 48 ] . A student with little previous contact to programming ( in JavaScript and Java ) explains that they had to pay attention to differences in syntax when learning to program in Python : ‚ÄúAnd also before , I have always programmed with Java , I think . And there , the syntax is a bit different , especially with if - else , there are no colons or there were some other things . In other programming languages , you have to put semicolons at the end , that‚Äôs not the case with Python . Yes , so I had to be a bit careful that I don‚Äôt forget or add things like that‚Äù ( PG5 ) . On another point , the same participant states that differences between a learned pro - gramming language and a programming language to be learned can cause irritation in the learning process : ‚ÄúYes , that true and false are capitalized . That‚Äôs not necessarily always like this [ . . . ] I find that irritating , because I would probably forget to write it in capital letters , because in other programming languages it doesn‚Äôt even matter whether you write things in capital or small letters , and in Python it seems to matter . And I find that irritating ‚Äù ( PG5 ) . These statements show that , as in the transfer of natural languages , knowl - edge of the syntax is transferred to the new programming language . Differences between the source and target language involve the risk of transferring information incorrectly and thus making mistakes , but similarities can be transferred more quickly . Training of the differences and similarities between the source and target programming language facilitates transfer . 5 . 3 . 2 Natural Language ‚Üí Python . The structure of Python was generally rated as ‚Äúrelatively logical‚Äù ( PG2 ) and not difficult by participants from the Git group as well as from the Brocanto group . This impression was created among the participants , because they felt that Python was similar to natural languages , so ‚Äúvery pleasant , because you had to pay attention to very few things . So , it was relative , I want to do that , I write it down and it fits like that . ‚Äù ( PB3 ) The absent brackets also seemed to be beneficial : ‚ÄúSo , without , ‚Äôthere must be five brackets here and there and so on . ‚Äô [ . . . ] ‚Äù ( PB3 ) , and ‚Äúas some of the syntax is not yet [ understood ] , like these brackets that you have to think about [ . . . ] , you might understand it ( Python ) a little better at the beginning because it‚Äôs closer to natural language [ . . . ] , or there aren‚Äôt so many formal things‚Äù ( PG5 ) . A further benefit in Python was indentation , which provides structuring , similar to literal speech in natural - language texts , as PG2 describes : ‚Äúlogical , [ . . . ] that you just somehow indent a condi - tion , you would perhaps also , I don‚Äôt know , make quotation marks if you now quote someone or something‚Äù ( PG2 ) . PG5 has a similar consideration : ‚ÄúFrom a purely technical writing point of view , in Python you would somehow indent things and start new lines . If one compares that now with a written language , one would set perhaps a punctuation mark‚Äù ( PG5 ) . Thus , it might be easier for students to start off with variants of programming or artificial lan - guages that are close to natural languages and step by step become more similar to a full programming language . Hedy is one example of starting close to natural languages , and step by step becoming Python [ 18 ] . When learning a first programming language , a closeness to natural language is beneficial . The more programming languages a person is familiar with , the farther away they can be from natural language . However , there is also interference from natural language to Python , especially where natural languages and Python differ . Es - pecially features in syntax have to be applied several times until it is learned . PB3 calls for this ‚Äúthat in the beginning I always forgot to add the colon to if or for ‚Äù ( PB3 ) . A participant from the control group can also generally imagine that , in connection between nat - ural and artificial languages , and Python , ‚Äú [ learning an artificial language ] might be a bit confusing , because some of the rules or typical structures of the natural language are still in there . And if Elisa Madeleine Hartmann , Annabelle Bergum , Dominik Gorgosch , Norman Peitek , Sven Apel , and Janet Siegmund you then use the programming language , it can perhaps happen that you still use these things‚Äù ( PG5 ) . Thus , despite the logical structure of Python , which can be logically linked to structures of natural languages , ‚Äúthis structure , these strands , which you have to follow , and at the beginning especially the syntax in general‚Äù ( PG2 ) are considered as ‚Äúvery difficult‚Äù ( PG2 ) when learning programming , which is in line with research describing that actually learning syntax is a struggle for students [ 9 , 10 ] . These statements suggest that the differences in the states of and to which knowledge is to be transferred can lead to problems . We state When learning a new programming language , providing explicit guidance on similarities and differences is beneficial . Providing focused guidance on difficult to memorize constructs supports learning programming . In the interviews , students focused on learning the syntax . However , one participant made an interesting statement about the semantics level , which also hints at a specific difference between natural language and programming languages , but also at why training with an artificial language may be helpful . In this statement , PG2 concerns ‚Äúgoing through loops‚Äù ( PG2 ) and the fact that one does not see on the written level of the program ‚Äúhow the [ program ] does [ the loop ] now , but you have only written there , what is to be done and does not see however , how that is done , except you let it give the output . ‚Äù ( PG2 ) The participant describes the semantic level , which cannot be decoded for programming beginners just by learning the syntax . At this level of acquisition , the code must be output to see what it ‚Äúdoes‚Äù . With natural languages , semantic understanding is already present from the first language learned , because people are familiar with the semantic system in natural languages . However , in programming , a new semantic system has to be learned , because it is different from natural languages . In this case , the artificial language can act as intermediate carrier , because it has a natural language syntax , but has no semantics in the strict sense . Thus , we conjecture that : Training with artificial languages serves as an intermediate stage for learning semantics of programming languages . 5 . 4 Further Insights 5 . 4 . 1 Implicit vs . Explicit Teaching . Some participants highlighted in the interview that they intuitively learned Brocanto , without being taught explicitly the syntactic rules . This implicit learning of artificial languages is the typical protocol in experiments with artificial languages [ 20 , 28 , 29 , 33 , 37 , 38 ] , and often likened with gut feeling , or ‚Äúintuitive‚Äù , or ‚Äúspontaneous‚Äù learning , or ‚Äúlearning without awareness‚Äù : ‚ÄúI honestly didn‚Äôt know , I think , I felt like I had a relatively large amount right . [ . . . ] I didn‚Äôt know why , though . ‚Äù ( PB3 ) The same participant states , they ‚Äúactively , have not detected any system‚Äù ( PB3 ) . Thus , the participant was aware that they had not actively recognized and used any system , but had nevertheless improved in the correctness of the test blocks ( red in Fig . 4 . Strik - ingly , this participant gave the definition of implicit learning [ 14 ] : ‚ÄúI just looked at [ the sentences ] briefly and then I just pressed the first thing that came into my mind . [ . . . ] I just did it really intu - itively‚Äù ( PB3 ) . This ‚Äúgut feeling‚Äù or implicit learning can also be measured objectively ( e . g . , [ 37 , 38 ] ) : When syntactic violations oc - cur in acquired Brocanto sentences , event - related potentials for syntax violations can be observed , which are different than for cor - rect sentences . Thus , the brain gives an objective signal of intuitive learning . One participant of the control group explained that they gener - ally had ‚Äúsomehow been able to acquire the structures [ of a pro - gramming language ] ‚Äù ( PG5 ) . The assumption that this happened implicitly is supported by a statement of the same person at a later point in the interview . In this they denied that they had explicitly worked out structures as a learning strategy before , or applied them : ‚ÄúI‚Äôm no such person [ like the ones that ] even in [ school subject ] [ . . . ] structure something . I have never done that‚Äù ( PG5 ) . This state - ment refers to a general implicit structuring of the programming language during learning . Individual aspects are not mentioned . However , it might also be observable for programming languages , that syntactically incorrect statements elicit a different neuronal re - sponse than correct statements , which might be a further hint to the similarity between natural , artificial , and programming languages , making the intermediate step of learning an artificial language viable . Syntactic violations in statements in a programming language elicit a specific neuronal response . Interestingly , despite describing implicit learning , the partici - pant described at a later point concrete rules from Brocanto , indicat - ing that they identified explicit rules ( e . g . , ‚Äúthree - word constructs [ . . . ] many sentences that always started with three words and then almost all sentences [ started ] with these three words . ‚Äù ( PB3 ) ; cf . Section 5 . 2 ) . In contrast to the implicit learning of the artificial language , participants perceived the learning of Python as explicit : ‚ÄúBecause the [ Python ] rules were given and not just examples from which you could derive the rules , I think it was even easier to un - derstand than with this artificial language . ‚Äù ( PG2 ) . Nevertheless , there are also hints that knowledge about a programming language can also be implicit [ 26 ] . For each new programming construct , participants received tem - plates for the respective construct , such that they can use them with the variables of their program and combine constructs in more complex tasks . Thus , the participants were explicitly instructed that these templates will be relevant in the further process of pro - gramming . When asked about the use of the template , PB3 states : ‚ÄúI thought it was good in any case , [ . . . ] that you always got the basics first , because of , this is how it looks , this is how it is built up from the [ . . . ] ( syntactic ) components , is this structure put together , these are the rules , how do you write this and so on [ . . . ] . For me , it definitely helped to [ learn ] the structure . ‚Äù Here , it becomes clear that the participant does not have to derive the rules themselves , but understands the given rules for syntactic structures in the pro - gramming language and then applies them . For the intermediate programming assignments and posttest , the participants then ‚Äúputs together everything [ . . . ] that I learned‚Äù ( PT3 ) . To summarize , Brocanto was learned implicitly , Python explicitly . Explicit learning seems to make it easier for students to understand the rules , but implicit learning of Brocanto is closer to natural lan - guage learning . Thus , to activate strategies from natural language learning and apply an explicit learning approach , a two - step ap - proach that starts with teaching an artificial language implicitly ( to tap into the language system ) , and then teaches an ( other ) artificial Tapping into the Natural Language System with Artificial Languages when Learning Programming language explicitly ( to support recognition of rules ) might prove effective . Combining implicit and explicit teaching approaches of an artifi - cial language positively influences initial programming language learning . 5 . 4 . 2 Meta - Level Semantics . In the interview , participants reflected on problems that they had in learning programming . It describes the semantic level of code and of natural languages . It became clear that code has more levels than text . The principle behind code is described as ‚Äúvery abstract‚Äù ( PG5 ) . The intent of the program , that is , what it ‚Äúdoes‚Äù ( PG5 ) , is not directly clear until the program runs and produces an output . PG5 gives an example : ‚ÄúYou have just letters or something , [ . . . ] or variables that you remember as something or that you define and that you then have all the time and that just count like that . ‚Äù ( PG5 ) . As another example , even though a loop is written once , it is not necessarily executed once , but likely several times , depending on the concrete input . And with different input , the same loop can behave differently . Thus , what is written in code first needs to be re - written internally to truly reflect what it is doing . This is different in natural languages , in which the intent of a sentence is already the sentence itself . The message to be conveyed is concretely conveyed by the sentence itself , so there is a closer connection between text and semantics . Thus , it may be helpful for beginner programmers to translate a piece of source code into its actual behavior and write it down , for example , all loop iterations ( given reasonable input ) or replace the occurrences of all variables with actual values . This might help to understand how the different level of semantic in code ( i . e . , its behavior ) translates to the actual , written source code . Explicitly writing down the specific behavior of code helps to bridge the different levels of code . 5 . 5 Summary of Discussion The interviews provided valuable insights , including the activation of language learning strategies by training an artificial language , as well as new approaches to transfer , that is , transferring known patterns to a similar , yet unknown subject , from natural language to programming language or between programming languages . In addition , we made observations regarding implicit and explicit learning , which concern new approaches of teaching programming languages as well as artificial languages . Furthermore , we high - lighted the difficulty of beginners to decode the semantics behind the programming language . This differs at the comprehension level compared to the sentence - level semantics in natural languages . This difference seems to make it difficult to comprehend programming language constructs . Even though these conjectures were derived from a small sample size and may depend on factors , such as personal preferences and existing programming and language learning experience , they give us interesting insights and inspiration that are worth wile to follow up on . With this new angle on programming learning , we hope that in the future , programming learning will become easier and more students are motivated to pursue it . 6 THREATS TO VALIDITY 6 . 1 Construct Validity To mitigate potential threats caused by inaccurate measurement of the latent constructs , we used an evaluated programming test , and also worked with a well - established questionnaire to measure programming experience . In the same line , we followed a standard protocol to teach Brocanto , and followed a curriculum of teaching programming . Thus , threats to construct validity are minimized . 6 . 2 Internal Validity The programming course took place within a week and thus in a short time frame to sufficiently observe the influence of the treat - ment on programming learning . To get an impression of longer - term effects , we looked at the results of the programming tasks from the first - semester course Algorithms and Programming six months after the course . Due to the high drop - out rate in the course , we can only compare a few results . The two very similar groups differed only in the treatment , so we can take a good look at the effect of the treatment . In our study , we included participants with no programming experience as well as participants with little programming experience . We could not assess the extent to which prior experience might influence our research . However , data from the first - semester course Algorithms and Programming show that participants from our course who re - ported having some programming experience did not necessarily perform better in the programming tasks than participants without programming experience . Thus , we count them as beginners as the participants who had no programming experience . It is quite possi - ble that at the measuring points , despite the request to work on the tests alone , the tests were worked on with the person sitting next to them or were larded . Since , in addition to the treatment , all par - ticipants took part in the programming course and all significantly improved their programming ability , it is possible to conclude that the course had an effect on performance . The effect of the treatment can be separated , but not observed in the results . The control treat - ment of the Git group did not include any programming aspects . Nevertheless , we cannot fully rule out the possibility that further engagement with Git taught strategies that may have contributed to learning programming . Furthermore , some students dropped out , because it was too easy for them . This can also be seen in the 100 % correctness in their pretest scores . While this reduces statistical power , it does not threaten internal validity , as the too high programming competency might have confounded the results more in favor for the control group . 6 . 3 External Validity In the course , we worked only with Python and Brocanto , and cov - ered only one week . With another programming and / or artificial language , or courses spanning longer time spans , results may be different . In addition , all of the students were part of the computer science faculty , so a general interest in computer science already existed . We cannot say with certainty whether students from other departments would learn the artificial language or programming Elisa Madeleine Hartmann , Annabelle Bergum , Dominik Gorgosch , Norman Peitek , Sven Apel , and Janet Siegmund language with different strategies . Nevertheless , our results are ap - plicable to this important population of students who learn Python or similar programming languages . 7 CONCLUSION Teaching the first programming language is accompanied by many difficulties . Research has shown that pairing learning programming with foreign language acquisition can be beneficial . In conjunction , activating language learning strategies can facilitate the learning of the first programming language through transfer . In our study as part of a programming course , we investigated whether students who learn an artificial language before learning programming bet - ter acquire programming competency . Within the time frame of our study , we did not find a general effect on programming learn - ing when an artificial language was previously learned . However , we observed that the participants learning the artificial language performed better on the intermediate assignments on conditionals and loops , which may indicate that strategies involved in the struc - turing that were used in learning the artificial language . However , we cannot derive a clear result yet . We also took a long - term look at programming outcomes from the students‚Äô first semester ; but due to the high drop - out rates , could not make any estimates of the long - term effects of the treatment . The conducted study will serve as a basis for the new programming course in the next winter semester . On a methodological level , we learned that experiment designs from the field of foreign language acquisition research can be used for fathoming computer science problems . By doing so , we rep - resent a step on the road map that can be explored for computer science research . We highlighted relevant points on the roadmap by providing 11 conjectures that are good starting points to explore this experiment landscape . ACKNOWLEDGMENT We thank the students for participating in the study . Apel‚Äôs work is supported by ERC Advanced Grant 101052182 . REFERENCES [ 1 ] Alireza Ahadi , Raymond Lister , and Donna Teague . 2014 . Falling Behind Early and Staying Behind When Learning to Program . In PPIG , Vol . 14 . 12 pages . [ 2 ] JohnAndersonandLaelSchooler . 2000 . TheAdaptiveNatureofMemory . ( 2000 ) . [ 3 ] Laura Batterink and Helen Neville . 2013 . Implicit and Explicit Second Language Training recruit Common Neural Mechanisms for Syntactic Processing . Journal of Cognitive Neuroscience 25 , 6 ( 2013 ) , 936 ‚Äì 951 . [ 4 ] Jens Bennedsen and Michael Caspersen . 2007 . Failure Rates in Introductory Programming . ACM SIGCSE Bulletin 39 , 2 ( 2007 ) , 32 ‚Äì 36 . [ 5 ] Jens Bennedsen and Michael Caspersen . 2019 . Failure Rates in Introductory Programming : 12 Years later . ACM Inroads 10 , 2 ( 2019 ) , 30 ‚Äì 36 . [ 6 ] Lee Brooks and John Vokey . 1991 . Abstract Analogies and Abstracted Grammars : Comments on Reber ( 1989 ) and Mathews et al . ( 1989 ) . ( 1991 ) . [ 7 ] Patricia Carrell . 1989 . Metacognitive Awareness and Second Language Reading . The modern language journal 73 , 2 ( 1989 ) , 121 ‚Äì 134 . [ 8 ] Alison Cooper . 2019 . The Influence of Position in the Sleep Wake Cycle on the Functional Brain Processes involved in Memory Consolidation during Acquisition of an Artificial Language ( BROCANTO ) . University of Surrey ( United Kingdom ) . [ 9 ] Paul Denny , Andrew Luxton - Reilly , Ewan Tempero , and Jacob Hendrickx . 2011 . Understanding the Syntax Barrier for Novices . In Proc . Conf . Innovation and Tech - nology in Computer Science Education ( ITiCSE ‚Äô11 ) . Association for Computing Machinery , New York , NY , USA , 208 ‚Äì 212 . [ 10 ] John Edwards , Joseph Ditton , Dragan Trninic , Hillary Swanson , Shelsey Sullivan , and Chad Mano . 2020 . Syntax Exercises in CS1 . In Proc . Conf . on International Computing Education Research ( ICER ‚Äô20 ) . ACM , New York , NY , USA , 216 ‚Äì 226 . [ 11 ] NickEllis . 2002 . ReflectionsonFrequencyEffectsinLanguageProcessing . Studies in second language acquisition 24 , 2 ( 2002 ) , 297 ‚Äì 339 . [ 12 ] MarcEttlinger , KaraMorgan - Short , MandyFaretta - Stutenberg , andPatrickWong . 2016 . The Relationship between Artificial and Second Language Learning . Cog - nitive science 40 , 4 ( 2016 ) , 822 ‚Äì 847 . [ 13 ] AnaFrancoandArnaudDestrebecqz . 2012 . ChunkingorNotChunking ? Howdo wefindWordsinArtificialLanguageLearning ? AdvancesinCognitivePsychology 8 , 2 ( 2012 ) , 144 . [ 14 ] Peter Frensch and Dennis R√ºnger . 2003 . Implicit Learning . Current Directions in Psychological Science 12 , 1 ( 2003 ) , 13 ‚Äì 18 . [ 15 ] AngelaFriederici , KarstenSteinhauer , andErdmutPfeifer . 2002 . BrainSignatures of Artificial Language Processing : Evidence Challenging the Critical Period Hypothesis . Proc . of the National Academy of Sciences 99 , 1 ( 2002 ) , 529 ‚Äì 534 . [ 16 ] Isabel Gauthier , Pawel Skudlarski , John Gore , and Adam Anderson . 2000 . Ex - pertise for Cars and Birds Recruits Brain Areas Involved in Face Recognition . Nature Neuroscience 3 , 2 ( Feb 2000 ) , 191 ‚Äì 197 . [ 17 ] Mary Gick and Keith Holyoak . 1983 . Schema Induction and Analogical Transfer . Cognitive psychology 15 , 1 ( 1983 ) , 1 ‚Äì 38 . [ 18 ] FelienneHermans . 2020 . Hedy : AGradualLanguageforProgrammingEducation . In Int . Conf . Educational Research ( ICER ) . ACM , 259 ‚Äì 270 . [ 19 ] Takeshi Hongo , Takao Yakou , Kenji Yoshinaga , Toshiharu Kano , Michiko Miyazaki , and Takashi Hanakawa . 2022 . Structural Neuroplasticity in Com - puter Programming Beginners . Cerebral Cortex ( 10 2022 ) . Online first . [ 20 ] Annette Kinder and Anja Assmann . 2000 . Learning Artificial Grammars : No Evidence for the Acquisition of Rules . Memory & Cognition 28 , 8 ( 2000 ) , 1321 ‚Äì 1332 . [ 21 ] Barbara Knowlton and Larry Squire . 1996 . Artificial Grammar Learning Depends on Implicit Acquisition of both Abstract and Exemplar - Specific Information . Journal of Experimental Psychology : Learning , Memory , and Cognition 22 , 1 ( 1996 ) , 169 . [ 22 ] RyanKrueger , YuHuang , XinyuLiu , TylerSantander , WestleyWeimer , andKevin Leach . 2020 . Neurological Divide : an fMRI Study of Prose and Code Writing . In Proc . Int‚Äôl Conf . Software Engineering ( ICSE ) . IEEE , 678 ‚Äì 690 . [ 23 ] Raymond Lister , Elizabeth S . Adams , Sue Fitzgerald , William Fone , John Hamer , Morten Lindholm , Robert McCartney , Jan Erik Mostr√∂m , Kate Sanders , Otto Sepp√§l√§ , Beth Simon , and Lynda Thomas . 2004 . A Multi - National Study of Reading and Tracing Skills in Novice Programmers . ACM SIGCSE Bulletin 36 , 4 ( 2004 ) , 119 ‚Äì 150 . [ 24 ] RaymondLister , BethSimon , ErrolThompson , JacquelineWhalley , andChristine Prasad . 2006 . Not Seeing the Forest for the Trees : Novice Programmers and the SOLO Taxonomy . SIGCSE Bull . 38 , 3 ( 2006 ) , 118 ‚Äì 122 . [ 25 ] Andrew Luxton - Reilly . 2016 . Learning to Program is Easy . In Proc . Conf . In - novation and Technology in Computer Science Education . ACM , Arequipa Peru , 284 ‚Äì 289 . [ 26 ] Rebecca Mancy . 2007 . Explicit and Implicit Learning : The Case of Computer Programming . Ph . D . Dissertation . University of Glasgow . [ 27 ] Michael McCracken , Vicki Almstrum , Danny Diaz , Mark Guzdial , Dianne Hagan , Yifat Ben - David Kolikant , Cary Laxer , Lynda Thomas , Ian Utting , and Tadeusz Wilusz . 2001 . A Multi - National , Multi - Institutional Study of Assessment of Programming Skills of First - Year CS Students . In Working group reports from ITiCSE on Innovation and technology in computer science education ( ITiCSE - WGR ‚Äô01 ) . Association for Computing Machinery , New York , NY , USA , 125 ‚Äì 180 . [ 28 ] Thierry Meulemans and Martial Van der Linden . 1997 . Associative Chunk Strength in Artificial Grammar Learning . Journal of Experimental Psychology : Learning , Memory , and Cognition 23 , 4 ( 1997 ) , 1007 . [ 29 ] Bertram Opitz , Nicola Ferdinand , and Axel Mecklinger . 2011 . Timing Matters : the Impact of Immediate and Delayed Feedback on Artificial Language Learning . Frontiers in human neuroscience 5 ( 2011 ) , 8 . [ 30 ] Bertram Opitz and Angela Friederici . 2003 . Interactions of the Hippocampal System and the Prefrontal Cortex in Learning Language - Like Rules . NeuroImage 19 , 4 ( 2003 ) , 1730 ‚Äì 1737 . [ 31 ] Bertram Opitz and Angela Friederici . 2004 . Brain Correlates of Language Learn - ing : the Neuronal Dissociation of Rule - Based versus Similarity - Based Learning . Journal of Neuroscience 24 , 39 ( 2004 ) , 8436 ‚Äì 8440 . [ 32 ] NormanPeitek , SvenApel , ChrisParnin , Andr√©Brechmann , andJanetSiegmund . 2021 . Program Comprehension and Code Complexity Metrics : An fMRI Study . In ICSE . IEEE . [ 33 ] Pierre Perruchet and Chantal Pacteau . 1990 . Synthetic Grammar Learning : Implicit Rule Abstraction or Explicit Fragmentary Knowledge ? Journal of experi - mental psychology : General 119 , 3 ( 1990 ) , 264 . [ 34 ] Karl - Magnus Petersson , Vasiliki Folia , and Peter Hagoort . 2012 . What Artificial GrammarLearningrevealsabouttheNeurobiologyofSyntax . Brainandlanguage 120 , 2 ( 2012 ) , 83 ‚Äì 95 . [ 35 ] Manfred Pienemann , Malcolm Johnston , and Geoff Brindley . 1988 . Constructing an Acquisition - Based Procedure for Second Language Assessment . Studies in second language acquisition 10 , 2 ( 1988 ) , 217 ‚Äì 243 . [ 36 ] Chantel S Prat , Tara M Madhyastha , Malayka J Mottarella , and Chu - Hsuan Kuo . 2020 . Relating natural language aptitude to individual differences in learning Tapping into the Natural Language System with Artificial Languages when Learning Programming programming languages . Scientific reports 10 , 1 ( 2020 ) , 3817 . [ 37 ] Arthur Reber . 1967 . Implicit Learning of Artificial Grammars . , 855 ‚Äì 863 pages . [ 38 ] Arthur Reber . 1989 . Implicit Learning and Tacit Knowledge . Journal of Experi - mental Psychology : General 118 , 3 ( 1989 ) , 219 . [ 39 ] Jacquelyn Schachter . 1983 . A New Account of Language Transfer . Language transfer in language learning 2 ( 1983 ) , 98 ‚Äì 111 . [ 40 ] Larry Selinker . 1969 . Language Transfer . General linguistics 9 , 2 ( 1969 ) , 67 . [ 41 ] Nischal Shrestha , Titus Barik , and Chris Parnin . 2018 . It‚Äôs like Python but : To - wardsSupportingTransferofProgrammingLanguageKnowledge . In Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . IEEE , 177 ‚Äì 185 . [ 42 ] Nischal Shrestha , Colton Botta , Titus Barik , and Chris Parnin . 2020 . Here We Go Again : Why Is It Difficult for Developers to Learn Another Programming Language ? . In ICSE . IEEE , 691 ‚Äì 701 . [ 43 ] Janet Siegmund , Christian K√§stner , Sven Apel , Chris Parnin , Anja Bethmann , Thomas Leich , Gunter Saake , and Andr√© Brechmann . 2014 . Understanding Understanding Source Code with Functional Magnetic Resonance Imaging . In Proc . Int‚Äôl Conf . Software Engineering ( ICSE ) . ACM , 378 ‚Äì 389 . [ 44 ] JanetSiegmund , ChristianK√§stner , J√∂rgLiebig , SvenApel , andStefanHanenberg . 2014 . Measuring and Modeling Programming Experience . Empirical Software Engineering 19 , 5 ( 2014 ) , 1299 ‚Äì 1334 . [ 45 ] Simon , Andrew Luxton - Reilly , Vangel Ajanovski , Eric Fouh , Christabel Gon - salvez , Juho Leinonen , Jack Parkinson , Matthew Poole , and Neena Thota . 2019 . Pass Rates in Introductory Programming and in other STEM Disciplines . In Proc . of the Working Group Reports on Innovation and Technology in Computer Science Education . ACM , Aberdeen Scotland Uk , 53 ‚Äì 71 . [ 46 ] Elliot Soloway , Kate Ehrlich , and Jeffrey Bonar . 1982 . Tapping into Tacit Pro - gramming Knowledge . In Proceedings of the 1982 conference on Human factors in computing systems - CHI ‚Äô82 . ACM Press , Gaithersburg , Maryland , United States , 52 ‚Äì 57 . [ 47 ] Edward Thorndike and Robert Woodworth . 1901 . The Influence of Improvement in One Mental Function upon the Efficiency of Other Functions . Psychological Review 8 ( 1901 ) , 247 ‚Äì 261 . 3 . [ 48 ] EthelTshukuduandQuintinCutts . 2020 . UnderstandingConceptualTransferfor Students Learning New Programming Languages . In Proc . Conf . Int‚Äôl Computing Education Research . ACM , 227 ‚Äì 237 . [ 49 ] Ian Utting , Allison Elliott Tew , Mike McCracken , Lynda Thomas , Dennis Bou - vier , Roger Frye , James Paterson , Michael Caspersen , Yifat Ben - David Kolikant , Juha Sorva , and Tadeusz Wilusz . 2013 . A Fresh Look at Novice Programmers‚Äô Performance and Their Teachers‚Äô Expectations . In Proc . of the ITiCSE Working Group Reports Conference on Innovation and Technology in Computer Science Education - Working Group Reports ( ITiCSE - WGR ‚Äô13 ) . Association for Computing Machinery , New York , NY , USA , 15 ‚Äì 32 . [ 50 ] Christopher Watson and Frederick Li . 2014 . Failure Rates in Introductory Pro - gramming Revisited . In Proc . Conf . on Innovation & Technology in Computer Science Education ( ITiCSE ‚Äô14 ) . ACM , New York , NY , USA , 39 ‚Äì 44 . [ 51 ] Benjamin Xie , Dastyni Loksa , Greg Nelson , Matthew Davidson , Dongsheng Dong , Harrison Kwik , Alex Hui Tan , Leanne Hwa , Min Li , and Amy Ko . 2019 . A Theory of Instruction for Introductory Programming Skills . Computer Science Education 29 , 2 - 3 ( 2019 ) , 205 ‚Äì 253 .