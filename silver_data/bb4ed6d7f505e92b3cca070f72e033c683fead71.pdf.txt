30 ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support GONZALO RAMOS , Microsoft Research , USA NAPOL RACHATASUMRIT , Carnegie Mellon University , USA JINA SUH , RACHEL NG , and CHRISTOPHER MEEK , Microsoft Research , USA Online research is a frequent and important activity people perform on the Internet , yet current support for this task is basic , fragmented and not well integrated into web browser experiences . Guided by sensemaking theory , we present ForSense , a browser extension for accelerating people’s online research experience . The two primary sources of novelty of ForSense are the integration of multiple stages of online research and pro - viding machine assistance to the user by leveraging recent advances in neural - driven machine reading . We use ForSense as a design probe to explore ( 1 ) the benefits of integrating multiple stages of online research , ( 2 ) the opportunities to accelerate online research using current advances in machine reading , ( 3 ) the oppor - tunities to support online research tasks in the presence of imprecise machine suggestions , and ( 4 ) insights about the behaviors people exhibit when performing online research , the pages they visit , and the artifacts they create . Through our design probe , we observe people performing online research tasks , and see that they benefit from ForSense’s integration and machine support for online research . From the information and insights we collected , we derive and share key recommendations for designing and supporting imprecise machine assistance for research tasks . CCS Concepts : • Human - centered computing → Interactive systems and tools ; Empirical studies in interaction design ; • Information systems → Web searching and information discovery ; Additional Key Words and Phrases : Human - AI collaboration , sensemaking ACM Reference format : Gonzalo Ramos , Napol Rachatasumrit , Jina Suh , Rachel Ng , and Christopher Meek . 2022 . ForSense : Accelerat - ing Online Research Through Sensemaking Integration and Machine Research Support . ACM Trans . Interact . Intell . Syst . 12 , 4 , Article 30 ( November 2022 ) , 23 pages . https : / / doi . org / 10 . 1145 / 3532853 1 INTRODUCTION The world - wide - web has become an indispensable tool for conducting research [ 35 ] . The Internet is essential for many people during times of emergency to access information and fulfill their needs in social , professional , and educational settings [ 34 ] . Some information needs are best described as finding the answer to a well - defined question ( i . e . , question - answering ) . For such information needs , the current browser experience driven by search engines provides strong support , often The reviewing of this article was managed by special issue associate editors Tracy Hammond , Bart Knijnenburg , John O’Donovan , Paul Taele . Authors’ addresses : G . Ramos , J . Suh , R . Ng , and C . Meek , Microsoft Research , USA ; emails : { goramos , jinsuh , rachel . ng , meek } @ microsoft . com ; N . Rachatasumrit , Carnegie Mellon University , USA ; email : napol @ cmu . com . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . © 2022 Association for Computing Machinery . 2160 - 6455 / 2022 / 11 - ART30 $ 15 . 00 https : / / doi . org / 10 . 1145 / 3532853 ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 2 G . Ramos et al . enabling information seekers to quickly satisfy their information needs . Our focus , however , is on information needs best described as exploratory research tasks and where successful research outcomes are typically the result of seeking , collecting , analyzing , and synthesizing information found in diverse online locations or documents . In contrast to question - answering information needs , exploratory research is a complex task . During this type of research , people engage in activities such as collecting and organizing infor - mation clippings , both of which can demand substantial amounts of time and cognitive efforts . For instance , Kellar et al . [ 16 ] distilled five categories describing the different information seeking tasks people do with their web browsers . Of these , they found that information gathering was the task that demanded more time , browser windows , pages visited , searches , and usage of a browser’s functions . There are several tools that assist people in information gathering , such as bookmarks built into most browsers or browser extensions that support collection and organization . However , browser’s bookmarks typically do not provide insight into why the information on a web page was relevant to the information need . Furthermore , information organizing activities are less supported natively in the browser ; the collecting - organizing experience often involves fragmented notes or clippings across external applications or extensions such as Pocket [ 30 ] , Pinterest [ 28 ] , or Notion [ 26 ] . In addition to supporting some form of folksonomies [ 27 ] , these applications and services provide machine - learning ( ML ) enhancements in the form of article recommendations or keyword sug - gestions which are often separated from the original research material or the web browser . Our goal is to improve the efficiency of the web browser - based online research experience . We see opportunities to accelerate online research tasks by framing them as an integrated sensemaking experience . Our work draws inspiration from work on sensemaking . Sensemaking describes the process of , given a knowledge building task , iteratively creating , and refining a representation system for information , and the subsequent process of encoding information into that system . Seminal work by [ 29 , 36 ] describes this process and its costs ( cognitive and external ) . During this process , people are engaged into two interconnected loops or activities : foraging and sensemaking . In fact , the name of our system , ForSense , is a portmanteau of these words . While foraging , people collect information , look at diverse sets of examples or evidence , and start to develop theories about how to organize information as their knowledge about a topic evolves . While sensemaking , people explicitly form an information representation system , test it , and refine it using the information collected during the foraging stage . Sensemaking theory provides an elegant framework that highlights opportunities and require - ments for integrating foraging and sensemaking as activities a person should easily alternate in - between when doing research . We argue that such integration leads to less fragmented experiences with fewer distractions arising from context or application switching [ 14 ] . Applying a sensemak - ing lens brings attention to tasks that have the potential for machine support . Some of these tasks are things current machine - learned functions can do quite well over large sets of documents , for instance , searching for relations , reading and extracting information , and suggesting structures or groupings . We also see opportunities to accelerate online research tasks by providing task support en - abled by recent advances in deep neural transformer models applied to natural language under - standing ( NLU ) of semantically coherent text clippings . These models enable systems to perform remarkable tasks such as named entity detection , question answering , next word or sentence pre - diction , and text summarization . A fundamental property of these models is their ability to produce embeddings of text phrases or sentences . These embeddings can be seen as encoding some form of meaning and provide numerical representations that allow a machine to suggest the semantic proximity of two embeddings to a person , who can then take advantage of that information . This ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 3 ability to process and understand information can be used to support and complement people en - gaged in online research activities . In particular , these models have a higher chance of understand - ing a part of a web page as a cohesive concept than the totality of a web page . This observation makes these ML models very relevant when focusing on parts or clippings of a web document as units of information . Motivated by these observations , opportunities , and “the lack of support for sensemaking in existing systems” [ 43 ] , we present ForSense , a browser extension for accelerating people’s online research experience . ForSense’s key features consist of integrating multiple sensemaking activities , and leveraging recent advances in transformer models for NLU to support and complement users during their activities . We use ForSense as a design probe to explore ( 1 ) the benefits of integrating multiple stages of online research in the same tool , ( 2 ) the opportunities to accelerate online research using current advances in machine reading , ( 3 ) the opportunities to support online research tasks in the pres - ence of imprecise machine suggestions , and ( 4 ) insights about the behaviors people exhibit when performing online research , the pages they visit , and the artifacts they create . In our study , we observe people performing online research tasks and see how our integrated sensemaking design brings benefits like keeping people in a state of flow that facilitates the research task . We also find that machine support based on modern transformer models is beneficial to the experience by supporting users at different points during their research . By analyzing people’s behaviors and actions during our study , we share insights about distinctive sensemaking patterns as well as the properties and evolution of the collection of clips people collected , and the groups they created . Our design probe not only helped us provide answers to the above four issues , but it also enabled us to identify key recommendations for designing and supporting imperfect machine assistance when designing human - AI collaborative experiences for online research . 2 RELATED WORK 2 . 1 Designing for Machine Support Prior work in mixed - initiative systems [ 13 ] underscores design principles to enhance a user’s ex - perience by “an elegant coupling of automated services with direct manipulation” . [ 2 ] proposes design guidelines for human - AI interaction in AI - infused applications , with an emphasis on think - ing critically about the properties of AI or ML as a design component early in a system’s inception process . We draw inspirations from these guidelines to inform our prototype design , specifically , principles such as minimizing the cost of poor guesses , considering uncertainty about a user’s goals , supporting efficient correction and conveying the consequences of user actions . As applications where the interaction or collaboration between people and some form of AI / ML system become more sophisticated and ubiquitous , researchers try to assess their efficacy in getting tasks done . [ 15 ] looked at this issue with the added dimension of perceived effectiveness in the context of an AI - assisted sorting task . They observed that while the system helped people being more efficient , people’s perceptions of efficacy were inverted . This work reveals the challenges of how interacting with a system intended to enhance an experience can affect someone’s perception of one’s abilities . We consider these ideas in our work and try to minimize undesired influence from a machine research system , by augmenting a person’s agency and supporting the research task flow . 2 . 2 Sensemaking Tools Sensemaking tools should support users to be in the flow across stages and help them move fluidly between foraging and sensemaking activities [ 4 ] . However , most of the tools do not assist users throughout the full process . SenseMaker [ 3 ] focuses on foraging across heterogenous sources , ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 4 G . Ramos et al . while providing some organization capabilities . WebCutter [ 23 ] allows users to visualize a net - work of related web documents to facilitate their selection . IdeaMache [ 21 ] expands the notion of slideware onto a free - form canvas to foster sensemaking . Tools mentioned above typically use a web page or a document as the smallest unit of infor - mation . It has been shown , however , that users regularly think and work with smaller units , or parts of a document [ 24 , 37 ] . There are other tools designed to support more granular information units . Hunter Gatherer [ 38 ] deals with clippings from web pages , [ 9 ] lets users collect parts of a web page , and Kittur’s Clipper [ 17 ] supports saving web page’s parts along with their summary . Nonetheless , these tools do not fully support the foraging sensemaking processes . Tools that only partially support the process can lead to divided attention as users switch be - tween them [ 41 ] . On the other hand , tools that integrate searching , collecting , and organizing documents have been shown to benefit from supporting the full foraging - sensemaking process [ 11 , 43 ] . SenseMap [ 25 ] supports the full spectrum of sensemaking activities through letting users implicitly build a history map of their web navigation history , capture clips from the pages they see , and build a relationships map for further understanding of a topic . Our work builds on the idea of supporting the foraging - sensemaking process in its entirety . In addition , we leverage parts of web pages as our unit of information and introduce intelligent machine support in each of the steps in the process . 2 . 3 Reading and Collecting Information on the Web Related to the support of research tasks is the practice of active reading [ 1 ] . During active reading , a reader is engaged in critical thinking and actively marks , highlights and takes notes . The XLibris is one of the early systems that integrates this practice in electronic form and introduces different types of computer support for its users [ 31 ] . Aspects of our work are inspired by the XLibris system . In particular , we adapt ideas and features about highlighting documents while reading and using these markings to provide research support , to online research using a web browser and the Internet . Later work [ 24 ] investigated understanding the role of clipping information people encounter and its implications for the design of interactions with electronic documents . They found clippings play an important role as reference materials , reminders or sharing materials , and they also found challenges in organization and revisitation of clips . Our work leverages clips as an important in - formation unit that people are familiar and work with . We combine these observations with the notion that clips also provide coherent semantic units that machines can understand and build support from . Several products in the market target helping users with collecting and organizing web content . Pocket [ 30 ] focuses on the collection of articles , videos and stories from web sources that help users tee up the sequence of content that they want to go through . Services such as Pinterest [ 28 ] suggest related clippings from other sources as an attempt for cross - pollination , yet affinity and connections between existing clippings are not highlighted . In Evernote’s browser extension [ 10 ] , past clippings related to a current search are surfaced to remind users of prior clippings that might be associated or related to the search activity . Nonetheless , these suggestions encourage a comple - mentary revisiting of old clippings , rather than encouraging users to actively synthesize research at hand . Prominence is placed on the foraging process of research , rather than sensemaking . 3 THE FORSENSE SYSTEM 3 . 1 Sensemaking Framing We apply sensemaking theory [ 29 , 36 ] as a design framework not only to organize tasks and ac - tions that people perform during online research activities but also to identify opportunities for a ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 5 Fig . 1 . Human actions and machine support for foraging and sensemaking loops in online search activi - ties . Machines can support foraging and sensemaking actions throughout the entire process to speed up alternating between foraging and sensemaking actions . Solid lines for machine support indicate that these capabilities are implemented in the current ForSense prototype . machine to support them . At a high level , the sensemaking process involves alternating between foraging and sensemaking loops to form an information representation structure . Each loop can be further characterized by actions that support online research . Figure 1 illustrates how foraging and sensemaking actions can be organized for online research tasks . During the foraging loop , people interact with data sources ( e . g . , web pages ) to search for in - formation ( Figure 1 ( A ) ) . After reading and comprehending the information ( Figure 1 ( B ) ) , people curate a set of relevant and promising information by clipping and extracting information from web pages ( Figure 1 ( C ) ) . This collecting activity fits the common practice of active reading [ 1 , 31 ] and forms the basis of the foraging loop . As people clip information , they form a collection called a shoebox . As people engage in foraging tasks , they also form theories about how the collected information can be organized or structured . This is the start of a process Pirolli and Card [ 29 ] call schematization , described as the nexus between foraging and sensemaking loops . During the sensemaking loop , people form a schema from collected information . Schemas can be seen as an articulation and representation of the knowledge and understanding gained during the larger sensemaking process that informs the overall online research . Inspired by [ 18 ] , we further break down the sensemaking loop into defining and modifying a schema or groups of clipped information ( Figure 1 ( D ) ) and evolving a schema or group semantics ( Figure 1 ( E ) ) as people test the schema’s fit for the clipped information ( Figure 1 ( F ) ) . Each one of the human actions performed during this sensemaking process provides an oppor - tunity for machines to provide research support . This could either be directly related to the current action at hand or could accelerate the overall research goals by facilitating foraging or sensemak - ing tasks in parallel . For example , when people are collecting clips of information from a web page , the machine could suggest other relevant parts the web page to be clipped , thus assisting with the current foraging action . On the other hand , a machine can also suggest how the clip supports exist - ing schema or which group the clip belongs to , thus assisting with a sensemaking action in parallel . Machine supports in Figure 1 demonstrate such potential opportunities for machines to augment each foraging and sensemaking action . Although this list of opportunities is not exhaustive , they provide inspiration for our system design . 3 . 2 Design Principles With sensemaking theory as a design framework , we identified tasks and design opportunities for machine support for online research activities . In addition to supporting these human actions , we ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 6 G . Ramos et al . wanted to account for the iterative and evolutionary nature of online research , support the fre - quent alternation and overlap between foraging and sensemaking loops , and incorporate machine support without hampering the main research task . Therefore , we summarize our design goals into the following principles to guide our design : DP1 - Use small units of analysis . As people collect information , they naturally underline , mark or clip part of a larger document [ 24 ] . We argue not only that leveraging this practice is valuable , but also that having smaller information chunks leads to more semantically coherent units that facilitates schematization and machine support . DP2 - Leverage machine’s capabilities . We aim to explore opportunities for leveraging modern machine - reading capabilities for the system to support online research activities as illustrated in Figure 1 . These machine capabilities include seeing relationships among pieces of clips people have collected as well as revealing connections among unseen clips , at large scales and at speeds beyond human capabilities . DP3 - Support integrated sensemaking activities . Existing support for online research is frag - mented , for instance , people often have to switch between different applications or move across separate foraging and sensemaking activities . We aimed at eliminating the cognitive burden from these fragmented experiences by directly integrating support tools into where the research is per - formed and by making it easy to switch between foraging and sensemaking actions . DP4 - Minimize the cost of incorrect machine support . Powerful and enabling at best , system support fueled by machine learning can be at times unhelpful or incorrect . We strive to augment human capabilities , while giving people the agency to disregard or easily recover from unwanted machine suggestions . 3 . 3 System Overview Guided by sensemaking theory and our design principles , we crafted ForSense , a chromium browser extension prototype to support and improve people’s online research experience . We de - signed and implemented our design probe using short design - critique iterative cycles between the main authors and design stakeholders in our research lab , in a way similar to how prototypes are created during a Design Sprint [ 19 ] . At a high level , ForSense supports human actions as well as machine support capabilities outlined in Figure 1 . ForSense consists of three main components : the browser extension ( Section 3 . 3 . 1 ) , an NLP service providing paragraph encoding capabilities ( Section 3 . 3 . 2 ) , and a data and synchronization service that stores clips and updates different web browser elements about changes made by a user ( Section 3 . 3 . 3 ) . 3 . 3 . 1 Browser Extension . We implemented our prototype as a chromium extension to directly integrate the experience into the tool people use to find and research information for their task . ForSense supports in place foraging activities through a clips sidebar ( Figure 2 ( A ) ) by letting people highlight interesting or meaningful parts of the web pages under review . We call these collected highlights clips . The extension also allows people to easily switch into sensemaking ac - tivities through a sensemaking canvas ( Figure 3 ) by letting them organize collected clips into groups that can provide an overview of what they are researching . As people collect and organize relevant information they find by navigating web pages , they can make progress towards fulfilling a variety of research tasks . Clips Sidebar and Clipping . ForSense injects a clips sidebar ( Figure 2 ( A ) ) , an area that keeps a record of clips people collect during their web browsing research and fulfills the role of the shoebox from the sensemaking theory . People collect clips by highlighting a part of a web page that is ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 7 Fig . 2 . ForSense foraging experience . ( A ) Clip sidebar injected into the web page , ( B ) Save clip / page but - ton , ( C ) a clipped item card , ( D ) the card has grey color if ungrouped , otherwise it has the group’s color , ( E ) clipped item highlighted in the web page , ( F ) Sensemaking canvas button , ( G ) Machine suggested clip , and ( H ) jnteracting on a suggested clip . currently in view and hitting the Save Clip button at the clips sidebar ( Figure 2 ( B ) ) . Once collected , a truncated view of the of the clip appears as a card in the sidebar , while its highlight remains in the page ( Figure 2 ( E ) ) . Because it is sometime desirable to collect a whole page , the sidebar allows to collect a whole page if no selection is currently being made . Clicking on clips reveals the clip detail view which contains the full captured content . The clip detail view also provides the opportunity to add custom comments to the clip , to qualify the reason why a clip was captured , for example , and to assign a clip into existing groups if the user has created groups of clips . The Sensemaking Canvas . People can inspect and organize the clips they have collected in a view we call sensemaking canvas or canvas for short , which is designed to directly support the sensemaking loop ( Figure 3 ) . The canvas is opened as a browser tab when people click its button in the sidebar ( Figure 2 ( F ) ) . The main canvas area allows people to organize the clips they have collected into groups and spatially arrange them to make sense of a larger picture or a set of topics ( Figure 3 ( A ) ) . To the left of the main canvas area is the collection pane which contains the clips a user has collected and has not yet put onto the canvas ( Figure 3 ( B ) ) . This collection pane also has a filter that lets users find clips with highlights or notes containing a search term . A user can move a clip onto the canvas by dragging it from the collection pane onto any location that makes sense to them . Users can then create groups that represent a topic or a category for a set of clips on the canvas by selecting one or more of them hitting the create group button that appears near them ( Figure 3 ( C ) ) . Once created , users can click on a group’s area to reveal a details pane that lets them edits its name or write comments . Each group has a unique color associated with it . Clips belonging to a group will display the group’s color to indicate their membership . If a clip on the canvas does not have a color , it means that it does not belong to a group . The canvas ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 8 G . Ramos et al . Fig . 3 . ForSense’s sensemaking canvas . ( A ) Main canvas area where people can spatially position clips into groups , ( B ) Collection pane that contains collected clips and filter / search functionality , ( C ) New group button , ( D ) Example of a group and clips within them , ( E ) Auto group button in the collection pane , and ( F ) the group it is suggesting with a emphasized border . lets users evolve their knowledge representation over time by dragging clips in and out of groups . In this way , large groups can split into other groups , or smaller groups merged . Machine Support . As we illustrated in Figure 1 , machines can provide both foraging and sense - making support . Our prototype uses the clips in a group to compute a group embedding , which is used to make suggestions for related clips or groups . As such , ForSense will make better sugges - tions if the clips in a group represent a coherent theme or topic . Section 3 . 3 . 2 describes how we computed embeddings . After ForSense learns about the ideas , concepts or themes that are important to the current on - line research task , it will start suggesting parts of the web pages that might be of interest during the foraging loop . These suggestions are highlighted as decorations ( Figure 2 ( G ) ) on the web page that the user is currently viewing . In addition , the clips are colored according to the group that the machine thinks the clip belongs to , hence allowing for direct integration of schematization activ - ity within this foraging loop . The users can collect these suggestions as clips , mark as irrelevant , or ignore ( Figure 2 ( H ) ) . If the suggested group is incorrect , the user can correct the clip’s group membership in the clip detail view . Similar to group suggestions during the foraging loop , ForSense also suggests what group a clip likely belongs to within the sensemaking canvas . Each clip from the collection pane has an autoplace button that , when hovered over , highlights the group that ForSense suggests as the most likely destination ( Figure 3 ( E ) , ( F ) ) . This preview helps users consider if they want to accept the system’s suggestion . If a user agrees with that suggestion , they can click the button and have the prototype move the clip onto the suggested group area . ForSense provides a counterpart to the autoplace functionality . Hovering on the attract button on a clip or a group highlights ungrouped clips on the canvas likely to be related . Clicking on this button brings these clips close to the attracting clip or group . To allow easy recovery from undesired machine suggestions , we provide an undo button to recover previous states . ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 9 3 . 3 . 2 NLP Services . Modern transformer ML models such as BERT [ 8 ] can be used as a way to encode text input into a representation made up of an array of numbers , called embedding . These embeddings have the remarkable property that two semantically close pieces of text will also be close in the embedding space according to a distance metric ( e . g . , the cosine distance between two vectors ) . ForSense takes advantage of this machine capability and applies it to the clips that users collect while researching online . ForSense computes an embedding of every clip users collect . Similarly , when users visit a web page , ForSense computes a list of embeddings from its parts ( text content within the < p > or < li > tags ) . Page clips and parts are likely to be semantically more coherent than a whole page , which makes their embeddings to be more faithful representations of their original content . When users create or update a group , its embedding is calculated as an average of its clip’s embeddings . Our system uses these embeddings in several ways . Given a set of groups , the system can sug - gest which clips are within a specified semantic distance to the groups . This is done by calculating and sorting the cosine similarity distance between a group’s vector representation , and the vec - tor representation of collected clips . This is the basis for ForSense’s attract functionality . Given a clip , the system can suggest which groups are closer than a specific semantic distance to it . This is done by calculating and sorting the cosine similarity distance between the given clip’s vector representation and those of the defined groups . This is the basis for ForSense’s autoplace function - ality . Finally , given a group , ForSense can suggest which parts of a page are within a specified semantic distance to the group . These suggestions are based on a general distance threshold that we determined through pilot studies to favor recall over precision and used by ForSense to suggest related parts of a webpage to existing groups . The embeddings computation was separated from the browser due to its computational cost . We implemented a RESTful service that is accessible to the browser extension . This service com - putes BERT embeddings using bert - as - a - service [ 42 ] from different types of input such as text paragraphs or a web page’s URL . We used the pre - trained uncased _ L - 12 _ H - 768 _ A - 12 BERT model which provided useful suggestions through pilot studies . 3 . 3 . 3 Data and Synchronization Services . Between the browser extension and the NLP services , we have data and synchronization service layer , a RESTful service that provides data storage and Create / Read / Update / Delete ( CRUD ) capabilities to the extension . This service also interfaces with the NLP services to obtain the embeddings , which it uses to provide the machine suggestions enumerated in Section 3 . 3 . 2 to the system . The browser extension’s UI is kept synchronized and consistent across different browser tabs through websockets . 4 USER STUDY We built ForSense as a design probe . Design probes are adapted from cultural probes , which often consist of designed objects used in open - ended , sometime oblique tasks with the goal of engaging participants into the design process while revealing knowledge that can be reflected upon by all stakeholders to further a research activity . [ 5 ] discusses how the HCI field has adapted cultural probes in different , mostly information - seeking ways . Our use of ForSense as a design probe fol - lows a use of probes that consists of going from a broad collection of data to a set of requirements , themes , and insights which are used to inform design . Through our study , we seek to engage potential users of the system in our design process and to collect information that can help us understand how the integrated support for foraging - sensemaking experiences and the use of ML - based machine support can enhance online research tasks . We use the probe in combination with a task - based , semi - structured interviews in order to observe realistic use of the system in an on - line research task and to elicit feedback from participants about our current design and potential ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 10 G . Ramos et al . new directions for the system . Thus , in our user study , we aim to answer the following research questions in the context of our online research task : RQ1 . How do people and their actions benefit from the machine’s support as they perform the online research task ? RQ2 . How useful is the integration of foraging and sensemaking activities into the system and the flexible alternation between them in helping people accelerate their research task ? RQ3 . What are effective strategies for handling imprecise support by the machine ? RQ4 . What does the probe reveal about the nature of this online research task , the behaviors people exhibit when performing it , and the artifacts they create ? 4 . 1 Participants We recruited 10 ( 6 Female , 4 Male ) participants from a large technology company , which aligns with local standards for sample size for design probe studies in HCI [ 7 , 12 , 20 ] . This number of participants is sufficient in similar user research scenarios to reveal to researchers promising di - rections in which to move forward , such as finding 80 % of major usability issues during heuristic evaluations , 1 or collecting enough information to decide whether to fund the development of a product [ 19 ] after a Design Sprint . These participants hold diverse backgrounds and roles raging from Designers , Program Man - agers , Scientist , Design Producers , and Software Engineers . All participants have performed online research tasks on the Internet using a web browser . Seven participants were between 25 – 34 years of age , one was between 18 – 24 years of age , and two were between 35 – 44 years of age . Four participants had a bachelor’s degree , and six held a Master’s degree or higher . Participants were compensated with a $ 25 gift card . 4 . 2 Procedure We conducted the study remotely using the Teams video conferencing platform . The study con - sisted of three stages : introduction , practice , and task . During the introduction , participants watched an approximately 5 - minute - long video that presented the main features of ForSense : se - lecting and clipping text parts of a web page , organizing these clips in the sensemaking canvas , and using the system’s highlights and suggestion features . After the introduction , participants connected to a remote machine that had the ForSense extension installed . 2 Participants shared their screen as they practiced with the system’s features for about 10 minutes , and the researcher answered questions about the system . After the practice stage and a brief explanation of the task , participants began the online research task for 30 – 40 minutes and were encouraged to think aloud . Section 4 . 3 describes the task in more detail . Once participants completed their research task , they filled a system usability scale ( SUS ) survey [ 6 ] . The study concluded with a 10 - minute semi - structured interview about their experience : what aspects of the experience they liked , which ones had room for improvement , and what other types of machine support they would welcome . People’s screen interactions and voice were recorded on video . After the study was completed , two researchers reviewed and coded these videos using an open coding strategy . This task con - verged to a set of 36 codes that capture the actions people took during their task . Tables 1 and 2 list the set of codes we converged to and used during the analysis of the sessions . While we organized codes according to actions related to Clips , Groups , Browser , ML , and Other , codes can be associ - ated ( almost distinctively ) to the sensemaking or foraging phase in the task . These codes emerged 1 https : / / www . nngroup . com / articles / how - to - conduct - a - heuristic - evaluation / . 2 To reduce setup time and avoid installation issues , we provided a remote machine with the appropriate set up that partic - ipants could use for the study . ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 11 Table 1 . Codes used During the Qualitative Analysis of the Online Research Sessions Groups Code Description Foraging Sensemaking # Codes # Participants Clips unpin Remove clip from canvas x 5 2 add _ page Add page x 17 7 add _ clip Add clip x 135 10 add _ clip _ canvas Drag clip to group x 91 10 add _ clip _ sidebar Add clip to group x 8 3 del _ clip Delete clip x x 3 3 del _ clip _ canvas Drag clip out of group x 9 4 del _ clip _ sidebar Remove clip from group x 0 0 drop _ clip _ canvas Drag clip onto canvas ( not group ) x 125 10 Groups del _ group Delete group x 2 2 tidy _ group Tidy group x 105 10 ren _ group Rename group x 3 1 new _ group Create group x 51 10 switch _ clip _ canvas Drag clip from group A to B x 6 4 switch _ clip _ sidebar Change clip from group A to B x 1 1 Browser navigate _ to Navigate to page x 113 8 new _ tab Open new tab x 17 7 switch _ to Switch between browser and another app x 106 9 close _ tab Close tab x 21 7 search Web search x 66 10 open _ link _ doc Open new tab from a link on a webpage x 24 5 open _ link _ search Open new tab from a link on a search page x 52 8 switch _ tab Switch tabs x 225 10 open _ link _ clip Open new tab from a link on a clip x x 6 2 open _ canvas Open or switch to the sensemaking canvas x 94 10 We group codes according to the main nature of the observed action / activity . While some codes can occur during foraging and sensemaking phases , most codes apply to one phase . The table also includes for each code , how many codes were captured , and how many participants produced them . Codes continue in Table 2 . from iteratively inspecting three representative videos out of the ten available . Because of this choice , some of the generated codes are the result of reasonable assumptions about the likelihood of them appearing during a session . Our assumption did not hold for two codes ( del _ clip _ sidebar , ignore _ suggestion ) which had a total count of zero . We also analyzed the data artifacts produced by the participants over time : the clips they captured , their source and the groups they formed af - terwards . In the next sections , we discuss insights from the analysis of the sessions . These insights stem from observations done across our ten participants , thus while they lead to valid arguments and hypothesis to follow on , at this moment they do not have generalization power . 4 . 3 Online Research Task Participants were asked to conduct online research in order to prepare an outline for an intro - ductory presentation about a topic . They could choose a research topic that they were not familiar with but were interested in learning about . Although we provided a list of research topics to choose ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 12 G . Ramos et al . Table 2 . Codes used During the Qualitative Analysis of the Online Research Sessions ( Continued ) Groups Code Description Foraging Sensemaking # Codes # Participants ML save _ suggestion Save clip suggestion x 11 5 ignore _ suggestion Ignore ( not hover ) clip suggestion x 0 0 attract Use attract feature from a group x 13 6 attract _ hover Hover over the attract feature on a group x 19 7 autoplace Use autoplace feature on a clip x 20 5 autoplace _ hover Hover over the autoplace feature on a clip x 40 5 consider _ suggestion Hover over the suggestion feature on a suggestion x 15 6 Other add _ comment Add comment to a clip or group x x 32 8 search _ canvas Filter clips on the sensemaking canvas x 3 3 begin _ task Marks the beginning of the task 10 10 end _ task Marks the end of the task . 10 10 We group codes according to the main nature of the observed action / activity . While some codes can occur during foraging and sensemaking phases , most codes apply to one phase . The table also includes for each code , how many codes were captured , and how many participants produced them . from , participants were free to come up with their own topic . Example topics include Designing a board game , What is Kombucha and how to make it , and Becoming a birdwatcher . Participants had 30 minutes to complete their online research , with up to an additional 10 minutes to commit their presentation outline . We gave people the choice to produce this outline as a bulleted list ( using a standard text editor ) or in the system’s sensemaking canvas . During this task , we encouraged participants to think aloud as they performed it so as to identify and collect insights and impres - sions about the task and tool . When using the think aloud protocol , there is always a risk of it interfering the normal flow of the task where automatic behaviours take place . In our case , we aimed at minimizing these effects by not engaging in a conversation with participants until they were done with the task , and by ( if needed ) reminding them to think aloud only during moments where they were not performing an action or seemed deep in thinking . Also , the task we presented participants is novel enough so that any automatic behaviours that thinking aloud might affect did not correspond with the main aspects we interested in observing . Figures 4 and 5 show example outcome artifacts of the study . 5 RESULTS All participants successfully completed their research task and produced outlines for their chosen topics . In the following sections , we summarize and discuss our observations and insights that address our research questions . 5 . 1 Machine Support Accelerated Human Online Research Actions ( RQ1 ) Participants thought that machine support helped their foraging and sensemaking activities . Par - ticipants who took advantage of the autoplace or attract features praised them as shortcuts to accelerate sensemaking : “ ( P07 ) For me I think it’s exciting because it’s going to surface relationships ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 13 Fig . 4 . Screenshot of a participant’s sensemaking canvas at the end of the study . The participant used the sensemaking canvas to define seven groups to help them in their research about how to create a board game : Theme , Pitch , Rules , Market , Asia - Pacific Market , Distribution Channels , and Prototype . Fig . 5 . Output from one of the study’s participants . In addition to the final configuration of the sensemaking canvas , some participants synthesized their output into a high - level text document . ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 14 G . Ramos et al . Fig . 6 . Example of attract actions taken by participants P02 , P05 , P08 , and P10 during the study task . We show a subset of codes from Table 1 to simplify the chart . We group labels outside of that subset under the label “other” . We plot actions in separate horizontal lanes to avoid visual overlap among the actions . We color code actions according to the phase they correspond to : foraging ( blue ) and sensemaking ( magenta ) . The x - axis denotes the session’s time normalized into a 0 – 100 number scale spanning the beginning and end of the task . The figures show how attract actions are followed by a succession of add - clip ones ( a ) to the group clips were attracted to . within data . Maybe relationships that I hadn’t thought of when I created that rough outline to go and research” . Participants also liked the system suggesting parts of web pages as potential content to clip : “ ( P08 ) [ I just like ] the idea to , like , clipping and cataloging things” . Attraction seems to have helped people building groups quicker by bringing uncategorized clips close to the potential group to include them on . This type of support spares people from having to sift through clips and separate the ones they think best fit a group . Figure 6 zooms into moments in the sessions where participants made use of the attract feature . Participants followed the use of the attract feature with a succession of add - clip actions over the majority of the attracted clips . It is reasonable to assume that this series of actions was faster than manually looking for and judging group membership for uncategorized clips . Autoplace seems to have helped people to make faster decisions confidently . As the system puts a clip close to a related group , people either agree with the system by adding the clip into the group , or take a corrective action by adding the clip into the group they think is a better fit , which includes the possibility of creating a new group . We hypothesize that this intervention is helpful as showing people a paragraph they can edit instead of writing from scratch . Figure 7 zooms into an example of the actions a participant takes immediately after they use autoplace . We also observed that machine suggestions accelerated the research task . First , clip suggestions allowed participants to quickly focus on relevant parts of a page . Second , they helped participants attend to parts of a page they would have otherwise missed because they were quickly scanning a page or focusing only on noticeable images or fonts : “ ( P05 ) Did you see how I naturally scroll right over it , but I noticed the pink line , and like . . . wait woah , let’s go back up there” . Third , machine sug - gestions gave people a starting point for a mixed - initiative interaction [ 13 ] , an opinion they could editorialize , undo , or correct . Regardless of the quality of the suggestions , they provided visual landmarks for efficient active reading process , increased a reader’s awareness of topics , themes , and concepts of interest in the page , and accelerated clipping . We observed other patterns of use that could be further investigated . Clip suggestions were more visible for those people that frequently alternated between foraging and sensemaking ac - tivities than those that performed these activities in batches or chunks because the participants’ schematization of clips into groups gave the machine structural information to provide updated ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 15 Fig . 7 . Detail of autoplace actions taken by participant P04 during the study task . We show a subset of codes from Table 1 to simplify the chart . We group labels outside of that subset under the label “other” . We plot actions in separate horizontal lanes to avoid visual overlap among the actions . We color code actions according to the phase they correspond to : foraging ( blue ) and sensemaking ( magenta ) . The x - axis denotes the session’s time normalized into a 0 – 100 number scale spanning the beginning and end of the task . The figure show how autoplace actions are often closely followed with add - clip ( a ) . This seems to indicate that this type of machine agency helps people take quick decisions . suggestions . On the other hand , the system implementation did not provide suggestions without existing groups , illustrating a well - known cold - start problem in learning systems . We could have used existing clips to suggest other clips but this was a design choice that should be revisited . Some participants missed suggestions that could have enhanced their clipping and grouping ac - tions early on . Others expressed that they would have liked to see the system propose potential groups given a set of clips , even as an imperfect starting point to refine : “ ( P05 ) If there was a way to maybe suggest . . . at the very beginning when you just started your search and you were just starting to save things . , It could auto suggest categories” . Although the autoplace feature was well understood , some people were confused about the attract feature : “ ( P11 ) The only concept that was a little weird to me was attract” . In addition to making the feature more intuitive , participants suggested a way to control the strength of the attraction and modulate how many or semantically distant clips it affects . Such interaction could potentially be used to improve control and understanding of the system . 5 . 2 Seamless Integration between Foraging and Sensemaking Promoted Research flow ( RQ2 ) , and Lead to Activity Patterns ( RQ4 ) Participants expressed how they liked having the ability to collect clips ( i . e . , foraging ) and organize them ( i . e . , sensemaking ) all within the same browser : “ ( P06 ) I mean the more the more stuff we can do in the browser the better , and not having to switch between a million apps . ” We observed how the sensemaking canvas provided participants with a way to externalize their current mental model about a topic ( create groups ) , test it ( assign clips to groups ) , refine it ( create new group or sub - groups ) and quickly switch back to collecting more information from the same browser session by simply opening a new tab and starting a new search . We found that participants had differing research patterns that influenced and often dominated how they navigated between foraging and sensemaking loops . These patterns can be seen as char - acterizing a session without them having to occupy the totality of the session’s time . Through our video analysis we identified three patterns : Clear split ( P04 , P06 , P07 , P08 ) . In this pattern , a significant portion of the task is divided in two well - defined stages : People will spend the first portion of their time foraging , where they collect the majority of clips from a few number of pages . This stage is later followed by a large sensemaking period , where people sensemake and organize the collected clips into groups . We hypothesize that participants that fit this pattern form and keep in their heads the schema they will later articulate ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 16 G . Ramos et al . during sensemaking . Figure 8 - P08 shows an exemplar of this pattern where clip collection and foraging activities happened almost exclusively during the first half of the session . Convergence ( P02 , P03 , P05 , P12 ) . In this pattern , people frequently flow back and forth between foraging and sensemaking stages where the duration of foraging activities gets shorter in dura - tion as the task nears completion . Our observations suggest that this convergence relates to a person’s increasing understanding of the information they have collected , as it also converges to a stable set of groups and concepts . During this pattern , people visit and revisit many pages , to help them evolve their understanding of a topic and to collect clips to add to existing or new groups . Figure 8 - P05 shows an exemplar of this pattern where the duration of foraging activities decreases over time . Uniform activity ( P10 , P11 ) . This is the least frequent pattern that we observed in our studies . People that followed this pattern flowed evenly across time often between foraging and sensemak - ing activities . Similarly to convergence people visited and revisited many pages to help them evolve their understanding of a topic and to collect clips to add to existing or new groups . We theorize that the set of groups and concepts they defined did not reach a stable state in the time they had . It is possible that if they were given more time to complete a task , they behaviour will eventually match that of the people on the convergence group . Figure 8 - P11 shows an exemplar of this pattern dominating the session . When this pattern takes place , foraging and sensemaking actions are more evenly interspersed . For all three phases , it was common to observe that towards the end of the task , when people thought of the task’s goal of preparing / articulating a presentation outline , they sporadically and briefly left the sensemaking canvas to inspect the source material on the web browser . We observed that people did this to access material to support articulating an presentation outline . During this preparation task , some people did engage into final , yet minimal foraging actions . Our study and observations revealed opportunities for further task integration and to help peo - ple with their online research task . One of these opportunities stems from participants expressing a desire to do a “brain dump” at any point during the research task . An example of this desire is when participants thought out loud the groups they wanted to create before or during the forag - ing stage , and wanted to create empty groups , before any clips about it were collected : “ ( P04 ) I’m going to create a group . . . oh , . . . I was hoping that I could just [ do that ] ” . Future systems that support research and sensemaking activities should support this either allowing people to create groups at any stage , or by the systems suggesting relevant groups for documents during sensemaking , as Figure 1 alludes to . We observed that being able to switch between foraging and sensemaking activities in the browser kept participants in a state of research flow ; participants who were able to blur the boundaries between collecting and organizing were more efficient at their tasks . This observation underscores opportunity to help people during a research task that are ”stuck” on any particular phase . For example , the system can suggest that after collecting a certain number of clips , it might make sense to switch to a sensemaking period . Conversely , a system can suggest new documents to forage after it detects a person has converged to a stable set of groups . Figure 1 also alludes to this type of intervention as the main form of machine agency supporting foraging . It is possible that observing more complex research activities would reveal patterns different from the ones we present . The patterns we observe are the result of observing ten individuals each performing a particular research task , and as such , more studies need to be done to claim general results . However , we believe that these three patterns we observed can be used to unpack longer , more complex research sessions where any combination of them can take place . Regardless of what pattern people utilized , the fact that we observed such diversity of styles reinforces our arguments ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 17 Fig . 8 . Actions taken by participant P08 , P05 , and P11 during the study task . We show a subset of codes from Table 1 to simplify the chart . We group labels outside of that subset under the label “other” . We plot actions in separate horizontal lanes to avoid visual overlap among the actions . We color code actions according to the phase they correspond to : foraging ( blue ) and sensemaking ( magenta ) . The x - axis denotes the session’s time normalized into a 0 – 100 number scale spanning the beginning and end of the task . Above each of the plots we summarize the foraging and sensemaking phases as lines that help describe the dominant patterns for each participant . We emphasize these dominant patterns inside marking boxes , ( A ) , ( B ) , and ( C ) . P08 interactions were dominated by a Clear split pattern ( A ) where most clips were captured during the first half of the session . P05 interactions were dominated by a Convergence pattern ( B ) where most events were foraging actions ( in this case add - clip ) that decreased in duration over time . P11 interactions were dominated by Uniform activity patterns ( C ) where foraging and sensemaking activities look evenly distributed across time . about the need for integrated online research experiences that facilitate seamless flowing between foraging and sensemaking activities . 5 . 3 Machine Suggestions were Accepted as Part of the Process , and Needed to be Correctable ( RQ3 ) Occasionally during the study , the system provided imprecise or unhelpful suggestions to the par - ticipants . We observed that participants formed a mental model about how the system works and how they can affect it [ 33 ] . For example , some participants took these unhelpful suggestions as signals for human intervention , that they needed to collect more clips for a group , or that a group ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 18 G . Ramos et al . Fig . 9 . Web page visitation pattern for P04 that illustrates an anchor page ( lane G , highlighted ) . We normalize time scales into a 0 – 100 number scale spanning the beginning and end of the task . The chart shows clip collection ( circles ) for different web pages over time with color denoting the group the clips will end up going to . The chart also shows moments when the participant switched to a webpage ( X ) . We separate different web pages in different horizontal lanes . was not well defined . After human intervention , participants previewed group suggestions to eval - uate if the system started to understand what theme or concept was important for each group . Some participants rationalized machine suggestions : even when they saw a decision they did not agree with , they forgave the system because the system did not have the full picture : “ ( P11 ) I feel like maybe I trained it poorly and it would not highlight good things , but I’m still super interested in that highlighting feature . ” Other participants wanted to correct an incorrect suggestion by teach - ing the system what it did wrong or what to look for in clips , highlighting a “teaching” moment that future systems could design for [ 32 ] . Participants thought that the ability to revert an unhelpful machine suggestion was especially useful during the attract action , where many clips could be brought into a group . However , be - cause attract operation could move several clips with a mix of helpful and unhelpful suggestions , participants wanted finer control beyond previews and undo actions to regulate the system’s rec - ommendations and to verify their understanding of the quality of the suggestion . We observed that there were human costs associated with unhelpful suggestions : “ ( P05 ) if a computer is telling me it should go here [ the group that she doesn’t expect ] , I would reread it and I would be like maybe I’m misinterpreting it . ” However , others pointed out the ease of handling errors with a generous tolerance for incorrect suggestions : “ ( P04 ) For machine learning , honestly , I would hope for at least a 50 % like success rate at least since it’s not like super critical and I can easily change it . 50 to 70 % would be good . ” Therefore , understanding and embracing a system’s limitations can be key in establishing how a person and a machine’s capabilities complement one another . 5 . 4 Key Web Pages Contributed Clips to Many Groups , and Acted as Knowledge Anchors ( RQ4 ) While for most of the pages they visited , people produced one clip ( thus contributed to one group ) , there were pages that contributed clips to many groups . We call these pages anchor pages . These pages consist of an overview of a topic of interest , and are well structured into topical sections , that participants would use as a starting point for their initial research task and schema ideation . Examples of such pages include content from sites like Wikipedia , and Wikihow . Because of the referential nature of these pages , people revisit them throughout the task , much more frequently than other pages , and treated them as an authoritative reference to verify if they are missing any significant aspects of the topic . Figure 9 illustrates an example of the how different pages contributed to the clips people collected and to the groups they formed . Lane G shows an example of an anchor page that is visited multiple times during P04’s foraging activities - P04 followed a clear split pattern where most foraging occurred during the first half of the session . Anchor pages were not the only pages that people visited more than once . However , most of non - anchor pages only contributed to one group . Our video observations showed that people were ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 19 Fig . 10 . Distribution of answers for SUS questions from the study’s participants . Each horizontal bar ac - counts for 10 responses . checking for more content to augment groups , or new insights to evolve the evolving schema . The presence of this kind of referential pages and revisitation patterns suggests opportunities for machine support during the foraging and sensemaking stages . During foraging it is feasible to identify that a page is referential in nature ( e . g . , by identifying their providence ) and suggest them as important places to visit after a search , and pre - suggest parts of their content to collect . One can also envision machine interventions that suggest as the schema evolves , what pages are worth revisiting , and equally important , which ones are not . This type of intervention can save people time from a tedious back and forth switching among documents . During sensemaking , the system can use anchor pages as sources for suggested groups or schemas , and the existing schema to suggest places to revisit . 5 . 5 Usability and System Limitations The average and median SUS scores were 72 . 3 and 73 . 8 , respectively . Figure 10 illustrates the distri - bution of the participants’ answers . Participants that scored the system below these values pointed to prototype limitations in grouping functionality and sporadic bugs that required reloading the current web page . Participants suggested additional features to improve the usability of the sys - tem . For example , participants wanted the ability to clip images or videos from web pages or to automatically layout clips within a group . Others suggested the ability to define multiple research session to decompose their tasks . Finally , some participants wanted to directly export or connect their sensemaking work into other systems so that it could be used as a basis for a presentation deck or to share findings with other people . 6 DESIGN RECOMMENDATIONS Using ForSense as a design probe , we learned that machine support can accelerate human online research efforts and that fluid interaction between foraging and sensemaking promoted research flow . We also found that people formed mental models about the system and wanted to correct unhelpful or incorrect suggestions . Based on our findings and observations from the user study , we identified several key design considerations for incorporating machine support in human - AI collaborative online research systems : Imprecise machine support can be useful . During our study , we consistently observed that partic - ipants not only tolerated , but also valued imprecise support . Suggestions provided opportunities ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 20 G . Ramos et al . to question their perspectives , and exploring the diversity of information , which is crucial during research tasks . These suggestions also provided an insight about the system’s model of the world ; people used that information to form theories on what the system needs to improve . Therefore , it is important to design a system that allows people to form appropriate mental models about the system , for example , through visualizing and inspecting the factors that affect the system’s decision or suggestion . Think about complementing before collaborating . While there is a collective aspiration for sys - tems that display general intelligence , most intelligent systems nowadays only provide specialized behaviors for specific tasks ( e . g . , classification , detection , prediction ) or subject domains . Over the course of our study , we found it useful not to think about human - AI collaboration , which can elicit imagery of aligning goals from two entities , but rather to think about complementing human and AI capabilities . This perspective relaxes what one needs to expect from a system and think about how a person’s capabilities can be augmented , not replaced by ML technologies . In a human - AI complementary framework , machine support begins where human agency ends - and vice - versa . Figure 1 illustrates how we used sensemaking theory to identify how to complement people’s actions throughout an online research task . Identify and design for teaching moments . In our study , participants understood that defining groups was a means to tell ForSense about what concepts were important to them . In our system , the only way to express these concepts was to collect clips . Even though groups and clips were suf - ficient for the underlying natural language understanding model to be helpful in online research tasks , participants expressed additional ways to teach the system such as a desire to mark a sug - gested clip as a negative example for a group . Therefore , it is important to identify and design for these teaching moments that give people agency about telling the system what is important , what is not , and why . We hypothesize that a system that receives this information should be better at supporting a person with their research activities . Teaching opportunities can also originate from the system . ForSense’s users could have benefited from system nudges , similar to those in [ 40 ] , that could have helped them take actions that move their data collection or organization tasks forward . ( Short ) Clips are useful units of information . In our study , we saw that participants were com - fortable with collecting and manipulating snippets from web pages ( i . e . , clips ) . Furthermore , our participants readily use these clips to express concepts and building blocks for higher - level seman - tic structures . The clips were typically more semantically coherent than the web pages containing them , and our observation of the presence of pages that provided clips to form different groups further reinforce the need of units of information that are but a part of a page . We argue that using these clips as units of information leads to easier human manipulation and understanding as well as better machine comprehension and suggestion . Assist people with their flow and focus . In our analysis of people’s actions , we observed different patterns of behavior that spoke of the different ways people switched between foraging and sense - making phases . We observed that some people stayed in one research modality for long periods of time . This was particularly apparent for participants with clear split patterns . While there is no cookbook that defines the cadence at which a sensemaking loop should be driven , there is an op - portunity to provide people engaging in such tasks with suggestions to switch to either foraging or sensemaking phases at certain times , when a critical volume of collected information is reached , or when a schema seems stales . Our analysis also revealed interesting patterns of revisitation for pages . While some pages served as anchors to go back to and inform potential schemas , others were visited unnecessarily , for instance , the information or insight people were looking was not ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 21 there . There are opportunities to focus people on documents that have high chance of being se - mantically related to the evolving schema , while muting into the background documents that have a high chance of having served their purpose . 7 FUTURE DIRECTIONS During our study , we identified promising directions for future research and studies : Accelerating the selection of search results . Participants in our study unanimously used web search to look for content to read and , if relevant , later collect . We believe that decorating a list of search results with their potential relevance to groups or topics of the research task may help accelerate selecting worthwhile results . Improving complementary support by increasing a person’s vocabulary to express concepts . We believe it is important to increase the ways in which people can express knowledge to a system . In addition to providing positive clips to define a group , it should be straightforward to provide negative clips to refine it . The distance calculation to this group may favor clips close to the positive set of examples , while penalizing clips closer to the negative set . Enhancing research flow by incorporating foraging into sensemaking , and supporting switching between phases . In the same way that participants performed grouping activities in the foraging stage , there is an opportunity to collect clips during the schematization stage . As illustrated in Figure 1 , future versions of ForSense can provide suggested clips found from sources such as the browser’s history , currently opened tabs , active web search results , well - known news or document sources , etc . Also , there is work to be done to characterize moments when it would be helpful to change between foraging and sensemaking . E . g . , moments like these could occur when one switches to sensemaking too early ( without having seen enough data to formulate schemas ) , or too late ( after uninterruptedly collecting too many clips ) . Leveraging embeddings beyond text for collecting more diverse relevant information . Although ForSense only leveraged text - based embeddings , current ML advances can produce representations or embeddings for other types of media such as images [ 22 , 44 ] or videos [ 39 ] . Furthermore , images can be translated into textual descriptions which can be used to calculate semantic distances with clipped text paragraphs . Future versions of ForSense can leverage these additional embeddings to provide semantic similarities between different types of media . Being able to suggest relations between different types of media can accelerate not only people’s ability to schematize , but also to collect relevant information for their research . 8 CONCLUSION In this work , we use sensemaking theory to ground the design of ForSense , a web browser exten - sion for accelerating people’s online research experience . ForSense integrates foraging and sense - making activities into the web browser experience and leverages recent advances in neural - driven machine reading to provide complementary support while a person collects and groups relevant information . We use ForSense as a design probe during a user study where people performed a real research task . We observed that the system’s integrated foraging - sensemaking approach and machine - driven support promoted people’s research flow , while complementing and enhancing people’s capacity to collect and group information . We were happy to find that people engaged in research tasks are tolerant to imprecise system suggestions and that these imprecise suggestions can still be useful . Lastly , our work underscored that complementary human - AI is a useful way to think about the interaction between people and AI in systems , in situations where the AI is specialized or imprecise . ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . 30 : 22 G . Ramos et al . REFERENCES [ 1 ] M . J . Adler and C . Van Doren . 2014 . How to read a book : The classic guide to intelligent reading ( Touchstone ed . ) . [ 2 ] Saleema Amershi , Dan Weld , Mihaela Vorvoreanu , Adam Fourney , Besmira Nushi , Penny Collisson , Jina Suh , Shamsi Iqbal , Paul N . Bennett , Kori Inkpen , Jaime Teevan , Ruth Kikin - Gil , and Eric Horvitz . 2019 . Guidelines for human - AI interaction . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland , UK ) ( CHI’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . [ 3 ] Michelle Q . Wang Baldonado and Terry Winograd . 1997 . SenseMaker : An information - exploration interface support - ing the contextual evolution of a user’s interests . In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems . 11 – 18 . [ 4 ] Benjamin B . Bederson . 2004 . Interfaces for staying in the flow . Ubiquity 5 , 27 ( 2004 ) , 1 . [ 5 ] Kirsten Boehner , JanetVertesi , PhoebeSengers , andPaul Dourish . 2007 . How HCI interpretsthe probes . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems . 1077 – 1086 . [ 6 ] John Brooke . 2013 . SUS : A retrospective . J . Usability Studies 8 , 2 ( Feb . 2013 ) , 29 – 40 . [ 7 ] Kelly Caine . 2016 . Local standards for sample size at CHI . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems ( San Jose , California , USA ) ( CHI’16 ) . Association for Computing Machinery , New York , NY , USA , 981 – 992 . [ 8 ] Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . BERT : Pre - training of deep bidirectional transformers for language understanding . In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) . Associa - tion for Computational Linguistics , Minneapolis , Minnesota , 4171 – 4186 . [ 9 ] Mira Dontcheva , Steven M . Drucker , Geraldine Wade , David Salesin , and Michael F . Cohen . 2006 . Collecting and organizingwebcontent . In PersonalInformationManagement - SpecialInterestGroupforInformationRetrievalWorkshop . 44 – 47 . [ 10 ] Evernote . 2020 . Evernote is the home for everything you need to remember , and everything you want to achieve . https : / / evernote . com / . Accessed October 2020 . [ 11 ] Marti A . Hearst and Duane Degler . 2013 . Sewing the seams of sensemaking : A practical interface for tagging and organizing saved search results . In Proceedings of the Symposium on Human - computer Interaction and Information Retrieval . 1 – 10 . [ 12 ] Fred Hohman , Andrew Head , Rich Caruana , Robert DeLine , and Steven M . Drucker . 2019 . Gamut : A design probe to understand how data scientists understand machine learning models . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland , UK ) ( CHI’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . [ 13 ] Eric Horvitz . 1999 . Principles of mixed - initiative user interfaces . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Pittsburgh , Pennsylvania , USA ) ( CHI’99 ) . Association for Computing Machinery , New York , NY , USA , 159 – 166 . [ 14 ] Shamsi T . Iqbal and Eric Horvitz . 2007 . Disruption and recovery of computing tasks : Field study , analysis , and direc - tions . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems . 677 – 686 . [ 15 ] Rune Møberg Jacobsen , Lukas Bjørn Leer Bysted , Patrick Skov Johansen , Eleftherios Papachristos , and Mikael B . Skov . 2020 . Perceived and measured task effectiveness in human - AI collaboration . In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems ( Honolulu , HI , USA ) ( CHI EA’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 9 . [ 16 ] Melanie Kellar , Carolyn Watters , and Michael Shepherd . 2007 . A field study characterizing web - based information - seeking tasks . Journal of the American Society for Information Science and Technology 58 , 7 ( 2007 ) , 999 – 1018 . [ 17 ] Aniket Kittur , Andrew M . Peters , AbdiganiDiriye , andMichaelBove . 2014 . Standingon the schemasofgiants : Socially augmented information foraging . In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing . 999 – 1010 . [ 18 ] Gary Klein , Jennifer K . Phillips , Erica L . Rall , and Deborah A . Peluso . 2007 . A Data - frame Theory of Sensemaking . Lawrence Erlbaum Associates Publishers , Mahwah , NJ , US , 113 – 155 . [ 19 ] J . Knapp , J . Zeratsky , and B . Kowitz . 2016 . Sprint : How to Solve Big Problems and Test New Ideas in Just Five Days . Simon & Schuster . [ 20 ] Simone Kriglstein and Gunter Wallner . 2005 . HOMIE : An artificial companion for elderly people . In CHI’05 Extended Abstracts on Human Factors in Computing Systems ( Portland , OR , USA ) ( CHI EA’05 ) . Association for Computing Ma - chinery , New York , NY , USA , 2094 – 2098 . [ 21 ] Rhema Linder , Nic Lupfer , Andruid Kerne , Andrew M . Webb , Cameron Hill , Yin Qu , Kade Keith , Matthew Carrasco , and Elizabeth Kellogg . 2015 . Beyond slideware : How a free - form presentation medium stimulates free - form thinking in the classroom . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition . 285 – 294 . ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 . ForSense : Accelerating Online Research Through Sensemaking Integration 30 : 23 [ 22 ] Jiasen Lu , Dhruv Batra , Devi Parikh , and Stefan Lee . 2019 . ViLBERT : Pretraining Task - Agnostic Visiolinguistic Rep - resentations for Vision - and - Language Tasks . arXiv : 1908 . 02265 [ cs . CV ] [ 23 ] Yoelle S . Maarek , Michal Jacovi , Menachem Shtalhaim , Sigalit Ur , Dror Zernik , and Israel Z . Ben - Shaul . 1997 . We - bCutter : A system for dynamic and tailorable site mapping . Computer Networks and ISDN Systems 29 , 8 – 13 ( 1997 ) , 1269 – 1279 . [ 24 ] Catherine C . Marshall and Sara Bly . 2005 . Saving and using encountered information : Implications for electronic periodicals . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Portland , Oregon , USA ) ( CHI’05 ) . Association for Computing Machinery , New York , NY , USA , 111 – 120 . [ 25 ] P . H . Nguyen , K . Xu , A . Bardill , B . Salman , K . Herd , and B . L . W . Wong . 2016 . SenseMap : Supporting browser - based online sensemaking through analytic provenance . In 2016 IEEE Conference on Visual Analytics Science and Technology ( VAST ) . 91 – 100 . [ 26 ] Notion . 2020 . Notion : All in one workplace . https : / / www . notion . so / . Accessed October 2020 . [ 27 ] I . Peters and P . Becker . 2009 . Folksonomies : Indexing and Retrieval in Web 2 . 0 . De Gruyter / Saur . [ 28 ] Pinterest . 2020 . Pinterest : Welcome to visual discovery . https : / / www . pinterest . com / . Accessed October 2020 . [ 29 ] Peter Pirolli and Stuart Card . 2005 . The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis . In Proceedings of International Conference on Intelligence Analysis , Vol . 5 . McLean , VA , USA , 2 – 4 . [ 30 ] Pocket . 2020 . Pocket . https : / / app . getpocket . com / . Accessed October 2020 . [ 31 ] Morgan N . Price , Bill N . Schilit , and Gene Golovchinsky . 1998 . XLibris : The active reading machine . In CHI 98 Con - ference Summary on Human Factors in Computing Systems ( Los Angeles , California , USA ) ( CHI’98 ) . Association for Computing Machinery , New York , NY , USA , 22 – 23 . [ 32 ] Gonzalo Ramos , Christopher Meek , Patrice Simard , Jina Suh , and Soroush Ghorashi . 2020 . Interactive machine teach - ing : A human - centered approach to building machine - learned models . Human - Computer Interaction 35 , 5 – 6 ( 2020 ) , 413 – 451 . [ 33 ] Gonzalo Ramos , Felicia Ng , Nicole Sultanum , Chris Meek , Jina Suh , and Soroush Ghorashi . 2019 . Do machine teachers dream of algorithms ? Workshop on Human - Centric Machine Learning at the 33rd Conference on Neural Information Processing Systems . ( December 2019 ) . [ 34 ] Pew Research . 2020 . 53 % of Americans Say the Internet Has Been Essential During the COVID - 19 Outbreak . https : / / tinyurl . com / y7lvxmkr . Accessed October 2020 . [ 35 ] Pew Research . 2020 . Most Americans rely on their own research to make big decisions , and that often means online searches . https : / / tinyurl . com / yaay6vbr . Accessed September 2020 . [ 36 ] Daniel M . Russell , Mark J . Stefik , Peter Pirolli , and Stuart K . Card . 1993 . The cost structure of sensemaking . In Proceed - ings of the INTERACT’93 and CHI’93 Conference on Human Factors in Computing Systems ( Amsterdam , The Nether - lands ) ( CHI’93 ) . Association for Computing Machinery , New York , NY , USA , 269 – 276 . [ 37 ] M . C . Schraefel and Yuxiang Zhu . 2001 . Interaction design for web - based , within - page collection making and man - agement . In Proceedings of the 12th ACM Conference on Hypertext and Hypermedia . 125 – 125 . [ 38 ] Monica C . Schraefel , Yuxiang Zhu , David Modjeska , Daniel Wigdor , and Shengdong Zhao . 2002 . Hunter gatherer : Interaction support for the creation and management of within - web - page collections . In Proceedings of the 11th Inter - national Conference on World Wide Web . 172 – 181 . [ 39 ] Chen Sun , Austin Myers , Carl Vondrick , Kevin Murphy , and Cordelia Schmid . 2019 . VideoBERT : A Joint Model for Video and Language Representation Learning . arXiv : 1904 . 01766 [ cs . CV ] [ 40 ] Emily Wall , Soroush Ghorashi , and Gonzalo Ramos . 2019 . Using expert patterns in assisted interactive machine learn - ing : A study in machine teaching . In Human - Computer Interaction - INTERACT 2019 - 17th IFIP TC 13 International Conference , Paphos , Cyprus , September 2 – 6 , 2019 , Proceedings , Part III . 578 – 599 . [ 41 ] Christopher D . Wickens , Justin G . Hollands , Simon Banbury , and Raja Parasuraman . 2015 . Engineering Psychology and Human Performance . Psychology Press . [ 42 ] Han Xiao . 2018 . bert - as - service . https : / / github . com / hanxiao / bert - as - service . [ 43 ] XiaolongZhang , YanQu , C . LeeGiles , andPiyouSong . 2008 . CiteSense : Supportingsensemakingofresearchliterature . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Florence , Italy ) ( CHI’08 ) . Association for Computing Machinery , New York , NY , USA , 677 – 680 . [ 44 ] Luowei Zhou , Hamid Palangi , Lei Zhang , Houdong Hu , Jason J . Corso , and Jianfeng Gao . 2019 . Unified Vision - Language Pre - Training for Image Captioning and VQA . arXiv : 1909 . 11059 [ cs . CV ] Received 30 July 2021 ; revised 14 March 2022 ; accepted 11 April 2022 ACM Transactions on Interactive Intelligent Systems , Vol . 12 , No . 4 , Article 30 . Publication date : November 2022 .