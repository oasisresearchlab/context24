The Limits of Design in Ensuring Responsible Outcomes from Technology Aaditeshwar Seth IIT Delhi and Gram Vaani aseth @ gramvaani . org ABSTRACT Ensuring responsible outcomes from technology is a challenging goal , and several design methods have been proposed to embed ethical values into the technology itself . Based on a case - study of a voice - based community media platform running in rural India , we argue that design alone is not sufficient to prevent harmful effects and that careful management of the technology during its deployment is also essential . We identify several processes that can be useful to specifically manage digital platforms for information sharing among users . While this may not be a significant insight , we draw attention for researchers to understand the deployment management of technology , beyond its design , as an important area of research in technology and ethics . CCS CONCEPTS • Human - centered computing • Applied computing • Information systems KEYWORDS Design , deployment , management , ethics , community media , IVR ( Interactive Voice Response ) systems , ICTD , social impact ACM Reference format : Aaditeshwar Seth . 2020 . The Limits of Design in Ensuring Responsible Outcomes from Technology . In Proceedings of Information and Communication Technologies and Development conference ( ICTD’20 ) . ACM , New York , NY , USA , 2 pages . https : / / doi . org / 10 . 1145 / 3392561 . 3394631 1 Introduction There is growing concern that even though rapid progress in the development of many technologies has produced positive outcomes , there have also been significant harmful effects as well . The reasons vary : Technology providers may be unable to control what their technology gets used for and by whom [ 13 , 14 ] , they may not understand the limitations of their own technology in advance [ 15 , 16 ] , the regulatory response of the state might be too slow in drawing attention to ignored critical aspects [ 17 , 18 ] , etc . Even in the field of ICT4D ( Information and Communication Technologies for Development ) , technologies designed specifically to address certain social development objectives , may fail to do so for similar reasons [ 19 , 20 ] . The dominant approaches which have emerged to ensure responsible outcomes from ICTs are to embed ethics into the design of the technology artefact itself [ 9 , 10 , 11 , 12 ] , and to use participatory methods to design the technology so that power dynamics and other aspects about the users’ context can be taken into account [ 7 , 31 , 32 ] . Both these approaches assume that innovations designed with ( for example ) principles like privacy or fairness encoded in them upfront , will operate in responsible ways . We argue in this paper using the example of an ICT4D case - study from rural India , that ensuring responsible outcomes by design alone is not sufficient . We argue that much of the harmful effects with technology arise at its socio - technological interface when it is deployed and used by people , post design . Careful design can enable or constrain certain affordances in how the designed objects are used , and the design can also be altered iteratively to modify these affordances [ 2 , 3 ] . However this notion of design that a blueprint comes first and it then shapes the usage of the designed objects accordingly , as most design methods are framed [ 4 , 5 , 6 , 7 , 8 ] , is inadequate . We argue that the management of the designed objects is also important to shape their usage , especially to ensure that responsible outcome arise through their use . A lack of attention placed on management of the socio - technological interface can be misleading – approaches of ethics by design may solve some problems but not all , and relying on just them could in fact give a false sense of safety . This deployment management of the socio - technological interface can include many aspects , which we illustrate through our case - study in the subsequent sections . Who is included or excluded from access to the technologies [ 19 , 20 ] , policies to shape appropriate usage norms of the technologies [ 21 , 22 ] , priority placed on social impact as compared to other issues like financial sustainability [ 23 , 24 ] , etc , all need careful management of the technologies beyond anything which the design can ensure by itself . These aspects of the socio - technological interface which need careful attention may arise in ways entirely unforeseen at the design stage , which may sometimes be due to a lack of adequately diverse prototyping or sometimes simply due to surprises that are bound to arise when technologies are deployed in a world that is immensely complex . This attention to management becomes even Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . ICTD’20 , June , 2020 , Guayaquil , Equador © 2020 Copyright held by the owner / author ( s ) . 978 - 1 - 4503 - 8762 - 0 / 20 / 06 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3392561 . 3394631 ICTD’20 , June , 2018 , Guayaquil , Equador A . Seth more relevant in the current context when many digital platforms have deeply permeated our lives : These platforms are being used by millions and billions by people , and are embedded in a complex global web of finance and politics , that it is daunting to even conceive an eventuality in which they will be re - designed or replaced . In such a situation , it becomes imperative to examine the management processes of these platforms to understand how problems arising at their socio - technological interface are being managed . Are these processes participatory , what ethical values underpin these processes , are they overly bureaucratic or are they context - sensitive [ 83 ] , etc , all become relevant questions to ask . We propose in this paper that just like several design frameworks suggest ethics as the foundation to design , similarly ethics can serve as guardrails to building management processes for the management of the socio - technological interface as well . Our contributions are three fold : We justify our argument for the need to manage the socio - technological interface of technology during its deployment , we outline several aspects of this interface that need careful management , and we propose a conceptual framework for technology designers and managers to bring consistency in their design and deployment management efforts by using a common ethical system as a foundation . Our work is especially relevant since it is based on a case - study of a participatory media information sharing platform similar to Internet - based social media platforms , albeit at a smaller scale , but having to manage similar issues as the Internet - based platforms . We next describe related work in the area of technology design models and methods , followed by a presentation of our case - study , and then conclude with a discussion about how consistent principles should be applied in both the design as well as the deployment management of technologies to ensure responsible outcomes . 2 Related work 2 . 1 Shortcomings of ethics by design approaches The need to ground technology design in ethics has been recognized since a long time . Duquenoy , et al [ 25 ] pointed out the power imbalance that exists between designers and users , and that designers should recognize their responsibility to ensure that their innovations create a just world and do good . This becomes challenging because designers may have biases and may not always know the circumstances of their users or how the technology might affect them . Hence Duquenoy , et al suggested that designers should operate using the Rawlsian principle of the veil of ignorance by placing themselves as unspecified users [ 26 ] , and then check that the technology will not erode their own rights of liberty and equality . Sen’s criticism of the Rawlsian framework is based on the recognition that equality will be hard to achieve as an eventual goal with just using the veil of ignorance , since disadvantaged individuals may need access to additional resources to help them catch up with others , pointing to the need for mechanisms like affirmative action to bring equality [ 27 , 28 ] . Applying this logic to Duquenoy’s suggestion supports our argument that design alone may not be sufficient to avoid outcomes like inequality : Users less capable to use the technology , for example , may lose out because benefits from the technology will accrue to those who are able to use it effectively . Therefore deployment management beyond the technology design , such as capacity building of less tech - savvy users , will be needed to avoid an increase in inequality because of the technology [ 29 ] , even if the designers were unbiased to start with . Things are even harder in actual practice . Far from following Rawlsian or other ethical frameworks , the politics of designers shape what values they will espouse at the outset . Winner showed through many examples that technology design facilitates codification of the politics of designers , and which could potentially manifest into largescale changes in society itself if the technology is wielded by powerful agencies like authoritarian governments or corporations and the media [ 30 ] . Processes to notice such problems , through regular feedback or other mechanisms , then become essential to take corrective action . This highlights the need for robust feedback processes to manage deployments , beyond the design , to ensure responsible outcomes . To overcome the challenges of designer bias as described by Duquenoy [ 25 ] and Winner [ 30 ] , Participatory Design ( PD ) approaches were developed [ 7 , 31 , 32 ] . PD methods go beyond methods like co - design [ 5 ] and human centered design [ 5 ] where typically external designers engage with prospective users to understand them , and build , prototype , and fine - tune tools for them . PD however , is grounded in democratic values aimed at enabling all users to influence the design by arriving at a consensus through joint consultations . It especially focuses on power differentials between different classes of users like when designing tools that are to be used at a factory workplace where employers and workers may have conflicting concerns . It also embraces ongoing capacity building of the users to enable them to participate in the design process effectively [ 84 , 85 ] , and focuses beyond just an objective to create greater usage of the technology tools , rather to design such that the tools lead to fulfilment of democratic objectives like equality and justice [ 31 ] . However the PD model still primarily sees its objective as getting the design right , as opposed to constant attention being required for deployment management as well . Several long - term PD projects do discuss challenges with sustainability [ 86 ] but have not analyzed the relevance of processes to manage various aspects of the socio - technological interface , especially in the context of digital platforms for information sharing . A greater challenge with the full - fledged PD process is the practicality of applying it in today’s context of developing and scaling large digital platforms . PD requires time - consuming consultations , prototyping , capacity building of the participants , etc , whereas platform designers are typically driven by a build - and - break approach with a singular goal to gain quick user traction through which they can claim access to more funding to scale their platforms [ 24 ] . Any fundamental problems in the design that might surface later , become concretized and hard to change as the platform grows larger , pointing to the classic Collingridge dilemma of why it becomes hard to control The limits of design in ensuring responsible outcomes from technology ICTD’20 , June , 2018 , Guayaquil , Equador technologies as they scale [ 33 ] . Further , the commercialization strategy of platforms may bias them to aligning with one set of users than another , as noticed with Uber which favours commuters more than drivers [ 34 ] , or bluecollar work platforms which seem more interested to serve employer interests than worker interests [ 35 ] . The information systems literature has also since several decades looked at PD - like methods , especially within organizational settings , but the focus again has mostly been on design [ 32 , 87 ] . The limitations of design in influencing the outcomes of technology has also been highlighted by Dahlbom and Mathiassen who state that system designers need to immerse themselves as activists into technology operations to truly have a chance at influencing the outcomes [ 88 ] . Our views resonate with their argument . The VSD ( Value Sensitive Design ) approach has a similar starting point as PD in terms of following a participatory process to arrive at a core set of values through consultations with users or other means . These values are then baked into the technology design itself so that they are never violated when the technologies are deployed [ 9 ] . Based on several VSD examples discussed in the literature however [ 36 ] , this typically seems to have led to the incorporation of context - free design features like data privacy or fairness definitions or informed consent to be encoded in the technology . When technologies are deployed in diverse contexts however and demand dynamic adaptation to new situations , then alertness in management processes becomes essential to change the design , or to manage the affordances allowed by the design . Such discussions are absent in the VSD literature , and we discuss in the case - study many examples that needed careful management irrespective of whatever initial design methods were followed . Note that we are not proposing a design method as an alternative to PD or VSD or even other methods , our intention is to simply point out that most design methods have not looked closely at deployment management , which is just as important as design to ensure responsible outcomes from technology . In fact , relevant design methods such as the above would indeed be a first step to technology design , with deployment management as the subsequent step , following by ongoing interactions between the two . We clarify this further in Section 5 where we present a common framework within which design and deployment can be separately situated , but guided by a common ethical system . Wiener [ 37 ] was among the first ones to draw attention to the need for designers to remain involved in the deployment of their technology , famously highlighted in his open letter titled A Scientist Rebels where he refused to share details of his technology design with irresponsible militarists . He goes to further illustrate how totalitarian governments or profit - seeking capitalists can ignore fundamental human values in their adoption and use of technology , and asks scientists to not be naïve and take responsibility for how their inventions and innovations could be used by others for unethical private or political gain . Similar views are expressed by Jonas [ 38 ] in discussing the uncertainty with many new technological innovations in their influence on future generations of humans , and hence he too emphasizes that usage principles should evolve continuously through oversight and monitoring during deployment . Our own views about the need for deployment management are shaped by this same logic that design alone will not galvanize technology for responsible outcomes , it needs ongoing management as well . 2 . 2 Action research for deployment management Given that deployment management is just as important as careful design , this brings us to the question of how deployment management can be done to ensure responsible outcomes . The action research method comes closest . Action research has more ambitious goals than participatory design and aims to continually shape an intervention based on deployment feedback , with all decision making done through participation of the community in the process [ 39 , 40 ] . This naturally requires long - term engagement with the community , with slow and careful evolution through experimentation and consultation . Truly long - term action research based interventions are rare even in the ICT4D space [ 41 , 42 , 54 , 89 , 90 , 91 ] , and the slow iterative process is further perceived as unwieldy and impractical in non - ICT4D settings where technologies and platforms in today’s context go through rapid adoption and churn cycles , driven by commercial interests that prioritize scaling than anything else . This brings back the emphasis to greater responsibility lying with the managers of technologies to ensure responsible outcomes when technologies are deployed , because moving slowly is not seen as a viable option today . In the forthcoming sections , we use our case - study to outline several useful processes that can facilitate careful management of the socio - technological interface during deployment . We do not suggest that such processes can be a substitute for action research methods , but that this may be a more realistic strategy today that can possibly even be verified for compliances and assurances . 2 . 3 Ethics and artificial intelligence Concerns arising with the application of AI in many domains , have of late brought significant attention to the development of new data management and algorithmic techniques . Biased and discriminatory decision making arising from unchecked biases in the data used to train machine learning algorithms [ 16 , 17 ] , has led to the adoption of several methods to audit the data as well as organizational processes to ensure that such auditing is compulsorily done [ 44 ] . Research communities have realized that the objectives codified in algorithms can also lead to biases , such as the choice of fairness definitions to be used in different applications [ 15 , 10 ] , or ranking algorithms that can amplify biases [ 45 ] , and regulators have also begun to pay attention to algorithmic auditing [ 46 ] and the need for explanatory capability in algorithms [ 47 ] . Participatory processes to collect inputs from users to accordingly choose and parameterize AI algorithms , have also seen progress [ 48 ] . All these developments however are still rooted in an ethics by design model . To preserve continued ethical functioning of technologies will require due attention paid to deployment management as well . For example , deployment management processes are needed to ensure that any biases in ICTD’20 , June , 2018 , Guayaquil , Equador A . Seth data completeness are addressed on priority and that models are re - trained to continue to perform in line with the committed assurance guarantees on fairness metrics [ 44 ] . Similarly , accepting accountability for the outcome of the algorithms , transparency and explainability of the results , and providing appeal procedures against unfair decisions made by the algorithms [ 49 ] , are necessary to deal with mistakes and take corrective action . All these require careful management . Ensuring ethics by design in artificial intelligence technologies , as adopted in declarations such as ICDPCC [ 50 ] , are therefore unlikely to be sufficient by themselves . 3 Case study : Mobile Vaani We next describe the case - study of a voice - based community media platform called Mobile Vaani ( MV ) , which has been operating since more than seven years in rural central India [ 23 ] . We highlight several values that shaped the design of the platform technology , and we then show how these values also guided management of the socio - technological interface of the platform . We discuss several aspects of the socio - technological interface that threw up surprises as MV was deployed and scaled , and the processes developed to manage these aspects . We do not consider MV as a pure participatory design or action research project because most decisions were actually not taken in consultation with the users , but were guided through a more user - centered approach of understanding the context and reiterating the design or deployment management policies accordingly . The MV case - study therefore shares more in common with digital platforms like Facebook and Twitter , where as discussed in previous sections the designers and managers of these platforms have greater onus to ensure responsible outcomes from their technologies , since participatory or action research oriented methods are not practically viable for them to follow . Similar to these platforms , MV has been used in diverse contexts by different classes of users who could sometimes even be in conflict with one another , and has been subject to financial and scaling pressures that tend to put social impact objectives on the backburner . We therefore believe that much of the processes developed to manage the MV socio - technological interface may be generic enough to be applied to other digital platforms as well . 3 . 1 Background about Mobile Vaani The concept of community media is centered in the idea that the needs of local or interest based communities is best understood by the community itself , and editorially driven mass media run by external institutions is not able to address these needs largely because of their lack of local context . Community media thus espouses the value of user autonomy for communities to define their own agenda with the media platform , and create and distribute their own content . Several such models for community embedded media initiatives exist in India itself , such as Khabar Lahariya which supports rural women to write newspapers [ 51 ] , Video Volunteers which trains rural community correspondents to produce videos about human rights [ 52 ] , and several community radio stations that create radio programmes of local relevance [ 53 ] . In this rich mix of initiatives , Mobile Vaani started as a phone based community media service in rural central India in 2012 . Driven by a value to be inclusive towards less - literate and low - income populations , MV uses Interactive Voice Response ( IVR ) systems to enable voice driven communication and allows access even via simple phones not requiring the Internet . Several initiatives have reported their success with using IVR systems in such environments [ 54 , 55 , 56 , 57 ] . MV runs in the following manner : People give a missed - call to a unique phone number . The IVR system then initiates a call back to the callers , effectively making it a free service for them , and the people use phone keypad buttons to browse a list of audio messages or record their own message . Any messages recorded by them go through a manual moderation process before being published on the IVR for others to hear , essentially to filter out poor quality audio recordings or undesirable content . The goal with this initiative was to bring about social development through the use of technology , along the following four lines . First , taking a human rights based approach which values dignity and equality of power , the MV team were convinced about the transparency and accountability function that such a platform could play in local governance , by making it simple for people to share information about civic or governance issues that they were facing , and to demand transparency in decision making . Second , prior research in social media analysis showed that discussions on participatory media platforms are specifically useful because the homophily effect [ 59 ] leads to people receiving information from their strong ties [ 60 ] which is highly contextual and understandable by them , and participation by diverse users from across weak ties leads to information that enhances completeness [ 58 ] . Messages evolve as they traverse a social network , gaining both context and completeness through comments made on the messages by people occupying different positions in the social network graph [ 61 ] . It was therefore believed that since MV could facilitate people to share their views and experiences on various topics , it could lead to a more complete and actionable understanding gained by people for relevant topics , and thereby also support the values of plurality and diversity . Third , people gain significant self - empowerment when they can be heard by many others , ie . they gain a voice , and are able to challenge exploitative power structures [ 53 ] , thus strengthen the values of dignity and equality . Fourth , strong community building impact emerges when community media runs traditional songs and music , and covers local events , making the community closer knitted [ 55 ] . While mobilizing these impact pathways , the MV team also wanted to have a business and operations model that could be replicated readily for scaling either by us or through partners to bring wider and large - scale impact . MV was therefore initiated with a clear design of what values were to be embedded in the technology design , and the change it was supposed to bring through the impact pathways listed above . The actual journey turned out to be more complex , as is explained next by highlighting many different challenges that arose at the socio - technological interface in realizing this vision . By building The limits of design in ensuring responsible outcomes from technology ICTD’20 , June , 2018 , Guayaquil , Equador processes to manage this interface , guided by the same values incorporate towards the technology design , the MV team was able to reasonably achieve their vision . 3 . 2 Mobile Vaani’s socio - technological interface We define the socio - technological interface as the boundary with technology engineering and user interface and system design on one side , and factors that shape how people use the technology on the other side . We do not mean to suggest that people who engineer the technology or design the user interfaces do not consider the social context in which the technology is intended to be used . In fact , several of their choices may be shaped by the social context very much like how the MV choice of using IVR was shaped by the low literacy and high mobile phone usage in our communities of interest . The socio - technological interface however that we talk about is in the dimension of how the technology is used by people post - design , and not how it is engineered or designed . The different aspects about the socio - technological interface which we discuss next are by no means exhaustive , but nevertheless this list is intended to serve as a starting point to which more aspects can be added . The rest of this section is written in a chronological manner to capture the complexities as they arose and were handled . Aspect # 1 : Technology literacy and access . The MV team soon found that IVR itself was an alien concept for many people [ 23 ] . Men had access to phones and were functionally literate to use it to dial numbers and pick up calls , but most had not used automated IVR systems in the past . The usage of the system had to be demonstrated to them , and in the absence of any other media in these areas , offline training sessions were the most effective [ 54 ] . Further , they had to be explained the concept of community media and what they could do with access to such a platform , but that too was not straightforward to convey – it required practical examples and self - validation for people to understand the use of the technology [ 23 ] . Finally , access of phones by women , and access to women to tell them about MV , were both significant challenges . Due to patriarchal norms , women are typically less literate , do not own their own phones , rely on shared access , and consequently their capability to use phones is lower than that of men [ 19 , 62 ] . Physical mobility of women is also lower and hence it is harder to reach women to participate on MV . It was clear that the wide usage of mobile phones was not going to easily translate into MV adoption , and low - cost and scalable processes needed to be developed to overcome these barriers of technology and platform literacy , and technology access . Related work has explored several interesting dynamics through which new technologies are learned . Poorly literate construction workers were able to learn a complex sequence of steps to share videos over Bluetooth , suggesting that self - motivation to use technology ( in this case , for entertainment ) could lead to self - learning [ 63 ] . In a study of Facebook use among urban youth [ 64 ] , a mix of financial and social incentives led to users teaching their peers about the platform . In the context of women , despite strong patriarchal norms , women learned to navigate family and community spaces to use mobile phones [ 65 ] . Similar dynamics were seen with MV as well . Users would tell their friends about it especially if their message got published on MV . Some would listen to MV in groups which led to wider listening and learning . Hearing stories of validation of MV’s impact especially in the area of grievance redressal which we explain later , also led to MV achieving strong social credibility and popularity through word of mouth [ 66 , 67 ] . These were however not systematic and reproducible processes that could be considered as part of a replicable MV model . The MV team therefore took a different approach , as explained in the next section , to develop an innovative low - cost offline process through community volunteers which could manage this need to create technology and platform literacy , and at the same time also address the next aspect of the socio - technological interface to ensure community embeddedness of MV . Aspect # 2 : Community embeddedness . As a community media platform , MV espoused a vision that its agenda should be driven by the community itself , including content creation , choice of discussion topics , etc . Related work has discussed the concept of communitization of technology [ 68 ] , ie . when a community learns the essence of what a technology can do and is able to leverage it for the community’s needs . The study highlights the role that a few key tech - savvy community members can play in the process . These people are termed as Human Access Points ( HAPs ) , and are essentially technologically advanced users who understand both the needs of their community and the capabilities of the technology , and are able to conceptualize relevant use - cases for the technology . This notion of HAPs most closely explains the methodology chosen by us to communitize MV . Through different partner organizations , as the MV team was introduced into new communities , they kept coming across HAPs who quickly understood the technology and were among its early adopters . To gain faster popularity for MV in the community , people were inducted from among these HAPs as community volunteers , and a financial incentive model was built to cover for out - of - pocket expenses incurred by them to popularize MV and guide its usage . They would travel to different villages and tell people about MV , demonstrate its usage , and encourage its adoption . The volunteers were also encouraged to discover use - cases for the platform on their own though , based on their understanding of the community [ 67 ] . As a result , over time when MV expanded to different locations running their own local MV chapters , the volunteers created their own topic priorities for respective local MV chapters . The volunteers in one location where MV was heavily popular with farmers , built linkages with the local agricultural institutes to answer questions put up by farmers . Another location built linkages with school and college coaching classes to advice their predominantly youth userbase with career counselling tips . All the locations also took up a hyperlocal news reporting function that we discovered to be a universal need , due to the scarce penetration of other media in these geographies . Such processes helped MV ICTD’20 , June , 2018 , Guayaquil , Equador A . Seth adhere to values of user autonomy to run community media platforms that were governed by the people . The platform was also supplemented with content created by the MV team on cultural and entertainment themes , discussions on social norms such as early marriage and domestic violence , rules and eligibility for government schemes , etc . The choice of this content was guided by feedback processes developed to interview users over the phone , conduct focused group discussions in the community , and also run IVR - based surveys to get user feedback [ 23 ] , which further helped respond to user needs . The journey with identifying and training volunteers , and retaining them , was however by no means smooth . We next discuss the aspect of internal accountability expected of the volunteers to build MV into a sustainable institution in itself . Aspect # 3 : Internal accountability & sustained participation . Initially MV started as a state - wide service in Jharkhand and was popularized in different areas by the volunteers . Subsequently , services were also started in the states of Bihar and Madhya Pradesh . The MV field team however consisted of only a few people who found it difficult to coordinate with dozens of volunteers from across different locations . Further , volunteer attrition became high because many people would join MV as volunteers with the expectation of financial returns , but the small stipend that was offered was not attractive in itself [ 67 ] . The MV team realized that they had to improve their selection process to identify volunteers who were genuinely interested in bringing a positive change in their communities and for whom these social incentives would be stronger than the monetary incentives . The concept of federated groups in the context of trade unions is believed to be more resilient than a single large group [ 69 ] , and this method was adopted . The state MVs were split into district level local chapters , each of which had its own unique phone number and could build its own identity . Further , the volunteers from each district were grouped into a volunteer club for that district . The club elects a coordinator and meets on a monthly basis to discuss their activities and plans . Through this hierarchical arrangement , the MV field team now only had to engage with the club coordinators . Further it was found that this structure also built strong solidarity and mutual accountability among the volunteers , which reduced attrition to practically zero . A careful financial incentive model was developed as a combination of a group incentive which was divided equally among all the volunteers in the club ( calculated pro - rata on the number of active users in each club ) and individual incentives for each volunteer ( based on the number of good quality contributions by the volunteer , and offline community mobilization activities organized by them ) [ 67 ] . This model further made explicit the ethos that a volunteer club should act as a collective to which all the volunteers were expected to make individual contributions to achieve the club’s collective aim . It also helped the MV team realize the importance of collectivism as a value , which since then has influenced several other decisions as well . The club model further helped construct the kernel for MV operations that could be readily replicated for scaling , and has already been tested with replication at thirty local chapters . Aspect # 4 : Biases in inclusion and exclusion . The unique position of power occupied by the MV volunteers began to raise some unanticipated issues as well . The volunteers would sometimes popularize to the users an altered mandate of MV which made more sense to them based on their individual socio - economic - political views and priorities which could be different from that of their clubs . They would similarly sometimes prioritize enabling access for a select group of users by training them well while excluding others . For example , during the initial days of MV , several volunteers were associated with human rights activist organizations and hence they were more interested in governance topics , to the extent that they began to discourage people from using MV for cultural expression through folk songs and poetry [ 67 ] . Similarly , they would sometimes discourage users from recording content themselves and would record on their behalf , especially when these users were from less educated backgrounds and found it difficult to articulate themselves through a digital platform . Inherent social norms also caused disruptions – once a class - based conflict arose in a club when a lower - class volunteer was elected as a club coordinator , thereby challenging socially established norms of power . Such incidents have now become rare due to the more rigorous selection and training methods for volunteers , and also paying a special attention to recruiting volunteers from diverse class and caste backgrounds . Underlying values of plurality helped guide the MV team to take these steps . What was also useful to make the necessary course corrections was an openness to hear complaints which the users recorded on MV or shared with the team during field visits . This roughly designed internal grievance redressal process helped empower the users , and helped the MV team to uncover such cases of undesirable appropriation of technology , again highlighting the relevance of values of user dignity and rights to continuously listen to user feedback . A challenge which does remain unsolved is in overcoming the technology gender divide [ 19 ] . Most of the MV volunteers are men and find it hard to reach women to tell them about MV . Having a female volunteer in a club of all male volunteers is also difficult in the dominant patriarchal cultural setup of rural north India . An all - women MV club was also started and despite all the volunteers being extremely dynamic , the active userbase of the club remained small due to the limited mobility of women volunteers to reach other women [ 67 ] . It is worth mentioning that in a recent project the MV team worked with a large women Self Help Group ( SHG ) network and were able to reach many women through SHG meetings [ 62 ] . The regularity of the SHG meetings which take place for financial bookkeeping , and the exclusive women constituency to which access was gained , provided an opportunity for both targeted outreach to women as well as repeated interactions with them to encourage technology adoption . Gaps still remain though . For instance , meetings with SHGs of very poor women were held irregularly since these women were busy with work or often migrated to other locations for work , and The limits of design in ensuring responsible outcomes from technology ICTD’20 , June , 2018 , Guayaquil , Equador hence those who could potentially benefit the most from access to the platform were excluded even via this pathway . These examples highlight the importance of managing the socio - technological interface to prevent biases in inclusion and exclusion that can arise due to the social context , or even due to appropriation of the technology by more powerful and adept users . Not tackling this challenge stands the risk of increasing the inequalities that might exist in the social context , because the more powerful or adept users of technology will be able to leverage it for their agenda and move further ahead , leaving the others to play a perpetual catch - up game [ 29 ] . Aspect # 5 : Nurturing responsible usage norms . Like any other social media platform , MV is also susceptible to misuse through fake news or hate speech content submitted to the platform [ 13 , 70 ] . User generated content on MV is therefore manually moderated to accept or reject submitted content from publication for others to hear [ 23 ] . Moderators can also download and edit the content to improve its audio quality , add transcripts and tags to the content , and control its ranking on the IVR . Content moderation serves an important role of signaling to users about what is permitted or not , and thereby shapes the usage norms , as also seen in studies on Reddit [ 21 , 71 ] and Slashdot [ 22 ] . An average of only 0 . 5 % of rejected contributions on MV are due to objectionable content , showing that users hardly even attempt to misuse it . The bulk of rejections happen due to unpreparedness in recording well - articulated content , for which offline training or manual phone calls are made to guide the users . Whenever misuse has occurred , it has been dealt with severely . Abusive or threatening recordings once made by a user were reported to the police . Cases of hate speech were escalated to the volunteers who directly then spoke to the people . In general though , hate speech or angry voices against other users have been extremely rare , and even discussions on contentious topics have taken place in a measured tone of respect and decency to respect values of plurality , dignity , and mutual respect . A liberal moderation policy allows as many voices as possible , and filters based chiefly on concerns about audio quality and the tone of the message . This leads us to believe that in contrast to many Internet - based social media platforms like Facebook and Twitter which allow unmoderated postings and then resort to algorithmic policing or community reporting methods , misuse is prevented on MV by establishing a precedent of respectful use from the very beginning . The volunteers and users are passionate about preserving this ethos and vociferously protest if objectionable content sometimes slips by the moderators . Editorial policies to ensure diversity in content are also actively pursued . The moderators rank content based on its quality and novelty , by prioritizing content which is more detailed and informative , or brings a new viewpoint [ 23 ] . Careful list construction is also done so that the collection of content in a list of items about a given discussion topic is diverse and touches upon different aspects , rather than have multiple items in the list about the same aspect . An algorithm is also being implemented which can generate such lists automatically to guarantee properties like short - term diversity and long - term fairness on a given topic [ 72 ] . Crowd - sourced indicators may also help , as suggested in several experiments on community radio [ 55 ] and other voice - based forums [ 73 ] . Aspect # 6 : Building social and institutional credibility : It is reasonable to expect that sustained participation and utilization of a technology will only happen once the expectation of the users is met . We next discuss the relevance of managing user expectations so that the technology can gain respect of the users , as another important aspect of the socio - technological interface . To understand the community needs and frame expectations , we first give an overview of the context in which MV is deployed . Regional newspaper and television media has not deeply reached MV communities , and also has a chequered reputation of having ignored problems of lower caste people , or having suppressed news against the local elite possibly even in return for extortion payment [ 74 ] . The poor and marginalized groups have historically lacked a strong voice in the community , and even their political representation has had its own ups and downs [ 75 ] . They are also intimidated by complicated government office processes for grievance redressal , and may not be able to take time off their daily livelihood routine to pursue even legitimate cases of violation of their rights and entitlements [ 76 ] . In such a context , MV was presented to the community as helping meet several use - cases . Media related use - cases included : “ It is a platform for you to talk about whatever you feel is relevant for you and your community that is not covered in the mainstream media ” , “ You can get breaking news about your community way before any newspaper or TV channel ” , and “ MV is a platform where you will get useful information on agriculture , career counselling , health , government schemes , among other topics ” . Governance related use - cases included : “ You can discuss local and national policy , and we will convey your feedback to the right stakeholders ” , and “ MV volunteers will help resolve problems that your community is facing , especially on welfare entitlements and public services ” . While these use - cases were relevant , positioning MV as making these strong promises to enable people to overcome the social inequalities within which they have lived all their lives , stands the risk that if their expectations are not met then they will dismiss MV cynically as yet another false promise . MV was however able to gain significant social credibility by successfully demonstrating its impact , which helped people validate its stated promises and intentions , and also demonstrated the value of honesty . The editorial processes of moderation were kept liberal to only filter out poor quality audio messages , or those that were spoken in a rude tone , or blatantly incorrect facts . Towards the initial stages of MV , the moderators even made phone calls to users who seemed to be wanting to say something important but were not able to articulate it well , and guided them to make better audio recordings . This helped validate a strong commitment of MV towards empowering users to voice themselves . Similarly , grievances recorded by the people , or questions asked by them , were rigorously followed - up by the volunteers with reminders and ICTD’20 , June , 2018 , Guayaquil , Equador A . Seth support provided by the moderators , to convey to users about action having been initiated upon their requests . This helped build trust of the users in MV . All the MV volunteers were also trained on news reporting to cover in unbiased ways any news events that they came across , and strengthened people’s perceptions about MV as being an unbiased news source about local events . MV was similarly able to successfully facilitate improvements in local governance . A detailed discussion of social accountability loops created by MV is provided by Chakraborty , et al [ 76 , 77 ] , based on 300 + impact stories shared by the users on MV . The experience emphasizes that the target beneficiaries of welfare schemes are much in need of offline support via social workers to demand their rights and entitlements because self - service mechanisms like centralized helplines and web portals can be disempowering as they are hard for the people to use . Furthermore many categories of grievances arise due to issues at the local level and cannot be resolved through centralized mechanisms . MV’s network of volunteers not only provided such offline support to overcome the disempowerment of people in engaging with government authorities , but was also able to use MV to draw the attention of government officials towards specific grievances and brought about higher rates of grievance redressal . A recent IVR - based survey of several hundred MV users [ 66 ] showed that 67 % of the users agreed that MV is different from other mass media in giving an opportunity for anybody to voice themselves , 69 % acknowledged the value of dialogue created on the platform to understand different viewpoints , 88 % reported an increase in connecting back to their cultural roots , 85 % reported an increase in political awareness , 50 % acknowledged having learned new ways to articulate their views , 64 % reported having gained agency in addressing problems with local governance directly themselves , and 84 % acknowledged strong offline support received from MV volunteers in helping solve their problems . These functions of grievance follow - up and news reporting , in addition to exposing users on technology literacy about MV , demonstrate the relevance of deployment management processes beyond the design stage , and also show how these processes emerged from common ethical values which had shaped the design . Institutional credibility was also important for MV to get constructive reactions from the state for grievance redressal or on policy implementation feedback collected from the users . As the MV volunteers built stronger networks with local government officials , and demonstrated sustained usage over many years , the state too responded positively and began to view MV as an innovative means for citizen engagement which they could utilize themselves , while respecting the independence of MV . Local government officials now routinely use MV to make announcements of new schemes and subsidies , give interviews about their views on policy implementation , offer a commitment for resolution of grave issues , and respond actively to requests by MV users and volunteers . Institutional credibility thus reinforced social credibility , and helped embed MV not just with the community but with other local institutions as well . This was clearly a direct outcome of MV going beyond just functioning as a technology platform , to also nurturing its relationships with other stakeholders and to uphold its underlying values . Aspect # 7 : Influence of the business model on agenda . So far we explained how several aspects had to be managed that went beyond the technology of MV into its interface with the community and local institutions , and built into a replicable operations model . The final aspect we discuss is complexities that arise from the MV business model . The MV business model has three revenue streams [ 24 ] . First , philanthropic donations and government advertising to fund awareness and behaviour change campaigns on topics such as health , nutrition , education , and livelihood . Second , community funding where the users may themselves contribute small amounts for a community media platform , plus crowd - funding to raise micro - grants for specific activities and sponsorships from economically well - off people . Third , commercial advertising by companies interested in reaching rural markets . While there is strong validation of the first revenue stream , the second is untested as of now , and the third is yet to be tested at scale . We believe that all three revenue streams will kick - in sooner or later , since MV presents a good product - market fit in the absence of other media outreach channels for Indian rural markets . What we do not know however is what challenges will come up in sustaining the unbiased and community driven coverage provided on MV currently . As the revenue streams from government or corporate advertising get larger and MV’s dependence on them increases to ensure its financial sustainability , MV is likely to become susceptible to have its agenda get influenced by government and corporate interests . The MV team does not have any experience so far in building processes to manage this likely forthcoming challenge , since MV has until now been sustained either through philanthropic grants or internal funding by Gram Vaani , but it is likely to emerge in the future as an important aspect of MV’s socio - technological interface and we believe it will need similar grounding in values to guide the creation of these processes . 4 Managing the socio - technological interface We showed in the previous section several complex aspects that arose during the long - term deployment of Mobile Vaani , which had to be managed to ensure responsible outcomes , beyond the initial design of the technology itself . Similar aspects are known to arise on other digital platforms like Facebook and Twitter when certain groups of users may appropriate the platforms to their advantage , platforms may fail to sustain their values over time , strong usage norms may fail to emerge , the credibility of the platforms may get compromised , etc . We showed that it is possible to build processes to manage the socio - technological interface and ensure responsible outcomes , by taking guidance from underlying ethical values . Not being able to manage this interface during deployment stands the chance of technologies that were meant to empower people , to actually disempower them . We next attempt to generalize these processes . The limits of design in ensuring responsible outcomes from technology ICTD’20 , June , 2018 , Guayaquil , Equador 4 . 1 Management processes Federated platforms : These make management of the digital platforms easier , and allow for both contextualization as well as diversity in use of the technologies . Smaller communities can evolve use - cases according to their needs and lead to greater community embeddedness of the technology . Further , this community embeddedness can be facilitated through a subset of users who can mediate as volunteers or representatives , with whom technology providers can engage in more detail . This can help make centrally managed platforms more participate [ 83 ] . Internal feedback processes : Technology providers can build processes to get regular usage feedback on factors such as the following . Internal grievance redressal : This can alert technology providers about cases of misappropriation of the technology by malicious users , or malfunctioning of the technology itself , both of which are likely to happen in any digital platform . Addressing these issues promptly can contribute to building credibility of the technology in the eyes of its users , and also empower and incentivize them to not have the technologies get misused . Tracking of inclusion and exclusion : Biases in access or usage arising from gender or other categories of inequity can be spotted through periodic demographic studies of the users . The reasons behind the biases can be identified through deeper field immersion , and appropriate action can be taken . This can help avoid an increase in inequalities through inclusion and exclusion biases arising from inequities in the social context itself that constrains access to the technology for different usergroups . Design of incentives : Managing federated setups and building a closer feedback loop with the end - users may require additional effort from the technology providers . MV showed that it is possible to distribute this effort by building appropriate incentives to involve the users themselves or their community representatives in the management of the technologies . Suitable social , solidarity , and monetary initiatives can lead to strong internal accountability and sustained usage , and create long standing community embeddedness . Further , being able to align the incentives with positive social change as an overarching objective may lead to greater participation by the users towards the management of digital platforms and also build the platforms’ social credibility . Addressing gaps in technology literacy : Not all users can be expected to have a good understanding of how to use the technology , and what it could be used for . Tracking inclusion - exclusion metrics and usage profiles , through the feedback processes mentioned above , can help spot specific biases that could be arising from this disparity in technology literacy . Appropriate steps can then be taken to bridge the gaps . Depending upon the context , this gap could be bridged through online mechanisms like tutorial videos or it may require offline mechanisms such as training workshops , and it may be undertaken by the technology providers or it may require incentive mechanisms for the users or community representatives to do this . In some extreme contexts , bringing about this technology literacy may not be straightforward or even possible , and in such cases processes to facilitate assisted usage may be needed . All such steps can significantly avoid disempowerment effects that some users may notice from their inability to learn to use new technologies easily . Signaling : Misuse of technologies can be avoided by nurturing appropriate usage norms . Methods like content moderation or highlighting positive behavior are useful to send signals to the users about acceptable and unacceptable practices . 4 . 2 Summary We have discussed so far that unforeseen aspects at the socio - technological interface can arise even when well - designed technologies are deployed , and technology providers should incorporate processes such as the ones listed above to manage the socio - technological interface for their technologies . Underlying ethical values can serve as guardrails to guide this activity . To summarize , this interface is defined in a given social context through aspects such as the need to address gaps in technology literacy and access , build community embeddedness , achieve internal accountability and sustained usage , guard against technology appropriation which can lead to inclusion and exclusion biases , shape appropriate usage norms to avoid misuse , achieve strong social and institutional credibility by meeting expectations of the users , and create a business model that can bring financial sustainability but not compromise processes required to manage the rest of the aspects . Other digital platforms especially in a similar social context as MV , are likely to encounter the same socio - technological interface and may need similar processes . We next describe a few other digital platforms and the fallouts if strong processes are not built to manage their socio - technological interface . One of the largest digital platforms , Facebook , has lost considerable credibility in recent years for the limited attention it paid to check the presence of echo chambers and filter bubbles created through its algorithms and the metrics it chose to optimize [ 78 ] , slow efforts to detect fake news [ 13 ] , poor ability to control data leaks [ 79 ] , etc . Platforms like Reddit and Slashdot on the other hand , have shown resilience to such cases of misappropriation [ 80 ] . They have a strong moderation system mediated by people , and Reddit in fact is set up as a federated system which allows different communities to build their own respective moderation policies [ 21 ] . Other successful collaborative knowledge building platforms like Wikipedia and Quora similarly have strong moderation policies and a somewhat implicit federated structure defined on the basis of topic interests of users . Even though Facebook has now scaled its human driven moderation processes , along with automated methods to detect misuse , it allows only very coarse moderation features and thereby does not truly empower users to take responsibility for the administration of their groups . We feel that such a design limits the ownership that users can perceive . Reddit and Slashdot on the ICTD’20 , June , 2018 , Guayaquil , Equador A . Seth other hand , like MV , have elaborate moderation policies which empower users to manage their groups and send signals to others to prevent misuse . Volunteer moderators of many popular Reddit groups demonstrated strong ownership and voice during the 2015 AMAgeddon episode when Reddit fired a popular employee [ 43 ] . Like Facebook , Whatsapp also does not provide adequate tools to the administrators to manage their groups and prevent misuse . Further , the encrypted nature of communication makes it difficult for users to manage it , and Whatsapp has also absolved itself of any responsibility towards facilitating more appropriate administration of its forums . We therefore conclude that even though such platforms have enabled communication and collaboration at massive scales , but not managing the socio - technological interface effectively has led to undesirable consequences . 5 Discussion and conclusions We showed in the previous sections that design alone is not sufficient to ensure responsible outcomes from technology , and that careful management of the socio - technological interface is also critical . This is not a novel insight in any way . Organizations deploying technology have always had teams to manage it . Our emphasis however is on the lack of discussion in most academic literature about methods to manage technology , to ensure responsible outcomes . Barring the discussion of content moderation as a deployment management activity [ 21 , 22 , 71 ] , most literature has focused only on characterizations of misuse , like on dimensions of gender [ 19 ] , technology access [ 20 ] , information veracity [ 13 , 14 ] , etc . The study of deployment management of technology as an area , it seem has not had as much attention as the study of design . Such studies need long term deployments , while most design innovations are analysed at a prototype stage only . The study of prototypes however misses out on complexities at the socio - technological interface that emerge in long - term deployments . Figure 1 : Ethical underpinnings to information systems This leads to question that just like ethics has emerged as a foundation for design that can facilitate responsible outcomes , can ethics also serve as a foundation for processes to manage deployments ? This is extensively discussed elsewhere [ 81 ] , and a three layer framework is proposed as shown in Figure 1 . A common ethical framework can serve as a foundation to define the objectives of a technology project , influence its design , and shape its deployment management processes . The design layer itself can be conceptualized as being comprised of three components : The user interface , data management and algorithms , and the system design , each of which need to be informed by the ethical framework . There is extensive discussion about the ethical foundations to each of these three components . Through our case - study , we have further shown how each aspect of the socio - technological interface was managed through similar ethical foundations during MV’s deployment . Having a common ethical framework to influence each of these layers is useful for many reasons . It can serve to test technology projects for internal consistency in the values and policies that influenced the different layers of the project . Several information systems have been analysed with this view [ 81 ] , of what values seem to have shaped their objectives , what values shaped their design , and what values shaped their management style , and then verify whether these values are consistent with one another or not . A common ethical framework can similarly bring clarity to different project teams about what values should drive them when they think of new design modifications or build processes to manage their platforms . Project teams otherwise come from different academic backgrounds and diverse experiences , and can come up with even conflicting solutions . For example , consider a mobile - money company that wants to reduce fraud on its platform by malicious users who take advantage of unsuspecting and less technology - savvy customers . Some project teams may want to run financial literacy awareness workshops with their customers , some teams may want to find technological solutions to detect fraud , and some may suggest to do nothing and let customers learn on their own . A common underlying ethical system can help provide answers by prioritizing deeper values like equality , fairness , or human rights . Similarly , in the case study we discussed , a deeper ethical value of inclusion followed by the MV team led to steps to build offline volunteer networks that could reach marginalized user groups . Not prioritizing this value could have led to an altogether different solution , like to focus on low - hanging fruit to on - board only young male users who are already technology savvy and can be acquired at lower costs [ 67 , 82 ] . To conclude , we showed that management of the socio - technological interface when a technology is in deployment , is a complex activity that needs careful attention to ensure responsible outcomes from the technology . We gave examples of several aspects of the socio - technological interface relevant especially for ICT4D projects and digital information sharing platforms , and processes to manage these aspects . Researchers should try to understand how such management processes evolve , outcomes they lead to , and how to experiment with new processes . Finally , ethical frameworks can serve as a foundation to build these management processes , just like how design can be informed from ethics . These ethical frameworks can serve as guardrails for the designers and managers of technologies , when they make decisions to ensure responsible outcomes from technology [ 81 ] . The limits of design in ensuring responsible outcomes from technology ICTD’20 , June , 2018 , Guayaquil , Equador ACKNOWLEDGMENTS We are extremely grateful to thoughtful feedback from the reviewers which greatly helped strengthen the paper . None of this work would have been possible without the fantastic Gram Vaani team , our volunteers , partners , donors , and investors . The commitment of the team to respecting human rights is extraordinary to say the least , and it is a matter to pride to have such colleagues who have created a wonderful platform . REFERENCES [ 1 ] Accessed Nov 2019 . Design ( noun ) . Merriam - Webster Dictionary . https : / / www . merriam - webster . com / dictionary / design [ 2 ] Vredenburg , K . , Mao , J . , Smith , P . W . , and Carey , T . 2002 . A Survey of User - Centered Design Practice . In Proc . ACM CHI . [ 3 ] Gibson , J . J . 1979 . The Ecological Approach to Visual Perception . Houghton Mifflin Harcourt , USA . [ 4 ] Sanders , L . 2008 . An Evolving Map of Design Practice and Design Research . In ACM Interactions , Volume XV . 6 . [ 5 ] Ideo . 2015 . Design Kit : The Human Centered Design Toolkit . https : / / www . ideo . com / post / design - kit [ 6 ] Sanders , E . B . - N . , and P . J . Stappers . 2008 . Co - creation and the New Landscapes of Design . CoDesign , 4 ( 1 ) : 5 – 18 . [ 7 ] Spinuzzi , C . 2005 . The Methodology of Participatory Design . Technical Communication , Volume 52 ( 2 ) . [ 8 ] Blomberg , J . , Giacomi , J . , Mosher , A . and Swenton - Wall , P . 1993 . Ethnographic Field Methods and Their Relation to Design . In Participatory Design : Principles and Practices , edited by Schuler , D . and Namioka , A . Lawrence Erlbaum Associates , USA . [ 9 ] Friedman , B . , Kahn , P . H . , and Borning , A . 2013 . Value Sensitive Design and Information Systems . In Human Computer Interaction in Management Information Systems : Foundations , M . E . Sharpe , New York . [ 10 ] Accessed Nov 2019 . Fairness , Accountability , and Transparency in Machine Learning . https : / / www . fatml . org / [ 11 ] Berdichevsky , D . and Neuenschwander , E . 1999 . Toward an Ethics of Persuasive Technology . In Communications of the ACM , 42 ( 5 ) . [ 12 ] Goldsmith , J . and Burton , E . 2017 . Why Teaching Ethics to AI Practitioners is Important . In AAAI workshop on AI , Ethics , and Society . [ 13 ] Arun , C . 2019 . On WhatsApp , Rumours , and Lynchings . Economic & Political Weekly 54 ( 6 ) . [ 14 ] Vosoughi , S . , Roy , D . and Aral , S . 2018 . The Spread of True and False News Online . Science 359 ( 6380 ) . [ 15 ] Chouldechova , A . and Roth , A . 2018 . The Frontiers of Fairness in Machine Learning . CCC ( Computing Community Consortium ) Workshop report . [ 16 ] Angwin , J . , Larson , J . , Mattu , S . and Kirchner , L . 2016 . Machine Bias . ProPublica . https : / / www . propublica . org / article / machine - bias - risk - assessments - in - criminal - sentencing [ 17 ] Cathy O’Neil . 2016 . Weapons of Math Destruction : How Big Data Increases Inequality and Threatens Democracy . Crown USA . [ 18 ] Buchanan , L . and Seshagiri , A . 2016 . How Uber Uses Psychological Tricks to Push Its Drivers’ Buttons . New York Times . https : / / www . nytimes . com / interactive / 2017 / 04 / 02 / technology / uber - drivers - psychological - tricks . html [ 19 ] Barboni , G . , Field , E . , Pande , R . , Rigol , N . , Schaner , S . , and Troyer , C . 2018 . A Tough Call : Understanding Barriers to and Impacts of Women’s Mobile Phone Adoption in India . Harvard Kennedy School . [ 20 ] Khera , R . 2017 . Impact of Aadhaar in Welfare Programmes . In Economic and Political Weekly . [ 21 ] Chandrasekharan , E . , Samory , M . , Jhaver , S . , Charvat , H . , Bruckman , A . , Lampe , C . , Eisenstein , J . and Gilbert , E . 2018 . The Internet’s Hidden Rules : An Empirical Study of Reddit Norm Violations at Micro , Meso , and Macro Scales . Proc . ACM Hum . - Comput . Interact . 2 , CSCW , Article 32 . [ 22 ] Lampe , C . and Resnik , P . 2004 . Slash ( dot ) and Burn : Distributed Moderation in a Large Online Conversation Space . In Proc . CHI . [ 23 ] Moitra , A . , Das , V . , Gram Vaani , Kumar , A . , and Seth , A . 2016 . Design Lessons from Creating a Mobile - based Community Media Platform in Rural India . In Proc . ICTD [ 24 ] Seth , A . 2020 . The Elusive Model of Technology , Media , Social Development , and Financial Sustainability . To appear in Harnessing Technology Development for Social Impact , edited by Poonamallee , L . , Scillitoe , J . and Joy , S . Palgrave MacMillan . [ 25 ] Duquenoy , P and Thimbley , H . 1999 . Justice and Design . In Human - Computer Interaction INTERACT 1999 . [ 26 ] Sandel . M . 2009 . Justice : What’s the Right Thing to Do . Penguin . [ 27 ] Sen , A . 2009 . The Idea of Justice . Harvard University Press . [ 28 ] Simons , J . 2019 . The Politics of Machine Learning : Discrimination , Fairness , and Equality . Personal communication . [ 29 ] Tim Unwin . Why we shouldn’t use terms such as “bridging the digital divide” or “digital leapfrogging” , Oct 2018 , and Contributions to UNESCO’s first Partners’ Forum : notes from the underground , Sep 2018 . https : / / unwin . wordpress . com / [ 30 ] Winner , L . 1980 . Do Artefacts Have Politics . Daedalus , Vol . 109 , No . 1 , Modern Technology : Problem or Opportunity ? [ 31 ] Bjerknes , G . and Bratteteig , T . 1995 . User Participation and Democracy : A Discussion of Scandinavian Research on System Development . Scandinavian Journal of Information Systems , 7 ( 1 ) . [ 32 ] Mumford , E . and Weir , M . W . 1979 . Computer Systems in Work Design : The ETHICS Method : Effective Technical and Human Implementation of Computer System . New York : John Wiley & Sons . [ 33 ] Collingridge , D . 1980 . The Social Control of Technology . St Martin’s Press , England [ 34 ] Rosenblat , A . and Stark , L . 2016 . Algorithmic Labour and Information Asymmetries : A Case - study of Uber Drivers . International Journal of Communication , 10 ( 2016 ) . [ 35 ] Betterplace . https : / / www . betterplace . co . in / [ 36 ] Winkler , T . and Spiekermann , S . 2018 . Twenty Years of Value Sensitive Design : A Review of Methodological Practives in VSD Projects . In Ethics and Information Technology . [ 37 ] Wiener , N . 1950 . The Human Use of Human Beings : Cybernetics and Society . Houghton Mifflin . [ 38 ] Jonas , H . 1985 . The Imperative of Responsibility : In Search of an Ethics for the Technological Age . Chicago University Press . [ 39 ] Greenwood , D . J . and Levin , M . 2007 . Introduction to Action Research : Social Research for Social Change . Sage Publictions , London , UK . [ 40 ] Hayes , G . 2011 . The Relationship of Action Research to Human - Computer Interaction . In ACM Transactions on Computer - Human Interaction . [ 41 ] Braa , J . , Monteiro , E . and Sahay , S . 2004 . Networks of Action : Sustainable Health Information Systems Across Developing Countries . In MIS Quarterly 28 ( 3 ) . [ 42 ] Bodker , S . and Kyng , M . 2018 . Participatory Design that Matters : Facing the Big Issues . In ACM Transactions on Computer - Human Interaction 25 ( 1 ) . [ 43 ] Centivany , A . and Glushko , B . 2016 . “Popcorn Tastes Good” : Participatory Policymaking and Reddit’s “AMAgeddon” . In Proc . CHI . [ 44 ] Bird , S . , Hutchinson , B . , Kenthapadi , K . , Kiciman , E . , and Mitchell , M . 2019 . Fairness - aware Machine Learning in Practice ( tutorial ) , KDD . [ 45 ] Hindman , M . , Tsioutsiouliklis . and Johnson , J . A . 2003 . Googlearchy : How a Few Heavily - Linked Sites Dominate Politics on the Web . In Annual Meeting of the Midwest Political Science Association . [ 46 ] Diakopoulos , N . 2017 . Algorithmic Accountability Reporting : On the Investigation of Black Boxes . Tow Center for Digital Journalism , Columbia University . [ 47 ] Goodman , B . and Flaxman , S . 2017 . European Union Regulations on Algorithmic Decision - Making and a ‘Right to Explanation’ . In AI Magazine , 38 ( 5 ) . [ 48 ] Lee , M . K , et al . 2018 . WeBuildAI : Participatory Frameworks for Fair and Efficient Algorithmic Governance . CMU technical report . [ 49 ] Vaccaro , V . and Karahalios , K . 2017 . Algorithmic Appeals . Trustworthy Algorithms . [ 50 ] ICDPPC . 2018 . Declaration on Ethics and Data Protection in Artificial Intelligence . International Conference of Data Protection and Privacy Commissioners . [ 51 ] Khabar Lahariya , http : / / khabarlahariya . org / [ 52 ] Video Volunteers , https : / / www . videovolunteers . org / [ 53 ] Pavarala , V . , & Malik , K . K . 2007 . Other voices : The struggle for community radio in India . SAGE Publications India . [ 54 ] Koradia , Z . , Balachandran , C . , Dadheech , K . , Shivam , M . , & Seth , A . 2012 . Experiences of deploying and commercializing a community radio automation system in India . In Proc . ACM DEV . [ 55 ] Koradia , Z . , Aggarwal , P . , Seth , A . , and Luthra , G . 2013 . Gurgaon idol : A Singing Competition Over Community Radio and IVRS . In Proc . ACM DEV . ICTD’20 , June , 2018 , Guayaquil , Equador A . Seth [ 56 ] Patel , N . , Chittamuru , D . , Jain , A . , Dave , P . , and Parikh , T . S . 2010 . Avaaj Otalo - A Field Study of an Interactive Voice Forum for Small Farmers in Rural India . In Proc . SIGCHI . [ 57 ] Mudliar , P . , Donner , J . , and Thies , W . 2013 . Emergent Practices Around CGNet Swara , A Voice Forum for Citizen Journalism in Rural India . ITID Vol . 9 ( 2 ) , Special Issue [ 58 ] Seth , A . , Zhang , J . , & Cohen , R . 2015 . A personalized credibility model for recommending messages in social participatory media environments . World Wide Web , 18 , 1 , 111 - 137 . [ 59 ] McPherson , M . , Smith - Lovin , A . and Cook , J . 2001 . Birds of a Feather : Homophily in Social Networks , Annual Review of Sociology , Vol . 27 . [ 60 ] Granovetter , M . 1973 . The Strength of Weak Ties , American Journal of Sociology , Vol . 78 , No . 6 . [ 61 ] Seth , A . and Zhang , J . 2008 . A Social Network Based Approach to Personalized Recommendation of Participatory Media Content , Proc . ICWSM . [ 62 ] Chakraborty , D . , Gupta , A . , Gram Vaani Team , Seth , A . 2019 . Experiences from a Mobile - based Behaviour Change Campaign on Maternal and Child Nutrition in Rural India , In Proc . ICTD . [ 63 ] Smyth , T . N . , Kumar , S . , Medhi , I . , & Toyama , K . ( 2010 , April ) . Where There ' s a Will There ' s a Way : Mobile Media Sharing in Urban India . In Proc . SIGCHI . [ 64 ] Kumar , N . ( 2014 ) . Facebook for Self - empowerment ? A Study of Facebook Adoption in urban India . New Media & Society , 16 ( 7 ) , 1122 - 1137 . [ 65 ] Neha Kumar . 2015 . The Gender - technology Divide or Perceptions of Non - use ? First Monday 20 , 11 ( 2015 ) . [ 66 ] Moitra , A . , Kumar , A . , and Seth , A . 2019 . An Analysis of Impact Pathways Arising from a Mobile - based Community Media Platform in Rural India . Working paper [ 67 ] Moitra , A . , Kumar , A . , and Seth , A . 2018 . An Analysis of Community Mobilization Strategies of a Voice - based Community Media Platform in Rural India . Information Technologies & International Development 14 ( 2018 ) . [ 68 ] Marsden , G . , Maunder , A . , and Parker , M . 2008 . People are People , but Technology is not Technology . Philosophical Transactions of the Royal Society of London A : Mathematical , Physical and Engineering Sciences , 366 ( 1881 ) , 3795 - 3804 . [ 69 ] Olson , M . 2009 . The Logic of Collective Action . Harvard Univ . Press . [ 70 ] Mondal , M . , Silva , L . A . , and Benevenuto , F . 2017 . A Measurement Study of Hate Speech in Social Media . In Proc . ACM Hypertext and Social Media . [ 71 ] Chandrasekharan , E . , Pavalanathan , U . , Srinivasan , A . , Glynn , A . , Eisenstein , J . , and Gilbert , E . 2018 . You Can’t Stay Here : The Efficacy of Reddit’s 2015 Ban Examined Through Hate Speech . In Proc . CSCW . [ 72 ] Muskaan , Dhaliwal , M . P . , and Seth . A . 2019 . Fairness and Diversity in the Recommendation and Ranking of Participatory Media Content . KDD Workshop on Intelligent Information Feeds . [ 73 ] Vashistha , A . , Cutrell , E . , Borriello , G . and Thies , B . 2015 . Sangeet Swara : A Community - Moderated Voice Forum in Rural India . In Proc . ACM CHI . [ 74 ] Ninan , S . 2007 . Headlines from the Heartland : Reinventing the Hindi Public Sphere . SAGE Publications . [ 75 ] Mosse , D . 2018 . Caste and Development : Contemporary Perspectives on a Structure of Discrimination and Advantage . In World Development 110 . [ 76 ] Chakraborty , D . , Ahmad , M . S . , and Seth , A . 2017 . Findings from a Civil Society Mediated and Technology Assisted Grievance Redressal Model in Rural India . In Proc . ICTD . [ 77 ] Chakraborty , D . 2018 . Building ICT Based Information Flows To Improve Citizen - Government Engagement . PhD thesis , IIT Delhi . [ 78 ] Tufekci , Z . 2016 . The Real Bias Built In at Facebook . New York Times . https : / / www . nytimes . com / 2016 / 05 / 19 / opinion / the - real - bias - built - in - at - facebook . html . [ 79 ] Cadwalladr , C . 2018 . The Cambridge Analytica Files . The Guardian . [ 80 ] Stoddard , G . 2017 . Popularity Dynamics and Intrinsic Quality in Reddit and Hacker News . In Proc . ICWSM . [ 81 ] Seth , A . 2019 . A New Paradigm to Accommodate Ethical Foundations in the Design and Management of Digital Platforms . Manuscript . [ 82 ] Sachitanand , R . 2018 . Voice , Video and Vernacular : India’s Internet Landscape is Changing to Tap New Users . Economic Times . https : / / bit . ly / 35iYyyJ [ 83 ] Geiger , R . S . 2015 . Does Facebook Have Civil Servants ? On Governmentality and Computational Social Science . CSCW workshop on Ethics for Studying Sociotechnical Systems in a Big Data World . [ 84 ] Farooq , U . , Merkel , C . B . , Nash , H . , Rosson , M . B . , Carroll , J . M . , and Xiao , L . 2005 . Participatory Design as Apprenticeship : Sustainable Watershed Management as a Community Computing Application . Hawaii International Conference on System Sciences . [ 85 ] Christiansen , E . 2014 . From “Ethics of the Eye” to “Ethics of the Hand” by Collaborative Prototyping . Journal of Information Communication and Ethics in Society . [ 86 ] Lodato , T . and DiSalvo , C . 2018 . Institutional Constraints : The Forms and Limits of Participatory Design in the Public Realm . Participatory Design Conference . [ 87 ] Hirschheim , R . and Klein , H . K . 1989 . Four Paradigms of Information Systems Development . In Proc . CACM . [ 88 ] Dahlbom , B . and Mathiassen , L . 1993 . Computers in Context . Blackwell Publishers . [ 89 ] Surana , S . , Patra , R . , Nedevschi , S . , Ramos , M . , Subramanian , L . , Ben - david , Y . , and Brewer , E . Beyond Pilots : Keeping Rural Wireless Networks Alive . In Proc . NSDI . [ 90 ] Cross , A . , et al . 2019 . 99DOTS : A Low - cost Approach to Monitoring and Improving Medication Adherence . In Proc . ICTD . [ 91 ] Best , M . and Kumar , R . 2008 . Sustainability Failures of Rural Telecenters : Challenges from the Sustainable Access in Rural India ( SARI ) Project . In ITID Volume 4 , Number 4 .