a r X i v : 0707 . 3545v1 [ m a t h . P R ] 24 J u l 2007 Exchangeable Random Networks F . Bassetti ∗ , M . Cosentino Lagomarsino † S . Mandr ` a ‡ October 17 , 2007 Abstract We introduce and study a class of exchangeable random graph ensembles . They can be used as statistical null models for empirical networks , and as a tool for theoretical investigations . We provide general theorems that carachterize the degree distribution of the ensemble graphs , together with some features that are important for applications , such as subgraph distributions and kernel of the adjacency matrix . These results are used to compare to other models of simple and complex networks . A particular case of directed networks with power - law out – degree is studied in more detail , as an example of the ﬂexibility of the model in applications . Key words and phrases Complex networks , Exchangeable graphs , Power law distributions , Random Graphs , Scale free graphs , Transcription networks . 1 Introduction Random graphs have attracted much interest as null - and positive models for many real - world systems involving many interacting agents , such as the internet , epidemics , social and biological interactions ( see for instance [ 55 , 45 , 47 , 43 ] ) . In many of these instances , one is naturally confronted with properties that diﬀer from the classical Erd¨os - R´enyi model . We recall that , in the Erd¨os - R´enyi model , edges in the graph exist independently from each other , with a ﬁxed probability ( dependent on the dimension of the graph ) . While for the Erd¨os - R´enyi model analytical expressions for many of the relevant observable properties of the graph ( such as the diameter , clustering coeﬃcient , component size distributions , subgraph distribution , giant component , etc ) are available , less is known for other kinds of models . In the recent years , in connection with the availability of large - scale data on real - life networks , many studies addressing random graph models going beyond the Erd¨os – R´eny model have appeared . Two studies that are worth mentioning are the so - called ”small – world” model [ 56 ] and the preferential - attachment model [ 4 ] , addressing the empirically observable phenomena of short shortest - paths and power - law degree distributions respectively . This new wave of models has aﬀected also the mathematical literature ( see , for instance refs [ 1 , 2 , 8 , 11 , 7 , 9 , 10 , 13 , 14 , 16 , 45 , 46 ] ) . Among the many recent mathematical books on the subject , we would like to mention , for classical random graph theory , [ 34 ] and [ 6 ] , and , for more recent models of random graphs , [ 15 ] and [ 19 ] . From a statistical point of view , which we adopt here , it is natural to seek a parameterizable stochastic model of complex ∗ Universit ` a degli Studi di Pavia , Dip . Matematica , Via Ferrata 1 , 27100 , Pavia , Italy ; e - mail : federico . bassetti @ unipv . it † UMR 168 / Institut Curie , 26 rue d’Ulm 75005 Paris , France ; Universit ` a degli Studi di Milano , Dip . Fisica , Via Celoria 16 , 20133 Milano , Italy ; e - mail : mcl @ curie . fr ‡ Universit ` a degli Studi di Milano , Dip . Fisica , Via Celoria 16 , 20133 Milano , Italy ; e - mail : dagart @ pcteor1 . mi . infn . it 1 graphs , that would be at the same time ﬂexible for practical use and mathematically tractable for theoretical exploration . Moreover , it is desirable that the qualitative properties of the model should emerge from some simple unifying mathematical structure rather than from ad - hoc considerations , see [ 2 , 6 , 11 , 7 , 9 , 14 , 47 ] . The aim of this paper is to present a general class of random graphs that addresses these needs . It was introduced in [ 5 ] in a particular case , connected to the study of null models for tran - scriptional regulation networks [ 3 ] . The deﬁning property of the graph ensemble is the exchangeable structure of its degree correlations . This symmetry property makes it particularly apt to be used as a statistical null model . The most important advantages of such an approach are the following : ( i ) Much as in the Erd¨os - R´enyi model , some observables can be easily computed analytically for ﬁnite sizes and asymptotically , rather than estimated numerically . ( ii ) It is fast and versatile in computational implementations and statistical applications . As we will show in the diﬀerent sections of this paper , many observables that are commonly useful in the analysis of large - scale networks are particularly simple to access with our ensemble . In order to show the range of applicability , we discuss multiple applications to observables in the model graphs rather than presenting a very detailed analysis on a single graph feature . In the use as a null model , diﬀerently from other approaches used in the study of transcriptional and other networks [ 31 , 50 , 12 ] , our generating method for random graphs is not designed to conserve the degree sequence of the observed real graph , but rather as a method to generate graphs with degree distributions having certain prescribed properties . The paper is structured as follows . Section 2 introduces a rather general class of random directed network ensembles that can be produced with the same deﬁning principle of exchangeability , and discusses some simple variants . The following part is intended to show how the structure of the proposed model is useful in the the study of many relevant topological features of the ensemble . To this aim , in Section 3 we prove some theorems which characterize the degree distributions and the distribution of the size of the ”hub” ( or the maximally connected node ) . In particular , we show that the model can generate an ensemble characterized by a Poisson limit distribution for the in – degree , and a mixture of Poisson limit distributions for the out - degree . This important property enables to obtain a limit out – degree distribution with power – law tails . In the same section , we show that the probability that the graph is disconnected goes to 1 as the size of the graph diverges . Section 4 gives some results concerning the mean number of subgraphs ( a quantity of some importance in many applications ) , roots and leaves . Section 5 considers a particular Boolean optimization problem deﬁned on the graph , which emerges in statistical physics and theoretical computer science . More precisely , we will give some results concerning the non - trivial problem of the dimension of the kernel of the adjacency matrix . In Section 6 we brieﬂy comment the two variants of the main model . Finally , Section 7 contains the detailed analysis of a simple two - parameter ensemble derived from the general model presented in Section 2 . All the proofs are provided in the Appendix . 2 The Model Although the ideas we describe are applicable to both directed and undirected graphs , we will mainly consider here the case of directed graphs . Any directed random graph G n with n nodes is completely speciﬁed by its adjacency matrix X n = X ( G n ) = [ X ( n ) i , j ] i , j = 1 , . . . , n , where X ( n ) i , j = 1 if there is a directed edge i → j , 0 otherwise . Instead of square matrices , one may also consider rectangular matrices . In what follows we will deal with rectangular matrices m n × n . As we will see in Section 7 , this is particularly useful for networks with power - law degree distributions having exponent equal or lower than 2 ( this with diverging average ) to keep the asymptotics well - behaved . One of the interests of our procedure is the fact that it can produce graphs with diﬀerent in - and out - degrees distributions . Naturally , if the graph is generated by throwing independently each directed edge with a ﬁxed probability – as in the case of ( undirected ) Erd¨os - R´eny graphs – this is not possible . In order to build a random graph with diﬀerent in - and out – degree distributions , one must give up total independence and allow some kind of dependence among edges . In particular , maintaining the 2 maximal symmetry leads to the choice of exchangeability . 2 . 1 Partially Exchangeable Random Graphs The ﬁrst general class we will consider includes directed graphs whose in - or out – degrees , i . e . the columns or the rows of X n , are exchangeable , while the out - or in – degrees are stochastically indepen - dent . Diﬀerently put , our model ensemble can be deﬁned using the following generative algorithm . For each row of X n , independently , ( i ) throw a bias θ from a prescribed probability distribution π n on [ 0 , 1 ] ( ii ) and set the row elements of X n to be 0 or 1 according to the toss of a coin with bias θ . Since each row is thrown independently , the resulting probability law is P { X ( n ) i , j = e i , j , i = 1 , . . . , m n , j = 1 , . . . , n } = m n Y i = 1 Z [ 0 , 1 ] θ P nj = 1 e i , j i ( 1 − θ i ) n − P nj = 1 e i , j π n ( dθ i ) ( 1 ) where e i , j ∈ { 0 , 1 } , i , j = 1 , . . . n . In other words , each row of X ( G n ) is independent from the others with exchangeable law directed by π n . One can apply an identical procedure to the transposed matrix of X n and switch the role of in - and out – degrees . To complete the model , one has to specify the choice for π n , which determines the behavior of the graph ensemble . For example , in [ 5 ] , we have chosen the two - parameter distribution π n ( dθ ) = Z − 1 θ − β I ( αn , 1 ] ( θ ) dθ ( 2 ) where α > 0 and β > 1 are free parameters , I ( αn , 1 ] is the indicator function of the interval ( αn , 1 ] , taking the value one inside the interval and zero everywhere else , and Z : = ( ( n / α ) β − 1 − 1 ) / ( β − 1 ) is the normalization constant . As we will see in Section 7 , this choice produces a graph ensemble with heavy - tailed degree sequences . As a second example , taking π n ( dθ ) = δ λ / n ( dθ ) , one obtains a directed version of the Erd¨os - R´eny graph . A naturally interesting problem is to characterize the general forms of the probability measure π n that lead to graph ensembles with qualitatively diﬀerent characteristics . In Section 3 we shall give some results in this direction . Note that a general way of producing the distribution π n for each n , starting form a given ”seed” F ( F being a ﬁxed distribution function on R + ) , is easily described by the following assumption : F n ( x ) : = Z [ 0 , x ] π n ( dθ ) = F ( xn ) / F ( n ) . ( 3 ) With the above assumption , F n is a well - deﬁned distribution function on [ 0 , 1 ] whenever F ( n ) > 0 , which certainly holds for large enough values of n . 2 . 2 Completely exchangeable graphs The above described method of generating exchangeable graphs is quite general , so that one can imagine many simple variants . For example , one can consider the following algorithm : ( i ) throw a bias θ from a prescribed probability distribution π n and ( ii ) set all the elements of X n to be 0 or 1 according to the toss of a coin with bias θ . The resulting probability law , say Q , is Q { X i , j = e i , j ; i , j = 1 , . . . , n } = Z [ 0 , 1 ] θ P i , j e i , j ( 1 − θ ) n 2 − P i , j e i , j π n ( dθ ) for any e i , j in { 0 , 1 } i , j = 1 , . . . n , that is under Q , { X i , j ; i , j = 1 , . . . , n } are exchangeable , with de Finetti measure π n . 3 2 . 3 Hierarchical models Another possible variant considers a hierarchy of probability distributions to generate the bias of the coins . In this case one can take Q ∗ { X ( n ) i , j = e i , j , i = 1 , . . . , m n , j = 1 , . . . , n } = R R + Q m n i = 1 R [ 0 , 1 ] θ P nj = 1 e i , j i ( 1 − θ i ) n − P nj = 1 e i , j π n ( dθ i | α ) λ n ( dα ) ( 4 ) λ n being a probability on R + and π n ( dθ | α ) being a kernel on [ 0 , 1 ] × R + , that is : for every α in R + , π n ( · | α ) is a measure on the Borel σ – ﬁeld of [ 0 , 1 ] and , for every measurable subset B of [ 0 , 1 ] , α 7→ π n ( B | α ) is measurable . 3 Connectivities We will carry the main discussion considering the case of partially exchangeable graphs of Subsec - tion 2 . 2 . Some brief comments on the other variants are reported in Section 6 . In the rest of the paper , with the exception of Section 6 , we suppose that all the random elements are deﬁned on the same probability space ( Ω , F , P ) and we denote by E ( Y ) the mathematical expectation of a given random variable Y with respect to P . With a slight abuse of notation we shall use indiﬀerently G n , the random graph , and its adjacency matrix X n . 3 . 1 In and out connectivity The ﬁrst quantities that we want to characterize are the graph degree distributions . The random vari - able Z m n , j : = P m n i = 1 X ( n ) i , j represents the in – degree of the j - th node in the random graph , while S n , i : = P nj = 1 X ( n ) i , j can be seen as the out – degree of the i - th node ( 1 ≤ i ≤ m n ) . Note that ( Z m n , 1 , . . . , Z m n , n ) are identically distributed as well as ( S n , 1 , . . . , S n , m n ) . Moreover , ( S n , 1 , . . . , S n , m n ) are independent , and each S n , i is a sum of exchangeable Boolean random variables , while ( Z m n , 1 , . . . , Z m n , n ) are de - pendent . Each Z n , i is a sum of independent Boolean random variables . Clearly , the mean degrees are equal to m n µ n and nµ n , respectively , where µ n : = P { X ( n ) i , j = 1 } = R [ 0 , 1 ] θπ n ( dθ ) is the probability of the link i → j . Note that , while in the Erd¨os – R´eny model nµ n = λ for every n , in this case nµ n generally depends on n . On the other hand , in the case when ( 3 ) is in force nµ n = Z [ 0 , 1 ] nθπ n ( dθ ) = Z n 0 xd „ F ( x ) F ( n ) « = Z n 0 ( 1 − F ( x ) / F ( n ) ) dx , and hence , if µ : = R + ∞ 0 xdF ( x ) < + ∞ it follows that nµ n = µ + o ( 1 ) . The ( marginal ) degree distributions are given by P { S n , i = k } = n k ! Z [ 0 , 1 ] θ k ( 1 − θ ) n − k π n ( dθ ) and P { Z m n , j = k } = m n k ! µ k n ( 1 − µ n ) m n − k . With the above expressions , the problem of determining the asymptotic distribution of ( Z m n , 1 ) n ≥ 1 and ( S n , 1 ) n ≥ 1 is simply cast in a central limit problem for triangular arrays . In fact , while for ( Z m n , 1 ) n ≥ 1 a classical central limit theorem ( CLT ) for triangular arrays of independent random variables works , for ( S n , i ) n ≥ 1 one needs a CLT for exchangeable random variables . General CLTs for exchangeable random variables are well known ( see , for instance , [ 51 , 25 ] ) . Here the situation is particularly simple , 4 since we are dealing with 0 − 1 random variables . Consequently , we need only a simple ad - hoc CLT , for exchangeable Boolean random variables . Let ˜ θ n be a random variable taking values in [ 0 , 1 ] with distribution π n and set T n : = n ˜ θ n . The next proposition shows that , under a set of reasonable assumptions on T n , the limit law of ( S n , 1 ) n ≥ 1 is a mixture of Poisson distributions , while the limit law of ( Z n , 1 ) n ≥ 1 is a simple Poisson distribution . Proposition 3 . 1 ( CLT ) If ( T n ) n ≥ 1 converges in distribution to a random variable T with distribu - tion function F , then , for every integer j ≥ 1 , lim n → + ∞ P { S n , j = k } = E » 1 k ! T k e − T – = Z + ∞ 0 t k k ! e − t dF ( t ) ( k = 0 , 1 , . . . ) . ( 5 ) Moreover , if for some λ > 0 and for a sequence ( a n ) n ≥ 1 lim n → + ∞ a n E ( T n ) = lim n → + ∞ na n Z [ 0 , 1 ] θπ n ( dθ ) = λ ( 6 ) holds true , then , for every integers k ≥ 0 and j , lim n → + ∞ P { Z m n , j = k } = λ k e − λ k ! with m n = [ na n ] ( [ x ] being the integer part of x ) . Remark 1 ( a ) If ( 3 ) holds true , then the distribution of T is exactly F . Indeed , in this case , lim n → + ∞ P { T n ≤ x } = lim n → + ∞ P { θ n ≤ x / n } = lim n → + ∞ F ( x ) / F ( n ) = F ( x ) ( x ≥ 0 ) . ( b ) It is worth noticing that as a corollary of Theorem 5 in [ 25 ] one has that the convergence of T n is a necessary and suﬃcient condition in order to obtain a Poisson mixture as a limit law for ( S n , j ) n ≥ 1 . Hence , the ﬁrst part of the previous proposition can be proved invoking such a theorem . Nevertheless , for the sake of completeness , we shall give a simple direct proof in the Appendix . Since ( 5 ) is a mixture of Poisson distributions with weight given by F , the above result can be used to “discharge” the choice of π n on the perhaps more intuitive choice of the mixing distribution F . Clearly , the emergence of heavy - tailed distributions is not a simple consequence of ( 1 ) , but depends on the choice of π n . The following example describes a mixing probability which gives rise to a compact out – degree distribution . Example 1 Take π n ( dθ ) = nγ 1 − e − γn e − γnθ dθ ( γ > 0 ) , or , in other words , assume ( 3 ) with F ( x ) = R x 0 γe − γt dt = 1 − e − γx . With this choice , the limit distribution of S n , 1 is an exponential mixture of Poisson distribution . Precisely , we ﬁnd it to be a geometric distribution , i . e . lim n → + ∞ P { S n , j = k } = γ Z + ∞ 0 t k k ! e − t e − γt dt = γ 1 + γ ( 1 + γ ) − k ( k = 0 , 1 , . . . ) . Moreover , choosing a n = 1 and λ = 1 / γ leads to lim n → + ∞ P { Z n , 1 = k } = γ − k e − 1 / γ k ! . 5 A generalization of the previous example takes , instead of an exponential distribution , a gamma dis - tribution , i . e . F ( x ) = Z x 0 γ r t r − 1 e − γt Γ ( r ) dt ( r > 0 ) . It is easy to check that the limiting distribution is a negative binomial distribution with parameter r . That is , lim n → + ∞ P { S n , j = k } = r + k − 1 k ! „ γ 1 + γ « r ( 1 + γ ) − k ( k = 0 , 1 , . . . ) . Moreover , lim n → + ∞ P { Z n , 1 = k } = ( rγ ) k e − r / γ k ! . In the above example , mixturing the Poisson distribution with exponential weights proves insuﬃcient to produce a power - law distribution . In other instances , a suitable choice of F in ( 5 ) can give rise to an out – degree probability distribution with heavy tails . Consider the following Example 2 Assume a slight generalization of ( 2 ) , i . e . π n ( dθ ) = Z − 1 θ − β g ( nθ ) I ( αn , 1 ] ( θ ) dθ ( 7 ) with 0 < c 1 ≤ g ( τ ) ≤ c 2 < + ∞ for every τ in [ 0 , + ∞ ) and Z : = Z 1 a / n θ − β g ( nθ ) dθ . Note that ( 7 ) satisﬁes ( 3 ) with F ( x ) = R x α t − β e − t g ( t ) dt R + ∞ α t − β g ( t ) dt . Hence , it is straightforward to verify that Proposition 3 . 1 yields lim n → + ∞ P { S n , j = k } = 1 k ! R + ∞ α t k − β e − t g ( t ) dt R + ∞ α t − β g ( t ) dt = : q ( k ) . We now show that such a distribution is a power - law - tailed distribution . In order to prove this , let us consider ﬁrst the special case in which g = 1 , i . e . the older ( 2 ) . With this choice , we get q ( k ) = p α , β ( k ) : = α β − 1 ( β − 1 ) k ! Z + ∞ α t k − β e − t dt ( k ≥ 0 ) . Hence , if k > β , write p α , β ( k ) = α β − 1 ( β − 1 ) „ Γ ( k + 1 − β ) Γ ( k + 1 ) − 1 Γ ( k + 1 ) Z α 0 t k − β e − t dt « and note that , by the well known asymptotic expansion for the gamma function , Γ ( k + 1 − β ) Γ ( k + 1 ) ∼ 1 k β . Moreover , k β Γ ( k + 1 ) Z α 0 t k − β e − t dt = o ( 1 ) . Consequently , we get p α , β ( k ) = α β − 1 ( β − 1 ) 1 k β ( 1 + o ( 1 ) ) . 6 Now note that , since c 1 c 2 p α , β ( k ) ≤ q ( k ) ≤ c 2 c 1 p α , β ( k ) , q k has power - law tails also for g 6 = 1 . Finally , the following example shows a more complex , already mixtured distribution , leading to a heavy tail . Example 3 Given α > 1 and s > 1 , set , for every positive x , f α , s ( x ) : = 1 Γ ( s ) Φ ( 1 , s , α ) Z + ∞ 0 e − x ( e τ − 1 ) τ s − 1 e − τ ( α − 1 ) dτ where Φ ( z , s , α ) is the well - known Lerch transcendent , deﬁned as Φ ( z , s , α ) : = P k ≥ 0 z k ( α + k ) − s , for every complex z with | z | ≤ 1 . See , for instance , 9 . 550 in [ 27 ] . Note that f α , s ( x ) ≥ 0 . Moreover , by means of the following integral representation Φ ( z , s , α ) = Γ ( s ) − 1 R + ∞ 0 τ s − 1 e − τα ( 1 − ze − τ ) − 1 dτ ( see 9 . 556 in [ 27 ] ) , one can check that R + ∞ 0 f α , s ( x ) dx = 1 . In other words , f α , s deﬁnes a density distribution . Note that f α , s is itself a mixture of exponential densities . Indeed , it can be rewritten as f α , s ( x ) = Z + ∞ 0 ( e τ − 1 ) e − x ( e τ − 1 ) τ s − 1 e − τα Γ ( s ) Φ ( 1 , s , α ) ( 1 − e − τ ) dτ = Z + ∞ 0 ue − xu log s − 1 ( u + 1 ) Γ ( s ) Φ ( 1 , s , α ) u ( u + 1 ) α − 1 du with Z + ∞ 0 τ s − 1 e − τα Γ ( s ) Φ ( 1 , s , α ) ( 1 − e − τ ) dτ = Z + ∞ 0 log s − 1 ( u + 1 ) Γ ( s ) Φ ( 1 , s , α ) u ( u + 1 ) α − 1 du = 1 . It can be veriﬁed that for every real q with | q | < 1 , X k ≥ 0 ( iq ) k Z + ∞ 0 t k k ! e − t f α , s ( t ) dt = Z + ∞ 0 e iqt e − t f α , s ( t ) dt = Φ ( iq , s , α ) Φ ( 1 , s , α ) = X k ≥ 0 ( iq ) k Φ ( 1 , s , α ) ( α + k ) s ( where i : = √− 1 ) , from which it follows that Z + ∞ 0 t k k ! e − t f α , s ( t ) dt = 1 Φ ( 1 , s , a ) ( α + k ) s . Hence , if one takes an exchangeable random graph G n , with mixing distribution satisfying ( 3 ) with F ( x ) : = Z x 0 f α , s ( t ) dt , then the limit law of S n , 1 is given by lim n → + ∞ P { S n , 1 = k } = Z + ∞ 0 t k k ! e − t f α , s ( t ) dt = Φ ( 1 , s , a ) − 1 ( α + k ) − s for every k ≥ 0 . As the above examples show , the model can produce graphs with disparate features , depend - ing on the choice of the probability distribution of the coin biases . In particular , it is interesting to investigate under which conditions do heavy - tailed distributions emerge as limit distributions of the 7 out – degree . If one supposes that T n converges in law to a random variable with probability distri - bution function F , we have shown how the question can be reduced to the problem of determining under which conditions on F the probability deﬁned by ( 5 ) has heavy tails . It is worth noticing that mixtures of Poisson distributions have been extensively studied ( see , e . g . , [ 28 ] ) . Let us brieﬂy recall some useful properties of such distributions . First of all , if q k : = Z + ∞ 0 1 k ! t k e − t dF i ( t ) ( k ≥ 0 , i = 1 , 2 ) for two distribution functions F 1 and F 2 with F i ( x ) = 0 for every x ≤ 0 , then F 1 = F 2 , this simple fact was ﬁrst noticed in [ 23 ] , see also Theorem 2 . 1 ( i ) in [ 28 ] . Hence one hopes to recover many properties of p k : = R + ∞ 0 1 k ! t k e − t dF ( t ) from the properties of F . In particular , Theorem 2 . 1 in [ 57 ] states that if F has a density f with respect to the Lebesgue measure or to the counting measure , such that f ( x ) ∼ L ( x ) x α exp { − βx } x → + ∞ where L is locally bounded and varies slowly at inﬁnity , β ≥ 0 , −∞ < α < + ∞ ( with α < − 1 if β = 0 ) , then p k ∼ L ( k ) β − ( α + 1 ) ( 1 / ( 1 + β ) ) k k α k → + ∞ . Recall that a slowly varying function L is a measurable function such that lim x → + ∞ L ( xt ) / L ( x ) = 1 for every positive t . Under no assumptions on F we have the following very simple Lemma 3 . 2 Let F be a distribution function with F ( x ) = 0 for every x ≤ 0 , and set p k : = R + ∞ 0 1 k ! t k e − t dF ( t ) . Then , for every positive γ X k ≥ 0 k γ q k < + ∞ if ad only if Z + ∞ 0 t γ dF ( t ) < + ∞ . It is also worth mentioning that a random variable T is a mixture of Poisson distribution if and only if its generating function G T ( s ) = E ( s T ) is absolutely monotone in ( −∞ , 1 ) , that is if G ( n ) T ( s ) ≥ 0 for every integer n and s in ( −∞ , 1 ) . See [ 49 ] and Proposition 2 . 2 in [ 28 ] . Finally , we recall that ( p k ) k inherits many properties from F . For example , ( p k ) k has a monotone density if F has a monotone distribution , ( p k ) k has log - convex density if F has log - convex distribution , ( p k ) k is inﬁnite divisible if F is so . For more details , see , for instance [ 54 , 28 ] . The next subsections will deal with the computation of interesting observables that go beyond the degree distributions . 3 . 2 The hub size As a ﬁrst example of observable , we discuss the size of the so – called hub , i . e . the node having maximal out – degree among the nodes ( thus , in many concrete networks , being the most important for routing and the most vulnerable to attack , see , e . g . [ 8 ] ) . The hub size is deﬁned by the expression H n : = max i = 1 , . . . , m n ( S n , i ) . In particular , the most interesting case for the behavior of the hub is when the tail of the out – degree is power - law , as this means that there can be no characteristic size for the hub . As we will explain , it interesting to give an analytical expression of the limit law of this quantity under a suitable rescaling . 8 The idea is very simple : by stochastic independence , it is clear that P { H n ≤ xb n } = ( 1 − P { S n , 1 > xb n } ) m n , where x > 0 is any positive number . Now , after setting L : = sup { y ≥ 0 : lim sup n [ yb n ] / n < 1 } , if we can prove that P { S n , 1 ≤ xb n } = 1 − g ( x ) / m n + o ( 1 / m n ) for any x ≤ L , then lim n P { H n ≤ xb n } = e − g ( x ) I [ 0 , L ) ( x ) + I [ L , + ∞ ) ( x ) . We will show that , in some situations , it is possible to determine explicitly g , b n and L . The following proposition concerns the hub behavior in case of heavy tails for the out – degree . Proposition 3 . 3 Suppose there exist two positive constants η , c η , a sequence of positive numbers ( c η , n ) n ≥ 1 , and a sequence of functions ( r n ) n ≥ 1 , such that , for every t in ( 0 , 1 ) Z ( t , 1 ] π n ( dθ ) = c η , n 1 ( nt ) η + r n ( t ) , c η , n → c η and R 1 0 r n ( t ) t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 B ( [ b n x ] + 1 , n − [ b n x ] ) = o ( 1 m n ) ( 8 ) with b n : = m 1 / η n . Then lim n → + ∞ P { H n ≤ [ xb n ] } = e − c η x − η I [ 0 , L ) ( x ) + I [ L , + ∞ ) ( x ) where L : = sup { y ≥ 0 : lim sup n → + ∞ [ y m 1 / η n ] / n < 1 } . We give now two simple conditions that imply the validity of ( 8 ) , and can be useful in concrete applications . The ﬁrst conditions will be used in the example that we spell out in detail in the second part of this paper ( Proposition 7 . 2 ) . Lemma 3 . 4 If for some α > 0 , C < + ∞ and η > 0 | r n ( t ) | ≤ C ` I { nt < α } ( 1 + ( nt ) − η ) + n − η ´ ( 9 ) with m n / n η = o ( 1 ) , then ( 8 ) holds true . We conclude this subsection observing that when ( 3 ) is in force , then Z ( t , 1 ] π n ( dθ ) = 1 − F n ( t ) = F ( n ) − 1 + 1 − F ( nt ) F ( n ) , hence it is natural to assume some hypotheses on 1 − F ( x ) . In particular , recall that a distribution function F is in the domain of attraction of the extreme value Fr´echet distribution if and only if sup { x : F ( x ) < 1 } = + ∞ and 1 − F ( x ) = 1 x η L ( x ) ( 10 ) where L is a slowly varying function . See , for instance , [ 26 ] . This means that ( 10 ) holds if and only if given a sequence of independent and identically distributed random variables ( ξ ) n ≥ 1 with common law F lim n → + ∞ P { a − 1 n max { ξ 1 , . . . , ξ n } ≤ x } = e − c η x − η ( x > 0 ) for a suitable normalizing sequence ( a n ) n . In point of fact ( 10 ) is not suﬃcient , in our case , to ensure that r n is a reminder of the right order . Hence , we need a heavier requirement . 9 Lemma 3 . 5 Assume that ( 3 ) is in force with 1 − F ( x ) = c η x η [ 1 + h ( x ) ] ( 11 ) for some η > 0 and 0 < c η < + ∞ , with | h ( x ) | ≤ A „ 1 x δ 1 + 1 x δ 2 « ( x > 0 , A < + ∞ , δ 1 , δ 2 > 0 ) , then ( 8 ) holds true with m n / n η = o ( 1 ) . Remark 2 Conditions ( 8 ) are somehow reminiscent of the so called strong normal domain of attrac - tion of the stable laws . See , e . g . , [ 18 , 32 ] . Example 4 As an example it is easy to see that 1 − F ( x ) = α η ( α + x ) η ( x ≥ 0 ) satisﬁes the assumption of the previous lemma . In point of fact 1 − F ( x ) = α η x η + α η x η » x η − ( α + x ) η ( x + α ) η – hence | h ( x ) | ≤ ( α + x ) η − x η x η . If x ≤ 1 , then | h ( x ) | ≤ ( 1 + α ) η / x η , while if x > 1 | h ( x ) | ≤ ( 1 + α x ) η − 1 . Since t → t η is a Lipschitz function of constant η ( 1 + α ) η − 1 on [ 1 , 1 + α ] , if x > 1 , it follows that ( 1 + α / x ) η − 1 ≤ η ( 1 + α ) η − 1 | 1 + α / x − 1 | = η ( 1 + α ) η − 1 a / x . Summarizing | h ( x ) | ≤ A » 1 x + 1 x η – . 4 Some non - local features of the graphs In this section , we deal with the subgraphs content and the mean number of roots and leaves of the model of Subsection 2 . 1 , 4 . 1 Subgraphs The simple exchangeable structure of the generated random graphs makes it possible to compute easily the mean value of the number of subgraphs ”of a given shape” contained in the graph , that can be used for the discovery of “network motifs” [ 53 , 41 , 42 , 38 ] . Consider a subgraph , with k nodes and m edge , given by H = { i 1 → i ( 1 , 1 ) , . . . , i 1 → i ( 1 , m 1 ) , i 2 → i ( 2 , 1 ) , . . . , i k → i ( k , 1 ) , . . . , i k → i ( k , m k ) } with P ki = 1 m i = m . Of course P { H ∈ G n } = Z [ 0 , 1 ] θ m 1 1 π n ( dθ 1 ) Z [ 0 , 1 ] θ m 2 2 π n ( dθ 2 ) . . . Z [ 0 , 1 ] θ m k k π n ( dθ k ) . 10 Denote by T the set of all subgraphs isomorphic to H contained in the complete n graph and by N ( H ) the cardinality of such set . Since the number N H ( G n ) of graph isomorphic to H contained in G n , can be clearly written as N H ( G n ) = X g ∈ T I { g ∈ G n } , it follows that E [ N H ( G n ) ] = N ( H ) P { H ∈ G n } , indeed by exchangeability P { g ∈ G n } = P { H ∈ G n } for every g in T . For example , let us consider the k – cycles . A subgraph H is called k – cycle if it has the form i 1 → i 2 → · · · → i k → i 1 . If N C k ( G n ) denote the number of k – cycles contained in G n , then E [ N C k ( G n ) ] = 2 n k ! µ kn . ( 12 ) Things are slightly more complicated for rectangular matrices because in the evaluation of N ( H ) one needs to take into consideration also the constrains given by the fact that only m n nodes can send outgoing edges . In what follows we will discuss mainly the case of square matrices . As we shall see , in the study of transcriptional networks , the 3 – cycle , i 1 → i 2 , i 2 → i 3 , i 3 → i 1 is called “feedback loop” ( fbl ) , while , with “feedforward loop” ( ffl ) one means a triangle of the form i 1 → i 2 → i 3 , i 1 → i 3 . Following the procedure described above , one gets E [ N fbl ( G n ) ] = 2 n 3 ! µ 3 n . ( 13 ) As for the evaluation of feedforward loops , we have E [ N ffl ( G n ) ] = 6 n 3 ! Z [ 0 , 1 ] θ 2 π n ( dθ ) Z [ 0 , 1 ] θπ n ( dθ ) . ( 14 ) It is worth mentioning that in principle it is possible to compute analytically the variance , as well any other moment of the number of subgraphs isomorphic to a given subgraph . However , com - putations become lengthy and cumbersome rather soon . As an example , we considered the variance of the number of feedback loops and feedforward loops . The key point is evaluating E N ffl ( G n ) 2 and E N fbl ( G n ) 2 . Again , for the sake of symplicity , we will deal only with square matrices . It is clear that E N fbl ( G n ) 2 = P t ∈ T P s ∈ T P { s , t ∈ G n } , T being the set of all feedback loops contained in the complete n graph . Analogously one obtains E N fll ( G n ) 2 taking as T the set of all feedforward loops . Simple calculations give E [ N fbl ( G n ) 2 ] = 4 n 3 ! n − 3 3 ! µ 6 n + 12 n 3 ! n − 3 2 ! µ 2 n δ 2 , n + 6 ( n − 3 ) n 3 ! ( µ 3 n + µ 2 n δ 22 , n ) + 2 n 3 ! µ 3 n where δ i , n : = R 1 0 θ i π n ( dθ ) . As for N ffl , the computations are longer , but essentially the same . The problem is that P { s , t ∈ G n } can take many diﬀerent expressions depending on s and t . With straightforward but tedious calculations one gets E [ N ffl ( G n ) 2 ] = 6 n 3 ! A n + 6 ( n − 3 ) n 3 ! B n + 12 n 3 ! n − 3 2 ! C n + 36 n 3 ! n − 3 3 ! D n 11 with A n = δ 1 , n δ 2 , n + δ 22 , n + δ 21 , n δ 2 , n , B n = δ 2 , n δ 3 , n + 5 δ 1 , n δ 22 , n + 3 δ 21 , n δ 3 , n + δ 23 , n + 2 δ 1 , n δ 2 , n δ 3 , n + 2 δ 32 , n + 4 δ 21 , n δ 22 , n , C n = 2 δ 1 , n δ 2 , n δ 3 , n + δ 21 , n δ 4 , n + 5 δ 21 , n δ 2 , n + δ 32 , n D n = δ 21 , n δ 22 , n . Hence , V ar ( N fbl ( G n ) ) = 12 n 3 ! n − 3 2 ! µ 2 n δ 2 , n + 6 ( n − 3 ) n 3 ! ( µ 3 n + µ 2 n δ 22 , n ) + 2 n 3 ! µ 3 n − 4 n 3 ! R n µ 6 n ( 15 ) and V ar ( N ffl ( G n ) ) = 6 n 3 ! A n + 6 ( n − 3 ) n 3 ! B n + 12 n 3 ! n − 3 2 ! C n − 36 R n D n ( 16 ) with R n = [ ` n 3 ´ − ` n − 3 3 ´ ] . 4 . 2 Roots and leaves We say that i is a root if there is no edge of the kind j → i but there is at least one edge of the kind i → j with j 6 = i . Loops do not count . Conversely , we say that i is a leaf if there is no edge of the kind i → j but there is at least one edge of the kind j → i with j 6 = i , again we exclude loops and isolated points . Let L ( G n ) be the number of leaves in G n and R ( G ) the number of roots in G n . Of course , L ( G n ) = P ni = 1 L i ( G n ) and R ( G n ) = P m n i = 1 R i ( G n ) where L i ( G n ) is equal to 1 if i is a leaf of G n and 0 otherwise and , similarly , R i ( G ) = 1 if i is a root of G n and 0 otherwise . It follows that R i ( G n ) = I ( m n X j = 1 X j , i = 0 ) 0 @ 1 − I 8 < : n X j = 1 , i 6 = j X i , j = 0 9 = ; 1 A , analogously , L i ( G n ) = I ( n X j = 1 X i , j = 0 ) 0 @ 1 − I 8 < : m n X j = 1 , j 6 = i X j , i = 0 9 = ; 1 A . Hence , E [ L i ( G n ) ] = ( 1 − µ n ) m n ( 1 − P { S n − 1 , i = 0 } ) ( 17 ) and E [ R i ( G n ) ] = ( 1 − ( 1 − µ n ) m n − 1 ) P { S n , i = 0 } ( 18 ) and then E [ L ( G n ) ] = n ( 1 − µ n ) m n ( 1 − P { S n − 1 , i = 0 } ) E [ R i ( G n ) ] = m n ( 1 − ( 1 − µ n ) m n − 1 ) P { S n , i = 0 } . 12 4 . 3 Connected components One of the classic and most studied problems in the mathematics of random graphs is the existence and the size of the so - called giant component ( see , for instance , refs . [ 10 , 16 , 13 ] , the books [ 15 , 19 ] and references therein ) . We did not prove anything regarding the emergence of a giant component . The graphs we generated numerically under ( 2 ) seem to have a large component , although it is not hard to see that the probability that G n has only one connected component goes to zero as n diverges ( at least for β > 2 and square matrices ) . This is a consequence of a more general proposition . Proposition 4 . 1 Let m n = n and assume that lim n → + ∞ ( 1 − µ n ) n − 1 P { S n , i = 0 } = a > 0 , then lim n → + ∞ P { G n is connected } = 0 . 5 Threshold properties in the kernel of A n Another interesting use of the echangeable graph ensemble has a connection with the theory of systems of random equations over ﬁnite algebraic structures . This problem has fairly important applications in the theory of ﬁnite state automata , the theory of coding , cryptography and combinatorial optimization problems ( satisﬁability , colouring ) . This kind of problems arise in many branches of science , ranging from statistical physics ( theory of glasses ) to information theory ( e . g . low - density parity - check codes ) . See , e . g . , [ 21 , 22 , 34 , 37 , 39 , 40 , 44 , 36 ] . One interesting problem in random linear systems over ﬁnite algebraic structures is to prove a threshold property for the random graph G n with adjacency matrix X n of dimension m n × n . More precisely , one aims to prove that if m n and n diverge with n / m n → γ ≤ 1 , then an abrupt change in the behavior of the rank of the matrix X n occurs when the parameter γ exceeds a “critical” value γ c . This property can be expressed in terms of the total number of hypercycles in G n deﬁned as S ( X n ) = 2 Ker ( X n ) − 1 = 2 n − m n N ( X n ) − 1 ( 19 ) where N ( X n ) is the number of nontrivial ( i . e . non zero ) solutions of the linear system in GF 2 ( the ﬁeld with elements 0 and 1 ) X Tn x = 0 . ( 20 ) Problems of this kind have been extensively studied for a few ensembles of random graphs , see , for instance , Theorem 3 . 5 . 1 in [ 34 ] and Theorem 1 in [ 36 ] . In the next proposition , we give an exact expression for the mean value of the number of solutions of the linear system ( 20 ) . This expression can be used to prove the existence of a threshold property for S ( X n ) . Moreover , the same expression is a ﬁrst step for a more exhaustive characterization of solution space , which shall be dealt with in a forthcoming paper . In order to state the next proposition introduce the following notations . Deﬁne ξ n ( i ) = Z [ 0 , 1 ] ( 1 − 2 θ ) i π n ( dθ ) and Z n = { j ∈ { 0 , 1 , . . . , n } | ξ n ( j ) = 0 } . Proposition 5 . 1 Assume that X n is a random adjacency matrix of dimension m n × n with law ( 1 ) . Then E N ( X n ) = 2 − n n X i = 1 n i ! ( 1 + ξ n ( i ) ) m n ( 21 ) whenever Z n is the empty set . 13 Using the previous result one easily obtains the following large deviation estimate Proposition 5 . 2 If m n = [ nγ ] ( γ ≤ 1 ) and ( T n ) n ≥ 1 converges in distribution to a random variable T with distribution function F , then lim n → + ∞ 1 n log ( E N ( X n ) ) = sup x ∈ [ 0 , 1 ] Θ γ ( x ) = : I γ with Θ γ ( x ) : = 1 γ " log 1 + Z [ 0 , + ∞ ) e − 2 xt dF ( t ) ! − γ ( x log ( x ) + ( 1 − x ) log ( 1 − x ) + log ( 2 ) ) # whenever Z n is the empty set for n large enough . Combining the previous result with ( 19 ) it is clear that , under the hypotheses of Proposition 5 . 2 , the mean number of hypercycles E S ( X n ) can be written as E S ( X n ) ∼ 2 n − m n e nI γ P n − 1 = exp { n ( I γ − ( 1 / γ − 1 ) log ( 2 ) } P n − 1 P n begin a function of n which is at most polynomial , i . e . 1 n log ( P n ) = o ( 1 ) ( as n → + ∞ ) . Hence , if I γ > ( 1 / γ − 1 ) log ( 2 ) , it follows that E S ( X n ) diverges exponentially in n as n goes to + ∞ , while if I γ = ( 1 / γ − 1 ) log ( 2 ) it is sub – exponential , that is for some b ≥ 0 , E S ( X n ) / n B goes to zero as n diverges . In point of fact we have the following Lemma 5 . 3 If R [ 0 , + ∞ ) tdF ( t ) < + ∞ then sup x ∈ [ 0 , 1 ] Θ γ ( x ) > Θ γ ( 0 ) = „ 1 γ − 1 « log ( 2 ) . ( 22 ) If log ( x ) Z [ 0 , + ∞ ) te − 2 xt dF ( t ) ! − 1 = o ( 1 ) ( x → 0 ) ( 23 ) then there exists a γ c such that for any γ ≤ γ c sup x ∈ [ 0 , 1 ] Θ γ ( x ) = Θ γ ( 0 ) = „ 1 γ − 1 « log ( 2 ) . ( 24 ) while for γ > γ c sup x ∈ [ 0 , 1 ] Θ γ ( x ) > Θ γ ( 0 ) = „ 1 γ − 1 « log ( 2 ) . ( 25 ) In particular , if 1 − F ( t ) = t − β L ( t ) ( 26 ) with 0 < β < 1 and L a slowly varying function then ( 23 ) holds true . In other words , under the hypotheses of Proposition 5 . 2 , if ( 23 ) holds true , then there exists a constant 0 < γ c < 1 such that lim n → + ∞ E S ( X n ) / n b =  0 for some b = b ( γ ) ≥ 0 if γ ≤ γ c + ∞ for every b ≥ 0 if γ > γ c That is , the above mentioned threshold property holds . 14 6 Other Models In this short section we give some comments about the other two models presented in Subsections 2 . 2 - 2 . 3 . 6 . 1 Completely exchangeable graphs Most of the properties and quantities discussed above can be easily established for the totally ex - changeable case . Again , µ n : = Q { X ( n ) i , j = 1 } = R [ 0 , 1 ] θπ n ( dθ ) , and , for instance , the degree distribu - tions ( for a square adjacency matrix ) , are given by Q { S n , i = k } = Q { Z n , j = k } = n k ! Z [ 0 , 1 ] θ k ( 1 − θ ) n − k π n ( dθ ) , Hence , for instance , we have the following Proposition 6 . 1 If ( T n ) n ≥ 1 converges in distribution to a random variable T with distribution func - tion F , then , for every integer j ≥ 1 , lim n → + ∞ Q { S n , j = k } = E » 1 k ! T k e − T – = Z + ∞ 0 t k k ! e − t dF ( t ) ( k = 0 , 1 , . . . ) and lim n → + ∞ Q { Z n , j = k } = E » 1 k ! T k e − T – = Z + ∞ 0 t k k ! e − t dF ( t ) ( k = 0 , 1 , . . . ) . For this model , quantities such as the mean number of subgraphs , roots , leaves , are again easily computed analytically along the same lines described above . For example , for motifs Q { H ∈ G n } = Z [ 0 , 1 ] θ m π ( dθ ) . when H = { i 1 → i ( 1 , 1 ) , . . . , i 1 → i ( 1 , m 1 ) , i 2 → i ( 2 , 1 ) , . . . , i k → i ( k , 1 ) , . . . , i k → i ( k , m k ) } with P ki = 1 m i = m . Hence , E Q ( N H ( G n ) ) = N ( H ) Q { H ∈ G n } . Finally , throwing triangular matrices with the same algorithm , one can easily generate models for undirected graphs . 6 . 2 Hierarchical models One interesting use of this variant is that it can be exploited to produce directed graphs having power - law tailed in - and out - degree distributions with diﬀerent exponents . To illustrate this point , we will consider the following example . Example 5 If γ > β > 2 , A > 0 , λ n ( dα ) ∝ I [ A , n / 2 ] α − γ dα and π n ( dθ | α ) ∝ I ( α / n , 1 ] θ − β dθ , then Q ∗ { S n , 1 = k } ∼ c 1 k − β and Q ∗ { Z n , 1 = k } ∼ c 2 k − γ . Indeed , it is easy to check ( by means of a usual dominated convergence argument ) that lim k → + ∞ Q ∗ { S n , 1 = k } = ( β − 1 ) ( γ − 1 ) A γ − 1 k ! Z + ∞ A Z + ∞ α α β − γ − 1 t k − β e − t dtdα and , moreover , ( β − 1 ) ( γ − 1 ) A γ − 1 k ! Z + ∞ A Z + ∞ α α β − γ − 1 t k − β e − t dtdα = γ − 1 γ − β p A , β ( k ) − β − 1 γ − β p A , γ ( k ) . In the same way it is easy to check that lim k → + ∞ Q ∗ { Z n , 1 = k } = p u , γ ( k ) with u = A ( β − 1 ) / ( β − 2 ) . 15 7 A simple two parameters model In this section , we focus our attention on random graphs generated by assuming ( 2 ) and we shall specialize the results of previous sections to this two parameters model . This model has been suggested by a biological application . Hence , before presenting the results , we brieﬂy recall the main features of a transcription network . Transcription networks are directed graphs that represent regulatory interactions between genes . Speciﬁcally , the link a → b exists if the protein coded by gene a aﬀects the transcription of gene b in mRNA form by binding along DNA in a site upstream of its coding region [ 3 ] . For a few organisms , such as E . coli and S . cerevisiae , a signiﬁcant fraction of the wiring diagram of this network is known [ 35 , 29 , 52 , 30 ] . The topological features of the graphs can be studied to infer information on the large - scale architecture and evolution of gene regulation in living systems . For instance , the connectivity and the clustering coeﬃcient have been considered [ 29 ] . For this kind of analysis one has to consider null ensembles of random networks with some topological invariant compared to the empirical case . The idea behind it is to establish when and to what extent the empirical topology deviates from the “typical case” statistics of the null ensemble . For example , a topological feature that has lead to relevant biological ﬁndings , in particular for transcription , is the occurrence of small subgraphs - or “network motifs” [ 41 , 42 , 58 , 59 ] . As usual in statistical studies , the choice of the invariant properties for the randomized coun - terpart is delicate . For instance , the null ensemble used to for motif discovery usually conserves the degree sequences of the original network . The observed degree sequences for the known transcription networks roughly follow a power - law distribution for the outdegree , with exponent between one and two , while being Poissonian in the indegree [ 29 , 17 ] . These features suggest to consider also alterna - tive null models for directed random graphs with poisson in degree distribution and ( approximately ) power - law out - degree distribution , which can be easily generated with our model under ( 2 ) . In the remainder of the paper , we will discuss this case in more detail , showing explicit calculations of the observables discussed in the previous sections . 7 . 1 In and out connectivity By simple calculations from ( 2 ) , we get If 1 < β < 2 , then µ n = ( β − 1 ) α β − 1 ( 2 − β ) n β − 1 1 − ` α n ´ 2 − β 1 − ` αn ´ 1 − β = 1 n β − 1 α β − 1 ( β − 1 ) 2 − β [ 1 + o ( 1 ) ] as n → + ∞ . If β = 2 , then µ n = α n − α ( log n − log α ) = log n n α [ 1 + o ( 1 ) ] as n → + ∞ . If β > 2 , then µ n = ( β − 1 ) ( β − 2 ) ` nα ´ β − 2 − 1 ` nα ´ β − 1 − 1 = 1 n α ( β − 1 ) β − 2 [ 1 + o ( 1 ) ] as n → + ∞ . The next proposition , which is a consequence of Proposition 3 . 1 , shows that S n , i is asymp - totically power - law distributed . While Z n , i , at least with a suitable choice of m n , is asymptotically Poisson distributed . One has to distinguish among the diﬀerent possible scalings for µ n . More pre - cisely , we have the following Proposition 7 . 1 Assume that ( 2 ) holds true . Then , for every α > 0 and β > 1 , lim n → + ∞ P { S n , j = k } = p α , β ( k ) ( j > 0 , k ≥ 0 ) . 16 Moreover , if β > 2 and m n = [ δn ] ( δ ∈ ( 0 , 1 ] , [ y ] being the integer part of y ) lim n → + ∞ P { Z m n , j = k } = e − λ λ k k ! ( j > 0 , k ≥ 0 ) , where λ = δα ( β − 1 ) ( β − 2 ) . If β = 2 and m n = [ δn / log ( n ) ] lim n → + ∞ P { Z m n , j = k } = e − δα ( δα ) k k ! ( j > 0 , k ≥ 0 ) . If 1 < β < 2 and m n = [ δn β − 1 ] lim n → + ∞ P { Z m n , j = k } = e − λ λ k k ! ( j > 0 , k ≥ 0 ) where λ = δα β − 1 ( β − 1 ) ( 2 − β ) . It is worth noticing that asking for a degree distribution that brings to an outdegree having a power - law tail with divergent mean ( β ≤ 2 ) poses a heavy constraint on the number of regulator nodes ( the rows of the matrix ) . 7 . 2 Subgraphs We will discuss mainly the case of square matrices , where calculations are simpler and conceptually equivalent . 7 . 2 . 1 k – cycles Under ( 2 ) , using ( 12 ) , if β > 2 lim n → + ∞ 1 2 E ( N C k ( G n ) ) = 1 k ! » α ( β − 1 ) ( β − 2 ) – k , if β = 2 lim n → + ∞ 1 2 ( log n ) k E ( N C k ( G n ) ) = α k k ! and if 1 < β < 2 lim n → + ∞ 1 2 n k ( 2 − β ) E ( N C k ( G n ) ) = 1 k ! „ ( β − 1 ) α β − 1 2 − β « k . 7 . 2 . 2 Triangles The feedforward loop is a classical example of “network motif” , i . e . it is overrepresented in known transcription networks . Conversely , feedback loops ( which in principle could form switches and oscil - lators ) are usually underrepresented ( “anti - motifs” ) in transcription networks [ 53 , 42 ] . Here , we evaluate , for our model , the mean number of feedback loops versus feedforward loops . Under ( 2 ) , ( 14 ) yields E N ffl ( G n ) = 6 n 3 ! ( β − 1 ) 2 [ ( n / α ) β − 1 − 1 ] 2 Z 1 α / n θ 2 − β dθ Z 1 α / n θ 1 − β dθ . Hence : If β > 3 , then lim n → + ∞ E ( N ffl ( G n ) ) = ( β − 1 ) 2 α 3 ( β − 3 ) ( β − 2 ) > 3 lim n → + ∞ E ( N fbl ( G n ) ) = ( β − 1 ) 3 α 3 ( β − 2 ) 3 . 17 If β = 3 lim n → + ∞ 1 log n E ( N ffl ( G n ) ) = α 3 . If 2 < β < 3 lim n → + ∞ 1 n 3 − β E ( N ffl ( G n ) ) = α β ( β − 1 ) 2 ( β − 1 ) ( 3 − β ) . If β = 2 lim n → + ∞ 1 n log n E ( N ffl ( G n ) ) = α 2 . Finally , if 1 < β < 2 lim n → + ∞ 1 n 5 − 2 β E ( N ffl ( G n ) ) = α 2 β − 2 ( β − 1 ) 2 ( 3 − β ) ( 2 − β ) . At this stage one can give the scaling behavior of ratio of the mean number of feedback and feedforward loops , which is E N ffl ( G n ) E N fbl ( G n ) ∼ 8 > > > > < > > > > : n β − 1 if 1 < β < 2 n / ( log n ) 2 if β = 2 n 3 − β if 2 < β < 3 log n if β = 3 λ if β > 3 where λ = 3 ( β − 2 ) 2 ( β − 3 ) − 1 ( β − 1 ) − 1 > 1 . Thus , the ffl always dominates , although there is a wide range of regimes . Note that the dominance of feedforward triangles is even stronger if one considers the rectangular adjacency matrices discussed above . For example , for 1 < β < 2 , and rectangular matrices with m n = n β − 1 , we calculate E N ffl ( G n ) E N fbl ( G n ) ∼ n . As for the variances , for instance , one obtains V ar ( N fbl ( G n ) ) ∼ 8 < : n 5 ( 2 − β ) if 1 < β < 2 ( log n ) 4 if β = 2 13 ( α β − 1 β − 2 ) 3 if β ≥ 2 . 7 . 3 Roots and leaves By simple computations , from ( 18 ) we obtain : If 1 < β < 2 then lim n 1 n 2 − β log [ E ( R i ( G n ) ) ] = − β − 1 2 − β α β − 1 and hence E ( R i ( G n ) ) ∼ e − β − 1 2 − β α β − 1 n 2 − β . If β = 2 then lim n 1 log n log [ E ( R i ( G n ) ) ] = − α and hence E ( R i ( G n ) ) ∼ 1 n α . If β > 2 then lim n E ( R i ( G n ) ) = ( 1 − e − β − 1 β − 2 α ) p α , β ( 0 ) . Analogously , from ( 17 ) , we derive : 18 If 1 < β < 2 then lim n 1 n 2 − β log [ 1 − E ( L i ( G n ) ) p α , β ( 0 ) − 1 ] = − β − 1 2 − β α β − 1 and hence E ( L i ( G n ) ) ∼ ( 1 − e − β − 1 2 − β α β − 1 n 2 − β ) p α , β ( 0 ) . If β = 2 then lim n 1 log n log [ 1 − E ( L i ( G n ) ) p α , β ( 0 ) − 1 ] = − α and hence E ( L i ( G n ) ) ∼ ( 1 − 1 n α ) p α , β ( 0 ) . If β > 2 then lim n E ( L i ( G n ) ) = ( 1 − e − β − 1 β − 2 α ) ( 1 − p α , β ( 0 ) ) . Combining all the previous statements , we get E ( L ( G n ) ) ∼ n while E ( R ( G n ) ) ∼ 8 < : n if β > 2 n 1 − α if β = 2 e − λ 2 n 2 − β if 1 < β < 2 where λ 2 = β − 1 2 − β α β − 1 . In concrete applications , these properties can be used for example to impose a well - deﬁned scaling for the roots - to - leaves ratio of the null network ensemble . 7 . 4 The hub In Section 3 . 2 , we have already explored the implications on the limit laws of the maximally connected node of a power - law distributed out - degree . Using that results under ( 2 ) , it is possible to prove an explicit limit theorem for the size of the hub . Proposition 7 . 2 For β > 2 and for every positive number x lim n → + ∞ P { H n / b n ≤ x } = e − ( α / x ) β − 1 ( 27 ) with m n = n and b n = n 1 / ( β − 1 ) . For β = 2 and for every positive number x lim n → + ∞ P { H n / b n ≤ x } = e − ( α / x ) β − 1 with m n = b n = n / log n . Finally , for 1 < β < 2 and m n = n β − 1 , lim n → + ∞ P { H n / n ≤ x } = e − ( α / x ) β − 1 I ( 0 , 1 ) ( x ) + I [ 1 , ∞ ) ( x ) for every positive x . Remark 3 ( a ) Recall that e − ( α / x ) β − 1 I [ 0 , + ∞ ) ( x ) is the Frechet type II extreme value distribution , that is one of the three kind of extreme value distributions which can arise from limit law of maximum of independent and identically distributed random variables . ( b ) Note that in the last case the limit distribution is not exactly of extreme value kind and the probability of ﬁnding a hub of size n is asymptotically ﬁnite and equal to 1 − e − ( α ) β − 1 . This concentration eﬀect was already noted in [ 31 ] for another kind of random graphs ensemble . For β > 2 one can guess that E [ H n ] ∼ n 1 / ( β − 1 ) , as claimed in [ 31 ] in the analyisis of another scale - free random graph ensemble . In point of fact , we have the following Proposition 7 . 3 If β > 2 and d is such that β − d > 1 then lim n → + ∞ E [ n − d / ( β − 1 ) H d n ] = ( β − 1 ) 2 α 2 Γ „ β − 1 − d β − 1 « . 19 7 . 5 Random linear system in GF 2 Under ( 2 ) one has F ( x ) = α β − 1 ( β − 1 ) Z x α 1 t β dt = „ 1 − α β − 1 x β − 1 « ( x > α ) . Hence , applying Lemma 5 . 3 , one has that , if 1 < β < 2 , then there exists a constant γ c ( β ) such that lim n → + ∞ E S ( X n ) / n b =  0 for some b = b ( γ ) if γ ≤ γ c ( β ) + ∞ for every b ≥ 0 if γ > γ c ( β ) While if β > 2 no threshold property holds since R + ∞ 0 xdF ( x ) < + ∞ . A Appendix Proof of Proposition 3 . 1 . Since T n : = n ˜ θ n , one has P { S n , j = k } = E " n k ! 1 n k T kn „ 1 − T n n « n ( 1 − k / n ) # = E [ φ n ( T n ) ] where φ n ( x ) = n k ! 1 n k x k ( 1 − x n ) n ( 1 − k / n ) . Now , E [ φ n ( T n ) ] = E [ φ ( T n ) ] + R n where φ ( x ) = 1 k ! x k e − x and R n = E [ φ n ( T n ) ] − E [ φ ( T n ) ] . Since φ n converges uniformly on every compact set to φ and ( T n ) n ≥ 1 is a tight sequence , one gets that for every ǫ > 0 there exists K > 0 such that lim n → + ∞ | R n | ≤ lim n → + ∞ [ sup | x | ≤ K | φ n ( x ) − φ ( x ) | + 2 P { | T n | ≥ K } ] ≤ ǫ . The ﬁrst part of the thesis then follows by the hypothesis , yielding E [ φ ( T n ) ] → E [ φ ( T ) ] . The second part of the thesis follows immediately by the classical Poisson approximation to binomial distribution . Indeed µ n = λ na n ( 1 + o ( 1 ) ) . ♦ Proof of Lemma 3 . 2 . Assume ﬁrst that γ is not an integer and let k > γ , k being an integer . By hypothesis Γ ( k + 1 ) Γ ( k − γ + 1 ) q k = Z + ∞ 0 t k − γ Γ ( k − γ + 1 ) e − t dG ( t ) where G ( x ) = R ( 0 , x ] t γ dF ( t ) . Summing both sides on k , one can write M X k = [ γ ] + 1 Γ ( k + 1 ) Γ ( k − γ + 1 ) q k = Z + ∞ 0 φ γ , M ( t ) e − t dG ( t ) with φ γ , M ( t ) : = M X k = [ γ ] + 1 x k − γ 1 Γ ( k − γ ) = M − [ γ ] − 1 X m = 0 x m + ν 1 Γ ( m + ν + 1 ) , 20 and ν : = [ γ ] + 1 − γ . Hence , M − [ γ ] − 1 X m = 0 Γ ( m + [ γ ] + 2 ) Γ ( m + ν + 1 ) q m + 1 + [ γ ] = Z + ∞ 0 φ γ , M ( t ) e − t dG ( t ) . Now , for every x > 0 , φ γ , M ( x ) ≥ 0 , and it converges monotonically to g ( γ , x ) e x as M diverges , where g ( γ , x ) = 1 Γ ( ν ) Z x 0 τ ν − 1 e − τ dτ , see 5 . 27 . 20 in [ 48 ] . Hence , taking the limit as M goes to + ∞ , by monotone convergence one obtains + ∞ X m = 0 Γ ( m + [ γ ] + 2 ) Γ ( m + ν + 1 ) q m + 1 + [ γ ] = Z + ∞ 0 g ( γ , t ) t γ dF ( t ) , with R + ∞ 0 g ( γ , t ) t γ dF ( t ) < + ∞ if and only if P + ∞ m = 0 Γ ( m + [ γ ] + 2 ) Γ ( m + ν + 1 ) − 1 q m + 1 + [ γ ] < + ∞ . Now , since g ( γ , x ) is a distribution function , one has R + ∞ 0 g ( γ , t ) t γ dF ( t ) < + ∞ if and only if R + ∞ 0 t γ dF ( t ) < + ∞ . Moreover , P + ∞ m = 0 Γ ( m + [ γ ] + 2 ) Γ ( m + ν + 1 ) − 1 q m + 1 + [ γ ] < + ∞ if and only if P + ∞ m = 0 ( m + [ γ ] + 1 ) γ q m + 1 + [ γ ] < + ∞ , which proves the lemma . The case in which γ is an integer is proven following the same outline , taking 1 in the place of g . ♦ Proof of Proposition 3 . 3 . We consider the quantity P { S n , 1 > [ xb n ] } = 1 − Z [ 0 , 1 ] [ xb n ] X k = 0 θ k ( 1 − θ ) n − k π n ( dθ ) and , since n X k = [ xb n ] + 1 θ k ( 1 − θ ) n − k = R θ 0 t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 B ( [ b n x ] + 1 , n − [ b n x ] ) dt with B ( α , β ) = R 1 0 t α − 1 ( 1 − t ) β − 1 dt = Γ ( α ) Γ ( b ) / Γ ( a + b ) , by Fubini’s theorem , it follows that P { S n , 1 > [ xb n ] } = 1 B ( [ b n x ] + 1 , n − [ b n x ] ) Z 1 0 t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 F ∗ ( t ) dt with F ∗ n ( t ) : = P { ˜ θ n > t } = Z ( t , 1 ] π n ( dθ ) . Now , by hypothesis F ∗ n ( t ) = c η , n 1 ( nt ) η + r n ( t ) . Hence , the quantity under consideration can be written as P { S n , 1 > [ xb n ] } = 1 B ( [ b n x ] + 1 , n − [ b n x ] ) c n , γ n γ Z 1 0 t [ b n x ] − γ ( 1 − t ) n − [ b n x ] − 1 dt + R n ( x ) with R n ( x ) : = 1 B ( [ b n x ] + 1 , n − [ b n x ] ) Z [ 0 , 1 ] r n ( t ) t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 = o ( 1 m n ) . 21 Then , using once more the asymptotic expression Γ ( n + a ) / Γ ( n + b ) ∼ n a − b , one obtains P { S n , 1 > [ xb n ] } = 1 m n „ c n , γ m n n γ Γ ( n + 1 ) Γ ( [ b n x ] + 1 − γ ) Γ ( n + 1 − γ ) Γ ( [ b n x ] + 1 ) + o ( 1 ) « = 1 m n „„ b n [ xb n ] « η c γ + o ( 1 ) « , which is P { S n , 1 > [ xb n ] } = 1 m n h c η x η + o ( 1 ) i . ♦ Proof of Lemma 3 . 4 . Set β n : = [ xb n ] and I n ( d ) = m n 1 B ( β n + 1 + d , n − β n ) Z α / n 0 t β n + d ( 1 − t ) n − β n − 1 dt . Hence , m n | R n ( x ) | ≤ Cm n ( 1 B ( β n + 1 , n − β n ) Z α / n 0 ( 1 + 1 / ( nt ) η ) t βn ( 1 − t ) n − β n − 1 dt + 1 n η ) ≤ C  I n ( 0 ) + I n ( − η ) B ( β n + 1 − η , n − β n ) n η B ( β n + 1 , n − β n ) + o ( 1 ) ﬀ ≤ C ˘ I n ( 0 ) + I n ( − η ) β − η n + o ( 1 ) ¯ . It remains to show that I n ( 0 ) + I n ( − η ) β − η n = o ( 1 ) . With the help of the Sirling formula , one has I n ( d ) = m n Γ ( n + 1 + d ) Γ ( β n + 1 + d ) Γ ( n − β n ) Z α / n 0 t β n + d ( 1 − t ) n − β n − 1 dt ≤ m n m n Γ ( n + 1 + d ) Γ ( β n + 1 + d ) Γ ( n − β n ) ( α / n ) β n + d − 1 ≤ C 1 m n exp { log ( α ) ( 1 + d + β n ) } ( n + 1 + d ) n + d + 1 / 2 n β n + d + 1 ( β n + 1 + d ) β n + d + 1 / 2 ( n − β n ) n − β n − 1 / 2 exp { − ( n + 1 + d ) + β n + 1 + d + n − β n } = C 1 m n exp { log ( α ) ( 1 + d + β n ) } ( 1 + 1 + dn ) n ( 1 + d + 1 / 2 n ) β β n + d + 1 / 2 n ( 1 + 1 + d β n ) β n ( 1 + d + 1 / 2 b n ) ( 1 − b n n ) n ( 1 − βn + 1 / 2 n ) ≤ C 2 m n exp { log ( α ) ( 1 + d + β n ) − log ( β n ) ( 1 / 2 + d + β n ) } [ ( 1 − β n n ) n / β n ] β n − β 2 n / n ≤ C 3 m n exp { log ( α ) ( 1 + d + β n ) − log ( β n ) ( 1 / 2 + d + β n ) + ( β n − β 2 n / n ) } ≤ C 4 exp { log ( m n ) − C 5 β n log ( β n ) } . Since β n ∼ x 1 / η m 1 / η n and m 1 / η n / n = o ( 1 ) the thesis follows easily . ♦ Proof of Lemma 3 . 5 . Assume that δ 1 = δ and δ 2 = δ . In the same notation of the proof of Proposition 3 . 3 r n ( t ) = c η F ( n ) n η ( 1 + h ( n ) ) + c η h ( nt ) F ( n ) ( nt ) η Now R n : = R n ( x ) = 1 B ( [ b n x ] + 1 , n − [ b n x ] ) Z [ 0 , 1 ] r n ( t ) t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 dt = R ( 1 ) n + R ( 2 ) n with R ( 1 ) n = c η ( 1 + h ( n ) ) F ( n ) n η 1 B ( [ b n x ] + 1 , n − [ b n x ] ) Z [ 0 , 1 ] t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 dt = c η ( 1 + h ( n ) ) F ( n ) n η = o ( m − 1 n ) 22 and R ( 2 ) n = 1 B ( [ b n x ] + 1 , n − [ b n x ] ) Z [ 0 , 1 ] t [ b n x ] ( 1 − t ) n − [ b n x ] − 1 c η h ( nt ) F ( n ) ( nt ) η dt . Finally | R ( 2 ) n | ≤ c η 2 A n δ + η B ( [ b n x ] + 1 , n − [ b n x ] ) Z [ 0 , 1 ] t [ b n x ] − ( η + δ ) ( 1 − t ) n − [ b n x ] − 1 ≤ c η 2 AB ( [ b n x ] + 1 − η − δ , n − [ b n x ] ) n δ + η B ( [ b n x ] + 1 , n − [ b n x ] ) ≤ c η 2 A Γ ( [ b n x ] + 1 − η − δ ) Γ ( n + 1 ) n δ + η Γ ( n + 1 − η − δ ) Γ ( [ b n x ] + 1 ) ≤ c η 2 A ′ ( n + 1 ) δ + η n δ + η ( [ b n x ] + 1 ) δ + η ≤ c η 2 A ′ 2 δ + η „ b n [ b n x ] « δ + η 1 b δ + η n . for a suitable constant A ′ , hence , since b ηn = m n , | R ( 2 ) n | = o ( m − 1 n ) . The general case follows in the same way . ♦ Proof of Proposition 4 . 1 . If Y ( n ) = P ni = 1 Y i , n with Y i , n = I { S n , i = 0 , Z n , i = 0 } , then P { G n is connected } ≤ P { Y ( n ) = 0 } ≤ V ar ( Y ( n ) ) E ( Y 2 ( n ) ) = 1 − E ( Y ( n ) ) 2 E ( Y 2 ( n ) ) . Since E ( Y ( n ) ) = n E ( Y 1 , n ) = nP { S n , i = 0 , Z n , i = 0 } and E ( Y ( n ) 2 ) = n E ( Y 21 , n ) + n ( n − 1 ) E ( Y 1 , n Y 2 , n ) = nP { S n , 1 = 0 , Z n , 1 = 0 } + n ( n − 1 ) P { S n , 1 = 0 , Z n , 1 = 0 , S n , 2 = 0 , Z n , 2 = 0 } = n ( 1 − µ n ) n − 1 P { S n , 1 = 0 } + n ( n − 1 ) ( 1 − µ n ) 2 n − 2 P { S n , 1 = 0 } 2 , we get P { G n is connected } ≤ 1 − ( 1 − µ n ) 2 n − 2 P { S n , 1 = 0 } 2 n − 1 n ( 1 − µ n ) 2 n − 2 P { S n , 1 = 0 } 2 + 1 n ( 1 − µ n ) n − 1 P { S n , 1 = 0 } . Taking the limit for n → + ∞ gives the thesis . ♦ Proof of Proposition 5 . 1 . Denote by M ( m n , n ) the set of all m n × n – adjacency matrices . The number of solutions of linear system X Tn x = 0 is deﬁned as N ( X n ) = X x ∈ GF mn 2 I { X T n = GF 2 0 } hence , noting that I { x = GF 2 0 } = 1 + ( − 1 ) x 2 and denoting by p a density for X n , one has E N ( X n ) = X A n ∈ M ( m n , n ) p ( A n ) X x ∈ GF mn 2 n Y j = 1 1 + ( − 1 ) P mni = 1 ( A n ) ij x i 2 . Using ( 1 ) rewrite the last expression as E N ( X n ) = 2 − n X x ∈ GF mn 2 X A n ∈ M ( m n , n ) Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # " n Y j = 1 “ 1 + ( − 1 ) P mni = 1 ( A n ) ij x i ” # " n Y j = 1 m n Y i = 1 θ ( A n ) ij i ( 1 − θ i ) 1 − ( A n ) ij # = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn m n Y i = 1 π n ( dθ i ) 2 4 n Y j = 1 X ( A n ) j ∈ GF mn 2 “ 1 + ( − 1 ) P mn i = 1 ( A n ) ij x i ” m n Y i = 1 θ ( A n ) ij i ( 1 − θ i ) 1 − ( A n ) ij 3 5 23 where ( A n ) j = { ( A n ) 1 j , . . . , ( A n ) m n j } and ( A n ) ij is the element in position ( i , j ) of matrix A n . Since the above expression in square brackets is independent of j , E N ( X n ) can be written as E N ( A n ) = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # 2 4 X a ∈ GF mn 2 “ 1 + ( − 1 ) P mni = 1 a i x i ” m n Y i = 1 θ a i i ( 1 − θ i ) 1 − a i 3 5 n . At this stage note that X a ∈ GF mn 2 m n Y i = 1 θ a i i ( 1 − θ i ) 1 − a i = 1 and then E N ( X n ) = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # 2 4 1 + X a ∈ GF mn 2 ( − 1 ) P mni = 1 a i x i m n Y i = 1 θ a i i ( 1 − θ i ) 1 − a i 3 5 n = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # 2 4 1 + m n Y i = 1 X a i ∈ GF 2 ( ( − 1 ) x i θ i ) a i ( 1 − θ i ) 1 − a i 3 5 n and after summing over a i we have E N ( X n ) = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # " 1 + m n Y i = 1 ( 1 − θ i ( 1 − ( − 1 ) x i ) ) # n . ( 28 ) Now , using I { ¯ x = GF 2 0 } = 1 − ( − 1 ) x 2 where ¯ x = x + 1 in GF 2 , expression ( 28 ) can be written as E N ( X n ) = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # " 1 + m n Y i = 1 ( 1 − 2 θ i I { ¯ x i = GF 2 0 } ) # n . Moreover , since ( 1 − 2 θ i I { ¯ x i = GF 2 0 } ) = ( 1 − 2 θ i ) I { ¯ x i = GF 2 = 0 } we can rewrite the mean number as E N ( X n ) = 2 − n X x ∈ GF mn 2 Z [ 0 , 1 ] mn " m n Y i = 1 π n ( dθ i ) # " 1 + m n Y i = 1 ( 1 − 2 θ i ) I { ¯ x i = GF 2 0 } # n . After the expansion of the last square bracket we obtain E N ( A n ) = 2 − n n X j = 1 n j ! m n Y i = 1 X x i ∈ GF 2 Z [ 0 , 1 ] π n ( dθ i ) ( 1 − 2 θ i ) I { ¯ x i = GF 2 0 } j = 2 − n n X j = 1 n j ! m n Y i = 1 X x i ∈ GF 2 ξ n ( I { ¯ x i = GF 2 0 } j ) . Finally , it is easy to see that the last sum is independent of i . Then E N ( A n ) = 2 − n n X j = 1 n j ! 2 4 X σ ∈ GF 2 ξ n ( I { ¯ σ = GF 2 0 } j ) 3 5 m n = 2 − n n X j = 1 n j ! ( 1 + ξ n ( j ) ) m n . 24 ♦ Proof Proposition 5 . 2 . First of all , observe that E N ( A n ) = n X j = 1 2 − n n j ! exp { nψ n ( j / n ) } where ψ n ( x ) = m n n log ( 1 + ξ n ( xn ) ) = m n n log ( 1 + E [ ( 1 − 2 T n n ) xn ] ) . Now recall that one of the most classical example of large deviation estimate is lim M → + ∞ 1 M log M X j = 0 M j ! e Mf M ( j / M ) ! = sup x ∈ [ 0 , 1 ] [ f ( x ) − { x log ( x ) + ( 1 − x ) log ( 1 − x ) + log ( 2 ) } ] whenever lim M → + ∞ sup x ∈ [ 0 , 1 ] | f M ( x ) − f ( x ) | = 0 , f being a continuous function on [ 0 , 1 ] . See , e . g . , Theorem 7 . 1 and 10 . 2 in [ 20 ] . Hence , the thesis follows if we prove that for every K < + ∞ lim n → + ∞ sup | x | ≤ K | ψ n ( x ) − 1 γ log 1 + Z [ 0 , + ∞ ) e − 2 xt dF ( t ) ! | = 0 . ( 29 ) To prove ( 29 ) it is enough to prove that for every K < + ∞ lim M → + ∞ sup | x | ≤ K | E [ ( 1 − 2 T M M ) Mx − e − 2 Tx ] | = 0 . ( 30 ) Since T M converges weakly to T and e − t is a bounded and continuous function on [ 0 , + ∞ ) , then lim M → + ∞ E | e − 2 T M − e − 2 T | = 0 . ( 31 ) Moreover we claim that lim M → + ∞ E [ | ( 1 − 2 T M M ) M − e − 2 T M | = 0 . ( 32 ) To prove this last claim , set φ n ( x ) = ( 1 − xn ) n and note that φ n converges uniformly on every compact set to e − x . Hence , given K , lim M sup | x | ≤ K | φ M ( x ) − e − x | = 0 . Moreover , since ( T M ) M is tight , for every ǫ there exists K > 0 such that sup M P { | T M | ≥ K } ≤ ǫ . Now | ( 1 − 2 T M M ) M − e − 2 T M | ≤ 2 and then lim M → + ∞ E [ | ( 1 − 2 T M M ) M − e − 2 T M | ≤ lim M → + ∞ [ sup | x | ≤ K | φ M ( x ) − φ ( x ) | + 2 P { | T M | ≥ K } ] ≤ 2 ǫ . That is ( 32 ) . Finally , given a , b in [ − 1 , 1 ] and x > 0 | a x − b x | ≤ sup y ∈ [ − 1 , 1 ] | d dyy x | | a − b | = x | a − b | , hence , since 0 < T M ≤ M , one has − 1 ≤ 1 − 2 T M M ≤ 1 and then | E [ ( 1 − 2 T M M ) Mx − e − 2 Tx ] | ≤ E [ | ( 1 − 2 T M M ) Mx − e − 2 T M x | + E | e − 2 T M x − e − 2 Tx | ] ≤ | x | { E [ | ( 1 − 2 T M M ) M − e − 2 T M | + E | e − 2 T M − e − 2 T | } . ( 33 ) Combining ( 31 ) , ( 32 ) and ( 33 ) we get ( 30 ) . ♦ 25 Proof of Lemma 5 . 3 . Note that , for every x in ( 0 , 1 ) , γ ˙Θ γ ( x ) = 2 R [ 0 , + ∞ ) te − 2 xt dF ( t ) 1 + R [ 0 , + ∞ ) e − 2 xt dF ( t ) − γ log x + γ log ( 1 − x ) . Hence , if R [ 0 , + ∞ ) tdF ( t ) < + ∞ then lim x → 0 + ˙Θ ( x ) = + ∞ and then , Θ is strictly increasing in a neighborhood of 0 . This last fact implies that sup x ∈ [ 0 , 1 ] Θ γ ( x ) > Θ γ ( 0 ) = „ 1 γ − 1 « log ( 2 ) . While if ( 23 ) holds true then lim x → 0 + ˙Θ γ ( x ) = −∞ , and hence , there exists γ c such that for any γ ≤ γ c sup x ∈ [ 0 , 1 ] Θ γ ( x ) = Θ γ ( 0 ) = „ 1 γ − 1 « log ( 2 ) . Now set A ( x ) = Z x 0 tdF ( t ) , and H ( s ) : = Z + ∞ 0 te − ts dF ( t ) = Z + ∞ 0 e − ts dA ( t ) . The well – known Karamata tauberian theorem ( see , e . g . [ 24 ] ) yields that , given σ > 0 and L slowly varying , H ( s ) ∼ s − σ L ( 1 / s ) as s goes to 0 if and only if A ( x ) ∼ x σ L ( x ) / Γ ( 1 + σ ) as x goes to + ∞ . Hence , it remains to prove that if ( 26 ) holds true then A ( x ) ∼ x σ L ( x ) / Γ ( 1 + σ ) . Observe that A ( x ) = − L ( x ) x 1 − β + Z x 0 s − β L ( s ) ds . At this stage the claim follows since it is easy to check that R x 0 s − β L ( s ) ds = x 1 − β ˜ L ( x ) , where ˜ L ( x ) is still slowly varying . ♦ Proof of Proposition 7 . 2 . Let β > 2 . In the same notation of the proof of Proposition 3 . 3 , F ∗ n ( t ) = I { α / n ≤ t } α β − 1 n β − 1 − α β − 1 ( t 1 − β − 1 ) + I { α / n > t } , hence η = β − 1 , c n , γ = α β − 1 1 − n 1 − β → c γ = α β − 1 and r n ( t ) = I { α / n > t } „ 1 − 1 ( nt ) β − 1 α β − 1 1 − ( α / n ) β − 1 « − I { α / n ≤ t } 1 n β − 1 α β − 1 1 − ( α / n ) β − 1 . The thesis follows by Proposition 3 . 3 and Lemma 3 . 4 noticing that | r n ( t ) | ≤ C „ ( 1 ( nt ) β − 1 + 1 ) I { α / n > t } + 1 n β − 1 « . Arguing essentially in the same way one can prove the statements for β ≤ 2 . ♦ Proof of Proposition 7 . 3 . We begin with the case d = 1 . In Proposition 7 . 2 we have just proved that ( Y n ) n ≥ 1 : = ( H n / n γ ) n ≥ 1 converges in distribution with γ = 1 / ( β − 1 ) . So , it is enough to prove that ( Y n ) is uniformly integrable , i . e . lim L → + ∞ sup n E [ | Y n | I | Y n | ≥ L ] = 0 . See for instance Lemma 4 . 11 in [ 33 ] . Note , ﬁrst , that E [ | Y n | I | Y n | ≥ L ] = LP { H n / n γ > L } + Z + ∞ L ( 1 − P { H n / n γ ≤ x } ) dx . 26 Now by ( 27 ) LP { H n / n γ > L } ≤ C 1 L ( 1 − e − α β − 1 L β − 1 ) = o ( 1 ) for a suitable constant C 1 . As for the second term , setting F S n ( x ) = P { S n ≤ x } , one has 1 − P { H n / n γ ≤ x } = 1 − [ F S n ( xn γ ) ] n = 1 − exp { n log ( F S n ( xn γ ) ) } [ using 1 − e x ≤ − x ] ≤ − n log ( 1 − ( 1 − F S n ( xn γ ) ) ) ≤ ( 1 + C 2 ) n ( 1 − F S n ( xn γ ) ) . Hence , Z + ∞ L ( 1 − P { H n / n γ ≤ x } ) dx ≤ ( 1 + C 2 ) Z + ∞ L n ( 1 − F S n ( xn γ ) ) dx = : I n . Since 1 − F S n ( xn γ ) = 0 if xn γ > n , that is if x ≥ n β − 2 β − 1 , I n = ( β − 1 ) ( 1 + C 2 ) n n β − 1 ( 1 α β − 1 − 1 n β − 1 ) Z n β − 2 β − 1 L Z 1 α / n n X k = [ xn γ ] + 1 n k ! θk − β ( 1 − θ ) n − k dθdx Now , if L > ( β − 1 ) / n γ then [ xn γ ] + 1 > 0 for every x > L , hence I n ≤ C 3 n 2 − β Z n β − 2 β − 1 L n X k = [ xn γ ] + 1 n k ! B ( n − k + 1 , k − β + 1 ) dx = C 3 n 2 − β Z n β − 2 β − 1 L Γ ( n + 1 ) Γ ( n − β + 2 ) n X k = [ xn γ ] + 1 Γ ( k − β + 1 ) Γ ( k + 1 ) dx ≤ C 4 n Z n β − 2 β − 1 L n X k = [ xn γ ] + 1 1 k β dx at least for L large enough . Since , n X k = M 1 k β ≤ Z n M − 1 1 x β dx it follows that I n ≤ C 4 Z + ∞ L „ 1 [ xn γ ] « dx ≤ C 5 1 ( L − 1 ) β − 2 = o ( 1 ) . The proof of the case with d > 1 follows an identical procedure , with x 1 / d in place of x and L 1 / d in place of L . ♦ Acknowledgments We would like to thank Bruno Bassetti for useful discussions and for having encouraged us during this work . References [ 1 ] W . Aiello , F . Chung , and L . Lu . A random graph model for power law graphs . Experiment . Math . , 10 : 53 – 66 , 2001 . 27 [ 2 ] W . Aiello , F . Chung , and L . Lu . Random evolution in massive graphs . In Handbook of massive data sets , volume 4 of Massive Comput . , pages 97 – 122 . Kluwer Acad . Publ . , Dordrecht , 2002 . [ 3 ] M . Babu , N . Luscombe , L . Aravind , M . Gerstein , and S . Teichmann . Structure and evolution of transcriptional regulatory networks . Curr . Opin . Struct . Biol . , 14 : 283 – 291 , 2004 . [ 4 ] A . Barabasi and R . Albert . Emergence of scaling in random networks . Science , 286 : 509 – 512 , 1999 . [ 5 ] F . Bassetti , M . Cosentino Lagomarsino , B . Bassetti , and P . Jona . Random networks tossing biased coins . Phys . Rev . E , 75 , 2007 . [ 6 ] B . Bollob´as . Random graphs , volume 73 of Cambridge Studies in Advanced Mathematics . Cam - bridge University Press , Cambridge , second edition , 2001 . [ 7 ] B . Bollob´as , C . Borgs , J . Chayes , and O . Riordan . Directed scale - free graphs , 2003 . [ 8 ] B . Bollob´as and O . Riordan . Robustness and vulnerability of scale - free random graphs . Internet Math . , 1 ( 1 ) : 1 – 35 , 2003 . [ 9 ] B . Bollob´as and O . Riordan . Coupling scale - free and classical random graphs . Internet Math . , 1 ( 2 ) : 215 – 225 , 2004 . [ 10 ] B . Bollob´as and O . Riordan . The diameter of a scale - free random graph . Combinatorica , 24 ( 1 ) : 5 – 34 , 2004 . [ 11 ] B . Bollob´as and O . M . Riordan . Mathematical results on scale - free random graphs . In Handbook of graphs and networks , pages 1 – 34 . Wiley - VCH , Weinheim , 2003 . [ 12 ] Y . Chen , P . Diaconis , S . P . Holmes , and J . S . Liu . Sequential Monte Carlo methods for statistical analysis of tables . J . Amer . Statist . Assoc . , 100 ( 469 ) : 109 – 120 , 2005 . [ 13 ] F . Chung and L . Lu . The average distance in a random graph with given expected degrees . Internet Math . , 1 ( 1 ) : 91 – 113 , 2003 . [ 14 ] F . Chung and L . Lu . The small world phenomenon in hybrid power law graphs . In Complex networks , volume 650 of Lecture Notes in Phys . , pages 89 – 104 . Springer , Berlin , 2004 . [ 15 ] F . Chung and L . Lu . Complex graphs and networks , volume 107 of CBMS Regional Confer - ence Series in Mathematics . Published for the Conference Board of the Mathematical Sciences , Washington , DC , 2006 . [ 16 ] F . Chung and L . Lu . The volume of the giant component of a random graph with given expected degrees . SIAM J . Discrete Math . , 20 ( 2 ) : 395 – 411 ( electronic ) , 2006 . [ 17 ] M . Cosentino Lagomarsino , B . Bassetti , and P . Jona . The Large - scale Logico - chemical Structure of a Transcription Network . In Soft Condensed Matter : New Research . Nova Science Publishers , 2005 . ( q - bio . MN / 0502017 ) . [ 18 ] H . Cram´er . On asymptotic expansions for sums of independent random variables with a limiting stable distribution . Sankhy¯a Ser . A 25 ( 1963 ) , 13 - 24 ; addendum , ibid . , 25 : 216 , 1963 . [ 19 ] R . Durrett . Random graph dynamics . Cambridge Series in Statistical and Probabilistic Mathe - matics . Cambridge University Press , Cambridge , 2007 . [ 20 ] R . S . Ellis . The Theory of Large Deviation and Applications to Statistical Mechanics . 2006 . Lectures for the international seminar on Extreme Events in Complex Dynamics . http : / / www . math . umass . edu / ˜ rsellis / pdf - ﬁles / Dresden - lectures . pdf Max - Planck - Institut . [ 21 ] P . Erd˝os and A . R´enyi . On random matrices . Magyar Tud . Akad . Mat . Kutat´o Int . K¨ozl , 8 : 455 – 461 ( 1964 ) , 1964 . [ 22 ] P . Erd˝os and A . R´enyi . On random matrices . II . Studia Sci . Math . Hungar . , 3 : 459 – 464 , 1968 . [ 23 ] W . Feller . On probability problems in the theory of counters . In Studies and Essays Presented to R . Courant on his 60th Birthday , January 8 , 1948 , pages 105 – 115 . Interscience Publishers , Inc . , New York , 1948 . 28 [ 24 ] W . Feller . An introduction to probability theory and its applications . Vol . II . Second edition . John Wiley & Sons Inc . , New York , 1971 . [ 25 ] S . Fortini , L . Ladelli , and E . Regazzini . A central limit problem for partially exchangeable random variables . Teor . Veroyatnost . i Primenen . , 41 ( 2 ) : 353 – 379 , 1996 . [ 26 ] J . Galambos . The asymptotic theory of extreme order statistics . Robert E . Krieger Publishing Co . Inc . , Melbourne , FL , second edition , 1987 . [ 27 ] I . S . Gradshteyn and I . M . Ryzhik . Table of integrals , series , and products . Academic Press Inc . , San Diego , CA , sixth edition , 2000 . [ 28 ] J . Grandell . Mixed Poisson processes , volume 77 . Chapman & Hall , London , 1997 . [ 29 ] N . Guelzim , S . Bottani , P . Bourgine , and K . Kepes . Topological and causal structure of the yeast transcriptional regulatory network . Nat . Genet . , 31 : 60 – 63 , 2002 . [ 30 ] C . Harbison and al . . Transcriptional regulatory code of a eukaryotic genome . Nature , 431 : 99 – 104 , 2004 . [ 31 ] S . Itzkovitz , R . Milo , N . Kashtan , G . Ziv , and U . Alon . Subgraphs in random networks . Phys Rev E Stat Nonlin Soft Matter Phys , 68 ( 2 Pt 2 ) : 026127 , 2003 . [ 32 ] O . Johnson and R . Samworth . Central limit theorem and convergence to stable laws in Mallows distance . Bernoulli , 11 ( 5 ) : 829 – 845 , 2005 . [ 33 ] O . Kallenberg . Foundations of modern probability . Probability and its Applications ( New York ) . Springer - Verlag , New York , second edition , 2002 . [ 34 ] V . F . Kolchin . Random graphs , volume 53 of Encyclopedia of Mathematics and its Applications . Cambridge University Press , Cambridge , 1999 . [ 35 ] T . Lee and al . Transcriptional regulatory networks in saccharomyces cerevisiae . Science , 298 : 799 , 2002 . [ 36 ] A . A . Levitskaya . Systems of random equations over ﬁnite algebraic structures . Kibernet . Sistem . Anal . , 41 ( 1 ) : 82 – 116 , 190 , 2005 . [ 37 ] D . J . C . MacKay . Good error - correcting codes based on very sparse matrices . Information Theory , IEEE Transactions , 45 : 399 – 431 , 1999 . [ 38 ] S . Matias , C . amd Schbath , E . Birmela , J . J . Daudin , and S . Robin . Networks motifs : mean and variance for the count . Rev . Stat . , page 31 , 2006 . [ 39 ] M . M´ezard , G . Parisi , and R . Zecchina . Analytic and algorithmic solution of random satisﬁability problems . Science , 297 : 812 , 2002 . [ 40 ] M . Mezard , F . Ricci - Tersenghi , and R . Zecchina . Alternative solutions to diluted p - spin models and xorsat problems . J . STAT . PHYS . , 111 : 505 , 2003 . [ 41 ] R . Milo and al . . Network motifs : Simple building blocks of complex networks . Science , 298 : 824 – 827 , 2002 . [ 42 ] R . Milo and al . Superfamilies of evolved and designed networks . Nova Science Publishers , Science ( 303 ) : 1538 – 1542 , 2004 . [ 43 ] J . M . Montoya , S . L . Pimm , and R . V . Sole . Abstract ecological networks and their fragility . Nature , 442 : 259 – 264 , 2006 . [ 44 ] T . Murayama and M . Okada . One step rsb scheme for the rate distortion function . J . Phys . , 36 : 11123 – 11130 , 2003 . [ 45 ] M . E . J . Newman . Random graphs as models of networks . In Handbook of graphs and networks , pages 35 – 68 . Wiley - VCH , Weinheim , 2003 . [ 46 ] M . E . J . Newman . The structure and function of complex networks . SIAM Rev . , 45 ( 2 ) : 167 – 256 ( electronic ) , 2003 . 29 [ 47 ] M . E . J . Newman , A . L . Barabasi , and D . J . Watts . The Structure and Dynamics of Networks . Princeton University Press , Melbourne , FL , 2006 . [ 48 ] A . P . Prudnikov , Yu . A . Brychkov , and O . I . Marichev . Integrals and series . Vol . 1 . Gordon & Breach Science Publishers , New York , 1986 . [ 49 ] P . S . Puri and C . M . Goldie . Poisson mixtures and quasi - inﬁnite divisibility of distributions . J . Appl . Probab . , 16 ( 1 ) : 138 – 153 , 1979 . [ 50 ] A . Rao , R . Jana , and S . Bandyopadhyay . A markov chain monte carlo method for generating random ( 0 , 1 ) - matrices with given marginals . Sankhy¯a , 58 ( A ) : 225 – 242 , 1996 . [ 51 ] E . Regazzini and V . V . Sazonov . On the central limit problem for partially exchangeable random variables with values in a Hilbert space . Teor . Veroyatnost . i Primenen . , 42 ( 4 ) : 796 – 812 , 1997 . [ 52 ] H . Salgado and al . Regulondb ( version 3 . 2 ) : transcriptional regulation and operon organization in escherichia coli k - 12 . Nucleic Acids Res . , 29 : 72 – 74 , 2001 . [ 53 ] S . Shen - Orr , R . Milo , S . Mangan , and U . Alon . Network motifs in the transcriptional regulation network of escherichia coli . Nat . Genet . , 31 : 64 – 68 , 2002 . [ 54 ] F . W . Steutel and K . van Harn . Inﬁnite divisibility of probability distributions on the real line , volume 259 . Marcel Dekker Inc . , New York , 2004 . [ 55 ] S . H . Strogatz . Exploring complex networks . Nature , 410 : 268 – 276 , 2001 . [ 56 ] D . J . Watts and S . H . Strogatz . Collective dynamics of ”small – world” networks . Nature , 393 : 440 – 442 , 1998 . [ 57 ] Gordon E . Willmot . Asymptotic tail behaviour of Poisson mixtures with applications . Adv . in Appl . Probab . , 22 ( 1 ) : 147 – 159 , 1990 . [ 58 ] D . Wolf and A . Arkin . Motifs , modules and games in bacteria . Curr . Opin . Microbiol . , 6 : 125 , 2003 . [ 59 ] E . Yeger - Lotem , S . Sattath , N . Kashtan , S . Itzkovitz , R . Milo , R . Y . Pinter , U . Alon , and H . Mar - galit . Network motifs in integrated cellular networks of transcriptionregulation and proteinprotein interaction . Proc . Natl . Acad . Sci . U S A , 101 ( 16 ) : 5934 – 5939 , 2004 . 30