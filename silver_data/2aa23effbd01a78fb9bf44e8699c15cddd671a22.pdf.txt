A Programmatic Deﬁnition of Visualization Tasks , Insights , and Objectives Leilani Battle and Alvitta Ottley Abstract — Researchers have developed several theoretical models for identifying and categorizing data analysis tasks for visualization systems . However , these models focus primarily on abstraction or generalizing speciﬁc tasks into higher - level concepts , resulting in broad guidelines that are not always straightforward to implement within visualization systems . Few models ﬂow in the opposite direction to enable instantiation or a precise approach to applying high - level task concepts to speciﬁc analysis scenarios or user interaction logs . This paper presents a synthesis of existing task theory into a new instantiation - focused model and Pyxis , a speciﬁcation language for applying this model to existing evaluation methods . Speciﬁcally , Pyxis enables researchers to dissect theoretical and study - driven analysis sessions to identify instances of tasks that users have performed . Further , it formalizes the relationship between tasks , insights , and objectives implied in prior work . We present three use cases that apply Pyxis to a wide range of analysis scenarios from the literature to demonstrate its utility . Finally , we discuss the model’s implications and opportunities for future work . Index Terms —Visualization models , task analysis , declarative speciﬁcation . 1 I NTRODUCTION It is generally considered best practice to design visualization tools around speciﬁc tasks that analysts seek to perform [ 36 ] . Many tax - onomies , typologies , and frameworks have been developed to help visualization researchers determine which tasks to focus on [ 5 , 45 ] , ranging from categorizing the low - level interactions that users perform with an interface ( e . g . , [ 6 , 66 ] ) , to classifying the higher level intents that often drive these interactions ( e . g . , [ 5 , 31 ] ) . We refer to these theoretical structures as task models in this paper . Whether they are taxonomies , typologies , or frameworks , existing models focus on task abstraction – translating speciﬁc instances of ob - served tasks into more universal , general - purpose structures [ 14 ] . This abstraction generally ﬂows from low - level system details to high - level , system - agnostic concepts , such as analyzing a speciﬁc interaction log to abstract concepts in an academic paper . We can even abstract these con - cepts further , such as by translating high - level concepts from multiple papers into a broader meta - level framework ( e . g . , [ 6 , 31 , 53 ] ) . Although these task models have provided useful guidelines for visualization developers , few if any models provide support for the instantiation of tasks that is often helpful for evaluating visual analytics systems . In other words , few models seem to ease the ﬂow of mapping from high - level theoretical concepts of the task back down to speciﬁc observations of concrete tasks within low - level systems data , such as interaction logs . Further , the research community lacks a concrete framework for expressing relationships between objectives , insights , and tasks , leading to ad hoc evaluation approaches that do not generalize easily . We contribute a model for transforming abstract task models into actionable instantiations to address these open challenges . Our model enables a precise , systematic approach to applying high - level theories of tasks to low - level interaction data . To derive this model , we synthesize existing task theory literature into a precise deﬁnition of task that can be implemented through code . Our model relies on a key idea proposed in existing work [ 2 , 45 , 47 ] : rather than deﬁning a task as a sequence of interactions , we can instead deﬁne a task by the user’s objective in performing the task , and the insights extracted as a result of completing the task . Assuming a retrospective analysis , where we have detailed knowledge of the user’s objectives , actions , and insights ( i . e . , through rich user study data ) , we can infer the scope of the corresponding tasks programmatically using the inferences and data transformations made • Leilani Battle is with the University of Washington . E - mail : leibatt @ cs . washington . edu . • Alvitta Ottley is with Washington University in St . Louis . E - mail : alvitta @ wustl . edu . by the user . Given access to concrete task instances , we can evaluate how well existing models align with observed instances , for example , whether the observed task instances match the task classes proposed in existing taxonomies , or the ﬂow of analysis proposed in existing frameworks . We can also analyze the breadth and depth of extracted insights , and potentially streamline the process of assessing the quality and rigor of these insights [ 70 ] . To this end , we also contribute Pyxis , a language that allows re - searchers to specify how high - level task models explain the motiva - tions , insights and analytic actions they observe during sensemaking . Pyxis implements our synthesized task model so it can be applied to both existing theories and experiment data . To demonstrate the utility of Pyxis , we apply it to a wide range of example tasks , insights , and analysis sessions from the literature . Not only was Pyxis expressive in all cases , but the resulting structures contribute new understanding and nuance to established theories regarding the scope , complexity , and discovery of insights . All of the data and code for our example applications are available in our open - source repository 1 . In summary , this paper makes the following three contributions : • We present an instantiation - focused model that enables visualiza - tion researchers to precisely delineate the scope of an analysis task , and measure the complexity of this task . • We present a corresponding speciﬁcation language called Pyxis that enables visualization researchers to apply our model directly to existing theories and logs of visual analysis sessions . • We show the utility of Pyxis through a wide range of demonstra - tive scenarios , where we use it to recreate insights , tasks , and snippets of interaction logs from existing work . 2 B ACKGROUND In this section , we review the speciﬁc concepts from existing visualiza - tion task theory that we build upon in Pyxis . We use these theories to guide our formal deﬁnition of task and language design . 2 . 1 Task To build an effective and meaningful visualization system , researchers and developers are encouraged to consider the context under which the visualization system will be used [ 36 ] . A key component of this characterization process is identifying the analysis tasks that users seek to perform [ 34 , 53 ] . Many theoretical models have been developed to streamline the process of identifying relevant and meaningful visual analysis tasks to drive system design [ 45 ] . These models often take the 1 https : / / osf . io / t9e63 / ? view _ only = 9857ef52c3334739b0001dd6d7cf324c a r X i v : 2206 . 04767v1 [ c s . H C ] 9 J un 2022 Fig . 1 : A task is typically demarcated by the objective driving it and insights discovered while completing it . form of task taxonomies and typologies [ 14 ] , where speciﬁc tasks ob - served in the ﬁeld or in lab studies are generalized into an abstract set of task classes , such as “Find Anomalies” [ 2 ] , “Search / Comparison” [ 27 ] or “characterizing data distributions and relationships” [ 5 ] . These mod - els also take the form of frameworks , where the scope and structure of observed tasks , and relationships between these tasks , are abstracted into general - purpose hierarchies . Examples include the framework of tasks , sub - tasks , actions , and events proposed by Gotz and Zhou [ 16 ] , and the goals to tasks framework proposed by Lam et al . [ 31 ] . We integrate ideas from existing task models with principles from domain - speciﬁc languages for data science ( e . g . , [ 10 , 24 , 25 , 62 ] ) to build Pyxis . Prominent in the literature is the notion that the completion of tasks are often denoted by the insights that were ( or were not ) derived . For example , when an analyst discovers insights that answer their current question or support / refute their current hypothesis , then they will likely end the current task and move on to a new one [ 15 , 19 , 42 ] . Furthermore , if the analyst discovers insights that favor the pursuit of a new and unexpected task , then the analyst is also likely to end the current task and pivot to the new one [ 49 ] . This scenario also comes into play when an analyst fails to uncover any insights relevant to the current task , and switches to a more promising alternative [ 4 , 70 ] . We also observe in the literature that an analyst’s objectives in pursuing certain visual analysis tasks are often deﬁned in relation to the kinds of insights they expect to uncover . This observation stems from the idea that a user’s data analysis strategy is not random ; it is likely informed by an initial goal or “hunch” [ 5 , 31 , 70 ] , even if only vaguely at ﬁrst [ 5 ] . In summary , the literature seems to suggest that visual analysis tasks are demarcated in the beginning by the objective driving the task and at the end by the insights uncovered from the task ; this relationship is shown in Figure 1 . This loose speciﬁcation of the beginning and end of tasks from the literature points to a potential declarative approach to specifying visual analysis tasks , which we explore further in this paper . This speciﬁcation is distinct from previous deﬁnitions of analysis tasks found in the literature , which tend to focus on imperative deﬁnitions of tasks , such as by deﬁning tasks in terms of the speciﬁc visualisations created or sequence of interactions performed [ 5 , 45 , 64 ] . In the remain - der of this section , we review the existing literature on objectives and insights , the primary components for declaratively specifying visual analysis tasks in Pyxis . 2 . 2 Objective The existing literature emphasizes the importance of objectives or goals in visual analysis tasks [ 5 , 31 , 45 ] . In a survey of the literature on exploratory visual analysis , Battle and Heer observe that goals are a pervasive topic [ 5 ] . Lam et al . make a similar observation in their survey of the design study literature [ 31 ] . Furthermore , in their review of existing deﬁnitions of visual analysis tasks , Rind et al . argue that the concept of objective should be emphasized over the concept of task in visualization research [ 45 ] . For these reasons , we incorporate objectives as a key component in our formal model of visual analysis tasks . In this sub - section , we review existing deﬁnitions and characteristics of objectives , and highlight overlaps that we can exploit in Pyxis . The notion that objectives are questions is prominent in the litera - ture . For example , North [ 37 ] suggests that analysis questions seem to drive user data analysis and exploration sessions . The insight - based evaluation protocol proposed by Saraiya et al [ 49 ] embraces this idea and involves ﬁrst asking participants to list the analysis questions they might ask about a given data . O’brien et al . adopted the insight - based evaluation method for this study and asked participants to record initial questions that they may want to investigate about a particular genomics dataset prior to exploration [ 39 ] . O’brien et al . suggest that these questions represent “expected insights” that can later be compared with users’ actual insights after exploration . Finally , more recent work by He et al . adopted a similar strategy , where they asked study participants to “input tasks , ” which shared a similar structure to open - ended questions , e . g . , “to explore effective drugs for * * tumor” [ 21 ] , which could be reframed as “what drugs are considered effective for * * tumor ? ” . He et al . also observe that users may switch tasks mid - exploration , denoted by inputting a new task description . In their model , Sacha et al . [ 47 ] focus on hypotheses rather than initial questions , pointing to another potential deﬁnition , objectives are hypotheses . They argue that “the visual analytics process is guided by hypotheses” [ 47 ] . Shrinivasan et al . too observe that hypotheses tend to drive subsequent analysis actions [ 56 ] . Further work by Rind et al . extend the knowledge generation model proposed by Sacha et al . to explicitly include the concept of a user analysis objective , which clariﬁes the relationship between users’ hypotheses and insights [ 45 ] . However , Green et al . observe signiﬁcant potential but also signiﬁcant risk in users’ hypothesis generation processes as “it can be fraught with human cognitive bias” [ 18 ] . To mitigate potential conﬁrmation bias , Zgraggen et al . take this idea further by framing exploratory visual analysis as multiple hypothesis testing , and evaluate each insight re - ported by study participants as separate hypotheses to be tested against the data [ 70 ] . Whether objectives are questions or hypotheses is not always clear - cut . For example , in their studies of exploratory visual analysis behav - ior , Liu and Heer [ 32 ] and Gomez et al [ 15 ] observe analysts using both analysis questions and hypotheses as exploration objectives . Our conceptualization builds directly on the deﬁnition of objective proposed by Rind et al [ 45 ] . We reinforce the connection between objectives , hypotheses , and questions established in the literature by linking these concepts : hypotheses or analysis questions are often used to structure the user’s objective . Further , we specify the connection between objec - tives ( expected insights from a dataset ) and insights ( actual observations made from this dataset ) , which together deﬁne analytic tasks . 2 . 3 Insight Existing research places a strong emphasis on insight discovery during visual analysis and exploration tasks [ 7 , 19 , 37 ] . For example , re - searchers often test visual analysis tools by the quantity , accuracy , and quality of insights users generate while using them [ 5 , 32 , 38 , 49 , 70 ] . Thus , insights appear to play a critical role in visual analysis tasks , where the formulation of insights ( or lack thereof ) may suggest the end of a task . For these reasons , insights are of particular interest for developing a formal model of visual analysis tasks . Here , we summa - rize existing deﬁnitions and characteristics of insight , and highlight recurring overlaps and themes that we leverage to build Pyxis . 2 . 3 . 1 Categories of Insight . The prior work details several high - level categories of insights . For example , Chang et al . [ 7 ] distinguish between a “knowledge - building in - sight , ” or information that directly extends a user’s existing knowledge structures , and “spontaneous insight , ” or a “eureka” moment that reorga - nizes or connects loosely related knowledge structures . This distinction is similar to “directed” versus “unexpected” insights as proposed by Saraiya et al . [ 49 ] . Chang et al . [ 7 ] argue that knowledge - building in - sight is typically the focus of visualization and visual analytics work [ 7 ] , though some argue the opposite [ 43 , 44 , 55 ] . We focus on analyzing knowledge - building insights in this paper , however Pyxis could be extended to represent spontaneous insights as well . Alternatively , Smuc et al . [ 58 ] and Liu and Heer [ 32 ] observe that users may also gain insights into how to improve the visual analysis tool they are interacting with , and distinguish between data insights and tool insights . Further , Pousman et al . argue that traditional visual analytics systems focus on “analytic insight , ” and suggest that tools designed for casual information visualization scenarios support other kinds of insight , in particular “awareness insight , ” “social insight , ” and “reﬂective insight” [ 44 ] . Saraiya et al . deﬁne four different categories of insights [ 48 , 49 ] : “overview , ” “patterns , ” “groups , ” and “details . ” Finally , Liu and Heer propose seven insight categories for analyzing exploratory visual analysis outcomes [ 32 ] : “observation , ” “generaliza - tion , ” “hypothesis , ” “question , ” “recall , ” “interface , ” and “simulation , ” where we ﬁnd that the simulation category was not proposed in prior insight studies . These categories act as a supserset of sorts , and overlap signiﬁcantly with categories proposed in the literature , such as those by Saraiya et al . [ 48 – 50 ] and North [ 38 ] , Smuc et al . [ 58 ] , Gomez et al . [ 15 ] and Guo et al . [ 19 ] , and Yi et al [ 67 ] . Rather than deﬁning ﬁxed insight classes , we instead introduce a formal deﬁnition for data relationships , which can capture differing levels of dataset coverage ( overview ) , statistical patterns and clus - ters ( patterns ) , user - deﬁned groupings of data tuples ( groups ) , and detailed information for individual tuples of interest ( details ) such as outliers [ 38 ] . Note that these categories are not mutually exclusive , and have been found to co - occur [ 58 ] . 2 . 3 . 2 The Varying Deﬁnitions of Insight . The literature present inconsistent deﬁnitions for what constitutes an insight . We use these existing deﬁnitions to mine the literature for concrete examples of insights , which we recreate using Pyxis to demon - strate its applicability to a wide range of data analysis and exploration scenarios . For example , insights are utterances . In the context of a user study , Saraiya et al . deﬁne insight as “an individual observa - tion about the data by the participant , a unit of discovery , ” [ 48 , 49 ] which can include “any data observation that the user mentions” during in - person lab studies [ 32 , 49 , 69 , 70 ] , as well as self - reported insight diaries collected through ﬁeld studies [ 50 ] and competition submis - sions [ 43 ] . Gomez et al . observe that users may only report a subset of their insights that are relevant to the study at hand [ 15 ] . Zgraggen et al . posit that insights may not only be explicitly deﬁned through direct user reporting but also implicitly deﬁned through observation , such as when the user is observed performing an analysis but does not ofﬁcially report the outcome of this analysis to experimenters [ 70 ] . The prior work also suggests that insights are knowledge links . In particular , Chang et al . argue that in visual analytics “insight is considered to be more or less units of knowledge” [ 7 ] . Others re - ﬁne this idea further by deﬁning insights as links that connect anal - ysis ﬁndings , such as visualizations and statistical results [ 59 ] , with user knowledge [ 2 , 3 , 16 – 18 , 21 , 37 , 45 , 47 , 49 , 50 , 56 – 58 , 67 ] , such as knowledge synthesized from the current session or earlier ses - sions [ 7 , 16 – 18 , 21 , 50 , 56 – 58 ] , or a priori knowledge the user brings to the exploration process [ 3 , 17 , 18 , 21 , 44 , 47 , 50 , 56 , 58 , 67 ] . These links can be implicit , such as when observed through qualitative insight studies [ 49 , 50 , 58 ] , or explicit , such as when users apply annotation interactions [ 16 , 17 ] or link interactions [ 12 , 16 , 17 , 21 , 56 , 57 ] to connect system visualization state with concepts recorded in their own digitized notes . Furthermore , insights can be hierarchical in nature , and build on one another over time , increasing the complexity of subsequent insights [ 16 , 18 , 33 , 37 , 44 , 49 , 50 , 56 , 58 ] . Moreover , Pike et al . argue for more formal semantics for capturing user insights , which can enable visual analysis systems to more effec - tively process , reason about and even extract new insights [ 40 ] . Smuc et al . argue that insights can be more effectively analyzed through a direct analysis of how users’ reported insights build on one another , and propose relational insight organizers ( or RIOs ) to organize and visualize the resulting insight graph [ 58 ] . RIOs share similarities with the structures proposed by Gotz et al . [ 17 ] , where user knowledge is also captured as a graph , with high level concepts and instantiations of these concepts stored as nodes within the graph , and links between concepts and analysis ﬁndings stored as edges in the graph . Similar graph - based structures have also been suggested by Shrinivasan and van Wijk [ 57 ] , Mathisen et al . [ 33 ] , and He et al . [ 21 ] . Several works categorize insights in terms of how they support user hypotheses , claims , and reﬂections , pointing to a third deﬁnition – insights are data facts . Choe and Lee propose eight insight classes , where ﬁve classes are statistical in nature ( “trend , ” “correlation , ” “data summary , ” “distribution , ” and “outlier” ) , two are adapted from existing taxonomies ( “detail” [ 49 , 50 ] and “self - reﬂection” [ 44 ] ) , and the ﬁnal “comparison” class reinforces the established link between analysis ﬁndings and user knowledge that deﬁnes insights . Zgraggen et al . propose ﬁve insight classes , all of which are statistical in nature [ 70 ] : “shape , ” “mean , ” “variance , ” “correlation” and “ranking” . We observe that the statistical insight classes proposed by Choe and Lee [ 8 ] and Zgraggen et al . [ 70 ] all fall under the “patterns” category originally proposed by Saraiya et al . [ 49 , 50 ] . Visualization recommendation systems such as Voyager [ 63 ] , ForeSight [ 11 ] , DataSite [ 9 ] , SeeDB [ 61 ] , and Voder [ 59 ] extract statistical patterns , relationships , and anomalies to strengthen the user’s understanding of the data , and hopefully guide the user toward new insights . Chen et al . formalize the relationship between statistical analysis ﬁndings , or data facts , and insight through their Fact Management Framework [ 65 ] , which provides a theoretical base from which to derive formal deﬁnitions for analytic insights , objectives , and ultimately tasks . Finally , the prior work suggests that insights are hypotheses and / or evidence . For example , to evaluate how study participants perform during open - ended exploration tasks , Gomez et al . label each observed insight from their study as a “claim , ” i . e . , “a general hypothesis , ques - tion , or remark about the data model that is potentially synthesized from multiple observations , ” or as “evidence , ” such as an observa - tion comprised of “speciﬁc references to data points” that support the claim [ 15 ] . Guo et al . augment the claim - evidence structure proposed by Gomez et al . to encompass “facts , ” “generalizations , ” and “hypothe - ses” [ 19 ] , where facts are units of truth extracted about speciﬁc entities observed in the data , generalizations are inferred relationships between observed entities , and hypotheses are claims that can be supported by facts and generalizations . Sacha et al . argue that users leverage analysis ﬁndings primarily as evidence to support , refute , or generate new hypotheses [ 47 ] : “Analysts try to ﬁnd evidence that supports or contradicts hypotheses in order to gain knowledge from data . ” At face value , these deﬁnitions of insight may appear distinct . How - ever , a close look at the varying perspectives points to an overarching theme – an insight is a unit of knowledge . How one might capture ( e . g . , through utterances ) or represent ( e . g . , as data facts or evidence ) speciﬁc instances of insights would depend on the instrumentation and observations available to the researcher . Our work unites these perspec - tives . Rather than focusing on how we capture the users’ knowledge , we present a programmatic representation that captures the knowledge source and links . 3 R ESEARCH G OALS This paper aims to provide a formal and executable implementation of the existing theory that can capture observed nuances between current deﬁnitions of insight . We interweave core ideas and deﬁnitions in the literature to formalize the theoretical and computational models that connect tasks , objectives , and insights together . Speciﬁcally , we deﬁne analysis tasks as a process of collecting evidence ( i . e . , insights ) in support of or against existing objectives ( i . e . , hypotheses , questions ) or favor of alternative ( and in some cases , unexpected ) analysis objectives . We build on three fundamental principles extracted from our review of the literature , which connect insights , objectives , and tasks : • First , we observe that objectives and insights often demarcate tasks and the literature consistently describes the structure of analysis tasks : they tend to begin with an objective driving the task and end with discovering insights that either meet the objective or hint at an alternative ( subsection 2 . 1 ) . • Second , we can represent insights as linked units of knowledge . We observe in the literature that insights establish links between the user’s data observations and their knowledge of related phe - nomena , and new insights often link back to old ones as analysts’ understanding of the data evolves ( subsubsection 2 . 3 . 2 ) . Further - more , analysts’ data interpretations often involve mining facts or relationships from the data , which researchers categorize in various ways ( subsubsection 2 . 3 . 1 ) . Fig . 2 : We present an example of our speciﬁcation language demonstrating the connection between tasks , objectives , and insights . Here , we use an illustrative scenario that follows a ﬁctional crime analyst as he investigate a crime peak in Baltimore that coincides with protests in the area [ 33 ] . ( b ) demonstrates the programmatic deﬁnition of an analytic task as a pairing of an objective , ( a ) , and an insight , ( c ) . We specify an insight as a link between domain and analytic knowledge as exempliﬁed by ( d ) and ( e ) . Finally , ( f ) demonstrates how the language enables data transformations . • Third , objectives often look like insights . Insights can lead to new questions and hypotheses , suggesting that insights can themselves become objectives that drive future analysis tasks ( subsubsec - tion 2 . 3 . 2 ) . This insight - objective connection is exempliﬁed by how insights build on each other over time . Some even suggest that objectives are insights ( e . g . , [ 19 ] ) , blurring the line between insights and objectives even more . Together , these three principles motivate the programmatic deﬁnition of task presented in the following section . 4 A P ROGRAMMATIC D EFINITION OF T ASK In Pyxis , tasks are speciﬁed using the objective motivating the task and the insights extracted from completing the task . We present a synthe - sized deﬁnition for visual analysis tasks that connects the concepts of insights and objectives deﬁned the literature . Further , we explain how we have implemented this deﬁnition as a fully - functional speciﬁcation language in TypeScript . Throughout this section , we demonstrate how to use Pyxis using an existing data analysis scenario from Mathisen et al . [ 33 ] , which follows a ﬁctional analyst , John , as he investigates crime peaks in Baltimore from 2012 through 2015 . John’s analysis uncovers the ﬁrst crime peak on April 27 , 2015 which coincides with protests sparked by the funeral of Freddie Gray , a young black man who was killed by the Baltimore police . 4 . 1 Deﬁning Task as Objective - Insight Pairs We deﬁne a task as a pairing of two sets , where the ﬁrst set contains the objectives driving the task , and the second set contains the insights dis - covered while completing the task . Using our Baltimore crimes exam - ple , we can specify a task as indicated in Figure 2 ( b ) . In this case , John has an objective to explore potential relationships between protests and incidence of crime , represented by the protestsObjective object in line 3 . In pursuing this objective , he arrives at an insight , represented by the protestsInsight object in line 4 . Tasks can also be hierarchical in nature , and may comprise several smaller sub - tasks [ 5 , 31 ] . To account for these more complex tasks , we include optional properties to track tasks informed by or that inform this task ( lines 5 - 6 ) . In the remainder of this section , we formally deﬁne the insights and objectives that together form tasks , and use these def - initions to specify the protestsInsight and protestsObjective objects mentioned above . 4 . 2 Deﬁning Insight as Knowledge Links Our insight deﬁnition is inspired by the work of Gotz et al . , which deﬁnes an insight as a link connecting multiple knowledge bases used by an analyst [ 17 ] . Gotz et al . classify these knowledge bases into one of two groups : analytic knowledge , i . e . , information derived from manipulating and visualizing data , and domain knowledge , i . e . , out - side information that provides meaning and context to this data . We summarize this relationship in Figure 3 . Domain knowledge and ana - lytic knowledge are the low - level building blocks of Pyxis . One unit of domain or analytic knowledge is represented as a node within a Fig . 3 : Insights link domain knowledge , i . e . , the user’s experience with the phenomena of interest , with analytic knowledge , i . e . , the user’s interpretation of a dataset . larger knowledge graph . A grouping of domain knowledge and analytic knowledge nodes represents an insight . Thus , insights are a higher level representation of knowledge within Pyxis . To develop domain knowledge , analysts extract information through database searches or ﬁeld investigations [ 17 , 33 , 42 ] . Analysts formalize their domain knowledge as abstract concepts , e . g . , the “protests” con - cept in Figure 3 , and speciﬁc instances of these concepts , e . g . , the “Bal - timore protests” instance in Figure 3 [ 17 ] . To develop analytic knowl - edge , analysts infer relationships from a given dataset [ 17 , 42 , 59 , 65 ] , such as by visualizing potential trends or testing correlations through computational models , e . g . , calculating a linear regression as shown in Figure 3 . To prepare the data for visualization or modeling , analysts apply data transformations [ 22 , 51 , 65 ] , such as deriving new data at - tributes for further analysis , aggregating the data to calculate summary statistics , or ﬁltering the data to remove irrelevant records as shown in Figure 3 . 4 . 2 . 1 Linking Domain Knowledge and Analytic Knowledge Figure 2 ( c ) shows how we can link analytic and domain knowl - edge nodes together using an insight object in Pyxis , speciﬁcally the protestsInsight object from our task speciﬁcation in subsection 4 . 1 . First , we give this insight an identiﬁer ( line 2 ) and describe the ﬁndings behind John’s insight ( lines 3 - 4 ) . Then , we link the relevant domain and analytic knowledge nodes ( lines 5 - 6 ) . In analyzing the Baltimore crime dataset , John records the top three days of peak crime in Bal - timore , the highest peak being on April 27 , 2015 , represented as the analytic knowledge node crimePeaksNode on line 5 . In response , John performs a search for events associated with this date and ﬁnds the Wikipedia article on the Baltimore protests recorded in the domain knowledge node protestsNode on line 6 . We deﬁne domain knowl - edge nodes and analytic knowledge nodes in subsubsection 4 . 2 . 2 and subsubsection 4 . 2 . 3 , respectively . This formulation enables us to track the growth of an analyst’s domain knowledge and analytic knowledge in tandem , as well as mean - ingful intersections between the two , i . e . , insights . With a precise speciﬁcation of insights , we can accurately record which analysis ﬁnd - ings ( or the lack thereof ) that led to the completion of a given analysis task . However , insights can also be null results , which we can eas - ily record by connecting the relevant null results from our analytic knowledge nodes . Insights can also be signiﬁcantly more complex , and may become hierarchical in nature as new insights connect to or summarize existing ones [ 17 , 42 , 58 ] . To support more complex in - sights , more than one node can be speciﬁed in the domainKnowledge and analyticKnowledge properties ( lines 5 - 6 ) . Furthermore , we can make note of any previous insights that informed the current insight ( line 7 ) . In later analyses , we can link new insights that were informed by the current insight ( line 8 ) . 4 . 2 . 2 Deﬁning Domain Knowledge Gotz et al . propose two data structures to encode domain knowledge : concepts and instances [ 17 ] . Concepts represent a type of domain knowledge that the analyst wants to express , such as the concepts of an “organization” , “conspiracy” , or “protest” . We adopt a similar structure in our deﬁnition of insights to represent domain knowledge , as shown in our continuing example from Mathisen et al . [ 33 ] in Figure 2 ( d ) . First , we deﬁne the concepts “Crime” and “Protest” ( lines 2 - 11 ) . Second , we deﬁne an instance of the “Protest” concept based on the Baltimore Protests in 2015 ( lines 12 - 25 ) . Third , we deﬁne a unit of domain knowledge as a new domain knowledge node ( lines 26 - 27 ) . Each node is associated with a speciﬁc instance , and each instance is associated with a core concept and ( optional ) relevant concepts . Re - searchers can link instances together by programming edges between their corresponding nodes which represent different conceptual relation - ships , such as one node “causing” another node , suggesting a directed relationship between the two nodes , or one node being “related to” another node , suggesting a general link but no causal direction . 4 . 2 . 3 Deﬁning Analytic Knowledge Analysts integrate domain knowledge with analytic knowledge to gener - ate insights . We observe in subsubsection 2 . 3 . 2 that analytic knowledge typically takes the form of statistical characteristics derived from a dataset , such as correlations , distributions , sequences , or anomalies . We refer to these statistical characteristics as data relationships in Pyxis . However , analysts often have to pre - process their data prior to infer - ring relationships , such as ﬁltering , aggregating , sorting , etc . , which we refer to as data transformations . Both data relationships and data transformations are considered forms of analytic knowledge in Pyxis . We deﬁne them and share concrete examples here . We demonstrate the application of these ideas through our continuing example . Speciﬁcally , we can record how John processed the data to identify peaks in a new analytic knowledge node , shown in Figure 2 ( e ) . First , we give this unit of analytic knowledge an identiﬁer ( line 2 ) and describe what John learned ( lines 3 - 5 ) and when he learned it ( line 6 ) . Then , we connect any relevant data transformations and / or relationships ( line 9 - 10 ) . In this case , John’s ﬁndings relate only to the aggTransform object which executes a data transformation . Finally , we note any existing nodes that led to this node ( line 7 ) . In the future we can connect new analytic knowledge nodes that were informed by this one ( line 8 ) . Data Transformations and Relationships Before we can infer data relationships , we often need to ﬁlter the data , group and aggregate the data , join two datasets together , or perform other data transforma - tions . These data transformations are often recorded as separate steps from specifying data relationships , exempliﬁed through the transforms structure used in Vega [ 52 ] and Vega - Lite [ 51 ] . Our codebase imports the Vega transforms library and Arquero library [ 22 ] directly within Pyxis , so any transform that can be speciﬁed in Vega or Arquero can also be speciﬁed in Pyxis . We demonstrate how to create data transformation objects through a continuation of the Baltimore crime example . Here , we use Arquero to calculate total reported crimes per day and identify peak crime days as shown in Figure 2 ( f ) . First , we specify the input datasets , in this case the Baltimore crime dataset ( line 2 ) . Then , we list the transforms to execute : group the reported crimes by date ( lines 5 - 8 ) , count total records per day ( lines 8 - 13 ) , sort the dates by count ( lines 14 - 17 ) , and ﬁlter for only the top three dates with the highest counts ( lines 18 - 21 ) . Finally , we execute the transformations on the data using the executeDataTransformation method on line 24 . Pyxis can also record data relationships in analytic knowledge nodes . Consider the following extension of the Baltimore example : Suppose John is interested in determining whether location is indicative of crime type , for example , whether different crimes happen indoors versus outdoors , or in an apartment versus a business . We can specify a new model to predict this relationship as follows : 1 const dt = new DecisionTreeClassificationRelationshipModel ( " baltimoreCrimes " , / / dataset name (cid:44) → (cid:44) → 2 [ / / input attributes to predict with 3 { 4 name : " Inside / Outside " , 5 attributeType : AttributeType . nominal } , 6 { 7 name : " Premise " , 8 attributeType : AttributeType . nominal } 9 ] , 10 { / / output attribute to be predicted 11 name : " Description " , 12 attributeType : AttributeType . nominal } 13 ) ; 14 dt . train ( baltimoreCrimes . records ) ; 15 const prediction = dt . predict ( baltimoreCrimes . records [ 0 ] ) ; (cid:44) → Here , we specify a decision tree classiﬁer to predict the relationship ( line 1 ) . The input attributes used to train the model are “Inside / Outside” and “Premise” ( lines 4 - 6 ) . The output attribute being predicted is “De - scription” ( lines 7 - 10 ) , which describes the type of crime reported . Pyxis enables one to not only specify data relationships but also com - pute them directly on the input data . For example , Line 18 shows how we can train the speciﬁed decision tree model on the Baltimore crimes dataset using our language , and Line 19 shows how this model can be used to predict the crime type of speciﬁc records . In this way , speciﬁed analytic knowledge can be evaluated for statistical rigor by testing the accuracy of the underlying data relationships , supporting prior calls for more precise evaluation of user insights [ 70 ] . Note that Pyxis supports multiple models for capturing multivariate relationships , such as K nearest neighbors , linear regression , and naive Bayes models , as well as univariate relationships ( e . g . , via kernel den - sity estimation ) and other statistical relationships such as outliers ( e . g . , via isolation forests ) . 4 . 3 Deﬁning Objectives as Partially Speciﬁed Insights Analysis tasks tend to begin with objectives and end with insights , where insights are well - deﬁned but objectives are often described only vaguely , if at all . This uncertainty can make objectives difﬁcult to specify in a consistent way , demonstrated by the variability in how objectives are deﬁned in the literature ( see subsection 2 . 2 ) . However , we leverage two key principles that remain consistent across prior work ( see section 3 ) . First , visual analysis objectives are described more as goals to be attained rather than actions to be performed , suggesting a declarative speciﬁcation of objectives is possible . Second , objectives appear to be informed at least in part by the type of insights the user seeks to uncover , such as evidence for or against a given hypothesis or answers to a speciﬁc analysis question . This suggests that objectives could be speciﬁed in relation to expected insights . The intuition behind our deﬁnition of objectives is that they are structured much like insights . Objectives can be represented as links between domain knowledge and analytic knowledge nodes . For exam - ple , objectives often take the form of analysts evaluating an existing “hunch” they have about a certain phenomenon [ 13 , 17 , 70 ] , such as a potential conspiracy or crime . Objectives can also be hierarchical in nature , and thus can also connect to or summarize existing objec - tives , such as when analysts break goals down into smaller sub - tasks ( e . g . , [ 5 , 45 ] ) . However , the key difference lies in how objectives are often underspeciﬁed compared to insights . In Pyxis , we handle the uncertainty associated with objectives using the concept of wildcards . Speciﬁcally , we can represent an objective using an insight object in Pyxis , and insert a placeholder value ( i . e . , a wildcard ) for properties that are not currently speciﬁed . 4 . 3 . 1 Deﬁning Objectives with Wildcards We demonstrate the use of a wildcard ( denoted with “ ? ” ) in Figure 2 ( a ) . In this case , we have a complete speciﬁcation for domain knowledge ( line 5 ) but not for analytic knowledge ( line 6 ) . This suggests that John wants to explore a range of analyses that may potentially connect data with his existing domain knowledge , which we can represent as an analysis question : How did the date of Freddy Gray’s funeral ( April 27 , 2015 ) impact crime in Baltimore ? Now , suppose we stepped backward into John’s analysis timeline where he had initially uncovered the crime peak on April 27 , 2015 , but before he learned about Freddy Gray’s funeral . We can represent the corresponding objective with the following question : What happened on April 27 , 2015 that may have led to more crime ? In this example , we specify analytic knowledge ( line 5 ) and the wildcard appears for domain knowledge ( line 4 ) : 1 const aprilCrimeObjective = { 2 name : " aprilCrimeObjective " , 3 description : " What was happened on April 27 , 2015 that may have led to more crime ? " , (cid:44) → 4 domainKnowledge : [ " ? " ] , 5 analyticKnowledge : [ crimePeaksNode ] , 6 sourceInsights : [ ] , 7 targetInsights : [ ] 8 } ; Note that we can also include wildcards within nested properties , for example within a data relationship or data transform . 5 D EMONSTRATIVE U SAGE S CENARIOS Two distinguishing features of Pyxis are : ( 1 ) it collates existing task deﬁnitions into a coherent set of data structures and ( 2 ) it enables researchers to quantitatively analyze observed insights by declaratively specifying instances of these data structures . In particular , we can use Pyxis to replicate existing examples of insights , objectives and tasks , and quantify the complexity and scope of these examples . We present three usage scenarios representing a diverse range of theoretical and empirical examples developed by Amar et al . [ 2 ] ( sub - section 5 . 1 ) , North [ 37 ] ( subsection 5 . 2 ) , and Battle and Heer [ 5 ] ( subsection 5 . 3 ) . By recreating these instances with Pyxis , we enable the community to revisit existing work from a new perspective , reveal - ing unexplored ideas and opportunities for future research . We share the code for each usage scenario in our supplemental materials . 5 . 1 Usage Scenario 1 : Recreating Low - Level Components of Analytic Activity By enabling precise speciﬁcation of visual analysis tasks , researchers who use Pyxis to represent insights , objectives , and tasks can clearly un - derstand how their speciﬁcations connect with prior work . We demon - strate these beneﬁts through a usage scenario that explores an example task proposed by Amar et al . [ 2 ] . Our goal is to provide deeper insights into the task structure revealed by Pyxis . Amar et al . pose a broad , exploration - focused objective : “under - standing trends in [ movie ] popularity over time” . Then , they suggest two analysis sub - tasks in pursuit of this objective : ( 1 ) identify movies that have won Academy Awards in the last ten years and ( 2 ) test for a correlation between movie length and popularity among award winners . To recreate this exploration task , we capture the results of the proposed analysis activity using a new insight object and show how to specify the proposed objective using wildcards . 1a ) First , We Deﬁne the Task . . . Figure 4 demonstrates a partially - speciﬁed task with unknown insights . 1b ) . . . And the Objective as a Partially - Speciﬁed Insight . . . . Given the original objective is quite broad , our objective in Figure 4 includes a domain knowledge node but replaces the analytic knowledge nodes with a wildcard in our speciﬁcation . This speciﬁcation suggests that the analyst is initially interested in ﬁlm length , but the analysis approach is not yet known . We populate the filmLengthNode variable in the next step . 1c ) . . . And We Specify Domain Knowledge . Our objective depends on domain knowledge representing the analyst’s understanding of factors that may affect ﬁlm quality . For example , Figure 4 demonstrates how we can specify a new quality concept and record relevant articles as instances of the quality concept , such as articles discussing the effect of ﬁlm length on movie popularity . Then , we record these instances in a new domain knowledge node ( filmLengthNode ) . 2 ) Then , We Record Analytic Knowledge representing our under - standing of how the data supports our concepts . For sub - task one , the example in Figure 4 joins a well - known movies dataset [ 63 ] with an Oscars dataset 2 to get detailed information for award - 2 https : / / datahub . io / rufuspollock / oscars - nominees - and - winners # data Fig . 4 : An demonstrative scenario recreating Amar et al . ’s movie data exploration task [ 3 ] . First , we ( 1a ) specify the task with a wildcard to denote known domain knowledge but unknown analytic knowledge . This task involves an analysis objective ( 1b ) to explore relationships between ﬁlm length and quality . We ( 1c ) record relevant domain knowledge in the form of online articles discussing ﬁlm length . As we analyze the data in pursuit of the objective , we can ( 2 ) record our ﬁndings as analytic knowledge , and ﬁnally ( 3 ) link our domain and analytic knowledge to form an insight object , which we can use to complete our original task speciﬁcation in ( 1a ) . winning movies in our target time period as shown in the partial code snippet below . For sub - task two , we can specify a data relationship to test correlations between movie length and popu - larity ( e . g . , linear regression , decision tree regression , etc . ) . Our supplementary material provides fully implemented examples for both sub - tasks . 3 ) Finally , We Link our Domain Knowledge Node and Analytic Knowledge Node by passing them as inputs to a new insight object named moviesInsight . Then , we can revisit our task deﬁnition , replacing the wildcard in Figure 4 ( 1a ) with the moviesInsight object to complete our task speciﬁcation . Beneﬁts of Pyxis . Some may consider the original objective posed by Amar et al . to be under - speciﬁed . For example , it is unclear whether studying movie length is the full objective ( as suggested by the in - sights proposed by Amar et al . ) or only part of a broader objective ( as suggested by the description of the objective ) . Under - speciﬁed objectives are generally considered difﬁcult to analyze , however under - speciﬁed objectives are also common and even necessary in certain scenarios such as data exploration [ 1 , 5 ] . Pyxis provides just enough structure to preserve the ﬂexibility of the analyst’s intent while also making the corresponding objectives more actionable for visualization systems . For example , now an objective can be speciﬁed in terms of permuting data inputs , data outputs , and the relationships between them , which provides a well - deﬁned space of actions for generating automated recommendations . An objective can also be speciﬁed in relation to informative online articles , which could be mined for topics and keywords using NLP techniques , which in turn could guide the generation of recommendations for relevant datasets to analyze . In this way , Pyxis transforms under - speciﬁed objectives into a strength rather than a weakness , and provides useful data structures for studying complex analysis scenarios like data exploration . 5 . 2 Usage Scenario 2 : Representing Analytic Knowledge of Varied Complexity To the best of our knowledge , Pyxis encapsulates the ﬁrst task model that can programmatically quantify the depth and breadth of speciﬁed insights . We demonstrate this capability by exploring a range of in - sights posed by North [ 37 ] . North describes three forms of insights over monthly rents : calculating the maximum and minimum value , estimating a normal distribution , and capturing the shape of the data using a histogram . We use the 50th percentile rent estimates provided by the U . S . Department of Housing and Urban Development as our input dataset 3 . A ) Record “Simple” Insights . The simplest insight suggested by North computes minimum and maximum rent values . We can calculate them in our code using an aggregate data transformation . B ) Record “More Complex” Insights . North’s example of a “more complex” insight is to estimate a normal distribution over the rent data . We can specify a normal distribution data relationship in our code using Vega’s native support for statistical distributions 4 . C ) Record “Even More Complex” Insights . The most complex in - sight that North describes is estimating the shape of the rent distribution using a histogram . This estimate translates to a series of data transforms to bin the data and then aggregate it using the bin ranges , which we can calculate using Vega or Arquero . Beneﬁts of Pyxis . In reﬂecting on this example as a whole , we see that North is deﬁning insights at a relatively low level , even though these insights vary in complexity . Technically , the described data transformations and relationships are not considered full insights within our framework , and instead are sub - units of analytic knowledge ( see subsubsection 4 . 2 . 3 ) . In this way , we also see how North’s deﬁnition of insight differs from the deﬁnition proposed by Gotz et al . [ 17 ] , which deﬁnes insights at a higher level of abstraction ( connecting analytic knowledge with domain knowledge ) . Furthermore , we see how these two deﬁnitions still connect to broaden our overall understanding of insight . Speciﬁcally , both deﬁnitions include critical building blocks of insight , but North’s deﬁnition describes a component of the broader deﬁnition of insight proposed by Gotz et al [ 17 ] . However , as hinted at by North , we can quantify the overall complex - ity of an insight by measuring the depth and breadth of its corresponding analytic knowledge nodes . Using Pyxis , we can measure the depth of any knowledge node by computing the longest path from this node to the earliest node that it builds upon , which aligns with existing def - initions of exploration depth posed in the literature [ 5 ] . In this case study , we see that all three examples are self - contained , i . e . , they are not connected to any other knowledge nodes . As a result , they all have 3 https : / / www . huduser . gov / portal / datasets / 50per . html 4 https : / / github . com / vega / vega - statistics / a depth of one . We can calculate the breadth of an analytic knowledge node as the percentage of data values ( rows × columns ) involved as inputs and outputs to the corresponding data transformations and / or re - lationships . Here , all three examples take the same data attribute ( rent ) and the same number of rows as input . Where they vary is in the size of the output of each corresponding data transformation / relationship , which shows that North may be deﬁning the complexity of analytic knowledge primarily in terms of output size . 5 . 3 Usage Scenario 3 : Analyzing Participants’ Insights Although insight - based user studies have been critical to understanding how people form insights , participants’ insights are generally self - reported , requiring a means of validating insight quality . Traditionally this has been done by hand [ 19 , 32 , 37 , 49 , 50 ] . However , recent work explores ways to partially automate the validation process [ 5 , 21 , 70 ] . Pyxis provides a convenient structure for validating participants’ insights and could facilitate further automation . We demonstrate this beneﬁt by recreating insights reported by Battle and Heer from their study of how analysts explore data in Tableau [ 5 ] . We focus on task “T3” for the wildlife strikes dataset 5 , which asks : “What relationships ( if any ) do you observe involving weather conditions and strike fre - quency , or counts over time ? ” The task also speciﬁes three attributes to consider : precip , sky , and incident date . We recreate two con - tradictory insights observed by Battle and Heer : ( A ) strikes are not correlated with time ( reported by 13 participants ) and ( B ) bad weather leads to more strikes over time ( reported by 3 participants ) . We use Pyxis to shed light on the discrepancy among participants , summarized in Figure 5 . A ) Analyze the precip Attribute . To recreate the ﬁrst insight , we analyze the incidence of wildlife strikes using precip attribute , shown in Figure 5a . Speciﬁcally , we apply a series of data trans - formations ( using Arquero ) to remove null precip entries on lines 4 - 7 , extract the year from each incident date on line 11 , and count the total incidents observed per year , grouped by precip conditions ( e . g . , “fog , ” “rain , ” etc . ) on lines 15 - 26 . Over - all , we see that incidents do not appear to increase with time , with the exception of “rain” conditions , shown in Figure 5b . We can record these ﬁndings in a new analytic knowledge node named precipNode in Figure 5a . B ) Analyze the sky Attribute . To recreate the second insight , we repeat this analysis , but replace the precip attribute with the sky attribute . To do this , we replace precip with sky on lines 6 and 12 in our code , denoted in yellow in Figure 5a . In this case , we see a steady increase in incidents per year for all observed weather conditions , shown in Figure 5c . We can record these ﬁndings in a new analytic knowledge node named skyNode in Figure 5a . Beneﬁts of Pyxis . We see that even if participants performed the exact same data transformations , they could still derive drastically different insights based on which attributes were analyzed . These results seem to suggest that even if participants’ analyzed both attributes while completing T3 , their ﬁnal insights were likely inﬂuenced by which attribute they favored , precip or sky . Since Battle and Heer focused primarily on interaction sequences in their analysis [ 5 ] ( i . e . , imperative deﬁnitions of task ) , they may have overlooked potential structural similarities in participants’ insights . By using a consistent structure to represent these insights , we see how the data could directly inﬂuence the direction of participants’ conclusions in this analysis task , regardless of which interaction sequences were performed . 6 D ISCUSSION A powerful takeaway from our research is that although existing deﬁni - tions differ in how they label the major components of insights , they largely agree on what these major components are and how they relate to one another . In other words , existing deﬁnitions are structurally consistent but semantically inconsistent . By formally deﬁning these components and their relationships , our framework reinforces existing 5 https : / / wildlife . faa . gov / search structural consistencies and reduces semantic inconsistencies , enabling visualization researchers to re - examine these deﬁnitions on a more leveled playing ﬁeld . Going one step further , our framework could po - tentially be used in the future as an evaluation tool for new and existing deﬁnitions of insight , objective , and task in visualization research . For instance , Pyxis can enable the visualization community to ex - plore multiple alternatives for expressing user behavior and user anal - ysis intent . Although we focus on declarative speciﬁcations in this paper , Pyxis could potentially be used to capture imperative deﬁnitions of task as well , i . e . , the sequence of activities a particular user per - formed during a task . For example , interactions often map to speciﬁc low - level data transformations , such as changing an encoding to aggre - gate the data , or ﬁltering the data via dynamic queries [ 6 , 23 ] . Using Pyxis , researchers could record these interactions as a chain of analytic nodes , each containing an individual data transformation . Relevant utterances could be recorded using the description property of the corresponding nodes . Furthermore , analytic nodes can easily be ex - tended to include new properties , for example a Vega - Lite speciﬁcation representing how each interaction was rendered [ 51 ] . 6 . 1 Using wildcards for Partial Speciﬁcation The adoption of wildcards enables further ﬂexibility , which was inspired by partial speciﬁcations in visualization recommendation research [ 35 , 62 , 63 , 68 ] . For example , the Voyager 2 system allows users to specify wildcards in place of individual encoding choices , which the system uses to generate recommendations [ 63 ] ; for example , if a user wants to “examine potential associations among quantitative ﬁelds , ” they can specify two quantitative attributes wildcards and encoding wildcards to visualize all pairs of quantitative attributes . This partial speciﬁcation approach is of particular interest because the visualization design space is generally modeled as a graph , where individual visualizations map to speciﬁc nodes within this graph [ 68 ] . A complete speciﬁcation within the visualization design space leads to a single visualization design and thus a single node within the corresponding graph , whereas a partial speciﬁcation leads to multiple visualization designs and potentially multiple target nodes . In other words , wildcards provide a way to control which properties of the design space will be permuted , allowing a visualization recommendation system to limit the range of nodes to be explored within the underlying design space graph . Much like how individual visualization designs are modeled as nodes within a larger design space , we model individual units of knowl - edge as nodes within one or multiple knowledge bases . However , in our case , the full graph is not known a priori . We observed this in Scenario 1 of subsection 5 . 1 in which the initial moviesTask and moviesObjectives were both partially - speciﬁed . That being said , our goal is to enable speciﬁcation of individual tasks and objectives , and not necessarily to enumerate and rank the space of all the possi - bilities ( i . e . , the goal of visualization recommendation systems [ 68 ] ) . However , we can still use wildcards to our advantage when deﬁning individual objectives and tasks . Moreover , wildcards highlight a vital principle of Pyxis : a partially - speciﬁed insight is an objective . 6 . 2 Modeling Analysts as Goal - Based Agents Pyxis aims to integrate multiple deﬁnitions and theories in visualization into a holistic framework . As a result , the structure of Pyxis could elucidate the visualization community’s perception of human analysis behavior and reasoning as a whole . For example , we observe that Pyxis shares structural similarities with goal - based agents in artiﬁcial intelligence . In AI , a simple goal - based agent has an objective function which inﬂuences its actions . It then senses how its actions inﬂuence the environment and either continue doing more of the same , terminate the tasks if it believes it has achieved the goal state , or a slightly more sophisticated agent might update its objective function using reinforcement learning [ 46 , 60 ] . This is markedly similar to assumptions of existing visualization research and task models [ 5 , 31 ] , including our own . In an analytic scenario , we often assume that the analyst has a particular objective that drives their tasks and actions , and explores until they either uncovered evidence that aligns with their initial objective , or they reﬁne or update their hypotheses and goals . These overlaps in ( a ) Speciﬁed data transformations ( left ) and analytic knowledge nodes ( right ) . Only lines 6 and 12 on the left need to change to analyze the precip or sky attribute , shown in yellow . 1 , 990 2 , 000 2 , 010 year 0 100 200 300 f r e qu e n cy fog fog , rain fog , rain , snow fog , snow rain rain , snow snow precip Total Strikes Per Year , Grouped By Precipitation ( b ) Results of analyzing the precip attribute . Participants likely concluded that strikes do not increase with time . 1 , 990 2 , 000 2 , 010 year 0 1 , 000 2 , 000 3 , 000 f r e qu e n cy no cloud overcast some cloud some clouds sky Total Strikes Per Year , Grouped By Sky Conditions ( c ) Results of analyzing the sky attribute . Participants likely con - cluded that strikes do increase with time . Fig . 5 : A recreation of results from a prior study where participants explored wildlife - aircraft strikes under various weather conditions , precip and sky [ 5 ] . Holding data transformations constant ( a ) , we posit that participants that focused on the precip attribute ( b ) likely drew different conclusions from those who focused on the sky attribute ( c ) , showing how attribute selection can inﬂuence insight discovery . structure might suggest that visualization researchers often model and describe analysts’ behavior as goal - based agents . On the one hand , this synergy opens up new opportunities to de - sign automated support features ( e . g . , visualization recommendation engines [ 68 ] ) by leveraging existing techniques in artiﬁcial intelligence . For example , we represent analytic knowledge as graphs in this paper , where insights represent one or more nodes within these graphs . We also represent objectives as partially speciﬁed insight objects , which in turn represent a subset of possible goal nodes within these graphs . Us - ing this framing , researchers could potentially formulate visual analysis tasks in the future as graph search problems , which could be solved using existing search algorithms ( e . g . , A * [ 20 ] ) and path planning algo - rithms ( e . g . , probabilistic roadmaps [ 28 ] ) . Since our proposed objective speciﬁcations constrain the space of possible goal nodes , researchers could also tackle this problem using constraint - based search techniques ( e . g . , answer set programming [ 35 ] ) . On the other hand , there are other kinds of intelligent agents dis - cussed in AI and robotics that could be a better ﬁt , depending on the user’s analysis context . Examples include utility - based agents [ 46 ] , which decide on actions based on how they lead to improvements in a pre - deﬁned performance measure , or learning - based agents [ 46 ] , which assumes no prior knowledge or objectives and can build or update its knowledge base as it explores and learns from the environment . In sce - narios where an analyst explores an unfamiliar dataset , a learning - based agent may be a more accurate representation of their analysis behavior compared to a goal - based one . In the future , it would be interesting to reformulate our understanding of insights , objectives , and tasks in terms of these other agent models . 6 . 3 Limitations & Future Work We designed Pyxis primarily as an evaluation tool , limiting its imme - diate applicability . For example , although it is theoretically possible to incorporate Pyxis directly into visualization systems , as shown by the iterative description in Scenario 1 of subsection 5 . 1 , future work is needed to make said application a reality . In particular , instantia - tions of Pyxis assume that tasks and objective details are known . Thus , implementation would require capturing annotations or inferring such information in real - time , both of which involve overcoming human - related or technical challenges . However , researchers and developers can still use components of Pyxis in a systems design context , such as using objectives to guide auto - generated data relationships and insight recommendations ( see subsection 6 . 2 ) . Furthermore , Pyxis assumes that the user’s goals are always deﬁned in terms of what the analyst knows and doesn’t know about the data or their domain . In reality , an analyst may have many reasons for analyz - ing a dataset , such as to present their ﬁndings to others [ 30 , 33 , 41 , 54 ] , or even just pure enjoyment [ 6 , 44 ] . An exciting opportunity for future work would be to extend Pyxis to incorporate alternative motivations . As an example , one could model factors such as surprise or enjoy - ment as cost functions over the edges of an analytic knowledge graph . In other words , the analyst may search for a goal node that not only satisﬁes the speciﬁed objective but also maximizes surprise or enjoy - ment along the way . In another example , research in communication and narrative may require modeling not only the user’s knowledge but also the knowledge of the target audience [ 26 , 29 ] . How should domain and analytic knowledge be speciﬁed for target audiences ? How should relationships or discrepancies between presenter and audience knowledge be modeled ? With a manipulable graph representation for analysis tasks , objectives , and insights , researchers can make theoretical inferences that complement existing work . 7 C ONCLUSION In a review of the literature , we ﬁnd that researchers seem to agree on the structure of visual analysis tasks , i . e . , their major building blocks , but not the semantics of tasks , i . e . , terminology , ideal levels of ab - straction , etc . However , the literature also seems to converge on the idea that objectives tend to be goals deﬁned in relation to expected insights , hinting at a declarative approach to deﬁning visual analysis tasks . Leveraging these ideas , we propose a uniﬁed model of visual analysis tasks based on the objectives driving the task and the insights gained from the task . We implemented the model as a library in Type - Script , which supports both declarative and imperative speciﬁcation of visual analysis tasks . To demonstrate the versatility of our model , we use it to recreate insights , objectives , and tasks from four different research papers . Through these case studies , we observe how different deﬁnitions of insight , objective and task interact with one another , we show how the expressiveness of our model enhances these deﬁnitions , and and we highlight potential blind spots in existing work revealed by our model , which present interesting opportunities for future research . R EFERENCES [ 1 ] S . Alspaugh , N . Zokaei , A . Liu , C . Jin , and M . A . Hearst . Futzing and moseying : Interviews with professional data analysts on exploration practices . IEEE Transactions on Visualization and Computer Graphics , 25 ( 1 ) : 22 – 31 , 2019 . doi : 10 . 1109 / TVCG . 2018 . 2865040 [ 2 ] R . Amar , J . Eagan , and J . Stasko . Low - level components of analytic activity in information visualization . In IEEE Symposium on Information Visualization , 2005 . INFOVIS 2005 . , pp . 111 – 117 , Oct . 2005 . ISSN : 1522 - 404X . doi : 10 . 1109 / INFVIS . 2005 . 1532136 [ 3 ] R . A . Amar and J . T . Stasko . Knowledge precepts for design and evaluation of information visualizations . IEEE Transactions on Visualization and Computer Graphics , 11 ( 4 ) : 432 – 442 , July 2005 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2005 . 63 [ 4 ] C . Bao , S . Li , S . Flores , M . Correll , and L . Battle . Recommendations for visualization recommendations : Exploring preferences and priorities in public health . arXiv preprint arXiv : 2202 . 01335 ( to appear in CHI 2022 ) , 2022 . [ 5 ] L . Battle and J . Heer . Characterizing Exploratory Visual Analy - sis : A Literature Review and Evaluation of Analytic Provenance in Tableau . Computer Graphics Forum , 38 ( 3 ) : 145 – 159 , 2019 . eprint : https : / / onlinelibrary . wiley . com / doi / pdf / 10 . 1111 / cgf . 13678 . doi : 10 . 1111 / cgf . 13678 [ 6 ] M . Brehmer and T . Munzner . A Multi - Level Typology of Abstract Vi - sualization Tasks . IEEE Transactions on Visualization and Computer Graphics , 19 ( 12 ) : 2376 – 2385 , Dec . 2013 . Conference Name : IEEE Trans - actions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2013 . 124 [ 7 ] R . Chang , C . Ziemkiewicz , T . M . Green , and W . Ribarsky . Deﬁning Insight for Visual Analytics . IEEE Computer Graphics and Applications , 29 ( 2 ) : 14 – 17 , Mar . 2009 . Conference Name : IEEE Computer Graphics and Applications . doi : 10 . 1109 / MCG . 2009 . 22 [ 8 ] E . K . Choe , B . Lee , and m . c . schraefel . Characterizing Visualization Insights from Quantiﬁed Selfers’ Personal Data Presentations . IEEE Computer Graphics and Applications , 35 ( 4 ) : 28 – 37 , July 2015 . Conference Name : IEEE Computer Graphics and Applications . doi : 10 . 1109 / MCG . 2015 . 51 [ 9 ] Z . Cui , S . K . Badam , M . A . Yalc¸in , and N . Elmqvist . DataSite : Proactive visual data exploration with computation of insight - based recommenda - tions . Information Visualization , 18 ( 2 ) : 251 – 267 , Apr . 2019 . Publisher : SAGE Publications . doi : 10 . 1177 / 1473871618806555 [ 10 ] R . A . DeLine . Glinda : Supporting data science with live programming , guis and a domain - speciﬁc language . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems , CHI ’21 . Asso - ciation for Computing Machinery , New York , NY , USA , 2021 . doi : 10 . 1145 / 3411764 . 3445267 [ 11 ] Demiralp , C¸a˘gatay and Haas , Peter J . and Parthasarathy , Srinivasan and Pedapati , Tejaswini . Foresight : recommending visual insights . Proceed - ings of the VLDB Endowment , 10 ( 12 ) : 1937 – 1940 , Aug . 2017 . doi : 10 . 14778 / 3137765 . 3137813 [ 12 ] W . Dou , D . H . Jeong , F . Stukes , W . Ribarsky , H . R . Lipford , and R . Chang . Recovering Reasoning Processes from User Interactions . IEEE Computer Graphics and Applications , 29 ( 3 ) : 52 – 61 , May 2009 . Conference Name : IEEE Computer Graphics and Applications . doi : 10 . 1109 / MCG . 2009 . 49 [ 13 ] W . Dou , C . Ziemkiewicz , L . Harrison , D . H . Jeong , W . Ribarsky , X . Wang , and R . Chang . Toward a deeper understanding of the relationship between interaction constraints and visual isomorphs . Information Visualization , 11 ( 3 ) : 222 – 236 , July 2012 . Publisher : SAGE Publications . doi : 10 . 1177 / 1473871611433712 [ 14 ] S . Gathani , S . Monadjemi , A . Ottley , and L . Battle . A grammar - based approach to applying visualization taxonomies to interaction logs . ( to appear in ) EuroVis 2022 , 2022 . [ 15 ] S . R . Gomez , H . Guo , C . Ziemkiewicz , and D . H . Laidlaw . An insight - and task - based methodology for evaluating spatiotemporal visual analytics . In 2014 IEEE Conference on Visual Analytics Science and Technology ( VAST ) , pp . 63 – 72 , Oct . 2014 . doi : 10 . 1109 / VAST . 2014 . 7042482 [ 16 ] D . Gotz and M . X . Zhou . Characterizing Users’ Visual Analytic Activity for Insight Provenance . Information Visualization , 8 ( 1 ) : 42 – 55 , Jan . 2009 . Publisher : SAGE Publications . doi : 10 . 1057 / ivs . 2008 . 31 [ 17 ] D . Gotz , M . X . Zhou , and V . Aggarwal . Interactive Visual Synthesis of Analytic Knowledge . In 2006 IEEE Symposium On Visual Analytics Science And Technology , pp . 51 – 58 , Oct . 2006 . doi : 10 . 1109 / VAST . 2006 . 261430 [ 18 ] T . M . Green , W . Ribarsky , and B . Fisher . Visual analytics for complex concepts using a human cognition model . In 2008 IEEE Symposium on Visual Analytics Science and Technology , pp . 91 – 98 , Oct . 2008 . doi : 10 . 1109 / VAST . 2008 . 4677361 [ 19 ] H . Guo , S . R . Gomez , C . Ziemkiewicz , and D . H . Laidlaw . A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights . IEEE Transactions on Visualization and Computer Graphics , 22 ( 1 ) : 51 – 60 , Jan . 2016 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2015 . 2467613 [ 20 ] P . E . Hart , N . J . Nilsson , and B . Raphael . A formal basis for the heuristic determination of minimum cost paths . IEEE Transactions on Systems Science and Cybernetics , 4 ( 2 ) : 100 – 107 , 1968 . doi : 10 . 1109 / TSSC . 1968 . 300136 [ 21 ] C . He , L . Micallef , L . He , G . Peddinti , T . Aittokallio , and G . Jacucci . Characterizing the Quality of Insight by Interactions : A Case Study . IEEE Transactions on Visualization and Computer Graphics , pp . 1 – 1 , 2020 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2020 . 2977634 [ 22 ] J . Heer . Arquero — arquero , 2021 . [ 23 ] J . Heer and B . Shneiderman . Interactive Dynamics for Visual Analysis : A taxonomy of tools that support the ﬂuent and ﬂexible use of visualizations . Queue , 10 ( 2 ) : 30 – 55 , Feb . 2012 . doi : 10 . 1145 / 2133416 . 2146416 [ 24 ] E . Jun , M . Daum , J . Roesch , S . Chasins , E . Berger , R . Just , and K . Rei - necke . Tea : A high - level language and runtime system for automating statistical analysis . In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology , UIST ’19 , p . 591 – 603 . As - sociation for Computing Machinery , New York , NY , USA , 2019 . doi : 10 . 1145 / 3332165 . 3347940 [ 25 ] E . Jun , A . Seo , J . Heer , and R . Just . Tisane : Authoring statistical mod - els via formal reasoning from conceptual and data relationships . arXiv preprint arXiv : 2201 . 02705 , 2022 . [ 26 ] A . Kale , Y . Wu , and J . Hullman . Causal support : Modeling causal in - ferences with visualizations . IEEE Transactions on Visualization and Computer Graphics , 28 ( 1 ) : 1150 – 1160 , 2022 . doi : 10 . 1109 / TVCG . 2021 . 3114824 [ 27 ] Y . Kang and J . Stasko . Examining the Use of a Visual Analytics Sys - tem for Sensemaking Tasks : Case Studies with Domain Experts . IEEE Transactions on Visualization and Computer Graphics , 18 ( 12 ) : 2869 – 2878 , Dec . 2012 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2012 . 224 [ 28 ] L . Kavraki , P . Svestka , J . - C . Latombe , and M . Overmars . Probabilistic roadmaps for path planning in high - dimensional conﬁguration spaces . IEEE Transactions on Robotics and Automation , 12 ( 4 ) : 566 – 580 , 1996 . doi : 10 . 1109 / 70 . 508439 [ 29 ] Y . - S . Kim , K . Reinecke , and J . Hullman . Explaining the gap : Visual - izing one’s predictions improves recall and comprehension of data . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , CHI ’17 , p . 1375 – 1386 . Association for Computing Machinery , New York , NY , USA , 2017 . doi : 10 . 1145 / 3025453 . 3025592 [ 30 ] R . Kosara and J . Mackinlay . Storytelling : The next step for visualization . Computer , 46 ( 5 ) : 44 – 50 , 2013 . doi : 10 . 1109 / MC . 2013 . 36 [ 31 ] H . Lam , M . Tory , and T . Munzner . Bridging from Goals to Tasks with Design Study Analysis Reports . IEEE Transactions on Visualization and Computer Graphics , 24 ( 1 ) : 435 – 445 , Jan . 2018 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2017 . 2744319 [ 32 ] Z . Liu and J . Heer . The Effects of Interactive Latency on Exploratory Visual Analysis . IEEE Transactions on Visualization and Computer Graph - ics , 20 ( 12 ) : 2122 – 2131 , Dec . 2014 . Conference Name : IEEE Transac - tions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2014 . 2346452 [ 33 ] A . Mathisen , T . Horak , C . N . Klokmose , K . Grønbæk , and N . Elmqvist . InsideInsights : Integrating Data - Driven Reporting in Collaborative Visual Analytics . Computer Graphics Forum , 38 ( 3 ) : 649 – 661 , 2019 . eprint : https : / / onlinelibrary . wiley . com / doi / pdf / 10 . 1111 / cgf . 13717 . doi : 10 . 1111 / cgf . 13717 [ 34 ] S . McKenna , D . Mazur , J . Agutter , and M . Meyer . Design Activity Framework for Visualization Design . IEEE Transactions on Visualization and Computer Graphics , 20 ( 12 ) : 2191 – 2200 , Dec . 2014 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2014 . 2346331 [ 35 ] D . Moritz , C . Wang , G . L . Nelson , H . Lin , A . M . Smith , B . Howe , and J . Heer . Formalizing visualization design knowledge as constraints : Ac - tionable and extensible models in draco . IEEE Transactions on Visualiza - tion and Computer Graphics , 25 ( 1 ) : 438 – 448 , 2019 . doi : 10 . 1109 / TVCG . 2018 . 2865240 [ 36 ] T . Munzner . A Nested Model for Visualization Design and Validation . IEEE Transactions on Visualization and Computer Graphics , 15 ( 6 ) : 921 – 928 , Nov . 2009 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2009 . 111 [ 37 ] C . North . Toward measuring visualization insight . IEEE Computer Graph - ics and Applications , 26 ( 3 ) : 6 – 9 , May 2006 . Conference Name : IEEE Computer Graphics and Applications . doi : 10 . 1109 / MCG . 2006 . 70 [ 38 ] C . North , P . Saraiya , and K . Duca . A comparison of benchmark task and insight evaluation methods for information visualization . Information Vi - sualization , 10 ( 3 ) : 162 – 181 , July 2011 . doi : 10 . 1177 / 1473871611415989 [ 39 ] T . O’Brien , A . Ritz , B . Raphael , and D . Laidlaw . Gremlin : An Interac - tive Visualization Model for Analyzing Genomic Rearrangements . IEEE Transactions on Visualization and Computer Graphics , 16 ( 6 ) : 918 – 926 , Nov . 2010 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2010 . 163 [ 40 ] W . A . Pike , J . Stasko , R . Chang , and T . A . O’Connell . The Science of Interaction . Information Visualization , 8 ( 4 ) : 263 – 274 , Jan . 2009 . Publisher : SAGE Publications . doi : 10 . 1057 / ivs . 2009 . 22 [ 41 ] P . Pirolli . Cognitive models of human - information interaction . In Hand - book of applied cognition , 2nd ed , pp . 443 – 470 . John Wiley & Sons , Inc . , Hoboken , NJ , US , 2007 . doi : 10 . 1002 / 9780470713181 . ch17 [ 42 ] P . Pirolli and S . Card . The sensemaking process and leverage points for analyst technology as identiﬁed through cognitive task analysis . In Proceedings of International Conference on Intelligence Analysis , vol . 5 , Jan . 2005 . [ 43 ] C . Plaisant , J . - D . Fekete , and G . Grinstein . Promoting Insight - Based Evaluation of Visualizations : From Contest to Benchmark Repository . IEEE Transactions on Visualization and Computer Graphics , 14 ( 1 ) : 120 – 134 , Jan . 2008 . doi : 10 . 1109 / TVCG . 2007 . 70412 [ 44 ] Z . Pousman , J . Stasko , and M . Mateas . Casual Information Visualization : Depictions of Data in Everyday Life . IEEE Transactions on Visualization and Computer Graphics , 13 ( 6 ) : 1145 – 1152 , Nov . 2007 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2007 . 70541 [ 45 ] A . Rind , W . Aigner , M . Wagner , S . Miksch , and T . Lammarsch . Task Cube : A three - dimensional conceptual space of user tasks in visualization design and evaluation . Information Visualization , 15 ( 4 ) : 288 – 300 , Oct . 2016 . Publisher : SAGE Publications . doi : 10 . 1177 / 1473871615621602 [ 46 ] S . Russell and P . Norvig . Artiﬁcial intelligence : a modern approach . 2002 . Chapter 2 . [ 47 ] D . Sacha , A . Stoffel , F . Stoffel , B . C . Kwon , G . Ellis , and D . A . Keim . Knowledge Generation Model for Visual Analytics . IEEE Transactions on Visualization and Computer Graphics , 20 ( 12 ) : 1604 – 1613 , Dec . 2014 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2014 . 2346481 [ 48 ] P . Saraiya , C . North , and K . Duca . An Evaluation of Microarray Visual - ization Tools for Biological Insight . In IEEE Symposium on Information Visualization , pp . 1 – 8 , Oct . 2004 . ISSN : 1522 - 404X . doi : 10 . 1109 / INFVIS . 2004 . 5 [ 49 ] P . Saraiya , C . North , and K . Duca . An Insight - Based Methodology for Evaluating Bioinformatics Visualizations . IEEE Transactions on Visu - alization and Computer Graphics , 11 ( 4 ) : 443 – 456 , July 2005 . doi : 10 . 1109 / TVCG . 2005 . 53 [ 50 ] P . Saraiya , C . North , Vy Lam , and K . Duca . An Insight - Based Longitudi - nal Study of Visual Analytics . IEEE Transactions on Visualization and Computer Graphics , 12 ( 6 ) : 1511 – 1522 , Nov . 2006 . doi : 10 . 1109 / TVCG . 2006 . 85 [ 51 ] A . Satyanarayan , D . Moritz , K . Wongsuphasawat , and J . Heer . Vega - lite : A grammar of interactive graphics . IEEE Transactions on Visualization and Computer Graphics , 23 ( 1 ) : 341 – 350 , 2017 . doi : 10 . 1109 / TVCG . 2016 . 2599030 [ 52 ] A . Satyanarayan , R . Russell , J . Hoffswell , and J . Heer . Reactive Vega : A Streaming Dataﬂow Architecture for Declarative Interactive Visualization . IEEE Transactions on Visualization and Computer Graphics , 22 ( 1 ) : 659 – 668 , Jan . 2016 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2015 . 2467091 [ 53 ] M . Sedlmair , M . Meyer , and T . Munzner . Design Study Methodology : Reﬂections from the Trenches and the Stacks . IEEE Transactions on Visualization and Computer Graphics , 18 ( 12 ) : 2431 – 2440 , Dec . 2012 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2012 . 213 [ 54 ] E . Segel and J . Heer . Narrative visualization : Telling stories with data . IEEE Transactions on Visualization and Computer Graphics , 16 ( 6 ) : 1139 – 1148 , 2010 . doi : 10 . 1109 / TVCG . 2010 . 179 [ 55 ] B . Shneiderman . Inventing Discovery Tools : Combining Information Visualization with Data Mining . Information Visualization , 1 ( 1 ) : 5 – 12 , Mar . 2002 . Publisher : SAGE Publications . doi : 10 . 1057 / palgrave . ivs . 9500006 [ 56 ] Y . B . Shrinivasan , D . Gotzy , and J . Lu . Connecting the dots in visual analysis . In 2009 IEEE Symposium on Visual Analytics Science and Technology , pp . 123 – 130 , Oct . 2009 . doi : 10 . 1109 / VAST . 2009 . 5333023 [ 57 ] Y . B . Shrinivasan and J . J . van Wijk . Supporting the analytical reason - ing process in information visualization . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , CHI ’08 , pp . 1237 – 1246 . Association for Computing Machinery , New York , NY , USA , Apr . 2008 . doi : 10 . 1145 / 1357054 . 1357247 [ 58 ] M . Smuc , E . Mayr , T . Lammarsch , W . Aigner , S . Miksch , and J . G¨artner . To Score or Not to Score ? Tripling Insights for Participatory Design . IEEE Computer Graphics and Applications , 29 ( 3 ) : 29 – 38 , May 2009 . Conference Name : IEEE Computer Graphics and Applications . doi : 10 . 1109 / MCG . 2009 . 53 [ 59 ] A . Srinivasan , S . M . Drucker , A . Endert , and J . Stasko . Augmenting Visu - alizations with Interactive Data Facts to Facilitate Interpretation and Com - munication . IEEE Transactions on Visualization and Computer Graphics , 25 ( 1 ) : 672 – 681 , Jan . 2019 . Conference Name : IEEE Transactions on Visu - alization and Computer Graphics . doi : 10 . 1109 / TVCG . 2018 . 2865145 [ 60 ] R . S . Sutton and A . G . Barto . Reinforcement learning : An introduction . MIT press , 2018 . [ 61 ] M . Vartak , S . Rahman , S . Madden , A . Parameswaran , and N . Polyzotis . SeeDB : Efﬁcient Data - Driven Visualization Recommendations to Support Visual Analytics . Proceedings of the VLDB Endowment International Conference on Very Large Data Bases , 8 ( 13 ) : 2182 – 2193 , Sept . 2015 . [ 62 ] K . Wongsuphasawat , D . Moritz , A . Anand , J . Mackinlay , B . Howe , and J . Heer . Towards a general - purpose query language for visualization recommendation . In Proceedings of the Workshop on Human - In - the - Loop Data Analytics , HILDA ’16 . Association for Computing Machinery , New York , NY , USA , 2016 . doi : 10 . 1145 / 2939502 . 2939506 [ 63 ] K . Wongsuphasawat , Z . Qu , D . Moritz , R . Chang , F . Ouk , A . Anand , J . Mackinlay , B . Howe , and J . Heer . Voyager 2 : Augmenting Visual Analysis with Partial View Speciﬁcations . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , CHI ’17 , pp . 2648 – 2659 . Association for Computing Machinery , New York , NY , USA , May 2017 . doi : 10 . 1145 / 3025453 . 3025768 [ 64 ] J . N . Yan , Z . Gu , and J . M . Rzeszotarski . Tessera : Discretizing data analy - sis workﬂows on a task level . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems , CHI ’21 . Association for Com - puting Machinery , New York , NY , USA , 2021 . doi : 10 . 1145 / 3411764 . 3445728 [ 65 ] Yang Chen , Jing Yang , and W . Ribarsky . Toward effective insight man - agement in visual analytics systems . In 2009 IEEE Paciﬁc Visualization Symposium , pp . 49 – 56 , Apr . 2009 . ISSN : 2165 - 8773 . doi : 10 . 1109 / PACIFICVIS . 2009 . 4906837 [ 66 ] J . S . Yi , Y . a . Kang , J . Stasko , and J . A . Jacko . Toward a Deeper Under - standing of the Role of Interaction in Information Visualization . IEEE Transactions on Visualization and Computer Graphics , 13 ( 6 ) : 1224 – 1231 , Nov . 2007 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2007 . 70515 [ 67 ] J . S . Yi , Y . - a . Kang , J . T . Stasko , and J . A . Jacko . Understanding and characterizing insights : how do people gain insights using information visualization ? In Proceedings of the 2008 conference on BEyond time and errors novel evaLuation methods for Information Visualization - BE - LIV ’08 , p . 1 . ACM Press , Florence , Italy , 2008 . doi : 10 . 1145 / 1377966 . 1377971 [ 68 ] Z . Zeng , P . Moh , F . Du , J . Hoffswell , T . Y . Lee , S . Malik , E . Koh , and L . Battle . An evaluation - focused framework for visualization recommen - dation algorithms . IEEE Transactions on Visualization and Computer Graphics , 28 ( 1 ) : 346 – 356 , 2022 . doi : 10 . 1109 / TVCG . 2021 . 3114814 [ 69 ] E . Zgraggen , A . Galakatos , A . Crotty , J . Fekete , and T . Kraska . How Pro - gressive Visualizations Affect Exploratory Analysis . IEEE Transactions on Visualization and Computer Graphics , 23 ( 8 ) : 1977 – 1987 , Aug . 2017 . Conference Name : IEEE Transactions on Visualization and Computer Graphics . doi : 10 . 1109 / TVCG . 2016 . 2607714 [ 70 ] E . Zgraggen , Z . Zhao , R . Zeleznik , and T . Kraska . Investigating the Effect of the Multiple Comparisons Problem in Visual Analysis . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , CHI ’18 , pp . 1 – 12 . Association for Computing Machinery , New York , NY , USA , Apr . 2018 . doi : 10 . 1145 / 3173574 . 3174053