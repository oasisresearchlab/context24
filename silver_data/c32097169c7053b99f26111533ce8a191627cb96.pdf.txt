Designing to Stop Live Streaming Cyberbullying A case study of Twitch Live Streaming Platform Yingfan Zhou YIZ142 @ pitt . edu School of Computing and Information University of Pittsburgh Rosta Farzan rfarzan @ pitt . edu School of Computing and Information University of Pittsburgh ABSTRACT Cyberbullying is widespread in online communities . The ability to protect users and platforms from the dangers of cyberbullying has become essential . In this work , we conducted a qualitative study of Twitch community to explore the design elements that can influence cyberbullying behavior and the reaction to it on a live - streaming platform . Our study involved interviewing 11 Twitch streamers and six months of Reddit posts from a Twitch sub - reddit community about Cyberbullying . The results of the study illustrate a number of design themes unique to live streaming platform that can promote or inhibit cyberbullying , including most importantly the informa - tion asymmetry between broadcaster and viewers . Based on our analysis results , we propose design guidelines for the live stream - ing platform to better support their users in intervening cases of cyberbullying . CCS CONCEPTS • Human - centered computing → Collaborative and social computing design and evaluation methods . KEYWORDS Cyberbullying , Design , Qualitative Study , Mixed Methods , Live streaming ACM Reference Format : Yingfan Zhou and Rosta Farzan . 2021 . Designing to Stop Live Stream - ing Cyberbullying : A case study of Twitch Live Streaming Platform . In C & T ’21 : Proceedings of the 10th International Conference on Communities & Technologies - Wicked Problems in the Age of Tech ( C & T ’21 ) , June 20 – 25 , 2021 , Seattle , WA , USA . ACM , New York , NY , USA , 13 pages . https : / / doi . org / 10 . 1145 / 3461564 . 3461574 1 INTRODUCTION With the growth of popularity of online communities and partic - ularly social media , cyberbullying has become a common threat on many online platforms . Despite the widespread cases of Cyber - bullying , there is a variety of ways Cyberbullying is defined and perceived . One common definition used in prior literature , consid - ers Cyberbullying as any behavior performed through electronic Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA © 2021 Association for Computing Machinery . ACM ISBN 978 - 1 - 4503 - 9056 - 9 / 21 / 06 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3461564 . 3461574 or digital media by individuals or groups that repeatedly commu - nicates hostile or aggressive messages intended to inflict harm or discomfort on others [ 59 ] . Flaming , harassment , denigration , impersonation , outing and trickery , interpersonal exclusion , and cyberstalking are examples of cyberbullying behavior [ 62 ] . These behaviors are common in many electronic communication plat - forms , including emails , text messages , online games , and social media . Duggan [ 14 ] reported that the number of individuals who experienced cyberbullying has increased to 41 % in 2017 compared to 35 % in 2014 . 31 % of individuals who experienced cyberbullying suffer emotional stress , psychiatric and psychosomatic health is - sues , such as headache , depression , anxiety , and even attempt at committing a suicide [ 14 , 27 ] . Additionally , cyberbullying can neg - atively impact the platforms as it degrades user online experience and can cause the platforms to lose users [ 31 , 33 ] . The ability to combat cyberbullying and to create a safe online space has become an important priority for policy makers , platform designers , and online groups [ 33 , 62 ] . The goal of this study is to understand how the design of online platforms can influence occurrence of cyber - bullying and users’ reactions to it . There are numerous studies on mitigating and reducing cyberbullying in various research areas . In computer science , one key research area focuses on the auto - matic detection of cyberbullying behavior using natural language processing and machine learning techniques [ 1 , 1 , 50 , 66 ] . The auto - matic detection tools moderate online content and possibly delete toxic content to decrease the harm of bully language on victims . Although the accuracy of some of the present predictive models for cyberbullying cases is high [ 44 ] , automatic cyberbullying detection still has limitations and applies to specific contexts . For example , the detection algorithms often cannot distinguish between humorous language and bully language [ 12 ] . Additionally , the performance of detection models relies on the size and quality of the training datasets that are often labor intensive and complex to generate . Existing datasets rarely cover every type of cyberbullying behavior and the standard of judgment on cyberbullying behavior is influ - enced by the annotators [ 46 ] . Also , the use of user data to build such algorithms can lead to privacy concerns [ 44 ] . Overall , cyberbullying detection technology still needs to be combined with intervention and prevention actions on the platforms [ 46 ] . Complementing the detection approaches , the platforms’ inter - face design can provide an opportunity to mitigate or prevent cy - berbullying and support victims of cyberbullying . Lowry et al . [ 38 ] noted that system design features , such as identifiability , monitor - ing , or awareness of social presence can help reduce the difference of power between the perpetrator and the victim , thus lead to pre - vention of the cyberbullying behaviors [ 38 ] . Recent studies [ 11 , 58 ] have emphasized the role of bystanders in cyberbullying incidents 138 C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Zhou and Farzan and have found that certain design features can encourage and sup - port bystanders to mitigate cyberbullying . DiFranzo et al . [ 11 ] found that the presentation of information about the audience size and viewership increases the possibility of bystander’s interventions through public surveillance , accountability , and personal responsi - bility . They suggested that the bystanders are more likely to request help from administrators rather than fight against bully behavior themselves . Taylor et al . [ 58 ] evaluated the effect of design focusing on empathy nudges and social transparency , including presenting a feeling prompt above the comment box and the view notification . Their experimental study verified the hypothesis that the design changes can increase accountability and empathy in bystanders and encourage them to intervene they witness cyberbullying . In this study , we focus on the live streaming platforms and aim to understand how different design elements influence occurrence of cyberbullying incidents and users’ reactions to them . We use Twitch 1 as an exemplary live streaming platform . Twitch is one of the largely used live streaming platform , ranked 4th in the US internet traffic [ 13 ] . We conducted a qualitative study involving 11 individual interviews of Twitch streamers and a content analysis of six months of posts from the Reddit Twitch community related to cyberbullying 2 . Our study explored design elements that deemed important to the live streaming platform in relation to cyberbullying . Based on our findings , we propose guidelines on how live stream - ing platforms can be redesigned to better support prevention and intervention of cyberbullying . Our study contributes to increasing understanding of cyberbullying in the context of multi - media inter - actions and how design of socio - technical systems can be improved to support victims and communities in dealing with cyberbullying . Specifically , in this work we seek to answer the following re - search questions : ( 1 ) RQ1 : ( a ) At what level design elements identified in the prior literature appear to be important in relation to cyberbul - lying incidents on live - streaming platforms ? ( b ) Are there design elements specific to live - streaming platforms that are important in relation to cyberbullying ? ( 2 ) RQ2 : How do these design elements impact user behavior on live streaming platform and What are the challenges and opportunities faced by live streaming platforms in dealing with cyberbullying ? 2 LIVE STREAMING PLATFORMS Live streaming platforms refer to the media environments that enable users to broadcasts over the Internet in real - time . The pop - ularity of online live streaming platforms has attracted a large number of users across various cultural backgrounds in the past decade [ 40 , 42 ] . Three in ten global internet users aged 16 to 64 have watched a live gaming stream as part of their routine internet activities 3 . Most popular live streaming platforms include Face - book Live , Instagram Live , YouTube Live , and Twitch 4 . Key to all live - streaming platforms is the integration of multimedia , including 1 https : / / www . twitch . tv / 2 https : / / www . reddit . com / r / Twitch / 3 https : / / blog . globalwebindex . com / chart - of - the - week / the - rise - of - twitch / 4 A number of other live streaming platforms have been shut down in recent years , including Periscope that was shut down in March 2021 , and Meerkat that was shut down in 2016 using of Webcam to stream video and voice . Viewers can interact with the streamers through chatrooms , using rich texts including emojis . They also support the streamers to provide Video On De - mand ( VOD ) once the live streaming is over . The degree of public access , however , varies across these platforms . Unline YouTube live and Twitch , Facebook and Instagram Live are closely connected to the social network structure they are part of and provide the streamers with an option to choose the scope of the audience and for example , to limit their audience to only friends . A study of Face - book live also indicate a large percentage of interaction of viewers happens after the live streaming , making it “less live” [ 42 ] . Our study focuses on Twitch live streaming platform . The open - ness and public nature of Twitch makes is particularly an interest - ing case for study of Cyberbullying . As of February 2020 , Twitch owns 15 million daily active users and 3 million monthly cre - ators ( broadcaster ) 5 in over 230 countries . As of 2019 , 65 % of Twitch users identify as male , and 35 % as female . Majority of Twitch users are below 44 years old ( 44 % 16 to 24 , 32 % 25 to 34 and 17 % 35 to 44 ) . 10 % of the users are above 44 years old 6 7 . Figure 1 shows the main user interface of Twitch while watching the stream . Different elements of the interface have been identified in the Figure , including the live video of the streamer , the game environment , the streamer profile information , and the comments from the viewers 8 . Twitch provides services to their users with diverse forms of media , such as projection of the game environments , the streaming of the live webcam video , and a text - based online chat . Any individual can have a personal channel to broadcast their own activities and interact with viewers in real - time . The use of various multimedia features helps to reduce the virtual space between users and promotes online interpersonal relationship building [ 3 , 45 , 49 ] . Moreover , the communication happening on the streaming channel help streamers and viewers to gain shared experiences and form a community [ 24 ] . Within these communities of communities , the broadcaster of a streaming channel plays a leading role in community building and manage - ment . As a result , the norms and the rules vary across different streaming channels [ 24 ] . The diversity of communication and the resulting norms and rules have introduced nuances with respect to cyberbullying . Within this same live streaming platform , the incidence of cyberbullying and the degree of tolerance of it differs across various streaming channels . This has lead to challenges in identification of bullying behavior as well as moderation and management of cyberbullying on live - streaming platform [ 16 , 41 ] . A few prior studies have explored the issues of cyberbullying on live streaming platforms [ 21 , 22 , 56 ] . Their results indicate that cyberbullying in the form of inappropriate language is likely to happen , and especially in case of political live streaming [ 22 ] or when the streamer is female in game streaming [ 21 ] . This inappropriate language along with the synchronous interactions and with large number of comments can often make the streamers overwhelmed [ 22 ] . While previous research studied system designs related to cyberbullying behavior on various social media 5 https : / / videogamesstats . com / twitch - stats - facts / 6 https : / / twitchadvertising . tv / audience / 7 https : / / blog . globalwebindex . com / chart - of - the - week / the - rise - of - twitch / 8 To protect privacy of the users , we have blurred out the comments in this figure . 139 Designing to Stop Live Streaming Cyberbullying C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Figure 1 : Main interface of Twitch live streaming platform , 2020 . platforms [ 2 , 11 , 51 , 58 ] , there is limited research about the rela - tionship between system features and incidents of cyberbullying on live streaming platforms [ 6 , 30 , 47 , 47 ] . The unique features of real - time interactions on live streaming platforms can make it particularly challenging to fight toxic behaviors . At the same time , the innovative streaming services and the patterns of user behavior on the live streaming platform can provide new and unique op - portunities to understand the relationship between system design elements and cyberbullying behavior that happens in multi - media context and across various sub - communities on the platform . 3 INTERACTION DESIGN AND CYBERBULLYING Within the context of live - streaming platforms and Twitch in par - ticular , we identified five key design elements that can be especially relevant to cyberbullying . While a number of other factors such as audience demographics , content genre , or level of streamer’s experience can be relevant to cyberbullying on these platforms , we focus on features that ( 1 ) have been identified by prior research related to cyberbullying and interaction design as important ; ( 2 ) they correspond to structure and elements that can be manipulated by the designers of these platforms to afford different interaction patterns . We discuss each of these elements and the possible rela - tionship between these design elements and cyberbullying behavior on live - streaming platforms . 3 . 1 Synchronous interaction Synchronous interaction , i . e . the ability for the users to interact with each other in real - time is a key feature of live - streaming platforms . As the streamers broadcast on the platform , the built - in chatroom allows users to react to the streamer instantly with text - based communication [ 40 ] . This is in contrast to many content sharing platforms on which the interaction between the content creator and other users is asynchronous and not real - time . The delay in sharing of the content and interactions provide the opportunity for users to think , organize their thoughts , and consider their language before commenting [ 4 ] . On the other hand , the instant , continuous , and rapid expressions happening on live streaming platforms can lead to inappropriate and harmful language . The fast reaction has been shown to increase users’ cognitive load [ 20 ] and under high cognitive load and high levels of time pressure , people are more likely to make decisions based on feelings rather than thoughtful processing of the situation [ 60 ] . The intensity of the situation may inhibit ethical decision making and sense - making [ 17 , 19 ] . This moral disengagement is significantly associated with cyberbullying behavior [ 61 ] . As a result , we anticipate that design features on Twitch that promote synchronous interactions can be viewed to lead to higher instances of cyberbullying . 3 . 2 Anonymity Anonymity and not sharing personal identifiers in online activities have been offered by many platforms to protect the privacy of users . At the same time , it can affect the user’s behavior in the group . Hiding identifiable information that can be associated with status , or stereotypical biases can provide an opportunity for more equitable access and promote community engagement [ 9 ] . However , it can also suspend offline moral inclinations and promote anti - social and aggressive behaviors [ 9 , 26 , 39 ] , including cyberbullying [ 29 ] . The perpetrator’s confidence in their ability to escape from the punishment of cyberbullying can be increased when it is more 140 C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Zhou and Farzan difficult to identify them or trace back the history of their activities to them [ 39 , 65 ] . Anonymity can also lead to the possibilities of creating multiple accounts under the same identity . The ability to create an unlimited number of accounts with temporary identities or pseudonyms decreases the cost of cyberbullying as allows the perpetrator to escape from incidence into other accounts [ 4 , 65 ] . The inability to identify the perpetrator or associate behavior with unique accounts can increase the emotional harm to the victims because the unknown perpetrator means that anyone can be their bully [ 54 ] . Anonymitycan beparticularly complexonlive - streaming platforms . While the viewers can stay anonymous , streamers are fully exposed to their viewers . Streaming videos present streamers’ personal styles and disclose information such as , appearance , sur - rounding environment , or their voice that can include information such as specific accent . As a result , we anticipate that anonymity in general and specifically this nonreciprocal nature of it on the live streaming platforms can lead to incidents of cyberbullying . 3 . 3 Ephemerality Ephemerality means that the user - generated content is transitory and will be deleted after a short time . For example , on 4chan 9 , an image - board website , only the most recent threads are saved [ 5 ] . The temporal content on 4chan decreases the liability in discourse and increases trolling behavior [ 32 ] . Ephemerality has been studied on several platforms to explore its relationship with cyberbullying behavior . Singh et al [ 52 ] conducted a focus group and follow - up individual interviews with high school students who use Snapchat , another social media platform with ephemeral content . They sug - gested that the ephemerality of media content leads to aggressive language and bullying behavior [ 53 ] , as it creates a perceived safe space for the perpetrators who think can escape from the pun - ishment of cyberbullying since the evidence of cyberbullying is less likely to be saved and available . At the same time , individual users assume the content will be deleted soon , and might not worry about what they shared in a snap . However , the perpetrator may save the content in other ways ( i . e . , screenshots ) for later bullying purposes . On Twitch , by default , the broadcasts are ephemeral and can not be stored . Broadcasters can enable VOD ( video on demand ) to archive streaming videos with chat history in the chatroom and share online after the broadcast ends . Based on prior research on ephemerality and potentially of bullying behaviors , we hypothesize that ephemerality of live streaming videos and chat room messages can be associated with increases of cyberbullying behavior . 3 . 4 Invisibility Invisibility refers to the ability to be physically unseen [ 55 ] . Under text - based online interactions , the users can often hide their physi - cal presence , such as how they look , how they sound or how their surroundings look like . Previous literature shows that invisibility contributes to the online disinhibition effect which means people can be more likely to behave online with less restraint compared to their offline usual behavior [ 7 , 55 ] . The lack of face - to - face commu - nication and eye contact can make users feel free from the offline social norms and restrictions . The users are more willing to act aggressively in a text - based environment ; for example , it is shown 9 https : / / www . 4chan . org / text - based environment can increase online flaming [ 35 ] . Integra - tion of diverse media , including video , voice , and text , on the live streaming platform provides opportunities towards relationship building with the broadcaster ; however , similar to anonymity it has a nonreciprocal nature . The viewers can see the broadcaster and their surroundings , but they are invisible to the streamer . We hypothesize that the visibility design on live - streaming platforms can lead to mixed results with respect to cyberbullying : on one hand the visibility of the streamer can support positive behavior and community building but on the other hand the imbalance of high invisibility of viewers can lead to cyberbullying behavior . 3 . 5 Moderation Moderation is the practice of setting the norms or policies . Modera - tors act as an arbiter to judge the appropriateness of user - generated content [ 18 , 43 ] . Currently , two major models of moderation are applied to govern most online communities : ( 1 ) automated con - tent moderation , such as AI - based approaches in detecting in - appropriate content [ 12 ] or filtering language with the blacklist terms [ 30 ] ; ( 2 ) human moderation , including centralized and fed - erated moderation [ 36 ] . In centralized moderation , the content is judged by a closed group of moderators [ 36 ] . Federated moderation means that the judgment is made by a distributed group of peo - ple who participate in the online community [ 34 ] . Live - streaming platforms such as Twitch include both automated and human moderation [ 30 , 47 , 48 , 64 ] . Gillespie [ 18 ] pointed out that the con - tent moderation acts as the gatekeeping , shaping the content pre - sented on the platform and decreasing the bullying content on the platform . Additionally , Wise et al [ 63 ] found that the users are more likely to control their behavior in the moderated community which reduces flaming and trolling . On Twitch , the human moderation follows a distributed model and the norms and rules in each channel are strongly influenced by what the broadcasters and their modera - tors enforce . We hypothesize that this distributed moderation can support groups to enforce levels of moderation appropriate to their group , reduce cyberbullying behavior , and encourage a healthy community environment . 4 METHODS In this study , we conducted semi - structured interviews with Twitch users and content analysis on posts in a Reddit Twitch community . This study is reviewed and approved by the Institutional Review Board at the University of Pittsburgh . We combined interviews with content analysis of Reddit posts to reduce the self - selection bias inherent to interview studies . By complementing the interviews with open content on a Twitch community on Reddit , we were able to collect broader perspectives on how interaction design on Twitch relates to cyberbullying and how do the community responds to it . 4 . 1 Interview Study To recruit participants for the interview study , ( 1 ) we contacted users on Twitch using the in - system messaging ; and ( 2 ) we con - tacted users on Twitter who posted Twitch related tweets or if their profiles and tweets contained keywords , such as Twitch , streaming , stream , streamer . The recruitment focused on Twitch users who 141 Designing to Stop Live Streaming Cyberbullying C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA were familiar with live streaming but we did not focus on any spe - cific role within Twitch to be able to collect user experiences and perspectives in different roles in relation to cyberbullying . Overall , we contacted 400 users on Twitch and Twitter but only received responses from only 16 Twitter users and 11 people agreed to partic - ipate in interviews . Two participants shared one streaming channel and were interviewed together . The interviews happened between July , 2020 till Sep , 2020 . Four interviews were conducted on Twitter with direct messages by text . Seven interviews were conducted on Zoom by video . The video interviews lasted between 30 to 120 minutes . Interviews done through text messaging took 120 min - utes to several days to finish all questions . All our interviewees identified as streamers . Three out of 11 also identified as modera - tor . Nine participants identified as female and two participants as male . In terms of ethnicity , our participants included seven white , two Asian / Pacific Islander , and two Hispanic / Latino . The age of participants ranged from 18 to 32 . Compared to the general Twitch demographic , our sample represent significantly more female . The interview included three sections : It started with demo - graphic questions , including race , age group , and gender . The sec - ond part included questions on their general experience with using Twitch . Example questions included , “Can you describe what you usually do on Twitch ? ” , “How do you interact with other users ? ” . Once we learned about their general usage of the platform , the par - ticipants were encouraged to talk about cyberbullying and whether and how they had experienced it on Twitch . They were invited to share their thoughts as much as they were comfortable doing so . Example questions included , “Can you tell me what you think cyberbullying is ? ” , “What do you usually do if you encounter a case of cyberbullying ? ” 4 . 2 Reddit Twitch Community To enrich our interview data , additionally , we collected posts from a Reddit Twitch community 10 in order to diversify our data repre - sentation of cases of cyberbullying issues on Twitch . The Twitch community on Reddit is very active and also the public and open nature of data on Reddit made it an appropriate source of data for our study . We queried Reddit Twitch community for the posts containing keywords such as cyberbully , bully , and harassment [ 62 ] , and col - lected the relevant posts and their associated related comments in 6 months prior to data collection , from April , 2020 to September , 2020 . We identified other relevant keywords from these initial results , in - cluding terms such as sniping , doxxing , or stalking . We then refined our search with these new queries for the posts in the same time period . We manually eliminated the threads that did not include information about cyberbullying . Overall , after the filtering , our data included 48 original Reddit threads which included the original posts and related comments . The average number of comments for the threads in our data is 34 . In total , we coded 1 , 660 posts including the original posts and comments in the 48 Reddit threads . 4 . 3 Thematic analysis We used Temi ( https : / / www . temi . com / ) to automatically transcribe the interviews and reviewed the transcripts for accuracy manually . 10 https : / / www . reddit . com / r / Twitch Figure 2 : Example of the coding process We then conducted a mixed of open coding as well as coding of any information related to the five identified design elements of anonymity , invisibility , ephemerality , moderation , and synchro - nous interaction . The coding on the transcripts and Reddit posts was done using the NVivo software . After finishing coding 4 in - terviews and 20 Reddit posts , we created a set of initial codes such as “streaming setting” , or “community building” . We then clustered the codes based on the relationship between them into categories . These formed our codebook for coding the rest of the data . We re - fined the coding book while coding the rest of the data . Overall , 550 initial coding nodes were created . After classifying the relationship between initial codes , we categorized and generated 55 first - level categories . In another iteration to make the categories more gen - eral , the 55 were grouped into second - level categories , a total of 23 . Overall , three major themes emerged in our data , including “cyberbullying behavior” , “system design features” , and “streaming” . Each theme includes sub - themes ; for example , system design was further included the five interaction design elements as well as new elements that we identified in our data . Cyberbullying behavior theme includes definition of cyberbullying , behavior associated with it , reaction of users to it , and possible solutions . Figure 2 repre - sents example of our coding process , and how low level codes were generated and categories to higher level categories and themes . 5 FINDINGS In this section , we present our findings in response to our research questions about our participants’ experiences with cyberbullying on Twitch and how the different platform features relate to these experiences . To anonymize , the participants are represented by just a number for example P1 , or P2 and Reddits posts with R1 , R2 , etc . 5 . 1 RQ1 - Interaction design elements and cyberbullying on live - streaming platforms In response to our first research question , we coded how these ele - ments appeared in our interview and content analysis data and what other key elements were highlighted in our data . Table 1 shows the summary of interaction design elements related to cyberbullying on Twitch and how they are represented on Twitch . Overall , we observed that four out of the five design elements identified in the prior literature also emerged in our data as impor - tant factors experienced by Twitch users . All of our participants confirmed the importance of moderation , synchronous interaction , anonymity , and invisibility in relation to cyberbullying on the live 142 C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Zhou and Farzan Table 1 : Design elements and related platform features Implementation on Twitch Synchronousinteraction Live video broadcasting and live chat - room both support synchronous inter - actions Anonymity Live video makes broadcasters not anonymous to viewers but no identifi - able information is displayed about the viewers in the chatroom Visibility Webcam and broadcasting provides high degree of visibility ; the textual cha - troom provides very low degree of visi - bility Ephemerality Most content on Twitch is ephemeral by default ; VOD ( video on demand ) pro - vides option for permanent content by choice of the streamer Moderation Twitch supports automatic language fil - tering and community moderators streaming platform . Moderation was particularly very strongly highlighted in our data . 42 out of 48 Reddit threads talked about how they use moderation to deal with the cyberbullying . They highlighted two main moderation settings on the live streaming platform , including language filtering and human moderation to deal with the cyberbullying and to decrease the negative impact of cyberbullying on the community . Quotes below exemplifying how these elements were observed in our data : “ mods 10000 % make sure they know ( I’m as - suming they already do ) about this situa - tion ( cyberbullying ) and let them play defense in chat . ” - R1 “ you could always try stepping up on the auto moderation you have on your stream or have bots do it for you . ” - R2 After moderation , invisibility and anonymity were next in terms of their importance in our data : 18 out of 48 Reddit threads talked about anonymity and 9 Reddit threads mentioned invisibility . Our interview participants confirmed the anonymity and invisibility are closely related to cyberbullying behaviors , as highlighted in the example quote below . “ Cause you cant see the other person , they think that the other person is not really there and in a sense you just stay stuff and nothing can happen to you . Like its almost anonymous . ” - P3 Synchronous interaction is fundamental to the live - streaming plat - form and it existed implicitly in all our data . It was explicitly high - lighted in 17 Reddit threads and all our interview participants talked about how this synchronous interaction impacts their communica - tion with their viewers . They specifically identified how this instant communication between streamers and viewers is important when users face cyberbullying . P4 shared his idea about how synchronous interaction support both the streamers and viewers perspective . “ I try to tell them that its not right to do smth like this , try to explain to them . . . the kind of help i would want is my community standing up for me , defending the stream and themselves . . . I take pride in being interactive and responsive to my audience . ” - P4 The concept of ephemerality did not come up in any of our partici - pants’ responses about their experience on Twitch and appeared only once in our Reddit data . In addition to the five elements from prior literature , we identi - fied two additional important interaction elements related to cyber - bullying on Twitch : signaling and rule setting . By Signaling . we refer to interaction elements that provide the ability to the user to convey particular information to the receiver [ 10 ] . The streamer use plat - form interface features such as tagging to signal their viewers about what kinds of content and behavior is accepted in their channel . Rule setting refers to interaction elements that provide the users with the ability to generate rules and using rules to organize social interactions [ 15 ] . The rule setting mainly includes the chat rules set by the streamer and moderator and terms of service set by Twitch . While these two elements might not be specific to live - streaming platforms , they support important interaction patterns on Twitch with regards to dealing with cyberbullying as we discuss in more de - tails in the next section . Two of our participants raised the concept of signaling and two out of 48 Reddit threads mentioned signaling . Six interview participants and 16 Reddit threads mentioned the rule setting . Below , there is an example of indication of the chat rules in one of the Reddit posts . “ Ultimately though you’re in control of your stream , nothing stopping you from banning them if they’re making you uncomfortable . That’s why there are chat rules ” - R3 5 . 2 RQ2 - User behavior in response to cyberbullying on live - streaming platform Below , we highlight the main themes that emerged in our data which present the challenges and opportunities of live - streaming platforms in dealing with incidence of cyberbullying and how differ - ent design elements influenced the user behavior on the platform . Anonymity combined with synchronous interaction generate new type of cyberbullying behavior known as sniping Unlike other social media platforms , full anonymity is almost im - possible for streamers on the live - streaming platforms because of its unique media format . While viewers can stay fully anonymous with non - identifiable usernames and even multiple usernames and accounts , lots of information about the identity of the streamers is available to the viewers . Most streamers publicly broadcast their game playing and using the microphone to share their opinions or to chat with the viewers in real - time [ 24 , 37 ] . In addition to reveal - ing identity information , this live streaming also provides clues for other users about the streamer game environment [ 37 ] . Viewers can gather in - game information from the streaming content , such as in - game location , or in - game role , and use this information to their 143 Designing to Stop Live Streaming Cyberbullying C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA advantage in the same game . This behavior is called stream sniping which is considered as cyberbullying behavior in our participants’ opinion . P6 explains the streaming snipping : “ It’s basically when they watch my stream to know where I am so that they can kill me and my team . . . they’re going to be like , Hey , Twitch , streamer , you’re an idiot . Why don’t you have more latency on your stream ? ” - P6 The stream snipping harms the vibe of the streaming channel and streamers’ experience , as described in this Reddit post : “ I have been getting stream sniped by an - other twitch affiliate for a few days in a row now . . . Anytime I’m playing he will come with his clan and ruin the stream . It’s really upsetting as I’ve had pretty good growth with this game and I’d rather not give up on it . ” - R4 High level of visibility is a double - edged sword in live - streaming platform Our participants confirmed the advantages of the availability of multi - media features on Twitch , especially , they expressed that us - ing the webcam makes streaming more interesting , attracts viewers , and increases their engagement . “ Viewers want to see and hear you too . like I said , it makes it easier for them to interact with a face . . . added activities you can do on stream ( like cook - ing streams or some traditional art streams ) ” – P5 At the same time , more visibility brings risks since multi - media based communication exposes more personal information than textual communication . This was highlighted in a number of Reddit posts and comments , including the following : “ People can and will mess with us , because show - ing yourself live on the Internet makes you vul - nerable , as you are giving up your anonymity . It sucks , but that’s what we get for streaming , I suppose . ” - R5 Moreover , not only streamers themselves but others who might appear on the webcam can be the target of harassment and personal attack . For example , it was mentioned in R7 “ he saw my girlfriend in the webcam and talked about her pants . . . but then my girlfriend send me a screenshot ( to not bring to much attention to it on stream ) where this guy was asking her for pictures of her feet and nudes . ” - R7 Additionally , the online activity of the streamer is easier to be traced , which exposes them to risks of cyberstalking . Even if the streamers change their username and their channel name to escape from the bullying incidence , the perpetrator is able to identify them based on their video , image , or sound and continue the harassment . “ The troll will easily be able to track OP down again based on schedule and categories . Espe - cially if he uses a cam . ” - R8 5 . 3 One way and unbalanced anonymity increases cyberbullying on Twitch There are many reasons to support anonymity on a social platform ; however , the one - sided nature of anonymity on Twitch which ex - poses the streamers fully to the viewers while viewers stay fully anonymous to the streamers contributes to increase cases of cy - berbullying towards the streamers , such as encountering sexual harassment and personal attacks based on the gender , appearance , or the surroundings of the streamer as highlighted in the quotes below in our data . “ There’s still that stigma that women should be in the kitchen . . . someone will come up in chat . . . they will be likely ( to say ) , go back to the kitchen . . . ” – P10 “ I get hate for my size and looks A LOT ! ” – R6 Overall our results highlight that the participants expressed concern regarding the one - sided and high - level anonymity and invisibility of viewers . They believe these can lead to more bullying behavior since perpetrators feel less exposed . “ people feel so powerful behind a screen . they think there are no consequences because no one can see them . . . ”—P5 Our results align with the finding in previous literature [ 35 ] that also highlights the relationship between anonymity and higher cases of cyberbullying ; however , what is unique in this context is the unbalanced nature of the anonymity between victims and perpetrators . While streamers expose more identifiable information than many other social media platforms , the viewers stay almost fully anonymous . Social anonymity increases the difficulty of the moderation Hayne and Rice [ 25 ] introduced two types of anonymity , including social anonymity and technical anonymity . Technical anonymity refers to the identifiers of individuals being removed or hidden from the online communication technically , such as hiding IP address , or not displaying the real name , or allowing non - identifiable user - names . Social anonymity refers to users not perceiving any social cue to attribute to the individual’s identity . On Twitch , the informa - tion which can identify users offline , such as IP address , is removed by default . Among viewers , users usually identify each other by the user ID and username . The viewers on Twitch are highly socially and technically anonymous , since it is difficult for streamers to identify the user identity behind several usernames or accounts . This technical and social anonymity introduces challenges with the moderation of content and behavior . For example , after P10 banned someone who sent inappropriate language in the chatroom , several new accounts came into the channel who continued same bullying behavior and seemed to be related to the same individual as P10 indicates : “ Sometimes I wonder if it is somebody I banned previously ” . Although frequent interaction between the streamer and viewers in the streaming channel may decrease social anonymity as pointed out by one of our participants ( P3 ) , social anonymity still increases the difficulty of moderation when streamers face some persistent cyberbullying behavior , as highlighted in the quote below from P8 . 144 C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Zhou and Farzan “ the more you stream and the more they come back you kind of get to know them and they become friends in a sense . . . when a viewer keeps coming back often it feels less anonymous . ” - P3 “ Nobody really has to put any of their private information public on platforms . I mean , you could make an account in like five minutes with a fake email address and a fake name . . . somebody if they want to go on a stream and be mean to somebody or comment hateful thing . . . They could just make a side account really easily . ” – P8 Since the cost of creating new accounts is low , the perpetrators can keep creating new accounts and then come back to the channel . There are no effective solutions for the streamers and moderators to stop continuous bullying with multiple accounts . In order to make streaming vibe active and stop constant bullying behavior , streamers and moderators need to keep deleting bully messages and punishing perpetrators , like banning , blocking , until they stop . However , it is difficult for the streamers , particularly those who are newcomers , to deal with this situation . For example , one streamer posted on Reddit , “ Someone just created nine troll accounts over the course of two hours so they could continuously ha - rass me on stream . . . . It’s easy enough to ban each account as it comes in , but it’s obviously some - thingI’drathernotdealwith everytimeIstream . . . Or is this just my reality until the person gets bored of me or I decide to stop streaming ? ” - R9 Some streamers get help by dedicating a moderation role in their channel . Previous studies pointed out that , in many cases , the mod - erators in those cases are the person who streamers have known for a long time , such as friends , family members , or regular viewers [ 64 ] . However , as a newcomer , with a low number of regular viewers , a streamer can face challenges in having the resources for moderating their channel , specifically when being repeated trolled by bullies . As a result , in a number of cases , the newcomer streamer gives up streaming or leaves the platform altogether . This was reflected in responses of our participants as well as the posts on Reddit : “ It is hard to find a person who will consistently be in the stream as well as be able to help out constantly . ” – P4 “ I tried to get mods but no one is willing to watch me stream for 3 hours a day . ” – R10 Synchronous interaction gives opportunities for instant moderation to limit cyberbullying Previous studies [ 55 ] point out that continuous and instant feed - back in the communication can help reinforce social norms . In our results , we observed that the continuous feedback is particularly beneficial to prevent cyberbullying in the synchronous interactions where the delay between the toxic behavior and feedback can be eliminated . Several respondents discussed how synchronous inter - actions between streamer and viewers reinforces the community norms on live streaming platforms . For example , some of our par - ticipants indicated that they stopped streaming and tried to have a conversation with the perpetrators and educate perpetrators when they faced cyberbullying incidence . “ Sometimes somebody will say something pro - voking but propound . So maybe it’s a good discus - sion piece . . . I’m gonna put you in timeout . You sit there and cool down . . . And then we’ll talk . . . and then I’ll un - time them out and I’ll see if they want to become correct . ” – P10 “ I do believe that some of these people are just looking for attention . I try to give them positive attention and tell them to cool it before laying down the hammer because sometimes people just don’t know how to get attention so they opt for the negative variety . ” – R11 Even if in some cases the reaction from perpetrators is to con - tinue the personal attacking , the conversation between streamers and users provides the hopeful possibility of decreasing the toxic behavior . For example , some perpetrators apologize after they have had a discussion with the streamer . “ Some people , they never say anything , and some people apologize and they’re like , Oh shit . I didn’t know . And it’s , it’s always really shocking when they apologize , because that’s such a rarity . Most of the time people are like , well , no , fuck you , blah , blah , blah . ” – P2 “ I’ve actually made two really good friends that came in and tried to insult me because they were upset then realized hi , she’s not trying to be a rude person . Let’s be friends now . So they either leave or they end up just stopping , being that angry and just enjoy watching a stream instead . ”—P6 Several participants compared the synchronous interactions pro - vided by live streaming platforms , such as Twitch , to the asynchro - nous interaction on the video - sharing platform , like YouTube . On Twitch , users cannot comment on the previously streamed videos . Moderators and streamers can manually ban a viewer who uses inappropriate language and delete related messages as soon as it appears in the chatroom . Only the chats that happened during the streaming can be saved and read by others after streamers upload the videos . The participants indicated that compared to asynchro - nous interaction , synchronous interaction between viewers and streamers with the possibility of ongoing and instant moderation decreases the possibility of bullying behavior , since ( 1 ) there is less time and opportunity for posting toxic messages ; ( 2 ) toxic messages can be identified instantly and therefore reduce their potential harm ; ( 3 ) synchronous communication involves smaller audience size who might be exposed to bullying behavior before it is being moderated . “ I would say [ YouTube is ] even more toxic than Twitch . . . The trolls’re looking to try and get an audience to their trolling . They’re trying to get attention most of the time . So , on YouTube , it’s really easy because you can just leave a com - ment on the video and everybody that watches the video will see it . But on Twitch , you pretty 145 Designing to Stop Live Streaming Cyberbullying C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA much have to be in the chat while the Twitch person is streaming . ”—P6 The synchronous interaction within the community can also provide emotional support for the victims right at the time that cyberbullying happens . “ Some will react and either speak up against the person or tell them off , others will simply say something supportive to myself / the streamer to boost their morale , which is really heartwarm - ing . ” - P1 Signaling and rule setting help to make the community norms visible and support the moderation process Most of our participants emphasized that focusing on building a pos - itive community can reduce toxic behavior and give support to the victims on the live streaming platform . Similar to past studies [ 24 ] , many of our participants described that the relationship between streamer and viewers can become a friendship and the streamer can play a leading role in building and managing their own community . “ You have the benefit of building the community you want . If you are a good person looking for good people , you will find an abundance of people like that out there . Spend you energy on the ones you want around you , and a quick ban to those you don’t . Your channel , your community , your rules ” – R12 Thus , the community norms are often different in different chan - nels as streamers has their own personal boundaries and approaches in building connections with their viewers . They also have different levels of tolerance to what appears as bullying behavior to them . “ So everybody has their own boundaries , I guess . . . so there’s probably things I allow that other people wouldn’t and likewise , those things other people allow that I absolutely would not . Um , I’ve seen people use like slurs and stuff , fa - mous streamers chats and the streamer just not care . . . I would not be cool with that . ” – P2 In order to build a supportive and positive community , the streamers set rules and use signals available on the platform to make their community norms visible and highlighted . These be - come guidelines for the streamers and moderators to manage the community . Users often use signaling to convey the information effectively on the platform . On Twitch , streamers use tags they can create and add to their channels as means to signal their community norms about streaming content , streaming style , personality , or attitudes on marginalized population ; for example , they use tags such as “Family Friendly” , or “Horror” to inform newcomers about channel content , or “LGBTQIA + ” tag to signal about care for a minority group . Additionally , Twitch provides a “mature content " flag that streamers can apply to their channel to notify viewers that their streams generally contain sensitive content . If this setting is applied , newcomers to the channel are presented with a message in - dicating that the stream is for mature audiences when they visit the channel for the first time . Such users are only permitted to view the streamed content after they click a button that reads “I understand " . “ Like I curse sometimes , and I don’t want a kid to come in and hear me cursing or stuff like that . So I marked my streams as 18 plus that way , most of my chat are adults . . . . So we do of course use adult language and occasionally bring up adult topics in moderation . ” – P6 Another example is the use of tag to protect minority groups such as LGBTQIA + group who are often scared of possible harassment on the live streaming platform . They have been recommended to use the tag to highlight their group and form a friendly community who can support each other . “ Stream in the LGBTQ tag ”—R13 “ There are lots of great people who have found me through the LGBTQ tag who are trans themselves . ” – R14 In addition to the informal signaling of the community norms , Twitch provides rule setting to support a more formal approach in regulating the social interaction on the platform . In addition to the platform - level term of service , Twitch platform allows the streamers to set their own rules to moderate and manage their channels . For example , the streamers set chat rules based on their expectation of the content and their acceptance of online behavior . Figure 3 provides an example for chat rules in the streaming channel which was set by one of our participants , P2 , who describes how she set rules to help her channel in being supportive of people with disabilities and minority groups . Figure 3 : Twitch community chat rule board ( secOne stream - ing channel ) “ I wanted to make a space that was safe for people with disabilities or who were LGBT or people of color . I wanted to make a space where everybody could feel safe and not feel marginalized . . . And then I have my chat rules . . . The first thing that greets you is don’t be racist . Don’t be sexist . Don’t be homophobic transphobic . Don’t be unable to just like do those things and we’re going to get on . ” – P2 Once the rules are set , then if someone breaks the chat rules , they will be banned or blocked in that channel . Streamers accept it as 146 C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Zhou and Farzan their responsibility to use these mechanisms to police their commu - nity and not let it become the breeding ground of bullying or harass - ment behavior . However , while having respectful and friendly view - ers as more important than just the number of viewers , some new streamers expressed concern aboout losing viewers due to banning . “ The only person responsible for the state of a channel’s chat is the streamer . . . If they are lax on moderation and let trolls do their thing then it turns into a toxic shitshow . If they ruthlessly moderate and build a community then they will have a supportive chat non - trolls will want to hang out in ” – R15 These community norms not only help to stop perpetrator’s bullying behavior , but also to encourage bystander behavior and intervening of bullying as demonstrated in the quote below : “ You can encourage your chat to call out bad behaviour and don’t accept it as the norm ” – R16 6 DISCUSSION In this study , we explored the design elements related to cyberbul - lying behavior on the live streaming platform . We first identified five elements from prior literature , including anonymity , ephemer - ality , synchronous interaction , invisibility , and moderation as key interaction elements that can influence occurrence of cyberbullying incidents as well as the user behavior during cyberbullying inci - dent on social media platforms . Four of these five elements were identified as important factors on Twitch through our qualitative analysis . Ephemerality did not appear to be as important in our data . Additionally , through our qualitative analysis , we identified signaling and rule setting to be particularly important on Twitch platform in dealing with cyberbullying . Our second research question was focused on understanding the impact of specific interaction design elements on user behavior in dealing with cyberbullying . In our results , we highlight how the design decisions on Twitch platform provide challenges and oppor - tunities for the streamers as they interact with their viewers . We particularly observed how interaction design elements can inter - act with each other and create nuances in the interaction patterns and promotion or prevention of cyberbullying . More specifically , compared to asynchronous video - sharing platform , synchronous interaction on Twitch provides streamers ( content creators ) instant feedback from viewers . The synchronous interaction combined with moderation decreases the harm of cyberbullying . At the same time , lower invisibility combined with synchronous interaction exposed information in real time and induce stream sniping . This aligns with findings from previous studies that point out the information asym - metry between perpetrators and victims leads to cyberbullying [ 38 ] . The information asymmetry also existed on the live streaming plat - form between different roles . For example , compared to streamers , the viewers exposed less personal information . The unbalanced anonymity between the streamer and viewers induced cyberbully - ing . It also increases the difficulty in escaping from the perpetrator and introduces new challenges for moderation . The information asymmetry also affects the newcomers as compared to the estab - lished members of the community . As the norms of cyberbullying varied across different channels defined by different streamers , new - comers who are not familiar with the community norms can be more likely to behave inappropriately . To help newcomers , the streamers utilize signaling and rule - setting to reduce this informa - tion asymmetry in order to prevent the undesired behavior . 6 . 1 Limitations As any research , our study is not free of limitations . Most impor - tantly the number of participants in our interview study is lim - ited and also skewed towards female streamers . Given the higher percentage of male users on Twitch ( 65 % ) , this is particularly an important point of consideration . We speculate that female users might be more likely to be victims of cyberbullying on this plat - form , as suggested by prior research and perhaps more likely to respond to call for participation in a study about that . However , future research with more balanced representation of users both in terms of gender distribution and role distribution is necessary . Observations in streaming channels might be a method to over - come some of these biases ; however , often members of social media groups are not happy to consent to be observed as part of a re - search study . Additionally , our study has focused on cyberbullying towards streamers while cyberbullying can happen by streamers towards viewers or viewers towards each other . In considerations of future design of platforms , it is important to understand these different possible targets and sources of cyberbullying . Design Implications Informed by our study of prior literature and our current research , and assessment of the current platform designs , in this section we provide a few design guidelines to be adapted by live - streaming plat - forms to better support their users in dealing with cyberbullying . Design Guideline 1 : Reducing unbalanced anonymity can reduce chances of cyberbullying . Future design on the live streaming platform should consider to reduce the anonymity un - balance between streamers and viewers . This can be achieved by allowing the streamers to conceal some of their personal infor - mation . As viewers like to see the reaction of streamers to the game , multimedia using is a trade - off for the streamers between the entertainment of streaming and putting themselves at risk of cyberbullying . To support less disclosure of the identifiable per - sonal information , the platform , for example , can provide 2D or 3D model for the streamer to catch their facial expression and or provide a voice changer to allow streamers to alternate their real voice . Additionally , since the activity on the live streaming platform is closely linked to other platforms , like the audio chat platform , the game , the live streaming platform should coordinate with other platforms to cover the privacy information [ 37 ] . Another direction to address this unbalance of anonymity is to decrease the high social anonymity of viewers . Based on our find - ings , two features are closely related to the high social anonymity of viewers . One is the low cost of creating accounts . The users can cover their identityunder multiple accounts . The platformshould in - crease the cost of creating accounts , like the phone number of credit card verification , or set time intervals between account creation on the same device . Second is the difficulty in tracing back certain activity to specific viewers which also increases social anonymity 147 Designing to Stop Live Streaming Cyberbullying C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA of the viewers [ 65 ] . The platform can present the viewer’s history of activities , particularly any action leading to banning or blocking , more visible . At the same time , to ensure protecting the privacy of users , even the perpetrators , the platforms can use innovative design to hold the perpetrator accountable . For example , a user can be put on probation which enforces limited access to the user rather than full blocking of the user . For a user to move out of probation , a set of community support actions can be defined . These actions can also be used as a way to better educate the perpetrator about the community norms and harms of their actions to others . Design Guideline2 : Higher sense of belonging and commu - nity attachment leads to a less toxic community . Our data highlights the importance of community attachment and the sense of belonging in creating a friendly rather than hostile environment . The participants mentioned that the sense of belonging to a support - ive community not only provides the victims with the emotional support they need but also decreases the incidence of cyberbully - ing . While some of the current features of Twitch try to support building a sense of community , additional elements can further im - prove that . For example , the integration of different type of media , such as video , voice and text can improve relationship building [ 24 ] , however , the current design only provide this affordance to the streamers and viewers have much more limited opportunities to connect back to the streamers . Future design can consider in - novative ways to provide richer interaction opportunities to the viewers to encourage their active engagement in the streaming community and to build close relationship between viewers and streamers . For example , the design can allow viewers to become part of the streaming by allowing them to share their video through their Web cam upon permission from the main streamer . Viewers can also earn badges such as a “fan” badge if they have followed a streamer for a certain period of time . Design Guideline 3 : Increase support for moderation , par - ticularly for newcomer streamers . While one hopes that a sup - portive community leads to no toxic behavior , in reality , some level of inappropriate behavior will continue to happen despite the friendly and supportive environment . To cultivate a safer commu - nity , the design should also support effective moderation to help with the community management . Our results present that the persistent cyberbullying with multi accounts makes the modera - tion very challenging . The platforms can consider designing better to both support multiple account while prohibiting the malicious behavior associated with multiple accounts . For example , new ac - counts can have a “warm up” period in which they are only allowed to observe but not to post anything . This particularly is a challenge for newcomers who have a harder time in having the support for the moderation process . Supporting newcomers in this process of moderation and more broadly socializing the newcomers into the platform is an important element for consideration of the future design . Designing for newcomers’ socialization has been a challenge for a number of online communities [ 8 , 23 , 28 , 57 ] . Currently , to support newcomers in dealing with harassment , Twitch provides detailed Q & A 11 and 11 https : / / www . twitch . tv / p / en / legal / community - guidelines / some instructions 12 on how to utilize different functionality of the platform . However , these supports do not seem to satisfy the need of the community , as it was mentioned by our interview participants that many of the streamers use external platforms to create support communities and external forums to discuss the problems met and to help each other . In fact , the Reddit community we studied in this work is one such example . Twitch can provide better support in teaching the ropes to the newcomers by facilitating creation of social and information support communities . Additionally , since moderation is one of most important mechanisms to actively create a friendly environment , newcomers should be better supported by the platform for moderating their channels . This can be done , for example , through match - making of the newcomer with members from other established channels with a large number of committed viewers and similar norms , rules , and characteristics . 7 CONCLUSION Our mixed - method research of interviewing Twitch users , as well as the content analysis of Reddit discussion on issues of cyberbullying on Twitch , revealed interesting patterns of how design decisions of the live - streaming platform promote or obstruct cyberbullying . Our work contributes to the body of research on understanding the challenges and opportunities of the socio - technical design of new technologies . Although we faced challenges in recruiting subjects , partly due to the pandemic and the struggles it imposed on many , our mixed methodologies in combining text - based and video - based interviews as well as content analysis provided us with unique opportunities to collect rich data on users’ experiences in relation to cyberbullying . Our interviewee population is biased towards higher number of female , however , our mixed interview approach allowed us to collect concerns and feedback from venerable popu - lation such as LGBTQ and individuals with disability who do not always feel comfortable in traditional settings to provide informa - tion . The findings of our research highlight design possibilities for future improvement of live - streaming platforms to better support their users in dealing with cyberbullying . In doing so , we consider how our design guidelines can be assessed through participatory design approaches as well as experimental designs to systematically evaluate our proposed interaction design elements . ACKNOWLEDGMENTS We would like to thank members of the Sustainable Social Com - puting lab at the University of Pittsburgh for their support all throughout this research , particularly Ang Li and Keyang Zheng for their feedback on different stages of this research . We would also like to thank our reviewers who provided great feedback to improve our paper , specially one of our reviewers who particularly provided us with new design guideline ideas that have been incor - porated in this version of the paper . We would further like to thank all our participants for making this research happen . As requested by our participants we acknowledge Woo Tia , Rina Shogyo Mo - gyo , SecOne , Lex , DaemonPlays , vixenoire , Pegsicle , Toralynne for sharing their experiences on Twitch with us . 13 . This research is 12 https : / / help . twitch . tv / s / article / how - to - manage - harassment - in - chat ? language = en _ US 13 These participants explicitly asked for Twitch usernames to be included as opposed to anonymous participants 148 C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA Zhou and Farzan partially supported by an award from the University of Pittsburgh Institute for Cyber Law , Policy , and Security and an award from AT & T . REFERENCES [ 1 ] Zahra Ashktorab . 2016 . A study of cyberbullying detection and mitigation on instagram . In Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion . 126 – 130 . [ 2 ] ZahraAshktorabandJessicaVitak . 2016 . Designingcyberbullyingmitigationand prevention solutions through participatory design with teenagers . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems . 3895 – 3905 . [ 3 ] Saeideh Bakhshi , David A Shamma , and Eric Gilbert . 2014 . Faces engage us : Photos with faces attract more likes and comments on instagram . In Proceedings of the SIGCHI conference on human factors in computing systems . 965 – 974 . [ 4 ] Nancy K Baym . 2015 . Personal connections in the digital age . John Wiley & Sons . [ 5 ] Michael Bernstein , Andrés Monroy - Hernández , Drew Harry , Paul André , Katrina Panovich , and Greg Vargas . 2011 . 4chan and / b : An Analysis of Anonymity and Ephemerality in a Large Online Community . In Proceedings of the International AAAI Conference on Web and Social Media , Vol . 5 . [ 6 ] JieCaiandDongheeYvetteWohn . 2019 . WhatareEffectiveStrategiesofHandling Harassment on Twitch ? Users’ Perspectives . In Conference companion publication ofthe2019oncomputersupportedcooperativeworkandsocialcomputing . 166 – 170 . [ 7 ] V Orengo Castellá , AM Zornoza Abad , F Prieto Alonso , and JM Peiró Silla . 2000 . The influence of familiarity among group members , group atmosphere and as - sertiveness on uninhibited behavior through three different communication media . Computers in Human Behavior 16 , 2 ( 2000 ) , 141 – 159 . [ 8 ] Boreum Choi , Kira Alexander , Robert E Kraut , and John M Levine . 2010 . So - cialization tactics in wikipedia and their effects . In Proceedings of the 2010 ACM conference on Computer supported cooperative work . 107 – 116 . [ 9 ] Kimberly M Christopherson . 2007 . The positive and negative implications of anonymityinInternetsocialinteractions : “OntheInternet , NobodyKnowsYou’re a Dog” . Computers in Human Behavior 23 , 6 ( 2007 ) , 3038 – 3056 . [ 10 ] Brian L Connelly , S Trevis Certo , R Duane Ireland , and Christopher R Reutzel . 2011 . Signaling theory : A review and assessment . Journal of management 37 , 1 ( 2011 ) , 39 – 67 . [ 11 ] Dominic DiFranzo , Samuel Hardman Taylor , Franccesca Kazerooni , Olivia D Wherry , and Natalya N Bazarova . 2018 . Upstanding by design : Bystander inter - vention in cyberbullying . In Proceedings of the 2018 CHI conference on human factors in computing systems . 1 – 12 . [ 12 ] KarthikDinakar , BiragoJones , CatherineHavasi , HenryLieberman , andRosalind Picard . 2012 . Common sense reasoning for detection , prevention , and mitigation of cyberbullying . ACM Transactions on Interactive Intelligent Systems ( TiiS ) 2 , 3 ( 2012 ) , 1 – 30 . [ 13 ] Matthew DiPietro . 2014 . Twitch is 4th in peak US internet traffic . Twitch . tv ( 2014 ) . [ 14 ] Maeve Duggan . 2017 . Online harassment 2017 . ( 2017 ) . [ 15 ] Seth Frey , PM Krafft , and Brian C Keegan . 2019 . " This Place Does What It Was Built For " Designing Digital Institutions for Participatory Change . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( 2019 ) , 1 – 31 . [ 16 ] Marcus Garcia . 2018 . ( T ) witch Hunting : A Crusade Against Women and Femi - ninity in the Digital Age . ( 2018 ) . [ 17 ] Alice Gaudine and Linda Thorne . 2001 . Emotion and ethical decision - making in organizations . Journal of Business Ethics 31 , 2 ( 2001 ) , 175 – 187 . [ 18 ] Tarleton Gillespie . 2018 . Custodians of the Internet : Platforms , content moderation , and the hidden decisions that shape social media . Yale University Press . [ 19 ] Joshua Greene and Jonathan Haidt . 2002 . How ( and where ) does moral judgment work ? Trends in cognitive sciences 6 , 12 ( 2002 ) , 517 – 523 . [ 20 ] Joshua D Greene , Sylvia A Morelli , Kelly Lowenberg , Leigh E Nystrom , and Jonathan D Cohen . 2008 . Cognitive load selectively interferes with utilitarian moral judgment . Cognition 107 , 3 ( 2008 ) , 1144 – 1154 . [ 21 ] Nicholas - BrieGuarriello . 2019 . Nevergiveup , neversurrender : Gamelivestream - ing , neoliberal work , and personalized media economies . New Media & Society 21 , 8 ( 2019 ) , 1750 – 1769 . [ 22 ] Oliver L Haimson and John C Tang . 2017 . What makes live events engaging on Facebook Live , Periscope , and Snapchat . In Proceedings of the 2017 CHI conference on human factors in computing systems . 48 – 60 . [ 23 ] Aaron Halfaker , R Stuart Geiger , and Loren G Terveen . 2014 . Snuggle : Designing for efficient socialization and ideological critique . In Proceedings of the SIGCHI conference on human factors in computing systems . 311 – 320 . [ 24 ] William A Hamilton , Oliver Garretson , and Andruid Kerne . 2014 . Streaming on twitch : fostering participatory communities of play within live mixed media . In Proceedings of the SIGCHI conference on human factors in computing systems . 1315 – 1324 . [ 25 ] Stephen C Hayne and Ronald E Rice . 1997 . Attribution accuracy when using anonymity in group support systems . International Journal of Human - Computer Studies 47 , 3 ( 1997 ) , 429 – 452 . [ 26 ] Susan C Herring . 2003 . Gender and power in on - line communication . The handbook of language and gender ( 2003 ) , 202 – 228 . [ 27 ] Sameer Hinduja and Justin W Patchin . 2010 . Bullying , cyberbullying , and suicide . Archives of suicide research 14 , 3 ( 2010 ) , 206 – 221 . [ 28 ] Gary Hsieh , Youyang Hou , Ian Chen , and Khai N Truong . 2013 . " Welcome ! " socialandpsychologicalpredictorsofvolunteersocializersinonlinecommunities . In Proceedings of the 2013 conference on Computer supported cooperative work . 827 – 838 . [ 29 ] Yun - yin Huang and Chien Chou . 2010 . An analysis of multiple factors of cyber - bullying among junior high school students in Taiwan . Computers in Human Behavior 26 , 6 ( 2010 ) , 1581 – 1590 . [ 30 ] Shagun Jhaver , Sucheta Ghoshal , Amy Bruckman , and Eric Gilbert . 2018 . Online harassment and content moderation : The case of blocklists . ACM Transactions on Computer - Human Interaction ( TOCHI ) 25 , 2 ( 2018 ) , 1 – 33 . [ 31 ] Seungwook Kim , Daeyoung Choi , Eunjung Lee , and Wonjong Rhee . 2017 . Churn prediction of mobile and online casual games using play log data . PloS one 12 , 7 ( 2017 ) , e0180735 . [ 32 ] Lee Knuttila . 2011 . User unknown : 4chan , anonymity and contingency . First Monday ( 2011 ) . [ 33 ] Haewoon Kwak , Jeremy Blackburn , and Seungyeop Han . 2015 . Exploring cyber - bullying and other toxic behavior in team competition online games . In Proceed - ings of the 33rd Annual ACM Conference on Human Factors in Computing Systems . 3739 – 3748 . [ 34 ] Cliff Lampe and Paul Resnick . 2004 . Slash ( dot ) and burn : distributed moderation in a large online conversation space . In Proceedings of the SIGCHI conference on Human factors in computing systems . 543 – 550 . [ 35 ] Noam Lapidot - Lefler and Azy Barak . 2012 . Effects of anonymity , invisibility , and lack of eye - contact on toxic online disinhibition . Computers in human behavior 28 , 2 ( 2012 ) , 434 – 443 . [ 36 ] Chung - Sheng Li , Guanglei Xiong , and Emmanuel Munguia Tapia . 2018 . New frontiers in cognitive content curation and moderation . APSIPA Transactions on Signal and Information Processing 7 ( 2018 ) . [ 37 ] Yao Li , Yubo Kou , Je Seok Lee , and Alfred Kobsa . 2018 . Tell me before you stream me : Managing information disclosure in video game live streaming . Proceedings of the ACM on Human - Computer Interaction 2 , CSCW ( 2018 ) , 1 – 18 . [ 38 ] Paul Benjamin Lowry , Gregory D Moody , and Sutirtha Chatterjee . 2017 . Using IT design to prevent cyberbullying . Journal of Management Information Systems 34 , 3 ( 2017 ) , 863 – 901 . [ 39 ] Paul Benjamin Lowry , Jun Zhang , Chuang Wang , and Mikko Siponen . 2016 . Why do adults engage in cyberbullying on social media ? An integration of online disinhibition and deindividuation effects with the social structure and social learning model . Information Systems Research 27 , 4 ( 2016 ) , 962 – 986 . [ 40 ] Karine Pires and Gwendal Simon . 2015 . YouTube live and Twitch : a tour of user - generated live streaming systems . In Proceedings of the 6th ACM multimedia systems conference . 225 – 230 . [ 41 ] Roman Poyane . 2019 . Toxic Communication on Twitch . tv . Effect of a Streamer . In International Conference on Digital Transformation and Global Society . Springer , 414 – 421 . [ 42 ] Aravindh Raman , Gareth Tyson , and Nishanth Sastry . 2018 . Facebook ( A ) Live ? Are Live Social Broadcasts Really Broad casts ? . In Proceedings of the 2018 world wide web conference . 1491 – 1500 . [ 43 ] Sarah T Roberts . 2016 . Commercial content moderation : Digital laborers’ dirty work . ( 2016 ) . [ 44 ] Hugo Rosa , N Pereira , Ricardo Ribeiro , Paula Costa Ferreira , João Paulo Carvalho , SofiaOliveira , LuísaCoheur , PaulaPaulino , AMVeigaSimão , andIsabelTrancoso . 2019 . Automatic cyberbullying detection : A systematic review . Computers in Human Behavior 93 ( 2019 ) , 333 – 345 . [ 45 ] Dana Rotman and Jennifer Preece . 2010 . The’WeTube’in YouTube – creating an online community through video sharing . International Journal of Web Based Communities 6 , 3 ( 2010 ) , 317 – 333 . [ 46 ] Semiu Salawu , Yulan He , and Joanna Lumsden . 2017 . Approaches to automated detection of cyberbullying : A survey . IEEE Transactions on Affective Computing ( 2017 ) . [ 47 ] Joseph Seering , Robert Kraut , and Laura Dabbish . 2017 . Shaping pro and anti - socialbehaviorontwitchthroughmoderationandexample - setting . In Proceedings of the 2017 ACM conference on computer supported cooperative work and social computing . 111 – 125 . [ 48 ] Joseph Seering , Tony Wang , Jina Yoon , and Geoff Kaufman . 2019 . Moderator engagement and community development in the age of algorithms . New Media & Society 21 , 7 ( 2019 ) , 1417 – 1443 . [ 49 ] Vivian C Sheer . 2011 . Teenagers’ use of MSN features , discussion topics , and onlinefriendshipdevelopment : Theimpactofmediarichnessandcommunication control . Communication Quarterly 59 , 1 ( 2011 ) , 82 – 103 . [ 50 ] Vivek K Singh , Souvick Ghosh , and Christin Jose . 2017 . Toward multimodal cyberbullying detection . In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems . 2090 – 2099 . [ 51 ] Vivek K Singh , Qianjia Huang , and Pradeep K Atrey . 2016 . Cyberbullying de - tection using probabilistic socio - textual information fusion . In 2016 IEEE / ACM 149 Designing to Stop Live Streaming Cyberbullying C & T ’21 , June 20 – 25 , 2021 , Seattle , WA , USA International Conference on Advances in Social Networks Analysis and Mining ( ASONAM ) . IEEE , 884 – 887 . [ 52 ] Vivek K Singh , Marie L Radford , Qianjia Huang , and Susan Furrer . 2017 . " They basically like destroyed the school one day " On Newer App Features and CyberbullyinginSchools . In Proceedingsofthe2017ACMConferenceonComputer Supported Cooperative Work and Social Computing . 1210 – 1216 . [ 53 ] Daniel J Solove . 2007 . The future of reputation : Gossip , rumor , and privacy on the Internet . Yale University Press . [ 54 ] Fabio Sticca and Sonja Perren . 2013 . Is cyberbullying worse than traditional bullying ? Examining the differential roles of medium , publicity , and anonymity for the perceived severity of bullying . Journal of youth and adolescence 42 , 5 ( 2013 ) , 739 – 750 . [ 55 ] John Suler . 2004 . The online disinhibition effect . Cyberpsychology & behavior 7 , 3 ( 2004 ) , 321 – 326 . [ 56 ] John C Tang , Gina Venolia , and Kori M Inkpen . 2016 . Meerkat and periscope : I stream , you stream , apps stream for live streams . In Proceedings of the 2016 CHI conference on human factors in computing systems . 4770 – 4780 . [ 57 ] YlaTausczik , RostaFarzan , JohnLevine , andRobertKraut . 2018 . EffectsofCollec - tive Socialization on Newcomers’ Response to Feedback in Online Communities . ACM Transactions on Social Computing 1 , 2 ( 2018 ) , 1 – 23 . [ 58 ] Samuel Hardman Taylor , Dominic DiFranzo , Yoon Hyung Choi , Shruti Sannon , and Natalya N Bazarova . 2019 . Accountability and Empathy by Design : Encour - aging Bystander Intervention to Cyberbullying on Social Media . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( 2019 ) , 1 – 26 . [ 59 ] Robert S Tokunaga . 2010 . Following you home from school : A critical review and synthesis of research on cyberbullying victimization . Computers in human behavior 26 , 3 ( 2010 ) , 277 – 287 . [ 60 ] Kees Van den Bos , Susanne L Peters , D Ramona Bobocel , and Jan Fekke Ybema . 2006 . On preferences and doing the right thing : Satisfaction with advantageous inequity when cognitive processing is limited . Journal of Experimental Social Psychology 42 , 3 ( 2006 ) , 273 – 289 . [ 61 ] Xingchao Wang , Li Lei , Dong Liu , and Huahua Hu . 2016 . Moderating effects of moral reasoning and gender on the relation between moral disengagement and cyberbullying in adolescents . Personality and Individual Differences 98 ( 2016 ) , 244 – 249 . [ 62 ] NancyEWillard . 2007 . Cyberbullyingandcyberthreats : Respondingtothechallenge of online social aggression , threats , and distress . Research press . [ 63 ] Kevin Wise , Brian Hamman , and Kjerstin Thorson . 2006 . Moderation , response rate , and message interactivity : Features of online communities and their effects on intent to participate . Journal of Computer - Mediated Communication 12 , 1 ( 2006 ) , 24 – 41 . [ 64 ] Donghee Yvette Wohn . 2019 . Volunteer moderators in twitch micro communities : How they get involved , the roles they play , and the emotional labor they experi - ence . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . 1 – 13 . [ 65 ] Michelle F Wright . 2013 . The relationship between young adults’ beliefs about anonymity and subsequent cyber aggression . Cyberpsychology , Behavior , and Social Networking 16 , 12 ( 2013 ) , 858 – 862 . [ 66 ] Dawei Yin , Zhenzhen Xue , Liangjie Hong , Brian D Davison , April Kontostathis , and Lynne Edwards . 2009 . Detection of harassment on web 2 . 0 . Proceedings of the Content Analysis in the WEB 2 ( 2009 ) , 1 – 7 . 150