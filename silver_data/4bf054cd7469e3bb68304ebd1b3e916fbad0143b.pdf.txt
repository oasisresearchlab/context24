MacroScope : First - Person Perspective in Physical Scale Models Abstract Traditionally , architects and designers have used scale models to explore , communicate , and evaluate con - cepts and ideas in large - scale , spatial projects . These scale models offer the user a bird ' s eye perspective and often tangible ways of interacting with the model . Nev - ertheless , they lack a realistic , first - person view on the effects that the design solutions have in the space . In this paper , we explore MacroScope , a tool that aims to support collaborative spatial design by providing a real time , 360 o first - person perspective in a physical scale model , by means of a virtual reality head - mounted dis - play . We reflect on the usage potentials in collaborative creative processes , before describing next steps for the development of MacroScope . Author Keywords Virtual reality ; mixed reality ; scale models ; collabora - tive design ; creative processes ; first - person perspec - tive . Introduction Prototyping is a way to consider the effects of design solutions , to test their validity and usability , and to communicate ideas . In large - scale , spatial projects , constructing full - size prototypes is often an expensive undertaking , requiring many resources and plenty of man - power . Therefore , architects and designers alike Permission to make digital or hard copies of part or all of this work for per - sonal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the Owner / Author . TEI ' 18 , March 18 – 21 , 2018 , Stockholm , Sweden © 2018 Copyright is held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 5568 - 1 / 18 / 03 . https : / / doi . org / 10 . 1145 / 3173225 . 3173276 Dorothé Smit University of Salzburg Salzburg , Austria dorothe . smit @ sbg . ac . at Thomas Grah University of Salzburg Salzburg , Austria thomas . grah @ sbg . ac . at Martin Murer University of Salzburg Salzburg , Austria martin . murer @ sbg . ac . at Vincent van Rheden University of Salzburg Salzburg , Austria vincentvanrheden @ gmail . com Manfred Tscheligi University of Salzburg , Salzburg , Austria manfred . tscheligi @ sbg . ac . at Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 253 make use of scale models to grasp , evaluate and com - municate the impact of their ideas on the physical space in which they are situated [ 11 , 13 ] . Nevertheless , scale models offer the user only a single perspective : a top - down look on the design space , rather than a real - istic view on what effects creative ideas and concepts in the space may have from a first - person perspective . In architecture , the first - person perspective in conjunc - tion with physical scale models is a common theme [ 10 ] . To achieve this perspective , the use of endo - scopes was popular in the 80s and 90s . However , the development of CAD tools for digital 3D models reduced the use of physical scale models , and the underwhelm - ing images ( in terms of quality and field of view [ 8 ] ) from endoscopes were replaced by digital walk - throughs [ 9 ] . Recently , due to the advances in rapid prototyping , physical scale models have regained rele - vance in the architectural field [ 10 ] due to their ease of use in multi - stakeholder , collaborative creative pro - cesses [ 4 , 12 ] . In this paper , we introduce an improved version of the first - person perspective in physical scale models by means of MacroScope ( figure 1 ) . MacroScope consists of a fully immersive head - mounted display ( HMD ) fea - turing a real - time 360 o video stream from the first - person perspective in a scale model . Based on explora - tions of respectively a basic and a more elaborate im - mersive system , we reflect on how the use of a first - person perspective in physical scale models can facili - tate collaborative , creative processes in large - scale spatial projects . Related Work In the realm of the combination between a virtual first - person perspectives and tangible tools , Stoakley et al . [ 14 ] introduced ‘World - in - Miniature’ ( WIM ) in 1995 . WIM is an individual user interface that combines a fully immersive HMD , displaying a virtual environment , with a hand - held , miniature version of the virtual environ - ment , used to navigate the environment and manipu - late objects in the environment . They found that hold - ing the physical copy of the virtual environment helps the immersed user orient , plan pathways , locate ob - jects in the space , and estimate distance . In 1999 , Underkoffler and Ishii [ 15 ] created Urp , a sys - tem for urban planning . The system allows architectural scale models to be placed on any ordinary table to , e . g . , simulate wind flow , by means of projections on the scale model . Users of the system responded well to the use of physical architectural models as the system ' s primary interface . The tangible tools support the com - munication of ideas to others on the design team , as well as outsiders . More recently , Ibayashi et al . [ 5 ] created Dollhouse VR , consisting of a multi - touch tabletop screen , displaying a 2D view on a miniature interior paired with an HMD . The tabletop provides a bird’s eye view for designers , and the HMD provides a first - person perspective for occupants . They found that efficient communication between the occupants and the designers is crucial , but particularly difficult , as HMDs usually cover the eyes and a large part of the face . Efforts have also been made recently to create point - of - view 360 o live streams ( e . g . [ 6 ] ) . These systems are often applied in dislocated situations in which two per - Figure 1 : The MacroScope system provides a first person perspective in a physical scale model Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 254 sons work towards a shared goal . The difficulties of integrating these systems often involve the contradic - tion between quality and latency , the complexity of live stitching multiple camera feeds into one 360 o image , and motion sickness of the ( stationary ) viewer of the footage . MacroScope Considering the work previously done in this field , we set out to explore the first - person perspective in a physical scale model as an alternative or addition to the bird ' s eye perspective . The system we describe in this paper , MacroScope , is an immersive virtual reality sys - tem , constructed to explore the creative and interactive possibilities of the first - person perspective in a physical scale model . It allows users to take advantage of the combination between the bird ' s eye perspective , and the first - person perspective . Its application goes be - yond creative processes related to ( interior ) architec - ture , but could conceivably support education , manual labor , stage design , etc . In the current version of MacroScope , only one user at the time can have the first - person perspective . Other users will have the bird ' s eye perspective , with no visual indication of what the immersed user is seeing . The aim of the system is to provide a realistic viewpoint on design interventions made in the scale model . We have explored the first - person perspective using two different setups . The first setup was studied as a proof of concept , before a second , more elaborate set - up was realized . The proof of concept was explored with one group of three participants in three 20 - minute design cases . The second setup was explored with two groups of three participants . Both of these groups also took part in three 20 - minute design cases , respectively . During each design case , only one of the participants wore the HMD , while the other participants interacted with the scale model from a bird ' s eye perspective . Each participant wore the HMD once , each for the dura - tion of one of the total of three design cases that each group of participants performed . All creative sessions were recorded on video via a GoPro camera mounted above the scale model ( see figure 2 ) . Semi - structured group interviews , to gather anecdotal feedback on the system , were conducted with the participants after each exploration . Proof of Concept In this first setup , video was captured by a HD wide - angle webcam in the scale model . The camera lens was positioned at the height of an average male at a scale of 1 : 43 , in order to match the scale of the model . The video stream from the scale model was sent to the Oculus Rift DK1 . Creative Sessions - Three participants explored the first setup in three twenty - minute creative sessions ( figure 3 ) . The participants had backgrounds in interaction de - sign , game design , and communication science , respec - tively . In the sessions , the participants collaboratively worked on three design cases pertaining to the design of the interior of a car showroom . The participants used miniature furniture models , cars , and puppets ; and LEGO TM blocks to construct concepts and ideas in the scale model . They were also provided with markers to draw on the floors and the walls of the scale model . Technical Limitations - In the first setup of MacroScope , the HMD that was used has an effective resolution of 640 x 800 per eye and a maximum frame rate of 30 Figure 3 : Three participants ex - plore a scale model , with one person using the first version of MacroScope to gain a first - person perspective . Figure 2 : The top - view recordings of the design cases from the Go - Pro . Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 255 fps . It also suffers from the ‘screen - door effect’ , caus - ing the pixels in the image to look like they are bor - dered by black lines . The field of view of this setup was limited to 120 o due to the webcam that was used . As a consequence , whenever a participant turned his or her head further than the available field of view , he or she would be confronted with a vertical black bar on the side of the screen . Second Setup In the second setup , we used a GoPro Hero 4 fitted with a 280 o fish - eye lens , mounted on an arm and turned face - down ( figure 1 ) , so as to provide partici - pants with a 360 o viewing angle around the scale mod - el , effectively leaving out the ‘sky above’ , ( figure 4 , bottom ) . The fish - eye video was then projected onto a virtual 360 o dome and fed to an HTC Vive , increasing both the frame rate and resolution of the video stream viewed by the participants wearing the HMD . The head - tracking of the HTC Vive allows the user to look around in the virtual scene by turning the head . Creative Sessions - The second , more elaborate setup was explored by two groups of three participants , with backgrounds in information technology , geo - informatics , communication science , and psychology . Again , both groups were introduced to the first - person perspective in three twenty - minute creative sessions . This time , the creative sessions were focused on the development of diverse , creative workspaces . In these sessions , participants used miniature furniture models , puppets , whiteboard markers and LEGO TM blocks , as well as Playcorn and colored cardboard . Technical Limitations - The video stream in the second setup is monoscopic , so although the users are pre - sented with an HD stereoscopic rendering through the HMD , they not fully benefit from the stereoscopic capa - bilities of the used HMD . Furthermore , the current set - up doesn ' t allow the user to move their view through - out the scale model , other than through head move - ments . Reflections In the next section , we detail our reflections on the use of MacroScope , based on the analysis of the recorded video of the sessions , the interviews with participants and the researchers ' observations . The reflections are divided into five themes . Embodiment in the Virtual Environment In the real world , humans act as embodied beings : through our senses , our bodies provide us with feed - back about our presence , activity , attention , capabilities and many other factors [ 2 ] in the environment in which we act . Wearing an HMD has a great effect on the way a user connects to his surroundings , including the way he communicates to other people in his vicinity [ 3 ] . For example , users reported a sense of ‘bodilessness’ , i . e . , when wearing the VR headset in the particular setting as previously described , the user becomes ‘a pair of eyes’ , floating in space , rather than an embodied being capable of physically interacting with and moving around in the space . As a result , the wearer of the HMD often took on an assessing role in the creative process , overseeing the design concepts built by the other par - ticipants , rather than actively constructing . Contribu - tions to the creative sessions were mainly of a verbal nature ( sometimes supplemented with gestures ) , dis - cussing the effects of the concepts from the immersed perspective . Figure 4 : From top to bottom : The first person perspective as seen from the HMD in the first setup ; the fisheye footage from the second setup ; and the equirectangular footage that was streamed to the HMD in the se - cond setup . Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 256 Proportions and Orientation in the Model Initially , users wearing the HMD had difficulty deter - mining size and proportions of the scale model , and orienting themselves in the scale model ( P4 : “I found the scale felt a lot bigger in VR . ” ) . The participants that were not immersed quickly noticed that they could help orient the wearer by placing visual references ( e . g . , the miniature cars or colored cardboards ) in view for the wearer of the HMD to give him a sense of proportion , and by showing the wearer points of reference in the space ( figure 5 ) . In each of the exploration , it was noted that during the second and third design case each group did , the par - ticipants who had experience with wearing the HMD from the previous cases , used that experience to pro - vide visual references in the model for the ( new ) wear - er of the HMD . This awareness increased the efficiency of orientation in the scale model for ( new ) HMD wear - ers . Visualizing the perspective of the immersed partic - ipants to the other participants ( e . g . , via an external screen or a projection of the field of view onto the scale model ) may lead to a more efficient shared under - standing between participants . Eye - contact , Gesturing and Orientation Eye gaze , facial expressions and gesturing are key to efficient interpersonal communication in co - located set - tings [ 2 , 7 ] . Similar to the findings in [ 5 ] , we found that , although the immersed participants still use ges - tures to communicate ideas ( figure 6 ) , covering the eyes by the HMD hinders communication between par - ticipants . This is due to the fact that the wearer of the HMD cannot visually confirm whether he is being ad - dressed , and the other participants cannot visually con - firm whether the wearer of the HMD is paying attention to the situation at hand . This situation was especially present after incorporating a 360 o camera in the second exploration because the gaze direction of the partici - pant wearing the HMD could not be deducted from the orientation of the camera . Additionally , because of the full 360 o viewing angle , the wearer of the HMD would often completely turn away from the physical scale model and his / her team mates , to look at something placed ‘behind’ him / her ( figure 7 ) . As a result , the wearer may gesture towards something that lines up with the visual image provided to him / her through the HMD , but in reality will be pointing in a completely dif - ferent direction . Constructing a Shared Understanding Bringing different points of view together in a shared understanding is crucial in co - creative processes [ 1 ] . To create a shared understanding , it is imperative that all participants know what the others are seeing . When one participant is wearing an HMD , this knowledge can - not be derived from eye - contact or gaze direction . The participants were therefore forced to quickly devise new ways of aligning their perspectives . We noticed that participants who were not wearing the HMD did so by asking specific questions about the viewpoint of the wearer of the HMD ( P2 : “Can you see the blue car in the corner ? ” ) or by asking the wearer to describe the viewpoint ( P9 : “What can you see ? Can you see around the corner ? ” ) . The wearer of the HMD confirmed his viewpoint to the other participants by relaying infor - mation about his field of view ( P1 : “On the far left , I can see the wall , and on the far right I can see the cars . ” ; P8 , gesturing : “No , I can ' t see , there is sort of a wall in the way . ” ) . Participants were not introduced to the immersed perspective at the beginning of the ex - ploration , nor were they provided an on - screen view of Figure 5 : Participants placing markers around the camera as references . Figure 6 : The immersed person instructing the other partici - pants on how to construct an idea . Figure 7 : The large viewing angle in the second setup caused the wearer of the HMD to sometimes completely turn away from the other partici - pants . Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 257 the video stream that was visible in the HMD . Shared understanding was established more quickly in the se - cond and third design cases of each session , as the participants who had worn the HMD previously could better imagine what the current wearer of the HMD was seeing . Roles during the Collaborative Creative Process From the observations during the exploration , and the interviews conducted afterwards , we can deduce that the roles the participants took on during the design cases greatly differed depending on their state ( i . e . , wearing the HMD or not wearing the HMD ) . The wearer of the HMD becomes a ‘contractor’ of sorts , verbally assessing the design solutions and concepts that the ‘builders’ create for him ( figure 8 ) . During the explora - tion , it became apparent that the contractor had the deciding vote on the concepts , deeming them suitable or unsuitable . In the explorations , we saw the building participants often relay reflective assessment of their ideas to the wearer of the HMD . As P1 described : “It did make me [ . . . ] have less of a boundary of , ‘okay , this idea is bad anyway’ . But you just want to figure out whether it is bad [ . . . ] by placing it and then asking [ the wearer of the HMD ] : what do you think ? ” Each idea the builders came up with was thus discussed externally , rather than potentially being dismissed internally , giving the other participants the opportunity to use , transform and build on those ideas . Conclusion & Future Work Consumer - grade VR systems have advanced rapidly since the launch of the Oculus DK1 in 2012 , but re - search into communication and interaction between immersed and non - immersed people in mixed reality settings is still fairly sparse . A system like MacroScope can help inform the development for VR tools in collab - orative , co - located settings . We continue to explore the implications of the first - person perspective in physical scale models in several application areas . We are working towards a system that allows the wear - er of the HMD to move the camera autonomously , solv - ing one of the issues that may contribute to a feeling of ‘bodilessness’ users experienced while wearing the headset . The current system makes use of a mono - scopic camera feed , as 360 o cameras that are small enough to simulate stereoscopic view at a 1 : 43 scale do not currently exist . A possible solution is to use two smaller cameras with a limited field of view mounted on a panning mechanism , that moves synchronously with the HMD . To stimulate constructive contribution , and increase shared understanding during the creative ses - sion , we are exploring the possibility of giving the wearer ( s ) of the HMD the option to switch from a bird ' s eye perspective when building , to a first - person per - spective when assessing the design solutions and con - cepts . Additionally , we will construct means of com - municating gaze direction and viewpoint of the im - mersed user to other participants in the creative ses - sion ( e . g . , by mapping a projection of the field of view of the immersed user in the scale model ) . Acknowledgements We gratefully acknowledge the support by the Automotive Retail Lab ( hci . sbg . ac . at / ARL ) . Figure 8 : The wearer of the HMD instructs the two other participants . Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 258 References 1 . Ernesto Arias , Hal Eden , Gerhard Fischer , Andrew Gorman , and Eric Scharff . 2000 . Transcending the individual human mind - - creating shared under - standing through collaborative design . ACM Trans - actions on Computer - Human Interaction ( TOCHI ) 7 , 1 : 84 – 113 . 2 . Steve Benford , John Bowers , Lennart E . Fahlén , Chris Greenhalgh , and Dave Snowden . 1995 . User embodiment in collaborative virtual environments . Proceedings of the SIGCHI conference on Human factors in computing systems , ACM Press / Addison - Wesley Publishing Co . , 242 – 249 . 3 . Frank Biocca . 1997 . The Cyborg’s Dilemma : Pro - gressive Embodiment in Virtual Environments [ 1 ] . Journal of Computer - Mediated Communication 3 , 2 : 0 – 0 . 4 . Eva Brandt . 2007 . How tangible mock - ups support design collaboration . Knowledge , Technology & Pol - icy 20 , 3 : 179 – 192 . 5 . Hikaru Ibayashi , Yuta Sugiura , Daisuke Sakamoto , et al . 2015 . Dollhouse VR : a multi - view , multi - user collaborative design workspace with VR technolo - gy . ACM Press , 1 – 2 . 6 . S . Kasahara , S . Nagai , and J . Rekimoto . 2017 . JackIn Head : Immersive Visual Telepresence Sys - tem with Omnidirectional Wearable Camera . IEEE Transactions on Visualization and Computer Graphics 23 , 3 : 1222 – 1234 . 7 . Kristine Lund . 2007 . The importance of gaze and gesture in interactive multimodal explanation . Lan - guage Resources and Evaluation 41 , 3 - 4 : 289 – 303 . 8 . Bob Martens . 1999 . A Rennaissance of Architectur - al Endoscopy ? Retrieved November 4 , 2017 from http : / / info . tuwien . ac . at / eaea / Renaissance / rae . html 9 . Bob Martens and Wolf - Michael Tschuppik . 2003 . Displaying Spatially Complex Constellations . 6th EAEA - Conference Proceedings , Bratislava ( Slo - vakia ) , SUT Publishing , 101 – 107 . 10 . Bob Martens , Wolf - Michael Tschuppik , and Alexan - der G . Keul . 2008 . Endoscopy without Endoscopes : Alternatives for Gaining Shared - IN - sights at an Eye - level . Special Issue AMIT ( Intern . Journal of Architecture and modern Information Technolo - gies ) - April 2008 - Proceedings of the 8th EAEA Conference 2007 . 11 . Andrea Mina . 2009 . intimate immensity , an interior architecture . Retrieved August 30 , 2016 from http : / / researchbank . rmit . edu . au / view / rmit : 6161 . 12 . Mark Morris . 2006 . Models : Architecture and the Miniature . Academy Press . 13 . Albert C . Smith . 2004 . Architectural model as ma - chine : a new view of models from antiquity to the present day . Architectural Press , Oxford . 14 . Richard Stoakley , Matthew J . Conway , and Randy Pausch . 1995 . Virtual reality on a WIM : interactive worlds in miniature . Proceedings of the SIGCHI conference on Human factors in computing sys - tems , ACM Press / Addison - Wesley Publishing Co . , 265 – 272 . 15 . John Underkoffler and Hiroshi Ishii . 1999 . Urp : a luminous - tangible workbench for urban planning and design . Proceedings of the SIGCHI conference on Human Factors in Computing Systems , ACM , 386 – 393 . Work - in - Progress TEI 2018 , March 18 – 21 , 2018 , Stockholm , Sweden 259