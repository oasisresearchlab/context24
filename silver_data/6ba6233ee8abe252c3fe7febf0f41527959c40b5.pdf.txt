Unsupervised Judgment of Properties Based on Transformation Recognition Ryo Takatsuki , Yoshiyuki Ohmura and Yasuo Kuniyoshi Graduate School of Information Science and Technology , The University of Tokyo , Tokyo , Japan Email : { takatsuki , ohmura , kuniyosh } @ isi . imi . i . u - tokyo . ac . jp Abstract —Humans judge equivalence not only by appear - ance , but also by structural similarity , such as through analogy . The relationship between analogy and creativity shows that the identiﬁcation of structural similarity requires human - level high intelligence . In contrast , machine learning judges equivalence by appearance alone , using local features . Although the identiﬁcation of structural similarity is important , there is currently no method for judging structural similarity in unsupervised learning . In this paper , we propose a method for judging structural similarity using representation learning , whereby image sequences are represented as a combination of objects and transformations . Conventional representation learning methods generally use vector representations , but this does not permit any judgment of structural similarity . The proposed representation learning method using objects and transformations allows the structure of an equation to reﬂect the structure of an image sequence , making it possible to assess structural similarity . To represent the input in the form of equations , Lie transformations , which are often used in formulations of the permanence of perception , are adopted for learning the object transformations . Building on the base model , the structure of the equations is then modiﬁed by tolerating certain deformations of the objects . To stabilize the learning results , an integration layer is introduced to the base model to simplify the equations . As a result , the proposed method can judge structural similarity even when objects have different appearances . I . I NTRODUCTION Humans classify objects not only by appearance , but also by structural similarity , such as through analogy . Analogical reasoning is very important , because analogy is linked to creativity . For example , several studies have shown that distant analogies increase the rate of concept generation in teams [ 1 ] and contribute to originality and consumer willingness to buy [ 3 ] . In the context of development , humans begin to un - derstand the function of tools in infancy [ 6 ] and develop delayed imitation and symbolic functions [ 9 ] . Functional understanding and delayed imitation cannot be established by appearance alone , but are related to analogy or its model , structure mapping theory [ 4 ] . Such abilities have only been conﬁrmed in a few animals . Therefore , “judgment based on structural similarity” requires human - level intelligence . At present , there is no method of judging structural similarity using unsupervised learning in place of human interpretation . Current representational learning methods are limited to judgments based on local features , such as variational au - toencoders [ 13 ] and generative adversarial networks [ 5 ] . To learn more independent features , disentangled representation learning methods such as β - VAE [ 7 ] and generative mod - els [ 10 ] have been developed , but these do not incorporate judgments based on structural similarity . The consideration of structural similarity is overlooked because these methods learn features in the form of vectors , and learned vectors cannot judge structure . Gentner proposed the “structure mapping theory” and stated that an analogy arises from the coincidence of rela - tions between objects , attributes , and relations [ 4 ] . To apply structure mapping , it is not sufﬁcient to represent objects as vectors ; rather , the relationships between objects must be formulated . A natural way of formulating relations between objects is the invariant transformation formula , which focuses on the permanence of perception . Hoffman showed that geometric transformations can be expressed in general terms by us - ing Lie transformations to represent the similarity between objects [ 8 ] . Otsu used a similar formulation to construct a general theory of shape recognition [ 12 ] . Based on these ﬁnd - ings , a representation learning method for representing image sequences with multiple objects and their Lie transforms was developed [ 15 ] . This approach ( called Takada’s method in this paper ) uses neural ordinary differential equations ( NODEs ) [ 2 ] that satisfy the conditions of the Lie group as the transform , and then learns expressions from the input in the form of equations rather than vectors . Based on Takada’s method , it may be possible to judge structural similarity . Fig . 1 . Research concept : Representation learning in the form of expres - sions to determine structural similarity . X denotes a sequence , T denotes a transformation , and P denotes a pattern . The purpose of this study is to judge structural similarity using a form of representation learning that learns the equa - tions of the inputs ( Fig . 1 ) . In order to enrich the variation in the equation representation , the formulation of Takada’s method is modiﬁed to allow for object deformation in the sequence . To stabilize the learning results , an integration layer is 2023 IEEE International Conference on Development and Learning ( ICDL ) November 9 - 11 , Macau , China 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 ©2023 IEEE 409 2023 I EEE I n t e r n a t i o n a l C o n f e r e n c e o n D e v e l o p m e n t a nd L e a r n i n g ( I C D L ) | 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 © 2023 I EEE | D O I : 10 . 1109 / I C D L 55364 . 2023 . 10364494 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 2 . Proposed model : The object and transformation are learned in the form of equations using the image sequence as input , and the properties are determined by integrating them appropriately . introduced to the base model to prevent the equation repre - sentation from becoming too complex . A mechanism is also introduced to judge the degree of structural similarity from the results . Speciﬁcally , we take a black and white image sequence as input and determine whether objects in the sequence have been separated or whether objects have stopped . The proposed model can judge structural similarity regardless of the appearance of the objects . This research is a new approach to representation learning in which the learning part is based on Takada’s method . II . P RELIMINARIES Takada et al . separated objects and transformations from the input sequence by learning object transformations as Lie transformations [ 15 ] . They assume that a single object is a set of pixel images , and that all pixel images should be transformed by the same transformation , to learn a shape - invariant transformation that can be applied to any unseen object . This allows the model to be trained regardless of the appearance of the object . Based on Takada’s work , a brief explanation is given here to aid readers’ understanding . Takada’s model formulates the input sequence as a pattern P , a transformation T , and the amount of transformation λ . Here , the transformation is assumed to be the Lie transfor - mation because this is commonly used as a model for the permanence of perception . Lie groups satisfy the following conditions : T ( µ ) + T ( λ ) = T ( µ + λ ) = T ( λ ) + T ( µ ) ( λ , µ ∈ R ) ( 1 ) T ( 0 ) = I ( Identity operator ) ( 2 ) T ( λ ) − 1 = T ( − λ ) ( Inverse operator ) ( 3 ) In this model , NODEs [ 2 ] are used as the Lie transformers because they satisfy these conditions . Lie groups are groups of differential equations , so Lie transformations can be realized by using NODEs [ 14 ] . The pixel transformation in the base model is formulated as follows . d dt [ x ( t ) y ( t ) ] = f ( [ x ( t ) y ( t ) ] ) = A [ x ( t ) y ( t ) ] + b ( 4 ) where x and y denote the position of each pixel and A ∈ R 2 × 2 and b ∈ R 2 × 1 are learned . Instead of learning vector representations from input se - quences , the model learns objects as images and transfor - mations as pixel transformations . The objects and transfor - mations are learned as separate information . After learning , either the transformations or the objects are evaluated . How - ever , this method has the problem that it assumes the objects are ﬁxed in the sequence , which means that the number of objects in the sequence is ﬁxed at the beginning of the sequence . The formulation is ﬁxed not only for the objects , but also for the transformations , with only the transformation amount λ permitted to vary within the sequence . To investi - gate the similarity of structures , it must be possible to deﬁne richer structures . Thus , in this study , the model is extended to investigate the similarity of structures . III . P ROPOSED M ODEL The base model [ 15 ] suffers from the problem that the shape of objects is spatiotemporally ﬁxed in the sequence . This ﬁxed appearance restricts the form changes of the repre - sented equation . To resolve this issue , the formulation of the base model is extended to allow for changes of the shape of objects and the number of objects within the sequence . Since this change made the learning results unstable , we added an integration layer that simpliﬁes the represented equation to repair the representation of over - separated objects . To realise this , we assumed that the more concise the form of the represented equation , the more reliable it is ( Fig . 2 ) . This idea was inspired by the law of organisation in Gestalt psychology [ 11 ] . 2023 IEEE International Conference on Development and Learning ( ICDL ) November 9 - 11 , Macau , China 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 ©2023 IEEE 410 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . A . Reconstruction of Input Sequence In the base model , the sequence X is formulated as a pattern reﬂecting the shape of object P , the transformer T , and the amount of transformation λ . In sequence X , X i is the image at time i , L is the number of objects , and K is the number of transformations . We can express X i as : X i = L ∑ l = 1 ( K ∏ k = 1 T k ( λ k , i , l ) ) P l = L ∑ l = 1 T 1 ( λ 1 , i , l ) ◦ · · · ◦ T K ( λ K , i , l ) P l = T 1 ( λ 1 , i , 1 ) ◦ · · · ◦ T K ( λ K , i , 1 ) P 1 + T 1 ( λ 1 , i , 2 ) ◦ · · · ◦ T K ( λ K , i , 2 ) P 2 + · · · + T 1 ( λ 1 , i , L ) ◦ · · · ◦ T K ( λ K , i , L ) P L ( 5 ) Fig . 3 shows how scene X i is reconstructed with patterns P 1 , . . . , P L and transformations T 1 , . . . , T K . W is a mask that cuts out objects from the image . Fig . 3 . Reconstruction architecture of Takada’s model . All patterns P l , transformers T k , and variables λ k , l , i are learning targets [ 15 ] . The previous method [ 15 ] assumes that the image at any given time can be reproduced using transformations of the objects learned from the input at the start of the sequence . The object is obtained by element - wise product of X 0 and W . Therefore , a number of learning parameters W is equal to the maximum number of potential objects . However , this method does not allow for changes in the shape or number of objects . In this study , the base model is modiﬁed to remove the object ﬁxation constraint . As a result , the proposed model admits object deformations in the sequence . Equation ( 6 ) describes how to reconstruct the input . Fig . 4 shows how scene X i is reconstructed with patterns P 1 , 0 , . . . , P L , N − 1 and transformations T 1 , . . . , T K . In contrast to the previous method , the number of parameters of the mask W has increased by a factor of N , since object masks are required for each time frame in the sequence . X i = L ∑ l = 1 ( K ∏ k = 1 T k ( λ k , i , l ) ) P l , i = L ∑ l = 1 T 1 ( λ 1 , i , l ) ◦ · · · ◦ T K ( λ K , i , l ) P l , i = T 1 ( λ 1 , i , 1 ) ◦ · · · ◦ T K ( λ K , i , 1 ) P 1 , i + T 1 ( λ 1 , i , 2 ) ◦ · · · ◦ T K ( λ K , i , 2 ) P 2 , i + · · · + T 1 ( λ 1 , i , L ) ◦ · · · ◦ T K ( λ K , i , L ) P L , i ( 6 ) B . Learning Schedule In the proposed model , the loss is calculated from the predicted sequence Y , input sequence X , and transformer T . This error backpropagation updates either the transformer or the shape of the object . Details of the learning method are described in Algorithm 1 . C . Loss Function The loss function used in the learning process is as follows . As the model reconstructs the inputs , let X be the input and Y be the reconstruction . The mean square error ( MSE ) is used as the loss function . This is computed as follows . L Pattern = L MSE = | | Y − X | | 2 ( 7 ) For the transformer , the following masked MSE is used as the loss function ( 8 ) . We use the masked MSE because , when using the normal MSE , the model will attempt to minimize the loss by pushing the object out of the image . In addition , if the background of the image X i is uniformly black , it can be used as the mask image [ 14 ] . L maskedMSE = | | Y ⊙ X − X | | 2 ( 8 ) To prevent complex afﬁne transformations from becoming trapped around local minima , the following L1 - norm reg - ularization term is introduced to the loss function for the transform model parameter θ k ( k = 1 , 2 , . . . , K ) : L trsL 1 = ∑ k | | θ k | | 2 ( 9 ) In summary , the loss function for the transformer is as follows . L Transformer = L maskedMSE + α L trsL 1 + β L λscale ( 10 ) D . Integration Layer When the base model was modiﬁed to allow object defor - mation , excessive object separation was observed ( Fig . 5 ) . To prevent excessive object separation , an integration layer is introduced . The integration layer minimises the number of objects and transformations to reduce an evaluation value . The evaluation value is calculated as follows . 2023 IEEE International Conference on Development and Learning ( ICDL ) November 9 - 11 , Macau , China 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 ©2023 IEEE 411 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 4 . Reconstruction architecture of proposed model . The objects comprising the image at time i + 1 are always predicted from time i . All patterns P l , i , transformers T k , and variables λ k , l , i are learning targets . Algorithm 1 Learning method 1 : for i = 0 , i ¡ 500 ; i + + do 2 : P , T , λ ← predict ( X ) 3 : Y ← reconstruct ( P , T , λ ) 4 : L ← Loss ( X , Y , P , T , λ ) 5 : if 1 ≤ mod ( i , 25 ) ≤ 20 then 6 : T , λ ← update ( T , λ , L ) 7 : else 8 : P ← update ( P , L ) 9 : end if 10 : end for Fig . 5 . Experimental results in the absence of an integration layer : when the sequence for a moving circle was trained , excessive object separation occurred because the objects were allowed to deform . E judgment = L MSE + γ L PtnEntropy ( 11 ) L PtnEntropy = − ∑ i Q i , j logQ i , j ( 12 ) Q i , j = X i ⊙ W i , j ∑ j X i ⊙ W i , j ( 13 ) Equation ( 11 ) describes an evaluation score for the number of the object or transformer after training . In ( 12 ) and ( 13 ) , i is the frame of the sequence , j is the object number . Therefore Q i , j is the object occupancy . If the number of objects is 1 , ( Q i , 0 , Q i , 1 , . . . , Q i , L ) is a one - hot vector and L PtnEntropy = 0 ( minimum ) . For the number of objects , if an overfragmented object can be integrated into an object and the integration does not cause a signiﬁcant difference in image reproduction , we assume that it is a better representation for the object . If E judgment decreases when the objects are combined , the objects are considered to be the same object because L PtnEntropy is smaller as the number of objects decreases . For the transformer , if the amount of transformation λ can be zero , in other words , the object is stationary and there is no signiﬁcant difference in the image reproduction , we assume that it is a better representation for the transformer . If the MSE loss decreases when the amount of transformation is replaced by 0 , it is assumed that the object doesn’t move . Therefore , a lower E judgment corresponds to a simpler form of the equation . The integration layer makes the learned equation more concise : unnecessary objects are integrated and micro - transformations are ignored . IV . E XPERIMENTS The model judges structural similarity by learning the input as an equation . In this paper , the results from three kinds of experiments are presented : Judgment of Movement , Judgment of Separation , and Robustness of Appearance . In these experiments , all parameters were the same except for the input . The input is a sequence of ﬁve images of 15 pixels × 15 pixels . The maximum number of patterns and transforma - tions is two , given as hyperparameters . In formulation ( 6 ) , K = L = 2 . The number of parameters to be trained for an image sequence is 1820 , consisting of 1800 ( two kinds of patterns , four changes in a sequence , 15 × 15 image size ) for the patterns P , 12 ( two kinds of transformer , six parameters in each transformer ) for the transforms T , and eight ( two kinds of transformer , four changes in a sequence ) for the amount of transformation λ . The coefﬁcients of the loss function and evaluation score are ( α , β ) = ( 0 . 01 , 0 . 1 ) and γ = 0 . 003 in ( 10 ) , ( 11 ) . 2023 IEEE International Conference on Development and Learning ( ICDL ) November 9 - 11 , Macau , China 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 ©2023 IEEE 412 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . A . Experiment 1 : Judgment of Movement First , an experiment was conducted to determine the presence or absence of a stationary object using a simple sequence . The presence or absence of the stationary object can be determined from the amount of transformation of the learned equation . This experiment involved one sequence in which a circle moves and another in which a circle stops . The results of representation learning and integration are shown in Fig . 6 . Minute transformations are performed during representation learning , but unnecessary transformations are rewritten as constant transformations in the integration layer . There is no constraint on reducing the amount of transformation to zero during representation learning , but a simpler equation structure is obtained by reducing the amount of unnec - essary transformation to zero in the integration layer . In the expression , stationarity is determined by the amount of transformation of the pattern being zero . The results show that the model adequately determines the stationarity of the pattern . B . Experiment 2 : Judgment of Separation Next , an experiment was conducted to determine the presence or absence of separation using a simple sequence . The presence or absence of separation is judged by whether there is an increase in the number of objects . In the equation , this can be checked by the number of objects subject to transformation . This experiment used one sequence in which a circle moves and another in which a circle separates in the middle . The results of representation learning and integration are shown in Fig . 7 . The objects are unnecessarily separated dur - ing representation learning , but the integration layer results in simpler recognition . This is because the number of objects is reduced by obtaining a simpler equation structure in the integration layer rather than during representation learning . Here , separation is determined by the increase in the number of pattern types in the equation . The results show that the presence or absence of separation is adequately determined . C . Experiment 3 : Robustness of Appearance The model assumes that an object is a set of pixel images , and learns a shape - invariant transformation that can be applied to unseen objects by transforming all pixel images with the same transformation . Thus , theoretically , the model can be trained regardless of the appearance of the object . To check this robustness in practice , experiments were conducted to determine the presence or absence of separation for sequences with different appearances . This experiment considered three types of sequences : a circle separating , a square separating , and a star separating . The parameters were the same as in the other experiments . The results of representation learning and integration are shown in Fig . 8 . The separation of the circle , square , and star shapes can be recognized . The results show that structural similarity can be determined from the shape of the equation , even if it has a complex appearance , such as a star shape . V . C ONCLUSION In this study , we developed an approach for judging structural similarity by learning representations in the form of equations . Structural similarity was judged using the fact that the form of the learned equation reﬂects the form of the structure . Experiments have shown that the proposed model is able to judge whether an object is moving or whether an object has been separated , regardless of its appearance . The proposed method takes black and white images as input , and employs NODEs as transformers . The learning model is based on Takada’s method . The structure of the equation was modiﬁed by tolerating defor - mations of the object and changes in the number of objects . To stabilize the learning results , an integration layer was introduced in the base model to simplify the equations . As a result , the structural similarity of the inputs can be judged by the shape of the equations , even when objects have different appearances . This is a novel approach to representation learning . However , the integration methods are still arbitrary and have not yet been generalized . It also remains to be seen how this approach can be adapted to real images . Despite these limitations , an understanding of structural similarity independent of appearance is necessary for higher intelligence and is an important issue for children’s imita - tion [ 9 ] . The results of this study will contribute to the further development of research on methods for assessing structural similarity , including analogy . A CKNOWLEDGEMENT This work was supported by Next Generation Artiﬁcial Intelligence Research Center ( AI Center ) , The University of Tokyo , and the Donated Chair of Frontier AI Research and Education , School of Information Science and Technology , The University of Tokyo . We thank Stuart Jenkinson , PhD , from Edanz ( https : / / jp . edanz . com / ac ) for editing a draft of this manuscript . R EFERENCES [ 1 ] J . Chan and C . Schunn , “The impact of analogies on creative concept generation : Lessons from an in vivo study in engineering design , ” Cognitive science , vol . 39 , no . 1 , pp . 126 – 155 , 2015 . [ 2 ] R . T . Chen , Y . Rubanova , J . Bettencourt , and D . Duvenaud , “Neural ordinary differential equations , ” arXiv preprint arXiv : 1806 . 07366 , 2018 . [ 3 ] D . W . Dahl and P . Moreau , “The inﬂuence and value of analogical thinking during new product ideation , ” Journal of marketing research , vol . 39 , no . 1 , pp . 47 – 60 , 2002 . [ 4 ] D . Gentner , “Structure - mapping : A theoretical framework for analogy , ” Cognitive science , vol . 7 , no . 2 , pp . 155 – 170 , 1983 . [ 5 ] I . Goodfellow , J . Pouget - Abadie , M . Mirza , B . Xu , D . Warde - Farley , S . Ozair , A . Courville , and Y . Bengio , “Generative adversarial net - works , ” Communications of the ACM , vol . 63 , no . 11 , pp . 139 – 144 , 2020 . [ 6 ] M . Hernik and G . Csibra , “Functional understanding facilitates learn - ing about tools in human children , ” Current Opinion in Neurobiology , vol . 19 , no . 1 , pp . 34 – 38 , 2009 . [ 7 ] I . Higgins , L . Matthey , A . Pal , C . Burgess , X . Glorot , M . Botvinick , S . Mohamed , and A . Lerchner , “beta - vae : Learning basic visual concepts with a constrained variational framework , ” 2016 . 2023 IEEE International Conference on Development and Learning ( ICDL ) November 9 - 11 , Macau , China 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 ©2023 IEEE 413 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 6 . Judgment of Movement : sequences in which ( a ) a circle stops in the middle and ( b ) a circle moves . Images show , from left to right , the input , reconstructed sequence after learning , and reconstructed sequence after integration . Fig . 7 . Judgment of Separation : sequences in which ( c ) a circle stops in the middle and ( d ) a circle separates in the middle . Images show , from left to right , the input , reconstructed sequence after learning , and reconstructed sequence after integration . Fig . 8 . Robustness of Appearance : sequence in which ( e ) a circle separates in the middle , ( f ) a square separates in the middle , and ( g ) a star separates in the middle . Images show , from left to right , the input , reconstructed sequence after learning , and reconstructed sequence after integration . [ 8 ] W . C . Hoffman , “The lie algebra of visual perception , ” Journal of mathematical Psychology , vol . 3 , no . 1 , pp . 65 – 98 , 1966 . [ 9 ] W . Huitt and J . Hummel , “Piaget’s theory of cognitive development , ” Educational psychology interactive , vol . 3 , no . 2 , pp . 1 – 5 , 2003 . [ 10 ] D . P . Kingma , S . Mohamed , D . J . Rezende , and M . Welling , “Semi - supervised learning with deep generative models , ” in Advances in neural information processing systems , 2014 , pp . 3581 – 3589 . [ 11 ] K . Koffka , Principles of Gestalt psychology . routledge , 2013 , vol . 44 . [ 12 ] N . Otsu , “Recognition of shape and transformation – an invariant - theoretical foundation , ” Science on Form , pp . 413 – 420 , 1986 . [ 13 ] Y . Pu , Z . Gan , R . Henao , X . Yuan , C . Li , A . Stevens , and L . Carin , “Variational autoencoder for deep learning of images , labels and captions , ” Advances in neural information processing systems , vol . 29 , pp . 2352 – 2360 , 2016 . [ 14 ] T . Takada , Y . Ohmura , and Y . Kuniyoshi , “Unsupervised learning of shape - invariant lie group transformer by embedding ordinary differen - tial equation , ” in 2021 IEEE International Conference on Development and Learning ( ICDL ) . IEEE , 2021 , pp . 1 – 6 . [ 15 ] T . Takada , W . Shimaya , Y . Ohmura , and Y . Kuniyoshi , “Disentangling patterns and transformations from one sequence of images with shape - invariant lie group transformer , ” in 2022 IEEE International Conference on Development and Learning ( ICDL ) . IEEE , 2022 , pp . 54 – 59 . 2023 IEEE International Conference on Development and Learning ( ICDL ) November 9 - 11 , Macau , China 978 - 1 - 6654 - 7075 - 9 / 23 / $ 31 . 00 ©2023 IEEE 414 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply .