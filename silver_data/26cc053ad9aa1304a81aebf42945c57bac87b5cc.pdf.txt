Real Solutions for Fake News ? Measuring the Eﬀectiveness of General Warnings and Fact - Check Tags in Reducing Belief in False Stories on Social Media Spencer Blair Jonathan A . Busam Katherine Clayton Samuel Forstner John Glance Guy Green Anna Kawata Akhila Kovvuri Jonathan Martin Evan Morgan Brendan Nyhan † Morgan Sandhu Rachel Sang Rachel Scholz - Bright Austin T . Welch Andrew G . Wolﬀ Amanda Zhou Abstract Social media has increasingly enabled “fake news” to circulate widely , most notably during the 2016 U . S . presidential campaign . These intentionally false or misleading stories threaten the democratic goal of a well - informed electorate . This study evaluates the eﬀectiveness of strate - gies that could be used by Facebook and other social media to counter fake news . Results from a pre - registered experiment indicate that false headlines are perceived as less accurate when people receive a general warning about misleading information on social media or when spe - ciﬁc headlines are accompanied by a “Disputed” or “Rated false” tag . Though the magnitudes of these eﬀects are relatively modest , they generally do not vary by whether headlines were con - genial to respondents’ political views . In addition , we ﬁnd that adding a “Rated false” tag to an article headline lowers its perceived accuracy more than adding a “Disputed” tag ( Facebook’s original approach ) relative to a control condition . Finally , though exposure to the “Disputed” or “Rated false” tags did not aﬀect the perceived accuracy of unlabeled false or true headlines , exposure to a general warning decreased belief in the accuracy of true headlines , suggesting the need for further research into how to most eﬀectively counter fake news without distorting belief in true information . † Professor of Government ( nyhan @ dartmouth . edu ) . Other co - authors are or were undergraduate students at Dartmouth . We thank the Dartmouth College Oﬃce of Undergraduate Research for generous funding support . We are also grateful to Ro’ee Levy and David Rand for helpful comments . Since the 2016 U . S . election , the eﬀects of “fake news” have received considerable attention . Many Americans now worry about the eﬀects of this factually dubious content that imitates the format of journalism but is produced with no regard for accuracy or fairness ( Lazer et al . 2018 ) . This type of content , which we will refer to as “false news” for expositional clarity , is most often created for proﬁt by dubious websites . 1 Many people appear to believe false news stories , which circulated widely before the election and generally favored Donald Trump over Hillary Clinton ( Silverman 2016 ; Silverman and Singer - Vine 2016 ) . Although false news most likely did not change the election’s outcome ( Allcott and Gentzkow 2017 ) , its prevalence is still an important concern . False news promotes misperceptions among voters and can induce distrust of legitimate information . In this sense , it presents a serious threat to American democracy . The public’s vulnerability to false information has grown as people have come to increasingly rely on social media as a source of news . According to a recent Pew survey , 62 percent of Ameri - can adults get news from social media sites such as Facebook ( Gottfried and Shearer 2017 ) , which played an especially important role in the spread of false news during the 2016 presidential cam - paign . The most viral false news articles were shared more on Facebook in the months prior to the election than the most widely shared mainstream news stories ( Silverman 2016 ) . Online mis - information , both political and otherwise , has continued to be a challenge since the election . For example , false claims swirled around social media in the aftermath of Hurricane Harvey , including an article claiming that Black Lives Matter protesters blocked emergency responders from reaching hurricane victims ( Schaedel 2017 ) . To address these concerns , Facebook began adding “Disputed” tags to stories in its News Feed that have been debunked by fact - checkers in December 2016 ( Mosseri 2016 ) . It used this approach for approximately one year before switching to providing fact - checks in a “Related Articles” format underneath suspect stories ( Smith , Jackson , and Raj 2017 ) . The company also promoted tips for 1 “Fake news” has many deﬁnitions and is frequently used in imprecise or confusing ways . Moreover , the debate over the meaning of the term and related concepts raises epistemological issues that are beyond the scope of this paper ( e . g . , speaker intent ; see Wardle and Derakhshan 2017 ) . We therefore employ “false news” as an alternative term throughout this paper , which deﬁne as described above ( “factually dubious content that imitates the format of journalism but is produced with no regard for accuracy or fairness” ; see Lazer et al . 2018 ) . This approach is consistent with the practices of various news and social media sources ( e . g . , Oremus 2017 ) and is intended to avoid unnecessary confusion . 1 spotting fake news at the top of News Feed in April 2017 and May 2018 ( Constine 2017 ; Owen 2018 ) . Both approaches presumably seek to reduce the probability that people will believe false news articles . Research suggests that combating misinformation is a diﬃcult challenge ( for reviews , see , e . g . , Flynn , Nyhan , and Reiﬂer 2017 ; Lewandowsky et al . 2012 ) . In particular , studies that focus specif - ically on exposure to false news on social media have found mixed results . Though “disputed” tags seem to modestly reduce belief in false news headlines , they may fail to counteract exposure ef - fects over time ( Pennycook , Cannon , and Rand 2017 ) and could create an “implied truth” eﬀect in which unlabeled false headlines are seen as more accurate ( Pennycook and Rand 2017 ) . Similarly , Ecker , Lewandowsky , and Tang ( 2010 ) ﬁnd that speciﬁc warnings are more eﬀective than general warnings at reducing the continued inﬂuence of exposure to false information on beliefs , but neither approach eliminates this eﬀect entirely . They argue that a speciﬁc warning ( directly alerting read - ers about how misinformation can continue to inﬂuence them even after being debunked ) reduces belief in false claims by helping people to tag misinformation , whereas a general warning ( telling participants that the media sometimes does not check facts before publishing information that turns out to be inaccurate ) promotes “nonspeciﬁcally induced alertness” ( Ecker , Lewandowsky , and Tang 2010 , p . 1096 ) that is less eﬀective . In this study , we investigate whether interventions like the ones used by Facebook can eﬀectively reduce belief in false news . Speciﬁcally , we test the eﬀects of both a general warning about false news and two types of speciﬁc warnings about individual articles questioned by fact - checkers . Our results indicate that exposure to a general warning about false news modestly reduces the perceived accuracy of false headlines . We also ﬁnd that adding a “Rated false” or “Disputed” tag underneath headlines reduces their perceived accuracy somewhat more . In particular , the “Rated false” tag is more eﬀective at reducing the perceived accuracy of false headlines , though neither tag measurably reduced the self - reported likelihood that headlines would be shared on social media . The eﬀects of these tags did not vary consistently depending on whether participants had previously received a general warning . Similarly , there were not consistent diﬀerences between the eﬀect of tags on 2 politically congenial or non - congenial information . Finally , though we ﬁnd no evidence that tagging headlines as “Rated false” or “Disputed” has large spillover eﬀects to belief in other headlines , exposure to a general warning did reduce belief in the accuracy of true headlines as well as false ones , suggesting that eﬀorts to promote greater skepticism toward false news can also increase distrust of legitimate news and information . Theoretical expectations We speciﬁcally test the following hypotheses and research questions , which were pre - registered at EGAP prior to the administration of our study . 2 First , though people’s initial belief in false information can be diﬃcult to change ( see Flynn , Ny - han , and Reiﬂer 2017 for a review ) , some evidence suggests that warnings about false information can reduce belief in false claims or prevent the uptake of misinformation . Ecker , Lewandowsky , and Tang ( 2010 ) ﬁnd that warnings about the limits of fact - checking in the media reduce belief in out - dated facts and increased acceptance of correct information , but do not entirely eliminate the eﬀect of misinformation . Similarly , Bolsen and Druckman ( 2015 ) ﬁnd that warnings are more eﬀective than corrections at countering directionally motivated reasoning about scientiﬁc claims . We focus speciﬁcally on headlines , which are the dominant form of content in social media and can be misleading even to relatively attentive readers ( e . g . , Ecker et al . 2014 ) . Our study tests the eﬀectiveness of two approaches that have been used by Facebook to try to reduce belief in false news : general warnings to beware of misleading content and speciﬁc tags on article headlines that mark them as “Disputed . ” We also test the eﬀectiveness of speciﬁc tags that instead mark headlines as “Rated false . ” The ﬁrst approach we test is a general warning . In April 2017 and May 2018 , Facebook rolled out a warning of this sort to users , distributing a message at the top of News Feed that highlighted “tips for spotting fake news” ( Mosseri 2017 ; Owen 2018 ) . In this experiment , we use an analogous 2 URL omitted for peer review . 3 warning message to test the following hypothesis : H1 : Exposure to a general warning about misleading articles will reduce the perceived accuracy of false headlines relative to a no - warning condition . Our study also tests the eﬀect of a speciﬁc warning by building on Pennycook , Cannon , and Rand ( 2017 ) , who ﬁnd that a Facebook - style “Disputed” tag under headlines reduces belief in the accuracy of false stories and reduces users’ intent to share them . Similarly , Bode and Vraga ( 2015 ) ﬁnd that including corrective information in Facebook’s “related stories” function , which links articles to other articles that may correct false claims , eﬀectively reduces misperceptions . These interventions warn users about misinformation or false news at the time when they are exposed to a headline and are intended to help readers notice false information as soon as they encounter it : H2a : The presence of a Facebook - style “Disputed” tag under false headlines will reduce their perceived accuracy relative to a no - tag condition . However , tags warning that a claim is “Disputed” may not be suﬃciently direct . We therefore evaluate the eﬀect of a speciﬁc warning directly stating that a false news headline is untrue in an additional condition . A warning of this nature , though not yet used by Facebook , might convey a stronger message than the inconclusive terminology of the “Disputed” warning . Our alternate speciﬁc warning describes a false news headline as “Rated False by Snopes and Politifact . ” This tag is speciﬁc enough to eﬀectively reduce belief ( Ecker , Lewandowsky , and Tang 2010 ) and more clearly conveys the consensus among fact - checking websites that the claim in the article is false ( Bolsen and Druckman 2015 ) . We therefore expect that the eﬀects of the “Rated false” tag would be larger than the eﬀects of the “Disputed” tag and propose the following hypothesis : H2b : The presence of a “Rated false” tag under false headlines will reduce their per - ceived accuracy relative to a no - tag condition . H2c : The presence of a “Rated false” tag under false headlines will reduce their per - ceived accuracy relative to a Facebook - style “Disputed” tag . 4 Ecker , Lewandowsky , and Tang ( 2010 ) do not test how general and speciﬁc warnings work in tandem with one another , though it is plausible that a general warning could increase alertness to subsequent speciﬁc warnings about false information . Indeed , van der Linden et al . ( 2017 ) ﬁnd that presenting respondents with information on the scientiﬁc consensus about global warming , as well as a general or speciﬁc statement about the existence of climate change , was more eﬀective at inoculating respondents against misinformation on climate change than either treatment alone . We therefore propose the following hypothesis about how exposure to a general warning will strengthen the eﬀects of speciﬁc warnings : H3 : Exposure to a general warning about misleading articles will increase the negative eﬀects of “Disputed” or “Rated false” tags on the perceived accuracy of false headlines . Consistent with prior research ( Flynn , Nyhan , and Reiﬂer 2017 ; Kahan 2015 ) , we also expect that people’s belief in false news depends on whether it aligns with their political identity and preferences . “Disputed” or “Rated false” tags could be less eﬀective when a person is viewing a headline with which they are inclined to agree ( e . g . , Nyhan and Reiﬂer 2010 ; Kahan et al . N . d . ) . In this case , we evaluate how the eﬀects of our experimental manipulations vary depending on participants’ approval of President Trump ( each article concerns either President Trump and his allies or his opponent , Hillary Clinton ) and the slant of the articles in question . For example , the negative eﬀect of a “Disputed” or “Rated false” tag on the perceived accuracy of a news story may be attenuated if the news story is politically congenial , e . g . , a pro - Trump headline seen by a Trump supporter . We therefore hypothesize that the eﬀect of speciﬁc warnings will be reduced when they accompany politically congenial information relative to uncongenial information : H4 : The eﬀect of a Facebook - style “Disputed” tag on perceived accuracy ( H4a ) or “Rated false” tag ( H4b ) will be reduced for politically congenial information versus uncongenial information ( versus a headline with no tag ) . Finally , we also seek to answer three pre - registered research questions about which we had weaker theoretical expectations . Drawing on previous research identifying the importance of polit - 5 ical preferences on belief in misinformation , we investigate whether the eﬀect of warnings on the perceived accuracy of headlines varies between congenial information and uncongenial information ( RQ1 ) . We also investigate whether speciﬁc warnings on a headline will aﬀect the perceived ac - curacy of untagged false ( RQ2a ) 3 or true ( RQ2b ) headlines , and whether a general warning about misleading articles will reduce the perceived accuracy of true information ( RQ3 ) . Practically , it would be diﬃcult for social media platforms to fact - check and add a “Disputed” or “Rated false” tag to every false news headline . Because some false news headlines could inevitably fall through the cracks , we are interested in seeing how general and speciﬁc warnings inﬂuence respondents’ perceived accuracy of such news items . 4 Methods Participants The study , which was approved by the authors’ institutional review board ( identifying information omitted for peer review ) , was conducted from May 8 – 9 , 2017 among participants recruited from Amazon Mechanical Turk ( MTurk ) . Although samples from MTurk are not nationally represen - tative , results from studies conducted with participants from the site mirror those obtained from other samples ( e . g . , Coppock 2016 ; Mullinix et al . 2015 ; Berinsky , Huber , and Lenz 2012 ; Horton , Rand , and Zeckhauser 2011 ) . 5 Non - U . S . residents , people under 18 years of age , and people who 3 Pennycook and Rand ( 2017 ) , which we had not seen at the time of pre - registration , also considers this question . 4 We pre - registered an additional research question about the eﬀects of exposure to a general warning and / or to a “Disputed” or “Rated false” tag on respondents’ self - reported likelihood of “liking” and sharing the headlines on Facebook . The results of this analysis are presented in Online Appendix B . 5 A minority of studies conclude that MTurk samples are not externally valid ( e . g . , Krupnikov and Levine 2014 ) . For example , participants on MTurk tend to skew liberal and young . Moreover , the underrepresentation of conservatives and older participants may suggest that these participants diﬀer from other conservatives or older individuals in the general population . However , numerous studies ﬁnd that experimental treatment eﬀect estimates typically generalize from MTurk to national probability samples , suggesting these problems are rare ( e . g . , Coppock 2016 ; Mullinix et al . 2015 ; Berinsky , Huber , and Lenz 2012 ; Horton , Rand , and Zeckhauser 2011 ) . Finally , our MTurk sample is externally valid in the sense that it is made up disproportionately of frequent users of the Internet — precisely the group who may be most likely to encounter false news ( Pennycook and Rand 2018a ) . We thus conclude that respondents from MTurk constitute a valid sample for testing our hypotheses , though replication on representative samples would of course be desirable . 6 completed a prior pilot study were not allowed to participate . 6 We also exclude six respondents from the data who dropped out prior to the experimental manipulation . Our ﬁnal sample is 2 , 994 participants . Although our sample is diverse , it skews female ( 54 % female ) , younger ( median age group 25 – 34 ) and more educated ( 55 % have a bachelor’s degree or greater ) than the U . S . population . Our sample also overrepresents Democrats—32 % identify as Republican or lean Republican , whereas 58 % identiﬁed as Democrat or lean Democrat . Participants also approve of Trump ( 30 % ) and voted for him ( 30 % of those who report voting ) at lower rates than the U . S . population . A detailed com - parison of the composition of our sample to population benchmarks is provided in Online Appendix C ( Table C1 ) . Experimental design and procedure We focus on beliefs in headlines because of their primacy on social media ( Manjoo 2013 ; Gabielkov et al . 2016 ) . The initial judgments that people form when reading headlines are also likely to shape their subsequent beliefs and opinions ( Thorson 2016 ) . The experiment used a 2 × 3 between - subjects design that also includes a pure control group . Participants were randomly assigned with equal probability to a pure control group or to one of six experimental conditions ( see Table 1 ) . We manipulated whether participants were exposed to a general warning about misleading articles or not ( middle column of Table 1 ) . We also indepen - dently randomized non - controls into one of three headline conditions : a condition in which no fact - checking tags were presented ( ﬁrst two rows of Table 1 ) , a speciﬁc warning condition that in - cluded tags labeling articles as “Disputed” ( second two rows of Table 1 ) , and a speciﬁc warning condition in which they were instead labeled as “Rated false” ( last two rows of Table 1 ) . The study proceeded as follows . Once participants consented to participate , they answered a series of demographic questions , followed by questions about their use of social media , political 6 The pilot study tested the eﬀects of “disputed” and “false” tags only on perceived accuracy and likelihood of liking / sharing for six false news headlines . The results of this study were similar to our main analysis , and are available upon request . 7 Table 1 : Experimental conditions Tag General warning N None No 469 None Yes 424 “Disputed” No 413 “Disputed” Yes 429 “Rated false” No 429 “Rated false” Yes 397 Pure control 433 preferences , voting behavior , and trust in fact - checking and the media . Participants were then asked to rate the accuracy of several real and fabricated political statements to test their predisposition to hold political misperceptions . 7 Afterward , they answered a political knowledge battery , which provided a buﬀer between the misperception items and the experimental task . In the general warning condition , participants were shown a message warning them about mis - leading articles and providing advice for identifying false information ( see Online Appendix A for exact wording and design ) . The design of the general warning was chosen to resemble Facebook’s false news message to users ( Mosseri 2017 ) . Participants in the no - warning conditions were shown an identical image with innocuous instructions to eliminate any potential confounding eﬀects . In the pure control group , respondents were exposed to no images , no articles , no general warning , no tags , and no headlines , and proceeded directly to the questions measuring the outcome variable ( discussed in the next section ) . Each participant who was not assigned to the pure control group was shown nine selected polit - ical headlines formatted as they would appear on Facebook in random order : three false pro - Trump headlines , three false anti - Trump headlines , and three true headlines ( see Online Appendix A for the exact stimuli used ) . Each participant saw each of the nine headlines , with the appearance of the 7 As in most studies , we cannot know how much false news respondents were exposed to during the 2016 presidential election and its aftermath ( e . g . , Allcott and Gentzkow 2017 ) . While it would be useful to measure this quantity , our main interest is the eﬀect of warnings and tags on belief accuracy when they encounter false news . In addition , the auxiliary measure of misperception belief mentioned above does allow us to test whether individuals who are susceptible to believing false news respond diﬀerently to warnings and tags than those who are not . We ﬁnd no consistent evidence of such heterogeneity in exploratory analyses reported in Online Appendix C . Scholars should collect data on individuals’ exposure to false news and explore treatment eﬀect heterogeneity by this variable directly in future research . 8 Table 2 : Headlines displayed in survey Headline Source Type Trump questions why U . S . Civil War had to happen Reuters True Trump Orders Airstrikes in Syria After Chemical Attack CBS New York True Neil Gorsuch Conﬁrmed to Supreme Court CNN True Trump on Revamping the Military : “We’re Bringing Back the Draft” Real News Right Now False , anti - Trump Trump Plagiarized the Bee Movie for Inaugural Speech Daily Kos False , anti - Trump FBI Discovers Kremlin is blackmailing Jason Chaﬀetz over Donald Trump and Russia Palmer Report False , anti - Trump “Donald Trump Protester Speaks Out : ‘I was paid $ 3 , 500 to protest Trump’s rally”’ ABCnews . com . co False , Pro - Trump Donald Trump Sent His Own Plane to Transport 200 Stranded Marines Top Rated Viral False , pro - Trump FBI Agent Suspected in Hillary Email Leaks Found Dead in Apparent Murder - Suicide Alexander Higgins False , pro - Trump In the study , the Chaﬀetz headline identiﬁed him as a “Republican Congressman . ” headlines ( i . e . , whether they included “Disputed” or “Rated false” tags ) randomly varying based on treatment condition . We selected a balance of pro - and anti - Trump false news articles from Snopes and Buzzfeed , excluding those related to the 2016 election that had become less relevant . 8 True political headlines from mainstream media sources were also included so that the veracity of headlines was not uniform . 9 Finally , though Pennycook and Rand ( 2018b ) ﬁnd that news sources do not signiﬁcantly aﬀect belief in the perceived accuracy of false news headlines , we purposefully omitted news sources ( and authors ) to minimize potentially confounding variables and isolate the eﬀects of warnings and tags on belief in false news headlines . In the disputed condition , two randomly chosen pro - Trump and two anti - Trump false news head - lines were tagged as “Disputed by Snopes . com and PolitiFact” ( see Online Appendix A for headline format ) . Similarly , in the false condition , two randomly chosen pro - Trump and two anti - Trump false 8 Some of these articles were originally used in Pennycook , Cannon , and Rand ( 2017 ) , which examined the eﬀect of prior exposure to fake news headlines on the perceived accuracy of fake news . Others were taken from Silverman ( 2016 ) , a compilation of the most widely shared fake news articles during the 2016 election . The original sources of the false news articles were dubious websites that had intentionally created them for proﬁt . 9 The true headlines that were tested were taken from actual mainstream news sources and were not intended to be explicitly pro - or anti - Trump , though respondent interpretations of them may diﬀer . 9 news headlines were tagged as “Rated false by Snopes . com and PolitiFact . ” The wording and format of these tags were chosen to resemble warnings implemented by Facebook . Tags were distributed evenly to pro - Trump and anti - Trump headlines ( i . e . , two of each ) . Finally , the two remaining false headlines ( one pro - Trump and one anti - Trump ) were not tagged . This distribution allows us to test the eﬀects of political congeniality while also simulating a typical news feed in which not all false news stories will be fact - checked . After each headline was displayed , participants were asked to evaluate the accuracy of the head - line and to self - report how likely they would be to “like” and share the story on Facebook ( see Online Appendix A for wording ) . Measures To test the perceived accuracy of the claims in false news headlines , participants were asked to evaluate the accuracy of each claim on a four - point Likert scale from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . 10 This question format is a common approach in recent studies measuring participants’ belief in misinformation and false news ( e . g . , Kuru , Pasek , and Traugott 2017 ; Penny - cook and Rand 2017 ; Clayton et al . 2018 ; Pennycook and Rand 2018a , b ) ; employing it allows us to directly compare our results with the existing literature . We reasoned that a unipolar four - point scale allowed respondents to express a more nuanced assessment of a statement’s accuracy than , for example , a binary true / false question ( e . g . , by choosing “somewhat accurate” versus “very ac - curate” ) . This question format was also appropriate for the pure control group , which did not view a headline but could be asked to assess each claim’s general accuracy . Finally , we elected not to include a “don’t know” option and instead permitted respondents to skip questions in the survey . 11 10 A potential concern is that highly attentive MTurk respondents saw these accuracy questions as an attention check rather than a measure of sincere belief and responded accordingly . However , previous research has found that the eﬀect of corrections to misinformation were almost identical among samples of MTurk workers and Morning Consult poll respondents ( Nyhan et al . 2017 ) and provides limited and inconsistent evidence of demand eﬀects in survey experiments ( Mummolo and Peterson N . d . ) . 11 de Leeuw , Hox , and Boevé ( 2015 ) ﬁnd that excluding “don’t know” options but allowing respondents to skip questions in online surveys ( as we did ) reduces missing data and increases reliability in online surveys relative to the inclusion of a “don’t know” option . 10 Summary measures of respondent belief in each of the nine false news headlines included in our survey are provided in Online Appendix C ( see Table C2 ) . 12 We also asked participants who indicated they use Facebook in a pre - treatment measure about their willingness to “like” or share a given headline on Facebook on a scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) ( see Online Appendix B for results ) . Finally , because our headlines in - cluded a mixture of pro - and anti - Trump stories , we measured respondents’ approval of President Trump prior to the manipulation on a scale from “Strongly disapprove” ( 1 ) to “Strongly approve” ( 4 ) and classiﬁed those who “strongly” or “somewhat” approve of him as approvers and those who “strongly” or “somewhat” disapprove as disapprovers . Results We analyzed the eﬀects of our experiment using OLS with robust standard errors . 13 All analyses were pre - registered in advance on EGAP unless otherwise speciﬁed . Our primary outcome measure is the perceived accuracy of false headlines , which we pooled across the false news headlines that respondents evaluated . The statistical analyses below include standard errors clustered by respondent and question ﬁxed eﬀects as well as indicators for expo - sure to a general warning about false news and whether the respondent saw a “Disputed” or “Rated false” tag under the headline in question . Importantly , our pre - registered speciﬁcations exclude re - sponses to untagged headlines by respondents in the disputed or false conditions . We thus compare responses to tagged headlines in the disputed and false conditions to responses to headlines in the condition in which no tags were shown . All experimental treatment eﬀects were estimated as intent to treat eﬀects . 14 12 Our preregistration did not oﬀer hypotheses about the correlates of false news belief , but see Pennycook and Rand ( 2018b ) , which ﬁnds that individuals who have a tendency to ascribe profundity to randomly generated sentences and who overstate their level of knowledge are more likely to perceive false news as accurate . ( Those who engage in analytic thinking are less susceptible . ) 13 All results were virtually identical when estimated using ordered probit instead . See Online Appendix C . 14 We do not include respondent ﬁxed eﬀects , which were incorrectly speciﬁed in the pre - registration ( they cannot be estimated due to multicollinearity ) . However , we show in Online Appendix C that our primary results are consistent when estimated in a model that includes random eﬀects by respondent . 11 Figure 1 : Eﬀects of general and speciﬁc warnings on the perceived accuracy of false headlines Not at all accurate Not very accurate Somewhat accurate No warning Warning Headline Headline + ' disputed ' tag Headline + ' false ' tag Mean belief that false headlines were accurate on a four - point Likert scale from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . See Online Appendix A for question wording and stimulus materials . Since we could not estimate respondents’ likelihood to “like” or share headlines ( results in On - line Appendix B ) in our pure control condition , we deviate from our pre - registration for expositional reasons to present estimates below that exclude the pure control group . As a result , we focus on the sample of 2 , 561 respondents assigned to our experimental conditions . Accordingly , the baseline in our statistical models is the group that did not receive a general warning about false news or any “Disputed” or “Rated false” tags on headlines . Our estimates are substantively identical when the pure control group is used as the baseline condition instead ( see Online Appendix C ) . Main eﬀects of general and speciﬁc warnings Figure 1 summarizes the mean perceived accuracy of the false news headlines by whether respon - dents received a general warning about misleading articles and / or whether the headline was iden - tiﬁed as “Disputed” or “Rated false” by fact - checkers . As the ﬁgure indicates , a general warning 12 only slightly decreased the perceived accuracy of false headlines in the untagged headlines con - dition , reducing it from 1 . 96 to 1 . 90 on our four - point Likert scale . The perceived accuracy of false headlines declined more when speciﬁc warnings were provided , decreasing from 1 . 96 to 1 . 73 when a “Disputed” tag appeared and 1 . 62 when a “Rated false” tag appeared . This eﬀect was nearly identical when a general warning was previously provided . In substantive terms , the “Disputed” tag reduced the mean proportion of respondents who accept a headline as “Somewhat accurate” or “Very accurate” when no general warning was provided from 29 % in the baseline condition to 19 % , a ten - percentage point decline ( 95 % CI in a regression using the binary accuracy measure described above as the outcome : − 7 to − 13 percentage points ) . Similarly , the “Rated false” tag reduced the proportion of respondents who accepted the headline as accurate to 16 % , a 13 - percentage point decline from the baseline condition ( 95 % CI : − 11 to − 17 percentage points ) . These eﬀects are larger than those reported in Pennycook and Rand ( 2017 ) , who ﬁnd that a “Disputed” tag reduces perceived accuracy by 3 . 7 percentage points ( a point estimate that is outside our 95 % conﬁdence interval ) . We test our hypotheses and research questions more formally in Table 3 , which shows the results of our pooled regression models for the perceived accuracy of false news headlines . Our results largely support the hypotheses that warnings reduce belief in false information . Consistent with H1 , average belief in false headlines was slightly lower for participants who saw a general warning before seeing headlines than for participants who saw headlines with no warning ( − 0 . 08 ; p < . 05 ) . However , the substantive magnitude of this reduction in perceived belief accuracy is small ( Cohen’s d = 0 . 08 ) . 15 The negative eﬀect of tags on perceived accuracy was stronger , however . Average perceived accuracy for participants who saw a headline with a “Disputed” tag was 0 . 24 points lower on our four - point scale than for participants who saw no tag ( p < . 01 ; Cohen’s d = 0 . 26 ) and 0 . 34 points lower for those who saw a “Rated false” tag than for those who saw no tag ( p < . 01 ; Cohen’s d = 0 . 38 ) , supporting H2a and H2b . Most notably , “Rated false” tags were signiﬁcantly more eﬀective 15 The eﬀects on perceived accuracy reported in Tables 3 – 5 are consistent when non - Facebook users are excluded from the sample in exploratory analyses ( see Online Appendix C ) . 13 Table 3 : Experimental eﬀects on perceived accuracy of false headlines Accuracy General warning - 0 . 08 * * ( 0 . 03 ) “Disputed” tag - 0 . 24 * * * ( 0 . 04 ) “Disputed” × warning 0 . 04 ( 0 . 05 ) “Rated false” tag - 0 . 34 * * * ( 0 . 04 ) “Rated false” × warning 0 . 03 ( 0 . 05 ) Constant 1 . 85 * * * ( 0 . 03 ) Question ﬁxed eﬀects Yes N ( responses ) 11962 Respondents 2554 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respon - dents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . than “Disputed” tags at reducing belief in false information relative to a no tag condition ( − 0 . 11 , p < . 01 ) , supporting H2c and suggesting that the eﬀect of speciﬁc warnings is greater when they clearly indicate that a headline is false . We ﬁnd no support for H3 . Our results do not allow us to reject the null hypothesis of no dif - ference in the eﬀect of the “Disputed” and “Rated false” tags when a general warning is present compared to when it was not . The marginal eﬀects of the tags remain negative and statistically signiﬁcant when a general warning was previously provided , however ( disputed : − 0 . 20 , p < . 01 ; false : − 0 . 31 , p < . 01 ) . We therefore conclude that a general warning did not augment the eﬀect of tags warning about speciﬁc misleading articles . Participants view speciﬁc warning tags imme - diately before answering questions about a headline’s accuracy , so the tag’s eﬀect may be more immediate and take precedence over that of the general warning shown earlier . 14 Diﬀerences by article slant We next test whether these eﬀects vary depending on whether the general or speciﬁc warnings provided to participants are politically congenial or uncongenial . To do so , we add a directional preference measure ( an indicator for Trump approval ) and corresponding interaction terms to our previous statistical model predicting the perceived accuracy of false news headlines . The coef - ﬁcients of interest are presented in Table 4 , which separately estimates results for false pro - and anti - Trump articles . These results are estimated only among respondents who approve or disap - prove of Trump . 16 Though Trump job approval is strongly associated with baseline levels of belief in the false head - lines , our ﬁndings do not support our hypothesis that people would resist warnings about politically congenial false news ( H4 ) . We also ﬁnd no diﬀerence in the eﬀect of a general warning , a re - search question for which we had weaker expectations because it does not challenge a speciﬁc story like a fact - checking tag ( RQ1 ) . For pro - Trump stories , we are unable to reject the null hypothesis that the eﬀects of the “Disputed” or “Rated false” tags do not diﬀer between Trump approvers and disapprovers . We also ﬁnd no measurable diﬀerence in the eﬀect of the “Disputed” tags by Trump approval for anti - Trump stories . One possible explanation for these ﬁndings is that the headlines we tested were likely unfamiliar to many respondents . As a result , they may have been less connected to respondents’ personal beliefs and thus more easily debunked than well - known misperceptions . 17 In one case , the eﬀect of a “Rated false” tag did signiﬁcantly diﬀer between Trump approvers and disapprovers for anti - Trump stories , but the sign of the eﬀect was the opposite of the hypothe - sized direction . The presence of a “Rated false” tag reduced the perceived accuracy of anti - Trump headlines signiﬁcantly more among Trump disapprovers for whom the headlines were politically 16 A typo in the pre - registration statement to this eﬀect instead mistakenly stated we would exclude “pure indepen - dents . ” The results below again exclude pure controls but equivalent results including those respondents are provided in Online Appendix C . We do not include respondents with no opinion of Trump in that model because there were so few ( n = 4 ) . 17 Pennycook and Rand ( 2018a ) similarly ﬁnd that " the correlation between CRT [ Cognitive Reﬂection Test scores ] and perceived accuracy is unrelated to how closely the headline aligns with the participant’s ideology . . . Our ﬁndings therefore suggest that susceptibility to fake news is driven more by lazy thinking than it is by partisan bias per se . " Similarly , Porter , Wood , and Kirby ( 2018 ) ﬁnd minimal diﬀerences between ideological groups in their willingness to accept fake news headlines . 15 Table 4 : Experimental eﬀects on perceived accuracy of false headlines by article slant Anti - Trump Pro - Trump General warning - 0 . 11 * * - 0 . 06 ( 0 . 05 ) ( 0 . 05 ) “Disputed” tag - 0 . 28 * * * - 0 . 24 * * * ( 0 . 05 ) ( 0 . 05 ) “Rated false” tag - 0 . 41 * * * - 0 . 37 * * * ( 0 . 05 ) ( 0 . 05 ) Trump approval - 0 . 18 * * * 0 . 64 * * * ( 0 . 07 ) ( 0 . 07 ) Warning × Trump approval - 0 . 04 0 . 06 ( 0 . 09 ) ( 0 . 10 ) “Disputed” × warning 0 . 10 0 . 04 ( 0 . 07 ) ( 0 . 07 ) “Disputed” × Trump approval 0 . 14 0 . 03 ( 0 . 09 ) ( 0 . 10 ) “Disputed” × warning × Trump approval - 0 . 05 - 0 . 12 ( 0 . 13 ) ( 0 . 15 ) “Rated false” × warning 0 . 12 * 0 . 01 ( 0 . 07 ) ( 0 . 07 ) “Rated false” × Trump approval 0 . 23 * * - 0 . 01 ( 0 . 10 ) ( 0 . 10 ) “Rated false” × warning × Trump approval - 0 . 06 - 0 . 07 ( 0 . 13 ) ( 0 . 15 ) Constant 1 . 91 * * * 1 . 99 * * * ( 0 . 04 ) ( 0 . 04 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 5972 5972 Respondents 2550 2548 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respon - dents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . congenial than among Trump approvers for whom they were uncongenial ( 0 . 20 , p < . 05 ) . This counterintuitive ﬁnding may be the result of diﬀering levels of trust in fact - checking and false news susceptibility . An exploratory analysis using pre - treatment measures shows that Trump approvers were much more likely to believe in election 2016 false news ( an average of 0 . 26 points higher on a four - point accuracy scale , p < . 01 ) and to distrust fact - checkers ( an average of 0 . 53 points lower on a four - point trust scale , p < . 01 ) than disapprovers . These results can be observed in Figure 2 , which displays the mean level of perceived accuracy 16 Figure 2 : Speciﬁc warning eﬀects by political congeniality of false headlines ( a ) Anti - Trump headlines Not at all accurate Not very accurate Somewhat accurate Trump disapprovers Trump approvers Headline Headline + ' disputed ' tag Headline + ' false ' tag ( b ) Pro - Trump headlines Not at all accurate Not very accurate Somewhat accurate Trump disapprovers Trump approvers Headline Headline + ' disputed ' tag Headline + ' false ' tag Mean belief that false headlines were accurate on a four - point Likert scale from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . See Online Appendix A for question wording and stimulus materials . Excludes respondents assigned to receive a general warning as well as those in the pure control condition . by condition for both anti - and pro - Trump headlines among respondents who did not receive a general warning . In general , the reduction in belief is similar regardless of whether the headline is politically congenial . The exception was anti - Trump headlines , which Trump disapprovers rate as more accurate than approvers when no tag is present , but view as less accurate when a “Rated false” tag accompanies the headline . 18 Spillover eﬀects Finally , we consider our last two research questions , which concern possible unintended spillover eﬀects from general or speciﬁc warnings . We ﬁrst test whether the presence of “Disputed” or “Rated false” tags aﬀects belief in untagged false or true news headlines ( RQ3 ) . In this case , the presence of tags could cause a contrast eﬀect that leads participants to infer other stories are accurate . Al - ternatively , the presence of these tags could make participants more skeptical about all news . We 18 An additional exploratory analysis was conducted to test whether the eﬀects of political congeniality were altered by a participant’s political knowledge . Consistent with previous research , we found that high political knowledge reduced belief in false news stories regardless of the article’s slant . However , we did not ﬁnd convincing evidence that high political knowledge meaningfully changed a speciﬁc warning’s eﬀect on belief in false news headlines . Results for this exploratory analysis are included in Online Appendix C ( Table C16 ) . 17 Table 5 : Experimental tests for spillover eﬀects of warnings on perceived accuracy Untagged True news false headlines headlines General warning - 0 . 08 * * - 0 . 12 * * * ( 0 . 03 ) ( 0 . 04 ) “Disputed” condition 0 . 02 0 . 06 ( 0 . 05 ) ( 0 . 04 ) “Rated false” condition 0 . 04 0 . 03 ( 0 . 04 ) ( 0 . 04 ) “Disputed” × warning 0 . 06 0 . 09 ( 0 . 06 ) ( 0 . 06 ) “Rated false” × warning 0 . 03 0 . 14 * * ( 0 . 06 ) ( 0 . 06 ) Constant 1 . 87 * * * 2 . 87 * * * ( 0 . 03 ) ( 0 . 03 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 7968 6585 Respondents 2436 2502 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respon - dents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a “Disputed” or “Rated false” tag for the speciﬁc headline in question . therefore test whether a general warning about false news aﬀects the perceived accuracy of true news headlines ( RQ3 ) . These research questions are evaluated in Table 5 , which separately tests these eﬀects on the perceived accuracy of both types of headlines . The models reported in the ﬁrst column exclude headlines in which respondents in the “Disputed” or “Rated false” conditions saw a tag ; they thus test the eﬀect of assignment to those conditions on the perceived accuracy of other headlines . 19 We ﬁnd no statistically measurable eﬀect on the perceived accuracy of untagged false articles when other false articles were tagged with a “Disputed” or “Rated false” tag ( RQ2a ) . However , our point estimates for “Disputed” ( 0 . 02 ) and “Rated false” ( 0 . 04 ) are similar to the “implied truth” eﬀect found by Pennycook and Rand ( 2017 ) ( 0 . 03 ) ; we simply lack the precision to detect an eﬀect 19 Headlines viewed by respondents in the “Disputed” or “Rated false” conditions before exposure to the ﬁrst tag are also excluded ( spillover is impossible for participants who are not yet treated ) . 18 Figure 3 : General warning eﬀects on belief in true and false news articles Not at all accurate Not very accurate Somewhat accurate False True No warning Warning Mean belief that true and false news headlines were accurate on a four - point Likert scale from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . See Online Appendix A for question wording and stimulus materials . of that magnitude ( 95 % CI for “Disputed” : - 0 . 07 , 0 . 11 ; 95 % CI for “Rated false” : - 0 . 05 , 0 . 16 ) . The perceived accuracy of true articles was also unaﬀected when other false articles were tagged with these tags ( RQ2b ) . However , the general warning had an unintended spillover eﬀect on the perceived accuracy of true headlines ( − 0 . 12 , p < . 01 ) , though the substantive magnitude of this eﬀect was small ( Cohen’s d = 0 . 12 ) . While overall levels of belief in false news stories were much lower than for true ones , the decrease in perceived accuracy from the general warning was greater with true stories ( − 0 . 12 ) than false ones ( − 0 . 08 ) , though an exploratory analysis pooling evaluations of true and false headlines shows we cannot reject the null hypothesis of no diﬀerence in perceived accuracy between them . The ﬁndings suggest that the speciﬁc warnings were more eﬀective because they reduced belief solely for false headlines and did not create spillover eﬀects on perceived accuracy of true news . 19 Conclusion This study provides several important new ﬁndings about how to most eﬀectively counter false in - formation on social media . First , both “Disputed” and “Rated false” tags modestly reduce belief in false news . Notably , we ﬁnd larger accuracy eﬀects for the “Disputed” tags than Pennycook and Rand 2017 . However , our results demonstrate that “Rated false” tags , which speciﬁcally tell users when claims made in headlines are untrue , are more eﬀective at reducing belief in misinforma - tion than the “Disputed” tags previously used by Facebook . Encouragingly , we ﬁnd no consistent evidence that the eﬀects of these tags varied by the political congeniality of the headlines or that exposure to the tags increases the perceived accuracy of unlabeled false headlines ( though our study lacks the precision necessary to detect the small “implied truth” eﬀect Pennycook and Rand 2017 identify ) . By contrast , though general warnings about false news also decreased belief in false headlines , the eﬀect of the warning was small compared to either type of tag . Moreover , general warnings also reduced belief in real news and did not enhance the eﬀects of the “Rated false” and “Disputed” tags , suggesting that they are a less eﬀective approach . Our results provide support for prior studies ﬁnding a negative eﬀect of general warnings on be - lief in misinformation ( Ecker , Lewandowsky , and Tang 2010 ; Bolsen and Druckman 2015 ; van der Linden et al . 2017 ) , but our ﬁnding that these warnings also reduce the perceived accuracy of true headlines suggest that they pose a potential hazard . False news may already increase distrust in legitimate information ; unintended spillover eﬀects from general warnings or related proposals to ﬁght false information by increasing media literacy ( e . g . , Atkins 2017 ) could exacerbate this prob - lem . Our “Disputed” and “Rated false” tags , which more eﬀectively reduced the perceived accuracy of false headlines without causing these spillover eﬀects , may be a safer way to reduce belief in mis - information . Further research is needed to evaluate this ﬁnding and better understand the mechanism for the spillover eﬀect we observe . One potential explanation is that warnings about false news prime peo - ple to think about misleading information online , making them less likely to trust any articles they 20 see on social media . Another possible interpretation is that we are observing a “tainted truth” eﬀect in the context of political misinformation . In social cognition research , such an eﬀect occurs when eyewitnesses who are warned about the inﬂuence of misinformation overcorrect for this threat and identify fewer true items than eyewitnesses who are not warned ( Echterhoﬀ et al . 2007 ; Szpitalak and Polczyk 2010 ) . Our results suggest that the tainted truth eﬀect could apply to prospective warn - ings about political misinformation , but further research is necessary to test if this ﬁnding holds in other contexts and designs . Our study has several important limitations that should be addressed in future research . First , our sample was more educated and politically active than the general population and leaned liberal ; future studies should be conducted with nationally representative sample . A second limitation is that our study examined the eﬀect of warnings and tags on pro - and anti - Trump headlines in the aftermath of a presidential election — a substantively important but speciﬁc context . While Trump - related headlines remain timely and salient , further research should be conducted to determine whether our results hold in other contexts and for other types of false headlines . Third , we do not examine over - time eﬀects . Future studies should evaluate long - term belief in false news after the initial exposure and how our manipulations aﬀect those beliefs . Fourth , as noted above , our design does not allow us to identify the causal mechanisms responsible for the eﬀects we observed — a challenge facing nearly all experimental studies ( Bullock , Green , and Ha 2010 ) . In particular , future research should employ designs that provide more leverage for understanding the eﬀects of warnings on belief in false news . Finally , as in any experimental study , we cannot fully rule out the possibility of demand eﬀects . Any survey that asks about the perceived accuracy of political statements and the eﬀects of interventions on those self - reports is susceptible to these eﬀects , though research suggests they are rare ( Mummolo and Peterson N . d . ) . Our study also made a number of design choices that should be revisited in future research . First , we focused on belief in headlines because they are prominently displayed on social media , but future studies should also measure the eﬀects of warnings and tags on belief when people actually read the articles in question . Second , false news articles typically appear on a user’s timeline because a 21 friend liked or shared the article , but we chose not to test the eﬀect of social endorsements or other contextual cues on belief in false news articles . Third , our headlines omitted article sources to allow us to isolate the eﬀect of our treatments , but these sources are likely to play a role in how individuals evaluate Facebook posts . Exploring the interactions between source credibility and warnings on belief in misinformation is another important avenue for future research . Finally , we chose to use the same two fact - checking sources throughout the study , PolitiFact and Snopes . However , people diﬀer in how much they trust the most prominent national fact - checking organizations ( e . g . , Nyhan and Reiﬂer N . d . ) . Future studies should vary the source of fact - checks in order to determine whether the fact - checking source inﬂuences individuals’ perceptions of true and false headlines . Despite these limitations , this study provides important insights into how eﬀorts to prevent belief in misinformation on social media could be more eﬀective and suggests that online false news can be countered with some degree of success . References Allcott , Hunt , and Matthew Gentzkow . 2017 . “Social Media and Fake News in the 2016 Election . ” Journal of Economic Perspectives 31 ( 2 ) : 211 – 236 . Atkins , Larry . 2017 . “States Should Require Schools To Teach Media Lit - eracy To Combat Fake News . ” The Huﬃngton Post , July 13 , 2017 . Down - loaded July 8 , 2018 from https : / / www . huffingtonpost . com / entry / states - should - require - schools - to - teach - media - literacy _ us _ 59676573e4b07b5e1d96ed86 . Berinsky , Adam J . , Gregory A . Huber , and Gabriel S . Lenz . 2012 . “Evaluating online labor markets for experimental research : Amazon . com’s Mechanical Turk . ” Political Analysis 20 ( 3 ) : 351 – 368 . Bode , Leticia , and Emily K . Vraga . 2015 . “In related news , that was wrong : The correction of 22 misinformation through related stories functionality in social media . ” Journal of Communication 65 ( 4 ) : 619 – 638 . Bolsen , Toby , and James N . Druckman . 2015 . “Counteracting the politicization of science . ” Journal of Communication 65 ( 5 ) : 745 – 769 . Bullock , John G . , Donald P . Green , and Shang E . Ha . 2010 . “Yes , But What’s the Mechanism ? ( Don’t Expect an Easy Answer ) . ” Journal of Personality and Social Psychology 98 ( 4 ) : 550 – 558 . Clayton , Katherine , Jase Davis , Kristen Hinckley , and Yusaku Horiuchi . 2018 . “Partisan Mo - tivated Reasoning and Misinformation in the Media : Is News from Ideologically Unconge - nial Sources More Suspicious ? ” Unpublished manuscript . Downloaded July 8 , 2018 from https : / / papers . ssrn . com / sol3 / papers . cfm ? abstract _ id = 3035272 . Constine , John . 2017 . “Facebook puts link to 10 tips for spot - ting ‘false news’ atop feed . ” Tech Crunch , April 6 , 2017 . Down - loaded July 18 from https : / / techcrunch . com / 2017 / 04 / 06 / facebook - puts - link - to - 10 - tips - for - spotting - false - news - atop - feed / . Coppock , Alexander . 2016 . “Generalizing from Survey Experiments Conducted on Mechani - cal Turk : A Replication Approach . ” Unpublished manuscript , March 22 , 2016 . Downloaded July 8 , 2018 from https : / / alexandercoppock . files . wordpress . com / 2016 / 02 / coppock _ generalizability2 . pdf . de Leeuw , Edith D . , Joop J . Hox , and Anja Boevé . 2015 . “Handling Do - Not - Know Answers : Ex - ploring New Approaches in Online and Mixed - Mode Surveys . ” Social Science Computer Review 34 ( 1 ) : 116 – 132 . Echterhoﬀ , Gerald , Stephan Groll , , and William Hirst . 2007 . “Tainted Truth : Overcorrection for Misinformation Inﬂuence on Eyewitness Memory . ” Social Cognition 25 ( 3 ) : 367 – 409 . 23 Ecker , Ullrich K . H . , Stephan Lewandowsky , and David T . W . Tang . 2010 . “Explicit warnings reduce but do not eliminate the continued inﬂuence of misinformation . ” Memory & cognition 38 ( 8 ) : 1087 – 1100 . Ecker , Ullrich K . H . , Stephan Lewandowsky , Ee Pin Chang , and Rekha Pillai . 2014 . “The eﬀects of subtle misinformation in news headlines . ” Journal of Experimental Psychology : Applied 20 ( 4 ) : 323 – 335 . Federal Election Commission . 2017 . “Oﬃcial 2016 Presidential General Election Results . ” Jan - uary 30 , 2017 . Downloaded September 27 , 2017 from https : / / transition . fec . gov / pubrec / fe2016 / 2016presgeresults . pdf . Flynn , D . J . , Brendan Nyhan , and Jason Reiﬂer . 2017 . “The nature and origins of misperceptions : Understanding false and unsupported beliefs about politics . ” Political Psychology 38 ( S1 ) : 127 – 150 . Gabielkov , Maksym , Arthi Ramachandran , Augustin Chaintreau , and Arnaud Legout . 2016 . “So - cial Clicks : What and Who Gets Read on Twitter ? ” In Proceedings of the 2016 ACM SIG - METRICS International Conference on Measurement and Modeling of Computer Science . ACM ACM . Gallup News . 2017 . “Gallup Daily : Trump Job Approval . ” Downloaded September 27 , 2017 from http : / / news . gallup . com / poll / 201617 / gallup - daily - trump - job - approval . aspx . Gottfried , Jeﬀrey , and Elisa Shearer . 2017 . “News Use Across Social Me - dia Platforms 2016 . ” Pew Research Center , May 26 , 2016 . Downloaded May 23 , 2017 from http : / / www . journalism . org / 2016 / 05 / 26 / news - use - across - social - media - platforms - 2016 / . Horton , John J . , David G . Rand , and Richard J . Zeckhauser . 2011 . “The online laboratory : Con - ducting experiments in a real labor market . ” Experimental Economics 14 ( 3 ) : 399 – 425 . 24 Howden , Lindsay M . , and Julie A . Meyer . 2011 . “Age and Sex Composition : 2010 . ” United States Census Bureau , May 2011 . Downloaded September 27 , 2017 from https : / / www . census . gov / prod / cen2010 / briefs / c2010br - 03 . pdf . Kahan , Dan M . 2015 . “Climate - science communication and the measurement problem . ” Political Psychology 36 ( S1 ) : 1 – 43 . Kahan , Dan M . , Erica Cantrell Dawson , Ellen Peters , and Paul Slovic . N . d . “Motivated Numeracy and Enlightened Self - Government . ” Unpublished manuscript . Krupnikov , Yanna , and Adam Seth Levine . 2014 . “Cross - Sample Comparisons and External Va - lidity . ” Journal of Experimental Political Science 1 ( 1 ) : 59 – 80 . Kuru , Ozan , Josh Pasek , and Michael W . Traugott . 2017 . “Motivated Reasoning in the Perceived Credibility of Public Opinion Polls . ” Public Opinion Quarterly 81 ( 2 ) : 422 – 446 . Lazer , David MJ , Matthew A Baum , Yochai Benkler , Adam J Berinsky , Kelly M Greenhill , Filippo Menczer , Miriam J Metzger , Brendan Nyhan , Gordon Pennycook , David Rothschild et al . 2018 . “The science of fake news . ” Science 359 ( 6380 ) : 1094 – 1096 . Lewandowsky , Stephan , Ullrich K . H . Ecker , Colleen M . Seifert , Norbert Schwarz , and John Cook . 2012 . “Misinformation and its correction : Continued inﬂuence and successful debiasing . ” Psy - chological Science in the Public Interest 13 ( 3 ) : 106 – 131 . Li , Huaye , and Yasuaki Sakamoto . 2014 . “Social impacts in social media : An examination of perceived truthfulness and sharing of information . ” Computers in Human Behavior 41 : 278 – 287 . Manjoo , Farhad . 2013 . “You won’t ﬁnish this article . ” Slate Magazine , June 6 , 2013 . Down - loaded May 23 , 2017 from http : / / www . slate . com / articles / technology / technology / 2013 / 06 / how _ people _ read _ online _ why _ you _ won _ t _ finish _ this _ article . html . 25 Messing , Solomon , and Sean J . Westwood . 2014 . “Selective exposure in the age of social media : Endorsements trump partisan source aﬃliation when selecting news online . ” Communication Research 41 ( 8 ) : 1042 – 1063 . Mosseri , Adam . 2016 . “Addressing Hoaxes and Fake News . ” Facebook , December 15 , 2016 . Downloaded July 18 , 2018 from https : / / newsroom . fb . com / news / 2016 / 12 / news - feed - fyi - addressing - hoaxes - and - fake - news / . Mosseri , Adam . 2017 . “A New Educational Tool Against Misinformation . ” Facebook , April 6 , 2017 . Downloaded May 23 , 2017 from https : / / newsroom . fb . com / news / 2017 / 04 / a - new - educational - tool - against - misinformation / . Mullinix , Kevin J . , Thomas J . Leeper , James N . Druckman , and Jeremy Freese . 2015 . “The Gen - eralizability of Survey Experiments . ” Journal of Experimental Political Science 2 ( 2 ) : 109 – 138 . Mummolo , Jonathan , and Erik Peterson . N . d . “Demand Eﬀects in Survey Experiments : An Em - pirical Assessment . ” Unpublished manuscript . Nyhan , Brendan , Ethan Porter , Jason Reiﬂer , and Thomas Wood . 2017 . “Taking Corrections Lit - erally But Not Seriously ? The Eﬀects of Information on Factual Beliefs and Candidate Favora - bility . ” Unpublished manuscript . Downloaded July 8 , 2018 from https : / / papers . ssrn . com / sol3 / papers . cfm ? abstract _ id = 2995128 . Nyhan , Brendan , and Jason Reiﬂer . 2010 . “When Corrections Fail : The persistence of political misperceptions . ” Political Behavior 32 ( 2 ) : 303 – 330 . Nyhan , Brendan , and Jason Reiﬂer . N . d . “Do People Actually Learn From Fact - Checking ? Evidence from a longitudinal study during the 2014 campaign . ” Unpublished manuscript . Downloaded September 20 , 2017 from http : / / www . dartmouth . edu / ~ nyhan / fact - checking - effects . pdf . 26 Oremus , Will . 2017 . “Facebook Has Stopped Saying “Fake News” . ” Slate , August 8 , 2017 . Downloaded July 8 , 2018 from http : / / www . slate . com / blogs / future _ tense / 2017 / 08 / 08 / facebook _ has _ stopped _ saying _ fake _ news _ is _ false _ news _ any _ better . html . Owen , Laura Hazard . 2018 . “Is your fake news about immigrants or politicians ? It all depends on where you live . ” Nieman Journalism Lab , May 25 , 2018 . Downloaded July 18 , 2018 from http : / / www . niemanlab . org / 2018 / 05 / is - your - fake - news - about - immigrants - or - politicians - it - all - depends - on - where - you - live / . Pennycook , Gordon , and David G . Rand . 2017 . “The Implied Truth Eﬀect : Attaching warnings to a subset of fake news stories increases perceived accuracy of stories without warnings . ” Unpub - lished manuscript . Downloaded July 8 , 2018 from https : / / papers . ssrn . com / sol3 / papers . cfm ? abstract _ id = 3035384 . Pennycook , Gordon , and David G . Rand . 2018a . “Lazy , Not Biased : Susceptibility to Parti - san Fake News Is Better Explained by Lack of Reasoning Than by Motivated Reasoning . ” In press , Cognition . Downloaded July 8 , 2018 from https : / / papers . ssrn . com / sol3 / papers . cfm ? abstract _ id = 3165567 . Pennycook , Gordon , and David G . Rand . 2018b . “Who Falls for Fake News ? The Roles of Analytic Thinking , Motivated Reasoning , Political Ideology , and Bullshit Receptivity . ” Unpub - lished manuscript . Downloaded July 10 , 2018 from https : / / papers . ssrn . com / sol3 / papers . cfm ? abstract _ id = 3023545 . Pennycook , Gordon , Tyrone D . Cannon , and David G . Rand . 2017 . “Prior Exposure Increases Perceived Accuracy of Fake News . ” Unpublished manuscript . Downloaded May 23 , 2017 from https : / / papers . ssrn . com / sol3 / papers . cfm ? abstract _ id = 2958246 . Porter , Ethan , Thomas J . Wood , and David Kirby . 2018 . “Sex traﬃcking , Russian inﬁltration , birth 27 certiﬁcates , and pedophilia : A survey experiment correcting fake news . ” Journal of Experimental Political Science 5 ( 2 ) : 159 – 164 . Schaedel , Sydney . 2017 . “Black Lives Matter Blocked Hurricane Relief ? ” Factcheck . org , September 1 , 2017 . Downloaded September 26 , 2017 from http : / / www . factcheck . org / 2017 / 09 / black - lives - matter - blocked - hurricane - relief / . Silverman , Craig . 2016 . “This Analysis Shows How Viral Fake Election News Sto - ries Outperformed Real News On Facebook . ” Buzzfeed , November 16 , 2016 . Down - loaded May 22 , 2017 from https : / / www . buzzfeed . com / craigsilverman / viral - fake - election - news - outperformed - real - news - on - facebook ? utm _ term = . lgQvmj974 # . qqXqL1AJV . Silverman , Craig , and Jeremy Singer - Vine Jeremy Singer - Vine . 2016 . “Most Americans Who See Fake News Believe It , New Survey Says . ” December 6 , 2016 . Downloaded May 23 , 2017 from https : / / www . buzzfeed . com / craigsilverman / fake - news - survey ? utm _ term = . srvopPEVR # . cqlAz0PeX . Smith , Jeﬀ , Grace Jackson , and Seetha Raj . 2017 . “Designing Against Misinformation . ” Medium , December 20 , 2017 . Downloaded July 8 , 2018 from https : / / medium . com / facebook - design / designing - against - misinformation - e5846b3aa1e2 . Szpitalak , Malwina , and Romuald Polczyk . 2010 . “Warning against warnings : Alerted subjects may perform worse . Misinformation , involvement and warning as determinants of witness testimony . ” Polish Psychological Bulletin 41 ( 3 ) : 105 – 112 . Thorson , Emily . 2016 . “Belief echoes : The persistent eﬀects of corrected misinformation . ” Political Communication 33 ( 3 ) : 460 – 480 . United States Census Bureau . 2017 . “Educational Attainment in the United States : 2016 . ” Down - loaded September 27 , 2017 from https : / / www . census . gov / data / tables / 2016 / demo / education - attainment / cps - detailed - tables . html . 28 van der Linden , Sander , Anthony Leiserowitz , Seth Rosenthal , and Edward Maibach . 2017 . “Inoc - ulating the public against misinformation about climate change . ” Global Challenges 1 ( 2 ) . Wardle , Claire , and Hossein Derakhshan . 2017 . “Information Disorder : Toward an in - terdisciplinary framework for research and policy making . ” Council of Europe Re - port , September 27 , 2017 . Downloaded July 8 , 2018 from https : / / rm . coe . int / information - disorder - toward - an - interdisciplinary - framework - for - researc / 168076277c . 29 Online Appendix A This study is being conducted by [ redacted for peer review ] . We ask for your attention for a few minutes and we thank you for your attention and your responses . Your participation is voluntary and you may decline the survey or withdraw at any time . No information that identiﬁes you will be collected or retained by the researchers . However , any online interaction carries some risk of being accessed . Do you consent to participate in the survey ? - Yes - No [ Demographics ] How old are you ? - Under 18 - 18 - 24 - 25 - 34 - 35 - 44 - 45 - 54 - 55 - 64 - 65 - 74 - 75 - 84 - 85 or older In what state do you currently reside ? - Alabama - Alaska - Arizona - Arkansas - California - Colorado - Connecticut - Delaware - District of Columbia - Florida - Georgia - Hawaii - Idaho - Illinois - Indiana - Iowa - Kansas - Kentucky - Louisiana - Maine - Maryland - Massachusetts - Michigan - Minnesota - Mississippi - Missouri - Montana - Nebraska - Nevada - New Hampshire - New Jersey - New Mexico - New York - North Carolina - North Dakota - Ohio - Oklahoma - Oregon - Pennsylvania - Rhode Island - South Carolina - South Dakota - Tennessee - Texas - Utah - Vermont - Virginia - Washington - West Virginia - Wisconsin - Wyoming - Puerto Rico - I do not reside in the United States What is your gender ? - Male - Female - Other When it comes to politics , would you describe yourself as liberal , conservative , or neither liberal nor conservative ? - Very conservative - Somewhat conservative - Slightly conservative - Moderate ; middle of the road - Slightly liberal - Somewhat liberal - Very liberal Generally speaking , do you usually think of yourself as a Republican , a Democrat , an Independent , or something else ? - Republican - Democrat - Independent - Something else [ If Democrat is selected ] Would you call yourself a strong Democrat or a not very strong Democrat ? - Strong Democrat - Not very strong Democrat [ If Republican is selected ] Would you call yourself a strong Republican or not a very strong Republican ? - Strong Republican - Not very strong Republican [ If Independent or Something else is selected ] Do you think of yourself as closer to the Republican Party or to the Democratic Party ? - Closer to the Republican Party - Closer to the Democratic Party - Neither What is the highest degree or level of school you have completed ? - Did not graduate from high school - High school diploma or the equivalent ( GED ) - Some college - Associate’s degree - Bachelor’s degree - Master’s degree - Professional or doctorate degree Please check one or more categories below to indicate what race ( s ) you consider yourself to be . - White - Black or African American - American Indian or Alaska Native - Asian / Paciﬁc Islander - Multi - racial - Other Are you of Spanish or Hispanic origin or descent ? - Yes - No Generally , how interested are you in politics ? - Extremely interested - Very interested - Somewhat interested - Not very interested - Not at all interested How frequently do you use Facebook ? - Daily - A few times a week - Once a week - A few times a month - Once a month - Less frequently than once a month - Never [ If Never is selected ] How frequently do you share political news stories on Facebook ? - Daily - A few times a week - Once a week - A few times a month - Once a month - Less frequently than once a month - Never In talking to people about elections , we often ﬁnd that a lot of people were not able to vote because they weren’t registered , they were sick , or they just didn’t have time . Which of the following state - ments best describes you ? - I did not vote in the election this November - I thought about voting this time , but didn’t - I usually vote , but didn’t this time - I am sure I voted [ If I am sure I voted is selected ] Who did you vote for in the presidential election ? - Hillary Clinton - Donald Trump - Gary Johnson - Jill Stein - Other candidate Do you approve or disapprove of the way Donald Trump is handling his job as President ? - Strongly approve ( 4 ) - Somewhat approve ( 3 ) - Somewhat disapprove ( 2 ) - Strongly disapprove ( 1 ) When fact - checking organizations like Snopes and PolitiFact evaluate the accuracy of claims made online , how much do you trust the information they provide ? - A great deal ( 4 ) - A moderate amount ( 3 ) - Not much ( 2 ) - Not at all ( 1 ) In general , how much trust and conﬁdence do you have in the mass media - such as newspapers , TV , and radio - when it comes to reporting the news fully , accurately , and fairly ? - A great deal ( 4 ) - A moderate amount ( 3 ) - Not much ( 2 ) - Not at all ( 1 ) [ Political knowledge and prior misperceptions ] The next set of questions helps us learn what types of information are commonly known to the public . Please answer these questions on your own without asking anyone or looking up the answers . Many people don’t know the answers to these questions , but we’d be grateful if you would please answer every question even if you’re not sure what the right answer is . It is important to us that you do NOT use outside sources like the Internet to search for the correct answer . Will you answer the following questions without help from outside sources ? - Yes - No To the best of your knowledge , how accurate are the following statements ? Pope Francis endorsed Donald Trump for president . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate As Secretary of State , Hillary Clinton arranged for the United States to sell weapons to the jihadist militant group known as ISIS . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate In May 2016 , Ireland announced that it was oﬃcially accepting Americans requesting political asylum from a Donald Trump presidency . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate FBI Director James Comey put a Trump sign on his front lawn . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate Hillary Clinton won the popular vote in the 2016 election . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate The FBI concluded that Hillary Clinton and her associates in the Department of State were ”ex - tremely careless in their handling of very sensitive , highly classiﬁed information . ” - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate Supreme Court Justice Antonin Scalia died in 2016 . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate The website WikiLeaks published numerous hacked emails from Hillary Clinton’s campaign . - Not at all accurate - Not very accurate - Somewhat accurate - Very accurate For how many years is a United States Senator elected - that is , how many years are there in one full term of oﬃce for a U . S . Senator ? - Two years - Four years - Six years - Eight years - None of these - Don’t know How many times can an individual be elected President of the United States under current laws ? - Once - Twice - Four times - Unlimited number of terms - Don’t know How many U . S . Senators are there from each state ? - One - Two - Four - Depends on which state - Don’t know Who is currently the Prime Minister of the United Kingdom ? - Richard Branson - Nick Clegg - David Cameron - Theresa May - Margaret Thatcher - Don’t know For how many years is a member of the United States House of Representatives elected - that is , how many years are there in one full term of oﬃce for a U . S . House member ? - Two years - Four years - Six years - Eight years - For life - Don’t know [ Pure control outcome measures ( order randomized ) ] To the best of your knowledge , how accurate is the claim that Trump questioned why the U . S . Civil War had to happen ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that Trump ordered airstrikes in Syria after a chemical attack ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that Neil Gorsuch was conﬁrmed to the Supreme Court ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that Trump is bringing back the draft ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that Trump plagiarized the Bee Movie for his inaugural speech ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that Republican Congressman Jason Chaf - fetz was blackmailed by the Kremlin ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that a Donald Trump protester was paid $ 3 , 500 to protest Trump’s rally ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that Donald Trump sent his own plane to transport 200 stranded Marines ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) To the best of your knowledge , how accurate is the claim that an FBI agent suspected in Hillary Clinton’s email leaks was found dead in an apparent murder - suicide ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ warning manipulation ( randomized ; not shown to pure controls ) ] [ no - warning image ( randomized ; not shown to pure controls ) ] [ tag conditions ( headline order randomized ; not shown to pure controls ) : - no tags : no tags were shown on any headlines - disputed : random subset of four false headlines were shown with “Disputed” tag - false : random subset of four of six false headlines were shown with “Rated false” tag ] To the best of your knowledge , how accurate is the claim that Trump is bringing back the draft ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that Trump plagiarized the Bee Movie for his inaugural speech ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that Republican Congressman Jason Chaf - fetz was blackmailed by the Kremlin ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that a Donald Trump protester was paid $ 3 , 500 to protest Trump’s rally ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that Donald Trump sent his own plane to transport 200 stranded Marines ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that an FBI agent suspected in Hillary Clinton’s email leaks was found dead in an apparent murder - suicide ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that Trump questioned why the U . S . Civil War had to happen ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that Trump ordered airstrikes in Syria after a chemical attack ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) To the best of your knowledge , how accurate is the claim that Neil Gorsuch was conﬁrmed to the Supreme Court ? - Not at all accurate ( 1 ) - Not very accurate ( 2 ) - Somewhat accurate ( 3 ) - Very accurate ( 4 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to “like” this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) [ If How frequently do you use Facebook ? Never Is Not Selected ] How likely would you be to share this story on Facebook ? - Very likely ( 4 ) - Somewhat likely ( 3 ) - Not very likely ( 2 ) - Not at all likely ( 1 ) It is essential for the validity of this study that we know whether participants looked up any infor - mation online during the study . Did you make an eﬀort to look up information during the study ? Please be honest ; you will still be paid and you will not be penalized in any way if you did . - Yes , I looked up information - No , I did not look up information Do you have any comments on the survey ? Please let us know about any problems you had or aspects of the survey that were confusing . [ textbox ] Thank you for answering these questions . The purpose of this study was to examine the believability of fake news , as well as the eﬀectiveness of diﬀerent forms of fact - checking . During this survey , participants were asked a series of questions about general information and their political opinions . After answering these questions , participants viewed a variety of headlines — both true and “fake” — in diﬀerent formats and with various levels of fact - checking . The “fake” articles , while not rooted in fact , were all obtained from existing websites . Thank you again for your participation . Please do not share any information about the nature of this study with other potential participants . This research is not intended to support or oppose any political candidate or oﬃce . The research has no aﬃliation with any political candidate or campaign and has received no ﬁnancial support from any political candidate or campaign . Should you have any questions about this study , please contact [ redacted for peer review ] . Online Appendix B In addition to examining the eﬀects of warnings on perceived accuracy of news headlines , we also investigated the eﬀect of a warning about misleading articles or the presence of a “Disputed” or “Rated false” tag on liking or sharing behavior ( RQ1 ) . Prior research has found that the perceived truthfulness of information , based on collective opinion data including number of other shares , impacts the likelihood that it is shared ( Li and Sakamoto 2014 ) . Tagging articles as disputed or false explicitly does this , yet this explicit tag has not yet been tested . Moreover , previous research has found that social endorsements predict individuals’ likelihood to like and share articles on Facebook ( Messing and Westwood 2014 ) . Our results show that participants reported being somewhat less likely to “like” false headlines that were tagged as “Rated false” but not to share them . We found that the presence of a “Rated false” tag causes a marginally signiﬁcant reduction in the probability that a respondent would “like” a story on Facebook ( − 0 . 06 , p < . 10 ) but has no measurable eﬀect on the self - reported likelihood of sharing it ( − 0 . 04 , ns ) . Moreover , we cannot conclude that exposure to a warning or a “Disputed” tag reduces self - reported willingness to “like” or share false stories . We note that our results for this research question may be the result of participants’ general unwillingness to “like” or share the arti - cles they saw . For example , 76 % of responses indicated that participants were “not at all likely” to “like” a given article and 80 % said they were “not at all likely” to share it . It is also worth noting that our decision to exclude non - users of Facebook from this analysis created a uniformly - distributed sampling bias that may have impacted the results . Finally , we note that regression models that ex - clude responses to untagged false headlines ( Table C3 ) , that include random eﬀects ( Table C4 ) , and that employ ordered probit ( Table C1 ) are included in Online Appendix C . Across all of these models , the fact - checking tags did not appear to have strong or consistent eﬀects on respondents’ self - reported willingness to “like” or share false news headlines . Table B1 : Experimental eﬀects on social endorsements of false headlines “Like” Share General warning 0 . 01 0 . 01 ( 0 . 04 ) ( 0 . 04 ) “Disputed” tag - 0 . 03 - 0 . 03 ( 0 . 04 ) ( 0 . 04 ) “Disputed” × warning - 0 . 04 - 0 . 05 ( 0 . 05 ) ( 0 . 05 ) “Rated false” tag - 0 . 06 * - 0 . 04 ( 0 . 04 ) ( 0 . 04 ) “Rated false” × warning - 0 . 04 - 0 . 07 ( 0 . 05 ) ( 0 . 05 ) Constant 1 . 27 * * * 1 . 29 * * * ( 0 . 03 ) ( 0 . 03 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 11127 11119 Respondents 2377 2377 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Like” measures the likelihood that Facebook users would “like” a headline on a four - point scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) . “Likelihood to share” measures the likelihood that Facebook users would share a headline on a four - point scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Online Appendix C Table C1 : Comparison of survey sample with population benchmarks Characteristic Sample Census Gallup FEC Education Less than high school 0 . 3 % 13 . 7 % - - High school or equivalent 8 . 4 % 26 . 0 % - - Some college 24 . 8 % 16 . 8 % - - Associate’s degree 11 . 7 % 10 . 1 % - - Bachelor’s degree 38 . 8 % 20 . 8 % - - Master’s degree 12 . 4 % 9 . 3 % - - Professional or doctorate degree 3 . 6 % 3 . 4 % - - Age 18 – 24 13 . 9 % 13 . 1 % - - 25 – 44 64 . 8 % 35 . 0 % - - 45 – 64 18 . 7 % 34 . 7 % - - 65 and older 2 . 6 % 17 . 2 % - - Gender Male 45 . 3 % 49 . 2 % - - Female 54 . 3 % 50 . 8 % - - Trump approval Disapprove 70 . 0 % - 53 . 0 % - Approve 30 . 0 % - 40 . 0 % - 2016 presidential vote Clinton 56 . 3 % - - 48 . 2 % Trump 30 . 1 % - - 46 . 1 % Other 13 . 6 % - - 5 . 7 % Sources for population benchmarks : education ( United States Census Bureau 2017 ) , age and gender ( Howden and Meyer 2011 ) , Trump approval ( Gallup News 2017 ) , 2016 election results ( Federal Election Commission 2017 ) . Table C2 : Distribution of accuracy beliefs Headline Not at all Not very Somewhat Very accurate accurate accurate accurate Draft reinstated ( F ) 52 . 1 % 28 . 0 % 15 . 8 % 4 . 1 % Bee movie ( F ) 54 . 6 % 28 . 7 % 12 . 1 % 4 . 5 % Chaﬀetz blackmail ( F ) 42 . 6 % 38 . 1 % 17 . 4 % 2 . 0 % Protesters paid ( F ) 35 . 9 % 30 . 6 % 24 . 6 % 9 . 0 % Marines in Trump plane ( F ) 41 . 8 % 29 . 6 % 21 . 0 % 7 . 6 % FBI agent dead ( F ) 50 . 7 % 27 . 2 % 16 . 3 % 5 . 8 % Trump / Civil war ( T ) 14 . 6 % 19 . 9 % 29 . 3 % 36 . 2 % Syria airstrikes ( T ) 2 . 3 % 5 . 2 % 18 . 4 % 74 . 1 % Gorsuch conﬁrmed ( T ) 3 . 9 % 9 . 1 % 23 . 4 % 63 . 7 % See Online Appendix A for question wording . “T” indicates true and “F” indicates false news headlines . Table C3 : Excludes responses to untagged false headlines in “Disputed” / “Rated false” conditions Accuracy “Like” Share General warning - 0 . 08 * * 0 . 01 0 . 01 ( 0 . 03 ) ( 0 . 04 ) ( 0 . 04 ) “Disputed” tag - 0 . 24 * * * - 0 . 03 - 0 . 03 ( 0 . 04 ) ( 0 . 04 ) ( 0 . 04 ) “Disputed” × warning 0 . 04 - 0 . 04 - 0 . 05 ( 0 . 05 ) ( 0 . 05 ) ( 0 . 05 ) “Rated false” tag - 0 . 34 * * * - 0 . 06 * - 0 . 04 ( 0 . 04 ) ( 0 . 04 ) ( 0 . 04 ) “Rated false” × warning 0 . 03 - 0 . 04 - 0 . 07 ( 0 . 05 ) ( 0 . 05 ) ( 0 . 05 ) Constant 1 . 85 * * * 1 . 27 * * * 1 . 29 * * * ( 0 . 03 ) ( 0 . 03 ) ( 0 . 03 ) Question ﬁxed eﬀects Yes Yes Yes N ( responses ) 11962 11127 11119 Respondents 2554 2377 2377 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . “Like” measures the likelihood that Facebook users would “like” a headline on a four - point scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) . “Likelihood to share” measures the likelihood that Facebook users would share a headline on a four - point scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) . Respondents in the pure control condition are excluded . Table C4 : Accuracy and social endorsement eﬀects models ( random eﬀects ) Accuracy “Like” Share General warning - 0 . 08 * * 0 . 01 0 . 01 ( 0 . 03 ) ( 0 . 04 ) ( 0 . 04 ) “Disputed” tag - 0 . 24 * * * - 0 . 03 - 0 . 03 ( 0 . 04 ) ( 0 . 04 ) ( 0 . 04 ) “Disputed” × warning 0 . 04 - 0 . 04 - 0 . 05 ( 0 . 05 ) ( 0 . 05 ) ( 0 . 05 ) “Rated false” tag - 0 . 34 * * * - 0 . 06 * - 0 . 04 ( 0 . 04 ) ( 0 . 04 ) ( 0 . 04 ) “Rated false” × warning 0 . 04 - 0 . 04 - 0 . 07 ( 0 . 05 ) ( 0 . 05 ) ( 0 . 05 ) Constant 1 . 86 * * * 1 . 28 * * * 1 . 30 * * * ( 0 . 03 ) ( 0 . 03 ) ( 0 . 03 ) Question ﬁxed eﬀects Yes Yes Yes Respondent random eﬀects Yes Yes Yes N ( responses ) 11962 11127 11119 Respondents 2554 2377 2377 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent and respondent random eﬀects . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . “Like” measures the likelihood that Facebook users would “like” a headline on a four - point scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) . “Likelihood to share” measures the likelihood that Facebook users would share a headline on a four - point scale from “Not at all likely” ( 1 ) to “Very likely” ( 4 ) . Respondents in the pure control condition and responses with an untagged false headline are excluded . Table C5 : Accuracy eﬀects models ( includes pure controls ) Accuracy No correction 0 . 05 ( 0 . 03 ) General warning - 0 . 08 * * ( no correction ) ( 0 . 03 ) “Disputed” tag - 0 . 19 * * * ( 0 . 04 ) “Disputed” × warning 0 . 04 ( 0 . 05 ) “Rated false” tag - 0 . 30 * * * ( 0 . 04 ) “Rated false” × warning 0 . 03 ( 0 . 05 ) Constant 1 . 80 * * * ( 0 . 03 ) Question ﬁxed eﬀects Yes N ( responses ) 14550 Respondents 2986 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Social endorsement eﬀects are not included because they could not be measured in respondents who had not seen a headline ( i . e . pure controls ) . Responses with an untagged false headline are excluded . ( Note : The eﬀect of the general warning in the pure control condition was misspeciﬁed in the pre - registration . It is calculated as the coeﬃcient for the general warning term , not the diﬀerence between the general warning and no correction coeﬃcients . ) Table C6 : Perceived accuracy eﬀects by article slant ( includes pure controls ) Anti - Trump Pro - Trump No correction 0 . 05 0 . 00 ( 0 . 05 ) ( 0 . 05 ) General warning - 0 . 11 * * - 0 . 06 ( 0 . 05 ) ( 0 . 05 ) “Disputed” tag - 0 . 23 * * * - 0 . 24 * * * ( 0 . 05 ) ( 0 . 05 ) “Rated false” tag - 0 . 37 * * * - 0 . 37 * * * ( 0 . 05 ) ( 0 . 05 ) Trump approval - 0 . 24 * * * 0 . 56 * * * ( 0 . 06 ) ( 0 . 08 ) No correction × Trump approval 0 . 06 0 . 07 ( 0 . 09 ) ( 0 . 10 ) Warning × Trump approval - 0 . 04 0 . 06 ( 0 . 09 ) ( 0 . 10 ) “Disputed” × warning 0 . 10 0 . 04 ( 0 . 07 ) ( 0 . 07 ) “Disputed” × Trump approval 0 . 20 * * 0 . 10 ( 0 . 09 ) ( 0 . 11 ) “Disputed” × warning × Trump approval - 0 . 05 - 0 . 12 ( 0 . 13 ) ( 0 . 15 ) “Rated false” × warning 0 . 12 * 0 . 01 ( 0 . 07 ) ( 0 . 07 ) “Rated false” × Trump approval 0 . 28 * * * 0 . 06 ( 0 . 09 ) ( 0 . 11 ) “Rated false” × warning × Trump approval - 0 . 06 - 0 . 07 ( 0 . 13 ) ( 0 . 15 ) Constant 1 . 86 * * * 1 . 99 * * * ( 0 . 04 ) ( 0 . 04 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 7266 7266 Respondents 2982 2980 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respon - dents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C7 : Ordered probit model of accuracy and social endorsement eﬀects Accuracy “Like” Share General warning - 0 . 09 * * 0 . 02 0 . 04 ( 0 . 04 ) ( 0 . 06 ) ( 0 . 07 ) “Disputed” tag - 0 . 29 * * * - 0 . 06 - 0 . 03 ( 0 . 05 ) ( 0 . 06 ) ( 0 . 07 ) “Rated false” tag - 0 . 45 * * * - 0 . 10 - 0 . 05 ( 0 . 05 ) ( 0 . 07 ) ( 0 . 07 ) “Disputed” × warning 0 . 04 - 0 . 08 - 0 . 12 ( 0 . 07 ) ( 0 . 09 ) ( 0 . 10 ) “Rated false” × warning 0 . 03 - 0 . 09 - 0 . 19 * ( 0 . 07 ) ( 0 . 10 ) ( 0 . 11 ) Question ﬁxed eﬀects Yes Yes Yes N ( responses ) 11962 11127 11119 Respondents 2554 2377 2377 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . Ordered probit model with robust standard errors clustered by respondent ( cutpoints omitted ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C8 : Ordered probit model of eﬀects on perceived accuracy of false headlines by article slant Anti - Trump Pro - Trump General warning - 0 . 13 * * - 0 . 08 ( 0 . 06 ) ( 0 . 06 ) “Disputed” tag - 0 . 37 * * * - 0 . 31 * * * ( 0 . 07 ) ( 0 . 07 ) “Rated false” tag - 0 . 57 * * * - 0 . 53 * * * ( 0 . 07 ) ( 0 . 07 ) Trump approval - 0 . 23 * * * 0 . 69 * * * ( 0 . 08 ) ( 0 . 07 ) Warning × Trump approval - 0 . 08 0 . 09 ( 0 . 12 ) ( 0 . 11 ) “Disputed” × warning 0 . 11 0 . 05 ( 0 . 10 ) ( 0 . 10 ) “Disputed” × Trump approval 0 . 19 0 . 09 ( 0 . 13 ) ( 0 . 12 ) “Disputed” × warning × Trump approval - 0 . 07 - 0 . 15 ( 0 . 19 ) ( 0 . 17 ) “Rated false” × warning 0 . 14 0 . 01 ( 0 . 11 ) ( 0 . 11 ) “Rated false” × Trump approval 0 . 28 * * 0 . 14 ( 0 . 14 ) ( 0 . 12 ) “Rated false” × warning × Trump approval - 0 . 06 - 0 . 10 ( 0 . 20 ) ( 0 . 18 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 5972 5972 Respondents 2550 2548 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . Ordered probit model with robust standard errors clustered by respondent ( cutpoints omitted ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C9 : Ordered probit model of spillover eﬀects of warnings on perceived accuracy Untagged Real false headlines headlines General warning - 0 . 10 * * - 0 . 15 * * ( 0 . 05 ) ( 0 . 07 ) “Disputed” condition 0 . 05 0 . 12 ( 0 . 07 ) ( 0 . 07 ) “Rated false” condition - 0 . 02 0 . 04 ( 0 . 06 ) ( 0 . 08 ) “Disputed” × warning 0 . 05 0 . 09 ( 0 . 09 ) ( 0 . 11 ) “Rated false” × warning 0 . 13 0 . 15 ( 0 . 09 ) ( 0 . 11 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 7953 6575 Respondents 2432 2498 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . Ordered probit models with robust standard errors clustered by respondent ( cutpoints omitted ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a “Disputed” or “Rated false” tag for the speciﬁc headline in question . Table C10 : Experimental eﬀects on perceived accuracy ( Facebook users ) Accuracy General warning - 0 . 08 * * ( 0 . 04 ) “Disputed” tag - 0 . 24 * * * ( 0 . 04 ) “Disputed” × warning 0 . 04 ( 0 . 05 ) “Rated false” tag - 0 . 34 * * * ( 0 . 04 ) “Rated false” × warning 0 . 03 ( 0 . 05 ) Constant 1 . 86 * * * ( 0 . 03 ) Question ﬁxed eﬀects Yes N ( responses ) 11118 Respondents 2376 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent ( excludes non - Facebook users ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C11 : Experimental eﬀects on perceived accuracy by article slant ( Facebook users ) Anti - Trump Pro - Trump General warning - 0 . 10 * - 0 . 08 ( 0 . 05 ) ( 0 . 05 ) “Disputed” tag - 0 . 27 * * * - 0 . 25 * * * ( 0 . 05 ) ( 0 . 05 ) “Rated false” tag - 0 . 41 * * * - 0 . 38 * * * ( 0 . 05 ) ( 0 . 05 ) Trump approval - 0 . 19 * * * 0 . 64 * * * ( 0 . 07 ) ( 0 . 07 ) Warning × Trump approval - 0 . 05 0 . 07 ( 0 . 09 ) ( 0 . 10 ) “Disputed” × warning 0 . 08 0 . 07 ( 0 . 08 ) ( 0 . 07 ) “Disputed” × Trump approval 0 . 15 0 . 04 ( 0 . 10 ) ( 0 . 11 ) “Disputed” × warning × Trump approval - 0 . 03 - 0 . 14 ( 0 . 14 ) ( 0 . 15 ) “Rated false” × warning 0 . 11 0 . 02 ( 0 . 08 ) ( 0 . 07 ) “Rated false” × Trump approval 0 . 22 * * 0 . 00 ( 0 . 10 ) ( 0 . 10 ) “Rated false” × warning × Trump approval - 0 . 04 - 0 . 08 ( 0 . 14 ) ( 0 . 15 ) Constant 1 . 92 * * * 2 . 00 * * * ( 0 . 04 ) ( 0 . 04 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 5550 5550 Respondents 2372 2370 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent ( excludes non - Facebook users ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C12 : Experimental tests for spillover eﬀects of warnings ( Facebook users ) Untagged Real false headlines headlines General warning - 0 . 08 * * - 0 . 15 * * * ( 0 . 04 ) ( 0 . 04 ) “Disputed” condition 0 . 02 0 . 05 ( 0 . 05 ) ( 0 . 04 ) “Rated false” condition 0 . 05 0 . 01 ( 0 . 05 ) ( 0 . 04 ) “Disputed” × warning 0 . 07 0 . 10 * ( 0 . 06 ) ( 0 . 06 ) “Rated false” × warning 0 . 02 0 . 18 * * * ( 0 . 07 ) ( 0 . 06 ) Constant 1 . 88 * * * 2 . 87 * * * ( 0 . 03 ) ( 0 . 03 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 7409 6134 Respondents 2275 2326 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent ( excludes non - Facebook users ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a “Disputed” or “Rated false” tag for the speciﬁc headline in question . Table C13 : Experimental eﬀects on perceived accuracy by pre - treatment fake news belief tercile Accuracy General warning - 0 . 09 * ( 0 . 05 ) “Disputed” tag - 0 . 23 * * * ( 0 . 05 ) “Disputed” × warning 0 . 03 ( 0 . 07 ) “Rated false” tag - 0 . 33 * * * ( 0 . 05 ) “Rated false” × warning 0 . 03 ( 0 . 07 ) Medium fake news belief tercile 0 . 26 * * * ( 0 . 05 ) High fake news belief tercile 0 . 59 * * * ( 0 . 06 ) “Disputed” × medium tercile 0 . 02 ( 0 . 07 ) “Disputed” × high tercile - 0 . 10 ( 0 . 09 ) Warning × medium tercile 0 . 03 ( 0 . 07 ) Warning × high tercile - 0 . 07 ( 0 . 08 ) “Disputed” × warning × medium tercile - 0 . 03 ( 0 . 11 ) “Disputed” × warning × high tercile 0 . 15 ( 0 . 13 ) “Rated false” × medium tercile - 0 . 03 ( 0 . 08 ) “Rated false” × high tercile - 0 . 04 ( 0 . 09 ) “Rated false” × warning × medium tercile 0 . 04 ( 0 . 11 ) “Rated false” × warning × high tercile 0 . 02 ( 0 . 13 ) Constant 1 . 63 * * * ( 0 . 04 ) Question ﬁxed eﬀects Yes N ( responses ) 11118 Respondents 2376 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . Fake news belief terciles are calculated using a pre - treatment measure of average level of belief in four fake news claims ( the low tercile is the excluded category above ; see Online Appendix A for item wording ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C14 : Experimental eﬀects on perceived accuracy by pre - treatment fake news belief tercile Anti - Trump Pro - Trump Disapprove Approve Disapprove Approve General warning - 0 . 03 - 0 . 22 * * - 0 . 13 * * 0 . 03 ( 0 . 06 ) ( 0 . 10 ) ( 0 . 06 ) ( 0 . 14 ) “Disputed” tag - 0 . 22 * * * - 0 . 10 - 0 . 26 * * * - 0 . 28 * * ( 0 . 07 ) ( 0 . 11 ) ( 0 . 07 ) ( 0 . 14 ) “Disputed” × warning - 0 . 00 0 . 09 0 . 08 - 0 . 05 ( 0 . 09 ) ( 0 . 15 ) ( 0 . 09 ) ( 0 . 22 ) “Rated false” tag - 0 . 30 * * * - 0 . 16 - 0 . 37 * * * - 0 . 49 * * * ( 0 . 06 ) ( 0 . 13 ) ( 0 . 06 ) ( 0 . 16 ) “Rated false” × warning 0 . 04 0 . 06 0 . 03 - 0 . 05 ( 0 . 09 ) ( 0 . 17 ) ( 0 . 08 ) ( 0 . 24 ) Medium fake news belief tercile 0 . 42 * * * 0 . 21 * 0 . 15 * * 0 . 14 ( 0 . 07 ) ( 0 . 11 ) ( 0 . 07 ) ( 0 . 13 ) High fake news belief tercile 0 . 70 * * * 0 . 56 * * * 0 . 51 * * * 0 . 36 * * * ( 0 . 09 ) ( 0 . 14 ) ( 0 . 10 ) ( 0 . 14 ) “Disputed” × medium tercile - 0 . 03 - 0 . 05 0 . 16 - 0 . 14 ( 0 . 11 ) ( 0 . 17 ) ( 0 . 10 ) ( 0 . 21 ) “Disputed” × high tercile - 0 . 34 * * - 0 . 10 - 0 . 23 0 . 31 ( 0 . 14 ) ( 0 . 18 ) ( 0 . 15 ) ( 0 . 20 ) Warning × medium tercile - 0 . 13 0 . 12 0 . 18 * - 0 . 06 ( 0 . 10 ) ( 0 . 15 ) ( 0 . 10 ) ( 0 . 20 ) Warning × high tercile - 0 . 20 * 0 . 02 0 . 03 - 0 . 08 ( 0 . 12 ) ( 0 . 18 ) ( 0 . 14 ) ( 0 . 20 ) “Disputed” × warning × medium tercile 0 . 01 0 . 03 - 0 . 21 0 . 33 ( 0 . 16 ) ( 0 . 23 ) ( 0 . 15 ) ( 0 . 32 ) “Disputed” × warning × high tercile 0 . 58 * * * - 0 . 07 0 . 25 - 0 . 30 ( 0 . 19 ) ( 0 . 25 ) ( 0 . 20 ) ( 0 . 30 ) “Rated false” × medium tercile - 0 . 15 - 0 . 11 0 . 12 - 0 . 06 ( 0 . 11 ) ( 0 . 18 ) ( 0 . 11 ) ( 0 . 20 ) “Rated false” × high tercile - 0 . 29 * * - 0 . 06 - 0 . 12 0 . 24 ( 0 . 14 ) ( 0 . 20 ) ( 0 . 13 ) ( 0 . 22 ) “Rated false” × warning × medium tercile 0 . 09 0 . 15 - 0 . 11 0 . 28 ( 0 . 15 ) ( 0 . 24 ) ( 0 . 15 ) ( 0 . 32 ) “Rated false” × warning × high tercile 0 . 27 - 0 . 06 0 . 09 - 0 . 21 ( 0 . 21 ) ( 0 . 26 ) ( 0 . 20 ) ( 0 . 32 ) Constant 1 . 61 * * * 1 . 55 * * * 1 . 81 * * * 2 . 57 * * * ( 0 . 05 ) ( 0 . 09 ) ( 0 . 05 ) ( 0 . 10 ) Question ﬁxed eﬀects Yes Yes Yes Yes N ( responses ) 4165 1807 4162 1810 Respondents 1777 773 1775 773 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent ( excludes non - Facebook users ) . Fake news belief terciles are calculated using a pre - treatment measure of average level of belief in four fake news claims ( the low tercile is the excluded category above ; see Online Appendix A for item wording ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a false headline that did not include a “Disputed” or “Rated false” tag . Table C15 : Experimental tests for warning spillover eﬀects by pre - treatment fake news belief tercile Untagged Real false headlines headlines General warning - 0 . 09 * - 0 . 07 ( 0 . 05 ) ( 0 . 06 ) “Disputed” condition 0 . 05 0 . 12 * * ( 0 . 07 ) ( 0 . 06 ) “Disputed” × warning 0 . 03 0 . 05 ( 0 . 09 ) ( 0 . 08 ) “Rated false” condition 0 . 01 0 . 09 ( 0 . 06 ) ( 0 . 06 ) “Rated false” × warning 0 . 11 0 . 05 ( 0 . 09 ) ( 0 . 09 ) Medium fake news belief tercile 0 . 26 * * * - 0 . 11 * ( 0 . 05 ) ( 0 . 06 ) High fake news belief tercile 0 . 59 * * * - 0 . 43 * * * ( 0 . 06 ) ( 0 . 07 ) “Disputed” × medium tercile 0 . 01 - 0 . 17 * * ( 0 . 10 ) ( 0 . 09 ) “Disputed” × high tercile - 0 . 16 0 . 05 ( 0 . 12 ) ( 0 . 11 ) Warning × medium tercile 0 . 03 - 0 . 15 ( 0 . 07 ) ( 0 . 10 ) Warning × high tercile - 0 . 07 0 . 06 ( 0 . 08 ) ( 0 . 10 ) “Disputed” × warning × medium tercile 0 . 06 0 . 14 ( 0 . 14 ) ( 0 . 13 ) “Disputed” × warning × high tercile 0 . 13 - 0 . 13 ( 0 . 15 ) ( 0 . 15 ) “Rated false” × medium tercile 0 . 09 - 0 . 16 * ( 0 . 09 ) ( 0 . 09 ) “Rated false” × high tercile - 0 . 04 - 0 . 01 ( 0 . 11 ) ( 0 . 10 ) “Rated false” × warning × medium tercile - 0 . 16 0 . 24 * ( 0 . 13 ) ( 0 . 14 ) “Rated false” × warning × high tercile - 0 . 06 0 . 06 ( 0 . 15 ) ( 0 . 15 ) Constant 1 . 64 * * * 3 . 01 * * * ( 0 . 04 ) ( 0 . 04 ) Question ﬁxed eﬀects Yes Yes N ( responses ) 7968 6585 Respondents 2436 2502 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent ( excludes non - Facebook users ) . Fake news belief terciles are calculated using a pre - treatment measure of average level of belief in four fake news claims ( the low tercile is the excluded category above ; see Online Appendix A for item wording ) . “Accuracy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition are excluded , as are responses from participants in the disputed and false conditions who saw a “Disputed” or “Rated false” tag for the speciﬁc headline in question . Table C16 : Experimental eﬀects on perceived accuracy by political knowledge Trump disapprovers Trump approvers Belief - consistent Belief - inconsistent Belief - consistent Belief - inconsistent “Disputed” tag - 0 . 26 * * * - 0 . 23 * * * - 0 . 25 * * - 0 . 18 * ( 0 . 07 ) ( 0 . 07 ) ( 0 . 12 ) ( 0 . 10 ) “Rated false” tag - 0 . 51 * * * - 0 . 41 * * * - 0 . 43 * * * - 0 . 25 * * ( 0 . 07 ) ( 0 . 07 ) ( 0 . 12 ) ( 0 . 11 ) High knowledge - 0 . 34 * * * - 0 . 19 * * * - 0 . 05 - 0 . 45 * * * ( 0 . 07 ) ( 0 . 07 ) ( 0 . 12 ) ( 0 . 10 ) “Disputed” × high knowledge - 0 . 05 - 0 . 02 0 . 12 0 . 10 ( 0 . 10 ) ( 0 . 10 ) ( 0 . 18 ) ( 0 . 15 ) “Rated false” × high knowledge 0 . 24 * * 0 . 10 0 . 12 0 . 18 ( 0 . 10 ) ( 0 . 10 ) ( 0 . 18 ) ( 0 . 15 ) Constant 2 . 02 * * * 2 . 05 * * * 2 . 74 * * * 1 . 98 * * * ( 0 . 05 ) ( 0 . 05 ) ( 0 . 08 ) ( 0 . 08 ) Question ﬁxed eﬀects Yes Yes Yes Yes N ( responses ) 2141 2143 927 924 * p < 0 . 1 , * * p < 0 . 05 , * * * p < . 01 ( two - sided ) . OLS models with robust standard errors clustered by respondent . “Ac - curacy” measures belief that a headline is accurate from “Not at all accurate” ( 1 ) to “Very accurate” ( 4 ) . Respondents in the pure control condition and responses with an untagged false headline are excluded . Belief - consistent / inconsistent articles are those which match the assumed partisanship of a participant based on his or her approval of President Trump . If a participant approved of the President , then belief - consistent articles would be pro - Trump and belief - inconsistent articles would be anti - Trump .