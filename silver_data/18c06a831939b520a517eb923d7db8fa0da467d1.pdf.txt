Children’s Trust in Robots and the Information They Provide Thomas Beelen ∗ t . h . j . beelen @ utwente . nl University of Twente Enschede , The Netherlands Ella Velner ∗ p . c . velner @ utwente . nl University of Twente Enschede , The Netherlands Roeland Ordelman roeland . ordelman @ utwente . nl University of Twente Enschede , The Netherlands Khiet P . Truong k . p . truong @ utwente . nl University of Twente Enschede , The Netherlands Theo Huibers t . w . c . huibers @ utwente . nl University of Twente Enschede , The Netherlands Vanessa Evers v . evers @ utwente . nl University of Twente Enschede , The Netherlands ABSTRACT Previous work has shown that children tend to trust embodied con - versational agents such as social robots . Also , that children have difficulty assessing the credibility of information . The study re - ported in this paper addresses how children’s attitudes toward and trust in a robot affect their acceptance of information provided by the robot . We conducted a within - subjects study ( N = 30 ) where chil - dren engaged with a ‘trustworthy’ versus an ‘untrustworthy’ robot . Due to the pandemic period , this interaction was carried out via video call . The children played a quiz with the robot where we mea - sured whether they accepted the information provided by the robot . Results show that the manipulation of trustworthiness was suc - cessful . We did not find evidence for a causal relationship between trust in the robot and acceptance of the information . Furthermore , semi - structured interviews offered a more in - depth understand - ing of how children perceived the two different robots and their preference for the trustworthy robot . CCS CONCEPTS • Human - centered computing → Empirical studies in HCI ; User studies . KEYWORDS children , robots , trust , information assessment ACM Reference Format : Thomas Beelen , Ella Velner , Roeland Ordelman , Khiet P . Truong , Theo Huibers , and Vanessa Evers . 2023 . Children’s Trust in Robots and the Information They Provide . In Extended Abstracts of the 2023 CHI Con - ference on Human Factors in Computing Systems ( CHI EA ’23 ) , April 23 – 28 , 2023 , Hamburg , Germany . ACM , New York , NY , USA , 7 pages . https : / / doi . org / 10 . 1145 / 3544549 . 3585801 1 INTRODUCTION The internet is a rich source of information that children are ex - pected to use independently to learn about many different topics . ∗ Both authors contributed equally to this research . Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 9422 - 2 / 23 / 04 . https : / / doi . org / 10 . 1145 / 3544549 . 3585801 However , the quality of the information is variable . Information can be incomplete , irrelevant , or sometimes even outright false . We focus on children in their last two years of primary school since at this age children increasingly search for information online [ 17 ] but also struggle with assessing the credibility of information [ 14 ] . Children are increasingly exposed to conversational agents , e . g . , smart speakers and robots , for instance at home , in schools , and in public spaces . A robot’s embodiment evokes and smoothens so - cial interaction , and might help with learning [ 6 , 35 ] . Face - to - face , spoken , conversation that robots support provides a natural way of communicating and children often find talking to a robot engaging [ 23 ] and enjoyable [ 22 ] . This also brings challenges that need to be investigated . For instance , children tend to ( over ) trust social robots [ 12 , 13 ] . Children base their trust in conversational partners on characteristics , such as likeability [ 9 ] or errors the robot previously made [ 15 ] . Research by Vollmer et al . [ 36 ] has shown that when children trust robots , they tend to conform to what the robot is saying . We are interested in how the relationship between child , robot , and information impacts the search process . In the current study , we focus on how we can establish different trust levels in a robot , and how trust in the robot influences the acceptance of retrieved information , based on the challenges identified in [ 4 ] . 2 RELATED WORK 2 . 1 Children and online information Important skills relating to assessing the credibility of informa - tion are media literacy and informational skills . Media literacy is concerned with the ability to consciously , critically , and actively engage with media [ 8 ] . Informational skills include the signalling and analysing of an information need and the skills to search , select , process , and present information [ 8 ] . Although educators and gov - ernmental institutions emphasize the need for these skills , they are not always present with children [ 25 , 33 ] . However , from the age of 3 , children already understand that some information sources are more trustworthy than others [ 16 ] . In studies carried out in the US and in the Netherlands , a hoax website about a non - existent animal was used to gauge children’s ability to identify a fake website . Most children trusted the fake website [ 24 , 28 ] . Xu et al . [ 38 ] compared the ability to distinguish real and fake news and found that children performed significantly worse than adults and did not perform much better than chance . CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany Beelen et al . Flanagin and Metzger [ 14 ] list several reasons for children’s chal - lenges in assessing the credibility of online information . Firstly , since children have less life experience , they have accumulated less experience , knowledge , and awareness of competing resources on which credibility assessments are based . Secondly , assessing credi - bility requires cognitive skills still developing in children , making them more susceptible . They also emphasize the risks of assessing credibility inaccurately , which include hampered learning but also physical safety [ 14 ] . When children receive information from a robot , the risk of these issues may be increased due to the com - plex social and inherently trusting relationship they may have with a robot . Therefore , a deeper understanding of the relation - ship between child , robot , and information is necessary before information - providing robots can be designed responsibly . 2 . 2 Children’s trust in robots As children tend to build social relationships with robots [ 6 ] , it becomes important to take the consequences of such relationships into account . One of the consequences is the trust relationship between the child and the robot [ 12 ] . Trust can have consequences for what a user does before , during , or after the interaction [ 11 , 21 ] . If trust is absent in a human - robot relationship , the user might not be using the robot to its fullest capabilities and discard some of its functions ( underuse ) . Too much trust ( overtrust ) is also problematic since a user may over - rely on information from the robot , believing that the robot is always correct . Because of the complexity of trust , researchers have struggled with ways to measure trust reliably . Many try to capture it with self - report measures that aim to measure trust within the HRI con - text ( e . g . , the trust - in - hri questionnaire [ 30 ] , the HRI trust scale [ 39 ] , the trust scale for child - robot interaction [ 34 ] ) . However , these are subject to people - pleasing with children [ 5 ] . Others try with behavioural measures , such as a trust game ( based on [ 7 ] ) or endors - ing one robot over the other [ 15 ] . However , these measures restrict the interaction between the child and the robot and their design is not suitable for the context of information search . This context requires a broad measure of trust to account for the epistemic and social aspects that are involved in the interaction . Thus , we need a child - appropriate broad measure of trust . 2 . 2 . 1 Why children trust robots . To gain more insight into chil - dren’s perception of information - providing robots , we need to iden - tify what children base their trust on . Two core aspects seem to play a role : previous accuracy of the robot [ 10 , 15 ] , and a robot’s social traits , such as benevolence , attractiveness and intelligence [ 3 , 19 , 20 , 32 ] . However , this literature studied young children , showing that research is needed that looks into older children . As children age , they tend to rely more on the epistemic traits of the informant and less on social traits [ 26 ] . It is not known when this shift actually occurs . The older children get the more important epistemic traits such as intelligence become . They also still con - sider the likability of the robot as a proxy for trustworthiness [ 9 ] . Furthermore , literature suggests that children base their trust on the perceived likeability and intelligence of the robot , but the task context of the interaction can determine which factor is salient [ 15 ] . In this study , we implemented trust measures , as well as measures for perceived likeability , intelligence and knowledgeability to gain insight into children’s trust and reasoning . 3 AIM Previous research showed that children find it hard to assess infor - mation [ 14 ] . In addition , children tend to trust robots [ 12 , 13 , 31 ] . Therefore , we expect children will base their assessment of the credibility of the information on their trust in the robot presenting the information . This leads us to study the following hypothesis : H : Children who perceive a robot as more trustworthy are more likely to accept information presented by the robot , as compared to children who perceive a robot as less trustworthy . In addition to testing the hypothesis , we aim to to gain insight into children’s attitudes towards information - providing robots . Fi - nally , an important challenge in researching children’s trust in robots is to find a reliable method to induce trust or distrust in a robot . Therefore , we also aim to establish a reusable trust manipu - lation for child - robot interaction . 4 METHOD We conducted an online , within - subject study with a trustworthy robot ( 𝑇 ) and an untrustworthy robot ( 𝑈 ) . Children played a quiz with each robot where they assessed the credibility of the infor - mation that the robot provided . The within - subject design allows children to compare the conditions and makes more efficient use of the limited number of participants . The study was approved by the ethics committee of our university . 4 . 1 Participants Children ( N = 35 ) between 10 and 12 years old participated in the study . Responses from 5 participants were excluded from the anal - yses because they did not know what to answer more than once on the trust questionnaire , resulting in 𝑁 = 30 ( 𝑀 = 11 . 13 years old , 𝑆𝐷 = 0 . 73 ; 𝐹 = 15 , 𝑀 = 15 ) . They were all pupils of the last two years of primary school in the Netherlands . Parents / guardians gave informed consent on their behalf . Children also gave consent themselves . Participants were randomly assigned to first interact with the trustworthy or the untrustworthy robot , as well as whether they would play quiz A or B first . Two quiz versions were used to avoid repeating questions . 4 . 2 Independent variable The independent variable was the trustworthiness of the robot . The trustworthiness of the robot was manipulated based on research from social sciences and HRI , since the robot has a high anthro - pomorphic design , factors from human - human interaction can be mapped onto human - robot interaction , following the CASA para - digm [ 27 ] . To maximize the contrast between a trustworthy robot ( 𝑇 ) and an untrustworthy one ( 𝑈 ) , the manipulation focused on three key aspects of trust : the robot’s capabilities ( technological trust ) , its displayed emotions ( social trust ) , and its past accuracy ( epistemic trust ) [ 15 , 20 , 32 ] . These were integrated in three parts of the manipulation : a video testimonial of the robot , the demonstra - tion of the robot throughout the interaction , and the quiz answers . The manipulation was checked by measuring children’s trust level in the robot at two - time intervals ( see 4 . 3 for further detail ) . For Children’s Trust in Robots and the Information They Provide CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany ease of reference to the children , the trustworthy robot was named ‘Bart’ and the untrustworthy robot ‘Henk’ . First , children saw a 1 - minute video of the robot in question before they interacted with it , based on [ 20 , 32 ] . Bart was presented as very capable and reliable , with displays of positive emotions and the capability of making jokes . Henk was presented as very incapable , with displays of negative emotions , and faulty behaviour , such as speech recognition errors and flickering . The behaviour shown during the video was also present during the interactions . Furthermore , the demonstration of behaviour included Bart stating that they were there to help the child ( showing benevolence [ 19 ] ) , and Henk staying neutral or slightly negative in its expressions . Finally , Bart always suggested the correct answer , since errors can diminish a child’s trust in the robot [ 15 ] . Henk always suggested an incorrect yet probable answer . The ( in ) correctness of the robot was disclosed to the child after every question round . 4 . 3 Measures 4 . 3 . 1 Quantitative measures . We measured the children’s percep - tion of the robots with a focus on their trust . We implemented a validated trust questionnaire with four items , for measuring gen - eral trust between children and robots by Van Straten et al . [ 34 ] . Furthermore , we asked children about the perceived likeability , in - telligence , and knowledgeability of the robot ( two items each ) , that were inspired by the Godspeed questionnaire [ 2 ] , and adapted for children . The trust questionnaire was executed twice ( after their first introduction to the robot before the quiz , and after the quiz , referred to as trust 1 and trust 2 ) to understand trust development during the quiz , following the advice from Schaefer et al . [ 30 ] to measure trust multiple times throughout the interaction . Likeabil - ity , perceived intelligence and perceived knowledgeability were only measured in measurement moment II , since including them in both measurement moments would have made the process too long for the children . The measurement moments can be seen in figure 2 . For all measurements , we used a ( 5 - point ) smileyometer [ 29 ] that children could fill out in a web form . This was the same web form that the children used to play the quiz . We measured in - formation acceptance by having the child explicitly fill out whether they endorsed the robot’s answer or not . An overview of the trust questionnaires and robot perception scales is shown in table 2 . 4 . 3 . 2 Interviews . After the children engaged with both robots , a semi - structured interview of 15 questions was held via the video - call . The goal was to gain insight into the children’s perception of the robots when comparing the two , what they thought of robots and the internet in general and how they expected robots to deal with credibility issues of online information . We also asked about their current voice agent usage to see if children had experience with talking to an agent , and what they thought about the online setup , as opposed to a face - to - face setup . 4 . 4 Procedure and technical set - up The participant sat in front of a laptop in a separate room at school . To avoid physical proximity with regard to the COVID - 19 pandemic , the researcher , participant , and robot were connected through video call . The robot had a separate video feed ( see the left side of Fig . 1 ) . The researcher and robot were not visible at the same time . The Figure 1 : Setup at the office ( robot’s side , left ) and the school ( child’s side , right ) . video and window for the quiz and the questionnaires were dis - played in a split - screen . The researcher welcomed the participant and explained the procedure , including that they would talk to two versions of a robot . The goal was explained as earning as many points as possible by assessing the robot’s suggestion correctly . The participant was also told that they could stop at any moment without giving a reason . After the briefing , the participant watched a video where the robot was introduced according to the condition . They then had an introductory interaction consisting of small talk about the participant’s day , their expectations , and previous robot experience . This was followed by a questionnaire on their trust in the robot ( measurement moment I ; trust 1 ) . Then the quiz started and an open - ended question was displayed . The robot asked the participant to read the question out loud . The robot then asked whether the participant had an idea of what the answer might be and then gave a suggested answer . The participant chose whether to accept the suggestion or not . The correct answer was revealed before going to the next question . Children received points for judg - ing correctly whether the robot’s suggestion was correct or not , they did not have to provide a correct answer to the question . After three quiz questions , the participant filled out the questionnaire on trust and perceptions ( measurement moment II ; trust 2 , likeability , intelligence , knowledgeability ) , and proceeded to the second condi - tion which followed the same structure . In the end , the researcher held a semi - structured interview with the child as an expert . The procedure is shown in Fig . 2 . The robot we used was a Furhat [ 1 ] . The second researcher who was not visible in the call , teleoperated the robot ( called Wizard - of - Oz ) . The wizard was mainly functioning as the speech recognizer of the robot and clicked the appropriate button following a script . The only script deviations were when a participant did not understand , then a statement could be repeated . The wizard also controlled the laptop in the school to set it up for new participants . The quiz was on fun facts . The questions were designed to be unfamiliar to children , and the answers suggested by the robots were designed to appear equally plausible . This creates a situation in which children cannot rely on their own knowledge to base their judgement of the information on . We presented the robots as information - providing robots that can search online for the correct answer ( in debriefing we disclosed that this was pre - programmed and the internet was used ) . There were two versions of the quiz ( A and B ) in order for participants to have different questions each round . Examples of questions we used are “What do you call a 1 with 100 zeros ? ” , and “What animal cannot look up ? ” . Each quiz consisted of three questions . CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany Beelen et al . Table 1 : Manipulation of trust throughout the study . Manipulation Level Literature Low trust ( 𝑈 ) High trust ( 𝑇 ) Introduction [ 20 ] Robot is incapable , faulty , and made by shady roboticists Robot is very capable , smart , and made by the best roboticists Demonstration [ 20 ] Robot breaks down , flickers Robot interacts perfectly , shows micro - expressions Looks [ 32 ] Neutral face Smiling face Answers [ 15 ] Always incorrect Always correct Figure 2 : Procedure of the study . Top grey block is a within - subjects design with both robots ( X2 means it is encountered twice ) , the bottom grey block is the quiz design which entailed three questions ( X3 means it is encountered three times ) . 4 . 5 Analysis Our analysis consists of descriptive statistics , statistical tests , and qualitative analysis for the interviews . We checked for normality using Shapiro - Wilk tests ( R version 4 . 2 ) . Our data was not nor - mally distributed , therefore we proceeded with non - parametric tests . We also checked whether quiz type , quiz order and condi - tion order had effects on how trust and robot perception questions were answered . We checked for internal consistency ( Cronbach’s 𝛼 with R package psych 2 . 2 . 5 ) of the trust and perception scales . Wilcoxon - Pratt signed - rank tests ( R package coin 1 . 4 . 2 ) were used for assessing the effect of the condition on the trust measures ( both measurement points ) , and on the perception measures . We used a generalised linear mixed model ( R package lme4 1 . 1 . 30 ) to see if the likeliness of accepting the presented information was influenced by the trust condition . Finally , the interview answers were analysed qualitatively with a thematic analysis , which was done by the first two authors watching the video recordings of the interviews , and grouping children’s answers into topics of interest . The notes on these topics were then summarized collaboratively into themes that reflect the range of children’s responses . 5 RESULTS 5 . 1 Manipulation check of the trust conditions We wanted to check whether we could successfully manipulate trust and whether trustworthy and untrustworthy conditions were established . Following Van Straten et al . [ 35 ] , the four trust ques - tionnaire items were averaged for both measurement moments for this comparison . Internal consistency ( Chronbach’s 𝛼 ) was satisfac - tory for both measurement moments ( 0 . 76 for trust 1 , and 0 . 87 for trust 2 ; see Table 2 ) . A Shapiro - Wilk test showed deviance from the normal distri - bution therefore we used a Wilcoxon - Pratt Signed - Rank Test on trust 1 and trust 2 by condition . The descriptives of the two trust measurement moments are reported in table 2 . Before running our analyses we checked whether our experimen - tal design had any unintended influence on trust 2 , by checking for order effects with Wilcoxon - Pratt Signed - Rank Tests . No significant effects were found on condition order nor quiz order . During the experiment , we noticed the second question in quiz B had a strong effect on children’s information acceptance . This question involved exponential growth , which may have been too challenging . Using Fisher’s exact test we can see this question had a significant effect on acceptance ( 𝑝 < 0 . 001 ) . A Wilcoxon - Pratt Test showed that trust 1 answers were signifi - cantly different between the two trust conditions ( 𝑍 = 2 . 512 , 𝑝 = 0 . 010 , 𝑟 = 0 . 324 ) , with a 𝑇 condition median of 4 . 25 and a 𝑈 con - dition median of 4 . 0 . For trust 2 there was also significant differ - ence between the 𝑇 condition ( 𝑀𝑑𝑛 = 4 ) and the 𝑈 condition ( 𝑀𝑑𝑛 = 3 . 25 ) ( 𝑍 = 3 . 925 , 𝑝 < 0 . 001 , 𝑟 = 0 . 507 ) . These results can be found in figure 3 . The graph also shows a trust decrease during the quiz in both conditions , especially in the 𝑈 condition . 5 . 2 Trust and information acceptance We wanted to examine whether trust influenced children’s accep - tance of the information provided by the robot . Information accep - tance was based on the children’s choice in the third question , to give children time to become familiar with the robot during the first two questions . Children in the 𝑇 condition accepted the robot’s answer more often ( 21 times ) than children in the 𝑈 condition ( 14 times ) ( see also Table 3 ) . However , a GLMM with binary distribu - tion did not show significance . Therefore , our hypothesis could not be accepted . Children’s Trust in Robots and the Information They Provide CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany Table 2 : Measurements , their number of items , Cronbach’s alpha ( see section 5 ) , and the medians and mean absolute deviations ( MAD ) of the conditions and total scores . All items used a 5 - point smileyometer . See the appendix for the complete list of items . Construct Number N Cronbach’s 𝛼 T Median ( MAD ) U Median ( MAD ) Total Median ( MAD ) of items Trust 1 4 30 0 . 76 4 . 25 ( 0 . 37 ) 4 ( 1 . 11 ) 4 ( 0 . 74 ) Trust 2 4 30 0 . 87 4 ( 0 . 74 ) 3 . 25 ( 1 . 11 ) 3 . 75 ( 1 . 11 ) Likeability 2 29 0 . 8 4 . 5 ( 0 . 74 ) 4 . 5 ( 0 . 74 ) 4 . 5 ( 0 . 74 ) Intelligence 2 29 0 . 93 4 . 5 ( 0 . 74 ) 3 . 5 ( 1 . 48 ) 4 . 25 ( 1 . 11 ) Knowledgeability 2 29 0 . 93 5 ( 0 ) 4 ( 1 . 48 ) 4 . 5 ( 0 . 74 ) 3 . 0 3 . 5 4 . 0 4 . 5 1 2 measurement ( t ) v a l ue cond TU Figure 3 : Median values of trust measurement moment I ( trust 1 ) and II ( trust 2 ) by condition ( trustworthy 𝑇 robot vs . untrustworthy 𝑈 robot ) . Note that the y - axis is capped . Table 3 : Children’s answers on the quiz questions per con - dition ( trustworthy 𝑇 robot vs . untrustworthy 𝑈 robot ) . The questions with translation can be found in the appendix . 1 𝑠𝑡 question 2 𝑛𝑑 question 3 𝑟𝑑 question T U T U T U Accept 20 16 11 7 21 14 Not accepted 10 14 19 23 9 16 5 . 3 Trust , likeability , intelligence and knowledgeability of the robot The trust condition correlated with other perceptions children had of the robot . One participant was left out of this compari - son , due to answering ‘I do not know’ on one of the two items of the scale . After showing satisfactory internal consistency within the constructs ( 𝛼 > 0 . 70 , see Table 2 ) , we performed a Wilcoxon - Signed Rank test on perceived likeability , intelligence and knowl - edgeability of the robot between conditions . We found signifi - cant differences on all three constructs , showing higher outcomes in the trustworthy condition ; intelligence ( 𝑀𝑑𝑛 𝑇𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 = 4 . 5 , 𝑀𝑑𝑛𝑈𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 = 3 . 5 ) ( 𝑍 = 4 . 322 , 𝑝 < 0 . 001 , 𝑟 = 0 . 567 ) , knowledgeability ( 𝑀𝑑𝑛𝑇𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 = 5 , 𝑀𝑑𝑛𝑈𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 = 4 ) ( 𝑍 = 4 . 2941 , 𝑝 < 0 . 001 , 𝑟 = 0 . 564 ) , and likeability ( 𝑀𝑑𝑛𝑇𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 = 4 . 5 , 𝑀𝑑𝑛𝑈𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 = 4 . 5 ) ( 𝑍 = 2 . 117 , 𝑝 = 0 . 043 , 𝑟 = 0 . 278 ) . 5 . 4 Findings from interviews We gathered some interesting findings from the interviews at the end of each session . Children preferred Bart ( 𝑇 ) , mainly because it was perceived as smarter . Some children preferred Henk ( 𝑈 ) , because it behaved ‘funny’ . Children seemed to relate their thoughts about robots to their thoughts about people . For instance , Bart ( 𝑇 ) felt “like you were talking to a person” and talked “like we would say it” . On the other hand , differences between robots and people were also observed by the children . One child mentioned : “With people you can see when they lie , with robots you cannot ! ” . Occasionally ( N = 6 ) , children mentioned the programmer , and felt that any fault was the programmer’s doing . When asking children about their internet use and its credibility , children seemed to be aware of ‘bad’ information , but did not agree on which websites they could trust . Finally , we asked the children what the difference between a video call and a physical interaction would be for them , hypothetically . Children argued that physical could be more fun , but they would also be more nervous . 6 DISCUSSION AND CONCLUSION The results show that our trust manipulation to create two levels of trust in robots worked , although the ‘low trust’ in 𝑈 was still above the midpoint of the scale ( see Table 2 ) and should be considered as ‘low er trust’ . The qualitative results support these findings , showing that children noticed differences between the robots when asked about it , that were in line with our manipulation . Since the manip - ulation was successful , we could test our hypothesis that children are more likely to accept information presented by a trustworthy robot than by an untrustworthy one . Information acceptance was not significantly impacted by the trust condition , meaning we cannot accept our hypothesis H . Re - sults showed that children tend to accept information from the robot . This could be explained by the literature that shows children find it challenging to assess the credibility of information [ 14 , 38 ] . Furthermore , our behavioural measure of information acceptance was a first attempt at measuring this , but it might not have been sufficient to capture whether children accepted the information . For future research , the information acceptance measure should be tested further , and improved upon . Children did find the robot in the 𝑇 condition more likeable , intelligent and knowledgeable than the robot in the 𝑈 condition . Perceived trust was correlated with likeability , intelligence and knowledgeability . The study was designed as a quiz about fun facts for children and trust was therefore probably more epistemically ( based on knowledge of the robot ) judged than interpersonally CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany Beelen et al . ( based on the honesty of the robot ) . Future research should account for this by choosing an appropriate type of trust measure for their context , taking into account potential confounding factors . The fact that children often compared robots to humans , shows the strong urge of children to anthropomorphize robots [ 18 ] . How - ever , six children also showed awareness about the fact that people ( programmers ) are responsible for building the robots appropriately . This could impact future work : if children know the programmers behind the robot , this might influence their perception of the robot . For future trust research in child - robot interaction , this means that not only children’s trust in the robot should be studied , but also children’s trust in the programmer or developer . Using a behavioural measure for information acceptance , we believe , is useful in prompting more objective results than question - naires , since these are prone to people - pleasing , especially when children are involved [ 5 ] . However , we also suggest future stud - ies complement a behavioural measure with a self - report scale for measuring information acceptance . The self - report measure could reveal more subtleties in children’s acceptance decisions . Our study had several limitations . For example , it is unclear whether children perceived playing the quiz as risky ( a possible precondition for influencing behaviour based on trust [ 37 ] ) . The study was conducted via video call due to the pandemic , which likely affected the results . Furthermore , we did not check for chil - dren’s understanding of the information source , which could have affected their trust in the robot . Our conclusions should be con - sidered carefully , as a post - hoc power analysis showed a power of 0 . 797 with a sample size of 30 and a lack of diversity in the sample . We contribute to the field of HRI by finding that trust , in the con - text of our study , correlates with perceived likeability , intelligence , and knowledgeability and our manipulation of trustworthiness was successful and researchers can further build on our method used . Although we found trust had no significant impact on informa - tion acceptance , this first study yielded valuable insights . Future research will further examine the interaction between children , robots , and information . ACKNOWLEDGMENTS This research is supported by the Dutch SIDN fund ( https : / / www . sidn . nl / ) and TKI CLICKNL funding of the Dutch Ministry of Economic Affairs ( https : / / www . clicknl . nl / ) . REFERENCES [ 1 ] Samer Al Moubayed , Jonas Beskow , Gabriel Skantze , and Björn Granström . 2012 . Furhat : A back - projected human - like robot head for multiparty human - machine interaction . In LectureNotesinComputerScience ( includingsubseriesLectureNotes in Artificial Intelligence and Lecture Notes in Bioinformatics ) , Vol . 7403 LNCS . 114 – 130 . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 34584 - 5 { _ } 9 [ 2 ] Christoph Bartneck , Dana Kulić , Elizabeth Croft , and Susana Zoghbi . 2009 . Mea - surement Instruments for the Anthropomorphism , Animacy , Likeability , Per - ceivedIntelligence , andPerceivedSafetyofRobots . InternationalJournalofSocial Robotics 1 , 1 ( Jan . 2009 ) , 71 – 81 . https : / / doi . org / 10 . 1007 / s12369 - 008 - 0001 - 3 [ 3 ] Igor Bascandziev and Paul L . Harris . 2014 . In beauty we trust : Children prefer information from more attractive informants . British Journal of Developmental Psychology 32 , 1 ( 3 2014 ) , 94 – 99 . https : / / doi . org / 10 . 1111 / bjdp . 12022 [ 4 ] T . Beelen , E . Velner , R . Ordelman , K . P . Truong , V . Evers , and T . Huibers . 2021 . Does your robot know ? Enhancing children’s information retrieval through spoken conversation with responsible robots . arXiv : 2106 . 07931 [ cs ] ( June 2021 ) . http : / / arxiv . org / abs / 2106 . 07931 arXiv : 2106 . 07931 . [ 5 ] Tony Belpaeme , Paul Baxter , Joachim De Greeff , James Kennedy , Robin Read , Rosemarijn Looije , Mark Neerincx , Ilaria Baroni , and Mattia Coti Zelati . 2013 . Child - Robot Interaction : Perspectives andChallenges . In International Conference on Social Robotics . Springer , 452 – 459 . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 02675 - 6 { _ } 45 [ 6 ] Tony Belpaeme , Paul Baxter , Robin Read , Rachel Wood , Heriberto Cuayáhuitl , BerndKiefer , StefaniaRacioppa , IvanaKruijff - Korbayová , GeorgiosAthanasopou - los , Valentin Enescu , Rosemarijn Looije , Mark Neerincx , Yiannis Demiris , Raquel Ros - Espinoza , Aryel Beck , Lola Cañamero , Antione Hiolle , Matthew Lewis , Ilaria Baroni , Marco Nalin , Piero Cosi , Giulio Paci , Fabio Tesser , Giacomo Sommavilla , and Remi Humbert . 2013 . Multimodal child - robot interaction : building social bonds . Journal of Human - Robot Interaction 1 , 2 ( Jan . 2013 ) , 33 – 53 . [ 7 ] Joyce Berg , John Dickhaut , and Kevin McCabe . 1995 . Trust , Reciprocity , and Social History . Games and Economic Behavior 10 ( 1995 ) , 122 – 142 . [ 8 ] H . Boeke , L . Dondorp , M . Heitink , and R . Pijpers . 2017 . Monitor Jeugd en media 2017 . Zoetermeer : Kennisnet ( 2017 ) . [ 9 ] Natalia Calvo - Barajas , Giulia Perugia , and Ginevra Castellano . 2020 . The Ef - fects of Robot’s Facial Expressions on Children’s First Impressions of Trust - worthiness . 29th IEEE International Conference on Robot and Human Interactive Communication , RO - MAN 2020 ( 8 2020 ) , 165 – 171 . https : / / doi . org / 10 . 1109 / RO - MAN47096 . 2020 . 9223456 [ 10 ] Judith H . Danovitch and Reem Alzahabi . 2013 . Children Show Selective Trust in Technological Informants . Journal of Cognition and Development 14 , 3 ( 2013 ) , 499 – 513 . https : / / doi . org / 10 . 1080 / 15248372 . 2012 . 689391 [ 11 ] Ewart J . de Visser , Marieke M . M . Peeters , Malte F . Jung , Spencer Kohn , Tyler H . Shaw , Richard Pak , and Mark A . Neerincx . 2019 . Towards a Theory of Longitu - dinal Trust Calibration in Human – Robot Teams . International Journal of Social Robotics 2019 12 : 2 12 , 2 ( 11 2019 ) , 459 – 478 . https : / / doi . org / 10 . 1007 / S12369 - 019 - 00596 - X [ 12 ] Cinzia Di Dio , Federico Manzi , Giulia Peretti , Angelo Cangelosi , Paul L . Har - ris , Davide Massaro , and Antonella Marchetti . 2020 . Shall I Trust You ? From Child – Robot Interaction to Trusting Relationships . Frontiers in Psychology 11 ( 4 2020 ) . https : / / doi . org / 10 . 3389 / fpsyg . 2020 . 00469 [ 13 ] Meghann Fior , Sarah Nugent , Tanya N . Beran , Alejandro Ramirez - Serrano , and Roman Kuzyk . 2010 . Children’s Relationships with Robots : Robot is Child’s New Friend . Journal of Physical Agents 4 , 3 ( 2010 ) , 9 – 17 . [ 14 ] Andrew J . Flanagin and Miriam J . Metzger . 2008 . Digital media and youth : Unparalleledopportunityandunprecedentedresponsibility . MacArthurFoundation Digital Media and Learning Initiative . [ 15 ] Denise Y . Geiskkovitch , Raquel Thiessen , James E . Young , and Melanie R . Glen - wright . 2019 . What ? That’s Not a Chair ! : How Robot Informational Errors Affect Children’s Trust Towards Robots . In ACM / IEEE International Conference on Human - Robot Interaction , Vol . 2019 - March . IEEE Computer Society , 48 – 56 . https : / / doi . org / 10 . 1109 / HRI . 2019 . 8673024 [ 16 ] Gail D . Heyman . 2008 . Children’s critical thinking when learning from others . Current Directions in Psychological Science 17 , 5 ( 10 2008 ) , 344 – 347 . https : / / doi . org / 10 . 1111 / J . 1467 - 8721 . 2008 . 00603 . X [ 17 ] HannaJochmann - Mannak , TheoHuibers , LeoLentz , andTedSanders . 2010 . Chil - dren searching information on the Internet : Performance on children’s interfaces compared to Google . In SIGIR , Vol . 10 . 27 – 35 . [ 18 ] Peter H . Kahn Jr . , Takayuki Kanda , Hiroshi Ishiguro , Nathan G . Freier , Rachel L . Severson , Brian T . Gill , Jolina H . Ruckert , and Solace Shen . 2012 . “Robovie , you’ll have to go into the closet now” : Children’s social and moral relationships with a humanoid robot . Developmental Psychology 48 , 2 ( 2012 ) , 303 – 314 . https : / / doi . org / 10 . 1037 / a0027033 [ 19 ] Asheley R . Landrum , Candice M . Mills , and Angie M . Johnston . 2013 . When do children trust the expert ? Benevolence information influences children’s trust more than expertise . Developmental Science 16 , 4 ( 7 2013 ) , 622 – 638 . https : / / doi . org / 10 . 1111 / desc . 12059 [ 20 ] Jonathan D . Lane , Henry M . Wellman , and Susan A . Gelman . 2013 . Informants’ Traits Weigh Heavily in Young Children’s Trust in Testimony and in Their Epistemic Inferences . Child Development 84 , 4 ( 7 2013 ) , 1253 – 1268 . https : / / doi . org / 10 . 1111 / cdev . 12029 [ 21 ] John D . Lee and Katrina A . See . 2004 . Trust in Automation : Designing for Appropriate Reliance . Human Factors 46 , 1 ( March 2004 ) , 50 – 80 . https : / / doi . org / 10 . 1518 / hfes . 46 . 1 . 50 _ 30392 [ 22 ] IolandaLeite , AndréPereira , CarlosMartinho , andAnaPaiva . 2008 . Areemotional robots more fun to play with ? . In RO - MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication . IEEE , 77 – 82 . [ 23 ] Jamy Li . 2015 . The benefit of being physically present : A survey of exper - imental works comparing copresent robots , telepresent robots and virtual agents . International Journal of Human - Computer Studies 77 ( May 2015 ) , 23 – 37 . https : / / doi . org / 10 . 1016 / j . ijhcs . 2015 . 01 . 001 [ 24 ] Eugène Loos , Loredana Ivan , and Donald Leu . 2018 . “Save The Pacific Northwest Tree Octopus” : a hoax revisited . Or : how vulnerable are school children to Fake News ? Information and Learning Science ( 2018 ) . Publisher : Emerald Publishing Limited . [ 25 ] Miriam J . Metzger , Andrew J . Flanagin , Alex Markov , Rebekah Gross - man , and Monica Bulger . 2015 . Believing the Unbelievable : Understand - ing Young People’s Information Literacy Beliefs and Practices in the Children’s Trust in Robots and the Information They Provide CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany United States . Journal of Children and Media 9 , 3 ( July 2015 ) , 325 – 348 . https : / / doi . org / 10 . 1080 / 17482798 . 2015 . 1056817 Publisher : Routledge _ eprint : https : / / doi . org / 10 . 1080 / 17482798 . 2015 . 1056817 . [ 26 ] Grace W . Murray . 2021 . Who is more trustworthy , Alexa or mom ? : Children’s selective trust in a digital age . Technology , Mind , and Behavior 2 , 3 ( 9 2021 ) . https : / / doi . org / 10 . 1037 / TMB0000050 [ 27 ] Clifford Nass , Jonathan Steuer , and Ellen R . Tauber . 1994 . Computers are social actors . Proceedings of the SIGCHI conference on Human factors in computing systems celebrating interdependence - CHI ’94 ( 1994 ) , 72 – 78 . https : / / doi . org / 10 . 1145 / 191666 . 191703 [ 28 ] Jodi Pilgrim , Sheri Vasinda , Christie Bledsoe , and Elda Martinez . 2019 . Critical thinking is critical : Octopuses , online sources , and reliability reasoning . The Reading Teacher 73 , 1 ( 2019 ) , 85 – 93 . Publisher : Wiley Online Library . [ 29 ] Janet C . Read and Stuart MacFarlane . 2006 . Using the fun toolkit and other survey methods to gather opinions in child computer interaction . In Proceedings of the 2006 conference on Interaction design and children ( IDC ’06 ) . Association for Computing Machinery , New York , NY , USA , 81 – 88 . https : / / doi . org / 10 . 1145 / 1139073 . 1139096 [ 30 ] Kristin E . Schaefer . 2016 . Measuring Trust in Human Robot Interactions : De - velopment of the “Trust Perception Scale - HRI” . In Robust Intelligence and Trust in Autonomous Systems , Ranjeev Mittu , Donald Sofge , Alan Wagner , and W . F . Lawless ( Eds . ) . Springer US , Boston , MA , 191 – 218 . https : / / doi . org / 10 . 1007 / 978 - 1 - 4899 - 7668 - 0 _ 10 [ 31 ] Rebecca Stower and Arvid Kappas . 2020 . Oh no , my instructions were wrong ! An Exploratory Pilot Towards Children’s Trust in Social Robots . 29th IEEE Inter - national Conference on Robot and Human Interactive Communication , RO - MAN 2020 ( 8 2020 ) , 641 – 646 . https : / / doi . org / 10 . 1109 / RO - MAN47096 . 2020 . 9223495 [ 32 ] Yulong Tang , Paul L Harris , Hong Zou , and Qunxia Xu . 2018 . The impact of emotional expressions on children’s trust judgments . Cognition and Emotion 33 , 2 ( 2018 ) , 318 – 331 . https : / / doi . org / 10 . 1080 / 02699931 . 2018 . 1449735 [ 33 ] A . Thijs , P . Fisser , and M . Van der Hoeven . 2014 . 21e - eeuwse vaardigheden in het curriculum van het funderend onderwijs [ 21st century skills in the curriculum of fundamental education ] . [ 34 ] Caroline L . van Straten , Rinaldo Kühne , Jochen Peter , Chiara de Jong , and Alex Barco . 2020 . Closeness , trust , and perceived social support in child - robot relationship formation . Interaction Studies 21 , 1 ( 1 2020 ) , 57 – 84 . https : / / doi . org / 10 . 1075 / is . 18052 . str [ 35 ] Caroline L . van Straten , Jochen Peter , and Rinaldo Kühne . 2020 . Child – Robot Relationship Formation : A Narrative Review of Empirical Research . International Journal of Social Robotics 12 , 2 ( May 2020 ) , 325 – 344 . https : / / doi . org / 10 . 1007 / s12369 - 019 - 00569 - 0 [ 36 ] Anna - Lisa Vollmer , Robin Read , and Tony Belpaeme . 2018 . Children conform , adultsresist : Arobotgroupinducedpeerpressureonnormativesocialconformity . Science Robotics 3 ( 2018 ) , 1 – 7 . https : / / doi . org / 10 . 1126 / scirobotics . aat7111 [ 37 ] AlanRWagner , PaulRobinette , andAyannaHoward . 2018 . ModelingtheHuman - Robot Trust Phenomenon : A Conceptual Framework Based on Risk . ACM Trans . Interact . Intell . Syst . 8 , 4 ( 11 2018 ) . https : / / doi . org / 10 . 1145 / 3152890 [ 38 ] Shiao Xu , Andrew Shtulman , and Andrew G . Young . 2022 . Can Children Detect Fake News ? . In Proceedings of the Annual Meeting of the Cognitive Science Society . [ 39 ] RosemarieE . YagodaandDouglasJ . Gillan . 2012 . YouWantMetoTrustaROBOT ? TheDevelopmentofaHuman - RobotInteractionTrustScale . InternationalJournal ofSocialRobotics 4 , 3 ( 82012 ) , 235 – 248 . https : / / doi . org / 10 . 1007 / s12369 - 012 - 0144 - 0