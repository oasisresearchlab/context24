Observation - Based Design Methods for Gestural User Interfaces Abstract The design of gestural user interfaces is uniquely challenging because the input is freeform , personal , and often carries subconscious meanings that are domain - specific and difficult to articulate . These features suggest an approach of observation - based design : learning from what people do , rather than relying on what they say . To facilitate observation - based design , this dissertation is exploring two design methods : gesture brainstorming , a Wizard of Oz method for early prototyping of new interfaces , and gesture log analysis , a machine learning - based log analysis method for improving existing interfaces . These design methods will be tested by applying them to two gestural interfaces : a 3D pathway selection interface ( CINCH , see Figure 1 ) , and a 3D modeler ( Google SketchUp ) . Experience with CINCH already suggests the utility of observation - based design , while work on Google SketchUp is anticipated to begin this summer . These test cases should inform observation - based design for gestural user interfaces in general . Keywords Gestural user interfaces , brainstorming , usage log analysis , observation - based design . ACM Classification Keywords H . 5 . 2 [ Information Interfaces and Presentation ] : User Interfaces - prototyping , theory / methods Copyright is held by the author / owner ( s ) . CHI 2007 , April 28 – May 3 , 2007 , San Jose , California , USA . ACM 978 - 1 - 59593 - 642 - 4 / 07 / 0004 . David Akers PhD Candidate 353 Serra Mall , Gates 3B - 396 Stanford , CA 94305 dakers @ stanford . edu Figure 1 : The interface designer works together with a neuroscientist during a gesture brainstorming exercise for CINCH , a 3D pathway selection interface . Introduction Gestural user interfaces are coming into increasingly widespread use . With pen or mouse gestures , people can now author musical scores , create interactive mathematical demonstrations , and make architectural drawings , to name a few examples . Novel interfaces such as the Nintendo Wii make use of freeform hand - gestures to make for a more physical and engaging interactive experience . The design of gestural interfaces can be particularly challenging . The designer must invent a gesture language : a set of possible meanings for each of the freeform physical actions that a user might perform . What makes this so difficult is that physical gestures are loaded with subconscious meanings that are domain specific and often difficult to articulate . This dissertation explores the value of an observation - based design approach , in which we focus on what people do with gestural interfaces , rather than relying exclusively on what they say . Two observation - based design methods are proposed : gesture brainstorming , and gesture log analysis , which are described in the following section ( see Figure 2 ) . Design Methods Initially , a typical design process focuses on brain - storming : generating as many interface ideas as possi - ble , without worrying about narrowing these choices to a single final design . To further the goal of brainstorm - ing , this dissertation proposes a cooperative gesture brainstorming method . Gesture brainstorming makes use of a Wizard of Oz [ 5 ] strategy to allow end - users to invent their own gesture language ( see Figures 1 & 4 ) . The end - user explains the meaning of each invented gesture to the designer , who acts as the “wizard” to simulate the intended effect of the gesture behind the scenes . The Wizard of Oz strategy allows the simulation of complex system behaviors before these behaviors have been implemented . This enables designer and end - user to cooperatively explore the design space for gesture languages . Furthermore , this method can be iteratively applied , where gestures invented in previous sessions are used as tools for the wizard to simulate new ones . Once a gestural interface has been deployed , the focus shifts toward evaluating existing designs and iteratively improving them . The gesture log analysis method involves recording end - users’ physical gestures , and then analyzing the recorded data for design implica - tions . It is hypothesized that log analysis will reveal user intentions implicitly encoded in gestures . For ex - ample , if a user executes a gesture to rotate a three - dimensional scene , there is some domain - specific pur - pose of that rotation . The user may seek to resolve occlusions , or perhaps to orient the scene for a future gesture . Gesture log analysis seeks to recover the pur - pose by studying features of the recorded rotation ges - ture ( including its context within the application ) . Re - covering users’ intentions would have direct implica - tions for the design of new software features to support rotation ; understanding why users choose particular 3D views is a precursor to helping them with how to pick these views . Classification of intent such as this is an instance of data abstraction : extracting higher level meanings from raw event data ( see Figure 3 ) . This dis - sertation’s approach is to apply supervised machine learning techniques to automatically classify the log data . Training data could be hand - classified using a talk - aloud protocol or a post hoc video analysis . brainstorming refinement development gesture brainstorming gesture log analysis Figure 2 : A typical gestural inter - face evolves through several design phases . First , brainstorming results in design principles and candidates for a gesture language . Second , a full system is developed using rapid prototyping techniques . Finally , the resulting system is deployed and iteratively improved . Gesture brain - storming and gesture log analysis target the first and last stages of this evolution , respectively . 0 2 4 6 8 Time ( hours ) GestureGestureTypeNewSessionSelectionModeUndoRedo Figure 3 : A Gantt chart displays event log data from a scientist’s use of a gestural interface . To be useful to a designer , these raw log events must be classified and aggregated into meaningful semantic events . Applications This section describes the use of gesture brainstorming and gesture log analysis in the context of two gestural interfaces . CINCH [ 1 ] , a pen - based gestural interface for 3D pathway selection , demonstrates the use of both design methods . CINCH was designed cooperatively with neuroscientists , who require an interface to disentangle and analyze neural pathways estimated from magnetic resonance imaging . The design of CINCH began with gesture brainstorming sessions with five scientists . Aided by a Wizard of Oz prototype , the scientists invented a rich set of gestural commands for selecting pathways , three of which were adopted in the final design of the system ( see Figure 4 ) . The invention of the shape matching and touch ges - tures confirmed the designer’s hypotheses that these would be useful to scientists . The surface intersection operation was unanticipated by the designer , and pro - vides a critical way for scientists to ensure that path - ways pass through specific anatomical structures visible in the imaging data . The brainstorming process also resulted in several important interface design princi - ples . For example , we discovered that cutting planes of imaging data provide a natural way to mediate the depth ambiguity of marking operations in 3D ; marks should be interpreted only within the visible side of each cutting plane . A complete version of CINCH is ready for release to hundreds of neuroscientists worldwide , making it possi - ble to capture and benefit from extensive usage log data . It is hoped that gesture log analysis will help with two interface problems . First , CINCH users currently struggle with the problem of view selection : adjusting the 3D viewing parameters of the scene ( e . g . rotation and zoom ) . Some view changes are pragmatic : the sci - entist finds the right view to perform an action . Others serve an epistemic [ 6 ] purpose : the user attempts to understand what is in the scene . It is hypothesized that log analysis will prove capable of distinguishing be - tween pragmatic and epistemic changes of the view , using features of view change gestures and their sur - rounding context of actions . This classification would help in designing automatic support for view selection . A second remaining problem with CINCH is its numer - ous interface modes that control how gestural com - mands are interpreted . Managing these modes places demands on scientists’ short - term memory , interfering with their workflow . It is hypothesized that gesture log analysis can be used to dramatically simplify the mode system . For example , by analyzing the features of ges - tural commands , it may be possible to predict whether a scientist means to perform a shape match , touch , or surface intersection command , thus obviating the need for a prior selection of mode . A second system , Google SketchUp [ 8 ] , provides a potential opportunity to test the commercial viability of the proposed design methods . SketchUp is a stroke - based 3D modeling interface that allows users to quickly mock up ideas in 3D ( see Figures 5 and 6 ) . SketchUp has already been released and downloaded by hundreds of thousands of users , so the design team’s interest focuses on applying gesture log analysis to incrementally improve the current interface . SketchUp has some of the same design challenges as CINCH ( facilitating view selection and simplifying the Figure 4 : Three 3D selection gestures invented by CINCH users during gesture brainstorming : A ) shape match ( selects paths that look like the gesture curve ) . B ) touch ( selects any paths that touch the gesture ) . C ) surface - intersection ( selects paths that intersect the specified region on a cutting plane ) . mode system ) , but there are two further goals that the team is interested in pursuing . First , log analysis may help to detect common patterns of interface use ( e . g . stair - building ) , which could motivate new feature de - velopment . Second , log analysis could be used to im - prove context sensitive help , by detecting when users experience breakdowns using the interface . Related Work This research was inspired by extensive prior work in brainstorming methods and usage log analysis . Bødker and Grønbæk’s original work on cooperative prototyp - ing [ 2 ] established the importance of actively involving end - users in the brainstorming process , while Mackay et al . ’s research on video prototyping [ 7 ] demonstrated the value of the Wizard of Oz approach during brain - storming . This dissertation proposes similar strategies to brainstorm gestural commands . Hilbert and Redmiles provide a useful taxonomy of usage log analysis re - search [ 3 ] . The use of supervised machine learning to infer the hidden meanings of gestures can be classified in their taxonomy as a technique of “transforming event streams . ” Previous work on 3D pen - based interfaces has also provided a source of inspiration . In SKETCH [ 9 ] , Ze - leznik et al . pioneered the first pen - based 3D modeling interface . With the Teddy system [ 4 ] , Igarashi et al . invented an interface for freeform sketching of rough 3D shapes . CINCH [ 1 ] draws heavily upon both . Current and Future Work CINCH will be released to the public soon . Work has begun with local scientists to generate the training data necessary to train the classifiers . The Google SketchUp log analysis project is anticipated to begin this summer . Acknowledgements I thank Scott Klemmer , Terry Winograd , and my advi - sor Pat Hanrahan for their helpful discussions on fram - ing this research . References [ 1 ] Akers , D . CINCH : A Cooperatively Designed Marking Interface for 3D Pathway Selection . In UIST ’06 , pp . 33 - 42 , 2006 . [ 2 ] Bødker , S . and K . Grønbæk . Cooperative Prototyp - ing Studies – Users and Designers Envision a Dentist Case Record System . Studies in Computer - Supported Cooperative Work : Theory , practice and design , pp . 315 - 332 , 1989 . [ 3 ] Hilbert , D . and D . Redmiles . Extracting Usability Information from User Interface Events . ACM Com - puting Surveys , 32 ( 4 ) , pp . 384 - 421 , 2000 . [ 4 ] Igarashi , T . , S . Matsuoka , and H . Tanaka . Teddy : a Sketching Interface for 3D Freeform Design . In SIG - GRAPH ’99 , pp . 409 – 416 , 1999 . [ 5 ] Kelley , J . An Iterative Design Methodology for User - friendly Natural Language Office Information Appli - cations . ACM Transactions on Office Information Systems 2 ( 1 ) ( 1984 ) , 26 – 41 . [ 6 ] Kirsh , D . and P . Maglio . On Distinguishing Epistemic from Pragmatic Action . Cognitive Science , 18 ( 4 ) , pp . 513 – 549 , 1994 . [ 7 ] Mackay , W . , A . Ratzer , P . Janecek . Video Artifacts for Design : Bridging the Gap Between Abstraction and Detail . In DIS ’00 , pp . 72 - 82 , 2000 . [ 8 ] SketchUp , Google Inc . http : / / sketchup . google . com / [ 9 ] Zeleznik , R . , K . Herndon , and J . Hughes . SKETCH : An Interface for Sketching 3D Scenes . In SIGGRAPH ’96 , pp . 163 – 170 . 1996 . Figure 5 : Google SketchUp is a gestural interface for sketching 3D content . Gesture log analysis should help to address design problems and invent new features . Figure 6 : The SketchUp interface has 16 drawing modes that affect how pen strokes are interpreted . Such mode complexity can be the source of user frustration and error . Log analysis may help to redesign the mode system to minimize mode errors .