Stat . Appl . Genet . Mol . Biol . 2016 ; 15 ( 6 ) : 447 – 471 Audrey Qiuyan Fu a , * and Lior Pachter * Estimating intrinsic and extrinsic noise from single - cell gene expression measurements DOI 10 . 1515 / sagmb - 2016 - 0002 Abstract : Gene expression is stochastic and displays variation ( “noise” ) both within and between cells . Intracellular ( intrinsic ) variance can be distinguished from extracellular ( extrinsic ) variance by applying the law of total variance to data from two - reporter assays that probe expression of identically regulated gene pairs in single cells . We examine established formulas [ Elowitz , M . B . , A . J . Levine , E . D . Siggia and P . S . Swain ( 2002 ) : “Stochastic gene expression in a single cell , ” Science , 297 , 1183 – 1186 . ] for the estimation of intrinsic and extrinsic noise and provide interpretations of them in terms of a hierarchical model . This allows us to derive alternative estimators that minimize bias or mean squared error . We provide a geometric interpretation of these results that clarifies the interpretation in [ Elowitz , M . B . , A . J . Levine , E . D . Siggia and P . S . Swain ( 2002 ) : “Stochastic gene expression in a single cell , ” Science , 297 , 1183 – 1186 . ] . We also demonstrate through simulation and re - analysis of published data that the distribution assumptions underlying the hierarchical model have to be satisfied for the estimators to produce sensible results , which highlights the importance of normalization . Keywords : gene expression ; noise ; optimal estimators ; single cell . 1 Introduction A gene can have different expression levels in living cells that have the same genetic material and are subject to the same environment ( Stegle et al . , 2015 ) . During early development of an organism , distinct expression profiles eventually lead to formation of different tissues . Moreover , complex tissues such as brain have many different subtypes of cells with different gene expression profiles . However , variation in expression between cellsisreflectivenotonlyofdistinctbiologicalstate , butalsoofstochasticityunderlyingmanyoftheprocesses fundamental to the molecular biology of cell . In a classic paper on the stochasticity of gene expression in single cells , Elowitz et al . ( 2002 ) introduced a clever two - reporter expression assay designed to tease apart “intrinsic” and “extrinsic” variation ( also called “noise” ) from the overall variability in gene expression : the intrinsic noise is the variation in the expression of the same gene in identical environment , whereas the extrinsic noise is the variation in gene expression due to cellular environment that impacts all the genes at once . The idea is as follows : two identically regulated reporter genes ( cyan fluorescent protein and yellow fluorescent protein ) are inserted into individual E . coli . cells , allowing for comparable expression measurements within and between cells . If n cells are assayed , this leads to expression measurements c 1 , . . . c n and y 1 , . . . y n , where the pair ( c i , y i ) represent the expression measurements for the cyan and yellow reporters in the i th cell . The goal of the experiment is to measure the variance in gene expression from the pairs ( c i , y i ) ( denoted by η 2 tot ) and to ascribe it to two different sources : first , variability due to the different states of cells ( “extrinsic noise , ” denoted by η 2 ext ) , and second , inherent variability that exists even when the state of cells is fixed ( “intrinsic noise , ” denoted by η 2 int ) . In a Present address : Department of Statistical Science , University of Idaho , Moscow , ID 83844 , USA * Corresponding authors : Audrey Qiuyan Fu , Department of Genetics , Stanford University , Stanford , CA 94305 , USA ; and Department of Human Genetics , University of Chicago , Chicago , IL 60637 , USA , e - mail : audreyf @ uidaho . edu ; and Lior Pachter , Departments of Mathematics , Molecular & Cell Biology and Computer Science , University of California , Berkeley , Berkeley , CA 94720 , USA , e - mail : lpachter @ math . berkeley . edu 448 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Elowitz et al . ( 2002 ) , these noise terms are defined as squared coefficients of variation and specific formulas are provided for estimating η 2 ext , η 2 int and η 2 tot ( hereafter referred to as the ELSS estimates ) : η 2 int = 1 n (︀∑︀ ni = 1 12 ( c i − y i ) 2 )︀ c · y , ( 1 ) η 2 ext = 1 n ∑︀ ni = 1 c i · y i − c · y c · y , ( 2 ) η 2 tot = 1 n ∑︀ ni = 1 12 ( c 2 i + y 2 i ) − c · y c · y , ( 3 ) where c = 1 n ∑︀ ni = 1 c i and y = 1 n ∑︀ ni = 1 y i . Hilfinger and Paulsson ( 2011 ) later interpreted these estimates in terms of the “law of total variance” ( explained in the next section ) , which sheds light on the statistical basis of the ELSS estimators but does not address questions about their statistical properties . In this paper , we derive the bias and mean squared error of the ELSS estimators and examine their optimality . We also examine the geometric and biological interpretation of the estimators . The processes that lead to the expression of the reporters ( or genes in general ) are much more complex than described here , e . g . the models described in the paper ignore the effects of translation . Many studies ( e . g . Rausenberger and Kollmann 2008 and Komorowski et al . 2013 ) have developed detailed mathematical models for these processes . While some of our results may generalize and be relevant in more general settings , we restrict our analysis to the intrinsic and extrinsic noise as examined by Elowitz et al . ( 2002 ) and accessible via static reporter expression experiments . Analyses are implemented in the R package noise available on CRAN . 2 A hierarchical model We begin by introducing a hierarchical model that provides a formal model for the experiments of Elowitz et al . ( 2002 ) and that provides insight into the numerators of ( 1 , 2 , 3 ) . They are the key components of the Elowitz et al . ( 2002 ) formulas and can be viewed as estimators of true variances . We note that lower case letters such as c i and y i denote observations not only in the ELSS formulas but throughout our paper ; we reserve uppercase letters for random variables . A hierarchical model for expression of the two reporters in a cell emerges naturally from the assumption that reporter expression , conditioned on the same cellular environment , is represented by independent and identically distributed random variables . To allow each cell to be different from the others , we introduce independent identically distributed random variables Z i , for i = 1 , . . . , n that represent the environments of cells [ as in Hilfinger and Paulsson ( 2011 ) ] . Consistent with Elowitz et al . ( 2002 ) , we posit that the cellular conditional random variables associated to the two reporters have the same distribution F with mean M i and variance Σ 2 i , both parameters being unique to the i th cell : C i | Z i ∼ F ( M i , Σ 2 i ) ( 4 ) and Y i | Z i ∼ F ( M i , Σ 2 i ) . ( 5 ) Thinking of a two reporter experiment as “random , ” in the sense that the states of cells Z 1 , . . . Z n are random , across cells we have M i ∼ G ( µ , σ 2 µ ) and Σ 2 i ∼ H ( σ 2 , ϵ ) , where G is the distribution of all the M i s , with mean µ and variance σ 2 µ , and H that of all the Σ 2 i s , with mean σ 2 and variance ϵ . In other words , both the mean and variance of reporter expression level is cell specific A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 449 and the random variable Σ 2 i and its mean σ 2 represent the “within - cell " variation as distinguished from the parameter σ 2 µ which represents the “between - cell " variability in the ANOVA setting . For any i , the mean of C i or Y i is µ , according to the following calculation : E [ C i ] = E Z i [ E [ C i | Z i ] ] = E [ M i ] = µ . ( 6 ) The total variance in C i ( or Y i ) can be calculated using the “law of total variance” : Var [ C i ] = E Z i [ Var [ C i | Z i ] ] + Var Z i [ E [ C i | Z i ] ] . ( 7 ) Using the notation of the hierarchical model described above , and dropping the subscripts for expectation because they are clear by context , we have , for any i , E [ Var [ C i | Z i ] ] = σ 2 ( within - cell variability ; intrinsic noise ) , ( 8 ) Var [ E [ C i | Z i ] ] = σ 2 µ ( between - cell variability ; extrinsic noise ) . ( 9 ) With this notation equation ( 7 ) becomes Var [ C i ] = E [ Var [ C i | Z i ] ] + Var [ E [ C i | Z i ] ] = σ 2 + σ 2 µ ( total noise ) . ( 10 ) This means that the marginal ( unconditional ) distributions of C i and Y i are identical : C i ∼ F ′ ( µ , σ 2 + σ 2 µ ) ; Y i ∼ F ′ ( µ , σ 2 + σ 2 µ ) , where the marginal distribution F ′ may or may not be the same as the conditional distribution F . In the next sections , we will derive the estimators for extrinsic and intrinsic noise , and examine the bias and MSE of each estimator . Specifically , for any estimator S , the MSE of S with respect to the true parameter τ is calculated as follows : E [ ( S − τ ) 2 ] = E [ S − E [ S ] + E [ S ] − τ ] 2 = E [︂ ( S − E [ S ] ) 2 + ( E [ S ] − τ ) 2 + 2 ( S − E [ S ] ) ( E [ S ] − τ ) ]︂ = E [ S − E [ S ] ] 2 + E [ E [ S ] − τ ] 2 = Var [ S ] + ( E [ S ] − τ ) 2 , where E [ S ] − τ is the bias of S . 3 Extrinsic noise To examine estimators for extrinsic noise , we start with the law of total variance , noting that the within - cell variability Var [ E [ C i | Z i ] ] can be written as : Var [ E [ C i | Z i ] ] = E [ E [ C i | Z i ] 2 ] − ( E [ E [ C i ] Z i ] ) 2 = E [ E [ C i | Z i ] E [ Y i | Z i ] ] − ( E [ E [ C i ] Z i ] ) 2 = E [ E [ C i Y i | Z i ] ] − E [ E [ C i | Z i ] E [ E [ Y i | Z i ] ] = E [ C i Y i ] − E [ C i ] E [ Y i ] = Cov [ C i , Y i ] . ( 11 ) This connection between the extrinsic noise , the law of total variance and the covariance of C i and Y i was noted in Hilfinger and Paulsson ( 2011 ) . 450 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Formula ( 11 ) leads to the following unbiased estimator for the extrinsic noise , as it is an unbiased estimator estimator for the covariance : S * ext = 1 n − 1 (︃ n ∑︁ i = 1 C i Y i − n ¯ C ¯ Y )︃ . We note that the ELSS estimator ( 2 ) uses the scalar 1 / n , which unlike the case of the intrinsic noise estimator ( 1 ) leads to a biased estimator in this case . In order to find the estimator that minimizes the MSE , we consider the following general estimator : S ext = 1 a (︃ n ∑︁ i = 1 C i Y i − n ¯ C ¯ Y )︃ . We assume that M i is normal and that µ = 0 and ϵ = 0 . The MSE of S ext is E [ S ext − σ 2 µ ] 2 = n − 1 a 2 ( σ 2 + σ 2 µ ) 2 + ( n − 1 ) 2 na 2 σ 4 µ + (︂ n − 1 a σ 2 µ − σ 2 µ )︂ 2 = ( n − 1 ) ( σ 2 + σ 2 µ ) 2 1 a 2 + ( n − 1 ) 2 (︂ 1 + 1 n )︂ σ 4 µ 1 a 2 − 2 ( n − 1 ) σ 4 µ 1 a + σ 4 µ = (︂ ( n − 1 ) ( σ 2 + σ 2 µ ) 2 + ( n − 1 ) 2 (︂ 1 + 1 n )︂ σ 4 µ )︂ 1 a 2 − 2 ( n − 1 ) σ 4 µ 1 a + σ 4 µ , which is minimized when 1 a = σ 4 µ ( σ 2 + σ 2 µ ) 2 + ( n − 1 ) (︂ 1 + 1 n )︂ σ 4 µ , or equivalently a = ( n − 1 ) (︂ 1 + 1 n )︂ + (︂ σ 2 + σ 2 µ σ 2 µ )︂ 2 = ( n − 1 ) (︂ 1 + 1 n )︂ + 1 ρ 2 . ( 12 ) The last step in ( 12 ) is due to Equations ( 9 ) , ( 10 ) and ( 11 ) : σ 2 µ σ 2 + σ 2 µ = Cov [ C i , Y i ] Var [ C i ] = Cov [ C i , Y i ] √︀ Var [ C i ] √︀ Var [ Y i ] = ρ . ( 13 ) It is interesting to note that ( 12 ) comprises two parts : the first , ( n − 1 ) ( 1 + 1 n ) converges to n − 1 as n → ∞ , while the second , ( σ 2 + σ 2 µ σ 2 µ ) 2 is equal to 1 ρ 2 where ρ is the correlation between the two reporter expression vectors C and Y . See Appendices A and B for more details . 4 Intrinsic noise Also starting with the law of total variance , the within - cell variability E [ Var [ C i | Z i ] ] for cell i can be written as : E [ Var [ C i | Z i ] ] = Var [ C i ] − Var [ E [ C i | Z i ] ] = 1 2 [ Var [ C i ] + Var [ Y i ] ] − Cov [ C i , Y i ] = 1 2 [ Var [ C i ] − 2 Cov [ C i , Y i ] + Var [ Y i ] ] = 1 2 Var [ C i − Y i ] = 1 2 (︁ E [ C i − Y i ] 2 − ( E [ C i − Y i ] ) 2 )︁ . ( 14 ) A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 451 This leads to the following unbiased estimator for the intrinsic noise : S * int = 1 2 ( n − 1 ) n ∑︁ i = 1 [︂ ( C i − Y i ) − ( ¯ C − ¯ Y ) ]︂ 2 = 1 2 ( n − 1 ) n ∑︁ i = 1 ( C i − Y i ) 2 − n 2 ( n − 1 ) ( ¯ C − ¯ Y ) 2 . To find the estimator that minimizes the MSE , we consider estimators of the following general form S int = 1 2 a (︃ n ∑︁ 1 ( C i − Y i ) 2 − n ( ¯ C − ¯ Y ) 2 )︃ . ( 15 ) Assuming normality of the distribution G ( i . e . cell - specific means M i follow a normal distribution ) , as well as µ = 0 and ϵ = 0 , the MSE is given by E [ S int − σ 2 ] 2 = Var [ S int ] + ( E [ S int ] − σ 2 ) 2 = 1 2 a 2 [︂ ( 2 n 2 + 6 n − 7 ) σ 4 + 2 ( 2 n − 1 ) σ 2 σ 2 µ + 1 n σ 4 µ ]︂ − 2 ( n − 1 ) σ 4 1 a + σ 4 . The value of a that minimizes this expression is a = ( 2 n 3 − 7 n + 6 ) σ 4 + 2 ( 2 − n ) σ 2 σ 2 µ + σ 4 µ 2 ( n 2 − n ) σ 4 = 2 n 3 − 7 n + 6 2 ( n 2 − n ) + 2 − n n 2 − n σ 2 µ σ 2 + 1 2 ( n 2 − n ) (︂ σ 2 µ σ 2 )︂ 2 = 2 n 3 − 7 n + 6 2 ( n 2 − n ) + 2 − n n 2 − n ρ 1 − ρ + 1 2 ( n 2 − n ) (︂ ρ 1 − ρ )︂ 2 . See Appendices A and C for the complete derivation . The analysis above can be simplified with an additional assumption , namely that ¯ C = ¯ Y . In some experimentsthismaybeanaturalassumptiontomake , whereasinotherstheconditionislikelytobeviolated ; we comment on this in more detail in the discussion . Here we proceed to note that assuming that ¯ C = ¯ Y , the estimator ( 15 ) simplifies to ˜ S int = 1 2 a n ∑︁ i = 1 ( C i − Y i ) 2 . The unbiased estimator with this form is easily derived by observing that E [ ˜ S int ] = 1 2 a n ∑︁ i = 1 E [ C i − Y i ] 2 = 1 2 a n ∑︁ i = 1 Var [ C i − Y i ] = n 2 a ( 2 σ 2 + 2 σ 2 µ − 2 σ 2 µ ) = n a σ 2 . Thus , in order for ˜ S int to be unbiased the parameter a must be equal to n . The resulting formula is the ELSS formula in ( 1 ) . This makes clear that the assumption ¯ C = ¯ Y underlies the derivation of the ELSS intrinsic noise estimator . In order to study the mean squared error and derive an estimator that minimizes it , we again assume normality of G . The MSE of S int is then given by E [ ˜ S int − σ 2 ] 2 = Var [ ˜ S int ] + ( E [ ˜ S int ] − σ 2 ) 2 = n a 2 ( 3 ϵ + 2 σ 4 ) + ( n a σ 2 − σ 2 ) 2 . Assuming again that µ = 0 and ϵ = 0 , the MSE simplifies to E [ ˜ S int − σ 2 ] 2 = 2 n a 2 σ 4 + σ 4 (︂(︁ n a )︁ 2 − 2 n a + 1 )︂ = nσ 4 ( n + 2 ) a 2 − 2 nσ 4 a + σ 4 , which is minimized when a = n + 2 ( see Appendices A and D for the complete derivation ) . 452 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise 5 Geometric interpretation Figure 3A of Elowitz et al . ( 2002 ) shows a scatterplot of data ( c i , y i ) for an experiment and suggests thinking of intrinsic and extrinsic noise geometrically in terms of projection of the points onto a pair of orthogonal lines . While this geometric interpretation of noise agrees exactly with the ELSS intrinsic noise formula , the interpretation of extrinsic noise is more subtle . Here we complete the picture . To understand the intuition behind Figure 3A in Elowitz et al . ( 2002 ) , we have redrawn it in a format that highlights the math ( Figure 1 ) . The projection of a point ( c i , y i ) onto the line y = c is the point ( ( y i + c i ) / √ 2 , ( y i − c i ) / √ 2 ) , shown as the red point in Figure 1 . Assuming equal means ( ¯ c = ¯ y ) , the intrinsic noise , as estimated by the unbiased estimator ( 1 ) , is then the mean squared distance of the points from the line y = c . The ELSS estimate for the extrinsic noise is the sample covariance . Intuitively , it indicates how the measurements of one reporter track that of the other across cells . The geometric meaning of the sample covariance in Figure 1 is based on an alternative formulation of sample covariance ( Hayes , 2011 ) : Cov ( c , y ) = 2 n ( n − 1 ) n − 1 ∑︁ i = 1 n ∑︁ j > i 1 2 ( c i − c j ) ( y i − y j ) . ( 16 ) This formulation of the sample covariance has the interpretation of being an average of the signed area of triangles associated to pairs of points . Figure 1 illustrates these signed triangles using a randomly selected Figure 1 : Geometric interpretation of intrinsic and extrinsic noise . The intrinsic noise , or the within - cell variability , is the variance of the points projected to the line y = − c , which is perpendicular to y = c . In other words , it is the average of the squared lengths 12 ( y i − c i ) 2 . The red point is the projection of point ( c i , y i ) onto the line y = c . The green point is the centroid ( ¯ c , ¯ y ) ( or ( ( ¯ c + ¯ y ) / √ 2 , 0 ) after projection ) under the assumption that the two means are equal . See the main text for detail . The extrinsic noise , or the between - cell variability , is the sample covariance between c i and y i . The colored triangles around the blue point ( a randomly selected data point ) illustrate the geometric interpretation of the sample covariance : it is the average ( signed ) area of triangles formed by pairs of data points : green triangles in Q1 and Q3 ( some not shown ) represent a positive contribution to the covariance , whereas the magenta triangles in Q2 and Q4 a negative contribution . Since most data points lie in the 1st ( Q1 ) and 3rd ( Q3 ) quadrants relative to the blue point , most of the contribution involving the blue point is positive . Similarly , since most pairs of data points can be connected by a positively signed line , their positive contribution will result in a positive covariance . In Elowitz et al . ( 2002 ) the direction along the line y = c is labeled extrinsic , which makes sense in terms of the intuition for positive sample covariance . However we have placed that label “extrinsic” in quotes because the extrinsic noise estimator corresponding directly to the sample variance for points projected onto the line y = c ( in analogy with intrinsic noise ) is heavily biased and not usable in practice . A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 453 point ( the blue point ) . This formulation is very different from what might be considered at first glance an appropriate analogy to intrinsic noise , namely the sample variance along the line y = c . An alternative estimate for the extrinsic noise based on the sample variance of the projected points along the line y = c ( using the projected centroid as the mean , which is shown as the green point in Figure 1 ) turns out to be biased by an amount equal to the total noise . This sample variance averages the squared distances of the data points from the centroid ( green point ) after projection onto the line y = c ; see the distance between the red and green points in Figure 1 . Since ˜ S * ext = 1 n − 1 n ∑︁ i = 1 (︂ 1 √ 2 ( Y i − ¯ Y + C i − ¯ C ) )︂ 2 = 1 2 ( n − 1 ) n ∑︁ i = 1 (︁ ( C i + Y i ) 2 − ( ¯ C + ¯ Y ) 2 )︁ the bias is E [ ˜ S * ext ] − σ 2 µ = 1 2 Var [ C i + Y i ] − σ 2 µ = 1 2 (︀ Var [ C i ] + Var [ Y i ] + 2 Cov [ C i , Y i ] )︀ − σ 2 µ = 1 2 (︁ 2 ( σ 2 + σ 2 µ ) + 2 σ 2 µ )︁ − σ 2 µ = σ 2 + σ 2 µ which is the true total noise . The above calculation also shows that if the intrinsic and extrinsic noise are both estimated as variances along the projections to the lines y = − c and y = c respectively , then the total noise will be overestimated by a factor of two . In summary , the caption to Figure 3A in Elowitz et al . ( 2002 ) is completely accurate in stating that “Spread of points perpendicular to the diagonal line on which CFP and YFP intensities are equal corresponds to intrinsic noise , whereas spread parallel to this line is increased by extrinsic noise . ” However the geometric interpretation of covariance makes it precise how an increase in extrinsic noise relates to the spread of points in the direction of the line y = c . 6 Practical considerations 6 . 1 Optimal estimators for intrinsic and extrinsic noise We have derived the estimators that are optimal for minimizing bias or the MSE ( summarized in Table 1 ) . The ELSS estimator in ( 1 ) is in fact a special case of the general estimator under the assumption that ¯ C = ¯ Y , and is appropriate for data that are normalized to have the same sample mean ( i . e . ¯ c = ¯ y ) . In Elowitz et al . ( 2002 ) , the intensities of the two reporters were normalized to have mean 1 . In the case where the assumption of equal reporter means does not hold , the general estimator is more suitable . Similar to the estimators for the intrinsic noise , we derived two estimators for extrinsic noise , optimized for bias and for MSE respectively ( Table 1 ) . Thesamplesize n istheleadingterminthedenominatorofalltheoptimal ( ineitherthebiasorMSEsense ) intrinsic and extrinsic noise estimators . As a result , the unbiased estimator has the same form as the min - MSE estimator for large n ( Table 1 ) . For extrinsic noise , the general estimators converge to the ELSS estimate ( Table 1 ) . The mean and variance of the estimators are summarized in Table 6 in Appendix E . For intrinsic noise , assuming ¯ c = ¯ y , the ELSS estimator is optimal for bias and MSE at large n and optimal for bias at small n . Indeed , in Elowitz et al . ( 2002 ) , typical values for n are greater than 100 , making the ELSS formulas suitable for the analyses performed ( with the assumption of equal mean satisfied ) . However , our derivations indicate that the two types of noise can be estimated using fewer cells . As a general rule we recommend computing the inverse squared correlation between the c i and y i values and applying the min - MSE estimators when the sample size is small ( e . g . much less than 50 ) . 454 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Table 1 : Estimators for intrinsic and extrinsic noise . ρ is the correlation between the two reporters , and can be estimated by the sample correlation . Exact estimator for small n Large n Minimizing bias Minimizing MSE ( Unbiased ) Intrinsic noise General 1 2 ( n − 1 ) [︂∑︀ n 1 ( C i − Y i ) 2 − n ( ¯ C − ¯ Y ) 2 ]︂ / ( ¯ C ¯ Y ) 12 a [︂∑︀ n 1 ( C i − Y i ) 2 − n ( ¯ C − ¯ Y ) 2 ]︂ / ( ¯ C ¯ Y ) , where a = 2 n 3 − 7 n + 6 2 ( n 2 − n ) + 2 − n n 2 − n ρ 1 − ρ + 1 2 ( n 2 − n ) (︂ ρ 1 − ρ )︂ 2 12 n [︂∑︀ n 1 ( C i − Y i ) 2 − n ( ¯ C − ¯ Y ) 2 ]︂ / ( ¯ C ¯ Y ) Assuming ¯ C = ¯ Y 12 n ∑︀ ni = 1 ( C i − Y i ) 2 / ( ¯ C ¯ Y ) 1 2 ( n + 2 ) ∑︀ ni = 1 ( C i − Y i ) 2 / ( ¯ C ¯ Y ) 12 n ∑︀ ni = 1 ( C i − Y i ) 2 / ( ¯ C ¯ Y ) ( ELSS estimator ) ( ELSS estimator ) Extrinsic noise General 1 n − 1 ( ∑︀ ni = 1 C i Y i − n ¯ C ¯ Y ) / ( ¯ C ¯ Y ) 1 a (︀∑︀ ni = 1 C i Y i − n ¯ C ¯ Y )︀ / ( ¯ C ¯ Y ) , 1 n ( ∑︀ ni = 1 C i Y i − n ¯ C ¯ Y ) / ( ¯ C ¯ Y ) where a = 1 / ρ 2 + ( n − 1 ) ( 1 + 1 / n ) ( ELSS estimator ) It is worth pointing out that the correction factor 1 / a in the min - MSE estimators tends to be smaller than that in the unbiased estimators ( 1 / ( n − 1 ) ) and the asymptotic estimators ( 1 / n ; Table 1 ) . This smaller correction 1 / a makes the min - MSE estimators “shrinkage” estimators , such that they achieve better MSE despitebeingbiased , justliketheJame - Steinestimator ( JamesandStein , 1961 ) . Oursimulationresultsconfirm this point ( Table 2 ) . However , using the sample correlation , instead of the true one , in our min - MSE estimators leads to increased MSE , although the estimates with the sample correlation do not differ much on average from that with the true correlation . 6 . 2 Data normalization Our hierarchical model , as well as the ANOVA interpretation , is consistent with the model in Elowitz et al . ( 2002 ) ; both models assume that within each cell there are two distributions for the expression of the two reporter genes and that they have the same true mean and true variance . With the normality assumption , this means that the two reporters have identical distributions . Elowitz et al . measured the single - color distributions of strains that contained lac - repressible promoter pairs , which verified that this was a reasonable assumption in the case of cyan fluorescent protein ( CFP ) and yellow fluorescent protein ( YFP ) in their experiment . We also performed simulations under the hierarchical model , with and without identical distribution for the two reporters , and summarized the results in Table 3 . Estimates of intrinsic and extrinsic noise are the same as the truth when the identical distribution assumption applies . When this assumption is not satisfied , the theory breaks down and it is unclear what the estimates mean . Other studies have adapted this system and used other reporter combinations that may have markedly different distributions . For example , Yang et al . ( 2014 ) used CFP and mCherry with vastly different ranges of intensity values : whereas CFP varied from 0 to 6000 ( arbitrary units ; i . e . a . u . ) , mCherry could vary from 0 to 9000 ( a . u . ) ; see Figure 3A from their paper . In contrast , Schmiedel et al . ( 2015 ) normalized the two reporters used in their experiment ( ZsGreen and mCherry ) to have the same mean . However , the variances , or more generally , the two distributions , also need to be the same . Since the decomposition of the total noise depends ontheassumptionthatbothreportersinthesamecellularenvironmenthavesimilarvariance ( seeequations4 and 5 ) , we recommend that in general a quantile normalization which normalizes the reporter measurements to identical distributions be performed before the calculations of noise components . Such a normalization procedure is standard in many settings requiring similar assumptions . A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 455 Table 2 : Estimates of extrinsic noise in simulated data . Data were simulated under the hierarchical model , where the conditional distributions of the two reporters are identical . Two min - MSE estimators are applied , one using the true correlation , and the other the sample correlation . Mean estimates ( standard deviation in parentheses ) of intrinsic and extrinsic noise are summarized . Note that in order to compare the estimates with the true parameters , the estimates are unscaled ( i . e . not divided by ¯ c ¯ y ) . Simulation parameters Sample size ( n ) 50 Intrinsic noise ( σ 2 ) 0 . 7 Extrinsic noise ( σ 2 µ ) 0 . 8 Distribution of means ( G ) N ( 1 , 0 . 8 ) Distribution of vars ( H ) Constant : Σ 2 i = 0 . 7 Distribution of C i | Z i N ( M i , 0 . 7 ) Distribution of Y i | Z i N ( M i , 0 . 7 ) No . of data sets 500 Extrinsic noise estimate Unbiased 0 . 80 ( 0 . 25 ; 0 . 0604 ) minMSE ( true corr ) 0 . 73 ( 0 . 23 ; 0 . 0552 ) minMSE ( sample corr ) 0 . 73 ( 0 . 24 ; 0 . 0634 ) Asymptotic / ELSS 0 . 78 ( 0 . 06 ; 0 . 0582 ) Table 3 : Estimates of intrinsic and extrinsic noise in simulated data . Data were simulated under two schemes . The first scheme is consistent with the hierarchical model , where the conditional distributions of the two reporters are identical . Under the second scheme , the conditional distributions are different . Intrinsic and extrinsic noise are in fact not defined under the second scheme . Mean estimates ( standard deviation in parentheses ) of intrinsic and extrinsic noise are summarized . Note that in order to compare the estimates with the true parameters , the estimates are unscaled ( i . e . not divided by ¯ c ¯ y ) . Identical distribution Different distributions Simulation parameters Sample size ( n ) 1000 1000 Intrinsic noise ( σ 2 ) 0 . 7 0 . 7 Extrinsic noise ( σ 2 µ ) 0 . 8 0 . 8 Distribution of means ( G ) N ( 1 , 0 . 8 ) N ( 1 , 0 . 8 ) Distribution of vars ( H ) Constant : Σ 2 i = 0 . 7 Constant : Σ 2 i = 0 . 7 Distribution of C i | Z i N ( M i , 0 . 7 ) N ( M i , 0 . 7 ) Distribution of Y i | Z i N ( M i , 0 . 7 ) N ( 2 M i , 1 . 5 × 0 . 7 ) No . of data sets 500 500 Sample correlation 0 . 53 ( 0 . 02 ) 0 . 60 ( 0 . 02 ) Intrinsic noise ( ^ σ 2 ) General Unbiased 0 . 70 ( 0 . 03 ) 1 . 54 ( 0 . 07 ) minMSE 0 . 70 ( 0 . 03 ) 1 . 54 ( 0 . 07 ) Asymptotic 0 . 70 ( 0 . 03 ) 1 . 54 ( 0 . 07 ) Equal mean Unbiased / ELSS 0 . 70 ( 0 . 03 ) 2 . 04 ( 0 . 08 ) minMSE 0 . 70 ( 0 . 03 ) 2 . 04 ( 0 . 08 ) Asymptotic / ELSS 0 . 70 ( 0 . 03 ) 2 . 04 ( 0 . 08 ) Extrinsic noise ( ^ σ 2 µ ) Unbiased 0 . 80 ( 0 . 06 ) 1 . 60 ( 0 . 10 ) minMSE 0 . 80 ( 0 . 06 ) 1 . 59 ( 0 . 10 ) Asymptotic / ELSS 0 . 80 ( 0 . 06 ) 1 . 60 ( 0 . 10 ) ^ σ 2 µ / ( ^ σ 2 µ + ^ σ 2 ) General 0 . 53 0 . 51 Equal mean 0 . 53 0 . 44 456 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Table 4 : Re - analysis of published two - reporter experiment data . Summary statistics and estimates ( × 10 − 2 ) of intrinsic and extrinsic noise are listed , using the estimators from Table 1 . Elowitz et al . data Yang et al . data D22 M22 Figure 3A Normalized on log 2 Sample means CFP : 1 CFP : 1 CFP : 2660 CFP : 11 YFP : 1 YFP : 1 mCherry : 3986 mCherry : 11 Sample correlation 0 . 50 0 . 49 0 . 86 0 . 86 Intrinsic noise General Unbiased 0 . 79 0 . 36 5 . 44 0 . 11 minMSE 0 . 78 0 . 35 5 . 44 0 . 11 Asymptotic 0 . 78 0 . 35 5 . 44 0 . 11 Equal mean Unbiased / ELSS 0 . 78 0 . 35 13 . 72 0 . 11 minMSE 0 . 78 0 . 35 13 . 72 0 . 11 Asymptotic / ELSS 0 . 78 0 . 35 13 . 72 0 . 11 Extrinsic noise Unbiased 0 . 78 0 . 34 30 . 29 0 . 68 minMSE 0 . 76 0 . 33 30 . 29 0 . 68 Asymptotic / ELSS 0 . 77 0 . 34 30 . 29 0 . 68 ^ σ 2 µ / ( ^ σ 2 µ + ^ σ 2 ) General 0 . 50 0 . 49 0 . 85 0 . 86 Equal mean 0 . 50 0 . 49 0 . 69 0 . 86 6 . 3 Assessing the ratio of extrinsic to intrinsic noise from sample correlation We have seen from ( 13 ) that the proportion of the between - cell variability to total variability is the correlation ρ ( C , Y ) . This leads to a simple approach for estimating the relative magnitude of the two types of noise : one can compute the sample correlation of the expression of the two reporters , ρ ( c , y ) , and the ratio of extrinsic to intrinsic noise is then estimated by ρ ( c , y ) / [ 1 − ρ ( c , y ) ] . 7 Re - analysis of published two - reporter experiment data Michael Elowitz and Peter Swain have kindly shared with us their data published in Elowitz et al . ( 2002 ) . Here we focus on the data in Figure 3A of their paper , which contain the unnormalized fluorescence intensities of CFP and YFP in the E . coli . strain D22 and in strain M22 . We normalized the data as follows such that the resulting scatterplots are close to Figure 3A : D22 : c i = ( c * i − c * ) / ( 8 s * c ) + 1 ; y i = ( y * i − y * ) / ( 8 s * y ) + 1 ; M22 : c i = ( c * i − c * ) / ( 12 s * c ) + 1 ; y i = ( y * i − y * ) / ( 12 s * y ) + 1 , where c * i and y * i are the unnormalized intensity of the CFP and YFP , respectively , in the i th cell , c * the sample mean , and s * y the sample standard deviation . The normalized intensities are close to normal distributions , and all four distributions have mean 1 . At a sample size of over 200 , the different estimators in Table 4 give essentially the same result . Additionally , the ratio of the estimated extrinsic and total noise is close to the sample correlation , verifying our theoretical result . Nam Ki Lee and Sora Yang have also kindly shared with us their data published in Yang et al . ( 2014 ) . Here we analyze the data in Figure 3A of their paper , which are the expression levels ( intensities ) of two reporters , CFP and mCherry ( also see Sec . 6 . 2 ) . The shared , unnormalized intensities have very different sample means ( Table 4 ) . Application of the estimators in Table 1 to these data gives two different estimates of the intrinsic A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 457 noise , with the ELSS estimate being nearly three times the estimates under the equal mean assumption . To normalize the data , we removed the few negative values , log 2 transformed the data , and quantile normalized between the two reporters ( see summary statistics in Table 4 ) . Applying our estimators to the normalized data , all estimates are consistent with one another . This analysis illustrates the importance of the equal mean assumption : when this assumption is not satisfied , the ELSS estimator leads to overestimation of the intrinsic noise . Additionally , we subsampled from these data sets and assessed the performance of the estimators as the sample size decreased . At each sample size , we repeated the subsampling 1000 times and computed the meanandstandarddeviationofthenoiseestimates ( Table5 ) . Whereasthemeansoftheestimatesdonotdiffer from those obtained using the entire data sets , the variation ( measured by the standard deviation ) increases quickly with decreasing sample sizes . For the Elowitz et al . data , the standard deviation in the estimates roughly doubles for both types of noise as the sample size halves . Comparing the standard deviation to the mean suggests that 200 is indeed a reasonable sample size for estimates with small variation ( compare with their actual sample sizes of 284 and 250 for the two strains ) . For the Yang et al . data , the increase in the standard deviation is much less drastic , and 200 also appears a decent sample size for reasonably small variation in the estimates . 8 Conclusions and discussion Our hierarchical model for Elowitz et al . ( 2002 ) provides statistically interpretable parameters representing intrinsic and extrinsic noise , and allows for the derivation of estimators with optimality guarantees . Further - more , the model highlights experimental assumptions that need to be satisfied for the estimators to be valid , specifically that the two reporters need to have the same distribution ( within a cell ) and hence normalization may be necessary . Whereas similar hierarchical models have been proposed before to study heterogeneity among single cells ( see , e . g . Finkenstädt et al . , 2013 , and Koeppl et al . , 2012 ) , our hierarchical model explicitly parameterize the two types of noise , and reveals their equivalence to other quantities , as indicated by ( 11 ) and ( 14 ) , which enable derivation of closed - form estimators of these parameters ( summarized in Table 1 ) . We use bias and MSE to explicitly evaluate the performance of different estimators , and recognize the asymptotic equivalence of multiple estimators . Other experiments have been set up to explore and assess intrinsic and extrinsic noise , and some of our results may be useful in those settings . For example , Volfson et al . ( 2006 ) used a single reporter but two Saccharomyces cerevisiae strains , with one strain containing only one copy of the reporter , and the other strain two copies . Assuming no strain effect , which may be thought of as batch effect , the authors applied the following estimators for ( unscaled ) intrinsic and extrinsic noise ( consistent with their notation , and without the denominator of ¯ C ¯ Y as used in the ELSS estimators in Table 1 ) : V i = 2 V 1 − V 2 / 2 ; ( 17 ) V e = V 2 / 2 − V 1 , ( 18 ) where V 1 and V 2 are the variance in the 1 - copy and 2 - copy strains , respectively , and V i and V e are intrinsic and extrinsic noise , respectively . These estimators are in fact consistent with ( 11 ) and ( 14 ) under our hierarchical model : V 1 = Var [ C 1 ] = V i + V e = Var [ C 2 ] ; ( 19 ) V 2 = Var [ C 1 + C 2 ] = Var [ C 1 ] + Var [ C 2 ] + 2 Cov [ C 1 , C 2 ] = 2 ( V i + V e ) + 2 V e . ( 20 ) Together , ( 19 ) and ( 20 ) give rise to ( 17 ) and ( 18 ) . Note that ( 19 ) and ( 20 ) imply that the extrinsic noise is also the covariance here , except that the covariance is between the 1 - copy and 2 - copy strains with the same reporter ; this is also pointed out by Sherman et al . ( 2015 ) . Additionally , the total ( marginal ) noise of the reporter is the sum of intrinsic and extrinsic noise ( 19 ) . However , consistent with our analysis of the assumptions of the 458 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Table 5 : Noise estimates ( × 10 − 2 ) based on subsets of published data . Similar to Table 4 , we used the estimators from Table 1 . Elowitz et al . data Yang et al . data D22 M22 Normalized on log 2 Original sample size 284 250 40658 n = 200 Intrinsic noise General Unbiased 0 . 79 ( 0 . 06 ) 0 . 36 ( 0 . 02 ) 0 . 11 ( 0 . 02 ) minMSE 0 . 78 ( 0 . 06 ) 0 . 35 ( 0 . 02 ) 0 . 11 ( 0 . 02 ) Asymptotic 0 . 78 ( 0 . 06 ) 0 . 35 ( 0 . 02 ) 0 . 11 ( 0 . 02 ) Equal mean Unbiased / ELSS 0 . 78 ( 0 . 06 ) 0 . 35 ( 0 . 02 ) 0 . 11 ( 0 . 02 ) minMSE 0 . 78 ( 0 . 06 ) 0 . 35 ( 0 . 02 ) 0 . 11 ( 0 . 02 ) Asymptotic / ELSS 0 . 78 ( 0 . 06 ) 0 . 35 ( 0 . 02 ) 0 . 11 ( 0 . 02 ) Extrinsic noise Unbiased 0 . 78 ( 0 . 07 ) 0 . 34 ( 0 . 02 ) 0 . 68 ( 0 . 09 ) minMSE 0 . 76 ( 0 . 07 ) 0 . 33 ( 0 . 02 ) 0 . 67 ( 0 . 08 ) Asymptotic / ELSS 0 . 78 ( 0 . 07 ) 0 . 34 ( 0 . 02 ) 0 . 68 ( 0 . 08 ) n = 100 Intrinsic noise General Unbiased 0 . 79 ( 0 . 13 ) 0 . 36 ( 0 . 04 ) 0 . 11 ( 0 . 03 ) minMSE 0 . 77 ( 0 . 12 ) 0 . 35 ( 0 . 04 ) 0 . 11 ( 0 . 03 ) Asymptotic 0 . 78 ( 0 . 12 ) 0 . 35 ( 0 . 04 ) 0 . 11 ( 0 . 03 ) Equal mean Unbiased / ELSS 0 . 78 ( 0 . 12 ) 0 . 35 ( 0 . 04 ) 0 . 11 ( 0 . 03 ) minMSE 0 . 77 ( 0 . 12 ) 0 . 35 ( 0 . 04 ) 0 . 11 ( 0 . 03 ) Asymptotic / ELSS 0 . 78 ( 0 . 12 ) 0 . 35 ( 0 . 04 ) 0 . 11 ( 0 . 03 ) Extrinsic noise Unbiased 0 . 77 ( 0 . 14 ) 0 . 34 ( 0 . 05 ) 0 . 69 ( 0 . 12 ) minMSE 0 . 73 ( 0 . 14 ) 0 . 32 ( 0 . 05 ) 0 . 67 ( 0 . 12 ) Asymptotic / ELSS 0 . 76 ( 0 . 14 ) 0 . 34 ( 0 . 05 ) 0 . 68 ( 0 . 12 ) n = 50 Intrinsic noise General Unbiased 0 . 78 ( 0 . 21 ) 0 . 36 ( 0 . 07 ) 0 . 11 ( 0 . 04 ) minMSE 0 . 75 ( 0 . 20 ) 0 . 35 ( 0 . 07 ) 0 . 11 ( 0 . 04 ) Asymptotic 0 . 77 ( 0 . 20 ) 0 . 35 ( 0 . 07 ) 0 . 11 ( 0 . 04 ) Equal mean Unbiased / ELSS 0 . 78 ( 0 . 21 ) 0 . 36 ( 0 . 07 ) 0 . 11 ( 0 . 04 ) minMSE 0 . 75 ( 0 . 20 ) 0 . 34 ( 0 . 07 ) 0 . 11 ( 0 . 04 ) Asymptotic / ELSS 0 . 78 ( 0 . 21 ) 0 . 36 ( 0 . 07 ) 0 . 11 ( 0 . 04 ) Extrinsic noise Unbiased 0 . 78 ( 0 . 24 ) 0 . 34 ( 0 . 09 ) 0 . 68 ( 0 . 16 ) minMSE 0 . 70 ( 0 . 24 ) 0 . 30 ( 0 . 09 ) 0 . 65 ( 0 . 15 ) Asymptotic / ELSS 0 . 76 ( 0 . 23 ) 0 . 33 ( 0 . 09 ) 0 . 66 ( 0 . 16 ) hierarchical model , these estimators hold only when the variance for each single copy in the 2 - copy strain is identical to that in the 1 - copy strain . This is equivalent to assuming no strain ( batch ) effect , which can be a rather strong assumption . We note that during the preparation of this manuscript , Erik van Nimwegen independently examined the Elowitz et al . ( 2002 ) paper form a Bayesian point of view ( van Nimwegen , 2016 ) . Acknowledgment : ThisprojectbeganasaresultofdiscussionduringajournalclubmeetingofProf . Jonathan Pritchard’s group that A . F . was attending . We thank Michael Elowitz , Peter Swain , Nam Ki Lee and Sora Yang for sharing their data from Elowitz et al . ( 2002 ) and from Yang et al . ( 2014 ) , respectively . We also thank helpful comments we have received since posting the manuscript online . In particular , we thank Arjun Raj for bringing up the 1 - vs 2 - copy experiment , and Erik van Nimwegen for helpful discussions . We also thank Editor inChiefProf . MichaelStumpfandtwoanonymousreviewersforinsightfulcommentsthatledtoasignificantly A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 459 enriched version . A . F . was partially supported by K99 HG007368 and R00 HG007368 ( NIH / NHGRI ) . L . P . was partially supported by NIH grants R01 HG006129 and R01 DK094699 . A Moments of M i and C i under normality Assuming that M i ∼ N ( µ , σ 2 µ ) , we have E [ M i − µ ] 3 = 0 ; E [ M i − µ ] 4 = 3 σ 4 µ . We can compute the third and fourth moments of M i as follows : E [ M i − µ ] 3 = E [ M 2 i + µ 2 − 2 M i µ ) ( M i − µ ] = E [ M 3 i − 2 M 2 i µ + M i µ 2 − M 2 i µ − µ 3 + 2 M i µ 2 ] = E [ M 3 i − 3 M 2 i µ + 3 M i µ 2 − µ 3 ] = E [ M 3 i ] − 3 µ ( σ 2 µ + µ 2 ) + 3 µ 3 − µ 3 = E [ M 3 i ] − 3 µσ 2 µ − µ 3 , which gives E [ M 3 i ] = 3 µσ 2 µ + µ 3 . E [ M i − µ ] 4 = E [ M 2 i − 2 M i µ + µ 2 ] 2 = E [ M 4 i + µ 4 + 4 M 2 i µ 2 + 2 M 2 i µ 2 − 4 M 3 i µ − 4 M i µ 3 ] = E [ M 4 i + µ 4 + 6 M 2 i µ 2 − 4 M 3 i µ − 4 M i µ 3 ] = E [ M 4 i ] + µ 4 + 6 µ 2 ( σ 2 µ + µ 2 ) − 4 µ ( 3 µσ 2 µ + µ 3 ) − 4 µ 4 = E [ M 4 i ] + µ 4 + 6 µ 2 σ 2 µ + 6 µ 4 − 12 µ 2 σ 2 µ − 4 µ 4 − 4 µ 4 = E [ M 4 i ] − 6 µ 2 σ 2 µ − µ 4 , which gives E [ M 4 i ] = 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 . For the random variable C i , since Σ 2 i ∼ H ( σ 2 , ϵ ) , such that E [ Σ 2 i ] = σ 2 ; Var [ Σ 2 i ] = ϵ , we have E [ C 4 i ] = E [ E [ C 4 i | Z i ] ] = E [ 3 Σ 4 i + 6 M 2 i Σ 2 i + M 4 i ] = 3 ( ϵ + σ 4 ) + 6 ( σ 2 µ + µ 2 ) σ 2 + 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 = 3 ϵ + 3 σ 4 + 6 σ 2 µ σ 2 + 6 µ 2 σ 2 + 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 . Further assuming that µ = 0 , i . e . the means are all 0 , and that ϵ = 0 , which means that the variability is the same across cells , we have E [ M 3 i ] = 0 E [ M 4 i ] = 3 σ 4 µ ; and E [ C 3 i ] = 0 E [ C 4 i ] = 3 ( σ 2 + σ 2 µ ) 2 . 460 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise B Calculating Var [ S ext ] Var [ S ext ] = Var [︂ 1 a ( n ∑︁ i = 1 C i Y i − n ¯ C ¯ Y ) ]︂ = 1 a 2 Var [︂ n ∑︁ i = 1 C i Y i − n ¯ C ¯ Y ]︂ = 1 a 2 (︂ Var [︃ n ∑︁ i = 1 C i Y i ]︃ + Var [ n ¯ C ¯ Y ] − 2 Cov [︂ n ∑︁ i = 1 C i Y i , n ¯ C ¯ Y ]︂)︂ . B . 1 Calculating Var (cid:2)(cid:80) ni = 1 C i Y i (cid:3) Var [︃ n ∑︁ i = 1 C i Y i ]︃ = n ∑︁ i = 1 Var [ C i Y i ] = n ∑︁ i = 1 (︂ E [ C 2 i Y 2 i ] − ( E [ C i Y i ] ) 2 )︂ where E [ C i Y i ] 2 = E [︂ E [ C 2 i Y 2 i | Z i ] ]︂ = E [︂ E [ C 2 i | Z i ) E ( Y 2 i | Z i ] ]︂ = E [ Σ 2 i + M 2 i ] 2 = E [ Σ 4 i + M 4 i + 2 Σ 2 i M 2 i ] = Var [ Σ 2 i ] + ( E [ Σ 2 i ] ) 2 + E [ M 4 i ] + 2 E [ Σ 2 i ] E [ M 2 i ] = ϵ + σ 4 + E [ M 4 i ] + 2 σ 2 ( σ 2 µ + µ 2 ) ; and E [ C i Y i ] = Cov [ C i , Y i ] + E [ C i ] E [ Y i ] = σ 2 µ + µ 2 . Therefore , Var [︃ n ∑︁ i = 1 C i Y i ]︃ = n ∑︁ i = 1 (︂ ϵ + σ 4 + EM 4 i + 2 σ 2 ( σ 2 µ + µ 2 ) − ( σ 2 µ + µ 2 ) 2 )︂ . B . 2 Calculating Var [ n ¯ C ¯ Y ] Var [ n ¯ C ¯ Y ] = n 2 Var [︂ C 1 + · · · + C n n · Y 1 + · · · + Y n n ]︂ = n 2 n 4 Var [︂ ∑︁ k C k Y k + ∑︁ i / = j C i Y j ]︂ = 1 n 2 (︂ Var [︃∑︁ k C k Y k ]︃ + Var ⎡ ⎣∑︁ i / = j C i Y j ⎤ ⎦ + 2 Cov [︂ ∑︁ k C k Y k , ∑︁ i / = j C i Y j ]︂)︂ . Assuming normality on M i and assuming that µ = 0 and ϵ = 0 ( constant variance across cells ) , we have Var [︃∑︁ k C k Y k ]︃ = n ( σ 4 + 3 σ 4 µ + 2 σ 2 σ 2 µ − σ 4 µ ) = n ( σ 2 + σ 2 µ ) 2 + nσ 4 µ . A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 461 Also , Var ⎡ ⎣∑︁ i / = j C i Y j ⎤ ⎦ = ∑︁ i / = j Var [ C i Y j ] + 2 ∑︁ i = k or j = l Cov [ C i Y j , C k Y l ] + 2 ∑︁ i / = k and j / = l Cov [ C i Y j , C k Y l ] . Under the assumptions made above , we have Var [ C i Y j ] = E [ C 2 i Y 2 j ] − ( E [ C i Y j ] ) 2 = E [ C 2 i ] E [ Y 2 j ] − ( E [ C i ] E [ Y j ] ) 2 = ( σ 2 + σ 2 µ ) 2 . If i = k , Cov [ C i Y j , C k Y l ] = E [ C i Y j C k Y l ] − E [ C i Y j ] E [ C k Y l ] = E [ C 2 i ] E [ Y j ] E [ Y l ] − ( E [ C i ] ) 2 E [ Y j ] E [ Y l ] = 0 . Similarly , we can derive that the covariance is 0 for other cases where j = l or where i / = k and j / = l . Hence , Var ⎡ ⎣∑︁ i / = j C i Y j ⎤ ⎦ = n ( n − 1 ) ( σ 2 + σ 2 µ ) 2 . Additionally , under the normality assumption and with µ = 0 and ϵ = 0 , Cov [︂ ∑︁ k C k Y k , ∑︁ i / = j C i Y j ]︂ = 0 . Therefore , Var [ n ¯ C ¯ Y ] = 1 n 2 (︂ n ( σ 2 + σ 2 µ ) 2 + nσ 4 µ + n ( n − 1 ) ( σ 2 + σ 2 µ ) 2 )︂ = 1 n 2 (︂ n 2 ( σ 2 + σ 2 µ ) 2 + nσ 4 µ )︂ = ( σ 2 + σ 2 µ ) 2 + σ 4 µ n . B . 3 Calculating Cov (cid:2)(cid:80) ni = 1 C i Y i , n ¯ C ¯ Y (cid:3) Cov [︂ n ∑︁ i = 1 C i Y i , n ¯ C ¯ Y ]︂ = 1 n Cov ⎡ ⎣ n ∑︁ i = 1 C i Y i , ∑︁ k C k Y k + ∑︁ i / = j C i Y j ⎤ ⎦ = 1 n (︂ Cov [︂ n ∑︁ i = 1 C i Y i , ∑︁ k C k Y k ]︂ + Cov [︂ n ∑︁ i = 1 C i Y i , ∑︁ i / = j C i Y j ]︂)︂ = 1 n (︂ Var [︃ n ∑︁ i = 1 C i Y i ]︃ )︂ = ( σ 2 + σ 2 µ ) 2 + σ 4 µ . Putting the terms above together , we have Var [ S ext ] = 1 a 2 (︂ n ( σ 2 + σ 2 µ ) 2 + nσ 4 µ + ( σ 2 + σ 2 µ ) 2 + σ 4 µ n − 2 ( σ 2 + σ 2 µ ) 2 − 2 σ 4 µ )︂ = n − 1 a 2 ( σ 2 + σ 2 µ ) 2 + ( n − 1 ) 2 na 2 σ 4 µ . 462 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise C MSE of the general intrinsic noise estimator The general form of the estimator for intrinsic noise is S = 1 2 a (︃ n ∑︁ 1 ( C i − Y i ) 2 − n ( ¯ C − ¯ Y ) 2 )︃ . C . 1 Calculating Var [ S ] Thus Var [ S ] = 1 4 a 2 (︂ Var [︁∑︁ ( C i − Y i ) 2 ]︁ + n 2 Var [︁ ( ¯ C − ¯ Y ) 2 ]︁ − 2 nCov [︂ ∑︁ ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 ]︂)︂ . Below we will assume normality , as well as µ = 0 and ϵ = 0 , to facilitate the derivation . Note that Var [︀∑︀ ( C i − Y i ) 2 ]︀ is derived in Appendix D . C . 1 . 1 Calculating Var [ ( ¯ C − ¯ Y ) 2 ] First , we note that Var [ ( ¯ C − ¯ Y ) 2 ] = Var [ ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ] = Var [ ¯ C 2 ] + 4 Var [ ¯ C ¯ Y ] + Var [ ¯ Y 2 ] − 4 Cov [ ¯ C 2 , ¯ C ¯ Y ] − 4 Cov [ ¯ Y 2 , ¯ C ¯ Y ] + 2 Cov [ ¯ C 2 , ¯ Y 2 ] . Var [ ¯ C 2 ] = Var [︂ C 1 + · · · + C n n · C 1 + · · · + C n n ]︂ = 1 n 4 Var ⎡ ⎣∑︁ C 2 k + ∑︁ i / = j C i C j ⎤ ⎦ = 1 n 4 ⎛ ⎝ Var ∑︁ C 2 k + Var ⎡ ⎣∑︁ i / = j C i C j ⎤ ⎦ + 2 Cov ⎡ ⎣∑︁ C 2 k , ∑︁ i / = j C i C j ⎤ ⎦ ⎞ ⎠ = 1 n 4 (︁ 2 n ( σ 2 + σ 2 µ ) 2 + n ( n − 1 ) ( σ 2 + σ 2 µ ) 2 + 0 )︁ = n + 1 n 3 ( σ 2 + σ 2 µ ) 2 . This is because Var ⎡ ⎣ ∑︁ i / = j C i C j ⎤ ⎦ = ∑︁ i / = j Var [ C i C j ] = ∑︁ i / = j (︁ EC 2 i C 2 j − ( EC i C j ) 2 )︁ = ∑︁ i / = j (︁ ( σ 2 + σ 2 µ ) 2 − 0 )︁ = n ( n − 1 ) ( σ 2 + σ 2 µ ) 2 . Additionally , from Appendix B , we have Var [ ¯ C ¯ Y ] = 1 n 2 Var [ n ¯ C ¯ Y ] = 1 n 2 (︃ ( σ 2 + σ 2 µ ) 2 + σ 4 µ n )︃ = 1 n 2 ( σ 2 + σ 2 µ ) 2 + σ 4 µ n 3 . A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 463 Cov [ ¯ C 2 , ¯ C ¯ Y ] = 1 n 4 Cov ⎡ ⎣∑︁ C 2 k + ∑︁ i / = j C i C j , ∑︁ C l Y l + ∑︁ m / = r C m C r ⎤ ⎦ = 1 n 4 (︂ Cov [︁∑︁ C 2 k , ∑︁ C l Y l ]︁ + Cov ⎡ ⎣∑︁ C 2 k , ∑︁ m / = r C m C r ⎤ ⎦ + Cov ⎡ ⎣∑︁ i / = j C i C j , ∑︁ C l Y l ⎤ ⎦ + Cov ⎡ ⎣∑︁ i / = j C i C j , ∑︁ m / = r C m C r ⎤ ⎦ )︂ . Cov [︁∑︁ C 2 k , ∑︁ C l Y l ]︁ = Cov [︁∑︁ C 2 k , ∑︁ C k Y k ]︁ = ∑︁ ( E [ C 3 k Y k ] − E [ C 2 k ] E [ C k Y k ] ) = ∑︁ [︂ 3 σ 2 σ 2 µ + 3 σ 4 µ − ( σ 2 + σ 2 µ ) σ 2 µ ]︂ = 2 nσ 2 µ ( σ 2 + σ 2 µ ) . For Cov [︀∑︀ C 2 k , ∑︀ m / = r C m C r ]︀ , since Cov [ C 2 i , C i Y j ] = E [ C 3 i Y j ] − E [ C 2 i ] E [ C i Y j ] = 0 and Cov [ C 2 i , C j Y k ] = E [ C 2 i C j Y k ] − E [ C 2 i ] E [ C j Y k ] = 0 , we have Cov ⎡ ⎣∑︁ C 2 k , ∑︁ m / = r C m C r ⎤ ⎦ = 0 . For Cov [︁∑︀ i / = j C i C j , ∑︀ C l Y l ]︁ , since Cov [ C i C j , C i Y i ] = E [ C 2 i Y i C j ] − E [ C i C j ] E [ C i Y i ] = 0 and Cov [ C k C l , C i Y i ] = E [ C k C l C i Y i ] − E [ C k C l ] E [ C i Y i ] = 0 , we have Cov ⎡ ⎣∑︁ i / = j C i C j , ∑︁ C l Y l ⎤ ⎦ = 0 . Additionally , Cov ⎡ ⎣∑︁ i / = j C i C j , ∑︁ m / = r C m C r ⎤ ⎦ = ∑︁ i , j , m , r Cov [ C i C j , C m C r ] = ∑︁ i / = j Cov [ C i C j , C i C j ] = ∑︁ i / = j Var [ C i C j ] = n ( n − 1 ) ( σ 2 + σ 2 µ ) 2 . Therefore , Cov [ ¯ C 2 , ¯ C ¯ Y ] = 2 n 3 σ 2 µ ( σ 2 + σ 2 µ ) + n − 1 n 3 ( σ 2 + σ 2 µ ) 2 . 464 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Furthermore , Cov [ ¯ C 2 , ¯ Y 2 ] = 1 n 4 Cov ⎡ ⎣∑︁ C 2 k + ∑︁ i / = j C i C j , ∑︁ Y 2 l + ∑︁ m / = r Y m Y r ⎤ ⎦ = 1 n 4 (︂ Cov [︁∑︁ C 2 k , ∑︁ Y 2 l ]︁ + Cov ⎡ ⎣∑︁ C 2 k , ∑︁ m / = r Y m Y r ⎤ ⎦ + Cov ⎡ ⎣∑︁ Y 2 l , ∑︁ i / = j C i C j ⎤ ⎦ + Cov ⎡ ⎣∑︁ i / = j C i C j , ∑︁ m / = r Y m Y r ⎤ ⎦ )︂ . In the expression above , Cov [︁∑︁ C 2 k , ∑︁ Y 2 l ]︁ = 2 nσ 4 µ ; Cov ⎡ ⎣∑︁ C 2 k , ∑︁ m / = r Y m Y r ⎤ ⎦ = Cov ⎡ ⎣∑︁ Y 2 l , ∑︁ i / = j C i C j ⎤ ⎦ = 0 ; Cov ⎡ ⎣∑︁ i / = j C i C j , ∑︁ m / = r Y m Y r ⎤ ⎦ = ∑︁ i / = j Cov [ C i C j , Y i Y j ] = ∑︁ i / = j ( E [ C i C j Y i Y j ] − E [ C i C j ] E [ Y i Y j ] ) = ∑︁ i / = j ( E [ C i Y i ] E [ C j Y j ] − 0 ) = n ( n − 1 ) σ 4 µ . Then we have Cov [ ¯ C 2 , ¯ Y 2 ] = 1 n 4 (︂ 2 nσ 4 µ + n ( n − 1 ) σ 4 µ )︂ = n + 1 n 3 σ 4 µ . Putting the terms together , we have Var [ ¯ C − ¯ Y ] 2 = Var [ ¯ C 2 ] + 4 Var [ ¯ C ¯ Y ] + Var [ ¯ Y 2 ] − 4 Cov [ ¯ C 2 , ¯ C ¯ Y ] − 4 Cov [ ¯ Y 2 , ¯ C ¯ Y ] + 2 Cov [ ¯ C 2 , ¯ Y 2 ] = 2 ( n + 1 ) n 3 ( σ 2 + σ 2 µ ) 2 + 4 n 2 ( σ 2 + σ 2 µ ) 2 + 4 σ 4 µ n 3 − 16 n 3 σ 2 µ ( σ 2 + σ 2 µ ) − 8 ( n − 1 ) n 3 ( σ 2 + σ 2 µ ) 2 + 2 ( n + 1 ) n 3 σ 4 µ = 2 n 3 (︂ ( 6 − n ) ( σ 2 + σ 2 µ ) 2 − 8 σ 2 µ ( σ 2 + σ 2 µ ) + ( n + 3 ) σ 4 µ )︂ = 2 n 3 (︁ ( 6 − n ) σ 4 + ( 4 − 2 n ) σ 2 σ 2 µ + σ 4 µ )︁ . C . 1 . 2 Calculating Cov (cid:104)(cid:80) ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 (cid:105) Next , we note that Cov [︁∑︁ ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 ]︁ = ∑︁ Cov [︂ ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 ]︂ = ∑︁ (︂ E [ ( C 2 i − 2 C i Y i + Y 2 i ) ( ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ) ] − E [ ( C 2 i − 2 C i Y i + Y 2 i ) ] E [ ( ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ) ] )︂ , A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 465 where E [ ( C 2 i − 2 C i Y i + Y 2 i ) ( ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ) ] = E [︂ C 2 i ¯ C 2 − 2 C i Y i ¯ C 2 + Y 2 i ¯ C 2 − 2 C 2 i ¯ C ¯ Y + 4 C i Y i ¯ C ¯ Y − 2 Y 2 i ¯ C ¯ Y + C 2 i ¯ Y 2 − 2 C i Y i ¯ Y 2 + Y 2 i ¯ Y 2 ]︂ , and E [ C 2 i − 2 C i Y i + Y 2 i ] = 2 ( σ 2 + σ 2 µ ) − 2 σ 2 µ = 2 σ 2 , E [ ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ] = 2 n ( σ 2 + σ 2 µ ) − 2 n σ 2 µ = 2 σ 2 n . E [ C 2 i ¯ C 2 ] = 1 n 2 E ⎡ ⎣ C 2 i ⎛ ⎝∑︁ C 2 k + ∑︁ i / = j C i C j ⎞ ⎠ ⎤ ⎦ = 1 n 2 (︂ E [ C 4 i ] + ∑︁ k / = i E [ C 2 i ] E [ C 2 k ] + ∑︁ i / = j E [ C 2 k C i C j ] )︂ = 1 n 2 [︂ 3 ( σ 2 + σ 2 µ ) 2 + ( n − 1 ) ( σ 2 + σ 2 µ ) 2 + 0 ]︂ = n + 2 n 2 ( σ 2 + σ 2 µ ) 2 . E [ C i Y i ¯ C 2 ] = E [︂ C i Y i ∑︀ C 2 j + ∑︀ k / = l C k C l n 2 ]︂ = 1 n 2 (︂ E [ C i Y i C 2 i ] + ∑︁ j / = i E [ C i Y i C 2 j ] + ∑︁ k / = l E [ C i Y i C k C l ] )︂ = 1 n 2 (︂ 3 ( σ 2 σ 2 µ + σ 4 µ ) + ( n − 1 ) ( σ 2 σ 2 µ + σ 4 µ ) + 0 )︂ = n + 2 n 2 σ 2 µ ( σ 2 + σ 2 µ ) . E [ Y 2 i ¯ C 2 ] = E [︂ Y 2 i ∑︀ C 2 j + ∑︀ k / = l C k C l n 2 ]︂ = 1 n 2 (︂ E [ Y 2 i C 2 i ] + ∑︁ j / = i E [ Y 2 i C 2 j ] + ∑︁ k / = l E [ Y 2 i C k C l ] )︂ = 1 n 2 (︂ ( σ 2 + σ 2 µ ) 2 + 2 σ 4 µ + ( n − 1 ) ( σ 2 + σ 2 µ ) 2 + 0 )︂ = 1 n 2 (︂ n ( σ 2 + σ 2 µ ) 2 + 2 σ 4 µ )︂ . E [ C 2 i ¯ C ¯ Y ] = 1 n 2 (︂ E [ C 2 i C i Y i ] + ∑︁ j / = i E [ C 2 i C j Y j ] + ∑︁ k / = l E [ C 2 i C k Y l ] )︂ = 1 n 2 (︂ 3 ( σ 2 σ 2 µ + σ 4 µ ) + ( n − 1 ) ( σ 2 σ 2 µ + σ 4 µ ) + 0 )︂ = n + 2 n 2 σ 2 µ ( σ 2 + σ 2 µ ) . E [ C i Y i ¯ C ¯ Y ] = 1 n 2 (︂ E [ C 2 i Y 2 i ] + ∑︁ j / = i E [ C i Y i C j Y j ] + ∑︁ k / = l E [ C i Y i C k Y l ] )︂ = 1 n 2 (︂ ( σ 2 + σ 2 µ ) 2 + 2 σ 4 µ + ( n − 1 ) σ 4 µ + 0 )︂ = 1 n 2 (︂ ( σ 2 + σ 2 µ ) 2 + ( n + 1 ) σ 4 µ )︂ . 466 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Additionally , E [ Y 2 i ¯ C ¯ Y ] = E [ C 2 i ¯ C ¯ Y ] = n + 2 n 2 σ 2 µ ( σ 2 + σ 2 µ ) ; E [ C 2 i ¯ Y 2 ] = E [ Y 2 i ¯ C 2 ] = 1 n 2 (︂ n ( σ 2 + σ 2 µ ) 2 + 2 σ 4 µ )︂ ; E [ C i Y i ¯ Y 2 ] = E [ C i Y i ¯ C 2 ] = n + 2 n 2 σ 2 µ ( σ 2 + σ 2 µ ) ; E [ Y 2 i ¯ Y 2 ] = E [ C 2 i ¯ C 2 ] = n + 2 n 2 ( σ 2 + σ 2 µ ) 2 . Therefore , E [ ( C 2 i − 2 C i Y i + Y 2 i ) ( ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ) ] = E [︂ C 2 i ¯ C 2 − 2 C i Y i ¯ C 2 + Y 2 i ¯ C 2 − 2 C 2 i ¯ C ¯ Y + 4 C i Y i ¯ C ¯ Y − 2 Y 2 i ¯ C ¯ Y + C 2 i ¯ Y 2 − 2 C i Y i ¯ Y 2 + Y 2 i ¯ Y 2 ]︂ = 2 ( n + 2 ) n 2 ( σ 2 + σ 2 µ ) 2 − 4 ( n + 2 ) n 2 σ 2 µ ( σ 2 + σ 2 µ ) + 2 n 2 (︂ n ( σ 2 + σ 2 µ ) 2 + 2 σ 4 µ )︂ − 4 ( n + 2 ) n 2 σ 2 µ ( σ 2 + σ 2 µ ) + 4 n 2 (︂ ( σ 2 + σ 2 µ ) 2 + ( n + 1 ) σ 4 µ )︂ = 4 ( n + 2 ) σ 4 n 2 . So we have Cov [︂ ∑︁ ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 ]︂ = ∑︁ Cov [︂ ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 ]︂ = ∑︁ (︂ E ( C 2 i − 2 C i Y i + Y 2 i ) ( ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ) − E ( C 2 i − 2 C i Y i + Y 2 i ) E ( ¯ C 2 − 2¯ C ¯ Y + ¯ Y 2 ) )︂ = n (︂ 4 ( n + 2 ) σ 4 n 2 − 2 σ 2 2 σ 2 n )︂ = 8 σ 4 n . The variance of the estimator is then Var [ S ] = 1 4 a 2 (︂ Var [︁∑︁ ( C i − Y i ) 2 ]︁ + n 2 Var [ ¯ C − ¯ Y ] 2 − 2 nCov [︂ ∑︁ ( C i − Y i ) 2 , ( ¯ C − ¯ Y ) 2 ]︂)︂ = 1 4 a 2 (︂ 8 nσ 4 + 2 n (︂ ( 6 − n ) σ 4 + ( 4 − 2 n ) σ 2 σ 2 µ + σ 4 µ )︂ − 16 σ 4 )︂ = 1 2 a 2 (︂ 4 nσ 4 + 1 n (︂ ( 6 − n ) σ 4 + ( 4 − 2 n ) σ 2 σ 2 µ + σ 4 µ )︂ − 8 σ 4 )︂ . C . 2 Calculating E [ S ] The expectation of the estimator is E [ S ] = 1 2 a (︂ ∑︁ E [ C i − Y i ] 2 − nE [ ¯ C − ¯ Y ] 2 )︂ , where E [ ( C i − Y i ) 2 ] = Var [ C i − Y i ] = Var [ C i ] + Var [ Y i ] − 2 Cov [ C i , Y i ] = 2 ( σ 2 + σ 2 µ ) − 2 σ 2 µ = 2 σ 2 , A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 467 and E [ ( ¯ C − ¯ Y ) 2 ] = Var [ ¯ C − ¯ Y ] = Var [ ¯ C ] + Var [ ¯ Y ] − 2 Cov [ ¯ C , ¯ Y ] = 2 n ( σ 2 + σ 2 µ ) − 2 n σ 2 µ = 2 σ 2 n . Hence , E [ S ] = 1 2 a ( 2 nσ 2 − 2 σ 2 ) = n − 1 a σ 2 . C . 3 Calculating the MSE The MSE of the estimator is then E [ ( S − σ 2 ) 2 ] = Var [ S ] + ( E [ S ] − σ 2 ) 2 = 1 2 a 2 (︂ 4 nσ 4 + 1 n (︂ ( 6 − n ) σ 4 + ( 4 − 2 n ) σ 2 σ 2 µ + σ 4 µ )︂ − 8 σ 4 )︂ + (︂ n − 1 a − 1 )︂ 2 σ 4 = 1 2 a 2 (︂ 4 nσ 4 + 1 n (︂ ( 6 − n ) σ 4 + ( 4 − 2 n ) σ 2 σ 2 µ + σ 4 µ )︂ − 8 σ 4 + 2 ( n − 1 ) 2 σ 4 )︂ − 2 ( n − 1 ) σ 4 1 a + σ 4 = 1 2 a 2 (︂ ( 2 n 2 + 6 n − 7 ) σ 4 + 2 ( 2 n − 1 ) σ 2 σ 2 µ + 1 n σ 4 µ )︂ − 2 ( n − 1 ) σ 4 1 a + σ 4 . The value of a that minimizes this MSE is a = ( 2 n 3 − 7 n + 6 ) σ 4 + 2 ( 2 − n ) σ 2 σ 2 µ + σ 4 µ 2 ( n 2 − n ) σ 4 = 2 n 3 − 7 n + 6 2 ( n 2 − n ) + 2 − n n 2 − n σ 2 µ σ 2 + 1 2 ( n 2 − n ) (︂ σ 2 µ σ 2 )︂ 2 . D Calculating Var [ ˜ S int ] Var [ ˜ S int ] = 1 4 a 2 Var [︂ n ∑︁ i = 1 ( C i − Y i ) 2 ]︂ = 1 4 a 2 Var [︂ n ∑︁ i = 1 (︂ C 2 i + Y 2 i − 2 C i Y i )︂]︂ = 1 4 a 2 Var [︂ n ∑︁ i = 1 C 2 i + n ∑︁ i = 1 Y 2 i − 2 n ∑︁ i = 1 C i , Y i ]︂ = 1 4 a 2 (︂ Var [︃ n ∑︁ i = 1 C 2 i ]︃ + Var [︃ n ∑︁ i = 1 Y 2 i ]︃ + 4 Var [︃ n ∑︁ i = 1 C i Y i ]︃ + 2 Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 Y 2 i ]︃ − 4 Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 C i Y i ]︃ − 4 Cov [︃ n ∑︁ i = 1 Y 2 i , n ∑︁ i = 1 C i Y i ]︃ )︂ . 468 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise The individual terms can be computed as follows : Var [︃ n ∑︁ i = 1 C 2 i ]︃ = n ∑︁ i = 1 Var [ C 2 i ] = n ∑︁ i = 1 (︂ E [ C 4 i ] − ( E [ C 2 i ] ) 2 )︂ = n ∑︁ i = 1 (︂ E [ C 4 i ] − ( Var [ C i ] + ( E [ C i ] ) 2 ) 2 )︂ = n ∑︁ i = 1 (︂ E [ C 4 i ] − ( σ 2 + σ 2 µ + µ 2 ) 2 )︂ = nEC 41 − n ( σ 2 + σ 2 µ + µ 2 ) 2 . Assuming normality , we have Var [︃ n ∑︁ i = 1 C 2 i ]︃ = n (︂ 3 ϵ + 3 σ 4 + 6 σ 2 µ σ 2 + 6 µ 2 σ 2 + 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 − ( σ 2 + σ 2 µ + µ 2 ) 2 )︂ = n ( 3 ϵ + 2 σ 4 + 2 σ 4 µ + 4 σ 2 σ 2 µ + 4 µ 2 σ 2 + 4 µ 2 σ 2 µ ) . Assuming additionally that µ = 0 and ϵ = 0 , we have Var [︃ n ∑︁ i = 1 C 2 i ]︃ = 2 n ( σ 2 + σ 2 µ ) 2 . Since C i and Y i are symmetrically defined , we have Var [︃ n ∑︁ i = 1 Y 2 i ]︃ = Var [︃ n ∑︁ i = 1 C 2 i ]︃ . Next , from Appendix B , Var [︃ n ∑︁ i = 1 C i Y i ]︃ = n ∑︁ i = 1 (︂ ϵ + σ 4 + EM 4 i + 2 σ 2 ( σ 2 µ + µ 2 ) − ( σ 2 µ + µ 2 ) 2 )︂ . Assuming normality , we have E [ C i Y i ] 2 = ϵ + σ 4 + 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 + 2 σ 2 σ 2 µ + 2 σ 2 µ 2 ; E [ C i Y i ] = σ 2 µ + µ 2 ; Var [︃ n ∑︁ i = 1 C i Y i ]︃ = n ( ϵ + σ 4 + 2 σ 4 µ + 2 σ 2 σ 2 µ + 2 µ 2 σ 2 + 4 µ 2 σ 2 µ ) . Assuming additionally that µ = 0 and ϵ = 0 , we have E [ C i Y i ] 2 = ( σ 2 + σ 2 µ ) 2 + 2 σ 4 µ ; E [ C i Y i ] = σ 2 µ ; Var [︃ n ∑︁ i = 1 C i Y i ]︃ = n [︂ ( σ 2 + σ 2 µ ) 2 + σ 4 µ ]︂ . The covariance terms are computed as follows : Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 Y 2 i ]︃ = n ∑︁ i = 1 Cov [ C 2 i , Y 2 i ] = n ∑︁ i = 1 ( E [ C 2 i Y 2 i ] − E [ C 2 i ] E [ Y 2 i ] ) . A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 469 Assuming normality , we have Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 Y 2 i ]︃ = n (︂ ϵ + σ 4 + 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 + 2 σ 2 σ 2 µ + 2 σ 2 µ 2 − ( σ 2 + σ 2 µ + µ 2 ) 2 )︂ = n ( ϵ + 2 σ 4 µ + 4 µ 2 σ 2 µ ) . Assuming additionally that µ = 0 and ϵ = 0 , we have Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 Y 2 i ]︃ = 2 nσ 4 µ . Finally , since C i and Y i are symmetrically defined , we have Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 C i Y i ]︃ = Cov [︃ n ∑︁ i = 1 Y 2 i , n ∑︁ i = 1 C i Y i ]︃ = n ∑︁ i = 1 Cov [ C 2 i , C i Y i ] = n ∑︁ i = 1 (︂ E [ C 3 i Y i ] − E [ C 2 i ] E [ C i Y i ] )︂ , where E [ C 3 i Y i ] = E [︂ E [ C 3 i Y i | Z i ] ]︂ = E [︂ E [ C 3 i | Z i ] E [ Y i | Z i ] ]︂ . Assuming normality , we have E [ C 3 i Y i ] = E [︂ ( 3 M i Σ 2 i + M 3 i ) M i ]︂ = E [ 3 M 2 i Σ 2 i + M 4 i ] = 3 E [ M 2 i ] E [ Σ 2 i ] + E [ M 4 i ] = 3 ( σ 2 µ + µ 2 ) σ 2 + 3 σ 4 µ + 6 µ 2 σ 2 µ + µ 4 = µ 4 + 3 σ 4 µ + 3 σ 2 σ 2 µ + 3 µ 2 σ 2 + 6 µ 2 σ 2 µ ; E [ C 2 i ] = σ 2 + σ 2 µ + µ 2 ; E [ C i Y i ] = σ 2 µ + µ 2 ; and therefore , Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 C i Y i ]︃ = n (︂ µ 4 + 3 σ 4 µ + 3 σ 2 σ 2 µ + 3 µ 2 σ 2 + 6 µ 2 σ 2 µ − ( σ 2 + σ 2 µ + µ 2 ) ( σ 2 µ + µ 2 ) )︂ = n (︂ µ 4 + 3 σ 4 µ + 3 σ 2 σ 2 µ + 3 µ 2 σ 2 + 6 µ 2 σ 2 µ − ( µ 4 + σ 4 µ + σ 2 σ 2 µ + µ 2 σ 2 + 2 µ 2 σ 2 µ ) )︂ = 2 n ( σ 4 µ + σ 2 σ 2 µ + µ 2 σ 2 + 2 µ 2 σ 2 µ ) . Assuming additionally that µ = 0 and ϵ = 0 , we have E [ C 3 i Y i ] = 3 σ 2 σ 2 µ + 3 σ 4 µ ; E [ C 2 i ] = σ 2 + σ 2 µ ; E [ C i Y i ] = σ 2 µ ; Cov [︃ n ∑︁ i = 1 C 2 i , n ∑︁ i = 1 C i Y i ]︃ = 2 nσ 2 µ ( σ 2 + σ 2 µ ) . 470 | A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise Table 6 : Mean and variance of the estimators in Table 1 . Note that only the numerators of the estimators in the general forms are considered here ; that is , scalar a can take different values depending on which specific estimator is of interest . Values of a can be found in Table 1 . As in the main text , we assume normality of all distributions , and that µ = 0 and ϵ = 0 , when deriving the mean and variance . Estimator Mean Variance Intrinsic noise General 12 a (︀∑︀ n 1 ( C i − Y i ) 2 − n ( ¯ C − ¯ Y ) 2 )︀ n − 1 a σ 2 12 a 2 (︂ 4 nσ 4 + 1 n (︂ ( 6 − n ) σ 4 + ( 4 − 2 n ) σ 2 σ 2 µ + σ 4 µ )︂ − 8 σ 4 )︂ Equal mean 12 a ∑︀ ni = 1 ( C i − Y i ) 2 na σ 2 2 na 2 σ 4 Extrinsic noise 1 a ( ∑︀ ni = 1 C i Y i − n ¯ C ¯ Y ) n − 1 a σ 2 µ n − 1 a 2 ( σ 2 + σ 2 µ ) 2 + ( n − 1 ) 2 na 2 σ 4 µ Putting the terms together , we derive the variance as follows , assuming that M i follows a normal distribution , Var [ ˜ S int ] = 1 4 a 2 {︂ 2 n ( 3 ϵ + 2 σ 4 + 2 σ 4 µ + 4 σ 2 σ 2 µ + 4 µ 2 σ 2 + 4 µ 2 σ 2 µ ) + 4 n ( ϵ + σ 4 + 2 σ 4 µ + 2 σ 2 σ 2 µ + 2 µ 2 σ 2 + 4 µ 2 σ 2 µ ) + 2 n ( ϵ + 2 σ 4 µ + 4 µ 2 σ 2 µ ) − 16 n ( σ 4 µ + σ 2 σ 2 µ + µ 2 σ 2 + 2 µ 2 σ 2 µ ) }︂ = n a 2 ( 3 ϵ + 2 σ 4 ) . Assuming additionally that µ = 0 and ϵ = 0 , we have Var [ ˜ S int ] = 2 n a 2 σ 4 . E Summary of mean and variance of the estimators We summarize the mean and variance of the estimators in Table 6 . References Elowitz , M . B . , A . J . Levine , E . D . Siggia and P . S . Swain ( 2002 ) : “Stochastic gene expression in a single cell , ” Science , 297 , 1183 – 1186 . Finkenstädt , B . , D . J . Woodcock , M . Komorowski , C . V . Harper , J . R . Davis , M . R . White and D . A . Rand ( 2013 ) : “Quantifying intrinsic and extrinsic noise in gene transcription using the linear noise approximation : an application to single cell data , ” Ann . Appl . Stat . , 7 , 1960 – 1982 . Hayes , K . ( 2011 ) : “A geometrical interpretation of an alternative formula for the sample covariance , ” Am . Stat . , 65 , 110 – 112 . Hilfinger , A . and J . Paulsson ( 2011 ) : “Separating intrinsic from extrinsic fluctuations in dynamic biological systems , ” Proc . Natl . Acad . Sci . USA , 108 , 12167 – 12172 . James , W . and C . Stein ( 1961 ) : “Estimation with quadratic loss , ” Proc . Fourth Berkeley Symp . Math . Stat . Prob . , 1 , 361 – 379 . Koeppl , H . , C . Zechner , A . Ganguly , S . Pelet and M . Peter ( 2012 ) : “Accounting for extrinsic variability in the estimation of stochastic rate constants , ” Int . J . Robust Nonlin . , 22 , 1103 – 1119 . Komorowski , M . , J . Mie¸kisz and M . P . Stumpf ( 2013 ) : “Decomposing noise in biochemical signaling systems highlights the role of protein degradation , ” Biophys . J . , 104 , 1783 – 1793 . Rausenberger , J . and M . Kollmann ( 2008 ) : “Quantifying origins of cell - to - cell variations in gene expression , ” Biophys . J . , 95 , 4523 – 4528 . Schmiedel , J . M . , S . L . Klemm , Y . Zheng , A . Sahay , N . Blüthgen , D . S . Marks and A . van Oudenaarden ( 2015 ) : “MicroRNA control of protein expression noise , ” Science , 348 , 128 – 232 . A . Q . Fu and L . Pachter : Estimating intrinsic and extrinsic noise | 471 Sherman , M . S . , K . Lorenz , M . H . Lanier and B . A . Cohen ( 2015 ) : “Cell - to - cell variability in the propensity to transcribe explains correlated fluctuations in gene expression , ” Cell Syst . , 1 , 315 – 325 . Stegle , O . , S . A . Teichmann and J . C . Marioni ( 2015 ) : “Computational and analytical challenges in single - cell transcriptomics , ” Nat . Rev . Genet . , 16 , 133 – 145 . van Nimwegen , E . ( 2016 ) : “Inferring intrinsic and extrinsic noise from a dual fluorescent reporter , ” bioRxiv 049486 ; doi : http : / / dx . doi . org / 10 . 1101 / 049486 . Volfson , D . , J . Marciniak , W . J . Blake , N . Ostroff , L . S . Tsimring and J . Hasty ( 2006 ) : “Origins of extrinsic variability in eukaryotic gene expression , ” Nature , 439 , 861 – 864 . Yang , S . , S . Kim , Y . R . Lim , C . Kim , H . J . An , J . - H . Kim , J . Sung and N . K . Lee ( 2014 ) : “Contribution of RNA polymerase concentration variation to protein expression noise , ” Nat . Commun . , 5 , 4761 .