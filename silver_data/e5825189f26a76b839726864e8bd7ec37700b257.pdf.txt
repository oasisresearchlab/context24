1 . Introduction From a patient’s perspective , one would hope that medicine was always based on the rational use of evidence and not simply dispensed arbitrarily at the practitioner’s whim . However , with the rapidly increasing volume of medical research being con - ducted and clinical laboratory tests being developed , doctors are challenged increasingly on how best to integrate evidence in making decisions about the day - to - day care of their patients ( Black & Welch 1993 ; Casscells et al . 1987 ; Elstein et al . 1978 ; Haynes & Haines 1998 ; McAlister et al . 2000 ) . This relatively recent emphasis on doctors’ reasoning skills stands in counterpoint to the equally important exploration of how patients themselves make medical decisions ( e . g . Redelmeier et al . 1993 ; Sherbourne et al . 1999 ) . Cognitive and social psychologists have long been interested in identifying the factors that facilitate and impede effective evidence use in making decisions ( e . g . Bell et al . 1988 ; Einhorn & Hogarth 1981 ; Kahneman et al . 1982 ) . Many biases , or non - rational strategies , in decision making have been studied in the non - medical world , and their parallels in the medical domain are beginning to be addressed ( Bornstein et al . 1999 ; Dawson & Arkes 1987 ; Detmer et al . 1978 ; Dolan 1999 ; Elstein 1988 ; Hammond 1996 ; Hershberger et al . 1994 ) * . Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 © 2001 Blackwell Science 97 Correspondence Dr Brian H . Bornstein 238 Burnett Hall Department of Psychology University of Nebraska Lincoln NE 68588 - 0308 USA Keywords : biases , medical decision making Accepted for publication : 21 October 2000 Abstract The objectives of this study were to describe ways in which doctors make suboptimal diagnostic and treatment decisions , and to discuss possible means of alleviating those biases , using a review of past studies from the psychological and medical decision - making literatures . A number of biases can affect the ways in which doctors gather and use evidence in making diagnoses . Biases also exist in how doctors make treatment decisions once a deﬁnitive diagnosis has been made . These biases are not peculiar to the medical domain but , rather , are manifestations of suboptimal reasoning to which people are susceptible in general . None the less , they can have poten - tially grave consequences in medical settings , such as erroneous diagnosis or patient mismanagement . No sureﬁre methods exist for eliminating biases in medical decision making , but there is some evidence that the adoption of an evidence - based medicine approach or the incorporation of formal decision analytic tools can improve the quality of doctors’ reasoning . Doctors’ reasoning is vulnerable to a number of biases that can lead to errors in diagnosis and treatment , but there are positive signs that means for alleviating some of these biases are available . Rationality in medical decision making : a review of the literature on doctors’ decision - making biases Brian H . Bornstein and A . Christine Emler Louisiana State University , USA * A considerable proportion of this literature employs non - medical participants who are asked to make medical judgements ( i . e . diag - nostic or treatment decisions ) for hypothetical cases ( e . g . Klayman & Brown 1993 ; Medin et al . 1982 ) . Although such simulations are very helpful at uncovering general decision - making principles , we limit our discussion to studies in which participants have at least some medical training ( i . e . medical students , residents or practis - ing doctors ) . In focusing on common biases , we also do not con - sider differences across doctors varying in expertise , although we note that some research indicates that more experienced doctors do exhibit less bias ( e . g . Dawson et al . 1988 ; Elstein et al . 1978 ) . B . H . Bornstein and A . C . Emler There are many ways to dissect the complicated process of decision making . As biases can occur at every phase of doctors’ interactions with patients ( Moskowitz et al . 1988 ) , this paper is divided into the sequential steps of making a diagnosis ( section 2 ) and choosing a course of treatment ( section 3 ) . The diag - nosis section is subdivided further into biases related to : gathering evidence ; testing hypotheses by using , or integrating , evidence once it has been obtained ; and probability assessment ( cf . Dawson & Arkes 1987 ) . A list of the biases described in the paper is shown in Table 1 . The paper concludes with an evaluation of some of the proposed methods of ‘debiasing’ medical decision makers and recommendations on how to improve doctors’ reasoning ( section 4 ) . 2 . Making a diagnosis Suppose that a 63 - year - old male patient presents with chest pain , fever and diffuse pulmonary inﬁl - trates . He has had angina for several years and was diagnosed 14 months previously with pre - leukaemia and granulocytopenia ( taken from Moskowitz et al . 1988 ) . In evaluating this patient , the doctor must estimate the probability of a number of possible hypotheses ( i . e . diagnoses ) , decide what additional information to gather in order to rule out all but one diagnosis , and test competing hypotheses by evaluat - ing the information that has been gathered . In actual practice , of course , these processes occur more or less concurrently as each step provides feedback for the others . None the less , it is useful to distinguish between biases that pertain principally to : ( a ) the process of gathering evidence ; ( b ) the interpretation of evidence after it has been introduced ; or ( c ) esti - mating the probability that a patient has a particular illness . Gathering evidence The diagnostician must decide what evidence to seek in order to exclude some possibilities while increas - ing the likelihood of the ultimate diagnosis . Relevant evidence may come in a variety of forms , such as a patient’s responses to questioning about symptoms and medical history , physical examination or labora - tory test results . When one or several initial diagnoses are being considered , tests are typically ordered to reﬁne the differential diagnosis by improving the estimated probability of a tentative initial diagnosis , which is usually arrived at early on in the process , relative to other potential diagnoses . The evidence obtained from these tests is then synthesized and a ﬁnal proposal is made ( Elstein et al . 1978 ; Joseph 98 © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 Table 1 List and deﬁnition of biases Deﬁnition Diagnostic biases Conﬁrmation Selectively gathering and interpreting evidence that conﬁrms a diagnosis and ignoring evidence that might disconﬁrm it Representativeness Overemphasizing evidence that strongly resembles a class of events . Can lead to undervaluing of relevant base rates , ignoring regression to the mean , and gambler’s fallacy Availability Overestimating probability of a diagnosis when instances are relatively easy to recall Hindsight Overestimating probability of a diagnosis when the correct diagnosis is already known Regret Overestimating probability of a diagnosis with severe possible outcome because of anticipated regret if diagnosis were missed Treatment biases Regret / outcome Feeling worse about adverse outcomes due to active treatment than to inaction and taking more credit for treatment decisions that lead to positive outcomes than those that lead to adverse outcomes Framing Choosing riskier treatments when they are described in negative ( e . g . mortality ) rather than positive ( e . g . survival ) terms Number of alternatives Choosing a given treatment option more often when there are additional alternatives & Patel 1990 ) . The value of a diagnostic test lies in its power to change the doctor’s certainty that the patient has whatever illness is being evaluated ( Eddy 1982 ) . One bias that can affect this phase of decision making is ‘conﬁrmation bias’ , which leads one to seek and interpret evidence that predominantly conﬁrms a pre - existing hypothesis ( Elstein 1988 ) . Eddy points out several examples of this bias , such as using mam - mography not to dissuade a doctor from biopsy but solely to conﬁrm a hypothesis of malignancy , regard - less of the patient’s symptomatology or even the result of the mammogram . Interpretation of evidence Another manifestation of the conﬁrmation bias is the observation that doctors not only tend to seek conﬁrmatory information , but they also pay greater attention to conﬁrmatory evidence once it has been encountered ( Joseph & Patel 1990 ) . Conversely , they tend to undervalue disconﬁrming evidence . Christensen - Szalanski & Bushyhead ( 1981 ) evalu - ated internists’ evaluation of symptoms in diagnos - ing pneumonia . Although they were fairly sensitive to the diagnostic value of relevant symptoms when those symptoms – such as chills – were present , they were less sensitive to equally valuable absent ﬁnd - ings , such as the absence of chills , which would have weakened the same hypothesis . This bias is exacer - bated by the fact that present ﬁndings , such as an acute cough , night sweats or asymmetric respirations , are perceived as abnormal and therefore highly indicative of pneumonia , while absent symptoms , such as no chest pain or sinus tenderness , are per - ceived merely as normal ﬁndings ( Christensen - Szalanski & Bushyhead 1983 ) . None the less , the absent ﬁndings may be equally informative in making a correct diagnosis . These results should not be taken to mean that a reliance on an initial diagnosis , or hunch , is entirely a bad thing . On the contrary , the earlier one arrives at an appropriate diagnosis , the more effective sub - sequent hypothesis testing is likely to be ( Joseph & Patel 1990 ) . Without an appropriate preliminary diagnosis , relevant symptoms might not even be noticed . Brooks et al . ( 2000 ) showed groups of medical students and internists a series of head - and - shoulder photographs along with short case histories . Each photograph contained a physical sign that was key to a particular diagnosis ( e . g . a butterﬂy rash across the nose for lupus ) . Brooks et al . asked par - ticipants to identify any relevant clinical features in the photographs . Even though the photos were chosen to be unambiguous ( three - quarters were copied from textbook illustrations of the conditions ) , performance was far from perfect . Participants missed many of the relevant features and , conse - quently , made many erroneous diagnoses . Impor - tantly , however , they were signiﬁcantly better at detecting the features when they were provided with a provisional diagnosis . Thus , as with cognitive heuristics in general ( Bell et al . 1988 ; Kahneman et al . 1982 ) , the conﬁrmation bias can be helpful as well as harmful . As suggested by the ﬁndings of Christensen - Szalanski & Bushyhead ( 1981 , 1983 ) , present or abnormal ﬁndings may seem more ‘representative’ of a particular disorder . In assessing the likelihood that an exemplar ‘A’ belongs to a given class ‘B’ , decision makers tend to rely on the degree to which ‘A’ re - sembles ‘B’ , or how ‘representative’ the exemplar is of the class ( Tversky & Kahneman 1974 ) . For example , one’s estimate of the probability that an individual selected at random from a cinema audi - ence is a doctor would be heavily inﬂuenced by the extent to which the individual’s description adheres to one’s stereotype . Study participants who were told that the individual was a male wearing surgical scrubs and carrying a cell phone , pager and small black bag would give a higher probability estimate than those told that the person was a female wearing torn dungarees and carrying an apple , notebook and shopping bag . This ‘representativeness’ heuristic frequently yields accurate results because representativeness often correlates with likelihood . Unfortunately , it also leads people to overweight highly representative individuating evidence and to undervalue relevant prior probabilities ( Elstein 1988 ) . Positive test results are especially salient in this respect and difﬁcult to ignore , leading doctors in many cases to overestimate the probability of disease . For example , a positive mammogram is perceived as so indicative of breast cancer that it may lead doctors to ignore the relevant base rate – such as that women in a certain age group , without other symptoms , have a very low prior prob - Rationality in medical decisions © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 99 B . H . Bornstein and A . C . Emler ability of breast cancer – and hence to overweight the import of the positive test result ( Casscells et al . 1987 ; Eddy 1982 ) . Overestimating the probability of a diagnosis can , of course , have many negative conse - quences , not the least of which is causing patients undue worry . Overly representative evidence also leads deci - sion makers to ignore regression toward the mean . Regression to the mean means that whenever an individual’s score on some measure is initially extreme , it will tend to be closer to the mean when measured a second time . This damping of extreme values occurs because most biological measure - ments vary randomly , often being distributed sym - metrically about a mean value , in the normal population . Therefore , events with values closer to the mean are more common than events with values that are far from the mean . The failure to recognize the entity of regression toward the mean can affect many aspects of medical decision making ( Bland & Altman 1994 ) . Often doctors are in the position of treating patients with extreme values of a given mea - surement , be it weight , temperature , white blood cell count , blood pressure , etc . Measurements taken at a second time will usually be closer to the mean mea - surement for the entire population . If treatment was given in the interim , patient and doctor may attribute the ‘improved’ reading as a result of treatment . In other words , they may take the initial value as more representative of the true state of affairs than it in fact is . Finally , the representativeness bias may underlie the gambler’s fallacy , which arises when a series of events seems ‘one - sided’ , for example , 10 heads in a row while tossing a coin ( Tversky & Kahneman 1974 ) . Subjectively , it seems that tails is ‘due’ for the 11th toss , or that the probability of tails on the 11th toss is substantially greater than 0 . 5 ( Detmer et al . 1978 ) . For instance , the gambler’s fallacy would lead a doctor to expect that , having not seen any of the usual ﬁve cases of myocardial infarction ( MI ) per weekend , the next chest pain would be an MI ( Dawson & Arkes 1987 ) . A classic example of the gambler’s fallacy is the evaluation by New York City school doctors in the 1930s of children for possible tonsillectomy ( Bakwin 1945 ) . The initial examiners recommended tonsillec - tomy for 174 of 389 children , or 45 % . The excluded children were then examined by a second set of doctors . Tonsillectomy was recommended for 99 of these 215 children , or 46 % . The remaining 116 chil - dren were then examined by a third , independent examiner , and 44 % of these children were recom - mended for tonsillectomy . The doctors obviously expected that 45 % of New York City school children needed tonsillectomy and relied heavily on this assumption when forming medical decisions , even for children who had already been excluded . At ﬁrst blush , this reasoning might appear to reﬂect an over - reliance on base rates – unlike the under - use of base rates described above – but it results in fact because of the expectation that a small sample of events ( i . e . the children actually examined ) should be rep - resentative of the larger population ( Tversky & Kahneman 1974 ) , meaning that roughly 45 % of them ought to have tonsillitis . Although it is tempting to ascribe this ﬁnding to the unenlightened customs of medical practice 70 years ago , it has recently been replicated ( Ayanian & Berwick 1991 ) . Probability assessment In essence , the process of making a differential diagnosis involves assessing the probabilities of competing hypotheses until the probability of one hypothesis is markedly higher than the others . If these probabilistic estimates are in error , subsequent management of the patient will be misguided . Thus , the entire diagnostic process amounts to doctors’ ability to make accurate probability assessments . In making these types of prediction doctors do not have crystal balls ; in fact , their estimates can vary widely . Shapiro ( 1977 ) presented a group of rheumatologists with descriptions of a number of hypothetical patients and found that the variability of their opin - ions about the probability of given outcomes for the same set of circumstances spanned nearly the entire probability spectrum ( i . e . 0 – 1 . 0 ) . Probability esti - mates may be inﬂuenced by the availability heuristic , hindsight bias and regret . The availability heuristic involves estimating the probability of an event by how easily one recalls ( i . e . how ‘available’ are memories of ) similar events ( Tversky & Kahneman 1974 ) . As more frequent events are usually more easily recalled than less fre - 100 © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 quent events , the heuristic often leads to accurate predictions . In medical cases , for example , patients presenting symptoms that are typical of a disease receive more probable diagnoses , as they should , than patients presenting atypical symptoms ( Custers et al . 1996 ) . However , recent or salient events are also more easily recalled , regardless of the frequency with which they occur , and availability can thereby lead to biased probability assessment . Poses & Anthony ( 1991 ) examined the availability bias in doctors’ reasoning by asking doctors who had ordered blood cultures to estimate the probability that a culture would be positive for bacteraemia . In addition , they measured the availability of the doctors’ memories of bacteraemic patients by asking them questions such as how many patients they could recall who had had positive blood cultures within the past month . The greater the extent to which the doctors recalled caring for bacteraemic patients in the past ( i . e . the more available were their memories of bacteraemia ) , the higher were their estimates of the probability that a newly presenting patient had bacteraemia . It is also worth noting that their assess - ments were not very accurate , grossly overestimating the actual prevalence of infection . For example , when the doctors estimated the probability of bacteraemia between 41 % and 99 % the actual rate was only 12 % , and only two of ﬁve patients for whom they were absolutely certain of a positive test result ( i . e . 100 % estimated probability ) actually had it ( see also Christensen - Szalanski & Bushyhead 1981 ) . Doctors need not actually experience some event for it to become more available in memory . This variation on the availability heuristic – referred to as the ‘simulation’ heuristic ( Kahneman & Tversky 1982 ) – was found by Heath et al . ( 1991 ) to inﬂuence doctors’ estimates of the probability that they would be exposed to HIV at work . They found that the extent to which doctors merely imagined being exposed to HIV was correlated positively with the degree to which they perceived themselves to be at risk of exposure . Although this example does not deal with the diagnostic process per se , it shows none the less that availability can affect doctors’ probabil - ity assessments via imagined , and not necessarily experienced , events . Hindsight bias is another well - documented phe - nomenon that inhibits proper probability estimation . First documented by Fischhoff ( 1975 ) , the hindsight bias leads people who already know the outcome of an event to overestimate the probability that it would have occurred . Arkes et al . ( 1981 ) studied hindsight bias in the medical world by presenting doctors with case histories and then asking them to rank the like - lihood of four different diagnoses and to estimate the likelihood that they would be able to predict the correct diagnosis . Speciﬁcally , they were told that a 37 - year - old male bartender had developed swelling and heat in his wrist and knee . His liver was enlarged and test results revealed a normal CBC , ESR of 30 mm , negative latex , joint ﬂuid with 20 000 WBC , excess pus cells in urine and mild fever . The doctors were told to estimate the probability , based on this information , that the patient had Reiter’s syndrome , post - streptococcal arthritis , gout or hepatitis . One group ( the ‘foresight’ group ) was given no additional information , while four ‘hindsight’ groups were told that the patient was a case history of one of the four diseases . The doctors who were given the correct answer prior to making their diagnosis signiﬁcantly overestimated the probability of that illness . The hindsight bias has since been replicated in the arena of the clinicopathological conference ( CPC ) using a broader array of diagnostic problems ( Dawson et al . 1988 ) . More experienced doctors were affected by knowledge of the correct diagnosis less than were medical students and residents , but they were susceptible to it none the less . The researchers suggest that the hindsight bias may seriously lessen the educational value of the CPC format , as one cannot learn as much from a CPC if one believes that the correct diagnosis was obvious . Just as mere knowledge of an outcome can inﬂate one’s estimate of its probable occurrence , the unde - sirability of an outcome can also lead one to over - estimate its likelihood of occurrence . In other words , the regret or ‘chagrin’ ( Feinstein 1985 ) that doctors might anticipate experiencing from a missed diagno - sis could lead them to overestimate the probability of the diagnosis ( Dawson & Arkes 1987 ) . In one study , urologists overestimated the probability of tumour vs . a benign cyst , presumably because of the regret ( or liability ) they would have experienced if they had missed the more serious diagnosis ( Wallsten 1981 ) . Although a doctor may be justiﬁed in erring on the safe side when the consequences of a poten - Rationality in medical decisions © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 101 B . H . Bornstein and A . C . Emler tial diagnosis are dire , the inﬂation of the estimated probability of the more serious diagnosis may rule out other potential ( and perhaps correct ) diagnoses ( Dawson & Arkes 1987 ) . 3 . Deciding on a course of treatment After a diagnosis , even a tentative one , has been made , it remains to initiate treatment . Biases can occur at this phase that lead doctors to prefer one treatment over another , objectively similar one , to select a suboptimal treatment , or to maintain an unsuccessful treatment beyond the point when they should choose an alternative course . Treatment choices can be affected by the possible outcomes of various treatments , the manner in which treatments are described , or ‘framed’ , and the number of treat - ment alternatives . Treatment outcomes Regret can also affect this stage of doctors’ decision making . The anticipated regret , should a bad out - come occur , is greater if the outcome seems to result more from the doctor’s action in treating a disease than from inaction ( Elstein 1988 ) . This dif - ferential perception of harm caused by omissions , as opposed to commissions , is due to clinicians’ greater sense of responsibility if an adverse outcome is caused by treating something – such as negative drug effects – than by not treating it and adopting a ‘watchful waiting’ approach ( Elstein et al . 1986 ; see , generally , Spranca et al . 1991 ) . To some extent , pre - empting possible regret is one way in which doctors make themselves feel better about their diagnostic and treatment decisions . Accordingly , they also tend to take more credit for ‘good’ decisions ( i . e . those with positive outcomes ) than for ‘bad’ decisions and to evaluate them more positively ( Gruppen et al . 1994 ) . Treatment framing The framing effect is one of the more thoroughly studied aspects of medical decision - making biases , in patients as well as doctors ( e . g . Mazur & Hickam 1990 ; McNeil et al . 1988 ) . According to the framing effect , decision makers’ preference between options is inﬂuenced by the way in which equivalent infor - mation is formulated , or ‘framed’ . When outcomes are framed in terms of gains , such as saving lives or winning money , people are risk averse and choose a certain gain rather than a possible but uncertain larger gain ; in contrast , in the domain of losses , with outcomes such as losing lives or money , people tend to seek risk by avoiding a certain loss , even if an uncertain gamble might result in an even larger loss . In other words , individuals are more willing to accept risk when they perceive something as a potential loss , and they tend to avoid risk when they perceive a potential gain ( Tversky & Kahneman 1988 ) . Research on framing frequently uses medical examples . For example , McNeil et al . ( 1982 ; see also McNeil et al . 1988 ) asked participants to imagine that they had lung cancer . They were given probability - of - survival and life - expectancy data for two alternative treatments , surgery and radiation . For half the par - ticipants , the data were presented in a positive or ‘survival’ frame , while half received the data in a neg - ative or ‘mortality’ frame . Survival participants learned that of 100 people having surgery , 90 live through the procedure , 68 are alive after 1 year and 34 are alive after 5 years ; whereas of 100 people having radiation , all live through the treatment , 77 are alive after 1 year and 22 are alive after 5 years . Mortality participants received the same objective information presented in terms of the number of people who die ( e . g . for the surgery option , 10 die during surgery , 32 die by the end of the ﬁrst year and 66 die within 5 years ) . Participants preferred radia - tion therapy to surgery 44 % of the time in the mor - tality frame , but only 18 % of the time in the survival frame . In other words , the advantage of radiation therapy was greater when stated in terms of reduc - ing the risk of imminent death than when expressed in terms of increased survival . Interestingly , McNeil et al . ( 1982 ) found that doctors were just as suscepti - ble to the framing effect as non - medical participants ( patients and students ) . However , more recent research has called this ﬁnding into question . Marteau ( 1989 ) presented a group of medical students with a set of three medical situations , each having a choice of two treatment options , such as a patient with terminal liver disease needing to decide whether or not to have surgery . In addition to varying the framing of information ( i . e . 102 © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 chance of dying during surgery vs . surviving the operation ) , Marteau also varied whether participants were instructed to adopt the role of the patient or treating doctor . She found that framing was more likely to occur when participants adopted the role of patient than when they were advising a patient in their role as doctor . In the latter context , framing occurred in only one of the three cases . This ﬁnding raises the possibility that when reasoning on their own behalf , doctors demonstrate the same bias as everyone else ( consistent with the ﬁndings of McNeil et al . 1982 ; see also Bornstein et al . 1999 ) ; yet when making recommendations on others’ behalf in their role as health - care professionals , they are less sus - ceptible to bias . Another possibility is that framing effects are simply somewhat idiosyncratic and hard to pin down . In support of this explanation , Christensen et al . ( 1995 ) presented medical decision makers with a larger number of treatment decisions ( n = 12 ) than previous studies and obtained a framing effect in only two of the 12 cases , leading them to conclude that the prevalence of framing effects in doctors’ treatment decisions may be more limited than thought previously . One of the two cases where a framing effect occurred concerned whether bacterial endocarditis and aortic insufﬁciency should be treated by valve replacement or antibiotics , and the other concerned whether non - malignant right pari - etal AVM should be treated by surgery or watchful waiting . A greater appreciation of the types of cases in which framing effects are most likely to occur would allow doctors to be more judicious in recom - mending speciﬁc treatments in those cases . Number of alternatives Research on framing effects has typically compared treatment choices between two options . However , other research has addressed potential bias that results from having multiple ( vs . few ) treatment alternatives . Such concerns are very important in this era of hundreds of therapy and medication options . Redelmeier & Shaﬁr ( 1995 ) looked at a large sample of family doctors’ ( N = 287 ) decisions in treating osteoarthritis and neurologists’ and neurosurgeons’ ( N = 352 ) recommendations for carotid artery surgery when presented with a variable number of options . For example , one of the scenarios presented to family doctors described a 67 - year - old man with chronic hip pain , diagnosed with osteoarthritis . Half the participants were asked to imagine that they had tried several non - steroidal anti - inﬂammatory drugs ( NSAIDs ) , all of which were ineffective ; that they had referred him to an orthopaedist for possible hip replacement , but that they then discovered there was one NSAID the patient had not yet tried ( ibuprofen ) . They were then asked whether they would refer the patient to orthopaedics and also start ibuprofen , or refer the patient without starting any new medication . The other half of the participants were given the same basic information but were told that there were two untried NSAIDs ( ibuprofen and piroxicam ) . Redelmeier & Shaﬁr ( 1995 ) found that adding a new option increased the probability of choosing a previously available alternative . When only one med - ication was available , 53 % chose the default option ( i . e . refer without medication ) , whereas 72 % chose the default option when two medications were available . They concluded that ‘the uncertainty in deciding between two similar medications led some doctors to avoid this decision altogether and recom - mend not starting any new medication’ ( p . 304 ) , even though the relative merits of starting a new medica - tion ( vs . not ) were identical in the two conditions . The default option becomes especially attractive when the additional option is clearly inferior to it – even though again , objectively , its relative merits ( com - pared to a pre - existing , non - inferior alternative ) are the same whether or not another alternative is con - sidered ( Schwartz & Chapman 1999 ) . 4 . Improving doctors’ reasoning The simplest approach to improving doctors’ deci - sion making is to educate them about the existence of the biases , on the assumption that an awareness of the biases will permit them to avoid being inﬂuenced by them ( Arnoult & Anderson 1988 ) . This strategy is not only logical , but it is also justiﬁed by research showing that continuing medical education in general tends to improve doctor performance across a variety of domains and outcomes ( Davis et al . 1995 ) . How successful , then , are attempts to ‘de - bias’ doctors’ decision making ? Although informing Rationality in medical decisions © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 103 B . H . Bornstein and A . C . Emler people about biases is not very effective at reducing biased reasoning in non - medical settings ( Fischhoff 1982 ) , there is some indication that it can improve doctors’ reasoning in some respects . For example , Gruppen et al . ( 1994 ) found that informing doctors about a speciﬁc bias – the tendency to be inﬂuenced by a treatment’s outcome valence in evaluating treat - ment decisions – reduced its effect . One of the more optimistic ﬁndings in this arena was provided by Bornstein et al . ( 1999 ) , who studied the sunk - cost bias , which is the tendency to allow pre - vious investments to have an irrational inﬂuence on future decisions ( e . g . a doctor who has invested a lot of time and effort in a particular treatment might be reluctant to change it , even though it is not working ) . They found that although doctors were susceptible to the bias in non - medical settings they did not demon - strate the sunk - cost effect in medical situations , sug - gesting that some aspect of their medical training made them immune to the bias within their domain of expertise . As the doctors in this study were not speciﬁcally instructed about the bias , these results suggest that an overemphasis on the ways in which doctors’ reasoning is suboptimal may be a case of viewing the glass as half - empty rather than half - full : that is , doctors might indeed be susceptible to some biases , but their training makes them less susceptible than they would otherwise be ( cf . Marteau 1989 ) . The type of strategy most effective at reducing bias will depend on the type of judgement that is being made . The movement toward ‘evidence - based medi - cine’ can be very helpful at reducing bias in the stages of gathering evidence and choosing treatments , because it advocates making the best available research evidence accessible in clinical settings ( Haynes & Haines 1998 ; McAlister et al . 2000 ) . Evidence - based medicine is effective at managing disease because it provides valid and current infor - mation on disease characteristics , co - ordinates efforts of an interdisciplinary team , reduces devia - tions from optimal practice and identiﬁes gaps in current knowledge ( Ellrodt et al . 1997 ) . In short , by providing the most relevant and objective empirical information available , and incorporating it with clin - ical expertise , test results and patient preferences , many of the biases associated with doctors’ relying too heavily on intuition and selectively attending to some information while ignoring other relevant information could be avoided ( Ellrodt et al . 1997 ; McAlister et al . 2000 ) . In comparison to evidence - based medicine , decision analysis is a similar , but somewhat more technical , approach to ameliorating biased reasoning . Decision analysis relies on ‘statistical prediction rules’ , which ‘use statistical analyses of cases with known outcomes to determine which pieces of diag - nostic information . . . are relevant to a given diag - nostic decision and to what extent’ ( Swets et al . 2000 , p . 2 ) . Such analyses , which are typically computer aided , can be applied to a variety of domains ; medical decision making has been singled out as an area which could especially proﬁt from decision analysis because it occurs within a highly dynamic and com - plex problem space and has important real - world consequences ( Kleinmuntz & Kleinmuntz 1981 ; Swets et al . 2000 ) . Swets et al . ( 1991 ) explored the utility of decision analysis in a diagnostic context by asking six radiol - ogists , all of whom had extensive experience in mam - mography , to interpret 146 mammograms that were known to include normal images and benign and malignant lesions . They read the set of images twice , ﬁrst in their usual manner , and then with two deci - sion aids : a checklist that guided the reader in assign - ing a scale value to a number of relevant features , and a computer program – based on the same scale values provided by the reader – that optimally estimated the probability of malignancy . Both times , the doctors were asked to estimate the probability of malignancy for each case . Despite receiving very little training in how to use the technique ( about 2 hours ) , the doctors’ diagnostic accuracy improved substantially when they used the decision aids . Similar gains result when applying computer - based decision aids to the process of diagnosing prostate cancer from magnetic resonance images or screening for HIV ( Swets et al . 2000 ) . In conclusion , decision analytic aids and evidence - based medicine can improve doctors’ decision - making performance by encouraging them to attend to the most relevant information and to assign that information its proper weight – even when the weightings come from the doctors them - selves ( Swets et al . 2000 ) . Unfortunately , although decision analysis can improve diagnostic accuracy in an experimental setting ( Swets et al . 1991 ; 2000 ) , 104 © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 doctors may be reluctant to use decision aids effec - tively in their everyday patient management ( Haynes & Haines 1998 ; Lee et al . 1995 ) . Instead , they tend to rely for assistance on clinical colleagues , manuals , and textbooks ( Curley et al . 1990 ) . One solution to this problem is to make evidence - based services and decision - enhancing tools more widely available and easily accessible in clinical settings , a trend which currently seems to be under way ( Haynes & Haines 1998 ) . In light of doctors’ demonstrated susceptibil - ity to a variety of biases in making diagnostic and treatment decisions , it is clear that further efforts to reduce possible biases and to improve the quality of medical decision making would be well worth the effort . References Arnoult L . H . & Anderson C . A . ( 1988 ) Identifying and reducing causal reasoning biases in clinical practice . In Reasoning , Inference , and Judgment in Clinical Psychol - ogy ( eds D . Turk & P . Salovey ) , pp . 209 – 232 . Free Press , New York . Arkes H . R . , Wortmann R . L . , Saville P . D . & Harkness A . R . ( 1981 ) Hindsight bias among physicians weighing the likelihood of diagnoses . Journal of Applied Psychology 66 , 252 – 254 . Ayanian J . Z . & Berwick D . M . ( 1991 ) Do physicians have a bias toward action ? A classic study revisited . Medical Decision Making 11 , 154 – 158 . Bakwin H . ( 1945 ) Pseudodoxia pediatrica . New England Journal of Medicine 232 , 691 – 697 . Bell D . E . , Raiffa H . & Tversky A . ( 1988 ) Decision Making : Descriptive , Normative , and Prescriptive Interactions . Cambridge University Press , Cambridge . Black W . C . & Welch G . ( 1993 ) Advances in diagnostic imaging and overestimations of disease prevalence and the beneﬁts of therapy . New England Journal of Medi - cine 328 , 1237 – 1243 . Bland J . M . & Altman D . G . ( 1994 ) Some examples of regres - sion towards the mean . British Medical Journal 309 , 780 . Bornstein B . H . , Emler A . C . & Chapman G . B . ( 1999 ) Ratio - nality in medical treatment decisions : is there a sunk - cost effect ? Social Science and Medicine 49 , 215 – 222 . Brooks L . R . , LeBlanc V . R . & Norman G . R . ( 2000 ) On the difﬁculty of noticing obvious features in patient appear - ance . Psychological Science 11 , 112 – 117 . Casscells W . , Schoenberger A . & Graboys T . B . ( 1987 ) Inter - pretation by physicians of clinical laboratory results . New England Journal of Medicine 299 , 999 – 1001 . Christensen C . , Heckerling P . , Mackesy - Amiti M . E . , Bernstein L . M . & Elstein A . S . ( 1995 ) Pervasiveness of framing effects among physicians and medical students . Journal of Behavioral Decision Making 8 , 169 – 180 . Christensen - Szalanski J . J . J . & Bushyhead J . B . ( 1981 ) Physi - cians’ use of probabilistic information in a real clinical setting . Journal of Experimental Psychology : Human Perception and Performance 7 , 928 – 935 . Christensen - Szalanski J . J . J . & Bushyhead J . B . ( 1983 ) Physi - cians’ misunderstanding of normal ﬁndings . Medical Decision Making 3 , 169 – 175 . Curley S . P . , Connelly D . P . & Rich E . C . ( 1990 ) Physicians’ use of medical knowledge resources : preliminary theo - retical framework and ﬁndings . Medical Decision Making 10 , 231 – 241 . Custers E . , Boshuizen H . & Schmidt H . G . ( 1996 ) The inﬂuence of medical expertise , case typicality , and illness script component on case processing and disease probability estimates . Memory and Cognition 24 , 384 – 399 . Davis D . A . , Thomson M . A . , Oxman A . D . & Haynes B . ( 1995 ) Changing physician performance : a systematic review of the effect of continuing medical education strategies . Journal of the American Medical Association 274 , 700 – 705 . Dawson N . V . & Arkes H . R . ( 1987 ) Systematic errors in medical decision making : judgment limitations . Journal of General Internal Medicine 2 , 183 – 187 . Dawson N . V . , Arkes H . R . , Siciliano C . , Blinkhorn R . , Lakshmanan M . & Petrelli M . ( 1988 ) Hindsight bias : an impediment to accurate probability estimation in clini - copathologic conferences . Medical Decision Making 8 , 259 – 264 . Detmer D . E . , Fryback D . G . & Gassner K . ( 1978 ) Heuris - tics and biases in medical decision - making . Journal of Medical Education 53 , 682 – 683 . Dolan J . G . ( 1999 ) A method for evaluating health care providers’ decision making : the Provider Decision Process Assessment instrument . Medical Decision Making 19 , 38 – 41 . Eddy D . M . ( 1982 ) Probabilistic reasoning in clinical medi - cine : problems and opportunities . In Judgment Under Uncertainty : Heuristics and Biases ( eds D . Kahneman P . Slovic & A . Tversky ) , pp . 249 – 267 . Cambridge University Press , Cambridge . Einhorn H . J . & Hogarth R . M . ( 1981 ) Behavioral decision theory : processes of judgment and choice . Annual Review of Psychology 32 , 53 – 88 . Ellrodt G . , Cook D . J . , Lee J . , Cho M . , Hunt D . & Wein - garten S . ( 1997 ) Evidence - based disease management . Journal of the American Medical Association 278 , 1687 – 1692 . Rationality in medical decisions © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 105 B . H . Bornstein and A . C . Emler Elstein A . S . ( 1988 ) Cognitive processes in clinical inference and decision making . In Reasoning , Inference , and Judg - ment in Clinical Psychology ( eds D . Turk & P . Salovey ) , pp . 17 – 50 . Free Press , New York . Elstein A . S . , Holzman G . B . , Ravitch M . M . , Metheny W . A . , Holmes M . M . , Hoppe R . B . , Rothert M . L . & Rovner D . R . ( 1986 ) Comparison of physicians’ decisions regard - ing estrogen replacement therapy for menopausal women and decisions derived from a decision analytic model . American Journal of Medicine 80 , 246 – 258 . Elstein A . S . , Shulman L . S . & Sprafka S . A . ( 1978 ) Medical Problem Solving : An Analysis of Clinical Reasoning . Harvard University Press , Cambridge , MA . Feinstein A . R . ( 1985 ) The ‘chagrin factor’ and qualitative decision analysis . Archives of Internal Medicine 145 , 1257 – 1259 . Fischhoff B . ( 1975 ) Hindsight π foresight : the effect of outcome knowledge on judgment under uncertainty . Journal of Experimental Psychology : Human Perception and Performance 1 , 288 – 299 . Fischhoff B . ( 1982 ) Debiasing . In Judgment Under Uncer - tainty : Heuristics and Biases ( eds D . Kahneman , P . Slovic & A . Tversky ) , pp . 422 – 444 . Cambridge University Press , Cambridge . Gruppen L . D . , Margolin J . , Wisdom K . & Grum C . M . ( 1994 ) Outcome bias and cognitive dissonance in evaluating treatment decisions . Academic Medicine 69 , S57 – S59 . Hammond K . R . ( 1996 ) How convergence of research par - adigms can improve research on diagnostic judgment . Medical Decision Making 16 , 281 – 287 . Haynes B . & Haines A . ( 1998 ) Getting research ﬁndings into practice : barriers and bridges to evidence based clinical practice . British Medical Journal 317 , 273 – 276 . Heath L . , Acklin M . & Wiley K . ( 1991 ) Cognitive heuris - tics and AIDS risk assessment among physicians . Journal of Applied Social Psychology 21 , 1859 – 1867 . Hershberger P . J . , Part H . M . , Markert R . J . , Cohen S . M . & Finger W . W . ( 1994 ) Development of a test of cognitive bias in medical decision making . Academic Medicine 69 , 839 – 842 . Joseph G . - M . & Patel V . L . ( 1990 ) Domain knowledge and hypothesis generation in diagnostic reasoning . Medical Decision Making 10 , 31 – 46 . Kahneman D . , Slovic P . & Tversky A . ( 1982 ) Judgment Under Uncertainty : Heuristics and Biases . Cambridge University Press , Cambridge . Kahneman D . & Tversky A . ( 1982 ) The simulation heuris - tic . In Judgment Under Uncertainty : Heuristics and Biases ( eds D . Kahneman , P . Slovic & A . Tversky ) , pp . 201 – 208 . Cambridge University Press , Cambridge . Klayman J . & Brown K . ( 1993 ) Debias the environment instead of the judge : an alternative approach to reducing error in diagnostic ( and other ) judgment . In Reasoning and Decision Making ( eds P . N . Johnson - Laird & E . Shaﬁr ) , pp . 97 – 122 . Blackwell , Cambridge . Kleinmuntz D . N . & Kleinmuntz B . ( 1981 ) Systems simula - tion decision strategies in simulated environments . Behavioral Science 26 , 294 – 305 . Lee T . H . , Pearson S . D . , Johnson P . A . , Garcia T . B . , Weisberg M . C . , Guadagnoli E . , Cook E . F . & Goldman L . ( 1995 ) Failure of information as an intervention to modify clinical management : a time - series trial in patients with acute chest pain . Annals of Internal Medicine 122 , 434 – 437 . Marteau T . M . ( 1989 ) Framing of information : its inﬂuence upon decisions of doctors and patients . British Journal of Social Psychology 28 , 89 – 94 . Mazur D . J . & Hickam D . H . ( 1990 ) Treatment preferences of patients and physicians : inﬂuences of summary data when framing effects are controlled . Medical Decision Making 10 , 2 – 5 . McAlister F . A . , Straus S . E . , Guyatt G . H . & Haynes R . B . ( 2000 ) Users’ guides to the medical literature : XX . Inte - grating research evidence with the care of the individual patient . Journal of the American Medical Association 283 , 2829 – 2836 . McNeil B . J . , Pauker S . G . , Sox H . C . & Tversky A . ( 1982 ) On the elicitation of preferences for alternative therapies . New England Journal of Medicine 306 , 1259 – 1262 . McNeil B . J . , Pauker S . G . & Tversky A . ( 1988 ) On the framing of medical decisions . In Decision Making ( eds D . E . Bell , H . Raiffa & A . Tversky ) , pp . 562 – 568 . Cambridge University Press , Cambridge . Medin D . L . , Altom M . W . , Edelson S . M . & Freko D . ( 1982 ) Correlated symptoms and simulated medical classiﬁca - tion . Journal of Experimental Psychology : Learning , Memory , and Cognition 8 , 37 – 50 . Moskowitz A . J . , Kuipers B . J . & Kassirer J . P . ( 1988 ) Dealing with uncertainty , risks , and tradeoffs in clinical decisions : a cognitive science approach . Annals of Internal Medi - cine 108 , 435 – 449 . Poses R . M . & Anthony M . ( 1991 ) Availability , wishful thinking , and physicians’ diagnostic judgments for patients with suspected bacteremia . Medical Decision Making 11 , 159 – 168 . Redelmeier D . A . , Rozin P . & Kahneman D . ( 1993 ) Under - standing patients’ decisions : cognitive and emotional perspectives . Journal of the American Medical Associa - tion 270 , 72 – 76 . Redelmeier D . A . & Shaﬁr E . ( 1995 ) Medical decision making in situations that offer multiple alternatives . 106 © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 Journal of the American Medical Association 273 , 302 – 305 . Schwartz J . A . & Chapman G . B . ( 1999 ) Are more options always better ? The attraction effect in physicians’ deci - sions about medications . Medical Decision Making 19 , 315 – 323 . Shapiro A . R . ( 1977 ) The evaluation of clinical predictions : a method and initial application . New England Journal of Medicine 296 , 1509 – 1514 . Sherbourne C . D . , Sturm R . & Wells K . B . ( 1999 ) What out - comes matter to patients ? Journal of General Internal Medicine 14 , 357 – 363 . Spranca M . , Minsk E . & Baron J . ( 1991 ) Omission and com - mission in judgment and choice . Journal of Experimen - tal Social Psychology 27 , 76 – 105 . Swets J . A . , Dawes R . M . & Monahan J . ( 2000 ) Psychologi - cal science can improve diagnostic decisions . Psycholog - ical Science in the Public Interest 1 , 1 – 26 . Swets J . A . , Getty D . J . , Pickett R . M . , D’Orsi C . J . , Seltzer S . E . & McNeil B . J . ( 1991 ) Enhancing and evaluating diagnostic accuracy . Medical Decision Making 11 , 9 – 18 . Tversky A . & Kahneman D . ( 1974 ) Judgment under uncer - tainty : heuristics and biases . Science 185 , 1124 – 1131 . Tversky A . & Kahneman D . ( 1988 ) Rational choice and the framing of decisions . In Decision Making ( eds D . E . Bell , H . Raiffa & A . Tversky ) , pp . 167 – 192 . Cambridge Uni - versity Press , Cambridge . Wallsten T . S . ( 1981 ) Physician and medical student bias in evaluating diagnostic information . Medical Decision Making 1 , 145 – 164 . Rationality in medical decisions © 2001 Blackwell Science , Journal of Evaluation in Clinical Practice , 7 , 2 , 97 – 107 107