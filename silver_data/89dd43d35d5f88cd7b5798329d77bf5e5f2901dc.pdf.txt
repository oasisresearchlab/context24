Word2vec Conjecture and A Limitative Result Falcon Z . Dai Toyota Technological Institute at Chicago Chicago , USA dai @ ttic . edu Abstract Being inspired by the success of word2vec ( Mikolov et al . , 2013 ) in capturing analogies , we study the conjecture that analogical rela - tions can be represented by vector spaces . Un - like many previous works that focus on the distributional semantic aspect of word2vec , we study the purely representational question : can all semantic word - word relations be rep - resented by di ﬀ erences ( or directions ) of vec - tors ? We call this the word2vec conjecture and point out some of its desirable implications . However , we will exhibit a class of relations that cannot be represented in this way , thus fal - sifying the conjecture and establishing a limita - tive result for the representability of semantic relations by vector spaces over ﬁelds of char - acteristic 0 , e . g . , real or complex numbers . 1 Introduction Mikolov et al . ( 2013 ) have inspired a wave of excitement in natural language processing ( NLP ) research—much of which is still being felt today— that relies on some notion of distributional seman - tics ( Firth , 1957 ) and emphasizes learning from large corpora . As the plain yet memorable name of its codebase word2vec suggests , Mikolov et al . ( 2013 ) describes a learning - based method to rep - resent words with vectors ( in a ﬁnite - dimensional inner product vector space ) . Furthermore , perhaps most surprisingly , Mikolov et al . ( 2013 ) discovered that many analogies in the form of “ a is to b as c is to d ” are captured by the arithmetics in the representation vector space . Many excellent sub - sequent works ( Pennington et al . , 2014 ; Levy and Goldberg , 2014 ; Arora et al . , 2016 ) have studied this empirical phenomenon and provide some theo - retical explanations for the emergence of semantic analogies from a training objective based on esti - mating distribution of context words . We , on the other hand , study a purely representational question inspired by , and generalized from the original obser - vation . Can we represent words as vectors and all of their analogical relations as vector di ﬀ erences ? This question is purely representational because we are only concerned with if such representation is possible ignoring how to obtain them from corpus statistics . This is a generalization because we ask if this is true for all analogical relations . We call this question the word2vec conjecture to signify its origin and representations by vector spaces , but we do not suggest that the original work ( Mikolov et al . , 2013 ) claimed or relied on the conjecture being true . At the core of the word2vec conjecture , it is a concern whether the vector space structure su ﬃ ces to capture the structure of semantic relations . Per - haps not surprisingly to some readers , representing relations as vectors has its limitations . We will focus on a concrete limitation when trying to repre - sent group - like relations with vectors : the relations can loop around but vectors cannot due to linearity . We will use , as a simple but illustrative example , the successor relation over weekdays , i . e . , “ a is the weekday immediately after b ” , and the relations generated by it , e . g . , “ a is the second weekday after b ” ( see Section 3 . 2 ) . These relations form a cyclic group of order 7 as weekdays repeat themselves every seven days and , in particular , the successor relation is of order 7 . However no nonzero vector over a ﬁeld of characteristic 0 is of order 7 , thus forcing all the relations to be represented as the zero vector ( of order 1 ) . Despite the negative results , this work is primar - ily motivated by the positive goal of improving al - gorithmic natural language understanding . Accord - ingly , we will ﬁrst motivate and formulate the prob - lem of representing relations ( Section 3 . 1 ) . Then we formalize the vector representation of relations and pose the word2vec conjecture ( Section 3 . 4 ) . We will discuss some desirable implications of the a r X i v : 2010 . 12719v1 [ c s . C L ] 24 O c t 2020 conjecture . Then we will show a limitative result by exhibiting loopy semantic relations that cannot be represented by vector spaces ( Section 4 . 2 ) . Lastly we provide an extended discussion ( Section 5 ) . In the interest of self - containedness , we review the relevant algebraic concepts in the appendix ( Ap - pendix A and B ) . Our main contributions are two - fold . • We show that some semantic relations cannot be represented by vector spaces , thus showing a fundamental limitation of word2vec . • By using algebraic arguments to establish the limitative result , we demonstrate the utility of algebraic arguments in the study of semantic representations . 2 Related work Prior to word2vec , Turney and Littman ( 2005 ) ; Turney and Pantel ( 2010 ) studied representing words as vectors and relations as matrices . This is not a relation - as - vector representation and , in fact , can represent relations with a group structure ( see Section 5 . 3 ) . The conjecture that we propose and answer is similar in spirit to their concerns on the limitations of representations ( see Section 8 ( Turney and Pantel , 2010 ) ) . One major di ﬀ erence between the learning method of Turney and Pantel ( 2010 ) and that of Mikolov et al . ( 2013 ) is char - acterized as the count vs . prediction issue and is studied extensively ( Baroni et al . , 2014 ; Penning - ton et al . , 2014 ) . Basing on the connection to the ratio of conditional distributions noted by Mikolov et al . ( 2013 ) and by extension , to pointwise mu - tual information ( PMI ) ( Church and Hanks , 1990 ) , Levy and Goldberg ( 2014 ) studied building vector representation of relations explicitly . This work provides a limitative result for such e ﬀ orts , learn - ing or not . We will specialize our arguments to the ratio of conditional distributions , a common charac - terization of word2vec , to convey more concrete intuitions ( see Section 4 . 3 ) . Arora et al . ( 2016 ) studied rigorously the consequence of prediction under the choice of small dimensionality and pro - vided additional insight on learning word - vector representations by extending a theoretical model of word generation proposed by Mnih and Hinton ( 2007 ) . We note that due to the similarity mea - sures used by Mikolov et al . ( 2013 ) ; Arora et al . ( 2016 ) , relations are represented as directions and lines , respectively , instead of vectors . A conscious simpliﬁcation is made to focus on vectors with the hope to convey the main ideas more smoothly ( see Section 5 . 4 ) . 3 Formalism 3 . 1 Words and relations Short of a persuasive formal deﬁnition of linguistic understanding , we will posit a weak consequence . Postulate . If someone understands a collection of words , then he or she can correctly answer ques - tions about relations over those words . These relations can mirror physical relations which is of interest in grounding research but they can arise from other sources . More importantly , regardless of the sources of these relations , we can study the structure of them in abstract . Ultimately it is the structure of relations that we wish to ad - equately represent in some mathematical objects for manipulation and computation . As an exam - ple , consider the weekdays . If someone claims to understand the weekdays , then we expect them to correctly answer questions such as “Does Tues - day follow Monday ? ” and “Is Sunday the second weekday after Friday ? ” . Problem setting . Formally , given a set of words ( concepts ) W , and a set of binary relations R where r ∈ R is a subset of W × W . 1 We want to ﬁnd a representation ( W , R , E , ϕ ) such that ϕ : R → E nontrivially preserves the structure of R , i . e . , a nontrivial homomorphism . 3 . 2 Example of Weekdays Let W (cid:66) (cid:8) “Monday” , “Tuesday” , · · · , “Sunday” (cid:9) . Consider the usual successor relation s over the weekdays , e . g . , (cid:0) “Monday” , “Tuesday” (cid:1) ∈ s and (cid:0) “Monday” , “Sunday” (cid:1) (cid:60) s . Consider a rela - tion composition operation ◦ that constructs a relation out of two relations . Let r ◦ r (cid:48) (cid:66) { ( w , w (cid:48) ) : ∃ w (cid:48)(cid:48) . ( w , w (cid:48)(cid:48) ) ∈ r and ( w (cid:48)(cid:48) , w (cid:48) ) ∈ r (cid:48) } . The successor relation generates other relations by com - posing with itself , e . g . , s 2 = s ◦ s which intu - itively says whether w (cid:48) is the second weekday af - ter w . In this fashion , we can generate relation s k = s ◦ · · · ◦ s (cid:124) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) k times where ( w , w (cid:48) ) ∈ s k i ﬀ w (cid:48) is the k - th weekday after w . However , as weekdays repeat themselves every seven days , we have s k = s (cid:96) i ﬀ k ≡ (cid:96) ( mod 7 ) . Hence collecting all powers of s results in a set R (cid:66) (cid:110) s , s 2 , · · · , s 7 (cid:111) , a set of seven 1 We will focus on binary relations for the rest of the article and specialize relations to mean binary relations . binary relations . In fact , R is a cyclic group of order 7 ( see Appendix C for a proof ) . Proposition 3 . 1 . R = (cid:110) s , s 2 , · · · , s 7 (cid:111) together with composition ◦ forms a group isomorphic to Z 7 . 3 . 3 Relation - as - vector representations Suppose ( W , R , V , ϕ ) embeds words to a vector space over the reals V via the embedding map ϕ : W → V . Motivated by the empirical observation of emergence of relations as di ﬀ erences of word - vectors ( Mikolov et al . , 2013 ) , we call ( W , R , V , ϕ ) a relation - as - vector representation if for any rela - tion r ∈ R , we have ϕ ( b ) − ϕ ( a ) = ϕ ( d ) − ϕ ( c ) for any a , b , c , d ∈ W satisfying ( a , b ) ∈ r and ( c , d ) ∈ r . With a slight abuse of notations , we will denote this relation - vector as ϕ ( r ) = ϕ ( b ) − ϕ ( a ) ∈ V . 2 Lastly , we say that a set of relations R is well - represented by ( V , R , ϕ ) if ϕ ( r ) (cid:44) ϕ ( s ) for all r (cid:44) s ∈ R , i . e . , we can distinguish distinct relations . 3 . 4 Word2vec conjecture We ask whether relation - as - vector representation can universally represent any relations . Conjecture . Can all binary relations over words be well - represented by some relation - as - vector rep - resentation ? 3 . 5 An implication for metalinguistics Besides the potential in applications such as solv - ing analogical queries ( Mikolov et al . , 2013 ) , the recursiveness of representations of both words and relations might inspire interesting questions that are metalinguistic in nature . For example , if our conjecture is true—relations are representable as vectors— , then how about higher - order relations , i . e . , relations between relations ? Can they all be represented in the same way , i . e . , as vectors ? It is precisely this possibility that initiated our study of the current problem . 4 Results We will answer the conjecture in the negative in two steps . The ﬁrst is about algebraic structures , resulting in a general negative result ( Theorem 4 . 1 ) , and the second is an empirical observation about the existence of certain class of semantic relations . 4 . 1 Algebraic aspects of semantics Note that by the deﬁnition of relation - as - vector representation , ϕ is a homomorphism from ( R , ◦ ) 2 ϕ is a category theoretic functor in disguise . to the abelian group ( V , + ) . Suppose r , r (cid:48) ∈ R and ϕ ( r ) = ϕ ( c ) − ϕ ( b ) and ϕ ( r (cid:48) ) = ϕ ( b ) − ϕ ( a ) for some a , b , c ∈ W , then ϕ ( r ◦ r (cid:48) ) = ϕ ( c ) − ϕ ( b ) + ϕ ( b ) − ϕ ( a ) = ϕ ( r ) + ϕ ( r (cid:48) ) . This key observation means that in a relation - as - vector representation , we cannot assign two arbi - trary vectors to represent two relations if the two relations are compositionally related to each other . In particular , the identity relation , i . e . , ( w , w (cid:48) ) ∈ e i ﬀ w = w (cid:48) , has to be assigned the zero vector . And an inverse relation would have the negative relation - vector so they sum to the zero vector . In order to prove that no good representation exists , our strategy is to ﬁnd that some algebraic in - variants , which are preserved by homomorphisms , are not equal in ( R , ◦ ) and in ( V , + ) . Therefore no ϕ can well represent the given relations . 4 . 2 Orders and cyclic relations Consider the order of a group element ( see Ap - pendix A ) . It is a basic fact that the order of its homomorphic image in H divides its order in G , i . e . , | ϕ ( r ) | divides | r | ( see Proposition A . 1 ) . This fact is useful because the only element in a vector space over real numbers with a ﬁnite order is the zero vector . It has order of one | 0 | = 1 . Theorem 4 . 1 . If the given relations contains a re - lation r with a nontrivial ﬁnite order , i . e . , | r | (cid:44) 1 and | r | < ∞ , then they cannot be well - represented by any relation - as - vector representation using a vector space over a ﬁeld of characteristic 0 , e . g . , real or complex numbers . The key idea is that any homomorphism ϕ would have to represent all powers of r with the zero vector , thus failing to encode them distinctly ( see Appendix D for a detailed proof ) . Now , it remains to exhibit that there are semantic relations with a nontrivial ﬁnite order ( whose pow - ers forms cyclic groups ) . Conveniently , Weekdays provides such an example : the successor relation s is of order 7 . Similarly , many temporal concepts exhibit cyclic relations such as Z 12 for the months , Z 24 for the hours . An interesting non - temporal example are the antonyms , over which a parity re - lation is of order 2 . 4 . 3 Specialization to ratios of conditional distributions Due to the continuous bag of words ( CBOW ) learn - ing procedure used in ( Mikolov et al . , 2013 ) , it is suggested that the word - vector of w in word2vec is an approximation of the logarithm of the condi - tional distributions of context words around w . Sup - pose the space of context words is C and the prob - ability of a context word c ∈ C appearing near w is P [ c | w ] , then the speciﬁc relation - as - vector repre - sentation suggested is ( W , R , V ( C ) , ψ ) where V ( C ) is the free real vector space generated by C and ψ : W → V ( C ) : w (cid:55)→ (cid:0) c (cid:55)→ log P [ c | w ] (cid:1) . Then a relation r ∈ R is represented by the logarithm of the ratio of conditional distributions over each context word ψ ( r ) = ψ ( w (cid:48) ) − ψ ( w ) = (cid:0) c (cid:55)→ log P (cid:2) c | w (cid:48) (cid:3) − log P [ c | w ] (cid:1) = (cid:32) c (cid:55)→ log P [ c | w (cid:48) ] P [ c | w ] (cid:33) where ( w , w (cid:48) ) ∈ r . Note that the general conclusion of Theorem 4 . 1 applies to this speciﬁc relation - as - vector represen - tation : ψ cannot well - represent a loopy relation . However , we can specialize the analysis to ψ in the hope of gaining more intuition . Suppose over some context word c , some non - identity relation r has a nonzero coordinate , i . e . , P [ c | w (cid:48) ] P [ c | w ] (cid:44) 1 , otherwise r is the identity relation and ψ ( r ) = 0 . Any positive power of r , r k for k > 0 , would have a nonzero coordinate at c as (cid:18) P [ c | w (cid:48) ] P [ c | w ] (cid:19) k (cid:44) 1 . Therefore ψ (cid:16) r k (cid:17) (cid:44) 0 and ψ ( r ) cannot have a ﬁnite order . Intuitively , the ratio of distributions of context words is monotonic with respect to the power and thus cannot wrap around . 5 Discussion 5 . 1 Other limitations and examples Another representational limitation of vector space , being an abelian group , is that it cannot well - represent non - commutative relations . For example , consider longitude - latitude locations on the globe and translational relations . Due to the spherical geometry , going eastward for 10 miles then going northward for 10 miles is not the same as going north ﬁrst then east . The general deﬁciency of the vector space struc - ture to represent other algebraic structures de - scribed in this work applies to other “X2vec” meth - ods ( some outside of natural language processing ) . 5 . 2 Relevance to learning Broadly speaking in learning problems , there is usu - ally some target x ∗ within some hypothesis class to be learned from data , and the learned hypoth - esis ˆ x is approximately correct due to the limited data or computation . In this perspective , what we show with Theorem 4 . 1 is that certain semantic rela - tions does not correspond to any x ∗ within relation - as - vector representations . Practically for natural language understanding applications , we have to consider whether the representation class ( and al - gorithms ) is structurally compatible with the class of semantic relations . 5 . 3 Possible solutions Based on Cayley’s theorem and basic represen - tation theory , invertible square matrices would well represent relations exhibiting group structures . Less generally , for cyclic relations exhibiting Z k structure , we can represent the successor relation with the scalar multiplication by complex number e 2 π i / k . These solutions are not relation - as - vector representations . 5 . 4 Revisiting word2vec An expert reader might point out that due to the cosine similarity used in word2vec , a relation is represented by a direction ( and in the case of Arora et al . ( 2016 ) , a line due to squaring ) . However , this di ﬀ erence does not break our cyclic examples as directions or lines can be thought as quotient vector spaces where vectors of positive multiple of each other are identiﬁed , or those of nonzero multiple , respectively . 5 . 5 Analogy and abstract algebra Analogies and metaphors are important linguistic phenomena that relate one domain of concepts and relations to another in a way that preserves ( some of ) its structure . Some researchers argue that it is a key mechanism in linguistic understanding ( Falkenhainer et al . , 1989 ; Hofstadter and Mitchell , 1995 ; Lako ﬀ and Johnson , 2008 ) . Technically one can model the mechanism of analogy as algebraic structure - preserving maps , i . e . , homomorphisms . This work suggests an algebraic theory of se - mantics would be helpful , perhaps necessary , for studying structures in semantic representations . We leave the problem of learning ( discovering ) group - like semantic relations to future work . Note that identifying two groups ( known as the group iso - morphism problem ) are undecidable in general . Acknowledgments We thank David McAllester for discussions on word2vec . We thank Zheng Cai for discussions on linguistic analogy . We thank David Yunis for read - ing an early version of this work . Lastly , we thank an anonymous reviewer for constructive feedback and encouragement on an earlier version which led to an improved presentation . References Sanjeev Arora , Yuanzhi Li , Yingyu Liang , Tengyu Ma , and Andrej Risteski . 2016 . A latent variable model approach to pmi - based word embeddings . Transac - tions of the Association for Computational Linguis - tics , 4 : 385 – 399 . Marco Baroni , Georgiana Dinu , and Germ´an Kruszewski . 2014 . Don’t count , predict ! a systematic comparison of context - counting vs . context - predicting semantic vectors . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) , pages 238 – 247 . Kenneth Ward Church and Patrick Hanks . 1990 . Word association norms , mutual information , and lexicog - raphy . Computational linguistics , 16 ( 1 ) : 22 – 29 . Brian Falkenhainer , Kenneth D . Forbus , and Dedre Gentner . 1989 . The structure - mapping engine : Algorithm and examples . Artiﬁcial Intelligence , 41 ( 1 ) : 1 – 63 . John R Firth . 1957 . A synopsis of linguistic theory , 1930 - 1955 . Studies in linguistic analysis . Douglas Richard Hofstadter and Melanie Mitchell . 1995 . The copycat project : a model of mental ﬂu - idity and analogy - making . George Lako ﬀ and Mark Johnson . 2008 . Metaphors We Live By . University of Chicago Press . Omer Levy and Yoav Goldberg . 2014 . Linguistic regularities in sparse and explicit word representa - tions . In Proceedings of the Eighteenth Confer - ence on Computational Natural Language Learning , page 171 – 180 . Association for Computational Lin - guistics . Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Cor - rado , and Je ﬀ Dean . 2013 . Distributed representa - tions of words and phrases and their compositional - ity . In Advances in neural information processing systems , pages 3111 – 3119 . Andriy Mnih and Geo ﬀ rey Hinton . 2007 . Three new graphical models for statistical language modelling . In Proceedings of the 24th international conference on Machine learning , pages 641 – 648 . ACM . Je ﬀ rey Pennington , Richard Socher , and Christopher Manning . 2014 . Glove : Global vectors for word representation . In Proceedings of the 2014 Con - ference on Empirical Methods in Natural Language Processing ( EMNLP ) , page 1532 – 1543 . Association for Computational Linguistics . Peter D . Turney and Michael L . Littman . 2005 . Corpus - based learning of analogies and semantic relations . Machine Learning , 60 ( 1 ) : 251 – 278 . Peter D Turney and Patrick Pantel . 2010 . From fre - quency to meaning : Vector space models of se - mantics . Journal of artiﬁcial intelligence research , 37 : 141 – 188 . A Elementary group theory Deﬁnition A . 1 ( Group ) . A group is a set G to - gether with a binary operation ( group multiplica - tion ) · : G × G → G that satisﬁes the following axioms . As a convention , we write gh = g · h when there is no ambiguity . • ( identity ) There is an element e ∈ G such that for any x ∈ G , xe = x . We denote the ( right - ) identity with e as the left - and right - identity are the same and unique . • ( associativity ) For any x , y , z ∈ G , we have ( xy ) z = x ( yz ) . So conveniently , we can write their product as xyz without ambiguity . • ( inverses ) For any x ∈ G , there is some y ∈ G such that xy = e . We denote the ( right - ) inverse of x as x − 1 = y as y is unique and the left - and right - inverses are the same for x . Similarly to a group , a monoid might not have in - verses , and a semigroup might not have an identity or inverses . Group multiplication is generally not commutative , and we say a group is abelian if its group multiplication is commutative , i . e . , ab = ba . Furthermore , we commonly denote the group mul - tiplication with addition to emphasize its commuta - tivity , e . g . , integers with the usual addition ( Z , + ) forms an abelian group . The order of a group element x ∈ G is the small - est positive power of x that is identity , denoted by | x | (cid:66) min  n ∈ Z > 0 : x n = x · · · x (cid:124)(cid:123)(cid:122)(cid:125) n times = e  . If no posi - tive power of x is equal to e , then we say that the order of x is inﬁnite and denote | x | = ∞ . Deﬁnition A . 2 ( Group homomorphism ) . Given two groups ( G , · G ) and ( H , · H ) , we call a map ϕ : G → H a ( group ) homomorphism if for any a , b ∈ G ϕ ( a · G b ) = ϕ ( a ) · H ϕ ( b ) . Furthermore , if ϕ is bijective then we say ϕ is an isomorphism and G is isomorphic to G , denoted by G (cid:27) H . Proposition A . 1 . Given two groups G and H and a homomorphism ϕ : G → H between them , for any g ∈ G , we have | ϕ ( g ) | divides | g | . Proof . It is not hard to see that a homomorphism maps the identity in G to the identity in H . Suppose | g | = n then ϕ ( g n ) = ϕ ( e G ) = e H = ϕ ( g ) n . This implies that | ϕ ( g ) | divides n . (cid:3) If ϕ is an isomorphism , then | ϕ ( g ) | = | g | . B Fields and vector spaces A ﬁeld F is a set equipped with addition ( with iden - tity denoted by 0 ) and multiplication ( with identity denoted as 1 ) and multiplicative inverses exist for nonzero elements . Furthermore , both addition and multiplication are commutative and they follow the distributive law . Common examples are the ratio - nals Q , the reals R , the complex C and ﬁnite ﬁelds of prime order Z / p Z . Note that the integers Z is not a ﬁeld due to the missing multiplicative inverses . The characteristic of a ﬁeld F is deﬁned to be the smallest integer k such that 1 + · · · + 1 (cid:124) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) k times = 0 and if no such k exists , then we say that F has characteristic 0 . For example , R has characteristic 0 , and Z / p Z has characteristic p . A vector space V over a ﬁeld F ( also called a left F - module ) consists of an abelian group ( V , + ) with the identity element denoted as the zero vector 0 and a scalar multiplication · : F × V → V that plays nicely with addition and multiplication of F . A free F - vector space generated over a set S is a F - vector space with S as its basis . Thus its dimen - sionality is the size of S . Generally speaking , a free object is a “generic” object containing its gen - erating set that is free of any additional conditions and satisfying only those in the deﬁnition of that class of objects . C Proof of Proposition 3 . 1 Proof . First , we check that the relation composi - tion operation ◦ is associative over the successor relation s . If ( w , w (cid:48) ) ∈ ( s ◦ s ) ◦ s , then by deﬁni - tion , there is some u ∈ W such that ( w , u ) ∈ s ◦ s and ( u , w (cid:48) ) ∈ s . Again by deﬁnition , there is some v ∈ W such that ( w , v ) ∈ s and ( v , u ) ∈ s . This im - plies that ( v , w (cid:48) ) ∈ s ◦ s and ( w , w (cid:48) ) ∈ s ◦ ( s ◦ s ) . Sim - ilarly , we can show the reverse . Hence , ( w , w (cid:48) ) ∈ ( s ◦ s ) ◦ s i ﬀ ( w , w (cid:48) ) ∈ s ◦ ( s ◦ s ) , and we have ( s ◦ s ) ◦ s = s ◦ ( s ◦ s ) . This justiﬁes the notation for powers of s as s k in Section 3 . 2 . Second , s 7 ∈ R is the identity relation , i . e . , ( w , w (cid:48) ) ∈ s 7 i ﬀ w = w (cid:48) since weekdays repeat themselves every seven days . And for any binary relation r , ( w , w (cid:48) ) ∈ r i ﬀ ( w , w (cid:48) ) ∈ r ◦ s 7 , so r ◦ s 7 = r . Moreover , since r = s k for some k , we have s k = s (cid:96) i ﬀ k ≡ (cid:96) ( mod 7 ) . Accordingly , we can write the identity as s 0 = s 7 . Third , we have inverses . For any s k , choose (cid:96) so that k + (cid:96) ≡ 7 ( mod 7 ) , then s k ◦ s (cid:96) = s k + (cid:96) = s 0 . Fourth , we show that Weekdays is isomorphic to Z 7 = ( Z / 7 Z , + ) . Consider a map ϕ : Weekdays → Z 7 : s k (cid:55)→ k ( mod 7 ) . This is a homomorphism as ϕ (cid:16) s k ◦ s (cid:96) (cid:17) = ϕ (cid:16) s k + (cid:96) (cid:17) = k + (cid:96) = ϕ (cid:16) s k (cid:17) + ϕ (cid:16) s (cid:96) (cid:17) . ϕ is clearly injective , and surjective as Z 7 also has 7 elements . Therefore ϕ is an isomorphism . (cid:3) D Proof of Theorem 4 . 1 Proof . First , F - vector space V with addition is an abelian group . The identity is the zero vector de - noted by 0 whose order is 1 . If F has characteristic 0 , then by deﬁnition , for any nonzero vector v ∈ V and any k > 0 we have ( 1 + · · · + 1 (cid:124) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) k times ) v = v + · · · + v (cid:124) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) k times (cid:44) 0 . Thus any nonzero vector in V has order inﬁnite . Together with Proposition A . 1 , any homomorphism ϕ can only map a relation with nontrivial ﬁnite or - der to the zero vector , i . e . , ϕ ( r ) = 0 . But this implies that all powers are mapped to the zero vec - tor ϕ (cid:16) r k (cid:17) = ϕ ( r ) + · · · + ϕ ( r ) (cid:124) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) k times = 0 + · · · + 0 (cid:124) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125) k times = 0 . Therefore ϕ do not distinguish the powers of r . (cid:3)