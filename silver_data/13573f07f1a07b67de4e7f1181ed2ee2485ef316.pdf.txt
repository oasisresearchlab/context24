Robot - Supported Information Search : Which Conversational Interaction Style do Children Prefer ? Suyash Sharma s . sharma - 6 @ student . utwente . nl University of Twente Enschede , The Netherlands Thomas Beelen t . h . j . beelen @ utwente . nl University of Twente Enschede , The Netherlands Khiet P . Truong k . p . truong @ utwente . nl University of Twente Enschede , The Netherlands ABSTRACT Searching via speech with a robot can be used to better support children in expressing their information needs . We report on an exploratory study where children ( N = 35 ) worked on search tasks with two robots using different interaction styles . One system posed closed , yes / no questions and was more system - driven while the other system used open - ended questions and was more user - driven . We studied children’s preferences and experiences of these interac - tion styles using questionnaires and semi - structured interviews . We found no overall strong preference between the interaction styles . However , some children reported task - dependent preferences . We further report on children’s interpretation and reasoning around interaction styles for robots supporting information search . CCS CONCEPTS • Human - centered computing → Empirical studies in HCI ; Natural language interfaces ; User studies ; • Information systems → Search interfaces . KEYWORDS Conversational agents , conversational search , children , robots , clar - ifying questions , dialog systems . ACM Reference Format : SuyashSharma , ThomasBeelen , andKhietP . Truong . 2023 . Robot - Supported Information Search : Which Conversational Interaction Style do Children Prefer ? . In Companion of the 2023 ACM / IEEE International Conference on Human - Robot Interaction ( HRI ’23 Companion ) , March 13 – 16 , 2023 , Stockholm , Sweden . ACM , New York , NY , USA , 5 pages . https : / / doi . org / 10 . 1145 / 3568294 . 3580128 1 INTRODUCTION Despite being digital natives , most children today face difficulties trying to access information on the internet . This is in large due to the fact that current search engines were mainly designed keep - ing adults in mind - adults who can formulate and communicate queries effectively . There exist clear differences in how adults and children approach searching for information . Research shows that children tend to make more web moves , loop searches and hyper - links , backtrack and deviate more often from their target . They do not follow the more linear approach that adults do [ 7 ] . In a ThisworkislicensedunderaCreativeCommonsAttributionInternational4 . 0 License . HRI ’23 Companion , March 13 – 16 , 2023 , Stockholm , Sweden © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 9970 - 8 / 23 / 03 . https : / / doi . org / 10 . 1145 / 3568294 . 3580128 study by Druin et al . [ 8 ] , a child reported “It’s hard because you have to find the right words to put in the box . ” . In addition to this , their spelling , vocabulary , punctuation , and grammar skills are still developing . All these factors affect their abilities to form effective queries [ 11 ] . Children are still developing their problem solving capabilities . This points to the need for them to be assisted with their problem solving . This is also supported by research by Gossen et al . [ 10 ] which shows that children pay more attention to tools such as suggested queries than adults . Presently , methods to as - sist with query formulation for information retrieval for children include query expansion and query suggestions , but these do not meet children’s needs and expectations [ 9 ] . Using a conversational agent could prove to be a good inter - face that children could use to retrieve information as proposed by multiple researchers [ 3 , 4 , 12 , 17 ] . Using a physically embod - ied conversational agent , i . e . , a robot , could add benefits to the interaction as research has shown that more positive effects are associated with an agent’s physical embodiment [ 5 , 13 ] . We en - vision children communicating their needs in natural language , which is found to be their preference [ 11 ] , in interaction with a robot . However , despite using natural language , present - day con - versational agents , or robots , have not been able to provide children with helpful search experiences [ 14 ] . Current agents usually provide “query - response style” interactions , in which the child’s information need has to be compressed into a single query and conversational turn which is often too complex for children [ 17 ] . Furthermore , the “query - response” interaction style does not provide children with suggestions or clarification questions . It is unknown yet what kind of conversational interaction style with a robot can be used that not only supports children in their search needs , but that is also enjoyable and engaging . Inthispaper , wepresentanexploratorystudy intorobot - supported information search and how children experience this . To the best of our knowledge , the current effort is one of the few ( non - wizarded ) explorations into two different multi - turn conversational styles to support simple search tasks that are implemented on a robot for children . We evaluate these two interaction styles with 35 chil - dren aged 9 – 12 years old on children’s perceived likeability and preference . We used a mixed methods approach to account for the explorative character of the study . 2 RELATED WORK While there exist search environments such as Kidrex , Kiddle , and Kidzsearch [ 9 ] , which are made specifically for children , they do not assist greatly with query formulation but are rather focused on curating information and content aimed at children . Upon inspec - tion , it appears that the sites Kidrex and Kiddle provide little to no 466 HRI ’23 Companion , March 13 – 16 , 2023 , Stockholm , Sweden Suyash Sharma , Thomas Beelen , and Khiet P . Truong query suggestions and Kidzsearch provides only query completion tools similar to Google . But all these sites do not provide solutions for some of the more common difficulties that children face while formulating queries like misspelled query terms and long natural language queries , which has been reported by the work of Fails et al . [ 9 ] . The topic of generating clarification questions for users ( no specific age group ) has been reported on extensively by Zamani et al . [ 18 ] , where models for generating clarification questions have been studied and developed . In addition to this , the Qulac database has been developed for generating relevant clarification questions [ 1 ] 1 . There is also well - cited literature available on the topic of query formulation assistance for children [ 9 ] , and the idea of using conversational agents for information retrieval with children has been welcomed in the community ( e . g . , [ 4 , 12 ] ) . However , it is still understudied how exactly query ( re - ) formulation and clarification questions can be embedded in a multi - turn interaction style that is both effective and enjoyable for children , nor has it been studied how children perceive different interaction styles with a robot in this context . 3 METHODOLOGY A within - subject design study , in which children aged 9 – 12 years old conducted a search task with the Furhat robot , was carried out at two different schools . 3 . 1 Participants A total of 35 participants ( 23 boys and 12 girls ) , aged between 9 and 12 years , were recruited . The children were pupils of international schools in Amsterdam and The Hague ( language of instruction was English ) . Prior to participating in the research , all the candidates had to get consent from their parents and / or guardians . The study was approved by the Ethics Committee of the University of Twente . 3 . 2 Study design Children were presented with two different search tasks and the Furhat robot 2 with two different interaction styles . The order of the search tasks , as well as the presentation order of the interaction styles were randomised over the participants . The search tasks were to find information about Barack Obama and his personal family history ( referred to as the Obama topic ) , and about what era the velociraptor dinosaur lived in and what it ate ( referred to as the dinosaur topic ) . The Furhat robot would take input by listening to the user , convert the speech to text , run one of the two different interaction styles , generate a response based on the algorithm of that interaction style , and then convert that response back from text to speech for the user to hear . The two different algorithms for response generation in the interaction styles are described below : Qulac - based : This style is system - driven in which the robot asks a fixed set of yes / no - questions to clarify the user’s query and implic - itly also contain suggestions for aspects of information to search for . These yes / no - questions are extracted from the Qulac dataset [ 1 ] , a dataset on asking Questions for Lack of Clarity in open - domain 1 https : / / github . com / aliannejadi / qulac 2 https : / / furhatrobotics . com / information - seeking conversations , which included clarification questions for the topics Obama and dinosaurs . An example of an interaction with the Qulac - based robot is shown in Table 1 . Qulac : Hi ! IamFurhat ! HowcanIhelpyoutoday ? User : IwanttosearchforObama . Qulac : AreyouinterestedinseeingBarackObama’sfamily ? User : Yes . Qulac : Areyoulookingforbiologicalinformationonhisfamily ? User : YesIam . . . . . . Qulac : The Barack Obama familytree includes an African - American father from Kenya and a Caucasian mother from Kansas . Is this what you want to see ? If yes , then youcanendsearchingbysayingquit . Ifnot , thenpleasecontinuewithyournext question . Table 1 : Example of a Qulac - based interaction style . ELIZA - based : This user - driven style is based on the well - known ELIZA chatbot algorithm [ 16 ] . It responds to user input and asks open - ended questions . We modified a publicly available ELIZA script 3 to respond to specific keywords relating to the topics that were uttered by the user . The responses were rewritten to pose clarification questions that were more open - ended . An example of an interaction with the ELIZA - based robot is shown in Table 2 . ELIZA : Hi ! I’mFurhat ! HowcanIhelpyoutoday ? User : Iwanttosearchaboutdinosaurs . ELIZA Whatexactlydoyouwanttoknow ? User : Iwanttoknowtheeraofthevelociraptor . ELIZA : Whatabouttheeraofthevelociraptordoyouwanttoknow ? User : Whenitwaswhenitlived . ELIZA : VelociraptorisagenusofsmalldromaeosauriddinosaurthatlivedinAsiaduringtheLateCretaceousepoch , about75millionto71millionyeaarsago . Isthiswhat you want to see ? If yes , then you can end searching by saying quit . If not , then pleasecontinuewithyournextquestion . Table 2 : Example of an ELIZA - based interaction style . On both versions , a search result with a corresponding snippet of information would be displayed on a separate screen whenever a predefined keyword was spoken by the user . This was done to provide the users some positive feedback during the interaction . These information snippets were all found using the website re - sultstoexcel . com 4 , which displays Google search results for a query that can be stored in an Excel file . 3 . 3 Measurements We assessed the likeability of the two robot interaction styles through the Godspeed questionnaire ( likeability section ) [ 2 ] that was adapted to children by using 5 - point Likert scales with smiley faces ( as proposed by [ 15 ] ) . Additionally , after seeing both robots , we asked the participants to give an overall experience rating of each version of the robot on a 10 - point Likert scale with smileys . The questionnaires were complemented with interviews which can give us more insights into why children liked one robot better than the other . After seeing each robot , we interviewed the children using the following questions : • What did you think of this version of the robot ? Why ? 3 https : / / github . com / wadetb / ELIZA 4 https : / / resultstoexcel . com / 467 Robot - Supported Information Search : Which Conversational Interaction Style do Children Prefer ? HRI ’23 Companion , March 13 – 16 , 2023 , Stockholm , Sweden • Would you like to use this robot to search for information online ? Why or why not ? • What did you not like about the robot ? • Would you want to change something about the robot ? If so , what ? • Did you not like the topic or the version of the robot that you used ? Additionally , after seeing both robots , we asked : • Which version of the robot did you prefer ? Why ? • Did you notice a difference in the way the robot talked to you and asked questions in both the versions ? 3 . 4 Procedure The participant was invited into the room and requested to sit on the seat facing the Furhat . The researcher explained to the participants that the goal of the session was to talk to the robot to complete a search task that would be given to them . The participant was informed that the robot was not “very smart” and so they should try to be as clear and expressive as possible when talking and asking questions to the robot . The researcher also informed the participant that if the robot found a search result , it would display it on the screen next to the robot . If there were no further questions , the researcher would provide them with the search task and instructed them that they had five minutes to talk to the robot to complete the task . The researcher requested the participant to start with a specific statement to begin the interaction with the robot - if the task was about Obama , this sentence was “I want to search about Obama” and if the task was about dinosaurs , the sentence was “I want to search about dinosaurs” . Each child interacted with the Qulac - based and the ELIZA - based robot carrying out the Obama and dinosaur search task . After each robot interaction , the Godspeed likability questionnaire was administered and an interview was carried out . After seeing both robots , additional questions in the questionnaire as well as in the interview were asked . At the end , the participants were debriefed about the purpose of the study . 4 RESULTS 4 . 1 Likeability , overall experience rating , preference A Wilcoxon Signed - Rank Test performed on the data from the God - speed Likeability questionnaire did not show significant differences between the Qulac ( median = 1 . 6 – the lower , the more likeable ) and ELIZA version ( median = 1 . 6 ) , 𝑇 = 244 , 𝑍 = − 0 . 2269 , 𝑝 = 0 . 8205 . Similarly , the overall experience rating after both conditions , was not statistically different either between the two conditions ( 𝑇 = 254 . 5 , 𝑍 = − 1 . 168 , 𝑝 = 0 . 2427 ) . Finally , in the interview , after both conditions , participants were asked which version they preferred talking to . The results from the interviews show that 60 % ( 21 / 35 par - ticipants ) preferred the Qulac version and 40 % ( 14 / 35 participants ) preferred the ELIZA version . 4 . 2 Qualitative findings from the interviews A thematic analysis was performed on the interviews to identify recurring themes and patterns related to children’s interaction ex - perience with the two conditions . This could give us more insights into what specific aspects in the interaction children liked and dis - liked and why . We identified the following most common themes from the responses : Ease of use Most of the participants ( 97 % ; 34 out of 35 ) mentioned the fact that they would prefer talking to at least one version of the conversational robot , over typing out information using an iPad or a laptop . Among the 97 % of participants , 71 % said they would prefer talking to both versions of the conversational robot over typing . They gave several reasons for it , including it being “quicker than typing” and that it asked them questions back . A few participants ( 11 . 4 % ) also mentioned that they felt as though they had a friend they were talking to , who was helping them out . There were partic - ipants who had been diagnosed with ADHD who mentioned that searching for information online was harder using a computer , and if the robot was made smarter , it would be “easy” for someone with ADHD to find information by speaking to a robot . Two participants , whose first language was not English , said that they would prefer speaking to the robot over typing as they were not fluent in English yet . While most participants said they preferred using the robot to searching for information through a computer , there were a few exceptions . One of the older participants said they preferred the robot less than using computers . Their reasons for this included them saying they could find images and search through different websites if they just used a computer . Redundant questions ( Qulac and ELIZA ) In the interview , three participants reported that both versions of the robot sometimes kept asking them questions , despite them having stated what they wanted . They sometimes found this bothersome . Participants said that they would have preferred it if the robot had “listened better” . Didn’t understand what I wanted to search for ( Qulac ) An issue that six participants reported about the Qulac version was that it was difficult for it to understand what the children were saying . They reported that instead of responding to what they wanted , the Qulac robot would “keep jumping to other questions” and “go further away” . Some participants stated that they felt the system was “un - responsive” to what they were saying . Understood what I wanted to say ( ELIZA ) Two participants stated a preference for the ELIZA version of the robot as it asked sim - pler questions and its “replies were clearer” . Some participants said during the interview that they were able to “make more of a con - nection” with the ELIZA version of the robot . Random / Vague questions ( ELIZA ) While there were participants that enjoyed talking more to the ELIZA for its simplicity and clarity , five other participants found it asking a lot of vague and confusing questions . Participants reported that the ELIZA system sometimes kept repeating itself . They also talked about how the system can “distract” and go off - topic often . Prompts good questions ( Qulac ) Participants who liked the Qulac version more said that they liked how the Qulac system prompted them more questions : it “asked more specific questions” than the ELIZA version , did not go “off - track” and asked questions about 468 HRI ’23 Companion , March 13 – 16 , 2023 , Stockholm , Sweden Suyash Sharma , Thomas Beelen , and Khiet P . Truong the topics they wanted to talk about . They found the clarification questions that the system suggested helpful as it would ask different kinds of questions around the same topic . Social intelligence ( Qulac and ELIZA ) There were a few participants who commented on the robot’s voice ( 4 out of 35 participants ) . Participants said that they felt that the robot’s voice was a bit “emo - tionless” and “expressionless” . They would have preferred if the robot’s voice was “softer” and less “robotic” . A few participants also made general comments about the robot’s personality during the interviews . A participant mentioned that the robot should “have more feelings” . They thought that it “didn’t have feelings now” . An - other participant would have preferred it if the robot was “funnier” . They said that the robot would be more interesting to talk to this way and would appear more realistic . Broad vs specific information need Other comments from the in - terviews included how the participants preferred that the system printed out just one search result instead of having to scan through thousands of search results like Google . One of the participants responded that they would like to use the Qulac version to find out more about a broad topic ( they gave the example of US pres - idents ) as the Qulac system asks several relevant questions . And they would prefer using the ELIZA version for specific informa - tion ( they mentioned “in - depth searching” ) as it would ask more open - ended questions that would prompt the participant further . 5 DISCUSSIONS AND CONCLUSION 5 . 1 Discussion Using a conversational robot , we explored two interaction styles supporting children in their search tasks . When asked what robot they preferred , children slightly leaned more towards choosing the Qulac over the ELIZA version , while the Godspeed Likability scales did not show significant differences between the two versions . From the interviews , we learned that there were a few reasons that the participants preferred the Qulac version over the ELIZA version , which included prompting good query suggestions relevant to the topic in the form of clarification questions , staying on topic of the search task , not repeating itself . Another explanation may be that close - ended questions may require less effort to answer than open - ended questions [ 6 ] . Participants who indicated a preference for the ELIZA version more often reported feeling more “heard” and found its questions easier and simpler . One participant even associated the Qulac version with “broader” search tasks and the ELIZA version with more specific search task . So it seems that both versions proved to be useful in different ways , but it is unclear yet how these insights can be leveraged in a multi - turn conversational search interaction . 5 . 2 Limitations One of the limitations in our study was that the interactions were relatively short and basic . While the Qulac version had a set number of clarification questions that it asked each time , regardless of what the user said , the ELIZA version was more user - responsive which might have yielded more unexpected , erroneous responses due to the rather simple rule - matching strategy implemented by the first author . The simplicity of both versions and their errors might have influenced the results . Another point of attention is the difference in search task pro - vided to the children . The Obama search task was found to be more complex by the children , and additionally , some children did not know who Barack Obama was . Although the participants were given enough information about Obama before starting the search task , many participants stated that they would have preferred an - other topic to search information on . 5 . 3 Future research The current research gave us a firm basis to build our future re - search on . Children enjoyed the interactions with the robot , and were able to identify things they liked and disliked in the interac - tions : both conditions have their pros and cons . We will continue investigating the two different conversational interaction styles , particularly , we intend to make the system responses more robust , more adaptive to the user and social cues , and knowledge - based to support the child in a more intelligent manner in their search tasks . Moreover , inspired by one of the suggestions of the participants , we also plan to investigate how the type of search task or speci - ficity of the information need influences the type of conversational interaction style that one prefers . Another point of interest is that while children indicated a preference of talking to the robot over typing , future research should investigate in a more systematic manner why this is the case , by studying the embodiment ( virtual versus physical ) and the input modality ( typing versus talking ) . Finally , we will look more into the role of the robot . We found that the children generally liked the robot , but how exactly does the social presence of the robot affect the children’s experiences in this context ? For example , how does trust in the robot affect trust in the search results the robot provides ? 5 . 4 Conclusion In this exploratory study into robot - supported information search for children , we compared a more system - driven interaction style that asks closed - ended questions to a more user - responsive ELIZA - style conversational interaction , and found that participants had no strong preference for one interaction style over the other . Almost all children enjoyed talking to the robot instead of typing a query . Children were able to identify positive and negative aspects of both conversational styles . The Qulac version seemed to be liked because of its more on - topic suggestions , while the ELIZA version seemed to be more liked for evoking the feeling of “being heard” . Possibly , the specificity of the search task also influences a preferred interac - tion style . These rich insights will be taken into account in our next steps in the design of a conversational robot that can support chil - dren in their information search using multi - turn conversational interaction style . ACKNOWLEDGMENTS This research is supported by the Dutch SIDN fund https : / / www . sidn . nl / and TKI CLICKNL funding of the Dutch Ministry of Eco - nomic Affairs https : / / www . clicknl . nl / . We would also like to thank the staff and participants at HSV International Primary School ( NSL ) and the International School of Amsterdam for their participation . 469 Robot - Supported Information Search : Which Conversational Interaction Style do Children Prefer ? HRI ’23 Companion , March 13 – 16 , 2023 , Stockholm , Sweden REFERENCES [ 1 ] MohammadAliannejadi , HamedZamani , FabioCrestani , andWBruceCroft . 2019 . Asking clarifying questions in open - domain information - seeking conversations . In Proceedings of the 42nd international acm sigir conference on research and development in information retrieval . 475 – 484 . [ 2 ] Christoph Bartneck , Dana Kulić , Elizabeth Croft , and Susana Zoghbi . 2009 . Mea - surement instruments for the anthropomorphism , animacy , likeability , perceived intelligence , and perceived safety of robots . International journal of social robotics 1 , 1 ( 2009 ) , 71 – 81 . [ 3 ] Thomas Beelen , Khiet P . Truong , Roeland Ordelman , Ella Velner , Vanessa Evers , and Theo Huibers . 2022 . A Child - Friendly Approach to Spoken Conversational Search . In MICROS’22 : Mixed - InitiativeConveRsatiOnalSystemsworkshopatCIKM 2022 . https : / / ceur - ws . org / Vol - 3318 / short28 . pdf [ 4 ] Thomas Beelen , Ella Velner , Roeland Ordelman , Khiet P . Truong , Vanessa Ev - ers , and Theo Huibers . 2021 . Does your robot know ? Enhancing children’s information retrieval through spoken conversation with responsible robots . IR4Children’21 workshop at SIGIR 2021 abs / 2106 . 07931 ( 2021 ) . arXiv : 2106 . 07931 https : / / arxiv . org / abs / 2106 . 07931 [ 5 ] Tony Belpaeme , James Kennedy , Aditi Ramachandran , Brian Scassellati , and Fumihide Tanaka . 2018 . Social robots for education : A review . Science Robotics 3 , 21 ( Aug . 2018 ) . https : / / doi . org / 10 . 1126 / scirobotics . aat5954 [ 6 ] Keping Bi , Qingyao Ai , and W . Bruce Croft . 2021 . Asking Clarifying Questions Based on Negative Feedback in Conversational Search . arXiv : 2107 . 05760 [ cs ] ( July 2021 ) . https : / / doi . org / 10 . 1145 / 3471158 . 3472232 arXiv : 2107 . 05760 . [ 7 ] Dania Bilal and Joe Kirby . 2002 . Differences and similarities in information seeking : children and adults as Web users . Information Processing & Management 38 , 5 ( Sept . 2002 ) , 649 – 670 . https : / / doi . org / 10 . 1016 / S0306 - 4573 ( 01 ) 00057 - 7 [ 8 ] Allison Druin , Elizabeth Foss , Leshell Hatley , Evan Golub , Mona Leigh Guha , Jerry Fails , and Hilary Hutchinson . 2009 . How Children Search the Internet with Keyword Interfaces . ( 2009 ) . https : / / doi . org / doi [ 9 ] Jerry Alan Fails , Maria Soledad Pera , Oghenemaro Anuyah , Casey Kennington , Katherine Landau Wright , and William Bigirimana . 2019 . Query Formulation Assistance for Kids : What is Available , When to Help & What Kids Want . In Proceedings of the 18th ACM International Conference on Interaction Design and Children ( Boise , ID , USA ) ( IDC ’19 ) . Association for Computing Machinery , New York , NY , USA , 109 – 120 . https : / / doi . org / 10 . 1145 / 3311927 . 3323131 [ 10 ] Tatiana Gossen , Juliane Höbel , and Andreas Nürnberger . 2014 . A Comparative Study about Children’s and Adults’ Perception of Targeted Web Search Engines . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Toronto , Ontario , Canada ) ( CHI ’14 ) . Association for Computing Machinery , New York , NY , USA , 1821 – 1824 . https : / / doi . org / 10 . 1145 / 2556288 . 2557031 [ 11 ] Hanna Jochmann - Mannak , Theo Huibers , and Ted Sanders . 2008 . Children’s Information Retrieval : Beyond Examining Search Strategies and Interfaces . In Proceedings of the 2nd BCS IRSG Conference on Future Directions in Information Access ( London , UK ) ( FDIA’08 ) . BCS Learning & Development Ltd . , Swindon , GBR , 8 . [ 12 ] Monica Landoni , Davide Matteri , Emiliana Murgia , Theo Huibers , and Maria Soledad Pera . 2019 . Sonny , Cerca ! Evaluating the Impact of Using a Vocal Assistant to Search at School . In Experimental IR Meets Multilinguality , Multimodality , and Interaction : 10th International Conference of the CLEF As - sociation , CLEF 2019 , Lugano , Switzerland , September 9 – 12 , 2019 , Proceedings ( Lugano , Switzerland ) . Springer - Verlag , Berlin , Heidelberg , 101 – 113 . https : / / doi . org / 10 . 1007 / 978 - 3 - 030 - 28577 - 7 _ 6 [ 13 ] Jamy Li . 2015 . The benefit of being physically present : A survey of exper - imental works comparing copresent robots , telepresent robots and virtual agents . International Journal of Human - Computer Studies 77 ( May 2015 ) , 23 – 37 . https : / / doi . org / 10 . 1016 / j . ijhcs . 2015 . 01 . 001 [ 14 ] Silvia B . Lovato , Anne Marie Piper , and Ellen A . Wartella . 2019 . Hey Google , Do Unicorns Exist ? Conversational Agents as a Path to Answers to Children’s Questions . In Proceedings of the 18th ACM International Conference on Interaction Design and Children ( IDC ’19 ) . Association for Computing Machinery , Boise , ID , USA , 301 – 313 . https : / / doi . org / 10 . 1145 / 3311927 . 3323150 [ 15 ] Janet C . Read and Stuart MacFarlane . 2006 . Using the fun toolkit and other survey methods to gather opinions in child computer interaction . In Proceedings of the 2006 conference on Interaction design and children ( IDC ’06 ) . Association for Computing Machinery , New York , NY , USA , 81 – 88 . https : / / doi . org / 10 . 1145 / 1139073 . 1139096 [ 16 ] Joseph Weizenbaum . 1966 . ELIZA—a computer program for the study of natural language communication between man and machine . Commun . ACM 9 , 1 ( 1966 ) , 36 – 45 . [ 17 ] Svetlana Yarosh , Stryker Thompson , Kathleen Watson , Alice Chase , Ashwin Senthilkumar , YeYuan , andA . J . BernheimBrush . 2018 . Childrenaskingquestions : speechinterfacereformulationsandpersonificationpreferences . In Proceedingsof the17thACMConferenceonInteractionDesignandChildren ( IDC’18 ) . Association for Computing Machinery , Trondheim , Norway , 300 – 312 . https : / / doi . org / 10 . 1145 / 3202185 . 3202207 [ 18 ] Hamed Zamani , Susan Dumais , Nick Craswell , Paul Bennett , and Gord Lueck . 2020 . Generating clarifying questions for information retrieval . In Proceedings of the web conference 2020 . 418 – 428 . 470