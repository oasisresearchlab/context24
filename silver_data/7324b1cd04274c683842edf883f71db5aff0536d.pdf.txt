1 Diversity Breeds Innovation With Discounted Impact and Recognition Bas Hofstra 1 ∗ , Sebastian Munoz - Najar Galvez 1 , Bryan He 2 , Vivek V . Kulkarni 2 , & Daniel A . McFarland 1 * 1 Stanford University , Graduate School of Education , 520 Galvez Mall , Stanford , CA 94305 , USA 2 Stanford University , Department of Computer Science , 353 Serra Mall , Stanford , CA 94305 USA * To whom correspondence should be addressed : bhofstra @ stanford . edu or dmcfarla @ stanford . edu Abstract Prior work poses a diversity paradox for science . Diversity breeds scientific innovation , and yet , diverse individuals have less successful scientific careers . But if diversity is good for innovation , why is science not rewarding diversity ? We answer this question by utilizing a near - population of ~ 1 . 03 million US doctoral recipients from 1980 - 2015 and their careers into publishing and faculty roles . The article uses text analysis and machine learning techniques to answer a series of questions : How can we detect scientific innovation ? Does diversity breed innovation ? And are the innovations of diverse individuals adopted and rewarded ? Our analyses show that underrepresented groups produce higher rates of scientific novelty . However , their novel contributions are discounted : e . g . , innovations by gender minorities are taken up by other scholars at lower rates than innovations by gender majorities , and innovations by gender and racial minorities result in fewer academic positions . This suggests an unfair system in which diverse individuals innovate , but their innovations are disproportionately ignored and fail to convert into career success at the same rate as majority groups . In sum , there may be an unwarranted reproduction of stratification in academic careers that discounts diversity’s role in innovation and partly explains the underrepresentation of some groups in academia . Introduction Innovation is a key indicator of scientific progress . Innovation propels science into uncharted territories and expands humanity’s understanding of the natural and social world . Innovation is also believed to be predictive of successful scientific careers : innovators are science’s trailblazers and discoverers , so producing innovative science leads to successful academic careers ( 1 ) . At a 2 system - level , however , we know little about this apparent link . This lack of knowledge is caused by the absence of large - scale , cross - discipline , representative , and longitudinal data linking knowledge production to individual scholars’ careers . At the same time , a common hypothesis is that with diversity come ideas and innovation ( 2 - 4 ) . The combination of these two links – diversity - innovation and innovation - careers – depicts a paradox . If diverse groups such as gender and racially underrepresented scholars are likely to innovate and innovation leads to successful academic careers , where do persistent inequalities in scientific careers between diverse minority groups and majority groups come from ( 5 - 10 ) ? One explanation is that diverse scientists’ innovations get discounted , leading to inequalities in scientific impact and recognition . Here , we set out to address this conjecture . We provide a system - level account of science where we identify scientific innovations ( 11 - 15 ) and present an analysis of rates of innovation in different subgroups , the extent to which those innovations get utilized by other scholars , and their subsequent career recognition among the near - complete population of US doctorate recipients ( ~ 1 . 03 million ) spanning over three decades , across all scientific disciplines , and all US doctorate awarding institutions . Our analysis enables us to ( a ) compare diverse , minority scholars’ rates of novelty vis - à - vis majority scholars and then ascertain how likely their innovations ( b ) find impact or uptake , and in turn , ( c ) recognition and reward in a continued and ( elite ) research career . Innovation in Text Our dataset stems from ProQuest ( 16 ) , which includes records of nearly all US PhD theses and their metadata from 1980 - 2015 : student names , advisors , institutions , thesis titles , abstracts , disciplines , etc . These structural and semantic footprints enable us to consider students’ rates of 3 innovation at the very onset of their ( potential ) scholarly careers and their academic trajectory afterwards – i . e . , early innovative sparks’ relationship with ( failed ) academic careers ( 17 ) . In order to identify scientific innovation , we first identify the set of scientific concepts being employed and related in theses . For this , we use natural language processing techniques of phrase extraction and structural topic modeling ( 18 , 19 ) as they help us systematically identify terms in millions of documents and sensitize our analysis to concepts that are substantively meaningful ( see Materials and Methods and Supplementary Information ) ( 20 ) . Next , since these concepts are introduced in tandem with other concepts , and because they are introduced in different time - ordering , we identify when a concept is first related to other scientific concepts . This occurrence of novel links then reflects a set of conceptual innovations for each thesis and author . Scientific innovation becomes apparent by looking back at the concept space to find unique and innovative bridges between two concepts . Moreover , scientific impact emerges from looking forward in the semantic space to the uptake of those bridging links ( see Figure 1 for examples drawn from the data ) . Our overarching notion of innovation mirrors key theoretical perspectives on scientific innovation , where “science is the constellation of facts , theories , and methods collected in current texts ( 21 ) . ” Scientific development is then the process where concepts are added to the ever - growing “constellation” – i . e . , our accumulating corpus of texts – in new combinations – i . e . , our link introductions ( 11 , 12 , 21 ) . Advantages of our site and metrics include insensitivity to ( a ) varying indexing patterns of journal or citations’ across corpora , ( b ) prioritizing some academic disciplines over others , and ( c ) the plethora of reasons as to why scholars cite other work ( 22 , 23 ) . 4 Link intro in 1987 47 uses > 1987 HIV monkey . . . . . . . . . . . . . . . . . . HIV monkey a Lilian Bruch Purification of Simian T − cell Lymphotropic virus − III and a Comparison with Human Immunodeficiency Virus ( 1987 ) Link intro in 1985 83 uses > 1985 macro − level shape . . . . . . . . . . . . . . . macro − level shape b Peter Bearman Relations into Rhetorics ( 1985 ) Link intro in 1984 95 uses > 1984 masculinity justify . . . . . . . . . . . . . . . masculinity justify c Londa Schiebinger Women and the Origins of Modern Science ( 1984 ) Link intro in 1988 87 uses > 1988 glioblastoma molecular . . . . . . . . . . . . glioblastoma molecular d Kenneth W . Kinzler Gene Amplification in Human Cancer ( 1988 ) Link intro in 1989 22 uses > 1989 grate stretch . . . . . . . . . . . . . . . . . . grate stretch e Donna Strickland Development of an Ultrabright Laser and an Application to Multiphoton Ionization ( 1989 ) Link intro in 1985 54 uses > 1985 learn attractor . . . . . . . . . . . . . . . learn attractor f Michael I . Jordan The Learning of Representations for Sequential Performance ( 1985 ) Figure 1 . The introduction of innovations and their subsequent uptake . a - f . Examples ( abstracted ) drawn from the data suggestive of the type of novelty and impact we model . Nodes represent concepts and edge thickness indicates co - usage frequency of concepts by other students . Students themselves can introduce new links ( dotted lines ) as their work enters the corpus . These specific example novel links are taken up at disproportionate rates ( e . g . , 95 uses of Schiebinger’s link after 1984 ) as the median new links’ uptake is 1 . a . Lilian Bruch was among the pioneering HIV researchers ( 27 ) and her thesis introduced the link between HIV and monkeys , indicating innovation in scientific writing as HIV’s origins are often attributed to primates . c . Londa Schiebinger was the first to link “masculinity” with “justify , ” indicative of her pioneering work on gender bias in academia ( 28 ) . e . Donna Strickland won the 2018 Nobel Prize in Physics for her PhD work on chirped pulse amplification , utilizing grating - based stretchers and compressors ( 29 ) . Results So who innovates , whose inventions get taken up , and who gets recognized ? We first model individual rates of innovation ( link introductions ) by whether students are part of a numerical gender or racial minority in a given discipline and cohort ( see Figure 2 ) . We keep institution , academic discipline , and graduation year constant ( 24 , 25 ) ( see Materials and Methods and Supplementary Text for detailed accounts of our covariates , see Figures S1 - S2 and Table S1 for a 5 V s . G ende r m a j o r i t y V s . R a c i a l m a j o r i t y Gender minority Racial minority 0 . 00 0 . 01 0 . 02 0 . 03 Incidence rate difference for introducing new links Innovation by group indicator a 28 29 30 31 32 33 34 35 36 37 0 − . 1 . 1 − . 2 . 2 − . 3 . 3 − . 4 . 4 − . 5 . 5 − . 6 . 6 − . 7 . 7 − . 8 . 8 − . 9 9 − 1 30 . 0 32 . 5 35 . 0 37 . 5 0 . 00 0 . 25 0 . 35 0 . 50 0 . 75 1 . 00 Fraction same − gender in discipline E x pe c t ed # ne w li n ks Innovation by gender representation b range of robustness analyses finding qualitatively similar results ) . Students with membership in a discipline where their gender or race is a minority introduce novel links at higher rates ( p < . 001 ) compared to majority students . Additionally , those students whose discipline consists of 0 - 35 % same - gender peers are likely to introduce new links , but as the gender representation grows beyond ~ 35 % , rates of link introductions drop accordingly ( second - order polynomial ; p < . 001 ) . These findings suggest that with diversity comes innovation ; students who are members of underrepresented groups innovate at slightly higher rates compared to overrepresented groups ( 2 - 4 ) . Figure 2 . Minorities innovate at higher rates than gender majorities a . Introduction of new links ( # new links ) are shown by underrepresented group indicators ( N = 1 , 037 , 492 ) . Rates of new links suggest differences by group , where those gender - and race - underrepresented students introduce more links than overrepresented students do . These results suggest higher rates of scientific novelty for underrepresented groups in a discipline compared to overrepresented groups . b . The bottom and left - side bar graphs represent the variables’ distributions over the plotted range . The expected number of link introductions grows with one’s gender representation in a field , but only up until ~ 35 % and thereafter it drops sharply . No such relation exist for race representation in a discipline - cohort ( p = 0 . 196 ) . Second , we investigate impact , or whether individuals’ innovations get taken up at a similar rates across groups . We model the rate of total new link uptakes ( sum of uses a novel linkage gets going forward ) and impact as the average payoff per new link ( total link uptakes divided by link 6 V s . G ende r m a j o r i t y V s . R a c i a l m a j o r i t y Gender minority Racial minority − 0 . 01 0 . 00 0 . 01 0 . 02 0 . 03 Incidence rate difference for uptake links total uptake payoff per link introductions , see Figure 3 , and Table S1 ) . Minorities’ new links are taken up at higher rates compared to those students whose gender and race is overrepresented in a discipline ( p < . 001 ) . Because total link uptake is conditional on link introductions , we control for the number of links introduced – i . e . , payoff per link . Gender - underrepresented students’ payoff per new link has a lower rate compared to gender - overrepresented students of ( p < . 001 ) , suggesting that gender minorities’ innovations get taken up less often than those introduced by a majority . In contrast , racially underrepresented students’ payoff per link is somewhat higher compared to that of racially overrepresented students ( p < . 001 ) . Hence , diverse individuals introduce more innovation , but underrepresented genders find their innovations discounted , whereas racial minorities’ innovations get taken up at slightly higher rates compared to those of the racial majority group . Figure 3 . Gender minorities find lower impact than gender majorities Total new link uptake and impact as payoff per new link by social group ( when innovation is nonzero , N = 969 , 735 ) . Total novel link uptake is higher among gender and racial minorities rather than gender and racial majorities , resulting from them introducing more links ( see Figure 2 ) . Payoff per link is lower for gender - underrepresented vis - à - vis gender - overrepresented students , suggesting discounted innovations . Some diverse groups face discounted scientific innovations ( gender - underrepresented groups ) , whereas other diverse groups’ innovations get taken up at slightly higher rates ( racially underrepresented groups ) . 7 Third and most importantly , we examine whether and how levels of innovation and impact translate into recognition and extended research careers . We model career recognition as a ) obtaining an elite research faculty position , and b ) as continuing research endeavors ( see Figure 4 , Figure S3 , and Table S1 ) . The former reflects PhDs who become faculty advisors of PhDs themselves at US research universities , while the latter reflects the broader pool of PhDs who continue to conduct research even if they do not have research advisor roles ( e . g . , in industry , non - tenure line role , etc . ) . For the latter , we capture survival after obtaining their PhD and earliest innovations by identifying which doctorates become publishing authors in the Web of Science ( 26 ) , which consist of ~ 38 million publications . Innovation and impact in a student’s text positively corresponds with recognition . A one standard deviation increase ( s = 1 . 26 ) in the logged number of new links increases the odds of an elite faculty position by 8 . 4 % and continuing research by 3 . 1 % ( both p < . 001 ) ; and a one standard deviation increase in logged payoff per new link ( s = 1 . 35 ) increases the odds of an elite faculty position by 24 . 8 % and continuing research by 11 . 2 % ( both p < . 001 ; see Figure S3 ) . Students are more likely transition to academic scholars if they innovate and have more impact . If we keep innovation and impact ( and year , institution , and discipline ) constant , however , gender and racial inequality in scientific careers persists , which is consistent with prior work ( 5 - 10 ) . Underrepresented genders have lower odds of becoming elite research faculty ( ~ 14 % ) and sustaining research careers ( ~ 5 % ) compared to gender majorities ( all p < . 001 ) . Similarly , racial minorities have lower odds of becoming elite faculty ( ~ 22 . 5 % ) and continuing research endeavors ( ~ 25 % ; all p < . 001 ) compared to racial majorities . Moreover , the positive correlation of innovation and impact with career recognition varies between gender and racial groups . The long - term career returns for being innovative and impactful are lower for underrepresented rather than 8 M = 27 M + 1SD = 82 15 . 3 % diff . No sig . diff . 95 % of obs . 4 % 5 % 6 % 1 10 100 # new links A d j . p r ob . o f e li t e f a c u l t y Majority Minority Gender − specific innovation ® elite faculty a 25 . 2 % diff . 23 . 7 % diff . 4 % 5 % 6 % 1 10 100 # new links Race − specific innovation ® elite faculty b 5 . 3 % diff . No sig . diff . 22 % 24 % 26 % 28 % 1 10 100 # new links A d j . p r ob . o f c on t i nued r e s ea r c h Gender − specific innovation ® cont . research c 25 . 3 % diff . 13 . 8 % diff . 22 % 24 % 26 % 28 % 1 10 100 # new links Race − specific innovation ® cont . research d M = 1 . 5 M + 1SD = 10 . 45 16 . 4 % diff . 95 % of obs . 2 % of obs . Min . pay . per link No sig . diff . 2 % 4 % 6 % 8 % 0 . 007 0 . 1 1 10 payoff per link A d j . p r ob . o f e li t e f a c u l t y Gender − specific impact ® elite faculty e 27 % diff . 19 . 3 % diff . 2 % 4 % 6 % 8 % 0 . 007 0 . 1 1 10 payoff per link Race − specific impact ® elite faculty f 7 . 6 % diff . No sig . diff . 20 % 25 % 30 % 35 % 0 . 007 0 . 1 1 10 payoff per link A d j . p r ob . o f c on t i nued r e s ea r c h Gender − specific impact ® cont . research g 32 . 7 % diff . No sig . diff . 20 % 25 % 30 % 35 % 0 . 007 0 . 1 1 10 payoff per link Race − specific impact ® cont . research h overrepresented groups . At low impact , for instance , gender minorities and majorities have approximately similar probabilities of successful careers . With increasing impact , however , the probabilities diverge at the expense of gender minorities’ chances . Figure 4 Minorities find discounted innovation and impact for career recognition a - d . Gender - and race - specific innovation correlations with becoming elite research faculty and continued research endeavors ( when innovation is nonzero , N = 969 , 735 ) . e - f , Gender - and race - specific impact correlations with becoming elite research faculty and continued research endeavors ( when impact is nonzero , N = 915 , 553 ) . a - d . With low innovation the adjusted probability of becoming elite research faculty is similar between gender minorities and majorities . When innovation increases , probabilities between minorities and majorities diverge . While innovation is positively related to becoming elite research faculty for both groups , the difference in probability of becoming elite faculty grows to 15 . 3 % at one standard deviation from the median . Gender and racial and minorities’ innovations are discounted for continued research endeavors . e - f . Gender and racial minorities’ impact is discounted for elite research positions as well as for continued research careers . For instance , the probability for elite research faculty or continued research careers increases to 16 . 4 % and 7 . 6 % for underrepresented genders at one standard deviation from the median . Discussion Consistent with notions that diversity breeds ideas and innovation , we find higher rates of innovation among gender and racial minority groups ( 2 - 4 ) . Innovations are not adopted uniformly : 9 adoption depends on which social group proposes the innovation . Links introduced by an under - represented gender , for instance , yield less impact . This is suggestive of an innovation discount for some groups compared to others where not all innovators are equally impactful . Innovation and impact correspond with scientific careers , but in spite of this , inequality in career outcomes persists for gender and racial minorities ( 5 - 10 ) . We reveal hidden sources of these inequalities and underrepresented students gain less career returns for their innovation and impact compared to majorities . In sum , this article provides a system - level account of innovation and its subsequent impact and recognition across all academic fields from 1980 - 2015 by following over a million US students’ careers and their earliest intellectual footprints . We reveal a stratified system where diverse groups have to innovate at higher levels to reach similar levels of impact and recognition despite innovative scholarship . These results suggest diverse groups’ science careers end prematurely despite their crucial role in innovation . Which trailblazers has science missed out on as a consequence ? This question stresses the continued importance of critically evaluating and addressing biases in faculty hiring , research funding , and publication practices . Materials and Methods Data We utilize a longitudinal dataset of dissertations filed from doctorate - awarding universities across the United States in the period 1980 to 2015 from ProQuest ( 16 ) . These data contain more than 1 . 03 million dissertations and accompanying metadata such as the name of the doctoral candidate , year they were awarded the doctorate , their university , the abstract that belongs to their theses , their advisors ( 37 . 6 % of distinct advisors mentor one student ) , etc . These data cover approximately 10 86 % of all awarded doctorates in the US over three decades across all disciplines . These data allow us to follow PhD recipients ( N = 1 , 037 , 492 ) who overwhelmingly filed their dissertations in the database through time in a near - closed system of PhD recipients and their subsequent careers ( if they have an academic career ) . We link these data with several data sources to arrive at a near - ecology of US PhD students and their career trajectories . Specifically , we link ProQuest to the US Census data ( 2000 and 2010 ) and Social Security Administration data ( 1900 - 2016 ) to infer demographic information on students ( detailed below and additional information found in Supplementary Information ) ; we crosswalk ProQuest to Web of Science – a large - scale publication database with ~ 38 million academic publications ( 1900 - 2017 ) – to find out which students publish and how often ( the linking process is outlined in the Supplementary Information ) ; and we weigh our inferential analyses by population records of the number of PhD recipients for each distinct university - year combination ( e . g . , Harvard University , 1987 ) to render results generalizable to the population ( see Supplementary Information for information on population coverage and data weights ) . Measuring Innovation Through Citations , Keywords , and Text Researchers occasionally study citations or keywords to understand innovation . Our analyses of in - text concept usage overcomes some of the difficulties related to those conventional data sources . Prior work ( 11 ) used citations in research articles to study innovation understood as a novel recombination of prior bibliographic sources . However , it is difficult to draw explicit meaning from said combinations . Do pairs of references combine all ideas in the cited papers , or only some of them ? These difficulties are compounded by the variety of functions that references fulfill . For 11 instance , do authors mean to spread a paper’s idea or contend it ? Reference functions are not easily distinguished outside of the specific textual context of a citation ( 22 ) . Keywords constitute “plausible building blocks of content” ( 12 ) and do not suffer from the lack of granularity that affect citations . Prior work used keywords to study innovation through subfield integration ( 30 ) . An issue with keywords , however , is that it is difficult to ascertain whether it is a feature of the knowledge content in a paper . Researchers , and often editorial teams , assign keywords to optimize indexing and retrieval ( 31 ) . The use of keywords then begs the question of whether they locate innovation in a research article or in its classification . As an alternative to keywords , prior work used chemical entities from annotated MEDLINE abstracts as their units for innovation ( 12 ) . The entities extracted from abstracts overcome potential confounding classification dynamics . Yet , the study of chemical entities are highly specific to only one field . As such , scholars acknowledge , “new methods should be developed for mining building blocks with finer granularity” ( 12 : 901 ) . Our analysis of novel recombinations of in - text concept use overcomes the issues of citations and keywords and thus elaborate and extend the research program of innovation . Concept extraction from scientific text So how do we extract concepts from text ? Not all terms are equal means for innovation . Combining or introducing terms like “thus , ” “therefore , ” and “then , ” highly frequent terms , is not substantively similar to combining “HIV” and “monkey . ” However , differences between substantive and trivial concepts are not always as apparent . Furthermore , there is no established rule to discriminate between qualities of concepts . Hence , we set out to determine on what dimensions to determine meaningful concepts . To this end , we employ Structural Topic Models 12 ( STMs ) ( 18 ) . STMs are a quantitative way to detect latent thematic dimensions in large corpora of texts ( see also Supplementary Text : Structural Topic Models for Concept Extraction ) . These dimensions ( i . e . , topics ) are vectors of words weighted by their capacity to discriminate from other vectors of words . To extract concepts , we use STMs to find the dimensions in which some concepts might matter more than others . This kind of model requires that we input the number of topics to look for ( K ) . We fitted STMs for a range of number of topics ( K = [ 50 - 1000 ] ) with incremental steps of 50 initially , and steps of 100 when K > 600 ( to save computing time and resources ) . Our fit metrics ( internal validity , external validity , and consistency , see Figure S4 and Supplementary Text : Structural Topic Models for Concept Extraction ) plateau at K = 500 , and we use that K throughout the main text of the manuscript , although using either K = 400 or K = 600 does not qualitatively alter our results ( see Figure S3 and Table S1 ) . Furthermore , in these models we allow topics to be more or less prevalent over time . We do this by modelling the prevalence of topics in dissertation abstracts ( abstract synthesize full texts appropriately , see Supplementary Information : Analyzing Abstracts Versus Full texts ) as a linear function of the year in which scholars obtained their doctorate . The entire ProQuest corpus covers PhD recipients from 1977 to 2015 ( ~ 1 . 2 million dissertation abstracts ) and we use these as input documents for a semantic signal for the scientists’ scholarship at the onset of their careers . In our inferential analyses , we utilize the data from 1980 to 2010 ( ~ 1 . 03 million ) to a ) allow for the scientific concept space to accumulate three years before we measure which students start to introduce links and b ) to allow for the most recently graduated students ( up until 2010 ) to have opportunities for their new links to be taken up . However , we employ year fixed - effects in our inferential analyses ( detailed below ) to further account for this left - and right - censoring . 13 Using the STM output , we obtain the most - frequent and most - exclusive terms within a given topic . Extracting only the most - frequent terms at the expense of the most - exclusive terms ( or vice versa ) is not enough . The most - frequent terms are too general and consist of general language needed by all topics to be able to describe them ( e . g . , “data , ” “analyze , ” “study , ” etc . ) , whereas the most - exclusive terms might often be too idiosyncratic to be informative in and of themselves ( e . g . , “eucritta melanolimnete , ” “periplanone b , ” etc . ) . Therefore , we strike a balance between frequency and exclusivity : concepts that are simultaneously common and distinctive . Concepts that are as simple as possible , but as complex as necessary . To this end , we extract concepts on the basis of their FREX score ( 20 ) , which compounds the weighted frequency and exclusivity of a term in a topic . Here , we explore three weighting schemes : equally balancing frequency and exclusivity ( 50 / 50 ) , attaching more weight to frequency and less to exclusivity ( 75 / 25 ) , and attaching more weight to exclusivity and less to frequency ( 25 / 75 ) . We then extract the top - 100 FREX - words per topic – K = [ 400 - 600 ] with incremental steps of 100 , resulting in 40 , 000 , 50 , 000 , or 60 , 000 concepts – and measure our innovation and impact variables ( detailed below ) for all three K’s and three FREX weighting schemes ( i . e . , nine scenarios in total ) . The more - frequent semantic space defines the more - standard scientific vocabulary , and the more - exclusive semantic space is more idiosyncratic indicative of non - standard concept usage . Sensitivity analyses provide robust results across the scenarios for innovation , impact , and recognition ( see Table S1 ) . For the results depicted in the main text , we report the scenario where frequency and exclusivity are equally balanced at K = 500 , but the Extended Data report on all sensitivity analyses across all nine scenarios . We trim the students’ text keeping those words that we extracted using FREX and we consider these as the set of meaningful scientific concepts . 14 Outcome variables Using the extracted scientific concepts and by relying on the publication year ( i . e . , year of the doctorate ) of dissertations in the ProQuest database , we look backward in time and measure which students introduce a given link between concepts in the entire space in ProQuest for the first time ( # new links : M [ sample median ] = 24 ; s [ sample standard deviation ] = 54 . 477 ; 67 , 659 students never introduce a link [ or 7 % ] ) . If a link is introduced by two students in the same year they both get counted , as we cannot split into smaller time units given our data and we want to prevent unjustifiably discounting inventions . This metric – new link introductions – is what we label as the extent of innovation or novelty produced by students in their texts . A potential drawback of our universe ( ProQuest ) is that these link introductions might have arrived earlier in other corpora ( e . g . , peer - reviewed journals , or even fiction ) . However , it provides ( at the very least ) unique insight into which dissertations are highly novel compared to others dissertations and , thus , which students are competitive vis - à - vis others with their early - onset innovative sparks in knowledge production . Second , we measure impact as novel link uptake . We first capture the total number of events in which other students use that specific link for each student who introduces that new concept link , looking forward in time and conditional on introducing a link at all ( total link uptake ; M = 29 ; s = 1042 . 600 ; N = 969 , 735 ) . For instance , imagine a communication scholar who uses the concept “social _ media” with “privacy” for the first time in 2004 . We then count the total number of times other students use that link – i . e . , that same co - occurrence – as well as all other new links introduced in their texts from 2005 and onward . However , total link uptake is conditional on link introduction , so we normalize this metric by the number of new links such that we capture the payoff per new link ( payoff per link = total link uptake / # new links , M = 1 . 190 ; s = 8 . 981 ) . The payoff per new link is what we consider as the average scientific impact for an individual student . 15 See Figure S1 for the distributions and correlations of these outcome variables across the different K and FREX scenarios . As we mentioned before , there are at least two advantages to measuring innovation and impact with language of PhD recipients in dissertations vis - à - vis , for instance , citation records of scholars in journals . First , language metrics are relatively unaffected by academic search engines , journal guidelines , or differences in indexing across corpora , or by the variety of reasons as to why scholars cite others’ work ( 22 , 23 ) . As such , we detect signals of innovation that would otherwise be hard to trace and which are insensitive to potential biases resulting from corpora that unjustifiably exclude citations in other academic fields . Second , our corpus captures a near - population of scholars’ early texts and does not discriminate by prioritizing some academic fields at the expense of others . As such , the language and innovations of slower , book - oriented science ( e . g . , History ) , medium - paced , publication - oriented science ( e . g . , Sociology ) , or faster , proceedings - oriented science ( e . g . , Computer Science ) are all represented and measured in our corpus . Finally , we measure recognition as becoming an elite research faculty or an individual with continuing research endeavours . First , we conservatively proxy whether graduate students become elite faculty after their graduation ( elite faculty : mean = . 063 or N = 65 , 869 ) . This metric is based on whether we can identify scholars in the ProQuest corpus after their graduation as a primary advisor to other students in that same corpus . Ultimately , this captures who reproduces academically and who does not at a PhD - granting US university ; who transitions from mentee to mentor and was able to secure an faculty job with a lineage of students ? For those that graduated up until 2010 ( i . e . , the latest year we analyze ) , we still consider whether they transitioned to faculty between 2010 and 2015 . Second , we match the ProQuest database with WoS ( see Supplementary 16 Text : Linking ProQuest with Web of Science ) . The WoS database consists of ~ 38 million publication records and their associated meta - information from 1900 to 2017 ( disambiguated authors , title , cites , abstracts , etc . ) . Uniquely , this allows to follow scholars’ careers through time and enables to consider their research output after scholars obtained their doctorate . Using the ProQuest - WoS link , we measure whether students publish at least once in the five years after obtaining their PhD or if they become a PhD advisor , which we interpret as scholars who continue research endeavours ( continued academic research : mean = 0 . 305 or N = 316 , 645 ) . This metric captures a broader range of those who continue to pursue research : those scholars who continue to pursue science at institutions that might not grant PhDs ( e . g . , liberal arts colleges , think tanks , industry jobs , and so forth ) or move internationally . Diverse individuals might disproportionally move towards such institutions rather than PhD - granting US universities . Hence , examining both metrics indicates whether our results are robust to different academic strata . Main covariates The ProQuest data do not contain direct reports of student gender and race characteristics , but we identify the race and gender of students based on their first ( gender ) and last ( race ) names . We compiled datasets from the US censuses ( 32 ) to predict race and from the US Social Security Administration ( 33 ) to predict gender . We matched these to data on N = 20 , 264 Stanford University scholars between 1993 and 2015 . The Private University data contain race and gender information alongside scholar names , which allows us to train a threshold algorithm to estimate race and gender based on names . Using these thresholds , we classify advisees in the ProQuest data into one of four race categories and to assign a gender ( 34 ) . The race categories are White , Asian , Hispanic , and Other Race . The Other Race category is a residual category and combines African Americans , 17 Native Americans , and any racial categories not captured by the first three ( see Supplementary Text : Scholar Gender and Race ) . We then compute the relative representation of a given group in a given discipline and given year , from 1980 to 2010 – e . g . , the percentage of female PhD recipients in Aerospace Engineering in 1985 . We then measure whether a student is part of a gender or a racial minority – i . e . , whether a student is member of a group smaller than the largest group in a discipline - year ( Gender minority mean = . 423 ; Racial minority mean = . 366 ) . Finer - grained metrics of race would be preferable ; such “thinness” is an occasional issue in computational research ( 35 , 36 ) . In our case , however , finer - grained categories are by design more often labelled as underrepresented minorities . As a consequence , our relatively “course” race metric conservatively proxies our metrics’ effects . Additionally , we measure the fraction of students in a discipline - year carrying the same gender or race – e . g . , the percentage of women in Education in 1987 when a student is a woman , the percentage of Hispanic scholars when a student is Hispanic , and so forth ( Fraction same - gender mean = . 462 , s = . 177 ; Fraction same - race mean = . 488 , s = . 260 ) . Not all students who file theses to ProQuest list the department in which they obtained their doctorate . In order to determine the degree’s academic discipline , we trained a Random Forest Classifier ( RFC ) based on a list of features from the dissertation ( e . g . , keywords , listed university , etc . ) using the theses that do list department and degree as a ground truth . The RFC was able to infer department degree with 96 % precision ( N DISCIPLINE = 84 ; see Supplementary Text : Academic Discipline ) . Dissertations that are filed to ProQuest contain meta - information about the institution where the doctorate was awarded . In some cases , PhD recipients reported multiple universities . In these cases , we classify the student into the first institution that is filed to ProQuest ( N UNIVERSITY = 18 215 ) . We infer the graduation year in which the student obtains her / his doctorate as the year in which the dissertation was filed to ProQuest ( Range = 1980 - 2010 , N YEAR = 31 ) . Analytical strategy We model each of our indicators for novelty , impact , and recognition tailored to their statistical distributions . Scientific novelty as link introduction ( count of new links ) and impact as link uptake ( count of students’ new link that are taken up , payoff per link ) , are right - skewed counts of events or rates . For these outcomes , we employ negative binomial regression analyses , were the over - dispersion in the outcomes is modeled as a linear combination of the covariates ( 37 ) . Recognition as becoming elite faculty ( yes / no ) and obtaining an academic job ( yes / no ) are both binary outcomes , so we use logistic regression analyses for these . Analytically , these two models take the following forms : Pr ( 𝑌 = y j | µ j , a ) = Γ ( y j + a - 1 ) Γ ( a - 1 ) Γ ( y j + 1 ) # 1 1 + a µ j $ a - 1 # a µ j 1 + a µ j $ y j , ( 1 . 1 ) where µ j = exp ( β 0 + β 1 X j + … + β k X j ) , ( 1 . 2 ) Pr ( 𝑌 ≠ 0 | X j ) = exp ( β 0 + β 1 X j + … + β k X j ) 1 + exp ( β 0 + β 1 X j + … + β k X j ) . ( 2 ) Equation ( 1 ) models the expected count of link introduction , link uptake , and payoff per new link , whereas equation ( 2 ) models career survival as becoming elite faculty or obtaining an academic positions , all for individual student j . In these models , β 0 represent intercepts and β 1 X j + … + β k X j represent our vector of covariates from the first to the k th variable that predicts the outcome Y . Variables included in this vector are our main predictors ( indicators for gender and race representation ) and the confounding factors ( institution , discipline , and year ) . We exponentiate the 19 log - odd coefficients from the logistic and negative binomials regressions to report differences in odds ratios ( logistic ) and incidence rates ( negative binomial ) between social groups . The whiskers or shaded lines in Figures 2 - 4 represent upper and lower bounds of 95 % confidence intervals of the models’ coefficients , and the p - values we report are two - sided tests based on the negative binomial and logistic regressions . Figure 3b represents expected values with all other values held at their averages . Payoff per link is a non - integer rate instead of an integer event count . An occasional method to be able to model non - integers is to offset the negative binomial regression with logged independent variables . Here , we do so for the number of new links when we model payoff per link so as to interpret coefficients of other independent variables as rate increases or decreases ( 37 , 38 ) . A ( simplified ) example is an expected count µ x , where µ x is dependent on some covariate X , so that log ( µ x ) = β 0 + β 1 X . If t X would then indicate exposure ( or offset ) , then log ( µ X / t X ) = β 0 + β 1 X models an expected rate ( count divided by exposure ) and this is analytically equal to log ( µ X ) = β 0 + β 1 X + log ( t X ) . Hence , we include a logged offset variable t X in the form of logged number of new links . As such , we are able to model payoffs as non - integer rates . We include three sets of fixed effects in our models to attempt to isolate our main predictors from confounding factors . We keep institution , academic discipline , and graduation year constant throughout . This is to account for universities that arguably vary greatly in their prestige and the resources they make available to students ( 24 ) , for academic disciplinary cultures that vary ( 25 ) , and for “older” scholars that have had more time to make career transitions or to get recognized . We weigh the data by the total number of doctorates awarded by an institution in a given year ( see Supplementary Text : Population Coverage and Data Weights ) to account for possible selectivity between universities in years when filing their doctorates’ theses in the ProQuest 20 database and to render our results generalizable to the US scholarly population . These survey weights are based on the relative number of PhD recipients in the ProQuest data vis - à - vis the US PhD population per year for each university . Finally , link uptake is modelled for those students who introduce at least one link whereas becoming elite research faculty or continued research endeavors is modeled for those who introduce at least one link ( 93 . 5 % ; N = 969 , 735 ) or whose payoff per link nonzero ( 88 . 3 % ; N = 915 , 553 ) . Acknowledgements We acknowledge Stanford University and the Stanford Research Computing Center for providing computational resources and support that contributed to these research results . This paper benefited from discussions with Lanu Kim , Raphael Heiberger , Mathias W . Nielsen , Anthony Lising Antonio , James Zou , and Londa Schiebinger . Funding This paper was supported by two National Science Foundation grants [ NSF # 1633036 and NSF # 1827477 ] and by a grant from the Dutch Organization for Scientific Research [ NWO # 019 . 181SG . 005 ] . Author contributions B . Ho . and D . M . conceptualized and designed the study . B . Ho . , S . M . N . G . , B . He . V . K . , and D . M . analyzed the data . B . Ho . and D . M . did the writing . Competing interests The authors declare no competing interests . 21 Data and materials availability The data used in this study were obtained according to protocol 12996 , approved by Stanford University . We acquired written permission from ProQuest to scrape and analyze their data for scientific purposes . Code and anonymized data to reproduce the main analyses in the paper will be made available upon publication . References 1 . R . K . Merton , The Sociology of Science ( University of Chicago Press , Chicago , 1973 ) . 2 . M . S . Granovetter , The Strength of Weak Ties . American Journal of Sociology 78 , 1360 - 1380 ( 1973 ) . 3 . R . S . Burt , Structural Holes and Good Ideas . American Journal of Sociology 110 , 349 - 399 ( 2004 ) . 4 . M . W . Nielsen , et al . Gender Diversity Leads to Better Science . Proceedings of the National Academy of Sciences of the United States of America 109 , 1740 - 1742 ( 2017 ) . 5 . C . A . Moss - Racusin , J . F . Dovidio , V . L . Brescoll , M . J . Graham , J . Handelsman , J , Science Faculty’s Subtle Gender Biases Favor Male Students . Proceedings of the National Academy of Sciences of the United States of America 109 , 16474 - 16479 ( 2012 ) . 6 . W . W . Ding , F . Murray , T . E . Stuart , Gender Differences in Patenting in the Academic Life Sciences . Science 313 , 665 - 667 ( 2006 ) . 7 . J . D . West , J . Jacquet , M . M . King , S . J . Correl , C . T . Bergstrom , The Role of Gender in Scholarly Authorship . PLoS ONE 8 , e66212 ( 2013 ) . 8 . L . A . Rivera , When Two Bodies Are ( Not ) a Problem : Gender and Relationship Status Discrimination in Academic Hiring . American Sociological Review 82 , 1111 - 1138 ( 2017 ) . 22 9 . M . H . K . Bendels , R . Müller , D . Brueggmann , & D . A . Groneberg Gender Disparities in High - quality Research Revealed by Nature Index Journals . PLoS One 13 , e0189136 ( 2018 ) . 10 . A . Clauset , S . Arbesman , & D . B . Larremore , Systematic Inequality and Hierarchy in Faculty Hiring Networks . Science Advances 1 , e1400005 ( 2015 ) . 11 . B . Uzzi , S . Mukherjee , M . Stringer , B . Jones , Atypical Combinations and Scientific Impact . Science 342 , 468 – 472 ( 2013 ) . 12 . J . G . Foster , A . Rzhetsky , J . A . Evans , Tradition and Innovation in Scientists’ Research Strategies . American Sociological Review 80 , 875 - 908 ( 2015 ) . 13 . D . Wang , C . Song , A . Barabási , Quentifying Long - Term Scientific Impact . Science 342 , 127 - 132 ( 2013 ) . 14 . A . T . J . Barron , J . Huang , R . L . Spang , & S . DeDeo , Individuals , Institutions , and Innovation in the Debates of the French Revolution . Proceedings of the National Academy of Science of the United States of America 115 , 4607 - 4612 ( 2018 ) . 15 . I . Iacopini , S . Milojevi ć , & V . Latora , Networks Dynamics of Innovation Processes . Physical Review Letters 120 , 048301 ( 2018 ) . 16 . ProQuest . ProQuest : Ready to Do Some Research ? ( 2019 ) . At < http : / / www . proquest . com / > 17 . S . Fortunato et al , Science of Science . Science 359 , eaao0185 ( 2018 ) . 18 . M . E . Roberts et al , Structural Topic Models for Open - Ended Survey Responses . American Journal of Political Science 58 , 1064 - 1082 ( 2014 ) . 19 . A . El - Kishky et al , Scalable Topical Phrase Mining from Text Corpora . Proceedings of the VLDB Endowment 8 ( 2014 ) . 20 . J . M . Bischof , E . M . Airoldi , Summarizing topical content with word frequency and exclusivity . Proceedings of the International Conference on Machine Learning ( 2012 ) . 23 21 . T . S . Kuhn . The Structure of Scientific Revolutions . ( The University of Chicago Press , Chicago , 1962 ) . 22 . D . Jurgens et al , Measuring the Evolution of a Scientific Field through Citation Frames . Transactions of the Association for Computational Linguistics 6 , 391 - 406 ( 2018 ) . 23 . H . Small , On the shoulders of Robert Merton : Towards a normative theory of citation . Scientometrics 60 , 71 - 79 ( 2004 ) . 24 . V . Burris , The Academic Caste System : Prestige Hierarchies in PhD Exchange Networks . American Sociological Review 69 , 239 - 264 ( 2004 ) . 25 . A . Abbott , The System of Professions : An Essay on the Division of Expert Labor . ( The University of Chicago Press , 1998 ) . 26 . Clarivate Analytics . Web of Science Raw Data ( XML ) . At < https : / / clarivate . libguides . com / rawdata > 27 . M . H . Sarngadharan , M . Popovic , L . Bruch , J . Schupback , R . C . Gallo , Antibodies Reactive with Human T - lymphotropic Retroviruses ( HTLV - III ) in the Serum of Patients With AIDS . Science 224 , 506 - 508 ( 1984 ) . 28 . L , Schiebinger , The Mind Has No Sex ? Women in the Origins of Modern Science . ( Harvard University Press , Boston , 1991 ) . 29 . D . Strickland , G . Mourou , Compression of Amplified Chirped Optical Pulses . Optics Communications 6 , 447 - 449 ( 1985 ) . 30 . E . Leahey , J . Moody , Sociological Innovation through Subfield Integration . Social Currents 1 , 228 - 256 ( 2014 ) . 24 31 . I . Gil - Leiva , A . Alonso - Arroyo , Keywords Given by Authors of Scientific Articles in Database Descriptors . Journal of the American Society for Information Science and Technology 58 , 1175 - 1187 ( 2007 ) . 32 . US Census Bureau . Frequently Occurring Surnames from the Census . ( 2017 ) at < https : / / www . census . gov / topics / population / genealogy / data / 2000 _ surnames . html > 33 . Social Security Administration . Popular Baby Names . ( 2017 ) . at < https : / / www . ssa . gov / oact / babynames / limits . html > 34 . B . Hofstra , R . Corten , F . Van Tubergen , N . C . Ellison , Sources of Segregation in Social Networks : A Novel Approach Using Facebook . American Sociological Review 82 , 625 - 656 ( 2017 ) . 35 . B . Hofstra , N . C . De Schipper , Predicting Ethnicity With First Names in Online Social Media Networks . Big Data & Society , 1 - 4 ( 2018 ) . 36 . D . A . McFarland , H . R . McFarland , Big Data and the Danger of Being Precisely Inaccurate . Big Data & Society , 1 - 4 ( 2015 ) . 37 . C . A . Cameron , P . K . Trivedi , Microeconomics Using Stata . 553 - 598 ( Stata Press , 2010 ) . 38 . A . Agresti . An Introduction to Categorical Data Analysis . 74 - 84 ( Wiley , 2007 ) . 25 Supplementary Information for Diversity Breeds Innovation With Discounted Impact and Recognition Bas Hofstra 1 ∗ , Sebastian Munoz - Najar Galvez1 , Bryan He 2 , Vivek V . Kulkarni 2 , & Daniel A . McFarland 1 * 1 Stanford University , Graduate School of Education , 520 Galvez Mall , Stanford , CA 94305 , USA 2 Stanford University , Department of Computer Science , 353 Serra Mall , Stanford , CA 94305 USA * To whom correspondence should be addressed : bhofstra @ stanford . edu or dmcfarla @ stanford . edu This PDF file includes : Supplementary Text Structural Topic Models for Concept Extraction Student Gender and Race Academic Discipline Population Coverage and Data Weights Linking ProQuest to Web of Science Figures S1 to S4 Table S1 SI References 26 Supplementary Text Structural Topic Models for Concept Extraction To identify scientific novelty with scientific concepts , we first fit Structural Topic Models ( STMs ) ( 1 ) where we model the prevalence of topics in dissertation abstracts ( ~ 1 . 03 million ) as a linear function of the year in which scholars obtained their doctorate . Structural topic modelling is an unsupervised learning technique that represents texts within a corpus as a mixture of latent thematic dimensions without a priori knowledge of what these dimensions might be . STMs rely on co - occurring words within documents . In an iterative process , this kind of model draws samples from a corpus to derive a series of topics – i . e . , weighted sets of co - occurring words in a text . The outcome of this process is twofold : ( a ) the model arrives at the set of topics best suited to explain the thematic dimensions of a corpus of texts ; and ( b ) the model produces an optimal representation of every document as a mixture of topics . We mention “best - suited” topics and “optimal” document representations because STMs , like other mixture models of its kind , allow for the validation of different numbers of possible topics . Here , we fit STMs within a range of a set number of topics [ K = 50 - 1000 ] , with incremental steps of 50 ( and steps of 100 when K > 600 to save computing time ) . Internal and external validation indices show that the optimum of the number of topics is at approximately K = 400 - 600 topics . In the main text of the study , we’ve presented results for K = 500 . This means that we used the weights on the vocabulary from an STM with 500 topics to extract the concepts that best describe the latent dimension in the corpus . Namely , the extracted concepts belong to the top - 100 FREX terms of each topic . However , our results remain robust under alternative specifications for concept extraction ( leaning towards either frequency , exclusivity , or balancing both equally ) and for a range of K ( for 27 400 , 500 , and 600 ) . Here , we outline how we preprocess the data and arrive at K = [ 400 - 600 ] based on several fit metrics . Preprocessing Texts and Fitting STMs We preprocess the data by the following steps . We remove stand - alone numbers , punctuation , English stop words , and special characters from the text . However , we keep numbers belonging to terms such as molecules ( e . g . , H2S ) , which might refer to substantive concepts . We then stem the words using the Snowball algorithm and remove those tokens that only appear once across all documents . We extract n - grams for sequences of words that occur more frequently than by chance using El - Kishky et al . ’s method ( 2 ) . We then fit STMs at K [ K = 50 - 1000 ] in incremental steps of 50 ( and steps of 100 when K > 600 to reduce computing time ) by training each for 20 epochs . Internal validation We then internally validate the models to find out what number of topics retrieves the most - discriminant latent thematic dimensions ; which is equivalent to finding the dimensionality reduction solution that retains the most information about the corpus . To do so , we consider both the coherence and exclusivity ( 1 , 3 ) of the topics produced by models at different values of K . The coherence of a topic assesses its internal consistency . Semantic coherence is obtained by calculating the frequency with which high - probability words within a given topic co - occur in documents . The most - probable words in a highly - coherent topic tend to appear together in documents . Conversely , a low - coherence topic comprises high - probability words that appear in isolation from each other . It would be difficult to argue that a low - coherence topic is of much use in representing documents , since it can appear in multiple documents with very different terms . 28 Assessing topics solely on their semantic coherence is not enough , since this measurement can be trivially maximized by reducing the number of topics . For instance , if we had a single topic , high - probability terms would co - occur by construction . Similarly , a topic that comprises very common words of a topic ( e . g . , data , study , etc . ) will appear to be very coherent since these terms co - occur in most documents by convention . Therefore , as a complement to semantic coherence , we want our model to produce topics that have very distinct high - probability terms ; that is to say , we want topics with high exclusivity . Exclusivity measures the extent to which words within a topic are distinct from the words in other topics . There is a trade - off between a topic’s exclusivity and semantic coherence – i . e . , overall high - probability words tend to drive very coherent topics , since they are likely to co - occur ; but these words also tend to co - occur with the terms from many topics , and so they drive low exclusivity topics . Given this trade - off , we explore the solution space along values of K looking for the model where both exclusivity and coherence plateau and do not improve nor decrease with a lower or higher number of topics , thus providing us with a potential limit for K . Figures S4 - a and S4 - b shows that this limit is likely to be in the range of K = 400 - 600 . External validation In addition to internal validation , we also employ external validation . To this end , we compare the distance between documents based on an STM with a given K with the document distances based on author - provided keywords and fields . We use the academic fields and keywords that students file with their dissertations . We draw a random sample of 1000 documents that remains constant across values of K , and compute the cosine similarity between document pairs in this sample based on the documents’ topic mixtures . In so doing , we leverage that all document pairs are comparable in vector θ , which represents any given document as a probability distribution over all topics . We 29 then consider any given document pair to be related if their cosine similarity is greater than the median similarity in the sample . For the field and keyword relations between documents , we consider whether bigrams ( fields + keywords ) occurring within a document co - occur between two documents ; when this is the case , we render these documents related . We represent the relations described above as two document - to - document networks , one STM - based and one bigram - based network , and study their overlap . We are interested in four kinds of comparisons at the level of document dyads , which we can picture as a two - by - two matrix where the rows indicate if a document dyad appears in the STM - based network ( Yes / No ) and the columns indicate if the dyad appears in the bigram - based network ( Yes / No ) . Given the comparisons of interest , we compute the Matthew correlation coefficient , which measures the overlap at the dyad level between the STM and bigram networks . An advantage of the Matthew correlation metric is that it accounts for overlap on true negatives ( i . e . , when a document dyad does not appear in either the STM or the bigram network ) . The Matthew correlation coefficient is defined as follows : Matthew correlation = TP × TN - FP × FN ( ( TP + FP ) ( TP + FN ) ( TN + FP ) ( TN + FN ) ⁄ , where T and F define true and false , and P and N define positives and negatives . Figure S4 - c depicts the result of the correlations between keyword and STM relations . We find that the curve follows a similar trend compared to the internal validity metrics . There is a decrease as K moves beyond 500 , providing some external validation with user - labeled information that the number of topics seems to optimize around K = 500 . Consistency Additionally , we study the consistency of topic assignments across the range of K [ 50 - 1000 ] – i . e . , whether the topics retrieved at one value of K are informative of the topics obtained at another 30 value . To this end , we first classify all documents by their highest - proportion topic at each value of K . This step results in a set of classification schemes , one scheme for each model with a different value of K . We then compare the classification schemes of consecutive models ( i . e . the document classification under K = 50 compared to the classification under K = 100 ) using the Fowlkes - Mallows index ( FM ) . In Figure 4 - d we describe the rate at which the overlap between classification schemes vary when comparing each model with K topics to the immediate prior model with smaller K . We see relatively high values of consistency with a gradually growing curve , which suggests that classification schemes are more similar at the higher end of values of K . The range of K suggested by FM is in line with the previous measures : we see a steady rise until K = 450 and only a gradually improvement afterwards . Raw FM scores suggest that more than two - thirds of document - to - topic assignments are stable from K = 450 . The “Right” K Finally , we emphasize that we do not use the “right” K , as that would imply that we are perfectly aware of the topic ( and , hence , scientific ) universe . We use K = 500 in the main text as the metrics all seem to plateau around that value . However , if we choose K = 400 or K = 600 and measure concept / link introduction and uptake in a similar way ( using low , medium , and high FREX - weight ) , our results do not qualitatively change . The “right” K – if one is to interpret that as the set number of scientific topics at the specialization within disciplines level – likely is somewhere between 400 - 600 . A benefit of our approach , and what our associated results show , is that the results stay qualitatively similar whichever K ( 400 , 500 , or 600 ) we choose . 31 On Analyzing Abstracts Versus Full Texts We analyze dissertation abstracts based on the conjecture that abstracts are a good approximation of the knowledge and concepts that populate full texts . Prior work consistently shows that this conjecture is a reasonable one , as abstracts provide a clean , uncluttered synthesis of the full text . Prior work suggests that the goal of abstracts is to summarize and emphasize a paper’s key contributions ( 4 ) . Empirical work observes that abstracts provide sufficient syntheses of concepts , tables , graphs , and topics in papers ( 5 - 7 ) . Pragmatic arguments in favor of using abstracts is that the use of full text is highly restricted by its general inaccessibility , poor scalability , and high demand on computational resources for large corpora . In contrast , abstracts are easier to obtain and typically demand far fewer computational resources . Additionally , with the use of full text come some theoretical difficulties . For instance , if we study concept co - occurrence in full text , at what distance do concepts need to co - occur in order to render the co - occurrence substantively meaningful ? In the same text , section , paragraph , or sentence ? Co - occurrences in abstracts are far more likely to be substantively meaningful as abstracts only cover ~ 10 sentences . Finally , our main results would only qualitatively change if numerical minorities write abstracts that are inherently different compared to those written by majorities . Given the general goal of abstracts – i . e . , summarizing main contributions and findings ( 4 ) – we assume that the retention of innovations in abstracts versus full text is not higher ( or lower ) for numerical minorities vis - à - vis majorities . Student Gender and Race The ProQuest corpus ( 8 ) does not contain records of gender and race of students that filed their theses . Therefore , we predict the race and gender of students based on their first ( gender ) and last ( race ) names ( 9 ) . For race , we compiled US Census data of 2000 and 2010 ( 10 ) . These censuses 32 show relative frequencies of racial backgrounds of last names that occur more than 100 times ( N = 167 , 409 distinct last names that cover > 95 % of the US population ) . For instance , it shows the fraction of individuals who carry the last name “Jones” whom are white . The correlation in racial background percentages of overlapping names ( N = 146 , 516 ) in both censuses is . 99 . For gender , we compiled data of the US Social Security Administration ( 11 ) . This corpus shows the fraction of girls and boys among the top 1000 first names from people born from 1900 to 2016 ( N = 96 , 122 distinct first names that occur at least five times ) – e . g . , the fraction of girls named “Jane . ” We matched distinct last names of the censuses to the last names ( up to the first space or hyphen ) in data from Stanford University where we are aware of self - reported race ( N total = 24 , 150 ; N match = 20 , 264 [ 83 . 9 % ] ) . We matched all distinct first names of the social security data to the first names in the Stanford University data where we are aware of self - reported gender ( N total = 35 , 469 ; N match = 31 , 026 [ 87 . 5 % ] ) . An algorithm automatically traced which thresholds of the fraction of the last - and first - name carriers’ race and gender yield the highest possible correlations between real and assigned gender or race . It did so by correlating self - reported gender and race with all permutations of the thresholds in steps of 1 percent . A threshold where at least 71 . 45 % of the first - name carriers are female to assign students to a female gender provided the highest correlation between self - reported and assigned gender ( r = . 91 ) . Additionally , the highest correlations for race were . 83 ( white , 12 , 929 of 13 , 197 identified correctly [ 97 . 2 % ] ) , . 93 ( Asian , 5 , 079 of 5 , 436 identified correctly [ 93 . 4 % ] ) , . 73 ( Hispanic , 698 of 992 identified correctly [ 70 . 4 % ] ) , and . 25 ( Other Race , only 63 of 639 identified correctly [ 9 . 9 % ] ) . We are aware that the fraction of correctly identified in the “Other Race” category is low . We found that these students are predominantly labelled under “white” ( 528 white out of 639 Other Race ) . We assume that labelling these individuals under white makes 33 analyses of racial inequalities more - conservative , given prior findings of racial inequality American higher education . Essentially , we might underestimate our effect when one group that has higher likelihood of innovation or lower likelihood of recognition than white students and that group is labelled under the white students category . Using these thresholds , we classify students into a racial background and gender . If students are classified into multiple races given our thresholds , we use a decision rule ; ( 1 ) when a students was classified into the “Other Race” or any other category , we classify him / her as “Other Race” ; ( 2 ) when a student was classified into the “Hispanic” and “white” or “Asian” category , we classify the student as “Hispanic” ; ( 3 ) when students were classified into the “Asian” and “white” category , we classified the student as “Asian” category . Finally , if the thresholds did not classify a student into a category , we used a majority rule to categorize the student into a race . For instance , when “Yao” does not meet a threshold while most individuals named “Yao” are in fact Asian we classify these as “Asian . ” Academic Discipline To infer discipline degree for those who did not file it to ProQuest database by students , all theses with departments in ProQuest were first extracted . Each department was then semi - manually canonicalized to a National Research Council ( NRC ) department . Given that there are many spelling mistakes , a fuzzy string matching was used to match the ProQuest department with the actual listed NRC departments based on a 90 % string similarity ( a manual analysis showed 100 % accuracy ) . For the frequent department names that matched around and 70 - 89 % to an NRC department , each canonicalization from ProQuest to NRC were manually verified ( while rejecting those that were invalid ) . All dissertations whose department name could not be mapped to an NRC 34 department had their department inferred as if it had not been listed . We used the successfully matched dissertations with an NRC department ( N = 178 , 511 ) as a ground truth . Next , we trained a Random Forest Classifier ( RFC ) based on a list of features from the dissertation ; binary features for whether the dissertation was listed with an NRC subject category , binary features for whether the dissertation was listed with ProQuest subject category , all keywords used for the dissertation , the topic distribution of the dissertation abstract using a 100 - topic Latent Dirichlet Allocation model , the average Word2Vec word vector for each of the ( 1 ) keywords , ( 2 ) ProQuest fields , ( 3 ) NRC fields , and ( 4 ) title , and the degree - granting university . The RFC infers department degree with 96 % precision ( N DISCIPLINE = 84 ) . Population Coverage and Data Weights During the study period ( 1980 – 2010 ) approximately 1 . 2 million doctorates were awarded in total . This suggests that the ProQuest data cover approximately 86 % of the total number of US doctorates over three decades . If we plot the ProQuest database and the population of awarded doctorates in the US over time , the rends are highly similar . In our inferential analyses , we weigh the data by the total number of doctorates awarded by an institution in a given year 9 to account for possible selectivity between universities in years in filing their doctorates’ theses in the ProQuest database . To do this we calculate for each distinct year - university combination ( e . g . , at Harvard University in 1987 ) the number of PhD recipients and divide this number by the total number of PhD recipients in the ProQuest data , 1980 – 2010 . This yields the relative number of PhD recipients in the ProQuest data per year for each university . We repeat this calculation for the total PhD recipients according to the data from the National Science Foundation . We then divide the relative number of PhD recipients for the university - year combinations in the ProQuest data by the relative 35 number of PhD recipients for the university - year combinations in the census to obtain our data weights . We use these weights as survey weights in our inferential analyses . For the negative binomial outcomes ( # new links and payoff per link ) , we use the “Zelig” R - package to use survey weights and for computational speed and parallelization . The weights are continuously valued , and in that case Zelig’ bootstraps the data and uses the relative weights as bootstrap probabilities . The expected values ( keeping other variables at their means ) in Figure 2 , panel b are computed using custom code in R . For the binary outcome models ( i . e . , career recognition ) , we use Stata 13 for the inferential analyses and to compute adjusted probabilities in Fig 4 . Linking ProQuest to Web of Science We attempt to link each student in the ProQuest corpus to their corresponding identity in two sets of publication corpora , specifically the Web of Science ( WoS ) obtained from Clarivate Analytics . The first set contains publications from 1900 to 2009 ( ~ 22 million ) and the second set contains publications from 2009 to 2017 ( ~ 16 million ) . The matching process between ProQuest and both WoS corpora relies on substantial meta - data in each of the three data sources . The pre - 2009 WoS data does not contain canonical author identifiers with high precision so we use a disambiguated author cluster ( 12 ) , which contains groups of publication records in WoS estimated to be authored by the same person with substantial certainty ( 83 % ) . The post - 2009 does contain disambiguated authors by Clarivate Analytics with substantial accuracy post - 2009 , but with poor accuracy pre - 2009 . In order to make optimal use of both disambiguated datasets , we needed to reconcile the pre - 2009 clusters and the post - 2009 clusters . Hence , the goal is to link these two author - disambiguated datasets so as to benefit from the high accuracy from both datasets across the whole time range and increase coverage throughout . We pinpointed which author - 36 clusters in the pre - 2009 set were which clusters in the post - 2009 set . We generated a link between the pre - 2009 and the post - 2009 author clusters , indicating that both clusters are the same author , if any of the following conditions were met , in addition to sharing a full name : 1 – 75 % of the pre - 2009 cluster articles are a subset of the post - 2009 cluster articles ; 2 – There is at least one matching email address between an old cluster and a new cluster . Once these rules were applied , we finished cluster linking by manually checking and verifying a random sample of entries , in addition to automated verification of linking rules being followed on a larger random sample . The method above is conservative in its creation of links as a result of the strictness requiring a 75 % match in order to link . This approach prioritizes the reduction of mistakenly - linked clusters at the expense of undiscovered linkages . Precision of the line - up between the two sets is 97 % , which we inferred from a set of online , self - labeled publications by scholars that Clarivate Analytics provided ( ResearcherID ) . In turn , matching between WoS ( linked pre - and post - 2009 ) follows a multi - step sieve process , where scholar matches are evaluated using multiple successive criteria starting with the highest - confidence first : ( 1 ) number of article co - authorships with a known advisor or advisee , ( 2 ) number of articles where the WoS author is at one of the same institutions from the ProQuest data ( as an advisor or advisee ) , ( 3 ) number of article keywords matching those from their dissertation keywords , ( 4 ) minimum string similarity of the authors’ names ( as reported for each article ) with the name in ProQuest , and ( 5 ) textual similarity of the articles’ abstracts and titles with the dissertation abstract . For naming similarity , our method is robust to minor typographic errors in names ( as ProQuest information is manually entered ) and to recognized naming variants ( e . g . , Dave or David ) and abbreviations in the first and middle names of the individuals . This entire 37 matching process amounts to a maximum bipartite matching of the ProQuest and WoS authors , ensuring that one author from either side is never linked to more than one author on the other side . As this matching process could potentially be noisy , we take additional steps to heuristically reduce the potential for mismatches . First , we restrict WoS matches to only those individuals whose publication history is similar to their graduation date ; this restriction excludes matching those individuals whose nearest publication date is 15 years after or 10 years before graduation . Second , we avoid matching individuals where the bulk of their publication occurs before their graduation , except in the case where there is additional evidence to support the matching from co - authorship with their advisor . Third , we avoid matching individuals whose only evidence for being the same person is their name similarity and a textual similarity between their dissertation and the articles ( e . g . , no evidence of being at the same institution where they would have graduated or advised students ) . 38 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 10 100 1000 # new links D en s i t y # New links a 0 50 100 150 200 250 1980 1990 2000 2010 Year of graduation M # ne w li n ks b 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 1e + 00 1e + 01 1e + 02 1e + 03 1e + 05 # total uptakes D en s i t y # Total uptakes c 0 2000 4000 1980 1990 2000 2010 Year of graduation M # up t a k e li n ks d 0 . 0 0 . 2 0 . 4 0 . 6 1 10 100 payoff per link D en s i t y Payoff per link e 0 5 10 15 20 1980 1990 2000 2010 Year of graduation M pa y o ff pe r li n k f K & FREX values : k400 , freq75 / excl25 k400 , freq50 / excl50 k400 , freq25 / excl75 k500 , freq75 / excl25 K500 , freq50 / excl50 K500 , freq25 / excl75 k600 , freq75 / excl25 K600 , freq50 / excl50 K600 , freq25 / excl75 k400 , 75 / 25 k400 , 50 / 50 k400 , 25 / 75 k500 , 75 / 25 k500 , 50 / 50 k500 , 25 / 75 k600 , 75 / 25 k600 , 50 / 50 k 400 , 50 / 50 k 400 , 25 / 75 k 500 , 75 / 25 k 500 , 50 / 50 k 500 , 25 / 75 k 600 , 75 / 25 k 600 , 50 / 50 k 600 , 25 / 75 0 . 00 0 . 25 0 . 50 0 . 75 1 . 00 Correlation # new links g k400 , 75 / 25 k400 , 50 / 50 k400 , 25 / 75 k500 , 75 / 25 k500 , 50 / 50 k500 , 25 / 75 k600 , 75 / 25 k600 , 50 / 50 k 400 , 50 / 50 k 400 , 25 / 75 k 500 , 75 / 25 k 500 , 50 / 50 k 500 , 25 / 75 k 600 , 75 / 25 k 600 , 50 / 50 k 600 , 25 / 75 # total uptake h k400 , 75 / 25 k400 , 50 / 50 k400 , 25 / 75 k500 , 75 / 25 k500 , 50 / 50 k500 , 25 / 75 k600 , 75 / 25 k600 , 50 / 50 k 400 , 50 / 50 k 400 , 25 / 75 k 500 , 75 / 25 k 500 , 50 / 50 k 500 , 25 / 75 k 600 , 75 / 25 k 600 , 50 / 50 k 600 , 25 / 75 Payoff per link i Figure S1 . Distribution of innovation and impact a , c , e . Density distributions of innovation and impact scores for different a different number of K and different scenarios for FREX ( medium , low , or high frequency or exclusivity ) . Despite absolute differences , the distributions are highly akin , which is also reflected in qualitatively similar inferential results across these different scenarios . b , d , f . The figures over time show a decreasing effect for innovation and impact . As time increases , it becomes harder to introduce new links in the corpus , as the scientific concept space and their co - occurrences become increasingly crowded . Additionally , as time increases students have less impact as there is less time to have links taken up . Therefore , we include time fixed - effects in our inferential analyses . g , h , i . The figures show Pearson correlations between the different numbers of K and FREX scenarios ( all p < . 001 ) . Generally , the correlations are high ( > r = . 6 ) . Scenarios that are conceptually closer – e . g . , high K and high frequency – correlate higher . 39 Agric Sci Bio & Health Educ Engin Human Phys & Math Social Sci 0 . 4 0 . 6 0 . 8 1980 1990 2000 2010 Year F r a c t i on m a l e sc ho l a r s Male scholars in field a Agric Sci Bio & Health Educ Engin Human Phys & Math Social Sci 0 . 4 0 . 6 0 . 8 1980 1990 2000 2010 Year F r a c t i on m a j o r i t y r a c e sc ho l a r s Size of numerical gender majority in field b Agric Sci Bio & Health Educ Engin Human Phys & Math Social Sci 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 1980 1990 2000 2010 Year F r a c t i on w h i t e sc ho l a r s White scholars in field c Agric Sci Bio & Health Educ Engin Human Phys & Math Social Sci 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 1980 1990 2000 2010 Year F r a c t i on m a j o r i t y r a c e sc ho l a r s Size of numerical racial majority in field d Figure S2 . Gender and racial representation of students in academic fields over time a - d . We aggregate the disciplines into broader academic fields for a clearer visual depiction of minority statuses . Across all fields , women and non - White students are numerical minorities frequently . a . Women become numerical majorities ( and men minorities ) when the fraction of male students drops below . 5 ( education > 1983 , and biology & health , humanities , and social sciences approximately > 1998 ) . b . Numerical gender majorities cannot drop below . 5 by design . c - d . In few cases non - White students become numerical racial majorities ( i . e . , only if white < . 5 ) . However , becoming a numerical racial majority is not a given when white < . 5 , as there are more than two racial groups – i . e . , whites ( or another group ) might still be majorities if the remaining fraction is split into several smaller nonwhite subgroups . 40 E ff e c t s o f # ne w li n ks k400 , freq75 / excl25 k400 , freq50 / excl50 k400 , freq25 / excl75 k500 , freq75 / excl25 k500 , freq50 / excl50 k500 , freq25 / excl75 k600 , freq75 / excl25 k600 , freq50 / excl50 k600 , freq25 / excl75 0 . 000 0 . 025 0 . 050 0 . 075 Odds ratio difference for elite research faculty log ( # new links ) on elite research faculty a E ff e c t s o f pa y o ff pe r li n k k400 , freq75 / excl25 k400 , freq50 / excl50 k400 , freq25 / excl75 k500 , freq75 / excl25 k500 , freq50 / excl50 k500 , freq25 / excl75 k600 , freq75 / excl25 k600 , freq50 / excl50 k600 , freq25 / excl75 0 . 0 0 . 1 0 . 2 0 . 3 Odds ratio difference for elite research faculty log ( payoff per link ) on elite research faculty b E ff e c t s o f # ne w li n k s k400 , freq75 / excl25 k400 , freq50 / excl50 k400 , freq25 / excl75 k500 , freq75 / excl25 k500 , freq50 / excl50 k500 , freq25 / excl75 k600 , freq75 / excl25 k600 , freq50 / excl50 k600 , freq25 / excl75 0 . 00 0 . 01 0 . 02 0 . 03 0 . 04 Odds ratio difference for cont . research log ( # new links ) on cont . research c E ff e c t s o f pa y o ff pe r l i n k k400 , freq75 / excl25 k400 , freq50 / excl50 k400 , freq25 / excl75 k500 , freq75 / excl25 k500 , freq50 / excl50 k500 , freq25 / excl75 k600 , freq75 / excl25 k600 , freq50 / excl50 k600 , freq25 / excl75 0 . 000 0 . 025 0 . 050 0 . 075 0 . 100 0 . 125 Odds ratio difference for cont . research log ( payoff per link ) on cont . research d Figure S3 . Innovation and impact positively correlates with career recognition a - d . Correlations of innovation ( log ( # new links ) ) and impact ( log ( payoff per link ) ) with career recognition as finding an elite faculty position or academic position . At all K and FREX scenarios our metrics for innovation and impact are significantly and positively related to career outcomes . Throughout our sensitivity analyses , the pattern of results is similar – i . e . , minorities innovate with a minority discount on their inventions – whereas here we find a statistically distinct signal for the different scenarios on career recognition . Correlations of innovation and impact with careers seem to decrease with higher exclusivity . The results suggest a pattern where a more - frequent lexicon more - positively relates to careers ( particularly so for impact ) . 41 − 175 − 150 − 125 250 500 750 1000 K C ohe r en c e Coherence a 9 . 85 9 . 90 9 . 95 250 500 750 1000 K E xc l u s i v i t y Exclusivity b 0 . 18 0 . 20 0 . 22 0 . 24 250 500 750 1000 K M a tt he w c o rr e l a t i on Matthew correlations c 0 . 4 0 . 5 0 . 6 0 . 7 250 500 750 1000 K F M I nde x Fowlkes − Mallows indices d Fig S4 . Internal and external validity and coherence for structural topic models . a - d . We highlight the range of K we use ( K = 400 - 600 ) , see Supplementary Methods for detailed information on these metrics and their associated logic . a - b . Values of coherence and exclusivity across a range of K . With a rising number of topics exclusivity increases but plateaus at approximately K = 400 , while coherence decreases somewhat continuously , although less steep from K = 400 . c . Matthew correlations between external relations between documents and keywords and relations between documents derived from the topic models . d . Fowlkes - Mallows indices indicating overlap of topic - assignments for consecutive K’s . The Fowlkes - Mallows correlation plateaus from approximately K = 400 and onwards , with a spike at about K = 600 . 42 Table S1 . Sensitivity analyses across K and FREX scenarios show a similar pattern of results . We find a qualitatively similar pattern of results across our K and FREX scenarios . This shows that our main results are insensitive to the way we extract concepts – i . e . , weighing more to frequency or exclusivity – despite that the quantitative correlations might vary across scenarios . Possibly , the quantitative variation is due the direct effect of innovation and impact on career recognition that varies across the scenarios ( see Figure S3 ) . Here , we show that either linking frequent or exclusive terms in novel ways discounts novelty of underrepresented groups . There is one exception to this discount rule ; racial minorities do not face discounted impact at K = 400 with high exclusivity . Interestingly , the latter is the scenario with the lowest median number of new links , suggesting that in a space with the fewest potential links of highly - exclusive concepts there is no innovation discount between racial groups . We present the “middle” scenario as the main one in the paper ( K500 , freq50 / excl50 ) . K 400 , f r e q 75 / ex c l 25 K 400 , f r e q 50 / e xc l 50 K 400 , f r e q 25 / ex c l 75 K 500 , f r e q 75 / e xc l 25 K 500 , f r e q 50 / e xc l 50 K 500 , f r e q 25 / e xc l 75 K 600 , f r e q 75 / ex c l 25 K 600 , f r e q 50 / ex c l 50 K 600 , f r e q 25 / e xc l 75 Gender minorities ↑ # new links ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Racial minorities ↑ # new links ? No No No Yes Yes Yes Yes Yes Yes Threshold effect gender representation on innovation ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Gender minorities ↓ payoff per link ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Racial minorities ↑ payoff per link ? Yes Yes Yes Yes Yes Yes Yes Yes No Innovation discount Gender minorities innovation discount for elite faculty ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Gender minorities innovation discount for cont . research ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Racial minorities innovation discount for elite faculty ? No No No No No No No No No Racial minorities innovation discount for cont . research ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Impact discount Gender minorities impact discount for elite faculty ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Gender minorities impact discount for cont . research ? Yes Yes Yes Yes Yes Yes Yes Yes Yes Racial minorities impact discount for elite faculty ? Yes Yes No Yes Yes Yes Yes Yes Yes Racial minorities impact discount for cont . research ? Yes Yes Yes Yes Yes Yes Yes Yes Yes 43 Supplementary References 1 . M . E . Roberts et al , Structural Topic Models for Open - Ended Survey Responses . American Journal of Political Science 58 , 1064 - 1082 ( 2014 ) . 2 . A . El - Kishky et al , Scalable Topical Phrase Mining from Text Corpora . Proceedings of the VLDB Endowment 8 ( 2014 ) . 3 . Mimno , D . , Wallach , H . M . , Talley , E . , Leenders , M . , & McCallum , A . Optimizing Semantic Coherence in Topic Models . Proceedings of the Conference on Empirical Methods in Natural Language Processing , 262 - 272 ( 2011 ) . 4 . C . Orasan , “Patterns in Scientific Abstracts” in Proceedings of Corpus Linguistics 2001 Conference , P . Rayson , A . Wilson , T . McEnery , A . Hardie , S . Khoja , Eds ( Lancaster , 2001 ) , pp . 433 – 443 . 5 . H . Yu , M . Lee , Accessing Bioscience Images from Abstract Sentences . Bioinformatics 22 , e547 - e556 ( 2006 ) . 6 . P . K . Shah , C . Perez - Iratxeta , P . Bork , M . A Andrade , Information Extraction from Full Text Scientific Articles : Where are the Keywords ? BMC Bioinformatics 4 , 1 - 9 ( 2003 ) . 4 . M . J . Schuemie , M , et al , Distribution of Information in Biomedical Abstracts and Full - Text Publications . Bioinformatics 20 , 2597 - 2604 ( 2004 ) . 7 . S . Syed , M . Spruit , Full - text or Abstract ? Examining topic Coherence Scores Using Latent Dirichlet Allocation . 2017 IEEE International conference on data science and advanced analytics , 165 - 174 ( 2017 ) . 8 . ProQuest . ProQuest : Ready to Do Some Research ? ( 2019 ) . At < http : / / www . proquest . com / > 9 . Hofstra , B . , Corten . R . , Van Tubergen , F . , & Ellison , N . C . Sources of Segregation in Social Networks : A Novel Approach Using Facebook . American Sociological Review 82 , 625 - 656 ( 2017 ) . 10 . US Census Bureau . Frequently Occurring Surnames from the Census . ( 2017 ) at < https : / / www . census . gov / topics / population / genealogy / data / 2000 _ surnames . html > 11 . Social Security Administration . Popular Baby Names . ( 2017 ) . at < https : / / www . ssa . gov / oact / babynames / limits . html > 12 . M . Levin , S . Krawczyk , S . Bethard , D . Jurafsky , Citation - Based Bootstrapping for Large - Scale Author Disambiguation . Journal of the American Society for Information Science and Technology 63 , 1030 - 1047 ( 2012 ) .