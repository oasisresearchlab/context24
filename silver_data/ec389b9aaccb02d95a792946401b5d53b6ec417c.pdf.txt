Power and Public Participation in AI Eric Corbett Google Research New York , New York , USA ecorbett @ google . com Remi Denton Google Research New York , New York , USA dentone @ google . com Sheena Erete University of Maryland College Park , Maryland , USA serete @ umd . edu ABSTRACT The rapid growth of AI in contemporary life has outpaced the public participation necessary for society to determine how these tech - nologies should be used . As scholars respond to this challenge by exploring new modes of public participation in AI , we help advance these efforts by introducing influential work from public planning scholarship , the Ladder of Citizen Participation , as an analytical lens to help compare and contrast power in this work . We used the ladder to analyze participatory approaches to AI development in recent scholarship , finding that most of this work informs or consults rather than partners with or delegates control to partici - pants . We also found that papers frequently reflect a writing style that makes it difficult to ascertain the degree of power afforded . We discuss implications from our work for powerholders ( developers , researchers , practitioners ) offering participatory approaches to AI and for people ( specific communities , stakeholders , general public ) participating in those processes . KEYWORDS power , participatory AI , participatory design , human - centered AI , algorithmic decision making , democracy , machine learning , public participation , AI , algorithms ACM Reference Format : Eric Corbett , Remi Denton , and Sheena Erete . 2023 . Power and Public Partic - ipation in AI . In Equity and Access in Algorithms , Mechanisms , and Optimiza - tion ( EAAMO ’23 ) , October 30 – November 01 , 2023 , Boston , MA , USA . ACM , New York , NY , USA , 13 pages . https : / / doi . org / 10 . 1145 / 3617694 . 3623228 1 INTRODUCTION In response to concerns regarding the moral , ethical , and politi - cal impacts that AI technologies have on contemporary life [ 1 – 5 , 10 , 30 , 46 ] , calls for more public participation are growing . A common idea underlies these calls : by participating in development , people ( i . e . , end - users , citizens , communities , the general public ) can become empowered to determine the outcomes and consequences of AI systems . Computing and HCI scholars have responded to these calls for participation with a wide array of approaches . For instance , Brown et al . employed storytelling and group interviews with communities involved with child welfare services to allow them to participate in redesigning a risk assessment algorithm [ 15 ] . Lee et al . used bottom - up democratic voting process that enabled Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 979 - 8 - 4007 - 0381 - 2 / 23 / 10 . https : / / doi . org / 10 . 1145 / 3617694 . 3623228 stakeholders of a food donation allocation algorithm to participate in building computational models that reflected their views [ 43 ] . Suresh et al . drew from feminist principles to create partnerships with activist groups who participated in developing ML data - sets and models for monitoring gender - based killing of women and girls [ 65 ] . While these projects differ in context and method , each features a participatory approach that gives people ( in varying degrees ) power to help determine how an AI system should work . One challenge this growing body of scholarship will need to address is coming up with a way to compare and contrast how the power afforded to people changes depending on the approach . Enabling such comparisons matters for setting expectations and creating accountability between the researchers and practitioners developing AI systems and the general public and stakeholders participating in those development processes . To this end , we intro - duce the public administration scholar Sherry Arnstein’s influential Ladder of Citizen Participation [ 7 ] . Arnstein’s work uses a visual metaphor ( Figure 1 ) , an eight rung ladder , where each rung depicts the degree of power afforded to people by different approaches to participation . The higher up the ladder the participation approach is ( eight being the highest and one being the lowest ) , the more power people have when engaging in public planning of their com - munities . Arnstein developed the ladder to help people who have been disenfranchised enact meaningful social reform by reclaiming power from authorities during participation processes in commu - nity development [ 31 ] . By making power explicit in participation , the ladder became an effective tool to compare empty and manipu - lative approaches to citizen participation efforts against meaningful and legitimate approaches [ 6 ] . Given its success and familiarity , we were motivated to explore how it might help assess and compare participatory approaches to AI . To explore the utility of the ladder for understanding power in participatory approaches to AI , we used it to analyze papers from the ACM digital library . We looked for papers that talked about how people participated in the design process of an AI system or pro - vided a technique or process intended to be used in a participation process related to AI . Our goal was not to conduct an exhaustive re - view , but rather to find a set of papers to read against the ladder and identify exemplars for each rung . We found 21 papers that reported on the participatory approaches and then analyzed these papers with Arnstein’s ladder as a heuristic , mapping each paper to one of the the eight levels of power provided by the ladder . We found most of the papers were informing or consulting the public ( lower rungs on the ladder which indicates less agency ) on AI , rather than partnering with or delegating control ( higher rungs on the ladder which indicates more agency ) directly in design . Moreover , we also found many of the papers report on participation in such way that often depoliticises the processes they designed even while they EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Corbett et al . make claims about how empowering their approaches are . As a result , it is hard to assess the degree of power actually afforded . This paper makes several contributions . First , our analysis pro - vides insight into , and evaluation of , public participation in AI scholarship , answering calls to create more equitable methods of participation in the development of AI technologies [ 10 , 19 , 30 , 46 ] . Second , we demonstrate how Arnstein’s ladder can provide a heuris - tic for understanding how power is ( or is not ) redistributed within participatory approaches to AI development , building on critical perspectives of participation in AI and how to make those processes more equitable [ 19 , 51 , 61 , 62 ] . Thirdly , our project extends prior literature that highlights the need for methods that better center equity and community expertise [ 21 , 33 ] by calling attention to the various dimensions of public participation in AI development and by introducing a method to analyze and evaluate these dimensions . Lastly , this paper illustrates the need for stronger reflexivity and deeper engagement with sociopolitical conditions of participation , extending existing literature in HCI and AI scholarship [ 19 , 25 , 51 ] . 2 RELATED WORK 2 . 1 Power and Participation in AI The growing body of interdisciplinary scholarship on algorithmic injustice and bias has called attention to the moral , ethical , and political impacts of AI systems [ 10 , 30 , 46 , 48 , 54 ] . Society has re - sponded to this scholarship by advancing an array of solutions to mitigate algorithmic injustice : training and tooling for AI practition - ers to encourage ethical development practices [ 23 , 37 ] ; governance mechanisms to institute ethical research standards for researchers [ 52 ] ; litigating and legislating frameworks for lawyers and elected officials to develop laws and policy to govern AI [ 47 ] . While these solutions are a necessary step to critically engage those who create AI , these expert - based approaches not only miss the fundamental challenge AI presents for society , but have the potential to further compound the problem by not including the voices of those most impacted by the outcomes of unfair and biased AI technologies [ 61 , 62 ] . Given the negative impact of biased AI technologies and the lack of opportunity to meaningfully participate in the develop - ment of AI tools , AI has risks creating a state of algrocacy , “when ‘authority becomes embedded in the technology itself [ 22 ] . ” Algro - cracy is at odds with methods that aim to democratize AI : on one hand , it centralizes the power of technical elites by allowing them to encode their values into the delivery of public services ; and on the other , it disfranchises populations that are rarely represented in development and decision - making . From this standpoint , expert - based solutions to algorithmic injustice contribute to the growth of algrocacy by resolving issues of bias and fairness without ever opening these issues to the public . There has been a push to incorporate more participatory methods in AI developments processes in order to create more transparent , fair , and equitable systems [ 10 , 19 , 61 , 62 ] ; however , those efforts are not without concern or criticism [ 14 , 51 , 61 , 62 ] . Sloane et al . [ 61 ] warns that much of the push towards participation in AI can result in “ participation washing , ” where participation is based on " man - ufactured consent and . . . ( post - ) colonial structures of global power " which can lead to community extraction rather than true power sharing . Participatory design methods have also been criticized due to the lack of acknowledgment of historical oppression structuring design spaces [ 13 , 14 , 19 , 33 ] . Recent work has examined participa - tory methods in AI literature and found variations in the type of participation that exists [ 19 ] . Here , there is a strong parallel with Arnstein’s work as it attempts to make clear “ that there are signifi - cant gradations of citizen participation ” depending on how officials engage with public participation [ 7 ] . The eight rungs in Arnstein’s ladder act as descriptive categories to understand power in public participation . In this paper , we leverage the ladder to examine how structure ( i . e . , relationships , infrastructures , and interactions ) and processes ( i . e . , methods of engagement ) define power during public participation in the development of AI tools and technologies . 2 . 2 Entry Points for Public Participation The development process of most contemporary AI systems typi - cally has four interconnected steps : problem formulation ; dataset development ; model design and training ; deployment and monitor - ing . Each of these steps offers an entry point for public participation . In the first step , problem formulation , high - level goals or objectives are translated into a problem that can be parsed and acted on by a computational system . Problem formulation is often shaped by a multitude of different actors , who negotiate their aspirations and practices within a web of technical , organizational , legal , and eco - nomic constraints . Decisions made at this stage embed normative commitments , beliefs , and values of those formulating the prob - lem and their perspective and play a consequential role in shaping downstream design decisions , making it one of the most opportune ( and consequential ) entry point for public participation [ 44 , 49 ] . In the next step , dataset development , the formulated problem is translated into a machine - readable dataset that defines the problem in computational terms , often by providing examples of input data alongside the corresponding output an AI system ought to produce . AI datasets have been heavily implicated in debates about algorith - mic injustices and play a consequential role in shaping downstream outcomes [ 50 , 55 ] . Decisions about what data to include ( or exclude ) , what categories should structure the data , and how key variables should be operationalized also inject normative political beliefs into the process [ 27 , 36 ] underscoring the importance of dataset development as an important entry point for public participation . In the third step of model design and training , a mathematical way of expressing relationships in the data is selected and optimized for the task at hand . The resulting model specifies a predictive mapping – a set of rules , in short – that can be applied to new data instances to make predictions . While this step is the most technical and thus least accessible for public participation , entry points are still present . For instance , different models come with varying de - grees of interpretability , which limit how well ( if at all ) they can be explained , examined , and audited . Likewise , measuring and defin - ing performance can be equally subjective . In many contexts , false positives and negatives are different types of errors with different risks for different people . Public participation can be brought to bear to balance the trade - offs between different modeling approaches or to co - determine how to measure overall performance . The last step of deployment and monitoring is when the system is deployed into the world , monitored , and potentially regulated by federal , state , or local government bodies . The performance and Power and Public Participation in AI EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Figure 1 : Arnstein’s typology of citizen participation is pre - sented as a metaphorical “ladder , ” with each ascending rung representing increasing levels of citizen agency , control , and power . Rung Papers Rung 8 : Citizen Control [ 45 ] Rung 7 : Delegated Power [ 43 ] , [ 68 ] Rung 6 : Partnership [ 42 ] , [ 58 ] , [ 65 ] Rung 5 : Placation [ 35 ] Rung 4 : Consultation [ 15 ] , [ 16 ] , [ 39 ] , [ 59 ] , [ 60 ] , [ 63 ] , [ 66 ] , [ 67 ] Rung 3 : Informing [ 9 ] , [ 11 ] , [ 38 ] , [ 40 ] , [ 53 ] Rung 2 : Therapy [ 56 ] Rung 1 : Manipulation — Table 1 : Papers mapped to Arnstein’s Ladder behavior of an AI system can change over time , and even impact the state of the world in ways that were not measurable at the time of deployment [ 24 , 28 ] . There may also be divergences between real - world data and the more controlled data an AI system was developed on , necessitating careful evaluations and monitoring under real - world conditions . Public participation is critical at this final touch point where AI meets society , to bring diverse communities into the monitoring and auditing frameworks and into AI policy decision making . These entry points for public participation guide our analysis alongside Arnstein’s ladder . The power afforded to people is de - pendant on which ( and how many ) entry point ( s ) they participate in and the extent to which they can influence decision making at each entry point . Notably , authors reporting of participation may themselves be limited in the entry points they can influence . For example , those best positioned to increase participation in the development of AI policy may not be similarly set up to increase participation in development pipelines . 2 . 3 The Ladder of Citizen Participation One of the most widely referenced and influential publications in the field of public planning is Sherry Arnstein’s " Ladder of Citizen Participation [ 7 ] . " The ladder is a visual metaphor that orders the degree of power afforded to citizens based on how government officials engage the public in local decision - making . Arnstein , a community advocate and social worker , developed the ladder from her experience working in the U . S . Department of Housing , Educa - tion , and Welfare ( HUD ) as the chief advisor of citizen participation in the Model Cities Program in the late 1960s [ 31 ] . At the time , what constituted citizen participation was not defined , resulting in a wide array of approaches that often ended up misleading or manipulating citizens rather than informing and empowering them . The Ladder of Citizen Participation was the culmination of Arn - stein’s efforts within HUD to stop this abuse [ 31 ] . Arnstein’s thesis is simple : " citizen participation is citizen power . " For her , power and participation are inseparable ; one cannot do participation without redistributing power : " it is the redistribution of power that enables the have - not citizens , presently excluded from the political and economic process , to be deliberately included in the future " [ 7 , p . 216 ] . With this central focus on power in mind , Arnstein examined various ap - proaches to citizen participation taken by municipalities applying for Model Cities funding . As a result of her analysis , she introduced a simple visual metaphor , an eight rung ladder , to illustrate the gradients of power distribution in public participation : ( 1 ) manipu - lation , ( 2 ) therapy , ( 3 ) informing , ( 4 ) consulting , ( 5 ) placation , ( 6 ) partnership , ( 7 ) delegated power , and ( 8 ) citizen control . Building on the growing interest and research on participatory AI , our field can leverage the Ladder of Citizen Participation’s public popularity , approach , and familiarity , using it as a boundary object [ 64 ] , to bridge the gap between publics demanding participation and the growing algrocacy . 3 APPROACH To explore the utility of Arnstein’s ladder , we identified a sample of papers that reported on how people participated in designing an AI system . The goal was not to create an exhaustive list of all literature on participatory AI practices , but instead to find a subset of scholarly publications that illustrate a range of approaches to - wards participation in AI development . To this end , we performed a keyword search of the Association for Computing Machinery ( ACM ) Digital Library 1 on every combination of terms from the fol - lowing two groups : ( i ) machine learning , AI , automated , algorithm ; ( ii ) public engagement , stakeholder , participatory , empowerment ( for instance , a search for “algorithm” AND “public engagement” ) for a total of 16 combinations of keyword queries . We examined the first 200 results for each of the 16 queries ( for a total of 3200 articles ) to see if it was a paper related to public participation and AI in any sense ; if so , it was initially included . In our review of the search results , the majority ( 3 , 138 or 98 % ) were categorized as unrelated , because there was either no mention of methods that included participants in the AI development process . We then ex - amined the remaining 62 papers to identify those that report on users participating in the development of a AI technique ( e . g . , a 1 http : / / dl . acm . org EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Corbett et al . novel value elicitation technique ) or in a process ( e . g . , a series of workshop activities ) . As a result , 21 papers fit this criteria . We analyzed how papers reported on the structural elements of the participation process : goals , relationships , and communica - tion . For goals , we look to where and by who did the goal of the participation process originate . For relationships , we look at how re - lationships are framed and the degree to which these relationships have clear accountability mechanisms in place . Communication focuses on how and where information flows . Generally speaking , we expect to see the following approaches to structure across the rungs : • Degrees of Power Rungs ( 8 - 6 ) : must feature some form of co - determining part of the structure or all of it . • Tokenism Rungs ( 5 - 3 ) : the structure is predetermined . • Non - Participation Rungs ( 2 - 1 ) : structure is predetermined , specifically to create structural conditions that render par - ticipation useless or performative . For the process , we focus on what entry points into the AI devel - opment phases were created and how people were able to control the decisions to move from phase to phase . Generally speaking , we expect to see the following kinds of process across the rungs : • Degrees of Power Rungs ( 8 - 6 ) : feature processes that are malleable and deferential to participant control . • Tokenism Rungs ( 5 - 3 ) : feature participation processes that are rigid and less deferential to participant control . • Non - Participation Rungs ( 2 - 1 ) : the process is generally irrel - evant in the sense that it is a sham in the grand scheme of things . In addition to structure and process , we summarized how each paper reported on participation . When unsure of how a paper re - lates to the Ladder , we discussed , documented , and further for - malized the criteria . As we discuss in more depth in Section 5 , we encountered several challenges w using the ladder for to analyz - ing participatory AI scholarship , due in part to a lack of details reported in publications and to gaps between Artnstein’s context and ours . Nonetheless , the ladder still offered a valuable analytic lens , revealing valuable insights about participation in AI . 4 FINDINGS The final corpus that we analyzed consisted of 21 papers , and they cover a broad range of domains : child welfare [ 15 , 16 ] , food dona - tion [ 43 ] , job placement [ 35 ] , housing [ 39 ] , library services [ 60 ] , surveillance [ 38 ] , social media platforms [ 59 , 67 , 68 ] , public safety [ 66 ] , health care [ 42 , 58 ] , autonomous vehicles [ 9 ] , digital activism [ 65 ] , and language technologies [ 45 ] . Notably , all papers that met the inclusion criteria have been published within the last five years ( See Table 2 ) . The recency of this work evinces that the field is in the early phase of a participatory turn in AI . Eleven papers reported on a participatory engagement , while the remainder proposed a framework or toolkit to support participation . For papers proposing a framework or toolkit , we analyzed the participatory process it was designed to support , rather than the development process of the toolkit itself ( which sometimes adopted a participatory method ) . Table 1 presents the 21 papers mapped to the ladder’s eight rungs . In the remainder of this section , we traverse the ladder , from top to bottom , presenting one paper that features the structures and processes that typify the rung . Our intent with this presentation strategy ( a deeper dive into one paper per rung instead of a narrower overview of multiple papers ) is to provide a richer , focused view of the gradients of power across the ladder’s rungs . 4 . 1 Degrees of Power : Rungs 8 - 6 The Degrees of Power rungs – Control , Delegation , Partnership – are distinguished by structures where the goal is at least partially formed by participants and relates to an existing problem that par - ticipants are invested in , with at least some mechanisms in place for accountability , and where communication is open and continuous . In terms of participation process , these rungs feature malleable pro - cesses , with multiple entry points that afford participants degrees of control across many or all phases of development . 4 . 1 . 1 Rung 8 - Citizen Control : Participatory Research for Low - resourced Machine Translation : A Case Study in African Languages . Nekoto et al . [ 45 ] report on a participatory approach for developing and sustaining linguistically and geographically diverse research communities focused on advancing machine translation for low - resourced languages . This paper details a case study of this approach for African languages . Rather than presenting a singular partici - pation process , this work presents a constellation of processes for digital communication , knowledge and resource sharing , and re - lationship building that collectively constitute a geographically distributed research community known as Masakhane . The organi - zational framework connects individuals with a range of expertise , including those who can speak , read , and produce content in the source and target languages , those who can translate between lan - guages , and those with expertise to design and evaluate language technologies . In the African language case study , the resulting com - munity consisted of over 400 participants , from over 20 different countries who self - organized to form mentorship and collaboration networks . Collectively , this community produced research artifacts including publications , datasets , benchmarks , and models . Indeed , the entire research community is credited with authorship of the paper detailing the case study . The goals , relationships , and communication reported on in the paper afford participants direct control over the research commu - nity and its outputs . The organizational structure also explicitly ensures participants themselves drive subgoal ( s ) that emerge within the participatory process to ensure " research questions evolve based on stakeholder demands , rather than being imposed upon by exter - nal forces . ” Relationships between participants develop and evolve organically in a manner that is self - directed by the participants themselves . The precise roles participants inhabit are also fluid and directed by participants and their evolving relationships to one another . Everyone in the community is framed as a participant and community member , including paper authors themselves . Finally , the community norms are intentionally designed to enable open and continuous communication , meaning anyone can initiate com - munication , sub - group discussions can and do organically form , meetings are directed by democratically voted upon agendas , and meeting notes are made public to enable flexible engagement . In the Power and Public Participation in AI EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Year 2018 2019 2020 2021 2022 Citation Zhu et al . [ 68 ] Kihara et al . [ 38 ] Skinner et al . [ 60 ] Krafft et al . [ 40 ] Suresh et al . [ 65 ] Web et al . [ 67 ] Kozubev et al . [ 39 ] Møller et al . [ 35 ] Cheng et al . [ 16 ] Award et al . [ 9 ] Brown et al . [ 15 ] Robb et al . [ 56 ] Shen et al . [ 56 ] Lee et al . [ 43 ] Smith et al . [ 63 ] Blair et al . [ 11 ] Register & Ko [ 53 ] Van Berkel et al . [ 66 ] Lee et al . [ 42 ] Nekoto et al . [ 45 ] Sendak et al . [ 58 ] Table 2 : Yearly breakdown of papers that met the inclusion criteria for the corpus words of the community , the aim is to drive machine translation re - search “for Africans , by Africans . ” 2 The research community were empowered to participate at , and move between , different stages of the machine translation process , depending on their interests , skills , and background . Nekoto et al’s work exemplifies the key characteristics of Arn - stein’s top rung : citizen control . Participants are in complete control of the research community’s goals , structure , processes , norms , and outputs . Notably , there is no clear distinction between researchers enacting a participation process and participants operating within the process . Rather , an initial set of actors laid the groundwork for participation by establishing the basic infrastructure for the research community and recruiting individuals to take part . Com - munication is also structured to enable knowledge transfer between individuals working at different stages . From the paper , we infer that the initial setup was designed to minimize centralization of power , lower barriers to participation , and position Africans as the ultimate drivers of the resulting community . Over time , Masakhane has developed into a thriving research community , governed demo - cratically by its members , the majority of whom speak African languages and / or reside in African countries . 4 . 1 . 2 Rung 7 - Delegated Power : WeBuildAI : Participatory Frame - work for Algorithmic Governance . Lee et al . [ 43 ] report on how people participated in the development of a recommendation algo - rithm for 412 Food Rescue , a food rescue nonprofit . 412 Food Rescue matches food donors with recipient organizations using a revolving pool of volunteer drivers : when donor organizations ( grocery and retail stores ) with extra expiring food contact 412 Food Rescue , the organization attempts to match these incoming donations to non - profit recipient organizations around the city . After the matching decision is made , 412 Food Rescue submits this information to their app where potential volunteers can then pick - up and deliver the donation . The recommendation algorithm was designed to help coordinate this matching process . The goals , relationships , and communication reported on in the paper structure participation in such a way that affords a great deal of control to participants . First , the goal of the participation pro - cess comes entirely from the participants . While the relationship between developers ( researchers at CMU and UT Austin ) and the participants ( 412 Food Rescue staff , recipient organizations , donor organizations , volunteers ) are not explicitly framed , throughout the paper researchers attest to being highly deferential to participants , 2 https : / / www . masakhane . io / as evidenced by the clear and open communication process , where anyone can initiate conversations , push - back , and even reject deci - sions . The participation process began at the problem formulation stage , where researchers conducted interviews with multiple stake - holders , and continued in the data collection and processing stage where more interviews were conducted to help determine feature selection ( i . e . , what information to use or not use in the algorithm ) . In the model selection and building stage , stakeholders completed a series of pairwise comparisons to identify their individual prefer - ences for models that were then aggregated via voting to create the final algorithm . Finally , in the deployment and monitoring stage , there was an initial interface evaluation and then post - deployment interviews to understand stakeholders’ perceptions of the system ( technically and socially ) . Lee et al . ’s paper seems to resemble delegated power . At the delegated power rung , “ citizens achieve dominant decision - making authority over a particular plan or program . ” Lee et al . ’s work seems to afford participants dominant decision - making authority over multiple stages . For instance , the problem was a known , existing one , where participants initiated the development process and thus set the scope for where and how the system would be inserted into socio - political conditions of their space . Participants had granu - lar control of the technical aspects of the development as well . In deployment and monitoring , participants evaluated the system in terms of its technical performance and as it relates to their moral and political beliefs . Because Lee et al . does not explicitly define accountability mechanisms in their relationships with participants , we can only infer the extent to which this is the case . While Dele - gated Power requires “citizens hold significant cards to assure ac - countability of the program to them” [ 7 ] , explicit discussion about accountability and reflection were rare throughout all of the papers , making it difficult for us to assess , a point we return to in Section 5 . 4 . 1 . 3 Rung 6 - Partnership : Towards Intersectional Feminist and Par - ticipatory ML : A Case Study in Supporting Feminicide Counterdata Collection . Suresh et al . [ 65 ] report on the ongoing work of the Data Against Feminicide project — co - organized by the Data + Feminism Lab at MIT , Feminicidio Uruguay , and the Latin American Initiative for Open Data ( ILDA ) . This collaboration supports feminicide data activists through knowledge - sharing , technology development and community building . They are committed to the application of fem - inist and participatory methodologies to design ML datasets and models to support activists in their efforts to collect and monitor EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Corbett et al . data about gender - based killing of women and girls . Through a co - design process with two specific activist organizations , they conceptualized , built and deployed an ML system , subsequently evaluating its utility in real worlds contexts . The goals , relationships , and communication reported on in the paper appear to structure the participation process in such a way that does afford some control to participants . First and most im - portantly , the goal , supporting the efforts of activists who collect and monitor data about feminicide , was co - determined by the par - ticipants and the researchers . For the relationships , the paper is less clear : the authors explicitly discuss how an examination of power guides their research approach , in particular their decision to partner with civil society activists rather than large non - profits or governmental organizations . However , they do not explicitly dis - cuss power dynamics between the academic research team and the two activist groups they are seeking to support with this work . The communication appears to be two - way but bound to the model eval - uation stage of the process where researchers used semi - structured interviews and surveys to understand how activists were able to incorporate the model’s into their workflows . The participation process involves participants in multiple entry points . First , the problem was framed broadly through interviews with 31 different activist organizations and subsequent co - design sessions with a subset of organizations that were focused on conceptualization , development of the system , and evaluation of the system . The par - ticipation process further narrowed , with iterative data collection , modeling , and evaluation steps with two organizations . For Arnstien the partnership rung requires “ power is in fact redistributed through negotiation between citizens and powerhold - ers . ” While Suresh et al . do not report a structure that formalized decision - making to the degree expected by Arnstien , the paper describes shared planning and decision - making responsibilities through such structures as joint policy boards , planning commit - tees , and mechanisms for resolving impasses . Activist groups are described as partners and researchers are explicit about creating the conditions of this partnership , characterizing success as “ the extent to which trust is built with partner organizations , power and re - sources are shared , community is built . ” While the researchers do not clearly reveal how they achieved these ends , to the extent they did , it would align with how Arnstien noted participation as partnership should afford fair negotiations , adequate access to resources , and the ability to initiate actions in the decision - making process . 4 . 2 Tokenism : Rungs 5 - 3 The Tokenism Rungs – Placation , Consultation , Informing – are dis - tinguished from the preceding rungs in that goals that are predeter - mined and fixed prior to the engagement , and there are no account - ability mechanisms in place to ensure the participation process impacts any design or implementation decisions . Communication processes vary across the rungs . Generally speaking , placation is two - way , continuous ; Consultation is two - way , bound ; Informing is one - way , bound . In terms of process , these rungs feature processes that might only have a limited number of entry points ( sometimes only one ) with no control for participants to decide on how and when to move from phases of development . 4 . 2 . 1 Rung 5 - Placation : Shifting Concepts of Value Designing Al - gorithmic Decision - Support Systems for Public Services . Møller et al . [ 35 ] report on the development of an algorithmic component to improve the efficiency of public job placement services in a Danish municipality . Believing the existing process was highly subjective and lacked any metrics for the success , the municipality commis - sioned a project to design an algorithm that could process data to surface some concrete value metrics to aid caseworkers in their decision - making . The research team aimed to document the design process , amplify participatory and ethical elements , and to robustly involve caseworkers in development . The goals , relationships , and communication reported on in the paper structure participation in such a way that affords some control to participants . First , while the project goal ( i . e . , increasing the efficiency of casework flow ) was predetermined , the specifics of how that goal was to be achieved was left open - ended . Additionally , the relationship between researchers , participants , and developers was designed with a high - level mandate ( from the municipality ) for researchers to act as mediators and champions between participants and developers but did not fully guarantee decision - making power . Finally , the communication throughout the process was open , two - way , and unbound in that participants could engage with developers at any point , affording participants the ability to push back , clarify , and reject some decisions . The participation process consisted of field observations of caseworkers day - to - day work , interviews with caseworkers , and workshops where caseworkers and developers reviewed data to understand the current workflows . Caseworkers were encouraged to guide and correct the development team if there were misinterpretations . Taken together , we argue the structure and participation process reported in the paper strongly resembles the fifth rung of the ladder : placation . Placation typically takes the form of powerholders hand - picking a citizens ( in this case , it was a handful of caseworkers from the job placement center ) to serve on organizing committees or advisory boards ( in the case the design team ) but these committees and boards often had no policy - making function or minimal au - thority . The communication that took place during participation afforded participants some , but not all , control over the predeter - mined goal for the system . In placation , “c itizens begin to have some degree of influence . . . [ they ] advise or plan ad infinitum but retain for powerholders the right to judge the legitimacy or feasibility of the advice . ” In this project , caseworkers are given a seat at the ta - ble and gained some influence through their proximity to power , but only some of their suggestions were taken , with others being overruled , indicating a lack of power - sharing in decision - making structures . The development team was not held totally accountable to the caseworkers and certainly did not agree to share planning and decision - making responsibilities through any formal structures ( partnership ) . However , the caseworkers weren’t simply consulted to gather their opinions either . What is left , what if any power is gained is through the flow of communication allotted by way of proximity to development . 4 . 2 . 2 Rung 4 - Consultation : Toward Algorithmic Accountability in Public Services : A Qualitative Study of Affected Community Per - spectives on Algorithmic Decision - Making in Child Welfare Services . Brown et al . [ 15 ] aim to understand of how the use of algorithmic Power and Public Participation in AI EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA decision making tools in child welfare services impacts families and social workers . To do so , the researchers held a series of workshops where stakeholders ( families and social workers ) collectively work through story - driven scenarios of potential uses of algorithmic decision - making in child welfare . In the workshops , participants read these scenarios , ranked their level of comfort and trust indi - vidually on paper " comfort boards , ” and then collectively discussed their feelings and concerns with the scenarios . Insights from the workshops are intended to aid government agencies and data sci - entists in improving community comfort levels with algorithmic decision - making . The goals , relationships , and communication reported on in the paper structure participation in such a way that affords limited agency for participants . First , the goal “to improve child welfare outcomes through the use of data - driven algorithmic tools” is pre - determined ( likely by the local government and / or researchers ) . Moreover , that the “ study was conducted in a US county that is al - ready in the process of adopting algorithmic decision - support tools in the child welfare context ” only further distances participants from agency , as their opinions are an attempt to improve or alter an existing system , which they may or may not have had any initial input on . The relationships between researchers and participants is without any structure for accountability , meaning the researchers facilitate the workshops but only deliver the workshops insights to the system designers and the local government . Insights from the workshops may or may not be used in the implementation . The communication is two - way but seemed to be bound to the the work - shops . The participation process involves participants in one entry point of AI development ( post - deployment assessment ) and affords participants no control of how the process should proceed . In all , the workshops created a dialogic space where stakeholders learned more about how these systems can be used and also provided them an opportunity to express their concerns . Arnstein defines consultation as participation when “ citizens may indeed hear and be heard . . . but lack the power to ensure that their views will be heeded by the powerful . ” Brown et al . illustrate how people can participate , by consulting on some aspects of the development of an AI system . Likewise , in Brown et al . ’s workshops , stakeholders hear and are heard , but because this dialogue takes place outside of an actual development process , ultimately their concerns may not be implemented . Moreover , the county where this work took place already had a risk algorithm in use . Brown et al . suggest their work might influence future iterations of that system but at the time still largely remain a product of the developers intentions . Since Brown et al . ’s work did not take place in an actual development process of the existing algorithm , stakeholders were simply being consulted on how comfortable they are with it . 4 . 2 . 3 Rung 3 - Informing : Designing an Escape Room in the City for Public Engagement with AI - enhanced Surveillance . Kihara et al . [ 38 ] explore how to engage public participation in examining the ethical issues presented by AI - enhanced surveillance systems ( i . e . , facial recognition ) in urban environments . They argue that the complexity of systems prevent informed public discussion despite their clear dangers for freedom and civil liberties . Thus , they designed and tested a game , “Escape the Smart City " to bring awareness about the implications of AI - surveillance technology common in smart cities . The ultimate goal was to encourage partic - ipants to engage in discourse to shape AI - surveillance technologies in urban environments . The goals , relationships , and communication reported on in the paper structure participation in such a way that affords no con - trol for participants outside of the limited scope of the game . The goal of the game , informing citizens about the ethical issues of urban AI surveillance , was predetermined . The relationships are be - tween researchers ( who are the game developers ) and city residents , but none with authorities or system developers that control the decision - making . Finally , the communication is one - way , bound , and closed , where researchers communicate with residents through the game but no methods for dialogue . There were no opportunities for city residents to engage in the participation process of the AI tools , instead they learned about them through the game . Kihara et al . ’s game is a perfect example of the informing rung of the ladder . For Arnstien , participation as informing occurs when the public can learn about “ their rights , responsibilities , and options ” in issues of governance . Furthermore , this learning often comes in one way flow of information . This is identical for Kihara et al . ’s game : participants learn about AI - enhanced surveillance via the mechanics of the game ( interactive activities and one - way flows of information ) . Participants stated that the experience was in - deed informative . However , the game itself is disconnected from any official decision - making process about these technologies ( e . g . to inform the planning process for developing new smart city in - frastructure or develop a report to develop policy for regulating existing systems ) . Without these structural elements in place , Arn - stien would argue , " there is no follow - through , no ‘muscle , ’ hence no assurance of changing the status quo . ” 4 . 3 Non - Participation : Rungs 2 - 1 The Non - participation rungs – Therapy and Manipulation – are dis - tinguished by predetermined structures that produce participation processes that are useless or performative . What is especially unique ( and disturbing ) about these rungs is that they either do not reveal the actual goal to participants or gaslight them into a goal that is harmful . No mechanisms of accountability are in place and partici - pants are often misled about the nature of the relationship . Because of all this , the nature of communication is generally irrelevant but likely will be limited in terms of flow ( bound , one way , closed ) . Likewise , the process is generally irrelevant , as the participation is typically performative , designed to give the appearance of legiti - macy without any real control . 4 . 3 . 1 Rung 2 - Therapy : Robots in the Danger Zone : Exploring Public Perception through Engagement . Robb et al . [ 56 ] argue that an informed public is vital to advancing the growth of Robotics and Artificial Intelligence ( RAI ) in society . Thus , they designed a series of public participation activities to reduce the general public’s misconceptions and build trust of RAI . They posit that providing this information could then impact the possible safety benefits and increases in productivity and / or living standards that the RAI systems could provide , stating : “ If a negative view of RAI exists , there will be resistance to their use , adoption , and funding . " EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Corbett et al . The goals , relationships , and communication reported on in the paper leave little agency for participation . First , the goals are en - tirely predetermined by the researchers ( i . e . , ‘ ‘more engagement building positive public perception [ of RAI ] is needed” ) . Addition - ally , there is no relationship between the participants and the re - searchers , nor any accountability . Communication is one - way and bound to the researchers’ activities that intended to change public perception of RAI . The participation process engages one entry point of AI development ( the public policy and regulation ) and affords participants no control over the outcomes . Researchers , for example , hosted interactive activities at large public events ( e . g . , a science fair ) to illustrate robots’ utility in situations that would be dangerous if not impossible for humans to work in . After en - gaging with the activities , participants were given a quiz to gauge whether there were shifts in knowledge or perception of RAI . This approach left no room for people to participate , but instead focused on changing the public’s perception of RAI . We argue Robb et al . ’s work , as reported in the paper , strongly resembles therapy . According to Arnstien , a key defining trait of therapy is experts’ psychological maneuvers to “cure” beliefs or attitudes possessed by the public they deem deviant or deficient . Even when these beliefs or attitudes might be warranted , experts can configure the structure and participation process in such a way that deflects the issue at hand back onto the public and then claim credit for “curing” them . This description aligns well with Rob et al’s goal , which focuses on " fixing " the public misunderstanding of RAI . We doubt Robb et al . ’s work is intentionally misleading or malicious in the manner Artnstein’s therapy rung would entail . However , the work is nonetheless based on the underlying assumption that the public is incorrect in their fears , thus motivating its placement on this rung . 4 . 3 . 2 Rung 1 - Manipulation . We did not find a paper that matched the manipulation rung . Manipulation occurs when powerholders use the appearance of legitimate participation to gain political or social capital without giving any control to participants . Thus , par - ticipants are led to believe they have participated but instead were used by those in power to “demonstrate” the use of citizen partici - pation . While any participation process could end up not affording power to participants for a number of reasons ( e . g . , funding , en - trenched disagreements , delays , etc . ) , the differentiating factor of this rung is the intentional deception regarding the nature of partici - pation . It is this intent , the desire to derive power from the theater of participation , that distinguishes this rung where participation ends up “ a public relations vehicle by powerholders . ” Given the blatant unethical nature of manipulation as participation , we would not expect a contemporary academic paper to match . However , in the discussion section , we do point out how elements of participation as manipulation might present itself in AI development . 5 DISCUSSION Arnstein’s primary goal for the ladder was to help “ illustrate the point that so many have missed—that there are significant gradations of citizen participation . ” She hoped that , “ knowing these gradations makes it possible to cut through the hyperbole to understand the increasingly strident demands for participation from the have - nots as well as the gamut of confusing responses from the powerholders . ” Our goal here is similar ; by illustrating the degrees of power in public participation in AI within the current scholarship in this space , the field can organize , compare , and build a common set of expectations not only for ourselves but also for the public who are beginning to demand power in participation . To this end , we discuss two prospective views of the ladder : one for powerholders ( developers , researchers , practitioners ) looking to engage participants in design AI systems , and one from community members ( general public , NGOS , specific communities ) that are participating . By discussing the implications of the ladder on these two opposing views , we hope the ladder can act as a boundary object that will support the calls for more participation in AI . 5 . 1 Looking down the ladder : Views and instructions for researchers and practitioners Examining participatory AI scholarship with the ladder under - scores the importance of incorporating a reflexive practice into participatory engagements , examining oneself as a researcher , the research relationship with participants , and the power dynamics operative in the engagement . Reflexivity is best illustrated in con - trast to its methodological differences with the goal of the positivist tradition : to “minimize reactivity ( the effect of the experimenter ) , and ensure reliability , replicability and representativeness” [ 57 ] . In practice , positivist stances create the “disinterested , impartial view from nowhere” [ 32 ] style of research and writing , which in turn obfuscates power dynamics of the design space . This style of research is arguably incompatible with participatory approaches to AI that are fundamentally about power redistribution between actors in the design space . Despite this fact , our analysis found that more often than not researchers were “missing” from the design spaces they constructed and reported on . Authors often omitted discussion of the precise role they occupied in the engagement , and the details of the relationships that structured the engagement were often left unsaid . This posed challenges for our application of the ladder , as power dynamics were often hard “to see” in the current work and we as readers had to read between the lines to infer the background structure forming the conditions of participa - tion . These omissions stem , in part , from disciplinary norms that guide what gets reported ( and what gets omitted ) within academic publications . However , we argue for the importance of centering re - search relationships and researcher reflexivity within publications claiming participatory methods . In this regard , we echo scholar - ship on action research style of reporting on research relationships [ 34 ] , including positionality statements [ 12 ] , and adopting reflexive accounts in writing commonplace in ethnographic practice [ 17 ] . Implementing these remedies “ positions the researcher within the social hierarchy of the context , providing a better understanding of the site and the researcher’s influence over the events ” [ 41 ] which is vital for understanding power and public participation in AI . Papers mapped to the upper rungs of the ladder highlight the substantial requirements underpinning participatory engagements that meaningfully shift power . Researchers may need to provide AI / ML learning support while also being available to listen to com - munity partners’ lived experiences [ 10 , 21 , 33 ] . Researchers may also need to invest time in learning about and adapting to norms Power and Public Participation in AI EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA within participant communities to minimize the burden of participa - tion . This in turn necessitates longer timelines of relationship and trust building that must be factored in for research teams aiming to operate at higher rungs . Arnstein’s ladder suggests that all public participation should be at the higher rungs ; however , as previously discussed , there are valid reasons why participatory AI efforts may be divorced from decision making ( and thus positioned lower on the ladder ) . That said , we as researchers , designers , and practitioners should be prepared to support community participants and organizations in deciding if / how / when / where they want to participate in the devel - opment of AI technologies , where possible . While the middle rungs afford participants less agency over the structure and participatory processes , we encourage researchers operating at these rungs to be transparent with participant communities regarding the nature of the work and the degree of influence the research team has . This in turn enables participants to make an informed decision to participate ( or not ) . We also urge researchers to critically examine how structural inequality may have shaped the design space , as the same forces often manifest in relationship dynamics , funding models , community outreach , and other aspects of the engagement [ 62 ] . The lowest two rungs , which characterize forms on non - participation , make clear the characteristics of engagements that are actively harmful . Here , we echo prior scholarship that has cau - tioned researchers away from feel - good participatory efforts , that under the surface rely on exploitative forms of community partic - ipation [ 62 ] . We advocate for relational , rather that transactional interactions and exchanges [ 8 , 20 , 26 ] , while also recognizing that intentional non - participation can act as a mode of resistance to oppressive power structures [ 18 ] . 5 . 2 Looking up the Ladder : Engaging from the community perspective Community - based organizations , residents , and activists can use the ladder to critically examine new and existing AI collabora - tions and to create community - led infrastructures that question fairness and potential conflicts that may emerge in a collaboration . For example , community organizations such as the Detroit URC 3 evaluate potential community - based participatory research ( CBPR ) partnerships between Detroit - based community organizations and researchers to ensure fairness and equitable partnerships that align with community needs and avoids potential exploitation and ex - traction [ 61 , 62 ] . Such models—where communities have their own organizations that examine systems of power by looking at the structures and process of a potential collaboration—are ideal in that it takes the burden off smaller organizations to spend time becom - ing familiar with the ways in which researchers and developers have and continue to exploit community organizations . Instead , it allows a community - centered body to advise and advocate for bet - ter public participation practices . Community - led infrastructures that critically examine participatory practices in AI development allows us to move beyond researcher - centered bodies ( e . g . , Insti - tutional Review Boards or IRBs ) or corporate consent forms and agreements ( e . g . , non - disclosure agreements or NDAs ) that cover 3 https : / / www . detroiturc . org / researchers and companies goals but that inherently situate power outside of the public , and we argue that the ladder could be a tool that they can further leverage to examine equitable collaboration and partnerships . In addition to traditional participatory design methods where community organizations co - create goals , methods , and outcomes of AI development research projects , we propose more transfor - mative approaches , where power is shifted in every aspect of the project including the shaping of communication practices , consent , funding structure , and storytelling ( dissemination ) . Communication and relationship building should be co - determined at the beginning of the relationship including how often , the results , who initiates communication , response expectations , etc . Consent is typically created before the project begins using boilerplate language . Shift - ing power to the community means that the language of consent forms should be co - constructed . Funding , or monetary control , is incredibly important to public participation but rarely discussed . AI developers and researchers have the ability to reimagine funding structures during their collaboration that support public participa - tion equitably , where for example , the community organizations are the lead institution ( principal investigator ) and the collaborat - ing institutions are subawardees [ 29 ] . Lastly , it is important that project narratives and outcomes are co - analyzed and co - written such that both the developers / researchers and the public share in the storytelling of the project . In our corpus , only two papers [ 40 , 45 ] were co - authored with the participants and developers . In fact , one of our limitations is that we analyzed a corpus that was mainly written by researchers and developers as opposed to hearing from the community perspective . Without public input into the dissemination of the results , developers and researchers retain power over the project narrative . 6 CONCLUSION Arnstein’s ladder was originally intended to be a tool to critically examine and reshape their engagement in public participation with a lens towards equity [ 7 ] . By framing our work using the ladder , we can leverage its existing familiarity with the general public to create a shared set of expectations and start a common discourse on power and public participation in AI . REFERENCES [ 1 ] 2021 . StopLAPDSpyingCoalition . https : / / stoplapdspying . org / [ Online ; accessed 2021 - 09 - 07 ] . [ 2 ] 2022 . About | # MoreThanCode . https : / / morethancode . cc / about / [ Online ; accessed 2021 - 09 - 07 ] . [ 3 ] 2022 . Data 4 Black Lives | About Us . https : / / d4bl . org / about . html [ Online ; accessed 2022 - 09 - 07 ] . [ 4 ] 2022 . Design Justice Network . https : / / designjustice . org / [ Online ; accessed 2022 - 09 - 07 ] . [ 5 ] 2022 . Minderoo Initiative – UCLA Center for Critical Internet Inquiry . https : / / www . c2i2 . ucla . edu / minderoo - initiative / [ Online ; accessed 2022 - 09 - 07 ] . [ 6 ] Sherry Arnstein . 2007 . A Ladder of Citizen Participation . Journal of the American Institute of Planners 35 , 4 ( 2007 ) , 216 – 224 . https : / / doi . org / 10 . 1007 / s13398 - 014 - 0173 - 7 . 2 [ 7 ] SherryRArnstein . 1969 . Aladderofcitizenparticipation . JournaloftheAmerican Institute of planners 35 , 4 ( 1969 ) , 216 – 224 . [ 8 ] Mariam Asad , Christopher A . Le Dantec , Becky Nielsen , and Kate Diedrick . 2017 . Creating a Sociotechnical API : Designing City - Scale Community Engagement . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems ( Denver , Colorado , USA ) ( CHI ’17 ) . Association for Computing Machinery , New York , NY , USA , 2295 – 2306 . https : / / doi . org / 10 . 1145 / 3025453 . 3025963 EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Corbett et al . [ 9 ] Edmond Awad , Sohan Dsouza , Richard Kim , Jonathan Schulz , Joseph Henrich , Azim Shariff , Jean - François Bonnefon , and Iyad Rahwan . 2018 . The moral ma - chine experiment . Nature 563 , 7729 ( 2018 ) , 59 – 64 . [ 10 ] Ruha Benjamin . 2019 . Race after technology : Abolitionist tools for the new jim code . John Wiley & Sons . [ 11 ] Kathryn Blair , Jean - Rene Leblanc , and Lora Oehlberg . 2019 . Exploring Public Engagement with the Social Impact of Algorithms . Companion Publication of the 2019 on Designing Interactive Systems Conference 2019 Companion , 129 – 133 . [ 12 ] Brian Bourke . 2014 . Positionality : Reflecting on the research process . The qualitative report 19 , 33 ( 2014 ) , 1 – 9 . [ 13 ] Tone Bratteteig and Guri Verne . 2018 . Does AI Make PD Obsolete ? Exploring Challenges from Artificial Intelligence to Participatory Design . In Proceedings of the15thParticipatoryDesignConference : ShortPapers , SituatedActions , Workshops and Tutorial - Volume 2 ( Hasselt and Genk , Belgium ) ( PDC ’18 ) . Association for Computing Machinery , New York , NY , USA , Article 8 , 5 pages . https : / / doi . org / 10 . 1145 / 3210604 . 3210646 [ 14 ] Tone Bratteteig and Ina Wagner . 2016 . What is a participatory design result ? Proceedings of the 14th Participatory Design Conference on Full papers - PDC ’16 ( 2016 ) , 141 – 150 . https : / / doi . org / 10 . 1145 / 2940299 . 2940316 [ 15 ] Anna Brown , Alexandra Chouldechova , Emily Putnam - Hornstein , Andrew To - bin , and Rhema Vaithianathan . 2019 . Toward Algorithmic Accountability in Public Services : A Qualitative Study of Affected Community Perspectives on Algorithmic Decision - making in Child Welfare Services . Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems , 41 . [ 16 ] Hao - Fei Cheng , Logan Stapleton , Ruiqi Wang , Paige Bullock , Alexandra Choulde - chova , Zhiwei Steven Steven Wu , and Haiyi Zhu . 2021 . Soliciting Stakeholders’ Fairness Notions in Child Maltreatment Predictive Systems . Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems , 1 – 17 . [ 17 ] James Clifford . 2008 . On Ethnographic Authority * . 2 ( 2008 ) , 118 – 146 . [ 18 ] Patricia Hill Collins . 2002 . Black feminist thought : Knowledge , consciousness , and the politics of empowerment . routledge . [ 19 ] Ned Cooper , Tiffanie Horne , Gillian Hayes , Courtney Heldreth , Michal Lahav , JessSconHolbrook , andLaurenWilcox . 2022 . ASystematicReviewandThematic AnalysisofCommunity - CollaborativeApproachestoComputingResearch . https : / / dl . acm . org / doi / abs / 10 . 1145 / 3491102 . 3517716 [ 20 ] EricCorbettandChristopherA . LeDantec . 2018 . GoingtheDistance : TrustWork for Citizen Participation . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems ( Montreal QC , Canada ) ( CHI ’18 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3173574 . 3173886 [ 21 ] Sasha Costanza - Chock . 2020 . Design justice : Community - led practices to build the worlds we need . The MIT Press . [ 22 ] Robert A Dahl . 2005 . Who governs ? : Democracy and power in an American city . Yale University Press . [ 23 ] Brian d’Alessandro , Cathy O’Neil , and Tom LaGatta . 2017 . Conscientious classifi - cation : A data scientist’s guide to discrimination - aware classification . Big data 5 , 2 ( 2017 ) , 120 – 134 . [ 24 ] Alexander D’Amour , Hansa Srinivasan , James Atwood , Pallavi Baljekar , D . Sculley , and Yoni Halpern . 2020 . Fairness is Not Static : Deeper Understand - ing of Long Term Fairness via Simulation Studies . In Proceedings of the 2020 Conference on Fairness , Accountability , and Transparency ( Barcelona , Spain ) ( FAT * ’20 ) . Association for Computing Machinery , New York , NY , USA , 525 – 534 . https : / / doi . org / 10 . 1145 / 3351095 . 3372878 [ 25 ] Fernando Delgado , Stephen Yang , Michael Madaio , and Qian Yang . 2021 . Stake - holder Participation in AI : Beyond " Add Diverse Stakeholders and Stir " . https : / / doi . org / 10 . 48550 / ARXIV . 2111 . 01122 [ 26 ] Jessa Dickinson , Mark Díaz , Christopher A . Le Dantec , and Sheena Erete . 2019 . " The Cavalry Ain’t Coming in to Save Us " : Supporting Capacities and Relation - ships through Civic Tech . Proc . ACM Hum . - Comput . Interact . 3 , CSCW , Article 123 ( nov 2019 ) , 21 pages . https : / / doi . org / 10 . 1145 / 3359225 [ 27 ] Catherine D’Ignazio and Lauren F . Klein . 2020 . Data Feminism . The MIT Press . https : / / doi . org / 10 . 7551 / mitpress / 11805 . 001 . 0001 [ 28 ] Danielle Ensign , Sorelle A . Friedler , Scott Neville , Carlos Scheidegger , and Suresh Venkatasubramanian . 2018 . Runaway Feedback Loops in Predictive Policing . In Proceedings of the 1st Conference on Fairness , Accountability and Transparency ( ProceedingsofMachineLearningResearch , Vol . 81 ) , SorelleA . FriedlerandChristo Wilson ( Eds . ) . PMLR , 160 – 171 . https : / / proceedings . mlr . press / v81 / ensign18a . html [ 29 ] Rankin Y . R Thomas J . O . Erete , S . 2022 . A Method to the Madness : Applying an Intersectional Analysis of Structural Oppression and Power in HCI and Design . ACM Transactions on Computer - Human Interaction 0 , 0 ( 2022 ) , 1 – 20 . [ 30 ] Virginia Eubanks . 2018 . Automating inequality : How high - tech tools profile , police , and punish the poor . St . Martin’s Press . [ 31 ] John Gaber . 2019 . Building “A Ladder of Citizen Participation” Sherry Arn - stein , Citizen Participation , and Model Cities . Journal of the American planning association 85 , 3 ( 2019 ) , 188 – 201 . [ 32 ] Sandra Harding . 1992 . Rethinking standpoint epistemology : What is " strong objectivity ? " . The Centennial Review 36 , 3 ( 1992 ) , 437 – 470 . [ 33 ] Christina Harrington , Sheena Erete , and Anne Marie Piper . 2019 . Deconstructing community - based collaborative design : Towards more equitable participatory design engagements . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( 2019 ) , 1 – 25 . [ 34 ] Gillian R . Hayes . 2011 . The relationship of action research to human - computer interaction . ACM Transactions on Computer - Human Interaction 18 , 3 ( 2011 ) , 1 – 20 . https : / / doi . org / 10 . 1145 / 1993060 . 1993065 [ 35 ] Naja Holten Møller , Irina Shklovski , and Thomas T Hildebrandt . 2020 . Shifting concepts of value : Designing algorithmic decision - support systems for public ser - vices . Proceedings of the 11th Nordic Conference on Human - Computer Interaction : Shaping Experiences , Shaping Society , 1 – 12 . [ 36 ] Abigail Z . Jacobs and Hanna Wallach . 2021 . Measurement and Fairness . In Pro - ceedingsofthe2021ACMConferenceonFairness , Accountability , andTransparency ( Virtual Event , Canada ) ( FAccT ’21 ) . Association for Computing Machinery , New York , NY , USA , 375 – 385 . https : / / doi . org / 10 . 1145 / 3442188 . 3445901 [ 37 ] Anna Jobin , Marcello Ienca , and Effy Vayena . 2019 . The global landscape of AI ethics guidelines . Nature Machine Intelligence 1 , 9 ( 2019 ) , 389 – 399 . [ 38 ] Tomo Kihara , Roy Bendor , and Derek Lomas . 2019 . Designing an escape room in thecityforpublicengagementwithAI - enhancedsurveillance . ExtendedAbstracts of the 2019 CHI Conference on Human Factors in Computing Systems , 1 – 6 . [ 39 ] SandjarKozubaev , FernandoRochaix , CarlDiSalvo , andChristopherALeDantec . 2019 . Spaces and Traces : Implications of Smart Technology in Public Housing . Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems , 439 . [ 40 ] P M Krafft , Meg Young , Michael Katell , Jennifer E Lee , Shankar Narayan , Micah Epstein , DharmaDailey , BerneaseHerman , AaronTam , VivianGuetler , etal . 2021 . An Action - Oriented AI Policy Toolkit for Technology Audits by Community Advocates and Activists . Proceedings of the 2021 ACM Conference on Fairness , Accountability , and Transparency , 772 – 781 . [ 41 ] Christopher A Le Dantec and Sarah Fox . 2015 . Strangers at the gate : Gaining access , building rapport , and co - constructing community - based research . Pro - ceedings of the 18th ACM conference on computer supported cooperative work & social computing , 1348 – 1358 . [ 42 ] Min Hun Lee , Daniel P Siewiorek , Asim Smailagic , Alexandre Bernardino , and Sergi i Badia . 2020 . Co - Design and Evaluation of an Intelligent Decision Support System for Stroke Rehabilitation Assessment . Proceedings of the ACM on Human - Computer Interaction 4 , CSCW2 ( 2020 ) , 1 – 27 . [ 43 ] Min Kyung Lee , Daniel Kusbit , Anson Kahng , Ji Tae Kim , Xinran Yuan , Allissa Chan , Daniel See , Ritesh Noothigattu , Siheon Lee , Alexandros Psomas , et al . 2019 . WeBuildAI : Participatory framework for algorithmic governance . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( 2019 ) , 1 – 35 . [ 44 ] Donald Martin , Vinodkumar Prabhakaran , Jill Kuhlberg , Andrew Smart , and William S . Isaac . 2020 . Participatory Problem Formulation for Fairer Machine Learning Through Community Based System Dynamics . [ 45 ] Wilhelmina Nekoto , Vukosi Marivate , Tshinondiwa Matsila , Timi Fasubaa , Tajudeen Kolawole , Taiwo Fagbohungbe , Solomon Oluwole Akinola , Shamsud - deen Hassan Muhammad , Salomon Kabongo , Salomey Osei , Sackey Freshia , Rubungo Andre Niyongabo , Ricky Macharm , Perez Ogayo , Orevaoghene Ahia , Musie Meressa , Mofe Adeyemi , Masabata Mokgesi - Selinga , Lawrence Okegbemi , Laura Jane Martinus , Kolawole Tajudeen , Kevin Degila , Kelechi Ogueji , Kath - leen Siminyu , Julia Kreutzer , Jason Webster , Jamiil Toure Ali , Jade Abbott , Iroro Orife , Ignatius Ezeani , Idris Abdulkabir Dangana , Herman Kamper , Hady Elsa - har , Goodness Duru , Ghollah Kioko , Espoir Murhabazi , Elan van Biljon , Daniel Whitenack , Christopher Onyefuluchi , Chris Emezue , Bonaventure Dossou , Bless - ing Sibanda , Blessing Itoro Bassey , Ayodele Olabiyi , Arshath Ramkilowan , Alp Öktem , Adewale Akinfaderin , and Abdallah Bashir . 2020 . Participatory Research for Low - resourced Machine Translation : A Case Study in African Languages . arXiv : 2010 . 02353 [ cs . CL ] [ 46 ] Safiya Umoja Noble . 2018 . Algorithms of oppression : How search engines reinforce racism . nyu Press . [ 47 ] A I Now . 2018 . Algorithmic Accountability Policy Toolkit . ( 2018 ) . [ 48 ] CathyO’neil . 2016 . Weaponsofmathdestruction : Howbigdataincreasesinequality and threatens democracy . Broadway Books . [ 49 ] Samir Passi and Solon Barocas . 2019 . Problem Formulation and Fairness . In Pro - ceedings of the Conference on Fairness , Accountability , and Transparency ( Atlanta , GA , USA ) ( FAT * ’19 ) . Association for Computing Machinery , New York , NY , USA , 39 – 48 . https : / / doi . org / 10 . 1145 / 3287560 . 3287567 [ 50 ] Amandalynne Paullada , Inioluwa Deborah Raji , Emily M . Bender , Emily Denton , andAlexHanna . 2021 . Dataandits ( dis ) contents : Asurveyofdatasetdevelopment and use in machine learning research . Patterns 2 , 11 ( 2021 ) , 100336 . https : / / doi . org / 10 . 1016 / j . patter . 2021 . 100336 [ 51 ] Jennifer Pierre , Roderic Crooks , Morgan Currie , Britt Paris , and Irene Pasquetto . 2021 . Getting Ourselves Together : Data - Centered Participatory Design Research & Epistemic Burden . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 406 , 11 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445103 Power and Public Participation in AI EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA [ 52 ] Carina E . A . Prunkl , Carolyn Ashurst , Markus Anderljung , Helena Webb , Jan Leike , and Allan Dafoe . 2021 . Institutionalizing ethics in AI through broader impact requirements . Nature Machine Intelligence 3 , 2 ( 01 Feb 2021 ) , 104 – 110 . https : / / doi . org / 10 . 1038 / s42256 - 021 - 00298 - y [ 53 ] Yim Register and Amy J Ko . 2020 . Learning machine learning with personal data helps stakeholders ground advocacy arguments in model mechanics . Proceedings of the 2020 ACM Conference on International Computing Education Research , 67 – 78 . [ 54 ] Rashida Richardson , Jason Schultz , and Kate Crawford . 2019 . Dirty Data , Bad Predictions : How Civil Rights Violations Impact Police Data , Predictive Policing Systems , andJustice . NewYorkUniversityLawReviewOnline , Forthcoming ( 2019 ) . [ 55 ] RashidaRichardson , J . Schultz , andK . Crawford . 2019 . DirtyData , BadPredictions : How Civil Rights Violations Impact Police Data , Predictive Policing Systems , and Justice . [ 56 ] David A Robb , Muneeb I Ahmad , Carlo Tiseo , Simona Aracri , Alistair C Mc - Connell , Vincent Page , Christian Dondrup , Francisco J Chiyah Garcia , Hai - Nguyen Nguyen , Èric Pairet , et al . 2020 . Robots in the danger zone : explor - ing public perception through engagement . Proceedings of the 2020 ACM / IEEE International Conference on Human - Robot Interaction , 93 – 102 . [ 57 ] Jennifer A . Rode . 2011 . Reflexivity in digital anthropology . Proceedings of the 2011 annual conference on Human factors in computing systems - CHI ’11 ( 2011 ) , 123 . https : / / doi . org / 10 . 1145 / 1978942 . 1978961 [ 58 ] MarkSendak , MadeleineClareElish , MichaelGao , JosephFutoma , WilliamRatliff , Marshall Nichols , Armando Bedoya , Suresh Balu , and Cara O’Brien . 2020 . " The Human Body is a Black Box " : Supporting Clinical Decision - Making with Deep Learning . In Proceedings of the 2020 Conference on Fairness , Accountability , and Transparency ( Barcelona , Spain ) ( FAT * ’20 ) . Association for Computing Machin - ery , New York , NY , USA , 99 – 109 . https : / / doi . org / 10 . 1145 / 3351095 . 3372827 [ 59 ] Hong Shen , Alicia DeVos , Motahhare Eslami , and Kenneth Holstein . 2021 . Every - day algorithm auditing : Understanding the power of everyday users in surfacing harmful algorithmic behaviors . arXiv preprint arXiv : 2105 . 02980 ( 2021 ) . [ 60 ] ZoeSkinner , StaceyBrown , andGregWalsh . 2020 . ChildrenofColor’sPerceptions of Fairness in AI : An Exploration of Equitable and Inclusive Co - Design . Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems , 1 – 8 . [ 61 ] Mona Sloane . 2019 . Inequality Is the Name of the Game : Thoughts on the Emerging Field of Technology , Ethics and Social Justice . In Proceedings of the Weizenbaum Conference 2019 " Challenges of Digital Inequality - Digital Education , Digital Work , Digital Life " . Berlin , 9 . https : / / doi . org / 10 . 34669 / wi . cp / 2 . 9 [ 62 ] Mona Sloane , Emanuel Moss , Olaitan Awomolo , and Laura Forlano . 2020 . Par - ticipation is not a Design Fix for Machine Learning . https : / / doi . org / 10 . 48550 / ARXIV . 2007 . 02423 [ 63 ] C Estelle Smith , Bowen Yu , Anjali Srivastava , Aaron Halfaker , Loren Terveen , and Haiyi Zhu . 2020 . Keeping community in the loop : Understanding wikipedia stakeholder values for machine learning - based systems . Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems , 1 – 14 . [ 64 ] Susan Leigh Star and James R . Griesemer . 1989 . Institutional Ecology and Bound - ary Objects . Social Studies of Science 19 , 3 ( 1989 ) , 387 – 420 . [ 65 ] Harini Suresh , Rajiv Movva , Amelia Lee Dogan , Rahul Bhargava , Isadora Cruxen , Angeles Martinez Cuba , Guilia Taurino , Wonyoung So , and Catherine D’Ignazio . 2022 . Towards Intersectional Feminist and Participatory ML : A Case Study in Supporting Feminicide Counterdata Collection . In 2022 ACM Conference on Fairness , Accountability , and Transparency ( Seoul , Republic of Korea ) ( FAccT ’22 ) . Association for Computing Machinery , New York , NY , USA , 667 – 678 . https : / / doi . org / 10 . 1145 / 3531146 . 3533132 [ 66 ] Niels Van Berkel , Jorge Goncalves , Danula Hettiachchi , Senuri Wijenayake , Ryan M Kelly , and Vassilis Kostakos . 2019 . Crowdsourcing perceptions of fair predictors for machine learning : a recidivism case study . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( 2019 ) , 1 – 21 . [ 67 ] Helena Webb , Ansgar Koene , Menisha Patel , and Elvira Perez Vallejos . 2018 . Multi - stakeholder dialogue for policy recommendations on algorithmic fairness . Proceedingsofthe9thinternationalconferenceonsocialmediaandsociety , 395 – 399 . [ 68 ] Haiyi Zhu , Bowen Yu , Aaron Halfaker , and Loren Terveen . 2018 . Value - sensitive algorithm design : Method , case study , and lessons . Proceedings of the ACM on Human - Computer Interaction 2 , CSCW ( 2018 ) , 1 – 23 . EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Corbett et al . APPENDIX A Table 3 : Analysis table with all 21 papers with goals and descriptions . Paper Participation goal ( s ) Origin of goal ( s ) Description ( s ) of researchers and participants positions Entry points Nekoto et al . [ 45 ] Developing machine transla - tion tools for low - resourced lan - guages . Goal ( s ) are determined by partici - pants and reflect an existing prob - lem the participants are invested in . No division between researchers and participants . Roles include speakers of low resourced lanaguages and language technolo - gists . The precise roles individuals inhabit are fluid and directed by individuals and their evolving relationships to one another . Problem Formulation Data Set Development Model Development Evaluation / Monitoring Zhu et al . [ 68 ] An algorithmic tool to help WikiProjects identify and re - cruit new members . Goal ( s ) co - determined with com - munity and / or reflect an existing problemthecommunityisinvestedin Participants : stakeholders Researchers : Framed outside - in ( had to gain access to community ) Lee et al . [ 43 ] Recommender algorithm for food donation organization . Goal ( s ) co - determined with com - munityandreflectanexistingprob - lem the community is invested in Participants : stakeholders Researchers : developers , collabora - tors Problem Formulation Data Set Development Model Development Evaluation / Monitoring Lee et al . [ 42 ] Decision support system for stroke rehabilitation assessment . Goal ( s ) are co - determined and re - flect an existing problem the par - ticipants are invested in . Participants : Medical experts Researchers : Role not explicitly framed Problem Formulation Model Development Evaluation / Monitoring Sendak et al . [ 58 ] Machine learning - driven tool to assist clinicians in the early di - agnosis and treatment of sepsis . Goal ( s ) are co - determined and re - flect an existing problem the par - ticipants are invested in . Participants : stakeholders , clini - ciansResearchers : Partners , collabora - tors Problem Formulation Data Set Development Model Development Evaluation / Monitoring Suresh et al . [ 65 ] ML tool that will surface ( via email alerts ) media relevant ac - tivist efforts of monitor femini - cide . Goal ( s ) are co - determined and re - flect an existing problem the par - ticipants are invested in . Participants : Activists Researchers : Collaborators , part - ners , supporters Problem Formulation Data Set Development Model Development Evaluation / Monitoring Holten et al . [ 35 ] Algorithmic decision support tool for municipal job place - ment services . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : experts Researchers : HCI researchers aim - ing to amplify participatory and ethical aspects of development pro - cess Problem Formulation Webb et al . [ 67 ] Policy recommendations for al - gorithms used in various on - line information activities ( web browsers , rec systems , social media filters , etc ) . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : stakeholder Researchers : Role not explicitly framed Problem Formulation Kozubaev et al . [ 39 ] Understanding of the opportu - nities and issues of smart tech - nologiesandservicesinapublichousingcomplex . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : stakeholder , commu - nity , resident Researchers : Neutral , third party mediators . Problem Formulation Brown et al . [ 15 ] Improving community com - fort levels with algorithmic decision - making in child wel - fare services . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : stakeholders Researchers : designers , conveners , faccilitators Deployment and Monitor - ing . Van Berkel et al . [ 66 ] Understanding perceptions of fairness in the context of auto - mated recidivism ML prediction ( framework applicable in other contexts ) . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : Crowdworkers Researchers : Role not explicitly framed Problem Formulation Skinner et al . [ 60 ] Understanding children of color’s perceptions of fairness regarding AI systems . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : Affected community , childrenResearchers : Role not explicitly framed Problem Formulation Continued on next page Power and Public Participation in AI EAAMO ’23 , October 30 – November 01 , 2023 , Boston , MA , USA Table 3 – continued from previous page Paper Participation goal ( s ) Origin of goal ( s ) Description ( s ) of researchers and participants positions Entry points Smith et al . [ 63 ] An ML - based quality prediction system on Wikipedia . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : Stakeholder , commu - nity , expert Researchers : Partners , researchers , developers Deployment and Monitoring Cheng et al . [ 16 ] How to elicit notions of fairness into a system . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Problem Formulation Shen et al . [ 59 ] Enabling non - expert , " every - day " users of algorithmic tech - nology engage in adhoc audit - ing processes similar to expert based auditing . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : General public Researchers : Role not explicitly framed Deployment and Monitoring Awad et al . [ 9 ] Quantify societal expectations about the ethical principles that shouldguideself - drivingcarsin the context of unavoidable acci - dents . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : General public Researchers : Role not explicitly framed Problem Formulation Kihara et al . [ 38 ] Creatingpublic participation on the ethical issues presented by AI - enhanced surveillance sys - tems in urban environments Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : General public Researchers : Role not explicitly framed Problem Formulation Blair et al . [ 11 ] Give public exposure the social impacts of algorithms used by corporations and governments . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : General public Researchers : Role not explicitly framed Problem Formulation Register et al . [ 53 ] Teaching non - experts ML con - cepts to enable participation in algorithmic governance . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : General public Researchers : Role not explicitly framed Krafft et al . [ 40 ] Providing an information guide forgeneralpubliceducationandengagementwithAIuseinthepublicsector . Goal ( s ) are pre - determined , made visible to participants , and may re - flect an existing problem the par - ticipants are invested in . Participants : stakeholder , partner , affected , community Researchers : Role not explicitly framed ; we can infer researchers are equity and social justice pur - suits of community organizations . Deployment and Monitoring Robb et al . [ 56 ] BuildingpublictrustinRoboticsandArtificialIntelligence ( RAI ) . Goal ( s ) are pre - determined and not made visible to participants . Partic - ipants may be misled regarding the nature of goal ( s ) . Participants : General public Researchers : Role not explicitly framed Deployment and Monitoring