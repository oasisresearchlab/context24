PAIRED COMPARISONS FOR GAMES OF CHANCE ALEX COWAN Abstract . We present a Bayesian rating system based on the method of paired comparisons . Our system is a ﬂexible generalization of the well - known Glicko , and in particular can better accommodate games with signiﬁcant elements of luck . Our system is currently in use in the online game Duelyst II , and in that setting outperforms Glicko2 . Contents 1 . Introduction 1 Acknowledgments 2 2 . Model 2 2 . 1 . Match outcomes 2 2 . 2 . Knowledge of players 5 2 . 3 . Player growth 7 3 . Parameter choices 8 3 . 1 . The luck function Λ and its tails 8 3 . 2 . ν 0 for unknown players 10 3 . 3 . The kernel κ 11 3 . 4 . Summary 11 4 . Algorithms 12 4 . 1 . Naive algorithms 12 4 . 2 . FFT - based algorithms 13 4 . 3 . Laplace algorithms 14 5 . Performance in Duelyst II 16 References 17 1 . Introduction The method of paired comparisons [ 4 ] is a framework for ranking many items by comparing them two at a time . Often the outcome of these comparisons is non - deterministic , only a small fraction of all possible pairs will be compared , and some pairs may be compared multiple times . In this paper we discuss the method of paired comparisons in the context of ranking the players of a symmetric competitive two - player game according to their strength , i . e . ability to win matches . We present a rating system which , based only on the outcomes of previously played matches , estimates how likely any player is to defeat any other player . There are several other systems designed for this purpose , such as Elo [ 6 ] , Glicko2 [ 9 ] , and TrueSkill [ 11 , 15 ] . Our system is fundamentally a generalization of the well - known system Glicko [ 8 ] ( but not Glicko2 ; see Remark 2 . 19 ) . With this generalization , we can adapt our system to speciﬁc situations in a way that avoids certain assumptions and certain approximations which might not be appropriate in those settings . In particular , Glicko and many other systems use the Bradley – Terry model [ 27 , 1 ] Date : March 28 , 2023 . The author was supported by the Simons Foundation Collaboration Grant 550031 . 1 a r X i v : 2303 . 14857v1 [ s t a t . M E ] 27 M a r 2023 2 ALEX COWAN for estimating the winning chances of players whose strength is known exactly . This model tends to overestimate the winning chances of players much stronger than their opponents , and also reﬂects reality poorly when used in games with elements of luck ; c . f . Example 2 . 9 and Section 3 . 1 . Our system is in use in the online collectible card game Duelyst II , and there our system outperforms Glicko2 , which was the rating system the game used previously . We discuss this in Section 5 . The core part of our system is made up of three models : Model 2 . 1 is used to predict the outcome of matches , Model 2 . 11 is used to update the system’s beliefs about players based on match outcomes , and Model 2 . 16 is used to account for changes in player strength between matches due to external factors . The system functions by choosing some prior for a player’s strength to assign to unknown players , and then using Model 2 . 11 and Model 2 . 16 after each match . Models 2 . 1 , 2 . 11 , and 2 . 16 are presented in substantial generality , and to use our system one must choose values for three parameters : Λ in Model 2 . 1 , a prior ν 0 for unknown players to use in Model 2 . 11 , and κ in Model 2 . 16 . In Section 3 , we present the parameter choices we made for Duelyst II , and give a very succinct summary of the resulting system in Section 3 . 4 . We think similar choices will be reasonable in many other situations . An essential component of Glicko2’s popularity is that it is computationally feasible to use it in large scale applications , such as on the major chess website Lichess [ 14 ] . We present two sets of algorithms in Section 4 . 2 and Section 4 . 3 for implementing our system . These algorithms are eﬃcient enough to be practical for similar applications ; Duelyst II’s implementation can process roughly 170 matches per second per vCPU . We also highlight the algorithms in Section 4 . 1 , which might help one in understanding the system , and Algorithm 4 . 5 and Algorithm 4 . 6 for taking convolutions of discrete distributions with Laplace distribution PDFs and CDFs which might be of independent interest . Implementation of all of these algorithms are available on the author’s GitHub [ 2 ] . Acknowledgments . We thank Michael Snarski for many very helpful conversations , Oleg Maslen - nikov for integrating all aspects of our system into Duelyst II , and the Duelyst II community for their enthusiastic testing and thorough feedback . 2 . Model Our system is made up of three models . Model 2 . 1 is used to predict the outcome of matches . Model 2 . 11 is used after every match to update the system’s beliefs about the strengths of players . Model 2 . 16 is used after each of these updates , to account for changes in player strength between matches due to external factors . In this section , we present these models in general . To use our system in practice , one then has to choose values for the following parameters : • In Model 2 . 1 , Λ • In Model 2 . 11 , a prior ν 0 for unknown players • In Model 2 . 16 , κ We give a variety of examples of parameter choices for each individual model to highlight relationships to existing systems : • The Bradley – Terry model [ 27 , 1 ] in Example 2 . 5 and Example 2 . 6 • TrueSkill [ 11 , 15 ] in Example 2 . 7 • FIDE [ 7 ] in Example 2 . 8 • Glicko [ 8 ] in Example 2 . 13 and Example 2 . 18 In Section 3 , we give recommendations for parameter choices which we expect to be suitable for most applications , and which allow for a more concrete formulation of our system . 2 . 1 . Match outcomes . The outcome of a match between two players A and B depends on both how well A and B perform in that match as well as the nature of the game that they are playing . In this section we present Model 2 . 1 for predicting match outcomes in a way that takes into consideration both of these factors . PAIRED COMPARISONS FOR GAMES OF CHANCE 3 Model 2 . 1 . • Let S be a complete separable metric space . • Let P ( S ) be the set of Borel probability measures on S . • Let Λ : S 2 → [ 0 , 1 ] ⊂ R be measurable and such that Λ ( x , y ) = 1 − Λ ( y , x ) for all x , y ∈ S . • For any µ A and µ B in P ( S ) , deﬁne L ( µ A , µ B ) : = (cid:90) S 2 Λ ( x , y ) µ A ( dx ) µ B ( dy ) . Players A and B are modeled by the probability measures µ A and µ B respectively , and the average score of A playing against B is modeled by L ( µ A , µ B ) . We call Λ a luck function . In Model 2 . 1 , games are determined by the choice of Λ , and players by their associated probability measures . The luck function Λ reﬂects the nature of the game being played , in particular how much luck inﬂuences the outcomes of matches , and should be chosen on a case - by - case basis . The probability measures associated to players reﬂect how consistently that player performs from match to match . When two ﬁxed players A and B play multiple matches against one another and multiple outcomes are observed , in many situations it is possible to explain this variation in outcome equally well as a consequence of inconsistent performances by the players ( reﬂected in µ A and µ B ) , as a consequence of an element of luck inherent in the game ( reﬂected in Λ ) , or by various combinations of these two factors . Example 2 . 5 and Example 2 . 6 show how the Bradley – Terry model [ 27 , 1 ] can arise from either the perspective of the game involving luck or players performing inconsistently . Deﬁnition 2 . 2 . We take Heaviside function to be the function H : R → R deﬁned as H ( x ) =   0 , x < 0 12 , x = 0 1 , x > 0 . Deﬁnition 2 . 3 . For any x ∈ S , the Dirac measure δ x ∈ P ( S ) is deﬁned by δ x ( U ) = (cid:40) 0 , x (cid:54)∈ U 1 , x ∈ U for all Borel - measurable sets U ⊆ S . Example 2 . 4 . Take S = R . If Λ ( x , y ) = H ( x − y ) , where H is the Heaviside function as in Deﬁnition 2 . 2 , then Model 2 . 1 can be interpreted as a game in which the player who performs better in any given match wins that match . Conversely , if Λ ( x , y ) = 1 2 for all x , y ∈ S , then this can be interpreted as a game in which the outcome of every match is determined uniformly at random . If µ A is a Dirac measure as in Deﬁnition 2 . 3 , i . e . µ A ( { x } ) = 1 for some x ∈ S , this can be inter - preted as the player A being perfectly consistent , performing with exactly the same strength every match . Conversely , if µ A is a probability measure with high variance , then this can be interpreted as the player A being very inconsistent in their performance . However , there is no analogue to the luck function Λ ( x , y ) = 12 , essentially because there is no uniform probability distribution on R . We will see in Section 3 . 1 that this discrepancy is signiﬁcant . (cid:52) Example 2 . 5 . The Bradley – Terry model [ 27 , 1 ] is the special case of Model 2 . 1 where S = R > 0 , Λ ( x , y ) = x x + y , 4 ALEX COWAN and µ A and µ B are Dirac measures . These choices can be interpreted as • the players A and B always perform at the same strength , and • it is possible for a match to be won by the player that played worse in that match . The Bradley – Terry model is often encountered under the reparameterizations x (cid:55)→ e x [ 9 ] or x (cid:55)→ 10 x 400 [ 7 , 8 ] . (cid:52) Example 2 . 6 . “Linear models” in the sense described by David in [ 4 , § 1 . 3 , § 4 ] is the special case of Model 2 . 1 where S = R and Λ ( x , y ) = H ( x − y ) . As discussed in [ 4 ] , the Thurstone – Mosteller [ 23 , 24 , 16 , 17 , 18 ] and Bradley – Terry [ 27 , 1 ] models are recovered by requiring that µ A and µ B be normal distributions or Gumbel distributions with scale parameter 1 . In contrast with Example 2 . 5 , these choices can be interpreted as • the players A and B perform at diﬀerent strengths from one match to the next , and • every match is won by whichever player played best . Note that both this example and Example 2 . 5 recover the Bradley – Terry model , but do so in diﬀerent ways , and can be interpreted diﬀerently . (cid:52) Example 2 . 7 . The TrueSkill system [ 11 , 15 ] uses the special case of Model 2 . 1 in which S = R , Λ ( x , y ) =   1 x − y > ε 12 | x − y | ≤ ε 0 x − y < − ε for some ε > 0 , and µ A and µ B are normal distributions . (cid:52) Example 2 . 8 . The rating system [ 7 , § 8 ] used by FIDE , the de facto governing body of chess , cor - responds to Model 2 . 1 with S = R , a choice of Λ which is piecewise constant but well - approximated by the modiﬁed Bradley – Terry model Λ ( x , y ) =   1011 if x − y > 400 111 if x − y < − 400 1 1 + 10 y − x 400 if | x − y | ≤ 400 , and µ A , µ B Dirac measures . (cid:52) Example 2 . 9 . Consider the game G β in which a chess match is played with probability β ∈ ( 0 , 1 ) , and a winner is chosen uniformly at random with probability 1 − β . If the game of chess is perfectly modeled by the Bradley – Terry model as presented in Example 2 . 5 , then the game G β is best modeled by the choice of parameters S = R > 0 , Λ ( x , y ) = β x x + y + ( 1 − β ) 1 2 , and µ A and µ B Dirac measures . None of the previous examples are good models for games in which it is impossible to win with probability arbitrarily close to 1 . For instance , they cannot properly model the fact that the world champion of chess would win a match of G β against both the author and a rock with probability 1 + β 2 , and the author would also win against the rock with probability 1 + β 2 . These sorts of considerations also cause problems when using the Rasch model [ 20 ] for multiple - choice tests where guessing is possible [ 12 ] . (cid:52) Example 2 . 10 . Take S = R 3 and Λ (cid:0) ( x 1 , x 2 , x 3 ) , ( y 1 , y 2 , y 3 ) (cid:1) =   1 if # { i ∈ { 1 , 2 , 3 } : x i > y i } ≥ 2 0 if # { i ∈ { 1 , 2 , 3 } : y i > x i } ≥ 2 12 otherwise . PAIRED COMPARISONS FOR GAMES OF CHANCE 5 For Dirac measures µ A , µ B , µ C ∈ P ( S ) deﬁned by µ A ( { ( 3 , 3 , 3 ) } ) = 1 , µ B ( { ( 4 , 4 , 1 ) } ) = 1 , µ A ( { ( 5 , 2 , 2 ) } ) = 1 , we have L ( µ A , µ B ) = L ( µ B , µ C ) = L ( µ C , µ A ) = 0 . This sort of non - transitivity arises in human play and is also an obstacle for machine learning [ 3 , 21 , 26 ] . It is unclear how one would properly model this non - transitivity with the widely - used linear models that were presented in Example 2 . 6 . (cid:52) Model 2 . 1 makes two assumptions about the function Λ which we use to simplify Model 2 . 11 . However , there are situations in which these assumptions aren’t appropriate . We discuss the assump - tions below . In both cases , it seems straightforward conceptually to omit the assumption , but then one must repeat the work done in subsequent sections without using the associated simpliﬁcations . The ﬁrst assumption is that Λ ( x , y ) = 1 − Λ ( y , x ) . This is appropriate for symmetric games , but probably isn’t for asymmetric games . For example , the game in which players ﬂip a coin to determine who plays with white in a game of chess is symmetric , but the game of chess after having picked colours is not . At the time of writing , there have been 3 , 988 , 065 , 350 matches of chess played on lichess . org , and in them white scored 52 % [ 13 ] . To model this , one might instead ﬁx two diﬀerent Λ ’s , each satisfying Λ ( x , x ) = 0 . 5 ± 0 . 02 , and consider which player was playing with the white pieces to determine which one to use . The second assumption , that Λ ( x , y ) ∈ [ 0 , 1 ] , builds on the ﬁrst . There are situations where one is interested not in the probability of each player winning , but other notions of score . For example , in poker “cash games” players can exchange money for chips at any time , and strive to win as many chips as possible . Thus , if A and B win a and b chips respectively while playing a prescribed number of hands against each other in a poker cash game , then it is most meaningful to consider the quantities a and b themselves , and not whether or not a > b . This contrasts with games like Go , where the winner of the match is the player with the highest score , regardless of the magnitude of the scores or the diﬀerence between them . It seems more natural to model poker cash games with a choice of Λ which takes values outside of [ 0 , 1 ] . This also allows one to consider games which are not zero - sum . In two player games , when one player wins , the other loses , but other notions of score needn’t sum to zero . In the preceding poker example , one expects that a + b < 0 , as casinos take a small portion of each pot . 2 . 2 . Knowledge of players . Model 2 . 1 posits that the player A is determined by a Borel probability measure µ A ∈ P ( S ) . Our rating system will not know with certainty what the true underlying measure µ A is , and represents its current beliefs with a Borel probability measure ν A ∈ P ( P ( S ) ) . The only observations our rating system will consider are match outcomes , and Model 2 . 11 gives the resulting posteriors . Model 2 . 11 . Let S and L be as in Model 2 . 1 . For any ν A and ν B in P ( P ( S ) ) , deﬁne ν A , A > B to be any element of P ( P ( S ) ) satisfying , for all Borel - measurable sets U ⊆ P ( S ) , (cid:90) U ν A , A > B ( dµ ) = (cid:82) U (cid:104)(cid:82) P ( S ) L ( µ , µ (cid:48) ) ν B ( dµ (cid:48) ) (cid:105) ν A ( dµ ) (cid:82) P ( S ) (cid:104)(cid:82) P ( S ) L ( µ , µ (cid:48) ) ν B ( dµ (cid:48) ) (cid:105) ν A ( dµ ) . Deﬁne ν A , B > A as above but with all instances of L ( µ , µ (cid:48) ) replaced by L ( µ (cid:48) , µ ) . The prior distribution over probability measures associated to a player A is modeled by ν A , and the posterior after observing a match in which A defeats B or B defeats A is modeled by ν A , A > B or ν A , B > A . After updating the prior ν A to the posterior ν A , A > B or ν A , B > A , that posterior will then be used as the prior when processing the next match A plays . 6 ALEX COWAN In some games there are match outcomes such as draws which are neither wins nor losses . When one can reasonably model these outcomes by a real number θ , e . g . θ = 12 for draws , then we suggest taking the posterior , which we’ll denote ν A , θ , to be any probability measure which satisﬁes (cid:90) U ν A , θ ( dµ ) = (cid:82) U (cid:104)(cid:82) P ( S ) L ( µ , µ (cid:48) ) θ L ( µ (cid:48) , µ ) 1 − θ ν B ( dµ (cid:48) ) (cid:105) ν A ( dµ ) (cid:82) P ( S ) (cid:104)(cid:82) P ( S ) L ( µ , µ (cid:48) ) θ L ( µ (cid:48) , µ ) 1 − θ ν B ( dµ (cid:48) ) (cid:105) ν A ( dµ ) ( 1 ) for all Borel - measurable sets U ⊆ P ( S ) . Our reasoning for this is the same as the reasoning given in [ 8 , § 2 ] . This formula can also be viewed as encompassing the one given in Model 2 . 11 if one takes θ = 1 if A > B and θ = 0 if B > A . It may be helpful in some cases to note that the assumptions in Model 2 . 1 imply that L ( µ (cid:48) , µ ) = 1 − L ( µ , µ (cid:48) ) . One must choose what prior ν 0 ∈ P ( P ( S ) ) to assign to a player which is completely unknown to the system . Below , we give one type of prior which is a convenient choice for many applications . Deﬁnition 2 . 12 . For a given complete separable metric space S , we will call a Borel probability measure ν ∈ P ( P ( S ) ) Dirac - only if and only if , for all Borel - measurable U ⊆ P ( S ) , U ∩ (cid:8) δ x : x ∈ S (cid:9) = ∅ = ⇒ ν ( U ) = 0 , where δ x is the Dirac measure as in Deﬁnition 2 . 3 . Dirac - only priors are convenient for two reasons : ( 1 ) If ν A is Dirac - only , then the posteriors ν A , A > B and ν A , B > A from Model 2 . 11 are too . ( 2 ) If ν is Dirac - only , then we can treat ν as an element of P ( S ) via ν ( U ⊆ S ) : = ν (cid:0)(cid:8) δ x : x ∈ U (cid:9)(cid:1) . Example 2 . 13 . This example gives a description of the Bayesian inference part of the widely - used Glicko system [ 8 ] . Take S = R and Λ to be the parameterization of the Bradley – Terry model [ 27 , 1 ] given by Λ ( x , y ) = 1 1 + 10 y − x 400 . To an unknown player , assign a Dirac - only ( Deﬁnition 2 . 12 ) prior ν 0 which , viewed as a probability measure on R , is a normal distribution . When updating according to Model 2 . 11 , approximate the marginal likelihood (cid:82) P ( S ) L ( µ , µ (cid:48) ) ν B ( dµ (cid:48) ) by a normal density with the same mode and second derivative at that mode ; see [ 8 , Appendix A ] for details . A consequence of this approximation is that the posterior ν A , θ ( Eq . ( 1 ) ) is again normal . (cid:52) Example 2 . 14 . Take S = R and Λ ( x , y ) = H ( x − y ) , where H is the Heaviside function ( Deﬁni - tion 2 . 2 ) . Suppose Alice and Abi share the account A in an online game , and in any given match Alice plays with probability p ∈ ( 0 , 1 ) and Abi plays otherwise . When Alice plays she always per - forms with strength x 1 , and when Abi plays she always performs with strength x 2 . Suppose there is another player B which always performs with strength y . In the case where our rating system is aware of all this information except for the value of p , we can model the situation as follows . Let µ p be a probability measure satisfying µ p ( { x 1 } ) = p and µ p ( { x 2 } ) = 1 − p . A reasonable choice of prior ν A would be the measure which , for any Borel - measurable subset U of [ 0 , 1 ] , gives probability λ ( U ) to the set { µ p : p ∈ U } , where λ is the Lebesgue measure . This corresponds to a uniform prior for p . The prior ν B should be taken to be δ δ y ( Deﬁnition 2 . 3 ) . If x 1 < y < x 2 , then observations of match outcomes between A and B are essentially samples of Bernoulli random variable with unknown parameter p , and the rating system is attempting to deter - mine p . Model 2 . 11 uses the usual Bayesian inference to estimate p and yields a beta distribution . If one considers only Dirac - only choices of ν A , like in Example 2 . 13 , then one cannot reasonably model the situation given in this example . If it is known that B always performs with strength y PAIRED COMPARISONS FOR GAMES OF CHANCE 7 and that every match is won by the player who performed better , then , after a single observation of A > B , the posterior ν A , A > B gives probability 0 to all δ x with x < y . The posterior after observing both A > B and B > A would give probability 0 to all δ x with x (cid:54) = y . If p is far from 12 , then δ y would be a very poor guess for µ A . If there is another player C who is known to always perform with strength z satisfying x 1 < y < z < x 2 , then assuming µ A is a Dirac measure would cause system to believe that the sequence of match outcomes A > B , B > A , and A > C could never occur , and in the proportion p ( 1 − p ) 2 of cases in which it does the system’s behaviour would be undeﬁned . (cid:52) Example 2 . 15 . In this example we restate Model 2 . 11 under the assumption that ν A and ν B are discrete distributions over discrete distributions . We use the following notation : • ( α i ) i and ( β j ) j are integer - indexed sequences of non - negative real numbers which each sum to 1 , as are ( p i , k ) k for each i , and ( q j , (cid:96) ) (cid:96) for each j . • ( x i , k ) k and ( y j , (cid:96) ) (cid:96) are integer - indexed sequences of elements of S . • δ ∗ is the Dirac measure at ∗ ( Deﬁnition 2 . 3 ) . • ∝ means that values should be normalized so that they sum to 1 . Write ν A = (cid:88) i α i δ µ A , i , ν B = (cid:88) j β j δ µ B , j , µ A , i = (cid:88) k p i , k δ x i , k , µ B , j = (cid:88) (cid:96) q j , (cid:96) δ y j , (cid:96) . Then L ( µ A , i , µ B , j ) = (cid:88) k , (cid:96) p i , k q j , (cid:96) Λ ( x i , k , y j , (cid:96) ) and ν A , A > B = (cid:88) i ˆ α i δ µ A , i , ˆ α i ∝ α i (cid:88) j β j (cid:88) k , (cid:96) p i , k q j , (cid:96) Λ ( x i , k , y j , (cid:96) ) . (cid:52) 2 . 3 . Player growth . In practice , the strength of a player A is likely change over time for a variety of reasons . For example , A might read a book to learn a new chess opening , or acquire new cards in a collectible card game . Using Model 2 . 11 to process many of A ’s matches can easily lead to situations where ν A gives probability nearly 0 to certain measures . If external factors then cause A ’s strength to change , a purely Bayesian system might need to observe many match outcomes before it gives a non - negligible probability to the measure corresponding to A ’s new strength . In this section , we present Model 2 . 16 for how a player’s underlying measure can change between matches . Model 2 . 16 . Let S be a complete separable metric space . Fix a function κ : P ( S ) → P ( P ( S ) ) and denote by κ µ the value of κ evaluated at µ . Given any ν ∈ P ( P ( S ) ) , deﬁne ˜ ν to be any element of P ( P ( S ) ) satisfying , for all Borel - measurable sets U ⊆ P ( S ) , (cid:90) U ˜ ν ( dµ (cid:48) ) : = (cid:90) P ( S ) (cid:90) U κ µ ( dµ (cid:48) ) ν ( dµ ) . The possibility of the strength of A changing between matches because of external factors is modeled by replacing the measure ν A Model 2 . 11 associates to them by ˜ ν A . We call the function κ a kernel . Example 2 . 17 . If κ µ = δ µ for all µ ∈ P ( S ) , then ˜ ν = ν for all ν . Here δ µ denotes the Dirac measure at µ ( Deﬁnition 2 . 3 ) . (cid:52) Example 2 . 18 . Recall the description of the Glicko system given in Example 2 . 13 . Let ϕ ( · | x , σ 2 ) be the normal density on R with mean x and variance σ 2 . As described in [ 8 , § 3 . 2 ] , one step of the 8 ALEX COWAN Glicko system is using Model 2 . 16 with κ δ x the Dirac - only measure ( Deﬁnition 2 . 12 ) satisfying κ δ x ( { δ y : y ∈ U } ) = (cid:90) U ϕ ( y | x , σ 2 ) dy for some ﬁxed σ 2 and all Borel - measurable U ⊆ R . As mentioned in Example 2 . 13 , this formulation of Glicko only involves ν which are Dirac - only , so the value κ µ when µ isn’t a Dirac measure is irrelevant . It’s computationally convenient that if ν and κ are normal in this sense , then ˜ ν is again normal ; c . f . [ 8 , Eq . ( 7 ) ] . (cid:52) Remark 2 . 19 . In some applications allowing κ to depend on the player can increase the accuracy of the model . The main innovation of Glicko2 [ 9 ] over Glicko is choosing such a dependence . However , this can incentivize players seeking to maximize their rating to intentionally lose games in some cir - cumstances [ 5 , § 5 . 1 ] . Competitive players of Pokémon GO have done this and perceive the resulting rankings to be inaccurate [ 25 ] . 3 . Parameter choices Our system is in use in the online collectible card game Duelyst II . To implement the system , we needed to choose values for the parameters listed at the beginning of Section 2 : • In Model 2 . 1 , a luck function Λ • In Model 2 . 11 , a prior ν 0 for unknown players • In Model 2 . 16 , a kernel κ In this section we present the choices we made and give a concrete description of the resulting system . Our system is succinctly summarized in Section 3 . 4 . We expect that similar choices will be suitable for many applications , and discuss minor variations other situations might call for . 3 . 1 . The luck function Λ and its tails . For Duelyst II , we take S = R . There are situations like those discussed in Example 2 . 10 which call for diﬀerent choices of S , but we didn’t feel that this was necessary for our application . Our choice of Λ is Λ ( x , y ) = 1 − β 2 + β 1 + exp ( y − x ) ( 2 ) with β = 0 . 8 . This is the Λ from Example 2 . 9 , and we discuss it there . When displaying ratings in game , we ﬁrst apply the transformation x (cid:55)→ 400 log 10 x + 1500 ( 3 ) so that we match the parameterization of the Bradley – Terry model used by FIDE [ 7 ] and Glicko [ 8 ] . Our Λ is a linear combination of a constant function and a sigmoid . We chose a logistic curve for the sigmoid , but we would guess that other choices , like a normal CDF as in the Thurstone – Mosteller model [ 23 , 24 , 16 , 17 , 18 ] , would work just as well . In contrast , the constant term in Λ has a very large impact on the behaviour of the system . PAIRED COMPARISONS FOR GAMES OF CHANCE 9 Figure 3 . 1 . Diﬀerence in means ( 4 ) between ν A ∼ N ( m , σ 2 ) and ν A , A > B as a function of m . Here ν B = δ δ 2000 , and Λ is given by ( 2 ) and ( 3 ) with , from left to right , β = 0 . 8 , 0 . 99 , and 1 . The maximum diﬀerences for m ∈ [ 0 , 4000 ] are highlighted . Figure 3 . 1 illustrates the eﬀect of including a constant term in Λ . We suppose B ’s strength is always 2000 ( i . e . ν B = δ δ 2000 ; c . f . Deﬁnition 2 . 3 ) , A ’s strength is an unknown real number ( i . e . ν A is “Dirac - only” as in Deﬁnition 2 . 12 ) , and the system’s prior ν A for A ’s strength is a normal distribution with mean m and variance σ 2 . If the match outcome A > B is observed , then the system uses Model 2 . 11 to update its belief about A ’s strength . Let m (cid:48) be the mean of A ’s updated distribution ν A , A > B . Figure 3 . 1 plots the diﬀerence m (cid:48) − m as a function of m for Λ as in ( 2 ) and reparameterized according to ( 3 ) , β = 0 . 8 , 0 . 99 , 1 , and various σ . Unpacking the deﬁnitions , one can write the quantity being plotted explicitly : m (cid:48) − m = 1 − β 2 m + (cid:90) R β 1 + 10 2000 − x 400 exp (cid:18) − ( x − m ) 2 2 σ 2 (cid:19) x dx √ 2 πσ 2 1 − β 2 + (cid:90) R β 1 + 10 2000 − x 400 exp (cid:18) − ( x − m ) 2 2 σ 2 (cid:19) dx √ 2 πσ 2 − m . ( 4 ) When β < 1 , one interpretation is that , like in Example 2 . 9 , there is a nonzero chance that the winner of a match is decided uniformly at random . If B is vastly stronger than A , then , when the match outcome A > B is observed , the only plausible explanation is that the outcome of the match was in fact decided by chance , and the posterior distribution ν A , A > B for A is very similar to their prior ν A . In ( 4 ) , this intuition is reﬂected in the value of the integrals being much smaller than the constant terms , because there is nearly no overlap between the factors β 1 + 10 2000 − x 400 and exp (cid:16) − ( x − m ) 2 2 σ 2 (cid:17) , which respectively come from the sigmoidal term in Λ ( deﬁned in ( 2 ) ) and the prior ν A . In contrast , when β = 1 , the constant terms in the numerator and denominator of ( 4 ) vanish , and the diﬀerence in the means of ν A and ν A , A > B is the ratio of the two exponentially small integrals . Essentially , the system views the chance of A having strength comparable to B ’s as vanishingly small , but also views the chance of observing the match outcome A > B as vanishingly small . Because ν A has the exp ( − x 2 ) tails of a normal distribution , but Λ has the much heavier tail exp ( − x ) , almost all of the mass in the integrals comes from x ≈ m . A straightforward calculation shows that m (cid:48) − m −→ σ 2 log 10 400 as m −→ −∞ . The behaviour with β = 1 overall seems much less reasonable to us than when β < 1 , since it leads to massive rating changes for A based on ratios of minuscule probabilities . We view these probabilities as being substantially smaller than the chance that something bizarre has happened 10 ALEX COWAN that the β = 1 model is not equipped to consider , and believe that a model that better reﬂects reality should not view this match outcome as extremely strong evidence that A is tremendously underrated . Figure 3 . 1 shows that changing β from 1 to 0 . 99 changes the behaviour of the model much more than changing β from 0 . 99 to 0 . 8 . Figure 3 . 2 . Change in rating after each match for the two Duelyst II players that have played the most matches at the time of writing , plotted against diﬀerence be - tween their rating and their opponent’s . The ﬁrst 100 matches from each player are excluded . We note that [ 10 , Fig . 1 ] reports that four widely - used systems based on the Bradley – Terry model all overesti - mate the performance of very highly rated competitors , that Sonas reports observing the same phenomenon in the popular article [ 22 ] with a dataset of 1 . 54 million chess games from FIDE , and that FIDE truncates the tails of the Λ it uses ; see Example 2 . 8 . This is consis - tent with our qualitative assessment of Figure 3 . 1 above : the Bradley – Terry model , with exponential asymptotes at 0 and 1 , overestimates the winning chances of a much higher rated player . The two players who have played the most matches in our Duelyst II dataset of the ﬁrst 1 , 126 , 592 ranked matches played since the game’s launch , who we call P and Q . have played 2162 and 2142 matches respectively , and are ranked by our system to be at the 95 th and 99 . 95 th percentiles among all players having played at least one ranked match . Figure 3 . 2 shows the change in rating , i . e . mean of ν P or ν Q , after each of their matches beyond the ﬁrst 100 they played . The horizontal axis shows the rating diﬀerence at the time of the match between the player and their opponent . P is shown in red , and Q in blue . Points above the axis are wins and points below are losses , except for the 10 distinctly visible draws separate from the rest of the points . The shape of the clusters in Figure 3 . 2 is similar to what’s shown in Figure 3 . 1 , as expected . The qualitative observation that the blue points are noisier than the red points is explained by the fact that Var ( ν Q ) varies between about 52 2 and 62 2 for the plotted matches , whereas Var ( ν P ) is almost always between 48 2 and 52 2 . 3 . 2 . ν 0 for unknown players . Duelyst II’s implementation considers only values of ν which are Dirac - only ( Deﬁnition 2 . 12 ) . We can then view ν as a probability distribution on R , with the interpretation that each player’s strength could in principle be described by a single real number , and ν describes the system’s knowledge of said real number . The prior ν 0 we assign to an unknown player , viewed as a distribution on R , is ν 0 = n (cid:88) k = 0 ρ ( x k ) δ x k ( 5 ) with x k = − M + 2 M n k , ρ ( x k ) ∝ ϕ ( x k | 0 , σ 20 ) , n = 1000 , M = 7 , σ 20 = 0 . 7 2 . Here δ x k is a Dirac measure ( Deﬁnition 2 . 3 ) , ϕ ( · | x , σ 20 ) is the normal density with mean x and variance σ 20 , and ∝ indicates that the values of ρ ( x k ) are rescaled so that they sum to 1 . It would be more natural to take ν 0 to be the normal distribution N ( 0 , 0 . 7 2 ) , but we choose the discrete distribution ( 5 ) with ﬁnite support because it is straightforward to implement : we can encode ( 5 ) as the tuple ( ρ ( x 0 ) , . . . , ρ ( x 1000 ) ) ∈ R 1001 , a list of 1001 real numbers . The measure ( 5 ) is an approximation to N ( 0 , 0 . 7 2 ) in the sense of weak convergence as n , M −→ ∞ . PAIRED COMPARISONS FOR GAMES OF CHANCE 11 We chose the values of n = 1000 , M = 7 , and σ 20 = 0 . 7 2 by examining the system’s performance on the dataset of the ﬁrst 1 , 126 , 592 ranked matches played since Duelyst II’s launch . We were primarily concerned with producing a reliable ranking for the game’s strongest players . The resulting rankings were relatively insensitive to these choices . We found that , for this dataset , taking σ 20 = 1 lead to a small but non - negligible chance for players who happened to do very well in their ﬁrst few matches getting ranked inappropriately highly , whereas taking σ 20 = 0 . 7 2 seemingly did not . Taking smaller values of σ 20 would require top players to play more matches to be accurately rated . The numbers M and n control how precisely the system can determine a player’s strength , but larger values make the system more computationally expensive to use in practice . We chose M = 7 because no player had non - negligible mass outside [ − M , M ] , and n = 1000 because doubling this value did not meaningfully change the system’s output for our dataset . 3 . 3 . The kernel κ . For Duelyst II , we took κ to be κ δ x = n (cid:88) k = 0 K ( x , x k ) δ x k ( 6 ) with x k = − M + 2 M n k , K ( x , x k ) ∝ ϕ ( x | x k , σ 2 κ ) , n = 1000 , M = 7 , σ 2 κ = 0 . 03 2 , using the same notation as Eq . ( 5 ) . Because all ν ’s that arise will be Dirac - only ( Deﬁnition 2 . 12 ) , the value of κ µ when µ is not a Dirac measure irrelevant . As was the case in Section 3 . 2 , a more natural choice for κ , viewed as a distribution on R , would be the normal distribution N ( x k , σ 2 κ ) ( and in some applications it might be desirable to take κ to be , more generally , a mixture of normal distributions with the same mean ) , but , for computational convenience , we want ˜ ν to give 0 mass to R \ { x 0 , . . . , x n } . 3 . 4 . Summary . In Duelyst II , each player A is represented as a tuple of 1001 real numbers : (cid:18) ρ A ( 141000 · 0 − 7 ) , ρ A ( 141000 · 1 − 7 ) , . . . , ρ A ( 141000 k − 7 ) , . . . , ρ A ( 7 ) (cid:19) . New players are set such that ρ A ( x ) ∝ 1 √ 2 π · 0 . 7 2 exp (cid:18) − x 2 2 · 0 . 7 2 (cid:19) . Here and later , ∝ indicates that the values are then normalized so that they sum to 1 . After the match outcome A > B is observed , the system updates the values of ρ A and ρ B to ρ A , A > B ( x ) ∝ ρ A ( x ) 1000 (cid:88) k = 0 ρ B (cid:0) 141000 k − 7 (cid:1) (cid:34) 0 . 1 + 0 . 8 1 + exp (cid:0) ( 141000 k − 7 ) − x (cid:1) (cid:35) , ρ B , A > B ( x ) ∝ ρ B ( x ) 1000 (cid:88) k = 0 ρ A (cid:0) 141000 k − 7 (cid:1) (cid:34) 0 . 1 + 0 . 8 1 + exp (cid:0) x − ( 141000 k − 7 ) (cid:1) (cid:35) . We evaluate these expressions using the Fast Fourier Transform ( FFT ) as described in Section 4 . 2 . The values of ρ A and ρ B are then replaced with the values of ρ A , A > B and ρ B , A > B . Immediately after completing the step above , ρ A is replaced with ˜ ρ A , deﬁned by ˜ ρ A ( x ) ∝ 1000 (cid:88) k = 0 ρ A (cid:0) 141000 k − 7 (cid:1) 1 √ 2 π · 0 . 03 2 exp (cid:32) − (cid:0) x − ( 141000 k − 7 ) (cid:1) 2 2 · 0 . 03 2 (cid:33) , and ρ B is replaced with ˜ ρ B deﬁned analogously . FFT is used to compute the values of ˜ ρ A and ˜ ρ B . 12 ALEX COWAN 4 . Algorithms Our rating system operates as follows : • Assign a prior ν 0 to unknown players ( see Model 2 . 11 and Section 3 . 2 ) . • After every match : ( 1 ) update ν A and ν B to ν A , A > B and ν B , A > B using to Model 2 . 11 , ( 2 ) replace ν A and ν B with ˜ ν A and ˜ ν B using Model 2 . 16 , where A and B are the winner and loser of that match respectively . We call step 1 above match processing , and step 2 kernel processing . In this section , we present three algorithms for each of these steps , for three special cases of parameter choices . In all three cases , we will assume that the playing strength of an arbitrary player A is an unknown ﬁxed real number that is an element of a known ﬁnite set S A ( which can depend on A ) of size at most n + 1 ( which cannot depend on A ) . In Section 4 . 1 , we give an algorithm that is fully general besides the assumptions above . This algorithm takes time (cid:29) n 2 for each of the match processing step from Model 2 . 11 and the kernel processing step from Model 2 . 16 , whereas the other two algorithms we present take time (cid:28) n 1 + ε for these steps . This algorithm is useful because it is the simplest of the three . In Section 4 . 2 , we give an algorithm based on the Fast Fourier Transform ( FFT ) that processes matches and kernels in time (cid:28) n 1 + ε , but requires some mild additional assumptions . This is the algorithm that we think is most useful for applications , and that we used in Duelyst II . In Section 4 . 3 , we give another algorithm that processes matches and kernels in (cid:28) n 1 + ε , but does not rely on FFT , and instead is completely elementary . It makes the somewhat restrictive assumption that the functions Λ and κ are essentially short linear combinations of CDFs or PDFs of Laplace distributions respectively , but omits assumptions on S A that were necessary for the FFT - based algorithms . 4 . 1 . Naive algorithms . Let ρ A be such that ρ A ( x ) = ν A ( { x } ) for all x . If the match A > B is observed , then A ’s posterior distribution is given by ρ A , A > B ( x ) ∝ ρ A ( x ) (cid:88) x k ∈ S B ρ B ( x k ) Λ ( x , x k ) . ( 7 ) Evaluating ρ A , A > B ( x ) for a speciﬁc x by summing the right hand side above directly takes time O ( n ) . The function ρ A is supported on at most n points , so overall the posterior can be computed in time O ( n 2 ) . If B > A is observed instead , then the same formula can be used with Λ ( x , x k ) replaced by Λ ( x k , x ) = 1 − Λ ( x , x k ) . Example 4 . 1 . Suppose Λ ( x , y ) = x x + y , ρ A ( 2 ) = 9 20 , ρ A ( 5 ) = 3 20 , ρ A ( 13 ) = 8 20 , ρ B ( 3 ) = 2 11 , ρ B ( 7 ) = 4 11 , ρ B ( 11 ) = 5 11 . If A > B is observed , then ρ A , A > B ( 2 ) ∝ ρ A ( 2 ) (cid:88) x k ∈ { 3 , 7 , 11 } ρ B ( x k ) 2 2 + x k = 719 7150 , ρ A , A > B ( 5 ) ∝ 43 704 , ρ A , A > B ( 13 ) ∝ 208 825 . PAIRED COMPARISONS FOR GAMES OF CHANCE 13 Normalizing gives ρ A , A > B ( 2 ) = 69024 284005 ≈ 0 . 24 , ρ A , A > B ( 5 ) = 41925 284005 ≈ 0 . 15 , ρ A , A > B ( 13 ) = 173056 284005 ≈ 0 . 61 . Similarly , ρ B , A > B ( 3 ) = 74724 284005 ≈ 0 . 26 , ρ B , A > B ( 7 ) = 105456 284005 ≈ 0 . 37 , ρ B , A > B ( 11 ) = 103825 284005 ≈ 0 . 37 . Note that we use ρ A , not ρ A , A > B , to update ρ B . (cid:52) Let K : R 2 → R be deﬁned by κ δ x = (cid:88) x k ∈ S A K ( x , x k ) δ x k as in ( 6 ) . Then ˜ ρ A can be computed as ˜ ρ A ( x ) ∝ (cid:88) x k ∈ S A ρ A ( x k ) K ( x , x k ) ( 8 ) for x ∈ S A . Like the case with match processing discussed above , computing ˜ ρ A this way takes time O ( n 2 ) . Example 4 . 2 . Suppose S A = { 1 , 2 , . . . , 100 } and K ( x , y ) = (cid:40) 13 if x − y ∈ { − 1 , 0 , 1 } 0 otherwise , ρ A ( n ) = (cid:40) 110 if n is a perfect square 0 otherwise . Then ˜ ρ A ( n ) = (cid:40) 128 n ∈ U 0 otherwise , where U = (cid:8) n ∈ Z ∩ [ 1 , 100 ] : for some δ ∈ { − 1 , 0 , 1 } , n + δ ∈ [ 1 , 100 ] and √ n + δ ∈ Z (cid:9) = { 1 , 2 , 3 , 4 , 5 , 8 , 9 , 10 , 15 , 16 , 17 , 24 , 25 , 26 , 35 , 36 , 37 , 48 , 49 , 50 , 63 , 64 , 65 , 80 , 81 , 82 , 99 , 100 } . (cid:52) 4 . 2 . FFT - based algorithms . We write f ( n ) = ˜ O ( g ( n ) ) to mean f ( n ) = O ( g ( n ) n ε ) for all ε > 0 . Deﬁne ρ A , ρ B , and K as in the previous section . We will recognize ( 7 ) and ( 8 ) as convolutions , and then use the Fast Fourier Transform ( FFT ) to compute them in time ˜ O ( n ) . In this section , we assume the following : • S A = S B , • S A = { x 0 , . . . , x n } with x k = k ∆ for some ∆ ∈ R > 0 , • Λ ( x , y ) = 1 − β 2 + βF ( x − y ) for some β ∈ [ 0 , 1 ] and F : R → [ 0 , 1 ] increasing with asymptotes at 0 and 1 , • K ( x , y ) = G ( x − y ) for some G : R → R . We begin by presenting an algorithm for kernel processing . With the assumptions above , ( 8 ) can be written as ˜ ρ A ( k ∆ ) = n (cid:88) j = 0 ρ A ( j ∆ ) G (cid:0) ( k − j ) ∆ (cid:1) . We recognize this as a discrete convolution : ˜ ρ A = ρ A ∗ G . We can then compute all the values in the list ˜ ρ A = (cid:0) ˜ ρ A ( 0 ) , ˜ ρ A ( ∆ ) , . . . , ˜ ρ A ( n ∆ ) (cid:1) in time ˜ O ( n ) by using FFT . Our algorithm for computing the posterior ( 7 ) is similar , but involves some additional elementary manipulations . Deﬁne R ( x ) : = F ( x ) − H ( x ) , 14 ALEX COWAN where H is the Heaviside function ( Deﬁnition 2 . 2 ) . Our assumptions imply that R ( x ) −→ 0 as | x | −→ ∞ , and that ρ A , A > B ( k ∆ ) ∝ ρ A ( k ∆ ) (cid:18) 1 − β 2 + β (cid:0) L R ( k ∆ ) + L H ( k ∆ ) (cid:1)(cid:19) and ρ A , A < B ( k ∆ ) ∝ ρ A ( k ∆ ) (cid:18) 1 + β 2 − β (cid:0) L R ( k ∆ ) + L H ( k ∆ ) (cid:1)(cid:19) , where L R ( k ∆ ) : = n (cid:88) j = 0 ρ B ( j ∆ ) R (cid:0) ( k − j ) ∆ (cid:1) and L H ( k ∆ ) : = n (cid:88) j = 0 ρ B ( j ∆ ) H (cid:0) ( k − j ) ∆ (cid:1) . The function L R is a convolution : L R = ρ B ∗ R . We compute all values in the list L R = (cid:0) L R ( 0 ) , . . . , L R ( n ∆ ) (cid:1) in time ˜ O ( n ) using FFT . The following algorithm computes all values in the list L H = (cid:0) L H ( 0 ) , . . . , L H ( n ∆ ) (cid:1) in time O ( n ) . Algorithm 4 . 3 . Compute L H ( k ∆ ) for all k ∈ { 0 , 1 , . . . , n } . Σ ← 0 for 0 ≤ k ≤ n do Σ ← Σ + 12 ρ B ( k ∆ ) ( Because H ( 0 ) = 12 ) L H ( k ∆ ) ← Σ Σ ← Σ + 12 ρ B ( k ∆ ) end for 4 . 3 . Laplace algorithms . Let ρ A , ρ B , and K be as in Section 4 . 1 . Deﬁne f ( x | b ) : = 1 2 b exp (cid:18) − | x | b (cid:19) and F ( x | b ) : =   12 exp (cid:16) − | x | b (cid:17) x < 0 1 − 12 exp (cid:16) − | x | b (cid:17) x ≥ 0 . These are respectively the PDF and CDF of a Laplace distribution . Assume • Λ ( x , y ) = 1 − β 2 + β (cid:80) (cid:96)j = 1 p j F ( x − y | a j ) for non - negative reals p j which sum to 1 , • K ( x , y ) = (cid:80) (cid:96)j = 1 q j f ( x − y | b j ) for non - negative reals q j which sum to 1 . With these assumptions , ( 7 ) and ( 8 ) become ρ A , A > B ∝ ρ a ( x )   1 − β 2 + β (cid:96) (cid:88) j = 1 p j (cid:88) x k ∈ S B ρ B ( x k ) F ( x − x k | a j )   and ˜ ρ A ( x ) ∝ (cid:96) (cid:88) j = 1 q j (cid:88) x k ∈ S A ρ A ( x k ) f ( x − x k | b j ) . We evaluate the inner sums for all x ∈ S A simultaneously in time ˜ O ( n ) using Algorithm 4 . 6 and Algorithm 4 . 5 described below . Doing the remaining arithmetic in the usual way , we evaluate the right hand sides for all x ∈ S A in time ˜ O ( (cid:96)n ) . The ﬁnal normalization can be done in time O ( n ) . The rest of this section explains Algorithm 4 . 6 and Algorithm 4 . 5 . Fix ρ : R → R non - negative , supported on x 1 , . . . , x n , and such that its values sum to 1 . Deﬁne Q : R → R by Q ( y ) : = n (cid:88) k = 1 ρ ( x k ) f ( y − x k | b ) . PAIRED COMPARISONS FOR GAMES OF CHANCE 15 Algorithm 4 . 5 takes as input an arbitrary ﬁnite set of real numbers y 1 , . . . , y m and computes , in time ˜ O ( m + n ) , all of the m quantities Q ( y 1 ) , . . . , Q ( y m ) . Deﬁne Q L ( y ) : = (cid:88) x k ≤ y ρ ( x k ) f ( y − x k | b ) and Q R ( y ) : = (cid:88) x k > y ρ ( x k ) f ( y − x k | b ) . The following observation , which is immediate from the deﬁnitions , is the main idea underlying Algorithm 4 . 5 and Algorithm 4 . 6 . Observation 4 . 4 . If y and ∆ are such that { x 1 , . . . , x n } ∩ [ y , y + ∆ ] = ∅ , then Q L ( y + ∆ ) = e − ∆ b Q L ( y ) and Q R ( y + ∆ ) = e ∆ b Q R ( y ) . Algorithm 4 . 5 . Compute Q ( y i ) for all y i ∈ { y 1 , . . . , y m } . U ← { x 1 , . . . , x n } ∪ { y 1 , . . . , y m } Sort U from smallest to largest . L ← 0 z 0 ← U [ 0 ] for z ∈ U do ∆ ← z − z 0 L ← e − ∆ b L + 12 b ρ ( z ) Q ( z ) ← L z 0 ← z end for Sort U from largest to smallest . R ← 0 for z ∈ U do ∆ ← z 0 − z R ← e − ∆ b R Q ( z ) ← Q ( z ) + R R ← R + 12 b ρ ( z ) z 0 ← z end for It is possible to compute the contribution from Q R ( y i ) during the ﬁrst iteration over U . However , doing so requires that the arithmetic be done using (cid:29) 1 b ( max U − min U ) bits of precision because Q R ( y + ∆ ) grows exponentially in ∆ . In almost all applications it’ll be the case that 1 b ( max U − min U ) (cid:29) m + n , and the algorithm won’t run in time ˜ O ( m + n ) . Deﬁne T : R → R by T ( y ) : = n (cid:88) k = 1 ρ ( x k ) F ( y − x k | b ) . T ( y ) can be decomposed into the three sums T ( y ) = (cid:88) x k ≤ y ρ ( x k ) − (cid:88) x k ≤ y 12 ρ ( x k ) exp (cid:18) x k − y b (cid:19) + (cid:88) x k > y 12 ρ ( x k ) exp (cid:18) y − x k b (cid:19) . With this decomposition and the ideas used to produce Algorithm 4 . 3 and Algorithm 4 . 5 , we can construct Algorithm 4 . 6 that takes as input a set { y 1 , . . . , y m } and computes all of the corresponding values T ( y i ) in time ˜ O ( m + n ) . Algorithm 4 . 6 . Compute T ( y i ) for all y i ∈ { y 1 , . . . , y m } . U ← { x 1 , . . . , x n } ∪ { y 1 , . . . , y m } Sort U from smallest to largest . M ← 0 16 ALEX COWAN L ← 0 z 0 ← U [ 0 ] for z ∈ U do ∆ ← z − z 0 M ← M + ρ ( z ) L ← e − ∆ b L + 12 ρ ( z ) T ( z ) ← M − L z 0 ← z end for Sort U from largest to smallest . R ← 0 for z ∈ U do ∆ ← z 0 − z R ← e − ∆ b R T ( z ) ← T ( z ) + R R ← R + 12 ρ ( z ) z 0 ← z end for 5 . Performance in Duelyst II In this section , we compare the performance of Glicko2 with our system , as well as our system but with β = 0 . 9 instead of β = 0 . 8 in ( 2 ) , on the dataset of the ﬁrst 1 , 126 , 592 ranked matches played since Duelyst II’s launch . Duelyst II used Glicko2 [ 9 ] to rate players previously , with parameters chosen to be the same as the ones used in the prequel Duelyst between 2016 to 2020 : τ = 0 . 5 and default rating 1500 , RD 200 , and volatility 0 . 06 [ 19 ] . Each of the three systems we analyze in this section we processed the matches in our dataset in chronological order . For each match , each system estimated the probability p of the observed match outcome occurring . Our system estimated p using Model 2 . 1 , and Glicko2 estimated p using [ 8 , Eq . ( 16 ) ] . For the matches in which both players had variance less than 70 2 after the reparameterization ( 3 ) , we computed − log p , the log loss of that match . The average log loss was 0 . 6625 for Glicko2 , 0 . 6613 for β = 0 . 8 , and 0 . 6559 for β = 0 . 9 . Figure 5 . 1 . Left : Log loss of each match by rating diﬀerence . Right : Proportion of the dataset’s total log loss by rating diﬀerence , normalized to integrate to average log loss . The left image in Figure 5 . 1 plots the log loss of each match individually , coloured by system . The horizontal axis is the diﬀerence in the ratings of the two players . For each colour , the three distinct curves correspond to wins by the weaker player ( top ) , draws ( middle ) , and wins by the PAIRED COMPARISONS FOR GAMES OF CHANCE 17 stronger player ( bottom ) . The number of matches being plotted is large : 557973 for Glicko2 , 566213 for β = 0 . 8 , and 653660 for β = 0 . 9 , causing many of the points to overlap . The right image of Figure 5 . 1 quantiﬁes the density of points in the left image by showing the relative contribution of each rating diﬀerence to the total log loss in the dataset . Let K ( x , y ) : = 1 √ 2 π · 5 2 exp (cid:18) − ( x − y ) 2 2 · 5 2 (cid:19) denote a Gaussian kernel with variance 5 2 . The curve plotted on the right is proportional to (cid:88) − log p · K ( x , | r A − r B | ) (cid:82) ∞ 0 K ( x , t ) dt , where the sum is over matches in which both players have variance at most 70 2 , the quantities r A and r B denote the means of the players ( i . e . their ratings ) , p is the probability of the observed match outcome occurring as estimated by each system , and x is the variable for the horizontal axis . The proportionality constant is such that the plotted function integrates to the average log loss . While the value β = 0 . 9 had smaller total log loss than the value β = 0 . 8 which was implemented , our judgment was that β = 0 . 8 was the better choice for our purposes for two reasons . First , in our application , maximizing the probability observing the empirical data was not our goal . For us , it was much more important to accurately rank the game’s top players relative to each other . The choice β = 0 . 8 yields more stable and reliable rankings , which is very important in practice . Second , many players actively enjoy interacting with the in - game rating system ; trying to max - imize the number the game displays to them becomes one of their primary objectives . From the perspective of game design , harshly penalizing unlucky losses is remarkably frustrating . References [ 1 ] Ralph Allan Bradley and Milton E . Terry . Rank analysis of incomplete block designs . I . The method of paired comparisons . Biometrika , 39 : 324 – 345 , 1952 . [ 2 ] Alex Cowan . BlatMMR . https : / / github . com / thealexcowan / blatmmr , March 2023 . [ 3 ] Wojciech M . Czarnecki , Gauthier Gidel , Brendan Tracey , Karl Tuyls , Shayegan Omidshaﬁei , David Balduzzi , and Max Jaderberg . Real world games look like spinning tops . In H . Larochelle , M . Ranzato , R . Hadsell , M . F . Balcan , and H . Lin , editors , Advances in Neural Information Processing Systems , volume 33 , pages 17443 – 17454 . Curran Associates , Inc . , 2020 . [ 4 ] H . A . David . The method of paired comparisons , volume 41 of Griﬃn’s Statistical Monographs & Courses . Charles Griﬃn & Co . , Ltd . , London ; The Clarendon Press , Oxford University Press , New York , second edition , 1988 . [ 5 ] Aram Ebtekar and Paul Liu . Elo - MMR : A rating system for massive multiplayer competitions . In Proceedings of the Web Conference 2021 , WWW ’21 , pages 1772 – 1784 , New York , NY , USA , 2021 . Association for Computing Machinery . [ 6 ] Arpad E . Elo . The Rating of Chessplayers , Past and Present . Arco Pub . , New York , 2nd edition , 1986 . [ 7 ] FIDE . Rating regulations . https : / / handbook . fide . com / chapter / B022022 , 2023 . [ Online ; accessed 25 January 2023 ] . [ 8 ] Mark E . Glickman . Parameter estimation in large dynamic paired comparison experiments . Applied Statistics , 48 ( 3 ) : 377 – 394 , 1999 . [ 9 ] Mark E . Glickman . Dynamic paired comparison models with stochastic variances . J . Appl . Stat . , 28 ( 6 ) : 673 – 689 , 2001 . [ 10 ] Mark E . Glickman , Jonathan Hennessy , and Alister Bent . A comparison of rating systems for competitive women’s beach volleyball . Statistica Applicata - Italian Journal of Applied Statistics , 30 ( 2 ) : 233 – 254 , Feb . 2020 . [ 11 ] Ralf Herbrich , Tom Minka , and Thore Graepel . TrueSkill ( TM ) : A bayesian skill rating system . In Advances in Neural Information Processing Systems 20 , pages 569 – 576 . MIT Press , January 2007 . [ 12 ] Trevor A . Holster and J . Lake . Guessing and the Rasch model . Language Assessment Quarterly , 13 ( 2 ) : 124 – 141 , 2016 . [ 13 ] Lichess . Analysis board . https : / / lichess . org / analysis , 2023 . [ Online ; accessed 23 January 2023 ] . [ 14 ] Lichess . Rating system source code . https : / / github . com / lichess - org / lila / blob / master / modules / rating / src / main / glicko2 / RatingCalculator . scala , 2023 . [ Online ; accessed 28 February 2023 ] . [ 15 ] Tom Minka , Ryan Cleven , and Yordan Zaykov . TrueSkill 2 : An improved bayesian skill rating system . Technical Report MSR - TR - 2018 - 8 , Microsoft , March 2018 . 18 ALEX COWAN [ 16 ] Frederick Mosteller . Remarks on the method of paired comparisons : I . The least squares solution assuming equal standard deviations and equal correlations . Psychometrika , 16 : 3 – 9 , 1951 . [ 17 ] Frederick Mosteller . Remarks on the method of paired comparisons : II . The eﬀect of an aberrant standard deviation when equal standard deviations and equal correlations are assumed . Psychometrika , 16 : 203 – 206 , 1951 . [ 18 ] Frederick Mosteller . Remarks on the method of paired comparisons : III . A test of signiﬁcance for paired compar - isons when equal standard deviations and equal correlations are assumed . Psychometrika , 16 : 207 – 218 , 1951 . [ 19 ] Open Duelyst . Glicko2 parameters . https : / / github . com / open - duelyst / duelyst / blob / main / server / lib / data _ access / rank . coffee # L527 , 2023 . [ Online ; accessed 22 February 2023 ] . [ 20 ] Georg Rasch . Studies in mathematical psychology : I . Probabilistic models for some intelligence and attainment tests . 1960 . [ 21 ] Ricky Sanjaya , Jun Wang , and Yaodong Yang . Measuring the non - transitivity in chess . Algorithms , 15 ( 5 ) , 2022 . [ 22 ] Jeﬀ Sonas . The Elo rating system – correcting the expectancy table . https : / / en . chessbase . com / post / the - elo - rating - system - correcting - the - expectancy - tables , 2011 . [ Online ; accessed 29 January 2023 ] . [ 23 ] L . L . Thurstone . A law of comparative judgment . Psychological Review , 34 : 273 – 286 , 1927 . [ 24 ] L . L . Thurstone . Psychophysical analysis . The American Journal of Psychology , 38 ( 3 ) : 368 – 389 , 1927 . [ 25 ] vlfph . Farming Volatility : How a major ﬂaw in a well - known rating system takes over the GBL leaderboard . https : / / www . reddit . com / r / TheSilphRoad / comments / hwff2d / farming _ volatility _ how _ a _ major _ flaw _ in _ a / , 2023 . [ Online ; accessed 25 January 2023 ] . [ 26 ] Xue Yan , Yali Du , Binxin Ru , Jun Wang , Haifeng Zhang , and Xu Chen . Learning to Identify Top Elo Ratings : A Dueling Bandits Approach , pages 6375 – 6383 . AAAI Press , 2022 . [ 27 ] E . Zermelo . Die Berechnung der Turnier - Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung . Math . Z . , 29 ( 1 ) : 436 – 460 , 1929 . Department of Mathematics , Harvard University , Cambridge , MA 02138 USA Email address : cowan @ math . harvard . edu