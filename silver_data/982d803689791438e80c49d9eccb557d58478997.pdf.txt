SPECIAL SECTION Edward A . Fox Guest Editor Virtual Video Editing in Interactive Multimedia Applications Drawing examples from four interrelated sets of multimedia tools and applications under development at MIT , the authors examine the role of digitized video in the areas of entertainment , learning , research , and communication . Wendy E . Mackay and Glorianna Davenport Early experiments in interactive video included surro - gate travel , trainin ) ; , electronic books , point - of - purchase sales , and arcade g ; tme scenarios . Granularity , inter - ruptability , and lixrited look ahead were quickly identi - fied as generic attributes of the medium [ l ] . Most early applications restric : ed the user’s interaction with the video to traveling along paths predetermined by the author of the program . Recent work has favored a more constructivist approach , increasing the level of interac - tivity ‘by allowing L . sers to build , annotate , and modify their own environnlents . Tod . ay’s multitasl : ing workstations can digitize and display video in reel - time in one or more windows on the screen . Users citn quickly change their level of in - teraction from passvely watching a movie or the net - work news to activ ? ly controlling a remote camera and sending the output to colleagues at another location [ g ] . In this environment , video becomes an information stream , a data type that can be tagged and edited , ana - lyzed iand annotatetl . This , article explc res how principles and techniques of user - controlled video editing have been integrated into four multimed a environments . The goal of the authors is to explai I in each case how the assumptions embedded in particu1a . r applications have shaped a set of tools for building constructivist environments , and to comment on how tile evolution of a compressed digital UNIX is il trademark of AT % T 1314 Laboratories . MicroVAX is a trademark ( f Digital Equipment Corporation . PC / RT ic ; a trademark of IEM . Parallax is a trademark of l’arallax , Inc . 0 1989 ACM OOOl - 0782 / 89 / 0700 - 0802 $ 1 . 50 video data format might affect these kinds of informa - tion environments in the future . ANALOG VIDEO EDITING One of the most salient aspects of interactive video applications is the ability of the programmer or the viewer to reconfigure [ lo ] video playback , preferably in real time . The user must be able to order video sequences and the system must be able to remember and display them , even if they are not physically adja - cent to each other . It is useful to briefly review the process of traditional analog video editing in order to understand both its influence on computer - based video editing tools and why it is so important to provide virtual editing capabilities for interactive multimedia applications . A video professional uses one or more source video - tape decks to select a desired video shot or segment , which is then recorded onto a destination deck . The defined in and out points of this segment represent the granularity at which a movie or television program is assembled . At any given point in the process , the editor may work at the shot , sequence , or scene level . Edit controllers provide a variable speed shuttle knob that allows the editor to easily position the videotape at the right frame while concentrating on the picture or sound . Desired edits are placed into a list and refer - enced by SMPTE time code numbers , which specify a location on a videotape . A few advanced systems also offer special features such as iconic representation of shots , transcript follow , and digital sound stores . The combined technology of an analog video signal and magnetic tape presents limitations that plague edi - tors . Video editing is a very slow process , far slower 802 Communications of the . 4CM ] uly 1989 Volume 3 : ! Number 7 than the creative decision - making process of selecting the next shot . The process is also totally linear . Some more advanced ( and expensive ) video editing systems such as Editflex , Montage , and Editdroid allow editors to preview multiple edits from different videotapes or videodiscs before actually recording them . This concept of virtual viewing was first implemented for an entirely different purpose in the Aspen Interactive Video project of 1980 [ a ] , almost four years before Montage and Editdroid were born . Some features of analog video editing tools have proven useful for computer - based video editing applica - tions . However , the creation of applications that pro - vide end users with editing control has introduced a number of new requirements . Tool designers must decide who will have editing control , when it will be available , and how quickly it must be adjusted to the user’s requirements . Some applications give an author or programmer sole editing control ; the end user simply views and interacts with the results . In others , the au - thor may make the first cut but not create any particu - lar interactive scenario ; the user can explore and anno - tate within the database as desired . Groups of users may work collaboratively , sharing the task of creation and editing equally . The computer may also become a participant and may modify information presentation based on the content of the video as well as on the user’s behavior . Different perspectives in visual design also affect editing decisions . For example , an English - speaking graphic designer who lays out print in books knows that the eye starts in the upper left - hand corner and travels from left to right and downward in columns . A movie director organizes scenes according to rules designed for a large , wide image projected on a distant movie screen . Subjects are rarely centered in the mid - dle , but often move diagonally across the screen . Video producers learn that the center of the television screen is the “hot spot” and that the eye will be drawn there . SPECIAL SECTION In each case , the information designer is visually liter - ate , but takes for granted conventions that are not rec - ognized by the others . Conflicts arise from the clash in assumptions . Although new conventions will probably become established over time , visual designers will for now need tools to suggest reasonable layouts and users need to be able to override those suggestions based on current needs . MULTIMEDIA TOOLS AND APPLICATIONS Assumptions about the nature of video and of interac - tivity deeply affect the ways in which people think about and use interactive video technology . We are all greatly influenced by television , and may be tempted to place video into that somewhat limited broadcast - based view . Notions of interactivity tend to extend about as far as the buttons on a VCR : stop , start , slow motion , etc . However , different applications make different demands on the kinds and level of interactivity : l Documentary film makers want to choose an optimal ordering of video segments . l Educational software designers want to create inter - active learning environments for students to explore . l Human factors researchers want to isolate events , identify patterns , and summarize their data to illus - trate theories and phenomena . l Users of on - line communication systems want to share and modify messages , enabling the exchange of research data , educational software , and other kinds of information , The authors have been involved in the development of tools and applications in each of these areas , and have struggled with building an integrated environ - ment that includes digitized video in each . This work has been influenced by other work , both at MIT and at other institutions , and the specific tools and applica - tions have influenced each other . Table I summarizes four sets of multimedia tools and Research Ares Interactive Documentaries TABLE I . Multimedia Tools and Applications under Development at MIT Tool Appticaiifit ~ _ . ; I _ ‘ > ~ idq & ~ & y # i & & , B , : b Film / Video interactive Viewing A City in Transition : New Recombination of video & Editing Tool Orleans 1983 - 86 segments Seamless editing Database of shots and edit - lists lconic representation of shots Display of associated annotation Learning Environments Athena Muse : A Multimedia Navigation Project Construction Set French Language Synchronization of different media User control of dimensions User interface Research Multimedia Communication EVA : Experimental Video Annotator Pygmalion : Multimedia Message System Experiment in Intelligent Tutoring Neuroanatomy Research Database Live annotation of video Multimedia annotation Rule - based analysis of video Networked video editing Sharing interactive video data ] uly 1989 Volume 32 Number 7 Communications of the ACM 803 SPECIAL SECT / LX’ / applications under ~ levelopment at MIT’s Media Labo - ratory and Project tithena’ and successively identifies video editing issues rai . sed by each . Most of this work has belen developed on a distributed network of visual workstations at MI’1’ . * This table is not intended to be exhaustive ; rather , it is intended to illustrate the differ - ent roles that digitir , ed video can play and trace how these alpplications and tools have positively influenced each other . INTER . ACTIVE DOIXJMENTARIES Movie - , making is hil ; hl : y interactive during the making , but quite intentionally minimizes interaction on the part of the audience in order to allow viewers to enter a state of revery . To a filmmaker , editing means shaping a cinematic narrati1 . e . In the case of narrative films , predefined shooting constraints , usually detailed in a storyboard , result ir . multiple takes of the same action ; the editor selects the best takes and adjusts the length of shots and scenes to enhance dramatic pacing . Edi - tor’s logs are an into gral aid in the process . Music and special sound effect ; are added to enhance the cine - matic experience . Good documental y on the other hand tries to engage the viewer in an ex ? loration . The story is sculpted first by the filmmaker 011 the fly during shooting . As all shots are unique , ec . iting involves further sculpting by selecting which shots reflect the most interesting and coherent aspects of the story . Editors must balance what is available against exactly what has already been included and select : . ng those shots that will make the sequence at hand a : , powerful as possible . A major ad - justment in one sequence may require the filmmaker to make dozens of othl ! r adjustments . A City in Transitiox New Orleans , 1983 - 88 The premise of the , : ase study , “A City in Transition : New Orleans , 1983 - 86 . ” was that cinema in combina - tion with text could provide insights into the people , their power and the process through which they affect urban change . Prod iced by Glorianna Davenport with cinematography by Richard Leacock , the z - hour 41 % minute film was edi ted for both linear and interactive viewing [ Z ] . The interactive version of this project was developed as a curr : . culum resource for students in ur - ban planning and political science . Rather than creating a thoroughly script6 d interactive experience , faculty who use this videodisc set design a problem that moti - vates the student as explorer . The editor’s log is re - placed with a datab lse that contains text annotation ’ The Media Lab at MIT eq lores new information technologies , connecting advanced scientific researclt with innovative applications for communications media . Project Athena is an eight - year . $ 100 . million experiment in education at MIT , co - sponsored bv Dirital Eauiument Corooration and IBM . _ . . . ’ The hardware consists of I IEC MicroVAX or IBM PC / RT workstations run - ning UNIX and the X Window System . Each workstation has a Parallax board which digitizes video in real - time from any NTSC video source , such as a video camera or a videodisc . Motion or still video can be mapped into win - dows on a high - resolution c & w graphics monitor in conjunction with text and graphics . and ancillary documentation which are critical for in - depth analysis and interpretation . An Interactive Video Viewing and Editing Tool A generic interactive viewing and editing tool was de - veloped to let viewers browse , search , select , and anno - tate specific portions of this or other videodisc movies . Each movie has a master database of shots , sequences , and scenes ; a master “postage stamp” icon is associated with each entry . Authors or users can query existing databases for related scenes or ancillary docu , mentation at any point during the session or they can build new databases and cross - reference them to the main data - base . The Galatea videodisc server , designed by Daniel Applebaum at MIT , permits remote access to the video . The current prototypes include four to six videodisc players and a full audio break - away crosspoint . switcher ; for some applications this is sufficient to achieve seamless playback of the video . A viewer can watch the movie at his or her own pace by controlling a spring - loaded mouse on a shuttle bar or pressing a play button . The user can pause at any point to select and mark a segment . Segments can be saved by storing a representative postage stamp icon on a palette ; the icon can later be moved to an active edit strip where it is sequenced for playback . Once a shot has been defined , the user can annotate it in , a number of associated databases . A graphical representation of the shot or edit strip allows advanced users to mark audio and video separately ( Figure 1 ) . The traditional concept of edit - list management is used to save and update lists made by users as they fill a palette or make an edit strip . Users can give each new list a name and a master icon - a verbal and visual memory aid ; these are then used to place sequenced lists into longer edits or into multimedia documents . The database design significantly expands the informa - tion available to both the computer and the e , ditor about a particular shot . Future Directions The goal of this experiment is to represent shots and abstract story models in a way that allows the com - puter to make choices about what the viewer would like to see next and create a cohesive story . The kind of information needed to make complex editing decisions may be roughly divided into two categories : ( ‘1 ) content [ who , what , when , where , why ) ; and ( 2 ) aesthetics [ camera position relative to object position in a time continuum ) [ 9 ] . Much of the information that is now entered into a ( database manually could be encoded during shooting or ( extracted from the pictures using advanced signal pro - cessing techniques . Digital video will also allow the computer to generate new views of a scene from spa - tially encoded video data . Finally , it will become easier to mix computer graphics with real images , which will both encourage the creation of new constructivist envi - ronments and make all video suspect . 804 Commul ~ ications of the . acbl ] uly 1989 Volume 32 Number 7 SPECIAL SECTION FIGURE 1 . , Film / Video Tool for Editing Video with Two Sound Tracks ( Graphical Interface D esigned by Hal Birkeland , MIT ) INTERACTIVE LEARNING ENVIRONMENTS The use of digitized video in education spans a range of educational philosophies from goal - oriented tutorials to open - ended explorations . The underlying philosophy tends to dictate the level of interactivity and video edit - ing control given to authors and users of any program . Programmed instruction and its successors are interac - tive in the sense that a student must respond to the information presented ; it is not possible to be a passive observer . However , only the author has flexible video editing capabilities ; the student is expected to work within the structures provided , following the desig - nated paths to reach criterion levels of mastery of the information . Hypermedia provides the user with a wider range of opportunities to explore , by following links within a network of information nodes . An even richer form of interactivity allows users to actively con - struct their environments , not just follow or even ex - plore . The constructivist approach provides students with some of the same kinds of editing and annotation tools as authors of applications . The Navigation Learning Environment In 1983 , Wendy Mackay , working with members of the Educational Services Research and Development Group at Digital Equipment Corporation , began a set of re - search projects in multimedia educational software . The goals were to compare different instructional strat - egies , improve the software development process and address the technical problems of creating multimedia object - oriented databases and learning environ - ments [ 6 ] . Coastal navigation was chosen as a test appli - cation to push the limits of the technology . Not only does it require real - time handling of a complex set of real images , symbols , text , and graphics , but it has also been presented to students using a wide range of edu - cational philosophies , ranging from structured military training to open - ended experiential learning at Outward Bound . The heart of the navigation information database is a videodisc containing over 20 discrete types of informa - tion , including nautical charts , aerial views , tide tables , navigation instruments , graphs and other reference materials . The videodisc also contains over 10 , 000 still photographs taken systematically from a boat in Penob - Scot Bay , Maine , to enable a form of surrogate travel similar to the MIT Aspen project mentioned earlier . The synchronization of images in three - dimensional space was essential to the visualization of this applica - tion . The project leader , Matt Hodges , brought the ideas and videodiscs to the Visual Computing Group at Proj - ect Athena . This project became one of the inspirations for the development of Athena Muse , a collaborative effort with Russ Sasnett and Mark Ackerman [ 3 ] . Athena Muse At Project Athena , the required spatial dimensions for the Navigation disk were generalized to include tem - poral and other dimensions . In particular , several for - eign language videodiscs funded by the Annenburg July 1989 Volume 32 Number 7 Communica‘tions of the ACh4 805 SPECIAL SECTION Foundlation were b : ing produced under the direction of Janet Murray . An i : nportant goal was to provide cul - tural context in adclition to practice with grammar and vocabulary . Students were presented with interactive scenarios featuring native speakers . In order to respond correctly , students needed to understand the speakers . Thus , they needed subtitles synchronized to the video and the ability to control them together . The concept of u , ; er - controllable dimensions was cre - ated as a general solution to the control of spatially organized material [ as in the Navigation project ) and temporally organizcid material ( as in the foreign lan - guage projects ) . Atl . ena Muse packages text , graphics , and video informat . on together and allows them to be linked in a directed graph format or operated indepen - dently ( Figure 2 ) . Different media can be linked to any number of dimensions which can then be controlled by the student or end ‘lser . When reimplemented in Athena Muse , the Naviga - tion Learning Environ : ment used seven dimensions to simulalte the movernent of a boat . Two dimensions rep - resent the boat’s position on the water and two more represlent the boat’s heading and speed . A fifth tracks the user’s viewing angle and the sixth and seventh manage a simulatecI compass that can be positioned anywhere on the screen . The user can move freely within . the enviromnent and use the tools available to a sailor to check 1oca : ion ( charts , compass , looking in all directions around t : re boat ) to set a course . Other as - pects of a simulation can be added , such as other boats , weathler conditions uncharted rocks , etc . Here , the user does not chanj : e the underlying structure of the information , since it is based on constraints in the real world , but he or shl : can move freely , ask questions , and save informatic’n in the form of notes and annota - tions for future use . Future Directions Direct recording of compressed digital video data may provide more sophisticated ways to embed visual data into simulations of real and artificial environments . Issues of synchroni : : ation will change , as some kinds of data are encoded as part of the signal . For example , subtitles or sign language for the hearing impaired will be an integral part of the original video , obviating the need for external synchronization . Other kinds of data will continue to ret uire externally - controlled synchro - nization , to handle the changing relationships among data in different ap : , lications . Users should have more sophisticated methods of controlling these associated data types , either irl real time or under program control . Cross - referencing of visual information across data - bases will also be e . isier . For example , a photograph of an island , taken iom a known location in the bay , must currently be linked by hand to the other forms of information ( charts . aerial views , software simulations ) from which it might also be viewed . Digitally encoded representations of these images will make it easier to FIGURE 2 . An Example from Athena Muse in whiich Video Segments and Subtitles are Synchronized along a Temporal Dimension calculate these relationships . Digital encoding would also allow views to be created that were not actually photographed . For exalmple , the eight still images representing a 360 - degree view from the water could be converted into a moving video se - quence in which the user appears to be slowly turning in a circle . If enough visual information has been en - coded , it may also be possible to create the illusion of moving in any direction across the water . Digital repre - sentation will also make it easier to provide smooth zooming in and out to view closeups of particular objects . Given advances in limited domain natural language recognition and natural language parsing , it may be possible to automatically encode the audio portion of a video sequence . Future versions of the foreign language projects would then allow students to engage in more sophisticated dialogs . VIDEO DATA ANALYSIS Video has become an increasingly prevalent Form of data for social scientists and other researchers , requir - ing both quantitative and qualitative analysis . The term video data can have several meanings . To a program - mer , video data is an information coding scheme , like ASCII text or bitmapped graphics . To a researcher , who uses video in field studies or to record experiments , video data is the content , rather than the format , of the video . The requirements researchers place upon video edit - ing go far beyond the capabilities of traditional analog editing equipment . They want to flexibly annotate video and redisplay video segments on the fly . They often need to synchronize video with other kinds of data , such as tracks of eye movements or keystroke logs . They want methods for exploring their data at different levels of granularity , identifying patterns through recombination or compression and summariz - ing it for other researchers . 606 Communications of the ACM July 1989 Volume 32 Number 7 SPECIAL SECTION A clear priority for many researchers is to reduce the total amount of viewing time required for a particular type of analysis . Researchers who use multiple cameras have an even more difficult problem ; they must either synchronize multiple video streams and view them to - gether or significantly increase viewing times . Some re - searchers must also share control of their data , main - taining the ability to create and modify individual annotations without affecting the source data . Just as with numerical data , different researchers should be able to perform different kinds of analyses on the same data and produce different kinds of results . The ability to integrate video and computers has spurred the development of new tools to help research - ers record , analyze and present the latter form of video data . ( A number of these tools are described in [ ll ] . ) Wendy Mackay created a tool , EVA [ B ] , written in Athena Muse to help analyze video data from an exper - iment on intelligent tutoring . The goal was to allow the researcher to annotate video data in meaningful ways and use existing computer - based tools to help analyze the data . EVA : An Experimental Video Annotator EVA , or Experimental Video Annotator , allows re - searchers to create their own labels and annotation symbols prior to a session and permits live annotation of video during an experiment . In a typical session , the researcher begins by creating software buttons to tag particular events , such as successful interactions or serious misunderstandings ( Figure 3 ) . During a session , a subject sits in front of a workstation and begins to use a new software package . A video camera is directed at the subject’s face and a log of the keystrokes may be saved . The researcher sits at the visual workstation and live video from the camera appears in a window on the screen . Another window displays the subject’s screen and an additional window is available for taking notes . The researcher has several controls available through - out the session . One is a general time stamp button , which the researcher presses whenever an interesting but unanticipated event occurs . The rest are buttons that the researcher created prior to the session . Annotation during the session saves time later when the researcher is ready to review and analyze the data . The researcher can quickly review the highlights of the previous session and mark them for more detailed analysis . The original tags may be modified and new ones created as needed . Tags can be symbolic descrip - tions of events , recorded patterns of keystrokes , visual images ( single - frame snapshots from the video ) , pat - terns of text ( from a transcription of the audio track ) , or clock times or frame numbers . Tags that refer to the events in different processes , such as the text of the audio and the corresponding video images , can be syn - chronized and addressed together . Note that annotation of live events , while useful , re - quires intense concentration . The mechanics of taking notes may cause the researcher to miss important events , and events will often be tagged several seconds after they occur . Subsequent passes are almost always necessary to create precise annotations of events . While EVA does not address all of the general problems of protocol analysis , it does provide the researcher with more meaningful methods for analyzing video data . Future Directions Digital video offers possibilities for new kinds of data analysis , both in the discovery of patterns across video segments and in the understanding of events within a segment . Video data can be compressed and summa - rized in order to provide a shortened version of what occurred , to tell a story about typical events , to high - light unusual events or to present collections of inter - esting observations . The use of highlights can either concisely summarize a session or completely misrepre - sent it . Just as with quantitative data , it is important to balance presentation of the unusual data points ( out - liers ) with typical data points . In statistics , the field of exploratory data analysis provides rigorous methods for exploring and seeking out patterns in quantitative data . These techniques may be applied profitably here . An application that requires graphic overlays over sections of video needs a method of identifying the video frame or frames , a method for storing the overlay and method for storing the combination of the two . Other kinds of annotation could permit later redisplay of the video segments under program control . For ex - ample , linkages with text scripts would enable a pro - gram to present all instances in which the subject said “aha ! ” Researchers could use rules for accessing video segments with particular fields ; for example , all seg - ments might have a time stamp and a flag to indicate whether or not the subject was talking . Then a rule might be : If ( time > 11 : OO ) and ( voice on ) then display the segment . FIGURE 3 . Live Video Is Captured from a Video Camera and Presented on the Researcher’s Screen Iuly 1989 Volume 32 Number 7 Communications of the ACM a07 SPECIAL SECTION MULTIMEDIA ca MMUNICATION Electronic mail anIl telephones provide two separate forms of long - distance communication , both involving the exchange of in ! ormation . Early attempts to incorpo - rate video into Ion ; distance communication were based on a model elf the telephone , simply adding video to the audio channel . A different strategy is to incorpo - rate video into on - : ine message systems , such as elec - tronic mail , on - lim consulting systems , and bulletin board , s . The latter zlpplications enable users to ex - change informatior : asynchronously , rather than setting up a synchronous link . . If video is included , the video annotation techniques described earlier can be used to help recipients idelitify interesting messages and han - dle their mail mars efficiently . Scientists are likf ! ly candidates for using multimedia communication systems , because they face an increas - ing need to compare their data from photographs and video sources with that obtained by other scientists . The Neuroanatomy Research Database , developed by Steven Wertheim under a faculty grant from Project Athena , provides a set of multimedia messages and a set of Icommunicati m requirements that can be used to define the functionality of a multimedia message system . The NeuroanatomJr Research Database The Neuroanatomy Research Database began with a database of terms about the anatomy of the brain , in - c1udin . g over 1200 text definitions of anatomical parts , video of a brain dissection , slides of brain cross sec - tions , and a three - dimensional model of the brain re - constructed from tllese brain sections ( Figure 4 ) . Video portio : ns of the data base could be located remotely and accessed by any vitleo workstation through the Galatea video network server . A single image or video sequence can be incorporatetl into as many electronic pages as appropriate , withotlt duplicating the images . Future work will extend tlte database to enable scientists to inc1ud . e images from their own experiments and com - pare them with existing images . Pygmalion : A Mull imedia Message System Pygmalion is a multimedia message system based on a three - dimensional : nodel for on - line communication systems developed by Wendy Mackay and Win Treese [ 7 ] . The model allows users to control message ex - changes along three : dimensions : synchronous or asyn - chronous , stream or database and control by sender or the receiver . All ml ? ssages , including text , graphics and video are stored in a database at a central post office and a pointer to tht ! message is sent to the user . The user has the impre ! sion that individual messages are local , ‘but they are ; mtually stored whether it is most conve : nient in the r . etwork . Current technology re - quires the video network to be separate from the com - puter network , but conceptually , they can be treated in the sa : me way . The first test of Pygmalion will be at the SIGGRAPH ‘89 Conference , where a preliminary version will be made available to conference attendees . Over 30 , 000 people will be able to send and receive multimedia messages from a distributed network of workstations . The software is being developed by individuals from MIT’s Project Athena , the Media Lab , MIT’s ! < loan School of Management , and Digital’s Cambridge Research Laboratory . An important aspect of managing informaoon over - load at the conference is to provide a balance between control over access to messages between senders and receivers . Senders who are willing to individually iden - tify the recipients of a message can send messages di - rectly , as in electronic mail . Senders who want to reach a large audience must annotate their messages and send them to a central database , as in an elec : tronic bulletin board or on - line conferencing system . Recipi - ents then receive personally addressed messages and can browse the database for messages of inte : rest . Attendees will be able to record and edit messages con - taining video as well as text and graphics . An important feature is that all the messages can be edited by both the sender and the receiver of the message , which allows for shared control of the information . Future Directions A multimedia message system designed for a one - week event such as SIGGRAPH ‘89 , must address different design constraints than a system designed for daily use . However , since large scale implementations of the lat - ter are not currently technically feasible , implementa - tion of the former may provide useful information about the design considerations for such systems . Pygmalion will allow us to explore balance of control issues between senders and receivers of messages , the effectiveness of different annotation and retr : ieval schemes , particularly for multimedia messages , and the management of scarce video resources . Video takes a lot of room . A laser videodisc , which holds 54 , 000 frames , has only 30 minutes of video per side . Write - once disks are available , but the per - disk cost is high . The speed of access to the video is impor - tant , and has implications for how the video is laid down on the disk . The Pygmalion system stores only one copy of each message and mails a pointer , rather than the actual video , text , and graphics . ( Note that this model works at Athena , which has 850 workstations in a distributed network , but does not address the problems of sending multi - media messages over larger distances . ) Sharing presents a problem in that one person’s an - notation may not make sense to another person . Also , message senders must perform extra work to annotate messages , which decreases the likelihood that it will be done . Message templates , with fields to be filled in , are one approach . Another is to provide the option of ask - ing the sender for annotations before the message is sent . What if two people try to manipulate video at the same time ? It depends , of course , on whether they’re 808 Communications of the ACM July 1989 Volume 32 Number 7 SPECIAL SECTION FlGl Elm JRE 4 . Accessing One or : tronic Pages that Contain Graphics , and / or Video More Text , cooperating or competing , and what they’re trying to accomplish . It also depends on whether they are mak - ing decisions about a fixed order of video segments , e . g . , looking at different views of the same visual data - base or providing different kinds of annotations . In all of these cases , the participants are working together to construct a shared information environment . algorithms cause delays at different points in the ~ . compression / decompression cycle . Thus , some applica - tions that require high quality images and long video segments may not find a 30 second preliminary delay problematic . Other applications may require very rapid changes among short segments , in which delays of sev - eral seconds may not be acceptable . The importance of image quality varies across applications , and the advent of HDTV may further change the requirements . All new technologies present tradeoffs between costs and features . Before deciding on those tradeoffs , it is impor - tant for manufacturers of digital video equipment to understand the ways in which it will be used . The tools and applications presented in this article are biased to - ward a constructivist point of view , which maximizes user control over the media and the environment . Digi - tal video offers the potential for significantly enhancing them all and expanding our views of interactivity . CONCLUSIONS Computer control of analog video has been commer - cially available to broadcasters for almost two decades and in personal computing environments for almost a decade . The requirements for interactivity and flexible manipulation of video and associated data are increas - ing and emphasize the limits of current technology . Analog video storage on optical videodiscs is expensive and videotape does not provide sufficiently accurate or precise control . Cooperative work applications , as in shared authorship of multimedia documents , and video prototyping , as in interactive design of multimedia soft - ware , are promising new application areas that will extend the requirements of video as an information medium . New techniques for compressing video and encoding content and other information into the signal promise to both decrease the costs and increase the possibilities for future applications . It is important that assumptions about current and future video - based applications be taken into account when choosing among compression tradeoffs . Some applications require real - time de - compression and can afford to wait for a long compres - sion process . Others may require the reverse . Different Acknowledgments . The authors would like to thank Geoffrey Bock , Andy Lippman , Lester Ludgwig , and Deborah Tatar for early comments on this article . The work described here occurred in a stimulating environ - ment at MIT and has been influenced by many creative people . We would like to thank Hal Birkeland , Hans Peter Brondmo , Jeff Johnson , Patrick Purcell , and Ben Rubin at the Media Lab ; Ben Davis , Matt Hodges , Evelyn Schlusselberg , Win Treese , and Steve Wertheim from Project Athena ; and Mark Ackerman , Dan Apple - baum , Brian Gardner , Brian Michon , and Russ Sasnett who have been associated with both the Media Lab and Project Athena . July 1989 Volume 32 Number 7 Communications of the ACM 899 SPECML SECTfON The authors wo dd also like to thank the participants and reviewers for the ACM / SIGCHI Workshop on Video as a Researc : h and Design Tool , particularly Aus - tin Henderson , Deborah Tatar , Raymonde Guindon , Marilyn Mantei , and Lucy Suchman . REFERENCES 1 . Backer , D . , and Lip’xnan , A . Future Interactive Graphics : Personal Video . Presented tc NCGA Conference , Architecture Machine Group , MIT , Baltimore , Md . , June , 1981 . 2 . Davenport , G . New Orleans in Transition , 1983 - 1986 : The Interac - tive Delivery of a Cinematic Case Study . International Congress for Design and Planning Theory , Film / Video Group , MIT Media Laho - ratory , August , 198 7 . 3 . Hodges , M . The Vialal Database Project : Navigation . Digital Equip - ment Corporation , ‘3edford , Mass . , May , 1986 . 4 . Lippman , A . Movie , Maps : An application of the optical videodisc to computer graphics . SIGGRAPH ‘80 Conference Proceedings , Archi - tecture Machine GI oup , MIT , July , 1980 . 5 . Ludwig . L . . and Do m , D . Laboratory for Emulation and Study of Integrated and Coo , dinated Media Communication . SIGCOM ‘87 Conference Proceetlings . SIGCOM . Stowe , Vt . , 1987 . 6 . Mackay , W . E . Tuto . ing , Information Databases and Iterative Design . In instructional Designs for Microcomputer Courseware , D . H . Jonassen , Ed . L . Erlbaum Assxiates , Inc . , Hillsdale , N . J . , 1988 . 7 . Mackay , W . E . , Treese , W . , Applebaum , D . , Gardner , B . , Michon , B . , Schlusselberg , E . , P ckerman , M . , and Davis , D . Pygmalion : An Ex - periment in Multi - lrledia Communication . SIGGRAPH ‘89 Panel Proceedings , Bostoll , MA , July , 1989 . Special event to be presented at SIGGRAPH ‘89 . 8 . Mackay , W . E . EVA An Experimental Video Annotator for Symbolic Analysis of Video Ilata . SIGCHI Bulletin 21 , 1 ( Oct . 1989 ) . To be published in the Special Issue on Video as a Research and Design Tool . 9 . Rubin , B . , and Davlmport , G . Structured Content Modelling for Cin - ematic Information . SXCHI Bulletin 21 , 1 ( Oct . 1989 ) . To be pub - lished in the Speci ; 1 Issue on Video as a Research and Design Tool . 10 . Sasnett , R . Reconfigurable Video . Master’s thesis , Department of Architecture , Massachusetts Institute of Technology , 1986 . 11 . Mackay , W . E . , Ed . Workshop on Video as a Research and Design Tool ACM / SIGCHI , 1989 . In press . CR Categories and Subject Descriptors : D . 2 [ Software ] : Software En - gineering ; D . 2 . 2 [ Software ] : Tools and Techniques - - user interfaces ; D . 2 . 6 [ Software ] : Programming Environments - interacfine ; Em [ Data ] ; Mis - cellaneous - - video data General Terms : Design , Human Factors Additional Key Words and Phrases : Digital video , video ABOUT THE AUTHORS : WENDY E . MACKAY has worked for Digital Equipment Cor - poration for 10 years . Currently , she is a doctoral candidate at MIT under a scholarship from Digital . Her interests include multimedia education and communication . Author’s Present Address : MIT Project Athena , E40 - 366 , 1 Amherst Street , Cam - bridge , MA 02139 . GLORIANNA DAVENPORT is an assistant professor of media technology and director of film / video research at MIT’s Media Laboratory . She has produced , shot , and edited a number of obskrvational documentary movies and has been involved in the development of interactive editing and delivery systems since 1983 . Author’s Present Address : MIT Film / Video Group , The Media Laboratory , El5 - 432 , 20 Ames St . , Cambridge , MA 02139 . Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commer - cial advantage , the ACM copyright notice and the title of the publication and its date appear , and notice is given that copying is by permission of the Association for Computing Machinery . To copy otherwise , or to republish , requires a fee and / or specific permission . ACMVIDEOTAPE ON INTERACTIVE ~ iiiz & l DIGITAL VIDEO l - YGi = L J ACM is developing a videotape t : hat will further demonstrate the technologies discussed in these pages . In addition to serving as a video supplement to this issue , the videotape will contain the following material : 1 I Excerpts from Palenque ( an InteractiveHistory Lesson ) The Carnegie Mellon % ftware Engineering Training Program using interactive video Samples of the state - of - the - art work being done at the MIT Media Lab The use of video compression and playback developed by Intel - Circle II I I8 on Ileader Service Card 810 Communications of the ACM July 1989 Volume . 32 Number 7