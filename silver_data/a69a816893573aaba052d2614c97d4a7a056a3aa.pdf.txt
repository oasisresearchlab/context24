Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Co - clustering documents and words using Bipartite Spectral Graph Partitioning Inderjit S . Dhillon Presenter : Lei Tang 16th April 2006 Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Problem Bipartite Graph Model Duality of word and document clustering The past work focus on clustering on one axis ( either document or word ) Document Clustering : Agglomerative clustering , k - means , LSA , self - organizing maps , multidimensional scaling etc . Word Clustering : distributional clustering , information bottleneck etc . Co - clustering simultaneous cluster words and documents ! Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Problem Bipartite Graph Model Duality of word and document clustering The past work focus on clustering on one axis ( either document or word ) Document Clustering : Agglomerative clustering , k - means , LSA , self - organizing maps , multidimensional scaling etc . Word Clustering : distributional clustering , information bottleneck etc . Co - clustering simultaneous cluster words and documents ! Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Problem Bipartite Graph Model Duality of word and document clustering Adjacency Matrix M ij = (cid:26) E ij , if there is an edge { i , j } 0 , otherwise Cut ( V 1 , V 2 ) = X i ∈ V 1 , j ∈ V 2 M ij G = ( D , W , E ) where D : docs ; W : words ; E : edges representing a word occurring in a doc . The adjacency matrix : M = (cid:20) 0 A | D | × | W | A T 0 (cid:21) No links between documents ; No links between words Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Problem Bipartite Graph Model Duality of word and document clustering Adjacency Matrix M ij = (cid:26) E ij , if there is an edge { i , j } 0 , otherwise Cut ( V 1 , V 2 ) = X i ∈ V 1 , j ∈ V 2 M ij G = ( D , W , E ) where D : docs ; W : words ; E : edges representing a word occurring in a doc . The adjacency matrix : M = (cid:20) 0 A | D | × | W | A T 0 (cid:21) No links between documents ; No links between words Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Problem Bipartite Graph Model Duality of word and document clustering Disjoint document clusters : D 1 , D 2 , · · · , D k Disjoint word clusters : W 1 , W 2 , · · · , W k Idea : Document clusters determine word clusters ; word clusters in turn determine ( better ) document clusters . ( seems familiar ? recall HITS : Authorities / Hub Computation ) The “best” partition is the k - way cut of the bipartite graph . cut ( W 1 ∪ D 1 , · · · , W k ∪ D k ) = min V 1 , ··· , V k cut ( V 1 , · · · , V k ) Solution : Spectral Graph Partition Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Problem Bipartite Graph Model Duality of word and document clustering Disjoint document clusters : D 1 , D 2 , · · · , D k Disjoint word clusters : W 1 , W 2 , · · · , W k Idea : Document clusters determine word clusters ; word clusters in turn determine ( better ) document clusters . ( seems familiar ? recall HITS : Authorities / Hub Computation ) The “best” partition is the k - way cut of the bipartite graph . cut ( W 1 ∪ D 1 , · · · , W k ∪ D k ) = min V 1 , ··· , V k cut ( V 1 , · · · , V k ) Solution : Spectral Graph Partition Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors 2 - partition problem : Partition a graph ( not necessarily bipartite ) into two parts with minimum between - cluster weights . The above problem actually tries to ﬁnd a minimum cut to partition the graph into two parts . Drawbacks : Always ﬁnd unbalanced cut . Weight of cut is directly proportional to the number of edges in the cut . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors 2 - partition problem : Partition a graph ( not necessarily bipartite ) into two parts with minimum between - cluster weights . The above problem actually tries to ﬁnd a minimum cut to partition the graph into two parts . Drawbacks : Always ﬁnd unbalanced cut . Weight of cut is directly proportional to the number of edges in the cut . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors An eﬀective heuristic : W eightedCut ( A , B ) = cut ( A , B ) weight ( A ) + cut ( A , B ) weight ( B ) If weight ( A ) = | A | , then Ratio - cut ; If weight ( A ) = cut ( A , B ) + within ( A ) , then Normalized - cut . cut ( A , B ) = w ( 3 , 4 ) + w ( 2 , 4 ) + w ( 2 , 5 ) weight ( A ) = w ( 1 , 3 ) + w ( 1 , 2 ) + w ( 2 , 3 ) + w ( 3 , 4 ) + w ( 2 , 4 ) + w ( 2 , 5 ) weight ( B ) = w ( 4 , 5 ) + w ( 3 , 4 ) + w ( 2 , 4 ) + w ( 2 , 5 ) Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors An eﬀective heuristic : W eightedCut ( A , B ) = cut ( A , B ) weight ( A ) + cut ( A , B ) weight ( B ) If weight ( A ) = | A | , then Ratio - cut ; If weight ( A ) = cut ( A , B ) + within ( A ) , then Normalized - cut . cut ( A , B ) = w ( 3 , 4 ) + w ( 2 , 4 ) + w ( 2 , 5 ) weight ( A ) = w ( 1 , 3 ) + w ( 1 , 2 ) + w ( 2 , 3 ) + w ( 3 , 4 ) + w ( 2 , 4 ) + w ( 2 , 5 ) weight ( B ) = w ( 4 , 5 ) + w ( 3 , 4 ) + w ( 2 , 4 ) + w ( 2 , 5 ) Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors Solution Finding the weighted cut boils down to solve a generalized eigenvalue problem : Lz = λW z where L is Laplacian matrix and W is a diagonal weight matrix and z denotes the cut . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors Laplacian Matrix for G ( V , E ) : L ij =   P k E i k , i = j − E ij , i 6 = jand there is an edge { i , j } 0 otherwise Properties L = D − M . M is the adjacency matrix , D is the diagonal “degree” matrix with D ii = P k E ik L = I G I TG where I G is the | V | × | E | incidence matrix . For edge ( i , j ) , I G is 0 except for the i - th and j - th entry which are p E ij and − p E ij respectively . L ˆ 1 = 0 x T Lx = P i , j ∈ E E ij ( x i − x j ) ( αx + β ˆ 1 ) T L ( αx + β ˆ 1 ) = α 2 x T Lx . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors Let p be a vector to denote a cut : So p i = (cid:26) + 1 , i ∈ A − 1 , i ∈ B p T Lp = X i , j ∈ E E ij ( p i − p j ) 2 = 4 cut ( A , B ) Introduce another vector q s . t . q i =   + q weight ( B ) weight ( A ) , i ∈ A − q weight ( A ) weight ( B ) , i ∈ B T hen q = w A + w B 2 √ w A w B p + w B − w A 2 √ w A w B ˆ 1 q T Lq = ( w A + w B ) 2 4 w A w B p T Lp ( as L ˆ 1 = 0 ) = ( w A + w B ) 2 w A w B · cut ( A , B ) Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors Let p be a vector to denote a cut : So p i = (cid:26) + 1 , i ∈ A − 1 , i ∈ B p T Lp = X i , j ∈ E E ij ( p i − p j ) 2 = 4 cut ( A , B ) Introduce another vector q s . t . q i =   + q weight ( B ) weight ( A ) , i ∈ A − q weight ( A ) weight ( B ) , i ∈ B T hen q = w A + w B 2 √ w A w B p + w B − w A 2 √ w A w B ˆ 1 q T Lq = ( w A + w B ) 2 4 w A w B p T Lp ( as L ˆ 1 = 0 ) = ( w A + w B ) 2 w A w B · cut ( A , B ) Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors Property of q q T W e = 0 q T W q = weight ( V ) = w A + w B Then q T Lq q T W q = ( w A + w B ) 2 w A w B · cut ( A , B ) w A + w B = w A + w B w A w B · cut ( A , B ) = cut ( A , B ) weight ( A ) + cut ( A , B ) weight ( B ) = W eightedCut ( A , B ) Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors Property of q q T W e = 0 q T W q = weight ( V ) = w A + w B Then q T Lq q T W q = ( w A + w B ) 2 w A w B · cut ( A , B ) w A + w B = w A + w B w A w B · cut ( A , B ) = cut ( A , B ) weight ( A ) + cut ( A , B ) weight ( B ) = W eightedCut ( A , B ) Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors So , we need to ﬁnd a vector q s . t . min q 6 = 0 q T Lq q T W q , s . t . q T W e = 0 . This is solved when q is the eigenvector corresponds to the 2nd smallest eigenvalue λ 2 of the generalized eigenvalue problem : Lz = λW z In nature , a relaxation to the discrete optimization problem of ﬁnding minimum normalized cut . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors So , we need to ﬁnd a vector q s . t . min q 6 = 0 q T Lq q T W q , s . t . q T W e = 0 . This is solved when q is the eigenvector corresponds to the 2nd smallest eigenvalue λ 2 of the generalized eigenvalue problem : Lz = λW z In nature , a relaxation to the discrete optimization problem of ﬁnding minimum normalized cut . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Minimum Cut Weighted Cut Laplacian matrix Eigenvectors So , we need to ﬁnd a vector q s . t . min q 6 = 0 q T Lq q T W q , s . t . q T W e = 0 . This is solved when q is the eigenvector corresponds to the 2nd smallest eigenvalue λ 2 of the generalized eigenvalue problem : Lz = λW z In nature , a relaxation to the discrete optimization problem of ﬁnding minimum normalized cut . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary SVD Connection Multipartition L = (cid:20) D 1 − A − A T D 2 (cid:21) ; W = (cid:20) D 1 0 0 D 2 (cid:21) where D 1 ( i , i ) = P j A ( i , j ) and D 2 ( j , j ) = P i A ( i , j ) . Can we make the computation of Lz = λW z more eﬃciently by taking the advantage of bipartite ? Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary SVD Connection Multipartition L = (cid:20) D 1 − A − A T D 2 (cid:21) ; W = (cid:20) D 1 0 0 D 2 (cid:21) where D 1 ( i , i ) = P j A ( i , j ) and D 2 ( j , j ) = P i A ( i , j ) . Can we make the computation of Lz = λW z more eﬃciently by taking the advantage of bipartite ? Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary SVD Connection Multipartition (cid:20) D 1 − A − A T D 2 (cid:21) (cid:20) x y (cid:21) = λ (cid:20) D 1 0 0 D 2 (cid:21) (cid:20) x y (cid:21) Reformulation D 1 / 2 1 x − D − 1 / 2 1 Ay = λD 1 / 2 1 x − D − 1 / 2 2 A T x + D 1 / 2 2 y = λD 1 / 2 2 y Let u = D 1 / 2 1 x and v = D 1 / 2 2 y , D − 1 / 2 1 AD − 1 / 2 2 v = ( 1 − λ ) u D − 1 / 2 2 AD − 1 / 2 1 u = ( 1 − λ ) v Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary SVD Connection Multipartition Instead of computing the 2nd smallest eigenvector , we can compute the left and right singular vectors corresponding to the 2nd largest singular value of A n : A n v 2 = σ 2 u 2 ; A Tn u 2 = σ 2 v 2 where σ 2 = 1 − λ 2 T hen z 2 = " D − 1 / 2 1 u 2 D − 1 / 2 2 v 2 # Bipartition Algorithm : 1 Given A , form A n = D 1 / 2 1 AD 2 − 1 / 2 . ( note that D 1 and D 2 are both diagonal , easy to compute ) 2 Compute z 2 by SVD 3 Run k - means with k = 2 on the 1 - dimentional z 2 to obtain the desired partitioning . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary SVD Connection Multipartition Multipartition Algorithm : For k clusters , compute l = d log 2 k e singular vectors of A n and form l eigenvectors Z . Then apply k - means to ﬁnd k - way partitioning . Experiment Result Both Bipartition and multipartition algorithm works ﬁne in text domain even without removing the stop words Comment : No comparison is performed . I think this work’s major contribution is to introduce spectral clustering into text domain and present a neat formulation for co - clustering . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary SVD Connection Multipartition Multipartition Algorithm : For k clusters , compute l = d log 2 k e singular vectors of A n and form l eigenvectors Z . Then apply k - means to ﬁnd k - way partitioning . Experiment Result Both Bipartition and multipartition algorithm works ﬁne in text domain even without removing the stop words Comment : No comparison is performed . I think this work’s major contribution is to introduce spectral clustering into text domain and present a neat formulation for co - clustering . Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Contributions Questions Contributions 1 Model document collection as a bipartite graph ( Extendable to almost all the data sets . Two components : data points , Feature set ) 2 Use spectral graph partitioning for Co - clustering 3 Reslove the problem using SVD 4 Beautiful Theory Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning Introduction Review of Spectral Graph Partitioning Bipartite ExtensionSummary Contributions Questions Questions 1 Connection to HITS ? Docs as hubs , Words as authorities . Can we get the same result as bipartitioning ? In HITS , a i = A T Aa i − 1 and h i = AA T h i − 1 corresponding to the largest eigenvector of AA T and A T A , respectively . 2 Extendable to Semi - supervised Learning ? How to solve the problem is some documents and words are already labeled ? ( This is done ? ) Can we get good result by applying DengYong Zhou’s semi - supervised method ? Any other question ? Thank you ! Inderjit S . Dhillon Presenter : Lei Tang Co - clustering documents and words using Bipartite Spectral Graph Partitioning