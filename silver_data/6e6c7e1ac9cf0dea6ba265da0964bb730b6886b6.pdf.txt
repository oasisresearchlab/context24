Blu : What GUIs are made of Vinoth Pandian Sermuga Pandian Fraunhofer FIT Sankt Augustin , Germany pandian @ fit . fraunhofer . de Sarah Suleri RWTH Aachen University Aachen , Germany sarah . suleri @ rwth - aachen . de Matthias Jarke RWTH Aachen University Aachen , Germany jarke @ informatik . rwth - aachen . de ABSTRACT UI designers look for inspirational examples from existing UI designs during the prototyping process . However , they have to reconstruct these example UI designs from scratch to edit content or apply styling . The existing solution at - tempts to make UI screens into editable vector graphics us - ing image segmentation techniques . In this research , we aim to use deep learning and gestalt laws - based algorithms to convert UI screens to editable blueprints by identifying the constituent UI element categories , their location , dimension , text content , and layout hierarchy . In this paper , we present a proof - of - concept web application that uses the UI screens and annotations from the RICO dataset and generates an editable blueprint vector graphic , and a UI layout tree . With this research , we aim to support UX designers in reconstruct - ing UI screens and communicating UI layout information to developers . CCS CONCEPTS • Computing methodologies → Object detection ; • Human - centered computing → Graphical user interfaces ; User interface design ; Interface design prototyping . KEYWORDS UI Design , Deep Learning ; Object Detection ; Blueprints ; UI Layout ; Prototyping . ACM Reference Format : Vinoth Pandian Sermuga Pandian , Sarah Suleri , and Matthias Jarke . 2020 . Blu : What GUIs are made of . In 25th International Conference on Intelligent User Interfaces Companion ( IUI ’20 Companion ) , March 17 – 20 , 2020 , Cagliari , Italy . ACM , New York , NY , USA , 2 pages . https : / / doi . org / 10 . 1145 / 3379336 . 3381497 1 INTRODUCTION UI designers create user interfaces ( UI ) by following an itera - tive process of low - , medium - , and high - fidelity prototyping . Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . IUI ’20 Companion , March 17 – 20 , 2020 , Cagliari , Italy © 2020 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 7513 - 9 / 20 / 03 . https : / / doi . org / 10 . 1145 / 3379336 . 3381497 Suleri et al . analyzed the subjective workload experienced during prototyping and reported an increase in frustration , temporal demand , and effort as designers progress through different prototyping fidelities [ 4 ] . One approach UI designers use to tackle this problem is to look for existing UI design examples for inspiration and reconstruct them [ 2 , 4 ] . However , to change the content and style of an example UI , designers have to recreate it from scratch [ 2 , 3 ] . To address this problem , Swearngin et al . presented a proof - of - concept system to convert UIs into editable vec - tor graphics by detecting and vectorizing primitive shapes and text . However , they recommended applying deep learn - ing techniques to improve the accuracy of their vectorization pipeline [ 5 ] . 2 PROPOSED SOLUTION Based on their recommendation , we propose Blu , a UI layout detector using a Deep Neural Network ( DNN ) . Blu utilizes an object detection model to identify UI element categories , their locations , and dimensions . Then , it uses Tesseract OCR to identify text content for each UI element . It then uses all this information and applies Gestalt laws - based algorithms to identify the UI layout hierarchy . UI Element Detection : As the ground truth for training Blu , we use RICO dataset [ 1 ] , which contains UI screens annotated with UI element categories , their locations , and dimensions . RICO dataset consists of 72 , 219 screenshots of annotated android UI screens containing 25 categories of UI elements . We choose 80 % of the RICO dataset for training Blu’s ob - ject detection model . Then , we convert the annotations of RICO to the COCO annotation data format . With these UI screens and annotations , we train a Single - Shot MultiBox Detection ( SSD ) object detection model with Resnet back - bone to detect UI element categories , their locations , and dimensions . We then apply Tesseract OCR for each identified UI element to get the text content . To evaluate this model , we use the remaining 20 % of the RICO dataset and measure the COCO detection metrics . Layout Tree Generation : Blu applies Gestalt laws such as the law of proximity , closure , similarity , element con - nectedness , and common region for creating a UI alignment 81 IUI ’20 Companion , March 17 – 20 , 2020 , Cagliari , Italy Pandian , et al . Figure 1 : UI screen ( left ) and its respective blueprint ( middle ) and UI layout tree ( right ) created using Blu . algorithm . This algorithm takes a list of UI elements , their locations , and dimensions as input and returns the layout as a tree - structured JSON file as output . Usage : Utilizing this UI element detection and layout tree generation , we aim to generate UI layout information of any given UI screen . This layout information can be further utilized to generate editable vector graphics and front - end code for the respective screen . 3 PROOF - OF - CONCEPT SYSTEM In this paper , we present a proof - of - concept system that mimics the behavior of our proposed solution without using object detection . It is an open - source web application 1 that uses 3 , 421 UI screens and their annotations from the RICO dataset to generate editable blueprints vector graphics and UI layout trees ( Figure 1 ) . UI Blueprint : For each UI screen , its blueprint shows all the constituent UI element categories , their location , dimensions , text content , and their pixel distance relative to their par - ent . These UI blueprints are downloadable as editable vector graphics that can be imported and edited in prototyping tools with SVG support such as Sketchapp , Adobe XD , Figma , or Illustrator . Following this approach , UI designers can build on top of an existing UI screen rather than reconstructing it from scratch . UI Layout Tree : This web application further provides a UI layout tree of each UI screen . UI layout tree organizes the layout hierarchy into various nodes and sub - nodes to depict layering information of the UI screen . In addition to the blueprint , the UI layout tree helps in communicating UI design information to designers and developers . 4 USAGE SCENARIO Emma is a UX designer at Nerd - Chef software house . Usually , when she starts designing UI screens , she looks around for 1 https : / / blu . blackbox - toolkit . com / design inspiration . The only problem was once she found something she liked , she still had to design the UI from scratch . Most of the time , she had to do hit and trial to guess the design layers . However , now Emma uses Blu to solve this problem . She uploads any UI screen she likes , and Blu detects the constituent UI elements of that screen . Further , Blu provides the underlying layout information of the UI screen . Emma can also view the hierarchy of UI layers . This helps Emma in understanding the details of the UI design . To Emma’s delight , she can also download the editable SVG of the uploaded UI screen . Now Emma utilizes Blu to create aesthetically pleasing UI designs faster and easier . 5 CONCLUSION & FUTURE WORK We proposed Blu , a UI layout detector that utilizes DNN based object detection model trained using the RICO dataset to identify UI elements , their locations , dimensions , and text content . It uses this information and generates the UI lay - out tree based on Gestalt laws . As a result , Blu provides an editable vector graphic blueprint and a UI layout tree for each UI screen . This UI layout information can support de - signers to explore the design details of a UI screen and to communicate these details with developers . In this paper , we introduced a proof - of - concept system that utilizes the annotations from the RICO dataset to mimic the behavior of our proposed system without object detection . In the future , we aim to further the implementation of Blu based on the proposed concept and evaluate its accuracy , precision , and recall . We also plan to generate front - end code . REFERENCES [ 1 ] Biplab Deka , Zifeng Huang , Chad Franzen , Joshua Hibschman , Daniel Afergan , Yang Li , Jeffrey Nichols , and Ranjitha Kumar . 2017 . Rico : A mobile app dataset for building data - driven design applications . In Pro - ceedings of the 30th Annual ACM Symposium on User Interface Software and Technology . ACM , 845 – 854 . [ 2 ] Scarlett R Herring , Chia Chen Chang , Jesse Krantzler , and Brian P Bailey . 2009 . Getting inspired ! Understanding how and why examples are used increativedesignpractice . In ConferenceonHumanFactorsinComputing Systems - Proceedings . 87 – 96 . https : / / doi . org / 10 . 1145 / 1518701 . 1518717 [ 3 ] Sarah Suleri , Nilda Kipi , Linh Chi Tran , and Matthias Jarke . 2019 . UI Design Pattern - driven Rapid Prototyping for Agile Development of Mobile Applications ( MobileHCI ’19 ) . ACM , New York , NY , USA , Article 52 , 6 pages . https : / / doi . org / 10 . 1145 / 3338286 . 3344399 [ 4 ] Sarah Suleri , Vinoth Pandian Sermuga Pandian , Svetlana Shishkovets , and Matthias Jarke . 2019 . Eve : A Sketch - based Software Prototyping Workbench ( CHI EA ’19 ) . ACM , New York , NY , USA , Article LBW1410 , 6 pages . https : / / doi . org / 10 . 1145 / 3290607 . 3312994 [ 5 ] Amanda Swearngin , Mira Dontcheva , Wilmot Li , Joel Brandt , Morgan Dixon , Andrew J Ko , Adobe Research , and Paul G Allen School . 2018 . Rewire : Interface Design Assistance from Examples . ( 2018 ) . https : / / doi . org / 10 . 1145 / 3173574 . 3174078 82