Statistics textbooks in the social , behavioral , and biomed - ical sciences typically stress the importance of power analy - ses . By definition , the power of a statistical test is the prob - ability that its null hypothesis ( H 0 ) will be rejected given that it is in fact false . Obviously , significance tests that lack sta - tistical power are of limited use because they cannot reliably discriminate between H 0 and the alternative hypothesis ( H 1 ) of interest . However , although power analyses are indispens - able for rational statistical decisions , it was not until the late 1980s that power charts ( see , e . g . , Scheffé , 1959 ) and power tables ( see , e . g . , Cohen , 1988 ) were supplemented by more efficient , precise , and easy - to - use power analysis programs for personal computers ( Goldstein , 1989 ) . G * Power 2 ( Erd - felder , Faul , & Buchner , 1996 ) can be seen as a second - generation power analysis program designed as a stand - alone application to handle several types of statistical tests commonly used in social and behavioral research . In the past 10 years , this program has been found useful not only in the social and behavioral sciences but also in many other disci - plines that routinely apply statistical tests , including biology ( Baeza & Stotz , 2003 ) , genetics ( Akkad et al . , 2006 ) , ecol - ogy ( Sheppard , 1999 ) , forest and wildlife research ( Mellina , Hinch , Donaldson , & Pearson , 2005 ) , the geosciences ( Bus - bey , 1999 ) , pharmacology ( Quednow et al . , 2004 ) , and med - ical research ( Gleissner , Clusmann , Sassen , Elger , & Helm - staedter , 2006 ) . G * Power 2 was evaluated positively in the reviews of which we are aware ( Kornbrot , 1997 ; Ortseifen , Bruckner , Burke , & Kieser , 1997 ; Thomas & Krebs , 1997 ) . It has been used in several power tutorials ( e . g . , Buchner , Erdfelder , & Faul , 1996 , 1997 ; Erdfelder , Buchner , Faul , & Brandt , 2004 ; Levin , 1997 ; Sheppard , 1999 ) and in statis - tics textbooks ( e . g . , Field , 2005 ; Keppel & Wickens , 2004 ; Myers & Well , 2003 ; Rasch , Friese , Hofmann , & Naumann , 2006a , 2006b ) . Nevertheless , the user feedback that we re - ceived coincided with our own experience in showing some limitations and weaknesses of G * Power 2 that required a major extension and revision . In the present article , we describe G * Power 3 , a program that was designed to address the problems of G * Power 2 . We begin with an outline of the major improvements in G * Power 3 and then discuss the types of power analyses cov - ered by this program . Next , we describe program handling and the types of statistical tests to which it can be applied . We then discuss the statistical algorithms of G * Power 3 and their accuracy . Finally , program availability and some Inter - net resources supporting users of G * Power 3 are described . Improvements In G * power 3 In ComparIson wIth G * power 2 G * Power 3 is an improvement over G * Power 2 in five major respects . First , whereas G * Power 2 requires the 175 Copyright 2007 Psychonomic Society , Inc . G * power 3 : a flexible statistical power analysis program for the social , behavioral , and biomedical sciences F ranz F aul Christian - Albrechts - Universität Kiel , Kiel , Germany E dgar E rdFEldEr Universität Mannheim , Mannheim , Germany and a lbErt - g Eorg l ang and a xEl b uchnEr Heinrich - Heine - Universität Düsseldorf , Düsseldorf , Germany G * Power ( Erdfelder , Faul , & Buchner , 1996 ) was designed as a general stand - alone power analysis program for statistical tests commonly used in social and behavioral research . G * Power 3 is a major extension of , and improvement over , the previous versions . It runs on widely used computer platforms ( i . e . , Windows XP , Win - dows Vista , and Mac OS X 10 . 4 ) and covers many different statistical tests of the t , F , and c 2 test families . In addition , it includes power analyses for z tests and some exact tests . G * Power 3 provides improved effect size calculators and graphic options , supports both distribution - based and design - based input modes , and offers all types of power analyses in which users might be interested . Like its predecessors , G * Power 3 is free . Behavior Research Methods 2007 , 39 ( 2 ) , 175 - 191 e . erdfelder , erdfelder @ psychologie . uni - mannheim . de 176 F aul , E rdFEldEr , l ang , and B uchnEr DOS and Mac OS 7 – 9 operating systems that were com - mon in the 1990s but are now outdated , G * Power 3 runs on the personal computer platforms currently in widest use : Windows XP , Windows Vista , and Mac OS X 10 . 4 . The Windows and Mac versions of the program are es - sentially equivalent . They use the same computational routines and share very similar user interfaces . For this reason , we will not differentiate between these versions in what follows ; users simply have to make sure to download the version appropriate for their operating system . Second , whereas G * Power 2 is limited to three types of power analyses , G * Power 3 supports five different ways to assess statistical power . In addition to the a pri - ori , post hoc , and compromise power analyses that were already covered by G * Power 2 , the new program offers sensitivity analyses and criterion analyses . Third , G * Power 3 provides dedicated power analysis options for a variety of frequently used t , F , z , c 2 , and exact tests in addition to the standard tests covered by G * Power 2 . The tests captured by G * Power 3 and their effect size parameters are described in the Program Han - dling section . Importantly , users are not limited to these tests because G * Power 3 also offers power analyses for generic t , F , z , c 2 , and binomial tests for which the non - centrality parameter of the distribution under H 1 may be entered directly . In this way , users are provided with a flexible tool for computing the power of basically any statistical test that uses t , F , z , c 2 , or binomial reference distributions . Fourth , statistical tests can be specified in G * Power 3 using two different approaches : the distribution - based ap - proach and the design - based approach . In the distribution - based approach , users select the family of the test statistic ( t , F , z , c 2 , or exact test ) and the particular test within that family . This is how power analyses were specified in G * Power 2 . In addition , a separate menu in G * Power 3 provides access to power analyses via the design - based approach : Users select ( 1 ) the parameter class to which the statistical test refers ( correlations , means , proportions , regression coefficients , variances ) and ( 2 ) the design of the study ( e . g . , number of groups , independent vs . depen - dent samples ) . On the basis of the feedback we received about G * Power 2 , we expect that some users might find the design - based input mode more intuitive and easier to use . Fifth , G * Power 3 supports users with enhanced graph - ics features . The details of these features will be outlined in the Program Handling section . types of statIstICal power analyses The power ( 1 2 b ) of a statistical test is the complement of b , which denotes the Type II or beta error probability of falsely retaining an incorrect H 0 . Statistical power de - pends on three classes of parameters : ( 1 ) the significance level ( i . e . , the Type I error probability ) a of the test , ( 2 ) the size ( s ) of the sample ( s ) used for the test , and ( 3 ) an effect size parameter defining H 1 and thus indexing the degree of deviation from H 0 in the underlying population . De - pending on the available resources , the actual phase of the research process , and the specific research question , five different types of power analysis can be reasonable ( cf . Erdfelder et al . , 2004 ; Erdfelder , Faul , & Buchner , 2005 ) . We describe these methods and their uses in turn . a priori power analyses In a priori power analyses ( Cohen , 1988 ) , sample size N is computed as a function of the required power level ( 1 2 b ) , the prespecified significance level a , and the population effect size to be detected with probability 1 2 b . A priori analyses provide an efficient method of controlling statistical power before a study is actually con - ducted ( see , e . g . , Bredenkamp , 1969 ; Hager , 2006 ) and can be recommended whenever resources such as the time and money required for data collection are not critical . post hoc power analyses In contrast to a priori power analyses , post hoc power analyses ( Cohen , 1988 ) often make sense after a study has already been conducted . In post hoc analyses , 1 2 b is computed as a function of a , the population effect size parameter , and the sample size ( s ) used in a study . It thus becomes possible to assess whether or not a published statistical test in fact had a fair chance of rejecting an in - correct H 0 . Importantly , post hoc analyses , like a priori analyses , require an H 1 effect size specification for the underlying population . Post hoc power analyses should not be confused with so - called retrospective power anal - yses , in which the effect size is estimated from sample data and used to calculate the observed power , a sample estimate of the true power . 1 Retrospective power analy - ses are based on the highly questionable assumption that the sample effect size is essentially identical to the effect size in the population from which it was drawn ( Zumbo & Hubley , 1998 ) . Obviously , this assumption is likely to be false , and the more so the smaller the sample . In addition , sample effect sizes are typically biased estimates of their population counterparts ( Richardson , 1996 ) . For these reasons , we agree with other critics of retrospective power analyses ( e . g . , Gerard , Smith , & Weerakkody , 1998 ; Hoe - nig & Heisey , 2001 ; Kromrey & Hogarty , 2000 ; Lenth , 2001 ; Steidl , Hayes , & Schauber , 1997 ) . Rather than use retrospective power analyses , researchers should specify population effect sizes on a priori grounds . To specify the effect size simply means to define the minimum degree of violation of H 0 a researcher would like to detect with a probability not less than 1 2 b . Cohen’s definitions of small , medium , and large effects can be helpful in such effect size specifications ( see , e . g . , Smith & Bayen , 2005 ) . However , researchers should be aware of the fact that these conventions may have different meanings for differ - ent tests ( cf . Erdfelder et al . , 2005 ) . Compromise power analyses In compromise power analyses ( Erdfelder , 1984 ; Erdfelder et al . , 1996 ; Müller , Manz , & Hoyer , 2002 ) , both a and 1 2 b are computed as functions of the ef - fect size , N , and the error probability ratio q 5 b / a . To illustrate , setting q to 1 would mean that the researcher prefers balanced Type I and Type II error risks ( a 5 b ) , g * P owEr 3 177 whereas a q of 4 would imply that b 5 4 a ( cf . Cohen , 1988 ) . Compromise power analyses can be useful both before and after data collection . For example , an a priori power analysis might result in a sample size that exceeds the available resources . In such a situation , a researcher could specify the maximum affordable sample size and , using a compromise power analysis , compute a and 1 2 b associated with , say , q 5 b / a 5 4 . Alternatively , if a study has already been conducted but has not yet been analyzed , a researcher could ask for a reasonable decision criterion that guarantees perfectly balanced error risks ( i . e . , a 5 b ) given the size of the sample and the critical effect size in which he or she is interested . Of course , compromise power analyses can easily result in unconventional sig - nificance levels greater than a 5 . 05 ( in the case of small samples or effect sizes ) or less than a 5 . 001 ( in the case of large samples or effect sizes ) . However , we believe that the benefit of balanced Type I and Type II error risks often offsets the costs of violating significance level conven - tions ( cf . Gigerenzer , Krauss , & Vitouch , 2004 ) . sensitivity analyses In sensitivity analyses , the critical population effect size is computed as a function of a , 1 2 b , and N . Sensitivity analyses may be particularly useful for evaluating pub - lished research . They provide answers to questions such as “What effect size was a study able to detect with a power of 1 2 b 5 . 80 given its sample size and a as specified by the author ? In other words , what is the minimum ef - fect size to which the test was sufficiently sensitive ? ” In addition , it may be useful to perform sensitivity analyses before conducting a study to see whether , given a lim - ited N , the size of the effect that can be detected is at all realistic ( or , for instance , much too large to be expected realistically ) . Criterion analyses Finally , criterion analyses compute a ( and the associ - ated decision criterion ) as a function of 1 2 b , the effect size , and a given sample size . Criterion analyses are alter - natives to post hoc power analyses . They may be reason - able whenever the control of a is less important than the control of b . In case of goodness - of - fit tests for statistical models , for example , it is most important to minimize the b risk of wrong decisions in favor of the model ( H 0 ) . Re - searchers could thus use criterion analyses to compute the significance level a which is compatible with b 5 . 05 for a small effect size . Whereas G * Power 2 was limited to the first three types of power analysis , G * Power 3 covers all five types . On the basis of the feedback we received from G * Power 2 users , we believe that any question related to statistical power that arises in research practice can be categorized under one of these analysis types . proGram handlInG Using G * Power 3 typically involves the following four steps : ( 1 ) Select the statistical test appropriate for the problem , ( 2 ) choose one of the five types of power analyses defined in the previous section , ( 3 ) provide the input parameters required for the analysis , and ( 4 ) click on “Calculate” to obtain the results . In the first step , the statistical test is chosen using the distribution - based or the design - based approach . G * Power 2 users probably have adapted to the distribution - based approach : One first selects the family of the test statistic ( t , F , z , c 2 , or exact test ) using the “Test fam - ily” menu in the main window . The “Statistical test” menu adapts accordingly , showing a list of all tests available for the test family . For the two - groups t test , for example , one would first select the t family of distributions and then “Means : Difference between two independent means ( two groups ) ” in the “Statistical test” menu ( see Figure 1 ) . Al - ternatively , one might use the design - based approach of test selection . With the “Tests” pull - down menu in the top row , it is possible to select ( 1 ) the parameter class to which the statistical test refers ( i . e . , correlation and regression , means , proportions , variances , or generic ) and ( 2 ) the de - sign of the study ( e . g . , number of groups , independent vs . dependent samples ) . For example , a researcher would select “Means” followed by “Two independent groups” to specify the two - groups t test ( see Figure 2 ) . The design - based approach has the advantage that test options refer - ring to the same parameter class ( e . g . , means ) are located in close proximity , whereas in the distribution - based ap - proach they may be scattered across different distribution families . In the second step , the “Type of power analysis” menu in the center of the main window should be used to choose the appropriate analysis type . In the third step , the power analysis input parameters are specified in the lower left of the main window . To illustrate , an a priori power analysis for a two - groups t test would require a decision between a one - tailed and a two - tailed test , a specification of Cohen’s ( 1988 ) effect size measure ( d ) under H 1 , the significance level a , the required power ( 1 2 b ) of the test , and the preferred group size allocation ratio n 2 / n 1 . The final step consists of clicking on “Calculate” to obtain the output in the lower right of the main window . For instance , input parameters specifying a one - tailed t test , a medium effect size of d 5 0 . 5 , a 5 . 05 , 1 2 b 5 . 95 , and an allocation ratio of n 2 / n 1 5 1 would result in a total sample size of N 5 176 ( 88 observation units in each group ; see Figures 1 and 2 ) . The noncentrality pa - rameter d defining the t distribution under H 1 , the decision criterion to be used ( i . e . , the critical value of the t statis - tic ) , the degrees of freedom 2 of the t test , and the actual power value are also displayed . Note that the actual power will often be slightly larger than the prespecified power in a priori power analyses . The reason is that noninteger sample sizes are always rounded up by G * Power to obtain integer values consistent with a power level not lower than the prespecified one . In addition to the numerical output , G * Power 3 dis - plays the central ( H 0 ) and the noncentral ( H 1 ) test statistic distributions along with the decision criterion and the as - sociated error probabilities in the upper part of the main window ( see Figure 1 ) . 3 This supports understanding of the effects of the input parameters and is likely to be a 178 F aul , E rdFEldEr , l ang , and B uchnEr useful visualization tool in the teaching of , or the learning about , inferential statistics . The distributions plot can be printed , saved , or copied by clicking on the right mouse button inside the plot area . The input and output of each power calculation in a G * Power session is automatically written to a protocol that can be displayed by selecting the “Protocol of power analyses” tab in the main window . It is possible to clear the protocol or to print , save , and copy the protocol in the same way as the distributions plot . Because Cohen’s ( 1988 ) book on power analysis appears to be well - known in the social and behavioral sciences , we made use of his effect size measures whenever possible . Researchers unfamiliar with these measures and users who prefer to compute Cohen’s measures from more basic parameters can click on the “Determine” button to the left of the “Effect size” input field ( see Figures 1 and 2 ) . A drawer will open next to the main window and provide access to an effect size calculator tailored to the selected test ( see Figure 2 ) . For the two - groups t test , for example , users can specify the means ( m 1 , m 2 ) and the common SD ( s ) in the populations underlying the groups to calculate Cohen’s d 5 | m 1 2 m 2 | / s . Clicking on the “Calculate and transfer to main window” button copies the computed ef - fect size to the appropriate field in the main window . Another useful option is the Power Plot window ( see Figure 3 ) , which is opened by clicking on “ X – Y plot for a range of values” on the lower right side of the main win - dow ( see Figures 1 and 2 ) . By selecting the appropriate parameters for the y - and x - axes , one parameter ( a , 1 2 b , effect size , or sample size ) can be plotted as a function of any other parameter . Of the remaining two parameters , one can be chosen to draw a fam - ily of graphs , whereas the fourth parameter is kept constant . For instance , sample size can be drawn as a function of the power 1 2 b for several different population effects sizes while a is kept at a particular value . The plot may be printed , saved , or copied by clicking on the right mouse button inside the plot area . Selecting the “Table” tab reveals the data un - derlying the plot ; they may be copied to other applications . The Power Plot window inherits all input parameters of the analysis that is active when the “ X – Y plot for a range of figure 1 . the distribution - based approach of test specification in G * power 3 . 0 . g * P owEr 3 179 figure 2 . the design - based approach of test specification in G * power 3 . 0 and the “effect size” drawer . figure 3 . the power plot window of G * power 3 . 0 . 180 F aul , E rdFEldEr , l ang , and B uchnEr values” button is clicked . Only some of these parameters can be directly manipulated in the Power Plot window . For instance , switching from a plot of a two - tailed test to a plot of a one - tailed test requires choosing the “Tail ( s ) : One” option in the main window and then clicking on the “ X – Y plot for a range of values” button . types of statIstICal tests G * Power 3 provides power analyses for test statistics following t , F , c 2 , or standard normal distributions under H 0 ( either exact or asymptotic ) and noncentral distributions of the same test families under H 1 . In addition , it includes power analyses for some exact tests . In Tables 2 – 9 , we briefly describe the tests currently covered by G * Power 3 . Table 1 lists the symbols used in Tables 2 – 9 and their meanings . tests for Correlation and regression Table 2 summarizes the procedures supported for test - ing hypotheses on correlation and regression . One - sample tests are provided for the point – biserial model—that is , the model for correlations between a binary variable and a continuous variable—and for correlations between two normally distributed variables ( Cohen , 1988 , chap . 3 ) . 4 The latter test uses the exact sample correlation coefficient distribution ( Barabesi & Greco , 2002 ) or , optionally , a large - sample approximation based on Fisher’s r - to - z trans - formation . The two - sample test for differences between two correlations uses Cohen’s ( 1988 , chap . 4 ) effect size q and is based on Fisher’s r - to - z transformation . Cohen de - fines q s of 0 . 10 , 0 . 30 , and 0 . 50 as small , medium , and large effects , respectively . The two procedures available for the multiple regres - sion model handle the cases of ( 1 ) a test of an overall effect—that is , the hypothesis that the population value of R 2 is different from zero—and ( 2 ) a test of the hypoth - esis that adding more predictors increases the value of R 2 ( Cohen , 1988 , chap . 9 ) . According to Cohen’s criteria , effect sizes ( f 2 ) of 0 . 02 , 0 . 15 , and 0 . 35 are considered small , medium , and large , respectively . tests for means ( Univariate Case ) Table 3 summarizes the power analysis procedures for tests on means . G * Power 3 supports all cases of the t test for means described by Cohen ( 1988 , chap . 2 ) : the test for independent means , the test of the null hypothesis that the population mean equals some specified value ( one sample case ) , and the test on the means of two dependent samples ( matched pairs ) . Cohen’s d and d z are used as effect size indices . Cohen defines d s of 0 . 2 , 0 . 5 , and 0 . 8 as small , medium , and large effects , respectively . Effect size dialogs are available to compute the appropriate effect size param - eter from means and SD s . For example , assume we want to compare visual search times for targets embedded in rare versus frequent local contexts in a within - subjects design ( cf . Hoffmann & Sebald , 2005 , Experiment 1 ) . It is ex - pected that the mean search time for targets in rare contexts ( e . g . , 600 msec ) should decrease by at least 10 msec ( i . e . , to 590 msec ) in frequent contexts as a consequence of local contextual cuing . If prior evidence suggests population SD s of , say , s 5 25 msec in each of the conditions and a correlation of r 5 . 70 between search times in the two con - ditions , we can use the “Effect size” drawer of G * Power 3 for the matched pairs t test to calculate the effect size d z 5 0 . 516 ( see the second row of Table 3 for the formula ) . By selecting a post hoc power analysis for one - tailed matched pairs t tests , we easily see that for d z 5 0 . 516 , a 5 . 05 , and N 5 16 participants , the power ( 1 2 b ) is only . 47 . Thus , provided that the assumptions outlined above are appropri - ate , the nonsignificant statistic [ t ( 15 ) 5 1 . 475 ] obtained by Hoffmann and Sebald ( 2005 , Experiment 1 , p . 34 ) might in fact be due to a Type II error . This interpretation would be consistent with the fact that Hoffmann and Sebald ob - table 1 symbols and their meanings as Used in the tables Symbols Meaning m ( m i ) population mean ( in group i ) m  ( m  i ) vector of population means ( in group i ) m x 2 y population mean of the difference N total sample size n i sample size in group i s standard deviation in the population s m standard deviation of the effect s x 2 y standard deviation of the difference l noncentrality parameter of the noncentral F and c 2 distribution d noncentrality parameter of the noncentral t distribution df degrees of freedom df 1 , df 2 numerator and denominator degrees of freedom , respectively r ( r i ) population correlation ( in group i ) R 2 Y ⋅ A , R 2 Y ⋅ A , B squared multiple correlation coefficients , corresponding to the proportion of Y variance that can be accounted for by multiple regression on the set of predictor variables A and A ∪ B , respectively S population variance – covariance matrix m matrix of regression parameters ( population means ) C contrast matrix ( contrasts between rows of m ) a contrast matrix ( contrasts between columns of m ) p ( p i ) probability of success ( in group i ) g * P owEr 3 181 served significant local contextual cuing effects in each of the other four experiments they reported . The procedures provided by G * Power 3 to test effects in between - subjects designs with more than two groups ( i . e . , one - way ANOVA designs and general main effects and interactions in factorial ANOVA designs of any order ) are identical to those in G * Power 2 ( Erdfelder et al . , 1996 ) . In all these cases , the effect size f as defined by Cohen ( 1988 ) is used . In a one - way ANOVA , the “Effect size” drawer can be used to compute f from the means and group sizes of k groups and an SD common to all groups . For tests of effects in factorial designs , the “Effect size” drawer offers the possibility of computing effect size f from the vari - ance explained by the tested effect and the error variance . Cohen defines f s of 0 . 1 , 0 . 25 , and 0 . 4 as small , medium , and large effects , respectively . New in G * Power 3 are procedures for analyzing main effects and interactions for A 3 B mixed designs , where A is a between - subjects factor ( or an enumeration of the groups generated by cross - classification of several between - subjects factors ) and B is a within - subjects fac - tor ( or an enumeration of the repeated measures generated by cross - classification of several within - subjects factors ) . Both the univariate and the multivariate approaches to re - peated measures ( O’Brien & Kaiser , 1985 ) are supported . The multivariate approach will be discussed below . The univariate approach is based on the sphericity assump - tion . This assumption is correct if ( in the population ) all variances of the repeated measurements are equal and all correlations between pairs of repeated measurements are equal . If all the distributional assumptions are met , then the univariate approach is the most powerful method ( Muller & Barton , 1989 ; O’Brien & Kaiser , 1985 ) . Unfortunately , the assumption of equal correlations is violated quite often , which can lead to very misleading results . In order to compensate for such adverse effects in tests of within effects or between – within interactions , the noncentrality parameter and the degrees of freedom of the F distribu - tion can be multiplied by a correction factor e ( Geisser & Greenhouse , 1958 ; Huynh & Feldt , 1970 ) . e 5 1 if the sphericity assumption is met and approaches 1 / ( m 2 1 ) with increasing degrees of violation of sphericity , where m denotes the number of repeated measurements . G * Power provides three separate yet very similar rou - tines to calculate power in the univariate approach for between effects , within effects , and interactions . If the to - be - detected effect size f is known , these procedures are very easy to apply . To illustrate , Berti , Münzer , Schröger , and Pechmann ( 2006 ) compared the pitch discrimination ability of 10 musicians and 10 control subjects ( between - subjects factor A ) for 10 different interference conditions ( within - subjects factor B ) . Assuming that A , B , and A 3 B effects of medium size ( f 5 0 . 25 ; see Cohen , 1988 ; Table 3 of the present article ) should be detected given a correlation of r 5 . 50 between repeated measures and a significance level of a 5 . 05 , the power values of the F tests for the A main effect , the B main effect , and the A 3 B interaction are easily computed as . 30 , . 95 , and . 95 , re - spectively , by inserting f 5 0 . 25 , a 5 . 05 , the total sample size ( 20 ) , the number of groups ( 2 ) , the number of repeti - tions ( 10 ) , and r 5 . 50 into the appropriate input fields of the procedures designed for these tests . If the to - be - detected effect size f is unknown , it must be computed from more basic parameters characterizing the expected population scenario under H 1 . To demonstrate the general procedure , we will show how to do post hoc power analyses in the scenario illustrated in Figure 4 as - suming the variance and correlations structure defined in matrix sr 1 . We first consider the power of the within effect : We select the “ F tests” family , the “Repeated mea - table 2 tests for Correlation and regression Test Null Noncentrality Parameter Test Family Hypothesis Effect Size Other Parameters and Degrees of Freedom Difference from t tests r 5 0 r δ ρ ρ = − ⋅ 2 2 1 N zero : point biserial model df 5 N 2 2 Difference from constant ( bivariate normal ) exact tests r 5 c r Constant correlation c Inequality of two correlationcoefficients z tests r 1 5 r 2 q 5 z 1 2 z 2 z i i i = + − 12 1 1 ln ρ ρ m q s 1 = s n n n n = + − − ( ) − ( ) 1 2 1 2 6 3 3 Multiple regression : deviation of R 2 from zero F tests R 2 Y ⋅ A 5 0 f R R Y A Y A 2 2 2 1 = − ⋅ ⋅ Number of predictors p ( # A ) l 5 f 2 N df 1 5 p df 2 5 N 2 p 2 1 Multiple regression : increase of R 2 F tests R 2 Y ⋅ A , B 5 R 2 Y ⋅ A f R R R Y AB Y A Y AB 2 2 2 2 1 = − − ⋅ ⋅ ⋅ , , Total number of predictors p ( # A 1 # B ) Number of tested l 5 f 2 N df 1 5 q df 2 5 N 2 p 2 1 predictors q ( # B ) 182 F aul , E rdFEldEr , l ang , and B uchnEr sures : Within factors , ANOVA - approach” test , and “post hoc” as the type of power analysis . Both the “Number of groups” and “Repetitions” fields are set to 3 . Total sample size is set to 90 and a error probability to . 05 . Referring to matrix sr 1 , we insert . 3 in the “Corr among rep mea - sures” input field and—since sphericity obviously holds in this case—set nonsphericity correction e to 1 . To deter - mine effect size f , we first calculate s m 2 , the variance of the table 3 tests for means ( Univariate Case ) Test Null Noncentrality Parameter Test Family Hypothesis Effect Size Other Parameters and Degrees of Freedom Difference from constant ( one - sample case ) t tests m 5 c d c = −µ σ d 5 d √ _ _ N df 5 N 2 1 Inequality of two dependent means ( matched pairs ) t tests m x 2 y 5 0 d z x y x y = − − µ σ d 5 d z √ _ _ N df 5 N 2 1 σ σ σ ρσ σ x y x y x y − = + − 2 2 2 Inequality of two independent means t tests m 1 5 m 2 d = − µ µ σ 1 2 δ = + d n n n n 1 2 1 2 df 5 N 2 2 ANOVA , fixed effects , one way : inequality of multiple means F tests m i 2 m 5 0 i 5 1 , . . . , k f = σ σ µ Number of groups k l 5 f 2 N df 1 5 k 2 1 df 2 5 N 2 k σ µ µ µ 2 2 1 = − ( ) = ∑ n N j i i k ANOVA , fixed effects , multifactordesigns , and planned comparisons F tests m i 2 m 5 0 i 5 1 , . . . , k f = σ σ µ Total number of cells in the design k Degrees of freedom of the tested effect q l 5 f 2 N df 1 5 q df 2 5 N 2 k ANOVA : repeatedmeasures , between effects F tests m i 2 m 5 0 i 5 1 , . . . , k f = σ σ µ Levels of between factor k l 5 f 2 uN e u mm = + − 1 1 ( ) ρ Levels of repeated measures factor m df 1 5 k 2 1 df 2 5 N 2 k ANOVA : repeatedmeasures , within effects F tests m i 2 m 5 0 i 5 1 , . . . , m f = σ σ µ l 5 f 2 uN u m = − 1 ρ Population correlation df 1 5 ( m 2 1 ) e among repeated measures r df 2 5 ( N 2 k ) ( m 2 1 ) e ANOVA : repeated measures , between – within interactions F tests m ij 2 m i 2 . . . m j 1 m 5 0 i 5 1 , . . . , k j 5 1 , . . . , m f = σ σ µ l 5 f 2 uN e u m = − 1 ρ For within and within – between df 1 5 ( k 2 1 ) ( m 2 1 ) e interactions : df 2 5 ( N 2 k ) ( m 2 1 ) e Nonsphericity correction e Time 1 Time 2 Time 3 m i • n i Group 1 10 15 20 15 30 Group 2 10 12 15 12 . 333 30 Group 3 10 12 12 11 . 333 30 m • j 10 13 15 . 667 m •• 5 12 . 889 sr sr 2 1 10 0 3 0 1 0 3 9 0 3 0 1 0 3 8 9 0 =       = . . . . . . . . . . . . . 3 0 3 0 3 9 0 3 0 3 0 3 9       figure 4 . sample 3 3 3 repeated measures designs . three groups are repeatedly measured at three dif - ferent times . the shaded portion of the table is the postulated matrix m of population means m ij . the last column of the table contains the sample size of each group . the symmetric matrices sr i specify two dif - ferent covariance structures between measurements taken at different times : the main diagonal contains the SD s of the measurements at each time , and the off - diagonal elements contain the correlations between pairs of measurements taken at different times . g * P owEr 3 183 within effect . From the three column means m • j of matrix m and the grand mean m •• , we get σ µ 2 = − + − + − ( 10 12 . 889 ) ( 13 12 . 889 ) ( 15 . 667 12 . 88 2 2 99 ) 5 . 35679 . 2 3 = Clicking on the “Determine” button next to the “Effect size” label opens the “Effect size” drawer . We choose the “From variances” option and set “Variance explained by special effect” to 5 . 357 and “Variance within groups” to 9 2 5 81 . Clicking on the “Calculate and transfer to main window” button calculates an effect size f 5 0 . 2572 and transfers f to the effect size field in the main window . Clicking on “Calculate” yields the results : The power is . 997 , the critical F value with df 1 5 2 and df 2 5 174 is 3 . 048 , and the noncentrality parameter l is 25 . 52 . The procedure for tests of between – within interactions ef - fects ( “Repeated measures : Within – between interac - tions , ANOVA - approach” ) is almost identical to that just described . The only difference is in how the effect size f is computed . Here , we first calculate the variance of the residual values m ij 2 m i • 2 m • j 1 m •• of matrix m : σ µ 2 2 10 10 15 12 889 12 15 667 11 33 = − − + + + − − ( . ) . . . ( . . 33 12 889 9 0 1 90123 2 + = . ) . . . Using the “Effect size” drawer in the same way as above , we get an effect size f 5 0 . 1532 , which results in a power of . 653 . To test between effects , we choose “Repeated measures : Between factors , ANOVA - approach” and set all parameters to the same values as before . Note that in this case we do not need to specify e —no correction is necessary because tests of between factors do not require the sphericity assumption . To calculate the effect size , we use “Effect size from means” in the “Effect size” drawer . We select three groups , set “ SD s within each group” to 9 , and insert for each group the cor - responding row mean m i • of m ( 15 , 12 . 3333 , 11 . 3333 ) and an equal group size of 30 . Effect size f 5 0 . 1719571 is cal - culated , and the resulting power is . 488 . Note that G * Power 3 can easily handle pure repeated measures designs without any between - subjects factors ( see , e . g . , Frings & Wentura , 2005 ; Schwarz & Müller , 2006 ) by choosing the “Repeated measures : Within fac - tors , ANOVA - approach” procedure and setting the num - ber of groups to 1 . tests for mean vectors ( multivariate Case ) G * Power 3 contains several procedures for performing power analyses in multivariate designs ( see Table 4 ) . All these tests belong to the F test family . The Hotelling T 2 tests are extensions of univariate t tests to the multivariate case , in which more than one dependent variable is measured : Instead of two single means , two mean vectors are compared , and instead of a single variance , a variance – covariance matrix is consid - ered ( Rencher , 1998 ) . In the one - sample case , H 0 posits that the vector of population means is identical to a speci - fied constant mean vector . The “Effect size” drawer can be used to calculate the effect size D from the difference m  2 c  and the expected variance – covariance matrix under H 1 . For example , assume that we have two variables , a difference vector m  2 c  5 ( 1 . 88 , 1 . 88 ) under H 1 , vari - ances s 12 5 56 . 79 , s 22 5 29 . 28 , and a covariance of 11 . 98 ( Rencher , 1998 , p . 106 ) . To perform a post hoc power analysis , choose “ F tests , ” then “Multivariate : Hotelling T 2 , one group” and set the analysis type to “Post hoc . ” Enter 2 in the “Response variables” field and then click on the “Determine” button next to the “Effect size” label . In the “Effect size” drawer , at “Input method : Means and . . . , ” choose “Variance – covariance matrix” and click on “Specify / edit input values . ” Under the “Means” tab , insert 1 . 88 in both input fields ; under the “Cov sigma” tab , in - sert 56 . 79 and 29 . 28 in the main diagonal and 11 . 98 as the off - diagonal element in the lower left cell . Clicking on the “Calculate and transfer to main window” button initiates the calculation of the effect size ( 0 . 380 ) and transfers it to the main window . For this effect size , a 5 . 05 , and a total sample size of N 5 100 , the power amounts to . 9282 . The procedure in the two - group case is exactly the same , with the following exceptions . First , in the “Effect size” drawer two mean vectors have to be specified . Second , the group sizes may differ . The MANOVA tests in G * Power 3 refer to the multi - variate general linear model ( O’Brien & Muller , 1993 ; O’Brien & Shieh , 1999 ) : y 5 XB 1 e , where y is N 3 p of rank p , X is N 3 r of rank r , and the r 3 p matrix B contains fixed coefficients . The rows of e are taken to be independent p - variate normal random vectors with mean 0 and p 3 p positive definite covariance matrix S . The multivariate general linear hypothesis is H 0 : CBa 5 Q 0 , where C is c 3 r with full row rank and a is p 3 a with full column rank ( in G * Power 3 , Q 0 is assumed to be zero ) . H 0 has df 1 5 a ⋅ c degrees of freedom . All tests of the hypothesis H 0 refer to the matrices h CBU C X wX C CBU h = − ( ) ( )     − ( ) = − − N N T T T ΘΘ ΘΘ 0 1 1 0 * and E U U = − ( ) T N r ΣΣ , where ¨X is a q 3 q essence model matrix , w is a q 3 q di - agonal matrix containing weights w j 5 n j / N , and X T X 5 N ( ¨X T w ¨X ) ( see O’Brien & Shieh , 1999 , p . 14 ) . Let { f 1 * , . . . , f s * } be the s 5 min ( a , c ) eigenvalues of e 2 1 h * and { f 1 , . . . , f s } the s eigenvalues of e 2 1 h / ( N 2 r ) —that is , f i 5 f i * N / ( N 2 r ) . G * Power 3 offers power analyses for the multivariate model following either the approach outlined in Muller and Peterson ( 1984 ; Muller , LaVange , Landesman - Ramey , & Ramey , 1992 ) or , alternatively , the approach of O’Brien and Shieh ( 1999 ; Shieh , 2003 ) . Both approaches approximate the exact distributions of Wilks’s U ( Rao , 1951 ) , the Hotelling – Lawley T 1 ( Pillai & Samson , 1959 ) , the Hotelling – Lawley 184 F aul , E rdFEldEr , l ang , and B uchnEr T 2 ( McKeon , 1974 ) , and Pillai’s V ( Pillai & Mijares , 1959 ) by F distributions and are asymptotically equivalent . Table 5 outlines details of both approximations . The type of statistic ( U , T 1 , T 2 , V ) and the approach ( Muller & Peterson , 1984 , or O’Brien & Shieh , 1999 ) can be selected in an Options dialog that can be evoked by clicking on the “Options” but - ton at the bottom of the main window . The approach of Muller and Peterson ( 1984 ) has found widespread use ; for instance , it has been adopted in the SPSS software package . We nevertheless recommend the approach of O’Brien and Shieh ( 1999 ) because it has a number of advantages : ( 1 ) Unlike the method of Muller and Peterson , it provides the exact noncentral F distri - bution whenever the hypothesis involves at most s 5 1 positive eigenvalues ; ( 2 ) its approximations for s . 1 eigenvalues are almost always more accurate than those of Muller and Peterson’s method ( which systematically underestimates power ) ; and ( 3 ) it provides a simpler form of the noncentrality parameter—that is , l 5 l * N , where l * is not a function of the total sample size . G * Power 3 provides procedures to calculate the power for global effects in a one - way MANOVA and for special effects and interactions in factorial MANOVA designs . These procedures are the direct multivariate analogues of the ANOVA routines described above . Table 5 sum - marizes information that is needed in addition to the formulas given above to calculate effect size f from hy - pothesized values for mean matrix m ( corresponding to matrix B in the model ) , covariance matrix S , and contrast matrix C , which describes the effect under scrutiny . The “Effect size” drawer can be used to calculate f from known values of the statistic U , T 1 , T 2 , or V . Note , however , that the transformation of T 2 to f depends on the sample size . Thus , this test statistic seems not very well suited for a priori analyses . In line with Bredenkamp and Erdfelder ( 1985 ) , we recommend V as the multivariate test statistic . Another group of procedures in G * Power 3 supports the multivariate approach to power analyses of repeated measures designs . G * Power provides separate but very similar routines for the analysis of between effects , within effects , and interactions in simple A 3 B designs , where A is a between - subjects factor and B a within - subjects factor . To illustrate the general procedure , we describe in some detail a post hoc analysis of the within effect for table 4 tests for mean vectors ( multivariate Case ) Test Null Noncentrality Parameter Test Family Hypothesis Effect Size Other Parameters and Degrees of Freedom Hotelling T 2 : F tests m  5 c  D 5 √ _ _ _ _ _ _ _ v  T S 2 1 v  Number of l 5 D 2 N difference from v 5 m  2 c  response df 1 5 k constant mean variables k df 2 5 N 2 k vector Hotelling T 2 : difference between two mean vectors F tests m  1 5 m  2 D 5 √ _ _ _ _ _ _ _ v  T S 2 1 v  v 5 m  1 2 m  2 Number of response variables k λ = + ∆ 2 1 2 1 2 n n n n df 1 5 k df 2 5 N 2 k 2 1 MANOVA : global effects F tests Cm 5 0 Means matrix m Contrast matrix C Effect size f mult depends on the test statistics : • Wilks’s U • Hotelling – • Lawley T 1 • Hotelling – • Lawley T 2 • Pillai’s V and algorithms : • Muller & • Peterson • ( 1984 ) • O’Brien & • Shieh • ( 1999 ) Number of groups g Number of response variables k Noncentrality parameter and degrees of freedom depend on the test statistic and algorithm used ( see Effect Size column and Table 5 ) . MANOVA : special effects F tests Number of groups g Number of predictors p Number of response variables k MANOVA : repeated measures , between effects F tests Cma 5 0 Means matrix m Between contrast matrix C Within contrast matrix a Levels of between factor k Levels of repeated measures factor m MANOVA : repeated measures , within effects F tests MANOVA : repeated measures , between – within interactions F tests g * P owEr 3 185 the scenario illustrated in Figure 4 , assuming the variance and correlations structure defined in matrix sr 2 . We first choose “ F tests , ” then “Repeated measures : Within factors , MANOVA - approach . ” In the “Type of power analysis” menu , we choose “Post hoc . ” We click on the “Options” button to open a dialog in which we deselect the “Use mean correlation in effect size calculation” option . We choose Pillai’s V statistic and the O’Brien and Shieh algorithm . Back at the main window , we set both number of groups and repetitions to 3 , total sample size to 90 , and a error probability to . 05 . To compute the effect size f ( V ) for the Pillai statistic , we open the “Effect size” drawer by clicking on the “Determine” button next to the “Effect size” label . In the “Effect size” drawer , select , as procedure , “Effect size from mean and variance – covariance matrix” and , as input method , “ SD and correlation matrix . ” Clicking on “Specify / edit matrices” opens another window , in which we specify the hypothesized parameters . Under the “Means” tab , we insert our means matrix m ; under the “Cov sigma” tab , we choose “ SD and correlation” and insert the values of sr 2 . Because this matrix is always symmetric , it suf - fices to specify the lower diagonal values . After closing the dialog and clicking on “Calculate and transfer to main window , ” we get a value of 0 . 1791 for Pillai’s V and the effect size f ( V ) 5 0 . 4672 . Clicking on “Calculate” shows that the power is . 980 . The analyses of between effects and interaction effects are performed analogously . tests for proportions The support for tests on proportions has been greatly enhanced in G * Power 3 . Table 6 summarizes the tests that are currently implemented . In particular , all tests on pro - portions considered by Cohen ( 1988 ) are now available , including the sign test ( chap . 5 ) , the z tests for the differ - ence between two proportions ( chap . 6 ) , and the c 2 tests for goodness - of - fit and contingency tables ( chap . 7 ) . The sign test is implemented as a special case ( c 5 . 5 ) of the more general binomial test ( also available in G * Power 3 ) that a single proportion has a specified value c . In both procedures , Cohen’s ( 1988 ) effect size g is used and exact power values based on the binomial distribution are cal - culated . Note , however , that , due to the discrete nature of the binomial distribution , the nominal value of a usually cannot be realized . Since the tables in chapter 5 of Cohen’s book use the a value closest to the nominal value , even if it is higher than the nominal value , the tabulated power values table 5 approximating Univariate statistics for multivariate hypotheses Effect Size and Statistic Formula Numerator df 2 Noncentrality Parameter Wilks’s U MP U k k s = + ( ) − = ∏ 1 1 1 φ df 2 5 g ( N 2 g 1 ) 2 g 2 g r a c 1 1 2 = + − + g ca 2 2 2 = − g ca ca c a ca = ≤ − + − ≤    1 3 4 5 4 2 2 2 ( ) f U U U g g ( ) / / 2 1 1 1 = − l 5 f ( U ) 2 df 2 Wilks’s U OS U k k s = + ( ) − = ∏ 1 1 1 φ * f U U U g g ( ) / / 2 1 1 1 = − l 5 Ng f ( U ) 2 Pillai’s V MP V k k k s = + ( ) = ∏ φ φ / 1 1 df 2 5 s ( N 2 r 2 a 1 s ) f V V s V ( ) ( ) 2 = − l 5 f ( V ) 2 df 2 Pillai’s V OS V k k k s = + ( ) = ∏ φ φ * * / 1 1 f V V s V ( ) ( ) 2 = − l 5 Ns f ( V ) 2 Hotelling – Lawley T 1 MP T k k s = = ∏ φ 1 df 2 5 s ( N 2 r 2 a 2 1 ) 1 2 f ( T ) 2 5 T / s l 5 f ( T ) 2 df 2 Hotelling – Lawley T 1 OS T k k s = = ∏ φ * 1 f ( T ) 2 5 T / s l 5 Ns f ( T ) 2 Hotelling – Lawley T 2 MP T k k s = = ∏ φ 1 df 2 5 4 1 ( ca 1 2 ) g g N r N r g g N r g g = − − − + − − ( ) ( ) ( ) 2 4 3 2 1 g 1 5 c 1 2 a 1 a 2 2 1 g 2 5 c 1 a 1 1 g 3 5 a ( a 1 3 ) g 4 5 2 a 1 3 h df N r a = − − − − 2 2 1 f ( T ) 2 5 T / h l 5 f ( T ) 2 df 2 Hotelling – Lawley T 2 OS T k k s = = ∏ φ * 1 f ( T ) 2 5 T / h l 5 Nh f ( T ) 2 Note—MP , Muller – Peterson algorithm ; OS , O’Brien and Shieh algorithm . f and f * are eigenvalues of the effect size matrix ( for details and the meaning of the variables a , c , r , and N , see text on p . 183 ) . 186 F aul , E rdFEldEr , l ang , and B uchnEr are sometimes larger than those calculated by G * Power 3 . G * Power 3 always requires the actual a not to be larger than the nominal value . Numerous procedures have been proposed to test the null hypothesis that two independent proportions are iden - tical ( Cohen , 1988 ; D’Agostino , Chase , & Belanger , 1988 ; Suissa & Shuster , 1985 ; Upton , 1982 ) , and G * Power 3 implements several of them . The simplest procedure is a z test with optional arcsin transformation and optional conti - nuity correction . Besides these two computational options , one can also choose whether Cohen’s effect size measure h or , alternatively , two proportions are used to specify the alternate hypothesis . With the options “Use continuity cor - rection” off and “Use arcsin transform” on , the procedure calculates power values close to those tabulated by Cohen ( 1988 , chap . 6 ) . With both “Use continuity correction” and “Use arcsin transform” off , the uncorrected c 2 approxima - tion is computed ( Fleiss , 1981 ) ; with “Use continuity cor - rection” on and “Use arcsin transform” off , the corrected c 2 approximation is computed ( Fleiss , 1981 ) . A second variant is Fisher’s exact conditional test ( Hase - man , 1978 ) . Normally , G * Power 3 calculates the exact unconditional power . However , despite the highly opti - mized algorithm used in G * Power 3 , long computation times may result for large sample sizes ( e . g . , N . 1 , 000 ) . Therefore , a limiting N can be specified in the Options dialog that determines at which sample size G * Power 3 switches to a large sample approximation . A third variant calculates the exact unconditional power for approximate test statistics T ( Table 7 summarizes the supported statistics ) . The logic underlying this procedure is to enumerate all possible outcomes for the 2 3 2 bi - nomial table , given fixed sample sizes n 1 , n 2 in the two respective groups . This is done by choosing , as success frequencies x 1 and x 2 in the first and the second groups , respectively , any combination of the values 0 , x 1 # n 1 and 0 , x 2 # n 2 . Given the success probabilities p 1 , p 2 in the two respective groups , the probability of observing a table X with success frequencies x 1 , x 2 is P X n x n x x n x | , π π π π 1 2 1 1 1 1 2 2 1 1 1 1 ( ) =       − ( )    −    − ( ) − π π 2 2 2 2 2 1 x n x . table 6 tests for proportions Test Noncentrality Test Family Hypothesis Effect Size Other Parameters Parameter Contingencytables and goodness of fit c 2 tests p 1 i 5 p 0 i i 5 1 , . . . , k π 0 1 1 i i k = = ∑ w i i i i k = − ( ) = ∑ π π π 1 0 2 0 1 l 5 w 2 N Difference from constant ( one - sample case ) exacttests p 5 c g 5 p 2 c constant proportion c Inequality of two dependent proportions ( McNemar ) exacttests p 12 / p 21 5 1 odds ratio 5 p 12 / p 21 proportion of discordant pairs 5 p 12 1 p 21 Sign test exacttests p 5 1 / 2 g 5 p 2 1 / 2 Inequality of two independent proportions z tests p 1 5 p 2 ( A ) alternate proportion : p 2 ( B ) h 5 f 1 2 f 2 ( A ) f i 5 2 arcsin √ _ _ p i ( A ) null proportion : p 1 Inequality of two independent proportions ( Fisher’s exact test ) exacttests p 1 5 p 2 alternate proportion : p 1 null proportion : p 2 Inequality of two independent proportions ( unconditional ) exacttests p 1 5 p 2 ( A ) alternate proportion : p 1 ( B ) difference : p 2 2 p 1 ( C ) risk ratio : p 2 / p 1 ( D ) odds ratio : π π π π 1 1 2 2 1 1 / / − ( ) − ( ) null proportion : p 2 Inequality with offset of two independent proportions ( unconditional ) exacttests p 1 5 p 2 1 c ( A ) alternate proportion : p 1 | H 1 ( B ) difference : p 2 2 p 1 | H 1 ( C ) risk ratio : p 2 / p 1 | H 1 ( D ) odds ratio : π π π π 1 1 2 2 1 1 1 1 | | / / H H − ( ) − ( ) ( A ) proportion : p 1 | H 0 ( B ) difference : p 2 2 p 1 | H 0 ( C ) risk ratio : p 2 / p 1 | H 0 ( D ) odds ratio : π π π π 1 1 2 2 0 0 1 1 | | / / H H − ( ) − ( ) ( A ) null proportion : p 2 Note— ( A ) – ( D ) indicate alternative effect size measures . g * P owEr 3 187 To calculate power and the actual Type I error a * , the test statistic T is computed for each table and compared with the critical value T a . If A denotes the set of all ta - bles X rejected by this criterion—that is , those with T . T a —then the power and the a level are given by 1 1 2 − = ( ) ∈ ∑ β π π P X X A | , and α π π * | , , = ( ) ∈ ∑ P X X A 2 2 where p 2 denotes the success probability in both groups as assumed in the null hypothesis . Note that the actual a level can be larger than the nominal level ! The preferred input method ( proportions , difference , risk ratio , or odds ratio ; see Table 6 ) and the test statistic to use ( see Table 7 ) can be changed in the Options dialog . Note that the test statistic actually used to analyze the data must be chosen . For large sample sizes , the exact computation may take too much time . Therefore , a limiting N can be specified in the Options dialog that determines at which sample size G * Power switches to large sample approximations . G * Power 3 also provides a group of procedures to test the hypothesis that the difference , risk ratio , or odds ratio of a proportion with respect to a specified reference pro - portion p is different under H 1 from a difference , risk ratio , or odds ratio of the same reference proportion assumed in H 0 . These procedures are available in the “Exact” test family as “Proportions : Inequality ( offset ) , two indepen - dent groups ( unconditional ) . ” The enumeration proce - dure described above for the tests on differences between proportions without offset is also used in this case . In the tests without offset , the different input parameters ( e . g . , differences , risk ratio ) are equivalent ways of specifying two proportions . The specific choice has no influence on the results . In the case of tests with offset , however , each input method has a different set of available test statistics . The preferred input method ( see Table 6 ) and the test sta - tistic to use ( see Table 8 ) can be changed in the Options dialog . As in the other exact procedures , the computation may be time - consuming , and a limiting N can be specified in the Options dialog that determines at which sample size G * Power switches to large sample approximations . Also new in G * Power 3 is an exact procedure to calcu - late the power for the McNemar test . The null hypothesis of this test states that the proportions of successes are identi - cal in two dependent samples . Figure 5 shows the structure of the underlying design : A binary response is sampled from the same subject or a matched pair in a standard con - dition and in a treatment condition . The null hypothesis , p s 5 p t , is formally equivalent to the hypothesis for the odd ratio : OR 5 p 12 / p 21 5 1 . To fully specify H 1 , we need to specify not only the odds ratio but also the proportion of discordant pairs ( p D ) —that is , the expected proportion of responses that differ in the standard and the treatment conditions . The exact procedure used in G * Power 3 calcu - lates the unconditional power for the exact conditional test , which calculates the power conditional on the number of discordant pairs ( n D ) . Let p ( n D 5 i ) be the probability that the number of discordant pairs is i . Then , the unconditional power is the sum over all i ∈ { 0 , . . . , N } of the conditional power for n D 5 i weighted with p ( n D 5 i ) . This procedure is very efficient , but for very large sample sizes the exact computation may take too much time . Again , a limiting N that determines at which sample size G * Power switches to a large sample approximation can be specified in the Op - tions dialog . The large sample approximation calculates table 7 test statistics Used in tests of the difference Between two Independent proportions No . Name Statistic 1 z test pooled variance z n n n = − = − ( ) +     = ˆ ˆ ˆ ; ˆ ˆ ˆ ; ˆ ˆ π π σ σ π π π 1 2 1 2 1 1 1 1 ππ π 1 2 2 1 2 + + n n n ˆ 2 z test pooled variance with continuity correction z k n n k = − + +     = − ˆ ˆ ˆ ; ˆ ( π π σ σ 1 2 1 2 2 1 1 see No . 1 ) ; 11 1 lower tail upper tail +  3 z test unpooled variance z n n = − = − ( ) + − ( ) ˆ ˆ ˆ ; ˆ ˆ ˆ ˆ ˆ π π σ σ π π π π 1 2 1 1 1 2 2 2 1 1 4 z test unpooled variance with continuity correction z k n n k = − + +     = − ˆ ˆ ˆ ; ˆ ( π π σ σ 1 2 1 2 2 1 1 see No . 3 ) ; 11 1 lower tail upper tail +  5 Mantel – Haenszel test z x E x V x E x n x x N V x n n = − ( ) ( ) ( ) = + ( ) ( ) = 1 1 1 1 1 1 2 1 1 2 ; ; xx x N x x N N 1 2 1 2 2 1 + ( ) − − ( ) − ( ) 6 Likelihood ratio ( Upton , 1982 ) lr t x t x t x t x t N = ( ) + ( ) + − ( ) + − ( ) + − 2 1 1 1 2 1 2 ( ) . . . . . . tt n t n t x x t N x x t x 1 2 1 2 1 2 ( ) − ( ) − + ( ) − − − ( )     ; ( ) : : ln ( ) = x x 7 t test with df 5 N 2 2 ( D’Agostino et al . , 1988 ) t x x x x N N n x x n N − = − ( ) − − ( )   − − ( ) + 2 1 2 2 1 2 1 1 1 1 1 2 1 xx x 2 2 1 − ( )   Note— x i , success frequency in group i ; n i , sample size in group i ; N 5 n 1 1 n 2 , total sample size ; ˆ p i 5 x i / n i . The z tests in the table are more commonly known as c 2 tests ( the equivalent z test is used to provide two - sided tests ) . 188 F aul , E rdFEldEr , l ang , and B uchnEr the power on the basis of an ordinary one - sample binomial test with Bin ( N p D , 0 . 5 ) as the distribution under H 0 and Bin [ N p D , OR / ( 1 1 OR ) ] as the H 1 distribution . tests for variances Table 9 summarizes important properties of the two procedures for testing hypotheses on variances that are currently supported by G * Power 3 . In the one - group case , the null hypothesis that the population variance s 2 has a specified value c is tested . The variance ratio s 2 / c is used as the effect size . The central and noncentral distributions , corresponding to H 0 and H 1 , respectively , are central c 2 distributions with N 2 1 df s ( because H 0 and H 1 are based on the same mean ) . To compare the variance distributions under both hypotheses , the H 1 distribution is scaled with the value r postulated for the ratio s 2 / c in the alternate Standard Treatment Yes No Yes p 11 p 12 p t No p 21 p 22 1 2 p t p s 1 2 p s 1 Proportion of discordant pairs : p D 5 p 12 1 p 21 Hypothesis : p s 5 p t or , equivalently , p 12 5 p 21 figure 5 . matched binary response design ( mcnemar test ) . table 8 test statistics Used in tests of the difference with offset Between two Independent proportions No . Name Statistic 1 z test pooled variance z n n n = − − = − ( ) + ( ) = ˆ ˆ ˆ ; ˆ ˆ ˆ / / ; ˆ ˆ π π δ σ σ π π π 1 2 1 2 1 1 1 1 ππ π 1 2 2 1 2 + + n n n ˆ 2 z test pooled variance with continuity correction z k n n k = − − + + ( ) = ˆ ˆ / / / ˆ ; ˆ ( π π δ σ σ 1 2 1 2 2 1 1 see No . 1 ) ; −− +  1 1 lower tail upper tail 3 z test unpooled variance z n n = − − = − ( ) + − ( ) ˆ ˆ ˆ ; ˆ ˆ ˆ / ˆ ˆ / π π δ σ σ π π π π 1 2 1 1 1 2 2 1 1 22 4 z test unpooled variance with continuity correction z k n n k = − − + + ( ) = ˆ ˆ / / / ˆ ; ˆ ( π π δ σ σ 1 2 1 2 2 1 1 see No . 3 ) ; −− +  1 1 lower tail upper tail 5 t test with df 5 N 2 2 ( D’Agostino et al . , 1988 ) t x n x x x n K K N N − = + ( ) − ( ) − − − ( )   = − 2 1 1 2 2 1 1 1 1 δ δ ; ( 22 1 1 2 1 1 1 2 2 ) / N n x x n x x − ( ) + − ( )   { } 6 Likelihood score ratio ( difference ) Miettinen & Nurminen ( 1985 ) Farrington & Manning ( 1990 ) Gart & Nam ( 1990 ) z n n = − − = − ( ) + − ( )   ˆ ˆ ˆ ; ˆ / / π π δ σ σ π π π π 1 2 1 1 1 2 2 2 1 1  K ~ ~ ~ ~ Miettinen & Nurminen : K 5 N / ( N 2 1 ) ; Farrington & Manning : K 5 1 ~ p 1 5 2 u cos ( w ) 2 b / ( 3 a ) ; ~ p 2 5 ~ p 1 2 d q 5 n 2 / n 1 ; a 5 1 1 q ; b 5 2 [ 1 1 q 1 ˆ p 1 1 q ˆ p 2 1 d ( q 1 2 ) ] c 5 d 2 1 d ( 2 ˆ p 1 1 q 1 1 ) 1 ˆ p 1 1 q ˆ p 2 ; d 5 2 ˆ p 1 d ( 1 1 d ) v 5 b 3 / ( 3 a ) 3 2 bc / ( 6 a 2 ) 1 d / ( 2 a ) ; w 5 [ 3 . 14159 1 cos 2 1 ( v / u 3 ) ] / 3 u 5 sgn ( v ) √ _ _ _ _ _ _ _ _ _ _ _ _ _ _ b 2 / ( 3 a ) 2 2 c / ( 3 a ) Skewness corrected z ′ ( Gart & Nam , 1990 ) ; z according to Farrington & Manning : z ′ 5 [ √ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 1 4 j ( j 1 z ) 2 1 ] / 2 j ; V 5 [ ~ p 1 ( 1 2 ~ p 1 ) / n 1 1 ~ p 2 ( 1 2 ~ p 2 ) / n 2 ] 2 1 j 5 V 2 / 3 / 6 [ ~ p 1 ( 1 2 ~ p 1 ) ( 1 2 2 ~ p 1 ) / n 1 1 ~ p 2 ( 1 2 ~ p 2 ) ( 1 2 2 ~ p 2 ) / n 2 ] 7 Likelihood score ratio ( risk ratio ) Miettinen & Nurminen ( 1985 ) Farrington & Manning ( 1990 ) Gart & Nam ( 1988 ) z n n = − = − ( ) + − ( )  ˆ ˆ ˆ ; ˆ / / π π φ σ σ π π φ π π 1 2 1 1 1 2 2 2 2 1 1  K ~ ~ ~ ~ Miettinen & Nurminen : K 5 N / ( N 2 1 ) ; Farrington & Manning : K 5 1 π φπ π φ φ 1 2 2 2 1 2 1 4 2 = = − − − + ( )       = − ; ; b b N x x N b n + + ( ) − − x x n 2 1 2 φ ~ ~ ~ Skewness corrected z ′ ( Gart & Nam , 1988 ) ; z according to Farrington & Manning : z ′ 5 [ √ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 1 4 j ( j 1 z ) 2 1 ] / 2 j ; V 5 ( 1 2 ~ p 1 ) / ( ~ p 1 n 1 ) 1 ( 1 2 ~ p 2 ) / ( ~ p 2 n 2 ) j 5 1 / ( 6 V 2 / 3 ) [ ( 1 2 ~ p 1 ) ( 1 2 2 ~ p 1 ) / ( n 1 ~ p 1 ) 2 1 ( 1 2 ~ p 2 ) ( 1 2 2 ~ p 2 ) / ( n 2 ~ p 2 ) 2 ] 8 Likelihood score ratio ( odds ratio ) Miettinen & Nurminen ( 1985 ) z = − ( ) − ( )   − − ( ) − ( )  ˆ / ˆ / π π π π π π π π 1 1 1 1 2 2 2 2 1 1  − ( )   + − ( )   1 1 1 1 1 1 1 2 2 2 / / n n K π π π π ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ Miettinen & Nurminen : K 5 N / ( N 2 1 ) ; Farrington & Manning : K 5 1 ~ p 1 5 ~ p 2 w / [ 1 1 ~ p 2 ( w 2 1 ) ] ; ~ p 2 5 [ 2 b 1 √ _ _ _ _ _ _ _ _ _ _ _ _ _ _ b 2 1 4 a ( x 1 1 x 2 ) ] / ( 2 a ) a 5 n 2 ( w 2 1 ) ; b 5 n 1 w 1 n 2 2 ( x 1 1 x 2 ) ( w 2 1 ) Note— x i , success frequency in group i ; n i , sample size in group i ; N 5 n 1 1 n 2 , total sample size ; ˆ p i 5 x i / n i ; d , difference between proportions postulated in H 0 ; f , risk ratio postulated in H 0 ; w , odds ratio postulated in H 0 . g * P owEr 3 189 hypothesis—that is , the noncentral distribution is r c 2 N 2 1 ( Ostle & Malone , 1988 ) . In the two - groups case , H 0 states that the variances in two populations are identical ( s 2 / s 1 5 1 ) . As in the one - sample case , two central F distri - butions are compared , the H 1 distribution being scaled by the value of the variance ratio s 2 / s 1 postulated in H 1 . Generic tests Besides the specific routines described in Tables 2 – 9 that cover a considerable part of the tests commonly used , G * Power 3 provides “generic” power analysis routines that may be used for any test based on the t , F , c 2 , z , or binomial distribution . In generic routines , the parameters of the central and noncentral distributions are specified directly . To demonstrate the uses and limitations of these generic routines , we will show how to do a two - tailed power analy - sis for the one - sample t test using the generic routine . The results can be compared with those of the specific rou - tine available in G * Power for that test . First , we select the “ t tests” family and then “Generic t test” ( the generic test option is always located at the end of the list of tests ) . Next , we select “Post hoc” as the type of power analysis . We choose a two - tailed test and . 05 as a error probability . We now need to specify the noncentrality parameter d and the degrees of freedom for our test . We look up the definitions for the one - sample test in Table 3 and find that d 5 d √ _ _ N and df 5 N 2 1 . Assuming a medium effect of d 5 0 . 5 and N 5 25 , we arrive at d 5 0 . 5·5 5 2 . 5 and df 5 24 . After inserting these values and clicking on “Calculate , ” we obtain a power of 1 2 b 5 . 6697 . The critical value t 5 2 . 0639 corresponds to the specified a . In this post hoc power analysis , the generic routine is almost as simple as the specific routine . The main disadvantage of the generic routines is , however , that the dependence of the noncen - trality parameter on the sample size is implicit . As a con - sequence , we cannot perform a priori analyses automati - cally . Rather , we need to iterate N by hand until we find an appropriate power value . statIstICal methods and nUmerICal alGorIthms The subroutines used to compute the distribution func - tions ( and the inverse ) of the noncentral t , F , c 2 , z , and binomial distributions are based on the C version of the DCDFLIB ( available from www . netlib . org / random / ) , which was slightly modified for our purposes . G * Power 3 does not provide the approximate power analyses that were available in the speed mode of G * Power 2 . Two ar - guments guided us in supporting exact power calculations only . First , four - digit precision of power calculations may be mandatory in many applications . For example , both compromise power analyses for very large samples , and error probability adjustments in case of multiple tests of significance may result in very small values of a or b ( Westermann & Hager , 1986 ) . Second , as a consequence of improved computer technology , exact calculations have become so fast that the speed gain associated with ap - proximate power calculations is not even noticeable . Thus , from a computational standpoint , there is little advantage to using approximate rather than exact methods ( cf . Brad - ley , Russell , & Reeve , 1998 ) . proGram avaIlaBIlIty and Internet sUpport To summarize , G * Power 3 is a major extension of , and improvement over , G * Power 2 in that it offers easy - to - apply power analyses for a much larger variety of common statistical tests . Program handling is more flexible , easier to understand , and more intuitive than in G * Power 2 , reducing the risk of erroneous applications . The added graphical features should be useful for both research and teaching purposes . Thus , G * Power 3 is likely to become a useful tool for empirical researchers and students of ap - plied statistics . Like its predecessor , G * Power 3 is a noncommercial program that can be downloaded free of charge . Copies of the Mac and Windows versions are available only at www . psycho . uni - duesseldorf . de / abteilungen / aap / gpower3 . Users interested in distributing the program in another way must ask for permission from the authors . Commer - cial distribution is strictly forbidden . The G * Power 3 Web page offers an expanding Web - based tutorial describing how to use the program , along with examples . Users who let us know their e - mail ad - dresses will be informed of updates . Although considerable effort has been put into program development and evalu - ation , there is no warranty whatsoever . Users are asked to kindly report possible bugs and difficulties in program handling to gpower - feedback @ uni - duesseldorf . de . table 9 tests for variances Test Null Other Test Family Hypothesis Effect Size Parameters Noncentrality Parameter Difference from constant ( one sample case ) c 2 tests σ 2 1 c = Variance ratio r c = σ 2 l 5 0 ( H 1 : central c 2 distribution , scaled with r ) df 5 N 2 1 Inequality of two variances F tests σ σ 22 12 1 = Variance ratio r = σ σ 22 12 l 5 0 ( H 1 : central F distribution , scaled with r ) df 1 5 n 1 2 1 df 2 5 n 2 2 1 190 F aul , E rdFEldEr , l ang , and B uchnEr aUthor note Manuscript preparation was supported by Grant SFB 504 ( Project A12 ) from the Deutsche Forschungsgemeinschaft and a grant from the state of Baden - Württemberg , Germany ( Landesforschungsprogramm “Evidenzbasierte Stressprävention” ) . Correspondence concerning this article should be addressed to F . Faul , Institut für Psychologie , Christian - Albrechts - Universität , Olshausenstr . 40 , D - 24098 Kiel , Germany , or to E . Erdfelder , Lehrstuhl für Psychologie III , Universität Mannheim , Schloss Ehrenhof Ost 255 , D - 68131 Mannheim , Germany ( e - mail : ffaul @ psychologie . uni - kiel . de or erdfelder @ psychologie . uni - mannheim . de ) . referenCes Akkad , D . A . , Jagiello , P . , Szyld , P . , Goedde , R . , Wieczorek , S . , Gross , W . L . , & Epplen , J . T . ( 2006 ) . Promoter polymorphism rs3087456 in the MHC class II transactivator gene is not associated with susceptibility for selected autoimmune diseases in German pa - tient groups . International Journal of Immunogenetics , 33 , 59 - 61 . Back , M . D . , Schmukle , S . C . , & Egloff , B . ( 2005 ) . Measuring task - switching ability in the Implicit Association Test . Experimental Psy - chology , 52 , 167 - 179 . Baeza , J . A . , & Stotz , W . ( 2003 ) . Host - use and selection of differ - ently colored sea anemones by the symbiotic crab Allopetrolisthes spinifrons . Journal of Experimental Marine Biology & Ecology , 284 , 25 - 39 . Barabesi , L . , & Greco , L . ( 2002 ) . A note on the exact computation of the Student t , Snedecor F , and sample correlation coefficient dis - tribution functions . Journal of the Royal Statistical Society , 51d , 105 - 110 . Berti , S . , Münzer , S . , Schröger , E . , & Pechmann , T . ( 2006 ) . Differ - ent interference effects in musicians and a control group . Experimen - tal Psychology , 53 , 111 - 116 . Bradley , D . R . , Russell , R . L . , & Reeve , C . P . ( 1998 ) . The accuracy of four approximations to noncentral F . Behavior Research Methods , Instruments , & Computers , 30 , 478 - 500 . Bredenkamp , J . ( 1969 ) . Über die Anwendung von Signifikanztests bei Theorie - testenden Experimenten [ The application of significance tests in theory - testing experiments ] . Psychologische Beiträge , 11 , 275 - 285 . Bredenkamp , J . , & Erdfelder , E . ( 1985 ) . Multivariate Varianzanalyse nach dem V - Kriterium [ Multivariate analysis of variance based on the V - criterion ] . Psychologische Beiträge , 27 , 127 - 154 . Buchner , A . , Erdfelder , E . , & Faul , F . ( 1996 ) . Teststärkeanalysen [ Power analyses ] . In E . Erdfelder , R . Mausfeld , T . Meiser , & G . Rudinger ( Eds . ) , Handbuch Quantitative Methoden [ Handbook of quantitative methods ] ( pp . 123 - 136 ) . Weinheim , Germany : Psycholo - gie Verlags Union . Buchner , A . , Erdfelder , E . , & Faul , F . ( 1997 ) . How to use G * Power [ Computer manual ] . Available at www . psycho . uni - duesseldorf . de / aap / projects / gpower / how _ to _ use _ gpower . html . Busbey , A . B . I . ( 1999 ) . Macintosh shareware / freeware earthscience software . Computers & Geosciences , 25 , 335 - 340 . Cohen , J . ( 1988 ) . Statistical power analysis for the behavioral sciences ( 2nd ed . ) . Hillsdale , NJ : Erlbaum . D’Agostino , R . B . , Chase , W . , & Belanger , A . ( 1988 ) . The appropri - ateness of some common procedures for testing the equality of two in - dependent binomial populations . American Statistician , 42 , 198 - 202 . Erdfelder , E . ( 1984 ) . Zur Bedeutung und Kontrolle des b - Fehlers bei der inferenzstatistischen Prüfung log - linearer Modelle [ Significance and control of the b error in statistical tests of log - linear models ] . Zeitschrift für Sozialpsychologie , 15 , 18 - 32 . Erdfelder , E . , Buchner , A . , Faul , F . , & Brandt , M . ( 2004 ) . GPOWER : Teststärkeanalysen leicht gemacht [ Power analyses made easy ] . In E . Erdfelder & J . Funke ( Eds . ) , Allgemeine Psychologie und deduktivis - tische Methodologie [ Experimental psychology and deductive method - ology ] ( pp . 148 - 166 ) . Göttingen : Vandenhoeck & Ruprecht . Erdfelder , E . , Faul , F . , & Buchner , A . ( 1996 ) . GPOWER : A general power analysis program . Behavior Research Methods , Instruments , & Computers , 28 , 1 - 11 . Erdfelder , E . , Faul , F . , & Buchner , A . ( 2005 ) . Power analysis for categorical methods . In B . S . Everitt & D . C . Howell ( Eds . ) , Encyclo - pedia of statistics in behavioral science ( pp . 1565 - 1570 ) . Chichester , U . K . : Wiley . Farrington , C . P . , & Manning , G . ( 1990 ) . Test statistics and sample size formulae for comparative binomial trials with null hypothesis of non - zero risk difference or non - unity relative risk . Statistics in Medi - cine , 9 , 1447 - 1454 . Field , A . P . ( 2005 ) . Discovering statistics with SPSS ( 2nd ed . ) . London : Sage . Fleiss , J . L . ( 1981 ) . Statistical methods for rates and proportions ( 2nd ed . ) . New York : Wiley . Frings , C . , & Wentura , D . ( 2005 ) . Negative priming with masked distractor - only prime trials : Awareness moderates negative priming . Experimental Psychology , 52 , 131 - 139 . Gart , J . J . , & Nam , J . ( 1988 ) . Approximate interval estimation of the ratio in binomial parameters : A review and correction for skewness . Biometrics , 44 , 323 - 338 . Gart , J . J . , & Nam , J . ( 1990 ) . Approximate interval estimation of the difference in binomial parameters : Correction for skewness and ex - tension to multiple tables . Biometrics , 46 , 637 - 643 . Geisser , S . , & Greenhouse , S . W . ( 1958 ) . An extension of Box’s re - sults on the use of the F distribution in multivariate analysis . Annals of Mathematical Statistics , 29 , 885 - 891 . Gerard , P . D . , Smith , D . R . , & Weerakkody , G . ( 1998 ) . Limits of retrospective power analysis . Journal of Wildlife Management , 62 , 801 - 807 . Gigerenzer , G . , Krauss , S . , & Vitouch , O . ( 2004 ) . The null ritual : What you always wanted to know about significance testing but were afraid to ask . In D . Kaplan ( Ed . ) , The SAGE handbook of quantitative methodology for the social sciences ( pp . 391 - 408 ) . Thousand Oaks , CA : Sage . Gleissner , U . , Clusmann , H . , Sassen , R . , Elger , C . E . , & Helm - staedter , C . ( 2006 ) . Postsurgical outcome in pediatric patients with epilepsy : A comparison of patients with intellectual disabilities , sub - average intelligence , and average - range intelligence . Epilepsia , 47 , 406 - 414 . Goldstein , R . ( 1989 ) . Power and sample size via MS / PC - DOS comput - ers . American Statistician , 43 , 253 - 262 . Hager , W . ( 2006 ) . Die Fallibilität empirischer Daten und die Notwen - digkeit der Kontrolle von falschen Entscheidungen [ The fallibility of empirical data and the need for controlling for false decisions ] . Zeitschrift für Psychologie , 214 , 10 - 23 . Haseman , J . K . ( 1978 ) . Exact sample sizes for use with the Fisher – Irwin test for 2 3 2 tables . Biometrics , 34 , 106 - 109 . Hoenig , J . N . , & Heisey , D . M . ( 2001 ) . The abuse of power : The perva - sive fallacy of power calculations for data analysis . American Statisti - cian , 55 , 19 - 24 . Hoffmann , J . , & Sebald , A . ( 2005 ) . Local contextual cuing in visual search . Experimental Psychology , 52 , 31 - 38 . Huynh , H . , & Feldt , L . S . ( 1970 ) . Conditions under which mean square ratios in repeated measurements designs have exact F - distribution . Journal of the American Statistical Association , 65 , 1582 - 1589 . Keppel , G . , & Wickens , T . D . ( 2004 ) . Design and analysis . A research - er’s handbook ( 4th ed . ) . Upper Saddle River , NJ : Pearson Education International . Kornbrot , D . E . ( 1997 ) . Review of statistical shareware G * Power . Brit - ish Journal of Mathematical & Statistical Psychology , 50 , 369 - 370 . Kromrey , J . , & Hogarty , K . Y . ( 2000 ) . Problems with probabilistic hindsight : A comparison of methods for retrospective statistical power analysis . Multiple Linear Regression Viewpoints , 26 , 7 - 14 . Lenth , R . V . ( 2001 ) . Some practical guidelines for effective sample size determination . American Statistician , 55 , 187 - 193 . Levin , J . R . ( 1997 ) . Overcoming feelings of powerlessness in “aging” researches : A primer on statistical power in analysis of variance de - signs . Psychology & Aging , 12 , 84 - 106 . McKeon , J . J . ( 1974 ) . F approximations to the distribution of Hotel - ling’s T 02 . Biometrika , 61 , 381 - 383 . Mellina , E . , Hinch , S . G . , Donaldson , E . M . , & Pearson , G . ( 2005 ) . Stream habitat and rainbow trout ( Oncorhynchus mykiss ) physiologi - cal stress responses to streamside clear - cut logging in British Colum - bia . Canadian Journal of Forest Research , 35 , 541 - 556 . Miettinen , O . , & Nurminen , M . ( 1985 ) . Comparative analysis of two rates . Statistics in Medicine , 4 , 213 - 226 . Müller , J . , Manz , R . , & Hoyer , J . ( 2002 ) . Was tun , wenn die Test - stärke zu gering ist ? Eine praktikable Strategie für Prä – Post - Designs [ What to do if statistical power is low ? A practical strategy for pre – g * P owEr 3 191 post - designs ] . Psychotherapie , Psychosomatik , Medizinische Psy - chologie , 52 , 408 - 416 . Muller , K . E . , & Barton , C . N . ( 1989 ) . Approximate power for repeated - measures ANOVA lacking sphericity . Journal of the American Statistical Association , 84 , 549 - 555 . Muller , K . E . , LaVange , L . M . , Landesman - Ramey , S . , & Ramey , C . T . ( 1992 ) . Power calculations for general linear multivariate models including repeated measures applications . Journal of the American Statistical Association , 87 , 1209 - 1226 . Muller , K . E . , & Peterson , B . L . ( 1984 ) . Practical methods for com - puting power in testing the multivariate general linear hypothesis . Computational Statistics & Data Analysis , 2 , 143 - 158 . Myers , J . L . , & Well , A . D . ( 2003 ) . Research design and statistical analysis ( 2nd ed . ) . Mahwah , NJ : Erlbaum . O’Brien , R . G . , & Kaiser , M . K . ( 1985 ) . MANOVA method for analyz - ing repeated measures designs : An extensive primer . Psychological Bulletin , 97 , 316 - 333 . O’Brien , R . G . , & Muller , K . E . ( 1993 ) . Unified power analysis for t - tests through multivariate hypotheses . In L . K . Edwards ( Ed . ) , Ap - plied analysis of variance in behavioral science ( pp . 297 - 344 ) . New York : Dekker . O’Brien , R . G . , & Shieh , G . ( 1999 ) . Pragmatic , unifying algorithm gives power probabilities for common F tests of the multivariate gen - eral linear hypothesis . Available at www . bio . ri . ccf . org / UnifyPow . Ortseifen , C . , Bruckner , T . , Burke , M . , & Kieser , M . ( 1997 ) . An overview of software tools for sample size determination . Informatik , Biometrie & Epidemiologie in Medizin & Biologie , 28 , 91 - 118 . Ostle , B . , & Malone , L . C . ( 1988 ) . Statistics in research : Basic con - cepts and techniques for research workers ( 4th ed . ) . Ames : Iowa State Press . Pillai , K . C . S . , & Mijares , T . A . ( 1959 ) . On the moments of the trace of a matrix and approximations to its distribution . Annals of Math - ematical Statistics , 30 , 1135 - 1140 . Pillai , K . C . S . , & Samson , P . , Jr . ( 1959 ) . On Hotelling’s generaliza - tion of T 2 . Biometrika , 46 , 160 - 168 . Quednow , B . B . , Kühn , K . - U . , Stelzenmueller , R . , Hoenig , K . , Maier , W . , & Wagner , M . ( 2004 ) . Effects of serotonergic and norad - renergic antidepressants on auditory startle response in patients with major depression . Psychopharmacology , 175 , 399 - 406 . Rao , C . R . ( 1951 ) . An asymptotic expansion of the distribution of Wilks’s criterion . Bulletin of the International Statistical Institute , 33 , 177 - 180 . Rasch , B . , Friese , M . , Hofmann , W . J . , & Naumann , E . ( 2006a ) . Quantitative Methoden 1 : Einführung in die Statistik ( 2 . Auflage ) [ Quantitative methods 1 : Introduction to statistics ( 2nd ed . ) ] . Heidel - berg , Germany : Springer . Rasch , B . , Friese , M . , Hofmann , W . J . , & Naumann , E . ( 2006b ) . Quantitative Methoden 2 : Einführung in die Statistik ( 2 . Auflage ) [ Quantitative methods 2 : Introduction to statistics ( 2nd ed . ) ] . Heidel - berg , Germany : Springer . Rencher , A . C . ( 1998 ) . Multivariate statistical inference and applica - tions . New York : Wiley . Richardson , J . T . E . ( 1996 ) . Measures of effect size . Behavior Research Methods , Instruments , & Computers , 28 , 12 - 22 . Scheffé , H . ( 1959 ) . The analysis of variance . New York : Wiley . Schwarz , W . , & Müller , D . ( 2006 ) . Spatial associations in number - related tasks : A comparison of manual and pedal responses . Experi - mental Psychology , 53 , 4 - 15 . Sheppard , C . ( 1999 ) . How large should my sample be ? Some quick guides to sample size and the power of tests . Marine Pollution Bul - letin , 38 , 439 - 447 . Shieh , G . ( 2003 ) . A comparative study of power and sample size cal - culations for multivariate general linear models . Multivariate Behav - ioral Research , 38 , 285 - 307 . Smith , R . E . , & Bayen , U . J . ( 2005 ) . The effects of working memory resource availability on prospective memory : A formal modeling ap - proach . Experimental Psychology , 52 , 243 - 256 . Steidl , R . J . , Hayes , J . P . , & Schauber , E . ( 1997 ) . Statistical power analysis in wildlife research . Journal of Wildlife Management , 61 , 270 - 279 . Suissa , S . , & Shuster , J . J . ( 1985 ) . Exact unconditional sample sizes for 2 3 2 binomial trial . Journal of the Royal Statistical Society A , 148 , 317 - 327 . Thomas , L . , & Krebs , C . J . ( 1997 ) . A review of statistical power analysis software . Bulletin of the Ecological Society of America , 78 , 126 - 139 . Upton , G . J . G . ( 1982 ) . A comparison of alternative tests for the 2 3 2 comparative trial . Journal of the Royal Statistical Society A , 145 , 86 - 105 . Westermann , R . , & Hager , W . ( 1986 ) . Error probabilities in educa - tional and psychological research . Journal of Educational Statistics , 11 , 117 - 146 . Zumbo , B . D . , & Hubley , A . M . ( 1998 ) . A note on misconceptions concerning prospective and retrospective power . The Statistician , 47 , 385 - 388 . notes 1 . The observed power is reported in many frequently used computer programs ( e . g . , the MANOVA procedure of SPSS ) . 2 . We recommend checking the degrees of freedom reported by G * Power by comparing them , for example , with those reported by the program used to analyze the sample data . If the degrees of freedom do not match , the input provided to G * Power is incorrect and the power calculations do not apply . 3 . Plots of the central and noncentral distributions are shown only for tests based on the t , F , z , c 2 , or binomial distribution . No plots are shown for tests that involve an enumeration procedure ( e . g . , the McNe - mar test ) . 4 . We thank Dave Kenny for making us aware of the fact that the t test ( correlation ) power analyses of G * Power 2 are correct only in the point – biserial case ( i . e . , for correlations between a binary variable and a continuous variable , the latter being normally distributed for each value of the binary variable ) . For correlations between two continu - ous variables following a bivariate normal distribution , the t test ( cor - relation ) procedure of G * Power 2 overestimates power . For this reason , G * Power 3 offers separate power analyses for point – biserial correlations ( in the t family of distributions ) and correlations between two normally distributed variables ( in the exact distribution family ) . However , power values usually differ only slightly between procedures . To illustrate , as - sume we are interested in the power of a two - tailed test of H 0 : r 5 . 00 for continuously distributed measures derived from two Implicit Association Tests ( IATs ) differing in content . Assume further that , due to method - specific variance in both versions of the IAT , the true Pearson correlation is actually r 5 . 30 ( effect size ) . Given a 5 . 05 and N 5 57 ( see Back , Schmukle , & Egloff , 2005 , p . 173 ) , an exact post hoc power analysis for “Correlations : Differences from constant ( one sample case ) ” reveals the correct power value of 1 2 b 5 . 63 . Choosing the incorrect “Correla - tion : point biserial model” procedure from the t test family would result in 1 2 b 5 . 65 . ( Manuscript received December 8 , 2006 ; accepted for publication January 23 , 2007 . )