Memory Access Scheduling and Binding Considering Energy Minimization in Multi - Bank Memory Systems Chun - Gi Lyuh Basic Research Laboratory , Electronics and Telecommunications Research Institute , Daejeon , Korea cglyuh @ etri . re . kr Taewhan Kim School of Electrical Engineering and Computer Science , Seoul National University , Seoul , Korea tkim @ ssl . snu . ac . kr ABSTRACT Memory - related activity is one of the major sources of energy con - sumption in embedded systems . Many types of memories used in embedded systems allow multiple operating modes ( e . g . , active , standby , nap , power - down ) to facilitate energy saving . Further - more , it has been known that the potential energy saving increases when the embedded systems use multiple memory banks in which their operating modes are controlled independently . In this paper , we propose ( a compiler - directed ) integrated approach to the prob - lem of maximally utilizing the operating modes of multiple mem - ory banks by solving the three important tasks simultaneously : ( 1 ) assignment of variables to memory banks , ( 2 ) scheduling of mem - ory access operations , and ( 3 ) determination of operating modes of banks . Speciﬁcally , for an instance of tasks 1 and 2 , we formu - late task 3 as a shortest path ( SP ) problem in a network and solved it optimally . We then develop an SP - based heuristic that solves tasks 2 and 3 efﬁciently in an integrated fashion . We then extend the proposed approach to address the limited register constraint in processor . From experiments with a set of benchmark programs , we conﬁrm that the proposed approach is able to reduce the en - ergy consumption by 15 . 76 % over that by the conventional greedy approach . Categories and Subject Descriptors : C . 3 [ Special - purpose and application - based systems ] : Real - time and embedded systems General Terms : Algorithms , Design Keywords : low energy design , scheduling , binding 1 . INTRODUCTION Lowering down the energy consumption is a major design objec - tive in many of today’s embedded system - on - chips ( SoCs ) design . However , traditionally , various sophisticated processor - to - memory architectures have been designed and used to better meet the per - formance requirement ( rather than energy requirement ) of the tar - get applications . Among them , the architecture with multiple mem - ory banks is one of the most effective features in increasing the system’s performance . For example , Motorola DSP 56000 and Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . DAC 2004 , June 7 – 11 , 2004 , San Diego , California , USA . Copyright 2004 ACM 1 - 58113 - 828 - 8 / 04 / 0006 . . . $ 5 . 00 . NEC 77016 DSP support this feature , and increase memory band - width by allowing multiple data memory accesses to occur concur - rently when the variables to be accessed belong to different mem - ory banks . An extensive research work has been done in the area of parallelizing variable accesses among multiple memory banks . [ 1 , 2 ] Recently , advanced low power memory architectures are de - signed to operate in multiple states ( e . g . , active , standby , nap , and power - down modes ) . However , the issue of minimizing energy consumption by exploiting the architecture with multiple memory banks combined with the operating modes of memory banks has not been ( relatively ) fully addressed in the literature , but the issue is very useful or critical in saving energy consumption in embedded systems , particularly those for computation - intensive applications . De La Luz , Kandenir , and Kolcu [ 3 ] proposed an automatic data migration to reduce energy consumption in multiple memory banks by exploiting the temporal afﬁnity among data . It assumes array is a basic unit of data to be considered for migration . It also assumes that the schedule of memory accesses is ﬁxed . Benini , Macii , and Poncino [ 4 ] proposed an algorithm for low - energy partitioning of memory into multiple banks for a given schedule of memory ac - cesses in code . In terms of utilizing the power modes , Benini et al . [ 5 ] proposed an execution proﬁle based energy - optimal algo - rithm for the automatic partitioning of on - chip SRAMs into mul - tiple banks . In addition , Lu , Benini , and De Micheli [ 6 ] proposed a low - power task scheduling technique for multiple devices with multiple power modes . De La Luz et al . [ 7 ] proposed an oper - ating system ( OS ) based power mode transition scheme in mem - ory power - mode management . They [ 8 ] also proposed a number of compiler directed techniques and applied them sequentially to solve the problem of bank assignment and operating mode selec - tion . In this paper , we propose a compiler - directed integrated approach to the problem of maximally utilizing the power modes of memory banks by solving the following three important tasks simultane - ously : ( 1 ) variable assignment to memory banks , ( 2 ) scheduling memory access operations , and ( 3 ) selecting operating modes of banks . Those three tasks are closely interrelated and their results affect each other in signiﬁcant ways . Consequently , our integrated approach is very necessary and desirable for achieving a globally maximal utilization of power modes of memory . 2 . MOTIVATING EXAMPLE We give an example to illustrate how scheduling of memory ac - cesses and variable assignment to multiple banks affect the en - ergy consumption of the memory . Consider a Rambus DRAM ( RDRAM ) module [ 9 ] , which is designed to operate in two differ - 2 cycles ~ 0 cycle 3 . 57 nJ / cycle 0 . 83 nJ / cycle ~ 0 nJ / cycle active mode ~ 3 . 57 nJ / cycle energy consumptions , and mode transitions ( a ) Simplified memory operating modes , their standby mode for a Rambus RDRAM in [ 3 ] Load G Store A Load A Load B Op 1 Op 5 Load E Load F Op 4 Load A Op 8 Store B Op 3 Load H Op 6 Op 7 Store D Load D Load C Op 2 Step 1 Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Step 9 Step 10 M1 step active M2 E = 32 . 96 nJ 10 Load A Load C Store A Load G Load E Load H Load A 1 2 3 4 5 6 7 8 9 Store B Store D Load F Load D Load B standby to active standby ( b ) A schedule of memory accesses where A to H stand for variables assignment of variables to memory banks M1 and M2 for the schedule and Op1 to Op8 stand for arithmetic / logic operations , and a greedy Load A Load B Op 1 Op 5 Load A Op 8 Store B Op 6 Op 7 Load D Load C Op 2 Store A Load G Op 3 Store D Load E Load F Op 4 Load H E = 24 . 74 nJ M1 M2 10 9 8 7 6 5 4 3 2 1 Load A Load D Store A Load E Load F Load H Load A Store D Store B Load G Load C Load B step Step 1 Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Step 9 Step 10 ( d ) Simultaneously optimized schedule of memory accesses and bank assignment Load G Store A Load A Load B Op 1 Op 5 Load E Load F Op 4 Load A Op 8 Store B Op 3 Load H Op 6 Op 7 Store D Load D Load C Op 2 M1 M2 10 Load A Load D Store A Load G Load E Load H Load A Store D 1 2 3 4 5 6 7 8 9 Load B Load C Load F Store B E = 30 . 22 nJ step Step 1 Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Step 9 Step 10 ( c ) The same schedule as that in ( b ) , but an optimized bank assignment for the schedule Figure 1 : Motivating examples illustrating the effects of memory access scheduling and memory binding on energy consumption . ent modes : active and standby modes ; Memory access operations will be performed only when the memory is in active mode . The energy consumption in active mode is 3 . 57 nJ per cycle . If the memory is in standby mode , it consumes much less energy , 0 . 83 nJ per cycle , but is required to be switched to an active mode to perform a memory access operation . The mode transition from ac - tive to standby takes negligible amounts of time and energy , but transition from standby to active takes two clock cycles and almost the same amount of energy as that in active mode [ 9 ] . 1 Figure 1 ( a ) describes the mode transition behavior of a RDRAM module [ 9 ] . Suppose a designer uses two RDRAM banks ( say M 1 and M 2 ) in [ 9 ] , that follows the mode transitions speciﬁed in Figure 1 ( a ) . Figure 1 ( b ) shows a schedule of variable access operations and the assignment of the variables according to the order of ﬁrst appear - ance in code with the schedule to memory banks M 1 and M 2 . The shaded boxes at the right side of the ﬁgure indicate the operating modes of the corresponding memory banks and clock steps . The total energy consumed in M 1 and M 2 is 32 . 96 nJ . On the other hand , Figure 1 ( c ) shows an energy - optimized memory binding for the same schedule as that in Figure 1 ( b ) . The energy consumption is reduced from 32 . 96 nJ to 30 . 22 nJ , which is 8 . 3 % reduction . A further energy saving can be achieved by considering scheduling and memory binding together , as indicated in Figure 1 ( d ) , in which the energy consumption is reduced to 24 . 74 nJ , which is 24 . 9 % and 18 . 1 % reductions over those in Figures 1 ( b ) and ( c ) , respectively . This example clearly reveals that it is very necessary to take into account memory access scheduling and memory binding simulta - neously to fully exploit the memory operating modes to minimize the energy consumed in memory . 1 Note that the mode transition overheads ( i . e . , time , energy ) as well as the number and types of memory operation modes vary depend - ing on the technologies used in designing memories . Our proposed approach can be parameterized with the varying factors , so that it is applicable to any kind of memories with multiple operating modes . It should be noted that embedded processors with multiple mem - ory banks have a limited number of registers to hold the values of variables that are accessed from / to memory . That means memory access scheduling should be constrained by the registers available to use . For example , in Figures 1 ( d ) , Load G operation is executed at clock step 3 , and the value of G is stored to a register until clock step 5 since the value will be used at clock step 5 as input to Op5 . We can easily see that a schedule of memory access operations de - termines the intervals of clock steps at which the values of variables accessed should be stored temporarily . The intervals of clock steps for the schedule in turn determine the minimum number of registers required to store the values of variables . 2 3 . THE PROBLEM FORMULATION We assume that scheduling of computation steps for arithmetic / logic operations to functional units has already been done . In other words , the clock steps at which the data values of variables that are read from memory are to be used and the values that are to be writ - ten to memory are generated are known . However , from / to which memory banks and at which clock steps the memory access opera - tions are executed have not yet been determined . For conciseness of presentation , we consider dual memory banks and non - array vari - able accesses . 3 Let S ( G ) be a schedule of memory access operations in a data - ﬂow graph ( DFG ) G and B ( S ) be the memory bank binding of variables whose accesses are executed according to S ( G ) . Further - more , f mode ( S ; B ; M i ; c j ) denotes the operating mode of mem - ory bank M i at clock step c j for schedule S and binding B , and E ( f mode ( S ; B ; M i ; c j ) ) denote the amount of energy consumed at c j in bank M i with memory mode f mode ( (cid:1) ) . 2 The issue of addressing the register constraint will be discussed in section 4 . 2 . 3 Extension of our proposed technique to the problem with an ar - bitrary number of memory banks and / or array variable accesses is rather straightforward . Then , the optimization problem we want to solve is to ﬁnd a schedule S , a binding B , and modes f mode ( (cid:1) ) that minimize the cost function : E total = K X i = 1 T X j = 1 E ( f mode ( S ; B ; M i ; c j ) ) ( 1 ) where K ( = 2 ) is the number of memory banks and T is the latency of G . 4 . THE PROPOSED APPROACH We propose an iterative technique , which consists of two phases : (cid:15) Initial Phase : We obtain an initial result of S and B by applying a simple list scheduling to memory access operations in G and a subsequent application of a greedy binding to the variables , from which we compute , for each memory bank , f mode at each clock step optimally , minimizing E total of the S and B . (cid:15) Reﬁnement Phase : We divide scheduling task into two subtasks , called r - scheduling and a - scheduling . R - scheduling determines a relative ( linear ) order among the memory access operations to a bank , and a - scheduling determines an absolute order among the operations that have relatively been ordered by the r - scheduling . Given an instance of binding B of variables and an r - schedule S r of B , we generate as many alternative bindings of variables and r - schedules which are slightly different from S r of B as possible , and obtain the corresponding E total value by calculating an optimal a - schedule S 0 a and f mode for each of the r - schedules of the alterna - tive bindings . Among the candidate bindings and r - schedules , we choose the binding B 0 and r - schedule S 0 r of B 0 that minimize the value of E total . By setting S r = S 0 r and B = B 0 , we repeat the process until there is no more reduction in the quantity of E total . In the following , we provide the details of the proposed tech - nique . First , we assume that the number of registers for storage is sufﬁciently large enough to hold all data values that are accessed from / to memory banks at any clock steps . That means the mem - ory access operations are to be scheduled to any of the clock steps only if the load accesses occur before the use of their values and the store accesses occur after the creation of their values . 4 We describe our stepwise reﬁnement technique using the exam - ple in Figure 2 . Consider the DFG G in Figure 2 ( a ) , in which the arithmetic / logic operations have already been scheduled . Fig - ure 2 ( c ) shows an instance of memory binding B and r - schedule S r of the memory access operations in G , which was initially de - rived by using a simple greedy scheme . That is , B is f M 1 : i , a , index , y , temp ; M 2 : x , k g , and S r is f M 1 : Load i ! Load a ! St index ! Load y ! Load temp ! St temp ; M 2 : Load x ! Load k g . Figure 2 ( d ) shows our network formulation for solving an optimal a - schedule , S a , of B and S r . ( The detailed network construction and solution will be presented in section 4 . 1 . ) Let us deﬁne two types of primitive operations that can be applied to B and S r . Deﬁnition : switch , denoted by M 1 Ci $ M 2 Cj , switches the i th access operation in S r of M 1 with the j th access operation in S r of M 2 , and move , denoted by M 1 Ci ! M 2 Cj ( or M 2 Ci ! M 1 Cj ) , moves the i th access operation in S r of M 1 ( or M 2 ) to the position of the j th access operation in S r of M 2 ( or M 1 ) . Note that the legal switch and move operations should not violate the operation dependencies in DFG . Our iterative process consists of two loops , one nesting the other : The inner - loop performs the following : It ﬁrst generates the in - 4 Our extension to the memory access scheduling and bank binding with the register constraint will be discussed in section 4 . 2 . Store index 16 Load i * j + Load a Load x Store temp + + * * Load temp Load y Load k j 1 j + Step 1 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Step 9 Step 10 Step 11 Step 12 Step 2 . . 1 5 6 Ld temp St temp col−5 col−6 s 1 4 5 START 9 11 t END Ld y col−4 Ld i Ld a St index col−1 col−2 col−3 Load i Load temp Store temp Load a Load x Store index Load k Load y M1 : { Load i > Load a > Store index > Load y > Load temp > Store temp } M2 : { Load x > Load k } col−1 col−2 Ld x Ld k 1 2 3 4 6 5 t s END START ( d . 1 ) The network formulation for a−schedule of ( d . 2 ) The network formulation for a−schedule of the binding and r−schedule in memory M2 of ( c ) . s START 4 3 2 1 Ld x 1 2 3 4 5 6 t END Ld y s 1 4 5 9 11 t START 5 6 Ld i Ld a St index Ld k Ld temp St temp END ( e . 1 ) The updated network formulation from ( d . 1 ) for the switch of bindings and r−schedules of Load _ y and Load _ k operations in ( c ) . ( e . 2 ) The updated network formulation from ( d . 2 ) for the switch of bindings and r−scehdule of Load _ y and Load _ k operations in ( c ) . 1 2 3 4 5 6 7 8 9 10 11 step Store index Load a Load i Load k Load temp Store temp M1 Load x Load y M2 switches ( denoted by < − > ) and moves ( denoted energy saving is obtained when Load _ y operation ( f ) The optimal idle time period for minimum energy consumption for each of the posssible by − > ) , as shown the example in ( e ) , from the binding and r−scheudle in ( c ) . The maximum in the fourth column in ( d . 1 ) is switched with Load _ k operation in the second column in ( d . 2 ) ( i . e . , M1C4 < − > M2C2 ) . ( g ) The resultant binding , a−schedule , and ( The active , transition , idle−states are indicated by black , heavy gray , and light gray colors ) . the memory states by M1C4 < − > M2C2 constants , and the dotted circles represent ( a ) A ( arithmetic / logic operation−scheduled ) DFG . The numbers in circles represent register access operations . ( b ) The intervals of clock steps at which the memory memory access operations in ( a ) memory access operations ) . can be executed . ( i . e . , the mobility of M1C1 − > M2C1 M1C4 − > M2C1 M1C4 − > M2C2 M1C4 − > M2C3 M2C1 − > M1C2 M1C1 < − > M2C1 M1C2 < − > M2C1 M1C5 − > M2C3 M1C2 − > M2C2 M1C3 − > M2C2 M1C6 − > M2C4 SWITCH / MOVE TOTAL IDLE TIME M1C4 < − > M2C2 M1 M2 M1 + M2 39 . 27 39 . 27 39 . 27 39 . 27 36 . 53 36 . 53 36 . 53 36 . 53 36 . 53 36 . 53 33 . 79 31 . 05 28 . 31 28 . 31 28 . 31 28 . 31 28 . 31 28 . 31 28 . 31 25 . 57 20 . 09 22 . 83 64 . 84 64 . 84 64 . 84 64 . 84 64 . 84 64 . 84 64 . 84 64 . 84 62 . 10 67 . 58 59 . 36 the binding and r−schedule in memory M1 of ( c ) . ( c ) A result by greedy memory binding and r−schedule Figure 2 : An example illustrating our iterative reﬁnement procedure of binding and scheduling . stances of all bindings and r - schedules that can be obtained by the application of a switch or a move operation to B and S r , and ﬁnd their optimal a - schedules . Then , among the instances of bindings and schedules , it chooses the one with the least energy consump - tion , and applies the corresponding switch or move operation to B and S r , producing B new and S newr . The access operations that were involved are then locked . This process repeats from B new and S newr , and the iteration stops when all the access operations are locked or no more switch or move can be applied without vi - olating the operation dependencies in DFG . The best instance of binding and schedule is the one with the least energy consumption among the instances obtained during the iterations . The outer - loop then unlocks all the access operations , and sets the best instance to be an initial instance of the next inner - loop . The outer - loop stops when there is no more reduction in energy consumption . For example , consider switch operation M 1 C 4 $ M 2 C 2 to the binding and r - schedule in Figure 2 ( c ) . That means , Load y , which is the fourth access operation in M 1 is switched with Load k , which is the second access operation in M 2 . We then determine an optimal a - schedule for the updated binding and r - schedule corre - sponding to M 1 C 4 $ M 2 C 2 using network formulation , as indi - cated in Figures 2 ( e . 1 ) and ( e . 2 ) . ( The details about the formulation will be described in section 4 . 1 . ) The table in Figure 2 ( f ) summa - rizes the energy consumptions for the rebindings and reschedules produced by the application of all legal switch / move operations to the binding and schedule in Figure 2 ( c ) . Among the switch / move operations , M 1 C 4 $ M 2 C 2 produces the result with the least energy consumption . Finally , Figure 2 ( g ) shows the resultant bind - ing and schedule corresponding to M 1 C 4 $ M 2 C 2 . The Load y and Load k operations are then locked , and , the process will repeat from the binding and r - schedule of Figure 2 ( g ) . The key feature of our procedure is to compute the energy con - sumption for every instance of bindings and r - schedules quickly , but optimally . This feature , which is the subject of the next sub - section , enables us to fully explore the search space in a reasonable amount of time to ﬁnd globally good solutions . We call the overall procedure of the proposed technique MACCESS - lp . The time complexity of the inner - loop is theoretically bounded by O ( N 5 T 4 ) where N is the number of memory access operations and T is the latency of G . However , the complexity of inner - loop is reduced to O ( N 4 T 2 ) due to the incremental fast network ﬂow computation , and in practice , the complexity is further reduced to that close to ( N 3 ) since the mobility of an access operation is much shorter than T due to the ﬁxed schedule of arithmetic / logic opera - tions . Note that the value of N ( i . e . , the number of access opera - tions ) is less than 100 in practice . 4 . 1 Optimal Cost Computation (cid:15) SP - based network formulation : Let us consider the binding B 0 and r - schedule S 0 r in Figure 2 ( e ) which is a local update of B and S r in Figure 2 ( d ) by switch operation : M 1 C 4 $ M 2 C 2 ( i . e . , Load y $ Load k ) . We will describe an SP - based network formulation using the example in Figure 2 ( e . 2 ) to ﬁnd a - schedule , S 0 a , of M 2 for minimum energy consumption . We construct network G 0 sp of M 2 for B 0 and S 0 r as follows : For the i th access operation op i to M 2 in S 0 r , if op i can be scheduled to any of k i clock steps , G 0 sp contains k i nodes , one for each clock step . The k i nodes are then arranged vertically , placing the nodes corresponding to the ﬁrst access operation in S 0 r to the ﬁrst column of G 0 sp and the nodes corresponding to the last in S 0 r to the last col - umn . We then create two dummy nodes , start and end nodes , and place them to the front and end of G 0 sp , respectively . Figure 2 ( e . 2 ) shows the node arrangement . For example , since Load x can be scheduled to any of clock steps 1 , 2 , 3 , and 4 for execution , G 0 sp contains 4 nodes in the ﬁrst column . For each pair of nodes op i ; s 1 and op i + 1 ; s 2 where op i ; s 1 is a node in the i th column of clock step s 1 , op i + 1 ; s 2 is a node in the i + 1 th column of clock step s 2 , and s 1 < s 2 , G 0 sp has an arc from op i ; s 1 to op i + 1 ; s 2 . G 0 sp also con - tains arcs from start node to every node in the ﬁrst column , and arcs from every node in the last column to end node . We then as - sign cost to each arc . The cost assigned to arc op i ; s 1 ! op i + 1 ; s 2 represents the amount of energy that can be minimally consumed during the clock step period of [ s 1 + 1 , s 2 ] . 5 For example , in Fig - ure 3 , the cost assigned to the arc from node a to b is 11 . 54 , which is the amount of energy dissipated minimally in M 2 for the clock step period of [ 3 , 6 ] . Precisely , M 2 stays in standby mode in clock step 3 and performs a mode transition in steps 4 and 5 , and stays in active mode in step 6 to execute Load y , resulting in the total amount of energy consumption for the period of [ 3 , 6 ] being 0 . 83 ( for standby ) + 3 . 54 (cid:2) 2 ( for mode transition ) + 3 . 54 ( for active ) = 11 . 54 nJ . Then , the problem of ﬁnding an energy - minimal a - schedule can be solved by ﬁnding a shortest path from start to end in G 0 sp . The heavy arrows in Figure 3 indicate a shortest path , whose length is 20 . 09 , which is equivalent to the amount of minimal energy con - sumed in M 2 for B 0 and S 0 r using memory operating modes . 1 2 3 4 7 . 14 10 . 71 11 . 54 3 . 57 3 . 57 START Ld x 7 . 14 10 . 71 11 . 54 s : 0 2 7 . 14 t : 12 12 . 95 END a 1 Ld y 10 . 71 3 4 14 . 28 15 . 11 5 15 . 94 6 12 . 12 11 . 29 10 . 46 9 . 63 b 3 . 57 7 . 14 10 . 71 11 . 54 12 . 37 3 . 577 . 1410 . 71 11 . 54 3 . 57 7 . 14 10 . 71 3 . 57 7 . 14 Figure 3 : The SP - based network with arc costs for the example in Figure 2 ( e . 2 ) . (cid:15) Fast incremental SP computation : The time complexity of a single - source SP computation in a network is O ( N 2 ) [ 10 ] where N is the number of nodes in the network . However , if we examine the structure of our SP - based network , the SP computation can be done in a linear time . The structure of the SP - based network is a sequence of columns of nodes , in which arcs exist only among the nodes in two con - secutive columns . In this special structure , for each node n i , we compute two numbers l start and l end , where l start is the length of a shortest path from start to n i , and l end is the length of a shortest path from n i to end . We compute the l start values of nodes from start to end in O ( N ) time , 6 and in the same way , compute the l end values of nodes from end to start in O ( N ) time . 6 The shortest path length from start to end is then the l end value of start or the l start value of end . We call this SP computation is called a sweep - based SP computation . Figure 4 ( a ) shows an example of l start and l end values of nodes in the SP - based network in Figure 2 ( d . 2 ) . Now , suppose a column of nodes is inserted to the SP - based network by the application of move operation to Load y . Figure 4 ( b ) shows the resultant SP - 5 For simplicity , we assume that each access operation takes one clock cycle . In addition , without loss of generality , we can assume that start and end nodes are scheduled in clock steps 0 , and T ( la - tency ) , respectively . 6 We assume the number of nodes ( < < T , in practice ) in each col - umn is constant bounded . based network . The l start and l end values of nodes in the inserted columns can be computed in a constant time . Then , the length of the shortest path on the updated network is the minimum value of l start + l end among the nodes in the inserted column , which is 17 : 14 + 24 : 74 ( l start + l end of shaded node ) . To perform the next iteration of the trials of switch / move oper - ations from an updated network , we need to compute the l start or l end values corresponding to the x’s in Figure 4 . That is , the l end values of the nodes in the left side ( i . e . , towards start node ) of the inserted column and the l start values of the nodes in the right side ( i . e . , towards end node ) of the inserted column can be obtained in O ( N ) time by using the sweep - based SP computation . 1 2 3 4 s : 0 5 6 t : 12 length of shortest path from start node length of shortest path to end node l start : l end : l end l end 1 2 3 4 s : 0 1 3 4 5 6 5 6 t : 12 l start l start l start l end Ld k END START Ld x ( 3 . 57 , 25 . 57 ) ( 7 . 14 , 24 . 74 ) ( 10 . 71 , 21 . 17 ) ( 11 . 54 , 17 . 60 ) ( 15 . 94 , 13 . 20 ) ( 15 . 11 , 14 . 03 ) ( 25 . 57 , 0 ) ( 0 , 25 . 57 ) ( a ) Calculating the lengths of shortest paths from start to nodes ( i . e . , ) and from nodes to end ( i . e . , ) inserted column x : indicates the ( current ) due to the inserted column ( x , 0 ) ( 0 , x ) START Ld k END ( 7 . 14 , 24 . 74 ) ( x , 25 . 57 ) ( 10 . 71 , 21 . 17 ) ( 14 . 28 , 17 . 60 ) ( 15 . 11 , 16 . 77 ) ( 15 . 94 , x ) ( x , 14 . 03 ) ( x , 13 . 20 ) ( 10 . 71 , x ) ( 7 . 14 , x ) ( 3 . 57 , x ) ( 11 . 54 , x ) Ld y Ld x 2 the nodes in the inserted column . value becomes invalid corresponding or ( b ) Updating the lengths of shortest paths and corresponding to Figure 4 : The SP - based network construction for the example in Fig - ure 2 ( e . 2 ) . 4 . 2 Consideration of Register Constraint Real processors have a limited number of registers to use for stor - ing temporary data values . Let j R j denote the number of registers available to use for load / store . The limited number of registers im - plies that , for each clock step , the number of data values that have to be placed maximally in registers at that clock step is j R j . Con - sequently , our SP - based approach should take into account the reg - ister constraint . We solve this issue by adjusting the life times of memory access operations so that the SP - based approach generates solutions that are immune to the violation of register constraint . For example , Figure 5 shows a step by step procedure of ad - justing the life times of access operations , initially starting from that in Figure 2 ( b ) , from the ﬁrst clock step to the last . Suppose j R j = 2 and let D i be the set of variables whose life times contain clock step i . Then , since D 1 = f Load i ; Load x ; Load y g ( i . e . , j D 1 j = 3 > j R j = 2 , we select a variable from D 1 and delete it from D 1 to make j D 1 j = j R j = 2 . The variable to be selected is the one with the least urgency in its use . Consequently , the variable selected is Load y because its use is at clock step 7 while the uses of Load i and Load x are at clock steps 2 and 5 , respectively . Fig - ure 5 ( a ) shows the life times updated at clock step 1 from the origi - nal life times in Figure 2 ( b ) . The shaded region indicates the clock step that is immune to the violation of register constraint . Then , the process repeats for the next clock step j at which j D j j > j R j until the region corresponding to the entire clock steps is shaded . Figure 2 ( b ) and ( c ) show the next life time adjustments in a se - quence , and Figures 2 ( d ) shows the ﬁnal adjustment of life times of variables , from which we can apply our SP - based network solution safely with no violation of register constraint . Load i Load a Load x Store index Load k Load y Load i Load a Load x Store index Load y Load k Load i Load temp Store temp Load a Load x Store index Load i Load temp Store temp Load a Load x Store index ( a ) Life time adjustment in clock step 1 Load y Load k Load y Load k ( b ) Life time adjustment in clock step 4 ( c ) Life time adjustment in clock step 5 ( d ) Final result of life time adjustment for | R | = 2 Figure 5 : The stepwise mobility adjustments for satisfying j R j = 2 in Figure 2 ( b ) . 5 . EXPERIMENTAL RESULTS The proposed integrated memory binding and memory access scheduling algorithm MACCESS - lp was implemented in C + + and was executed on an Intel Pentium IV computer . We tested a set of benchmark programs in [ 11 , 12 , 13 ] to demonstrate the effective - ness of the proposed low - energy memory binding and scheduling algorithm . The programs we tested are shown in the ﬁrst column of Table 1 . D IFF is the differential equation solver and D IFF . 2 is the design produced by unrolling D IFF design twice . K ALMAN is the state vector computation part of the Kalman ﬁlter design , EWF is the ﬁfth order elliptic ﬁlter design , and C OMPLEX is the arithmetic part of complex number calculation . G AULEG and G AUJAC , taken from [ 12 ] , are the main routines for Gaussian quadrature . B IQUAD and C HEBEV are taken from DSPstone benchmark suite in [ 13 ] and from [ 12 ] , respectively . (cid:15) The energy - efﬁciency of MACCESS - lp over the conventional approach : Table 1 shows comparisons of the results of energy con - sumption in memories for the designs produced by the conventional technique that binds variables and schedules memory accesses in a greedy manner according to the order of ﬁrst appearance in execu - tion ( indicated as called Greedy in Table 1 ) and our MACCESS - lp . j R j represents the number of registers available to use for data load / store . The last ﬁve columns of the table show , for each de - sign , the reductions of energy consumption used by MACCESS - lp varying the value of j R j over that by Greedy , which is about Greedy MACCESS - lp energy reduction ( % ) design j R j < 5 j R j = 1 j R j = 5 j R j = 4 j R j = 3 j R j = 2 j R j = 1 j R j = 5 j R j = 4 j R j = 3 j R j = 2 D IFF 86 . 34 72 . 64 72 . 64 72 . 64 72 . 64 72 . 64 15 . 87 15 . 87 15 . 87 15 . 87 15 . 87 D IFF . 2 172 . 68 145 . 28 145 . 28 145 . 28 145 . 28 145 . 28 15 . 87 15 . 87 15 . 87 15 . 87 15 . 87 K ALMAN 71 . 98 58 . 28 58 . 28 58 . 28 63 . 76 — 19 . 03 19 . 03 19 . 03 11 . 42 — EWF 240 . 18 196 . 34 196 . 34 196 . 34 — — 18 . 25 18 . 25 18 . 25 — — C OMPLEX 89 . 00 75 . 30 75 . 30 75 . 30 75 . 30 75 . 30 15 . 39 15 . 39 15 . 39 15 . 39 15 . 39 B IQUAD 124 . 70 100 . 04 100 . 04 100 . 04 100 . 04 97 . 30 19 . 78 19 . 78 19 . 78 19 . 78 21 . 97 G AULEG 56 . 12 50 . 64 50 . 64 56 . 12 56 . 12 61 . 60 9 . 76 9 . 76 0 . 00 0 . 00 - 9 . 76 G AUJAC 184 . 80 171 . 1 171 . 1 171 . 1 171 . 1 — 7 . 41 7 . 41 7 . 41 7 . 41 — C HEBEV 40 . 10 31 . 88 31 . 88 31 . 88 31 . 88 40 . 10 20 . 50 20 . 50 20 . 50 20 . 50 0 . 00 average 15 . 76 15 . 76 14 . 68 13 . 28 9 . 89 j R j : The number of registers available to use for load / store . — : indicate an infeasible ( operation ) schedule due to j R j . Table 1 : Comparisons of energy consumptions for the designs produced by a conventional memory binding and access scheduling and our MACCESS - lp . 15 . 76 % less energy consumption when a sufﬁciently large number of registers is available , and 9 . 89 % less energy even when only two registers are used . Note that the energy savings are consistent for all designs we tested . 100 90 80 EWFKalmanComplex ( % ) 1 initial 2 3 4 5 6 iterations energy consumption Figure 6 : Curves showing the reductions of energy saving as the iter - ations MACCESS - lp . (cid:15) The effectiveness of the procedure in MACCESS - lp : The curves in Figure 6 show how well the proposed MACCESS - lp iter - atively improves the designs . For EWF , MACCESS - lp terminates in six iterations whereas for Kalman and Complex , MACCESS - lp terminates in three iterations . On the other hand , Figure 7 shows how much energy saving MACCESS - lp can achieve from the en - ergy consumption at the initial solution and from that by the ex - ecution of MACCESS - lp with the exploitation of memory access scheduling only . In summary , the energy saving by our integrated approach is signiﬁcant , which is about 16 % . (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:0)(cid:1)(cid:0) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:3) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:4) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:6) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:7) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:8) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:10)(cid:1)(cid:10) (cid:11)(cid:1)(cid:11)(cid:12)(cid:1)(cid:12) 100 90 80 0 energy ( % ) consumption initial access scheduling only access scheduling + variable binding EWF Biquad Chebev Kalman Complex Figure 7 : Graph showing the comparisons of energy consumptions used by an initial solution , access scheduling only , and simultaneous access scheduling and variable binding of MACCESS - lp . 6 . CONCLUSIONS In this paper , we presented a new algorithm for reducing the en - ergy consumed by memory accesses via the exploitation of multi - ple memory operating modes in embedded system architecture with multiple memory banks . Speciﬁcally , we addressed the problem of maximally utilizing the operating modes of multiple memory banks by solving the three important tasks simultaneously : ( 1 ) assigning variables to memory banks , ( 2 ) scheduling of memory access op - erations , and ( 3 ) determining operating modes of banks . We con - ﬁrmed from experiments that the proposed SP ( shortest path ) - based integrated technique was able to reduce the energy consumption by 15 . 76 % on the average over the conventional greedy technique . It should be noted that even the proposed SP - based technique as - sumed two memory operating modes in the presentation , it can be easily extended to the case of any m ( > 2 ) operating modes while still maintaining the polynomial - time optimal computation of a - schedule . ACKNOWLEDGEMENT : This work was partially supported by the Korea Science and Engineering Foundation ( KOSEF ) through the Advanced Information Technology Research Center ( AITrc ) , and partially supported by Electronics and Telecommunications Re - search Institute ( ETRI ) . 7 . REFERENCES [ 1 ] A . Sudarsanam and S . Malik , “Simultaneous Reference Allocation in Code Generation for Dual Data Memory Bank ASIPs , ” ACM TODAES , Vol . 5 , 2000 . [ 2 ] J . Cho , Y . Paek , and D . Whalley , “Efﬁcient Register and Memory Assignment for Non - orthogonal Architecture Via Graph Coloring and MST Algorithms , ” ACM Joint Conference LCTES - SCOPES , 2002 . [ 3 ] V . De La Luz , M . Kandemir , and I . Kolcu , “Automatic Data Migration for Reducing Energy Consumption in Multi - Bank Memory Systems , ” DAC , 2002 . [ 4 ] L . Benini , A . Macii , and M . Poncino , “A Recursive Algorithm for Low - Power Memory Partitioning , ” ISLPED , 2000 . [ 5 ] L . Benini , L . Macchiarulo , A . Macii , and M . Poncino , “Layout - driven memory synthesis for embedded systems - on - chip , ” IEEE TVLSI , Vol . 10 , 2002 . [ 6 ] Y - H . Lu , L . Benini , and G . De Micheli , “Low Power Task Scheduling for Multiple Devices , ” International Workshop on Hardware / Software Codesign , 2000 . [ 7 ] V . De La Luz , A . Sivasubramaniam , M . Kandemir , N . Vijaykrishnan and M . J . Irwin , “Scheduler - Based DRAM Energy Management , ” DAC , 2002 . [ 8 ] V . De La Luz , M . Kandemir , N . Vijaykrishnan , A . Sivasubramaniam and M . J . Irwin , “Hardware and Software Techniques for Controlling DRAM Power Modes , ” IEEE TC , Vol . 50 , 2001 . [ 9 ] 128 / 144 - MBit Direct RDRAM Data Sheet , Rambus Inc . , May 1999 . [ 10 ] A . Aho , J . Hopcroft , and J . Ullman , The Design and Analysis of Computer Algorithms , Addison - Wesley , 1974 . [ 11 ] P . R . Panda and N . D . Dutt , “High - Level Synthesis Design Repository” , Proc . of ISSS ( http : / / www . ics . uci . edu / dutt ) , 1995 . [ 12 ] W . H . Press , et al . ( Editors ) , Numerical Recipes in C : The Art of Scientiﬁc Computing , Cambridge University Press , 1993 . [ 13 ] V . Zivojnovic , J . Velarde , and C . Schlager , “Dspstone : A DSP - oriented Benchmarking Methodology , ” International Conference on Signal Processing Applications and Technology , 1994 .