Pattern Classification All materials in these slides were taken from Pattern Classification ( 2nd ed ) by R . O . Duda , P . E . Hart and D . G . Stork , John Wiley & Sons , 2000 with the permission of the authors and the publisher Chapter 7 : Stochastic Methods • Learning – Integral in pattern recognition • General Approach (cid:198) - A model based on parameters - Parameter estimation based on training data • Analytic approaches – Problems in case of multiple maxima ! - Local solns . - Stochastic approaches – Use randomness Ch . 7 - - Topics • Stochastic Search - Simulated Annealing • Bolztmann Learning Physics Based • Genetic Programming Biology Based Pattern Classification , Chapter 7 3 Stochastic Search • Problem Statement : Consider • Magnet Analogy ~ Min energy state (cid:198) Most stable state ! • 2 N – Exhaustive search not possible in general ! • Greedy algorithm ~ Local { } 1 , 1 , − = ∈ B B s n 0 2 1 min arg = − − = ∈ ii T s w Symmetric W Ws s E s Find Pattern Classification , Chapter 7 4 Simulated Annealing ( Physics Motivated ) • Annealing ~ Finding low - energy configuration • Heating the system (cid:198) Increasing randomness (cid:198) Energetically unfavorable state • Temperature is lowered (cid:198) Low energy configuration ! • Attaining optimum configuration ! Pattern Classification , Chapter 7 6 Energy Surfaces Pattern Classification , Chapter 7 7 Boltzmann Factur • Statistical properties at temperature T (cid:198) State γ having energy E ( γ ) ∑ − − = = ξ ξ γ γ T E T E e T Z T Z e P / / ) ( ) ( ) ( Bolzmann factor Partition function Pattern Classification , Chapter 7 8 Stochastic Simulated Annealing • Consider a state change • If energy is lowered (cid:198) Accept this change • If energy is not lowered (cid:198) • Accept this change with prob ~ • Occasional change to higher energy state • Jump out of unacceptable local minima • High temperature (cid:198) Eq . prob . states • Low temperature (cid:198) States with high energy will be preferred less ! • Stop when the system has cooled ( T ~ 0 ) T E ab e / ∆ − 0 / e e T E ab ≈ ∆ − Pattern Classification , Chapter 7 9 Algorithm • Initialize T ( k ) , kmax , W , si , k (cid:197) 0 • k (cid:197) k + 1 • Choose node i randomly . Its state si • If Eb < Ea then si (cid:197) - si Else if exp ( - ( Eb - Ea ) / T ( k ) ) > Rand [ 0 , 1 ) then si (cid:197) - si • Until all nodes polled • Until k = kmax • Return E , s a b j i N j ij a E E s s w E i − = − = ∑ , 2 1 Pattern Classification , Chapter 7 10 Pattern Classification , Chapter 7 11 Pattern Classification , Chapter 7 12 Stochastic Simulated Annealing • Search space – Vertices of a N - dimensional hypercube • Trajectory (cid:198) Along the edges • Slow – Discrete nature of the search • Alternative : States s ε R Pattern Classification , Chapter 7 13 Deterministic Simulated Annealing • Updated value ∑ = = = j j ij i i i i s w l where T l T l f s ) / tanh ( ) , ( Pattern Classification , Chapter 7 14 DSA Algorithm • Initialize T ( k ) , kmax , W , s • k (cid:197) 0 • k (cid:197) k + 1 • Until k = kmax • Return E , s ) ) ( , ( k T l f s s w l i i j N j ij i i = = ∑ Pattern Classification , Chapter 7 15 Boltzmann Learning • How to learn W ? • Network structure – Input & output units • Input units ~ Feature values of input pattern • Output units ~ Category info • Inbetween units ~ Hidden units Pattern Classification , Chapter 7 16 Visible States • Alternative Problem : • Output units : A set of desired probability Q ( α ) • P ( α ) – Actual prob . • Find W such that Q ( α ) matches P ( α ) over a set of patterns • Visible units – Input and output units α • Hidden units – β • E αβ – Energy of the system , Z full partition function ∑ ∑ − = = β β αβ β α α Z T e P P E / ) , ( ) ( Pattern Classification , Chapter 7 17 Learning Visible States • Q ( α ) - P ( α ) (cid:198) Kullback - Leiber distance ( divergence ) • Gradient descent in relative entropy , η ~ Learning rate ) ( ) ( 0 , 0 ) ( ) ( log ) ( ) ) ( ) , ( ( α α χ χ χ α α χ Q P iff D P Q Q P Q D KL KL = = ≥ = ∑ ij ij KL ij w P P Q w D w ∂ ∂ − = ∂ ∂ − = ∆ ∑ χ α α η η ) ( ) ( Pattern Classification , Chapter 7 18 Pattern Classification , Chapter 7 19 Stochastic Learning IO Associations • Network (cid:198) Learn association btw input and output . ( ) CL j i Q j i Q ij KL ij i i i o i i o i o KL i o i o i oCL i o i s s E s s E T w D w P Q Q P Q P D Q P α αα α α η η α α α α α α α α α α α α α α α ) ( ) ( ) ( ) ( log ) ( ) ( ) ) ( ) , ( ( ) ( ) ( 0 0 − = = ∂ ∂ − = ∆ = ≈ ∑ ∑ Pattern Classification , Chapter 7 20 Pattern Classification , Chapter 7 21 Pattern Classification , Chapter 7 22 Deterministic Bolztmann Algorithm • Initialize D , η , T ( k ) , W , s • k (cid:197) 0 • k (cid:197) k + 1 • Randomly select training pattern x • Randomize states si • Anneal network with input and output clamped • @ Tfinal , compute [ si , sj ] with α i α o clamped • Randomize states si • Anneal network with α i clamped • @ Tfinal , compute [ si , sj ] with α i clamped • Until k = kmax • Return W [ ] [ ] [ ] iCL j i oCL i j i ij ij s s s s k T w w α αα η − + ← ) ( Pattern Classification , Chapter 7 23 Network Topology • # of hidden units • # of features and # of categories • Fully connected • Lower connectivity • Upperbound – The size of D data set n • log 2 n units to represent n • Initialization si • If + 1 feature , wij = 1 else wij = - 1 • Weight initialization • Half of them to be + 1 , half to be – • Number of iterations Pattern Classification , Chapter 7 24 Genetic Algorithms – Biology Motivated • Population ~ Several classifiers • Fitness - - Score each classifier and rank them • Survival of the fittest • Next generation ( offspring ) - - Stochastically alter the classifiers • Repeat until some sort of convergence ! Pattern Classification , Chapter 7 25 Basic Genetic Algorithm • Chromosome – Binary string • Mapping from chromosome to the features • Initialize θ , Pc , Pm , L N - bit chromosome • Evaluate f of each chromosome and rank them • Select two chromosomes with the highest score • If Rand [ 0 , 1 ) < Pc then crossover the pair at randomly chosen bit else change each bit with prob Pm • Until fitness > θ Pattern Classification , Chapter 7 26 Genetic Operators • Replication – Reproduced without any change • Crossover – The mixing ( mating ) of two chromosomes • Mutation – Each bit is changed to another value Pattern Classification , Chapter 7 27 Genetic Algorithms • Representation • Selection - Which members get passed on to the next generation ? • Ranking the chromosomes and choosing the fittest ! • Scoring ( Fitness ) Pattern Classification , Chapter 7 28 Genetic Operators Pattern Classification , Chapter 7 29