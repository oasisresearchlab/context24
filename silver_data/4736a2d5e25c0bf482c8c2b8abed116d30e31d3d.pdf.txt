A Survey of Recent Neural Network Models on Code - Mixed Indian Hate Speech Data Suman Dowlagar LTRC , IIIT - Hyderabad India suman . dowlagar @ research . iiit . ac . in Radhika Mamidi LTRC , IIIT - Hyderabad India radhika . mamidi @ iiit . ac . in ABSTRACT In recent years , given the exponential increase in social media content also led to an increase in online hate speech . We need automatic hate speech detection methods due to the volume of data on the web . Various approaches have been proposed to address hate speech and offensive content on social media . This paper surveys how neural - based models have rapidly evolved to address hate speech on multilingual code - mixed data . We discuss the current state of the research in hate speech and offensive language detection on code - mixed Indian datasets . CCS CONCEPTS • Computingmethodologies → Machinelearning ; Neuralnet - works . KEYWORDS Survey , Neural Networks , Hate Speech Detection , Code - Mixing ACM Reference Format : Suman Dowlagar and Radhika Mamidi . 2021 . A Survey of Recent Neural Network Models on Code - Mixed Indian Hate Speech Data . In Forum for Information Retrieval Evaluation ( FIRE 2021 ) , December 13 – 17 , 2021 , Virtual Event , India . ACM , New York , NY , USA , 8 pages . https : / / doi . org / 10 . 1145 / 3503162 . 3503168 1 INTRODUCTION The freedom of speech encouraged users to express and convey their thoughts all across the world in real - time . The misuse of speech often resulted in users posting offensive and abusive content online . At the end of March 2020 , a new trending hashtag 1 emerged on Twitter , blaming a religious sect for the spread of Covid - 19 in India . It had appeared over 300 , 000 times on Twitter by the beginning of April and was potentially seen by 165 million people . These statistics indicate the impact of hate speech on social media . To minimize the impact of hate speech content on social me - dia , interest in automated hate speech detection has continuously grown over the past years . Detecting hate speech is considered 1 https : / / strongcitiesnetwork . org / en / wp - content / uploads / sites / 5 / 2020 / 06 / CoronaJihad . pdf Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India © 2021 Association for Computing Machinery . ACM ISBN 978 - 1 - 4503 - 9596 - 0 / 21 / 12 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3503162 . 3503168 an essential aspect on social media platforms to discourage any unlawful activities . Due to their large - scale availability , the research related to hate speech has focused mainly on monolingual texts [ 33 , 46 ] . However , in several multilingual communities , it is common for speakers to use multilingual and code - mixed utterances . As in a multilingual society , language diversity and dialect changes instigate frequent code - mixing . Multilingualism and other mixed - speech forms have become increasingly common in urban and rural populations and formal and informal contexts . When two individuals who are bi - or multilingual in an overlapping set of languages communicate , they tend to switch seamlessly and effortlessly between the languages ( codes ) they share . When this code alternation occurs at or above the utterance level , the phenomenon is called code - switching ; when the alternation is utterance internal , code - mixing is common . Code - mixing happens when truly bi - lingual individuals are creating new meanings based on their complete and double language repertoire [ 25 ] . In order to encourage the work on code - mixed hate speech detection , new datasets have come to light , such as Hindi - English [ 3 , 24 ] , code - mixed datasets developed for Tamil , Malayalam , and Kannada languages [ 4 , 5 ] . In recent years , neural network - based models have achieved state of the art for a wide range of natural language processing tasks . Various neural architectures have experimented on hate speech detection , including RNN [ 18 ] , CNN [ 22 ] , transformer [ 11 ] models . Even models specific to code - mixing [ 12 ] and hate - speech identifi - cation [ 8 ] have come up . Such progress allows better addressing of hate - speech detection . We think that a survey on hate speech code - mixed models can be useful for researchers and practitioners on multilingual and code - mixed hate speech . The survey’s primary goal is to give a broad overview of recent neural models applied for hate speech on code - mixed data . The paper is structured as follows : Section 2 describes the related surveys on code - mixed hate speech detection . Section 3 provides the commonly used datasets in our tasks . Section 4 presents the models developed on these datasets and discusses the performance of existing models . Section 5 concludes our work . 2 HATE SPEECH DETECTION This section provides some terminology relevant to hate speech detection , the scope of the survey , and details the existing surveys on hate speech detection for code - mixed datasets . 2 . 1 Terminology By definition , hate speech is usually thought to include communi - cations of animosity or disparagement of an individual or a group 67 FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Suman Dowlagar and Radhika Mamidi on account of a group characteristic such as race , color , national origin , sex , disability , religion , or sexual orientation . Hate speech is considered as an umbrella term for abusive mes - sages , hostile messages [ 42 ] , cyberbullying [ 37 , 43 ] , insults , profan - ity , and malicious comments [ 41 ] , offensive language [ 9 , 27 , 39 ] , abusive language [ 30 , 31 ] , Sexism [ 13 , 19 ] , Online Harassment [ 16 ] and Toxicity [ 47 ] . 2 . 2 Scope of survey With the growing multilingualism and with the increased use of code - mixed text on social media , we decided to focus on code - mixed hate speech detection . In our survey , we generalize several recent machine learning and neural network methods modeled for detecting hate speech on code - mixed text . We focus on the methods that work at the comment or post level and classify the text as hate speech or not . We also present the approaches that try to handle multilingualism and spelling and grammar variations that are present in the code - mixed multilingual text and their impact on identifying the hate speech text . 2 . 3 Challenges of Code - Mixed Hate speech detection 2 . 3 . 1 Variations in spelling and script . The code - mixed social media dataset is mostly written in roman script . Most of the words in the code - mixed are morphed , such as " tliva ( Written in Tamil , in English , it means leader ) " . Even the hate speech words are also morphed , such as " chu " , " chu * * ya " ( written in Hindi , an abusive hate word ) . Sometimes these words are even indistinguishable by human annotators [ 29 ] . Handling such words make the process of automated hate speech detection a challenging task . 2 . 3 . 2 Analysis of code - mixed words . Code - mixing is a recent topic , with limited analysis on the nature of code - mixing . The code - mixed data is of low resource and the models the understand the code - mixed datasets are still under improvement . Such tasks include language identification , Part of Speech tagging , Shallow Parsing , Named Entity Recognition , etc . An improvement in such tasks can help in syntactic and semantic analysis of the code - mixed dataset and can help in improving the code - mixed hate speech detection . 2 . 3 . 3 Contextual Hate or Indirect Hate . Some comments require a deep context to understand if they are identified as hate or not . Such comments are often sarcastic or humorous and pose as " not - offensive " to the models . Capturing this implicit nature of speech via contextual models has not yet been modeled before . The sar - casm and contextuality for hate speech detection make this task challenging . 2 . 3 . 4 Lack of hate speech lexicon . Out of all the datasets used in the survey , we have seen that only one dataset has a profane word list [ 29 ] . A well - formed lexicon on the given hate speech datasets capture indirect hate words / phrases which can help the automated hate speech detection . This initiates the need to create more hate speech lexicon on the given datasets . Creating a lexicon helps in improved hate speech detection and can point the models towards aspect - based automated hate speech detection . 2 . 4 Related Work In the survey by Anna Schmidt and Michael Wiegand [ 38 ] , the authors provide a short and significant overview of the field of automatic hate speech detection in natural language processing . Initially , they present the definition and terminology necessary for studying hate speech . They analyze the features used for hate speech detection such as simple surface - level features , such as the bag of words or n - grams , generalizing words using word clusters , Sentiment Analysis as negative sentiment indicates hate speech , lexical dictionaries that contain hate speech terms , syntactic and semantic features , knowledge bases , multimodal features , and meta information . They also present a section dedicated to classification methods , challenges , and another about data . In the survey by Paula Fortuna and Sérgio Nunes [ 14 ] , the au - thors present detailed definitions of hate speech on various so - cial media websites such as Youtube , Facebook , Twitter . They also present different terminology on hate speech . They focus on descrip - tive statistics about hate speech detection . They present generic text mining features " and the " specific hate speech detection features " and conclude that the latter is essential for hate speech detection . The survey by Areej Al - Hassan and Hmood Al - Dossari on De - tection of hate speech in social networks on multilingual corpus [ 1 ] presented a background on hate speech and its related detection approaches . The paper mostly talks about the challenges and rec - ommendations for Arabic hate speech detection . They also present the results on the available multilingual corpus for hate speech and conclude by saying that deep learning features such as RNN and CNN are widely used for hate speech detection . The first survey on code - mixed hate speech detection was con - ducted by Priya et . al [ 34 ] . They presented a study on different hate speech detection methods for the Hindi - English code - mixed corpus . They point out that hate speech can be in code - mixed form too . And the challenges of code - mixed dataset such as spelling and grammar variations makes the task of hate speech detection a difficult task . They present a new annotated code - mixed Hindi - English dataset for hate speech detection . This paper talks about the performance of different machine learning and deep learning classifiers on the three different Hindi - English code - mixed data sets . The paper by Priya et al . [ 34 ] conducted the hate speech detection by focussing only on the code - mixed Hindi - English dataset . Down the line , we have come across new hate speech datasets Hindi - English code - mixed hate speech datasets [ 20 , 28 ] and Dravidian language code - mixed hate speech datasets [ 4 , 6 ] . We also came across advanced machine learning algorithms such as transformers [ 11 ] , graph convolutional neural networks [ 8 ] for detecting hate speech . We also came across some specific methods that address the code - mixed dataset challenges and how to handle the script variations and imbalanced datasets for hate speech detection [ 12 ] . We analyze the above models and compare them with the traditional machine learning approaches . We also emphasize that hate speech is a complex and challenging topic that needs additional language processing and analysis . 3 DATASETS This section lists available hate speech detection datasets where each comment or post is assigned to a label . 68 A Survey of Recent Neural Network Models on Code - Mixed Indian Hate Speech Data FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Table 1 : Dataset Statistics Dataset No . of comments Labels Dravidian Languages - EACL 2021 Malayalam - English dataset [ 7 ] 20 , 010 Not Offensive , Offensive Untargeted , Offensive Targeted Individual , Offensive Targeted Group , Offensive Targeted Other , Not Malayalam . HASOC - DravidianCodeMix Malayalam - English dataset [ 4 ] 5 , 000 Not Offensive , Offensive Dravidian Languages - EACL 2021 Tamil - English dataset [ 7 ] 43919 Not Offensive , Offensive Untargeted , Offensive Targeted Individual , Offensive Targeted Group , Offensive Targeted Other , Not Tamil . HASOC - DravidianCodeMix Tamil - English dataset [ 4 ] 4 , 000 Not Offensive , Offensive Dravidian Languages - EACL 2021 Kannada - English dataset [ 17 ] 7772 Not Offensive , Offensive Untargeted , Offensive Targeted Individual , Offensive Targeted Group , Offensive Targeted Other , Not Kannada . Bohra Hindi - English Code - Mixed dataset [ 3 ] 4575 no , yes HEOT ( Hindi - English Offensiv Tweet ) dataset [ 29 ] 3679 nonoffensive , abusive , hate - speech Malayalam - English . This dataset is obtained from 2 shared tasks : Of - fensive Language Identification in Dravidian Languages - EACL 2021 [ 7 ] , and HASOC - DravidianCodeMix [ 4 ] . These tasks aim to identify offensive language from a code - mixed dataset of comments / posts in social media . The dataset contains all types of code - mixing , such as inter - and intra - sentential . The mixing even happens at the script level , where some comments are written in Malayalam script , and the others are in roman script . The details of the dataset are given in table 1 . Tamil - English . This dataset is obtained from the shared task : Offen - sive Language Identification in Dravidian Languages - EACL 2021 [ 7 ] , and HASOC - DravidianCodeMix [ 4 ] . The Tamil - English code - mixed dataset was collected from tweets and comments . This dataset has comments / posts in roman characters . The statistics of the dataset are given in table 1 . Kannada - English . The dataset is obtained from the paper “KanCMD : Kannada CodeMixed Dataset for Sentiment Analysis and Offen - sive Language Detection " . [ 17 ] . The dataset is collected from 18 youtube videos on different topics ranging from movie trailers , current trends about the ban on mobile apps in India , India - China border issue , Mahabharata , and Transgenders . The data was col - lected between February 2020 and August 2020 . The statistics of the dataset are given in table 1 . Bohra Hindi - Engish . The paper [ 3 ] created a corpus on hate - speech Hindi - English Code - mixed data . For each word , a language iden - tification tag was assigned . The tags were ’eng’ , ’hin’ and ’other’ . ’eng’ , ’hin’ tag was assigned to words that are present in the Eng - lish language and the Hindi languages , respectively . The ’other’ is assigned to symbols , emoticons , hashtags , punctuations , named entities , and URLs . The data statistics are given in table 1 . HEOTHindi - English . Thepaper [ 29 ] introducedanoveltweetdataset , Hindi - English Offensive Tweet ( HEOT ) dataset . It consists of tweets in Hindi - English code switched language split into three classes . The data statistics are given in table 1 . 4 SUPERVISED AUTOMATED HATE SPEECH DETECTION ON CODE - MIXED DATA This section presents the task definition , the evaluation metrics , and the models used for automated hate speech detection on Code - Mixed ( CM ) data . 4 . 1 Task Definition We formulate the automated hate speech detection task as follows . Given an input sentence ( either post or comment ) x = ( x 1 , x 2 , . . , x T ) , hate speech detection is defined as classification over utterances , where the system has to assign the correct label y indicating the comment is hate speech or not for the whole sentence x . Most machine learning approaches generally learn a probabilistic model to estimate p ( y | x , θ ) where θ is the model’s parameter . 4 . 2 Evaluation Metrics For the hate speech detection task , evaluation is performed on the comment / post level . The typical evaluation metric for this task is the weighted F1 - score . The F1 - score is the harmonic mean score between precision and recall . Precision is the percentage of correct predictions from the model , while recall is the percentage of correct predictions in the corpus that the model finds . In weighted F1 , the F1 Scores are calculated for each label , and then their average is weighted by the number of samples from that class . It is intended to be used for emphasizing the importance of some samples w . r . t . the others . The hyper - parameters , the choice of embeddings , and the design of models were followed the same as given in the papers . Even though some models were designed only for some datasets , we reproduced the experiments for all the datasets for better compari - son . The neural network models were developed using Python 3 . 6 69 FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Suman Dowlagar and Radhika Mamidi environment using Pytorch , torchtext 2 , and transformer 3 libraries . We used the NVIDIA RTX 2070 graphics card with an 8GB GPU memory and google colab notebooks to run our models for hate speech detection tasks . 4 . 3 RNN models Recent neural models typically used RNN as the building block for hate speech detection . At each time step t , the encoder transforms the word representation x t to the hidden state h t . For hate speech detection , the last hidden state h T is used to predict the label y of the comment x . [ 21 , 45 ] used both basic unidirectional LSTM model and Bi - directional LSTM models for hate speech detection . Out of which , the Bi - directional LSTM produced better results . The input embed - dings are passed through the LSTM layer . Next , the output of the LSTM layer , i . e . , the hidden states , is given as an input to the global max - pooling layer or a dense layer . Lastly , the resulting output from the pooling layer is passed through the sigmoid activation function to give a final prediction . The proposed model was run on [ 3 , 4 ] . [ 45 ] presented an attention - based bi - directional LSTM model . The model uses an embedding Layer followed by two layers of Bidirectional LSTM’s . The output of Bi - LSTM is passed through the Hierarchical Attention Layer followed by a Dense layer with ReLU activation , and finally , by a Dense Layer with Sigmoid activation . The model was run on [ 4 ] . Performance of RNN variants on CM datasets is given in table 2 4 . 3 . 1 Analysis of RNN models . From the above table 2 , we can see that the [ 45 ] with Attention performed better on the given CM datasets when compared to the other RNN models . It is due to the presence of an attention mechanism in the model . The attention mechanism identified the key terms / phrases in the given sentence of the dataset that helped the model to perform better when com - pared to the other Models . On the Bohra Hi - En dataset , we have seen that the model mistagged most of the hate speech " yes " labels as " no " . It is due to the overfitting of high - frequency " no " labels in the dataset , the complex nature of the code - mixing in the dataset , and the presence of sarcastic comments . The model mostly per - formed better on the HEOT dataset with 85 % accuracy . We have observed that the model showed a little confusion between the true label " Hate - inducing " and predicted them as " Non - offensive " or " Abusive " . It is due to the imbalance present in the dataset , which made the model tune towards the high - frequency " Non - offensive " or " Abusive " labels . One of the main reasons the model performed better was that the dataset was collected by crawling the hate speech keywords . These keywords helped the model to perform better when neural networks were used . The HASOC CodeMix Tamil and EACL Malayalam datasets effectively understood the key phrases that identify the hate speech in the dataset . Hence they performed better on the given models . Whereas the other models , HASOC CodeMix Malayalam , EACL Tamil , and Kannada datasets , had many variations in spelling in the code - mixed content , the data imbalance issues resulted in decreased performance of the given RNN models on the dataset . 2 https : / / pytorch . org / text / stable / index . html 3 https : / / huggingface . co / transformers / 4 . 4 CNN models Traditionally , CNNs use filters ( also called kernels or receptive fields ) to scan a sentence and extract features from the sentence . This convolved text can be fed into another convolutional layer or a linear layer . The intuition here is that the appearance of certain bi - grams , tri - grams , and n - grams within the review will be a good indication of the final sentiment . [ 21 ] presented a CNN model . In this model , the embedded in - put is fed to 3 convolutional filters . The filters convolve over the embeddings and produce the feature maps . Following this , global - MaxPooling has a dropout probability of 0 . 5 . Then , the results are concatenated to form a single feature vector . Finally , the feature vector is passed through sigmoid activation to produce our final results . The proposed model was run on [ 3 ] . [ 50 ] proposed a CNN model that uses three different convolu - tional layers , with the filters of kernel sizes 3 , 4 , 5 , connected to the embedding layer . The output of each layer is connected and then passed to a global maximum pool layer , followed by two dense lay - ers . The idea behind using several filter sizes is to capture contexts of varying lengths . The convolution layer extracts local features around each word window , while the global maximum pool layer extracts the essential features in the feature map . [ 23 ] proposed two parallel CNN networks . One CNN model uses a character embedding matrix , and the other one uses a word embedding matrix . Two layers of CNN are used to process the char - acter embedding matrix . Similarly , to process the word embedding matrix , two layers of CNN in used . In the next step , the flattened vectors from both the parallel CNN networks are concatenated and passed to a dense layer . Finally , the output of the dense layer is passed to a softmax layer to get its class probability . 4 . 4 . 1 Analysis of CNN models . The [ 50 ] CNN model performed better on the given datasets . It is due to the use of various filters of kernel length 3 , 4 , 5 . They were effective enough to extract key features and differentiate between hate speech and not - hate speech comments when compared to other CNN models . The CNN mod - els also performed better when compared to RNN models because of the convolution methods used in these models . They extracted effective features using convolutions in the text that helped the automated hate speech detection rather than establishing long - term dependencies ( from RNN models ) in the dataset . During in - depth analysis of each dataset , we saw that the Bohra Hi - En dataset mis - classified most of the true " yes " labels as " no " and showed similar results to RNN models . The CNN models were also unable to decode the code - mixing in the data , resulting in decreased performance of the models . The HEOT dataset performed better on CNN models too . The dataset was collected by crawling through the profane words . These profane words helped in better identification of hate speech in the data . Similar to RNN , we have seen that the model confused between the true label " Hate - inducing " and predicted them as " Non - offensive " or " Abusive " . It is due to the bias present in the dataset , where most of the comments were tagged as ei - ther " Non - offensive " or " Abusive " . The bias made the CNN model fine - tune more towards these labels , thus resulting in decreased performance for the given " Hate - inducing " label . The CNN models also performed better on the HASOC CodeMix Tamil and EACL Malayalam datasets . The convolutions helped the model to capture 70 A Survey of Recent Neural Network Models on Code - Mixed Indian Hate Speech Data FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Table 2 : Weighted - F1 score for RNN variants on CM datasets Dataset / Models BohraHi - En HEOT HASOCCodeMix 2020 Tamil - En HASOCCodeMix 2020 Mal - En Dravidian - langTamil - En Dravidian - langMal - En Dravidian - lang Kannada - En [ 21 ] Bi - LSTM 80 . 43 81 . 23 83 . 81 67 . 12 68 . 25 85 . 19 51 . 99 [ 45 ] Bi - LSTM without At - tention 79 . 14 80 . 27 83 . 73 75 . 39 67 . 29 85 . 28 47 . 17 [ 45 ] Bi - LSTM with Atten - tion 80 . 52 82 . 19 86 . 11 77 . 21 68 . 55 86 . 35 52 . 43 Table 3 : Weighted - F1 score for CNN variants on CM datasets dataset / models BohraHi - En HEOT HASOCCodeMix 2020 Tamil - En HASOCCodeMix 2020 Mal - En Dravidian - langTamil - En Dravidian - langMal - En Dravidian - lang Kannada - En [ 21 ] CNN with max - pooling 80 . 85 82 . 21 83 . 76 67 . 38 73 . 28 94 . 51 67 . 75 [ 50 ] CNN different filters with max - pooling 81 . 82 82 . 27 74 . 18 68 . 39 83 . 91 94 . 67 67 . 79 [ 23 ] character and word based CNN 72 . 27 75 . 12 69 . 49 59 . 85 65 . 34 88 . 94 62 . 15 the data better when compared to the RNN models on these datasets . The variations in spelling in code - mixing and imbalance created due to Whereas the other datasets , HASOC CodeMix Malayalam , EACL Tamil , and Kannada datasets , had many variations in spelling in the code - mixed content , the data imbalance issues resulted due to the presence of high " Not - offensive " labels , made the data fine - tune towards them thus decreased performance of the given CNN models on the dataset . 4 . 5 Transformer Models A transformer [ 44 ] is a deep learning model that adopts the mech - anism of Attention . The crucial layers in the transformer model are self - attention and a feed - forward neural network . The trans - former consists of a series of self - attention , feed - forward networks , and layer normalizations to encode the given input sentence . They have achieved great results in text classification and other natural language processing tasks [ 11 ] . [ 15 , 48 ] used mBERT , a pre - trained multilingual BERT base model [ 10 ] . BERT uses a transformer [ 44 ] , multi - headed attention with a point - wise feed - forward network , to learn contextual relations between words ( or sub - words ) in a text . [ 12 , 26 ] used a multilingual BERT ( mBERT ) transformer model with the class balanced loss for offensive content identification . They solved the class - imbalance problem that existed in the training data by class weights and class combination . [ 26 , 49 ] used XLM - Roberta , a transformer - based language model similar to BERT . It relies on the Masked Language Model objective and is capable of processing text from 100 separate languages . The XLM - R model has been effective in cross - lingual and multilingual tasks and provided competitive results w . r . t the BERT model . Along with XLM - R model [ 49 ] used DPCNN , a . k . a Deep Pyramid Convo - lutional Neural Networks . DPCNN is a deep convolutional neural network developed to capture global representations of text . The proposed DPCNN has 15 weight layers . [ 35 ] presented an exhaustive exploration of different transformer models . They provided a genetic algorithm technique for ensem - bling different models . Genetic algorithms ( GA ) are used to optimize the weights of different classifiers , to improve the ensemble perfor - mance on the development set . The proposed CNN + XLMR - base + XLMR - C and CNN + XLMR - C + mBERT - base performed the best on the given code - mixed datasets where XLMR - C refers to custom - pre - trained XLM - Roberta - Base Classifier . 4 . 5 . 1 Analysis of Transformer Models . The transformer models performed better than the CNN and RNN models on the given datasets . It is due to the SOTA architecture of multi - headed Atten - tion present in those models . The SOTA architecture helped the model to understand the complex code - mixed sentences . The Ge - netic Algorithms [ 35 ] created a meta - learning scenario that helped the model to fine - tune more on the given code - mixed data . Upon in - depth analysis for each dataset , we have seen that , for the Bohra Hi - En dataset , the misclassifications between the true label " yes " are moderately resolved when compared to RNN and CNN mod - els . The model also performed better on the HEOT dataset . Even the " Hate - inducing " tag is correctly classified for most of the in - stances using these models . The Genetic Algorithms have also performed better on the HASOC CodeMix Tamil and EACL Malay - alam datasets when compared to the CNN and RNN models . The algorithm has correctly identified most of the " HATE " and " NOT " labels in these datasets . Similar to RNN and CNN models , the given transformer model was over - tuned on EACL Tamil , Kannada , and 71 FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Suman Dowlagar and Radhika Mamidi Table 4 : Weighted - F1 score for BERT variants on CM datasets dataset / models BohraHi - En HEOT HASOCCodeMix 2020 Tamil - En HASOCCodeMix 2020 Mal - En Dravidian - langTamil - En Dravidian - langMal - En Dravidian - lang Kannada - En [ 15 , 48 ] mBERT - base 70 . 55 85 . 64 87 . 74 74 . 13 75 . 19 94 . 63 72 . 13 [ 12 , 26 ] mBERT - base with class - balanced loss 70 . 49 84 . 23 87 . 19 73 . 76 74 . 38 92 . 67 67 . 11 [ 26 , 49 ] XLM - Roberta 71 . 84 84 . 29 87 . 18 73 . 54 74 . 34 93 . 21 71 . 50 [ 35 ] Genetic algorithms 70 . 85 85 . 77 88 . 10 74 . 56 77 . 18 93 . 65 73 . 17 HASOC Malayalam datasets . The complexities due to code - mixing in the given data decreased the performance of the transformer models . Class - balanced losses didn’t benefit the data , indicating that more research is necessary on adjusting the class - balance weights . 4 . 6 Models that Pre - process Code - Mixed Data Pre - trained models achieved great performance in dealing with code - mixed data [ 2 , 4 , 7 ] . But the pre - trained models and pre - trained embeddings are mostly trained on cross - lingual and monolingual tasks . They are not designed for code - mixed datasets . We take advantage of those pre - trained models by converting the code - mixed data to its respective high resource languages . [ 32 ] proposed converting the code - switched data written in the Roman script into its constituent high resource languages . The paper used language identification and transliteration followed by fine - tuning monolingual and cross - lingual contextual word embed - dings . The language models used are ULMFiT , ROBERTa , XLM - ROBERTa . Out of which , XLM - ROBERTa performed the best . [ 12 , 36 ] presented a technique of selective translation and translit - eration to deal with codemixed and romanized offensive speech classification in Dravidian languages . In this method , the native words present in the Roman script were transliterated to the native language words , and the English words in the text were translated to the matrix language in the code - mixed sentence selectively . They have used googletrans 4 API and NLTK 5 toolkit for this purpose . The modified code - mixed dataset is given to multilingual BERT and its variants for hate speech detection . [ 12 ] , identified that the mBERT models support a multilingual vocabulary . There is no need to translate the English words to the na - tive script . They presented a similar technique of selective translit - eration , i . e . , by transliterating only the code - mixed roman words to their native script . They have used ai4bharattransliteration 6 library for transliteration . The transliterated code - mixed dataset is given to mBERT and its ensembles for hate speech detection . [ 40 ] also used random transliteration and data augmentation to preprocess the code - mixed data . 4 . 6 . 1 Analysis of pre - processed CM methods . As coined by [ 12 , 32 , 36 ] , the use of linguistic resources in pre - processing of code - mixed data helped the models to distinguish between the English 4 https : / / pypi . org / project / googletrans / 5 https : / / www . nltk . org / 6 https : / / pypi . org / project / ai4bharat - transliteration / words present in the Roman script and the Native " Indian " words . The transliteration helped resolve the complexities present due to script changes in the data . The transliteration helped the multilin - gual models improve their performance on the given code - mixed datasets compared to Native models . All the transliteration models used transformer approaches , and all of them performed better on the code - mixed datasets when compared to the RNN , CNN , and BERT ensembles . The model didn’t perform better on the EACL Kannada CM dataset . We have observed that the transliteration on the Kannada dataset is not refined . The use of incorrect translitera - tion , and the presence of more spelling variations in the Kannada CM data , deteriorated the performance of the model on the given dataset . We can see improved performance for the Kannada CM dataset [ 40 ] pre - processed CM + Data Augmentation + mBERT model because there were instances where the augmented dataset consisted of both Roman script and transliterated sentences . The roman script helped the data to achieve better results even though the transliteration was incorrect . 4 . 7 Models considering hate speech features [ 29 ] maintained a hate speech lexicon dataset that contains a list of profane words for hate speech detection . [ 8 ] used the profanity word list and constructed a profanity vector . A one - hot representa - tion of profanity word list is maintained for each tweet , wherein 1 indicates the presence of a particularly bad word while its ab - sence is indicated by 0 . This vector is concatenated with each tweet embedding of the actual model . The model uses graph convolu - tional networks ( GCN’s ) for hate speech detection . In Graph neural networks , we construct a heterogeneous graph and apply neighbor - hood convolutions . The GCN’s performed competitively to RNN and CNN models . 4 . 7 . 1 Analysis of models that consider hate speech features . The profane word list helped the dataset to perform similar to the trans - former models . We cannot see the performance of the other datasets on the given model , as there was no annotation of hate speech key - words present on these models . 5 CONCLUSION We have surveyed recent neural - based models that are implemented for hate speech detection in the context of code - mixed datasets . We 72 A Survey of Recent Neural Network Models on Code - Mixed Indian Hate Speech Data FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Table 5 : Weighted - F1 score on pre - processed CM datasets dataset / models BohraHi - En HEOT HASOCCodeMix 2020 Tamil - En HASOCCodeMix 2020 Mal - En Dravidian - langTamil - En Dravidian - langMal - En Dravidian - lang Kannada - En [ 32 ] pre - processed CM + ULMFiT + ROBERTa + XLM - ROBERTa 71 . 91 86 . 24 92 . 17 73 . 61 75 . 37 96 . 54 65 . 18 [ 36 ] pre - processed CM + XLM - ROBERTa 71 . 83 86 . 45 93 . 64 73 . 58 75 . 43 96 . 67 65 . 47 [ 12 ] pre - processed CM + mBERT 71 . 84 86 . 44 93 . 52 73 . 69 75 . 29 96 . 46 65 . 39 [ 40 ] pre - processed CM + Data Augmentation + mBERT 71 . 78 86 . 92 86 . 54 72 . 51 75 . 14 95 . 23 72 . 81 Table 6 : Weighted - F1 score considering hate speech features dataset / CNN models BohraHi - En HEOT HASOCCodeMix 2020 Tamil - En HASOCCodeMix 2020 Mal - En Dravidian - langTamil - En Dravidian - langMal - En Dravidian - lang Kannada - En [ 8 ] GCN with profanity word vector - 85 . 71 - - - - - examined seven code - mixed datasets that were developed on 4 In - diancode - mixedlanguages Hindi - English , Tamil - English , Malayalam - English , Kannada - English . The models used RNN , CNN , trans - former architectures . A few methods used pre - processing steps on the code - mixed dataset . And a few models used hate speech lexicon sources . The models tailored on processing the code - mixed data and hate speech lexicon sources showed relatively better per - formance than the others . Empirical results have shown that pre - trained multilingual transformer models with selective translation and transliteration achieved the best results compared to other mod - els . Nevertheless , the code - mixed hate speech dataset has several challenges , such as the implicit nature of comments and variations in spelling and grammar , making code - mixed hate speech detection a challenging task . In this survey , we presented the Analysis of the general neural network Models that performed better on the given datasets . There might be some variants of the given models present , which were not included in the paper . REFERENCES [ 1 ] Areej Al - Hassan and Hmood Al - Dossari . 2019 . Detection of hate speech in social networks : a survey on multilingual corpus . In 6th International Conference on Computer Science and Information Technology , Vol . 10 . [ 2 ] Shubhanker Banerjee , Bharathi Raja Chakravarthi , and John P McCrae . 2020 . Comparison of pretrained embeddings to identify hate speech in Indian code - mixed text . In 2020 2nd International Conference on Advances in Computing , Communication Control and Networking ( ICACCCN ) . IEEE , 21 – 25 . [ 3 ] Aditya Bohra , Deepanshu Vijay , Vinay Singh , Syed Sarfaraz Akhtar , and Manish Shrivastava . 2018 . A dataset of Hindi - English code - mixed social media text for hate speech detection . In Proceedings of the second workshop on computational modeling of people’s opinions , personality , and emotions in social media . 36 – 41 . [ 4 ] Bharathi Raja Chakravarthi , Anand Kumar M , John P McCrae , B Premjith , KP Soman , and Thomas Mandl . 2020 . Overview of the track on HASOC - Offensive Language Identification - DravidianCodeMix . . In FIRE ( Working Notes ) . 112 – 120 . [ 5 ] Bharathi Raja Chakravarthi and Vigneshwaran Muralidaran . 2021 . Findings of the Shared Task on Hope Speech Detection for Equality , Diversity , and Inclusion . In ProceedingsoftheFirstWorkshoponLanguageTechnologyforEquality , Diversity and Inclusion . Association for Computational Linguistics , Kyiv , 61 – 72 . https : / / www . aclweb . org / anthology / 2021 . ltedi - 1 . 8 [ 6 ] Bharathi Raja Chakravarthi , Ruba Priyadharshini , Navya Jose , Anand Kumar M , Thomas Mandl , Prasanna Kumar Kumaresan , Rahul Ponnusamy , Hariharan R L , John P . McCrae , and Elizabeth Sherly . 2021 . Findings of the Shared Task on Offensive Language Identification in Tamil , Malayalam , and Kannada . In Pro - ceedings of the First Workshop on Speech and Language Technologies for Dra - vidian Languages . Association for Computational Linguistics , Kyiv , 133 – 145 . https : / / aclanthology . org / 2021 . dravidianlangtech - 1 . 17 [ 7 ] Bharathi Raja Chakravarthi , Ruba Priyadharshini , Navya Jose , Thomas Mandl , Prasanna Kumar Kumaresan , Rahul Ponnusamy , RL Hariharan , John Philip Mc - Crae , Elizabeth Sherly , et al . 2021 . Findings of the shared task on offensive language identification in Tamil , Malayalam , and Kannada . In Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages . 133 – 145 . [ 8 ] Shivang Chopra , Ramit Sawhney , Puneet Mathur , and Rajiv Ratn Shah . 2020 . Hindi - english hate speech detection : Author profiling , debiasing , and practical perspectives . In Proceedings of the AAAI Conference on Artificial Intelligence , Vol . 34 . 386 – 393 . [ 9 ] Thomas Davidson , Dana Warmsley , Michael Macy , and Ingmar Weber . 2017 . Automated hate speech detection and the problem of offensive language . In ProceedingsoftheInternationalAAAIConferenceonWebandSocialMedia , Vol . 11 . [ 10 ] Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2018 . Bert : Pre - trainingofdeepbidirectionaltransformersforlanguageunderstanding . arXiv preprint arXiv : 1810 . 04805 ( 2018 ) . [ 11 ] Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . BERT : Pre - training of Deep Bidirectional Transformers for Language Understanding . In Proceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociation for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) . 4171 – 4186 . [ 12 ] SumanDowlagarandRadhikaMamidi . 2021 . OFFLangOne @ DravidianLangTech - EACL2021 : Transformers with the Class Balanced Loss for Offensive Language Identification in Dravidian Code - Mixed text . . In Proceedings of the First Workshop 73 FIRE 2021 , December 13 – 17 , 2021 , Virtual Event , India Suman Dowlagar and Radhika Mamidi on Speech and Language Technologies for Dravidian Languages . 154 – 159 . [ 13 ] Elisabetta Fersini , Paolo Rosso , and Maria Anzovino . 2018 . Overview of the Task on Automatic Misogyny Identification at IberEval 2018 . IberEval @ SEPLN 2150 ( 2018 ) , 214 – 228 . [ 14 ] Paula Fortuna and Sérgio Nunes . 2018 . A survey on automatic detection of hate speech in text . ACM Computing Surveys ( CSUR ) 51 , 4 ( 2018 ) , 1 – 30 . [ 15 ] Nikhil Ghanghor , Parameswari Krishnamurthy , Sajeetha Thavareesan , Ruba Priyadharshini , and Bharathi Raja Chakravarthi . 2021 . IIITK @ DravidianLangTech - EACL2021 : Offensive Language Identification and Meme Classification in Tamil , Malayalam and Kannada . In Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages . 222 – 229 . [ 16 ] Jennifer Golbeck , Zahra Ashktorab , Rashad O Banjo , Alexandra Berlinger , Sid - dharth Bhagwan , Cody Buntain , Paul Cheakalos , Alicia A Geller , Rajesh Kumar Gnanasekaran , Raja Rajan Gunasekaran , et al . 2017 . A large labeled corpus for online harassment research . In Proceedings of the 2017 ACM on web science conference . 229 – 233 . [ 17 ] Adeep Hande , Ruba Priyadharshini , and Bharathi Raja Chakravarthi . 2020 . KanCMD : Kannada CodeMixed dataset for sentiment analysis and offensive language detection . In Proceedings of the Third Workshop on Computational Mod - eling of People’s Opinions , Personality , and Emotion’s in Social Media . 54 – 63 . [ 18 ] SeppHochreiterandJürgenSchmidhuber . 1997 . Longshort - termmemory . Neural computation 9 , 8 ( 1997 ) , 1735 – 1780 . [ 19 ] Akshita Jha and Radhika Mamidi . 2017 . When does a compliment become sexist ? analysis and classification of ambivalent sexism using twitter data . In Proceedings of the second workshop on NLP and computational social science . 7 – 16 . [ 20 ] Navya Jose , Bharathi Raja Chakravarthi , Shardul Suryawanshi , Elizabeth Sherly , and John P . McCrae . 2020 . A Survey of Current Datasets for Code - Switching Research . In 2020 6th International Conference on Advanced Computing and Com - munication Systems ( ICACCS ) . 136 – 141 . https : / / doi . org / 10 . 1109 / ICACCS48705 . 2020 . 9074205 [ 21 ] Satyajit Kamble and Aditya Joshi . 2018 . Hate speech detection from code - mixed hindi - english tweets using deep learning models . arXiv preprint arXiv : 1811 . 05145 ( 2018 ) . [ 22 ] Yoon Kim . 2014 . Convolutional Neural Networks for Sentence Classification . In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) . Association for Computational Linguistics , Doha , Qatar , 1746 – 1751 . https : / / doi . org / 10 . 3115 / v1 / D14 - 1181 [ 23 ] Abhinav Kumar , Sunil Saumya , and Jyoti Prakash Singh . 2020 . NITP - AI - NLP @ Dravidian - CodeMix - FIRE2020 : A Hybrid CNN and Bi - LSTM Network for Senti - ment Analysis of Dravidian Code - Mixed Social Media Posts . . In FIRE ( Working Notes ) . 582 – 590 . [ 24 ] Ritesh Kumar , Aishwarya N Reganti , Akshit Bhatia , and Tushar Maheshwari . 2018 . Aggression - annotated corpus of hindi - english code - mixed data . arXiv preprint arXiv : 1803 . 09402 ( 2018 ) . [ 25 ] Gwyn Lewis , Bryn Jones , and Colin Baker . 2012 . Translanguaging : Origins and development from school to street and beyond . Educational Research and Evaluation 18 , 7 ( 2012 ) , 641 – 654 . [ 26 ] Zichao Li . 2021 . Codewithzichao @ DravidianLangTech - EACL2021 : Exploring Multilingual Transformers for Offensive Language Identification on Code Mixing Text . In Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages . 164 – 168 . [ 27 ] ThomasMandl , SandipModha , AnandKumarM , andBharathiRajaChakravarthi . 2020 . Overview of the hasoc track at fire 2020 : Hate speech and offensive lan - guage identification in tamil , malayalam , hindi , english and german . In Forum for Information Retrieval Evaluation . 29 – 32 . [ 28 ] Puneet Mathur , Ramit Sawhney , Meghna Ayyar , and Rajiv Shah . 2018 . Did you offend me ? classification of offensive tweets in hinglish language . In Proceedings of the 2nd Workshop on Abusive Language Online ( ALW2 ) . 138 – 148 . [ 29 ] Puneet Mathur , Rajiv Shah , Ramit Sawhney , and Debanjan Mahata . 2018 . Detect - ing offensive tweets in hindi - english code - switched language . In Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media . 18 – 26 . [ 30 ] Hamdy Mubarak , Kareem Darwish , and Walid Magdy . 2017 . Abusive Language Detection on Arabic Social Media . In Proceedings of the First Workshop on Abusive Language Online . Association for Computational Linguistics , Vancouver , BC , Canada , 52 – 56 . https : / / doi . org / 10 . 18653 / v1 / W17 - 3008 [ 31 ] Hala Mulki , Hatem Haddad , Chedi Bechikh Ali , and Halima Alshabani . 2019 . L - HSAB : A Levantine Twitter Dataset for Hate Speech and Abusive Language . In Proceedings of the Third Workshop on Abusive Language Online . Association for Computational Linguistics , Florence , Italy , 111 – 118 . https : / / doi . org / 10 . 18653 / v1 / W19 - 3512 [ 32 ] Kartikey Pant and Tanvi Dadu . 2020 . Towards Code - switched Classification Exploiting Constituent Language Resources . In Proceedings of the 1st Conference of the Asia - Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing : Student Research Workshop . 37 – 43 . [ 33 ] Fabio Poletto , Valerio Basile , Manuela Sanguinetti , Cristina Bosco , and Viviana Patti . 2021 . Resources and benchmark corpora for hate speech detection : a systematic review . Language Resources and Evaluation 55 , 2 ( 2021 ) , 477 – 523 . [ 34 ] Priya Rani , Shardul Suryawanshi , Koustava Goswami , Bharathi Raja Chakravarthi , Theodorus Fransen , and John Philip McCrae . 2020 . A comparative study of different state - of - the - art hate speech detection methods in Hindi - English code - mixed data . In Proceedings of the Second Workshop on Trolling , Aggression and Cyberbullying . 42 – 48 . [ 35 ] Debjoy Saha , Naman Paharia , Debajit Chakraborty , Punyajoy Saha , and Ani - meshMukherjee . 2021 . Hate - Alert @ DravidianLangTech - EACL2021 : Ensembling strategies for Transformer - based Offensive language Detection . arXiv preprint arXiv : 2102 . 10084 ( 2021 ) . [ 36 ] Siva Sai and Yashvardhan Sharma . 2020 . Siva @ HASOC - Dravidian - CodeMix - FIRE - 2020 : Multilingual Offensive Speech Detection in Code - mixed and Roman - ized Text . . In FIRE ( Working Notes ) . 336 – 343 . [ 37 ] Semiu Salawu , Yulan He , and Joanna Lumsden . 2017 . Approaches to automated detection of cyberbullying : A survey . IEEE Transactions on Affective Computing 11 , 1 ( 2017 ) , 3 – 24 . [ 38 ] AnnaSchmidtandMichaelWiegand . 2017 . Asurveyonhatespeechdetectionus - ing natural language processing . In Proceedings of the fifth international workshop on natural language processing for social media . 1 – 10 . [ 39 ] Gudbjartur Ingi Sigurbergsson and Leon Derczynski . 2019 . Offensive language and hate speech detection for Danish . arXiv preprint arXiv : 1908 . 04531 ( 2019 ) . [ 40 ] Pankaj Singh and Pushpak Bhattacharyya . 2020 . CFILT IIT Bombay @ HASOC - Dravidian - CodeMix FIRE 2020 : Assisting ensemble of transformers with random transliteration . . In FIRE ( Working Notes ) . 411 – 416 . [ 41 ] Sara Owsley Sood , Elizabeth F Churchill , and Judd Antin . 2012 . Automatic identification of personal insults on social news sites . Journal of the American Society for Information Science and Technology 63 , 2 ( 2012 ) , 270 – 285 . [ 42 ] Ellen Spertus . 1997 . Smokey : Automatic recognition of hostile messages . In Aaai / iaai . 1058 – 1065 . [ 43 ] Cynthia Van Hee , Gilles Jacobs , Chris Emmery , Bart Desmet , Els Lefever , Ben Verhoeven , Guy De Pauw , Walter Daelemans , and Véronique Hoste . 2018 . Au - tomatic detection of cyberbullying in social media text . PloS one 13 , 10 ( 2018 ) , e0203794 . [ 44 ] Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . 2017 . Attention is all you need . In Advances in neural information processing systems . 5998 – 6008 . [ 45 ] PVVeena , PraveenaRamanan , andRemmiyaDeviG . 2020 . CENMates @ HASOC - Dravidian - CodeMix - FIRE2020 : Offensive Language Identification on Code - mixed Social Media Comments . . In FIRE ( Working Notes ) . 377 – 383 . [ 46 ] Bertie Vidgen and Leon Derczynski . 2020 . Directions in abusive language train - ing data , a systematic review : Garbage in , garbage out . PloS one 15 , 12 ( 2020 ) , e0243300 . [ 47 ] Ellery Wulczyn , Nithum Thain , and Lucas Dixon . 2017 . Ex machina : Personal attacks seen at scale . In Proceedings of the 26th international conference on world wide web . 1391 – 1399 . [ 48 ] Konthala Yasaswini , Karthik Puranik , Adeep Hande , Ruba Priyadharshini , Sajeetha Thavareesan , and Bharathi Raja Chakravarthi . 2021 . IIITT @ DravidianLangTech - EACL2021 : Transfer Learning for Offensive Language De - tection in Dravidian Languages . In Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages . 187 – 194 . [ 49 ] Yingjia Zhao and Xin Tao . 2021 . ZYJ123 @ DravidianLangTech - EACL2021 : Of - fensive Language Identification based on XLM - RoBERTa with DPCNN . In Pro - ceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages . 216 – 221 . [ 50 ] Yueying Zhu and Xiaobing Zhou . 2020 . Zyy1510 @ HASOC - Dravidian - CodeMix - FIRE2020 : An Ensemble Model for Offensive Language Identification . . In FIRE ( Working Notes ) . 397 – 403 . 74