The Effect of Monitoring by Cameras and Robots on the Privacy Enhancing Behaviors of Older Adults Kelly Caine Indiana University School of Informatics and Computing 919 E . 10 th Street , Bloomington IN caine @ indiana . edu Selma Š abanovi ć Indiana University School of Informatics and Computing 919 E . 10 th Street , Bloomington IN selmas @ indiana . edu Mary Carter Indiana University Psychological and Brain Sciences 1101 E . 10 th Street , Bloomington IN carterme @ indiana . edu ABSTRACT This paper describes the results of an experimental study in which older adult participants interacted with three monitoring technologies designed to support their ability to age in place in their own home—a camera , a stationary robot , and a mobile robot . The aim of our study was to evaluate users’ perceptions of privacy and their tendencies to engage in privacy enhancing behaviors ( PEBs ) by comparing the three conditions . We found that privacy concerns lead older adults to change their behavior in a home environment while being monitored by cameras or embodied robots . We expected participants to engage in more PEBs when they interacted with a mobile robot , which provided embodied cues of ongoing monitoring ; surprisingly , we found the opposite to be true—the camera was the condition in which participants performed more PEBs . We describe the results of quantitative and qualitative analyses of our survey , interview , and observational data and discuss the implications of our study for human - robot interaction , the study of privacy and technology , and the design of assistive robots for monitoring older adults . Categories and Subject Descriptors H . 1 . 2 . [ Models and Principles ] : User / Machine Systems – Human Factors , Software Psychology ; K . 4 . 1 [ Computers and Society ] : Public Policy Issues – Privacy , I . 2 . 9 [ Robotics ] : Operator Interfaces . General Terms Design , Experimentation , Security , Human Factors . Keywords Aging in place , home monitoring , home , older adult , privacy , human - robot interaction . 1 . INTRODUCTION The need to consider and protect user privacy is regularly cited as a benchmark for assistive robotic systems meant to be used in natural settings [ 12 , 18 , 20 , 27 ] . Neither user perceptions of privacy nor their privacy behaviors , however , have been objects of empirical research within the domain of human - robot interaction . As autonomous and teleoperated robots that can collect data on people’s behaviors and allow for remote operators to monitor others become more readily available to the public ( e . g . Texas , QB , CareBot ) , the need to study the effects of robotic technologies on user privacy is becoming urgent . This is particularly true for rapidly growing application areas for monitoring and telecommunication robots , such as elder care [ 3 ] . Human - computer interaction researchers have studied privacy issues in relation to a variety of technologies including computers , the Internet , and memory aids [ e . g . [ 7 , 16 ] , though relatively little work has examined privacy perceptions among older adults ( see [ 5 , 8 , 9 , 11 , 23 ] for exceptions ) . Researchers suggest that robots , in comparison to previously studied information and communication technologies , may provide unprecedented protections and challenges to user privacy because of their embodiment , mobility , and novelty for users [ 3 , 12 , 23 ] . Much of this existing research suggests that people’s privacy attitudes and behaviors are often out of synch [ 1 , 17 , 29 ] : while users might profess serious privacy concerns , they will disclose personal information freely in online and computer - based communication . One possible explanation for this discrepancy is that , because computer - based communication is radically different from the embodied , face - to - face interaction that people are accustomed to [ 6 ] , this difference results in a lack of understanding of what information is disclosed , to whom , and what the consequences of these disclosures may be . Research in human - computer interaction , however , has not addressed the issue of embodied interaction as it pertains to privacy . Robots , which are not only embodied and mobile devices , but are often designed to resemble humans and / or perform human - like behaviors and functions , provide an opportunity for researchers to study whether an embodied interface will affect and possibly enhance user privacy protection in ways that other technologies do not . In this paper , we study user privacy behaviors in the context of monitoring applications in the homes of older adults . Older adults comprise one of the most likely potential audiences for domestic assistive robotic technologies [ 12 ] ; robots can enable older adults to age in place by providing telepresence and monitoring capabilities for caregivers ( e . g . [ 3 , 4 , 22 ] ) , as well as various autonomous assistive services ( e . g . [ 5 , 26 ] . Our study focuses on teleoperation and monitoring as the most likely applications to be used in the near future . We compare two types of robots—mobile and stationary—to each other and to a wall - mounted camera to explore and understand the different privacy - related affordances of these devices from the perspective of older adult users . We also use our results to expand our understanding of the psychology of privacy with a particular focus on whether embodied and mobile devices make a difference in people’s awareness of monitoring and their performance of privacy enhancing behaviors ( PEBs ; [ 6 ] ) . After providing an overview of assistive robotics for older adults and privacy as it relates to monitoring technologies in general and robots more specifically , we describe the results of our study and discuss their contributions to HRI and the study of technology and privacy . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . HRI’12 , March 5 – 8 , 2012 , Boston , MA , USA . Copyright 2012 ACM 978 - 1 - 4503 - 1063 - 5 / 12 / 03 . . . $ 10 . 00 . Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 343 2 . BACKGROUND 2 . 1 Assistive robots for older adults The imminent use of robots in the daily aid and care of older adults brings up both the promise of helping people achieve their goals of aging in place [ 13 ] and concerns that robotic technologies might jeopardize the human rights of elders [ 27 ] . Based on an ethnographic study of the homes and everyday practices of older adults , [ 13 ] conclude that robotic technologies should conform to the local social ecology , support the values of independence and dignity , and also adapt to other actors in the environment to be appropriate for and helpful to older adults . Other researchers mention the possibility that using monitoring robots will deprive elders of much needed social interaction , infringe on their privacy , and cause loss of freedom and autonomy as robotic systems start making decisions and taking actions in the homes of elders [ 27 ] . [ 28 ] also suggest that the availability of robots will inevitably decrease older adults’ access to the human touch , an often forgotten but necessary component of care . They also caution that robots as monitors and telepresence devices may have a negative impact on the relationship between caregivers and receivers as both parties become more reliant on technology . More research on specific robotic applications in different contexts of use is necessary for developing appropriate design guidelines and practices for assistive robots for older adults . 2 . 2 Privacy in human - computer interaction While it is beyond the scope of this paper to review the literature related to privacy in HCI in its entirety ( for a review see [ 15 ] ) , we want to highlight one particularly relevant issue we explore in this study : the finding that privacy attitudes often do not match privacy behaviors ( e . g . , [ 1 ] ) . For example , in the context of e - commerce , online disclosure of personal information while interacting with an e - commerce site did not match privacy preferences users stated previously [ 29 ] . [ 1 ] offers a number of possible explanations for this mismatch , including limited information , self - control problems , and bounded rationality . However , another possibility is simply awareness ( see [ 6 ] ) . Because information and communication technologies do not offer the rich social experience provided by direct interaction with other humans , differences between privacy attitudes and behaviors may be explained by a lack of sufficient cues about the recipient , amount , and content of information being transmitted . Put simply , people’s stated attitudes about privacy may differ from their actual privacy behaviors because they are not fully aware of what information they are revealing and to whom . While some recent work has been done to provide more cues to people as they make privacy decisions ( e . g . , [ 7 ] ) , this explanation remains underexplored . In relation to this study , this explanation suggests there is great potential for robots to represent feedback that increases user awareness more than other information and communication technologies because of their embodied nature . 2 . 3 Privacy in human - robot interaction HRI scholars [ 12 , 18 ] emphasize privacy as an important benchmark in the design of “increasingly humanlike” and assistive robots . [ 18 ] suggest that the presence of robots can affect a user’s sense of privacy , particularly in relation to the robot’s ability to monitor and collect information about the individual . In a user study with 12 older adults , [ 3 ] cite the concern for privacy as the second highest category mentioned by their research participants and suggest that features allowing users to refuse monitoring at will could address some of these concerns ( see [ 8 ] for an independently derived conclusion and technical solution ) . [ 20 ] also suggest that privacy - oriented design is important for robots that operate in everyday human environments , pointing out that users may not be aware of the capabilities of robots and may like to be informed when they are being recorded or monitored . Robotic embodiment has been identified and studied as an important factor in assistive applications for older adults [ 21 ] , providing the user with a more naturalistic interface and encouraging the relationships with the technology . [ 12 ] propose that robots differ from other pervasive technologies because users can see when robots are observing them and send them away or avoid them , thus providing more possibilities for protecting user privacy ( p . 430 ) . Our study is a preliminary exploration of the effect of robots , as compared to more familiar technologies such as cameras , on privacy attitudes and behaviors of older adults . 2 . 4 Overview of the Study We used an experimental approach to evaluate whether privacy attitudes and behaviors of older adults being monitored by a camera would differ from those of older adults interacting with embodied monitoring devices ( i . e . , robots ) . We were particularly interested in understanding the differences between the three monitoring conditions . To elicit privacy concerns , we had participants perform a task in which they imagined themselves planning a surprise party for a caregiver who was monitoring them . Further details of the experiment are described below . 3 . METHODS 3 . 1 Participants Participants were 18 older adults between the ages of 69 and 88 recruited from a local retirement community through posted advertisements and by word of mouth . There were 11 women and 7 men and all participants lived independently . Table 1 shows detailed demographic information . Table 1 . Demographic information for participants Overall ( N = 18 ) Camera ( n = 6 ) Stationary Robot ( n = 6 ) Mobile Robot ( n = 6 ) Age Mean SD 81 ( 5 . 5 ) 82 ( 7 . 1 ) 80 ( 3 . 0 ) 80 ( 6 . 1 ) Race White 100 % 100 % 100 % 100 % Gender Female 61 % 50 % 50 % 83 % Male 39 % 50 % 50 % 17 % Income $ 30 - 49k 6 % 17 % 0 % 0 % $ 50 - $ 74k 33 % 0 % 33 % 67 % > $ 75k 56 % 83 % 50 % 33 % Prefer not to answer 6 % 0 % 17 % 0 % Education Some College 17 % 0 % 17 % 33 % College 83 % 100 % 83 % 67 % Living Situation Alone 56 % 50 % 67 % 50 % W / Spouse 39 % 50 % 33 % 33 % W / Family 6 % 0 % 0 % 17 % Marital Status Married 39 % 50 % 33 % 33 % Widowed 55 % 50 % 50 % 67 % Never Married 6 % 0 % 17 % 0 % Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 344 3 . 2 Design The study used a between subjects design . Participants were randomly assigned to one of three possible monitoring devices : camera , stationary robot , or mobile robot . We chose to use a camera because of its ubiquity as a monitoring technology and familiarity to users . The stationary robot was used as a control for the possibility that the robotic nature of the monitoring technology would influence participants . The mobile robot was the most embodied of our monitoring devices , as it followed the participant as they moved around the space during the experiment . 1 The main objective of the study was to evaluate users’ perceptions of privacy of three types of monitoring technologies designed to support older adults’ ability to age in place in their own home . To accomplish this , we focused on the following research questions and hypotheses : RQ1 : Will older adults’ level of comfort with household activities ( CHA ) change when they assume that they would be monitored ? • H 0 : | Δ CHA | = 0 • H 1 : | Δ CHA | ≠ 0 RQ2 : Which activities would be considered more comfortable to be performed while being monitored and which activities would be considered less comfortable ? • Exploratory / descriptive ( no specific activities hypothesized ) RQ3 : Will older adults’ level of comfort with household activities ( CHA ) change differentially by device type ? • H 0 : | Δ CHA | camera = | Δ CHA | stationary robot = | Δ CHA | mobile robot • H 1 : | Δ CHA | camera < | Δ CHA | stationary robot < | Δ CHA | mobile robot RQ4 : Will the proportion of older adults who engage in privacy enhancing behaviors ( PEBs ) differ by type of monitoring device ? • H 0 : # of PEBs camera = stationary robot = mobile robot • H 1 : # of PEBs camera < stationary robot < mobile robot RQ5 : What types of PEBs do older adults utilize to maintain privacy while being monitored ? • Exploratory / descriptive ( no specific behaviors hypothesized ) 3 . 3 Materials 3 . 3 . 1 Questionnaires Participants filled out four questionnaires at the beginning of the study : a demographics questionnaire , the Privacy Attitudes Questionnaire ( PAQ ; an extended version of the Westin segmentation index [ 17 , 19 ] ) , the Negative Attitudes towards Robots ( NARS [ 24 ] ) , and the modified comfort with household activities ( CHA ) questionnaire , which we developed using Frye and Dornisch’s [ 14 ] disclosure topics as the basis of our questionnaire items . The demographics questionnaire enquired about participants’ age , gender , household income , etc . ; the PAQ enquired about participants’ general privacy attitudes ; the NARS measured people’s existing attitudes towards robots ; and the 1 We use Dautenhahn’s definition of embodiment as “the existence of perturbatory channels between the robot and its environment” [ 10 ] , which in our case refers to its movement in response to the participant’s actions . modified CHA assessed general levels of comfort performing activities within a home environment . After participants had interacted with the monitoring technology , we administered two post - test questionnaires : The Collected Robot Scales and the modified CHA . The Collected Robot Scales questionnaire was used to assess the participants’ perceptions of the home monitoring technologies they encountered ; it combined the “Godspeed Scale” [ 2 ] , which includes measures of animacy , anthropomorphism , likeability , perceived intelligence , and perceived safety , and [ 25 ] ’s 6 - level scale for “fear , ” “surprise , ” “disgust , ” and “unpleasantness . ” The modified CHA ( as described above ) was also used in the post - test , but this time participants were asked to answer considering the device they were saw during the study was being used in their home . Change scores ( Δ CHA ) were calculated for each question on the CHA by subtracting the post - CHA score from the pre - CHA score . 3 . 3 . 2 Interview A verbal semi - structured interview was used to gather information about the participant’s perceptions of and reactions to the monitoring technologies . The interview covered topics such as the participants’ reasons for ( or reasons for not ) performing privacy enhancing behaviors , comfort with tasks , perceptions of the invasiveness of devices , and overall impressions of home monitoring technologies . One area of specific interest were PEBs . Each participant was asked if they engaged in any PEBs while performing the tasks assigned for the study . If the participant answered yes , the interviewer asked what type of behaviors the participant performed . If the participant answered no , the interviewer followed up to determine why no PEBs were employed . Researchers also asked each participant how they thought the monitoring technology they saw worked and whether they had any previous experience with monitoring technologies . Finally , participants were asked to describe situations in which the use of monitoring devices would be appropriate and inappropriate , as well as whether or not participants would use a monitoring technology such as the one they had interacted with in their home . 3 . 3 . 3 Scenario and tasks To observe participants performing tasks appropriate for the home environment while giving them an opportunity to engage in PEBs , we developed a scenario in which participants imagined preparing a surprise birthday party for their caregiver . Participants received a task list to complete in planning the fictional surprise party ; they were also asked to record completed tasks on the list . The tasks , in order of performance , included telephoning a guest to confirm their attendance , blowing a balloon , hanging a “Happy Birthday” banner , answering the door to receive a flower delivery , placing flowers in a vase , icing a cupcake , using sanitary wipes to clean their hands , putting on a tee shirt , and evaluating their appearance in a mirror . The tasks represented different levels of personal ( e . g . putting on a t - shirt , cleaning hands ) and informational disclosure ( e . g . hanging banner , phoning guests ) tasks . 3 . 3 . 4 Monitoring Technologies Participants interacted with one of three types of monitoring technology participants during the study—a wall - mounted camera , a stationary robot , and a mobile robot . The wall - mounted camera was an Axis 215 PTZ camera . The stationary and mobile robots used the same robotic platform , an off - the - shelf Videre model mobile platform ( See Figure 1 ) , with a webcam mounted on top . The robot is approximately 40cm by 41cm by 15cm and is regularly used in university lab research with human subjects . The robot exhibited different behaviors in the stationary and mobile Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 345 robot conditions . In the stationary condition , the robot was placed in the room prior to the participant’s entry and did not move from its spot throughout the study . In the mobile robot condition , a research assistant remotely operated the robot to follow the participant as they moved around the experimental space . The only interaction cues the robots provided to participants were physical presence in the case of the stationary robot and contingent movement in the case of the mobile robot . Figure 1 . ( a ) Robotic platform used in stationary and mobile conditions , ( b ) Wall - mounted pan - tilt - zoom camera . 3 . 3 . 5 Recording apparatus We used a GoPro HD camera to visually capture participants’ behavior throughout the study . Verbal data was collected using a digital voice recorder . 3 . 4 Procedure The study took place at the R - House Living Lab at Indiana University , a five - room house used for research on human - robot interaction and the design of domestic interactive technologies . Once participants arrived at the R - House , researchers obtained informed consent . Participants were then asked to fill out the pre - test questionnaires and were randomly assigned to one of three monitoring device conditions : camera , stationary robot , or mobile robot . Next , participants were asked to give us the name of someone who could be their caregiver , should the need arise . Afterwards , participants were asked to imagine that the experimental space was a room in their home and that the person they had identified as a potential caregiver could monitor them using the technology they had been randomly assigned to ( camera or stationary robot or mobile robot ) . The experimenter then introduced the monitoring technology , regardless of the condition , with the following script : “The [ TECHNOLOGY TYPE ] you see here can collect images and sound like those from a video camera . Your caregiver can access this whenever they choose . ” After being introduced to the monitoring technology , participants were given a scenario that described a fictional surprise birthday party for the caregiver they imagined and asked to prepare for that surprise party by performing the tasks on a list provided for the purpose ( see section 3 . 3 . 3 for a description of the tasks ) . The experimenter then left the room and observed the participants via camera until all tasks were completed or 30 minutes had passed . When the experimenter returned to the room , they conducted a semi - structured interview and administered the two post - test questionnaires . At the conclusion of the study , participants were debriefed as to the purpose of the study and remunerated $ 20 for their time . The entire study took approximately 1 ½ hours . 4 . RESULTS In the following section we discuss findings from each of the 5 research questions outlined in section 3 . 2 . 4 . 1 Comfort with Household Activities The first thing we were interested in was to understand how general comfort performing household activities would change in a non - monitored versus a monitored home . To determine this difference , we calculated the changes between the pre - and post - CHA score for each household activity ( Δ CHA ) . Overall 15 household activities changed by at least a quarter of a point ( note that a positive change score indicates a decrease in comfort when in a home with a monitoring device ) . Table 2 . Activities where participant comfort decreased Participants ( N = 18 ) Mean Δ CHA ( SD ) Engage in sexual activity with a partner 3 . 4 ( 2 . 6 ) Engage in physical contact with an intimate partner 1 . 9 ( 3 . 3 ) Take a shower 1 . 3 ( 2 . 1 ) Engage in sexual activity by myself 1 . 2 ( 2 . 8 ) Practice personal hygiene 0 . 8 ( 2 . 1 ) Take a bath 0 . 8 ( 2 . 2 ) Do personal finances ( pay bills , write checks ) 0 . 7 ( 1 . 6 ) Have friends over 0 . 3 ( 1 . 2 ) Blow my nose 0 . 3 ( 0 . 8 ) There were 9 activities where comfort with performing decreased with the addition of a monitoring device in the home ( see Table 2 ) and 6 activities where comfort increased ( see Table 3 ) . Table 3 . Activities where participant comfort increased Participants ( N = 18 ) Mean Δ CHA ( SD ) Engage in a argument - . 72 ( 2 . 2 ) Exercise - . 56 ( 1 . 6 ) Dance around the house - 0 . 5 ( 2 . 0 ) Drink alcohol - . 33 ( 1 . 6 ) Express my political views - . 33 ( 1 . 3 ) Watch any movie - . 39 ( 1 . 2 ) In addition , we were interested in understanding whether level of comfort changed differently based on the type of monitoring device ( camera , stationary robot , or mobile robot ) . A one - way ANOVA was used to test for differences in change scores by monitoring device type . The change score for two household activities—“engaging in sexual activity with a partner” and “drinking alcohol”—differed significantly by device type ( ps < . 05 ; see Table 4 ) . None of the other change scores significantly differed by device type ( ps > . 05 ) . Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 346 Table 4 . ANOVA of Δ CHA Device Type Camera Mean ( SD ) Stationary Robot Mean ( SD ) Mobile Robot Mean ( SD ) F p Alcohol 0 ( 0 ) . 67 ( 1 . 37 ) - 1 . 67 ( 1 . 86 ) 4 . 88 . 023 Sex 5 ( 1 . 55 ) 4 . 67 ( 1 . 37 ) . 50 ( 1 . 76 ) 15 . 36 . 001 4 . 1 . 1 Alcohol Bonferroni adjusted post - hoc comparisons of the three device types indicate that participants in the mobile robot group increased their comfort level with respect to consuming alcohol in a home containing the mobile robot whereas the Camera or Stationary Robot had very little change in their reported comfort with consuming alcohol , p = . 025 . There was no significant difference between the Camera and Stationary Robot ( ps < . 14 ) . 4 . 1 . 2 Sex Bonferroni adjusted post - hoc comparisons of the three device types indicate that participants in the mobile robot group changed their comfort level very little with respect to engaging in sexual activity with a partner in a home containing the mobile robot whereas participants in the Camera and Stationary Robot conditions reported significantly more concern , p = . 001 . Comparisons between the Camera and Stationary Robot were not statistically different ( ps < . 99 ) . 4 . 2 Privacy Enhancing Behaviors ( PEBs ) Privacy enhancing behaviors are behaviors that people engage in to avoid or alleviate privacy concerns [ 5 ] . We were interested whether PEBs differed by monitor type , what PEBs older adults would engage in , how frequently older adults engaged in PEBs , and to understand older adults PEB perceptions . 4 . 2 . 1 PEBs by Monitoring Type The first thing we wanted to understand was whether or not there were differences in privacy enhancing behaviors by monitoring device type . Because our sample size was not large enough to use a chi - square test ( requires minimum expected cell count of 5 ; our expected cell counts were 3 ) , we used Fisher’s exact test . Fisher’s exact test is most appropriately used with a 2 x 2 contingency table , so we pooled participants into “robot” and “camera” conditions for this analysis ( See Table 5 for the percentage of participants who engaged in PEBs by monitoring device type ) . Applying Fisher’s exact test , the proportion of participants in the camera condition who engaged in PEBs is significantly more than the proportion of participants who engaged in PEBs in the robot conditions ( p = . 057 ) . While 67 % of the participants in the camera condition engaged in PEBs only 17 % of participants in the robot condition engaged in PEBs . Table 5 . Privacy enhancing behavior by monitoring type PEB Camera ( n = 6 ) Stationary robot ( n = 6 ) Mobile robot ( n = 6 ) Yes 67 % 17 % 17 % No 33 % 83 % 83 % 4 . 2 . 2 Quantity of PEBs In addition to examining the presence of PEBs , we also wanted to understand , for participants who did engage in privacy behaviors , how often they engaged in PEBs over the course of the study . Overall , 6 of 18 participants engaged in PEBs during the session . However , there was a range in the quantity of PEBs per session . While most participants engaged in between 1 - 5 PEBs per session , 2 participants ( one in the camera and one in the mobile robot condition ) displayed 12 PEBs each . 4 . 2 . 3 Quality of PEBs To understand the range of behaviors participants used to enhance privacy while being monitored we examined the video of each participant during the session . PEBs included : • covering up camera with an object ( e . g . painting , scotch tape ) • turning camera in opposite direction ( on robot ) • self - censoring of speech during phone calls • using an alternative location : setting the party up in a different room • moving their bodies out of sight of camera ( to another room , behind furniture ) • turning their back towards the camera and walking backwards • obscuring objects with their body and / or other objects in the room ( see Figure 2a for screenshot of participant hiding flowers behind her back ) • covering chest to hide “happy birthday” printed t - shirt ( see Figure 2b for screenshot of participant hiding the contents of her t - shirt ) Figure 2 . PEBs : ( a ) Participant hiding flowers behind their back , ( b ) Participant covering the “Happy Birthday” writing on their shirt with their arms In addition to observable behaviors , we were also interested in participants’ subjective self - report of their PEBs . When asked , many participants reported specific PEBs they had engaged in during the experiment . In the quotes below , participants who were in the camera condition are identified by ‘cXX’ , those in the stationary robot condition by ‘srXX’ , and those in the mobile robot condition by ‘mrXX . ’ Participants described how they tried to “hide” ( mr025 ) from or “stay out of line” ( c024 ) of the monitoring device . Similarly , others described how they occluded what they were doing using their body and objects in the room : Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 347 “I stood with my back to the camera so they couldn’t see the number I was dialing… . The next task was to blow up the balloon so I got behind the chair . . . I left the balloon behind the chair until I had tape to put it under the camera . ” ( c24 ) “ [ I ] … did everything [ in the conference room ] that I could , including hanging the banner . And when I came in here with the shirt I tried to keep my back faced this way . ” ( c7 ) Three participants also reported censoring what they said on the phone to avoid letting the caregiver hear about the birthday party : “I was pretty oblique . . . I avoided saying when it was or what it was about . ” ( c24 ) “I just said she could come over… [ instead of mentioning birthday plans ] . ” ( c20 ) " I figured she [ my caregiver ] wouldn’t have any idea who it [ party guest ] was so it wouldn’t make any difference because I would certainly be calling other people at other times… I didn’t say anything… about the party . ” ( c7 ) 5 . DISCUSSION 5 . 1 Comfort with Household Activities 5 . 1 . 1 Change in Level of Comfort There were 9 activities where comfort with performing household activities decreased with the addition of a monitoring device in the home and 6 activities where comfort increased . Upon reflection , many of the activities where comfort decreased were activities that could be thought of as sensitive or personal . The 4 activities with the greatest decrease in comfort level were related to being nude and 3 of the 4 were related to intimate activities . On the other hand , many of the activities where comfort increased may be thought of as potentially dangerous activities during which older adults might get hurt . For example , engaging in an argument could raise one’s blood pressure , while engaging in exercise or dancing around the house could result in a fall . The evidence from the change in CHA scores indicates that participants understood the functionality of the monitoring systems , had privacy concerns about being watched while performing some activities ( e . g . , showering ) , but reported that they would be more comfortable performing some potentially dangerous activities in a home containing monitoring devices . 5 . 1 . 2 Change in Level of Comfort by Device Type We were also interested in understanding whether level of comfort with household activities changed differently based on the type of monitoring device ( camera , stationary robot , or mobile robot ) . We found that the change score for two household activities ( consuming alcohol and engaging in sexual activity with a partner ) differed significantly by device type . Participants in the mobile robot condition reported increased comfort with respect to consuming alcohol while participants in the other two conditions changed their comfort level very little . One possible explanation for the increased comfort with the mobile robot rather than either the stationary robot or camera is that participants may have thought that the mobile robot could find them should they need assistance if they had too much to drink . Thus , the mobile robot could be thought of as helpful and therefore make older adults feel more comfortable . As for the idea of engaging in sexual activity with a partner , participants comfort levels in the mobile robot condition changed very little from their initial comfort score to the score taken while considering engaging in the activity with the monitoring device present , whereas participants in the camera and stationary robot conditions reported significantly more concern when considering engaging in the activity with the monitoring device present . One possible explanation for this is that participants in the mobile robot condition may have thought they could “shoo” or tell the robot to leave the room should they decide to engage in such activity , or that perhaps the person controlling the robot would decide to leave of their own accord . 5 . 2 Privacy Enhancing Behaviors Overall we found that older adults in each of the three monitoring conditions engaged in PEBs . The quantity of observed PEBs participants expressed ranged from 1 PEB to 12 PEBs over the course of the session . PEBs were varied and included covering up the camera with an object , censoring speech during phone calls , and covering up the “happy birthday” print on their t - shirts . In addition to these objective , observable behaviors , participants also described PEBs they exhibited in their own words . In general , they told us they changed their behavior to hide from the monitoring device so that their caregiver would not see them preparing for the party . 5 . 2 . 1 Older adults engage in PEBs Taken together , this triangulated evidence from both objective and subjective sources suggests that older adults will change their behavior in the home if they are concerned about their privacy due to in - home monitoring . A number of researchers have suggested that monitoring devices , especially cameras , are associated with privacy concerns , however , the evidence reported here is the first behavioral study to demonstrate that privacy concerns lead older adults to change behavior in a home environment when they are monitored by a variety of monitoring devices , including embodied robots . 5 . 2 . 2 Incidence of PEBs Differs by Monitoring Type In addition to examining whether older adults would change their behavior due to privacy concerns , we also examined how these behaviors differed by type of monitoring device . We expected participants in the mobile robot conditions to engage in more PEBs than participants in the stationary robot condition , and participants in the camera condition to engage in fewer PEBs than in either of the robot conditions . We expected this because the embodied presence of robots in the user’s environment could make users more aware of being observed ( e . g . [ 12 ] ) and thus more likely to take actions to preserve their privacy . The results of this study , which show that more participants engaged in PEBs when being monitored by a camera , may be interpreted as evidence counter to the suggestion that users would be more aware of , or at least sensitive to , being observed . However , an alternative explanation relates to research on tele - operation and the elderly [ 3 ] , which suggests that users may not be familiar with the capabilities of robots and therefore may not be aware of when they are being monitored . In contrast , people may already be quite familiar with cameras and may have already developed privacy practices in response to them . Admittedly , the robots in our study also had visibly attached cameras , but users’ lack of familiarity with robots , or their interest in their novelty , may have trumped their recognition of the function of the mounted cameras . Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 348 To evaluate these explanations we examined the post - session interview data to understand how participants explained why they did not engage in PEBs . Users provided a variety of reasons for not engaging in PEBs . One reason , mentioned by four participants ( sr12 , sr10 , sr12 , mr21 ) , was that they assumed the monitoring caregiver was in a position from which they would not be able to observe them at the time they were preparing for the party . In the words of one participant : “I figured she would be on her way over and wouldn’t be able to see it anyway” ( mr21 ) . Another participant explained that the activity they engaged in would not be recognizable as preparation for a surprise party : “ I thought he might see me working . But I didn’t think he would catch on ; ” they also mentioned they were not bothered by the idea that their caregiver might see what they were doing , “Anyway , I wouldn’t be embarrassed if he saw me doing that” ( sr17 ) . Many participants ( c9 , sr19 , c22 ) reported that it never occurred to them to engage in PEBs : “ No . I didn’t think of it . ” ( sr 19 ) ; “It never occurred to me” ( c9 ) . One reason given for this was that participants were too engrossed in following the task - related directions to worry about being monitored : in c22’s words “ I didn’t know I was supposed to , I was just following directions . ” The complexity of the task , which might have put the monitoring out of the participants’ minds and led to fewer PEBs , is therefore a possible limitation of our study . Some participants also questioned the technology’s capabilities to monitor them : “It wasn’t at the right place , it didn’t have the capability” ( mr18 ) . One participant also mentioned not minding the robot “It was moving around and for some reason or other it never bothered me . I paid no attention to it . As if it wasn’t there” ( mr013 ) . Such comments suggested participants perceived the robot as not being able to see what they were doing—it was relatively low to the ground , while the stationary camera was mounted in one corner of the room next to the ceiling affording a wider angle of view . This explanation is particularly reasonable for the stationary robot , which did not give any indication of monitoring the person . However , the mobile robot followed the participants around the space as they did the tasks , giving them an ostensibly clear indication that the monitoring function was indeed working . Another limitation of our study therefore relates to the differential effects of camera height on the participants’ perception of the monitoring technology’s effectiveness . Our interpretation that participants may not be familiar with robots , and therefore less wary of their monitoring capabilities , was not born out by the interview data . When asked what they thought the monitoring technologies were doing , participants had reasonable explanations for all three conditions . For the camera , they mentioned that it could “ see me instantly like a TV , 24 / 7” ( c08 ) , “I’m assuming it just took a picture of me or could spot the motion” ( c020 ) , “It would probably pick up audio from anywhere in the room even if I was out of eyesight or camera sight” ( c24 ) . The stationary robot was described similarly , as “ very much like Skype ” ( sr012 ) , or a “remote TV and speaker type system” ( sr011 ) , while participants describing the mobile robot focused on its responses to their movements : “ The motion attracts it every time” ( mr06 ) , “I felt like it was kind of following me around” ( mr018 ) . More research is needed to figure out why participants did not respond by engaging in privacy enhancing behaviors while being monitored by the robot when they expressed understanding of its basic functions . One possibility is that participants ascribed more autonomous agency to the mobile robot than to the other two conditions , and were not as bothered by its ability to “see” and monitor them , as some of our participants suggested , as they would be if a person was doing the monitoring . This suggests future research to understand participants’ differential perceptions of being monitored by a robot and a person . An alternative explanation we will continue to explore is that participants in all conditions may not have understood that the caregiver they identified would be actively monitoring them while they were completing the tasks . For example , one participant told us they “selected a time when [ their caregiver ] wouldn’t be home ” ( sr10 ) , while another said that their caregiver would not be observing them because “ I know my daughter wouldn’t be around all day” ( sr27 ) . In future work , we will ensure that participants identify caregivers who they believe will be available during the study period . This alternative explanation also draws attention to the myriad and unexpected ways people protect their own privacy ; in this case participants understood that although they could be monitored , they were not actively being monitored as their caregiver was otherwise engaged . Other future work we are already pursuing will examine the effects of attitudes towards robots ( as measured by the NARS ) and privacy attitudes ( as measured by the PAQ ) on user perceptions of and reactions to the monitoring technologies . We plan to examine these , as well as other individual differences among participants , as possible differentiators for the varied reactions to the monitoring technologies . 6 . CONCLUSIONS This paper presented results from an experimental study of the privacy - related behaviors and perceptions of older adults interacting with three types of monitoring technology : a camera , a stationary robot ( with camera ) , and a mobile robot ( with camera ) . We were particularly interested in seeing how older adults reacted to the two robots in comparison to the camera , as there has been little empirical research on privacy behaviors in the context of human - robot interaction . While HCI researchers have investigated privacy with respect to many technologies ( e . g . , mobile , cameras , internet ) our work is the first to consider the notion of embodied and interactive monitoring technologies , such as robots . The literature in HRI has so far not delved into empirical research on privacy behaviors around robots , but one of the expectations researchers have put forth is that robots might enable users to protect their privacy more effectively , since they are physically larger than cameras , make movements obvious to users , and can be asked to move out of the room and thus evaded when desired . Our study specifically addressed this area at the intersection of HRI and HCI , looking at embodiment with respect to privacy . We hypothesized that an embodied , mobile monitoring technology would increase participants’ use of PEBs , but we found the opposite to be true—fewer participants engaged in PEBs around robots . While we discussed potential explanations for this finding , more research is needed to evaluate these and other explanations . In the future , we propose to do more research to find out why this is the case , as we were only able to get a partial understanding from user comments during the final interviews . 7 . ACKNOWLEDGMENTS This research was supported in part by Indiana University through the Center for Law , Ethics , and Applied Research in Health Information , the School of Informatics and Computing ( SOIC ) , and the SOIC Undergraduate Research Scholar Honorarium . We would like to thank B . Kechavarzi , M . Francisco , N . Michalik , M . Soladine , G . White , M . Kinkoph , and M . Degges for assistance in data collection , and our older adult participants . Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 349 8 . REFERENCES [ 1 ] Acquisti , A . and Grossklags , J . 2003 . Losses , Gains , and Hyperbolic Discounting : An Experimental Approach to Information Security Attitudes and Behavior . In Proceedings of 2nd Annual Workshop on " Economics and Information Security " , UC Berkeley . [ 2 ] Bartneck , C . , Kuli ć , D . , Croft , E . and Zoghbi , S . 2009 . Measurement Instruments for the Anthropomorphism , Animacy , Likeability , Perceived Intelligence , and Perceived Safety of Robots . International Journal of Social Robotics , 1 ( 1 ) , 71 - 81 . [ 3 ] Beer , J . M . and Takayama , L . 2011 . Mobile remote presence systems for older adults : Acceptance , benefits , and concerns . In Proceedings of 6th international conference on Human - robot interaction , Lausanne , Switzerland , ACM , 19 - 26 . [ 4 ] Boissy , P . , Corriveau , H . , Michaud , H . , Labonté , D . and Royer , M . 2007 . A qualitative study of in - home robotic telepresence for home care of community - living elderly subjects . Journal of Telemedicine and Telecare , 13 ( 2 ) , 79 - 84 . [ 5 ] Broadbent , E . , Stafford , R . and MacDonald , B . 2009 . Acceptance of Healthcare Robots for the Older Population : Review and Future Directions . International Journal of Social Robotics , 1 ( 4 ) , 319 - 330 . [ 6 ] Caine , K . 2005 . Understanding Privacy Behaviors and Misclosures Unpublished Dissertation , Georgia Institute of Technology , Atlanta , GA . [ 7 ] Caine , K . , Kisselburgh , L . G . and Lareau , L . 2011 . Audience visualization influences disclosures in online social networks Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems , ACM , Vancouver , BC , Canada , 1663 - 1668 . [ 8 ] Caine , K . , Zimmerman , C . , Schall - Zimmerman , Z . , Hazlewood , W . , Jean Camp , L . , Connelly , K . , Huber , L . and Shankar , K . 2011 . DigiSwitch : A Device to Allow Older Adults to Monitor and Direct the Collection and Transmission of Health Information Collected at Home . Journal of Medical Systems , 35 ( 5 ) , 1181 - 1195 . [ 9 ] Caine , K . E . , Fisk , A . D . and Rogers , W . A . 2006 . Benefits and Privacy Concerns of a Home Equipped with a Visual Sensing System : A Perspective from Older Adults . Proceedings of the Human Factors and Ergonomics Society Annual Meeting , 50 ( 2 ) , 180 - 184 . [ 10 ] Dautenhahn , K . , Ogden , B . and Quick , T . 2002 . From embodied to socially embedded agents - Implications for interaction - aware robots . Cognitive Systems Research , 3 , 397 - 428 . [ 11 ] Demiris , G . , Oliver , D . P . , Dickey , G . , Skubic , M . and Rantz , M . 2008 . Findings from a participatory evaluation of a smart home application for older adults . Technology and Health Care , 16 ( 2 ) , 111 - 118 . [ 12 ] Feil - Seifer , D . , Skinner , K . and Mataric , M . J . 2007 . Benchmarks for evaluating socially assistive robotics . Psychological Benchmarks of Human - Robot Interaction , 8 ( 3 ) , 423 - 429 . [ 13 ] Forlizzi , J . , DiSalvo , C . and Gemperle , F . 2004 . Assistive robotics and an ecology of elders living independently in their homes . Hum . - Comput . Interact . , 19 ( 1 ) , 25 - 59 . [ 14 ] Frye , N . E . and Dornisch , M . M . 2010 . When is trust not enough ? The role of perceived privacy of communication tools in comfort with self - disclosure . Computers in Human Behavior , 26 ( 5 ) , 1120 - 1127 . [ 15 ] Iachello , G . and Hong , J . 2007 . End - user privacy in human - computer interaction . Found . Trends Hum . - Comput . Interact . , 1 ( 1 ) , 1 - 137 . [ 16 ] Iachello , G . , Truong , K . N . , Abowd , G . D . , Hayes , G . R . and Stevens , M . 2006 . Prototyping and sampling experience to evaluate ubiquitous computing privacy in the real world Proceedings of the SIGCHI conference on Human Factors in computing systems , ACM , Montreal , Canada , 1009 - 1018 . [ 17 ] Jensen , C . , Potts , C . and Jensen , C . 2005 . Privacy practices of Internet users : Self - reports versus observed behavior . International Journal of Human - Computer Studies , 63 ( 1 ) , 203 - 227 . [ 18 ] Kahn , P . H . , Ishiguro , H . , Friedman , B . , Kanda , T . , Freier , N . G . , Severson , R . L . and Miller , J . 2007 . What is a human ? Toward psychological benchmarks in the field of humanrobot interaction . Interaction Studies , 8 ( 3 ) , 363 - 390 . [ 19 ] Kumaraguru , P . and Cranor , L . F . 2005 . Privacy indexes : A survey of Westin’s studies . ISRI Technical Report . [ 20 ] Lee , M . K . , Tang , K . P . , Forlizzi , J . and Kiesler , S . 2011 . Understanding users ' perception of privacy in human - robot interaction . In Proceedings of 6th International Conference on Human - robot Interaction , Lausanne , Switzerland , ACM , 181 - 182 . [ 21 ] Mataric , M . J . 2005 . The Role of Embodiment in Assistive Interactive Robotics for the Elderly Caring Machines : AI for the Elderly , Arlington , VA . [ 22 ] Michaud , F . , Boissy , P . , Corriveau , H . , Grant , A . , Lauria , M . , Labonte , D . , Cloutier , R . , Roux , M . A . and Iannuzzi , D . 2007 . Telepresence Robot for Home Care Assistance . In Proceedings of AAAI Spring Symposium 2007 on Multidisciplinary Collaboration for Socially Assistive Robotics , Stanford , CA . [ 23 ] Mynatt , E . D . , Melenhorst , A . - S . , Fisk , A . D . and Rogers , W . A . 2004 . Aware Technologies for aging in place : Understanding user needs and attitudes , IEEE Pervasive Computing , 36 - 41 . [ 24 ] Nomura , T . , Kanda , T . , Suzuki , T . and Kato , K . 2008 . Prediction of Human Behavior in Human - - Robot Interaction Using Psychological Scales for Anxiety and Negative Attitudes Toward Robots . Robotics , IEEE Transactions on , 24 ( 2 ) , 442 - 451 . [ 25 ] Nonaka , S . , Inoue , K . , Arai , T . and Mae , Y . 2004 . Evaluation of human sense of security for coexisting robots using virtual reality 1st report : Evaluation of pick and place motion of humanoid robots . In Proceedings of IEEE International Conference on Robotics and Automation , New Orleans , LA , 2770 – 2775 . [ 26 ] Pollack , M . E . , Brown , L . , Colbry , D . , Orosz , C . , Peintner , B . , Ramakrishnan , S . , Engberg , S . , Matthews , J . T . , Dunbar - Jacob , J . , McCarthy , C . E . , Thrun , S . , Montemerlo , M . , Pineau , J . and Roy , N . 2002 . Pearl : A Mobile Robotic Assistant for the Elderly AAAI Technical Report WS - 02 - 02 . [ 27 ] Sharkey , A . and Sharkey , N . 2011 . Granny and the robots : Ethical issues in robot care for the elderly . Ethics and Information Technology , 1 - 14 . [ 28 ] Sparrow , R . and Sparrow , L . 2006 . In the hands of machines ? The future of aged care . Minds and Machines , 16 ( 2 ) , 141 - 161 . [ 29 ] Spiekermann , S . , Grossklags , J . and Berendt , B . 2001 . E - privacy in 2nd generation e - commerce : Privacy preferences versus actual behavior . In Proceedings of 3rd ACM Conference on Electronic Commerce , Tampa , Florida , USA , ACM , 38 - 47 . Session : Living and Working with Service Robots March 5 – 8 , 2012 , Boston , Massachusetts , USA 350