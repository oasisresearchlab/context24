Continuous Optimization Charles L . Byrne Department of Mathematical Sciences University of Massachusetts Lowell Lowell , MA 01854 April 24 , 2013 ( The most recent version is available as a pdf ﬁle at http : / / faculty . uml . edu / cbyrne / cbyrne . html ) 2 Contents 1 Preface 1 1 . 1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . 2 Two Types of Applications . . . . . . . . . . . . . . . . . . 1 1 . 2 . 1 Natural Optimization . . . . . . . . . . . . . . . . . 2 1 . 2 . 2 Problems of Inference . . . . . . . . . . . . . . . . . 4 1 . 3 Types of Optimization Problems . . . . . . . . . . . . . . . 6 1 . 4 When Have We Solved the Problem ? . . . . . . . . . . . . . 6 1 . 5 Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1 . 5 . 1 Root - Finding . . . . . . . . . . . . . . . . . . . . . . 7 1 . 5 . 2 Iterative Descent Methods . . . . . . . . . . . . . . . 8 1 . 5 . 3 Solving Systems of Linear Equations . . . . . . . . . 9 1 . 5 . 4 Imposing Constraints . . . . . . . . . . . . . . . . . 9 1 . 5 . 5 Operators . . . . . . . . . . . . . . . . . . . . . . . . 9 1 . 5 . 6 Search Techniques . . . . . . . . . . . . . . . . . . . 10 1 . 5 . 7 Acceleration . . . . . . . . . . . . . . . . . . . . . . . 10 1 . 6 A Word about Prior Information . . . . . . . . . . . . . . . 10 2 Optimization Without Calculus 15 2 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 15 2 . 2 The Arithmetic Mean - Geometric Mean Inequality . . . . . 16 2 . 3 An Application of the AGM Inequality : the Number e . . . 16 2 . 4 Extending the AGM Inequality . . . . . . . . . . . . . . . . 17 2 . 5 Optimization Using the AGM Inequality . . . . . . . . . . . 17 2 . 5 . 1 Example 1 : Minimize This Sum . . . . . . . . . . . . 17 2 . 5 . 2 Example 2 : Maximize This Product . . . . . . . . . 18 2 . 5 . 3 Example 3 : A Harder Problem ? . . . . . . . . . . . . 18 2 . 6 The H¨older and Minkowski Inequalities . . . . . . . . . . . 18 2 . 6 . 1 H¨older’s Inequality . . . . . . . . . . . . . . . . . . . 19 2 . 6 . 2 Minkowski’s Inequality . . . . . . . . . . . . . . . . . 20 2 . 7 Cauchy’s Inequality . . . . . . . . . . . . . . . . . . . . . . 20 2 . 8 Optimizing using Cauchy’s Inequality . . . . . . . . . . . . 21 2 . 8 . 1 Example 4 : A Constrained Optimization . . . . . . . 21 i ii CONTENTS 2 . 8 . 2 Example 5 : A Basic Estimation Problem . . . . . . 22 2 . 8 . 3 Example 6 : A Filtering Problem . . . . . . . . . . . 23 2 . 9 An Inner Product for Square Matrices . . . . . . . . . . . . 25 2 . 10 Discrete Allocation Problems . . . . . . . . . . . . . . . . . 26 2 . 11 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 2 . 12 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 31 3 Geometric Programming 33 3 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 33 3 . 2 An Example of a GP Problem . . . . . . . . . . . . . . . . . 33 3 . 3 Posynomials and the GP Problem . . . . . . . . . . . . . . 34 3 . 4 The Dual GP Problem . . . . . . . . . . . . . . . . . . . . . 35 3 . 5 Solving the GP Problem . . . . . . . . . . . . . . . . . . . . 38 3 . 6 Solving the DGP Problem . . . . . . . . . . . . . . . . . . . 38 3 . 6 . 1 The MART . . . . . . . . . . . . . . . . . . . . . . . 38 3 . 6 . 2 Using the MART to Solve the DGP Problem . . . . 40 3 . 7 Constrained Geometric Programming . . . . . . . . . . . . 41 3 . 8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 3 . 9 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 44 4 Basic Analysis 45 4 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 45 4 . 2 Minima and Inﬁma . . . . . . . . . . . . . . . . . . . . . . . 45 4 . 3 Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 4 . 4 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . 47 4 . 5 Continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4 . 6 Limsup and Liminf . . . . . . . . . . . . . . . . . . . . . . . 50 4 . 7 Another View . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4 . 8 Semi - Continuity . . . . . . . . . . . . . . . . . . . . . . . . 52 4 . 9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 4 . 10 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 54 5 Diﬀerentiation 55 5 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 55 5 . 2 Directional Derivative . . . . . . . . . . . . . . . . . . . . . 55 5 . 2 . 1 Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . 55 5 . 3 Partial Derivatives . . . . . . . . . . . . . . . . . . . . . . . 56 5 . 4 Some Examples . . . . . . . . . . . . . . . . . . . . . . . . . 57 5 . 4 . 1 Example 1 . . . . . . . . . . . . . . . . . . . . . . . . 57 5 . 4 . 2 Example 2 . . . . . . . . . . . . . . . . . . . . . . . . 57 5 . 5 Gˆateaux Derivative . . . . . . . . . . . . . . . . . . . . . . . 57 5 . 6 Fr´echet Derivative . . . . . . . . . . . . . . . . . . . . . . . 58 5 . 6 . 1 The Deﬁnition . . . . . . . . . . . . . . . . . . . . . 58 5 . 6 . 2 Properties of the Fr´echet Derivative . . . . . . . . . 58 CONTENTS iii 5 . 7 The Chain Rule . . . . . . . . . . . . . . . . . . . . . . . . . 59 5 . 8 A Useful Proposition . . . . . . . . . . . . . . . . . . . . . . 59 5 . 9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 5 . 10 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 61 6 Convex Sets 63 6 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 63 6 . 2 The Geometry of Real Euclidean Space . . . . . . . . . . . 63 6 . 2 . 1 Inner Products . . . . . . . . . . . . . . . . . . . . . 63 6 . 2 . 2 Cauchy’s Inequality . . . . . . . . . . . . . . . . . . 64 6 . 2 . 3 Other Norms . . . . . . . . . . . . . . . . . . . . . . 65 6 . 3 A Bit of Topology . . . . . . . . . . . . . . . . . . . . . . . 65 6 . 4 Convex Sets in R J . . . . . . . . . . . . . . . . . . . . . . . 66 6 . 4 . 1 Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . 67 6 . 4 . 2 Orthogonal Projection onto Convex Sets . . . . . . . 70 6 . 5 Some Results on Projections . . . . . . . . . . . . . . . . . . 73 6 . 6 Linear and Aﬃne Operators on R J . . . . . . . . . . . . . . 74 6 . 7 The Fundamental Theorems . . . . . . . . . . . . . . . . . . 75 6 . 7 . 1 Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . 75 6 . 7 . 2 The Separation Theorem . . . . . . . . . . . . . . . 76 6 . 7 . 3 The Support Theorem . . . . . . . . . . . . . . . . . 76 6 . 8 Theorems of the Alternative . . . . . . . . . . . . . . . . . . 78 6 . 9 Another Proof of Farkas’ Lemma . . . . . . . . . . . . . . . 82 6 . 10 Gordan’s Theorem 6 . 8 Revisited . . . . . . . . . . . . . . . 84 6 . 11 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 6 . 12 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 88 7 Matrices 89 7 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 89 7 . 2 Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . 89 7 . 3 Basic Linear Algebra . . . . . . . . . . . . . . . . . . . . . . 91 7 . 3 . 1 Bases and Dimension . . . . . . . . . . . . . . . . . . 91 7 . 3 . 2 The Rank of a Matrix . . . . . . . . . . . . . . . . . 92 7 . 3 . 3 The “Matrix Inversion Theorem” . . . . . . . . . . . 94 7 . 3 . 4 Systems of Linear Equations . . . . . . . . . . . . . 94 7 . 3 . 5 Real and Complex Systems of Linear Equations . . . 96 7 . 4 LU and QR Factorization . . . . . . . . . . . . . . . . . . . 97 7 . 5 The LU Factorization . . . . . . . . . . . . . . . . . . . . . 98 7 . 5 . 1 A Shortcut . . . . . . . . . . . . . . . . . . . . . . . 98 7 . 5 . 2 A Warning ! . . . . . . . . . . . . . . . . . . . . . . . 99 7 . 5 . 3 The QR Factorization and Least Squares . . . . . . 102 7 . 6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 7 . 7 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 103 iv CONTENTS 8 Linear Programming 105 8 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 105 8 . 2 Primal and Dual Problems . . . . . . . . . . . . . . . . . . . 105 8 . 2 . 1 An Example . . . . . . . . . . . . . . . . . . . . . . 106 8 . 2 . 2 Canonical and Standard Forms . . . . . . . . . . . . 106 8 . 2 . 3 From Canonical to Standard and Back . . . . . . . . 107 8 . 2 . 4 Weak Duality . . . . . . . . . . . . . . . . . . . . . . 107 8 . 2 . 5 Primal - Dual Methods . . . . . . . . . . . . . . . . . 108 8 . 2 . 6 Strong Duality . . . . . . . . . . . . . . . . . . . . . 108 8 . 3 The Basic Strong Duality Theorem . . . . . . . . . . . . . . 109 8 . 4 Another Proof of Theorem 8 . 2 . . . . . . . . . . . . . . . . . 110 8 . 5 Proof of Gale’s Strong Duality Theorem . . . . . . . . . . . 114 8 . 6 Some Examples . . . . . . . . . . . . . . . . . . . . . . . . . 115 8 . 6 . 1 The Diet Problem . . . . . . . . . . . . . . . . . . . 115 8 . 6 . 2 The Transport Problem . . . . . . . . . . . . . . . . 115 8 . 7 The Simplex Method . . . . . . . . . . . . . . . . . . . . . . 116 8 . 8 Numerical Considerations . . . . . . . . . . . . . . . . . . . 118 8 . 9 An Example of the Simplex Method . . . . . . . . . . . . . 119 8 . 10 Another Example of the Simplex Method . . . . . . . . . . 121 8 . 11 Some Possible Diﬃculties . . . . . . . . . . . . . . . . . . . 123 8 . 11 . 1 A Third Example : . . . . . . . . . . . . . . . . . . . 123 8 . 12 Topics for Projects . . . . . . . . . . . . . . . . . . . . . . . 124 8 . 13 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124 8 . 14 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 126 9 Matrix Games and Optimization 127 9 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 127 9 . 2 Two - Person Zero - Sum Games . . . . . . . . . . . . . . . . . 127 9 . 3 Deterministic Solutions . . . . . . . . . . . . . . . . . . . . 128 9 . 3 . 1 Optimal Pure Strategies . . . . . . . . . . . . . . . . 128 9 . 3 . 2 An Exercise . . . . . . . . . . . . . . . . . . . . . . . 128 9 . 4 Randomized Solutions . . . . . . . . . . . . . . . . . . . . . 129 9 . 4 . 1 Optimal Randomized Strategies . . . . . . . . . . . . 129 9 . 4 . 2 An Exercise . . . . . . . . . . . . . . . . . . . . . . . 130 9 . 4 . 3 The Min - Max Theorem . . . . . . . . . . . . . . . . 131 9 . 5 Symmetric Games . . . . . . . . . . . . . . . . . . . . . . . 132 9 . 5 . 1 An Example of a Symmetric Game . . . . . . . . . . 133 9 . 5 . 2 Comments on the Proof of the Min - Max Theorem . 133 9 . 6 Positive Games . . . . . . . . . . . . . . . . . . . . . . . . . 133 9 . 6 . 1 Some Exercises . . . . . . . . . . . . . . . . . . . . . 134 9 . 6 . 2 Comments . . . . . . . . . . . . . . . . . . . . . . . . 134 9 . 7 Example : The “Bluﬃng” Game . . . . . . . . . . . . . . . 134 9 . 8 Learning the Game . . . . . . . . . . . . . . . . . . . . . . . 136 9 . 8 . 1 An Iterative Approach . . . . . . . . . . . . . . . . . 137 CONTENTS v 9 . 8 . 2 An Exercise . . . . . . . . . . . . . . . . . . . . . . . 137 9 . 9 Non - Constant - Sum Games . . . . . . . . . . . . . . . . . . . 137 9 . 9 . 1 The Prisoners’ Dilemma . . . . . . . . . . . . . . . . 138 9 . 9 . 2 Two Pay - Oﬀ Matrices Needed . . . . . . . . . . . . . 138 9 . 9 . 3 An Example : Illegal Drugs in Sports . . . . . . . . . 139 9 . 10 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 139 10 Convex Functions 141 10 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 141 10 . 2 Functions of a Single Real Variable . . . . . . . . . . . . . . 141 10 . 2 . 1 Fundamental Theorems . . . . . . . . . . . . . . . . 141 10 . 2 . 2 Proof of Rolle’s Theorem . . . . . . . . . . . . . . . 142 10 . 2 . 3 Proof of the Mean Value Theorem . . . . . . . . . . 142 10 . 2 . 4 A Proof of the MVT for Integrals . . . . . . . . . . . 142 10 . 2 . 5 Two Proofs of the EMVT . . . . . . . . . . . . . . . 143 10 . 2 . 6 Lipschitz Continuity . . . . . . . . . . . . . . . . . . 144 10 . 2 . 7 The Convex Case . . . . . . . . . . . . . . . . . . . . 144 10 . 3 Functions of Several Real Variables . . . . . . . . . . . . . . 148 10 . 3 . 1 Continuity . . . . . . . . . . . . . . . . . . . . . . . 148 10 . 3 . 2 Diﬀerentiability . . . . . . . . . . . . . . . . . . . . . 148 10 . 3 . 3 Second Diﬀerentiability . . . . . . . . . . . . . . . . 150 10 . 3 . 4 Finding Maxima and Minima . . . . . . . . . . . . . 151 10 . 3 . 5 Solving F ( x ) = 0 through Optimization . . . . . . . 151 10 . 3 . 6 When is F ( x ) a Gradient ? . . . . . . . . . . . . . . . 151 10 . 3 . 7 Lower Semi - Continuity . . . . . . . . . . . . . . . . . 152 10 . 3 . 8 The Convex Case . . . . . . . . . . . . . . . . . . . . 153 10 . 4 Sub - Diﬀerentials and Sub - Gradients . . . . . . . . . . . . . 155 10 . 5 Sub - Diﬀerentials and Directional Derivatives . . . . . . . . 157 10 . 5 . 1 Some Deﬁnitions . . . . . . . . . . . . . . . . . . . . 157 10 . 5 . 2 Sub - Linearity . . . . . . . . . . . . . . . . . . . . . . 158 10 . 5 . 3 Sub - Gradients and Directional Derivatives . . . . . . 160 10 . 6 Functions and Operators . . . . . . . . . . . . . . . . . . . . 163 10 . 7 Convex Sets and Convex Functions . . . . . . . . . . . . . . 165 10 . 8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166 10 . 9 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 168 11 Convex Programming 169 11 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 169 11 . 2 The Primal Problem . . . . . . . . . . . . . . . . . . . . . . 169 11 . 2 . 1 The Perturbed Problem . . . . . . . . . . . . . . . . 170 11 . 2 . 2 The Sensitivity Vector . . . . . . . . . . . . . . . . . 170 11 . 2 . 3 The Lagrangian Function . . . . . . . . . . . . . . . 171 11 . 3 From Constrained to Unconstrained . . . . . . . . . . . . . 171 11 . 4 Saddle Points . . . . . . . . . . . . . . . . . . . . . . . . . . 172 vi CONTENTS 11 . 4 . 1 The Primal and Dual Problems . . . . . . . . . . . . 172 11 . 4 . 2 The Main Theorem . . . . . . . . . . . . . . . . . . . 173 11 . 4 . 3 A Duality Approach to Optimization . . . . . . . . . 173 11 . 5 The Karush - Kuhn - Tucker Theorem . . . . . . . . . . . . . . 174 11 . 5 . 1 Suﬃcient Conditions . . . . . . . . . . . . . . . . . . 174 11 . 5 . 2 The KKT Theorem : Saddle - Point Form . . . . . . . 174 11 . 5 . 3 The KKT Theorem - The Gradient Form . . . . . . . 175 11 . 6 On Existence of Lagrange Multipliers . . . . . . . . . . . . . 176 11 . 7 The Problem of Equality Constraints . . . . . . . . . . . . . 176 11 . 7 . 1 The Problem . . . . . . . . . . . . . . . . . . . . . . 176 11 . 7 . 2 The KKT Theorem for Mixed Constraints . . . . . . 177 11 . 7 . 3 The KKT Theorem for LP . . . . . . . . . . . . . . 177 11 . 7 . 4 The Lagrangian Fallacy . . . . . . . . . . . . . . . . 178 11 . 8 Two Examples . . . . . . . . . . . . . . . . . . . . . . . . . 179 11 . 8 . 1 A Linear Programming Problem . . . . . . . . . . . 179 11 . 8 . 2 A Nonlinear Convex Programming Problem . . . . . 180 11 . 9 The Dual Problem . . . . . . . . . . . . . . . . . . . . . . . 182 11 . 9 . 1 When is MP = MD ? . . . . . . . . . . . . . . . . . 182 11 . 9 . 2 The Primal - Dual Method . . . . . . . . . . . . . . . 183 11 . 9 . 3 Using the KKT Theorem . . . . . . . . . . . . . . . 183 11 . 10Non - Negative Least - Squares . . . . . . . . . . . . . . . . . . 183 11 . 11An Example in Image Reconstruction . . . . . . . . . . . . 184 11 . 12Solving the Dual Problem . . . . . . . . . . . . . . . . . . . 186 11 . 12 . 1The Primal and Dual Problems . . . . . . . . . . . . 186 11 . 12 . 2Hildreth’s Dual Algorithm . . . . . . . . . . . . . . . 186 11 . 13Minimum One - Norm Solutions . . . . . . . . . . . . . . . . 187 11 . 13 . 1Reformulation as an LP Problem . . . . . . . . . . . 188 11 . 13 . 2Image Reconstruction . . . . . . . . . . . . . . . . . 188 11 . 14Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190 11 . 15Course Homework . . . . . . . . . . . . . . . . . . . . . . . 191 12 Iterative Optimization 193 12 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 193 12 . 2 The Need for Iterative Methods . . . . . . . . . . . . . . . . 193 12 . 3 Optimizing Functions of a Single Real Variable . . . . . . . 194 12 . 3 . 1 Iteration and Operators . . . . . . . . . . . . . . . . 194 12 . 4 Descent Methods . . . . . . . . . . . . . . . . . . . . . . . . 195 12 . 5 Optimizing Functions of Several Real Variables . . . . . . . 196 12 . 6 Projected Gradient - Descent Methods . . . . . . . . . . . . . 198 12 . 6 . 1 Using Auxiliary - Function Methods . . . . . . . . . . 199 12 . 6 . 2 Proving Convergence . . . . . . . . . . . . . . . . . . 200 12 . 7 The Newton - Raphson Approach . . . . . . . . . . . . . . . 201 12 . 7 . 1 Functions of a Single Variable . . . . . . . . . . . . . 201 12 . 7 . 2 Functions of Several Variables . . . . . . . . . . . . . 202 CONTENTS vii 12 . 8 Approximate Newton - Raphson Methods . . . . . . . . . . . 203 12 . 8 . 1 Avoiding the Hessian Matrix . . . . . . . . . . . . . 203 12 . 8 . 2 Avoiding the Gradient . . . . . . . . . . . . . . . . . 205 12 . 9 Derivative - Free Methods . . . . . . . . . . . . . . . . . . . . 205 12 . 9 . 1 Multi - directional Search Algorithms . . . . . . . . . 205 12 . 9 . 2 The Nelder - Mead Algorithm . . . . . . . . . . . . . 205 12 . 9 . 3 Comments on the Nelder - Mead Algorithm . . . . . . 206 12 . 10Rates of Convergence . . . . . . . . . . . . . . . . . . . . . . 206 12 . 10 . 1Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . 206 12 . 10 . 2Illustrating Quadratic Convergence . . . . . . . . . . 207 12 . 10 . 3Motivating the Newton - Raphson Method . . . . . . 207 12 . 11Feasible - Point Methods . . . . . . . . . . . . . . . . . . . . 208 12 . 11 . 1The Projected Gradient Algorithm . . . . . . . . . . 208 12 . 11 . 2Reduced Gradient Methods . . . . . . . . . . . . . . 208 12 . 11 . 3The Reduced Newton - Raphson Method . . . . . . . 209 12 . 11 . 4A Primal - Dual Approach . . . . . . . . . . . . . . . 210 12 . 12Simulated Annealing . . . . . . . . . . . . . . . . . . . . . . 211 12 . 13Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212 12 . 14Course Homework . . . . . . . . . . . . . . . . . . . . . . . 213 13 Solving Systems of Linear Equations 215 13 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 215 13 . 2 Arbitrary Systems of Linear Equations . . . . . . . . . . . . 215 13 . 2 . 1 Under - determined Systems of Linear Equations . . . 216 13 . 2 . 2 Over - determined Systems of Linear Equations . . . . 217 13 . 2 . 3 Landweber’s Method . . . . . . . . . . . . . . . . . . 217 13 . 2 . 4 The Projected Landweber Algorithm . . . . . . . . . 217 13 . 2 . 5 The Split - Feasibility Problem . . . . . . . . . . . . . 218 13 . 2 . 6 An Extension of the CQ Algorithm . . . . . . . . . . 220 13 . 2 . 7 The Algebraic Reconstruction Technique . . . . . . . 221 13 . 2 . 8 Double ART . . . . . . . . . . . . . . . . . . . . . . 221 13 . 3 Regularization . . . . . . . . . . . . . . . . . . . . . . . . . 222 13 . 3 . 1 Norm - Constrained Least - Squares . . . . . . . . . . . 222 13 . 3 . 2 Regularizing Landweber’s Algorithm . . . . . . . . . 222 13 . 3 . 3 Regularizing the ART . . . . . . . . . . . . . . . . . 223 13 . 4 Non - Negative Systems of Linear Equations . . . . . . . . . 224 13 . 4 . 1 The Multiplicative ART . . . . . . . . . . . . . . . . 224 13 . 4 . 2 The Simultaneous MART . . . . . . . . . . . . . . . 225 13 . 4 . 3 The EMML Iteration . . . . . . . . . . . . . . . . . 225 13 . 4 . 4 Alternating Minimization . . . . . . . . . . . . . . . 226 13 . 4 . 5 The Row - Action Variant of EMML . . . . . . . . . . 226 13 . 5 Regularized SMART and EMML . . . . . . . . . . . . . . . 227 13 . 5 . 1 Regularized SMART . . . . . . . . . . . . . . . . . . 228 13 . 5 . 2 Regularized EMML . . . . . . . . . . . . . . . . . . 228 viii CONTENTS 13 . 6 Block - Iterative Methods . . . . . . . . . . . . . . . . . . . . 228 13 . 7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229 13 . 8 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 229 14 Conjugate - Direction Methods 231 14 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 231 14 . 2 Iterative Minimization . . . . . . . . . . . . . . . . . . . . . 231 14 . 3 Quadratic Optimization . . . . . . . . . . . . . . . . . . . . 232 14 . 4 Conjugate Bases for R J . . . . . . . . . . . . . . . . . . . . 234 14 . 4 . 1 Conjugate Directions . . . . . . . . . . . . . . . . . . 235 14 . 4 . 2 The Gram - Schmidt Method . . . . . . . . . . . . . . 236 14 . 5 The Conjugate Gradient Method . . . . . . . . . . . . . . . 237 14 . 5 . 1 The Main Idea . . . . . . . . . . . . . . . . . . . . . 237 14 . 5 . 2 A Recursive Formula . . . . . . . . . . . . . . . . . . 237 14 . 6 Krylov Subspaces . . . . . . . . . . . . . . . . . . . . . . . . 238 14 . 7 Extensions of the CGM . . . . . . . . . . . . . . . . . . . . 239 14 . 8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239 14 . 9 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 240 15 Auxiliary - Function Methods 241 15 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 241 15 . 2 Sequential Unconstrained Minimization . . . . . . . . . . . 241 15 . 2 . 1 Barrier - Function Methods . . . . . . . . . . . . . . . 241 15 . 2 . 2 Penalty - Function Methods . . . . . . . . . . . . . . . 242 15 . 3 Auxiliary Functions . . . . . . . . . . . . . . . . . . . . . . 243 15 . 4 Using AF Methods . . . . . . . . . . . . . . . . . . . . . . . 243 15 . 5 Deﬁnition and Basic Properties of AF Methods . . . . . . . 243 15 . 5 . 1 AF Requirements . . . . . . . . . . . . . . . . . . . . 244 15 . 5 . 2 Barrier - and Penalty - Function Methods as AF . . . 244 15 . 6 The SUMMA Class of AF Methods . . . . . . . . . . . . . . 245 16 Barrier - Function Methods 247 16 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 247 16 . 2 Barrier functions . . . . . . . . . . . . . . . . . . . . . . . . 247 16 . 2 . 1 Examples of Barrier Functions . . . . . . . . . . . . 247 16 . 3 Barrier - Function Methods as SUMMA . . . . . . . . . . . . 248 16 . 4 Behavior of Barrier - Function Algorithms . . . . . . . . . . . 249 17 Penalty - Function Methods 251 17 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 251 17 . 2 Penalty - function Methods . . . . . . . . . . . . . . . . . . . 251 17 . 2 . 1 Examples of Penalty Functions . . . . . . . . . . . . 251 17 . 2 . 2 Basic Facts . . . . . . . . . . . . . . . . . . . . . . . 254 CONTENTS ix 18 Proximity - Function Methods 257 18 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 257 18 . 2 Bregman Distances . . . . . . . . . . . . . . . . . . . . . . . 257 18 . 3 Proximal Minimization Algorithms . . . . . . . . . . . . . . 258 18 . 4 The IPA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260 18 . 4 . 1 The Landweber and Projected Landweber Algorithms 260 18 . 4 . 2 The Simultaneous MART . . . . . . . . . . . . . . . 261 18 . 4 . 3 Forward - Backward Splitting . . . . . . . . . . . . . . 262 19 Forward - Backward Splitting 263 19 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 263 19 . 2 Moreau’s Proximity Operators . . . . . . . . . . . . . . . . 263 19 . 3 Forward - Backward Splitting Algorithms . . . . . . . . . . . 263 19 . 4 Convergence of FBS . . . . . . . . . . . . . . . . . . . . . . 264 19 . 5 Some Examples . . . . . . . . . . . . . . . . . . . . . . . . . 266 19 . 5 . 1 Projected Gradient Descent . . . . . . . . . . . . . . 266 19 . 5 . 2 The CQ Algorithm . . . . . . . . . . . . . . . . . . . 266 19 . 5 . 3 The Projected Landweber Algorithm . . . . . . . . . 267 19 . 5 . 4 Minimizing f 2 over a Linear Manifold . . . . . . . . 267 20 Alternating Minimization 269 20 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 269 20 . 2 The AM Framework . . . . . . . . . . . . . . . . . . . . . . 269 20 . 2 . 1 The AM Iteration . . . . . . . . . . . . . . . . . . . 269 20 . 2 . 2 The Five - Point Property for AM . . . . . . . . . . . 270 20 . 2 . 3 The Main Theorem for AM . . . . . . . . . . . . . . 270 20 . 2 . 4 The Three - and Four - Point Properties . . . . . . . . 271 20 . 3 Alternating Bregman Distance Minimization . . . . . . . . 272 20 . 3 . 1 Bregman Distances . . . . . . . . . . . . . . . . . . . 272 20 . 3 . 2 The Eggermont - LaRiccia Lemma . . . . . . . . . . . 273 20 . 4 Minimizing a Proximity Function . . . . . . . . . . . . . . . 274 20 . 5 Right and Left Bregman Projections . . . . . . . . . . . . . 274 20 . 6 More Proximity Function Minimization . . . . . . . . . . . 275 20 . 6 . 1 Cimmino’s Algorithm . . . . . . . . . . . . . . . . . 275 20 . 6 . 2 Simultaneous Projection for Convex Feasibility . . . 276 20 . 6 . 3 The Bauschke - Combettes - Noll Problem . . . . . . . 276 20 . 7 AM as SUMMA . . . . . . . . . . . . . . . . . . . . . . . . 278 21 A Tale of Two Algorithms 279 21 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 279 21 . 2 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279 21 . 3 The Two Algorithms . . . . . . . . . . . . . . . . . . . . . . 279 21 . 4 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . 280 21 . 5 The Kullback - Leibler Distance . . . . . . . . . . . . . . . . 280 x CONTENTS 21 . 6 The Alternating Minimization Paradigm . . . . . . . . . . . 281 21 . 6 . 1 Some Pythagorean Identities Involving the KL Dis - tance . . . . . . . . . . . . . . . . . . . . . . . . . . 282 21 . 6 . 2 Convergence of the SMART and EMML . . . . . . . 282 22 SMART and EMML as AF 285 22 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 285 22 . 2 The SMART and the EMML . . . . . . . . . . . . . . . . . 285 22 . 2 . 1 The SMART Iteration . . . . . . . . . . . . . . . . . 285 22 . 2 . 2 The EMML Iteration . . . . . . . . . . . . . . . . . 285 22 . 2 . 3 The EMML and the SMART as Alternating Mini - mization . . . . . . . . . . . . . . . . . . . . . . . . . 286 22 . 3 The SMART as a Case of SUMMA . . . . . . . . . . . . . . 286 22 . 4 The SMART as a Case of the PMA . . . . . . . . . . . . . 287 22 . 5 SMART and EMML as Projection Methods . . . . . . . . . 288 22 . 6 The MART and EMART Algorithms . . . . . . . . . . . . . 289 22 . 7 Possible Extensions of MART and EMART . . . . . . . . . 290 23 Fermi - Dirac Entropy 291 23 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 291 23 . 2 Modifying the KL distance . . . . . . . . . . . . . . . . . . 291 23 . 3 The ABMART Algorithm . . . . . . . . . . . . . . . . . . . 292 23 . 4 The ABEMML Algorithm . . . . . . . . . . . . . . . . . . . 293 24 Calculus of Variations 295 24 . 1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 295 24 . 2 Some Examples . . . . . . . . . . . . . . . . . . . . . . . . . 296 24 . 2 . 1 The Shortest Distance . . . . . . . . . . . . . . . . . 296 24 . 2 . 2 The Brachistochrone Problem . . . . . . . . . . . . . 296 24 . 2 . 3 Minimal Surface Area . . . . . . . . . . . . . . . . . 297 24 . 2 . 4 The Maximum Area . . . . . . . . . . . . . . . . . . 297 24 . 2 . 5 Maximizing Burg Entropy . . . . . . . . . . . . . . . 298 24 . 3 Comments on Notation . . . . . . . . . . . . . . . . . . . . 298 24 . 4 The Euler - Lagrange Equation . . . . . . . . . . . . . . . . . 299 24 . 5 Special Cases of the Euler - Lagrange Equation . . . . . . . . 300 24 . 5 . 1 If f is independent of v . . . . . . . . . . . . . . . . 300 24 . 5 . 2 If f is independent of u . . . . . . . . . . . . . . . . 300 24 . 6 Using the Euler - Lagrange Equation . . . . . . . . . . . . . . 301 24 . 6 . 1 The Shortest Distance . . . . . . . . . . . . . . . . . 301 24 . 6 . 2 The Brachistochrone Problem . . . . . . . . . . . . . 302 24 . 6 . 3 Minimizing the Surface Area . . . . . . . . . . . . . 303 24 . 7 Problems with Constraints . . . . . . . . . . . . . . . . . . . 304 24 . 7 . 1 The Isoperimetric Problem . . . . . . . . . . . . . . 304 24 . 7 . 2 Burg Entropy . . . . . . . . . . . . . . . . . . . . . . 305 CONTENTS xi 24 . 8 The Multivariate Case . . . . . . . . . . . . . . . . . . . . . 305 24 . 9 Finite Constraints . . . . . . . . . . . . . . . . . . . . . . . 307 24 . 9 . 1 The Geodesic Problem . . . . . . . . . . . . . . . . . 307 24 . 9 . 2 An Example . . . . . . . . . . . . . . . . . . . . . . 310 24 . 10Hamilton’s Principle and the Lagrangian . . . . . . . . . . . 311 24 . 10 . 1Generalized Coordinates . . . . . . . . . . . . . . . . 311 24 . 10 . 2Homogeneity and Euler’s Theorem . . . . . . . . . . 312 24 . 10 . 3Hamilton’s Principle . . . . . . . . . . . . . . . . . . 313 24 . 11Sturm - Liouville Diﬀerential Equations . . . . . . . . . . . . 313 24 . 12Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314 25 Bregman - Legendre Functions 315 25 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 315 25 . 2 Essential Smoothness and Essential Strict Convexity . . . . 315 25 . 3 Bregman Projections onto Closed Convex Sets . . . . . . . 316 25 . 4 Bregman - Legendre Functions . . . . . . . . . . . . . . . . . 317 25 . 5 Useful Results about Bregman - Legendre Functions . . . . . 317 26 Coordinate - Free Calculus 319 26 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 319 26 . 2 Euclidean Spaces . . . . . . . . . . . . . . . . . . . . . . . . 319 26 . 3 The Diﬀerential and the Gradient . . . . . . . . . . . . . . . 321 26 . 4 An Example in S J . . . . . . . . . . . . . . . . . . . . . . . 321 26 . 5 The Hessian . . . . . . . . . . . . . . . . . . . . . . . . . . . 322 26 . 6 Newton’s Method . . . . . . . . . . . . . . . . . . . . . . . . 323 26 . 7 Intrinsic Inner Products . . . . . . . . . . . . . . . . . . . . 324 26 . 8 Self - Concordant Functions . . . . . . . . . . . . . . . . . . . 324 26 . 9 Two Examples . . . . . . . . . . . . . . . . . . . . . . . . . 325 26 . 9 . 1 The Logarithmic Barrier Function . . . . . . . . . . 325 26 . 9 . 2 An Extension to S J + + . . . . . . . . . . . . . . . . . 326 26 . 10Using Self - Concordant Barrier Functions . . . . . . . . . . . 326 26 . 11Semi - Deﬁnite Programming . . . . . . . . . . . . . . . . . . 326 26 . 11 . 1Quadratically Constrained Quadratic Programs . . . 326 26 . 11 . 2Semideﬁnite Relaxation . . . . . . . . . . . . . . . . 327 26 . 11 . 3Semideﬁnite Programming . . . . . . . . . . . . . . . 327 26 . 12Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327 27 Quadratic Programming 329 27 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 329 27 . 2 The Quadratic - Programming Problem . . . . . . . . . . . . 329 27 . 3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . 331 27 . 4 Quadratic Programming with Equality Constraints . . . . . 332 27 . 5 Sequential Quadratic Programming . . . . . . . . . . . . . . 333 xii CONTENTS 28 Modiﬁed - Gradient Algorithms 335 28 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 335 28 . 2 Emission Tomography . . . . . . . . . . . . . . . . . . . . . 335 28 . 3 The Discrete Problem . . . . . . . . . . . . . . . . . . . . . 336 28 . 4 Likelihood Maximization . . . . . . . . . . . . . . . . . . . . 336 28 . 5 Gradient Ascent : The EMML Algorithm . . . . . . . . . . . 337 28 . 6 Another View of the EMML Algorithm . . . . . . . . . . . 338 28 . 7 A Partial - Gradient Approach . . . . . . . . . . . . . . . . . 338 28 . 8 The Simultaneous MART Algorithm . . . . . . . . . . . . . 339 28 . 9 Alternating Minimization . . . . . . . . . . . . . . . . . . . 341 28 . 9 . 1 The EMML Algorithm Revisited . . . . . . . . . . . 341 28 . 9 . 2 The SMART Revisited . . . . . . . . . . . . . . . . . 342 28 . 10Eﬀects of Noisy Data . . . . . . . . . . . . . . . . . . . . . . 343 29 Likelihood Maximization 345 29 . 1 Statistical Parameter Estimation . . . . . . . . . . . . . . . 345 29 . 2 Maximizing the Likelihood Function . . . . . . . . . . . . . 345 29 . 2 . 1 Example 1 : Estimating a Gaussian Mean . . . . . . 346 29 . 2 . 2 Example 2 : Estimating a Poisson Mean . . . . . . . 347 29 . 2 . 3 Example 3 : Estimating a Uniform Mean . . . . . . . 347 29 . 2 . 4 Example 4 : Image Restoration . . . . . . . . . . . . 348 29 . 2 . 5 Example 5 : Poisson Sums . . . . . . . . . . . . . . . 348 29 . 2 . 6 Example 6 : Finite Mixtures of Probability Vectors . 349 29 . 2 . 7 Example 7 : Finite Mixtures of Probability Density Functions . . . . . . . . . . . . . . . . . . . . . . . . 351 29 . 3 Alternative Approaches . . . . . . . . . . . . . . . . . . . . 352 30 Operators 355 30 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 355 30 . 2 Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355 30 . 3 Contraction Operators . . . . . . . . . . . . . . . . . . . . . 356 30 . 3 . 1 Lipschitz Continuous Operators . . . . . . . . . . . . 356 30 . 3 . 2 Non - Expansive Operators . . . . . . . . . . . . . . . 356 30 . 3 . 3 Strict Contractions . . . . . . . . . . . . . . . . . . . 358 30 . 3 . 4 Eventual Strict Contractions . . . . . . . . . . . . . 358 30 . 3 . 5 Instability . . . . . . . . . . . . . . . . . . . . . . . . 359 30 . 4 Orthogonal Projection Operators . . . . . . . . . . . . . . . 359 30 . 4 . 1 Properties of the Operator P C . . . . . . . . . . . . 360 30 . 5 Two Useful Identities . . . . . . . . . . . . . . . . . . . . . . 361 30 . 6 Averaged Operators . . . . . . . . . . . . . . . . . . . . . . 362 30 . 7 Gradient Operators . . . . . . . . . . . . . . . . . . . . . . . 364 30 . 7 . 1 The Krasnosel’skii - Mann - Opial Theorem . . . . . . . 365 30 . 8 Aﬃne Linear Operators . . . . . . . . . . . . . . . . . . . . 366 30 . 8 . 1 The Hermitian Case . . . . . . . . . . . . . . . . . . 366 CONTENTS xiii 30 . 9 Paracontractive Operators . . . . . . . . . . . . . . . . . . . 366 30 . 9 . 1 Linear and Aﬃne Paracontractions . . . . . . . . . . 367 30 . 9 . 2 The Elsner - Koltracht - Neumann Theorem . . . . . . 368 30 . 10Matrix Norms . . . . . . . . . . . . . . . . . . . . . . . . . . 370 30 . 10 . 1Induced Matrix Norms . . . . . . . . . . . . . . . . . 370 30 . 10 . 2Condition Number of a Square Matrix . . . . . . . . 370 30 . 10 . 3Some Examples of Induced Matrix Norms . . . . . . 371 30 . 10 . 4The Euclidean Norm of a Square Matrix . . . . . . . 373 30 . 11Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375 31 Saddle - Point Problems and Algorithms 377 31 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 377 31 . 2 Monotone Functions . . . . . . . . . . . . . . . . . . . . . . 377 31 . 3 The Split - Feasibility Problem . . . . . . . . . . . . . . . . . 378 31 . 4 The Variational Inequality Problem . . . . . . . . . . . . . . 379 31 . 5 Korpelevich’s Method for the VIP . . . . . . . . . . . . . . 379 31 . 5 . 1 The Special Case of C = R J . . . . . . . . . . . . . . 380 31 . 5 . 2 The General Case . . . . . . . . . . . . . . . . . . . 381 31 . 6 On Some Algorithms of Noor . . . . . . . . . . . . . . . . . 383 31 . 6 . 1 My Conjecture . . . . . . . . . . . . . . . . . . . . . 383 31 . 7 The Split Variational Inequality Problem . . . . . . . . . . 385 31 . 8 Saddle Points . . . . . . . . . . . . . . . . . . . . . . . . . . 387 31 . 8 . 1 Notation and Basic Facts . . . . . . . . . . . . . . . 387 31 . 8 . 2 The Saddle - Point Problem as a VIP . . . . . . . . . 387 31 . 8 . 3 Example : Convex Programming . . . . . . . . . . . 388 31 . 8 . 4 Example : Linear Programming . . . . . . . . . . . . 388 31 . 8 . 5 Example : Game Theory . . . . . . . . . . . . . . . . 388 31 . 9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389 32 Set - Valued Functions in Optimization 391 32 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 391 32 . 2 Notation and Deﬁnitions . . . . . . . . . . . . . . . . . . . . 391 32 . 3 Basic Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . 392 32 . 4 Monotone Set - Valued Functions . . . . . . . . . . . . . . . . 393 32 . 5 Resolvents . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393 32 . 6 The Split Monotone Variational Inclusion Problem . . . . . 394 32 . 7 Solving the SMVIP . . . . . . . . . . . . . . . . . . . . . . . 395 32 . 8 Special Cases of the SMVIP . . . . . . . . . . . . . . . . . . 395 32 . 8 . 1 The Split Minimization Problem . . . . . . . . . . . 395 32 . 9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395 xiv CONTENTS 33 Convex Feasibility and Related Problems 397 33 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 397 33 . 1 . 1 The Convex Feasibility Problem . . . . . . . . . . . 397 33 . 1 . 2 Constrained Optimization . . . . . . . . . . . . . . . 397 33 . 1 . 3 Proximity Function Minimization . . . . . . . . . . . 398 33 . 1 . 4 The Moreau Envelope and Proximity Operators . . . 400 33 . 1 . 5 The Split - Feasibility Problem . . . . . . . . . . . . . 400 33 . 2 Algorithms Based on Orthogonal Projection . . . . . . . . . 400 33 . 2 . 1 Projecting onto the Intersection of Convex Sets . . . 402 33 . 3 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403 34 Fenchel Duality 405 34 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 405 34 . 2 The Legendre - Fenchel Transformation . . . . . . . . . . . . 405 34 . 2 . 1 The Fenchel Conjugate . . . . . . . . . . . . . . . . 405 34 . 2 . 2 The Conjugate of the Conjugate . . . . . . . . . . . 406 34 . 2 . 3 Some Examples of Conjugate Functions . . . . . . . 407 34 . 2 . 4 Inﬁmal Convolution Again . . . . . . . . . . . . . . . 408 34 . 2 . 5 Conjugates and Sub - gradients . . . . . . . . . . . . . 409 34 . 2 . 6 The Conjugate of a Concave Function . . . . . . . . 409 34 . 3 Fenchel’s Duality Theorem . . . . . . . . . . . . . . . . . . 410 34 . 3 . 1 Fenchel’s Duality Theorem : Diﬀerentiable Case . . . 411 34 . 3 . 2 Optimization over Convex Subsets . . . . . . . . . . 412 34 . 4 An Application to Game Theory . . . . . . . . . . . . . . . 412 34 . 4 . 1 Pure and Randomized Strategies . . . . . . . . . . . 412 34 . 4 . 2 The Min - Max Theorem . . . . . . . . . . . . . . . . 413 34 . 5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415 34 . 6 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 415 35 Non - smooth Optimization 417 35 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 417 35 . 2 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417 35 . 3 Moreau’s Proximity Operators . . . . . . . . . . . . . . . . 418 35 . 4 Forward - Backward Splitting . . . . . . . . . . . . . . . . . . 420 35 . 4 . 1 The FBS algorithm . . . . . . . . . . . . . . . . . . . 421 35 . 4 . 2 A Simpler Convergence Proof for FBS . . . . . . . . 421 35 . 4 . 3 The CQ Algorithm as Forward - Backward Splitting . 423 35 . 5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424 35 . 6 Course Homework . . . . . . . . . . . . . . . . . . . . . . . 424 36 Generalized Projections onto Convex Sets 425 36 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 425 36 . 2 Bregman Functions and Bregman Distances . . . . . . . . . 425 36 . 3 The Successive Generalized Projections Algorithm . . . . . 426 CONTENTS xv 36 . 4 Bregman’s Primal - Dual Algorithm . . . . . . . . . . . . . . 427 36 . 5 Dykstra’s Algorithm for Bregman Projections . . . . . . . . 428 36 . 5 . 1 A Helpful Lemma . . . . . . . . . . . . . . . . . . . 428 37 Compressed Sensing 431 37 . 1 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . 431 37 . 2 Compressed Sensing . . . . . . . . . . . . . . . . . . . . . . 431 37 . 3 Sparse Solutions . . . . . . . . . . . . . . . . . . . . . . . . 433 37 . 3 . 1 Maximally Sparse Solutions . . . . . . . . . . . . . . 433 37 . 3 . 2 Minimum One - Norm Solutions . . . . . . . . . . . . 433 37 . 3 . 3 Why the One - Norm ? . . . . . . . . . . . . . . . . . . 433 37 . 3 . 4 Comparison with the PDFT . . . . . . . . . . . . . . 434 37 . 3 . 5 Iterative Reweighting . . . . . . . . . . . . . . . . . 435 37 . 4 Why Sparseness ? . . . . . . . . . . . . . . . . . . . . . . . . 435 37 . 4 . 1 Signal Analysis . . . . . . . . . . . . . . . . . . . . . 435 37 . 4 . 2 Locally Constant Signals . . . . . . . . . . . . . . . . 437 37 . 4 . 3 Tomographic Imaging . . . . . . . . . . . . . . . . . 437 37 . 5 Compressed Sampling . . . . . . . . . . . . . . . . . . . . . 438 Bibliography 438 Index 455 xvi CONTENTS Chapter 1 Preface 1 . 1 Overview There are many branches of optimization , such as discrete optimization , combinatorial optimization , stochastic optimization , and others . In this book the focus is on continuous optimization , meaning that the functions to be optimized are functions of one or more continuous variables . The focus is on generality , with emphasis on the fundamental problems of constrained and unconstrained optimization , linear and convex programming , on the fundamental iterative solution algorithms , gradient methods , the Newton - Raphson algorithm and its variants , sequential unconstrained optimization methods , and on the necessary mathematical tools and results that provide the proper foundation for our discussions . We include some applications , such as game theory , but the emphasis is on general problems and the underlying theory . 1 . 2 Two Types of Applications One reason for the usefulness of optimization in applied mathematics is that Nature herself often optimizes , or perhaps a better way to say it , economizes . The patterns and various sizes of tree branches form eﬃcient communication networks ; the hexagonal structures in honeycombs are an eﬃcient way to ﬁll the space ; the shape of a soap bubble minimizes the potential energy in the surface tension ; and so on . Optimization means maximizing or minimizing some function of one or , more often , several vari - ables . The function to be optimized is called the objective function . There are two distinct types of applications that lead to optimization problems , which , to give them a name , we shall call problems of optimization and problems of inference . 1 2 CHAPTER 1 . PREFACE 1 . 2 . 1 Natural Optimization On the one hand , there are problems of optimization that we might call natural optimization problems , in which optimizing the given function is , more or less , the sole and natural objective . The main goal , maximum proﬁts , shortest commute , is not open to question , although the precise function involved will depend on the simpliﬁcations adopted as the real - world problem is turned into mathematics . Examples of such problems are a manufacturer seeking to maximize proﬁts , subject to whatever restric - tions the situation imposes , or a commuter trying to minimize the time it takes to get to work , subject , of course , to speed limits . In converting the real - world problem to a mathematical problem , the manufacturer may or may not ignore non - linearities such as economies of scale , and the com - muter may or may not employ probabilistic models of traﬃc density . The resulting mathematical optimization problem to be solved will depend on such choices , but the original real - world problem is one of optimization , nevertheless . Operations Research ( OR ) is a broad ﬁeld involving a variety of applied optimization problems . Wars and organized violence have always given impetus to technological advances , most signiﬁcantly during the twentieth century . An important step was taken when scientists employed by the military realized that studying and improving the use of existing technology could be as important as discovering new technology . Conducting research into on - going operations , that is , doing operations research , led to the search for better , indeed , optimal , ways to schedule ships entering port , to design convoys , to paint the under - sides of aircraft , to hunt submarines , and many other seemingly mundane tasks [ 137 ] . Problems having to do with the allocation of limited resources arise in a wide variety of applications , all of which fall under the broad umbrella of OR . Sometimes we may want to optimize more than one thing ; that is , we may have more than one objective function that we wish to optimize . In image processing , we may want to ﬁnd an image as close as possible to measured data , but one that also has sharp edges . In general , such multiple - objective optimization is not possible ; what is best in one respect need not be best in other respects . In such cases , it is common to create a single objective function that is a combination , a sum perhaps , of the original objective functions , and then to optimize this combined objective function . In this way , the optimizer of the combined objective function provides a sort of compromise . The goal of simultaneously optimizing more than one objective func - tion , the so - called multiple - objective function problem , is a common fea - ture of many economics problems , such as bargaining situations , in which the various parties all wish to steer the outcome to their own advantage . Typically , of course , no single solution will optimize everyone’s objective 1 . 2 . TWO TYPES OF APPLICATIONS 3 function . Bargaining is then a method for ﬁnding a solution that , in some sense , makes everyone equally happy or unhappy . A Nash equilibrium is such a solution . In 1994 , the mathematician John Nash was awarded the Nobel Prize in Economics for his work in optimization and mathematical economics . His theory of equilibria is fundamental in the study of bargaining and game theory . In her book A Beautiful Mind [ 162 ] , later made into a movie of the same name starring Russell Crowe , Sylvia Nasar tells the touching story of Nash’s struggle with schizophrenia , said to have been made more acute by his obsession with the mysteries of quantum mechanics . Strictly speaking , there is no Nobel Prize in Economics ; what he received is “The Central Bank of Sweden Prize in Economic Science in Memory of Alfred Nobel” , which was instituted seventy years after Nobel created his prizes . Nevertheless , it is commonly spoken of as a Nobel Prize . To illustrate the notion of a Nash equilibrium , imagine that there are J store owners , each selling the same N items . Let p jn be the price that the j th seller charges for one unit of the n th item . The vector p j = ( p j 1 , . . . , p jN ) is then the list of prices used by the j th seller . Denote by P the set of all price vectors , P = { p 1 , . . . , p J } . How happy the j th seller is with his list p j will depend on what his com - petitors are charging . For each j denote by f j ( p 1 , p 2 , . . . , p J ) a quantitative measure of how happy the j th seller is with the entire pricing structure . Once the prices are set , it is natural for each individual seller to consider what might happen if he alone were to change his prices . Let the vector x = ( x 1 , . . . , x N ) denote an arbitrary set of prices that the j th seller might decide to use . The function g j ( x | P ) = f j ( p 1 , . . . , p j − 1 , x , p j + 1 , . . . , p J ) provides a quantitative measure of how happy the j th seller would be if he were to adopt the prices x , while the others continued to use the vectors in P . Note that all we have done is to replace the vector p j with the variable vector x . The j th seller might then select the vector x for which g j ( x | P ) is greatest . The problem , of course , is that once the j th seller has selected his best x , given P , the others may well change their prices also . A Nash equilibrium is a set of price vectors ˆ P = { ˆ p 1 , . . . , ˆ p J } with the property that g j ( ˆ p j | ˆ P ) ≥ g j ( x | ˆ P ) , for each j . In other words , once the sellers adopt the prices ˆ p jn , no individual seller has any motivation to change his prices . Nash showed that , with 4 CHAPTER 1 . PREFACE certain assumptions made about the behavior of the functions f j and the set of possible price vectors , there will be such an equilibrium set of price vectors . 1 . 2 . 2 Problems of Inference In addition to natural optimization problems , there are artiﬁcial optimiza - tion problems , often problems of inference , for which optimization provides useful tools , but is not the primary objective . These are often problems in which estimates are to be made from observations . Such problems arise in many remote sensing applications , radio astronomy , or medical imag - ing , for example , in which , for practical reasons , the data obtained are insuﬃcient or too noisy to specify a unique source , and one turns to op - timization methods , such as likelihood maximization or least - squares , to provide usable approximations . In such cases , it is not the optimization of a function that concerns us , but the optimization of technique . We cannot know which reconstructed image is the best , in the sense of most closely describing the true situation , but we do know which techniques of reconstruction are “best” in some speciﬁc sense . We choose techniques such as likelihood or entropy maximization , or least - mean - squares mini - mization , because these methods are “optimal” in some sense , not because any single result obtained using these methods is guaranteed to be the best . Generally , these methods are “best”in some average sense ; indeed , this is the basic idea in statistical estimation . Artiﬁcial optimization arises , for example , in solving systems of linear equations , Ax = b . Suppose , ﬁrst , that this system has no solution ; this over - determined case is common in practice , when the entries of the vector b are not perfectly accurate measurements of something . For example , consider the system of two equations in one unknown x = 1 and x = 2 ; clearly there is no x that satisﬁes this system . We then turn the problem into an optimization problem , by seeking the best compromise . One way that might occur to us is to minimize f ( x ) = | x − 1 | + | x − 2 | . This doesn’t work , however ; f ( x ) = 1 for every x in the interval [ 1 , 2 ] , so minimizing f ( x ) does not help us select a unique best answer . Instead , we try minimizing g ( x ) = ( x − 1 ) 2 + ( x − 2 ) 2 . Diﬀerentiating and setting the derivative to zero , we ﬁnd that 0 = 2 ( x − 1 ) + 2 ( x − 2 ) , or x = 1 . 5 . This is the least squares solution to the system . 1 . 2 . TWO TYPES OF APPLICATIONS 5 More generally , if we cannot ﬁnd an exact solution of Ax = b , we often turn to a least squares solution , which is a vector x that minimizes the function f ( x ) = (cid:107) Ax − b (cid:107) 2 . Unless otherwise noted , a norm of an N - dimensional vector will be the Euclidean norm or two - norm , given by (cid:107) z (cid:107) 2 = (cid:112) | z 1 | 2 + . . . + | z N | 2 . It usually is the case that there is only one such least - squares solution x , but it can happen that there is more than one . Suppose now that the system Ax = b has multiple solutions . This under - determined case also arises frequently in practice , when the entries of the vector b are measurements , but there aren’t enough of them to specify one unique x . In such cases , we can use optimization to help us select one solution from the many possible ones ; we can ﬁnd the minimum norm solution , which is the one that minimizes (cid:107) x (cid:107) 2 , subject to Ax = b . For example , consider the system of one equation in two unknowns x 1 + x 2 = 1 ; there are inﬁnitely many solutions . Unless we have a reason to do otherwise , it is reasonable to select the pair x = ( x 1 , x 2 ) that satisﬁes the equation and is closest to the origin ; that is , we minimize (cid:107) x (cid:107) 2 , subject to x 1 + x 2 = 1 . This is the minimum two - norm solution . For our example , the minimum two - norm solution is x 1 = x 2 = 0 . 5 . We often have a combination of the two situations , in which the entries of b are somewhat inaccurate measurements , but there are not enough of them , so multiple exact solutions exist . Because these measurements are somewhat inaccurate , we may not want an exact solution ; such an exact solution may have an unreasonably large norm . In such cases , we may seek a minimizer of the function g ( x ) = (cid:107) Ax − b (cid:107) 22 + (cid:15) (cid:107) x (cid:107) 22 . Now we are trying to get Ax close to b , but are keeping the norm of x under control at the same time . As we shall see , in both types of problems , the optimization usually cannot be performed by algebraic means alone and iterative algorithms are required . The mathematical tools required do not usually depend on which type of problem we are trying to solve . A manufacturer may use the theory of linear programming to maximize proﬁts , while an oncologist may use likelihood maximization to image a tumor and linear programming to determine a suitable spatial distribution of radiation intensities for the therapy . The only diﬀerence , perhaps , is that the doctor may have some choice in how , or even whether or not , to involve optimization in solving the medical 6 CHAPTER 1 . PREFACE problems , while the manufacturer’s problem is an optimization problem from the start , and a linear programming problem once the mathematical model is selected . 1 . 3 Types of Optimization Problems The optimization problems we shall discuss diﬀer , one from another , in the nature of the functions being optimized and the constraints that may or may not be imposed . The constraints may , themselves , involve other func - tions ; we may wish to minimize f ( x ) , subject to the constraint g ( x ) ≤ 0 . The functions may be diﬀerentiable , or not , they may be linear , or not . If they are not linear , they may be convex . They may become linear or convex once we change variables . The various problem types have names , such as Linear Programming , Quadratic Programming , Geometric Programming , and Convex Programming ; the use of the term ‘programming’ is an his - torical accident and has no connection with computer programming . All of the problems discussed so far involve functions of one or several real variables . In the Calculus of Variations , the function to be optimized is a functional , which is a real - valued function of functions . For example , we may wish to ﬁnd the curve having the shortest length connecting two given points , say ( 0 , 0 ) and ( 1 , 1 ) , in R 2 . The functional to be minimized is J ( y ) = (cid:90) 1 0 (cid:114) 1 + (cid:0) dy dx (cid:1) 2 dx . We know that the optimal function is a straight line . In general , the optimal function y = f ( x ) will satisfy a diﬀerential equation , known as the Euler - Lagrange Equation . 1 . 4 When Have We Solved the Problem ? Suppose we want to minimize the quartic function f ( x ) = x 4 − 10 x 3 + 35 x 2 − 50 x + 24 . The obvious way to begin is to calculate the derivative , which is f (cid:48) ( x ) = 4 x 3 − 30 x 2 + 70 x − 50 . We know that any minimizer of f ( x ) will satisfy f (cid:48) ( x ) = 0 , so , in a sense , we have “solved” the problem . We have found a necessary condition for a minimizer of f ( x ) ; in this example , it is a necessary and suﬃcient condition for a local extremum , but there may be local maxima . There are at most 1 . 5 . ALGORITHMS 7 three roots to examine , so the rest is easy . Or , is it ? Finding the roots of the derivative is not a simple matter . We now have two choices . The ﬁrst choice is to apply an iterative approximation method , like the bisection method , to ﬁnd the roots of f (cid:48) ( x ) . The second choice is to forget about f (cid:48) ( x ) and to estimate the minimizer of f ( x ) directly . Both choices involve iterative algorithms . The situation we face here is typical of optimization problems . The theory may provide us with conditions that the solution must satisfy , but using these conditions to calculate the answer may not be easy . We then have the choice of employing iterative methods to approximate vectors that satisfy the conditions , or using iterative methods to minimize the function directly . The algorithms we shall study are of both types . 1 . 5 Algorithms The algorithms we shall study in this course are mainly general - purpose optimization methods . In the companion text ACLA , we focus more on techniques tailored to particular problems . 1 . 5 . 1 Root - Finding One of the ﬁrst applications of the derivative that we encounter in Calcu - lus I is optimization , maximizing or minimizing a diﬀerentiable real - valued function f ( x ) of a single real variable over x in some interval [ a , b ] . Since f ( x ) is diﬀerentiable , it is continuous , so we know that f ( x ) attains its maximum and minimum values over the interval [ a , b ] . The standard pro - cedure is to diﬀerentiate f ( x ) and compare the values of f ( x ) at the places where f (cid:48) ( x ) = 0 with the values f ( a ) and f ( b ) . These places include the values of x where the optimal values of f ( x ) occur . However , we may not be able to solve the equation f (cid:48) ( x ) = 0 algebraically , and may need to employ numerical , approximate techniques . It may , in fact , be simpler to use an iterative technique to minimize f ( x ) directly . Perhaps the simplest example of an iterative method is the bi - section method for ﬁnding a root of a continuous function of a single real variable . Let g : R → R be continuous . Suppose that g ( a ) < 0 and g ( b ) > 0 . Then , by the Intermediate Value Theorem , we know that there is a point c in ( a , b ) with g ( c ) = 0 . Let m = a + b 2 be the mid - point of the interval . If g ( m ) = 0 , then we are done . If g ( m ) < 0 , replace a with m ; otherwise , replace b with m . Now calculate the mid - point of the new interval and continue . At each step , the new interval is half as big as the old one and still contains a root of g ( x ) . The distance from the left end point to the root is not greater than the length of the interval , which provides a good estimate of the accuracy of the approximation . 8 CHAPTER 1 . PREFACE 1 . 5 . 2 Iterative Descent Methods Suppose that we wish to minimize the real - valued function f : R J → R of J real variables . If f is Gˆateaux - diﬀerentiable ( see the chapter on Diﬀer - entiation ) , then the two - sided directional derivative of f , at the point a , in the direction of the unit vector d , is f (cid:48) ( a ; d ) = lim t → 0 1 t [ f ( a + td ) − f ( a ) ] = (cid:104)∇ f ( a ) , d (cid:105) . According to the Cauchy - Schwarz Inequality , we have | (cid:104)∇ f ( a ) , d (cid:105) | ≤ | | ∇ f ( a ) | | 2 | | d | | 2 , with equality if and only if the direction vector d is parallel to the vector ∇ f ( a ) . Therefore , from the point a , the direction of greatest increase of f is d = ∇ f ( a ) , and the direction of greatest decrease is d = −∇ f ( a ) . If f is Gˆateaux - diﬀerentiable , and f ( a ) ≤ f ( x ) , for all x , then ∇ f ( a ) = 0 . Therefore , we can , in theory , ﬁnd the minimum of f by ﬁnding the point ( or points ) x = a where the gradient is zero . For example , suppose we wish to minimize the function f ( x , y ) = 3 x 2 + 4 xy + 5 y 2 + 6 x + 7 y + 8 . Setting the partial derivatives to zero , we have 0 = 6 x + 4 y + 6 , and 0 = 4 x + 10 y + 7 . Therefore , minimizing f ( x , y ) involves solving this system of two linear equations in two unknowns . This is easy , but if f has many variables , not just two , or if f is not a quadratic function , the resulting system will be quite large and may include nonlinear functions , and we may need to employ iterative methods to solve this system . Once we decide that we need to use iterative methods , we may as well consider using them directly on the original optimization problem , rather than to solve the system derived by setting the gradient to zero . We cannot hope to solve all optimization problems simply by setting the gradient to zero and solving the resulting system of equations algebraically . For k = 0 , 1 , . . . , having calculated the current estimate x k , we select a direction vector d k such that f ( x k + αd k ) is decreasing , as a function of α > 0 , and a step - length α k . Our next estimate is x k + 1 = x k + α k d k . We may choose α k to minimize f ( x k + αd k ) , as a function of α , although this is usually computationally diﬃcult . For ( Gˆateaux ) diﬀerentiable f , the gradient , ∇ f ( x ) , is the direction of greatest increase of f , as we move away from the point x . Therefore , it is reasonable , although not required , to select d k = −∇ f ( x k ) as the new direction vector ; then we have a gradient descent method . 1 . 5 . ALGORITHMS 9 1 . 5 . 3 Solving Systems of Linear Equations Many of the problems we shall consider involve solving , as least approxi - mately , systems of linear equations . When an exact solution is sought and the number of equations and the number of unknowns are small , meth - ods such as Gauss elimination can be used . It is common , in applications such as medical imaging , to encounter problems involving hundreds or even thousands of equations and unknowns . It is also common to prefer inexact solutions to exact ones , when the equations involve noisy , measured data . Even when the number of equations and unknowns is large , there may not be enough data to specify a unique solution , and we need to incorporate prior knowledge about the desired answer . Such is the case with medi - cal tomographic imaging , in which the images are artiﬁcially discretized approximations of parts of the interior of the body . 1 . 5 . 4 Imposing Constraints The iterative algorithms we shall investigate begin with an initial guess x 0 of the solution , and then generate a sequence { x k } , converging , in the best cases , to our solution . Suppose we wish to minimize f ( x ) over all x in R J having non - negative entries . An iterative algorithm is said to be an interior - point method if each vector x k has non - negative entries . 1 . 5 . 5 Operators Most of the iterative algorithms we shall study involve an operator , that is , a function T : R J → R J . The algorithms begin with an initial guess , x 0 , and then proceed from x k to x k + 1 = Tx k . Ideally , the sequence { x k } converges to the solution to our optimization problem . In gradient descent methods with ﬁxed step - length α , for example , the operator is Tx = x − α ∇ f ( x ) . In problems with non - negativity constraints our solution x is required to have non - negative entries x j . In such problems , the clipping operator T , with ( Tx ) j = max { x j , 0 } , plays an important role . A subset C of R J is convex if , for any two points in C , the line segment connecting them is also within C . As we shall see , for any x outside C , there is a point c within C that is closest to x ; this point c is called the orthogonal projection of x onto C , and we write c = P C x . Operators of the type T = P C play important roles in iterative algorithms . The clipping operator deﬁned previously is of this type , for C the non - negative orthant of R J , that is , the set R J + = { x ∈ R J | x j ≥ 0 , j = 1 , . . . , J } . 10 CHAPTER 1 . PREFACE 1 . 5 . 6 Search Techniques The objective in linear programming is to minimize a linear function f ( x ) = c T x over those vectors x ≥ 0 in R J for which Ax ≥ b . It can be shown easily that the minimum of f ( x ) occurs at one of a ﬁnite number of vectors , the vertices , but evaluating f ( x ) at every one of these vertices is computa - tionally intractable . Useful algorithms , such as Dantzig’s simplex method , move from one vertex to another in an eﬃcient way , and , at least most of the time , solve the problem in a fraction of the time that would have been required to check each vertex . 1 . 5 . 7 Acceleration For problems involving many variables , it is important to use algorithms that provide an acceptable approximation of the solution in a reasonable amount of time . For medical tomography image reconstruction in a clinical setting , the algorithm must reconstruct a useful image from scanning data in the time it takes for the next patient to be scanned , which is roughly ﬁfteen minutes . Some of the algorithms we shall encounter work ﬁne on small problems , but require far too much time when the problem is large . Figuring out ways to speed up convergence is an important part of iterative optimization . 1 . 6 A Word about Prior Information As we noted earlier , optimization is often used when the data pertaining to a desired mathematical object ( a function , a vectorized image , etc . ) is not suﬃcient to specify uniquely one solution to the problem . It is common in remote sensing problems for there to be more than one mathematical solution that ﬁts the measured data . In such cases , it is helpful to turn to optimization , and seek the solution consistent with the data that is closest to what we expect the correct answer to look like . This means that we must somehow incorporate prior knowledge about the desired answer into the algorithm for ﬁnding it . In this section we give an example of such a method . Reconstructing a mathematical object from limited data pertaining to that object is often viewed as an interpolation or extrapolation problem , in which we seek to infer the measurements we did not take from those we did . From a purely mathematical point of view , this usually amounts to selecting a function that agrees with the data we have measured . For example , suppose we want a real - valued function f ( x ) of the real variable x that is consistent with the measurements f ( x n ) = y n , for n = 1 , . . . , N ; that is , we want to interpolate this data . How we do this should depend on why we want to do it , and on what we may already know about f ( x ) . 1 . 6 . A WORD ABOUT PRIOR INFORMATION 11 We can always ﬁnd a polynomial of degree N − 1 or less that is consistent with these measurements , but using this polynomial may not always be a good idea . To illustrate , imagine that we have f ( 0 ) = y 0 , f ( 1 ) = y 1 and f ( 2 ) = y 2 . We can always ﬁnd a polynomial of degree two or less that passes through the three points ( 0 , y 0 ) , ( 1 , y 1 ) , and ( 2 , y 2 ) . If our goal is to interpolate to infer the value f ( 0 . 75 ) or to estimate the integral of f ( x ) over [ 0 , 2 ] , then this may not be a bad way to proceed . On the other hand , if our objective is to extrapolate to infer the value f ( 53 ) , then we may be in trouble . Note that if y 0 = y 1 = y 2 = 0 , then the quadratic is a straight line , the x - axis . If , however , f ( 1 ) = 0 . 0001 , the quadratic opens downward , while if f ( 1 ) = − 0 . 0001 , the quadratic opens upward . The inferred values of f ( x ) , for large x , will be greatly diﬀerent in the two cases , even though the original data diﬀered only slightly . It sometimes happens that , when we plot the data points ( x n , y n ) , for n = 1 , . . . , N , we see the suggestion of a pattern . Perhaps this cloud of points nearly resembles a straight line . In this case , it may make more sense to ﬁnd the straight line that best ﬁts the data , what the statisticians call the regression line , rather than to ﬁnd a polynomial of high degree that ﬁts the data exactly , but that oscillates wildly between the data points . However , before we use the regression line , we should be reasonably convinced that a linear relationship is appropriate , over the region of x values we wish to consider . Again , the linear approximation may be a good one for interpo - lating to nearby values of x , but not so good for x well outside the region where we have measurements . If we have recorded the temperature every minute , from 10 am until 11 am today , we may see a linear relationship , and the regression line may be useful in estimating what the temperature was at eight seconds after twenty past ten . It probably will be less helpful in estimating what the temperature will be at 7 pm in the evening . For that purpose , prior information about the temperature the previous day may be helpful , which might suggest a sinusoidal model . In all such cases , we want to optimize in some way , but we need to tailor our notion of “best” to the problem at hand , using whatever prior knowledge we may have about the problem . An important point to keep in mind when applying linear - algebraic methods to measured data is that , while the data is usually limited , the information we seek may not be lost . Although processing the data in a reasonable way may suggest otherwise , other processing methods may reveal that the desired information is still available in the data . Figure 1 . 1 illustrates this point . The original image on the upper right of Figure 1 . 1 is a discrete rect - angular array of intensity values simulating a slice of a head . The data was obtained by taking the two - dimensional discrete Fourier transform of the original image , and then discarding , that is , setting to zero , all these 12 CHAPTER 1 . PREFACE spatial frequency values , except for those in a smaller rectangular region around the origin . The problem then is under - determined . A minimum - norm solution would seem to be a reasonable reconstruction method . The minimum - norm solution is shown on the lower right . It is calcu - lated simply by performing an inverse discrete Fourier transform on the array of modiﬁed discrete Fourier transform values . The original image has relatively large values where the skull is located , but the minimum - norm reconstruction does not want such high values ; the norm involves the sum of squares of intensities , and high values contribute disproportionately to the norm . Consequently , the minimum - norm reconstruction chooses in - stead to conform to the measured data by spreading what should be the skull intensities throughout the interior of the skull . The minimum - norm reconstruction does tell us something about the original ; it tells us about the existence of the skull itself , which , of course , is indeed a prominent feature of the original . However , in all likelihood , we would already know about the skull ; it would be the interior that we want to know about . Using our knowledge of the presence of a skull , which we might have ob - tained from the minimum - norm reconstruction itself , we construct the prior estimate shown in the upper left . Now we use the same data as before , and calculate a minimum - weighted - norm reconstruction , using as the weight vector the reciprocals of the values of the prior image . This minimum - weighted - norm reconstruction is shown on the lower left ; it is clearly almost the same as the original image . The calculation of the minimum - weighted norm solution can be done iteratively using the ART algorithm [ 189 ] . When we weight the skull area with the inverse of the prior image , we allow the reconstruction to place higher values there without having much of an eﬀect on the overall weighted norm . In addition , the reciprocal weighting in the interior makes spreading intensity into that region costly , so the interior remains relatively clear , allowing us to see what is really present there . When we try to reconstruct an image from limited data , it is easy to assume that the information we seek has been lost , particularly when a reasonable reconstruction method fails to reveal what we want to know . As this example , and many others , show , the information we seek is often still in the data , but needs to be brought out in a more subtle way . 1 . 6 . A WORD ABOUT PRIOR INFORMATION 13 Figure 1 . 1 : Extracting information in image reconstruction . 14 CHAPTER 1 . PREFACE Chapter 2 Optimization Without Calculus 2 . 1 Chapter Summary In our study of optimization , we shall encounter a number of sophisticated techniques , involving ﬁrst and second partial derivatives , systems of lin - ear equations , nonlinear operators , specialized distance measures , and so on . It is good to begin by looking at what can be accomplished without sophisticated techniques , even without calculus . It is possible to achieve much with powerful , yet simple , inequalities . As someone once remarked , exaggerating slightly , in the right hands , the Cauchy Inequality and inte - gration by parts are all that are really needed . Some of the discussion in this chapter follows that in Niven [ 167 ] . Students typically encounter optimization problems as applications of diﬀerentiation , while the possibility of optimizing without calculus is left unexplored . In this chapter we develop the Arithmetic Mean - Geometric Mean Inequality , abbreviated the AGM Inequality , from the convexity of the logarithm function , use the AGM to derive several important inequali - ties , including Cauchy’s Inequality , and then discuss optimization methods based on the Arithmetic Mean - Geometric Mean Inequality and Cauchy’s Inequality . 15 16 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS 2 . 2 The Arithmetic Mean - Geometric Mean Inequality Let x 1 , . . . , x N be positive numbers . According to the famous Arithmetic Mean - Geometric Mean Inequality , abbreviated AGM Inequality , G = ( x 1 · x 2 · · · x N ) 1 / N ≤ A = 1 N ( x 1 + x 2 + . . . + x N ) , ( 2 . 1 ) with equality if and only if x 1 = x 2 = . . . = x N . To prove this , consider the following modiﬁcation of the product x 1 · · · x N . Replace the smallest of the x n , call it x , with A and the largest , call it y , with x + y − A . This modiﬁcation does not change the arithmetic mean of the N numbers , but the product increases , unless x = y = A already , since xy ≤ A ( x + y − A ) ( Why ? ) . We repeat this modiﬁcation , until all the x n approach A , at which point the product reaches its maximum . For example , 2 · 3 · 4 · 6 · 20 becomes 3 · 4 · 6 · 7 · 15 , and then 4 · 6 · 7 · 7 · 11 , 6 · 7 · 7 · 7 · 8 , and ﬁnally 7 · 7 · 7 · 7 · 7 . 2 . 3 An Application of the AGM Inequality : the Number e We can use the AGM Inequality to show that lim n →∞ ( 1 + 1 n ) n = e . ( 2 . 2 ) Let f ( n ) = ( 1 + 1 n ) n , the product of the n + 1 numbers 1 , 1 + 1 n , . . . , 1 + 1 n . Applying the AGM Inequality , we obtain the inequality f ( n ) ≤ (cid:16) n + 2 n + 1 (cid:17) n + 1 = f ( n + 1 ) , so we know that the sequence { f ( n ) } is increasing . Now deﬁne g ( n ) = ( 1 + 1 n ) n + 1 ; we show that g ( n ) ≤ g ( n − 1 ) and f ( n ) ≤ g ( m ) , for all positive integers m and n . Consider ( 1 − 1 n ) n , the product of the n + 1 numbers 1 , 1 − 1 n , . . . , 1 − 1 n . Applying the AGM Inequality , we ﬁnd that (cid:16) 1 − 1 n + 1 (cid:17) n + 1 ≥ (cid:16) 1 − 1 n (cid:17) n , or (cid:16) n n + 1 (cid:17) n + 1 ≥ (cid:16) n − 1 n (cid:17) n . Taking reciprocals , we get g ( n ) ≤ g ( n − 1 ) . Since f ( n ) < g ( n ) and { f ( n ) } is increasing , while { g ( n ) } is decreasing , we can conclude that f ( n ) ≤ g ( m ) , 2 . 4 . EXTENDING THE AGM INEQUALITY 17 for all positive integers m and n . Both sequences therefore have limits . Because the diﬀerence g ( n ) − f ( n ) = 1 n ( 1 + 1 n ) n → 0 , as n → ∞ , we conclude that the limits are the same . This common limit we can deﬁne as the number e . 2 . 4 Extending the AGM Inequality Suppose , once again , that x 1 , . . . , x N are positive numbers . Let a 1 , . . . , a N be positive numbers that sum to one . Then the Generalized AGM Inequality ( GAGM Inequality ) is x a 1 1 x a 2 2 · · · x a N N ≤ a 1 x 1 + a 2 x 2 + . . . + a N x N , ( 2 . 3 ) with equality if and only if x 1 = x 2 = . . . = x N . We can prove this using the convexity of the function − log x . Deﬁnition 2 . 1 A function f ( x ) is said to be convex over an interval ( a , b ) if f ( a 1 t 1 + a 2 t 2 + . . . + a N t N ) ≤ a 1 f ( t 1 ) + a 2 f ( t 2 ) + . . . + a N f ( t N ) , for all positive integers N , all a n as above , and all real numbers t n in ( a , b ) . If the function f ( x ) is twice diﬀerentiable on ( a , b ) , then f ( x ) is convex over ( a , b ) if and only if the second derivative of f ( x ) is non - negative on ( a , b ) . For example , the function f ( x ) = − log x is convex on the positive x - axis . The GAGM Inequality follows immediately . 2 . 5 Optimization Using the AGM Inequality We illustrate the use of the AGM Inequality for optimization through sev - eral examples . 2 . 5 . 1 Example 1 : Minimize This Sum Find the minimum of the function f ( x , y ) = 12 x + 18 y + xy , over positive x and y . We note that the three terms in the sum have a ﬁxed product of 216 , so , by the AGM Inequality , the smallest value of 13 f ( x , y ) is ( 216 ) 1 / 3 = 6 and occurs when the three terms are equal and each equal to 6 , so when x = 2 and y = 3 . The smallest value of f ( x , y ) is therefore 18 . 18 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS 2 . 5 . 2 Example 2 : Maximize This Product Find the maximum value of the product f ( x , y ) = xy ( 72 − 3 x − 4 y ) , over positive x and y . The terms x , y and 72 − 3 x − 4 y do not have a constant sum , but the terms 3 x , 4 y and 72 − 3 x − 4 y do have a constant sum , namely 72 , so we rewrite f ( x , y ) as f ( x , y ) = 1 12 ( 3 x ) ( 4 y ) ( 72 − 3 x − 4 y ) . By the AGM Inequality , the product ( 3 x ) ( 4 y ) ( 72 − 3 x − 4 y ) is maximized when the factors 3 x , 4 y and 72 − 3 x − 4 y are each equal to 24 , so when x = 8 and y = 6 . The maximum value of the product is then 1152 . 2 . 5 . 3 Example 3 : A Harder Problem ? Both of the previous two problems can be solved using the standard calculus technique of setting the two ﬁrst partial derivatives to zero . Here is an example that may not be so easily solved in that way : minimize the function f ( x , y ) = 4 x + x y 2 + 4 y x , over positive values of x and y . Try taking the ﬁrst partial derivatives and setting them both to zero . Even if we manage to solve this system of cou - pled nonlinear equations , deciding if we actually have found the minimum may not be easy ; take a look at the second derivative matrix , the Hessian matrix . We can employ the AGM Inequality by rewriting f ( x , y ) as f ( x , y ) = 4 (cid:16) 4 x + xy 2 + 2 yx + 2 yx 4 (cid:17) . The product of the four terms in the arithmetic mean expression is 16 , so the GM is 2 . Therefore , 14 f ( x , y ) ≥ 2 , with equality when all four terms are equal to 2 ; that is , 4 x = 2 , so that x = 12 and 2 yx = 2 , so y = 12 also . The minimum value of f ( x , y ) is then 8 . 2 . 6 The H¨older and Minkowski Inequalities Let c = ( c 1 , . . . , c N ) and d = ( d 1 , . . . , d N ) be vectors with complex entries and let p and q be positive real numbers such that 1 p + 1 q = 1 . 2 . 6 . THE H ¨OLDER AND MINKOWSKI INEQUALITIES 19 The p - norm of c is deﬁned to be (cid:107) c (cid:107) p = (cid:16) N (cid:88) n = 1 | c n | p (cid:17) 1 / p , with the q - norm of d , denoted (cid:107) d (cid:107) q , deﬁned similarly . 2 . 6 . 1 H¨older’s Inequality H¨older’s Inequality is the following : N (cid:88) n = 1 | c n d n | ≤ (cid:107) c (cid:107) p (cid:107) d (cid:107) q , with equality if and only if (cid:16) | c n | (cid:107) c (cid:107) p (cid:17) p = (cid:16) | d n | (cid:107) d (cid:107) q (cid:17) q , for each n . H¨older’s Inequality follows from the GAGM Inequality . To see this , we ﬁx n and apply Inequality ( 2 . 3 ) , with x 1 = (cid:16) | c n | (cid:107) c (cid:107) p (cid:17) p , a 1 = 1 p , x 2 = (cid:16) | d n | (cid:107) d (cid:107) q (cid:17) q , and a 2 = 1 q . From ( 2 . 3 ) we then have (cid:16) | c n | (cid:107) c (cid:107) p (cid:17)(cid:16) | d n | (cid:107) d (cid:107) q (cid:17) ≤ 1 p (cid:16) | c n | (cid:107) c (cid:107) p (cid:17) p + 1 q (cid:16) | d n | (cid:107) d (cid:107) q (cid:17) q . Now sum both sides over the index n . 20 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS 2 . 6 . 2 Minkowski’s Inequality Minkowski’s Inequality , which is a consequence of H¨older’s Inequality , states that (cid:107) c + d (cid:107) p ≤ (cid:107) c (cid:107) p + (cid:107) d (cid:107) p ; it is the triangle inequality for the metric induced by the p - norm . To prove Minkowski’s Inequality , we write N (cid:88) n = 1 | c n + d n | p ≤ N (cid:88) n = 1 | c n | ( | c n + d n | ) p − 1 + N (cid:88) n = 1 | d n | ( | c n + d n | ) p − 1 . Then we apply H¨older’s Inequality to both of the sums on the right side of the equation . 2 . 7 Cauchy’s Inequality For the choices p = q = 2 , H¨older’s Inequality becomes the famous Cauchy Inequality , which we rederive in a diﬀerent way in this section . For sim - plicity , we assume now that the vectors have real entries and for notational convenience later we use x n and y n in place of c n and d n . Let x = ( x 1 , . . . , x N ) and y = ( y 1 , . . . , y N ) be vectors with real entries . The inner product of x and y is (cid:104) x , y (cid:105) = x 1 y 1 + x 2 y 2 + . . . + x N y N . ( 2 . 4 ) The 2 - norm of the vector x , which we shall simply call the norm of the vector x is (cid:107) x (cid:107) 2 = (cid:112) (cid:104) x , x (cid:105) . Cauchy’s Inequality is | (cid:104) x , y (cid:105) | ≤ (cid:107) x (cid:107) 2 (cid:107) y (cid:107) 2 , ( 2 . 5 ) with equality if and only if there is a real number a such that x = ay . A vector x = ( x 1 , . . . , x N ) in the real N - dimensional space R N can be viewed in two slightly diﬀerent ways . The ﬁrst way is to imagine x as simply a point in that space ; for example , if N = 2 , then x = ( x 1 , x 2 ) would be the point in two - dimensional space having x 1 for its ﬁrst coordinate and x 2 for its second . When we speak of the norm of x , which we think of as a length , we could be thinking of the distance from the origin to the point x . But we could also be thinking of the length of the directed line segment that extends from the origin to the point x . This line segment is also commonly denoted just x . There will be times when we want to think of the members of R N as points . At other times , we shall prefer to view them as directed line segments ; for example , if x and y are two points in R N , their diﬀerence , 2 . 8 . OPTIMIZING USING CAUCHY’S INEQUALITY 21 x − y , is more likely to be viewed as the directed line segment extending from y to x , rather than a third point situated somewhere else in R N . We shall make no explicit distinction between the two views , but rely on the situation to tell us which one is the better interpretation . To prove Cauchy’s Inequality , we begin with the fact that , for every real number t , 0 ≤ (cid:107) x − ty (cid:107) 22 = (cid:107) x (cid:107) 22 − ( 2 (cid:104) x , y (cid:105) ) t + (cid:107) y (cid:107) 22 t 2 . This quadratic in the variable t is never negative , so cannot have two real roots . It follows that the term under the radical sign in the quadratic equation must be non - positive , that is , ( 2 (cid:104) x , y (cid:105) ) 2 − 4 (cid:107) y (cid:107) 22 (cid:107) x (cid:107) 22 ≤ 0 . ( 2 . 6 ) We have equality in ( 2 . 6 ) if and only if the quadratic has a double real root , say t = a . Then we have (cid:107) x − ay (cid:107) 22 = 0 . As an aside , suppose we had allowed the variable t to be complex . Clearly (cid:107) x − ty (cid:107) cannot be zero for any non - real value of t . Doesn’t this contradict the fact that every quadratic has two roots in the complex plane ? The P´olya - Szeg¨o Inequality We can interpret Cauchy’s Inequality as providing an upper bound for the quantity (cid:16) N (cid:88) n = 1 x n y n (cid:17) 2 . The P´olya - Szeg¨o Inequality provides a lower bound for the same quantity . Let 0 < m 1 ≤ x n ≤ M 1 and 0 < m 2 ≤ y n ≤ M 2 , for all n . Then N (cid:88) n = 1 x 2 n N (cid:88) n = 1 y 2 n ≤ M 1 M 2 + m 1 m 2 √ 4 m 1 m 2 M 1 M 2 (cid:16) N (cid:88) n = 1 x n y n (cid:17) 2 . ( 2 . 7 ) 2 . 8 Optimizing using Cauchy’s Inequality We present three examples to illustrate the use of Cauchy’s Inequality in optimization . 2 . 8 . 1 Example 4 : A Constrained Optimization Find the largest and smallest values of the function f ( x , y , z ) = 2 x + 3 y + 6 z , ( 2 . 8 ) 22 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS among the points ( x , y , z ) with x 2 + y 2 + z 2 = 1 . From Cauchy’s Inequality we know that 49 = ( 2 2 + 3 2 + 6 2 ) ( x 2 + y 2 + z 2 ) ≥ ( 2 x + 3 y + 6 z ) 2 , so that f ( x , y , z ) lies in the interval [ − 7 , 7 ] . We have equality in Cauchy’s Inequality if and only if the vector ( 2 , 3 , 6 ) is parallel to the vector ( x , y , z ) , that is x 2 = y 3 = z 6 . It follows that x = t , y = 32 t , and z = 3 t , with t 2 = 449 . The smallest value of f ( x , y , z ) is − 7 , when x = − 27 , and the largest value is + 7 , when x = 27 . 2 . 8 . 2 Example 5 : A Basic Estimation Problem The simplest problem in estimation theory is to estimate the value of a constant c , given J data values z j = c + v j , j = 1 , . . . , J , where the v j are random variables representing additive noise or measurement error . Assume that the expected values of the v j are E ( v j ) = 0 , the v j are uncor - related , so E ( v j v k ) = 0 for j diﬀerent from k , and the variances of the v j are E ( v 2 j ) = σ 2 j > 0 . A linear estimate of c has the form ˆ c = J (cid:88) j = 1 b j z j . ( 2 . 9 ) The estimate ˆ c is unbiased if E ( ˆ c ) = c , which forces (cid:80) Jj = 1 b j = 1 . The best linear unbiased estimator , the BLUE , is the one for which E ( ( ˆ c − c ) 2 ) is minimized . This means that the b j must minimize E (cid:16) J (cid:88) j = 1 J (cid:88) k = 1 b j b k v j v k (cid:17) = J (cid:88) j = 1 b 2 j σ 2 j , ( 2 . 10 ) subject to J (cid:88) j = 1 b j = 1 . ( 2 . 11 ) To solve this minimization problem , we turn to Cauchy’s Inequality . We can write 1 = J (cid:88) j = 1 b j = J (cid:88) j = 1 ( b j σ j ) 1 σ j . 2 . 8 . OPTIMIZING USING CAUCHY’S INEQUALITY 23 Cauchy’s Inequality then tells us that 1 ≤ (cid:118)(cid:117)(cid:117)(cid:116) J (cid:88) j = 1 b 2 j σ 2 j (cid:118)(cid:117)(cid:117)(cid:116) J (cid:88) j = 1 1 σ 2 j , with equality if and only if there is a constant , say λ , such that b j σ j = λ 1 σ j , for each j . So we have b j = λ 1 σ 2 j , for each j . Summing on both sides and using Equation ( 2 . 11 ) , we ﬁnd that λ = 1 / J (cid:88) j = 1 1 σ 2 j . The BLUE is therefore ˆ c = λ J (cid:88) j = 1 z j σ 2 j . ( 2 . 12 ) When the variances σ 2 j are all the same , the BLUE is simply the arithmetic mean of the data values z j . 2 . 8 . 3 Example 6 : A Filtering Problem One of the fundamental operations in signal processing is ﬁltering the data vector x = γs + n , to remove the noise component n , while leaving the signal component s relatively unaltered [ 53 ] . This can be done either to estimate γ , the amount of the signal vector s present , or to detect if the signal is present at all , that is , to decide if γ = 0 or not . The noise is typically known only through its covariance matrix Q , which is the positive - deﬁnite , symmetric matrix having for its entries Q jk = E ( n j n k ) . The ﬁlter usually is linear and takes the form of an estimate of γ : ˆ γ = b T x . We want | b T s | 2 large , and , on average , | b T n | 2 small ; that is , we want E ( | b T n | 2 ) = b T E ( nn T ) b = b T Qb small . The best choice is the vector b that maximizes the gain of the ﬁlter , that is , the ratio | b T s | 2 / b T Qb . We can solve this problem using the Cauchy Inequality . 24 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS Deﬁnition 2 . 2 Let S be a square matrix . A non - zero vector u is an eigen - vector of S if there is a scalar λ such that Su = λu . Then the scalar λ is said to be an eigenvalue of S associated with the eigenvector u . Deﬁnition 2 . 3 The transpose , B = A T , of an M by N matrix A is the N by M matrix having the entries B n , m = A m , n . Deﬁnition 2 . 4 A square matrix S is symmetric if S T = S . A basic theorem in linear algebra is that , for any symmetric N by N matrix S , R N has an orthonormal basis consisting of mutually orthogonal , norm - one eigenvectors of S . We then deﬁne U to be the matrix whose columns are these orthonormal eigenvectors u n and L the diagonal matrix with the associated eigenvalues λ n on the diagonal , we can easily see that U is an orthogonal matrix , that is , U T U = I . We can then write S = ULU T ; ( 2 . 13 ) this is the eigenvalue / eigenvector decomposition of S . The eigenvalues of a symmetric S are always real numbers . Deﬁnition 2 . 5 A J by J symmetric matrix Q is non - negative deﬁnite if , for every x in R J , we have x T Qx ≥ 0 . If x T Qx > 0 whenever x is not the zero vector , then Q is said to be positive deﬁnite . We leave it to the reader to show , in Exercise 2 . 13 , that the eigenval - ues of a non - negative ( positive ) deﬁnite matrix are always non - negative ( positive ) . A covariance matrix Q is always non - negative deﬁnite , since x T Qx = E ( | J (cid:88) j = 1 x j n j | 2 ) . ( 2 . 14 ) Therefore , its eigenvalues are non - negative ; typically , they are actually pos - itive , as we shall assume now . We then let C = U √ LU T , which is called the symmetric square root of Q since Q = C 2 = C T C . The Cauchy Inequality then tells us that | b T s | 2 = | b T CC − 1 s | 2 ≤ [ b T CC T b ] [ s T ( C − 1 ) T C − 1 s ] , with equality if and only if the vectors C T b and C − 1 s are parallel . It follows that b = α ( CC T ) − 1 s = αQ − 1 s , for any constant α . It is standard practice to select α so that b T s = 1 , therefore α = 1 / s T Q − 1 s and the optimal ﬁlter b is b = 1 s T Q − 1 sQ − 1 s . 2 . 9 . AN INNER PRODUCT FOR SQUARE MATRICES 25 2 . 9 An Inner Product for Square Matrices The trace of a square matrix M , denoted tr M , is the sum of the entries down the main diagonal . Given square matrices A and B with real entries , the trace of the product B T A deﬁnes an inner product , that is (cid:104) A , B (cid:105) = tr ( B T A ) , where the superscript T denotes the transpose of a matrix . This inner product can then be used to deﬁne a norm of A , called the Frobenius norm , by (cid:107) A (cid:107) F = (cid:112) (cid:104) A , A (cid:105) = (cid:113) tr ( A T A ) . ( 2 . 15 ) From the eigenvector / eigenvalue decomposition , we know that , for every symmetric matrix S , there is an orthogonal matrix U such that S = UD ( λ ( S ) ) U T , where λ ( S ) = ( λ 1 , . . . , λ N ) is a vector whose entries are eigenvalues of the symmetric matrix S , and D ( λ ( S ) ) is the diagonal matrix whose entries are the entries of λ ( S ) . Then we can easily see that (cid:107) S (cid:107) F = (cid:107) λ ( S ) (cid:107) 2 . Denote by [ λ ( S ) ] the vector of eigenvalues of S , ordered in non - increasing order . We have the following result . Theorem 2 . 1 ( Fan’s Theorem ) Any real symmetric matrices S and R satisfy the inequality tr ( SR ) ≤ (cid:104) [ λ ( S ) ] , [ λ ( R ) ] (cid:105) , with equality if and only if there is an orthogonal matrix U such that S = UD ( [ λ ( S ) ] ) U T , and R = UD ( [ λ ( R ) ] ) U T . From linear algebra , we know that S and R can be simultaneously diag - onalized if and only if they commute ; this is a stronger condition than simultaneous diagonalization . If S and R are diagonal matrices already , then Fan’s Theorem tells us that (cid:104) λ ( S ) , λ ( R ) (cid:105) ≤ (cid:104) [ λ ( S ) ] , [ λ ( R ) ] (cid:105) . 26 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS Since any real vectors x and y are λ ( S ) and λ ( R ) , for some symmetric S and R , respectively , we have the following Hardy - Littlewood - Polya Inequality : (cid:104) x , y (cid:105) ≤ (cid:104) [ x ] , [ y ] (cid:105) . Most of the optimization problems discussed in this chapter fall under the heading of Geometric Programming , which we shall present in a more formal way in a subsequent chapter . 2 . 10 Discrete Allocation Problems Most of the optimization problems we consider in this book are continuous problems , in the sense that the variables involved are free to take on values within a continuum . A large branch of optimization deals with discrete problems . Typically , these discrete problems can be solved , in principle , by an exhaustive checking of a large , but ﬁnite , number of possibilities ; what is needed is a faster method . The optimal allocation problem is a good example of a discrete optimization problem . We have n diﬀerent jobs to assign to n diﬀerent people . For i = 1 , . . . , n and j = 1 , . . . , n the quantity C ij is the cost of having person i do job j . The n by n matrix C with these entries is the cost matrix . An assignment is a selection of n entries of C so that no two are in the same column or the same row ; that is , everybody gets one job . Our goal is to ﬁnd an assignment that minimizes the total cost . We know that there are n ! ways to make assignments , so one solution method would be to determine the cost of each of these assignments and select the cheapest . But for large n this is impractical . We want an algo - rithm that will solve the problem with less calculation . The algorithm we present here , discovered in the 1930’s by two Hungarian mathematicians , is called , unimaginatively , the Hungarian Method . To illustrate , suppose there are three people and three jobs , and the cost matrix is C =   53 96 37 47 87 41 60 92 36   . ( 2 . 16 ) The number 41 in the second row , third column indicates that it costs 41 dollars to have the second person perform the third job . The algorithm is as follows : • Step 1 : Subtract the minimum of each row from all the entries of that row . This is equivalent to saying that each person charges a minimum amount just to be considered , which must be paid regardless of the 2 . 10 . DISCRETE ALLOCATION PROBLEMS 27 allocation made . All we can hope to do now is to reduce the remaining costs . Subtracting these ﬁxed costs , which do not depend on the allocations , does not change the optimal solution . The new matrix is then   16 59 0 6 46 0 24 56 0   . ( 2 . 17 ) • Step 2 : Subtract each column minimum from the entries of its col - umn . This is equivalent to saying that each job has a minimum cost , regardless of who performs it , perhaps for materials , say , or a permit . Subtracting those costs does not change the optimal solution . The matrix becomes   10 13 0 0 0 0 18 10 0   . ( 2 . 18 ) • Step 3 : Draw a line through the smallest number of rows and columns that results in all zeros being covered by a line ; here I have put in boldface the entries covered by a line . The matrix becomes   10 13 0 0 0 0 18 10 0   . ( 2 . 19 ) We have used a total of two lines , one row and one column . What we are searching for is a set of zeros such that each row and each column contains a zero . Then n lines will be required to cover the zeros . • Step 4 : If the number of lines just drawn is n we have ﬁnished ; the zeros just covered by a line tell us the assignment we want . Since n lines are needed , there must be a zero in each row and in each column . In our example , we are not ﬁnished . • Step 5 : If , as in our example , the number of lines drawn is fewer than n , determine the smallest entry not yet covered by a line ( not boldface , here ) . It is 10 in our example . Then subtract this number from all the uncovered entries and add it to all the entries covered by both a vertical and horizontal line . This rather complicated step can be explained as follows . It is equiv - alent to , ﬁrst , subtracting this smallest entry from all entries of each row not yet completely covered by a line , whether or not the entry is zero , and second , adding this quantity to every column covered by 28 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS a line . This second step has the eﬀect of restoring to zero those zero values that just became negative . As we have seen , subtracting the same quantity from every entry of a row does not change the optimal solution ; we are just raising the ﬁxed cost charged by certain of the participants . Similarly , adding the same quantity to each entry of a column just increases the cost of the job , regardless of who performs it , so does not change the optimal solution . Our matrix becomes   0 3 0 0 0 10 8 0 0   . ( 2 . 20 ) Now return to Step 3 . In our example , when we return to Step 3 we ﬁnd that we need three lines now and so we are ﬁnished . There are two optimal allocations : one is to assign the ﬁrst job to the ﬁrst person , the second job to the second person , and the third job to the third person , for a total cost of 176 dollars ; the other optimal allocation is to assign the second person to the ﬁrst job , the third person to the second job , and the ﬁrst person to the third job , again with a total cost of 176 dollars . 2 . 11 Exercises Ex . 2 . 1 [ 176 ] Suppose that , in order to reduce automobile gasoline con - sumption , the government sets a fuel - eﬃciency target of T km / liter , and then decrees that , if an auto maker produces a make of car with fuel eﬃ - ciency of b < T , then it must also produce a make of car with fuel eﬃciency rT , for some r > 1 , such that the average of rT and b is T . Assume that the car maker sells the same number of each make of car . The question is : Is this a good plan ? Why or why not ? Be speciﬁc and quantitative in your answer . Hint : The correct answer is No ! . Ex . 2 . 2 Let A be the arithmetic mean of a ﬁnite set of positive numbers , with x the smallest of these numbers , and y the largest . Show that xy ≤ A ( x + y − A ) , with equality if and only if x = y = A . Ex . 2 . 3 Some texts call a function f ( x ) convex if f ( αx + ( 1 − α ) y ) ≤ αf ( x ) + ( 1 − α ) f ( y ) 2 . 11 . EXERCISES 29 for all x and y in the domain of the function and for all α in the interval [ 0 , 1 ] . For this exercise , let us call this two - convex . Show that this deﬁ - nition is equivalent to the one given in Deﬁnition 2 . 1 . Hints : ﬁrst , give the appropriate deﬁnition of three - convex . Then show that three - convex is equivalent to two - convex ; it will help to write α 1 x 1 + α 2 x 2 = ( 1 − α 3 ) [ α 1 ( 1 − α 3 ) x 1 + α 2 ( 1 − α 3 ) x 2 ] . Finally , use induction on the number N . Ex . 2 . 4 Minimize the function f ( x ) = x 2 + 1 x 2 + 4 x + 4 x , over positive x . Note that the minimum value of f ( x , y ) cannot be found by a straight - forward application of the AGM Inequality to the four terms taken together . Try to ﬁnd a way of rewriting f ( x ) , perhaps using more than four terms , so that the AGM Inequality can be applied to all the terms . Ex . 2 . 5 Find the maximum value of f ( x , y ) = x 2 y , if x and y are restricted to positive real numbers for which 6 x + 5 y = 45 . Ex . 2 . 6 Find the smallest value of f ( x ) = 5 x + 16 x + 21 , over positive x . Ex . 2 . 7 Find the smallest value of the function f ( x , y ) = (cid:112) x 2 + y 2 , among those values of x and y satisfying 3 x − y = 20 . Ex . 2 . 8 Find the maximum and minimum values of the function f ( x ) = (cid:112) 100 + x 2 − x over non - negative x . Ex . 2 . 9 Multiply out the product ( x + y + z ) ( 1 x + 1 y + 1 z ) and deduce that the least value of this product , over non - negative x , y , and z , is 9 . Use this to ﬁnd the least value of the function f ( x , y , z ) = 1 x + 1 y + 1 z , over non - negative x , y , and z having a constant sum c . 30 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS Ex . 2 . 10 The harmonic mean of positive numbers a 1 , . . . , a N is H = [ ( 1 a 1 + . . . + 1 a N ) / N ] − 1 . Prove that the geometric mean G is not less than H . Ex . 2 . 11 Prove that ( 1 a 1 + . . . + 1 a N ) ( a 1 + . . . + a N ) ≥ N 2 , with equality if and only if a 1 = . . . = a N . Ex . 2 . 12 Show that the Equation ( 2 . 13 ) , S = ULU T , can be written as S = λ 1 u 1 ( u 1 ) T + λ 2 u 2 ( u 2 ) T + . . . + λ N u N ( u N ) T , ( 2 . 21 ) and S − 1 = 1 λ 1 u 1 ( u 1 ) T + 1 λ 2 u 2 ( u 2 ) T + . . . + 1 λ N u N ( u N ) T . ( 2 . 22 ) Ex . 2 . 13 Show that a real symmetric matrix Q is non - negative ( positive ) deﬁnite if and only if all its eigenvalues are non - negative ( positive ) . Ex . 2 . 14 Let Q be positive - deﬁnite , with positive eigenvalues λ 1 ≥ . . . ≥ λ N > 0 and associated mutually orthogonal norm - one eigenvectors u n . Show that x T Qx ≤ λ 1 , for all vectors x with (cid:107) x (cid:107) 2 = 1 , with equality if x = u 1 . Hints : use 1 = (cid:107) x (cid:107) 2 = x T x = x T Ix , I = u 1 ( u 1 ) T + . . . + u N ( u N ) T , and Equation ( 2 . 21 ) . Ex . 2 . 15 Relate Example 4 to eigenvectors and eigenvalues . Ex . 2 . 16 Young’s Inequality Suppose that p and q are positive numbers greater than one such that 1 p + 1 q = 1 . If x and y are positive numbers , then xy ≤ x p p + y q q , with equality if and only if x p = y q . Hint : use the GAGM Inequality . 2 . 12 . COURSE HOMEWORK 31 Ex . 2 . 17 ( [ 167 ] ) For given constants c and d , ﬁnd the largest and smallest values of cx + dy taken over all points ( x , y ) of the ellipse x 2 a 2 + y 2 b 2 = 1 . Ex . 2 . 18 ( [ 167 ] ) Find the largest and smallest values of 2 x + y on the circle x 2 + y 2 = 1 . Where do these values occur ? What does this have to do with eigenvectors and eigenvalues ? Ex . 2 . 19 When a real M by N matrix A is stored in the computer it is usually vectorized ; that is , the matrix A =   A 11 A 12 . . . A 1 N A 21 A 22 . . . A 2 N . . . A M 1 A M 2 . . . A MN   becomes vec ( A ) = ( A 11 , A 21 , . . . , A M 1 , A 12 , A 22 , . . . , A M 2 , . . . , A MN ) T . Show that the dot product vec ( A ) · vec ( B ) = vec ( B ) T vec ( A ) can be ob - tained by vec ( A ) · vec ( B ) = trace ( AB T ) = trace ( B T A ) . Ex . 2 . 20 Apply the Hungarian Method to solve the allocation problem with the cost matrix C =   90 75 75 80 35 85 55 65 125 95 90 105 45 110 95 115   . ( 2 . 23 ) You should ﬁnd that the minimum cost is 275 dollars . 2 . 12 Course Homework In this chapter , the suggested homework exercises for the course are Exer - cises 2 . 6 , 2 . 7 , 2 . 8 , 2 . 9 , 2 . 10 , 2 . 11 , 2 . 12 , 2 . 14 , and 2 . 20 . 32 CHAPTER 2 . OPTIMIZATION WITHOUT CALCULUS Chapter 3 Geometric Programming 3 . 1 Chapter Summary Geometric Programming ( GP ) involves the minimization of functions of a special type , known as posynomials . The ﬁrst systematic treatment of geometric programming appeared in the book [ 101 ] , by Duﬃn , Peterson and Zener , the founders of geometric programming . As we shall see , the Generalized Arithmetic - Geometric Mean Inequality plays an important role in the theoretical treatment of geometric programming . In this chapter we introduce the notions of duality and cross - entropy distance , and begin our study of iterative algorithms . Some of this discussion of the GP problem follows that in Peressini et al . [ 175 ] . 3 . 2 An Example of a GP Problem The following optimization problem was presented originally by Duﬃn , et al . [ 101 ] and discussed by Peressini et al . in [ 175 ] . It illustrates well the type of problem considered in geometric programming . Suppose that 400 cubic yards of gravel must be ferried across a river in an open box of length t 1 , width t 2 and height t 3 . Each round - trip cost ten cents . The sides and the bottom of the box cost 10 dollars per square yard to build , while the ends of the box cost twenty dollars per square yard . The box will have no salvage value after it has been used . Determine the dimensions of the box that minimize the total cost . Although we know that the number of trips across the river must be a positive integer , we shall ignore that limitation in what follows , and use 400 / t 1 t 2 t 3 as the number of trips . In this particular example , it will turn out that this quantity is a positive integer . 33 34 CHAPTER 3 . GEOMETRIC PROGRAMMING With t = ( t 1 , t 2 , t 3 ) , the cost function is g ( t ) = 40 t 1 t 2 t 3 + 20 t 1 t 3 + 10 t 1 t 2 + 40 t 2 t 3 , ( 3 . 1 ) which is to be minimized over t i > 0 , for i = 1 , 2 , 3 . The function g ( t ) is an example of a posynomial . 3 . 3 Posynomials and the GP Problem Functions g ( t ) of the form g ( t ) = n (cid:88) j = 1 c j (cid:16) m (cid:89) i = 1 t a ij i (cid:17) , ( 3 . 2 ) with t = ( t 1 , . . . , t m ) , the t i > 0 , c j > 0 and a ij real , are called posynomials . The geometric programming problem , denoted GP , is to minimize a given posynomial over positive t . In order for the minimum to be greater than zero , we need some of the a ij to be negative . We denote by u j ( t ) the function u j ( t ) = c j m (cid:89) i = 1 t a ij i , ( 3 . 3 ) so that g ( t ) = n (cid:88) j = 1 u j ( t ) . ( 3 . 4 ) For any choice of δ j > 0 , j = 1 , . . . , n , with n (cid:88) j = 1 δ j = 1 , we have g ( t ) = n (cid:88) j = 1 δ j (cid:16) u j ( t ) δ j (cid:17) . ( 3 . 5 ) Applying the Generalized Arithmetic - Geometric Mean ( GAGM ) Inequal - ity , we have g ( t ) ≥ n (cid:89) j = 1 (cid:16) u j ( t ) δ j (cid:17) δ j . ( 3 . 6 ) 3 . 4 . THE DUAL GP PROBLEM 35 Therefore , g ( t ) ≥ n (cid:89) j = 1 (cid:16) c j δ j (cid:17) δ j (cid:32) n (cid:89) j = 1 m (cid:89) i = 1 t a ij δ j i (cid:33) , ( 3 . 7 ) or g ( t ) ≥ n (cid:89) j = 1 (cid:16) c j δ j (cid:17) δ j (cid:16) m (cid:89) i = 1 t (cid:80) nj = 1 a ij δ j i (cid:17) , ( 3 . 8 ) Suppose that we can ﬁnd δ j > 0 with n (cid:88) j = 1 a ij δ j = 0 , ( 3 . 9 ) for each i . We let δ be the vector δ = ( δ 1 , . . . , δ n ) . Then the inequality in ( 3 . 8 ) becomes g ( t ) ≥ v ( δ ) , ( 3 . 10 ) for v ( δ ) = n (cid:89) j = 1 (cid:16) c j δ j (cid:17) δ j . ( 3 . 11 ) Note that we can also write log v ( δ ) = n (cid:88) j = 1 δ j log (cid:16) c j δ j (cid:17) . ( 3 . 12 ) 3 . 4 The Dual GP Problem The dual geometric programming problem , denoted DGP , is to maximize the function v ( δ ) , over all feasible δ = ( δ 1 , . . . , δ n ) , that is , all positive δ for which n (cid:88) j = 1 δ j = 1 , ( 3 . 13 ) and n (cid:88) j = 1 a ij δ j = 0 , ( 3 . 14 ) for each i = 1 , . . . , m . 36 CHAPTER 3 . GEOMETRIC PROGRAMMING Denote by A the m + 1 by n matrix with entries A ij = a ij , and A m + 1 , j = 1 , for j = 1 , . . . , n and i = 1 , . . . , m . Then we can write Equations ( 3 . 13 ) and ( 3 . 14 ) as Aδ = u =   00 ··· 01   . Clearly , we have g ( t ) ≥ v ( δ ) , ( 3 . 15 ) for any positive t and feasible δ . Of course , there may be no feasible δ , in which case DGP is said to be inconsistent . As we have seen , the inequality in ( 3 . 15 ) is based on the GAGM In - equality . We have equality in the GAGM Inequality if and only if the terms in the arithmetic mean are all equal . In this case , this says that there is a constant λ such that u j ( t ) δ j = λ , ( 3 . 16 ) for each j = 1 , . . . , n . Using the fact that the δ j sum to one , it follows that λ = n (cid:88) j = 1 u j ( t ) = g ( t ) , ( 3 . 17 ) and δ j = u j ( t ) g ( t ) , ( 3 . 18 ) for each j = 1 , . . . , n . As the theorem below asserts , if t ∗ is positive and minimizes g ( t ) , then δ ∗ , the associated δ from Equation ( 3 . 18 ) , is feasible and solves DGP . Since we have equality in the GAGM Inequality now , we have g ( t ∗ ) = v ( δ ∗ ) . The main theorem in geometric programming is the following . Theorem 3 . 1 If t ∗ > 0 minimizes g ( t ) , then DGP is consistent . In addi - tion , the choice δ ∗ j = u j ( t ∗ ) g ( t ∗ ) ( 3 . 19 ) 3 . 4 . THE DUAL GP PROBLEM 37 is feasible and solves DGP . Finally , g ( t ∗ ) = v ( δ ∗ ) ; ( 3 . 20 ) that is , there is no duality gap . Proof : We have ∂u j ∂t i ( t ∗ ) = a ij u j ( t ∗ ) t ∗ i , ( 3 . 21 ) so that t ∗ i ∂u j ∂t i ( t ∗ ) = a ij u j ( t ∗ ) , ( 3 . 22 ) for each i = 1 , . . . , m . Since t ∗ minimizes g ( t ) , we have 0 = ∂g ∂t i ( t ∗ ) = n (cid:88) j = 1 ∂u j ∂t i ( t ∗ ) , ( 3 . 23 ) so that , from Equation ( 3 . 22 ) , we have 0 = n (cid:88) j = 1 a ij u j ( t ∗ ) , ( 3 . 24 ) for each i = 1 , . . . , m . It follows that δ ∗ is feasible . Since u j ( t ∗ ) / δ ∗ j = g ( t ∗ ) = λ , for all j , we have equality in the GAGM Inequality , and we know g ( t ∗ ) = v ( δ ∗ ) . ( 3 . 25 ) Therefore , δ ∗ solves DGP . This completes the proof . In Exercise 3 . 1 you are asked to show that the function g ( t 1 , t 2 ) = 2 t 1 t 2 + t 1 t 2 + t 1 has no minimum over the region t 1 > 0 , and t 2 > 0 . As you will discover , the DGP is inconsistent in this case . We can still ask if there is a positive greatest lower bound to the values that g can take on . Without too much diﬃculty , we can determine that if t 1 ≥ 1 then g ( t 1 , t 2 ) ≥ 3 , while if t 2 ≤ 1 then g ( t 1 , t 2 ) ≥ 4 . Therefore , our hunt for the greatest lower bound is concentrated in the region described by 0 < t 1 < 1 , and t 2 > 1 . Since there is no minimum , we must consider values of t 2 going to inﬁnity , but such that t 1 t 2 does not go to inﬁnity and t 1 t 2 does not go to zero ; therefore , t 1 must go to zero . Suppose we let t 2 = f ( t 1 ) t 1 , for some function f ( t ) such that f ( 0 ) > 0 . Then , as t 1 goes to zero , g ( t 1 , t 2 ) goes to 2 f ( 0 ) + f ( 0 ) . The exercise asks you to determine how small this limiting quantity can be . 38 CHAPTER 3 . GEOMETRIC PROGRAMMING 3 . 5 Solving the GP Problem The theorem suggests how we might go about solving GP . First , we try to ﬁnd a feasible δ ∗ that maximizes v ( δ ) . This means we have to ﬁnd a positive solution to the system of m + 1 linear equations in n unknowns , given by n (cid:88) j = 1 δ j = 1 , ( 3 . 26 ) and n (cid:88) j = 1 a ij δ j = 0 , ( 3 . 27 ) for i = 1 , . . . , m , such that v ( δ ) is maximized . As we shall see , the multi - plicative algebraic reconstruction technique ( MART ) is an iterative proce - dure that we can use to ﬁnd such δ . If there is no such vector , then GP has no minimizer . Once the desired δ ∗ has been found , we set δ ∗ j = u j ( t ∗ ) v ( δ ∗ ) , ( 3 . 28 ) for each j = 1 , . . . , n , and then solve for the entries of t ∗ . This last step can be simpliﬁed by taking logs ; then we have a system of linear equations to solve for the values log t ∗ i . 3 . 6 Solving the DGP Problem The iterative multiplicative algebraic reconstruction technique MART can be used to maximize the function v ( δ ) , subject to linear equality con - straints , provided that the matrix involved has nonnegative entries . We cannot apply the MART yet , because the matrix A does not satisfy these conditions . 3 . 6 . 1 The MART The Kullback - Leibler , or KL distance [ 141 ] between positive numbers a and b is KL ( a , b ) = a log a b + b − a . ( 3 . 29 ) We also deﬁne KL ( a , 0 ) = + ∞ and KL ( 0 , b ) = b . Extending to non - negative vectors a = ( a 1 , . . . , a J ) T and b = ( b 1 , . . . , b J ) T , we have KL ( a , b ) = J (cid:88) j = 1 KL ( a j , b j ) = J (cid:88) j = 1 (cid:16) a j log a j b j + b j − a j (cid:17) . 3 . 6 . SOLVING THE DGP PROBLEM 39 The MART is an iterative algorithm for ﬁnding a non - negative solution of the system Px = y , for an I by J matrix P with non - negative entries and vector y with positive entries . We also assume that s j = I (cid:88) i = 1 P ij > 0 , for all j = 1 , . . . , J . When discussing the MART , we say that the system Px = y is consistent when it has non - negative solutions . We consider two diﬀerent versions of the MART . MART I The iterative step of the ﬁrst version of MART , which we shall call MART I , is the following : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = x kj (cid:16) y i ( Px k ) i (cid:17) P ij / m i , for j = 1 , . . . , J , where the parameter m i is deﬁned to be m i = max { P ij | j = 1 , . . . , J } . The MART I algorithm converges , in the consistent case , to the non - negative solution for which the KL distance KL ( x , x 0 ) is minimized . MART II The iterative step of the second version of MART , which we shall call MART II , is the following : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = x kj (cid:16) y i ( Px k ) i (cid:17) P ij / s j n i , for j = 1 , . . . , J , where the parameter n i is deﬁned to be n i = max { P ij s − 1 j | j = 1 , . . . , J } . The MART II algorithm converges , in the consistent case , to the non - negative solution for which the KL distance J (cid:88) j = 1 s j KL ( x j , x 0 j ) is minimized . 40 CHAPTER 3 . GEOMETRIC PROGRAMMING 3 . 6 . 2 Using the MART to Solve the DGP Problem The entries on the bottom row of A are all one , as is the bottom entry of the column vector u , since these entries correspond to the equation (cid:80) nj = 1 δ j = 1 . By adding suitably large positive multiples of this last equation to the other equations in the system , we obtain an equivalent system , Bδ = r , for which the new matrix B and the new vector r have only positive entries . Now we can apply the MART I algorithm to the system Bδ = r , letting I = m + 1 , J = n , P = B , s j = (cid:80) m + 1 i = 1 B ij , for j = 1 , . . . , n , δ = x , x 0 = c and y = r . In the consistent case , the MART I algorithm will ﬁnd the non - negative solution that minimizes KL ( x , x 0 ) , so we select x 0 = c . Then the MART I algorithm ﬁnds the non - negative δ ∗ satisfying Bδ ∗ = r , or , equivalently , Aδ ∗ = u , for which the KL distance KL ( δ , c ) = n (cid:88) j = 1 (cid:16) δ j log δ j c j + c j − δ j (cid:17) is minimized . Since we know that n (cid:88) j = 1 δ j = 1 , it follows that minimizing KL ( δ , c ) is equivalent to maximizing v ( δ ) . Using δ ∗ , we ﬁnd the optimal t ∗ solving the GP problem . For example , the linear system of equations Aδ = u corresponding to the posynomial in Equation ( 3 . 1 ) is Aδ = u =   − 1 1 1 0 − 1 0 1 1 − 1 1 0 1 1 1 1 1     δ 1 δ 2 δ 3 δ 4   =   0001   . Adding two times the last row to the other rows , the system becomes Bδ = r =   1 3 3 2 1 2 3 3 1 3 2 3 1 1 1 1     δ 1 δ 2 δ 3 δ 4   =   222 1   . The matrix B and the vector r are now positive . We are ready to apply the MART . The MART iteration is as follows . With i = k ( mod ( m + 1 ) ) + 1 , m i = max { B ij | j = 1 , 2 , . . . , n } and k = 0 , 1 , . . . , let δ k + 1 j = δ kj (cid:16) r i ( Bδ k ) i (cid:17) m − 1 i B ij . 3 . 7 . CONSTRAINED GEOMETRIC PROGRAMMING 41 Using the MART , beginning with δ 0 = c , we ﬁnd that the optimal δ ∗ is δ ∗ = ( . 4 , . 2 , . 2 , . 2 ) T . Now we ﬁnd v ( δ ∗ ) , which , by Theorem 3 . 1 , equals g ( t ∗ ) . We have v ( δ ∗ ) = (cid:16) 40 0 . 4 (cid:17) 0 . 4 (cid:16) 20 0 . 2 (cid:17) 0 . 2 (cid:16) 10 0 . 2 (cid:17) 0 . 2 (cid:16) 40 0 . 2 (cid:17) 0 . 2 , so that , after a little arithmetic , we discover that v ( δ ∗ ) = g ( t ∗ ) = 100 ; the lowest cost is one hundred dollars . Using Equation ( 3 . 19 ) for i = 1 , . . . , 4 , we have u 1 ( t ∗ ) = 40 t ∗ 1 t ∗ 2 t ∗ 3 = 100 δ ∗ 1 = 40 , u 2 ( t ∗ ) = 20 t ∗ 1 t ∗ 3 = 100 δ ∗ 2 = 20 , u 3 ( t ∗ ) = 10 t ∗ 1 t ∗ 2 = 100 δ ∗ 3 = 20 , and u 4 ( t ∗ ) = 40 t ∗ 2 t ∗ 3 = 100 δ ∗ 4 = 20 . Again , a little arithmetic reveals that t ∗ 1 = 2 , t ∗ 2 = 1 , and t ∗ 3 = 0 . 5 . Here we were able to solve the system of nonlinear equations fairly easily . Generally , however , we will need to take logarithms of both sides of each equation , and then solve the resulting system of linear equations for the unknowns x ∗ i = log t ∗ i . 3 . 7 Constrained Geometric Programming Consider now the following variant of the problem of transporting the gravel across the river . Suppose that the bottom and the two sides will be con - structed for free from scrap metal , but only four square yards are available . The cost function to be minimized becomes g 0 ( t ) = 40 t 1 t 2 t 3 + 40 t 2 t 3 , ( 3 . 30 ) and the constraint is g 1 ( t ) = t 1 t 3 2 + t 1 t 2 4 ≤ 1 . ( 3 . 31 ) With δ 1 > 0 , δ 2 > 0 , and δ 1 + δ 2 = 1 , we write g 0 ( t ) = δ 1 40 δ 1 t 1 t 2 t 3 + δ 2 40 t 2 t 3 δ 2 . ( 3 . 32 ) 42 CHAPTER 3 . GEOMETRIC PROGRAMMING Since 0 ≤ g 1 ( t ) ≤ 1 , we have g 0 ( t ) ≥ (cid:16) δ 1 40 δ 1 t 1 t 2 t 3 + δ 2 40 t 2 t 3 δ 2 (cid:17)(cid:16) g 1 ( t ) (cid:17) λ , ( 3 . 33 ) for any positive λ . The GAGM Inequality then tells us that g 0 ( t ) ≥ (cid:32)(cid:16) 40 δ 1 t 1 t 2 t 3 (cid:17) δ 1 (cid:16) 40 t 2 t 3 δ 2 (cid:17) δ 2 (cid:33)(cid:16) g 1 ( t ) (cid:17) λ , ( 3 . 34 ) so that g 0 ( t ) ≥ (cid:32)(cid:16) 40 δ 1 (cid:17) δ 1 (cid:16) 40 δ 2 (cid:17) δ 2 (cid:33) t − δ 1 1 t δ 2 − δ 1 2 t δ 2 − δ 1 3 (cid:16) g 1 ( t ) (cid:17) λ . ( 3 . 35 ) From the GAGM Inequality , we also know that , for δ 3 > 0 , δ 4 > 0 and λ = δ 3 + δ 4 , (cid:16) g 1 ( t ) (cid:17) λ ≥ ( λ ) λ (cid:32)(cid:16) 1 2 δ 3 (cid:17) δ 3 (cid:16) 1 4 δ 4 (cid:17) δ 4 (cid:33) t δ 3 + δ 4 1 t δ 4 2 t δ 3 3 . ( 3 . 36 ) Combining the inequalities in ( 3 . 35 ) and ( 3 . 36 ) , we obtain g 0 ( t ) ≥ v ( δ ) t − δ 1 + δ 3 + δ 4 1 t − δ 1 + δ 2 + δ 4 2 t − δ 1 + δ 2 + δ 3 3 , ( 3 . 37 ) with v ( δ ) = (cid:16) 40 δ 1 (cid:17) δ 1 (cid:16) 40 δ 2 (cid:17) δ 2 (cid:16) 1 2 δ 3 (cid:17) δ 3 (cid:16) 1 4 δ 4 (cid:17) δ 4 (cid:16) δ 3 + δ 4 (cid:17) δ 3 + δ 4 , ( 3 . 38 ) and δ = ( δ 1 , δ 2 , δ 3 , δ 4 ) . If we can ﬁnd a positive vector δ with δ 1 + δ 2 = 1 , − δ 1 + δ 3 + δ 4 = 0 , − δ 1 + δ 2 + δ 4 = 0 − δ 1 + δ 2 + δ 3 = 0 , ( 3 . 39 ) then g 0 ( t ) ≥ v ( δ ) . ( 3 . 40 ) In this particular case , there is a unique positive δ satisfying the equations ( 3 . 39 ) , namely δ ∗ 1 = 2 3 , δ ∗ 2 = 1 3 , δ ∗ 3 = 1 3 , and δ ∗ 4 = 1 3 , ( 3 . 41 ) 3 . 8 . EXERCISES 43 and v ( δ ∗ ) = 60 . ( 3 . 42 ) Therefore , g 0 ( t ) is bounded below by 60 . If there is t ∗ such that g 0 ( t ∗ ) = 60 , ( 3 . 43 ) then we must have g 1 ( t ∗ ) = 1 , ( 3 . 44 ) and equality in the GAGM Inequality . Consequently , 3 2 40 t ∗ 1 t ∗ 2 t ∗ 3 = 3 ( 40 t ∗ 2 t ∗ 3 ) = 60 , ( 3 . 45 ) and 3 2 t ∗ 1 t ∗ 3 = 3 4 t ∗ 1 t ∗ 2 = K . ( 3 . 46 ) Since g 1 ( t ∗ ) = 1 , we must have K = 32 . We solve these equations by taking logarithms , to obtain the solution t ∗ 1 = 2 , t ∗ 2 = 1 , and t ∗ 3 = 1 2 . ( 3 . 47 ) The change of variables t i = e x i converts the constrained GP problem into a constrained convex programming problem . The theory of the con - strained GP problem can then be obtained as a consequence of the theory for the convex problem , which we shall consider in a later chapter . 3 . 8 Exercises Ex . 3 . 1 Show that there is no solution to the problem of minimizing the function g ( t 1 , t 2 ) = 2 t 1 t 2 + t 1 t 2 + t 1 , ( 3 . 48 ) over t 1 > 0 , t 2 > 0 . Can g ( t 1 , t 2 ) ever be smaller than 2 √ 2 ? Ex . 3 . 2 Minimize the function g ( t 1 , t 2 ) = 1 t 1 t 2 + t 1 t 2 + t 1 + t 2 , ( 3 . 49 ) over t 1 > 0 , t 2 > 0 . This will require some iterative numerical method for solving equations . Ex . 3 . 3 Program the MART algorithm and use it to verify the assertions made previously concerning the solutions of the two numerical examples . 44 CHAPTER 3 . GEOMETRIC PROGRAMMING 3 . 9 Course Homework I suggest Exercise 3 . 1 . Do exercises 3 . 2 and 3 . 3 if you want to try some computation . Chapter 4 Basic Analysis 4 . 1 Chapter Summary In this chapter we present a review of some of the basic notions from analysis . 4 . 2 Minima and Inﬁma When we say that we seek the minimum value of a function f ( x ) over x within some set C we imply that there is a point z in C such that f ( z ) ≤ f ( x ) for all x in C . Of course , this need not be the case . For example , take the function f ( x ) = x deﬁned on the real numbers and C the set of positive real numbers . In such cases , instead of looking for the minimum of f ( x ) over x in C , we may seek the inﬁmum or greatest lower bound of the values f ( x ) , over x in C . Deﬁnition 4 . 1 We say that a number α is the inﬁmum of a subset S of R , abbreviated α = inf ( S ) , or the greatest lower bound of S , abbreviated α = glb ( S ) , if two conditions hold : • 1 . α ≤ s , for all s in S ; and • 2 . if t ≤ s for all s in S , then t ≤ α . Deﬁnition 4 . 2 We say that a number β is the supremum of a subset S in R , abbreviated β = sup ( S ) , or the least upper bound of S , abbreviated β = lub ( S ) , if two conditions hold : • 1 . β ≥ s , for all s in S ; and • 2 . if t ≥ s for all s in S , then t ≥ β . 45 46 CHAPTER 4 . BASIC ANALYSIS In our example of f ( x ) = x and C the positive real numbers , let S = { f ( x ) | x ∈ C } . Then the inﬁmum of S is α = 0 , although there is no s in S for which s = 0 . Whenever there is a point z in C with α = f ( z ) , then f ( z ) is both the inﬁmum and the minimum of f ( x ) over x in C . 4 . 3 Limits We begin with the basic deﬁnitions pertaining to limits . Concerning no - tation , we denote by x a member of R J , so that , for J = 1 , x will denote a real number . Entries of an x in R J we denote by x n , so x n will always denote a real number ; in contrast , x k will denote a member of R J , with entries x kn . For a vector x in R J we shall denote by (cid:107) x (cid:107) an arbitrary norm . The notation (cid:107) x (cid:107) 2 will always refer to the two - norm , or 2 - norm , of a vector x ; that is , (cid:107) x (cid:107) 2 = (cid:118)(cid:117)(cid:117)(cid:116) N (cid:88) n = 1 | x n | 2 . The 2 - norm of x is the Euclidean distance from the point x to the origin , or , equivalently , the length of the directed line segment from the origin to x . The two - norm is not the only interesting norm on R J , though . Another one is the one - norm , (cid:107) x (cid:107) 1 = J (cid:88) j = 1 | x n | . Any norm is a generalization of the notion of absolute value of a real number ; for any real number x we can view | x | as the distance from x to 0 . For real numbers x and z , | x − z | is the distance from x to z . For points x and z in R J , (cid:107) x − z (cid:107) should be viewed as the distance from the point x to the point z , or , equivalently , the length of the directed line segment from z to x ; each norm deﬁnes a diﬀerent notion of distance . In the deﬁnitions that follow we use an arbitrary norm on R J . The reason for this is that these deﬁnitions are independent of the particular norm used . A sequence is bounded , Cauchy , or convergent with respect to one norm if and only if it is the same with respect to any norm . Similarly , a function is continuous with respect to one norm if and only if it is continuous with respect to any other norm . Deﬁnition 4 . 3 A sequence { x n | n = 1 , 2 , . . . } , x n ∈ R J , is said to converge to z ∈ R J , or have limit z if , given any (cid:15) > 0 , there is N = N ( (cid:15) ) , usually depending on (cid:15) , such that (cid:107) x n − z (cid:107) ≤ (cid:15) , whenever n ≥ N ( (cid:15) ) . 4 . 4 . COMPLETENESS 47 Deﬁnition 4 . 4 A sequence { x n } in R J is bounded if there is a constant B such that (cid:107) x n (cid:107) ≤ B , for all n . It is convenient to extend the notion of limit of a sequence of real numbers to include the inﬁnities . Deﬁnition 4 . 5 A sequence of real numbers { x n | n = 1 , 2 , . . . } is said to converge to + ∞ if , given any b > 0 , there is N = N ( b ) , usually depending on b , such that x n ≥ b , whenever n ≥ N ( b ) . A sequence of real numbers { x n | n = 1 , 2 , . . . } is said to converge to −∞ if the sequence { − x n } converges to + ∞ . Deﬁnition 4 . 6 Let f : R J → R M . We say that z ∈ R M is the limit of f ( x ) , as x → a in R J , if , for every sequence { x n } converging to a , with x n (cid:54) = a for all n , the sequence { f ( x n ) } in R M converges to z . We then write z = lim x → a f ( x ) . For M = 1 , we allow z to be inﬁnite . 4 . 4 Completeness One version of the axiom of completeness for the set of real numbers R is that every non - empty subset of R that is bounded above has a least up - per bound , or , equivalently , every non - empty subset of R that is bounded below has a greatest lower bound . The notion of completeness is usually not emphasized in beginning calculus courses and encountered for the ﬁrst time in a real analysis course . But without completeness , many of the fun - damental theorems in calculus would not hold . If we tried to do calculus by considering only rational numbers , the intermediate value theorem would not hold , and it would be possible for a diﬀerentiable function to have a positive derivative without being increasing . To further illustrate the importance of completeness , consider the proof of the following proposition . Proposition 4 . 1 The sequence { 1 n } converges to zero . Suppose we attempt to prove this proposition simply by applying the def - inition of the limit of a sequence . Let (cid:15) > 0 be given . Select a positive integer N with N > 1 (cid:15) . Then , whenever n ≥ N , we have | 1 n − 0 | = 1 n ≤ 1 N < (cid:15) . This would seem to complete the proof of the proposition . But it is incor - rect . The ﬂaw in the argument is in the choice of N . We do not yet know 48 CHAPTER 4 . BASIC ANALYSIS that we can select N with N > 1 (cid:15) , since this is equivalent to 1 N < (cid:15) . Until we know that the proposition is true , we do not know that we can make 1 N as small as desired by the choice of N . The proof requires completeness . Let S be the set { 1 , 12 , 13 , 14 , . . . } . This set is non - empty and bounded below by any negative real number . Therefore , by completeness , S has a greatest lower bound ; call it L . It is not diﬃcult to prove that the decreasing sequence { 1 n } must then converge to L , and the subsequence { 12 n } must also converge to L . But since the limit of a product is the product of the limits , whenever all the limits exist , we also know that the sequence { 12 n } converges to L 2 . Therefore , L = L 2 , and L = 0 must follow . Now the proof is complete . The rational number line has “holes” in it that the irrational numbers ﬁll ; in this sense , the completeness of the real numbers is sometimes char - acterized by saying that it has no holes in it . But the completeness of the reals actually tells us other things about the structure of the real numbers . We know , for example , that there are no rational numbers that are larger than all the positive integers . But can there be irrational numbers that are larger than all the positive integers ? Completeness tells us that the answer is no . Corollary 4 . 1 There is no real number larger than all the positive integers . Proof : Suppose , to the contrary , that there is a real number b such that b > n , for all positive integers n . Then 0 < 1 b < 1 n , for all positive integers n . But this cannot happen , since , by the previous proposition , { 1 n } converges to zero . Notice that , if we restrict ourselves to the world of rational numbers when we deﬁne the concept of limit of a sequence , then we must also restrict the (cid:15) to the rationals ; suppose we call this the “rational limit” . When we do this , we can show that the sequence { 1 n } converges to zero . What we have really shown with the proposition and corollary above is that , if a sequence of rational numbers converges to a rational number , in the sense of the “rational limit” , then it converges to that rational number in the usual sense as well . For the more general spaces R J completeness is expressed , for example , by postulating that every Cauchy sequence is a convergent sequence . Deﬁnition 4 . 7 A sequence { x n } of vectors in R J is called a Cauchy se - quence if , for every (cid:15) > 0 there is a positive integer N = N ( (cid:15) ) , usu - ally depending on (cid:15) , such that , for all m and n greater than N , we have (cid:107) x n − x m (cid:107) < (cid:15) . Every convergent sequence in R J is bounded and is a Cauchy sequence . The Bolzano - Weierstrass Theorem tells us that every bounded sequence in R J has a convergent subsequence ; this is equivalent to the completeness of the metric space R J . 4 . 5 . CONTINUITY 49 Theorem 4 . 1 ( The Bolzano - Weierstrass Theorem ) Let { x n } be a bounded sequence of vectors in R J . Then { x n } has a convergent subse - quence . 4 . 5 Continuity A basic notion in analysis is that of a continuous function . Although we shall be concerned primarily with functions whose values are real numbers , we can deﬁne continuity for functions whose values lie in R M . Deﬁnition 4 . 8 We say the function f : R J → R M is continuous at x = a if f ( a ) = lim x → a f ( x ) . A basic theorem in real analysis is the following : Theorem 4 . 2 Let f : R J → R be continuous and let C be non - empty , closed , and bounded . Then there are a and b in C with f ( a ) ≤ f ( x ) and f ( b ) ≥ f ( x ) , for all x in C . We give some examples : • 1 . The function f ( x ) = x is continuous and the set C = [ 0 , 1 ] is non - empty , closed and bounded . The minimum occurs at x = 0 and the maximum occurs at x = 1 . • 2 . The set C = ( 0 , 1 ] is not closed . The function f ( x ) = x has no minimum value on C , but does have a maximum value f ( 1 ) = 1 . • 3 . The set C = ( −∞ , 0 ] is not bounded and f ( x ) = x has no minimum value on C . Note also that f ( x ) = x has no ﬁnite inﬁmum with respect to C . Deﬁnition 4 . 9 Let f : D ⊆ R J → R . For any real α , the level set of f corresponding to α is the set { x | f ( x ) ≤ α } . Proposition 4 . 2 ( Weierstrass ) Suppose that f : D ⊆ R J → R is con - tinuous , where D is non - empty and closed , and that every level set of f is bounded . Then f has a global minimizer . Proof : This is a standard application of the Bolzano - Weierstrass Theorem . 50 CHAPTER 4 . BASIC ANALYSIS 4 . 6 Limsup and Liminf Some of the functions we shall be interested in may be discontinuous at some points . For that reason , it is common in optimization to consider semi - continuity , which is weaker than continuity . While continuity involves limits , semi - continuity involves superior and inferior limits . We know that a real - valued function f ( x ) : R J → R is continuous at x = a if , given any (cid:15) > 0 , there is a δ > 0 such that (cid:107) x − a (cid:107) < δ implies that | f ( x ) − f ( a ) | < (cid:15) . We then write f ( a ) = lim x → a f ( x ) . We can generalize this notion as follows . Deﬁnition 4 . 10 We say that a ﬁnite real number β is the superior limit or lim sup of f ( x ) , as x approaches a , written β = lim sup x → a f ( x ) if , • 1 . for every (cid:15) > 0 , there is δ > 0 such that , for every x satisfying (cid:107) x − a (cid:107) < δ , we have f ( x ) < β + (cid:15) , and • 2 . for every (cid:15) > 0 and δ > 0 there is x with (cid:107) x − a (cid:107) < δ and f ( x ) > β − (cid:15) . Deﬁnition 4 . 11 We say that a ﬁnite real number α is the inferior limit or lim inf of f ( x ) , as x approaches a , written α = lim inf x → a f ( x ) if , • 1 . for every (cid:15) > 0 , there is δ > 0 such that , for every x satisfying (cid:107) x − a (cid:107) < δ , we have f ( x ) > α − (cid:15) , and • 2 . for every (cid:15) > 0 and δ > 0 there is x with (cid:107) x − a (cid:107) < δ and f ( x ) < α + (cid:15) . We leave it as Exercise 4 . 4 for the reader to show that α = lim inf x → a f ( x ) is the largest real number γ with the following property : for every (cid:15) > 0 , there is δ > 0 such that , if (cid:107) x − a (cid:107) < δ , then f ( x ) > γ − (cid:15) . Deﬁnition 4 . 12 We say that β = + ∞ is the superior limit or lim sup of f ( x ) , as x approaches a , written + ∞ = lim sup x → a f ( x ) if , for every B > 0 and δ > 0 there is x with (cid:107) x − a (cid:107) < δ and f ( x ) > B . Deﬁnition 4 . 13 We say that α = −∞ is the inferior limit or lim inf of f ( x ) , as x approaches a , written −∞ = lim inf x → a f ( x ) if , for every B > 0 and δ > 0 , there is x with (cid:107) x − a (cid:107) < δ and f ( x ) < − B . It follows from the deﬁnitions that α ≤ f ( a ) ≤ β . For example , suppose that a = 0 , f ( x ) = 0 , for x (cid:54) = 0 , and f ( 0 ) = 1 . Then β = 1 and α = 0 . If a = 0 , f ( x ) = − 1 / x for x < 0 and f ( x ) = 1 / x for x > 0 , then α = −∞ and β = + ∞ . 4 . 7 . ANOTHER VIEW 51 It is not immediately obvious that β and α always exist . The next section provides another view of these notions , from which it becomes clear that the existence of β and α is a consequence of the completeness of the space R . 4 . 7 Another View We can deﬁne the superior and inferior limits in terms of sequences . We leave it to the reader to show that these deﬁnitions are equivalent to the ones just given . Let f : R J → R and a be ﬁxed in R J . Let L be the set consisting of all γ , possibly including the inﬁnities , having the property that there is a sequence { x n } in R J converging to a such that { f ( x n ) } converges to γ . It is convenient , now , to permit the sequence x n = a for all n , so that γ = f ( a ) is in L and L is never empty . Therefore , we always have −∞ ≤ inf ( L ) ≤ f ( a ) ≤ sup ( L ) ≤ + ∞ . For example , let f ( x ) = 1 / x for x (cid:54) = 0 , f ( 0 ) = 0 , and a = 0 . Then L = { −∞ , 0 , + ∞ } , inf ( L ) = −∞ , and sup ( L ) = + ∞ . Deﬁnition 4 . 14 The ( possibly inﬁnite ) number inf ( L ) is called the inferior limit or lim inf of f ( x ) , as x → a in R J . The ( possibly inﬁnite ) number sup ( L ) is called the superior limit or lim sup of f ( x ) , as x → a in R J . It follows from these deﬁnitions and our previous discussion that lim inf x → a f ( x ) ≤ f ( a ) ≤ lim sup x → a f ( x ) . For example , let f ( x ) = x for x < 0 and f ( x ) = x + 1 for x > 0 . Then we have lim sup x → 0 f ( x ) = 1 , and lim inf x → 0 f ( x ) = 0 . Proposition 4 . 3 The inferior limit and the superior limit are in the set L . Proof : We leave the proof as Exercise 4 . 6 . The function doesn’t have to be deﬁned at a point in order for the lim sup and lim inf to be deﬁned there . If f : ( 0 , δ ) → R , for some δ > 0 , we have the following deﬁnitions : lim sup t ↓ 0 f ( t ) = lim t ↓ 0 (cid:16) sup { f ( x ) | 0 < x < t } (cid:17) , 52 CHAPTER 4 . BASIC ANALYSIS and lim inf t ↓ 0 f ( t ) = lim t ↓ 0 (cid:16) inf { f ( x ) | 0 < x < t } (cid:17) . 4 . 8 Semi - Continuity We know that α ≤ f ( a ) ≤ β . We can generalize the notion of continuity by replacing the limit with the inferior or superior limit . When M = 1 , f ( x ) is continuous at x = a if and only if lim inf x → a f ( x ) = lim sup x → a f ( x ) = f ( a ) . Deﬁnition 4 . 15 We say that f : R J → R is lower semi - continuous ( LSC ) at x = a if f ( a ) = α = lim inf x → a f ( x ) . Deﬁnition 4 . 16 We say that f : R J → R is upper semi - continuous ( USC ) at x = a if f ( a ) = β = lim sup x → a f ( x ) . Note that , if f ( x ) is LSC ( USC ) at x = a , then f ( x ) remains LSC ( USC ) when f ( a ) is replaced by any lower ( higher ) value . See Exercise 4 . 3 for an equivalent deﬁnition of lower semi - continuity . The following theorem of Weierstrass extends Theorem 4 . 2 and shows the importance of lower semi - continuity for minimization problems . Theorem 4 . 3 Let f : R J → R be LSC and let C be non - empty , closed , and bounded . Then there is a in C with f ( a ) ≤ f ( x ) , for all x in C . 4 . 9 Exercises Ex . 4 . 1 Let S and T be non - empty subsets of the real line , with s ≤ t for every s in S and t in T . Prove that lub ( S ) ≤ glb ( T ) . Ex . 4 . 2 Let f ( x , y ) : R 2 → R , and , for each ﬁxed y , let inf x f ( x , y ) denote the greatest lower bound of the set of numbers { f ( x , y ) | x ∈ R } . Show that inf x (cid:16) inf y f ( x , y ) (cid:17) = inf y (cid:16) inf x f ( x , y ) (cid:17) . ( 4 . 1 ) Hint : note that inf y f ( x , y ) ≤ f ( x , y ) , for all x and y . 4 . 9 . EXERCISES 53 Ex . 4 . 3 Prove that f : R J → R is lower semi - continuous at x = a if and only if , for every (cid:15) > 0 , there is δ > 0 such that (cid:107) x − a (cid:107) < δ implies that f ( x ) > f ( a ) − (cid:15) . Ex . 4 . 4 Show that I = lim inf x → a f ( x ) is the largest real number γ with the following property : for every (cid:15) > 0 , there is δ > 0 such that , if (cid:107) x − a (cid:107) < δ , then f ( x ) > γ − (cid:15) . Ex . 4 . 5 Consider the function f ( x ) deﬁned by f ( x ) = e − x , for x > 0 and by f ( x ) = − e x , for x < 0 . Show that − 1 = lim inf x → 0 f ( x ) and 1 = lim sup x → 0 f ( x ) . Ex . 4 . 6 For n = 1 , 2 , . . . , let A n = { x | (cid:107) x − a (cid:107) ≤ 1 n } , and let α n and β n be deﬁned by α n = inf { f ( x ) | x ∈ A n } , and β n = sup { f ( x ) | x ∈ A n } . • a ) Show that the sequence { α n } is increasing , bounded above by f ( a ) and converges to some α , while the sequence { β n } is decreasing , bounded below by f ( a ) and converges to some β . Hint : use the fact that , if A ⊆ B , where A and B are sets of real numbers , then inf ( A ) ≥ inf ( B ) . • b ) Show that α and β are in L . Hint : prove that there is a sequence { x n } with x n in A n and f ( x n ) ≤ α n + 1 n . • c ) Show that , if { x m } is any sequence converging to a , then there is a subsequence , denoted { x m n } , such that x m n is in A n , for each n . • d ) Show that , if { f ( x m ) } converges to γ , then α n ≤ f ( x m n ) ≤ β n , so that α ≤ γ ≤ β . • e ) Show that α = lim inf x → a f ( x ) and β = lim sup x → a f ( x ) . 54 CHAPTER 4 . BASIC ANALYSIS 4 . 10 Course Homework I suggest trying all the exercises in this chapter . Chapter 5 Diﬀerentiation 5 . 1 Chapter Summary The deﬁnition of the derivative of a function g : D ⊆ R → R is a familiar one . In this chapter we examine various ways in which this deﬁnition can be extended to functions f : D ⊆ R J → R of several variables . Here D is the domain of the function f and we assume that int ( D ) , the interior of the set D , is not empty . 5 . 2 Directional Derivative We begin with one - and two - sided directional derivatives . 5 . 2 . 1 Deﬁnitions The function g ( x ) = | x | does not have a derivative at x = 0 , but it has one - sided directional derivatives there . The one - sided directional derivative of g ( x ) at x = 0 , in the direction of x = 1 , is g (cid:48) + ( 0 ; 1 ) = lim t ↓ 0 1 t [ g ( 0 + t ) − g ( 0 ) ] = 1 , ( 5 . 1 ) and in the direction of x = − 1 , it is g (cid:48) + ( 0 ; − 1 ) = lim t ↓ 0 1 t [ g ( 0 − t ) − g ( 0 ) ] = 1 . ( 5 . 2 ) However , the two - sided derivative of g ( x ) = | x | does not exist at x = 0 . We can extend the concept of one - sided directional derivatives to func - tions of several variables . 55 56 CHAPTER 5 . DIFFERENTIATION Deﬁnition 5 . 1 Let f : D ⊆ R J → R be a real - valued function of several variables , let a be in int ( D ) , and let d be a unit vector in R J . The one - sided directional derivative of f ( x ) , at x = a , in the direction of d , is f (cid:48) + ( a ; d ) = lim t ↓ 0 1 t [ f ( a + td ) − f ( a ) ] . ( 5 . 3 ) Deﬁnition 5 . 2 The two - sided directional derivative of f ( x ) at x = a , in the direction of d , is f (cid:48) ( a ; d ) = lim t → 0 1 t ( f ( a + td ) − f ( a ) ) . ( 5 . 4 ) If the two - sided directional derivative exists then we have f (cid:48) ( a ; d ) = f (cid:48) + ( a ; d ) = − f (cid:48) + ( a ; − d ) . Given x = a and d , we deﬁne the function φ ( t ) = f ( a + td ) , for t such that a + td is in D . The derivative of φ ( t ) at t = 0 is then φ (cid:48) ( 0 ) = lim t → 0 1 t [ φ ( t ) − φ ( 0 ) ] = f (cid:48) ( a ; d ) . ( 5 . 5 ) In the deﬁnition of f (cid:48) ( a ; d ) we restricted d to unit vectors because the directional derivative f (cid:48) ( a ; d ) is intended to measure the rate of change of f ( x ) as x moves away from x = a in the direction d . Later , in our discussion of convex functions , it will be convenient to view f (cid:48) ( a ; d ) as a function of d and to extend this function to the more general function of arbitrary z deﬁned by f (cid:48) ( a ; z ) = lim t → 0 1 t ( f ( a + tz ) − f ( a ) ) . ( 5 . 6 ) It is easy to see that f (cid:48) ( a ; z ) = (cid:107) z (cid:107) 2 f (cid:48) ( a ; z / (cid:107) z (cid:107) 2 ) . 5 . 3 Partial Derivatives For j = 1 , . . . , J , denote by e j the vector whose entries are all zero , except for a one in the j th position . Deﬁnition 5 . 3 If f (cid:48) ( a ; e j ) exists , then it is ∂f∂x j ( a ) , the partial derivative of f ( x ) , at x = a , with respect to x j , the j th entry of the variable vector x . Deﬁnition 5 . 4 If the partial derivative , at x = a , with respect to x j , exists for each j , then the gradient of f ( x ) , at x = a , is the vector ∇ f ( a ) whose entries are ∂f∂x j ( a ) . 5 . 4 . SOME EXAMPLES 57 5 . 4 Some Examples We consider some examples of directional derivatives . 5 . 4 . 1 Example 1 . For ( x , y ) (cid:54) = ( 0 , 0 ) , let f ( x , y ) = 2 xy x 2 + y 2 , and deﬁne f ( 0 , 0 ) = 1 . Let d = ( cos θ , sin θ ) . Then it is easy to show that φ ( t ) = sin 2 θ , for t (cid:54) = 0 , and φ ( 0 ) = 1 . If θ is such that sin 2 θ = 1 , then φ ( t ) is constant , and φ (cid:48) ( 0 ) = 0 . But , if sin 2 θ (cid:54) = 1 , then φ ( t ) is discontinuous at t = 0 , so φ ( t ) is not diﬀerentiable at t = 0 . Therefore , f ( x , y ) has a two - sided directional derivative at ( x , y ) = ( 0 , 0 ) only in certain directions . 5 . 4 . 2 Example 2 . [ 114 ] For ( x , y ) (cid:54) = ( 0 , 0 ) , let f ( x , y ) = 2 xy 2 x 2 + y 4 , and f ( 0 , 0 ) = 0 . Again , let d = ( cos θ , sin θ ) . Then we have φ (cid:48) ( 0 ) = 2 sin 2 θ cos θ , for cos θ (cid:54) = 0 . If cos θ = 0 , then f ( x ) is the constant zero in that direction , so φ (cid:48) ( 0 ) = 0 . Therefore , the function f ( x , y ) has a two - sided directional derivative at ( x , y ) = ( 0 , 0 ) , for every vector d . Note that the two partial derivatives are both zero at ( x , y ) = ( 0 , 0 ) , so ∇ f ( 0 , 0 ) = 0 . Note also that , since f ( y 2 , y ) = 1 for all y (cid:54) = 0 , the function f ( x , y ) is not continuous at ( 0 , 0 ) . 5 . 5 Gˆateaux Derivative Just having a two - sided directional derivative for every d is not suﬃcient , in most cases ; we need something stronger . Deﬁnition 5 . 5 If f ( x ) has a two - sided directional derivative at x = a , for every vector d , and , in addition , f (cid:48) ( a ; d ) = (cid:104)∇ f ( a ) , d (cid:105) , for each d , then f ( x ) is Gˆateaux - diﬀerentiable at x = a , and ∇ f ( a ) is the Gˆateaux derivative of f ( x ) at x = a , also denoted f (cid:48) ( a ) . 58 CHAPTER 5 . DIFFERENTIATION Example 2 above showed that it is possible for f ( x ) to have a two - sided directional derivative at x = a , for every d , and yet fail to be Gˆateaux - diﬀerentiable . From Cauchy’s Inequality , we know that | f (cid:48) ( a ; d ) | = | (cid:104)∇ f ( a ) , d (cid:105) | ≤ | | ∇ f ( a ) | | 2 | | d | | 2 , and that f (cid:48) ( a ; d ) attains its most positive value when the direction d is a positive multiple of ∇ f ( a ) . This is the motivation for steepest descent optimization . For ordinary functions g : D ⊆ R → R , we know that diﬀerentiability implies continuity . It is possible for f ( x ) to be Gˆateaux - diﬀerentiable at x = a and yet not be continuous at x = a ; see Ortega and Rheinboldt [ 173 ] . This means that the notion of Gˆateaux - diﬀerentiability is too weak . In order to have a nice theory of multivariate diﬀerentiation , the notion of derivative must be strengthened . The stronger notion we seek is Fr´echet diﬀerentiability . 5 . 6 Fr´echet Derivative The notion of Fr´echet diﬀerentiability is the one appropriate for our pur - poses . 5 . 6 . 1 The Deﬁnition Deﬁnition 5 . 6 We say that f ( x ) is Fr´echet - diﬀerentiable at x = a and ∇ f ( a ) is its Fr´echet derivative if lim | | h | | → 0 1 | | h | | | f ( a + h ) − f ( a ) − (cid:104)∇ f ( a ) , h (cid:105) | = 0 . Notice that the limit in the deﬁnition of the Fr´echet derivative involves the norm of the incremental vector h , which is where the power of the Fr´echet derivative arises . Also , since the norm and the associated inner product can be changed , so can the Fr´echet derivative ; see Exercise 5 . 1 for an example . The corresponding limit in the deﬁnition of the Gˆateaux derivative involves only the scalar t , and therefore requires no norm and makes sense in any vector space . 5 . 6 . 2 Properties of the Fr´echet Derivative It can be shown that if f ( x ) is Fr´echet - diﬀerentiable at x = a , then f ( x ) is continuous at x = a . If f ( x ) is Gˆateaux - diﬀerentiable at each point in an open set containing x = a , and ∇ f ( x ) is continuous at x = a , then ∇ f ( a ) is also the Fr´echet derivative of f ( x ) at x = a . Since the continuity of ∇ f ( x ) 5 . 7 . THE CHAIN RULE 59 is equivalent to the continuity of each of the partial derivatives , we learn that f ( x ) is Fr´echet - diﬀerentiable at x = a if it is Gˆateaux - diﬀerentiable in a neighborhood of x = a and the partial derivatives are continuous at x = a . If ∇ f ( x ) is continuous in a neighborhood of x = a , the function f ( x ) is said to be continuously diﬀerentiable . Unless we write otherwise , when we say that a function is diﬀerentiable , we shall mean Gˆateaux - diﬀerentiable , since this is usually suﬃcient for our purposes and the two types of diﬀerentiability typically coincide anyway . 5 . 7 The Chain Rule For ﬁxed a and d in R J , the function φ ( t ) = f ( a + td ) , deﬁned for the real variable t , is a composition of the function f : R J → R itself and the function g : R → R J deﬁned by g ( t ) = a + td ; that is , φ ( t ) = f ( g ( t ) ) . Writing f ( a + td ) = f ( a 1 + td 1 , a 2 + td 2 , . . . , a J + td J ) , and applying the Chain Rule , we ﬁnd that f (cid:48) ( a ; d ) = φ (cid:48) ( 0 ) = ∂f ∂x 1 ( a ) d 1 + . . . + ∂f ∂x J ( a ) d J ; that is , f (cid:48) ( a ; d ) = φ (cid:48) ( 0 ) = (cid:104)∇ f ( a ) , d (cid:105) . But we know that f (cid:48) ( a ; d ) is not always equal to (cid:104)∇ f ( a ) , d (cid:105) . This means that the Chain Rule is not universally true and must involve conditions on the function f . Clearly , unless the function f is Gˆateaux - diﬀerentiable , the chain rule cannot hold . For an in - depth treatment of this matter , consult Ortega and Rheinboldt [ 173 ] . 5 . 8 A Useful Proposition The following proposition will be useful later in proving Gordan’s Theorem of the Alternative , Theorem 6 . 8 . Proposition 5 . 1 If the function f : R J → R is diﬀerentiable and bounded below , that is , there is a constant α such that α ≤ f ( x ) for all x , then for every (cid:15) > 0 there is a point x (cid:15) with (cid:107)∇ f ( x (cid:15) ) (cid:107) 2 ≤ (cid:15) . Proof : Fix (cid:15) > 0 . The function f ( x ) + (cid:15) (cid:107) x (cid:107) 2 has bounded level sets , so , by Proposition 4 . 2 , it has a global minimizer , which we denote by x (cid:15) . We show that d = ∇ f ( x (cid:15) ) has (cid:107) d (cid:107) 2 ≤ (cid:15) . 60 CHAPTER 5 . DIFFERENTIATION If not , then (cid:107) d (cid:107) 2 > (cid:15) . From the inequality lim t ↓ 0 f ( x (cid:15) − td ) − f ( x (cid:15) ) t = −(cid:104)∇ f ( x (cid:15) ) , d (cid:105) = −(cid:107) d (cid:107) 22 < − (cid:15) (cid:107) d (cid:107) 2 we would have , for small positive t , − t(cid:15) (cid:107) d (cid:107) 2 > f ( x (cid:15) − td ) − f ( x (cid:15) ) = ( f ( x (cid:15) − td ) + (cid:15) (cid:107) x (cid:15) − td (cid:107) 2 ) − ( f ( x (cid:15) ) + (cid:15) (cid:107) x (cid:15) (cid:107) 2 ) + (cid:15) ( (cid:107) x (cid:15) (cid:107) 2 − (cid:107) x (cid:15) − td (cid:107) 2 ) ≥ − t(cid:15) (cid:107) d (cid:107) 2 , which is impossible . 5 . 9 Exercises Ex . 5 . 1 Let Q be a real , positive - deﬁnite symmetric matrix . Deﬁne the Q - inner product on R J to be (cid:104) x , y (cid:105) Q = x T Qy = (cid:104) x , Qy (cid:105) , and the Q - norm to be | | x | | Q = (cid:113) (cid:104) x , x (cid:105) Q . Show that , if ∇ f ( a ) is the Fr´echet derivative of f ( x ) at x = a , for the usual Euclidean norm , then Q − 1 ∇ f ( a ) is the Fr´echet derivative of f ( x ) at x = a , for the Q - norm . Hint : use the inequality (cid:112) λ J | | h | | 2 ≤ | | h | | Q ≤ (cid:112) λ 1 | | h | | 2 , where λ 1 and λ J denote the greatest and smallest eigenvalues of Q , respec - tively . Ex . 5 . 2 ( [ 23 ] , Ex . 10 , p . 134 ) For ( x , y ) not equal to ( 0 , 0 ) , let f ( x , y ) = x a y b x p + y q , with f ( 0 , 0 ) = 0 . In each of the ﬁve cases below , determine if the function is continuous , Gˆateaux , Fr´echet or continuously diﬀerentiable at ( 0 , 0 ) . • 1 ) a = 2 , b = 3 , p = 2 , and q = 4 ; • 2 ) a = 1 , b = 3 , p = 2 , and q = 4 ; • 3 ) a = 2 , b = 4 , p = 4 , and q = 8 ; • 4 ) a = 1 , b = 2 , p = 2 , and q = 2 ; • 5 ) a = 1 , b = 2 , p = 2 , and q = 4 . 5 . 10 . COURSE HOMEWORK 61 5 . 10 Course Homework Try some of Exercise 5 . 2 . 62 CHAPTER 5 . DIFFERENTIATION Chapter 6 Convex Sets 6 . 1 Chapter Summary Convex sets and convex functions play important roles in optimization . In this chapter we survey the basic facts concerning the geometry of convex sets . We begin with the geometry of R J . 6 . 2 The Geometry of Real Euclidean Space We denote by R J the real Euclidean space consisting of all J - dimensional column vectors x = ( x 1 , . . . , x J ) T with real entries x j ; here the superscript T denotes the transpose of the 1 by J matrix ( or , row vector ) ( x 1 , . . . , x J ) . 6 . 2 . 1 Inner Products For x = ( x 1 , . . . , x J ) T and y = ( y 1 , . . . , y J ) T in R J , the dot product x · y is deﬁned to be x · y = J (cid:88) j = 1 x j y j . ( 6 . 1 ) Note that we can write x · y = y T x = x T y , ( 6 . 2 ) where juxtaposition indicates matrix multiplication . The 2 - norm , or Eu - clidean norm , or Euclidean length , of x is | | x | | 2 = √ x · x = √ x T x . ( 6 . 3 ) The Euclidean distance between two vectors x and y in R J is | | x − y | | 2 . 63 64 CHAPTER 6 . CONVEX SETS The space R J , along with its dot product , is an example of a ﬁnite - dimensional Hilbert space . Deﬁnition 6 . 1 Let V be a real vector space . The scalar - valued function (cid:104) u , v (cid:105) is called an inner product on V if the following four properties hold , for all u , w , and v in V , and all real c : (cid:104) u + w , v (cid:105) = (cid:104) u , v (cid:105) + (cid:104) w , v (cid:105) ; ( 6 . 4 ) (cid:104) cu , v (cid:105) = c (cid:104) u , v (cid:105) ; ( 6 . 5 ) (cid:104) v , u (cid:105) = (cid:104) u , v (cid:105) ; ( 6 . 6 ) and (cid:104) u , u (cid:105) ≥ 0 , ( 6 . 7 ) with equality in Inequality ( 6 . 7 ) if and only if u = 0 . The dot product of vectors is an example of an inner product . The prop - erties of an inner product are precisely the ones needed to prove Cauchy’s Inequality , which then holds for any inner product . We shall favor the dot product notation u · v for the inner product of vectors , although we shall occasionally use the matrix multiplication form , v T u or the inner product notation (cid:104) u , v (cid:105) . 6 . 2 . 2 Cauchy’s Inequality Cauchy’s Inequality , also called the Cauchy - Schwarz Inequality , tells us that | (cid:104) x , y (cid:105) | ≤ | | x | | 2 | | y | | 2 , ( 6 . 8 ) with equality if and only if y = αx , for some scalar α . The Cauchy - Schwarz Inequality holds for any inner product . We say that the vectors x and y are mutually orthogonal if (cid:104) x , y (cid:105) = 0 . A simple application of Cauchy’s inequality gives us | | x + y | | 2 ≤ | | x | | 2 + | | y | | 2 , ( 6 . 9 ) with equality if and only if one of the vectors is a non - negative multiple of the other one ; this is called the Triangle Inequality . The Parallelogram Law is an easy consequence of the deﬁnition of the 2 - norm : | | x + y | | 22 + | | x − y | | 22 = 2 | | x | | 22 + 2 | | y | | 22 . ( 6 . 10 ) 6 . 3 . A BIT OF TOPOLOGY 65 It is important to remember that Cauchy’s Inequality and the Parallelo - gram Law hold only for the 2 - norm . One consequence of the Parallelogram Law that we shall need later is the following : if x (cid:54) = y and (cid:107) x (cid:107) 2 = (cid:107) y (cid:107) 2 = d , then (cid:107) 12 ( x + y ) (cid:107) 2 < d ( Draw a picture ! ) . 6 . 2 . 3 Other Norms The two - norm is not the only norm we study on the space R J . We will also be interested in the one - norm ( see Exercise 6 . 4 ) . The purely topological results we discuss in the next section are independent of the choice of norm on R J , and we shall remind the reader of this by using the notation (cid:107) x (cid:107) to denote an arbitrary norm . Theorems concerning orthogonal projection hold only for the two - norm , which we shall denote by (cid:107) x (cid:107) 2 . In fact , whenever we use the word “orthogonal” , we shall imply that we are speaking about the two - norm . There have been attempts to deﬁne orthogonality in the absence of an inner product , and so for other norms , but the theory here is not as successful . 6 . 3 A Bit of Topology Having a norm allows us to deﬁne the distance between two points x and y in R J as | | x − y | | . Being able to talk about how close points are to each other enables us to deﬁne continuity of functions on R J and to consider topological notions of closed set , open set , interior of a set and boundary of a set . None of these notions depend on the particular norm we are using . Deﬁnition 6 . 2 A subset B of R J is closed if , whenever x k is in B for each non - negative integer k and | | x − x k | | → 0 , as k → + ∞ , then x is in B . For example , B = [ 0 , 1 ] is closed as a subset of R , but B = ( 0 , 1 ) is not . Deﬁnition 6 . 3 We say that d ≥ 0 is the distance from the point x to the set B if , for every (cid:15) > 0 , there is b (cid:15) in B , with | | x − b (cid:15) | | < d + (cid:15) , and no b in B with | | x − b | | < d . The Euclidean distance from the point 0 in R to the set ( 0 , 1 ) is zero , while its distance to the set ( 1 , 2 ) is one . It follows easily from the deﬁnitions that , if B is closed and d = 0 , then x is in B . Deﬁnition 6 . 4 The closure of a set B is the set of all points x whose distance from B is zero . The closure of the interval B = ( 0 , 1 ) is [ 0 , 1 ] . 66 CHAPTER 6 . CONVEX SETS Deﬁnition 6 . 5 A subset U of R J is open if its complement , the set of all points not in U , is closed . Deﬁnition 6 . 6 Let C be a subset of R J . A point x in C is said to be an interior point of set C if there is (cid:15) > 0 such that every point z with | | x − z | | < (cid:15) is in C . The interior of the set C , written int ( C ) , is the set of all interior points of C . It is also the largest open set contained within C . For example , the open interval ( 0 , 1 ) is the interior of the intervals ( 0 , 1 ] and [ 0 , 1 ] . A set C is open if and only if C = int ( C ) . Deﬁnition 6 . 7 A point x in R J is said to be a boundary point of set C if , for every (cid:15) > 0 , there are points y (cid:15) in C and z (cid:15) not in C , both depending on the choice of (cid:15) , with | | x − y (cid:15) | | < (cid:15) and | | x − z (cid:15) | | < (cid:15) . The boundary of C is the set of all boundary points of C . It is also the intersection of the closure of C with the closure of its complement . For example , the points x = 0 and x = 1 are boundary points of the set ( 0 , 1 ] . Deﬁnition 6 . 8 For k = 0 , 1 , 2 , . . . , let x k be a vector in R J . The sequence of vectors { x k } is said to converge to the vector z if , given any (cid:15) > 0 , there is positive integer n , usually depending on (cid:15) , such that , for every k > n , we have | | z − x k | | ≤ (cid:15) . Then we say that z is the limit of the sequence . For example , the sequence { x k = 1 k + 1 } in R converges to z = 0 . The sequence { ( − 1 ) k } alternates between 1 and − 1 , so does not converge . How - ever , the subsequence associated with odd k converges to z = − 1 , while the subsequence associated with even k converges to z = 1 . The values z = − 1 and z = 1 are called subsequential limit points , or , sometimes , cluster points of the sequence . Deﬁnition 6 . 9 A sequence { x k } of vectors in R J is said to be bounded if there is a constant b > 0 , such that | | x k | | ≤ b , for all k . A fundamental result in analysis is the following . Proposition 6 . 1 Every convergent sequence of vectors in R J is bounded . Every bounded sequence of vectors in R J has at least one convergent sub - sequence , therefore , has at least one cluster point . 6 . 4 Convex Sets in R J In preparation for our discussion of linear and nonlinear programming , we consider some of the basic concepts from the geometry of convex sets . 6 . 4 . CONVEX SETS IN R J 67 6 . 4 . 1 Basic Deﬁnitions We begin with the basic deﬁnitions . Deﬁnition 6 . 10 A vector z is said to be a convex combination of the vectors x and y if there is α in the interval [ 0 , 1 ] such that z = ( 1 − α ) x + αy . More generally , a vector z is a convex combination of the vectors x n , n = 1 , . . . , N , if there are numbers α n ≥ 0 with α 1 + . . . + α N = 1 and z = α 1 x 1 + . . . + α N x N . Deﬁnition 6 . 11 A nonempty set C in R J is said to be convex if , for any distinct points x and y in C , and for any real number α in the interval ( 0 , 1 ) , the point ( 1 − α ) x + αy is also in C ; that is , C is closed to convex combinations of any two members of C . In Exercise 6 . 1 you are asked to show that if C is convex then the convex combination of any number of members of C is again in C . We say then that C is closed to convex combinations . For example , the two - norm unit ball B in R J , consisting of all x with | | x | | 2 ≤ 1 , is convex , while the surface of the ball , the set of all x with | | x | | 2 = 1 , is not convex . More generally , the unit ball of R J in any norm is a convex set , as a consequence of the triangle inequality for norms . Deﬁnition 6 . 12 The convex hull of a set S , denoted conv ( S ) , is the small - est convex set containing S , by which we mean that if K is any convex set containing S , then K must also contain conv ( S ) . One weakness of this deﬁnition is that it does not tell us explicitly what the members of conv ( S ) look like , nor precisely how the individual members of conv ( S ) are related to the members of S itself . In fact , it is not obvious that a smallest such set exists at all . The following proposition remedies this ; the reader is asked to supply a proof in Exercise 6 . 2 later . Proposition 6 . 2 The convex hull of a set S is the set C of all convex combinations of members of S . Deﬁnition 6 . 13 A subset S of R J is a subspace if , for every x and y in S and scalars α and β , the linear combination αx + βy is again in S . A subspace is necessarily a convex set . 68 CHAPTER 6 . CONVEX SETS Deﬁnition 6 . 14 The orthogonal complement of a subspace S of R J , en - dowed with the two - norm , is the set S ⊥ = { u | (cid:104) u , s (cid:105) = u · s = u T s = 0 , for every s ∈ S } , ( 6 . 11 ) the set of all vectors u in R J that are orthogonal to every member of S . For example , in R 3 , the x , y - plane is a subspace and has for its orthog - onal complement the z - axis . Deﬁnition 6 . 15 A subset M of R J is a linear manifold if there is a sub - space S and a vector b such that M = S + b = { x | x = s + b , for some s in S } . Any linear manifold is convex . Deﬁnition 6 . 16 For a ﬁxed column vector a with Euclidean length one and a ﬁxed scalar γ the hyperplane determined by a and γ is the set H ( a , γ ) = { z | (cid:104) a , z (cid:105) = γ } . The hyperplanes H ( a , γ ) are linear manifolds , and the hyperplanes H ( a , 0 ) are subspaces . Hyperplanes in R J are naturally associated with lin - ear equations in J variables ; with a = ( a 1 , . . . , a J ) T , the hyperplane H ( a , γ ) is the set of all z = ( z 1 , . . . , z J ) T for which a 1 z 1 + a 2 z 2 + . . . + a J z J = γ . Earlier , we mentioned that there are two related , but distinct , ways to view members of the set R J . The ﬁrst is to see x in R J as a point in J - dimensional space , so that , for example , if J = 2 , then a member x of R 2 can be thought of as a point in a plane , the plane of the blackboard , say . The second way is to think of x is as the directed line segment from the origin to the point also denoted x . We purposely avoided making a choice between one interpretation and the other because there are cases in which we want to employ both interpretations ; the deﬁnition of the hyperplane H ( a , γ ) provides just such a case . We want to think of the members of the hyperplane as points in R J that lie within the set H ( a , γ ) , but we want to think of a as a directed line segment perpendicular , or normal , to the hyperplane . When x , viewed as a point , is in H ( a , γ ) , the directed line segment from the origin to x will not lie in the hyperplane , unless γ = 0 . Lemma 6 . 1 The distance from the hyperplane H ( a , γ ) to the hyperplane H ( a , γ + 1 ) is one . The proof is left as Exercise 6 . 8 . 6 . 4 . CONVEX SETS IN R J 69 Deﬁnition 6 . 17 For each vector a and each scalar γ , the sets H + ( a , γ ) = { z | (cid:104) a , z (cid:105) ≥ γ } H − ( a , γ ) = { z | (cid:104) a , z (cid:105) ≤ γ } are half - spaces . Half - spaces in R J are naturally associated with linear inequalities in J variables ; with a = ( a 1 , . . . , a J ) T , the half - space H + ( a , γ ) is the set of all z = ( z 1 , . . . , z J ) T for which a 1 z 1 + a 2 z 2 + . . . + a J z J ≥ γ . Perhaps the most important convex sets in optimization are the poly - hedrons : Deﬁnition 6 . 18 A subset P of R J is a polyhedron if P is the intersection of a ﬁnite number of half - spaces . A polyhedron is the set of all vectors that satisfy a ﬁnite number of linear inequalities : the set P in R 2 consisting of all vectors ( x 1 , x 2 ) with x 1 ≥ 0 , x 2 ≥ 0 is an unbounded polyhedron , while the set B in R 2 con - sisting of all vectors ( x 1 , x 2 ) with x 1 ≥ 0 , x 2 ≥ 0 and x 1 + x 2 ≤ 1 is a bounded polyhedron . The set B is also the convex hull of a ﬁnite set of points , namely the three points ( 0 , 0 ) , ( 1 , 0 ) and ( 0 , 1 ) , and therefore is also a polytope . Deﬁnition 6 . 19 Given a subset C of R J , the aﬃne hull of C , denoted aﬀ ( C ) , is the smallest linear manifold containing C . For example , let C be the line segment connecting the two points ( 0 , 1 ) and ( 1 , 2 ) in R 2 . The aﬃne hull of C is the straight line whose equation is y = x + 1 . Deﬁnition 6 . 20 The dimension of a subset of R J is the dimension of its aﬃne hull , which is the dimension of the subspace of which it is a translate . The set C above has dimension one . A set containing only one point is its own aﬃne hull , since it is a translate of the subspace { 0 } . In R 2 , the line segment connecting the points ( 0 , 1 ) and ( 1 , 2 ) has no interior ; it is a one - dimensional subset of a two - dimensional space and can contain no two - dimensional ball . But , the part of this set without its two end points is a sort of interior , called the relative interior . Deﬁnition 6 . 21 The relative interior of a subset C of R J , denoted ri ( C ) , is the interior of C , as deﬁned by considering C as a subset of its aﬃne hull . 70 CHAPTER 6 . CONVEX SETS Since a set consisting of a single point is its own aﬃne hull , it is its own relative interior . Deﬁnition 6 . 22 A point x in a convex set C is said to be an extreme point of C if the set obtained by removing x from C remains convex . Said another way , x ∈ C is an extreme point of C if x is not a convex combination of two other points in C ; that is , x cannot be written as x = ( 1 − α ) y + αz , ( 6 . 12 ) for y and z in C , y , z (cid:54) = x and α ∈ ( 0 , 1 ) . For example , the point x = 1 is an extreme point of the convex set C = [ 0 , 1 ] . Every point on the boundary of a sphere in R J is an extreme point of the sphere . The set of all extreme points of a convex set is denoted Ext ( C ) . Deﬁnition 6 . 23 A non - zero vector d is said to be a direction of unbound - edness of a convex set C if , for all x in C and all γ ≥ 0 , the vector x + γd is in C . For example , if C is the non - negative orthant in R J , then any non - negative vector d is a direction of unboundedness . Deﬁnition 6 . 24 A vector a is normal to a convex set C at the point s in C if (cid:104) a , c − s (cid:105) ≤ 0 , ( 6 . 13 ) for all c in C . Deﬁnition 6 . 25 Let C be convex and s in C . The normal cone to C at s , denoted N C ( s ) , is the set of all vectors a that are normal to C at s . Normality and the normal cone are notions that make sense only in a space with an inner product , so are implicitly connected to the two - norm . 6 . 4 . 2 Orthogonal Projection onto Convex Sets The following proposition is fundamental in the study of convexity and can be found in most books on the subject ; see , for example , the text by Goebel and Reich [ 118 ] . Proposition 6 . 3 Given any nonempty closed convex set C and an arbi - trary vector x in R J , there is a unique member P C x of C closest , in the sense of the two - norm , to x . The vector P C x is called the orthogonal ( or metric ) projection of x onto C and the operator P C the orthogonal projec - tion onto C . 6 . 4 . CONVEX SETS IN R J 71 Proof : If x is in C , then P C x = x , so assume that x is not in C . Then d > 0 , where d is the distance from x to C . For each positive integer n , select c n in C with | | x − c n | | 2 < d + 1 n . Then , since for all n we have (cid:107) c n (cid:107) 2 = (cid:107) c n − x + x (cid:107) 2 ≤ (cid:107) c n − x (cid:107) 2 + (cid:107) x (cid:107) 2 ≤ d + 1 n + (cid:107) x (cid:107) 2 < d + 1 + (cid:107) x (cid:107) 2 , the sequence { c n } is bounded ; let c ∗ be any cluster point . It follows easily that | | x − c ∗ | | 2 = d and that c ∗ is in C . If there is any other member c of C with | | x − c | | 2 = d , then , by the Parallelogram Law , we would have | | x − ( c ∗ + c ) / 2 | | 2 < d , which is a contradiction . Therefore , c ∗ is P C x . The proof just given relies on the Bolzano - Weierstrass Theorem 4 . 1 . There is another proof , which avoids this theorem and so is valid for inﬁnite - dimensional Hilbert space . The idea is to use the Parallelogram Law to show that the sequence { c n } is Cauchy and then to use completeness to get c ∗ . We leave the details to the reader . Here are some examples of orthogonal projection . If C = U , the unit ball , then P C x = x / | | x | | 2 , for all x such that | | x | | 2 > 1 , and P C x = x otherwise . If C is R J + , the nonnegative cone of R J , consisting of all vectors x with x j ≥ 0 , for each j , then P C x = x + , the vector whose entries are max ( x j , 0 ) . For any closed , convex set C , the distance from x to C is | | x − P C x | | 2 . If a nonempty closed set S is not convex , then the orthogonal projection of a vector x onto S need not be well deﬁned ; there may be more than one vector in S closest to x . In fact , it is known that a closed set S is convex if and only if , for every x not in S , there is a unique point in S closest to x ; this is Motzkin’s Theorem ( see [ 24 ] , p . 447 ) . Note that there may well be some x for which there is a unique closest point in S , but if S is closed , but not convex , then there must be at least one point without a unique closest point in S . The main reason for not speaking about orthogonal projection in the context of other norms is that there need not be a unique closest point in C to x ; remember that the Parallelogram Law need not hold . For example , consider the closed convex set C in R 2 consisting of all vectors ( a , b ) T with a ≥ 0 , b ≥ 0 , and a + b = 1 . Let x = ( 1 , 1 ) T . Then each point in C is a distance one from x , in the sense of the one - norm . Lemma 6 . 2 For H = H ( a , γ ) , z = P H x is the vector z = P H x = x + ( γ − (cid:104) a , x (cid:105) ) a . ( 6 . 14 ) We shall use this fact in our discussion of the ART algorithm . For an arbitrary nonempty closed convex set C in R J , the orthogonal projection T = P C is a nonlinear operator , unless , of course , C is a sub - space . We may not be able to describe P C x explicitly , but we do know a useful property of P C x . 72 CHAPTER 6 . CONVEX SETS Proposition 6 . 4 For a given x , a vector z in C is P C x if and only if (cid:104) c − z , z − x (cid:105) ≥ 0 , ( 6 . 15 ) for all c in the set C . Proof : Let c be arbitrary in C and α in ( 0 , 1 ) . Then | | x − P C x | | 22 ≤ | | x − ( 1 − α ) P C x − αc | | 22 = | | x − P C x + α ( P C x − c ) | | 22 = | | x − P C x | | 22 − 2 α (cid:104) x − P C x , c − P C x (cid:105) + α 2 | | P C x − c | | 22 . ( 6 . 16 ) Therefore , − 2 α (cid:104) x − P C x , c − P C x (cid:105) + α 2 | | P C x − c | | 22 ≥ 0 , ( 6 . 17 ) so that 2 (cid:104) x − P C x , c − P C x (cid:105) ≤ α | | P C x − c | | 22 . ( 6 . 18 ) Taking the limit , as α → 0 , we conclude that (cid:104) c − P C x , P C x − x (cid:105) ≥ 0 . ( 6 . 19 ) If z is a member of C that also has the property (cid:104) c − z , z − x (cid:105) ≥ 0 , ( 6 . 20 ) for all c in C , then we have both (cid:104) z − P C x , P C x − x (cid:105) ≥ 0 , ( 6 . 21 ) and (cid:104) z − P C x , x − z (cid:105) ≥ 0 . ( 6 . 22 ) Adding on both sides of these two inequalities lead to (cid:104) z − P C x , P C x − z (cid:105) ≥ 0 . ( 6 . 23 ) But , (cid:104) z − P C x , P C x − z (cid:105) = − | | z − P C x | | 22 , ( 6 . 24 ) so it must be the case that z = P C x . This completes the proof . Corollary 6 . 1 For any x and y in R J we have (cid:104) P C x − P C y , x − y (cid:105) ≥ (cid:107) P C x − P C y (cid:107) 22 . ( 6 . 25 ) 6 . 5 . SOME RESULTS ON PROJECTIONS 73 Proof : Use Inequality ( 6 . 4 ) to get (cid:104) P C y − P C x , P C x − x (cid:105) ≥ 0 , ( 6 . 26 ) and (cid:104) P C x − P C y , P C y − y (cid:105) ≥ 0 . ( 6 . 27 ) Add the two inequalities to obtain (cid:104) P C x − P C y , x − y (cid:105) ≥ | | P C x − P C y | | 22 . ( 6 . 28 ) 6 . 5 Some Results on Projections The characterization of the orthogonal projection operator P C given by Proposition 6 . 4 has a number of important consequences . Corollary 6 . 2 Let S be any subspace of R J . Then , for any x in R J and s in S , we have (cid:104) P S x − x , s (cid:105) = 0 . ( 6 . 29 ) Proof : Since S is a subspace , s + P S x is again in S , for all s , as is γs , for every scalar γ . This corollary enables us to prove the Decomposition Theorem . Theorem 6 . 1 Let S be any subspace of R J and x any member of R J . Then there are unique vectors s in S and u in S ⊥ such that x = s + u . The vector s is P S x and the vector u is P S ⊥ x . Proof : For the given x we take s = P S x and u = x − P S x . Corollary 6 . 2 assures us that u is in S ⊥ . Now we need to show that this decomposition is unique . To that end , suppose that we can write x = s 1 + u 1 , with s 1 in S and u 1 in S ⊥ . Then Proposition 6 . 4 tells us that , since s 1 − x is orthogonal to every member of S , s 1 must be P S x . This theorem is often presented in a slightly diﬀerent manner . Theorem 6 . 2 Let A be a real I by J matrix . Then every vector b in R I can be written uniquely as b = Ax + w , where A T w = 0 . To derive Theorem 6 . 2 from Theorem 6 . 1 , we simply let S = { Ax | x ∈ R J } . Then S ⊥ is the set of all w such that A T w = 0 . It follows that w is the member of the null space of A T closest to b . Here are additional consequences of Proposition 6 . 4 . 74 CHAPTER 6 . CONVEX SETS Corollary 6 . 3 Let S be any subspace of R J , d a ﬁxed vector , and V the linear manifold V = S + d = { v = s + d | s ∈ S } , obtained by translating the members of S by the vector d . Then , for every x in R J and every v in V , we have (cid:104) P V x − x , v − P V x (cid:105) = 0 . ( 6 . 30 ) Proof : Since v and P V x are in V , they have the form v = s + d , and P V x = ˆ s + d , for some s and ˆ s in S . Then v − P V x = s − ˆ s . Corollary 6 . 4 Let H be the hyperplane H ( a , γ ) . Then , for every x , and every h in H , we have (cid:104) P H x − x , h − P H x (cid:105) = 0 . ( 6 . 31 ) Corollary 6 . 5 Let S be a subspace of R J . Then ( S ⊥ ) ⊥ = S . Proof : Every x in R J has the form x = s + u , with s in S and u in S ⊥ . Suppose x is in ( S ⊥ ) ⊥ . Then u = 0 . 6 . 6 Linear and Aﬃne Operators on R J If A is a J by J real matrix , then we can deﬁne an operator T by setting Tx = Ax , for each x in R J ; here Ax denotes the multiplication of the matrix A and the column vector x . Deﬁnition 6 . 26 An operator T is said to be a linear operator if T ( αx + βy ) = αTx + βTy , ( 6 . 32 ) for each pair of vectors x and y and each pair of scalars α and β . Any operator T that comes from matrix multiplication , that is , for which Tx = Ax , is linear . Lemma 6 . 3 For H = H ( a , γ ) , H 0 = H ( a , 0 ) , and any x and y in R J , we have P H ( x + y ) = P H x + P H y − P H 0 , ( 6 . 33 ) so that P H 0 ( x + y ) = P H 0 x + P H 0 y , ( 6 . 34 ) that is , the operator P H 0 is an additive operator . In addition , P H 0 ( αx ) = αP H 0 x , ( 6 . 35 ) so that P H 0 is a linear operator . 6 . 7 . THE FUNDAMENTAL THEOREMS 75 Deﬁnition 6 . 27 If A is a J by J real matrix and d is a ﬁxed nonzero vector in R J , the operator deﬁned by Tx = Ax + d is an aﬃne linear operator . Lemma 6 . 4 For any hyperplane H = H ( a , γ ) and H 0 = H ( a , 0 ) , P H x = P H 0 x + P H 0 , ( 6 . 36 ) so P H is an aﬃne linear operator . Lemma 6 . 5 For i = 1 , . . . , I let H i be the hyperplane H i = H ( a i , γ i ) , H i 0 = H ( a i , 0 ) , and P i and P i 0 the orthogonal projections onto H i and H i 0 , respectively . Let T be the operator T = P I P I − 1 · · · P 2 P 1 . Then Tx = Bx + d , for some square matrix B and vector d ; that is , T is an aﬃne linear operator . 6 . 7 The Fundamental Theorems The Separation Theorem and the Support Theorem provide the foundation for the geometric approach to the calculus of functions of several variables . A real - valued function f ( x ) deﬁned for real x has a derivative at x = x 0 if and only if there is a unique line through the point ( x 0 , f ( x 0 ) ) tangent to the graph of f ( x ) at that point . If f ( x ) is not diﬀerentiable at x 0 , there may be more than one such tangent line , as happens with the function f ( x ) = | x | at x 0 = 0 . For functions of several variables the geometric view of diﬀerentiation involves tangent hyperplanes . 6 . 7 . 1 Basic Deﬁnitions It is convenient for us to consider functions on R J whose values may be inﬁnite . For example , we deﬁne the indicator function of a set C ⊆ R J to have the value zero for x in C , and the value + ∞ for x outside the set C . Deﬁnition 6 . 28 A function f : R J → [ −∞ , ∞ ] is proper if there is no x for which f ( x ) = −∞ and some x for which f ( x ) < + ∞ . All the functions we shall consider in this text will be proper . Deﬁnition 6 . 29 Let f be a proper function deﬁned on R J . The subset of R J + 1 deﬁned by epi ( f ) = { ( x , γ ) | f ( x ) ≤ γ } is the epi - graph of f . Then we say that f is convex if its epi - graph is a convex set . Alternative deﬁnitions of convex function are presented in the exercises . 76 CHAPTER 6 . CONVEX SETS Deﬁnition 6 . 30 The eﬀective domain of a proper function f : R J → ( −∞ , ∞ ] is the set dom f = { x | f ( x ) < + ∞ } . It is also the projection onto R J of its epi - graph . It is easily shown that he eﬀective domain of a convex function is a convex set . The important role played by hyperplanes tangent to the epigraph of f motivates our study of the relationship between hyperplanes and convex sets . 6 . 7 . 2 The Separation Theorem The Separation Theorem , sometimes called the Geometric Hahn - Banach Theorem , is an easy consequence of the existence of orthogonal projections onto closed convex sets . Theorem 6 . 3 ( The Separation Theorem ) Let C be a closed nonempty convex set in R J and x a point not in C . Then there is non - zero vector a in R J and real number α such that (cid:104) a , c (cid:105) ≤ α < (cid:104) a , x (cid:105) , for every c in C . Proof : Let z = P C x , a = x − z , and α = (cid:104) a , z (cid:105) . Then using Proposition 6 . 4 , we have (cid:104)− a , c − z (cid:105) ≥ 0 , or , equivalently , (cid:104) a , c (cid:105) ≤ (cid:104) a , z (cid:105) = α , for all c in C . But , we also have (cid:104) a , x (cid:105) = (cid:104) a , x − z (cid:105) + (cid:104) a , z (cid:105) = | | x − z | | 22 + α > α . This completes the proof . 6 . 7 . 3 The Support Theorem The Separation Theorem concerns a closed convex set C and a point x outside the set C , and asserts the existence of a hyperplane separating the two . Now we concerned with a point z on the boundary of a convex set C , such as a point ( b , f ( b ) ) on the boundary of the epigraph of f . The Support Theorem asserts the existence of a hyperplane through such a point z , having the convex set entirely contained in one of its half - spaces . If we knew a priori that the point z is P C x for some x outside 6 . 7 . THE FUNDAMENTAL THEOREMS 77 C , then we could simply take the vector a = x − z as the normal to the desired hyperplane . The essence of the Support Theorem is to provide such a normal vector without assuming that z = P C x . For the proofs that follow we shall need the following deﬁnitions . Deﬁnition 6 . 31 For subsets A and B of R J , and scalar γ , let the set A + B consist of all vectors v of the form v = a + b , and γA consist of all vectors w of the form w = γa , for some a in A and b in B . Let x be a ﬁxed member of R J . Then the set x + A is the set of all vectors y such that y = x + a , for some a in A . Lemma 6 . 6 Let B be the unit ball in R J , that is , B is the set of all vectors u with | | u | | 2 ≤ 1 . Let S be an arbitrary subset of R J . Then x is in the interior of S if and only if there is some (cid:15) > 0 such that x + (cid:15)B ⊆ S , and y is in the closure of S if and only if , for every (cid:15) > 0 , the set y + (cid:15)B has nonempty intersection with S . We begin with the Accessibility Lemma . Note that the relative interior of any non - empty convex set is always non - empty ( see [ 181 ] , Theorem 6 . 2 ) . Lemma 6 . 7 ( The Accessibility Lemma ) Let C be a convex set . Let x be in the relative interior of C and y in the closure of C . Then , for all scalars α in the interval [ 0 , 1 ) , the point ( 1 − α ) x + αy is in the relative interior of C . Proof : If the dimension of C is less than J , we can transform the problem into a space of smaller dimension . Therefore , without loss of generality , we can assume that the dimension of C is J , its aﬃne hull is all of R J , and its relative interior is its interior . Let α be ﬁxed , and B = { z | | | z | | 2 ≤ 1 } . We have to show that there is some (cid:15) > 0 such that the set ( 1 − α ) x + αy + (cid:15)B is a subset of the set C . We know that y is in the set C + (cid:15)B for every (cid:15) > 0 , since y is in the closure of C . Therefore , for all (cid:15) > 0 we have ( 1 − α ) x + αy + (cid:15)B ⊆ ( 1 − α ) x + α ( C + (cid:15)B ) + (cid:15)B = ( 1 − α ) x + ( 1 + α ) (cid:15)B + αC = ( 1 − α ) [ x + (cid:15) ( 1 + α ) ( 1 − α ) − 1 B ] + αC . Since x is in the interior of the set C , we know that [ x + (cid:15) ( 1 + α ) ( 1 − α ) − 1 B ] ⊆ C , for (cid:15) small enough . This completes the proof . Now we come to the Support Theorem . Theorem 6 . 4 ( Support Theorem ) Let C be convex , and let z be on the boundary of C . Then there is a non - zero vector a in R J with (cid:104) a , z (cid:105) ≥ (cid:104) a , c (cid:105) , for all c in C . 78 CHAPTER 6 . CONVEX SETS Proof : If the dimension of C is less than J , then every point of C is on the boundary of C . Let the aﬃne hull of C be M = S + b . Then the set C − b is contained in the subspace S , which , in turn , can be contained in a hyperplane through the origin , H ( a , 0 ) . Then (cid:104) a , c (cid:105) = (cid:104) a , b (cid:105) , for all c in C . So we focus on the case in which the dimension of C is J , in which case the interior of C must be non - empty . Let y be in the interior of C , and , for each t > 1 , let z t = y + t ( z − y ) . Note that z t is not in the closure of C , for any t > 1 , by the Accessibility Lemma , since z is not in the interior of C . By the Separation Theorem , there are vectors b t such that (cid:104) b t , c (cid:105) < (cid:104) b t , z t (cid:105) , for all c in C . For convenience , we assume that | | b t | | 2 = 1 , and that { t k } is a sequence with t k > 1 and { t k } → 1 , as k → ∞ . Let a k = b t k . Then there is a subsequence of the { a k } converging to some a , with | | a | | 2 = 1 , and (cid:104) a , c (cid:105) ≤ (cid:104) a , z (cid:105) , for all c in C . This completes the proof . If we knew that there was a vector x not in C , such that z = P C x , then we could choose a = x − z , as in the proof of the Separation Theorem . The point of the Support Theorem is that we cannot assume , a priori , that there is such an x . Once we have the vector a , however , any point x = z + λa , for λ ≥ 0 , has the property that z = P C x . 6 . 8 Theorems of the Alternative In linear algebra the emphasis is on systems of linear equations ; little time , if any , is spent on systems of linear inequalities . But linear inequalities are important in optimization . In this section we consider some of the basic theorems regarding linear inequalities . These theorems all ﬁt a certain pattern , known as a Theorem of the Alternative . These theorems assert that precisely one of two problems will have a solution . The proof of the ﬁrst theorem illustrates how we should go about proving such theorems . Theorem 6 . 5 ( Gale I ) [ 115 ] Precisely one of the following is true : • ( 1 ) there is x such that Ax = b ; • ( 2 ) there is y such that A T y = 0 and b T y = 1 . 6 . 8 . THEOREMS OF THE ALTERNATIVE 79 Proof : First , we show that it is not possible for both to be true at the same time . Suppose that Ax = b and A T y = 0 . Then b T y = x T A T y = 0 , so that we cannot have b T y = 1 . By Theorem 6 . 1 , the fundamental decomposition theorem from linear algebra , we know that , for any b , there are unique Ax and w with A T w = 0 such that b = Ax + w . Clearly , b = Ax if and only if w = 0 . Also , b T y = w T y . Therefore , if alternative ( 1 ) does not hold , we must have w non - zero , in which case A T y = 0 and b T y = 1 , for y = w / | | w | | 22 , so alternative ( 2 ) holds . In this section we consider several other theorems of this type . Perhaps the most well known of these theorems of the alternative is Farkas’ Lemma : Theorem 6 . 6 ( Farkas’ Lemma ) [ 110 ] Precisely one of the following is true : • ( 1 ) there is x ≥ 0 such that Ax = b ; • ( 2 ) there is y such that A T y ≥ 0 and b T y < 0 . Proof : We can restate the lemma as follows : there is a vector y with A T y ≥ 0 and b T y < 0 if and only if b is not a member of the convex set C = { Ax | x ≥ 0 } . If b is not in C , which is closed and convex , then , by the Separation Theorem , there is a non - zero vector a and real α with a T b < α ≤ a T Ax = ( A T a ) T x , for all x ≥ 0 . Since ( A T a ) T x is bounded below , as x runs over all non - negative vectors , it follows that A T a ≥ 0 . Choosing x = 0 , we have α ≤ 0 . Then let y = a . Conversely , if Ax = b does have a non - negative solution x , then A T y ≥ 0 implies that y T Ax = y T b ≥ 0 . The next theorem can be obtained from Farkas’ Lemma . Theorem 6 . 7 ( Gale II ) [ 115 ] Precisely one of the following is true : • ( 1 ) there is x such that Ax ≤ b ; • ( 2 ) there is y ≥ 0 such that A T y = 0 and b T y < 0 . Proof : First , if both are true , then 0 ≤ y T ( b − Ax ) = y T b − 0 = y T b , which is a contradiction . Now assume that ( 2 ) does not hold . Therefore , for every y ≥ 0 with A T y = 0 , we have b T y ≥ 0 . Let B = [ A b ] . Then the system B T y = [ 0 − 1 ] T has no non - negative solution . Applying Farkas’ Lemma , we ﬁnd that there is a vector w = [ z γ ] T with Bw ≥ 0 and [ 0 − 1 ] w < 0 . So , Az + γb ≥ 0 and γ > 0 . Let x = − 1 γ z to get Ax ≤ b , so that ( 1 ) holds . Theorem 6 . 8 ( Gordan ) [ 120 ] Precisely one of the following is true : 80 CHAPTER 6 . CONVEX SETS • ( 1 ) there is x such that Ax < 0 ; • ( 2 ) there is y ≥ 0 , y (cid:54) = 0 , such that A T y = 0 . Proof : First , if both are true , then 0 < − y T Ax = 0 , which cannot be true . Now assume that there is no non - zero y ≥ 0 with A T y = 0 . Then , with e = ( 1 , 1 , . . . , 1 ) T , C = [ A e ] , and d = ( 0 , 0 , . . . , 0 , 1 ) T , there is no non - negative solution of C T y = d . From Farkas’ Lemma we then know that there is a vector z = [ u T γ ] T , with Cz = Au + γe ≥ 0 , and d T z < 0 . Then Ax < 0 for x = − u . Here are several more theorems of the alternative . Theorem 6 . 9 ( Stiemke I ) [ 193 ] Precisely one of the following is true : • ( 1 ) there is x such that Ax ≤ 0 and Ax (cid:54) = 0 ; • ( 2 ) there is y > 0 such that A T y = 0 . Theorem 6 . 10 ( Stiemke II ) [ 193 ] Let c be a ﬁxed non - zero vector . Pre - cisely one of the following is true : • ( 1 ) there is x such that Ax ≤ 0 and c T x ≥ 0 and not both Ax = 0 and c T x = 0 ; • ( 2 ) there is y > 0 such that A T y = c . In the chapter on Linear Programming we shall encounter David Gale’s Strong Duality Theorem . His proof of that theorem will depend heavily on the following theorem of the alternative . Theorem 6 . 11 ( Gale III ) [ 115 ] Let b be a ﬁxed non - zero vector . Pre - cisely one of the following is true : • ( 1 ) there is x ≥ 0 such that Ax ≤ b ; • ( 2 ) there is y ≥ 0 such that A T y ≥ 0 and b T y < 0 . Proof : First , note that we cannot have both true at the same time , because b T y < 0 , y ≥ 0 , and Ax ≤ b would imply that x T A T y = x · A T y < 0 , which is a contradiction . Now suppose that ( 1 ) does not hold . Then there is no w = (cid:20) x u (cid:21) ≥ 0 such that [ A I ] w = b . By Farkas’ Lemma ( Theorem 6 . 6 ) , it follows that there is y with (cid:20) A T I (cid:21) y ≥ 0 , and b T y < 0 . Therefore , A T y ≥ 0 , Iy = y ≥ 0 , and b T y < 0 ; therefore , ( 2 ) holds . 6 . 8 . THEOREMS OF THE ALTERNATIVE 81 Theorem 6 . 12 ( Von Neumann ) [ 166 ] Precisely one of the following is true : • ( 1 ) there is x ≥ 0 such that Ax > 0 ; • ( 2 ) there is y ≥ 0 , y (cid:54) = 0 , such that A T y ≤ 0 . Proof : If both were true , then we would have 0 < ( Ax ) T y = x T ( A T y ) , so that A T y ≤ 0 would be false . Now suppose that ( 2 ) does not hold . Then there is no y ≥ 0 , y (cid:54) = 0 , with A T y ≤ 0 . Consequently , there is no y ≥ 0 , y (cid:54) = 0 , such that (cid:20) A T − u T (cid:21) y = (cid:20) A T y − u T y (cid:21) ≤ (cid:20) 0 − 1 (cid:21) , where u T = ( 1 , 1 , . . . , 1 ) . By Theorem 6 . 11 , there is z = (cid:20) xα (cid:21) ≥ 0 , such that [ A − u ] z = [ A − u ] (cid:20) xα (cid:21) ≥ 0 , and [ 0 T − 1 ] z = [ 0 T − 1 ] (cid:20) xα (cid:21) = − α < 0 . Therefore , α > 0 and ( Ax ) i − α ≥ 0 for each i , and so Ax > 0 and ( 1 ) holds . Theorem 6 . 13 ( Tucker ) [ 196 ] Precisely one of the following is true : • ( 1 ) there is x ≥ 0 such that Ax ≥ 0 , Ax (cid:54) = 0 ; • ( 2 ) there is y > 0 such that A T y ≤ 0 . Theorem 6 . 14 ( Theorem 21 . 1 , [ 181 ] ) Let C be a convex set , and let f 1 , . . . , f m be proper convex functions , with ri ( C ) ⊆ dom ( f i ) , for each i . Precisely one of the following is true : • ( 1 ) there is x ∈ C such that f i ( x ) < 0 , for i = 1 , . . . , m ; • ( 2 ) there are λ i ≥ 0 , not all equal to zero , such that λ 1 f 1 ( x ) + . . . + λ m f m ( x ) ≥ 0 , for all x in C . 82 CHAPTER 6 . CONVEX SETS Theorem 6 . 14 is fundamental in proving Helly’s Theorem : Theorem 6 . 15 ( Helly’s Theorem ) [ 181 ] Let { C i | i = 1 , . . . , I } be a ﬁ - nite collection of ( not necessarily closed ) convex sets in R N . If every sub - collection of N + 1 or fewer sets has non - empty intersection , then the entire collection has non - empty intersection . For instance , in the two - dimensional plane , if a ﬁnite collection of lines is such that every three have a common point of intersection , then they all have a common point of intersection . There is another version of Helly’s Theorem that applies to convex inequalities . Theorem 6 . 16 Let there be given a system of the form f 1 ( x ) < 0 , . . . , f k ( x ) < 0 , f k + 1 ( x ) ≤ 0 , . . . , f m ( x ) ≤ 0 , where the f i are convex functions on R J , and the inequalities may be all strict or all weak . If every subsystem of J + 1 or fewer inequalities has a solution in a given convex set C , then the entire system has a solution in C . 6 . 9 Another Proof of Farkas’ Lemma In the previous section , we proved Farkas’ Lemma , Theorem 6 . 6 , using the Separation Theorem , the proof of which , in turn , depended here on the existence of the orthogonal projection onto any closed convex set . It is possible to prove Farkas’ Lemma directly , along the lines of Gale [ 115 ] . Suppose that Ax = b has no non - negative solution . If , indeed , it has no solution whatsoever , then b = Ax + w , where w (cid:54) = 0 and A T w = 0 . Then we take y = − w / | | w | | 22 . So suppose that Ax = b does have solutions , but not any non - negative ones . The approach is to use induction on the number of columns of the matrix involved in the lemma . If A has only one column , denoted a 1 , then Ax = b can be written as x 1 a 1 = b . Assuming that there are no non - negative solutions , it must follow that x 1 < 0 . We take y = − b . Then b T y = − b T b = − | | b | | 22 < 0 , while A T y = ( a 1 ) T ( − b ) = − 1 x 1 b T b > 0 . Now assume that the lemma holds whenever the involved matrix has no more than m − 1 columns . We show the same is true for m columns . 6 . 9 . ANOTHER PROOF OF FARKAS’ LEMMA 83 If there is no non - negative solution of the system Ax = b , then clearly there are no non - negative real numbers x 1 , x 2 , . . . , x m − 1 such that x 1 a 1 + x 2 a 2 + . . . + x m − 1 a m − 1 = b , where a j denotes the j th column of the matrix A . By the induction hy - pothesis , there must be a vector v with ( a j ) T v ≥ 0 , for j = 1 , . . . , m − 1 , and b T v < 0 . If it happens that ( a m ) T v ≥ 0 also , then we are done . If , on the other hand , we have ( a m ) T v < 0 , then let c j = ( a j ) T a m − ( a m ) T a j , j = 1 , . . . , m − 1 , and d = ( b T v ) a m − ( ( a m ) T v ) b . Then there are no non - negative real numbers z 1 , . . . , z m − 1 such that z 1 c 1 + z 2 c 2 + . . . + z m − 1 c m − 1 = d , ( 6 . 37 ) since , otherwise , it would follow from simple calculations that − 1 ( a m ) T v (cid:16) [ m − 1 (cid:88) j = 1 z j ( ( a j ) T v ) ] − b T v (cid:17) a m − m − 1 (cid:88) j = 1 z j ( ( a m ) T v ) a j = b . Close inspection of this shows all the coeﬃcients to be non - negative , which implies that the system Ax = b has a non - negative solution , contrary to our assumption . It follows , therefore , that there can be no non - negative solution to the system in Equation ( 6 . 37 ) . By the induction hypothesis , it follows that there is a vector u such that ( c j ) T u ≥ 0 , j = 1 , . . . , m − 1 , and d T u < 0 . Now let y = ( ( a m ) T u ) v − ( ( a m ) T v ) u . We can easily verify that ( a j ) T y = ( c j ) T u ≥ 0 , j = 1 , . . . , m − 1 , b T y = d T u < 0 , and ( a m ) T y = 0 , 84 CHAPTER 6 . CONVEX SETS so that A T y ≥ 0 , and b T y < 0 . This completes the proof . 6 . 10 Gordan’s Theorem 6 . 8 Revisited In their text [ 23 ] , Borwein and Lewis give the following version of Gordan’s Theorem 6 . 8 . Theorem 6 . 17 For any vectors a 0 , a 1 , . . . , a m in R J , exactly one of the following systems has a solution : m (cid:88) i = 0 λ i a i = 0 , m (cid:88) i = 0 λ i = 1 , 0 ≤ λ 0 , λ 1 , . . . , λ m ; ( 6 . 38 ) or there is some x for which x T a i < 0 , for i = 0 , 1 , . . . , m . ( 6 . 39 ) Rather than prove this result using the theory of convex sets and sep - aration , as we did previously , they take the following approach . Let f ( x ) = log (cid:16) m (cid:88) i = 0 exp ( x T a i ) (cid:17) . We then have the following theorem . Theorem 6 . 18 The following statements are equivalent : • 1 ) . The function f ( x ) is bounded below . • 2 ) . System ( 6 . 38 ) is solvable . • 3 ) . System ( 6 . 39 ) is unsolvable . Proof : Showing that 2 ) implies 3 ) is easy . To show that 3 ) implies 1 ) , note that if f ( x ) is not bounded below , then there is some x with f ( x ) ≤ 0 , which forces x T a i < 0 , for all i . Finally , to show that 1 ) implies 2 ) , we use Proposition 5 . 1 . Then there is a sequence { x n } with (cid:107)∇ f ( x n ) (cid:107) 2 ≤ 1 n , for each n . Since ∇ f ( x n ) = m (cid:88) i = 0 λ ni a i , 6 . 11 . EXERCISES 85 for λ ni = exp ( ( x n ) T a i ) / m (cid:88) i = 0 exp ( ( x n ) T a i ) , it follows that (cid:107) m (cid:88) i = 0 λ ni a i (cid:107) 2 < 1 n , for each n . The sequence { λ n } is bounded , so there is a convergent subse - quence , converging to some λ ∗ for which (cid:80) mi = 0 λ ∗ i a i = 0 . 6 . 11 Exercises Ex . 6 . 1 Let C ⊆ R J , and let x n , n = 1 , . . . , N be members of C . For n = 1 , . . . , N , let α n > 0 , with α 1 + . . . + α N = 1 . Show that , if C is convex , then the convex combination α 1 x 1 + α 2 x 2 + . . . + α N x N is in C . Ex . 6 . 2 Prove Proposition 6 . 2 . Hint : show that the set C is convex . Ex . 6 . 3 Show that the subset of R J consisting of all vectors x with | | x | | 2 = 1 is not convex . Ex . 6 . 4 Let (cid:107) x (cid:107) 2 = (cid:107) y (cid:107) 2 = 1 and z = 12 ( x + y ) in R J . Show that (cid:107) z (cid:107) 2 < 1 unless x = y . Show that this conclusion does not hold if the two - norm (cid:107)·(cid:107) 2 is replaced by the one - norm , deﬁned by (cid:107) x (cid:107) 1 = J (cid:88) j = 1 | x j | . Ex . 6 . 5 Let C be the set of all vectors x in R J with (cid:107) x (cid:107) 2 ≤ 1 . Let K be a subset of C obtained by removing from C any number of its members for which (cid:107) x (cid:107) 2 = 1 . Show that K is convex . Consequently , every x in C with (cid:107) x (cid:107) 2 = 1 is an extreme point of C . Ex . 6 . 6 Prove that every subspace of R J is convex , and every linear man - ifold is convex . Ex . 6 . 7 Prove that every hyperplane H ( a , γ ) is a linear manifold . Ex . 6 . 8 Prove Lemma 6 . 1 . 86 CHAPTER 6 . CONVEX SETS Ex . 6 . 9 Let A and B be nonempty , closed convex subsets of R J . Deﬁne the set B − A to be all x in R J such that x = b − a for some a ∈ A and b ∈ B . Show that B − A is closed if one of the two sets is bounded . Find an example of two disjoint unbounded closed convex sets in R 2 that get arbitrarily close to each other . Show that , for this example , B − A is not closed . Ex . 6 . 10 ( a ) Let C be a circular region in R 2 . Determine the normal cone for a point on its circumference . ( b ) Let C be a rectangular region in R 2 . Determine the normal cone for a point on its boundary . Ex . 6 . 11 Prove Lemmas 6 . 3 , 6 . 4 and 6 . 5 . Ex . 6 . 12 Let C be a convex set and f : C ⊆ R J → ( −∞ , ∞ ] . Prove that f ( x ) is a convex function , according to Deﬁnition 6 . 29 , if and only if , for all x and y in C , and for all 0 < α < 1 , we have f ( αx + ( 1 − α ) y ) ≤ αf ( x ) + ( 1 − α ) f ( y ) . Ex . 6 . 13 Let f : R J → [ −∞ , ∞ ] . Prove that f ( x ) is a convex function if and only if , for all 0 < α < 1 , we have f ( αx + ( 1 − α ) y ) < αb + ( 1 − α ) c , whenever f ( x ) < b and f ( y ) < c . Ex . 6 . 14 Show that the vector a is orthogonal to the hyperplane H = H ( a , γ ) ; that is , if u and v are in H , then a is orthogonal to u − v . Ex . 6 . 15 Given a point s in a convex set C , where are the points x for which s = P C x ? Ex . 6 . 16 Show that it is possible to have a vector z ∈ R J such that (cid:104) z − x , c − z (cid:105) ≥ 0 for all c ∈ C , but z is not P C x . Ex . 6 . 17 Let z and a be as in the Support Theorem , let γ > 0 , and let x = z + γa . Show that z = P C x . Ex . 6 . 18 Let C be a closed , non - empty convex set in R J and x not in C . Show that the distance from x to C is equal to the maximum of the distances from x to any hyperplane that separates x from C . Hint : draw a picture . Ex . 6 . 19 Let C be a closed non - empty convex set in R J , x a vector not in C , and d > 0 the distance from x to C . Let σ C ( a ) = sup c ∈ C (cid:104) a , c (cid:105) , 6 . 11 . EXERCISES 87 the support function of C . Show that d = max | | a | | ≤ 1 { (cid:104) a , x (cid:105) − σ C ( a ) } . The point here is to turn a minimization problem into one involving only maximization . Try drawing a picture and using Lemma 6 . 1 . Hints : Con - sider the unit vector 1 d ( x − P C x ) , and use Cauchy’s Inequality and Propo - sition 6 . 4 . Remember that P C x is in C , so that (cid:104) a , P C x (cid:105) ≤ σ C ( a ) . Remark : If , in the deﬁnition of the support function , we take the vectors a to be unit vectors , with a = ( cos θ , sin θ ) , for 0 ≤ θ < 2 π , then we can deﬁne the function f ( θ ) = sup ( x , y ) ∈ C x cos θ + y sin θ . In [ 154 ] Tom Marzetta considers this function , as well as related functions of θ , such as the radius of curvature function , and establishes relationships between the behavior of these functions and the convex set itself . Ex . 6 . 20 ( R˚adstr¨om Cancellation [ 23 ] ) • ( a ) Show that , for any subset S of R N , we have 2 S ⊆ S + S , and 2 S = S + S if S is convex . • ( b ) Find three ﬁnite subsets of R , say A , B , and C , with A not contained in B , but with the property that A + C ⊆ B + C . Hint : try to ﬁnd an example where the set C is C = { − 1 , 0 , 1 } . • ( c ) Show that , if A and B are convex in R N , B is closed , and C is bounded in R N , then A + C ⊆ B + C implies that A ⊆ B . Hint : Note that , under these assumptions , 2 A + C = A + ( A + C ) ⊆ 2 B + C . Ex . 6 . 21 [ 10 ] Let A and B be non - empty closed convex subsets of R N . For each a ∈ A deﬁne d ( a , B ) = inf b ∈ B (cid:107) a − b (cid:107) 2 , and then deﬁne d ( A , B ) = inf a ∈ A d ( a , B ) . Let E = { a ∈ A | d ( a , B ) = d ( A , B ) } , 88 CHAPTER 6 . CONVEX SETS and F = { b ∈ B | d ( b , A ) = d ( B , A ) } ; assume that both E and F are not empty . The displacement vector is v = P K ( 0 ) , where K is the closure of the set B − A . For any transformation T : R N → R N , denote by Fix ( T ) the set of all x ∈ R N such that Tx = x . Prove the following : • ( a ) (cid:107) v (cid:107) 2 = d ( A , B ) ; • ( b ) E + v = F ; • ( c ) E = Fix ( P A P B ) = A ∩ ( B − v ) ; • ( d ) F = Fix ( P B P A ) = B ∩ ( A + v ) ; • ( e ) P B e = P F e = e + v , for all e ∈ E ; • ( f ) P A f = P E f = f − v , for all f ∈ F . 6 . 12 Course Homework Try all the exercises in this chapter . Chapter 7 Matrices 7 . 1 Chapter Summary In preparation for our discussion of linear programming , we present a brief review of the fundamentals of matrix theory . 7 . 2 Vector Spaces Linear algebra is the study of vector spaces and linear transformations . It is not simply the study of matrices , although matrix theory takes up most of linear algebra . It is common in mathematics to consider abstraction , which is simply a means of talking about more than one thing at the same time . A vector space V is an abstract algebraic structure deﬁned using axioms . There are many examples of vector spaces , such as the sets of real or complex numbers themselves , the set of all polynomials , the set of row or column vectors of a given dimension , the set of all inﬁnite sequences of real or complex numbers , the set of all matrices of a given size , and so on . The beauty of an abstract approach is that we can talk about all of these , and much more , all at once , without being speciﬁc about which example we mean . A vector space is a set whose members are called vectors , on which there are two algebraic operations , called scalar multiplication and vector addition . As in any axiomatic approach , these notions are intentionally abstract . A vector is deﬁned to be a member of a vector space , nothing more . Scalars are a bit more concrete , in that scalars are almost always real or complex numbers , although sometimes , but not in this book , they are members of an unspeciﬁed ﬁnite ﬁeld . The operations themselves are not explicitly deﬁned , except to say that they behave according to certain 89 90 CHAPTER 7 . MATRICES axioms , such as associativity and distributivity . If v is a member of a vector space V and α is a scalar , then we denote by αv the scalar multiplication of v by α . If w is also a member of V , then we denote by v + w the vector addition of v and w . The following properties serve to deﬁne a vector space , with u , v , and w denoting arbitrary members of V and α and β arbitrary scalars : • 1 . v + w = w + v ; • 2 . u + ( v + w ) = ( u + v ) + w ; • 3 . there is a unique “zero vector” , denoted 0 , such that v + 0 = v ; • 4 . for each v there is a unique vector − v such that v + ( − v ) = 0 ; • 5 . 1 v = v , for all v ; • 6 . ( αβ ) v = α ( βv ) ; • 7 . α ( v + w ) = αv + αw ; • 8 . ( α + β ) v = αv + βv . If u 1 , . . . , u N are members of V and c 1 , . . . , c N are scalars , then the vector x = c 1 u 1 + c 2 u 2 + . . . + c N u N is called a linear combination of the vectors u 1 , . . . , u N , with coeﬃcients c 1 , . . . , c N . If W is a subset of a vector space V , then W is called a subspace of V if W is also a vector space for the same operations . What this means is simply that when we perform scalar multiplication on a vector in W , or when we add vectors in W , we always get members of W back again . Another way to say this is that W is closed to linear combinations . When we speak of subspaces of V we do not mean to exclude the case of W = V . Note that V is itself a subspace , but not a proper subspace , of V . Every subspace must contain the zero vector , 0 ; the smallest subspace of V is the subspace containing only the zero vector , W = { 0 } . In the vector space V = R 2 , the subset of all vectors whose entries sum to zero is a subspace , but the subset of all vectors whose entries sum to one is not a subspace . We often refer to things like [ 1 2 0 ] as vectors , although they are but one example of a certain type of vector . For clarity , in this book we shall call such an object a real row vector of dimension three or a real row three - vector . Similarly , we shall call   3 i − 1 2 + i 6   a complex column vector of dimension four 7 . 3 . BASIC LINEAR ALGEBRA 91 or a complex column four - vector . For notational convenience , whenever we refer to something like a real three - vector or a complex four - vector , we shall always mean that they are columns , rather than rows . The space of real ( column ) N - vectors will be denoted R N , while the space of complex ( column ) N vectors is C N . Shortly after beginning a discussion of vector spaces , we arrive at the notion of the size or dimension of the vector space . A vector space can be ﬁnite dimensional or inﬁnite dimensional . The spaces R N and C N have dimension N ; not a big surprise . The vector spaces of all inﬁnite sequences of real or complex numbers are inﬁnite dimensional , as is the vector space of all real or complex polynomials . If we choose to go down the path of ﬁnite dimensionality , we very quickly ﬁnd ourselves talking about matrices . If we go down the path of inﬁnite dimensionality , we quickly begin to discuss convergence of inﬁnite sequences and sums , and ﬁnd that we need to introduce norms , which takes us into functional analysis and the study of Hilbert and Banach spaces . In this course we shall consider only the ﬁnite dimensional vector spaces , which means that we shall be talking mainly about matrices . 7 . 3 Basic Linear Algebra In this section we discuss bases and dimension , systems of linear equations , Gaussian elimination , and the notions of basic and non - basic variables . 7 . 3 . 1 Bases and Dimension The notions of a basis and of linear independence are fundamental in linear algebra . Let V be a vector space . Deﬁnition 7 . 1 A collection of vectors { u 1 , . . . , u N } in V is linearly inde - pendent if there is no choice of scalars α 1 , . . . , α N , not all zero , such that 0 = α 1 u 1 + . . . + α N u N . ( 7 . 1 ) Deﬁnition 7 . 2 The span of a collection of vectors { u 1 , . . . , u N } in V is the set of all vectors x that can be written as linear combinations of the u n ; that is , for which there are scalars c 1 , . . . , c N , such that x = c 1 u 1 + . . . + c N u N . ( 7 . 2 ) Deﬁnition 7 . 3 A collection of vectors { w 1 , . . . , w N } in V is called a span - ning set for a subspace S if the set S is their span . Deﬁnition 7 . 4 A collection of vectors { u 1 , . . . , u N } in V is called a basis for a subspace S if the collection is linearly independent and S is their span . 92 CHAPTER 7 . MATRICES Suppose that S is a subspace of V , that { w 1 , . . . , w N } is a spanning set for S , and { u 1 , . . . , u M } is a linearly independent subset of S . Beginning with w 1 , we augment the set { u 1 , . . . , u M } with w j if w j is not in the span of the u m and the w k previously included . At the end of this process , we have a linearly independent spanning set , and therefore , a basis , for S ( Why ? ) . Similarly , beginning with w 1 , we remove w j from the set { w 1 , . . . , w N } if w j is a linear combination of the w k , k = 1 , . . . , j − 1 . In this way we obtain a linearly independent set that spans S , hence another basis for S . The following lemma will allow us to prove that all bases for a subspace S have the same number of elements . Lemma 7 . 1 Let W = { w 1 , . . . , w N } be a spanning set for a subspace S in R I , and V = { v 1 , . . . , v M } a linearly independent subset of S . Then M ≤ N . Proof : Suppose that M > N . Let B 0 = { w 1 , . . . , w N } . To obtain the set B 1 , form the set C 1 = { v 1 , w 1 , . . . , w N } and remove the ﬁrst member of C 1 that is a linear combination of members of C 1 that occur to its left in the listing ; since v 1 has no members to its left , it is not removed . Since W is a spanning set , v 1 is a linear combination of the members of W , so that some member of W is a linear combination of v 1 and the members of W that precede it in the list ; remove the ﬁrst member of W for which this is true . We note that the set B 1 is a spanning set for S and has N members . Having obtained the spanning set B k , with N members and whose ﬁrst k members are v k , . . . , v 1 , we form the set C k + 1 = B k ∪ { v k + 1 } , listing the members so that the ﬁrst k + 1 of them are { v k + 1 , v k , . . . , v 1 } . To get the set B k + 1 we remove the ﬁrst member of C k + 1 that is a linear combination of the members to its left ; there must be one , since B k is a spanning set , and so v k + 1 is a linear combination of the members of B k . Since the set V is linearly independent , the member removed is from the set W . Continuing in this fashion , we obtain a sequence of spanning sets B 1 , . . . , B N , each with N members . The set B N is B N = { v 1 , . . . , v N } and v N + 1 must then be a linear combination of the members of B N , which contradicts the linear independence of V . Corollary 7 . 1 Every basis for a subspace S has the same number of ele - ments . Deﬁnition 7 . 5 The dimension of a subspace S is the number of elements in any basis . 7 . 3 . 2 The Rank of a Matrix Let A by an I by J matrix and x a J by 1 column vector . The equation Ax = b tells us that the vector b is a linear combination of the columns of 7 . 3 . BASIC LINEAR ALGEBRA 93 the matrix A , with the entries of the vector x as the coeﬃcients ; that is , b = x 1 a 1 + x 2 a 2 + . . . + x J a J , where a j denotes the j th column of A . Similarly , when we write the product C = AB , we are saying that the k th column of C is a linear combination of the columns of A , with the entries of the k th column of B as coeﬃcients . It will be helpful to keep this in mind when reading the proof of the next lemma . Lemma 7 . 2 For any matrix A , the maximum number of linearly indepen - dent rows equals the maximum number of linearly independent columns . Proof : Suppose that A is an I by J matrix , and that K ≤ J is the maximum number of linearly independent columns of A . Select K linearly independent columns of A and use them as the K columns of an I by K matrix U . Since every column of A must be a linear combination of these K selected ones , there is a K by J matrix M such that A = UM . From A T = M T U T we conclude that every column of A T is a linear combination of the K columns of the matrix M T . Therefore , there can be at most K linearly independent columns of A T . Deﬁnition 7 . 6 The rank of A is the maximum number of linearly inde - pendent rows or of linearly independent columns of A . Proposition 7 . 1 The rank of C = AB is not greater than the smaller of the rank of A and the rank of B . Proof : Every column of C is a linear combination of the columns of A , so the rank of C cannot exceed that of A . Since the rank of C † is the same as that of C , the proof is complete . Deﬁnition 7 . 7 We say that an M by N matrix A has full rank if its rank is as large as possible ; that is , the rank of A is the smaller of the two numbers M and N . Deﬁnition 7 . 8 A square matrix A is invertible if there is a matrix B such that AB = BA = I . Then B is the inverse of A and we write B = A − 1 . Proposition 7 . 2 Let A be a square matrix . If there are matrices B and C such that AB = I and CA = I , then B = C = A − 1 . Proof : From AB = I we have C = C ( AB ) = ( CA ) B = IB = B . Proposition 7 . 3 A square matrix A is invertible if and only if it has full rank . 94 CHAPTER 7 . MATRICES Proof : We leave the proof as Exercise 7 . 2 . Corollary 7 . 2 A square matrix A is invertible if and only if there is a matrix B such that AB is invertible . There are many other conditions that are equivalent to A being invertible ; we list several of these in the next subsection . 7 . 3 . 3 The “Matrix Inversion Theorem” In this subsection we bring together several of the conditions equivalent to saying that an N by N matrix A is invertible . Taken together , these conditions are sometimes called the “Matrix Inversion Theorem” . The equivalences on the list are roughly in increasing order of diﬃculty of proof . The reader is invited to supply proofs . We begin with the deﬁnition of invertibility . • 1 . We say A is invertible if there is a matrix B such that AB = BA = I . Then B = A − 1 , the inverse of A . • 2 . A is invertible if and only if there are matrices B and C such that AB = CA = I . Then B = C = A − 1 . • 3 . A is invertible if and only if the rank of A is N . • 4 . A is invertible if and only if there is a matrix B with AB = I . Then B = A − 1 . • 5 . A is invertible if and only if the columns of A are linearly inde - pendent . • 6 . A is invertible if and only if Ax = 0 implies x = 0 . • 7 . A is invertible if and only if A can be transformed by elementary row operations into an upper triangular matrix having no zero entries on its main diagonal . • 8 . A is invertible if and only if its determinant is not zero . • 9 . A is invertible if and only if A has no zero eigenvalues . 7 . 3 . 4 Systems of Linear Equations Consider the system of three linear equations in ﬁve unknowns given by x 1 + 2 x 2 + 2 x 4 + x 5 = 0 − x 1 − x 2 + x 3 + x 4 = 0 x 1 + 2 x 2 − 3 x 3 − x 4 − 2 x 5 = 0 . ( 7 . 3 ) 7 . 3 . BASIC LINEAR ALGEBRA 95 This system can be written in matrix form as Ax = 0 , with A the coeﬃcient matrix A =   1 2 0 2 1 − 1 − 1 1 1 0 1 2 − 3 − 1 − 2   , ( 7 . 4 ) and x = ( x 1 , x 2 , x 3 , x 4 , x 5 ) T . Applying Gaussian elimination to this sys - tem , we obtain a second , simpler , system with the same solutions : x 1 − 2 x 4 + x 5 = 0 x 2 + 2 x 4 = 0 x 3 + x 4 + x 5 = 0 . ( 7 . 5 ) From this simpler system we see that the variables x 4 and x 5 can be freely chosen , with the other three variables then determined by this system of equations . The variables x 4 and x 5 are then independent , the others de - pendent . The variables x 1 , x 2 and x 3 are then called basic variables . To obtain a basis of solutions we can let x 4 = 1 and x 5 = 0 , obtaining the solution x = ( 2 , − 2 , − 1 , 1 , 0 ) T , and then choose x 4 = 0 and x 5 = 1 to get the solution x = ( − 1 , 0 , − 1 , 0 , 1 ) T . Every solution to Ax = 0 is then a linear combination of these two solutions . Notice that which variables are basic and which are non - basic is somewhat arbitrary , in that we could have chosen as the non - basic variables any two whose columns are independent . Having decided that x 4 and x 5 are the non - basic variables , we can write the original matrix A as A = [ B N ] , where B is the square invertible matrix B =   1 2 0 − 1 − 1 1 1 2 − 3   , ( 7 . 6 ) and N is the matrix N =   2 1 1 0 − 1 − 2   . ( 7 . 7 ) With x B = ( x 1 , x 2 , x 3 ) T and x N = ( x 4 , x 5 ) T we can write Ax = Bx B + Nx N = 0 , ( 7 . 8 ) so that x B = − B − 1 Nx N . ( 7 . 9 ) 96 CHAPTER 7 . MATRICES 7 . 3 . 5 Real and Complex Systems of Linear Equations A system Ax = b of linear equations is called a complex system , or a real system if the entries of A , x and b are complex , or real , respectively . For any matrix A , we denote by A T and A † the transpose and conjugate transpose of A , respectively . Any complex system can be converted to a real system in the following way . A complex matrix A can be written as A = A 1 + iA 2 , where A 1 and A 2 are real matrices and i = √− 1 . Similarly , x = x 1 + ix 2 and b = b 1 + ib 2 , where x 1 , x 2 , b 1 and b 2 are real vectors . Denote by ˜ A the real matrix ˜ A = (cid:20) A 1 − A 2 A 2 A 1 (cid:21) , ( 7 . 10 ) by ˜ x the real vector ˜ x = (cid:20) x 1 x 2 (cid:21) , ( 7 . 11 ) and by ˜ b the real vector ˜ b = (cid:20) b 1 b 2 (cid:21) . ( 7 . 12 ) Then x satisﬁes the system Ax = b if and only if ˜ x satisﬁes the system ˜ A ˜ x = ˜ b . The matrices ˜ A , ˜ x and ˜ b are in block - matrix form , meaning that the entries of these matrices are described in terms of smaller matrices . This is a convenient shorthand that we shall use repeatedly in this text . When we write ˜ A ˜ x = ˜ b , we mean A 1 x 1 − A 2 x 2 = b 1 , and A 2 x 1 + A 1 x 2 = b 2 . Deﬁnition 7 . 9 A square matrix A is symmetric if A T = A and Hermitian if A † = A . Deﬁnition 7 . 10 A non - zero vector x is said to be an eigenvector of the square matrix A if there is a scalar λ such that Ax = λx . Then λ is said to be an eigenvalue of A . If x is an eigenvector of A with eigenvalue λ , then the matrix A − λI has no inverse , so its determinant is zero ; here I is the identity matrix with ones on the main diagonal and zeros elsewhere . Solving for the roots of the 7 . 4 . LU AND QR FACTORIZATION 97 determinant is one way to calculate the eigenvalues of A . For example , the eigenvalues of the Hermitian matrix B = (cid:20) 1 2 + i 2 − i 1 (cid:21) ( 7 . 13 ) are λ = 1 + √ 5 and λ = 1 − √ 5 , with corresponding eigenvectors u = ( √ 5 , 2 − i ) T and v = ( √ 5 , i − 2 ) T , respectively . Then ˜ B has the same eigenvalues , but both with multiplicity two . Finally , the associated eigen - vectors of ˜ B are (cid:20) u 1 u 2 (cid:21) , ( 7 . 14 ) and (cid:20) − u 2 u 1 (cid:21) , ( 7 . 15 ) for λ = 1 + √ 5 , and (cid:20) v 1 v 2 (cid:21) , ( 7 . 16 ) and (cid:20) − v 2 v 1 (cid:21) , ( 7 . 17 ) for λ = 1 − √ 5 . 7 . 4 LU and QR Factorization Let S be a real N by N matrix . Two important methods for solving the system Sx = b , the LU factorization and the QR factorization , involve factoring the matrix S and thereby reducing the problem to ﬁnding the solutions of simpler systems . In the LU factorization , we seek a lower triangular matrix L and an upper triangular matrix U so that S = LU . We then solve Sx = b by solving Lz = b and Ux = z . In the QR factorization , we seek an orthogonal matrix Q , that is , Q T = Q − 1 , and an upper triangular matrix R so that S = QR . Then we solve Sx = b by solving the upper triangular system Rx = Q T b . 98 CHAPTER 7 . MATRICES 7 . 5 The LU Factorization The matrix S =   2 1 1 4 1 0 − 2 2 1   can be reduced to the upper triangular matrix U =   2 1 1 0 − 1 − 2 0 0 − 4   through three elementary row operations : ﬁrst , add − 2 times the ﬁrst row to the second row ; second , add the ﬁrst row to the third row ; ﬁnally , add three times the new second row to the third row . Each of these row operations can be viewed as the result of multiplying on the left by the matrix obtained by applying the same row operation to the identity matrix . For example , adding − 2 times the ﬁrst row to the second row can be achieved by multiplying A on the left by the matrix L 1 =   1 0 0 − 2 1 0 0 0 1   ; note that the inverse of L 1 is L − 1 1 =   1 0 0 2 1 0 0 0 1   . We can write L 3 L 2 L 1 S = U , where L 1 , L 2 , and L 3 are the matrix representatives of the three elementary row operations . Therefore , we have S = L − 1 1 L − 1 2 L − 1 3 U = LU . This is the LU factorization of S . As we just saw , the LU factorization can be obtained along with the Gauss elimination . 7 . 5 . 1 A Shortcut There is a shortcut we can take in calculating the LU factorization . We begin with the identity matrix I , and then , as we perform a row operation , for example , adding − 2 times the ﬁrst row to the second row , we put the number 2 , the multiplier just used , but with a sign change , in the second 7 . 5 . THE LU FACTORIZATION 99 row , ﬁrst column , the position of the entry of S that was just converted to zero . Continuing in this fashion , we build up the matrix L as L =   1 0 0 2 1 0 − 1 − 3 1   , so that S =   2 1 1 4 1 0 − 2 2 1   =   1 0 0 2 1 0 − 1 − 3 1     2 1 1 0 − 1 − 2 0 0 − 4   . The entries of the main diagonal of L will be all ones . If we want the same to be true of U , we can rescale the rows of U and obtain the factorization S = LDU , where D is a diagonal matrix . 7 . 5 . 2 A Warning ! We have to be careful when we use the shortcut , as we illustrate now . For the purpose of this discussion let’s use the terminology R i + aR j to mean the row operation that adds a times the j th row to the i th row , and aR i to mean the operation that multiplies the i th row by a . Now we transform S to an upper triangular matrix U using the row operations • 1 . 12 R 1 ; • 2 . R 2 + ( − 4 ) R 1 ; • 3 . R 3 + 2 R 1 ; • 4 . R 3 + 3 R 2 ; • 5 . ( − 1 ) R 2 ; and ﬁnally , • 6 . ( − 14 ) R 3 . We end up with U =   1 1 / 2 1 / 2 0 1 2 0 0 1   . If we use the shortcut to form the lower triangular matrix L , we ﬁnd that L =   2 0 0 4 − 1 0 − 2 − 3 − 4   . Let’s go through how we formed L from the row operations listed above . We get L 11 = 2 from the ﬁrst row operation , L 21 = 4 from the second , 100 CHAPTER 7 . MATRICES L 31 = − 2 from the third , L 32 = − 3 from the fourth , L 22 = − 1 from the ﬁfth , and L 33 = − 14 from the sixth . But , if we multiple LU we do not get back S ! The problem is that we performed the fourth operation , adding to the third row three times the second row , before the ( 2 , 2 ) entry was rescaled to one . Suppose , instead , we do the row operations in this order : • 1 . 12 R 1 ; • 2 . R 2 + ( − 4 ) R 1 ; • 3 . R 3 + 2 R 1 ; • 4 . ( − 1 ) R 2 ; • 5 . R 3 − 3 R 2 ; and ﬁnally , • 6 . ( − 14 ) R 3 . Then the entry L 32 becomes 3 , instead of − 3 , and now LU = S . The message is that if we want to use the shortcut and we plan to rescale the diagonal entries of U to be one , we should rescale a given row prior to adding any multiple of that row to another row ; otherwise , we can get the wrong L . The problem is that certain elementary matrices associated with row operations do not commute . We just saw that L = L − 1 1 L − 1 2 L − 1 3 . However , when we form the matrix L simultaneously with performing the row operations , we are , in eﬀect , calculating L − 1 3 L − 1 2 L − 1 1 . Most of the time the order doesn’t matter , and we get the correct L anyway . But this is not always the case . For example , if we perform the operation 12 R 1 , followed by R 2 + ( − 4 ) R 1 , this is not the same as doing R 2 + ( − 4 ) R 1 , followed by 12 R 1 . With the matrix L 1 representing the operation 12 R 1 and the matrix L 2 representing the operation R 2 + ( − 4 ) R 1 , we ﬁnd that storing a 2 in the ( 1 , 1 ) position , and then a + 4 in the ( 1 , 2 ) position as we build L is not equivalent to multiplying the identity matrix by L − 1 2 L − 1 1 but rather multiplying the identity matrix by ( L − 1 1 L − 1 2 L 1 ) L − 1 1 = L − 1 1 L − 1 2 , which is the correct order . To illustrate this point , consider the matrix S given by S =   2 1 1 4 1 0 0 0 1   . 7 . 5 . THE LU FACTORIZATION 101 In the ﬁrst instance , we perform the row operations R 2 + ( − 2 ) R 1 , followed by 12 R 1 to get U =   1 0 . 5 0 . 5 0 − 1 − 2 0 0 1   . Using the shortcut , the matrix L becomes L =   2 0 0 2 1 0 0 0 1   , but we do not get S = LU . We do have U = L 2 L 1 S , where L 1 =   1 0 0 − 2 1 0 0 0 1   , and L 2 =   0 . 5 0 0 0 1 0 0 0 1   , so that S = L − 1 1 L − 1 2 U and the correct L is L = L − 1 1 L − 1 2 =   2 0 0 4 1 0 0 0 1   . But when we use the shortcut to generate L , we eﬀectively multiply the identity matrix ﬁrst by L − 1 1 and then by L − 1 2 , giving the matrix L − 1 2 L − 1 1 as our candidate for L . But L − 1 1 L − 1 2 and L − 1 2 L − 1 1 are not the same . But why does reversing the order of the row operations work ? When we perform 12 R 1 ﬁrst , and then R 2 + ( − 4 ) R 1 to get U , we are multiplying S ﬁrst by L 2 and then by the matrix E =   1 0 0 − 4 1 0 0 0 1   . The correct L is then L = L − 1 2 E − 1 . When we use the shortcut , we are ﬁrst multiplying the identity by the matrix L − 1 2 and then by a second matrix that we shall call J ; the correct L must then be L = JL − 1 2 . The matrix J is not E − 1 , but J = L − 1 2 E − 1 L 2 , 102 CHAPTER 7 . MATRICES so that L = JL − 1 2 = L − 1 2 E − 1 L 2 L − 1 2 = L − 1 2 E − 1 , which is correct . Note that it may not be possible to obtain A = LDU without ﬁrst permuting the rows of A ; in such cases we obtain PA = LDU , where P is obtained from the identity matrix by permuting rows . Suppose that we have to solve the system of linear equations Ax = b . Once we have the LU factorization , it is a simple matter to ﬁnd x : ﬁrst , we solve the system Lz = b , and then solve Ux = z . Because both L and U are triangular , solving these systems is a simple matter . Obtaining the LU factorization is often better than ﬁnding A − 1 ; when A is banded , that is , has non - zero values only for the main diagonal and a few diagonals on either side , the L and U retain that banded property , while A − 1 does not . If A is real and symmetric , and if A = LDU , then U = L T , so we have A = LDL T . If , in addition , the non - zero entries of D are positive , then we can write A = ( L √ D ) ( L √ D ) T , which is the Cholesky Decomposition of A . 7 . 5 . 3 The QR Factorization and Least Squares The least - squares solution of Ax = b is the solution of A T Ax = A T b . Once we have A = QR , we have A T A = R T Q T QR = R T R , so we ﬁnd the least squares solution easily , by solving R T z = A T b , and then Rx = z . Note that A T A = R T R is the Cholesky decomposition of A T A . 7 . 6 Exercises Ex . 7 . 1 Let W = { w 1 , . . . , w N } be a spanning set for a subspace S in R I , and V = { v 1 , . . . , v M } a linearly independent subset of S . Let A be the matrix whose columns are the v m , B the matrix whose columns are the w n . Show that there is an N by M matrix C such that A = BC . Prove Lemma 7 . 1 by showing that , if M > N , then there is a non - zero vector x with Cx = Ax = 0 . Ex . 7 . 2 Prove Proposition 7 . 3 . Ex . 7 . 3 Prove that if L is invertible and lower triangular , then so is L − 1 . Ex . 7 . 4 Show that the symmetric matrix H = (cid:20) 0 1 1 0 (cid:21) cannot be written as H = LDL T . 7 . 7 . COURSE HOMEWORK 103 Ex . 7 . 5 Show that the symmetric matrix H = (cid:20) 0 1 1 0 (cid:21) cannot be written as H = LU , where L is lower triangular , U is upper triangular , and both are invertible . Ex . 7 . 6 Let F be an invertible matrix that is the identity matrix , except for column s . Show that E = F − 1 is also the identity matrix , except for the entries in column s , which can be explicitly calculated from those of F . 7 . 7 Course Homework Try all the exercises in this chapter . 104 CHAPTER 7 . MATRICES Chapter 8 Linear Programming 8 . 1 Chapter Summary The term linear programming ( LP ) refers to the problem of optimizing a linear function of several variables over linear equality or inequality con - straints . In this chapter we present the problem and establish the basic facts , including weak and strong duality . We then turn to a discussion of the simplex method , the most well known method for solving LP problems . For a much more detailed treatment of linear programming , consult [ 163 ] . 8 . 2 Primal and Dual Problems The fundamental problem in linear programming is to minimize the func - tion f ( x ) = (cid:104) c , x (cid:105) = c · x = c T x , ( 8 . 1 ) over the feasible set F , that is , the convex set of all x ≥ 0 with Ax = b . This is the primal problem in standard form , denoted PS ; the set F is then the feasible set for PS . We shall use theorems of the alternative to establish the basic facts about LP problems . Shortly , we shall present an algebraic description of the extreme points of the feasible set F , in terms of basic feasible solutions , show that there are at most ﬁnitely many extreme points of F and that every member of F can be written as a convex combination of the extreme points , plus a direction of unboundedness . These results are also used to prove the basic theorems about linear programming problems and to describe the simplex algorithm . Associated with the basic problem in LP , called the primary problem , there is a second problem , the dual problem . Both of these problems can be 105 106 CHAPTER 8 . LINEAR PROGRAMMING written in two equivalent ways , the canonical form and the standard form . 8 . 2 . 1 An Example Consider the problem of maximizing the function f ( x 1 , x 2 ) = x 1 + 2 x 2 , over all x 1 ≥ 0 and x 2 ≥ 0 , for which the inequalities x 1 + x 2 ≤ 40 , and 2 x 1 + x 2 ≤ 60 are satisﬁed . The set of points satisfying all four inequalities is the quadri - lateral with vertices ( 0 , 0 ) , ( 30 , 0 ) , ( 20 , 20 ) , and ( 0 , 40 ) ; draw a picture . Since the level curves of the function f are straight lines , the maximum value must occur at one of these vertices ; in fact , it occurs at ( 0 , 40 ) and the maximum value of f over the constraint set is 80 . Rewriting the prob - lem as minimizing the function − x 1 − 2 x 2 , subject to x 1 ≥ 0 , x 2 ≥ 0 , − x 1 − x 2 ≥ − 40 , and − 2 x 1 − x 2 ≥ − 60 , the problem is now in what is called primal canonical form . 8 . 2 . 2 Canonical and Standard Forms Let b and c be ﬁxed vectors and A a ﬁxed matrix . The problem minimize z = c T x , subject to Ax ≥ b , x ≥ 0 ( PC ) ( 8 . 2 ) is the so - called primary problem of LP , in canonical form . The dual problem in canonical form is maximize w = b T y , subject to A T y ≤ c , y ≥ 0 . ( DC ) ( 8 . 3 ) The primary problem , in standard form , is minimize z = c T x , subject to Ax = b , x ≥ 0 ( PS ) ( 8 . 4 ) with the dual problem in standard form given by maximize w = b T y , subject to A T y ≤ c . ( DS ) ( 8 . 5 ) Notice that the dual problem in standard form does not require that y be nonnegative . Note also that PS makes sense only if the system Ax = b has solutions . For that reason , we shall assume , for the standard problems , 8 . 2 . PRIMAL AND DUAL PROBLEMS 107 that the I by J matrix A has at least as many columns as rows , so J ≥ I , and A has full rank I . The primal problem PC can be rewritten in dual canonical form , as maximize ( − c ) T x , subject to ( − A ) x ≤ − b , x ≥ 0 . The corresponding primal problem is then minimize ( − b ) T y , subject to ( − A ) T y ≥ − c , y ≥ 0 , which can obviously be rewritten as problem DC . This “symmetry”of the canonical forms will be useful later in proving strong duality theorems . 8 . 2 . 3 From Canonical to Standard and Back If we are given the primary problem in canonical form , we can convert it to standard form by augmenting the variables , that is , by introducing the slack variables u i = ( Ax ) i − b i , ( 8 . 6 ) for i = 1 , . . . , I , and rewriting Ax ≥ b as ˜ A ˜ x = b , ( 8 . 7 ) for ˜ A = [ A − I ] and ˜ x = [ x T u T ] T . If PC has a feasible solution , then so does its PS version . If the corresponding dual problem DC is feasible , then so is its DS version ; the new c is ˜ c = [ c T 0 T ] T . The quantities z and w remain unchanged . If we are given the primary problem in standard form , we can convert it to canonical form by writing the equations as inequalities , that is , by replacing Ax = b with the two matrix inequalities Ax ≥ b , and ( − A ) x ≥ − b and writing ˜ Ax ≥ ˜ b , where ˜ A = [ A T − A T ] T and ˜ b = [ b T − b T ] T . If the problem PS is feasible , then so is its PC version . If the corresponding dual problem DS is feasible , so is DC , where now the new y is ˜ y = [ u T − v T ] T , where u i = max { y i , 0 } and v i = y i − u i . Again , the z and w remain unchanged . 8 . 2 . 4 Weak Duality Consider the problems PS and DS . Say that x is feasible for PS if x ≥ 0 and Ax = b . Let F be the set of such feasible x . Say that y is feasible for DS if A T y ≤ c . When it is clear from the context which problems we are discussing , we shall simply say that x and y are feasible . The Weak Duality Theorem is the following : 108 CHAPTER 8 . LINEAR PROGRAMMING Theorem 8 . 1 Let x and y be feasible vectors . Then z = c T x ≥ b T y = w . ( 8 . 8 ) Corollary 8 . 1 If z is not bounded below , then there are no feasible y . Corollary 8 . 2 If x and y are both feasible , and z = w , then both x and y are optimal for their respective problems . The proof of the theorem and its corollaries are left as exercises . 8 . 2 . 5 Primal - Dual Methods The nonnegative quantity c T x − b T y is called the duality gap . The comple - mentary slackness condition says that , for optimal x and y , we have x j ( c j − ( A T y ) j ) = 0 , ( 8 . 9 ) for each j . Introducing the slack variables s j ≥ 0 , for j = 1 , . . . , J , we can write the dual problem constraint A T y ≤ c as A T y + s = c . Then the complementary slackness conditions x j s j = 0 for each j are equivalent to z = w , so the duality gap is zero . Primal - dual algorithms for solving linear programming problems are based on ﬁnding sequences of vectors { x k } , { y k } , and { s k } that drive x kj s kj down to zero , and therefore , the duality gap down to zero [ 163 ] . 8 . 2 . 6 Strong Duality The Strong Duality Theorems make a stronger statement . One such theo - rem is the following . Theorem 8 . 2 If one of the problems PS or DS has an optimal solution , then so does the other and z = w for the optimal vectors . Another strong duality theorem is due to David Gale [ 115 ] . Theorem 8 . 3 ( Gale’s Strong Duality Theorem ) If both problems PC and DC have feasible solutions , then both have optimal solutions and the optimal values are equal . 8 . 3 . THE BASIC STRONG DUALITY THEOREM 109 8 . 3 The Basic Strong Duality Theorem In this section we state and prove a basic strong duality theorem that has , as corollaries , both Theorem 8 . 2 and Gale’s Strong Duality Theorem 8 . 3 , as well as other theorems of this type . The proof of this basic strong duality theorem is an immediate consequence of Farkas’ Lemma , which we repeat here for convenience . Theorem 8 . 4 ( Farkas’ Lemma ) [ 110 ] Precisely one of the following is true : • ( 1 ) there is x ≥ 0 such that Ax = b ; • ( 2 ) there is y such that A T y ≥ 0 and b T y < 0 . We begin with a few items of notation . Let p be the inﬁmum of the values c T x , over all x ≥ 0 such that Ax = b , with p = ∞ if there are no such x . Let p ∗ be the supremum of the values b T y , over all y such that A T y ≤ c , with p ∗ = −∞ if there are no such y . Let v be the inﬁmum of the values c T x , over all x ≥ 0 such that Ax ≥ b , with v = ∞ if there are no such x . Let v ∗ be the supremum of the values b T y , over all y ≥ 0 such that A T y ≤ c , with v ∗ = −∞ if there are no such y . Our basic strong duality theorem is the following . Theorem 8 . 5 ( Basic Strong Duality Theorem ) If p ∗ is ﬁnite , then the primal problem PS has an optimal solution ˆ x and c T ˆ x = p ∗ . Proof : Consider the system of inequalities given in block - matrix form by (cid:20) − A T c 0 T 1 (cid:21) (cid:20) rα (cid:21) ≥ (cid:20) 00 (cid:21) , ( 8 . 10 ) and [ − b T p ∗ ] (cid:20) rα (cid:21) < 0 . ( 8 . 11 ) Here r is a column vector and α is a real number . We show that this system has no solution . If there is a solution with α > 0 , then y = 1 α r is feasible for the dual problem DS , but b T y > p ∗ , contradicting the deﬁnition of p ∗ . If there is a solution with α = 0 , then A T r ≤ 0 , and b T r > 0 . We know that the problem DS has feasible vectors , so let ˆ y be one such . Then the vectors ˆ y + nr are feasible vectors , for n = 1 , 2 , . . . . But b T ( ˆ y + nr ) → + ∞ , as n increases , contradicting the assumption that p ∗ is ﬁnite . Now , by Farkas’ Lemma , there must be ˆ x ≥ 0 and β ≥ 0 such that A ˆ x = b and c T ˆ x = p ∗ − β ≤ p ∗ . It follows that ˆ x is optimal for the primal problem PS and c T ˆ x = p ∗ . 110 CHAPTER 8 . LINEAR PROGRAMMING Now we reap the harvest of corollaries of this basic strong duality theo - rem . First , recall that LP problems in standard form can be reformulated as LP problems in canonical form , and vice versa . Also recall the “symme - try” of the canonical forms ; the problem PC can be rewritten in form of a DC problem , whose corresponding primal problem in canonical form is equivalent to the original DC problem . As a result , we have the following corollaries of Theorem 8 . 5 . Corollary 8 . 3 Let p be ﬁnite . Then DS has an optimal solution ˆ y and b T ˆ y = p . Corollary 8 . 4 Let v be ﬁnite . Then DC has an optimal solution ˆ y and b T ˆ y = v . Corollary 8 . 5 Let v ∗ be ﬁnite . Then PC has an optimal solution ˆ x and c T ˆ x = v ∗ . Corollary 8 . 6 Let p or p ∗ be ﬁnite . Then both PS and DS have optimal solutions ˆ x and ˆ y , respectively , with c T ˆ x = b T ˆ y . Corollary 8 . 7 Let v or v ∗ be ﬁnite . Then both PC and DC have optimal solutions ˆ x and ˆ y , respectively , with c T ˆ x = b T ˆ y . In addition , Theorem 8 . 2 follows as a corollary , since if either PS or DS has an optimal solution , then one of p or p ∗ must be ﬁnite . Gale’s Strong Duality Theorem 8 . 3 is also a consequence of Theorem 8 . 5 , since , if both PC and DC are feasible , then both v and v ∗ must be ﬁnite . 8 . 4 Another Proof of Theorem 8 . 2 We know that Theorem 8 . 2 is a consequence of Theorem 8 . 5 , which , in turn , follows from Farkas’ Lemma . However , it is instructive to consider an alternative proof . For that , we need some deﬁnitions and notation . Deﬁnition 8 . 1 A point x in F is said to be a basic feasible solution if the columns of A corresponding to positive entries of x are linearly independent . Recall that , for PS , we assume that J ≥ I and the rank of A is I . Consequently , if , for some nonnegative vector x , the columns j for which x j is positive are linearly independent , then x j is positive for at most I values of j . Therefore , a basic feasible solution can have at most I positive entries . For a given set of entries , there can be at most one basic feasible solution for which precisely those entries are positive . Therefore , there can be only ﬁnitely many basic feasible solutions . 8 . 4 . ANOTHER PROOF OF THEOREM 8 . 2 111 Now let x be an arbitrary basic feasible solution . Denote by B an invertible matrix obtained from A by deleting J − I columns associated with zero entries of x . Note that , if x has fewer than I positive entries , then some of the columns of A associated with zero values of x j are retained . The entries of an arbitrary vector y corresponding to the columns not deleted are called the basic variables . Then , assuming that the columns of B are the ﬁrst I columns of A , we write y T = ( y TB , y TN ) , and A = [ B N ] , ( 8 . 12 ) so that Ay = By B + Ny N , Ax = Bx B = b , and x B = B − 1 b . The following theorems are taken from the book by Nash and Sofer [ 163 ] . We begin with a characterization of the extreme points of F ( recall Deﬁnition 6 . 22 ) . Theorem 8 . 6 A point x is in Ext ( F ) if and only if x is a basic feasible solution . Proof : Suppose that x is a basic feasible solution , and we write x T = ( x TB , 0 T ) , A = [ B N ] . If x is not an extreme point of F , then there are y (cid:54) = x and z (cid:54) = x in F , and α in ( 0 , 1 ) , with x = ( 1 − α ) y + αz . ( 8 . 13 ) Then y T = ( y TB , y TN ) , z T = ( z TB , z TN ) , and y N ≥ 0 , z N ≥ 0 . From 0 = x N = ( 1 − α ) y N + ( α ) z N ( 8 . 14 ) it follows that y N = z N = 0 , ( 8 . 15 ) and b = By B = Bz B = Bx B . But , since B is invertible , we have x B = y B = z B . This is a contradiction , so x must be in Ext ( F ) . Conversely , suppose that x is in Ext ( F ) . Since x is in F , we know that Ax = b and x ≥ 0 . By reordering the variables if necessary , we may assume that x T = ( x TB , x TN ) , with x B > 0 and x N = 0 ; we do not know that x B is a vector of length I , however , so when we write A = [ B N ] , we do not know that B is square . If the columns of B are linearly independent , then , by deﬁnition , x is a basic feasible solution . If the columns of B were not linearly independent , we could construct y (cid:54) = x and z (cid:54) = x in F , such that x = 1 2 y + 1 2 z , ( 8 . 16 ) as we now show . If { B 1 , B 2 , . . . , B K } are the columns of B and are linearly dependent , then there are constants p 1 , p 2 , . . . , p K , not all zero , with p 1 B 1 + . . . + p K B K = 0 . ( 8 . 17 ) 112 CHAPTER 8 . LINEAR PROGRAMMING With p T = ( p 1 , . . . , p K ) , we have B ( x B + αp ) = B ( x B − αp ) = Bx B = b , ( 8 . 18 ) for all α ∈ ( 0 , 1 ) . We then select α so small that both x B + αp > 0 and x B − αp > 0 . Let y T = ( x TB + αp T , 0 T ) ( 8 . 19 ) and z T = ( x TB − αp T , 0 T ) . ( 8 . 20 ) Therefore x is not an extreme point of F , which is a contradiction . This completes the proof . Corollary 8 . 8 There are at most ﬁnitely many basic feasible solutions , so there are at most ﬁnitely many members of Ext ( F ) . Theorem 8 . 7 If F is not empty , then Ext ( F ) is not empty . In that case , let { v 1 , . . . , v M } be the members of Ext ( F ) . Every x in F can be written as x = d + α 1 v 1 + . . . + α M v M , ( 8 . 21 ) for some α m ≥ 0 , with (cid:80) Mm = 1 α m = 1 , and some direction of unbounded - ness , d . Proof : We consider only the case in which F is bounded , so there is no direction of unboundedness ; the unbounded case is similar . Let x be a feasible point . If x is an extreme point , ﬁne . If not , then x is not a basic feasible solution and the columns of A that correspond to the positive entries of x are not linearly independent . Then we can ﬁnd a vector p such that Ap = 0 and p j = 0 if x j = 0 . If | (cid:15) | is small enough , x + (cid:15)p is in F and ( x + (cid:15)p ) j = 0 if x j = 0 . Our objective now is to ﬁnd another member of F that has fewer positive entries than x has . We can alter (cid:15) in such a way that eventually y = x + (cid:15)p has at least one more zero entry than x has . To see this , let − (cid:15) = x k p k = min (cid:16) x j p j | x j > 0 , p j > 0 (cid:17) . Then the vector x + (cid:15)p is in F and has fewer positive entries than x has . Repeating this process , we must eventually reach the point at which there is no such vector p . At this point , we have obtained a basic feasible solution , which must then be an extreme point of F . Therefore , the set of extreme points of F is not empty . 8 . 4 . ANOTHER PROOF OF THEOREM 8 . 2 113 The set G of all x in F that can be written as in Equation ( 8 . 21 ) is a closed set . Consequently , if there is x in F that cannot be written in this way , there is a ball of radius r , centered at x , having no intersection with G . We can then repeat the previous construction to obtain a basic feasible solution that lies within this ball . But such a vector would be an extreme point of F , and so would have to be a member of G , which would be a contradiction . Therefore , every member of F can be written according to Equation ( 8 . 21 ) . Proof of Theorem 8 . 2 : Suppose now that x ∗ is a solution of the problem PS and z ∗ = c T x ∗ . Without loss of generality , we may assume that x ∗ is a basic feasible solution , hence an extreme point of F ( Why ? ) . Then we can write x T ∗ = ( ( B − 1 b ) T , 0 T ) , ( 8 . 22 ) c T = ( c TB , c TN ) , ( 8 . 23 ) and A = [ B N ] . We shall show that y ∗ = ( B − 1 ) T c B , which depends on x ∗ via the matrix B , and z ∗ = c T x ∗ = y T ∗ b = w ∗ . Every feasible solution has the form x T = ( ( B − 1 b ) T , 0 T ) + ( ( B − 1 Nv ) T , v T ) , ( 8 . 24 ) for some v ≥ 0 . From c T x ≥ c T x ∗ we ﬁnd that ( c TN − c TB B − 1 N ) ( v ) ≥ 0 , ( 8 . 25 ) for all v ≥ 0 . It follows that c TN − c TB B − 1 N = 0 . ( 8 . 26 ) Now let y ∗ = ( B − 1 ) T c B , or y T ∗ = c TB B − 1 . We show that y ∗ is feasible for DS ; that is , we show that A T y ∗ ≤ c T . ( 8 . 27 ) Since y T ∗ A = ( y T ∗ B , y T ∗ N ) = ( c TB , y T ∗ N ) = ( c TB , c TB B − 1 N ) ( 8 . 28 ) 114 CHAPTER 8 . LINEAR PROGRAMMING and c TN ≥ c TB B − 1 N , ( 8 . 29 ) we have y T ∗ A ≤ c T , ( 8 . 30 ) so y ∗ is feasible for DS . Finally , we show that c T x ∗ = y T ∗ b . ( 8 . 31 ) We have y T ∗ b = c TB B − 1 b = c T x ∗ . ( 8 . 32 ) This completes the proof . 8 . 5 Proof of Gale’s Strong Duality Theorem As we have seen , Gale’s Strong Duality Theorem 8 . 3 is a consequence of Theorem 8 . 5 , and so follows from Farkas’ Lemma . Gale’s own proof , which we give below , is somewhat diﬀerent , in that he uses Farkas’ Lemma to obtain Theorem 6 . 11 , and then the results of Theorem 6 . 11 to prove Theorem 8 . 3 . We show that there are non - negative vectors x and y such that Ax ≥ b , A T y ≤ c , and b T y − c T x ≥ 0 . It will then follow that z = c T x = b T y = w , so that x and y are both optimal . In matrix notation , we want to ﬁnd x ≥ 0 and y ≥ 0 such that   A 0 0 − A T − c T b T   (cid:20) xy (cid:21) ≥   b − c 0   . ( 8 . 33 ) In order to use Theorem 6 . 11 , we rewrite ( 8 . 33 ) as   − A 0 0 A T c T − b T   (cid:20) xy (cid:21) ≤   − bc 0   . ( 8 . 34 ) We assume that there are no x ≥ 0 and y ≥ 0 for which the inequalities in ( 8 . 34 ) hold . Then , according to Theorem 6 . 11 , there are non - negative vectors s and t , and non - negative scalar ρ such that (cid:20) − A T 0 c 0 A − b (cid:21)   stρ   ≥ 0 , ( 8 . 35 ) 8 . 6 . SOME EXAMPLES 115 and [ − b T c T 0 ]   stρ   < 0 . ( 8 . 36 ) Note that ρ cannot be zero , for then we would have A T s ≤ 0 and At ≥ 0 . Taking feasible vectors x and y , we would ﬁnd that s T Ax ≤ 0 , which implies that b T s ≤ 0 , and t T A T y ≥ 0 , which implies that c T t ≥ 0 . Therefore , we could not also have c T t − b T s < 0 . Writing out the inequalities , we have ρc T t ≥ s T At ≥ s T ( ρb ) = ρs T b . Using ρ > 0 , we ﬁnd that c T t ≥ b T s , which is a contradiction . Therefore , there do exist x ≥ 0 and y ≥ 0 such that Ax ≥ b , A T y ≤ c , and b T y − c T x ≥ 0 . 8 . 6 Some Examples We give two well known examples of LP problems . 8 . 6 . 1 The Diet Problem There are nutrients indexed by i = 1 , . . . , I and our diet must contain at least b i units of the i th nutrient . There are J foods , indexed by j = 1 , . . . , J , and one unit of the j th food cost c j dollars and contains A ij units of the i th nutrient . The problem is to minimize the cost , while obtaining at least the minimum amount of each nutrient . Let x j ≥ 0 be the amount of the j th food that we consume . Then we need Ax ≥ b , where A is the matrix with entries A ij , b is the vector with entries b i and x is the vector with entries x j ≥ 0 . With c the vector with entries c j , the total cost of our food is z = c T x . The problem is then to minimize z = c T x , subject to Ax ≥ b and x ≥ 0 . This is the primary LP problem , in canonical form . 8 . 6 . 2 The Transport Problem We must ship products from sources to destinations . There are I sources , indexed by i = 1 , . . . , I , and J destinations , indexed by j = 1 , . . . , J . There are a i units of product at the i th source , and we must have at least b j units reaching the j th destination . The customer will pay C ij dollars to get one unit from i to j . Let x ij be the number of units of product to go from 116 CHAPTER 8 . LINEAR PROGRAMMING the i th source to the j th destination . The producer wishes to maximize income , that is , maximize (cid:88) i , j C ij x ij , subject to x ij ≥ 0 , I (cid:88) i = 1 x ij ≥ b j , and J (cid:88) j = 1 x ij ≤ a i . Obviously , we must assume that I (cid:88) i = 1 a i ≥ J (cid:88) j = 1 b j . This problem is not yet in the form of the LP problems considered so far . It also introduces a new feature , namely , it may be necessary to have x ij a non - negative integer , if the products exist only in whole units . This leads to integer programming . 8 . 7 The Simplex Method In this section we sketch the main ideas of the simplex method . For further details see [ 163 ] . Begin with ˆ x , a basic feasible solution of PS . Assume , as previously , that A = [ B N ] , ( 8 . 37 ) where B is an I by I invertible matrix obtained by deleting from A some ( but perhaps not all ) columns associated with zero entries of ˆ x . As before , we assume the variables have been ordered so that the zero entries of ˆ x have the highest index values . The entries of an arbitrary x corresponding to the ﬁrst I columns are the basic variables . We write x T = ( x TB , x TN ) , and so that ˆ x N = 0 , A ˆ x = B ˆ x B = b , and ˆ x B = B − 1 b . The current value of z is ˆ z = c TB ˆ x B = c TB B − 1 b . We are interested in what happens to z as x N takes on positive entries . 8 . 7 . THE SIMPLEX METHOD 117 For any feasible x we have Ax = b = Bx B + Nx n , so that x B = B − 1 b − B − 1 Nx N , and z = c T x = c TB x B + c TN x N = c TB ( B − 1 b − B − 1 Nx N ) + c TN x N . Therefore , z = c TB B − 1 b + ( c TN − c TB B − 1 N ) x N = ˆ z + r T x N , where r T = ( c TN − c TB B − 1 N ) . The vector r is called the reduced cost vector . We deﬁne the vector y T = c T B B − 1 of simplex multipliers , and write z − ˆ z = r T x N = ( c TN − y T N ) x N . We are interested in how z changes as we move away from ˆ x and permit x N to have positive entries . If x N is non - zero , then z changes by r T x N . Therefore , if r ≥ 0 , the current ˆ z cannot be made smaller by letting x N have some positive entries ; the current ˆ x is then optimal . Initially , at least , r will have some negative entries , and we use these as a guide in deciding how to select x N . Keep in mind that the vectors x N and r have length J − I and the j th column of N is the ( I + j ) th column of A . Select an index j such that r j < 0 , ( 8 . 38 ) and r j is the most negative of the negative entries of r . Then x I + j is called the entering variable . Compute d j = B − 1 a j , where a j is the ( I + j ) th column of A , which is the j th column of N . If we allow ( x N ) j = x I + j to be positive , then x B = B − 1 b − x I + j B − 1 a j = B − 1 b − x I + j d j . We need to make sure that x B remains non - negative , so we need ( B − 1 b ) i − x I + j d ji ≥ 0 , for all indices i = 1 , . . . , I . If the i th entry d ji is negative , then ( x B ) i increases as x I + j becomes positive ; if d ji = 0 , then ( x B ) i remains unchanged . The problem arises when d ji is positive . 118 CHAPTER 8 . LINEAR PROGRAMMING Find an index s in { 1 , . . . , I } for which ( B − 1 b ) s d js = min { ( B − 1 b ) i d ji : d ji > 0 } . ( 8 . 39 ) Then x s is the leaving variable , replacing x I + j ; that is , the new set of indices corresponding to new basic variables will now include I + j , and no longer include s . The new entries of ˆ x are ˆ x s = 0 and ˆ x I + j = ( B − 1 b ) s d js . We then rearrange the columns of A to redeﬁne B and N , and rearrange the positions of the entries of x , to get the new basic variables vector x B , the new x N and the new c . Then we repeat the process . In Exercise 8 . 6 you are asked to show that when we have reached the optimal solution for the primal problem PS the vector y with y T = c TB B − 1 is feasible for the dual problem DS and is the optimal solution for DS . 8 . 8 Numerical Considerations It is helpful to note that when the columns of A are rearranged and a new B is deﬁned , the new B diﬀers from the old B in only one column . Therefore B new = B old − uv T , ( 8 . 40 ) where u is the column vector that equals the old column minus the new one , and v is the column of the identity matrix corresponding to the column of B old being altered . In Exercise 8 . 5 the reader is asked to prove that 1 − v T B − 1 old u (cid:54) = 0 . Once we know that , the inverse of B new can be obtained fairly easily from the inverse of B old using the Sherman - Morrison - Woodbury Identity . The Sherman - Morrison - Woodbury Identity : When B is invertible , we have ( B − uv T ) − 1 = B − 1 + α ( B − 1 u ) ( v T B − 1 ) , ( 8 . 41 ) whenever α − 1 = 1 − v T B − 1 u (cid:54) = 0 . When α − 1 = 0 , the matrix B − uv T has no inverse . We shall illustrate this in the example below . 8 . 9 . AN EXAMPLE OF THE SIMPLEX METHOD 119 For large - scale problems , issues of storage , computational eﬃciency and numerical accuracy become increasingly important [ 202 ] . For such prob - lems , other ways of updating the matrix B − 1 are used . Let F be the identity matrix , except for having the vector d j as column s . It is easy to see that B new = BF , so that ( B new ) − 1 = EB − 1 , where E = F − 1 . In Exercise 7 . 6 you are asked to show that E is also the identity matrix , except for the entries in column s , which can be explicitly calculated ( see [ 163 ] ) . Therefore , as the simplex iteration proceeds , the next ( B new ) − 1 can be represented as ( B new ) − 1 = E k E k − 1 · · · E 1 B − 1 , where B is the original matrix selected at the beginning of the calculations , and the other factors are the E matrices used at each step . Another approach is to employ the LU - decomposition method for solv - ing systems of linear equations , with numerically stable procedures for up - dating the matrices L and U as the columns of B are swapped . Finding methods for doing this is an active area of research [ 202 ] . 8 . 9 An Example of the Simplex Method Consider once again the problem of maximizing the function f ( x 1 , x 2 ) = x 1 + 2 x 2 , over all x 1 ≥ 0 and x 2 ≥ 0 , for which the inequalities x 1 + x 2 ≤ 40 , and 2 x 1 + x 2 ≤ 60 are satisﬁed . In PS form , the problem is to minimize the function − x 1 − 2 x 2 , subject to x 1 ≥ 0 , x 2 ≥ 0 , x 3 ≥ 0 , x 4 ≥ 0 , − x 1 − x 2 − x 3 = − 40 , and − 2 x 1 − x 2 − x 4 = − 60 . The matrix A is then A = (cid:20) − 1 − 1 − 1 0 − 2 − 1 0 − 1 (cid:21) . ( 8 . 42 ) Let’s choose x 1 and x 2 as the basic variables , so that the matrix B is B = (cid:20) − 1 − 1 − 2 − 1 (cid:21) , ( 8 . 43 ) 120 CHAPTER 8 . LINEAR PROGRAMMING with inverse B − 1 = (cid:20) 1 − 1 − 2 1 (cid:21) , ( 8 . 44 ) and the matrix N is N = (cid:20) − 1 0 0 − 1 (cid:21) . ( 8 . 45 ) The vector b is b = ( − 40 , − 60 ) T . A general vector x is x = ( x 1 , x 2 , x 3 , x 4 ) T , with x B = ( x 1 , x 2 ) T and x N = ( x 3 , x 4 ) T , and c = ( − 1 , − 2 , 0 , 0 ) T , with c B = ( − 1 , − 2 ) T and c N = ( 0 , 0 ) T . The feasible set of points satisfy - ing all four inequalities is the quadrilateral in R 2 with vertices ( 0 , 0 ) , ( 30 , 0 ) , ( 20 , 20 ) , and ( 0 , 40 ) . In R 4 , these vertices correspond to the vec - tors ( 0 , 0 , 40 , 60 ) T , ( 30 , 0 , 10 , 0 ) T , ( 20 , 20 , 0 , 0 ) T , and ( 0 , 40 , 0 , 20 ) T . Since we have chosen to start with x 1 and x 2 as our basic variables , we let our starting vector be ˆ x = ( 20 , 20 , 0 , 0 ) T , so that ˆ x B = B − 1 b = ( 20 , 20 ) T , and ˆ x N = ( 0 , 0 ) T . Then we ﬁnd that y T = c TB B − 1 = ( 3 , − 1 ) , and y T N = ( − 3 , 1 ) . The reduced cost vector is then r T = c TN − y T N = ( 0 , 0 ) − ( − 3 , 1 ) = ( 3 , − 1 ) . Since r T has a negative entry in its second position , j = 2 , we learn that the entering variable is going to be x 2 + j = x 4 . The fourth column of A is ( 0 , − 1 ) T , so the vector d 2 is d 2 = B − 1 ( 0 , − 1 ) T = ( 1 , − 1 ) T . Therefore , we must select a new positive value for x 4 that satisﬁes ( 20 , 20 ) ≥ x 4 ( 1 , − 1 ) . The single positive entry of d 2 is the ﬁrst one , from which we conclude that the leaving variable will be x 1 . We therefore select as the new values of the variables ˆ x 1 = 0 , ˆ x 2 = 40 , ˆ x 3 = 0 , and ˆ x 4 = 20 . We then reorder the vari - ables as x = ( x 4 , x 2 , x 3 , x 1 ) T and rearrange the columns of A accordingly . Having done this , we see that we now have B = B new = (cid:20) 0 − 1 − 1 − 1 (cid:21) , ( 8 . 46 ) with inverse B − 1 = (cid:20) 1 − 1 − 1 0 (cid:21) , ( 8 . 47 ) and the matrix N is N = (cid:20) − 1 − 1 0 − 2 (cid:21) . ( 8 . 48 ) 8 . 10 . ANOTHER EXAMPLE OF THE SIMPLEX METHOD 121 Since B new = B old − (cid:20) − 1 − 1 (cid:21) [ 1 0 ] , we can apply the Sherman - Morrison - Woodbury Identity to get B − 1 new . The reduced cost vector is now r T = ( 2 , 1 ) . Since it has no negative entries , we have reached the optimal point ; the solution is ˆ x 1 = 0 , ˆ x 2 = 40 , with slack variables ˆ x 3 = 0 and ˆ x 4 = 20 . 8 . 10 Another Example of the Simplex Method The following example is taken from Fang and Puthenpura [ 109 ] . Minimize the function f ( x 1 , x 2 , x 3 , x 4 , x 5 , x 6 ) = − x 1 − x 2 − x 3 , subject to 2 x 1 + x 4 = 1 ; 2 x 2 + x 5 = 1 ; 2 x 3 + x 6 = 1 ; and x i ≥ 0 , for i = 1 , . . . , 6 . The variables x 4 , x 5 , and x 6 appear to be slack variables , introduced to obtain equality constraints . Initially , we deﬁne the matrix A to be A =   2 0 0 1 0 0 0 2 0 0 1 0 0 0 2 0 0 1   , ( 8 . 49 ) b = ( 1 , 1 , 1 ) T , c = ( − 1 , − 1 , − 1 , 0 , 0 , 0 ) T and x = ( x 1 , x 2 , x 3 , x 4 , x 5 , x 6 ) T . Suppose we begin with x 4 , x 5 , and x 6 as the basic variables . We then rearrange the entries of the vector of unknowns so that x = ( x 4 , x 5 , x 6 , x 1 , x 2 , x 3 ) T . Now we have to rearrange the columns of A as well ; the new A is A =   1 0 0 2 0 0 0 1 0 0 2 0 0 0 1 0 0 2   . ( 8 . 50 ) The vector c must also be redeﬁned ; the new one is c = ( 0 , 0 , 0 , − 1 , − 1 , − 1 ) T , so that c N = ( − 1 , − 1 , − 1 ) T and c B = ( 0 , 0 , 0 ) T . For this ﬁrst step of the simplex method we have B =   1 0 0 0 1 0 0 0 1   , 122 CHAPTER 8 . LINEAR PROGRAMMING and N =   2 0 0 0 2 0 0 0 2   . Note that one advantage in choosing the slack variables as the basic vari - ables is that it is easy then to ﬁnd the corresponding basic feasible solution , which is now ˆ x =   ˆ x 4 ˆ x 5 ˆ x 6 ˆ x 1 ˆ x 2 ˆ x 3   = (cid:20) ˆ x B ˆ x N (cid:21) =   111000   . The reduced cost vector r is then r = ( − 1 , − 1 , − 1 ) T ; since it has negative entries , the current basic feasible solution is not opti - mal . Suppose that we select a non - basic variable with negative reduced cost , say x 1 , which , we must remember , is the fourth entry of the redeﬁned x , so j = 1 and I + j = 4 . Then x 1 is the entering basic variable , and the vector d 1 is then d 1 = B − 1 a j = ( 2 , 0 , 0 ) T . The only positive entry of d 1 is the ﬁrst one , which means , according to Equation ( 8 . 39 ) , that the exiting variable should be x 4 . Now the new set of basic variables is { x 5 , x 6 , x 1 } and the new set of non - basic variables is { x 2 , x 3 , x 4 } . The new matrices B and N are B =   0 0 2 1 0 0 0 1 0   , and N =   0 0 1 2 0 0 0 2 0   . Continuing through two more steps , we ﬁnd that the optimal solution is − 3 / 2 , and it occurs at the vector x = ( x 1 , x 2 , x 3 , x 4 , x 5 , x 6 ) T = ( 1 / 2 , 1 / 2 , 1 / 2 , 0 , 0 , 0 ) T . 8 . 11 . SOME POSSIBLE DIFFICULTIES 123 8 . 11 Some Possible Diﬃculties In the ﬁrst example of the simplex method , we knew all four of the vertices of the feasible region , so we could choose any one of them to get our initial basic feasible solution . We chose to begin with x 1 and x 2 as our basic variables , which meant that the slack variables were zero and our ﬁrst basic feasible solution was ˆ x = ( 20 , 20 , 0 , 0 ) T . In the second example , we chose the slack variables to be the initial basic variables , which made it easy to ﬁnd the initial basic feasible solution . Generally , however , ﬁnding an initial basic feasible solution may not be easy . You might think that we can always simply take the slack variables as our initial basic variables , so that the initial B is just the identity matrix , and the initial basic feasible solution is merely the concatenation of the column vectors b and 0 , as in the second example . The following example shows why this may not always work . 8 . 11 . 1 A Third Example : Consider the problem of minimizing the function z = 2 x 1 + 3 x 2 , subject to 3 x 1 + 2 x 2 = 14 , 2 x 1 − 4 x 2 − x 3 = 2 , 4 x 1 + 3 x 2 + x 4 = 19 , and x i ≥ 0 , for i = 1 , . . . , 4 . The matrix A is now A =   3 2 0 0 2 − 4 − 1 0 4 3 0 1   . ( 8 . 51 ) There are only two slack variables , so we cannot construct our set of basic variables using only slack variables , since the matrix B must be square . We cannot begin with ˆ x 1 = ˆ x 2 = 0 , since this would force ˆ x 3 = − 2 , which is not permitted . We can choose ˆ x 2 = 0 and solve for the other three , to get ˆ x 1 = 14 3 , ˆ x 3 = 22 3 , and ˆ x 4 = 1 3 . This is relatively easy only because the problem is artiﬁcially small . The point here is that , for realistically large LP problems , ﬁnding a place to begin the simplex algorithm may not be a simple matter . For more on this matter , see [ 163 ] . In both of our ﬁrst two examples , ﬁnding the inverse of the matrix B is easy , since B is only 2 by 2 , or 3 by 3 . In larger problems , ﬁnding B − 1 , or better , solving y T B = c TB for y T , is not trivial and can be an expensive part of each iteration . The Sherman - Morrison - Woodbury identity is helpful here . 124 CHAPTER 8 . LINEAR PROGRAMMING 8 . 12 Topics for Projects The simplex method provides several interesting topics for projects . • 1 . Investigate the issue of ﬁnding a suitable starting basic feasible solution . Reference [ 163 ] can be helpful in this regard . • 2 . How can we reduce the cost associated with solving y T B = c TB for y T at each step of the simplex method ? • 3 . Suppose that , instead of needing the variables to be nonnegative , we need each x i to lie in the interval [ α i , β i ] . How can we modify the simplex method to incorporate these constraints ? • 4 . Investigate the role of linear programming and the simplex method in graph theory and networks , with particular attention to the trans - port problem . • 5 . There is a sizable literature on the computational complexity of the simplex method . Investigate this issue and summarize your ﬁndings . 8 . 13 Exercises Ex . 8 . 1 Prove Theorem 8 . 1 and its corollaries . Ex . 8 . 2 Use Farkas’ Lemma directly to prove that , if p ∗ is ﬁnite , then PS has a feasible solution . Ex . 8 . 3 Put the Transport Problem into the form of an LP problem in DS form . Ex . 8 . 4 The Sherman - Morrison - Woodbury Identity Let B be an invertible matrix . Show that ( B − uv T ) − 1 = B − 1 + α ( B − 1 u ) ( v T B − 1 ) , ( 8 . 52 ) whenever α − 1 = 1 − v T B − 1 u (cid:54) = 0 . Show that , if α − 1 = 0 , then the matrix B − uv T has no inverse . Ex . 8 . 5 Show that B new given in Equation ( 8 . 40 ) is invertible . Ex . 8 . 6 Show that when the simplex method has reached the optimal so - lution for the primal problem PS , the vector y with y T = c TB B − 1 becomes 8 . 13 . EXERCISES 125 a feasible vector for the dual problem and is therefore the optimal solution for DS . Hint : Clearly , we have z = c T x = c TB B − 1 b = y T b = w , so we need only show that A T y ≤ c . Ex . 8 . 7 Complete the calculation of the optimal solution for the problem in the second example of the simplex method . Ex . 8 . 8 Consider the following problem , taken from [ 109 ] . Minimize the function f ( x 1 , x 2 , x 3 , x 4 ) = − 3 x 1 − 2 x 2 , subject to x 1 + x 2 + x 3 = 40 , 2 x 1 + x 2 + x 4 = 60 , and x j ≥ 0 , for j = 1 , . . . , 4 . Use the simplex method to ﬁnd the optimum solution . Take as a starting vector x 0 = ( 0 , 0 , 40 , 60 ) T . Ex . 8 . 9 In the ﬁrst example on the simplex method , the new value of x 2 became 40 . Explain why this was the case . Ex . 8 . 10 Redo the ﬁrst example of the simplex method , starting with the vertex x 1 = 0 and x 2 = 0 . Ex . 8 . 11 Consider the LP problem of maximizing the function f ( x 1 , x 2 ) = x 1 + 2 x 2 , subject to − 2 x 1 + x 2 ≤ 2 , − x 1 + 2 x 2 ≤ 7 , x 1 ≤ 3 , and x 1 ≥ 0 , x 2 ≥ 0 . Start at x 1 = 0 , x 2 = 0 . You will ﬁnd that you have a choice for the entering variable ; try it both ways . Ex . 8 . 12 Carry out the next two steps of the simplex algorithm for the second example given earlier . Ex . 8 . 13 Apply the simplex method to the problem of minimizing z = − x 1 − 2 x 2 , subject to − x 1 + x 2 ≤ 2 , − 2 x 1 + x 2 ≤ 1 , and x 1 ≥ 0 , x 2 ≥ 0 . 126 CHAPTER 8 . LINEAR PROGRAMMING 8 . 14 Course Homework Try Exercises 8 . 2 , 8 . 10 , 8 . 11 , and 8 . 12 . Chapter 9 Matrix Games and Optimization 9 . 1 Chapter Summary The theory of two - person games is largely the work of John von Neumann , and was developed somewhat later by von Neumann and Morgenstern [ 166 ] as a tool for economic analysis . Two - person zero - sum games provide a nice example of optimization and an opportunity to apply some of the linear algebra and linear programming tools previously discussed . In this chapter we introduce the idea of two - person matrix games and use results from linear programming to prove the Fundamental Theorem of Game Theory . Our focus here is on the mathematics ; the DVD course by Stevens [ 192 ] provides a less mathematical introduction to game theory , with numer - ous examples drawn from business and economics . The classic book by Schelling [ 183 ] describes the roles played by game theory in international politics and warfare . 9 . 2 Two - Person Zero - Sum Games A two - person game is called a constant - sum game if the total payout is the same , each time the game is played . In such cases , we can subtract half the total payout from the payout to each player and record only the diﬀerence . Then the total payout appears to be zero , and such games are called zero - sum games . We can then suppose that whatever one player wins is paid by the other player . Except for the ﬁnal section , we shall consider only two - person , zero - sum games . 127 128 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION 9 . 3 Deterministic Solutions In this two - person game , the ﬁrst player , call him P1 , selects a row of the I by J real matrix A , say i , and the second player selects a column of A , say j . The second player , call her P2 , pays the ﬁrst player A ij . If some A ij < 0 , then this means that the ﬁrst player pays the second . Since whatever the ﬁrst player wins , the second loses , and vice versa , we need only one matrix to summarize the situation . Note that , even though we label the players in order , their selections are made simultaneously and without knowledge of the other player’s selection . 9 . 3 . 1 Optimal Pure Strategies In our ﬁrst example , the matrix is A = (cid:20) 7 8 4 4 7 2 (cid:21) . ( 9 . 1 ) The ﬁrst player notes that by selecting row i = 1 , he will get at least 4 , regardless of which column the second player plays . The second player notes that , by playing column j = 3 , she will pay the ﬁrst player no more than 4 , regardless of which row the ﬁrst player plays . If the ﬁrst player then begins to play i = 1 repeatedly , and the second player notices this consistency , she will still have no motivation to play any column except j = 3 , because the other pay - outs are both worse than 4 . Similarly , so long as the second player is playing j = 3 repeatedly , the ﬁrst player has no motivation to play anything other than i = 1 , since he will be paid less if he switches . Therefore , both players adopt a pure strategy of i = 1 and j = 3 . This game is said to be deterministic and the entry A 1 , 3 = 4 is a saddle - point because it is the maximum of its column and the minimum of its row . Note that we can write A i , 3 ≤ A 1 , 3 ≤ A 1 , j , so once the two players play ( 1 , 3 ) neither has any motivation to change . For this reason the entry A 1 , 3 is called a Nash equilibrium . The value A 1 , 3 = 4 is the maximum of the minimum wins the ﬁrst player can have , and also the minimum of the maximum losses the second player can suﬀer . Not all such two - person games have saddle - points , however . 9 . 3 . 2 An Exercise Ex . 9 . 1 Show that , in this case , we have max i min j A ij = 4 = min j max i A ij . 9 . 4 . RANDOMIZED SOLUTIONS 129 9 . 4 Randomized Solutions When the game has no saddle point , there is no optimal deterministic solu - tion . Instead , we consider approaches that involve selecting our strategies according to some random procedure , and seek an optimal randomized strategy . 9 . 4 . 1 Optimal Randomized Strategies Consider now the two - person game with pay - oﬀ matrix A = (cid:20) 4 1 2 3 (cid:21) . ( 9 . 2 ) The ﬁrst player notes that by selecting row i = 2 , he will get at least 2 , regardless of which column the second player plays . The second player notes that , by playing column j = 2 , she will pay the ﬁrst player no more than 3 , regardless of which row the ﬁrst player plays . If both begin by playing in this conservative manner , the ﬁrst player will play i = 2 and the second player will play j = 2 . If the ﬁrst player plays i = 2 repeatedly , and the second player notices this consistency , she will be tempted to switch to playing column j = 1 , thereby losing only 2 , instead of 3 . If she makes the switch and the ﬁrst player notices , he will be motivated to switch his play to row i = 1 , to get a pay - oﬀ of 4 , instead of 2 . The second player will then soon switch to playing j = 2 again , hoping that the ﬁrst player sticks with i = 1 . But the ﬁrst player is not stupid , and quickly returns to playing i = 2 . There is no saddle - point in this game ; the maximum of the minimum wins the ﬁrst player can have is 2 , but the minimum of the maximum losses the second player can suﬀer is 3 . For such games , it makes sense for both players to select their play at random , with the ﬁrst player playing i = 1 with probability p and i = 2 with probability 1 − p , and the second player playing column j = 1 with probability q and j = 2 with probability 1 − q . These are called randomized strategies . When the ﬁrst player plays i = 1 , he expects to get 4 q + ( 1 − q ) = 3 q + 1 , and when he plays i = 2 he expects to get 2 q + 3 ( 1 − q ) = 3 − q . Note that 3 q + 1 = 3 − q when q = 0 . 5 , so if the second player plays q = 0 . 5 , then the second player will not care what the ﬁrst player does , since the expected payoﬀ to the ﬁrst player is 5 / 2 in either case . If the second player plays a diﬀerent q , then the payoﬀ to the ﬁrst player will depend on what the ﬁrst player does , and can be larger than 5 / 2 . Since the ﬁrst player plays i = 1 with probability p , he expects to get p ( 3 q + 1 ) + ( 1 − p ) ( 3 − q ) = 4 pq − 2 p − q + 3 = ( 4 p − 1 ) q + 3 − 2 p . 130 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION He notices that if he selects p = 14 , then he expects to get 52 , regardless of what the second player does . If he plays something other than p = 14 , his expected winnings will depend on what the second player does . If he selects a value of p less than 14 , and q = 1 is selected , then he wins 2 p + 2 , but this is less than 52 . If he selects p > 14 and q = 0 is selected , then he wins 3 − 2 p , which again is less than 52 . The maximum of these minimum pay - oﬀs occurs when p = 14 and the max - min win is 52 . Similarly , the second player , noticing that p ( 3 q + 1 ) + ( 1 − p ) ( 3 − q ) = ( 4 q − 2 ) p + 3 − q , sees that she will pay out 52 if she takes q = 12 . If she selects a value of q less than 12 , and p = 0 is selected , then she pays out 3 − q , which is more than 52 . If , on the other hand , she selects a value of q that is greater than 12 , and p = 1 is selected , then she will pay out 3 q + 1 , which again is greater than 5 2 . The only way she can be certain to pay out no more than 5 2 is to select q = 12 . The minimum of these maximum pay - outs occurs when she chooses q = 12 , and the min - max pay - out is 52 . The choices of p = 14 and q = 12 constitute a Nash equilibrium , because , once these choices are made , neither player has any reason to change strategies . This leads us to the question of whether or not there will always be probability vectors for the players that will lead to the equality of the max - min win and the min - max pay - out . Note that , in general , since A i , j is the payout to P1 when ( i , j ) is played , for i = 1 , . . . , I and j = 1 , . . . , J , and the probability that ( i , j ) will be played is p i q j , the expected payout to P1 is I (cid:88) i = 1 J (cid:88) j = 1 p i A i , j q j = p T Aq . ( 9 . 3 ) The probabilities ˆ p and ˆ q will be optimal randomized strategies if p T A ˆ q ≤ ˆ p T A ˆ q ≤ ˆ p T Aq , ( 9 . 4 ) for any probabilities p and q . Once again , we have a Nash equilibrium , since once the optimal strategies are the chosen ones , neither player has any motivation to adopt a diﬀerent randomized strategy . 9 . 4 . 2 An Exercise Ex . 9 . 2 Suppose that there are two strains of ﬂu virus and two types of vaccine . The ﬁrst vaccine , call it V1 , is 0 . 85 eﬀective against the ﬁrst strain ( F1 ) and 0 . 70 eﬀective against the second ( F2 ) , while the second vaccine ( V2 ) is 0 . 60 eﬀective against F1 and 0 . 90 eﬀective against F2 . The public health service is the ﬁrst player , P1 , and nature is the second player , P2 . 9 . 4 . RANDOMIZED SOLUTIONS 131 The service has to decide what percentage of the vaccines manufactured and made available to the public are to be of type V1 and what percentage are to be of type V2 , while not knowing what percentage of the ﬂu virus is F1 and what percentage is F2 . Set this up as a matrix game and determine how the public health service should proceed . 9 . 4 . 3 The Min - Max Theorem We make a notational change at this point . From now on the letters p and q will denote probability column vectors , and not individual probabilities , as previously . Let A be an I by J pay - oﬀ matrix . Let P = { p = ( p 1 , . . . , p I ) | p i ≥ 0 , I (cid:88) i = 1 p i = 1 } , Q = { q = ( q 1 , . . . , q J ) | q j ≥ 0 , J (cid:88) j = 1 q j = 1 } , and R = A ( Q ) = { Aq | q ∈ Q } . The ﬁrst player selects a vector p in P and the second selects a vector q in Q . The expected pay - oﬀ to the ﬁrst player is E = (cid:104) p , Aq (cid:105) = p T Aq . Let m 0 = max p ∈ P min r ∈ R (cid:104) p , r (cid:105) , and m 0 = min r ∈ R max p ∈ P (cid:104) p , r (cid:105) ; the interested reader may want to prove that the maximum and minimum exist . Clearly , we have min r ∈ R (cid:104) p , r (cid:105) ≤ (cid:104) p , r (cid:105) ≤ max p ∈ P (cid:104) p , r (cid:105) , for all p ∈ P and r ∈ R . It follows that m 0 ≤ m 0 . The Min - Max Theorem , also known as the Fundamental Theorem of Game Theory , asserts that m 0 = m 0 . Theorem 9 . 1 The Fundamental Theorem of Game Theory Let A be an arbitrary real I by J matrix . Then there are vectors ˆ p in P and ˆ q in Q such that p T A ˆ q ≤ ˆ p T A ˆ q ≤ ˆ p T Aq , ( 9 . 5 ) for all p in P and q in Q . 132 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION The quantity ω = ˆ p T A ˆ q is called the value of the game . Notice that if P1 knows that P2 plays according to the mixed - strategy vector q , P1 could examine the entries ( Aq ) i , which are his expected pay - oﬀs should he play strategy i , and select the one for which this expected pay - oﬀ is largest . However , if P2 notices what P1 is doing , she can abandon q to her advantage . When q = ˆ q , it follows , from the inequalities in ( 9 . 5 ) by using p with the i th entry equal to one and the rest zero , that ( A ˆ q ) i ≤ ω for all i , and ( A ˆ q ) i = ω for all i for which ˆ p i > 0 . So there is no long - term advantage to P1 to move away from ˆ p . There are a number of diﬀerent proofs of the Fundamental Theorem . In a later chapter , we present a proof using Fenchel Duality . In this chapter we consider proofs based on linear algebraic methods , linear programming , and theorems of the alternative . 9 . 5 Symmetric Games A game is said to be symmetric if the available strategies are the same for both players , and if the players switch strategies , the outcomes switch also . In other words , the pay - oﬀ matrix A is skew - symmetric , that is , A is square and A ji = − A ij . For symmetric games , we can use Theorem 6 . 12 to prove the existence of a randomized solution . First , we show that there is a probability vector ˆ p ≥ 0 such that ˆ p T A ≥ 0 . Then we show that p T A ˆ p ≤ 0 = ˆ p T A ˆ p ≤ ˆ p T Aq , for all probability vectors p and q . It will then follow that ˆ p and ˆ q = ˆ p are the optimal mixed strategies . If there is no non - zero x ≥ 0 such that x T A ≥ 0 , then there is no non - zero x ≥ 0 such that A T x ≥ 0 . Then , by Theorem 6 . 12 , we know that there is y ≥ 0 with Ay < 0 ; obviously y is not the zero vector , in this case . Since A T = − A , it follows that y T A > 0 . Consequently , there is a non - zero x ≥ 0 , such that x T A ≥ 0 ; it is x = y . This is a contradiction . So ˆ p exists . Since the game is symmetric , we have ˆ p T A ˆ p = ( ˆ p T A ˆ p ) T = ˆ p T A T ˆ p = − ˆ p T A ˆ p , so that ˆ p T A ˆ p = 0 . 9 . 6 . POSITIVE GAMES 133 For any probability vectors p and q we have p T A ˆ p = ˆ p T A T p = − ˆ p T Ap ≤ 0 , and 0 ≤ ˆ p T Aq . We conclude that the mixed strategies ˆ p and ˆ q = ˆ p are optimal . 9 . 5 . 1 An Example of a Symmetric Game We present now a simple example of a symmetric game and compute the optimal randomized strategies . Consider the pay - oﬀ matrix A = (cid:20) 0 1 − 1 0 (cid:21) . ( 9 . 6 ) This matrix is skew - symmetric , so the game is symmetric . Let ˆ p T = [ 1 , 0 ] ; then ˆ p T A = [ 0 , 1 ] ≥ 0 . We show that ˆ p and ˆ q = ˆ p are the optimal random - ized strategies . For any probability vectors p T = [ p 1 , p 2 ] and q T = [ q 1 , q 2 ] , we have p T A ˆ p = − p 2 ≤ 0 , ˆ p T A ˆ p = 0 , and ˆ p T Aq = q 2 ≥ 0 . It follows that the pair of strategies ˆ p = ˆ q = [ 1 , 0 ] T are optimal randomized strategies . 9 . 5 . 2 Comments on the Proof of the Min - Max Theo - rem In [ 115 ] , Gale proves the existence of optimal randomized solutions for an arbitrary matrix game by showing that there is associated with such a game a symmetric matrix game and that an optimal randomized solution exists for one if and only if such exists for the other . Another way is by converting the existing game into a “positive” game . 9 . 6 Positive Games As Gale notes in [ 115 ] , it is striking that two fundamental mathemati - cal tools in linear economic theory , linear programming and game theory , developed simultaneously , and independently , in the years following the 134 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION Second World War . More remarkable still was the realization that these two areas are closely related . Gale’s proof of the Min - Max Theorem , which relates the game to a linear programming problem and employs his Strong Duality Theorem , provides a good illustration of this close connection . If the I by J pay - oﬀ matrix A has only positive entries , we can use Gale’s Strong Duality Theorem 8 . 3 for linear programming to prove the Min - Max Theorem . Let b and c be the vectors whose entries are all one . Consider the LP problem of minimizing z = c T x , over all x ≥ 0 with A T x ≥ b ; this is the PC problem . The DC problem is then to maximize w = b T y , over all y ≥ 0 with Ay ≤ c . Since A has only positive entries , both PC and DC are feasible , so , by Gale’s Strong Duality Theorem 8 . 3 , we know that there are feasible non - negative vectors ˆ x and ˆ y and non - negative µ such that ˆ z = c T ˆ x = µ = b T ˆ y = ˆ w . Since ˆ x cannot be zero , µ must be positive . 9 . 6 . 1 Some Exercises Ex . 9 . 3 Show that the vectors ˆ p = 1 µ ˆ x and ˆ q = 1 µ ˆ y are probability vectors and are optimal randomized strategies for the matrix game . Ex . 9 . 4 Given an arbitrary I by J matrix A , there is α > 0 so that the matrix B with entries B ij = A ij + α has only positive entries . Show that any optimal randomized probability vectors for the game with pay - oﬀ matrix B are also optimal for the game with pay - oﬀ matrix A . It follows from these exercises that there exist optimal randomized so - lutions for any matrix game . 9 . 6 . 2 Comments This proof of the Min - Max Theorem shows that we can associate with a given matrix game a linear programming problem . It follows that we can use the simplex method to ﬁnd optimal randomized solutions for matrix games . It also suggests that a given linear programming problem can be associated with a matrix game ; see Gale [ 115 ] for more discussion of this point . 9 . 7 Example : The “Bluﬃng” Game In [ 115 ] Gale discusses several games , one of which he calls the “bluﬃng” game . For this game , there is a box containing two cards , marked HI and 9 . 7 . EXAMPLE : THE “BLUFFING” GAME 135 LO , respectively . Both players begin by placing their “ante” a > 0 , on the table . Player One , P1 , draws one of the two cards and looks at it ; Player Two , P2 , does not see it . Then P1 can either “fold” , losing his ante a > 0 to P2 , or “bet” b > a . Then P2 can either fold , losing her ante also to P1 , or “call” , and bet b also . If P2 calls , she wins if LO is on the card drawn , and P1 wins if it is HI . Since it makes no sense for P1 to fold when HI , his two strategies are • s1 : bet in both cases ; and • s2 : bet if HI and fold if LO . Strategy s1 is “bluﬃng” on the part of P1 , since he bets even when he knows the card shows LO . Player Two has the two strategies • t1 : call ; and • t2 : fold . When ( s1 , t1 ) is played , P1 wins the bet half the time , so his expected gain is zero . When ( s1 , t2 ) is played , P1 wins the ante a from P2 . When ( s2 , t1 ) is played , P1 bets half the time , winning each time , so gaining b , but loses his ante a half the time . His expected gain is then ( b − a ) / 2 . When ( s2 , t2 ) is played , P1 wins the ante from P2 half the time , and they exchange antes half the time . Therefore , P1 expects to win a / 2 . The payoﬀ matrix for P1 is then A = (cid:20) 0 a b − a 2 a 2 (cid:21) . ( 9 . 7 ) Note that if b ≤ 2 a , then the game has a saddle point , ( s2 , t1 ) , and the saddle value is b − a 2 . If b > 2 a , then the players need randomized strategies . Suppose P1 plays s1 with probability p and s2 with probability 1 − p , while P2 plays t1 with probability q and t2 with probability 1 − q . Then the expected gain for P1 is p ( 1 − q ) a + ( 1 − p ) ( q b − a 2 + ( 1 − q ) a 2 ) , which can be written as ( 1 + p ) a 2 + q ( ( 1 − p ) b 2 − a ) , and as a 2 + q ( b 2 − a ) + p ( a 2 − q b 2 ) . 136 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION If ( ( 1 − p ) b 2 − a ) = 0 , or p = 1 − 2 ab , then P1 expects to win a − a 2 b = 2 a b b − a 2 , regardless of what q is . Similarly , if ( a 2 − q b 2 ) = 0 , or q = ab , then P2 expects to pay out a − a 2 b , regardless of what p is . These are the optimal randomized strategies . If b ≤ 2 a , then P1 should never bluﬀ , and should always play s2 . Then P2 will always play t1 and P1 wins b − a 2 , on average . But when b is higher than 2 a , P2 would always play t2 , if P1 always plays s2 , in which case the payoﬀ would be only a 2 , which is lower than the expected payoﬀ when P1 plays optimally . It pays P1 to bluﬀ , because it forces P2 to play t1 some of the time . 9 . 8 Learning the Game In our earlier discussion we saw that the matrix game involving the pay - oﬀ matrix A = (cid:20) 4 1 2 3 (cid:21) ( 9 . 8 ) is not deterministic . The best thing the players can do is to select their play at random , with the ﬁrst player playing i = 1 with probability p and i = 2 with probability 1 − p , and the second player playing column j = 1 with probability q and j = 2 with probability 1 − q . If the ﬁrst player , call him P1 , selects p = 14 , then he expects to get 52 , regardless of what the second player , call her P2 , does ; otherwise his fortunes depend on what P2 does . His optimal mixed - strategy ( column ) vector is [ 1 / 4 , 3 / 4 ] T . Similarly , the second player notices that the only way she can be certain to pay out no more than 52 is to select q = 1 2 . The minimum of these maximum pay - outs occurs when she chooses q = 12 , and the min - max pay - out is 52 . Because the pay - oﬀ matrix is two - by - two , we are able to determine easily the optimal mixed - strategy vectors for each player . When the pay - oﬀ matrix is larger , ﬁnding the optimal mixed - strategy vectors is not a simple matter . As we have seen , one approach is to obtain these vectors by solving a related linear - programming problem . In this section we consider other approaches to ﬁnding the optimal mixed - strategy vectors . 9 . 9 . NON - CONSTANT - SUM GAMES 137 9 . 8 . 1 An Iterative Approach In [ 115 ] Gale presents an iterative approach to learning how best to play a matrix game . The assumptions are that the game is to be played repeatedly and that the two players adjust their play as they go along , based on the earlier plays of their opponent . Suppose , for the moment , that P1 knows that P2 is playing the ran - domized strategy q , where , as earlier , we denote by p and q probability column vectors . The entry ( Aq ) i of the column vector Aq is the expected pay - oﬀ to P1 if he plays strategy i . It makes sense for P1 then to ﬁnd the index i for which this expected pay - oﬀ is largest and to play that strategy every time . Of course , if P2 notices what P1 is doing , she will abandon q to her advantage . After the game has been played n times , the players can examine the previous plays and make estimates of what the opponent is doing . Suppose that P1 has played strategy i n i times , where n i ≥ 0 and n 1 + n 2 + . . . + n I = n . Denote by p n the probability column vector whose i th entry is n i / n . Similarly , calculate q n . These two probability vectors summarize the tendencies of the two players over the ﬁrst n plays . It seems reasonable that an attempt to learn the game would involve these probability vectors . For example , P1 could see which entry of q n is the largest , assume that P2 is most likely to play that strategy the next time , and play his best strategy against that play of P2 . However , if there are several strategies for P2 to choose , it is still unlikely that P2 will choose this strategy the next time . Perhaps P1 could do better by considering his long - run fortunes and examining the vector Aq n of expected pay - oﬀs . In the exercise below , you are asked to investigate this matter . 9 . 8 . 2 An Exercise Ex . 9 . 5 Suppose that both players are attempting to learn how best to play the game by examining the vectors p n and q n after n plays . Devise an algorithm for the players to follow that will lead to optimal mixed strategies for both . Simulate repeated play of a particular matrix game to see how your algorithm performs . If the algorithm does its job , but does it slowly , that is , it takes many plays of the game for it to begin to work , investigate how it might be speeded up . 9 . 9 Non - Constant - Sum Games In this ﬁnal section we consider non - constant - sum games . These are more complicated and the mathematical results more diﬃcult to obtain than in the constant - sum games . Such non - constant - sum games can be used to model situations in which the players may both gain by cooperation , or , 138 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION when speaking of economic actors , by collusion [ 99 ] . We begin with the most famous example of a non - constant - sum game , the Prisoners’ Dilemma . 9 . 9 . 1 The Prisoners’ Dilemma Imagine that you and your partner are arrested for robbing a bank and both of you are guilty . The two of you are held in separate rooms and given the following options by the district attorney : ( 1 ) if you confess , but your partner does not , you go free , while he gets three years in jail ; ( 2 ) if he confesses , but you do not , he goes free and you get the three years ; ( 3 ) if both of you confess , you each get two years ; ( 4 ) if neither of you confesses , each of you gets one year in jail . Let us call you player number one , and your partner player number two . Let strategy one be to remain silent , and strategy two be to confess . Your pay - oﬀ matrix is A = (cid:20) − 1 − 3 0 − 2 (cid:21) , ( 9 . 9 ) so that , for example , if you remain silent , while your partner confesses , your pay - oﬀ is A 1 , 2 = − 3 , where the negative sign is used because jail time is undesirable . From your perspective , the game has a deterministic solution ; you should confess , assuring yourself of no more than two years in jail . Your partner views the situation the same way and also should confess . However , when the game is viewed , not from one individual’s perspective , but from the perspective of the pair of you , we see that by sticking together you each get one year in jail , instead of each of you getting two years ; if you cooperate , you both do better . 9 . 9 . 2 Two Pay - Oﬀ Matrices Needed In the case of non - constant - sum games , one pay - oﬀ matrix is not enough to capture the full picture . Consider the following example of a non - constant - sum game . Let the matrix A = (cid:20) 5 4 3 6 (cid:21) ( 9 . 10 ) be the pay - oﬀ matrix for Player One ( P 1 ) , and B = (cid:20) 5 6 7 2 (cid:21) ( 9 . 11 ) be the pay - oﬀ matrix for Player Two ( P 2 ) ; that is , A 1 , 2 = 4 and B 2 , 1 = 7 means that if P 1 plays the ﬁrst strategy and P 2 plays the second strategy , 9 . 10 . COURSE HOMEWORK 139 then P 1 gains four and P 2 gains seven . Notice that the total pay - oﬀ for each play of the game is not constant , so we require two matrices , not one . Player One , considering only the pay - oﬀ matrix A , discovers that the best strategy is a randomized strategy , with the ﬁrst strategy played three quarters of the time . Then P 1 has expected gain of 92 . Similarly , Player Two , applying the same analysis to his pay - oﬀ matrix , B , discovers that he should also play a randomized strategy , playing the ﬁrst strategy ﬁve sixths of the time ; he then has an expected gain of 163 . However , if P 1 switches and plays the ﬁrst strategy all the time , while P 2 continues with his randomized strategy , P 1 expects to gain 296 > 276 , while the expected gain of P 2 is unchanged . This is very diﬀerent from what happens in the case of a constant - sum game ; there , the sum of the expected gains is constant , and equals zero for a zero - sum game , so P 1 would not be able to increase his expected gain , if P 2 plays his optimal randomized strategy . 9 . 9 . 3 An Example : Illegal Drugs in Sports In a recent article in Scientiﬁc American [ 187 ] , Michael Shermer uses the model of a non - constant - sum game to analyze the problem of doping , or illegal drug use , in sports , and to suggest a solution . He is a former com - petitive cyclist and his speciﬁc example comes from the Tour de France . He is the ﬁrst player , and his opponent the second player . The choices are to cheat by taking illegal drugs or to stay within the rules . The assumption he makes is that a cyclist who sticks to the rules will become less competitive and will be dropped from his team . Currently , the likelihood of getting caught is low , and the penalty for cheating is not too high , so , as he shows , the rational choice is for everyone to cheat , as well as for every cheater to lie . He proposes changing the pay - oﬀ matrices by increasing the likelihood of being caught , as well as the penalty for cheating , so as to make sticking to the rules the rational choice . 9 . 10 Course Homework Do all the exercises in this chapter . 140 CHAPTER 9 . MATRIX GAMES AND OPTIMIZATION Chapter 10 Convex Functions 10 . 1 Chapter Summary In this chapter we investigate further the properties of convex functions of one and several variables , in preparation for our discussion of iterative optimization algorithms . 10 . 2 Functions of a Single Real Variable We begin by recalling some of the basic results concerning functions of a single real variable . 10 . 2 . 1 Fundamental Theorems • The Intermediate Value Theorem ( IVT ) : Theorem 10 . 1 Let f ( x ) be continuous on the interval [ a , b ] . If d is between f ( a ) and f ( b ) , then there is c between a and b with f ( c ) = d . • Rolle’s Theorem : Theorem 10 . 2 Let f ( x ) be continuous on the closed interval [ a , b ] and diﬀerentiable on ( a , b ) , with f ( a ) = f ( b ) . Then , there is c in ( a , b ) with f (cid:48) ( c ) = 0 . • The Mean Value Theorem ( MVT ) : Theorem 10 . 3 Let f ( x ) be continuous on the closed interval [ a , b ] and diﬀerentiable on ( a , b ) . Then , there is c in ( a , b ) with f ( b ) − f ( a ) = f (cid:48) ( c ) ( b − a ) . 141 142 CHAPTER 10 . CONVEX FUNCTIONS • A MVT for Integrals : Theorem 10 . 4 Let g ( x ) be continuous and h ( x ) integrable with con - stant sign on the interval [ a , b ] . Then there is c in ( a , b ) such that (cid:90) b a g ( x ) h ( x ) dx = g ( c ) (cid:90) b a h ( x ) dx . • The Extended Mean Value Theorem ( EMVT ) : Theorem 10 . 5 Let f ( x ) be twice diﬀerentiable on the interval ( u , v ) and let a and b be in ( u , v ) . Then there is c between a and b with f ( b ) = f ( a ) + f (cid:48) ( a ) ( b − a ) + 1 2 f (cid:48)(cid:48) ( c ) ( b − a ) 2 . If f ( x ) is a function with f (cid:48)(cid:48) ( x ) > 0 for all x and f (cid:48) ( a ) = 0 , then , from the EMVT , we know that f ( b ) > f ( a ) , unless b = a , so that x = a is a global minimizer of the function f ( x ) . As we shall see , such functions are strictly convex . 10 . 2 . 2 Proof of Rolle’s Theorem The IVT is a direct consequence of the completeness of R . To prove Rolle’s Theorem , we simply note that either f is constant , in which case f (cid:48) ( x ) = 0 for all x in ( a , b ) , or it has a local maximum or minimum at c in ( a , b ) , in which case f (cid:48) ( c ) = 0 . 10 . 2 . 3 Proof of the Mean Value Theorem The main use of Rolle’s Theorem is to prove the Mean Value Theorem . Let g ( x ) = f ( x ) − (cid:16) f ( b ) − f ( a ) b − a (cid:17) ( x − a ) . Then g ( a ) = g ( b ) and so there is c ∈ ( a , b ) with g (cid:48) ( c ) = 0 , or f ( b ) − f ( a ) = f (cid:48) ( c ) ( b − a ) . 10 . 2 . 4 A Proof of the MVT for Integrals We now prove the Mean Value Theorem for Integrals . Since g ( x ) is con - tinuous on the interval [ a , b ] , it takes on its minimum value , say m , and its maximum value , say M , and , by the Intermediate Value Theorem , g ( x ) 10 . 2 . FUNCTIONS OF A SINGLE REAL VARIABLE 143 also takes on any value in the interval [ m , M ] . Assume , without loss of gen - erality , that h ( x ) ≥ 0 , for all x in the interval [ a , b ] , so that (cid:82) b a h ( x ) dx ≥ 0 . Then we have m (cid:90) b a h ( x ) dx ≤ (cid:90) b a g ( x ) h ( x ) dx ≤ M (cid:90) b a h ( x ) dx , which says that the ratio (cid:82) b a g ( x ) h ( x ) dx (cid:82) b a h ( x ) dx lies in the interval [ m , M ] . Consequently , there is a value c in ( a , b ) for which g ( c ) has the value of this ratio . This completes the proof . 10 . 2 . 5 Two Proofs of the EMVT Now we present two proofs of the EMVT . We begin by using integration by parts , with u ( x ) = f (cid:48) ( x ) and v ( x ) = x − b , to get f ( b ) − f ( a ) = (cid:90) b a f (cid:48) ( x ) dx = f (cid:48) ( x ) ( x − b ) | ba − (cid:90) b a f (cid:48)(cid:48) ( x ) ( x − b ) dx , or f ( b ) − f ( a ) = − f (cid:48) ( a ) ( a − b ) − (cid:90) b a f (cid:48)(cid:48) ( x ) ( x − b ) dx . Then , using the MVT for integrals , with g ( x ) = f (cid:48)(cid:48) ( x ) assumed to be continuous , and h ( x ) = x − b , we have f ( b ) = f ( a ) + f (cid:48) ( a ) ( b − a ) − f (cid:48)(cid:48) ( c ) (cid:90) b a ( x − b ) dx , from which the assertion of the theorem follows immediately . A second proof of the EMVT , which does not require that f (cid:48)(cid:48) ( x ) be continuous , is as follows . Let a and b be ﬁxed and set F ( x ) = f ( x ) + f (cid:48) ( x ) ( b − x ) + A ( b − x ) 2 , for some constant A to be determined . Then F ( b ) = f ( b ) . Select A so that F ( a ) = f ( b ) . Then F ( b ) = F ( a ) , so there is c in ( a , b ) with F (cid:48) ( c ) = 0 , by the MVT , or , more simply , from Rolle’s Theorem . Therefore , 0 = F (cid:48) ( c ) = f (cid:48) ( c ) + f (cid:48)(cid:48) ( c ) ( b − c ) + f (cid:48) ( c ) ( − 1 ) − 2 A ( b − c ) = ( f (cid:48)(cid:48) ( c ) − 2 A ) ( b − c ) . So A = 12 f (cid:48)(cid:48) ( c ) and F ( x ) = f ( x ) + f (cid:48) ( x ) ( b − x ) + 1 2 f (cid:48)(cid:48) ( c ) ( b − x ) 2 , 144 CHAPTER 10 . CONVEX FUNCTIONS from which we get F ( a ) = f ( b ) = f ( a ) + f (cid:48) ( a ) ( b − a ) + 1 2 f (cid:48)(cid:48) ( c ) ( b − a ) 2 . This completes the second proof . 10 . 2 . 6 Lipschitz Continuity Let f : R → R be a diﬀerentiable function . From the Mean - Value Theorem we know that f ( b ) = f ( a ) + f (cid:48) ( c ) ( b − a ) , ( 10 . 1 ) for some c between a and b . If there is a constant L with | f (cid:48) ( x ) | ≤ L for all x , that is , the derivative is bounded , then we have | f ( b ) − f ( a ) | ≤ L | b − a | , ( 10 . 2 ) for all a and b ; functions that satisfy Equation ( 10 . 2 ) are said to be L - Lipschitz continuous . 10 . 2 . 7 The Convex Case We focus now on the special case of convex functions . Earlier , we said that a proper function g : R → ( −∞ , ∞ ] is convex if its epi - graph is a convex set , in which case the eﬀective domain of the function g must be a convex set , since it is the orthogonal projection of the convex epi - graph . For a real - valued function g deﬁned on the whole real line we have several conditions on g that are equivalent to being a convex function . Proposition 10 . 1 Let f : R → R . The following are equivalent : • 1 ) the epi - graph of g ( x ) is convex ; • 2 ) for all points a < x < b in R g ( x ) ≤ g ( b ) − g ( a ) b − a ( x − a ) + g ( a ) ; ( 10 . 3 ) • 3 ) for all points a < x < b in R g ( x ) ≤ g ( b ) − g ( a ) b − a ( x − b ) + g ( b ) ; ( 10 . 4 ) • 4 ) for all points a and b in R and for all α in the interval ( 0 , 1 ) g ( ( 1 − α ) a + αb ) ≤ ( 1 − α ) g ( a ) + αg ( b ) . ( 10 . 5 ) 10 . 2 . FUNCTIONS OF A SINGLE REAL VARIABLE 145 The proof of Proposition 10 . 1 is left as an exercise . As a result of Proposition 10 . 1 , we can use the following deﬁnition of a convex real - valued function . Deﬁnition 10 . 1 A function g : R → R is called convex if , for each pair of distinct real numbers a and b , the line segment connecting the two points A = ( a , g ( a ) ) and B = ( b , g ( b ) ) is on or above the graph of g ( x ) ; that is , for every α in ( 0 , 1 ) , g ( ( 1 − α ) a + αb ) ≤ ( 1 − α ) g ( a ) + αg ( b ) . If the inequality is always strict , then g ( x ) is strictly convex . The function g ( x ) = x 2 is a simple example of a convex function . If g ( x ) is convex , then g ( x ) is continuous , as well ( [ 175 ] , p . 47 ) . It follows from Proposition 10 . 1 that , if g ( x ) is convex , then , for every triple of points a < x < b , we have g ( x ) − g ( a ) x − a ≤ g ( b ) − g ( a ) b − a ≤ g ( b ) − g ( x ) b − x . ( 10 . 6 ) Therefore , for ﬁxed a , the ratio g ( x ) − g ( a ) x − a is an increasing function of x , and , for ﬁxed b , the ratio g ( b ) − g ( x ) b − x is an increasing function of x . If we allow g to take on the value + ∞ , then we say that g is convex if and only if , for all points a and b in R and for all α in the interval ( 0 , 1 ) , g ( ( 1 − α ) a + αb ) ≤ ( 1 − α ) g ( a ) + αg ( b ) . ( 10 . 7 ) If g ( x ) is a diﬀerentiable function , then convexity can be expressed in terms of properties of the derivative , g (cid:48) ( x ) ; for every triple of points a < x < b , we have g (cid:48) ( a ) ≤ g ( b ) − g ( a ) b − a ≤ g (cid:48) ( b ) . ( 10 . 8 ) If g ( x ) is diﬀerentiable and convex , then g (cid:48) ( x ) is an increasing function . In fact , the converse is also true , as we shall see shortly . Recall that the line tangent to the graph of g ( x ) at the point x = a has the equation y = g (cid:48) ( a ) ( x − a ) + g ( a ) . ( 10 . 9 ) 146 CHAPTER 10 . CONVEX FUNCTIONS Theorem 10 . 6 For the diﬀerentiable function g ( x ) , the following are equiv - alent : • 1 ) g ( x ) is convex ; • 2 ) for all a and x we have g ( x ) ≥ g ( a ) + g (cid:48) ( a ) ( x − a ) ; ( 10 . 10 ) • 3 ) the derivative , g (cid:48) ( x ) , is an increasing function , or , equivalently , ( g (cid:48) ( x ) − g (cid:48) ( a ) ) ( x − a ) ≥ 0 , ( 10 . 11 ) for all a and x . Proof : Assume that g ( x ) is convex . If x > a , then g (cid:48) ( a ) ≤ g ( x ) − g ( a ) x − a , ( 10 . 12 ) while , if x < a , then g ( a ) − g ( x ) a − x ≤ g (cid:48) ( a ) . ( 10 . 13 ) In either case , the inequality in ( 10 . 10 ) holds . Now , assume that the in - equality in ( 10 . 10 ) holds . Then g ( x ) ≥ g (cid:48) ( a ) ( x − a ) + g ( a ) , ( 10 . 14 ) and g ( a ) ≥ g (cid:48) ( x ) ( a − x ) + g ( x ) . ( 10 . 15 ) Adding the two inequalities , we obtain g ( a ) + g ( x ) ≥ ( g (cid:48) ( x ) − g (cid:48) ( a ) ) ( a − x ) + g ( a ) + g ( x ) , ( 10 . 16 ) from which we conclude that ( g (cid:48) ( x ) − g (cid:48) ( a ) ) ( x − a ) ≥ 0 . ( 10 . 17 ) So g (cid:48) ( x ) is increasing . Finally , we assume the derivative is increasing and show that g ( x ) is convex . If g ( x ) is not convex , then there are points a < b such that , for all x in ( a , b ) , g ( x ) − g ( a ) x − a > g ( b ) − g ( a ) b − a . ( 10 . 18 ) 10 . 2 . FUNCTIONS OF A SINGLE REAL VARIABLE 147 By the Mean Value Theorem there is c in ( a , b ) with g (cid:48) ( c ) = g ( b ) − g ( a ) b − a . ( 10 . 19 ) Select x in the interval ( a , c ) . Then there is d in ( a , x ) with g (cid:48) ( d ) = g ( x ) − g ( a ) x − a . ( 10 . 20 ) Then g (cid:48) ( d ) > g (cid:48) ( c ) , which contradicts the assumption that g (cid:48) ( x ) is increas - ing . This concludes the proof . If g ( x ) is twice diﬀerentiable , we can say more . If we multiply both sides of the inequality in ( 10 . 17 ) by ( x − a ) − 2 , we ﬁnd that g (cid:48) ( x ) − g (cid:48) ( a ) x − a ≥ 0 , ( 10 . 21 ) for all x and a . This inequality suggests the following theorem . Theorem 10 . 7 If g ( x ) is twice diﬀerentiable , then g ( x ) is convex if and only if g (cid:48)(cid:48) ( x ) ≥ 0 , for all x . Proof : According to the Mean Value Theorem , as applied to the function g (cid:48) ( x ) , for any points a < b there is c in ( a , b ) with g (cid:48) ( b ) − g (cid:48) ( a ) = g (cid:48)(cid:48) ( c ) ( b − a ) . If g (cid:48)(cid:48) ( x ) ≥ 0 , the right side of this equation is nonnegative , so the left side is also . Now assume that g ( x ) is convex , which implies that g (cid:48) ( x ) is an increasing function . Since g (cid:48) ( x + h ) − g (cid:48) ( x ) ≥ 0 for all h > 0 , it follows that g (cid:48)(cid:48) ( x ) ≥ 0 . The following result , as well as its extension to higher dimensions , will be helpful in our study of iterative optimization . Theorem 10 . 8 Let h ( x ) be convex and diﬀerentiable and its derivative , h (cid:48) ( x ) , non - expansive , that is , | h (cid:48) ( b ) − h (cid:48) ( a ) | ≤ | b − a | , ( 10 . 22 ) for all a and b . Then h (cid:48) ( x ) is ﬁrmly non - expansive , which means that ( h (cid:48) ( b ) − h (cid:48) ( a ) ) ( b − a ) ≥ ( h (cid:48) ( b ) − h (cid:48) ( a ) ) 2 . ( 10 . 23 ) Proof : Assume that h (cid:48) ( b ) − h (cid:48) ( a ) (cid:54) = 0 , since the alternative case is trivial . If h (cid:48) ( x ) is non - expansive , then the inequality in ( 10 . 21 ) tells us that 0 ≤ h (cid:48) ( b ) − h (cid:48) ( a ) b − a ≤ 1 , 148 CHAPTER 10 . CONVEX FUNCTIONS so that b − a h (cid:48) ( b ) − h (cid:48) ( a ) ≥ 1 . Now multiply both sides by ( h (cid:48) ( b ) − h (cid:48) ( a ) ) 2 . In the next section we extend these results to functions of several vari - ables . 10 . 3 Functions of Several Real Variables In this section we consider the continuity and diﬀerentiability of a function of several variables . For more details , see the chapter on diﬀerentiability . 10 . 3 . 1 Continuity In addition to real - valued functions f : R N → R , we shall also be interested in vector - valued functions F : R N → R M , such as F ( x ) = ∇ f ( x ) , whose range is in R N , not in R . Deﬁnition 10 . 2 We say that F : R N → R M is continuous at x = a if lim x → a f ( x ) = f ( a ) ; that is , (cid:107) f ( x ) − f ( a ) (cid:107) 2 → 0 , as (cid:107) x − a (cid:107) 2 → 0 . Deﬁnition 10 . 3 We say that F : R N → R M is L - Lipschitz , or an L - Lipschitz continuous function , with respect to the 2 - norm , if there is L > 0 such that (cid:107) F ( b ) − F ( a ) (cid:107) 2 ≤ L (cid:107) b − a (cid:107) 2 , ( 10 . 24 ) for all a and b in R N . 10 . 3 . 2 Diﬀerentiability Let F : D ⊆ R N → R M be a R M - valued function of N real variables , deﬁned on domain D with nonempty interior int ( D ) . Deﬁnition 10 . 4 The function F ( x ) is said to be ( Frechet ) diﬀerentiable at point x 0 in int ( D ) if there is an M by N matrix F (cid:48) ( x 0 ) such that lim h → 0 1 | | h | | 2 [ F ( x 0 + h ) − F ( x 0 ) − F (cid:48) ( x 0 ) h ] = 0 . ( 10 . 25 ) 10 . 3 . FUNCTIONS OF SEVERAL REAL VARIABLES 149 It can be shown that , if F is diﬀerentiable at x = x 0 , then F is continuous there as well [ 114 ] . If f : R J → R is diﬀerentiable , then f (cid:48) ( x 0 ) = ∇ f ( x 0 ) , the gradient of f at x 0 . The function f ( x ) is diﬀerentiable if each of its ﬁrst partial derivatives is continuous . If f is ﬁnite and convex and diﬀerentiable on an open convex set C , then ∇ f is continuous on C ( [ 181 ] , Corollary 25 . 5 . 1 ) . If the derivative f (cid:48) : R J → R J is , itself , diﬀerentiable , then f (cid:48)(cid:48) : R J → R J × J , and f (cid:48)(cid:48) ( x ) = H ( x ) = ∇ 2 f ( x ) , the Hessian matrix whose entries are the second partial derivatives of f . The function f ( x ) will be twice diﬀerentiable if each of the second partial derivatives is continuous . In that case , the mixed second partial derivatives are independent of the order of the variables , the Hessian matrix is symmetric , and the chain rule applies . Let f : R J → R be a diﬀerentiable function . The Mean - Value Theorem for f is the following . Theorem 10 . 9 ( The Mean Value Theorem ) For any two points a and b in R J , there is α in ( 0 , 1 ) such that f ( b ) = f ( a ) + (cid:104)∇ f ( ( 1 − α ) a + αb ) , b − a (cid:105) . ( 10 . 26 ) Proof : To prove this , we parameterize the line segment between the points a and b as x ( t ) = a + t ( b − a ) . Then we deﬁne g ( t ) = f ( x ( t ) ) . We can apply the ordinary mean value theorem to g ( t ) , to get g ( 1 ) = g ( 0 ) + g (cid:48) ( α ) , ( 10 . 27 ) for some α in the interval [ 0 , 1 ] . The derivative of g ( t ) is g (cid:48) ( t ) = (cid:104)∇ f ( x ( t ) ) , b − a (cid:105) , ( 10 . 28 ) where ∇ f ( x ( t ) ) = ( ∂f ∂x 1 ( x ( t ) ) , . . . , ∂f ∂x J ( x ( t ) ) ) . ( 10 . 29 ) Therefore , g (cid:48) ( α ) = (cid:104)∇ f ( x ( α ) , b − a (cid:105) . ( 10 . 30 ) Since x ( α ) = ( 1 − α ) a + αb , the proof is complete . If there is a constant L with | | ∇ f ( x ) | | 2 ≤ L for all x , that is , the gradient is bounded in norm , then we have | f ( b ) − f ( a ) | ≤ L | | b − a | | 2 , ( 10 . 31 ) for all a and b ; such functions are then L - Lipschitz continuous . We can study multivariate functions f : R J → R by using them to construct func - tions of a single real variable , given by φ ( t ) = f ( x 0 + t ( x − x 0 ) ) , 150 CHAPTER 10 . CONVEX FUNCTIONS where x and x 0 are ﬁxed ( column ) vectors in R J . If f ( x ) is diﬀerentiable , then φ (cid:48) ( t ) = (cid:104)∇ f ( x 0 + t ( x − x 0 ) ) , x − x 0 (cid:105) . If f ( x ) is twice continuously diﬀerentiable , then φ (cid:48)(cid:48) ( t ) = ( x − x 0 ) T ∇ 2 f ( x 0 + t ( x − x 0 ) ) ( x − x 0 ) . Deﬁnition 10 . 5 A function f : R J → R is called coercive if lim (cid:107) x (cid:107) 2 → + ∞ f ( x ) (cid:107) x (cid:107) 2 = + ∞ . We have the following proposition , whose proof is left as Exercise 10 . 3 . Proposition 10 . 2 Let f : R J → R be a coercive diﬀerentiable function . Then the gradient operator ∇ f : R J → R J is onto R J . For example , the function f : R → R given by f ( x ) = 1 2 x 2 satisﬁes the conditions of the proposition and its derivative is f (cid:48) ( x ) = x , whose range is all of R . In contrast , the function g ( x ) = 13 x 3 is not coercive and its derivative , g (cid:48) ( x ) = x 2 , does not have all of R for its range . 10 . 3 . 3 Second Diﬀerentiability Suppose , throughout this subsection , that f : R J → R has continuous second partial derivatives . Then H ( x ) = ∇ 2 f ( x ) , the Hessian matrix of f at the point x , has for its entries the second partial derivatives of f at x , and is symmetric . The following theorems are fundamental in describing local maxima and minima of f . Theorem 10 . 10 Suppose that x and x ∗ are points in R J . Then there is a point z on the line segment [ x ∗ , x ] connecting x with x ∗ such that f ( x ) = f ( x ∗ ) + ∇ f ( x ∗ ) · ( x − x ∗ ) + 1 2 ( x − x ∗ ) · H ( z ) ( x − x ∗ ) . Theorem 10 . 11 Suppose now that x ∗ is a critical point , that is , ∇ f ( x ∗ ) = 0 . Then • 1 ) x ∗ is a global minimizer of f ( x ) if ( x − x ∗ ) · H ( z ) ( x − x ∗ ) ≥ 0 for all x and for all z in [ x ∗ , x ] ; • 2 ) x ∗ is a strict global minimizer of f ( x ) if ( x − x ∗ ) · H ( z ) ( x − x ∗ ) > 0 for all x (cid:54) = x ∗ and for all z in [ x ∗ , x ] ; • 3 ) x ∗ is a global maximizer of f ( x ) if ( x − x ∗ ) · H ( z ) ( x − x ∗ ) ≤ 0 for all x and for all z in [ x ∗ , x ] ; • 4 ) x ∗ is a strict global maximizer of f ( x ) if ( x − x ∗ ) · H ( z ) ( x − x ∗ ) < 0 for all x (cid:54) = x ∗ and for all z in [ x ∗ , x ] . 10 . 3 . FUNCTIONS OF SEVERAL REAL VARIABLES 151 10 . 3 . 4 Finding Maxima and Minima Suppose g : R J → R is diﬀerentiable and attains its minimum value . We want to minimize the function g ( x ) . Solving ∇ g ( x ) = 0 to ﬁnd the optimal x = x ∗ may not be easy , so we may turn to an iterative algorithm for ﬁnding roots of ∇ g ( x ) , or one that minimizes g ( x ) directly . In the latter case , we may again consider a steepest descent algorithm of the form x k + 1 = x k − γ ∇ g ( x k ) , ( 10 . 32 ) for some γ > 0 . We denote by T the operator Tx = x − γ ∇ g ( x ) . ( 10 . 33 ) Then , using ∇ g ( x ∗ ) = 0 , we ﬁnd that | | x ∗ − x k + 1 | | 2 = | | Tx ∗ − Tx k | | 2 . ( 10 . 34 ) We would like to know if there are choices for γ that imply convergence of the iterative sequence . As in the case of functions of a single variable , for functions g ( x ) that are convex , the answer is yes . 10 . 3 . 5 Solving F ( x ) = 0 through Optimization Suppose that f ( x ) : R N → R is strictly convex and has a unique global minimum at ˆ x . If F ( x ) = ∇ f ( x ) for all x , then F ( ˆ x ) = 0 . In some cases it may be simpler to minimize the function f ( x ) than to solve for a zero of F ( x ) . If F ( x ) is not a gradient of any function f ( x ) , we may still be able to ﬁnd a zero of F ( x ) by minimizing some function . For example , let g ( x ) = (cid:107) x (cid:107) 2 . Then the function f ( x ) = g ( F ( x ) ) is minimized when F ( x ) = 0 . The function F ( x ) = Ax − b need not have a zero . In such cases , we can minimize the function f ( x ) = 12 (cid:107) Ax − b (cid:107) 22 to obtain the least - squares solution , which then can be viewed as an approximate zero of F ( x ) . 10 . 3 . 6 When is F ( x ) a Gradient ? The following theorem is classical and extends the familiar “test for exact - ness” ; see Ortega and Rheinboldt [ 173 ] . Theorem 10 . 12 Let F : D ⊆ R N → R N be continuously diﬀerentiable on an open convex set D 0 ⊆ D . Then there is a diﬀerentiable function f : D 0 → R N such that F ( x ) = ∇ f ( x ) for all x in D 0 if and only if the derivative F (cid:48) ( x ) is symmetric , where F (cid:48) ( x ) is the N by N Jacobian matrix with entries ( F (cid:48) ( x ) ) mn = ∂F m ( x ) ∂x n , 152 CHAPTER 10 . CONVEX FUNCTIONS and F ( x ) = ( F 1 ( x ) , F 2 ( x ) , . . . , F N ( x ) ) . Proof : If F ( x ) = ∇ f ( x ) for all x in D 0 and is continuously diﬀerentiable , then the second partial derivatives of f ( x ) are continuous , so that the mixed second partial derivatives of f ( x ) are independent of the order of diﬀerentiation . In other words , the matrix F (cid:48) ( x ) is symmetric , where now F (cid:48) ( x ) is the Hessian matrix of f ( x ) . For notational convenience , we present the proof of the converse only for the case of N = 3 ; the proof is the same in general . The proof in [ 173 ] is somewhat diﬀerent . Without loss of generality , we assume that the origin is a member of the set D 0 . Deﬁne f ( x , y , z ) by f ( x , y , z ) = (cid:90) x 0 F 1 ( u , 0 , 0 ) du + (cid:90) y 0 F 2 ( x , u , 0 ) du + (cid:90) z 0 F 3 ( x , y , u ) du . We prove that ∂f∂x ( x , y , z ) = F 1 ( x , y , z ) . The partial derivative of the ﬁrst integral , with respect to x , is F 1 ( x , 0 , 0 ) . The partial derivative of the second integral , with respect to x , obtained by diﬀerentiating under the integral sign , is (cid:90) y 0 ∂F 2 ∂x ( x , u , 0 ) du , which , by the symmetry of the Jacobian matrix , is (cid:90) y 0 ∂F 1 ∂y ( x , u , 0 ) du = F 1 ( x , y , 0 ) − F 1 ( x , 0 , 0 ) . The partial derivative of the third integral , with respect to x , obtained by diﬀerentiating under the integral sign , is (cid:90) z 0 ∂F 3 ∂x ( x , y , u ) du , which , by the symmetry of the Jacobian matrix , is (cid:90) z 0 ∂F 1 ∂z ( x , y , u ) du = F 1 ( x , y , z ) − F 1 ( x , y , 0 ) . We complete the proof by adding these three integral values . Similar cal - culations show that ∇ f ( x ) = F ( x ) . 10 . 3 . 7 Lower Semi - Continuity We begin with a deﬁnition . 10 . 3 . FUNCTIONS OF SEVERAL REAL VARIABLES 153 Deﬁnition 10 . 6 A proper function f from R J to ( −∞ , ∞ ] is lower semi - continuous if f ( x ) = lim inf f ( y ) , as y → x . The following theorem shows the importance of lower semi - continuity . Theorem 10 . 13 ( [ 181 ] , Theorem 7 . 1 ) Let f be an arbitrary proper function from R J to ( −∞ , ∞ ] . Then the following conditions are equiv - alent : • 1 ) f is lower semi - continuous throughout R J ; • 2 ) for every real α , the set { x | f ( x ) ≤ α } is closed ; • 3 ) the epi - graph of f ( x ) is closed . As an example , consider the function f ( x ) deﬁned for − 1 ≤ x < 0 by f ( x ) = − x − 1 , and for 0 < x ≤ 1 by f ( x ) = − x + 1 . If we deﬁne f ( 0 ) = − 1 , then f ( x ) becomes lower semi - continuous at x = 0 and the epi - graph becomes closed . If we deﬁne f ( 0 ) = 1 , the function is upper semi - continuous at x = 0 , but is no longer lower semi - continuous there ; its epi - graph is no longer closed . It is helpful to recall the following theorem : Theorem 10 . 14 Let f : R J → R be LSC and let C ⊆ R J be non - empty , closed , and bounded . Then there is a in C with f ( a ) ≤ f ( x ) , for all x in C . 10 . 3 . 8 The Convex Case We begin with some deﬁnitions . Deﬁnition 10 . 7 The proper function g ( x ) : R J → ( −∞ , ∞ ] is said to be convex if , for each pair of distinct vectors a and b and for every α in the interval ( 0 , 1 ) we have g ( ( 1 − α ) a + αb ) ≤ ( 1 − α ) g ( a ) + αg ( b ) . ( 10 . 35 ) If the inequality is always strict , then g ( x ) is called strictly convex . The function g ( x ) is convex if and only if , for every x and z in R J and real t , the function f ( t ) = g ( x + tz ) is a convex function of t . Therefore , the theorems for the multi - variable case can also be obtained from previous results for the single - variable case . Deﬁnition 10 . 8 A proper convex function g is closed if it is lower semi - continuous . A proper convex function g is closed if and only if its epigraph is a closed set . 154 CHAPTER 10 . CONVEX FUNCTIONS Deﬁnition 10 . 9 The closure of a proper convex function g is the function cl g deﬁned by cl g ( x ) = lim inf y → x g ( y ) . The function cl g is convex and lower semi - continuous and agrees with g , except perhaps at points of the relative boundary of dom ( g ) . The epigraph of cl g is the closure of the epigraph of g . If g is convex and ﬁnite on an open subset of dom ( g ) , then g is contin - uous there , as well ( [ 181 ] ) . In particular , we have the following theorem . Theorem 10 . 15 Let g : R J → R be convex and ﬁnite - valued on R J . Then g is continuous . Let ι C ( x ) be the indicator function of the closed convex set C , that is , ι C ( x ) = (cid:40) 0 , if x ∈ C ; + ∞ , if x / ∈ C . This function is lower semi - continuous , convex , but not continuous at points on the boundary of C . If we had deﬁned ι C ( x ) to be , say , 1 , for x not in C , then the function would have been lower semi - continuous , and ﬁnite everywhere , but would no longer be convex . As in the case of functions of a single real variable , we have several equivalent notions of convexity for diﬀerentiable functions of more than one variable . Theorem 10 . 16 Let g : R J → R be diﬀerentiable . The following are equivalent : • 1 ) g ( x ) is convex ; • 2 ) for all a and b we have g ( b ) ≥ g ( a ) + (cid:104)∇ g ( a ) , b − a (cid:105) ; ( 10 . 36 ) • 3 ) for all a and b we have (cid:104)∇ g ( b ) − ∇ g ( a ) , b − a (cid:105) ≥ 0 . ( 10 . 37 ) Corollary 10 . 1 The function g ( x ) = 12 (cid:16) (cid:107) x (cid:107) 22 − (cid:107) x − P C x (cid:107) 22 (cid:17) is convex . Proof : We show later in Corollary 13 . 1 that the gradient of g ( x ) is ∇ g ( x ) = P C x . From the inequality ( 6 . 25 ) we know that (cid:104) P C x − P C y , x − y (cid:105) ≥ 0 , for all x and y . Therefore , g ( x ) is convex , by Theorem 10 . 16 . 10 . 4 . SUB - DIFFERENTIALS AND SUB - GRADIENTS 155 Deﬁnition 10 . 10 Let g : R J → R be convex and diﬀerentiable . Then the Bregman distance , from x to y , associated with g is D g ( x , y ) = g ( x ) − g ( y ) − (cid:104)∇ g ( y ) , x − y (cid:105) . ( 10 . 38 ) Since g is convex , Theorem 10 . 16 tells us that D g ( x , y ) ≥ 0 , for all x and y . Also , for each ﬁxed y , the function d ( x ) = D g ( x , y ) is g ( x ) plus a linear function of x ; therefore , d ( x ) is also convex . If we impose additional restrictions on g , then we can endow D g ( x , y ) with additional properties usually associated with a distance measure ; for example , if g is strictly convex , then D g ( x , y ) = 0 if and only if x = y . As in the case of functions of a single variable , we can say more when the function g ( x ) is twice diﬀerentiable . To guarantee that the second deriva - tive matrix is symmetric , we assume that the second partial derivatives are continuous . Note that , by the chain rule again , f (cid:48)(cid:48) ( t ) = z T ∇ 2 g ( x + tz ) z . Theorem 10 . 17 Let each of the second partial derivatives of g ( x ) be con - tinuous , so that g ( x ) is twice continuously diﬀerentiable . Then g ( x ) is convex if and only if the second derivative matrix ∇ 2 g ( x ) is non - negative deﬁnite , for each x . 10 . 4 Sub - Diﬀerentials and Sub - Gradients The following proposition describes the relationship between hyperplanes supporting the epigraph of a diﬀerentiable function and its gradient . The proof is left as Exercise 10 . 5 . Proposition 10 . 3 Let g : R J → R be a convex function that is diﬀeren - tiable at the point x 0 . Then there is a unique hyperplane H supporting the epigraph of g at the point ( x 0 , g ( x 0 ) ) and H can be written as H = { z ∈ R J + 1 | (cid:104) a , z (cid:105) = γ } , for a T = ( ∇ g ( x 0 ) T , − 1 ) and γ = (cid:104)∇ g ( x 0 ) , x 0 (cid:105) − g ( x 0 ) . Now we want to extend Proposition 10 . 3 to the case of non - diﬀerentiable functions . Suppose that g : R J → ( −∞ , + ∞ ] is convex and g ( x ) is ﬁnite for x in the non - empty convex set C . If x 0 is in the interior of C , then g is continuous at x 0 . Applying the Support Theorem to the epigraph of cl g , we obtain the following theorem . 156 CHAPTER 10 . CONVEX FUNCTIONS Theorem 10 . 18 If x 0 is an interior point of the set C , then there is a non - zero vector u with g ( x ) ≥ g ( x 0 ) + (cid:104) u , x − x 0 (cid:105) , ( 10 . 39 ) for all x . Proof : The point ( x 0 , g ( x 0 ) ) is a boundary point of the epigraph of g . According to the Support Theorem , there is a non - zero vector a = ( b , c ) in R J + 1 , with b in R J and c real , such that (cid:104) b , x (cid:105) + cr = (cid:104) a , ( x , r ) (cid:105) ≤ (cid:104) a , ( x 0 , g ( x 0 ) ) (cid:105) = (cid:104) b , x 0 (cid:105) + cg ( x 0 ) , for all ( x , r ) in the epigraph of g , that is , all ( x , r ) with g ( x ) ≤ r . The real number c cannot be positive , since (cid:104) b , x (cid:105) + cr is bounded above , while r can be increased arbitrarily . Also c cannot be zero : if c = 0 , then b cannot be zero and we would have (cid:104) b , x (cid:105) ≤ (cid:104) b , x 0 (cid:105) for all x in C . But , since x 0 is in the interior of C , there is t > 0 such that x = x 0 + tb is in C . So c < 0 . We then select u = − 1 c b . The inequality in ( 10 . 39 ) follows . Note that it can happen that b = 0 ; therefore u = 0 is possible ; see Exercise 10 . 12 . Deﬁnition 10 . 11 A vector u is said to be a sub - gradient of the function g ( x ) at x = x 0 if , for all x , we have g ( x ) ≥ g ( x 0 ) + (cid:104) u , x − x 0 (cid:105) . The collection of all sub - gradients of g at x = x 0 is called the sub - diﬀerential of g at x = x 0 , denoted ∂g ( x 0 ) . The domain of ∂g is the set dom ∂g = { x | ∂g ( x ) (cid:54) = ∅ } . As an example , consider the function f ( x ) = x 2 . The epigraph of f ( x ) is the set of all points in the x , y - plane on or above the graph of f ( x ) . At the point ( 1 , 1 ) on the boundary of the epigraph the supporting hyperplane is just the tangent line , which can be written as y = 2 x − 1 or 2 x − y = 1 . The outward normal vector is a = ( b , c ) = ( 2 , − 1 ) . Then u = b = 2 = f (cid:48) ( 1 ) . As we have seen , if f : R J → R is diﬀerentiable , then an outward normal vector to the hyperplane supporting the epigraph at the boundary point ( x 0 , f ( x 0 ) ) is the vector a = ( b T , c T ) T = ( ∇ f ( x 0 ) T , − 1 ) T . So b = u = ∇ f ( x 0 ) . When f ( x ) is not diﬀerentiable at x = x 0 there will be multiple hyper - planes supporting the epigraph of f ( x ) at the boundary point ( x 0 , f ( x 0 ) ) ; the normals can be chosen to be a = ( b T , − 1 ) T , so that b = u is a sub - gradient of f ( x ) at x = x 0 . For example , consider the function of real x 10 . 5 . SUB - DIFFERENTIALS AND DIRECTIONAL DERIVATIVES 157 given by g ( x ) = | x | , and x 0 = 0 . For any α with | α | ≤ 1 , the graph of the straight line y = αx is a hyperplane supporting the epi - graph of g ( x ) at x = 0 . Writing αx − y = 0 , we see that the vector a = ( b , c ) = ( α , − 1 ) is normal to the hyperplane . The constant b = u = α is a sub - gradient and for all x we have g ( x ) = | x | ≥ g ( x 0 ) + (cid:104) u , x − x 0 (cid:105) = αx . Let g : R → R . Then m is in the sub - diﬀerential ∂g ( x 0 ) if and only if the line y = mx + b passes through the point ( x 0 , g ( x 0 ) ) and mx + b ≤ g ( x ) for all x . As the reader is asked to show in Exercise 10 . 4 , when g is diﬀerentiable at x = x 0 the only value of m that works is m = g (cid:48) ( x 0 ) , and the only line that works is the line tangent to the graph of g at x = x 0 . Theorem 10 . 18 says that the sub - diﬀerential of a convex function at an interior point of its domain is non - empty . If the sub - diﬀerential consists of a single vector , then g is diﬀerentiable at x = x 0 and that single vector is its gradient at x = x 0 . Note that , by the chain rule , f (cid:48) ( t ) = ∇ g ( x + tz ) · z , for the function f ( t ) = g ( x + tz ) . As we have just seen , whenever ∇ g ( x ) exists , it is the only sub - gradient for g at x . The following lemma , whose proof is left as Exercise 10 . 8 , provides a further connection between the partial derivatives of g and the entries of any sub - gradient vector u . Lemma 10 . 1 Let g : R J → R be a convex function , and u any sub - gradient of g at the point x . If ∂g∂x j ( x ) exists , then it is equal to u j . Proof : Providing a proof is Exercise 10 . 8 . 10 . 5 Sub - Diﬀerentials and Directional Deriva - tives In this section we investigate the relationship between the sub - gradients of a convex function and its directional derivatives . Our discussion follows that of [ 23 ] . 10 . 5 . 1 Some Deﬁnitions Deﬁnition 10 . 12 Let S be any subset of R J . A point x in S is said to be in the core of S , denoted core ( S ) , if , for every vector z in R J , there is an (cid:15) > 0 , which may depend on z , such that , if | t | ≤ (cid:15) , then x + tz and x − tz are in S . 158 CHAPTER 10 . CONVEX FUNCTIONS The core of a set is a more general notion than the interior of a set ; for x to be in the interior of S we must be able to ﬁnd an (cid:15) > 0 that works for all z . For example , let S ⊆ R 2 be the set of all points on or above the graph of y = x 2 , below or on the graph of y = − x 2 and the x - axis . The origin is then in the core of S , but is not in the interior of S . In Exercise 10 . 9 you will be asked to show that the core of S and the interior of S are the same , whenever S is convex . Deﬁnition 10 . 13 A function f : R J → ( −∞ , + ∞ ] is sub - linear if , for all x and y in R J and all non - negative a and b , f ( ax + by ) ≤ af ( x ) + bf ( y ) . We say that f is sub - additive if f ( x + y ) ≤ f ( x ) + f ( y ) , and positive homogeneous if , for all positive λ , f ( λx ) = λf ( x ) . 10 . 5 . 2 Sub - Linearity We have the following proposition , the proof of which is left as Exercise 10 . 6 . Proposition 10 . 4 A function f : R J → ( −∞ , + ∞ ] is sub - linear if and only if it is both sub - additive and positive homogenous . Deﬁnition 10 . 14 The lineality space of a sub - linear function f , denoted lin ( f ) , is the largest subspace of R J on which f is a linear functional . Suppose , for example , that S is a subspace of R J and a a ﬁxed member of R J . Deﬁne f ( x ) by f ( x ) = (cid:104) a , P S x (cid:105) + (cid:107) P S ⊥ x (cid:107) 2 . Then lin ( f ) is the subspace S . Proposition 10 . 5 Suppose that p : R J → ( −∞ , + ∞ ] is sub - linear and S = lin ( p ) . Then p ( s + x ) = p ( s ) + p ( x ) for any s in S and any x in R J . Proof : We know that p ( s + x ) ≤ p ( s ) + p ( x ) by the sub - additivity of p , so we need only show that p ( s + x ) ≥ p ( s ) + p ( x ) . 10 . 5 . SUB - DIFFERENTIALS AND DIRECTIONAL DERIVATIVES 159 Write p ( x ) = p ( x + s − s ) ≤ p ( s + x ) + p ( − s ) = p ( s + x ) − p ( s ) , so that p ( x ) + p ( s ) ≤ p ( s + x ) . Recall that the extended ( two - sided ) directional derivative of the func - tion f at x in the direction of the vector z is f (cid:48) ( x ; z ) = lim t → 0 1 t ( f ( x + tz ) − f ( x ) ) . Proposition 10 . 6 If f : R J → ( −∞ , + ∞ ] is convex and x is in the core of dom ( f ) , then the directional derivative of f , at x and in the direction z , denoted f (cid:48) ( x ; z ) , exists and is ﬁnite for all z and is a sub - linear function of z . Proof : For any z and real t (cid:54) = 0 let g ( z , t ) = 1 t ( f ( x + tz ) − f ( x ) ) . For 0 < t ≤ s write f ( x + tz ) = f ( ( 1 − t s ) x + t s ( x + sz ) ) ≤ ( 1 − t s ) f ( x ) + t sf ( x + sz ) . It follows that g ( z , t ) ≤ g ( z , s ) . A similar argument gives g ( z , − s ) ≤ g ( z , − t ) ≤ g ( z , t ) ≤ g ( z , s ) . Since x lies in the core of dom ( f ) , we can select s > 0 small enough so that both g ( z , − s ) and g ( z , s ) are ﬁnite . Therefore , as t ↓ 0 , the g ( z , t ) are decreasing to the ﬁnite limit f (cid:48) ( x ; z ) ; we have −∞ < g ( z , − s ) ≤ f (cid:48) ( x ; z ) ≤ g ( z , t ) ≤ g ( z , s ) < + ∞ . The sub - additivity of f (cid:48) ( x ; z ) as a function of z follows easily from the inequality g ( z + y , t ) ≤ g ( z , 2 t ) + g ( y , 2 t ) . Proving the positive homogeneity of f (cid:48) ( x ; z ) is easy . Therefore , f (cid:48) ( x ; z ) is sub - linear in z . 160 CHAPTER 10 . CONVEX FUNCTIONS As pointed out by Borwein and Lewis in [ 23 ] , the directional derivative of f is a local notion , deﬁned only in terms of what happens to f near x , while the notion of a sub - gradient is clearly a global one . If f is diﬀer - entiable at x , then we know that the derivative of f at x , which is then ∇ f ( x ) , can be used to express the directional derivatives of f at x : f (cid:48) ( x ; z ) = (cid:104)∇ f ( x ) , z (cid:105) . We want to extend this relationship to sub - gradients of non - diﬀerentiable functions . 10 . 5 . 3 Sub - Gradients and Directional Derivatives We have the following proposition , whose proof is left as Exercise 10 . 7 . Proposition 10 . 7 Let f : R J → ( −∞ , + ∞ ] be convex and x in dom ( f ) . Then u is a sub - gradient of f at x if and only if (cid:104) u , z (cid:105) ≤ f (cid:48) ( x ; z ) for all z . The main result of this subsection is the following theorem . Theorem 10 . 19 Let f : R J → ( −∞ , + ∞ ] be convex and x in the core of dom ( f ) . Let z be given . Then there is a u in ∂f ( x ) , with u depending on z , such that f (cid:48) ( x ; z ) = (cid:104) u , z (cid:105) . ( 10 . 40 ) Therefore f (cid:48) ( x ; z ) is the maximum of the quantities (cid:104) u , z (cid:105) , as u ranges over the sub - diﬀerential ∂f ( x ) . In particular , the sub - diﬀerential is not empty . Notice that Theorem 10 . 19 asserts that once z is selected , there will be a sub - gradient u for which Equation ( 10 . 40 ) holds . It does not assert that there will be one sub - gradient that works for all z ; this happens only when there is only one sub - gradient , namely ∇ f ( x ) . The theorem also tells us that the function f (cid:48) ( x ; · ) is the support function of the closed convex set C = ∂f ( x ) . We need the following proposition . Proposition 10 . 8 Suppose that p : R J → ( −∞ , + ∞ ] is sub - linear , and therefore convex , and that x lies in the core of dom ( f ) . Deﬁne the function q ( z ) = p (cid:48) ( x ; z ) . Then q ( z ) is sub - linear and has the following properties : 10 . 5 . SUB - DIFFERENTIALS AND DIRECTIONAL DERIVATIVES 161 • 1 ) q ( λx ) = λp ( x ) , for all λ ; • 2 ) q ( z ) ≤ p ( z ) , for all z ; • 3 ) lin ( q ) contains the set lin ( p ) + span { x } . Proof : If t > 0 is close enough to zero , then the quantity 1 + tγ is positive and p ( x + tγx ) = p ( ( 1 + tγ ) x ) = ( 1 + tγ ) p ( x ) , by the positive homogeneity of p . Therefore , q ( γx ) = lim t ↓ 0 1 t (cid:16) p ( x + tγx ) − p ( x ) (cid:17) = γp ( x ) . Since p ( x + tz ) ≤ p ( x ) + tp ( z ) , we have p ( x + tz ) − p ( x ) ≤ tp ( z ) , from which q ( z ) ≤ p ( z ) follows immediately . Finally , suppose that lin ( p ) = S . Then , by Proposition 10 . 5 , we have p ( x + t ( s + γx ) ) = p ( ts ) + p ( ( 1 + tγ ) x ) = tp ( s ) + ( 1 + tγ ) p ( x ) , for t > 0 close enough to zero . Therefore , we have q ( s + γx ) = p ( s ) + γp ( x ) . From this it is easy to show that q is linear on S + span { x } . Proof of Theorem 10 . 19 Let y be ﬁxed . Let { a 1 , a 2 , . . . , a J } be a basis for R J , with a 1 = y . Let p 0 ( z ) = f (cid:48) ( x ; z ) and p 1 ( z ) = p (cid:48) 0 ( a 1 ; z ) . Note that , since the function of z deﬁned by p 0 ( z ) = f (cid:48) ( x ; z ) is convex and ﬁnite for all values of z , p (cid:48) 0 ( z ; w ) exists and is ﬁnite , for all z and all w . Therefore , p 1 ( z ) = p (cid:48) 0 ( a 1 ; z ) is sub - linear , and so convex , and ﬁnite for all z . The function p 1 ( z ) is linear on the span of the vector a 1 . Because p (cid:48) 0 ( x ; z ) ≤ p 0 ( x + z ) − p 0 ( x ) and p 0 is sub - additive , we have p (cid:48) 0 ( x ; z ) = p 1 ( z ) ≤ p 0 ( z ) . Continuing in this way , we deﬁne , for k = 1 , 2 , . . . , J , p k ( z ) = p (cid:48) k − 1 ( a k ; z ) . Then each p k ( z ) is sub - linear , and linear on the span of { a 1 , . . . , a k } , and p k ( z ) ≤ p k − 1 ( z ) . 162 CHAPTER 10 . CONVEX FUNCTIONS Therefore , p J ( z ) is linear on all of R J . Finally , we have p J ( y ) ≤ p 0 ( y ) = p 0 ( a 1 ) = − p (cid:48) 0 ( a 1 ; − a 1 ) = − p 1 ( − a 1 ) = − p 1 ( − y ) ≤ − p J ( − y ) = p J ( y ) , with the last equality the result of the linearity of p J . Therefore , p J ( y ) = f (cid:48) ( x ; y ) . Since p J ( z ) is a linear function , there is a vector u such that p J ( z ) = (cid:104) u , z (cid:105) . Since p J ( z ) = (cid:104) u , z (cid:105) ≤ f (cid:48) ( x ; z ) = p 0 ( z ) for all z , we know that u ∈ ∂f ( x ) . Theorem 10 . 19 shows that the sub - linear function f (cid:48) ( x ; · ) is the support functional for the set ∂f ( x ) . In fact , every lower semi - continuous sub - linear function is the support functional of some closed convex set , and every support functional of a closed convex set is a lower semi - continuous sub - linear function [ 129 ] . An Example The function f : R 2 → R given by f ( x 1 , x 2 ) = 12 x 21 + | x 2 | has gradient ∇ f ( x 1 , x 2 ) = ( x 1 , 1 ) T if x 2 > 0 , and ∇ f ( x 1 , x 2 ) = ( x 1 , − 1 ) T if x 2 < 0 , but is not diﬀerentiable when x 2 = 0 . When x 2 = 0 , the directional derivative function is f (cid:48) ( ( x 1 , 0 ) ; ( z 1 , z 2 ) ) = x 1 z 1 + | z 2 | , and the sub - diﬀerential is ∂f ( ( x 1 , 0 ) ) = { φ = ( x 1 , γ ) T | − 1 ≤ γ ≤ 1 } . Therefore , f (cid:48) ( ( x 1 , 0 ) ; ( z 1 , z 2 ) ) = (cid:104) φ , z (cid:105) , with γ = 1 when z 2 ≥ 0 , and γ = − 1 when z 2 < 0 . In either case , we have f (cid:48) ( ( x 1 , 0 ) ; ( z 1 , z 2 ) ) = max φ ∈ ∂f ( x 1 , 0 ) (cid:104) φ , z (cid:105) . The directional derivative function f (cid:48) ( x ; z ) is linear for all z when x 2 is not zero , and when x 2 = 0 , f (cid:48) ( x ; z ) is linear for z in the subspace S of all z with z 2 = 0 . 10 . 6 . FUNCTIONS AND OPERATORS 163 10 . 6 Functions and Operators A function F : R J → R J is also called an operator on R J . For our purposes , the most important examples of operators on R J are the orthogonal projec - tions P C onto convex sets , and gradient operators , that is , F ( x ) = ∇ g ( x ) , for some diﬀerentiable function g ( x ) : R J → R . As we shall see later , the operators P C are also gradient operators . Deﬁnition 10 . 15 An operator F ( x ) on R J is called L - Lipschitz continu - ous , with respect to a given norm on R J , if , for every x and y in R J , we have (cid:107) F ( x ) − F ( y ) (cid:107) ≤ L (cid:107) x − y (cid:107) . ( 10 . 41 ) Deﬁnition 10 . 16 An operator F ( x ) on R J is called non - expansive , with respect to a given norm on R J , if , for every x and y in R J , we have (cid:107) F ( x ) − F ( y ) (cid:107) ≤ (cid:107) x − y (cid:107) . ( 10 . 42 ) Clearly , if an operator F ( x ) is L - Lipschitz continuous , then the operator G ( x ) = 1 L F ( x ) is non - expansive . Deﬁnition 10 . 17 An operator F ( x ) on R J is called ﬁrmly non - expansive , with respect to the 2 - norm on R J , if , for every x and y in R J , we have (cid:104) F ( x ) − F ( y ) , x − y (cid:105) ≥ (cid:107) F ( x ) − F ( y ) (cid:107) 22 . ( 10 . 43 ) Lemma 10 . 2 A ﬁrmly non - expansive operator on R J is non - expansive . We have the following analog of Theorem 10 . 8 . Theorem 10 . 20 Let h ( x ) be convex and diﬀerentiable and its derivative , ∇ h ( x ) , non - expansive in the two - norm , that is , | | ∇ h ( b ) − ∇ h ( a ) | | 2 ≤ | | b − a | | 2 , ( 10 . 44 ) for all a and b . Then ∇ h ( x ) is ﬁrmly non - expansive , which means that (cid:104)∇ h ( b ) − ∇ h ( a ) , b − a (cid:105) ≥ | | ∇ h ( b ) − ∇ h ( a ) | | 22 . ( 10 . 45 ) Suppose that g ( x ) : R J → R is convex and the function F ( x ) = ∇ g ( x ) is L - Lipschitz . Let h ( x ) = 1 L g ( x ) , so that ∇ h ( x ) is a non - expansive operator . According to Theorem 10 . 20 , the operator ∇ h ( x ) = 1 L ∇ g ( x ) is ﬁrmly non - expansive . Unlike the proof of Theorem 10 . 8 , the proof of Theorem 10 . 20 is not trivial . In [ 119 ] Golshtein and Tretyakov prove the following theorem , from which Theorem 10 . 20 follows immediately . 164 CHAPTER 10 . CONVEX FUNCTIONS Theorem 10 . 21 Let g : R J → R be convex and diﬀerentiable . The fol - lowing are equivalent : • 1 ) | | ∇ g ( x ) − ∇ g ( y ) | | 2 ≤ | | x − y | | 2 ; ( 10 . 46 ) • 2 ) g ( x ) ≥ g ( y ) + (cid:104)∇ g ( y ) , x − y (cid:105) + 1 2 | | ∇ g ( x ) − ∇ g ( y ) | | 22 ; ( 10 . 47 ) and • 3 ) (cid:104)∇ g ( x ) − ∇ g ( y ) , x − y (cid:105) ≥ | | ∇ g ( x ) − ∇ g ( y ) | | 22 . ( 10 . 48 ) Proof : The only non - trivial step in the proof is showing that Inequality ( 10 . 46 ) implies Inequality ( 10 . 47 ) . From Theorem 10 . 16 we see that In - equality ( 10 . 46 ) implies that the function h ( x ) = 12 (cid:107) x (cid:107) 2 − g ( x ) is convex , and that 1 2 (cid:107) x − y (cid:107) 2 ≥ g ( x ) − g ( y ) − (cid:104)∇ g ( y ) , x − y (cid:105) , for all x and y . Now ﬁx y and deﬁne d ( z ) = D g ( z , y ) = g ( z ) − g ( y ) − (cid:104)∇ g ( y ) , z − y (cid:105) , for all z . Since the function g ( z ) is convex , so is d ( z ) . Since ∇ d ( z ) = ∇ g ( z ) − ∇ g ( y ) , it follows from Inequality ( 10 . 46 ) that (cid:107)∇ d ( z ) − ∇ d ( x ) (cid:107) ≤ (cid:107) z − x (cid:107) , for all x and z . Then , from our previous calculations , we may conclude that 1 2 (cid:107) z − x (cid:107) 2 ≥ d ( z ) − d ( x ) − (cid:104)∇ d ( x ) , z − x (cid:105) , for all z and x . Now let x be arbitrary and z = x − ∇ g ( x ) + ∇ g ( y ) . Then 0 ≤ d ( z ) ≤ d ( x ) − 1 2 (cid:107)∇ g ( x ) − ∇ g ( y ) (cid:107) 2 . 10 . 7 . CONVEX SETS AND CONVEX FUNCTIONS 165 This completes the proof . We know from Corollary 10 . 1 that the function g ( x ) = 1 2 (cid:16) (cid:107) x (cid:107) 22 − (cid:107) x − P C x (cid:107) 22 (cid:17) is convex . As Corollary 13 . 1 tells us , its gradient is ∇ g ( x ) = P C x . We showed in Corollary 6 . 1 that the operator P C is non - expansive by showing that it is actually ﬁrmly non - expansive . Therefore , Theorem 10 . 20 can be viewed as a generalization of Corollary 6 . 1 . If g ( x ) is convex and f ( x ) = ∇ g ( x ) is L - Lipschitz , then 1 L ∇ g ( x ) is non - expansive , so , by Theorem 10 . 20 , it is ﬁrmly non - expansive . It follows that , for γ > 0 , the operator Tx = x − γ ∇ g ( x ) ( 10 . 49 ) is averaged , whenever 0 < γ < 2 L . By the KMO Theorem 30 . 2 , the iterative sequence x k + 1 = Tx k = x k − γ ∇ g ( x k ) converges to a minimizer of g ( x ) , whenever minimizers exist . 10 . 7 Convex Sets and Convex Functions In a previous chapter we said that a function f : R J → ( −∞ , ∞ ] is convex if its epigraph is a convex set in R J + 1 . At the same time , every closed convex set C ⊆ R J has the form C = { x | f ( x ) ≤ 0 } , ( 10 . 50 ) for some convex function f : R J → R . We are tempted to assume that the smoothness of the function f will be reﬂected in the geometry of the set C . In particular , we may well expect that , if x is on the boundary of C and f is diﬀerentiable at x , then there is a unique hyperplane supporting C at x and its normal is ∇ f ( x ) ; but this is wrong . Any closed convex nonempty set C can be written as in Equation ( 10 . 50 ) , for the diﬀerentiable function f ( x ) = 1 2 (cid:107) x − P C x (cid:107) 2 . As we shall see later , the gradient of f ( x ) is ∇ f ( x ) = x − P C x , so that ∇ f ( x ) = 0 for every x in C . Nevertheless , the set C may have a unique supporting hyperplane at each boundary point , or it may have multiple such hyperplanes , regardless of the properties of the f used to deﬁne C . When we ﬁrst encounter gradients , usually in Calculus III , they are almost always described geometrically as a vector that is a normal for the hyperplane that is tangent to the level surface of f at that point , and 166 CHAPTER 10 . CONVEX FUNCTIONS as indicating the direction of greatest increase of f . However , this is not always the case . Consider the function f : R 2 → R given by f ( x 1 , x 2 ) = 1 2 ( (cid:113) x 21 + x 22 − 1 ) 2 , for x 21 + x 22 ≥ 1 , and zero , otherwise . This function is diﬀerentiable and ∇ f ( x ) = (cid:107) x (cid:107) 2 − 1 (cid:107) x (cid:107) 2 x , for (cid:107) x (cid:107) 2 ≥ 1 , and ∇ f ( x ) = 0 , otherwise . The level surface in R 2 of all x such that f ( x ) ≤ 0 is the closed unit ball ; it is not a simple closed curve . At every point of its boundary the gradient is zero , and yet , at each boundary point , there is a unique supporting tangent line . Consider the function f : R 2 → R given by f ( x ) = f ( x 1 , x 2 ) = x 21 . The level curve C = { x | f ( x ) = 0 } is the x 2 axis . For any x such that x 1 = 0 the hyperplane supporting C at x is C itself , and any vector of the form ( γ , 0 ) is a normal to C . But the gradient of f ( x ) is zero at all points of C . So the gradient of f is not a normal vector to the supporting hyperplane . 10 . 8 Exercises Ex . 10 . 1 Say that a function f : R → R has the intermediate value prop - erty ( IVP ) if , for every a and b in R and , for any d between f ( a ) and f ( b ) , there is c between a and b with f ( c ) = d . Let g : R → R be diﬀerentiable and f ( x ) = g (cid:48) ( x ) . Show that f has the IVP , even if f is not continuous . Ex . 10 . 2 Prove Proposition 10 . 1 . Ex . 10 . 3 Prove Proposition 10 . 2 . Hint : ﬁx z ∈ R J and show that the function g ( x ) = f ( x ) − (cid:104) z , x (cid:105) has a global minimizer . Ex . 10 . 4 Let g : R → R be diﬀerentiable at x = x 0 . Show that , if the line y = mx + b passes through the point ( x 0 , g ( x 0 ) ) and mx + b ≤ g ( x ) for all x , then m = g (cid:48) ( x 0 ) . Ex . 10 . 5 Prove Proposition 10 . 3 . Ex . 10 . 6 Prove Proposition 10 . 4 . Ex . 10 . 7 Prove Proposition 10 . 7 . Ex . 10 . 8 Prove Lemma 10 . 1 . 10 . 8 . EXERCISES 167 Ex . 10 . 9 Let C be a non - empty convex subset of R J . Show that the core of C and the interior of C are the same . Hints : We need only consider the case in which the core of C is not empty . By shifting C if necessary , we may assume that 0 is in the core of C . Then we want to show that 0 is in the interior of C . The gauge function for C is γ C ( x ) = inf { λ ≥ 0 | x ∈ λC } . Show that the interior of C is the set of all x for which γ C ( x ) < 1 . Ex . 10 . 10 Let p : R J → R be sub - linear , and p ( − x n ) = − p ( x n ) for n = 1 , 2 , . . . , N . Show that p is linear on the span of { x 1 , . . . , x N } . Ex . 10 . 11 Prove Lemma 10 . 2 . Ex . 10 . 12 Show that , if ˆ x minimizes the function g ( x ) over all x in R J , then u = 0 is in the sub - diﬀerential ∂g ( ˆ x ) . Ex . 10 . 13 If f ( x ) and g ( x ) are convex functions on R J , is f ( x ) + g ( x ) convex ? Is f ( x ) g ( x ) convex ? Ex . 10 . 14 Let ι C ( x ) be the indicator function of the closed convex set C . Show that the sub - diﬀerential of the function ι C at a point c in C is the normal cone to C at the point c , that is , ∂ι C ( c ) = N C ( c ) , for all c in C . Ex . 10 . 15 [ 200 ] Let g ( t ) be a strictly convex function for t > 0 . For x > 0 and y > 0 , deﬁne the function f ( x , y ) = xg ( y x ) . Use induction to prove that N (cid:88) n = 1 f ( x n , y n ) ≥ f ( x + , y + ) , for any positive numbers x n and y n , where x + = (cid:80) Nn = 1 x n . Also show that equality obtains if and only if the ﬁnite sequences { x n } and { y n } are proportional . Ex . 10 . 16 Use the result in Exercise 10 . 15 to obtain Cauchy’s Inequality . Hint : let g ( t ) = −√ t . Ex . 10 . 17 Use the result in Exercise 10 . 15 to obtain H¨older’s Inequality . Hint : let g ( t ) = − t 1 / q . Ex . 10 . 18 Use the result in Exercise 10 . 15 to obtain Minkowski’s Inequal - ity . Hint : let g ( t ) = − ( t 1 / p + 1 ) p . 168 CHAPTER 10 . CONVEX FUNCTIONS Ex . 10 . 19 Use the result in Exercise 10 . 15 to obtain Milne’s Inequality : x + y + ≥ (cid:16) N (cid:88) n = 1 ( x n + y n ) (cid:17)(cid:16) N (cid:88) n = 1 x n y n x n + y n (cid:17) . Hint : let g ( t ) = − t 1 + t . Ex . 10 . 20 For x > 0 and y > 0 , let f ( x , y ) be the Kullback - Leibler function , f ( x , y ) = KL ( x , y ) = x (cid:16) log x y (cid:17) + y − x . Use Exercise 10 . 15 to show that N (cid:88) n = 1 KL ( x n , y n ) ≥ KL ( x + , y + ) . Compare this result with Lemma 22 . 1 . 10 . 9 Course Homework Try the ﬁrst fourteen exercises . Chapter 11 Convex Programming 11 . 1 Chapter Summary Convex programming ( CP ) refers to the minimization of a convex function of one or several variables over a convex set . The convex set is often deﬁned in terms of inequalities involving other convex functions . We begin by describing the basic problems of CP . We then discuss characterizations of the solutions given by the Karush - Kuhn - Tucker ( KKT ) Theorem , the concept of duality , and use these tools to solve certain CP problems . 11 . 2 The Primal Problem Let f and g i , i = 1 , . . . , I , be convex functions deﬁned on a non - empty closed convex subset C of R J . The primal problem in convex programming ( CP ) is the following : minimize f ( x ) , subject to g i ( x ) ≤ 0 , for i = 1 , . . . , I . ( P ) ( 11 . 1 ) For notational convenience , we deﬁne g ( x ) = ( g 1 ( x ) , . . . , g I ( x ) ) . Then P becomes minimize f ( x ) , subject to g ( x ) ≤ 0 . ( P ) ( 11 . 2 ) The feasible set for P is F = { x | g ( x ) ≤ 0 } , ( 11 . 3 ) and the members of F are called feasible points for P . Deﬁnition 11 . 1 The problem P is said to be consistent if F is not empty , and super - consistent if there is x in F with g i ( x ) < 0 for all i = 1 , . . . , I . Such a point x is then called a Slater point . 169 170 CHAPTER 11 . CONVEX PROGRAMMING 11 . 2 . 1 The Perturbed Problem For each z in R I let MP ( z ) = inf { f ( x ) | x ∈ C , g ( x ) ≤ z } , ( 11 . 4 ) and MP = MP ( 0 ) . The convex programming problem P ( z ) is to minimize the function f ( x ) over x in C with g ( x ) ≤ z . The feasible set for P ( z ) is F ( z ) = { x | g ( x ) ≤ z } . ( 11 . 5 ) We shall be interested in properties of the function MP ( z ) , in particular , how the function MP ( z ) behaves as z moves away from z = 0 . For example , let f ( x ) = x 2 ; the minimum occurs at x = 0 . Now consider the perturbed problem , minimize f ( x ) = x 2 , subject to x ≤ z . For z ≤ 0 , the minimum of the perturbed problem occurs at x = z , and we have MP ( z ) = z 2 . For z > 0 the minimum of the perturbed problem is the global minimum , which is at x = 0 , so MP ( z ) = 0 . The global minimum of MP ( z ) also occurs at z = 0 . We have the following theorem concerning the function MP ( z ) ; see the exercises for related results . Theorem 11 . 1 The function MP ( z ) is convex and its domain , the set of all z for which F ( z ) is not empty , is convex . If P is super - consistent , then z = 0 is an interior point of the domain of MP ( z ) . Proof : See [ 175 ] , Theorem 5 . 2 . 6 . From Theorem 10 . 18 we know that , if P is super - consistent , then there is a vector u such that MP ( z ) ≥ MP ( 0 ) + (cid:104) u , z − 0 (cid:105) . ( 11 . 6 ) In fact , we can show that , in this case , u ≤ 0 . Suppose that u i > 0 for some i . Since z = 0 is in the interior of the domain of MP ( z ) , there is r > 0 such that F ( z ) is not empty for all z with | | z | | < r . Let w j = 0 for j (cid:54) = i and w i = r / 2 . Then F ( w ) is not empty and MP ( 0 ) ≥ MP ( w ) , since F ⊆ F ( w ) . But from Equation ( 11 . 6 ) we have MP ( w ) ≥ MP ( 0 ) + r 2 u i > MP ( 0 ) . ( 11 . 7 ) This is a contradiction , and we conclude that u ≤ 0 . 11 . 2 . 2 The Sensitivity Vector From now on we shall use λ ∗ = − u instead of u . For any z we have (cid:104) λ ∗ , z (cid:105) ≥ MP ( 0 ) − MP ( z ) ; ( 11 . 8 ) 11 . 3 . FROM CONSTRAINED TO UNCONSTRAINED 171 so for z ≥ 0 we have MP ( z ) ≤ MP ( 0 ) , and (cid:104) λ ∗ , z (cid:105) ≥ MP ( 0 ) − MP ( z ) ≥ 0 . ( 11 . 9 ) The quantity (cid:104) λ ∗ , z (cid:105) measures how much MP ( z ) changes as we increase z away from z = 0 ; for that reason , λ ∗ is called the sensitivity vector , as well as the vector of Lagrange multipliers . 11 . 2 . 3 The Lagrangian Function The Lagrangian function for the problem P is the function L ( x , λ ) = f ( x ) + I (cid:88) i = 1 λ i g i ( x ) = f ( x ) + (cid:104) λ , g ( x ) (cid:105) , ( 11 . 10 ) deﬁned for all x in C and λ ≥ 0 . For each ﬁxed x in C , let F ( x ) = sup λ ≥ 0 L ( x , λ ) . ( 11 . 11 ) If x is feasible for P , then f ( x ) ≥ L ( x , λ ) , for all λ ≥ 0 , so that f ( x ) ≥ F ( x ) . On the other hand , since f ( x ) = L ( x , 0 ) ≤ F ( x ) , we can conclude that f ( x ) = F ( x ) for all feasible x in C . If x is not feasible , then F ( x ) = + ∞ . Consequently , minimizing f ( x ) over all feasible x in C is equivalent to minimizing F ( x ) over all x in C ; that is , we have removed the constraint that x be feasible for P . In the next section we pursue this idea further . 11 . 3 From Constrained to Unconstrained In addition to being a measure of the sensitivity of MP ( z ) to changes in z , the vector λ ∗ can be used to convert the original constrained minimization problem P into an unconstrained one . Theorem 11 . 2 If the problem P has a sensitivity vector λ ∗ ≥ 0 , in par - ticular , when P is super - consistent , then MP ( 0 ) = inf x ∈ C L ( x , λ ∗ ) , that is , MP ( 0 ) = inf x ∈ C (cid:16) f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) (cid:17) . ( 11 . 12 ) Proof : For any ﬁxed x in the set C , the set F ( g ( x ) ) = { t | g ( t ) ≤ g ( x ) } contains t = x and therefore is non - empty . By Equation ( 11 . 9 ) MP ( g ( x ) ) + (cid:104) λ ∗ , g ( x ) (cid:105) ≥ MP ( 0 ) . ( 11 . 13 ) 172 CHAPTER 11 . CONVEX PROGRAMMING Since x is in F ( g ( x ) ) , we have f ( x ) ≥ MP ( g ( x ) ) , ( 11 . 14 ) and it follows that f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) ≥ MP ( 0 ) . ( 11 . 15 ) Therefore , inf x ∈ C (cid:16) f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) (cid:17) ≥ MP ( 0 ) . ( 11 . 16 ) But inf x ∈ C (cid:16) f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) (cid:17) ≤ inf x ∈ C , g ( x ) ≤ 0 (cid:16) f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) (cid:17) , ( 11 . 17 ) and inf x ∈ C , g ( x ) ≤ 0 (cid:16) f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) (cid:17) ≤ inf x ∈ C , g ( x ) ≤ 0 f ( x ) = MP ( 0 ) , ( 11 . 18 ) since λ ∗ ≥ 0 and g ( x ) ≤ 0 . Note that the theorem tells us that the two sides of Equation ( 11 . 12 ) are equal . Although it is true , we cannot conclude , from Theorem 11 . 2 alone , that if both sides have a minimizer then the minimizers are the same vector . 11 . 4 Saddle Points To prepare for our discussion of the Karush - Kuhn - Tucker Theorem and duality , we consider the notion of saddle points . 11 . 4 . 1 The Primal and Dual Problems Suppose that X and Y are two non - empty sets and K : X × Y → ( −∞ , ∞ ) is a function of two variables . For each x in X , deﬁne the function f ( x ) by the supremum f ( x ) = sup y K ( x , y ) , ( 11 . 19 ) where the supremum , abbreviated “sup” , is the least upper bound of the real numbers K ( x , y ) , over all y in Y . Then we have K ( x , y ) ≤ f ( x ) , ( 11 . 20 ) for all x . Similarly , for each y in Y , deﬁne the function g ( y ) by g ( y ) = inf x K ( x , y ) ; ( 11 . 21 ) 11 . 4 . SADDLE POINTS 173 here the inﬁmum is the greatest lower bound of the numbers K ( x , y ) , over all x in X . Then we have g ( y ) ≤ K ( x , y ) , ( 11 . 22 ) for all y in Y . Putting together ( 11 . 20 ) and ( 11 . 22 ) , we have g ( y ) ≤ K ( x , y ) ≤ f ( x ) , ( 11 . 23 ) for all x and y . Now we consider two problems : the primal problem is minimizing f ( x ) and the dual problem is maximizing g ( y ) . Deﬁnition 11 . 2 The pair ( ˆ x , ˆ y ) is called a saddle point for the function K ( x , y ) if , for all x and y , we have K ( ˆ x , y ) ≤ K ( ˆ x , ˆ y ) ≤ K ( x , ˆ y ) . ( 11 . 24 ) The number K ( ˆ x , ˆ y ) is called the saddle value . For example , the function K ( x , y ) = x 2 − y 2 has ( 0 , 0 ) for a saddle point , with saddle value zero . 11 . 4 . 2 The Main Theorem We have the following theorem , with the proof left to the reader . Theorem 11 . 3 The following are equivalent : • ( 1 ) The pair ( ˆ x , ˆ y ) forms a saddle point for K ( x , y ) ; • ( 2 ) The point ˆ x solves the primal problem , that is , ˆ x minimizes f ( x ) , over all x in X , and ˆ y solves the dual problem , that is , ˆ y maximizes g ( y ) , over all y in Y , and f ( ˆ x ) = g ( ˆ y ) . When ( ˆ x , ˆ y ) forms a saddle point for K ( x , y ) , we have g ( y ) ≤ K ( ˆ x , ˆ y ) ≤ f ( x ) , ( 11 . 25 ) for all x and y , so that the maximum value of g ( y ) and the minimum value of f ( x ) are both equal to K ( ˆ x , ˆ y ) . 11 . 4 . 3 A Duality Approach to Optimization Suppose that our original problem is to minimize a function f ( x ) over x in some set X . One approach is to ﬁnd a second set Y and a function K ( x , y ) of two variables for which Equation ( 11 . 19 ) holds , use Equation ( 11 . 21 ) to construct a second function g ( y ) , deﬁned for y in Y , and then maximize g ( y ) . If a saddle point exists , then , according to the theorem , we have solved the original problem . 174 CHAPTER 11 . CONVEX PROGRAMMING 11 . 5 The Karush - Kuhn - Tucker Theorem We begin with suﬃcient conditions for a vector x ∗ to be a solution to the primal CP problem . Under certain restrictions , as speciﬁed by the Karush - Kuhn - Tucker Theorem , these conditions become necessary , as well . 11 . 5 . 1 Suﬃcient Conditions Proposition 11 . 1 Let x ∗ be a member of C . If there is λ ∗ ≥ 0 such that , for all x ∈ C and all vectors λ ≥ 0 , we have L ( x ∗ , λ ) ≤ L ( x ∗ , λ ∗ ) ≤ L ( x , λ ∗ ) , then x ∗ is feasible and x ∗ solves the primal CP problem . Proof : The proof is left as Exercise 11 . 1 . Corollary 11 . 1 If , for a given vector x ∗ ∈ C , there is λ ∗ ≥ 0 such that L ( x ∗ , λ ∗ ) ≤ L ( x , λ ∗ ) , for all x ∈ C , and λ ∗ i g i ( x ∗ ) = 0 , for all i , then x ∗ is feasible and x ∗ solves the primal CP problem . Proof : The proof is left as Exercise 11 . 2 . 11 . 5 . 2 The KKT Theorem : Saddle - Point Form This form of the KKT Theorem does not require that the functions in - volved be diﬀerentiable . The saddle - point form of the Karush - Kuhn - Tucker ( KKT ) Theorem is the following . Theorem 11 . 4 Let P , the primal CP problem , be super - consistent . Then x ∗ solves P if and only if there is a vector λ ∗ such that • 1 ) λ ∗ ≥ 0 ; • 2 ) L ( x ∗ , λ ) ≤ L ( x ∗ , λ ∗ ) ≤ L ( x , λ ∗ ) , for all x ∈ C and all λ ≥ 0 ; • 3 ) λ ∗ i g i ( x ∗ ) = 0 , for all i = 1 , . . . , I . Proof : Since P is super - consistent and x ∗ solves P , we know from Theorem 11 . 2 that there is λ ∗ ≥ 0 such that f ( x ∗ ) = inf x ∈ C L ( x , λ ∗ ) . ( 11 . 26 ) We do not yet know that f ( x ∗ ) = L ( x ∗ , λ ∗ ) , however . We do have f ( x ∗ ) ≤ L ( x ∗ , λ ∗ ) = f ( x ∗ ) + (cid:104) λ ∗ , g ( x ∗ ) (cid:105) , ( 11 . 27 ) 11 . 5 . THE KARUSH - KUHN - TUCKER THEOREM 175 though , and since λ ∗ ≥ 0 and g ( x ∗ ) ≤ 0 , we also have f ( x ∗ ) + (cid:104) λ ∗ , g ( x ∗ ) (cid:105) ≤ f ( x ∗ ) . ( 11 . 28 ) Now we can conclude that f ( x ∗ ) = L ( x ∗ , λ ∗ ) and (cid:104) λ ∗ , g ( x ∗ ) (cid:105) = 0 . It follows that λ ∗ i g i ( x ∗ ) = 0 , for all i = 1 , . . . , I . Since , for λ ≥ 0 , L ( x ∗ , λ ∗ ) − L ( x ∗ , λ ) = (cid:104) λ ∗ − λ , g ( x ∗ ) (cid:105) = (cid:104)− λ , g ( x ∗ ) (cid:105) ≥ 0 , ( 11 . 29 ) we also have L ( x ∗ , λ ) ≤ L ( x ∗ , λ ∗ ) , ( 11 . 30 ) for all λ ≥ 0 . Conversely , suppose that x ∗ and λ ∗ satisfy the three conditions of the theorem . First , we show that x ∗ is feasible for P , that is , g ( x ∗ ) ≤ 0 . Let i be ﬁxed and take λ to have the same entries as λ ∗ , except that λ i = λ ∗ i + 1 . Then we have λ ≥ 0 and 0 ≤ L ( x ∗ , λ ∗ ) − L ( x ∗ , λ ) = − g i ( x ∗ ) . ( 11 . 31 ) Also , f ( x ∗ ) = L ( x ∗ , 0 ) ≤ L ( x ∗ , λ ∗ ) = f ( x ∗ ) + (cid:104) λ ∗ , g ( x ∗ ) (cid:105) = f ( x ∗ ) , ( 11 . 32 ) so f ( x ∗ ) = L ( x ∗ , λ ∗ ) ≤ L ( x , λ ∗ ) . ( 11 . 33 ) But we also have L ( x ∗ , λ ∗ ) ≤ inf x ∈ C (cid:16) f ( x ) + (cid:104) λ ∗ , g ( x ) (cid:105) (cid:17) ≤ inf x ∈ C , g ( x ) ≤ 0 f ( x ) = MP ( 0 ) . ( 11 . 34 ) We conclude that f ( x ∗ ) = MP ( 0 ) , and since x ∗ is feasible for P , x ∗ solves P . Condition 3 ) is called complementary slackness . If g i ( x ∗ ) = 0 , we say that the i th constraint is binding . 11 . 5 . 3 The KKT Theorem - The Gradient Form Now we assume that the functions f ( x ) and g i ( x ) are diﬀerentiable . Theorem 11 . 5 Let P be super - consistent . Then x ∗ solves P if and only if there is a vector λ ∗ such that • 1 ) λ ∗ ≥ 0 ; • 2 ) λ ∗ i g i ( x ∗ ) = 0 , for all i = 1 , . . . , I ; • 3 ) ∇ f ( x ∗ ) + (cid:80) Ii = 1 λ ∗ i ∇ g i ( x ∗ ) = 0 . The proof is similar to the previous one and we omit it . The interested reader should consult [ 175 ] , p . 185 . 176 CHAPTER 11 . CONVEX PROGRAMMING 11 . 6 On Existence of Lagrange Multipliers As we saw previously , if P is super - consistent , then z = 0 is in the interior of the domain of the function MP ( z ) , and so the sub - diﬀerential of MP ( z ) is non - empty at z = 0 . The sub - gradient d was shown to be non - positive and we deﬁned the sensitivity vector , or the vector of Lagrange multipliers , to be λ ∗ = − d . Theorem 11 . 5 tells us that if P is super - consistent and x ∗ solves P , then the vector ∇ f ( x ∗ ) is a non - negative linear combination of the vectors −∇ g i ( x ∗ ) . This sounds like the assertion in Farkas’ Lemma . For any point x , deﬁne the set B ( x ) = { i | g i ( x ) = 0 } , and Z ( x ) = { z | z T ∇ g i ( x ) ≤ 0 , i ∈ B ( x ) , and z T ∇ f ( x ) < 0 } . If Z ( x ) is empty , then z T ( −∇ g i ( x ) ) ≥ 0 for i ∈ B ( x ) implies z T ∇ f ( x ) ≥ 0 , which , by Farkas’ Lemma , implies that ∇ f ( x ) is a non - negative linear combination of the vectors −∇ g i ( x ) for i ∈ B ( x ) . The objective , then , is to ﬁnd some condition which , if it holds at the solution x ∗ , will imply that Z ( x ∗ ) is empty ; ﬁrst - order necessary conditions are of this sort . It will then follow that there are non - negative Lagrange multipliers for which ∇ f ( x ∗ ) + I (cid:88) i = 1 λ ∗ i ∇ g i ( x ∗ ) = 0 ; for i not in B ( x ∗ ) we let λ ∗ i = 0 . For more discussion of this issue , see Fiacco and McCormick [ 112 ] 11 . 7 The Problem of Equality Constraints We consider now what happens when some of the constraints are equalities . 11 . 7 . 1 The Problem Let f and g i , i = 1 , . . . , I , be diﬀerentiable functions deﬁned on R J . We consider the following problem : minimize f ( x ) , subject to the constraints (cid:40) g i ( x ) ≤ 0 , for i = 1 , . . . , K ; g i ( x ) = 0 , for i = K + 1 , . . . , I . ( 11 . 35 ) 11 . 7 . THE PROBLEM OF EQUALITY CONSTRAINTS 177 If 1 ≤ K < I , the constraints are said to be mixed . If K = I , there are only inequality constraints , so , for convex f ( x ) and g i ( x ) , the problem is P , given by ( 11 . 1 ) . If K < I , we cannot convert it to a CP problem by rewriting the equality constraints as g i ( x ) ≤ 0 and − g i ( x ) ≤ 0 , since then we would lose the convexity property of the constraint functions . Nevertheless , a version of the KKT Theorem holds for such problems . Deﬁnition 11 . 3 The feasible set for this problem is the set F of all x satisfying the constraints . Deﬁnition 11 . 4 The problem is said to be consistent if F is not empty . Deﬁnition 11 . 5 Let I ( x ) be the set of all indices 1 ≤ i ≤ I for which g i ( x ) = 0 . The point x is regular if the set of gradients { ∇ g i ( x ) | i ∈ I ( x ) } is linearly independent . 11 . 7 . 2 The KKT Theorem for Mixed Constraints The following version of the KKT Theorem provides a necessary condition for a regular point x ∗ to be a local constrained minimizer . Theorem 11 . 6 Let x ∗ be a regular point for the problem in ( 11 . 35 ) . If x ∗ is a local constrained minimizer of f ( x ) , then there is a vector λ ∗ such that • 1 ) λ ∗ i ≥ 0 , for i = 1 , . . . , K ; • 2 ) λ ∗ i g i ( x ∗ ) = 0 , for i = 1 , . . . , K ; • 3 ) ∇ f ( x ∗ ) + (cid:80) Ii = 1 λ ∗ i ∇ g i ( x ∗ ) = 0 . Note that , if there are some equality constraints , then the vector λ need not be non - negative . 11 . 7 . 3 The KKT Theorem for LP Consider the LP problem PS : minimize z = c T x , subject to Ax = b and x ≥ 0 . We let z = f ( x ) = c T x , g i ( x ) = b i − ( Ax ) i , for i = 1 , . . . , I , and g i ( x ) = − x j , for i = I + 1 , . . . , I + J and j = i − I . We assume that I < J and that the I by J matrix A has rank I . Then , since −∇ g i ( x ) is a i , the i th column of A T , the vectors { ∇ g i ( x ) | i = 1 , . . . , I } are linearly independent and every x > 0 is a regular point . 178 CHAPTER 11 . CONVEX PROGRAMMING Suppose that a regular point x ∗ solves PS . Let λ ∗ be the vector in R I + J whose existence is guaranteed by Theorem 11 . 6 . Denote by y ∗ the vector in R I whose entries are the ﬁrst I entries of λ ∗ , and r the non - negative vector in R J whose entries are the last J entries of λ ∗ . Then , applying Theorem 11 . 6 , we have r T x ∗ = 0 , Ax ∗ = b , and c − I (cid:88) i = 1 λ ∗ i a i + J (cid:88) j = 1 r j ( − δ j ) = 0 , or , c − A T y ∗ = r ≥ 0 , where δ j is the column vector whose j th entry is one and the rest are zero . The KKT Theorem for this problem is then the following . Theorem 11 . 7 Let A have full rank I . The regular point x ∗ solves PS if and only if there are vectors y ∗ in R I and r ≥ 0 in R J such that • 1 ) Ax ∗ = b ; • 2 ) r = c − A T y ∗ ; • 3 ) r T x ∗ = 0 . Then y ∗ solves DS . The ﬁrst condition in the theorem is primal feasibility , the second one is dual feasibility , and the third is complementary slackness . The ﬁrst two conditions tell us that x ∗ is feasible for PS and y ∗ is feasible for DS . Combining these two conditions with complementary slackness , we can write z ∗ = c T x ∗ = ( A T y ∗ + r ) T x ∗ = ( A T y ∗ ) T x ∗ + r T x ∗ = ( y ∗ ) T b = w ∗ , so z ∗ = w ∗ and there is no duality gap . Invoking Corollary 8 . 2 to the Weak Duality Theorem , we conclude that x ∗ and y ∗ solve their respective problems . 11 . 7 . 4 The Lagrangian Fallacy As Kalman notes in [ 135 ] , it is quite common , when discussing the use of Lagrange multipliers in optimization , to say , incorrectly , that the problem of minimizing f ( x ) , subject to g ( x ) = 0 , has been converted into the prob - lem of ﬁnding a local minimum of the Lagrangian function L ( x , λ ) , as a function of ( x , λ ) . The following example , taken from [ 135 ] , shows that this interpretation is false . 11 . 8 . TWO EXAMPLES 179 Minimize the function f ( x , y ) = x 2 + y 2 , subject to g ( x , y ) = xy − 1 = 0 . Using a Lagrange multiplier λ , and the Lagrangian L ( x , y , λ ) = x 2 + y 2 + λ ( xy − 1 ) = ( x − y ) 2 + λ ( xy − 1 ) + 2 xy , we ﬁnd that 2 x + λy = 0 , 2 y + λx = 0 , and xy − 1 = 0 . It follows that x = 1 , y = 1 , λ = − 2 , and L ( 1 , 1 , − 2 ) = 2 . Now let us move away from the point ( 1 , 1 , − 2 ) along the line ( x , x , − 2 + t ) , so that the Lagrangian takes on the values L ( x , x , − 2 + t ) = ( x − x ) 2 + ( − 2 + t ) ( x 2 − 1 ) + 2 x 2 = 2 + t ( x 2 − 1 ) . For small positive values of t , the Lagrangian takes on values greater than 2 , while , for small negative values of t , its values are smaller than 2 . 11 . 8 Two Examples We illustrate the use of the gradient form of the KKT Theorem with two examples that appeared in the paper of Driscoll and Fox [ 100 ] . 11 . 8 . 1 A Linear Programming Problem Minimize f ( x 1 , x 2 ) = 3 x 1 + 2 x 2 , subject to the constraints 2 x 1 + x 2 ≥ 100 , x 1 + x 2 ≥ 80 , x 1 ≥ 0 and x 2 ≥ 0 . We deﬁne g 1 ( x 1 , x 2 ) = 100 − 2 x 1 − x 2 ≤ 0 , ( 11 . 36 ) g 2 ( x 1 , x 2 ) = 80 − x 1 − x 2 , ( 11 . 37 ) g 3 ( x 1 , x 2 ) = − x 1 , ( 11 . 38 ) g 4 ( x 1 , x 2 ) = − x 2 . ( 11 . 39 ) The Lagrangian is then L ( x , λ ) = 3 x 1 + 2 x 2 + λ 1 ( 100 − 2 x 1 − x 2 ) + λ 2 ( 80 − x 1 − x 2 ) − λ 3 x 1 − λ 4 x 2 . ( 11 . 40 ) From the KKT Theorem , we know that , if there is a solution x ∗ , then there is λ ∗ ≥ 0 with f ( x ∗ ) = L ( x ∗ , λ ∗ ) ≤ L ( x , λ ∗ ) , 180 CHAPTER 11 . CONVEX PROGRAMMING for all x . For notational simplicity , we write λ in place of λ ∗ . Taking the partial derivatives of L ( x , λ ) with respect to the variables x 1 and x 2 , we get 3 − 2 λ 1 − λ 2 − λ 3 = 0 , and ( 11 . 41 ) 2 − λ 1 − λ 2 − λ 4 = 0 . ( 11 . 42 ) The complementary slackness conditions are λ 1 = 0 , if 2 x 1 + x 2 (cid:54) = 100 , ( 11 . 43 ) λ 2 = 0 , if x 1 + x 2 (cid:54) = 80 , ( 11 . 44 ) λ 3 = 0 , if x 1 (cid:54) = 0 , and ( 11 . 45 ) λ 4 = 0 , if x 2 (cid:54) = 0 . ( 11 . 46 ) A little thought reveals that precisely two of the four constraints must be binding . Examining the six cases , we ﬁnd that the only case satisfying all the conditions of the KKT Theorem is λ 3 = λ 4 = 0 . The minimum occurs at x 1 = 20 and x 2 = 60 and the minimum value is f ( 20 , 60 ) = 180 . We can use these results to illustrate Theorem 11 . 2 . The sensitivity vector is λ ∗ = ( 1 , 1 , 0 , 0 ) and the Lagrangian function at λ ∗ is L ( x , λ ∗ ) = 3 x 1 + 2 x 2 + 1 ( 100 − 2 x 1 − x 2 ) + 1 ( 80 − x 1 − x 2 ) . ( 11 . 47 ) In this case , we ﬁnd that L ( x , λ ∗ ) = 180 , for all x . 11 . 8 . 2 A Nonlinear Convex Programming Problem Minimize the function f ( x 1 , x 2 ) = ( x 1 − 14 ) 2 + ( x 2 − 11 ) 2 , subject to g 1 ( x 1 , x 2 ) = ( x 1 − 11 ) 2 + ( x 2 − 13 ) 2 − 49 ≤ 0 , and g 2 ( x 1 , x 2 ) = x 1 + x 2 − 19 ≤ 0 . The Lagrangian is then L ( x , λ ) = ( x 1 − 14 ) 2 + ( x 2 − 11 ) 2 + λ 1 (cid:16) ( x 1 − 11 ) 2 + ( x 2 − 13 ) 2 − 49 (cid:17) + λ 2 (cid:16) x 1 + x 2 − 19 (cid:17) . ( 11 . 48 ) 11 . 8 . TWO EXAMPLES 181 Again , we write λ in place of λ ∗ . Setting the partial derivatives , with respect to x 1 and x 2 , to zero , we get the KKT equations 2 x 1 − 28 + 2 λ 1 x 1 − 22 λ 1 + λ 2 = 0 , ( 11 . 49 ) and 2 x 2 − 22 + 2 λ 1 x 2 − 26 λ 1 + λ 2 = 0 . ( 11 . 50 ) The complementary slackness conditions are λ 1 = 0 , if ( x 1 − 11 ) 2 + ( x 2 − 13 ) 2 (cid:54) = 49 , ( 11 . 51 ) and λ 2 = 0 , if x 1 + x 2 (cid:54) = 19 . ( 11 . 52 ) There are four cases to consider . First , if neither constraint is binding , the KKT equations have solution x 1 = 14 and x 2 = 11 , which is not feasible . If only the ﬁrst constraint is binding , we obtain two solutions , neither feasible . If only the second constraint is binding , we obtain x ∗ 1 = 11 , x ∗ 2 = 8 , and λ 2 = 6 . This is the optimal solution . If both constraints are binding , we obtain , with a bit of calculation , two solutions , neither feasible . The minimum value is f ( 11 , 8 ) = 18 , and the sensitivity vector is λ ∗ = ( 0 , 6 ) . Using these results , we once again illustrate Theorem 11 . 2 . The Lagrangian function at λ ∗ is L ( x , λ ∗ ) = ( x 1 − 14 ) 2 + ( x 2 − 11 ) 2 + 6 ( x 1 + x 2 − 19 ) . ( 11 . 53 ) Setting to zero the ﬁrst partial derivatives of L ( x , λ ∗ ) , we get 0 = 2 ( x 1 − 14 ) + 6 , and 0 = 2 ( x 2 − 11 ) + 6 , so that x ∗ 1 = 11 and x ∗ 2 = 8 . Note that Theorem 11 . 2 only guarantees that 18 is the inﬁmum of the function L ( x , λ ∗ ) . It does not say that this smallest value must occur at x = x ∗ or even occurs anywhere ; that is , it does not say that L ( x ∗ , λ ∗ ) ≤ L ( x , λ ∗ ) . This stronger result comes from the KKT Theorem . In this problem , we are able to use the KKT Theorem and a case - by - case analysis to ﬁnd the solution because the problem is artiﬁcial , with few variables and constraints . In practice there will be many more variables and constraints , making such a case - by - case approach impractical . It is for that reason that we turn to iterative optimization methods . 182 CHAPTER 11 . CONVEX PROGRAMMING 11 . 9 The Dual Problem The dual problem ( DP ) corresponding to P is to maximize h ( λ ) = inf x ∈ C L ( x , λ ) , ( 11 . 54 ) for λ ≥ 0 . Let MD = sup λ ≥ 0 h ( λ ) . ( 11 . 55 ) A vector λ ≥ 0 is feasible for DP if h ( λ ) > −∞ . Then DP is consistent if there are feasible λ . Recall that Theorem 11 . 2 tells us that if a sensitivity vector λ ∗ ≥ 0 exists , then h ( λ ∗ ) = MP . 11 . 9 . 1 When is MP = MD ? We have the following theorem . Theorem 11 . 8 Assume that P is super - consistent , so that there is a sen - sitivity vector λ ∗ ≥ 0 , and that MP is ﬁnite . Then • 1 ) MP = MD ; • 2 ) MD = h ( λ ∗ ) , so the supremum in Equation ( 11 . 55 ) is attained at λ ∗ ; • 3 ) if the inﬁmum in the deﬁnition of MP is attained at x ∗ , then (cid:104) λ ∗ , g ( x ∗ ) (cid:105) = 0 ; • 4 ) such an x ∗ also minimizes L ( x , λ ∗ ) over x ∈ C . Proof : For all λ ≥ 0 we have h ( λ ) = inf x ∈ C L ( x , λ ) ≤ inf x ∈ C , g ( x ) ≤ 0 L ( x , λ ) ≤ inf x ∈ C , g ( x ) ≤ 0 f ( x ) = MP . Therefore , MD ≤ MP . The diﬀerence MP − MD is known as the duality gap for CP . We also know that MP = h ( λ ∗ ) ≤ MD , so MP = MD , and the supremum in the deﬁnition of MD is attained at λ ∗ . From f ( x ∗ ) = MP = inf x ∈ C L ( x , λ ∗ ) ≤ inf x ∈ C , g ( x ) ≤ 0 L ( x , λ ∗ ) ≤ L ( x ∗ , λ ∗ ) ≤ f ( x ∗ ) , it follows that (cid:104) λ ∗ , g ( x ∗ ) (cid:105) = 0 . 11 . 10 . NON - NEGATIVE LEAST - SQUARES 183 11 . 9 . 2 The Primal - Dual Method From Theorem 11 . 8 we see that one approach to solving P is to solve DP for λ ∗ and then minimize L ( x , λ ∗ ) over x ∈ C . This is useful only if solving DP is simpler than solving P directly . Each evaluation of h ( λ ) involves minimizing L ( x , λ ) over x ∈ C . Once we have found λ ∗ , we ﬁnd x ∗ by minimizing L ( x , λ ∗ ) over x ∈ C . The advantage is that all the minimizations are over all x ∈ C , not over just the feasible vectors . 11 . 9 . 3 Using the KKT Theorem As we noted previously , using the KKT Theorem and a case - by - case anal - ysis , as in the example problems , is not practical for real - world problems involving many variables and constraints . The KKT Theorem can , how - ever , tell us something about the nature of the solution , and perhaps help us design an algorithm to solve the problem , as the following two examples illustrate . 11 . 10 Non - Negative Least - Squares If there is no solution to a system of linear equations Ax = b , then we may seek a least - squares “solution” , which is a minimizer of the function f ( x ) = I (cid:88) i = 1 (cid:16) ( J (cid:88) m = 1 A im x m ) − b i (cid:17) 2 = | | Ax − b | | 22 . The partial derivative of f ( x ) with respect to the variable x j is ∂f ∂x j ( x ) = 2 I (cid:88) i = 1 A ij (cid:16) ( J (cid:88) m = 1 A im x m ) − b i (cid:17) . Setting the gradient equal to zero , we ﬁnd that to get a least - squares solu - tion we must solve the system of equations A T ( Ax − b ) = 0 . Now we consider what happens when the additional constraints x j ≥ 0 are imposed . This problem ﬁts into the CP framework , when we deﬁne g j ( x ) = − x j , for each j . Let ˆ x be a least - squares solution . According to the KKT Theorem , for those values of j for which ˆ x j is not zero we have λ ∗ j = 0 and 184 CHAPTER 11 . CONVEX PROGRAMMING ∂f∂x j ( ˆ x ) = 0 . Therefore , if ˆ x j (cid:54) = 0 , 0 = I (cid:88) i = 1 A ij (cid:16) ( J (cid:88) m = 1 A im ˆ x m ) − b i (cid:17) . Let Q be the matrix obtained from A by deleting columns j for which ˆ x j = 0 . Then we can write Q T ( A ˆ x − b ) = 0 . If the matrix Q has full rank , which will almost always be the case , and has at least I columns , then Q T is a one - to - one linear transformation , which implies that A ˆ x = b . Therefore , when there is no non - negative solution of Ax = b , Q must have fewer than I columns , which means that ˆ x has fewer than I non - zero entries . We can state this result more formally . Deﬁnition 11 . 6 The matrix A has the full - rank property if A and every matrix Q obtained from A by deleting columns have full rank . Theorem 11 . 9 Let A have the full - rank property . Suppose there is no non - negative solution to the system of equations Ax = b . Then there is a subset S of the set { j = 1 , 2 , . . . , J } , with cardinality at most I − 1 , such that , if ˆ x is any minimizer of | | Ax − b | | 2 subject to x ≥ 0 , then ˆ x j = 0 for j not in S . Therefore , ˆ x is unique . This result has some practical implications in medical image reconstruction . 11 . 11 An Example in Image Reconstruction In many areas of image processing , including medical imaging , the vector x is a vectorized image that we seek , whose typically non - negative entries are the unknown pixel values , the entries of b are measurements obtained through the use of some device , such as a CAT - scan , and the matrix A describes , usually imperfectly , the relationship between the desired image x and the data b . In transmission tomography the data is often viewed as integrals along line segments through the object ; in the discrete version , the data may be viewed as the sums of the x j for those j for which the associated pixel intersects the given line segment . Figure 11 . 1 illustrates a head slice sub - divided into J = 36 pixels . To take an example , consider the line segment that ends in the pixel with j = 2 . It begins at the pixel with j = 30 , and passes through j = 24 , 23 , 17 , 16 , 10 , 9 , and 3 , before reaching j = 2 . If the line - integral data pertaining to that line segment is , say , 4 . 5 , we write x 2 + x 3 + x 9 + x 10 + x 16 + x 17 + x 23 + x 24 + x 30 = 4 . 5 . 11 . 11 . AN EXAMPLE IN IMAGE RECONSTRUCTION 185 We have similar equations for every line segment used by the scanner . The matrix A is then 36 by 36 , and each row has entries that are either zero or one . The row corresponding to the line segment in our example has ones in the columns j = 2 , 3 , 9 , 10 , 16 , 17 , 24 , and 30 , with zeros in the other columns . Notice that the matrix A is sparse , that is , most of its entries are zero . This is typical of such remote - sensing problems . It is helpful to note that the matrix A as just presented does not do a very good job of describing how the data is related to the pixels . By using only the values zero or one , we ignore the obvious fact that a line segment may intersect most of one pixel , while touching only a little of another . The line segment considered in our example above intersects a large portion of the pixels j = 2 , 9 , 16 , 23 , and 30 , but intersects only a small portion of j = 3 , 10 , 17 , and 24 . We need to make use of these observations in designing A , if we are to reduce the model error . We can do a better job by taking the entries of A to be numbers between zero and one that are the relative sizes of the intersection of the given line segment with the given pixel . There are other sources of error , as well : the line - integral model is only an approximation ; x - rays do not travel along exact straight lines , but along narrow strips ; the frequency content of the rays can change as the rays travel through the body ; the measured data are not precisely the sums given by the vector Ax , regardless of how accurately we describe the intersection of the line segments with the pixels . In short , the vector b also contains noise , known as measurement noise . For all these reasons , there may not be exact non - negative solutions of Ax = b , and even if there are such solutions , they may not be suitable for diagnosis . Once the data is obtained , the number of measurements I is determined . The number of pixels J is not yet ﬁxed , and we can select J to suit our needs . The scene being imaged or the patient being scanned has no pixels ; these are artiﬁcially imposed by us . If J is too small , we will not obtain the desired resolution in the reconstructed image . In the hope of improving the resolution of the reconstructed image , we may be tempted to take J , the number of pixels , larger than I , the number of equations arising from our measurement . Since the vector b consists of measured data , it is noisy and there may well not be a non - negative exact solution of Ax = b . As a result , the image obtained by non - negatively constrained least - squares will have at most I − 1 non - zero entries ; many of the pixels will be zero and they will be scattered throughout the image , making it unusable . The reconstructed images resemble stars in a night sky , and , as a result , the theorem is sometimes described as the “night sky” theorem . This “night sky” phenomenon is not restricted to least squares . The same thing happens with methods based on the Kullback - Leibler distance , such as MART , EMML and SMART . 186 CHAPTER 11 . CONVEX PROGRAMMING 11 . 12 Solving the Dual Problem In this section we use the KKT Theorem to derive an iterative algorithm to minimize the function f ( x ) = 1 2 (cid:107) x (cid:107) 22 , subject to Ax ≥ b , by solving the dual problem of maximizing h ( λ ) , over λ ≥ 0 . 11 . 12 . 1 The Primal and Dual Problems Minimizing f ( x ) over x such that Ax ≥ b is the primal problem . Here we let g i = b i − ( Ax ) i , for i = 1 , . . . , I , and the set C be all of R J . The Lagrangian is then L ( x , λ ) = 1 2 | | x | | 22 − λ T Ax + λ T b . ( 11 . 56 ) The inﬁmum of L ( x , λ ) over all x occurs when x = A T λ and so h ( λ ) = λ T b − 1 2 | | A T λ | | 22 . ( 11 . 57 ) For any x satisfying Ax ≥ b and any λ ≥ 0 we have h ( λ ) ≤ f ( x ) . If x ∗ is the unique solution of the primal problem and λ ∗ any solution of the dual problem , we have f ( x ∗ ) = h ( λ ∗ ) . The point here is that the constraints in the dual problem are easier to implement in an iterative algorithm , so solving the dual problem is the simpler task . The algorithm we present now calculates iteratively two sequences , { x k } and { λ k } , such that f ( x k ) − h ( λ k ) converges to zero . The limits of { x k } and { λ k } will be the solutions of the primal and dual problems , respectively . 11 . 12 . 2 Hildreth’s Dual Algorithm The iterative algorithm we describe here was originally published by Hil - dreth [ 128 ] , and later extended by Lent and Censor [ 147 ] . It is a row - action method in that , at each step of the iteration , only a single row of the matrix A is used . Having found x k and λ k , we use i = k ( mod I ) + 1 , A i the i - th row of A , and b i to calculate x k + 1 and λ k + 1 . We know that the optimal x ∗ and λ ∗ ≥ 0 must satisfy x ∗ = A T λ ∗ . Therefore , the algorithm guarantees that , at each step , we have λ k > 0 and x k = A T λ k . Having found x k and λ k , we proceed as follows . First , we select i = k ( mod I ) + 1 . Since h ( λ ) = b T λ − 1 2 (cid:107) A T λ (cid:107) 22 , 11 . 13 . MINIMUM ONE - NORM SOLUTIONS 187 we have ∇ h ( λ ) = b − AA T λ . A gradient ascent method to maximize h ( λ ) would then have the iterative step λ k + 1 = λ k + γ k ( b − AA T λ k ) = λ k + γ k ( b − Ax k ) , for some γ k > 0 . A row - action variant of gradient ascent modiﬁes only the i - th entry of λ at the k - th step , with λ k + 1 i = λ ki + γ k ( b i − ( Ax k ) i ) . ( 11 . 58 ) Since we require that λ k + 1 ≥ 0 , when ( b i − ( Ax k ) i ) < 0 we must select γ k so that γ k ( b i − ( Ax k ) i ) ≥ − λ ki . We then have x k + 1 = x k + γ k ( b i − ( Ax k ) i ) A Ti , which is used in the next step , in forming ∇ h ( λ k + 1 ) . Proof of convergence of this algorithm is presented in [ 83 ] . 11 . 13 Minimum One - Norm Solutions When the system of linear equations Ax = b is under - determined , it is common practice to seek a solution that also minimizes some objective function . For example , the minimum two - norm solution is the vector x satisfying Ax = b for which the ( square of the ) two - norm , | | x | | 22 = J (cid:88) j = 1 x 2 j , is minimized . Alternatively , we may seek the minimum one - norm solution , for which the one - norm , | | x | | 1 = J (cid:88) j = 1 | x j | , is minimized . If the vector x is required to be non - negative , then the one - norm is simply the sum of the entries , and minimizing the one - norm subject to Ax = b becomes a linear programming problem . This is the situation in applications involving image reconstruction . In compressed sampling [ 98 ] one seeks a solution of Ax = b having relatively few non - zero entries . The vector x here is not assumed to be non - negative , and the solution is found by minimizing the one - norm , subject to the constraints Ax = b . The one - norm is not a linear functional of x , but the problem can still be converted into a linear programming problem . 188 CHAPTER 11 . CONVEX PROGRAMMING 11 . 13 . 1 Reformulation as an LP Problem The entries of x need not be non - negative , so the problem is not yet a linear programming problem . Let B = [ A − A ] , and consider the linear programming problem of minimizing the function c T z = 2 J (cid:88) j = 1 z j , subject to the constraints z ≥ 0 , and Bz = b . Let z ∗ be the solution . We write z ∗ = (cid:20) u ∗ v ∗ (cid:21) . Then , as we shall see , x ∗ = u ∗ − v ∗ minimizes the one - norm , subject to Ax = b . First , we show that u ∗ j v ∗ j = 0 , for each j . If , say , there is a j such that 0 < v ∗ j ≤ u ∗ j , then we can create a new vector z from z ∗ by replacing the old u ∗ j with u ∗ j − v ∗ j and the old v ∗ j with zero , while maintaining Bz = b . But then , since u ∗ j − v ∗ j < u ∗ j + v ∗ j , it follows that c T z < c T z ∗ , which is a contradiction . Consequently , we have (cid:107) x ∗ (cid:107) 1 = c T z ∗ . Now we select any x with Ax = b . Write u j = x j , if x j ≥ 0 , and u j = 0 , otherwise . Let v j = u j − x j , so that x = u − v . Then let z = (cid:20) uv (cid:21) . Then b = Ax = Bz , and c T z = (cid:107) x (cid:107) 1 . Therefore (cid:107) x ∗ (cid:107) 1 = c T z ∗ ≤ c T z = (cid:107) x (cid:107) 1 , and x ∗ must be a minimum one - norm solution . The reader is invited to provide an example showing that a minimum one - norm solution of Ax = b need not be unique . 11 . 13 . 2 Image Reconstruction In image reconstruction from limited linear - functional data , the vector x is non - negative and arises as a vectorization of a two - dimensional image . The data we have pertaining to x is linear and takes the form Ax = b , for some matrix A and vector b . Typically , the problem is under - determined , since the number of entries of x is the number of pixels in the image , which we can make as large as we wish . The problem then is to select , from 11 . 13 . MINIMUM ONE - NORM SOLUTIONS 189 among all the feasible images , one particular one that has a good chance of being near the correct image . One approach is to take the solution of Ax = b having the minimum Euclidean norm , | | x | | 2 . Algorithms such as the projected ART and projected Landweber iterative methods can be used to ﬁnd such solutions . Another approach is to ﬁnd the non - negative solution of Ax = b for which the one - norm , | | x | | 1 = J (cid:88) j = 1 | x j | , is minimized [ 98 ] . Since the x j are to be non - negative , the problem becomes the following : minimize f ( x ) = J (cid:88) j = 1 x j , subject to g i ( x ) = ( Ax ) i − b i = 0 , for i = 1 , . . . , I , and g i ( x ) = − x i − I ≤ 0 , for i = I + 1 , . . . , I + J . When the system Ax = b is under - determined , the minimum one - norm solution tends to be sparser than the minimum two - norm solution . A simple example will illustrate this point . Consider the equation x + 2 y = 1 . The minimum two - norm solution is ( 0 . 2 , 0 . 4 ) , with two - norm √ 55 , which is about 0 . 4472 , but one - norm equal to 0 . 6 . The solution ( 0 , 0 . 5 ) has two - norm and one - norm equal to 0 . 5 , and the solution ( 1 . 0 , 0 ) has two - norm and one - norm equal to 1 . 0 . Therefore , the minimum one - norm solution is ( 0 , 0 . 5 ) , not ( 0 . 2 , 0 . 4 ) . We can write the one - norm of the vector x as | | x | | 1 = J (cid:88) j = 1 | x j | 2 | x j | . The PDFT approach to image reconstruction [ 53 ] selects the solution of Ax = b that minimizes the weighted two - norm | | x | | 2 w = J (cid:88) j = 1 | x j | 2 p j = J (cid:88) j = 1 | x j | 2 w j , where p j > 0 is a prior estimate of the non - negative image x to be recon - structed , and w j = p − 1 j . To the extent that p j accurately models the main features of x , such as which x j are nearly zero and which are not , the two approaches should give similar reconstructions . The PDFT can be imple - mented using the ART algorithm ( see [ 188 , 189 , 190 ] ) . For more discussion of one - norm minimization , see the chapter on compressed sensing . 190 CHAPTER 11 . CONVEX PROGRAMMING 11 . 14 Exercises Ex . 11 . 1 Prove Proposition 11 . 1 . Ex . 11 . 2 Prove Corollary 11 . 1 . Ex . 11 . 3 Show that , although K ( 1 , 1 ) = 0 , which is the saddle value , the point ( 1 , 1 ) is not a saddle point for the function K ( x , y ) = x 2 − y 2 . Ex . 11 . 4 Prove Theorem 11 . 3 . Ex . 11 . 5 Apply the gradient form of the KKT Theorem to minimize the function f ( x , y ) = ( x + 1 ) 2 + y 2 over all x ≥ 0 and y ≥ 0 . Ex . 11 . 6 ( [ 112 ] ) Consider the following problem : minimize the function f ( x , y ) = | x − 2 | + | y − 2 | , subject to g ( x , y ) = y 2 − x ≤ 0 , and h ( x , y ) = x 2 + y 2 − 1 = 0 . Illustrate this problem graphically , showing lines of constant value of f and the feasible region of points satisfying the constraints . Where is the solution of the problem ? Where is the solution , if the equality constraint is removed ? Where is the solution , if both constraints are removed ? Ex . 11 . 7 ( [ 175 ] , Ex . 5 . 2 . 9 ( a ) ) Minimize the function f ( x , y ) = (cid:112) x 2 + y 2 , subject to x + y ≤ 0 . Show that the function MP ( z ) is not diﬀerentiable at z = 0 . Ex . 11 . 8 ( [ 175 ] , Ex . 5 . 2 . 9 ( b ) ) Minimize the function f ( x , y ) = − 2 x − y , subject to x + y ≤ 1 , 0 ≤ x ≤ 1 , and y ≥ 0 . Again , show that the function MP ( z ) is not diﬀerentiable at z = 0 . 11 . 15 . COURSE HOMEWORK 191 Ex . 11 . 9 ( Duﬃn ; [ 175 ] , Ex . 5 . 2 . 9 ( c ) ) Minimize the function f ( x , y ) = e − y , subject to (cid:112) x 2 + y 2 − x ≤ 0 . Show that the function MP ( z ) is not continuous at z = 0 . Ex . 11 . 10 Apply the theory of convex programming to the primal Quadratic Programming Problem ( QP ) , which is to minimize the function f ( x ) = 1 2 x T Qx , subject to a T x ≤ c , where a (cid:54) = 0 is in R J , c < 0 is real , and Q is symmetric , and positive - deﬁnite . Ex . 11 . 11 Use Theorem 11 . 6 to prove that any real N by N symmetric matrix has N mutually orthonormal eigenvectors . 11 . 15 Course Homework Try Exercises 11 . 3 , 11 . 4 , 11 . 5 , and 11 . 6 . 192 CHAPTER 11 . CONVEX PROGRAMMING Figure 11 . 1 : Line segments through a discretized object . Chapter 12 Iterative Optimization 12 . 1 Chapter Summary Now we begin our discussion of iterative methods for solving optimization problems . Topics include the role of the gradient operator , the Newton - Raphson ( NR ) method , and various computationally simpler variants of the NR method . 12 . 2 The Need for Iterative Methods We know from beginning calculus that , if we want to optimize a diﬀeren - tiable function g ( x ) of a single real variable x , we begin by ﬁnding the places where the derivative is zero , g (cid:48) ( x ) = 0 . Similarly , if we want to optimize a diﬀerentiable function g ( x ) of a real vector variable x , we begin by ﬁnding the places where the gradient is zero , ∇ g ( x ) = 0 . Generally , though , this is not the end of the story , for we still have to solve an equation for the opti - mal x . Unless we are fortunate , solving this equation algebraically may be computationally expensive , or may even be impossible , and we will need to turn to iterative methods . This suggests that we might use iterative methods to minimize g ( x ) directly , and not solve an equation . For example , suppose we wish to solve the over - determined system of linear equations Ax = b , but we don’t know if the system has solutions . In that case , we may wish to minimize the function g ( x ) = 1 2 (cid:107) Ax − b (cid:107) 22 , to get a least - squares solution . We know from linear algebra that if the matrix A T A is invertible , then the unique minimizer of g ( x ) is given by x ∗ = ( A T A ) − 1 A T b . 193 194 CHAPTER 12 . ITERATIVE OPTIMIZATION In many applications , the number of equations and the number of unknowns may be quite large , making it expensive even to calculate the entries of the matrix A T A . In such cases , we can ﬁnd x ∗ using an iterative method such as Landweber’s Algorithm , which has the iterative step x k + 1 = x k + γA T ( b − Ax k ) . The sequence { x k } converges to x ∗ for any value of γ in the interval ( 0 , 2 / λ max ) , where λ max is the largest eigenvalue of the matrix A T A . 12 . 3 Optimizing Functions of a Single Real Variable Suppose g : R → R is diﬀerentiable and attains its minimum value . We want to minimize the function g ( x ) . Solving g (cid:48) ( x ) = 0 to ﬁnd the optimal x = x ∗ may not be easy , so we may turn to an iterative algorithm for ﬁnding roots of g (cid:48) ( x ) , or one that minimizes g ( x ) directly . In the latter case , we may consider an iterative procedure x k + 1 = x k − γ k g (cid:48) ( x k ) , ( 12 . 1 ) for some sequence { γ k } of positive numbers . Such iterative procedures are called descent algorithms because , if g (cid:48) ( x k ) > 0 , then we want to move to the left of x k , while , if g (cid:48) ( x k ) < 0 , we want to move to the right . We shall be particularly interested in algorithms in which γ k = γ for all k . We denote by T the operator Tx = x − γg (cid:48) ( x ) . ( 12 . 2 ) Then , using g (cid:48) ( x ∗ ) = 0 , we ﬁnd that | x ∗ − x k + 1 | = | Tx ∗ − Tx k | . ( 12 . 3 ) 12 . 3 . 1 Iteration and Operators The iterative methods we shall consider involve the calculation of a se - quence { x k } of vectors in R J , according to the formula x k + 1 = Tx k , where T is some function T : R J → R J ; such functions are called operators on R J . The operator Tx = x − g (cid:48) ( x ) above is an operator on R . Deﬁnition 12 . 1 An operator T on R J is continuous at x in the interior of its domain if lim z → x (cid:107) Tz − Tx (cid:107) = 0 . 12 . 4 . DESCENT METHODS 195 All the operators we shall consider are continuous . The sequences generated by iterative methods can then be written { T k x 0 } , where x = x 0 is the starting point for the iteration and T k means apply the operator T k times . If the sequence { x k } converges to a limit vector ˆ x in the domain of T , then , taking the limit , as k → + ∞ , on both sides of x k + 1 = Tx k , and using the continuity of the operator T , we have ˆ x = T ˆ x , that is , the limit vector ˆ x is a ﬁxed point of T . Deﬁnition 12 . 2 A vector x in the domain of the operator T is a ﬁxed point of T if T ˆ x = ˆ x . The set of all ﬁxed points of T is denoted Fix ( T ) . We have several concerns , when we use iterative methods : • Does the operator T have any ﬁxed points ? • Does the sequence { T k x 0 } converge ? • Does convergence depend on the choice of x 0 ? • When the sequence { T k x 0 } converges , is the limit a solution to our problem ? • How fast does the sequence { T k x 0 } converge ? • How diﬃcult is it to perform a single step , going from x k to x k + 1 ? • How does the limit depend on the starting vector x 0 ? To answer these questions , we will need to learn about the properties of the particular operator T being used . We begin our study of iterative optimization algorithms with the gradient descent methods , particularly as they apply to convex functions . 12 . 4 Descent Methods Suppose that g ( x ) is convex and the function f ( x ) = g (cid:48) ( x ) is L - Lipschitz . If g ( x ) is twice diﬀerentiable , this would be the case if 0 ≤ g (cid:48)(cid:48) ( x ) ≤ L , ( 12 . 4 ) for all x . If γ is in the interval ( 0 , 2 L ) , then the operator Tx = x − γg (cid:48) ( x ) is an averaged operator ; from the KMO Theorem 30 . 2 , we know that the 196 CHAPTER 12 . ITERATIVE OPTIMIZATION iterative sequence { T k x 0 } converges to a minimizer of g ( x ) , whenever a minimizer exists . If g ( x ) is convex and f ( x ) = g (cid:48) ( x ) is L - Lipschitz , then 1 L g (cid:48) ( x ) is non - expansive , so that , by Theorem 10 . 20 1 L g (cid:48) ( x ) is fne and g (cid:48) ( x ) is 1 L - ism . Then , as we shall see later , the operator Tx = x − γg (cid:48) ( x ) ( 12 . 5 ) is av whenever 0 < γ < 2 L , and so the iterative sequence x k + 1 = Tx k = x k − γg (cid:48) ( x k ) converges to a minimizer of g ( x ) , whenever minimizers exist . In the next section we extend these results to functions of several vari - ables . 12 . 5 Optimizing Functions of Several Real Vari - ables Suppose g : R J → R is diﬀerentiable and attains its minimum value . We want to minimize the function g ( x ) . Solving ∇ g ( x ) = 0 to ﬁnd the optimal x = x ∗ may not be easy , so we may turn to an iterative algorithm for ﬁnding roots of ∇ g ( x ) , or one that minimizes g ( x ) directly . From Cauchy’s Inequality , we know that the directional derivative of g ( x ) , at x = a , and in the direction of the vector unit vector d , satisﬁes | g (cid:48) ( a ; d ) | = | (cid:104)∇ g ( a ) , d (cid:105) | ≤ (cid:107)∇ g ( a ) (cid:107) 2 (cid:107) d (cid:107) 2 , and that g (cid:48) ( a ; d ) attains its most positive value when the direction d is a positive multiple of ∇ g ( a ) . This suggests steepest descent optimization . Steepest descent iterative optimization makes use of the fact that the direction of greatest increase of g ( x ) away from x = x k is in the direc - tion d = ∇ g ( x k ) . Therefore , we select as the next vector in the iterative sequence x k + 1 = x k − γ k ∇ g ( x k ) , ( 12 . 6 ) for some γ k > 0 . Ideally , we would choose γ k optimally , so that g ( x k − γ k ∇ g ( x k ) ) ≤ g ( x k − γ ∇ g ( x k ) ) , ( 12 . 7 ) for all γ ≥ 0 ; that is , we would proceed away from x k , in the direction of −∇ g ( x k ) , stopping just as g ( x ) begins to increase . Then we call this point x k + 1 and repeat the process . Lemma 12 . 1 Suppose that x k + 1 is chosen using the optimal value of γ k , as described by Equation ( 12 . 7 ) . Then (cid:104)∇ g ( x k + 1 ) , ∇ g ( x k ) (cid:105) = 0 . ( 12 . 8 ) 12 . 5 . OPTIMIZING FUNCTIONS OF SEVERAL REAL VARIABLES 197 In practice , ﬁnding the optimal γ k is not a simple matter . Instead , one can try a few values of α and accept the best of these few , or one can try to ﬁnd a constant value γ of the parameter having the property that the iterative step x k + 1 = x k − γ ∇ g ( x k ) leads to a convergent sequence . It is this latter approach that we shall consider here . We denote by T the operator Tx = x − γ ∇ g ( x ) . ( 12 . 9 ) Then , using ∇ g ( x ∗ ) = 0 , we ﬁnd that (cid:107) x ∗ − x k + 1 (cid:107) 2 = (cid:107) Tx ∗ − Tx k (cid:107) 2 . ( 12 . 10 ) We would like to know if there are choices for γ that imply convergence of the iterative sequence . As in the case of functions of a single variable , for functions g ( x ) that are convex , the answer is yes . If g ( x ) is convex and F ( x ) = ∇ g ( x ) is L - Lipschitz , then G ( x ) = 1 L ∇ g ( x ) is ﬁrmly non - expansive . Then , as we shall see later , for γ > 0 , the operator Tx = x − γ ∇ g ( x ) ( 12 . 11 ) is averaged , whenever 0 < γ < 2 L . It follows from the KMO Theorem 30 . 2 that the iterative sequence x k + 1 = Tx k = x k − γ ∇ g ( x k ) converges to a minimizer of g ( x ) , whenever minimizers exist . For example , the function g ( x ) = 12 (cid:107) Ax − b (cid:107) 22 is convex and its gradient is f ( x ) = ∇ g ( x ) = A T ( Ax − b ) . A steepest descent algorithm for minimizing g ( x ) then has the iterative step x k + 1 = x k − γ k A T ( Ax k − b ) , where the parameter γ k should be selected so that g ( x k + 1 ) < g ( x k ) . The linear operator that transforms each vector x into A T Ax has the prop - erty that (cid:107) A T Ax − A T Ay (cid:107) 2 ≤ λ max (cid:107) x − y (cid:107) 2 , where λ max is the largest eigenvalue of the matrix A T A ; this operator is then L - Lipschitz , for L = λ max . Consequently , the operator that trans - forms x into 1 L A T Ax is non - expansive . 198 CHAPTER 12 . ITERATIVE OPTIMIZATION 12 . 6 Projected Gradient - Descent Methods As we have remarked previously , one of the fundamental problems in con - tinuous optimization is to ﬁnd a minimizer of a function over a subset of R J . The following propositions will help to motivate the projected gradient - descent algorithm . Proposition 12 . 1 Let f : R J → R be convex and diﬀerentiable and let C ⊆ R J be closed , non - empty and convex . Then x ∈ C minimizes f over C if and only if (cid:104)∇ f ( x ) , c − x (cid:105) ≥ 0 , ( 12 . 12 ) for all c ∈ C . Proof : Since f is convex , we know from Theorem 10 . 16 that f ( b ) − f ( a ) ≥ (cid:104)∇ f ( a ) , b − a (cid:105) , for all a and b . Therefore , if (cid:104)∇ f ( x ) , c − x (cid:105) ≥ 0 , for all c ∈ C , then f ( c ) − f ( x ) ≥ 0 for all c ∈ C also . Conversely , suppose that f ( c ) − f ( x ) ≥ 0 , for all c ∈ C . For each c ∈ C , let d = c − x (cid:107) c − x (cid:107) 2 , so that (cid:104)∇ f ( x ) , d (cid:105) = 1 (cid:107) c − x (cid:107) 2 (cid:104)∇ f ( x ) , c − x (cid:105) is the directional derivative of f at x , in the direction of c . Because f ( c ) − f ( x ) ≥ 0 , for all c ∈ C , this directional derivative must be non - negative . Proposition 12 . 2 Let f : R J → R be convex and diﬀerentiable and let C ⊆ R J be closed , non - empty and convex . Then x ∈ C minimizes f over C if and only if x = P C ( x − γ ∇ f ( x ) ) , for all γ > 0 . Proof : By Proposition 6 . 4 , we know that x = P C ( x − γ ∇ f ( x ) ) if and only if (cid:104) x − ( x − γ ∇ f ( x ) ) , c − x (cid:105) ≥ 0 , for all c ∈ C . But this is equivalent to (cid:104)∇ f ( x ) , c − x (cid:105) ≥ 0 , 12 . 6 . PROJECTED GRADIENT - DESCENT METHODS 199 for all c ∈ C , which , by the previous proposition , is equivalent to x mini - mizing the function f over all c ∈ C . This leads us to the projected gradient - descent algorithm . According to the previous proposition , we know that x minimizes f over C if and only if x is a ﬁxed point of the operator Tx = P C ( x − γ ∇ f ( x ) ) . We provide an elementary proof of the following theorem : Theorem 12 . 1 Let f : R J → R be convex and diﬀerentiable , with ∇ f L - Lipschitz . Let C be any closed , convex subset of R J . For 0 < γ < 1 L , let T = P C ( I − γ ∇ f ) . If T has ﬁxed points , then the sequence { x k } given by x k = Tx k − 1 converges to a ﬁxed point of T , which is then a minimizer of f over C . The iterative step is given by x k = P C ( x k − 1 − γ ∇ f ( x k − 1 ) ) . ( 12 . 13 ) Any ﬁxed point of the operator T minimizes the function f ( x ) over x in C . It is a consequence of the KMO Theorem 30 . 2 for averaged operators that convergence holds for 0 < γ < 2 L . The proof given here employs sequential unconstrained minimization and avoids using the non - trivial re - sults that , because the operator 1 L ∇ f is non - expansive , it is ﬁrmly non - expansive ( see Theorem 10 . 20 ) , and that the product of averaged operators is again averaged ( see Proposition 30 . 1 ) . 12 . 6 . 1 Using Auxiliary - Function Methods We can use auxiliary - function ( AF ) methods to prove Theorem 12 . 1 . For each k = 1 , 2 , . . . let G k ( x ) = f ( x ) + 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f ( x , x k − 1 ) , ( 12 . 14 ) where D f ( x , x k − 1 ) = f ( x ) − f ( x k − 1 ) − (cid:104)∇ f ( x k − 1 ) , x − x k − 1 (cid:105) . ( 12 . 15 ) Since f ( x ) is convex , D f ( x , y ) ≥ 0 for all x and y and is the Bregman distance formed from the function f [ 25 ] . The auxiliary function g k ( x ) = 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f ( x , x k − 1 ) ( 12 . 16 ) 200 CHAPTER 12 . ITERATIVE OPTIMIZATION can be rewritten as g k ( x ) = D h ( x , x k − 1 ) , ( 12 . 17 ) where h ( x ) = 1 2 γ (cid:107) x (cid:107) 22 − f ( x ) . ( 12 . 18 ) Therefore , g k ( x ) ≥ 0 whenever h ( x ) is a convex function . We know that h ( x ) is convex if and only if (cid:104)∇ h ( x ) − ∇ h ( y ) , x − y (cid:105) ≥ 0 , ( 12 . 19 ) for all x and y . This is equivalent to 1 γ (cid:107) x − y (cid:107) 22 − (cid:104)∇ f ( x ) − ∇ f ( y ) , x − y (cid:105) ≥ 0 . ( 12 . 20 ) Since ∇ f is L - Lipschitz , the inequality ( 12 . 20 ) holds whenever 0 < γ < 1 L . Lemma 12 . 2 The x k that minimizes G k ( x ) over x ∈ C is given by Equa - tion ( 12 . 13 ) . Proof : We know that (cid:104)∇ G k ( x k ) , x − x k (cid:105) ≥ 0 , for all x ∈ C . With ∇ G k ( x k ) = 1 γ ( x k − x k − 1 ) + ∇ f ( x k − 1 ) , we have (cid:104) x k − ( x k − 1 − γ ∇ f ( x k − 1 ) ) , x − x k (cid:105) ≥ 0 , for all x ∈ C . We then conclude that x k = P C ( x k − 1 − γ ∇ f ( x k − 1 ) ) . 12 . 6 . 2 Proving Convergence A relatively simple calculation shows that G k ( x ) − G k ( x k ) = 1 2 γ (cid:107) x − x k (cid:107) 22 + 1 γ (cid:104) x k − ( x k − 1 − γ ∇ f ( x k − 1 ) ) , x − x k (cid:105) . ( 12 . 21 ) 12 . 7 . THE NEWTON - RAPHSON APPROACH 201 From Equation ( 12 . 13 ) it follows that G k ( x ) − G k ( x k ) ≥ 1 2 γ (cid:107) x − x k (cid:107) 22 , ( 12 . 22 ) for all x ∈ C , so that G k ( x ) − G k ( x k ) ≥ 1 2 γ (cid:107) x − x k (cid:107) 22 − D f ( x , x k ) = g k + 1 ( x ) . ( 12 . 23 ) Now let ˆ x minimize f ( x ) over all x ∈ C . Then G k ( ˆ x ) − G k ( x k ) = f ( ˆ x ) + g k ( ˆ x ) − f ( x k ) − g k ( x k ) ≤ f ( ˆ x ) + G k − 1 ( ˆ x ) − G k − 1 ( x k − 1 ) − f ( x k ) − g k ( x k ) , so that (cid:16) G k − 1 ( ˆ x ) − G k − 1 ( x k − 1 ) (cid:17) − (cid:16) G k ( ˆ x ) − G k ( x k ) (cid:17) ≥ f ( x k ) − f ( ˆ x ) + g k ( x k ) ≥ 0 . Therefore , the sequence { G k ( ˆ x ) − G k ( x k ) } is decreasing and the sequences { g k ( x k ) } and { f ( x k ) − f ( ˆ x ) } converge to zero . From G k ( ˆ x ) − G k ( x k ) ≥ 1 2 γ (cid:107) ˆ x − x k (cid:107) 22 , it follows that the sequence { x k } is bounded . Let { x k n } converge to x ∗ ∈ C with { x k n + 1 } converging to x ∗∗ ∈ C ; we then have f ( x ∗ ) = f ( x ∗∗ ) = f ( ˆ x ) . Replacing the generic ˆ x with x ∗∗ , we ﬁnd that { G k n + 1 ( x ∗∗ ) − G k n + 1 ( x k n + 1 ) } is decreasing . By Equation ( 12 . 21 ) , this subsequence converges to zero ; therefore , the entire sequence { G k ( x ∗∗ ) − G k ( x k ) } converges to zero . From the inequality in ( 12 . 22 ) , we conclude that the sequence { (cid:107) x ∗∗ − x k (cid:107) 22 } con - verges to zero , and so { x k } converges to x ∗∗ . This completes the proof of the theorem . 12 . 7 The Newton - Raphson Approach The Newton - Raphson approach to minimizing a real - valued function f : R J → R involves ﬁnding x ∗ such that ∇ f ( x ∗ ) = 0 . 12 . 7 . 1 Functions of a Single Variable We begin with the problem of ﬁnding a root of a function g : R → R . If x 0 is not a root , compute the line tangent to the graph of g at x = x 0 and let x 1 be the point at which this line intersects the horizontal axis ; that is , x 1 = x 0 − g ( x 0 ) / g (cid:48) ( x 0 ) . ( 12 . 24 ) 202 CHAPTER 12 . ITERATIVE OPTIMIZATION Continuing in this fashion , we have x k + 1 = x k − g ( x k ) / g (cid:48) ( x k ) . ( 12 . 25 ) This is the Newton - Raphson algorithm for ﬁnding roots . Convergence , when it occurs , is usually more rapid than gradient descent , but requires that x 0 be suﬃciently close to the solution . Now suppose that f : R → R is a real - valued function that we wish to minimize by solving f (cid:48) ( x ) = 0 . Letting g ( x ) = f (cid:48) ( x ) and applying the Newton - Raphson algorithm to g ( x ) gives the iterative step x k + 1 = x k − f (cid:48) ( x k ) / f (cid:48)(cid:48) ( x k ) . ( 12 . 26 ) This is the Newton - Raphson optimization algorithm . Now we extend these results to functions of several variables . 12 . 7 . 2 Functions of Several Variables The Newton - Raphson algorithm for ﬁnding roots of functions g : R J → R J has the iterative step x k + 1 = x k − [ J ( g ) ( x k ) ] − 1 g ( x k ) , ( 12 . 27 ) where J ( g ) ( x ) is the Jacobian matrix of ﬁrst partial derivatives , ∂g m ∂x j ( x k ) , for g ( x ) = ( g 1 ( x ) , . . . , g J ( x ) ) T . To minimize a function f : R J → R , we let g ( x ) = ∇ f ( x ) and ﬁnd a root of g . Then the Newton - Raphson iterative step becomes x k + 1 = x k − [ ∇ 2 f ( x k ) ] − 1 ∇ f ( x k ) , ( 12 . 28 ) where ∇ 2 f ( x ) = J ( g ) ( x ) is the Hessian matrix of second partial derivatives of f . The quadratic approximation to f ( x ) around the point x k is f ( x ) ≈ f ( x k ) + (cid:104)∇ f ( x k ) , x − x k (cid:105) + 1 2 ( x − x k ) T ∇ 2 f ( x k ) ( x − x k ) . The right side of this equation attains its minimum value when 0 = ∇ f ( x k ) + ∇ 2 f ( x k ) ( x − x k ) , that is , when x = x k + 1 as given by Equation ( 12 . 28 ) . If f ( x ) is a quadratic function , that is , f ( x ) = x T Qx + x T b + c , for constant invertible matrix Q and constant vectors b and c , then the Newton - Raphson iteration converges to the answer in one step . Therefore , 12 . 8 . APPROXIMATE NEWTON - RAPHSON METHODS 203 if f ( x ) is close to quadratic , the convergence should be reasonably rapid . This leads to the notion of self - concordant functions , for which the third derivative of f ( x ) is small , relative to the second derivative [ 163 ] . From the quadratic approximation f ( x k + 1 ) ≈ f ( x k ) + (cid:104)∇ f ( x k ) , x k + 1 − x k (cid:105) + 1 2 ( x k + 1 − x k ) T ∇ 2 f ( x k ) ( x k + 1 − x k ) , and the formula for the iterative NR step we ﬁnd that f ( x k + 1 ) − f ( x k ) ≈ − 1 2 ∇ f ( x k ) T [ ∇ 2 f ( x k ) ] − 1 ∇ f ( x k ) . If the Hessian matrix ∇ 2 f ( x k ) is always positive - deﬁnite , which may not be the case , then its inverse will also be positive - deﬁnite and the NR step will reduce the value of the objective function f ( x ) . One area of research in the intersection of numerical linear algebra and optimization focuses on ﬁnding positive - deﬁnite approximations of the Hessian matrix [ 202 ] . 12 . 8 Approximate Newton - Raphson Methods To use the NR method to minimize f ( x ) , at each step of the iteration we need to solve a system of equations involving the Hessian matrix for f . There are many iterative procedures designed to retain much of the advantages of the NR method , while avoiding the use of the Hessian matrix , or , indeed , while avoiding the use of the gradient . These methods are discussed in most texts on numerical methods [ 163 ] . We sketch brieﬂy some of these approaches . 12 . 8 . 1 Avoiding the Hessian Matrix Quasi - Newton methods , designed to avoid having to calculate the Hessian matrix , are often used instead of the Newton - Raphson algorithm . The iterative step of the quasi - Newton methods is x k + 1 = x k − B − 1 k ∇ f ( x k ) , ( 12 . 29 ) where the matrix B k is an approximation of ∇ 2 f ( x k ) that is easier to compute . In the case of g : R → R , the second derivative of g ( x ) is approximately g (cid:48)(cid:48) ( x k ) ≈ g (cid:48) ( x k ) − g (cid:48) ( x k − 1 ) x k − x k − 1 . ( 12 . 30 ) This suggests that , for the case of functions of several variables , the matrix B k should be selected so that B k ( x k − x k − 1 ) = ∇ f ( x k ) − ∇ f ( x k − 1 ) . ( 12 . 31 ) 204 CHAPTER 12 . ITERATIVE OPTIMIZATION In addition to satisfying Equation ( 12 . 31 ) , the matrix B k should also be symmetric and positive - deﬁnite . Finally , we should be able to obtain B k + 1 relatively easily from B k . The BFGS Method The Broyden , Fletcher , Goldfarb , and Shanno ( BFGS ) method uses the rank - two update formula B k + 1 = B k − ( B k s k ) ( B k s k ) T ( s k ) T B k s k + y k ( y k ) T ( y k ) T s k , ( 12 . 32 ) with s k = x k + 1 − x k , ( 12 . 33 ) and y k = ∇ f ( x k + 1 ) − ∇ f ( x k ) . ( 12 . 34 ) The Broyden Class A general class of update methods , known as the Broyden class , uses the update formula B k + 1 = B k − ( B k s k ) ( B k s k ) T ( s k ) T B k s k + y k ( y k ) T ( y k ) T s k + φ ( ( s k ) T B k s k ) u k ( u k ) T , ( 12 . 35 ) with φ a scalar and u k = y k ( y k ) T s k − B k s k ( s k ) T B k s k . ( 12 . 36 ) When φ = 0 we get the BFGS method , while the choice of φ = 1 gives the Davidon , Fletcher , and Powell ( DFP ) method . Note that for the updates in the Broyden class , the matrix B k + 1 has the form B k + 1 = B k + a k ( a k ) T + b k ( b k ) T + c k ( c k ) T , for certain vectors a k , b k and c k . Therefore , the inverse of B k + 1 can be ob - tained easily from the inverse of B k , with three applications of the Sherman - Morrison - Woodbury Identity ( see Exercise 8 . 4 ) . 12 . 9 . DERIVATIVE - FREE METHODS 205 12 . 8 . 2 Avoiding the Gradient Quasi - Newton methods use an approximation of the Hessian matrix that is simpler to calculate , but still employ the gradient at each step . For func - tions g : R → R , the derivative can be approximated by a ﬁnite diﬀerence , that is , g (cid:48) ( x k ) ≈ g ( x k ) − g ( x k − 1 ) x k − x k − 1 . ( 12 . 37 ) In the case of functions of several variables , the gradient vector can be approximated by using a ﬁnite - diﬀerence approximation for each of the ﬁrst partial derivatives . 12 . 9 Derivative - Free Methods In many important applications , calculating values of the function to be optimized is expensive and calculating gradients impractical . In such cases , it is common to use direct - search methods . Generally , these are iterative methods that are easy to program , do not employ derivatives or their ap - proximations , require relatively few function evaluations , and are useful even when the measurements are noisy . 12 . 9 . 1 Multi - directional Search Algorithms Methods such as the multi - directional search algorithms begin with the values of the function f ( x ) at J + 1 points , where x is in R J , and then use these values to move to a new set of points . These points are chosen to describe a simplex pattern in R J , that is , they do not all lie on a single hyperplane in R J . For that reason , these methods are sometimes called simplex methods , although they are unrelated to Dantzig’s method of the same name . The Nelder - Mead algorithm [ 164 , 142 , 155 ] is one such simplex algorithm . 12 . 9 . 2 The Nelder - Mead Algorithm For simplicity , we follow McKinnon [ 155 ] and describe the Nelder - Mead ( NM ) algorithm only for the case of J = 2 . The NM algorithm begins with the choice of vertices : ORDER : obtain b , s , and w , with f ( b ) ≤ f ( s ) ≤ f ( w ) . Then take m = 1 2 ( b + s ) . 206 CHAPTER 12 . ITERATIVE OPTIMIZATION Let the search line be L ( ρ ) = m + ρ ( m − w ) , and r = L ( 1 ) = 2 m − w . • { if f ( r ) < f ( b ) } let e = L ( 2 ) . If f ( e ) < f ( b ) accept e ; otherwise accept r . • { if f ( b ) ≤ f ( r ) } then – { if f ( r ) < f ( s ) } accept r . – { if f ( s ) ≤ f ( r ) } ∗ { if f ( r ) < f ( w ) } let c = L ( 0 . 5 ) · { if f ( c ) ≤ f ( r ) } accept c ; · { if f ( r ) < f ( c ) } go to SHRINK . ∗ { if f ( w ) ≤ f ( r ) } let c = L ( − 0 . 5 ) . · { if f ( c ) < f ( w ) } accept c ; otherwise go to SHRINK . Replace w with the accepted point and go to ORDER . SHRINK : Replace s with 12 ( s + b ) and w with 12 ( w + b ) ; go to ORDER . 12 . 9 . 3 Comments on the Nelder - Mead Algorithm Although the Nelder - Mead algorithm is quite popular in many areas of ap - plications , relatively little of a theoretical nature is known . The interested reader is directed to the papers [ 142 , 155 ] , as well as to more recent work by Margaret Wright of NYU . A good treatment of the Nelder - Mead algo - rithm , along with a number of other derivative - free techniques , is the new book by Conn , Scheinberg and Vicente [ 89 ] . 12 . 10 Rates of Convergence In this section we illustrate the concept of rate of convergence [ 30 ] by con - sidering the ﬁxed - point iteration x k + 1 = g ( x k ) , for the twice continuously diﬀerentiable function g : R → R . We suppose that g ( z ) = z and we are interested in the distance | x k − z | . 12 . 10 . 1 Basic Deﬁnitions Deﬁnition 12 . 3 Suppose the sequence { x k } converges to z . If there are positive constants λ and α such that lim k →∞ | x k + 1 − z | | x k − z | α = λ , ( 12 . 38 ) 12 . 10 . RATES OF CONVERGENCE 207 then { x k } is said to converge to z with order α and asymptotic error con - stant λ . If α = 1 , the convergence is said to be linear ; if α = 2 , the convergence is said to be quadratic . 12 . 10 . 2 Illustrating Quadratic Convergence According to the Extended Mean Value Theorem , g ( x ) = g ( z ) + g (cid:48) ( z ) ( x − z ) + 1 2 g (cid:48)(cid:48) ( c ) ( x − z ) 2 , ( 12 . 39 ) for some c between x and z . Suppose now that x k → z and , in addition , g (cid:48) ( z ) = 0 . Then we have x k + 1 = g ( x k ) = z + 1 2 g (cid:48)(cid:48) ( c k ) ( x k − z ) 2 , ( 12 . 40 ) for some c k between x k and z . Therefore , | x k + 1 − z | = 1 2 | g (cid:48)(cid:48) ( c k ) | | x k − z | 2 , ( 12 . 41 ) and the convergence is quadratic , with λ = | g (cid:48)(cid:48) ( z ) | . 12 . 10 . 3 Motivating the Newton - Raphson Method Suppose that we are seeking a root z of the function f : R → R . We deﬁne g ( x ) = x − h ( x ) f ( x ) , ( 12 . 42 ) for some function h ( x ) to be determined . Then f ( z ) = 0 implies that g ( z ) = z . In order to have quadratic convergence of the iterative sequence x k + 1 = g ( x k ) , we want g (cid:48) ( z ) = 0 . From g (cid:48) ( x ) = 1 − h (cid:48) ( x ) f ( x ) − h ( x ) f (cid:48) ( x ) , ( 12 . 43 ) it follows that we want h ( z ) = 1 / f (cid:48) ( z ) . ( 12 . 44 ) Therefore , we choose h ( x ) = 1 / f (cid:48) ( x ) , ( 12 . 45 ) so that g ( x ) = x − f ( x ) / f (cid:48) ( x ) . ( 12 . 46 ) The iteration then takes the form x k + 1 = g ( x k ) = x k − f ( x k ) / f (cid:48) ( x k ) , ( 12 . 47 ) which is the Newton - Raphson iteration . 208 CHAPTER 12 . ITERATIVE OPTIMIZATION 12 . 11 Feasible - Point Methods We consider now the problem of minimizing the function f ( x ) : R J → R , subject to the equality constraints Ax = b , where A is an I by J real matrix , with rank I and I < J . The methods we consider here are feasible - point methods , also called interior - point methods . 12 . 11 . 1 The Projected Gradient Algorithm Let C be the set of all x in R J such that Ax = b . For every z in R J , we have P C z = P NS ( A ) z + A T ( AA T ) − 1 b , ( 12 . 48 ) where NS ( A ) is the null space of A . Using P NS ( A ) z = z − A T ( AA T ) − 1 Az , ( 12 . 49 ) we have P C z = z + A T ( AA T ) − 1 ( b − Az ) . ( 12 . 50 ) The iteration in Equation ( 12 . 13 ) becomes c k = c k − 1 − γP NS ( A ) ∇ f ( c k − 1 ) , ( 12 . 51 ) which converges to a solution for any γ in ( 0 , 1 L ) , whenever solutions exist . We call this method the projected gradient algorithm . In the next subsection we present a somewhat simpler approach . 12 . 11 . 2 Reduced Gradient Methods Let c 0 be a feasible point , that is , Ac 0 = b . Then c = c 0 + p is also feasible if p is in the null space of A , that is , Ap = 0 . Let Z be a J by J − I matrix whose columns form a basis for the null space of A . We want p = Zv for some v . The best v will be the one for which the function φ ( v ) = f ( c 0 + Zv ) is minimized . We can apply to the function φ ( v ) the steepest descent method , or Newton - Raphson or any other minimization technique . The steepest descent method , applied to φ ( v ) , is called the reduced steepest descent method [ 163 ] . The gradient of φ ( v ) , also called the reduced gradient , is ∇ φ ( v ) = Z T ∇ f ( c ) , where c = c 0 + Zv . We choose the matrix Z so that ρ ( Z T Z ) ≤ 1 , so that the gradient operator ∇ φ is L - Lipschitz . 12 . 11 . FEASIBLE - POINT METHODS 209 For the reduced gradient algorithm , the iteration in Equation ( 12 . 13 ) becomes v k = v k − 1 − γ ∇ φ ( v k − 1 ) , ( 12 . 52 ) so that the iteration for c k = c 0 + Zv k is c k = c k − 1 − γZZ T ∇ f ( c k − 1 ) . ( 12 . 53 ) The vectors c k are feasible and the sequence { c k } converges to a solution , whenever solutions exist , for any 0 < γ < 1 L . 12 . 11 . 3 The Reduced Newton - Raphson Method The next method we consider is a modiﬁcation of the Newton - Raphson method , in which we begin with a feasible point and each NR step is in the null space of the matrix A , to maintain the condition Ax = b . The discussion here is taken from [ 163 ] . Once again , our objective is to minimize φ ( v ) . The Newton - Raphson method , applied to φ ( v ) , is called the reduced Newton - Raphson method . The Hessian matrix of φ ( v ) , also called the reduced Hessian matrix , is ∇ 2 φ ( v ) = Z T ∇ 2 f ( x ) Z , where x = ˆ x + Zv , so algorithms to minimize φ ( v ) can be written in terms of the gradient and Hessian of f itself . The reduced NR algorithm can then be viewed in terms of the vectors { v k } , with v 0 = 0 and v k + 1 = v k − [ ∇ 2 φ ( v k ) ] − 1 ∇ φ ( v k ) ; ( 12 . 54 ) the corresponding x k is x k = ˆ x + Zv k . An Example Consider the problem of minimizing the function f ( x ) = 1 2 x 21 − 1 2 x 23 + 4 x 1 x 2 + 3 x 1 x 3 − 2 x 2 x 3 , subject to x 1 − x 2 − x 3 = − 1 . Let ˆ x = [ 1 , 1 , 1 ] T . Then the matrix A is A = [ 1 , − 1 , − 1 ] and the vector b is b = [ − 1 ] . Let the matrix Z be Z =   1 1 1 0 0 1   . ( 12 . 55 ) 210 CHAPTER 12 . ITERATIVE OPTIMIZATION The reduced gradient at ˆ x is then Z T ∇ f ( ˆ x ) = (cid:20) 1 1 0 1 0 1 (cid:21)   820   = (cid:20) 108 (cid:21) , ( 12 . 56 ) and the reduced Hessian matrix at ˆ x is Z T ∇ 2 f ( ˆ x ) Z = (cid:20) 1 1 0 1 0 1 (cid:21)   1 4 3 4 0 − 2 3 − 2 − 1     1 1 1 0 0 1   = (cid:20) 9 6 6 6 (cid:21) . ( 12 . 57 ) Then the reduced Newton - Raphson equation yields v = (cid:20) − 2 / 3 − 2 / 3 (cid:21) , ( 12 . 58 ) and the reduced Newton - Raphson direction is p = Zv =   − 4 / 3 − 2 / 3 − 2 / 3   . ( 12 . 59 ) Since the function φ ( v ) is quadratic , one reduced Newton - Raphson step suﬃces to obtain the solution , x ∗ = [ − 1 / 3 , 1 / 3 , 1 / 3 ] T . 12 . 11 . 4 A Primal - Dual Approach Once again , the objective is to minimize the function f ( x ) : R J → R , subject to the equality constraints Ax = b . According to the Karush - Kuhn - Tucker Theorem 11 . 5 , ∇ L ( x , λ ) = 0 at the optimal values of x and λ , where the Lagrangian L ( x , λ ) is L ( x , λ ) = f ( x ) + λ T ( b − Ax ) . Finding a zero of the gradient of L ( x , λ ) means that we have to solve the equations ∇ f ( x ) − A T λ = 0 and Ax = b . We deﬁne the function G ( x , λ ) taking values in R J × R I to be G ( x , λ ) = ( ∇ f ( x ) − A T λ , Ax − b ) T . We then apply the NR method to ﬁnd a zero of the function G . The Jacobian matrix for G is J G ( x , λ ) = (cid:20) ∇ 2 f ( x ) − A T A 0 (cid:21) , 12 . 12 . SIMULATED ANNEALING 211 so one step of the NR method is ( x k + 1 , λ k + 1 ) T = ( x k , λ k ) T − J G ( x k , λ k ) − 1 G ( x k , λ k ) . ( 12 . 60 ) We can rewrite this as ∇ 2 f ( x k ) ( x k + 1 − x k ) − A T ( λ k + 1 − λ k ) = A T λ k − ∇ f ( x k ) , ( 12 . 61 ) and A ( x k + 1 − x k ) = b − Ax k . ( 12 . 62 ) It follows from Equation ( 12 . 62 ) that Ax k + 1 = b , for k = 0 , 1 , . . . , so that this primal - dual algorithm is a feasible - point algorithm . In the chapter on Quadratic Programming we shall see that the Equa - tions 12 . 61 and 12 . 62 produced by each step of the NR method are also precisely the conditions that the KKT Theorem gives for a solution to a particular quadratic - programming problem . Since , as we shall see , every quadratic - programming problem can be reformulated as a linear program - ming problem , each step of the primal - dual iteration can be computed using the simplex algorithm . Later , in our discussion of barrier - function methods and Karmarkar’s algorithm , we shall see how this primal - dual algorithm can be used to solve linear - programming problems . 12 . 12 Simulated Annealing In this chapter we have focused on the minimization of convex functions . For such functions , a local minimum is necessarily a global one . For non - convex functions , this is not the case . For example , the function f ( x ) = x 4 − 8 x 3 + 20 x 2 − 16 . 5 x + 7 has a local minimum around x = 0 . 6 and a global minimum around x = 3 . 5 . The descent methods we have discussed can get caught at a local minimum that is not global , since we insist on always taking a step that reduces f ( x ) . The simulated annealing algorithm [ 1 , 157 ] , also called the Metropolis algorithm , is sometimes able to avoid being trapped at a local minimum by permitting an occasional step that increases f ( x ) . The name comes from the analogy with the physical problem of lowering the energy of a solid by ﬁrst raising the temperature , to bring the particles into a disorganized state , and then gradually reducing the temperature , so that a more organized state is achieved . Suppose we have calculated x k . We now generate a random direction and a small random step length . If the new vector x k + ∆ x makes f ( x ) smaller , we accept the vector as x k + 1 . If not , then we accept this vector , with probability Prob ( accept ) = exp (cid:16) f ( x k ) − f ( x k + ∆ x ) c k (cid:17) , 212 CHAPTER 12 . ITERATIVE OPTIMIZATION where c k > 0 , known as the temperature , is chosen by the user . As the it - eration proceeds , the temperature c k is gradually reduced , making it easier to accept increases in f ( x ) early in the process , but harder later . How to select the temperatures is an art , not a science . 12 . 13 Exercises Ex . 12 . 1 Prove Lemma 12 . 1 . Ex . 12 . 2 Apply the Newton - Raphson method to obtain an iterative pro - cedure for ﬁnding √ a , for any positive a . For which x 0 does the method converge ? There are two answers , of course ; how does the choice of x 0 determine which square root becomes the limit ? Ex . 12 . 3 Apply the Newton - Raphson method to obtain an iterative pro - cedure for ﬁnding a 1 / 3 , for any real a . For which x 0 does the method converge ? Ex . 12 . 4 Extend the Newton - Raphson method to complex variables . Redo the previous exercises for the case of complex a . For the complex case , a has two square roots and three cube roots . How does the choice of x 0 aﬀect the limit ? Warning : The case of the cube root is not as simple as it may appear , and has a close connection to fractals and chaos ; see [ 185 ] . Ex . 12 . 5 Use the reduced Newton - Raphson method to minimize the func - tion 12 x T Qx , subject to Ax = b , where Q =   0 − 13 − 6 − 3 − 13 23 − 9 3 − 6 − 9 − 12 1 − 3 3 1 − 1   , A = (cid:20) 2 1 2 1 1 1 3 − 1 (cid:21) , and b = (cid:20) 32 (cid:21) . Start with x 0 =   1100   . Ex . 12 . 6 Use the reduced steepest descent method with an exact line search to solve the problem in the previous exercise . 12 . 14 . COURSE HOMEWORK 213 12 . 14 Course Homework Try Exercises 12 . 1 and 12 . 4 . Computer exercises 12 . 2 , 12 . 3 , and 12 . 5 are optional . 214 CHAPTER 12 . ITERATIVE OPTIMIZATION Chapter 13 Solving Systems of Linear Equations 13 . 1 Chapter Summary Optimization plays an important role in solving systems of linear equations . In many applications the linear system is under - determined , meaning that there are multiple , indeed , inﬁnitely many , solutions to the system . It is natural , then , to seek a solution that is optimal , in some sense . When the system involves measured data , as is often the case , there may be no exact solution , or an exact solution to the system may be too noisy . Then , an approximate solution , or a solution to a related , regularized , system is sought . In this chapter , we discuss brieﬂy both of these situations , focusing on iterative algorithms that have been designed for such problems . For a more in - depth analysis of these problems , see [ 60 ] . 13 . 2 Arbitrary Systems of Linear Equations We begin by considering systems of the form Ax = b , where A is a real M by N matrix , b a real M by 1 vector , and x is the N by 1 solution vector being sought . If the system has solutions , if there are no additional constraints being imposed on x , and if M and N are not too large , standard non - iterative methods , such as Gauss elimination , can be used to ﬁnd a solution . When one or more of these conditions is not met , iterative methods are usually needed . 215 216 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS 13 . 2 . 1 Under - determined Systems of Linear Equations Suppose that Ax = b is a consistent linear system of M equations in N unknowns , where M < N . Then there are inﬁnitely many solutions . A standard procedure in such cases is to ﬁnd that solution x having the smallest two - norm | | x | | 2 = (cid:118)(cid:117)(cid:117)(cid:116) N (cid:88) n = 1 | x n | 2 . As we shall see shortly , the minimum two - norm solution of Ax = b is a vector of the form x = A T z , where A T denotes the transpose of the matrix A . Then Ax = b becomes AA T z = b . Typically , ( AA T ) − 1 will exist , and we get z = ( AA T ) − 1 b , from which it follows that the minimum norm solution is x = A T ( AA T ) − 1 b . When M and N are not too large , forming the matrix AA T and solving for z is not prohibitively expensive and time - consuming . However , in image processing the vector x is often a vectorization of a two - dimensional ( or even three - dimensional ) image and M and N can be on the order of tens of thousands or more . The ART algorithm gives us a fast method for ﬁnding the minimum norm solution without computing AA T . We begin by describing the minimum two - norm solution of a consistent system Ax = b . Theorem 13 . 1 The minimum two - norm solution of Ax = b has the form x = A T z for some M - dimensional complex vector z . Proof : Let the null space of the matrix A be all N - dimensional complex vectors w with Aw = 0 . If Ax = b then A ( x + w ) = b for all w in the null space of A . If x = A T z and w is in the null space of A , then | | x + w | | 22 = | | A T z + w | | 22 = ( A T z + w ) T ( A T z + w ) = ( A T z ) T ( A T z ) + ( A T z ) T w + w T ( A T z ) + w T w = | | A T z | | 22 + ( A T z ) T w + w T ( A T z ) + | | w | | 22 = | | A T z | | 22 + | | w | | 22 , since w T ( A T z ) = ( Aw ) T z = 0 T z = 0 and ( A T z ) T w = z T Aw = z T 0 = 0 . Therefore , | | x + w | | 2 = | | A T z + w | | 2 > | | A T z | | 2 = | | x | | 2 unless w = 0 . This completes the proof . 13 . 2 . ARBITRARY SYSTEMS OF LINEAR EQUATIONS 217 13 . 2 . 2 Over - determined Systems of Linear Equations When the system Ax = b has no solutions , we can look for approximate solutions . For example , we can calculate a vector x for which the function f ( x ) = 1 2 (cid:107) Ax − b (cid:107) 22 is minimized ; such a vector is called a least - squares solution . Setting the gradient equal to zero , we obtain 0 = ∇ f ( x ) = A T ( Ax − b ) , so that x = ( A T A ) − 1 A T b , provided that A T A is invertible , which is usually the case . 13 . 2 . 3 Landweber’s Method Landweber’s iterative method [ 143 ] has the following iterative step : for k = 0 , 1 , . . . let x k + 1 = x k + γA T ( b − Ax k ) , ( 13 . 1 ) where A T denotes the transpose of the matrix A . If the parameter γ is chosen to lie within the interval ( 0 , 2 / L ) , where L is the largest eigenvalue of the matrix A T A , then the sequence { x k } converges to the solution of Ax = b for which (cid:107) x − x 0 (cid:107) 2 is minimized , provided that solutions exist . If not , the sequence { x k } converges to a least - squares solution : the limit is the minimizer of the function (cid:107) b − Ax (cid:107) 2 for which (cid:107) x − x 0 (cid:107) 2 is minimized . A least - squares solution of Ax = b is an exact solution of the system A T Ax = A T b . One advantage to using Landweber’s algorithm is that we do not have to use the matrix A T A , which can be time - consuming to calculate when M and N are large . As discussed in [ 60 ] , reasonable estimates of L can also be obtained without knowing A T A . 13 . 2 . 4 The Projected Landweber Algorithm Suppose that C is a non - empty , closed and convex subset of R N , and we want to ﬁnd an exact or approximate solution of Ax = b within C . The projected Landweber algorithm ( PLW ) has the following iterative step : x k + 1 = P C (cid:16) x k + γA T ( b − Ax k ) (cid:17) , ( 13 . 2 ) where P C x denotes the orthogonal projection of x onto C . 218 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS Theorem 13 . 2 If the parameter γ is chosen to lie within the interval ( 0 , 2 / L ) , the sequence { x k } converges to an x in C that solves Ax = b , provided that solutions exist in C . If not , the sequence { x k } converges to a minimizer , over x in C , of the function (cid:107) b − Ax (cid:107) , if such a minimizer exists . Proof : Suppose that z ∈ C minimizes f ( x ) = 12 (cid:107) b − Ax (cid:107) 2 , over all x ∈ C . Then we have z = P C ( z − γA T ( Az − b ) ) . Therefore , (cid:107) z − x k + 1 (cid:107) 2 = (cid:107) P C ( z − γA T ( Az − b ) ) − P C ( x k − γA T ( Ax k − b ) ) (cid:107) 2 ≤ (cid:107) ( z − γA T ( Az − b ) ) − ( x k − γA T ( Ax k − b ) ) (cid:107) 2 = (cid:107) z − x k + γA T ( Ax k − Az ) (cid:107) 2 = (cid:107) z − x k (cid:107) 2 + 2 γ (cid:104) z − x k , A T ( Ax k − Az ) (cid:105) + γ 2 (cid:107) A T ( Ax k − Az ) (cid:107) 2 ≤ (cid:107) z − x k (cid:107) 2 − 2 γ (cid:107) Az − Ax k (cid:107) 2 + γ 2 (cid:107) A T (cid:107) 2 (cid:107) Az − Ax k (cid:107) 2 = (cid:107) z − x k (cid:107) 2 − ( 2 γ − γ 2 L ) (cid:107) Az − Ax k (cid:107) 2 . So we have (cid:107) z − x k (cid:107) 2 − (cid:107) z − x k + 1 (cid:107) 2 ≥ ( 2 γ − γ 2 L ) (cid:107) Az − Ax k (cid:107) 2 ≥ 0 . Consequently , we have that the sequence { (cid:107) z − x k (cid:107) } is decreasing , the sequence { (cid:107) Az − Ax k (cid:107) } converges to zero , the sequence { x k } is bounded , and a subsequence converges to some x ∗ ∈ C , with Ax ∗ = Az . It follows that { (cid:107) x ∗ − x k (cid:107) } converges to zero , so that { x k } converges to x ∗ , which is a minimizer of f ( x ) over x ∈ C . 13 . 2 . 5 The Split - Feasibility Problem Suppose now that C and Q are non - empty , closed and convex subsets of R N and R M , respectively , and we want x in C for which Ax is in Q ; this is the split - feasibility problem ( SFP ) [ 71 ] . The CQ algorithm [ 50 , 51 ] has the following iterative step : x k + 1 = P C (cid:16) x k − γA T ( I − P Q ) Ax k (cid:17) . ( 13 . 3 ) For γ in the interval ( 0 , 2 / L ) , the CQ algorithm converges to a solution of the SFP , when solutions exist . If not , it converges to a minimizer , over x in C , of the function f ( x ) = 1 2 (cid:107) P Q Ax − Ax (cid:107) 22 , ( 13 . 4 ) provided such minimizers exist . Both the Landweber and projected Landwe - ber methods are special cases of the CQ algorithm . The following theorem describes the gradient of the function f ( x ) in Equation ( 13 . 4 ) . 13 . 2 . ARBITRARY SYSTEMS OF LINEAR EQUATIONS 219 Theorem 13 . 3 Let t ∈ ∂f ( x ) . Then t = A T ( I − P Q ) Ax , so that t = ∇ f ( x ) . Proof : First , we show that t = A T z ∗ for some z ∗ . Let s = x + w , where w is an arbitrary member of the null space of A . Then As = Ax and f ( s ) = f ( x ) . From 0 = f ( s ) − f ( x ) ≥ (cid:104) t , s − x (cid:105) = (cid:104) t , w (cid:105) , it follows that (cid:104) t , w (cid:105) = 0 , for all w in the null space of A , from which we conclude that t is in the range of A T . Therefore , we can write t = A T z ∗ . Let u be chosen so that (cid:107) A ( u − x ) (cid:107) = 1 , and let (cid:15) > 0 . We then have (cid:107) P Q Ax − A ( x + (cid:15) ( u − x ) ) (cid:107) 2 − (cid:107) P Q Ax − Ax (cid:107) 2 ≥ (cid:107) P Q ( Ax + (cid:15) ( u − x ) ) − A ( x + (cid:15) ( u − x ) ) (cid:107) 2 − (cid:107) P Q Ax − Ax (cid:107) 2 ≥ 2 (cid:15) (cid:104) t , u − x (cid:105) . Therefore , since (cid:107) P Q Ax − A ( x + (cid:15) ( u − x ) ) (cid:107) 2 = (cid:107) P Q Ax − Ax (cid:107) 2 − 2 (cid:15) (cid:104) P Q Ax − Ax , A ( u − x ) (cid:105) + (cid:15) 2 , it follows that (cid:15) 2 ≥ (cid:104) P Q Ax − Ax + z ∗ , A ( u − x ) (cid:105) = −(cid:104) A T ( I − P Q ) Ax − t , u − x (cid:105) . Since (cid:15) is arbitrary , it follows that (cid:104) A T ( I − P Q ) Ax − t , u − x (cid:105) ≥ 0 , for all appropriate u . But this is also true if we replace u with v = 2 x − u . Consequently , we have (cid:104) A T ( I − P Q ) Ax − t , u − x (cid:105) = 0 . Now we select u − x = ( A T ( I − P Q ) Ax − t ) / (cid:107) AA T ( I − P Q ) Ax − At (cid:107) , from which it follows that A T ( I − P Q ) Ax = t . 220 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS Corollary 13 . 1 The gradient of the function f ( x ) = 1 2 (cid:107) x − P C x (cid:107) 2 is ∇ f ( x ) = x − P C x , and the gradient of the function g ( x ) = 1 2 (cid:16) (cid:107) x (cid:107) 22 − (cid:107) x − P C x (cid:107) 22 (cid:17) is ∇ g ( x ) = P C x . Extensions of the CQ algorithm have been applied recently to problems in intensity - modulated radiation therapy [ 69 , 73 ] . 13 . 2 . 6 An Extension of the CQ Algorithm Let C ∈ R N and Q ∈ R M be closed , non - empty convex sets , and let A and B be J by N and J by M real matrices , respectively . The problem is to ﬁnd x ∈ C and y ∈ Q such that Ax = By . When there are no such x and y , we consider the problem of minimizing f ( x , y ) = 1 2 (cid:107) Ax − By (cid:107) 22 , over x ∈ C and y ∈ Q . Let K = C × Q in R N × R M . Deﬁne G = [ A − B ] , w = (cid:20) xy (cid:21) , so that G T G = (cid:20) A T A − A T B − B T A B T B (cid:21) . The original problem can now be reformulated as ﬁnding w ∈ K with Gw = 0 . We shall consider the more general problem of minimizing the function (cid:107) Gw (cid:107) over w ∈ K . The projected Landweber algorithm ( PLW ) solves this more general problem . The iterative step of the PLW algorithm is the following : w k + 1 = P K ( w k − γG ∗ ( Gw k ) ) . ( 13 . 5 ) Expressing this in terms of x and y , we obtain x k + 1 = P C ( x k − γA ∗ ( Ax k − By k ) ) ; ( 13 . 6 ) and y k + 1 = P Q ( y k + γB ∗ ( Ax k − By k ) ) . ( 13 . 7 ) The PLW converges , in this case , to a minimizer of (cid:107) Gw (cid:107) over w ∈ K , whenever such minimizers exist , for 0 < γ < 2 ρ ( G T G ) . 13 . 2 . ARBITRARY SYSTEMS OF LINEAR EQUATIONS 221 13 . 2 . 7 The Algebraic Reconstruction Technique The algorithms presented previously in this chapter are simultaneous meth - ods , meaning that all the equations of the system are used at each step of the iteration . Such methods tend to converge slowly , which presents a major problem for large systems . The algebraic reconstruction technique ( ART ) is a row - action method , meaning that only a single equation is used at each step of the iteration . The ART has the following iterative step : for k = 0 , 1 , . . . and m = k ( mod M ) + 1 , let x k + 1 n = x kn + A mn ( b m − ( Ax k ) m ) / N (cid:88) j = 1 | A mj | 2 . ( 13 . 8 ) We can describe the ART geometrically as follows : once we have x k and m , the vector x k + 1 is the orthogonal projection of x k onto the hyperplane H m given by H m = { x | ( Ax ) m = b m } . The Landweber algorithm can be similarly described : the vector x k + 1 is a weighted sum of the orthogonal projections of x k onto each of the hyper - planes H m , for all m . In the consistent case , when the system Ax = b has solutions , the ART converges to the solution for which (cid:107) x − x 0 (cid:107) is minimized . Unlike the simultaneous methods , when no solution exists , the ART sequence { x k } does not converge to a single vector , but subsequences do converge to members of a limit cycle consisting of ( typically ) M distinct vectors . Generally speaking , the ART will converge , in the consistent case , faster than the Landweber method , especially if the equations are selected in a random order [ 127 ] . 13 . 2 . 8 Double ART Because the ART is signiﬁcantly faster to converge than the Landweber method in the consistent case , we would like to be able to use the ART in the inconsistent case , as well , to get a least - squares solution . To avoid the limit - cycle behavior of ART in this case , we can use double ART ( DART ) . We know from basic linear algebra that the vector b can be written as b = A ˆ x + ˆ w , where ˆ x minimizes the function (cid:107) b − Ax (cid:107) 2 and w = ˆ w minimizes the function (cid:107) b − w (cid:107) 2 , subject to A T w = 0 . Said another way , A ˆ x is the orthogonal projection of b onto the range of A and ˆ w is the orthogonal projection of b onto the null space of A T . In DART we apply the ART algorithm twice , ﬁrst to the consistent linear system A T w = 0 , with w 0 = b , so that the limit is ˆ w , and then to 222 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS the consistent system Ax = b − ˆ w . The result is the minimizer of (cid:107) b − Ax (cid:107) for which (cid:107) x − x 0 (cid:107) is minimized . 13 . 3 Regularization In many applications in which systems of linear equations must be solved , the entries of the vector b are measured data and Ax = b is a model that attempts to describe , in a somewhat simpliﬁed way , how b depends on the unknown vector x . The statistical noise in the measured data introduces one type of error , while the approximate nature of the model itself intro - duces another . Because the model is simpliﬁed , but the data b is noisy , an exact solution x itself usually ends up noisy . Also , it is common for the system to be ill - conditioned , that is , for small changes in b to lead to large changes in the exact solution x . This happens when the ratio of the largest to smallest eigenvalues of the matrix A T A is large . In such cases even a minimum - norm solution of Ax = b can have a large norm . Consequently , we often do not want an exact solution of Ax = b , even when such solutions exist . Instead , we regularize the problem . 13 . 3 . 1 Norm - Constrained Least - Squares One way to regularize the problem is to minimize not (cid:107) b − Ax (cid:107) 2 , but , say , f ( x ) = (cid:107) b − Ax (cid:107) 22 + (cid:15) 2 (cid:107) x (cid:107) 22 , ( 13 . 9 ) for some small (cid:15) > 0 . Now we are still trying to make (cid:107) b − Ax (cid:107) 2 small , but managing to keep (cid:107) x (cid:107) 2 from becoming too large in the process . This leads to a norm - constrained least - squares solution . The minimizer of f ( x ) is the unique solution ˆ x (cid:15) of the system ( A T A + (cid:15) 2 I ) x = A T b . ( 13 . 10 ) When M and N are large , we need ways to solve this system without having to deal with the matrix A T A + (cid:15) 2 I . The Landweber method allowed us to avoid A T A in calculating the least - squares solution . Is there a similar method to use now ? Yes , there is . 13 . 3 . 2 Regularizing Landweber’s Algorithm Our goal is to minimize the function f ( x ) in Equation ( 13 . 9 ) . Notice that this is equivalent to minimizing the function F ( x ) = | | Bx − c | | 22 , ( 13 . 11 ) 13 . 3 . REGULARIZATION 223 for B = (cid:20) A(cid:15)I (cid:21) , ( 13 . 12 ) and c = (cid:20) b 0 (cid:21) , ( 13 . 13 ) where 0 denotes a column vector with all entries equal to zero . The Landwe - ber iteration for the problem Bx = c is x k + 1 = x k + αB T ( c − Bx k ) , ( 13 . 14 ) for 0 < α < 2 / ρ ( B T B ) , where ρ ( B T B ) is the largest eigenvalue , or the spectral radius , of B T B . Equation ( 13 . 14 ) can be written as x k + 1 = ( 1 − α(cid:15) 2 ) x k + αA T ( b − Ax k ) . ( 13 . 15 ) 13 . 3 . 3 Regularizing the ART We would like to get the regularized solution ˆ x (cid:15) by taking advantage of the faster convergence of the ART . Fortunately , there are ways to ﬁnd ˆ x (cid:15) , using only the matrix A and the ART algorithm . We discuss two methods for using ART to obtain regularized solutions of Ax = b . The ﬁrst one is presented in [ 53 ] , while the second one is due to Eggermont , Herman , and Lent [ 105 ] . In our ﬁrst method we use ART to solve the system of equations given in matrix form by [ A T (cid:15)I ] (cid:20) uv (cid:21) = 0 . ( 13 . 16 ) We begin with u 0 = b and v 0 = 0 . Then , the lower component of the limit vector is v ∞ = − (cid:15) ˆ x (cid:15) , while the upper limit is u ∞ = b − A ˆ x (cid:15) . The method of Eggermont et al . is similar . In their method we use ART to solve the system of equations given in matrix form by [ A (cid:15)I ] (cid:20) xv (cid:21) = b . ( 13 . 17 ) We begin at x 0 = 0 and v 0 = 0 . Then , the limit vector has for its upper component x ∞ = ˆ x (cid:15) , and (cid:15)v ∞ = b − A ˆ x (cid:15) . 224 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS 13 . 4 Non - Negative Systems of Linear Equa - tions We turn now to non - negative systems of linear equations , which we shall denote by y = Px , with the understanding that P is an I by J matrix with non - negative entries P ij , such that , for each j , the column sum s j = I (cid:88) i = 1 P ij is positive , y is an I by 1 vector with positive entries y i , and we seek a solution x with non - negative entries x j . We say that the system is consis - tent whenever such non - negative solutions exist . Denote by X the set of all non - negative x for which the vector Px has only positive entries . In what follows , all vectors x will lie in X and the initial vector x 0 will always be positive . 13 . 4 . 1 The Multiplicative ART Both the algebraic reconstruction technique ( ART ) and the multiplicative algebraic reconstruction technique ( MART ) were introduced by Gordon , Bender and Herman [ 121 ] as two iterative methods for discrete image re - construction in transmission tomography . It was noticed somewhat later that the ART is a special case of Kaczmarz’s algorithm [ 134 ] . Both methods are what are called row - action methods , meaning that each step of the iteration uses only a single equation from the system . The MART is limited to non - negative systems for which non - negative solutions are sought . In the under - determined case , both algorithms ﬁnd the solution closest to the starting vector , in the two - norm or weighted two - norm sense for ART , and in the cross - entropy sense for MART , so both algorithms can be viewed as solving optimization problems . We consider two diﬀerent versions of the MART . MART I The iterative step of the ﬁrst version of MART , which we call MART I , is the following : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = x kj (cid:16) y i ( Px k ) i (cid:17) P ij / m i , for j = 1 , . . . , J , where the parameter m i is deﬁned to be m i = max { P ij | j = 1 , . . . , J } . The MART I algorithm converges , in the consistent case , to the non - negative solution for which the KL distance KL ( x , x 0 ) is minimized . 13 . 4 . NON - NEGATIVE SYSTEMS OF LINEAR EQUATIONS 225 MART II The iterative step of the second version of MART , which we shall call MART II , is the following : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = x kj (cid:16) y i ( Px k ) i (cid:17) P ij / s j n i , for j = 1 , . . . , J , where the parameter n i is deﬁned to be n i = max { P ij s − 1 j | j = 1 , . . . , J } . The MART II algorithm converges , in the consistent case , to the non - negative solution for which the KL distance J (cid:88) j = 1 s j KL ( x j , x 0 j ) is minimized . Just as the Landweber method is a simultaneous cousin of the row - action ART , there is a simultaneous cousin of the MART , called , not surprisingly , the simultaneous MART ( SMART ) . 13 . 4 . 2 The Simultaneous MART The SMART minimizes the cross - entropy , or Kullback - Leibler distance , f ( x ) = KL ( Px , y ) , over nonnegative vectors x [ 93 , 81 , 184 , 39 ] . Having found the vector x k , the next vector in the SMART sequence is x k + 1 , with entries given by x k + 1 j = x kj exp (cid:16) s − 1 j I (cid:88) i = 1 P ij log (cid:16) y i ( Px k ) i (cid:17)(cid:17) . ( 13 . 18 ) As with MART II , when there are non - negative solutions of y = Px , the SMART converges to the solution for which the KL distance J (cid:88) j = 1 s j KL ( x j , x 0 j ) is minimized . 13 . 4 . 3 The EMML Iteration The expectation maximization maximum likelihood algorithm ( EMML ) min - imizes the function f ( x ) = KL ( y , Px ) , over nonnegative vectors x [ 186 , 226 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS 144 , 199 , 145 , 39 ] . Having found the vector x k , the next vector in the EMML sequence is x k + 1 , with entries given by x k + 1 j = x kj s − 1 j (cid:16) I (cid:88) i = 1 P ij (cid:16) y i ( Px k ) i (cid:17)(cid:17) . ( 13 . 19 ) The iterative step of the EMML is closely related to that of the SMART , except that the exponentiation and logarithm are missing . When there are non - negative solutions of the system y = Px , the EMML converges to a non - negative solution , but no further information about this solution is known . Both the SMART and the EMML are slow to converge , particularly when the system is large . 13 . 4 . 4 Alternating Minimization In [ 39 ] the SMART and the EMML were derived using the following alter - nating minimization approach . For each x ∈ X , let r ( x ) and q ( x ) be the I by J arrays with entries r ( x ) ij = x j P ij y i / ( Px ) i , ( 13 . 20 ) and q ( x ) ij = x j P ij . ( 13 . 21 ) In the iterative step of the SMART we get x k + 1 by minimizing the function KL ( q ( x ) , r ( x k ) ) = I (cid:88) i = 1 J (cid:88) j = 1 KL ( q ( x ) ij , r ( x k ) ij ) over x ≥ 0 . Note that KL ( Px , y ) = KL ( q ( x ) , r ( x ) ) . Similarly , the iterative step of the EMML is to minimize the function KL ( r ( x k ) , q ( x ) ) to get x = x k + 1 . Note that KL ( y , Px ) = KL ( r ( x ) , q ( x ) ) . 13 . 4 . 5 The Row - Action Variant of EMML When there are non - negative solutions of y = Px , the MART converges faster than the SMART , and to the same solution . The SMART involves exponentiation and a logarithm , and the MART a non - integral power , both of which complicate their calculation . The EMML is considerably simpler in this respect , but , like SMART , converges slowly . We would like to have a row - action variant of the EMML that converges faster than the EMML in the consistent case , but is easier to calculate than the MART . The EM - MART is such an algorithm . As with the MART , we distinguish two versions , EM - MART I and EM - MART II . When the system y = Px has non - negative solutions , both EM - MART I and EM - MART II converge to non - negative solutions , but nothing further is known about these solutions . To motivate these algorithms , we rewrite the MART algorithms as follows : 13 . 5 . REGULARIZED SMART AND EMML 227 MART I The iterative step of MART I can be written as follows : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = x kj exp (cid:16)(cid:16) P ij m i (cid:17) log (cid:16) y i ( Px k ) i (cid:17)(cid:17) , or , equivalently , as log x k + 1 j = (cid:16) 1 − P ij m i (cid:17) log x kj + (cid:16) P ij m i (cid:17) log (cid:16) x kj y i ( Px k ) i (cid:17) . ( 13 . 22 ) MART II Similarly , the iterative step of MART II can be written as follows : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = x kj exp (cid:16)(cid:16) P ij s j n i (cid:17) log (cid:16) y i ( Px k ) i (cid:17)(cid:17) , or , equivalently , as log x k + 1 j = (cid:16) 1 − P ij s j n i (cid:17) log x kj + (cid:16) P ij s j n i (cid:17) log (cid:16) x kj y i ( Px k ) i (cid:17) . ( 13 . 23 ) We obtain the EM - MART I and EM - MART II simply by removing the logarithms in Equations ( 13 . 22 ) and ( 13 . 23 ) , respectively . EM - MART I The iterative step of EM - MART I is as follows : for k = 0 , 1 , . . . , and i = k ( mod I ) + 1 , let x k + 1 j = (cid:16) 1 − P ij m i (cid:17) x kj + (cid:16) P ij m i (cid:17)(cid:16) x kj y i ( Px k ) i (cid:17) . ( 13 . 24 ) EM - MART II The iterative step of EM - MART II is as follows : x k + 1 j = (cid:16) 1 − P ij s j n i (cid:17) x kj + (cid:16) P ij s j n i (cid:17)(cid:16) x kj y i ( Px k ) i (cid:17) . ( 13 . 25 ) 13 . 5 Regularized SMART and EMML As with the Landweber algorithm , there are situations that arise in prac - tice in which , because of noisy measurements , the exact or approximate solutions of y = Px provided by the SMART and EMML algorithms are not suitable . In such cases , we need to regularize the SMART and the EMML , which is usually done by including a penalty function . 228 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS 13 . 5 . 1 Regularized SMART As we have seen , the iterative step of the SMART is obtained by minimizing the function KL ( q ( x ) , r ( x k ) ) over non - negative x , and the limit of the SMART minimizes KL ( Px , y ) . We can regularize by minimizing KL ( Px , y ) + KL ( x , p ) , where the vector p with positive entries p j is a prior estimate of the solution . To obtain x k + 1 from x k , we minimize KL ( q ( x ) , r ( x k ) ) + J (cid:88) j = 1 δ j KL ( x j , p j ) . There are many penalty functions we could use here , but the one we have chosen permits the minimizing x k + 1 to be obtained in closed form . The iterative step of the regularized SMART is as follows : log x k + 1 j = δ j δ j + s j log p j + 1 δ j + s j x kj I (cid:88) i = 1 P ij log (cid:16) y i ( Px k ) i (cid:17) . ( 13 . 26 ) 13 . 5 . 2 Regularized EMML As we have seen , the iterative step of the EMML is obtained by minimizing the function KL ( r ( x k ) , q ( x ) ) over non - negative x , and the limit of the EMML minimizes KL ( y , Px ) . We can regularize by minimizing KL ( y , Px ) + KL ( p , x ) . To obtain x k + 1 from x k , we minimize KL ( r ( x k ) , q ( x ) ) + J (cid:88) j = 1 δ j KL ( p j , x j ) . Again , there are many penalty functions we could use here , but the one we have chosen permits the minimizing x k + 1 to be obtained in closed form . The iterative step of the regularized EMML is as follows : x k + 1 j = δ j δ j + s j p j + 1 δ j + s j x kj I (cid:88) i = 1 P ij (cid:16) y i ( Px k ) i (cid:17) . ( 13 . 27 ) 13 . 6 Block - Iterative Methods The algorithms we have considered in this chapter are either simultaneous algorithms or row - action ones . There are also block - iterative variants of 13 . 7 . EXERCISES 229 MART and ART , in which some , but not all , equations of the system are used at each step . The subsets of equations used at a single step are called blocks . Generally speaking , the smaller the blocks , the faster the convergence , in the consistent case . On the other hand , it may be inconvenient , given the architecture of the computer , to deal with only a single equation at each step . By using blocks , we can achieve a compromise between speed of convergence and compatibility with the architecture of the computer . These block - iterative methods are discussed in detail in [ 60 ] . 13 . 7 Exercises Ex . 13 . 1 Show that the two algorithms associated with Equations ( 13 . 16 ) and ( 13 . 17 ) , respectively , do actually perform as claimed . 13 . 8 Course Homework Try Exercise 13 . 1 . 230 CHAPTER 13 . SOLVING SYSTEMS OF LINEAR EQUATIONS Chapter 14 Conjugate - Direction Methods 14 . 1 Chapter Summary Finding the least - squares solution of a possibly inconsistent system of linear equations Ax = b is equivalent to minimizing the quadratic function f ( x ) = 12 | | Ax − b | | 22 and so can be viewed within the framework of optimization . Iterative optimization methods can then be used to provide , or at least suggest , algorithms for obtaining the least - squares solution . The conjugate gradient method is one such method . Proofs for the lemmas in this chapter are exercises for the reader . 14 . 2 Iterative Minimization Iterative methods for minimizing a real - valued function f ( x ) over the vector variable x usually take the following form : having obtained x k − 1 , a new direction vector d k is selected , an appropriate scalar α k > 0 is determined and the next member of the iterative sequence is given by x k = x k − 1 + α k d k . ( 14 . 1 ) Ideally , one would choose the α k to be the value of α for which the function f ( x k − 1 + αd k ) is minimized . It is assumed that the direction d k is a descent direction ; that is , for small positive α the function f ( x k − 1 + αd k ) is strictly decreasing . Finding the optimal value of α at each step of the iteration is diﬃcult , if not impossible , in most cases , and approximate methods , using line searches , are commonly used . 231 232 CHAPTER 14 . CONJUGATE - DIRECTION METHODS Lemma 14 . 1 When x k is constructed using the optimal α , we have ∇ f ( x k ) · d k = 0 . ( 14 . 2 ) Proof : Diﬀerentiate the function f ( x k − 1 + αd k ) with respect to the variable α . Since the gradient ∇ f ( x k ) is orthogonal to the previous direction vector d k and also because −∇ f ( x ) is the direction of greatest decrease of f ( x ) , the choice of d k + 1 = −∇ f ( x k ) as the next direction vector is a reasonable one . With this choice we obtain Cauchy’s steepest descent method [ 150 ] : x k + 1 = x k − α k + 1 ∇ f ( x k ) . The steepest descent method need not converge in general and even when it does , it can do so slowly , suggesting that there may be better choices for the direction vectors . For example , the Newton - Raphson method [ 163 ] employs the following iteration : x k + 1 = x k − ∇ 2 f ( x k ) − 1 ∇ f ( x k ) , where ∇ 2 f ( x ) is the Hessian matrix for f ( x ) at x . To investigate further the issues associated with the selection of the direction vectors , we consider the more tractable special case of quadratic optimization . 14 . 3 Quadratic Optimization Let A be an arbitrary real I by J matrix . The linear system of equations Ax = b need not have any solutions , and we may wish to ﬁnd a least - squares solution x = ˆ x that minimizes f ( x ) = 1 2 | | b − Ax | | 22 . ( 14 . 3 ) The vector b can be written b = A ˆ x + ˆ w , where A T ˆ w = 0 and a least squares solution is an exact solution of the linear system Qx = c , with Q = A T A and c = A T b . We shall assume that Q is invertible and there is a unique least squares solution ; this is the typical case . We consider now the iterative scheme described by Equation ( 14 . 1 ) for f ( x ) as in Equation ( 14 . 3 ) . For now , the direction vectors d k are arbitrary . For this f ( x ) the gradient becomes ∇ f ( x ) = Qx − c . The optimal α k for the iteration can be obtained in closed form . 14 . 3 . QUADRATIC OPTIMIZATION 233 Lemma 14 . 2 The optimal α k is α k = r k · d k d k · Qd k , ( 14 . 4 ) where r k = c − Qx k − 1 . Lemma 14 . 3 Let | | x | | 2 Q = x · Qx denote the square of the Q - norm of x . Then | | ˆ x − x k − 1 | | 2 Q − | | ˆ x − x k | | 2 Q = ( r k · d k ) 2 / d k · Qd k ≥ 0 for any direction vectors d k . If the sequence of direction vectors { d k } is completely general , the iter - ative sequence need not converge . However , if the set of direction vectors is ﬁnite and spans R J and we employ them cyclically , convergence follows . Theorem 14 . 1 Let { d 1 , . . . , d J } be any basis for R J . Let α k be chosen according to Equation ( 14 . 4 ) . Then , for k = 1 , 2 , . . . , j = k ( mod J ) , and any x 0 , the sequence deﬁned by x k = x k − 1 + α k d j converges to the least squares solution . Proof : The sequence { | | ˆ x − x k | | 2 Q } is decreasing and , therefore , the sequence { ( r k · d k ) 2 / d k · Qd k must converge to zero . Therefore , the vectors x k are bounded , and for each j = 1 , . . . , J , the subsequences { x mJ + j , m = 0 , 1 , . . . } have cluster points , say x ∗ , j with x ∗ , j = x ∗ , j − 1 + ( c − Qx ∗ , j − 1 ) · d j d j · Qd j d j . Since r mJ + j · d j → 0 , it follows that , for each j = 1 , . . . , J , ( c − Qx ∗ , j ) · d j = 0 . Therefore , x ∗ , 1 = . . . = x ∗ , J = x ∗ with Qx ∗ = c . Consequently , x ∗ is the least squares solution and the sequence { | | x ∗ − x k | | Q } is decreasing . But a subsequence converges to zero ; therefore , { | | x ∗ − x k | | Q } → 0 . This completes the proof . There is an interesting corollary to this theorem that pertains to a mod - iﬁed version of the ART algorithm . For k = 0 , 1 , . . . and i = k ( mod M ) + 1 234 CHAPTER 14 . CONJUGATE - DIRECTION METHODS and with the rows of A normalized to have length one , the ART iterative step is x k + 1 = x k + ( b i − ( Ax k ) i ) a i , where a i is the i th column of A T . When Ax = b has no solutions , the ART algorithm does not converge to the least - squares solution ; rather , it exhibits subsequential convergence to a limit cycle . However , using the previous theorem , we can show that the following modiﬁcation of the ART , which we shall call the least squares ART ( LS - ART ) , converges to the least - squares solution for every x 0 : x k + 1 = x k + r k + 1 · a i a i · Qa i a i . In the quadratic case the steepest descent iteration has the form x k = x k − 1 + r k · r k r k · Qr k r k . We have the following result . Theorem 14 . 2 The steepest descent method converges to the least - squares solution . Proof : As in the proof of the previous theorem , we have | | ˆ x − x k − 1 | | 2 Q − | | ˆ x − x k | | 2 Q = ( r k · d k ) 2 / d k · Qd k ≥ 0 , where now the direction vectors are d k = r k . So , the sequence { | | ˆ x − x k | | 2 Q } is decreasing , and therefore the sequence { ( r k · r k ) 2 / r k · Qr k } must converge to zero . The sequence { x k } is bounded ; let x ∗ be a cluster point . It follows that c − Qx ∗ = 0 , so that x ∗ is the least - squares solution ˆ x . The rest of the proof follows as in the proof of the previous theorem . 14 . 4 Conjugate Bases for R J If the set { v 1 , . . . , v J } is a basis for R J , then any vector x in R J can be expressed as a linear combination of the basis vectors ; that is , there are real numbers a 1 , . . . , a J for which x = a 1 v 1 + a 2 v 2 + . . . + a J v J . For each x the coeﬃcients a j are unique . To determine the a j we write x · v m = a 1 v 1 · v m + a 2 v 2 · v m + . . . + a J v J · v m , 14 . 4 . CONJUGATE BASES FOR R J 235 for m = 1 , . . . , J . Having calculated the quantities x · v m and v j · v m , we solve the resulting system of linear equations for the a j . If , instead of an arbitrary basis { v 1 , . . . , v J } , we use an orthogonal basis { u 1 , . . . , u J } , that is , then u j · u m = 0 , unless j = m , then the system of linear equations is now trivial to solve . The solution is a j = x · u j / u j · u j , for each j . Of course , we still need to compute the quantities x · u j . The least - squares solution of the linear system of equations Ax = b is ˆ x = ( A T A ) − 1 A T b = Q − 1 c . To express ˆ x as a linear combination of the members of an orthogonal basis { u 1 , . . . , u J } we need the quantities ˆ x · u j , which usually means that we need to know ˆ x ﬁrst . For a special kind of basis , a Q - conjugate basis , knowing ˆ x ahead of time is not necessary ; we need only know Q and c . Therefore , we can use such a basis to ﬁnd ˆ x . This is the essence of the conjugate gradient method ( CGM ) , in which we calculate a conjugate basis and , in the process , determine ˆ x . 14 . 4 . 1 Conjugate Directions From Equation ( 14 . 2 ) we have ( c − Qx k ) · d k = 0 , which can be expressed as ( ˆ x − x k ) · Qd k = ( ˆ x − x k ) T Qd k = 0 . Two vectors x and y are said to be Q - orthogonal ( or Q - conjugate , or just conjugate ) , if x · Qy = 0 . So , the least - squares solution that we seek lies in a direction from x k that is Q - orthogonal to d k . This suggests that we can do better than steepest descent if we take the next direction to be Q - orthogonal to the previous one , rather than just orthogonal . This leads us to conjugate direction methods . Deﬁnition 14 . 1 We say that the set { p 1 , . . . , p n } is a conjugate set for R J if p i · Qp j = 0 for i (cid:54) = j . Lemma 14 . 4 A conjugate set that does not contain zero is linearly inde - pendent . If p n (cid:54) = 0 for n = 1 , . . . , J , then the least - squares vector ˆ x can be written as ˆ x = a 1 p 1 + . . . + a J p J , with a j = c · p j / p j · Qp j for each j . Proof : Use the Q - inner product (cid:104) x , y (cid:105) Q = x · Qy . Therefore , once we have a conjugate basis , computing the least squares solution is trivial . Generating a conjugate basis can obviously be done using the standard Gram - Schmidt approach . 236 CHAPTER 14 . CONJUGATE - DIRECTION METHODS 14 . 4 . 2 The Gram - Schmidt Method Let { v 1 , . . . , v J } be a linearly independent set of vectors in the space R M , where J ≤ M . The Gram - Schmidt method uses the v j to create an or - thogonal basis { u 1 , . . . , u J } for the span of the v j . Begin by taking u 1 = v 1 . For j = 2 , . . . , J , let u j = v j − u 1 · v j u 1 · u 1 u 1 − . . . − u j − 1 · v j u j − 1 · u j − 1 u j − 1 . To apply this approach to obtain a conjugate basis , we would simply replace the dot products u k · v j and u k · u k with the Q - inner products , that is , p j = v j − p 1 · Qv j p 1 · Qp 1 p 1 − . . . − p j − 1 · Qv j p j − 1 · Qp j − 1 p j − 1 . ( 14 . 5 ) Even though the Q - inner products can always be written as x · Qy = Ax · Ay , so that we need not compute the matrix Q , calculating a conjugate basis using Gram - Schmidt is not practical for large J . There is a way out , fortunately . If we take p 1 = v 1 and v j = Qp j − 1 , we have a much more eﬃcient mechanism for generating a conjugate basis , namely a three - term recursion formula [ 150 ] . The set { p 1 , Qp 1 , . . . , Qp J − 1 } need not be a linearly indepen - dent set , in general , but , if our goal is to ﬁnd ˆ x , and not really to calculate a full conjugate basis , this does not matter , as we shall see . Theorem 14 . 3 Let p 1 (cid:54) = 0 be arbitrary . Let p 2 be given by p 2 = Qp 1 − Qp 1 · Qp 1 p 1 · Qp 1 p 1 , so that p 2 · Qp 1 = 0 . Then , for n ≥ 2 , let p n + 1 be given by p n + 1 = Qp n − Qp n · Qp n p n · Qp n p n − Qp n − 1 · Qp n p n − 1 · Qp n − 1 p n − 1 . ( 14 . 6 ) Then , the set { p 1 , . . . , p J } is a conjugate set for R J . If p n (cid:54) = 0 for each n , then the set is a conjugate basis for R J . Proof : We consider the induction step of the proof . Assume that { p 1 , . . . , p n } is a Q - orthogonal set of vectors ; we then show that { p 1 , . . . , p n + 1 } is also , provided that n ≤ J − 1 . It is clear from Equation ( 14 . 6 ) that p n + 1 · Qp n = p n + 1 · Qp n − 1 = 0 . For j ≤ n − 2 , we have p n + 1 · Qp j = p j · Qp n + 1 = p j · Q 2 p n − ap j · Qp n − bp j · Qp n − 1 , 14 . 5 . THE CONJUGATE GRADIENT METHOD 237 for constants a and b . The second and third terms on the right side are then zero because of the induction hypothesis . The ﬁrst term is also zero since p j · Q 2 p n = ( Qp j ) · Qp n = 0 because Qp j is in the span of { p 1 , . . . , p j + 1 } , and so is Q - orthogonal to p n . The calculations in the three - term recursion formula Equation ( 14 . 6 ) also occur in the Gram - Schmidt approach in Equation ( 14 . 5 ) ; the point is that Equation ( 14 . 6 ) uses only the ﬁrst three terms , in every case . 14 . 5 The Conjugate Gradient Method 14 . 5 . 1 The Main Idea The main idea in the conjugate gradient method ( CGM ) is to build the conjugate set as we calculate the least squares solution using the iterative algorithm x n = x n − 1 + α n p n . ( 14 . 7 ) The α n is chosen so as to minimize f ( x n − 1 + αp n ) , as a function of α . So we have α n = r n · p n p n · Qp n , where r n = c − Qx n − 1 . Since the function f ( x ) = 12 | | Ax − b | | 22 has for its gradient ∇ f ( x ) = A T ( Ax − b ) = Qx − c , the residual vector r n = c − Qx n − 1 is the direction of steepest descent from the point x = x n − 1 . The CGM combines the use of the negative gradient directions from the steepest descent method with the use of a conjugate basis of directions , by using the r n + 1 to construct the next direction p n + 1 in such a way as to form a conjugate set { p 1 , . . . , p J } . 14 . 5 . 2 A Recursive Formula As before , there is an eﬃcient recursive formula that provides the next direction : let p 1 = r 1 = ( c − Qx 0 ) and for j = 2 , 3 , . . . p j = r j − β j − 1 p j − 1 , ( 14 . 8 ) with β j − 1 = r j · Qp j − 1 p j − 1 · Qp j − 1 . ( 14 . 9 ) 238 CHAPTER 14 . CONJUGATE - DIRECTION METHODS Note that it follows from the deﬁnition of β j − 1 that p j Qp j − 1 = 0 . ( 14 . 10 ) Since the α n is the optimal choice and r n + 1 = −∇ f ( x n ) , we have , according to Equation ( 14 . 2 ) , r n + 1 · p n = 0 . ( 14 . 11 ) In theory , the CGM converges to the least squares solution in ﬁnitely many steps , since we either reach p n + 1 = 0 or n + 1 = J . In practice , the CGM can be employed as a fully iterative method by cycling back through the previously used directions . An induction proof similar to the one used to prove Theorem 14 . 3 es - tablishes that the set { p 1 , . . . , p J } is a conjugate set [ 150 , 163 ] . In fact , we can say more . Theorem 14 . 4 For n = 1 , 2 , . . . , J and j = 1 , . . . , n − 1 we have • a ) r n · r j = 0 ; • b ) r n · p j = 0 ; and • c ) p n · Qp j = 0 . The proof presented here through a series of exercises at the end of the chapter is based on that given in [ 163 ] . 14 . 6 Krylov Subspaces Another approach to deriving the conjugate gradient method is to use Krylov subspaces . If we select x 0 = 0 as our starting vector for the CGM , then p 1 = r 1 = c , and each p n + 1 and x n + 1 lie in the Krylov subspace K n ( Q , c ) , deﬁned to be the span of the vectors { c , Qc , Q 2 c , . . . , Q n c } . For any x in R J , we have (cid:107) x − ˆ x (cid:107) 2 Q = ( x − ˆ x ) T Q ( x − ˆ x ) . Minimizing (cid:107) x − ˆ x (cid:107) 2 Q over all x in K n ( Q , c ) is equivalent to minimizing the same function over all x of the form x = x n + αp n + 1 . This , in turn , is equivalent to minimizing − 2 αp n + 1 · r n + 1 + α 2 p n + 1 · Qp n + 1 , over all α , which has for its solution the value α = α n + 1 used to calculate x n + 1 in the CGM . 14 . 7 . EXTENSIONS OF THE CGM 239 14 . 7 Extensions of the CGM The convergence rate of the CGM depends on the condition number of the matrix Q , which is the ratio of its largest to its smallest eigenvalues . When the condition number is much greater than one convergence can be accelerated by preconditioning the matrix Q ; this means replacing Q with P − 1 / 2 QP − 1 / 2 , for some positive - deﬁnite approximation P of Q ( see [ 7 ] ) . There are versions of the CGM for the minimization of non - quadratic functions . In the quadratic case the next conjugate direction p n + 1 is built from the residual r n + 1 and p n . Since , in that case , r n + 1 = −∇ f ( x n ) , this suggests that in the non - quadratic case we build p n + 1 from −∇ f ( x n ) and p n . This leads to the Fletcher - Reeves method . Other similar algorithms , such as the Polak - Ribiere and the Hestenes - Stiefel methods , perform better on certain problems [ 163 ] . 14 . 8 Exercises Ex . 14 . 1 There are several lemmas in this chapter whose proofs are only sketched . Complete the proofs of these lemma . The following exercises refer to the Conjugate Gradient Method . Ex . 14 . 2 Show that r n + 1 = r n − α n Qp n , ( 14 . 12 ) so Qp n is in the span of r n + 1 and r n . Ex . 14 . 3 Prove that r n = 0 whenever p n = 0 , in which case we have c = Qx n − 1 , so that x n − 1 is the least - squares solution . Ex . 14 . 4 Show that r n · p n = r n · r n , so that α n = r n · r n p n · Qp n . ( 14 . 13 ) The proof of Theorem 14 . 4 uses induction on the number n . Throughout the following exercises assume that the statements in Theorem 14 . 4 hold for some ﬁxed n with 2 ≤ n < J and for j = 1 , 2 , . . . , n − 1 . We prove that they hold also for n + 1 and j = 1 , 2 , . . . , n . Ex . 14 . 5 Show that p n · Qp n = r n · Qp n , so that α n = r n · r n r n · Qp n . ( 14 . 14 ) Hints : use Equation ( 14 . 8 ) and the induction assumption concerning c ) of the Theorem . 240 CHAPTER 14 . CONJUGATE - DIRECTION METHODS Ex . 14 . 6 Show that r n + 1 · r n = 0 . Hint : use Equations ( 14 . 14 ) and ( 14 . 12 ) . Ex . 14 . 7 Show that r n + 1 · r j = 0 , for j = 1 , . . . , n − 1 . Hints : write out r n + 1 using Equation ( 14 . 12 ) and r j using Equation ( 14 . 8 ) , and use the induction hypotheses . Ex . 14 . 8 Show that r n + 1 · p j = 0 , for j = 1 , . . . , n . Hints : use Equations ( 14 . 12 ) and ( 14 . 8 ) and induction assumptions b ) and c ) . Ex . 14 . 9 Show that p n + 1 · Qp j = 0 , for j = 1 , . . . , n − 1 . Hints : use Equation ( 14 . 12 ) , the previous exercise , and the induction assumptions . The ﬁnal step in the proof is to show that p n + 1 · Qp n = 0 . But this follows immediately from Equation ( 14 . 10 ) . 14 . 9 Course Homework Try all the exercises in this chapter . Chapter 15 Auxiliary - Function Methods 15 . 1 Chapter Summary In this chapter we present auxiliary - function ( AF ) methods for optimiza - tion . The AF methods are closely related to sequential unconstrained min - imization ( SUM ) [ 112 ] . A particularly useful subset of AF methods , called the SUMMA class of algorithms , is quite broad , and contains many impor - tant iterative methods . 15 . 2 Sequential Unconstrained Minimization Barrier - function and penalty - function algorithms are the best known exam - ples of sequential unconstrained minimization . The book [ 112 ] by Fiacco and McCormick has become a classic text on the subject . 15 . 2 . 1 Barrier - Function Methods Suppose that C ⊆ R J and b : C → R is a barrier function for C , that is , b has the property that b ( x ) → + ∞ as x approaches the boundary of C . At the k th step of the iteration we minimize F k ( x ) = f ( x ) + 1 k b ( x ) ( 15 . 1 ) to get x k . Then each x k is in C . We want the sequence { x k } to converge to some x ∗ in the closure of C that solves the original problem . Barrier - function methods are called interior - point methods because each x k satisﬁes the constraints . 241 242 CHAPTER 15 . AUXILIARY - FUNCTION METHODS For example , suppose that we want to minimize the function f ( x ) = f ( x 1 , x 2 ) = x 21 + x 22 , subject to the constraint that x 1 + x 2 ≥ 1 . The constraint is then written g ( x 1 , x 2 ) = 1 − ( x 1 + x 2 ) ≤ 0 . We use the logarithmic barrier function b ( x ) = − log ( x 1 + x 2 − 1 ) . For each positive integer k , the vector x k = ( x k 1 , x k 2 ) minimizing the function F k ( x ) = x 21 + x 22 − 1 k log ( x 1 + x 2 − 1 ) = f ( x ) + 1 k b ( x ) has entries x k 1 = x k 2 = 1 4 + 1 4 (cid:114) 1 + 4 k . Notice that x k 1 + x k 2 > 1 , so each x k satisﬁes the constraint . As k → + ∞ , x k converges to ( 12 , 12 ) , which is the solution to the original problem . The use of the logarithmic barrier function forces x 1 + x 2 − 1 to be positive , thereby enforcing the constraint on x = ( x 1 , x 2 ) . 15 . 2 . 2 Penalty - Function Methods Again , our goal is to minimize a function f : R J → R , subject to the constraint that x ∈ C , where C is a non - empty closed subset of R J . We select a non - negative function p : R J → R with the property that p ( x ) = 0 if and only if x is in C and then , for each positive integer k , we minimize F k ( x ) = f ( x ) + kp ( x ) , ( 15 . 2 ) to get x k . We then want the sequence { x k } to converge to some x ∗ ∈ C that solves the original problem . In order for this iterative algorithm to be useful , each x k should be relatively easy to calculate . If we decided to select p ( x ) = + ∞ for x not in C and p ( x ) = 0 for x in C , then minimizing F k ( x ) is equivalent to the original problem and we have achieved nothing . As an example , suppose that we want to minimize the function f ( x ) = ( x + 1 ) 2 , subject to x ≥ 0 . Let us select p ( x ) = x 2 , for x ≤ 0 , and p ( x ) = 0 otherwise . Then x k = − 1 k + 1 , which converges to the right answer , x ∗ = 0 , as k → ∞ . The main idea in both barrier - function and penalty - function algorithms is to add to the objective function f ( x ) a second function , a barrier function or a penalty function , multiplied by a parameter , and then to minimize the sum of these two functions . As the parameter is altered , we obtain a se - quence of approximate solutions to the original problem . These additional functions we call auxiliary functions . In the case of barrier - or penalty - function methods , the auxiliary functions are related to the constraint set C . There are other examples of the use of auxiliary functions , as we shall see in this chapter and in several that follow . 15 . 3 . AUXILIARY FUNCTIONS 243 15 . 3 Auxiliary Functions In this section we deﬁne auxiliary - function methods and establish their basic properties , introduce the SUMMA class of AF methods , and give several examples to be considered in more detail later . 15 . 4 Using AF Methods Minimizing a real - valued function subject to constraints on the indepen - dent variable can be a diﬃcult problem to solve ; typically , iterative algo - rithms are required . The auxiliary - function ( AF ) approach , which general - izes sequential - unconstrained minimization ( SUM ) [ 112 ] , is to replace the single diﬃcult constrained optimization problem with an inﬁnite sequence of problems that are more easily solved . In the best of cases , the sequence of minimizers will converge to a solution of the original constrained min - imization problem , or , failing that , their function values will converge to the constrained minimum , or , at least , will be non - increasing . Even when there are no constraints , the problem of minimizing a real - valued function may require iteration ; the formalism of AF minimization can be useful in deriving such iterative algorithms , as well as in proving convergence . As with SUM algorithms , AF methods can be used to impose the con - straints or to penalize any violation of the constraints . In addition , AF methods may also be employed to obtain closed - form expressions for the vectors of the iterative sequence . 15 . 5 Deﬁnition and Basic Properties of AF Methods Let C be a non - empty subset of an arbitrary set X , and f : X → R . We want to minimize f ( x ) over x in C . At the k th step of an auxiliary - function ( AF ) algorithm we minimize G k ( x ) = f ( x ) + g k ( x ) ( 15 . 3 ) over x ∈ C to obtain x k . Our main objective is to select the g k ( x ) so that the inﬁnite sequence { x k } generated by our algorithm converges to a solution of the problem ; this , of course , requires some topology on the set X . Failing that , we want the sequence { f ( x k ) } to converge to d = inf { f ( x ) | x ∈ C } or , at the very least , for the sequence { f ( x k ) } to be non - increasing . 244 CHAPTER 15 . AUXILIARY - FUNCTION METHODS 15 . 5 . 1 AF Requirements For all AF algorithms considered in this paper we require that the auxiliary functions g k ( x ) be chosen so that g k ( x ) ≥ 0 for all x ∈ C and g k ( x k − 1 ) = 0 . We have the following proposition . Proposition 15 . 1 Let the sequence { x k } be generated by an AF algorithm . Then the sequence { f ( x k ) } is non - increasing , and , if d is ﬁnite , the se - quence { g k ( x k ) } converges to zero . Proof : We have f ( x k ) + g k ( x k ) = G k ( x k ) ≤ G k ( x k − 1 ) = f ( x k − 1 ) + g k ( x k − 1 ) = f ( x k − 1 ) . Therefore , f ( x k − 1 ) − f ( x k ) ≥ g k ( x k ) ≥ 0 . Since the sequence { f ( x k ) } is decreasing and bounded below by d , the dif - ference sequence must converge to zero , if d is ﬁnite ; therefore , the sequence { g k ( x k ) } converges to zero in this case . 15 . 5 . 2 Barrier - and Penalty - Function Methods as AF The auxiliary functions used in Equation ( 15 . 1 ) do not have these properties but the barrier - function algorithm can be reformulated as an AF method with these properties . The iterate x k obtained by minimizing F k ( x ) in Equation ( 15 . 1 ) also minimizes the function G k ( x ) = f ( x ) + [ ( k − 1 ) f ( x ) + b ( x ) ] − [ ( k − 1 ) f ( x k − 1 ) + b ( x k − 1 ) ] . ( 15 . 4 ) The auxiliary functions g k ( x ) = [ ( k − 1 ) f ( x ) + b ( x ) ] − [ ( k − 1 ) f ( x k − 1 ) + b ( x k − 1 ) ] ( 15 . 5 ) now have the desired properties . In addition , we can easily show that G k ( x ) − G k ( x k ) = g k + 1 ( x ) for all x ∈ C , which will become signiﬁcant shortly . As originally formulated , the penalty - function methods do not ﬁt into the class of AF methods we consider here . However , a reformulation of the penalty - function approach , with p ( x ) and f ( x ) switching roles , permits the penalty - function methods to be studied as barrier - function methods , and therefore as acceptable AF methods . 15 . 6 . THE SUMMA CLASS OF AF METHODS 245 15 . 6 The SUMMA Class of AF Methods As we have seen , whenever the sequence { x k } is generated by an AF al - gorithm , the sequence { f ( x k ) } is non - increasing . We want more , however ; we want the sequence { f ( x k ) } to converge to d . This happens for those AF algorithms in the SUMMA class . An AF algorithm is said to be in the SUMMA class if the auxiliary functions g k ( x ) are chosen so that the SUMMA condition holds ; that is , G k ( x ) − G k ( x k ) ≥ g k + 1 ( x ) ≥ 0 , ( 15 . 6 ) for all x ∈ C . We have the following theorem . Theorem 15 . 1 If the sequence { x k } is generated by an algorithm in the SUMMA class , then the sequence { f ( x k ) } converges to d = inf { f ( x ) | x ∈ C } . Proof : Suppose that there is d ∗ > d with f ( x k ) ≥ d ∗ , for all k . Then there is z in C with f ( x k ) ≥ d ∗ > f ( z ) ≥ d , for all k . From the inequality ( 15 . 6 ) we have g k + 1 ( z ) ≤ G k ( z ) − G k ( x k ) , and so , for all k , g k ( z ) − g k + 1 ( z ) ≥ f ( x k ) + g k ( x k ) − f ( z ) ≥ f ( x k ) − f ( z ) ≥ d ∗ − f ( z ) > 0 . This tells us that the nonnegative sequence { g k ( z ) } is decreasing , but that successive diﬀerences remain bounded away from zero , which cannot hap - pen . The auxiliary functions used in Equation ( 15 . 1 ) do not satisfy the SUMMA condition in ( 15 . 6 ) but can be modiﬁed to make the barrier - function method a SUMMA method . The iterate x k obtained by minimiz - ing F k ( x ) in Equation ( 15 . 1 ) also minimizes the function G k ( x ) = f ( x ) + [ ( k − 1 ) f ( x ) + b ( x ) ] − [ ( k − 1 ) f ( x k − 1 ) + b ( x k − 1 ) ] . ( 15 . 7 ) For the functions g k ( x ) = [ ( k − 1 ) f ( x ) + b ( x ) ] − [ ( k − 1 ) f ( x k − 1 ) + b ( x k − 1 ) ] ( 15 . 8 ) we can easily show that G k ( x ) − G k ( x k ) = g k + 1 ( x ) for all x ∈ X . 246 CHAPTER 15 . AUXILIARY - FUNCTION METHODS As originally formulated , the penalty - function methods are not in the SUMMA class ; however , a reformulation of the penalty - function approach , with p ( x ) and f ( x ) switching roles , permits the penalty - function methods to be studied as barrier - function methods , and therefore as SUMMA meth - ods . The barrier - function and penalty - function methods , as well as other examples of SUMMA , are discussed in more detail in subsequent chapters . Chapter 16 Barrier - Function Methods 16 . 1 Chapter Summary In this chapter we consider barrier - function algorithms in more detail . 16 . 2 Barrier functions Let b ( x ) : R J → ( −∞ , + ∞ ] be continuous , with eﬀective domain the set D = { x | b ( x ) < + ∞ } . The goal is to minimize the objective function f ( x ) , over x in C , the closure of D . We assume that there is ˆ x ∈ C with f ( ˆ x ) ≤ f ( x ) , for all x in C . In the barrier - function method , we minimize f ( x ) + 1 k b ( x ) ( 16 . 1 ) over x in D to get x k . Each x k lies within D , so the method is an interior - point algorithm . If the sequence { x k } converges , the limit vector x ∗ will be in C and f ( x ∗ ) = f ( ˆ x ) . Barrier functions typically have the property that b ( x ) → + ∞ as x approaches the boundary of D , so not only is x k prevented from leaving D , it is discouraged from approaching the boundary . 16 . 2 . 1 Examples of Barrier Functions Consider the convex programming ( CP ) problem of minimizing the convex function f : R J → R , subject to g i ( x ) ≤ 0 , where each g i : R J → R is convex , for i = 1 , . . . , I . Let D = { x | g i ( x ) < 0 , i = 1 , . . . , I } ; then D is open . We consider two barrier functions appropriate for this problem . 247 248 CHAPTER 16 . BARRIER - FUNCTION METHODS The Logarithmic Barrier Function A suitable barrier function is the logarithmic barrier function b ( x ) = (cid:16) − I (cid:88) i = 1 log ( − g i ( x ) ) (cid:17) . ( 16 . 2 ) The function − log ( − g i ( x ) ) is deﬁned only for those x in D , and is positive for g i ( x ) > − 1 . If g i ( x ) is near zero , then so is − g i ( x ) and b ( x ) will be large . The Inverse Barrier Function Another suitable barrier function is the inverse barrier function b ( x ) = I (cid:88) i = 1 − 1 g i ( x ) , ( 16 . 3 ) deﬁned for those x in D . In both examples , when k is small , the minimization pays more at - tention to b ( x ) , and less to f ( x ) , forcing the g i ( x ) to be large negative numbers . But , as k grows larger , more attention is paid to minimizing f ( x ) and the g i ( x ) are allowed to be smaller negative numbers . By let - ting k → ∞ , we obtain an iterative method for solving the constrained minimization problem . 16 . 3 Barrier - Function Methods as SUMMA Barrier - function methods are particular cases of the SUMMA . The iterative step of the barrier - function method can be formulated as follows : minimize f ( x ) + [ ( k − 1 ) f ( x ) + b ( x ) ] ( 16 . 4 ) to get x k . Since , for k = 2 , 3 , . . . , the function ( k − 1 ) f ( x ) + b ( x ) ( 16 . 5 ) is minimized by x k − 1 , the function g k ( x ) = ( k − 1 ) f ( x ) + b ( x ) − ( k − 1 ) f ( x k − 1 ) − b ( x k − 1 ) ( 16 . 6 ) is nonnegative , and x k minimizes the function G k ( x ) = f ( x ) + g k ( x ) . ( 16 . 7 ) 16 . 4 . BEHAVIOR OF BARRIER - FUNCTION ALGORITHMS 249 From G k ( x ) = f ( x ) + ( k − 1 ) f ( x ) + b ( x ) − ( k − 1 ) f ( x k − 1 ) − b ( x k − 1 ) , it follows that G k ( x ) − G k ( x k ) = kf ( x ) + b ( x ) − kf ( x k ) − b ( x k ) = g k + 1 ( x ) , so that g k + 1 ( x ) satisﬁes the condition in ( 15 . 6 ) . This shows that the barrier - function method is a particular case of SUMMA . 16 . 4 Behavior of Barrier - Function Algorithms From the properties of SUMMA algorithms , we conclude that { f ( x k ) } is decreasing to f ( ˆ x ) , and that { g k ( x k ) } converges to zero . From the nonneg - ativity of g k ( x k ) we have that ( k − 1 ) ( f ( x k ) − f ( x k − 1 ) ) ≥ b ( x k − 1 ) − b ( x k ) . Since the sequence { f ( x k ) } is decreasing , the sequence { b ( x k ) } must be increasing , but might not be bounded above . If ˆ x is unique , and f ( x ) has bounded level sets , then it follows , from our discussion of SUMMA , that { x k } → ˆ x . Suppose now that ˆ x is not known to be unique , but can be chosen in D , so that G k ( ˆ x ) is ﬁnite for each k . From f ( ˆ x ) + 1 k b ( ˆ x ) ≥ f ( x k ) + 1 k b ( x k ) we have 1 k (cid:16) b ( ˆ x ) − b ( x k ) (cid:17) ≥ f ( x k ) − f ( ˆ x ) ≥ 0 , so that b ( ˆ x ) − b ( x k ) ≥ 0 , for all k . If either f or b has bounded level sets , then the sequence { x k } is bounded and has a cluster point , x ∗ in C . It follows that b ( x ∗ ) ≤ b ( ˆ x ) < + ∞ , so that x ∗ is in D . If we assume that f ( x ) is convex and b ( x ) is strictly convex on D , then we can show that x ∗ is unique in D , so that x ∗ = ˆ x and { x k } → ˆ x . To see this , assume , to the contrary , that there are two distinct cluster points x ∗ and x ∗∗ in D , with { x k n } → x ∗ , and { x j n } → x ∗∗ . 250 CHAPTER 16 . BARRIER - FUNCTION METHODS Without loss of generality , we assume that 0 < k n < j n < k n + 1 , for all n , so that b ( x k n ) ≤ b ( x j n ) ≤ b ( x k n + 1 ) . Therefore , b ( x ∗ ) = b ( x ∗∗ ) ≤ b ( ˆ x ) . From the strict convexity of b ( x ) on the set D , and the convexity of f ( x ) , we conclude that , for 0 < λ < 1 and y = ( 1 − λ ) x ∗ + λx ∗∗ , we have b ( y ) < b ( x ∗ ) and f ( y ) ≤ f ( x ∗ ) . But , we must then have f ( y ) = f ( x ∗ ) . There must then be some k n such that G k n ( y ) = f ( y ) + 1 k n b ( y ) < f ( x k n ) + 1 k n b ( x k n ) = G k n ( x k n ) . But , this is a contradiction . The following theorem summarizes what we have shown with regard to the barrier - function method . Theorem 16 . 1 Let f : R J → ( −∞ , + ∞ ] be a continuous function . Let b ( x ) : R J → ( 0 , + ∞ ] be a continuous function , with eﬀective domain the nonempty set D . Let ˆ x minimize f ( x ) over all x in C = D . For each positive integer k , let x k minimize the function f ( x ) + 1 k b ( x ) . Then the sequence { f ( x k ) } is monotonically decreasing to the limit f ( ˆ x ) , and the sequence { b ( x k ) } is increasing . If ˆ x is unique , and f ( x ) has bounded level sets , then the sequence { x k } converges to ˆ x . In particular , if ˆ x can be chosen in D , if either f ( x ) or b ( x ) has bounded level sets , if f ( x ) is convex and if b ( x ) is strictly convex on D , then ˆ x is unique in D and { x k } converges to ˆ x . At the k th step of the barrier method we must minimize the function f ( x ) + 1 k b ( x ) . In practice , this must also be performed iteratively , with , say , the Newton - Raphson algorithm . It is important , therefore , that bar - rier functions be selected so that relatively few Newton - Raphson steps are needed to produce acceptable solutions to the main problem . For more on these issues see Renegar [ 180 ] and Nesterov and Nemirovski [ 165 ] . Chapter 17 Penalty - Function Methods 17 . 1 Chapter Summary In this chapter we consider penalty - function methods in more detail . 17 . 2 Penalty - function Methods When we add a barrier function to f ( x ) we restrict the domain . When the barrier function is used in a sequential unconstrained minimization algorithm , the vector x k that minimizes the function f ( x ) + 1 k b ( x ) lies in the eﬀective domain D of b ( x ) , and we proved that , under certain conditions , the sequence { x k } converges to a minimizer of the function f ( x ) over the closure of D . The constraint of lying within the set D is satisﬁed at every step of the algorithm ; for that reason such algorithms are called interior - point methods . Constraints may also be imposed using a penalty function . In this case , violations of the constraints are discouraged , but not forbidden . When a penalty function is used in a sequential unconstrained minimization algorithm , the x k need not satisfy the constraints ; only the limit vector need be feasible . 17 . 2 . 1 Examples of Penalty Functions Consider the convex programming problem . We wish to minimize the con - vex function f ( x ) over all x for which the convex functions g i ( x ) ≤ 0 , for i = 1 , . . . , I . 251 252 CHAPTER 17 . PENALTY - FUNCTION METHODS The Absolute - Value Penalty Function We let g + i ( x ) = max { g i ( x ) , 0 } , and p ( x ) = I (cid:88) i = 1 g + i ( x ) . ( 17 . 1 ) This is the Absolute - Value penalty function ; it penalizes violations of the constraints g i ( x ) ≤ 0 , but does not forbid such violations . Then , for k = 1 , 2 , . . . , we minimize f ( x ) + kp ( x ) , ( 17 . 2 ) to get x k . As k → + ∞ , the penalty function becomes more heavily weighted , so that , in the limit , the constraints g i ( x ) ≤ 0 should hold . Be - cause only the limit vector satisﬁes the constraints , and the x k are allowed to violate them , such a method is called an exterior - point method . The Courant - Beltrami Penalty Function The Courant - Beltrami penalty - function method is similar , but uses p ( x ) = I (cid:88) i = 1 [ g + i ( x ) ] 2 . ( 17 . 3 ) The Quadratic - Loss Penalty Function Penalty methods can also be used with equality constraints . Consider the problem of minimizing the convex function f ( x ) , subject to the constraints g i ( x ) = 0 , i = 1 , . . . , I . The quadratic - loss penalty function is p ( x ) = 1 2 I (cid:88) i = 1 ( g i ( x ) ) 2 . ( 17 . 4 ) The inclusion of a penalty term can serve purposes other than to impose constraints on the location of the limit vector . In image processing , it is often desirable to obtain a reconstructed image that is locally smooth , but with well deﬁned edges . Penalty functions that favor such images can then be used in the iterative reconstruction [ 116 ] . We survey several instances in which we would want to use a penalized objective function . Regularized Least - Squares Suppose we want to solve the system of equations Ax = b . The prob - lem may have no exact solution , precisely one solution , or there may be 17 . 2 . PENALTY - FUNCTION METHODS 253 inﬁnitely many solutions . If we minimize the function f ( x ) = 1 2 (cid:107) Ax − b (cid:107) 22 , we get a least - squares solution , generally , and an exact solution , whenever exact solutions exist . When the matrix A is ill - conditioned , small changes in the vector b can lead to large changes in the solution . When the vector b comes from measured data , the entries of b may include measurement errors , so that an exact solution of Ax = b may be undesirable , even when such exact solutions exist ; exact solutions may correspond to x with unacceptably large norm , for example . In such cases , we may , instead , wish to minimize a function such as 1 2 (cid:107) Ax − b (cid:107) 22 + (cid:15) 2 (cid:107) x − z (cid:107) 22 , ( 17 . 5 ) for some vector z . If z = 0 , the minimizing vector x (cid:15) is then a norm - constrained least - squares solution . We then say that the least - squares prob - lem has been regularized . In the limit , as (cid:15) → 0 , these regularized solutions x (cid:15) converge to the least - squares solution closest to z . Suppose the system Ax = b has inﬁnitely many exact solutions . Our problem is to select one . Let us select z that incorporates features of the desired solution , to the extent that we know them a priori . Then , as (cid:15) → 0 , the vectors x (cid:15) converge to the exact solution closest to z . For example , taking z = 0 leads to the minimum - norm solution . Minimizing Cross - Entropy In image processing , it is common to encounter systems Px = y in which all the terms are non - negative . In such cases , it may be desirable to solve the system Px = y , approximately , perhaps , by minimizing the cross - entropy or Kullback - Leibler distance KL ( y , Px ) = I (cid:88) i = 1 (cid:16) y i log y i ( Px ) i + ( Px ) i − y i (cid:17) , ( 17 . 6 ) over vectors x ≥ 0 . When the vector y is noisy , the resulting solution , viewed as an image , can be unacceptable . It is wise , therefore , to add a penalty term , such as p ( x ) = (cid:15)KL ( z , x ) , where z > 0 is a prior estimate of the desired x [ 144 , 199 , 145 , 39 ] . A similar problem involves minimizing the function KL ( Px , y ) . Once again , noisy results can be avoided by including a penalty term , such as p ( x ) = (cid:15)KL ( x , z ) [ 39 ] . In order to relate penalty - function methods to barrier - function meth - ods , we note that minimizing T k ( x ) = f ( x ) + kp ( x ) is equivalent to mini - mizing p ( x ) + 1 k f ( x ) . This is the form of the barrier - function iteration , with 254 CHAPTER 17 . PENALTY - FUNCTION METHODS p ( x ) now in the role previously played by f ( x ) , and f ( x ) now in the role previously played by b ( x ) . We are not concerned here with the eﬀective domain of f ( x ) . Therefore , we can now mimic most , but not all , of what we did for barrier - function methods . 17 . 2 . 2 Basic Facts Lemma 17 . 1 The sequence { T k ( x k ) } is increasing , bounded above by d and converges to some γ ≤ d . Proof : We have T k ( x k ) ≤ T k ( x k + 1 ) ≤ T k ( x k + 1 ) + p ( x k + 1 ) = T k + 1 ( x k + 1 ) . Also , for any z ∈ C , and for each k , we have f ( z ) = f ( z ) + kp ( z ) = T k ( z ) ≥ T k ( x k ) ; therefore d ≥ γ . Lemma 17 . 2 The sequence { p ( x k ) } is decreasing to zero , the sequence { f ( x k ) } is increasing and converging to some β ≤ d . Proof : Since x k minimizes T k ( x ) and x k + 1 minimizes T k + 1 ( x ) , we have f ( x k ) + kp ( x k ) ≤ f ( x k + 1 ) + kp ( x k + 1 ) , and f ( x k + 1 ) + ( k + 1 ) p ( x k + 1 ) ≤ f ( x k ) + ( k + 1 ) p ( x k ) . Consequently , we have ( k + 1 ) [ p ( x k ) − p ( x k + 1 ) ] ≥ f ( x k + 1 ) − f ( x k ) ≥ k [ p ( x k ) − p ( x k + 1 ) ] . Therefore , p ( x k ) − p ( x k + 1 ) ≥ 0 , and f ( x k + 1 ) − f ( x k ) ≥ 0 . From f ( x k ) ≤ f ( x k ) + kp ( x k ) = T k ( x k ) ≤ γ ≤ d , it follows that the sequence { f ( x k ) } is increasing and converges to some β ≤ γ . Since α + kp ( x k ) ≤ f ( x k ) + kp ( x k ) = T k ( x k ) ≤ γ 17 . 2 . PENALTY - FUNCTION METHODS 255 for all k , we have 0 ≤ kp ( x k ) ≤ γ − α . Therefore , the sequence { p ( x k ) } converges to zero . We want β = d . To obtain this result , it appears that we need to make more assumptions : we assume , therefore , that X is a complete metric space , C is closed in X , the functions f and p are continuous and f has compact level sets . From these assumptions , we are able to assert that the sequence { x k } is bounded , so that there is a convergent subsequence ; let { x k n } → x ∗ . It follows that p ( x ∗ ) = 0 , so that x ∗ is in C . Then f ( x ∗ ) = f ( x ∗ ) + p ( x ∗ ) = lim n → + ∞ ( f ( x k n ) + p ( x k n ) ) ≤ lim n → + ∞ T k n ( x k n ) = γ ≤ d . But x ∗ ∈ C , so f ( x ∗ ) ≥ d . Therefore , f ( x ∗ ) = d . It may seem odd that we are trying to minimize f ( x ) over the set C using a sequence { x k } with { f ( x k ) } increasing , but remember that these x k are not in C . Deﬁnition 17 . 1 Let X be a complete metric space . A real - valued function p ( x ) on X has compact level sets if , for all real γ , the level set { x | p ( x ) ≤ γ } is compact . Theorem 17 . 1 Let X be a complete metric space , f ( x ) be a continuous function , and the restriction of f ( x ) to x in C have compact level sets . Then the sequence { x k } is bounded and has convergent subsequences . Fur - thermore , f ( x ∗ ) = d , for any subsequential limit point x ∗ ∈ X . If ˆ x is the unique minimizer of f ( x ) for x ∈ C , then x ∗ = ˆ x and { x k } → ˆ x . Proof : From the previous theorem we have f ( x ∗ ) = d , for all subsequential limit points x ∗ . But , by uniqueness , x ∗ = ˆ x , and so { x k } → ˆ x . Corollary 17 . 1 Let C ⊆ R J be closed and convex . Let f ( x ) : R J → R be closed , proper and convex . If ˆ x is the unique minimizer of f ( x ) over x ∈ C , the sequence { x k } converges to ˆ x . Proof : Let ι C ( x ) be the indicator function of the set C , that is , ι C ( x ) = 0 , for all x in C , and ι C ( x ) = + ∞ , otherwise . Then the function g ( x ) = f ( x ) + ι C ( x ) is closed , proper and convex . If ˆ x is unique , then we have { x | f ( x ) + ι C ( x ) ≤ f ( ˆ x ) } = { ˆ x } . Therefore , one of the level sets of g ( x ) is bounded and nonempty . It follows from Corollary 8 . 7 . 1 of [ 181 ] that every level set of g ( x ) is bounded , so that the sequence { x k } is bounded . 256 CHAPTER 17 . PENALTY - FUNCTION METHODS Chapter 18 Proximity - Function Methods 18 . 1 Chapter Summary In proximity - function minimization the auxiliary function is a Bregman distance . These distances can be used to design interior - point methods in which each iterate is within the interior of the domain of the Bregman func - tion . These distances can be selected to provide closed - form expressions for the iterates . 18 . 2 Bregman Distances Let f : R J → ( −∞ , + ∞ ] be a closed , proper , convex function . Let h be a closed proper convex function , with eﬀective domain D , that is diﬀeren - tiable on the nonempty open convex set int D . Assume that f ( x ) is ﬁnite on C = D and attains its minimum value on C at ˆ x . The corresponding Bregman distance D h ( x , z ) is deﬁned for x in D and z in int D by D h ( x , z ) = h ( x ) − h ( z ) − (cid:104)∇ h ( z ) , x − z (cid:105) . ( 18 . 1 ) Note that D h ( x , z ) ≥ 0 always . If h is essentially strictly convex , then D h ( x , z ) = 0 implies that x = z . Our objective is to minimize f ( x ) over x in C = D . 257 258 CHAPTER 18 . PROXIMITY - FUNCTION METHODS 18 . 3 Proximal Minimization Algorithms At the k th step of the proximal minimization algorithm ( PMA ) [ 47 ] , we minimize the function G k ( x ) = f ( x ) + D h ( x , x k − 1 ) , ( 18 . 2 ) to get x k . The function g k ( x ) = D h ( x , x k − 1 ) ( 18 . 3 ) is nonnegative and g k ( x k − 1 ) = 0 . We assume that each x k lies in int D . Since x k minimizes G k ( x ) within the set D , we have 0 ∈ ∂f ( x k ) + ∇ h ( x k ) − ∇ h ( x k − 1 ) , ( 18 . 4 ) so that ∇ h ( x k − 1 ) = u k + ∇ h ( x k ) , ( 18 . 5 ) for some u k in ∂f ( x k ) . So we must solve the equation u k + ∇ h ( x k ) = ∇ h ( x k − 1 ) , ( 18 . 6 ) for x k . If f ( x ) is diﬀerentiable , we must solve the equation ∇ f ( x k ) + ∇ h ( x k ) = ∇ h ( x k − 1 ) . ( 18 . 7 ) neither of these equations is easily solved in general , an issue we shall return to later . We show now that the PMA is a particular case of the SUMMA . We remind the reader that f ( x ) is now assumed to be convex . Lemma 18 . 1 For each k we have G k ( x ) − G k ( x k ) ≥ D h ( x , x k ) = g k + 1 ( x ) . ( 18 . 8 ) Proof : We have G k ( x ) − G k ( x k ) = f ( x ) − f ( x k ) + h ( x ) − h ( x k ) − (cid:104)∇ h ( x k − 1 ) , x − x k (cid:105) . Now substitute , using Equation ( 18 . 5 ) , to get G k ( x ) − G k ( x k ) = f ( x ) − f ( x k ) − (cid:104) u k , x − x k (cid:105) + D h ( x , x k ) . ( 18 . 9 ) Therefore , G k ( x ) − G k ( x k ) ≥ D h ( x , x k ) , since u k is in ∂f ( x k ) . 18 . 3 . PROXIMAL MINIMIZATION ALGORITHMS 259 We conclude , therefore , that the PMA are in the SUMMA class . The PMA do present certain computational obstacles , however ; Equations ( 18 . 6 ) and ( 18 . 7 ) are not easily solved . The IPA , which we discuss below , is de - signed to remedy this . From the discussion of the SUMMA we know that { f ( x k ) } is monoton - ically decreasing to f ( ˆ x ) . As we noted previously , if the sequence { x k } is bounded , and ˆ x is unique , we can conclude that { x k } → ˆ x . Suppose that ˆ x is not known to be unique , but can be chosen in D ; this will be the case , of course , whenever D is closed . Then G k ( ˆ x ) is ﬁnite for each k . From the deﬁnition of G k ( x ) we have G k ( ˆ x ) = f ( ˆ x ) + D h ( ˆ x , x k − 1 ) . ( 18 . 10 ) From Equation ( 18 . 9 ) we have G k ( ˆ x ) = G k ( x k ) + f ( ˆ x ) − f ( x k ) − (cid:104) u k , ˆ x − x k (cid:105) + D h ( ˆ x , x k ) . ( 18 . 11 ) Therefore , D h ( ˆ x , x k − 1 ) − D h ( ˆ x , x k ) = f ( x k ) − f ( ˆ x ) + D h ( x k , x k − 1 ) + f ( ˆ x ) − f ( x k ) − (cid:104) u k , ˆ x − x k (cid:105) . ( 18 . 12 ) It follows that the sequence { D h ( ˆ x , x k ) } is decreasing and that { f ( x k ) } converges to f ( ˆ x ) . If either the function f ( x ) or the function D h ( ˆ x , · ) has bounded level sets , then the sequence { x k } is bounded , has cluster points x ∗ in C , and f ( x ∗ ) = f ( ˆ x ) , for every x ∗ . We now show that ˆ x in D implies that x ∗ is also in D , whenever h is a Bregman - Legendre function . Let x ∗ be an arbitrary cluster point , with { x k n } → x ∗ . If ˆ x is not in the interior of D , then , by Property B2 of Bregman - Legendre functions , we know that D h ( x ∗ , x k n ) → 0 , so x ∗ is in D . Then the sequence { D h ( x ∗ , x k ) } is decreasing . Since a subsequence converges to zero , we have { D h ( x ∗ , x k ) } → 0 . From Property R5 , we conclude that { x k } → x ∗ . If ˆ x is in int D , but x ∗ is not , then { D h ( ˆ x , x k ) } → + ∞ , by Property R2 . But , this is a contradiction ; therefore x ∗ is in D . Once again , we conclude that { x k } → x ∗ . Now we summarize our results for the PMA . Let f : R J → ( −∞ , + ∞ ] be closed , proper , convex and diﬀerentiable . Let h be a closed proper convex function , with eﬀective domain D , that is diﬀerentiable on the nonempty open convex set int D . Assume that f ( x ) is ﬁnite on C = D and attains its minimum value on C at ˆ x . For each positive integer k , let x k minimize the function f ( x ) + D h ( x , x k − 1 ) . Assume that each x k is in the interior of D . 260 CHAPTER 18 . PROXIMITY - FUNCTION METHODS Theorem 18 . 1 If the restriction of f ( x ) to x in C has bounded level sets and ˆ x is unique , and then the sequence { x k } converges to ˆ x . Theorem 18 . 2 If h ( x ) is a Bregman - Legendre function and ˆ x can be cho - sen in D , then { x k } → x ∗ , x ∗ in D , with f ( x ∗ ) = f ( ˆ x ) . 18 . 4 The IPA The IPA is a modiﬁcation of the PMA designed to overcome some of the computational obstacles encountered in the PMA [ 47 , 55 ] . At the k th step of the IPA we minimize G k ( x ) = f ( x ) + D h ( x , x k − 1 ) ( 18 . 13 ) over either x ∈ R J or x ∈ C , where h ( x ) is as in the previous section . We have selected a ( x ) so that h ( x ) = a ( x ) − f ( x ) is convex and diﬀerentiable , and the equation ∇ a ( x k ) = ∇ a ( x k − 1 ) − ∇ f ( x k − 1 ) ( 18 . 14 ) is easily solved . As we saw previously , the projected gradient descent al - gorithm is an example of the IPA . In this section we consider several other examples and some potential generalizations . 18 . 4 . 1 The Landweber and Projected Landweber Al - gorithms The Landweber ( LW ) and projected Landweber ( PLW ) algorithms are spe - cial cases of the FBS . The objective now is to minimize the function f ( x ) = 1 2 (cid:107) Ax − b (cid:107) 22 , ( 18 . 15 ) over x ∈ R J or x ∈ C , where A is a real I by J matrix . The gradient of f ( x ) is ∇ f ( x ) = 1 γ A T ( Ax − b ) ( 18 . 16 ) and is L - Lipschitz continuous for L = ρ ( A T A ) , the largest eiqenvalue of A T A . The Bregman distance associated with f ( x ) is D f ( x , z ) = 1 2 γ (cid:107) Ax − Az (cid:107) 22 . ( 18 . 17 ) We let c ( x ) = 1 2 γ (cid:107) x (cid:107) 22 , ( 18 . 18 ) 18 . 4 . THE IPA 261 where 0 < γ < 1 L , so that the function h ( x ) = c ( x ) − f ( x ) is convex . At the k th step of the PLW we minimize G k ( x ) = f ( x ) + D h ( x , x k − 1 ) ( 18 . 19 ) over x ∈ C to get x k = P C ( x k − 1 − γA T ( Ax k − 1 − b ) ) ; ( 18 . 20 ) in the case of C = R J we get the Landweber algorithm . 18 . 4 . 2 The Simultaneous MART For a > 0 and b > 0 , the Kullback - Leibler distance , KL ( a , b ) , is deﬁned as KL ( a , b ) = a log a b + b − a . ( 18 . 21 ) In addition , KL ( 0 , 0 ) = 0 , KL ( a , 0 ) = + ∞ and KL ( 0 , b ) = b . The KL distance is then extended to nonnegative vectors coordinate - wise . It is easy to show that , for any non - negative vectors x and z , we have KL ( x , z ) ≥ KL ( x + , z + ) , ( 18 . 22 ) where x + = (cid:80) Jj = 1 x j . The simultaneous MART ( SMART ) minimizes the function f ( x ) = KL ( Px , y ) , where y is a positive vector , P is an I by J matrix with non - negative entries P ij for which s j = (cid:80) Ii = 1 P ij = 1 , for all j , and we seek a non - negative solution of the system y = Px . The Bregman distance associated with the function f ( x ) = KL ( Px , y ) is D f ( x , z ) = KL ( Px , Pz ) . ( 18 . 23 ) We select a ( x ) to be a ( x ) = J (cid:88) j = 1 x j log ( x j ) − x j . ( 18 . 24 ) It follows from the inequality in ( 18 . 22 ) that h ( x ) is convex and D h ( x , z ) = KL ( x , z ) − KL ( Px , Pz ) ≥ 0 . ( 18 . 25 ) At the k th step of the SMART we minimize G k ( x ) = f ( x ) + D h ( x , x k − 1 ) = KL ( Px , y ) + KL ( x , x k − 1 ) − KL ( Px , Px k − 1 ) ( 18 . 26 ) to get x kj = x k − 1 j exp (cid:16) I (cid:88) i = 1 P ij log y i ( Px k − 1 ) i (cid:17) . ( 18 . 27 ) 262 CHAPTER 18 . PROXIMITY - FUNCTION METHODS 18 . 4 . 3 Forward - Backward Splitting Closely related to the IPA is the forward - backward splitting ( FBS ) algorithm [ 88 , 59 ] . Note that minimizing G k ( x ) in Equation ( 18 . 13 ) over x ∈ C is equivalent to minimizing G k ( x ) = ι C ( x ) + f ( x ) + D h ( x , x k − 1 ) ( 18 . 28 ) over all x ∈ R J , where ι C ( x ) = 0 for x ∈ C and ι C ( x ) = + ∞ otherwise . This suggests a more general iterative algorithm , the FBS . Suppose that we want to minimize the function f 1 ( x ) + f 2 ( x ) , where both functions are convex and f 2 ( x ) is diﬀerentiable with an L - Lipschitz continuous gradient . At the k th step of the FBS algorithm we obtain x k by minimizing G k ( x ) = f 1 ( x ) + f 2 ( x ) + 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f 2 ( x , x k − 1 ) , ( 18 . 29 ) over all x ∈ R J , where 0 < γ < 12 γ . We shall discuss the FBS in more detail in the next chapter . Chapter 19 Forward - Backward Splitting 19 . 1 Chapter Summary The forward - backward splitting ( FBS ) methods form a quite large subclass of the SUMMA algorithms . In this chapter we discuss the FBS , prove a convergence theorem for FBS , and give several examples . 19 . 2 Moreau’s Proximity Operators Let f : R J → R be convex . For each z ∈ R J the function m f ( z ) : = min x { f ( x ) + 1 2 (cid:107) x − z (cid:107) 22 } ( 19 . 1 ) is minimized by a unique x [ 181 ] . The operator that associates with each z the minimizing x is Moreau’s proximity operator , and we write x = prox f ( z ) . The operator prox f extends the notion of orthogonal projection onto a closed convex set [ 158 , 159 , 160 ] . We have x = prox f ( z ) if and only if z − x ∈ ∂f ( x ) . Proximity operators are also ﬁrmly non - expansive [ 88 ] ; indeed , the proximity operator prox f is the resolvent of the maximal monotone operator B ( x ) = ∂f ( x ) and all such resolvent operators are ﬁrmly non - expansive [ 28 ] . 19 . 3 Forward - Backward Splitting Algorithms Our objective here is to provide an elementary proof of convergence for the forward - backward splitting ( FBS ) algorithm ; a detailed discussion of this algorithm and its history is given by Combettes and Wajs in [ 88 ] . 263 264 CHAPTER 19 . FORWARD - BACKWARD SPLITTING Let f : R J → R be convex , with f = f 1 + f 2 , both convex , f 2 diﬀer - entiable , and ∇ f 2 L - Lipschitz continuous . The iterative step of the FBS algorithm is x k = prox γf 1 (cid:16) x k − 1 − γ ∇ f 2 ( x k − 1 ) (cid:17) . ( 19 . 2 ) As we shall show , convergence of the sequence { x k } to a solution can be established , if γ is chosen to lie within the interval ( 0 , 1 / L ] . 19 . 4 Convergence of FBS Let f : R J → R be convex , with f = f 1 + f 2 , both convex , f 2 diﬀerentiable , and ∇ f 2 L - Lipschitz continuous . Let { x k } be deﬁned by Equation ( 35 . 19 ) and let 0 < γ ≤ 1 / L . For each k = 1 , 2 , . . . let G k ( x ) = f ( x ) + 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f 2 ( x , x k − 1 ) , ( 19 . 3 ) where D f 2 ( x , x k − 1 ) = f 2 ( x ) − f 2 ( x k − 1 ) − (cid:104)∇ f 2 ( x k − 1 ) , x − x k − 1 (cid:105) . ( 19 . 4 ) Since f 2 ( x ) is convex , D f 2 ( x , y ) ≥ 0 for all x and y and is the Bregman distance formed from the function f 2 [ 25 ] . The auxiliary function g k ( x ) = 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f 2 ( x , x k − 1 ) ( 19 . 5 ) can be rewritten as g k ( x ) = D h ( x , x k − 1 ) , ( 19 . 6 ) where h ( x ) = 1 2 γ (cid:107) x (cid:107) 22 − f 2 ( x ) . ( 19 . 7 ) Therefore , g k ( x ) ≥ 0 whenever h ( x ) is a convex function . We know that h ( x ) is convex if and only if (cid:104)∇ h ( x ) − ∇ h ( y ) , x − y (cid:105) ≥ 0 , ( 19 . 8 ) for all x and y . This is equivalent to 1 γ (cid:107) x − y (cid:107) 22 − (cid:104)∇ f 2 ( x ) − ∇ f 2 ( y ) , x − y (cid:105) ≥ 0 . ( 19 . 9 ) Since ∇ f 2 is L - Lipschitz , the inequality ( 19 . 9 ) holds for 0 < γ ≤ 1 / L . 19 . 4 . CONVERGENCE OF FBS 265 Lemma 19 . 1 The x k that minimizes G k ( x ) over x is given by Equation ( 35 . 19 ) . Proof : We know that x k minimizes G k ( x ) if and only if 0 ∈ ∇ f 2 ( x k ) + 1 γ ( x k − x k − 1 ) − ∇ f 2 ( x k ) + ∇ f 2 ( x k − 1 ) + ∂f 1 ( x k ) , or , equivalently , (cid:16) x k − 1 − γ ∇ f 2 ( x k − 1 ) (cid:17) − x k ∈ ∂ ( γf 1 ) ( x k ) . Consequently , x k = prox γf 1 ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) . Theorem 19 . 1 The sequence { x k } converges to a minimizer of the func - tion f ( x ) , whenever minimizers exist . Proof : A relatively simple calculation shows that G k ( x ) − G k ( x k ) = 1 2 γ (cid:107) x − x k (cid:107) 22 + (cid:16) f 1 ( x ) − f 1 ( x k ) − 1 γ (cid:104) ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) − x k , x − x k (cid:105) (cid:17) . ( 19 . 10 ) Since ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) − x k ∈ ∂ ( γf 1 ) ( x k ) , it follows that (cid:16) f 1 ( x ) − f 1 ( x k ) − 1 γ (cid:104) ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) − x k , x − x k (cid:105) (cid:17) ≥ 0 . Therefore , G k ( x ) − G k ( x k ) ≥ 1 2 γ (cid:107) x − x k (cid:107) 22 ≥ g k + 1 ( x ) . ( 19 . 11 ) Therefore , the inequality in ( 15 . 6 ) holds and the iteration ﬁts into the SUMMA class . Now let ˆ x minimize f ( x ) over all x . Then G k ( ˆ x ) − G k ( x k ) = f ( ˆ x ) + g k ( ˆ x ) − f ( x k ) − g k ( x k ) ≤ f ( ˆ x ) + G k − 1 ( ˆ x ) − G k − 1 ( x k − 1 ) − f ( x k ) − g k ( x k ) , 266 CHAPTER 19 . FORWARD - BACKWARD SPLITTING so that (cid:16) G k − 1 ( ˆ x ) − G k − 1 ( x k − 1 ) (cid:17) − (cid:16) G k ( ˆ x ) − G k ( x k ) (cid:17) ≥ f ( x k ) − f ( ˆ x ) + g k ( x k ) ≥ 0 . Therefore , the sequence { G k ( ˆ x ) − G k ( x k ) } is decreasing and the sequences { g k ( x k ) } and { f ( x k ) − f ( ˆ x ) } converge to zero . From G k ( ˆ x ) − G k ( x k ) ≥ 1 2 γ (cid:107) ˆ x − x k (cid:107) 22 , it follows that the sequence { x k } is bounded . Therefore , we may select a subsequence { x k n } converging to some x ∗∗ , with { x k n − 1 } converging to some x ∗ , and therefore f ( x ∗ ) = f ( x ∗∗ ) = f ( ˆ x ) . Replacing the generic ˆ x with x ∗∗ , we ﬁnd that { G k ( x ∗∗ ) − G k ( x k ) } is decreasing to zero . From the inequality in ( 19 . 11 ) , we conclude that the sequence { (cid:107) x ∗ − x k (cid:107) 2 2 } converges to zero , and so { x k } converges to x ∗ . This completes the proof of the theorem . 19 . 5 Some Examples We present some examples to illustrate the application of the convergence theorem . 19 . 5 . 1 Projected Gradient Descent Let C be a non - empty , closed convex subset of R J and f 1 ( x ) = ι C ( x ) , the function that is + ∞ for x not in C and zero for x in C . Then ι C ( x ) is convex , but not diﬀerentiable . We have prox γf 1 = P C , the orthogonal projection onto C . The iteration in Equation ( 35 . 19 ) becomes x k = P C (cid:16) x k − 1 − γ ∇ f 2 ( x k − 1 ) (cid:17) . ( 19 . 12 ) The sequence { x k } converges to a minimizer of f 2 over x ∈ C , whenever such minimizers exist , for 0 < γ ≤ 1 / L . 19 . 5 . 2 The CQ Algorithm Let A be a real I by J matrix , C ⊆ R J , and Q ⊆ R I , both closed convex sets . The split feasibility problem ( SFP ) is to ﬁnd x in C such that Ax is in Q . The function f 2 ( x ) = 1 2 (cid:107) P Q Ax − Ax (cid:107) 22 ( 19 . 13 ) 19 . 5 . SOME EXAMPLES 267 is convex , diﬀerentiable and ∇ f 2 is L - Lipschitz for L = ρ ( A T A ) , the spec - tral radius of A T A . The gradient of f 2 is ∇ f 2 ( x ) = A T ( I − P Q ) Ax . ( 19 . 14 ) We want to minimize the function f 2 ( x ) over x in C , or , equivalently , to minimize the function f ( x ) = ι C ( x ) + f 2 ( x ) . The projected gradient descent algorithm has the iterative step x k = P C (cid:16) x k − 1 − γA T ( I − P Q ) Ax k − 1 (cid:17) ; ( 19 . 15 ) this iterative method was called the CQ - algorithm in [ 50 , 51 ] . The sequence { x k } converges to a solution whenever f 2 has a minimum on the set C , for 0 < γ ≤ 1 / L . In [ 73 , 69 ] the CQ algorithm was extended to a multiple - sets algorithm and applied to the design of protocols for intensity - modulated radiation therapy . 19 . 5 . 3 The Projected Landweber Algorithm The problem is to minimize the function f 2 ( x ) = 1 2 (cid:107) Ax − b (cid:107) 22 , over x ∈ C . This is a special case of the SFP and we can use the CQ - algorithm , with Q = { b } . The resulting iteration is the projected Landwe - ber algorithm [ 19 ] ; when C = R J it becomes the Landweber algorithm [ 143 ] . 19 . 5 . 4 Minimizing f 2 over a Linear Manifold Suppose that we want to minimize f 2 over x in the linear manifold M = S + p , where S is a subspace of R J of dimension I < J and p is a ﬁxed vector . Let A be an I by J matrix such that the I columns of A T form a basis for S . For each z ∈ R I let d ( z ) = f 2 ( A T z + p ) , so that d is convex , diﬀerentiable , and its gradient , ∇ d ( z ) = A ∇ f 2 ( A T z + p ) , is K - Lipschitz continuous , for K = ρ ( A T A ) L . The sequence { z k } deﬁned by z k = z k − 1 − γ ∇ d ( z k − 1 ) ( 19 . 16 ) 268 CHAPTER 19 . FORWARD - BACKWARD SPLITTING converges to a minimizer of d over all z in R I , whenever minimizers exist , for 0 < γ ≤ 1 / K . From Equation ( 19 . 16 ) we get x k = x k − 1 − γA T A ∇ f 2 ( x k − 1 ) , ( 19 . 17 ) with x k = A T z k + p . The sequence { x k } converges to a minimizer of f 2 over all x in M . Suppose now that we begin with an algorithm having the iterative step x k = x k − 1 − γA T A ∇ f 2 ( x k − 1 ) , ( 19 . 18 ) where A is any real I by J matrix having rank I . Let x 0 be in the range of A T , so that x 0 = A T z 0 , for some z 0 ∈ R I . Then each x k = A T z k is again in the range of A T , and we have A T z k = A T z k − 1 − γA T A ∇ f 2 ( A T z k − 1 ) . ( 19 . 19 ) With d ( z ) = f 2 ( A T z ) , we can write Equation ( 19 . 19 ) as A T (cid:16) z k − ( z k − 1 − γ ∇ d ( z k − 1 ) ) (cid:17) = 0 . ( 19 . 20 ) Since A has rank I , A T is one - to - one , so that z k − z k − 1 − γ ∇ d ( z k − 1 ) = 0 . ( 19 . 21 ) The sequence { z k } converges to a minimizer of d , over all z ∈ R I , whenever such minimizers exist , for 0 < γ ≤ 1 / K . Therefore , the sequence { x k } converges to a minimizer of f 2 over all x in the range of A T . Chapter 20 Alternating Minimization 20 . 1 Chapter Summary The alternating minimization ( AM ) iteration of Csisz´ar and Tusn´ady [ 92 ] provides a useful framework for the derivation of iterative optimization algorithms . In this chapter we discuss their ﬁve - point property and use it to obtain a somewhat simpler proof of convergence for their AM algorithm . We then show that all AM algorithms with the ﬁve - point property are in the SUMMA class . 20 . 2 The AM Framework Suppose that P and Q are arbitrary non - empty sets and the function Θ ( p , q ) satisﬁes −∞ < Θ ( p , q ) ≤ + ∞ , for each p ∈ P and q ∈ Q . We assume that , for each p ∈ P , there is q ∈ Q with Θ ( p , q ) < + ∞ . There - fore , b = inf p ∈ P , q ∈ Q Θ ( p , q ) < + ∞ . We assume also that b > −∞ ; in many applications , the function Θ ( p , q ) is non - negative , so this additional assumption is unnecessary . We do not always assume there are ˆ p ∈ P and ˆ q ∈ Q such that Θ ( ˆ p , ˆ q ) = b ; when we do assume that such a ˆ p and ˆ q exist , we will not assume that ˆ p and ˆ q are unique with that property . The objective is to generate a sequence { ( p n , q n ) } such that Θ ( p n , q n ) → b . 20 . 2 . 1 The AM Iteration The general AM method proceeds in two steps : we begin with some q 0 , and , having found q n , we • 1 . minimize Θ ( p , q n ) over p ∈ P to get p = p n + 1 , and then • 2 . minimize Θ ( p n + 1 , q ) over q ∈ Q to get q = q n + 1 . 269 270 CHAPTER 20 . ALTERNATING MINIMIZATION In certain applications we consider the special case of alternating cross - entropy minimization . In that case , the vectors p and q are non - negative , and the function Θ ( p , q ) will have the value + ∞ whenever there is an index j such that p j > 0 , but q j = 0 . It is important for those particular applications that we select q 0 with all positive entries . We therefore assume , for the general case , that we have selected q 0 so that Θ ( p , q 0 ) is ﬁnite for all p . The sequence { Θ ( p n , q n ) } is decreasing and bounded below by b , since we have Θ ( p n , q n ) ≥ Θ ( p n + 1 , q n ) ≥ Θ ( p n + 1 , q n + 1 ) . ( 20 . 1 ) Therefore , the sequence { Θ ( p n , q n ) } converges to some B ≥ b . Without additional assumptions , we can say little more . We know two things : Θ ( p n + 1 , q n ) − Θ ( p n + 1 , q n + 1 ) ≥ 0 , ( 20 . 2 ) and Θ ( p n , q n ) − Θ ( p n + 1 , q n ) ≥ 0 . ( 20 . 3 ) Equation 20 . 3 can be strengthened to Θ ( p , q n ) − Θ ( p n + 1 , q n ) ≥ 0 . ( 20 . 4 ) We need to make these inequalities more precise . 20 . 2 . 2 The Five - Point Property for AM The ﬁve - point property is the following : for all p ∈ P and q ∈ Q and n = 1 , 2 , . . . The Five - Point Property Θ ( p , q ) + Θ ( p , q n − 1 ) ≥ Θ ( p , q n ) + Θ ( p n , q n − 1 ) . ( 20 . 5 ) 20 . 2 . 3 The Main Theorem for AM We want to ﬁnd suﬃcient conditions for the sequence { Θ ( p n , q n ) } to con - verge to b , that is , for B = b . The following is the main result of [ 92 ] . Theorem 20 . 1 If the ﬁve - point property holds then B = b . Proof : Suppose that B > b . Then there are p (cid:48) and q (cid:48) such that B > Θ ( p (cid:48) , q (cid:48) ) ≥ b . From the ﬁve - point property we have Θ ( p (cid:48) , q n − 1 ) − Θ ( p n , q n − 1 ) ≥ Θ ( p (cid:48) , q n ) − Θ ( p (cid:48) , q (cid:48) ) , ( 20 . 6 ) 20 . 2 . THE AM FRAMEWORK 271 so that Θ ( p (cid:48) , q n − 1 ) − Θ ( p (cid:48) , q n ) ≥ Θ ( p n , q n − 1 ) − Θ ( p (cid:48) , q (cid:48) ) ≥ 0 . ( 20 . 7 ) All the terms being subtracted can be shown to be ﬁnite . It follows that the sequence { Θ ( p (cid:48) , q n − 1 ) } is decreasing , bounded below , and therefore convergent . The right side of Equation ( 20 . 7 ) must therefore converge to zero , which is a contradiction . We conclude that B = b whenever the ﬁve - point property holds in AM . 20 . 2 . 4 The Three - and Four - Point Properties In [ 92 ] the ﬁve - point property is related to two other properties , the three - and four - point properties . This is a bit peculiar for two reasons : ﬁrst , as we have just seen , the ﬁve - point property is suﬃcient to prove the main theorem ; and second , these other properties involve a second function , ∆ : P × P → [ 0 , + ∞ ] , with ∆ ( p , p ) = 0 for all p ∈ P . The three - and four - point properties jointly imply the ﬁve - point property , but to get the converse , we need to use the ﬁve - point property to deﬁne this second function ; it can be done , however . The three - point property is the following : The Three - Point Property Θ ( p , q n ) − Θ ( p n + 1 , q n ) ≥ ∆ ( p , p n + 1 ) , ( 20 . 8 ) for all p . The four - point property is the following : The Four - Point Property ∆ ( p , p n + 1 ) + Θ ( p , q ) ≥ Θ ( p , q n + 1 ) , ( 20 . 9 ) for all p and q . It is clear that the three - and four - point properties together imply the ﬁve - point property . We show now that the three - point property and the four - point property are implied by the ﬁve - point property . For that purpose we need to deﬁne a suitable ∆ ( p , ˜ p ) . For any p and ˜ p in P deﬁne ∆ ( p , ˜ p ) = Θ ( p , q ( ˜ p ) ) − Θ ( p , q ( p ) ) , ( 20 . 10 ) where q ( p ) denotes a member of Q satisfying Θ ( p , q ( p ) ) ≤ Θ ( p , q ) , for all q in Q . Clearly , ∆ ( p , ˜ p ) ≥ 0 and ∆ ( p , p ) = 0 . The four - point property holds automatically from this deﬁnition , while the three - point property follows from the ﬁve - point property . Therefore , it is suﬃcient to discuss only the ﬁve - point property when speaking of the AM method . 272 CHAPTER 20 . ALTERNATING MINIMIZATION 20 . 3 Alternating Bregman Distance Minimiza - tion The general problem of minimizing Θ ( p , q ) is simply a minimization of a real - valued function of two variables , p ∈ P and q ∈ Q . In many cases the function Θ ( p , q ) is a distance between p and q , either (cid:107) p − q (cid:107) 22 or KL ( p , q ) . In the case of Θ ( p , q ) = (cid:107) p − q (cid:107) 22 , each step of the alternating minimization algorithm involves an orthogonal projection onto a closed convex set ; both projections are with respect to the same Euclidean distance function . In the case of cross - entropy minimization , we ﬁrst project q n onto the set P by minimizing the distance KL ( p , q n ) over all p ∈ P , and then project p n + 1 onto the set Q by minimizing the distance function KL ( p n + 1 , q ) . This suggests the possibility of using alternating minimization with respect to more general distance functions . We shall focus on Bregman distances . 20 . 3 . 1 Bregman Distances Let f : R J → R be a Bregman function [ 25 , 83 , 31 ] , and so f ( x ) is convex on its domain and diﬀerentiable in the interior of its domain . Then , for x in the domain and z in the interior , we deﬁne the Bregman distance D f ( x , z ) by D f ( x , z ) = f ( x ) − f ( z ) − (cid:104)∇ f ( z ) , x − z (cid:105) . ( 20 . 11 ) For example , the KL distance is a Bregman distance with associated Breg - man function f ( x ) = J (cid:88) j = 1 x j log x j − x j . ( 20 . 12 ) Suppose now that f ( x ) is a Bregman function and P and Q are closed convex subsets of the interior of the domain of f ( x ) . Let p n + 1 minimize D f ( p , q n ) over all p ∈ P . It follows then that (cid:104)∇ f ( p n + 1 ) − ∇ f ( q n ) , p − p n + 1 (cid:105) ≥ 0 , ( 20 . 13 ) for all p ∈ P . Since D f ( p , q n ) − D f ( p n + 1 , q n ) = D f ( p , p n + 1 ) + (cid:104)∇ f ( p n + 1 ) − ∇ f ( q n ) , p − p n + 1 (cid:105) , ( 20 . 14 ) it follows that the three - point property holds , with Θ ( p , q ) = D f ( p , q ) , ( 20 . 15 ) 20 . 3 . ALTERNATING BREGMAN DISTANCE MINIMIZATION 273 and ∆ ( p , ˆ p ) = D f ( p , ˜ p ) . ( 20 . 16 ) To get the four - point property we need to restrict D f somewhat ; we assume from now on that D f ( p , q ) is jointly convex , that is , it is convex in the combined vector variable ( p , q ) ( see [ 13 ] ) . Now we can invoke a lemma due to Eggermont and LaRiccia [ 106 ] . 20 . 3 . 2 The Eggermont - LaRiccia Lemma Lemma 20 . 1 Suppose that the Bregman distance D f ( p , q ) is jointly con - vex . Then it has the four - point property . Proof : By joint convexity we have D f ( p , q ) − D f ( p n , q n ) ≥ (cid:104)∇ 1 D f ( p n , q n ) , p − p n (cid:105) + (cid:104)∇ 2 D f ( p n , q n ) , q − q n (cid:105) , where ∇ 1 denotes the gradient with respect to the ﬁrst vector variable . Since q n minimizes D f ( p n , q ) over all q ∈ Q , we have (cid:104)∇ 2 D f ( p n , q n ) , q − q n (cid:105) ≥ 0 , for all q . Also , (cid:104)∇ 1 ( p n , q n ) , p − p n (cid:105) = (cid:104)∇ f ( p n ) − ∇ f ( q n ) , p − p n (cid:105) . It follows that D f ( p , q n ) − D f ( p , p n ) = D f ( p n , q n ) + (cid:104)∇ 1 ( p n , q n ) , p − p n (cid:105) ≤ D f ( p , q ) − (cid:104)∇ 2 D f ( p n , q n ) , q − q n (cid:105) ≤ D f ( p , q ) . Therefore , we have D f ( p , p n ) + D f ( p , q ) ≥ D f ( p , q n ) . This is the four - point property . We now know that the alternating minimization method works for any Bregman distance that is jointly convex . This includes the Euclidean and the KL distances . 274 CHAPTER 20 . ALTERNATING MINIMIZATION 20 . 4 Minimizing a Proximity Function We present now an example of alternating Bregman distance minimization taken from [ 49 ] . The problem is the convex feasibility problem ( CFP ) , to ﬁnd a member of the intersection C ⊆ R J of ﬁnitely many closed convex sets C i , i = 1 , . . . , I , or , failing that , to minimize the proximity function F ( x ) = I (cid:88) i = 1 D i ( ←− P i x , x ) , ( 20 . 17 ) where f i are Bregman functions for which D i , the associated Bregman distance , is jointly convex , and ←− P i x are the left Bregman projection of x onto the set C i , that is , ←− P i x ∈ C i and D i ( ←− P i x , x ) ≤ D i ( z , x ) , for all z ∈ C i . Because each D i is jointly convex , the function F ( x ) is convex . The problem can be formulated as an alternating minimization , where P ⊆ R IJ is the product set P = C 1 × C 2 × . . . × C I . A typical member of P has the form p = ( c 1 , c 2 , . . . , c I ) , where c i ∈ C i , and Q ⊆ R IJ is the diagonal subset , meaning that the elements of Q are the I - fold product of a single x ; that is Q = { d ( x ) = ( x , x , . . . , x ) ∈ R IJ } . We then take Θ ( p , q ) = I (cid:88) i = 1 D i ( c i , x ) , ( 20 . 18 ) and ∆ ( p , ˜ p ) = Θ ( p , ˜ p ) . In [ 71 ] a similar iterative algorithm was developed for solving the CFP , using the same sets P and Q , but using alternating projection , rather than alternating minimization . Now it is not necessary that the Bregman distances be jointly convex . Each iteration of their algorithm involves two steps : • 1 . minimize (cid:80) Ii = 1 D i ( c i , x n ) over c i ∈ C i , obtaining c i = ←− P i x n , and then • 2 . minimize (cid:80) Ii = 1 D i ( x , ←− P i x n ) . Because this method is an alternating projection approach , it converges only when the CFP has a solution , whereas the previous alternating mini - mization method minimizes F ( x ) , even when the CFP has no solution . 20 . 5 Right and Left Bregman Projections Because Bregman distances D f are not generally symmetric , we can speak of right and left Bregman projections onto a closed convex set . For any allowable vector x , the left Bregman projection of x onto C , if it exists , is 20 . 6 . MORE PROXIMITY FUNCTION MINIMIZATION 275 the vector ←− P C x ∈ C satisfying the inequality D f ( ←− P C x , x ) ≤ D f ( c , x ) , for all c ∈ C . Similarly , the right Bregman projection is the vector −→ P C x ∈ C satisfying the inequality D f ( x , −→ P C x ) ≤ D f ( x , c ) , for any c ∈ C . The alternating minimization approach described above to minimize the proximity function F ( x ) = I (cid:88) i = 1 D i ( ←− P i x , x ) ( 20 . 19 ) can be viewed as an alternating projection method , but employing both right and left Bregman projections . Consider the problem of ﬁnding a member of the intersection of two closed convex sets C and D . We could proceed as follows : having found x n , minimize D f ( x n , d ) over all d ∈ D , obtaining d = −→ P D x n , and then minimize D f ( c , −→ P D x n ) over all c ∈ C , obtaining c = x n + 1 = ←− P C −→ P D x n . The objective of this algorithm is to minimize D f ( c , d ) over all c ∈ C and d ∈ D ; such a minimum may not exist , of course . In [ 15 ] the authors note that the alternating minimization algorithm of [ 49 ] involves right and left Bregman projections , which suggests to them iterative methods involving a wider class of operators that they call “Breg - man retractions” . 20 . 6 More Proximity Function Minimization Proximity function minimization and right and left Bregman projections play a role in a variety of iterative algorithms . We survey several of them in this section . 20 . 6 . 1 Cimmino’s Algorithm Our objective here is to ﬁnd an exact or approximate solution of the system of I linear equations in J unknowns , written Ax = b . For each i let C i = { z | ( Az ) i = b i } , ( 20 . 20 ) and P i x be the orthogonal projection of x onto C i . Then ( P i x ) j = x j + α i A ij ( b i − ( Ax ) i ) , ( 20 . 21 ) where ( α i ) − 1 = J (cid:88) j = 1 A 2 ij . ( 20 . 22 ) 276 CHAPTER 20 . ALTERNATING MINIMIZATION Let F ( x ) = I (cid:88) i = 1 (cid:107) P i x − x (cid:107) 22 . ( 20 . 23 ) Using alternating minimization on this proximity function gives Cimmino’s algorithm , with the iterative step x n + 1 j = x nj + 1 I I (cid:88) i = 1 α i A ij ( b i − ( Ax n ) i ) . ( 20 . 24 ) 20 . 6 . 2 Simultaneous Projection for Convex Feasibility Now we let C i be any closed convex subsets of R J and deﬁne F ( x ) as in the previous section . Again , we apply alternating minimization . The iterative step of the resulting algorithm is x n + 1 = 1 I I (cid:88) i = 1 P i x n . ( 20 . 25 ) The objective here is to minimize F ( x ) , if there is a minimum . 20 . 6 . 3 The Bauschke - Combettes - Noll Problem In [ 16 ] Bauschke , Combettes and Noll consider the following problem : min - imize the function Θ ( p , q ) = Λ ( p , q ) = φ ( p ) + ψ ( q ) + D f ( p , q ) , ( 20 . 26 ) where φ and ψ are convex on R J , D = D f is a Bregman distance , and P = Q is the interior of the domain of f . They assume that b = inf ( p , q ) Λ ( p , q ) > −∞ , ( 20 . 27 ) and seek a sequence { ( p n , q n ) } such that { Λ ( p n , q n ) } converges to b . The se - quence is obtained by the AM method , as in our previous discussion . They prove that , if the Bregman distance is jointly convex , then { Λ ( p n , q n ) } ↓ b . In this subsection we obtain this result by showing that Λ ( p , q ) has the ﬁve - point property whenever D = D f is jointly convex . Our proof is loosely based on the proof of the Eggermont - LaRiccia lemma . The ﬁve - point property for Λ ( p , q ) is Λ ( p , q n − 1 ) − Λ ( p n , q n − 1 ) ≥ Λ ( p , q n ) − Λ ( p , q ) . ( 20 . 28 ) 20 . 6 . MORE PROXIMITY FUNCTION MINIMIZATION 277 A simple calculation shows that the inequality in ( 20 . 28 ) is equivalent to Λ ( p , q ) − Λ ( p n , q n ) ≥ D ( p , q n ) + D ( p n , q n − 1 ) − D ( p , q n − 1 ) − D ( p n , q n ) . ( 20 . 29 ) By the joint convexity of D ( p , q ) and the convexity of φ and ψ we have Λ ( p , q ) − Λ ( p n , q n ) ≥ (cid:104)∇ p Λ ( p n , q n ) , p − p n (cid:105) + (cid:104)∇ q Λ ( p n , q n ) , q − q n (cid:105) , ( 20 . 30 ) where ∇ p Λ ( p n , q n ) denotes the gradient of Λ ( p , q ) , with respect to p , eval - uated at ( p n , q n ) . Since q n minimizes Λ ( p n , q ) , it follows that (cid:104)∇ q Λ ( p n , q n ) , q − q n (cid:105) = 0 , ( 20 . 31 ) for all q . Therefore , Λ ( p , q ) − Λ ( p n , q n ) ≥ (cid:104)∇ p Λ ( p n , q n ) , p − p n (cid:105) . ( 20 . 32 ) We have (cid:104)∇ p Λ ( p n , q n ) , p − p n (cid:105) = (cid:104)∇ f ( p n ) − ∇ f ( q n ) , p − p n (cid:105) + (cid:104)∇ φ ( p n ) , p − p n (cid:105) . ( 20 . 33 ) Since p n minimizes Λ ( p , q n − 1 ) , we have ∇ p Λ ( p n , q n − 1 ) = 0 , ( 20 . 34 ) or ∇ φ ( p n ) = ∇ f ( q n − 1 ) − ∇ f ( p n ) , ( 20 . 35 ) so that (cid:104)∇ p Λ ( p n , q n ) , p − p n (cid:105) = (cid:104)∇ f ( q n − 1 ) − ∇ f ( q n ) , p − p n (cid:105) ( 20 . 36 ) = D ( p , q n ) + D ( p n , q n − 1 ) − D ( p , q n − 1 ) − D ( p n , q n ) . ( 20 . 37 ) Using ( 20 . 32 ) we obtain the inequality in ( 20 . 29 ) . This shows that Λ ( p , q ) has the ﬁve - point property whenever the Bregman distance D = D f is jointly convex . From our previous discussion of AM , we conclude that the sequence { Λ ( p n , q n ) } converges to b ; this is Corollary 4 . 3 of [ 16 ] . In [ 61 ] it was shown that , in certain cases , the expectation maximization maximum likelihood ( EM ) method involves alternating minimization of a function of the form Λ ( p , q ) . If ψ = 0 , then { Λ ( p n , q n ) } converges to b , even without the assumption that the distance D f is jointly convex . In such cases , Λ ( p , q ) has the form of the objective function in proximal minimization and therefore the problem falls into the SUMMA class ( see Lemma 18 . 1 ) . 278 CHAPTER 20 . ALTERNATING MINIMIZATION 20 . 7 AM as SUMMA We show now that the SUMMA class of sequential unconstrained mini - mization methods includes all the AM methods for which the ﬁve - point property holds . For each p in the set P , deﬁne q ( p ) in Q as a member of Q for which Θ ( p , q ( p ) ) ≤ Θ ( p , q ) , for all q ∈ Q . Let f ( p ) = Θ ( p , q ( p ) ) . At the n th step of AM we minimize G n ( p ) = Θ ( p , q n − 1 ) = Θ ( p , q ( p ) ) + (cid:16) Θ ( p , q n − 1 ) − Θ ( p , q ( p ) ) (cid:17) ( 20 . 38 ) to get p n . With g n ( p ) = (cid:16) Θ ( p , q n − 1 ) − Θ ( p , q ( p ) ) (cid:17) ≥ 0 , ( 20 . 39 ) we can write G n ( p ) = f ( p ) + g n ( p ) . ( 20 . 40 ) According to the ﬁve - point property , we have G n ( p ) − G n ( p n ) ≥ Θ ( p , q n ) − Θ ( p , q ( p ) ) = g n + 1 ( p ) . ( 20 . 41 ) It follows that AM is a member of the SUMMA class . Chapter 21 A Tale of Two Algorithms 21 . 1 Chapter Summary Although the EMML and SMART algorithms have quite diﬀerent histories and are not typically considered together , they are closely related , as we shall see [ 39 , 40 ] . In this chapter we examine these two algorithms in tan - dem , following [ 41 ] . Forging a link between the EMML and SMART led to a better understanding of both of these algorithms and to new results . The proof of convergence of the SMART in the inconsistent case [ 39 ] was based on the analogous proof for the EMML [ 199 ] , while discovery of the faster version of the EMML , the rescaled block - iterative EMML ( RBI - EMML ) [ 42 ] came from studying the analogous block - iterative version of SMART [ 81 ] . The proofs we give here are elementary and rely mainly on easily established properties of the cross - entropy or Kullback - Leibler distance . 21 . 2 Notation Let P be an I by J matrix with entries P ij ≥ 0 , such that , for each j = 1 , . . . , J , we have s j = (cid:80) Ii = 1 P ij > 0 . Let y = ( y 1 , . . . , y I ) T with y i > 0 for each i . We shall assume throughout this chapter that s j = 1 for each j . If this is not the case initially , we replace x j with x j s j and P ij with P ij / s j ; the quantities ( Px ) i are unchanged . 21 . 3 The Two Algorithms The algorithms we shall consider are the expectation maximization maxi - mum likelihood method ( EMML ) and the simultaneous multiplicative alge - braic reconstruction technique ( SMART ) . When y = Px has nonnegative 279 280 CHAPTER 21 . A TALE OF TWO ALGORITHMS solutions , both algorithms produce such a solution . In general , the EMML gives a nonnegative minimizer of KL ( y , Px ) , while the SMART minimizes KL ( Px , y ) over nonnegative x . For both algorithms we begin with an arbitrary positive vector x 0 . The iterative step for the EMML method is x kj = ( x k − 1 ) (cid:48) j = x k − 1 j I (cid:88) i = 1 P ij y i ( Px k − 1 ) i . ( 21 . 1 ) The iterative step for the SMART is x mj = ( x m − 1 ) (cid:48)(cid:48) j = x m − 1 j exp (cid:16) I (cid:88) i = 1 P ij log y i ( Px m − 1 ) i (cid:17) . ( 21 . 2 ) Note that , to avoid confusion , we use k for the iteration number of the EMML and m for the SMART . 21 . 4 Background The expectation maximization maximum likelihood method ( EMML ) has been the subject of much attention in the medical - imaging literature over the past decade . Statisticians like it because it is based on the well - studied principle of likelihood maximization for parameter estimation . Physicists like it because , unlike its competition , ﬁltered back - projection , it permits the inclusion of sophisticated models of the physical situation . Mathemati - cians like it because it can be derived from iterative optimization theory . Physicians like it because the images are often better than those produced by other means . No method is perfect , however , and the EMML suﬀers from sensitivity to noise and slow rate of convergence . Research is ongoing to ﬁnd faster and less sensitive versions of this algorithm . Another class of iterative algorithms was introduced into medical imag - ing by Gordon et al . in [ 121 ] . These include the algebraic reconstruction technique ( ART ) and its multiplicative version , MART . These methods were derived by viewing image reconstruction as solving systems of linear equations , possibly subject to constraints , such as positivity . The simulta - neous MART ( SMART ) [ 93 , 184 ] is a variant of MART that uses all the data at each step of the iteration . 21 . 5 The Kullback - Leibler Distance For a > 0 and b > 0 , let the cross - entropy or Kullback - Leibler distance from a to b be KL ( a , b ) = a log a b + b − a , ( 21 . 3 ) 21 . 6 . THE ALTERNATING MINIMIZATION PARADIGM 281 with KL ( a , 0 ) = + ∞ , and KL ( 0 , b ) = b . Extend to nonnegative vectors coordinate - wise , so that KL ( x , z ) = J (cid:88) j = 1 KL ( x j , z j ) . ( 21 . 4 ) Unlike the Euclidean distance , the KL distance is not symmetric ; KL ( Ax , b ) and KL ( b , Ax ) are distinct , and we can obtain diﬀerent approximate so - lutions of Ax = b by minimizing these two distances with respect to non - negative x . Clearly , the KL distance has the property KL ( cx , cz ) = cKL ( x , z ) for all positive scalars c . Ex . 21 . 1 Let z + = (cid:80) Jj = 1 z j > 0 . Prove that KL ( x , z ) = KL ( x + , z + ) + KL ( x , ( x + / z + ) z ) . ( 21 . 5 ) As we shall see , the KL distance mimics the ordinary Euclidean distance in several ways that make it particularly useful in designing optimization algorithms . The following exercise shows that the KL distance does exhibit some behavior not normally associated with a distance . Ex . 21 . 2 Let x be in the interval ( 0 , 1 ) . Show that KL ( x , 1 ) + KL ( 1 , x − 1 ) < KL ( x , x − 1 ) . 21 . 6 The Alternating Minimization Paradigm For each nonnegative vector x for which ( Px ) i = (cid:80) Jj = 1 P ij x j > 0 , let r ( x ) = { r ( x ) ij } and q ( x ) = { q ( x ) ij } be the I by J arrays with entries r ( x ) ij = x j P ij y i ( Px ) i and q ( x ) ij = x j P ij . The KL distances KL ( r ( x ) , q ( z ) ) = I (cid:88) i = 1 J (cid:88) j = 1 KL ( r ( x ) ij , q ( z ) ij ) and KL ( q ( x ) , r ( z ) ) = I (cid:88) i = 1 J (cid:88) j = 1 KL ( q ( x ) ij , r ( z ) ij ) will play important roles in the discussion that follows . Note that if there is nonnegative x with r ( x ) = q ( x ) then y = Px . 282 CHAPTER 21 . A TALE OF TWO ALGORITHMS 21 . 6 . 1 Some Pythagorean Identities Involving the KL Distance The iterative algorithms we discuss in this chapter are derived using the principle of alternating minimization , according to which the distances KL ( r ( x ) , q ( z ) ) and KL ( q ( x ) , r ( z ) ) are minimized , ﬁrst with respect to the variable x and then with respect to the variable z . Although the KL dis - tance is not Euclidean , and , in particular , not even symmetric , there are analogues of Pythagoras’ theorem that play important roles in the conver - gence proofs . Ex . 21 . 3 Establish the following Pythagorean identities : KL ( r ( x ) , q ( z ) ) = KL ( r ( z ) , q ( z ) ) + KL ( r ( x ) , r ( z ) ) ; ( 21 . 6 ) KL ( r ( x ) , q ( z ) ) = KL ( r ( x ) , q ( x (cid:48) ) ) + KL ( x (cid:48) , z ) , ( 21 . 7 ) for x (cid:48) j = x j I (cid:88) i = 1 P ij y i ( Px ) i ; ( 21 . 8 ) KL ( q ( x ) , r ( z ) ) = KL ( q ( x ) , r ( x ) ) + KL ( x , z ) − KL ( Px , Pz ) ; ( 21 . 9 ) KL ( q ( x ) , r ( z ) ) = KL ( q ( z (cid:48)(cid:48) ) , r ( z ) ) + KL ( x , z (cid:48)(cid:48) ) , ( 21 . 10 ) for z (cid:48)(cid:48) j = z j exp ( I (cid:88) i = 1 P ij log y i ( Pz ) i ) . ( 21 . 11 ) Note that it follows from Equation ( 22 . 5 ) that KL ( x , z ) − KL ( Px , Pz ) ≥ 0 . 21 . 6 . 2 Convergence of the SMART and EMML We shall prove convergence of the SMART and EMML algorithms through a series of exercises . Ex . 21 . 4 Show that , for { x k } given by Equation ( 21 . 1 ) , { KL ( y , Px k ) } is decreasing and { KL ( x k + 1 , x k ) } → 0 . Show that , for { x m } given by Equation ( 21 . 2 ) , { KL ( Px m , y ) } is decreasing and { KL ( x m , x m + 1 ) } → 0 . Hint : Use KL ( r ( x ) , q ( x ) ) = KL ( y , Px ) , KL ( q ( x ) , r ( x ) ) = KL ( Px , y ) , and the Pythagorean identities . 21 . 6 . THE ALTERNATING MINIMIZATION PARADIGM 283 Ex . 21 . 5 Show that the EMML sequence { x k } is bounded by showing J (cid:88) j = 1 x k + 1 j = I (cid:88) i = 1 y i . Show that the SMART sequence { x m } is bounded by showing that J (cid:88) j = 1 x m + 1 j ≤ I (cid:88) i = 1 y i . Ex . 21 . 6 Show that ( x ∗ ) (cid:48) = x ∗ for any cluster point x ∗ of the EMML sequence { x k } and that ( x ∗ ) (cid:48)(cid:48) = x ∗ for any cluster point x ∗ of the SMART sequence { x m } . Hint : Use { KL ( x k + 1 , x k ) } → 0 and { KL ( x m , x m + 1 ) } → 0 . Ex . 21 . 7 Let ˆ x and ˜ x minimize KL ( y , Px ) and KL ( Px , y ) , respectively , over all x ≥ 0 . Then , ( ˆ x ) (cid:48) = ˆ x and ( ˜ x ) (cid:48)(cid:48) = ˜ x . Hint : Apply Pythagorean identities to KL ( r ( ˆ x ) , q ( ˆ x ) ) and KL ( q ( ˜ x ) , r ( ˜ x ) ) . Note that , because of convexity properties of the KL distance , even if the minimizers ˆ x and ˜ x are not unique , the vectors P ˆ x and P ˜ x are unique . Ex . 21 . 8 For the EMML sequence { x k } with cluster point x ∗ and ˆ x as deﬁned previously , we have the double inequality KL ( ˆ x , x k ) ≥ KL ( r ( ˆ x ) , r ( x k ) ) ≥ KL ( ˆ x , x k + 1 ) , ( 21 . 12 ) from which we conclude that the sequence { KL ( ˆ x , x k ) } is decreasing and KL ( ˆ x , x ∗ ) < + ∞ . Hint : For the ﬁrst inequality calculate KL ( r ( ˆ x ) , q ( x k ) ) in two ways . For the second one , use ( x ) (cid:48) j = (cid:80) Ii = 1 r ( x ) ij and Exercise 21 . 1 . Ex . 21 . 9 Show that , for the SMART sequence { x m } with cluster point x ∗ and ˜ x as deﬁned previously , we have KL ( ˜ x , x m ) − KL ( ˜ x , x m + 1 ) = KL ( Px m + 1 , y ) − KL ( P ˜ x , y ) + KL ( P ˜ x , Px m ) + KL ( x m + 1 , x m ) − KL ( Px m + 1 , Px m ) , ( 21 . 13 ) and so KL ( P ˜ x , Px ∗ ) = 0 , the sequence { KL ( ˜ x , x m ) } is decreasing and KL ( ˜ x , x ∗ ) < + ∞ . Hint : Expand KL ( q ( ˜ x ) , r ( x m ) ) using the Pythagorean identities . 284 CHAPTER 21 . A TALE OF TWO ALGORITHMS Ex . 21 . 10 For x ∗ a cluster point of the EMML sequence { x k } we have KL ( y , Px ∗ ) = KL ( y , P ˆ x ) . Therefore , x ∗ is a nonnegative minimizer of KL ( y , Px ) . Consequently , the sequence { KL ( x ∗ , x k ) } converges to zero , and so { x k } → x ∗ . Hint : Use the double inequality of Equation ( 21 . 12 ) and KL ( r ( ˆ x ) , q ( x ∗ ) ) . Ex . 21 . 11 For x ∗ a cluster point of the SMART sequence { x m } we have KL ( Px ∗ , y ) = KL ( P ˜ x , y ) . Therefore , x ∗ is a nonnegative minimizer of KL ( Px , y ) . Consequently , the sequence { KL ( x ∗ , x m ) } converges to zero , and so { x m } → x ∗ . Moreover , KL ( ˜ x , x 0 ) ≥ KL ( x ∗ , x 0 ) for all ˜ x as before . Hints : Use Exercise 21 . 9 . For the ﬁnal assertion use the fact that the diﬀerence KL ( ˜ x , x m ) − KL ( ˜ x , x m + 1 ) is independent of the choice of ˜ x , since it depends only on Px ∗ = P ˜ x . Now sum over the index m . Both the EMML and the SMART algorithms are slow to converge . For that reason attention has shifted , in recent years , to block - iterative versions of these algorithms . Chapter 22 SMART and EMML as AF 22 . 1 Chapter Summary In this chapter we discuss the SMART and EMML algorithms in the con - text of AF methods and consider several extensions of these algorithms . 22 . 2 The SMART and the EMML 22 . 2 . 1 The SMART Iteration The SMART minimizes the function f ( x ) = KL ( Px , y ) , over nonnegative vectors x . Here y is a vector with positive entries , and P is a matrix with nonnegative entries , such that s j = (cid:80) Ii = 1 P ij > 0 . Denote by X the set of all nonnegative x for which the vector Px has only positive entries . Having found the vector x k − 1 , the next vector in the SMART sequence is x k , with entries given by x kj = x k − 1 j exp s − 1 j (cid:16) I (cid:88) i = 1 P ij log ( y i / ( Px k − 1 ) i ) (cid:17) . ( 22 . 1 ) 22 . 2 . 2 The EMML Iteration The EMML algorithm minimizes the function f ( x ) = KL ( y , Px ) , over nonnegative vectors x . Having found the vector x k − 1 , the next vector in 285 286 CHAPTER 22 . SMART AND EMML AS AF the EMML sequence is x k , with entries given by x kj = x k − 1 j s − 1 j (cid:16) I (cid:88) i = 1 P ij ( y i / ( Px k − 1 ) i ) (cid:17) . ( 22 . 2 ) 22 . 2 . 3 The EMML and the SMART as Alternating Minimization In [ 39 ] the SMART was derived using the following alternating minimiza - tion approach . For each x ∈ X , let r ( x ) and q ( x ) be the I by J arrays with entries r ( x ) ij = x j P ij y i / ( Px ) i , ( 22 . 3 ) and q ( x ) ij = x j P ij . ( 22 . 4 ) In the iterative step of the SMART we get x k by minimizing the function KL ( q ( x ) , r ( x k − 1 ) ) = I (cid:88) i = 1 J (cid:88) j = 1 KL ( q ( x ) ij , r ( x k − 1 ) ij ) over x ≥ 0 . Note that KL ( Px , y ) = KL ( q ( x ) , r ( x ) ) . Similarly , the iterative step of the EMML is to minimize the function KL ( r ( x k − 1 ) , q ( x ) ) to get x = x k . Note that KL ( y , Px ) = KL ( r ( x ) , q ( x ) ) . It follows from the identities established in [ 39 ] that the SMART can also be formulated as a particular case of the SUMMA . 22 . 3 The SMART as a Case of SUMMA We show now that the SMART is a particular case of the SUMMA . The following lemma is helpful in that regard . Lemma 22 . 1 For any non - negative vectors x and z , with z + = (cid:80) Jj = 1 z j > 0 , we have KL ( x , z ) = KL ( x + , z + ) + KL ( x , x + z + z ) . ( 22 . 5 ) For notational convenience , we assume , for the remainder of this section , that s j = 1 for all j . From the identities established for the SMART in [ 39 ] , we know that the iterative step of SMART can be expressed as follows : minimize the function G k ( x ) = KL ( Px , y ) + KL ( x , x k − 1 ) − KL ( Px , Px k − 1 ) ( 22 . 6 ) 22 . 4 . THE SMART AS A CASE OF THE PMA 287 to get x k . According to Lemma 22 . 1 , the quantity g k ( x ) = KL ( x , x k − 1 ) − KL ( Px , Px k − 1 ) is nonnegative , since s j = 1 . The g k ( x ) are deﬁned for all nonnegative x ; that is , the set D is the closed nonnegative orthant in R J . Each x k is a positive vector . It was shown in [ 39 ] that G k ( x ) = G k ( x k ) + KL ( x , x k ) , ( 22 . 7 ) from which it follows immediately that Assumption 2 holds for the SMART , so that the SMART is in the SUMMA class . Because the SMART is a particular case of the SUMMA , we know that the sequence { f ( x k ) } is monotonically decreasing to f ( ˆ x ) . It was shown in [ 39 ] that if y = Px has no nonnegative solution and the matrix P and every submatrix obtained from P by removing columns has full rank , then ˆ x is unique ; in that case , the sequence { x k } converges to ˆ x . As we shall see , the SMART sequence always converges to a nonnegative minimizer of f ( x ) . To establish this , we reformulate the SMART as a particular case of the PMA . 22 . 4 The SMART as a Case of the PMA We take F ( x ) to be the function F ( x ) = J (cid:88) j = 1 x j log x j . ( 22 . 8 ) Then D F ( x , z ) = KL ( x , z ) . ( 22 . 9 ) For nonnegative x and z in X , we have D f ( x , z ) = KL ( Px , Pz ) . ( 22 . 10 ) Lemma 22 . 2 D F ( x , z ) ≥ D f ( x , z ) . Proof : We have D F ( x , z ) ≥ J (cid:88) j = 1 KL ( x j , z j ) ≥ J (cid:88) j = 1 I (cid:88) i = 1 KL ( P ij x j , P ij z j ) ≥ I (cid:88) i = 1 KL ( ( Px ) i , ( Pz ) i ) = KL ( Px , Pz ) . ( 22 . 11 ) 288 CHAPTER 22 . SMART AND EMML AS AF We let h ( x ) = F ( x ) − f ( x ) ; then D h ( x , z ) ≥ 0 for nonnegative x and z in X . The iterative step of the SMART is to minimize the function f ( x ) + D h ( x , x k − 1 ) . ( 22 . 12 ) So the SMART is a particular case of the PMA . The function h ( x ) = F ( x ) − f ( x ) is ﬁnite on D the nonnegative orthant of R J , and diﬀerentiable on the interior , so C = D is closed in this example . Consequently , ˆ x is necessarily in D . From our earlier discussion of the PMA , we can conclude that the sequence { D h ( ˆ x , x k ) } is decreasing and the sequence { D f ( ˆ x , x k ) } → 0 . Since the function KL ( ˆ x , · ) has bounded level sets , the sequence { x k } is bounded , and f ( x ∗ ) = f ( ˆ x ) , for every cluster point . Therefore , the sequence { D h ( x ∗ , x k ) } is decreasing . Since a subsequence converges to zero , the entire sequence converges to zero . The convergence of { x k } to x ∗ follows from basic properties of the KL distance . From the fact that { D f ( ˆ x , x k ) } → 0 , we conclude that P ˆ x = Px ∗ . Equation ( 18 . 12 ) now tells us that the diﬀerence D h ( ˆ x , x k − 1 ) − D h ( ˆ x , x k ) depends on only on P ˆ x , and not directly on ˆ x . Therefore , the diﬀerence D h ( ˆ x , x 0 ) − D h ( ˆ x , x ∗ ) also depends only on P ˆ x and not directly on ˆ x . Minimizing D h ( ˆ x , x 0 ) over nonnegative minimizers ˆ x of f ( x ) is therefore equivalent to minimizing D h ( ˆ x , x ∗ ) over the same vectors . But the solution to the latter problem is obviously ˆ x = x ∗ . Thus we have shown that the limit of the SMART is the nonnegative minimizer of KL ( Px , y ) for which the distance KL ( x , x 0 ) is minimized . The following theorem summarizes the situation with regard to the SMART . Theorem 22 . 1 In the consistent case the SMART converges to the unique nonnegative solution of y = Px for which the distance (cid:80) Jj = 1 s j KL ( x j , x 0 j ) is minimized . In the inconsistent case it converges to the unique nonnega - tive minimizer of the distance KL ( Px , y ) for which (cid:80) Jj = 1 s j KL ( x j , x 0 j ) is minimized ; if P and every matrix derived from P by deleting columns has full rank then there is a unique nonnegative minimizer of KL ( Px , y ) and at most I − 1 of its entries are nonzero . 22 . 5 SMART and EMML as Projection Meth - ods For each i = 1 , 2 , . . . , I , let H i be the hyperplane H i = { z | ( Pz ) i = y i } . ( 22 . 13 ) The KL projection of a given positive x onto H i is the z in H i that min - imizes the KL distance KL ( z , x ) . Generally , the KL projection onto H i 22 . 6 . THE MART AND EMART ALGORITHMS 289 cannot be expressed in closed form . However , the z in H i that minimizes the weighted KL distance J (cid:88) j = 1 P ij KL ( z j , x j ) ( 22 . 14 ) is T i ( x ) given by T i ( x ) j = x j y i / ( Px ) i . ( 22 . 15 ) Both the SMART and the EMML can be described in terms of the T i . The iterative step of the SMART algorithm can be expressed as x k + 1 j = I (cid:89) i = 1 ( T i ( x k ) j ) P ij . ( 22 . 16 ) We see that x k + 1 j is a weighted geometric mean of the terms T i ( x k ) j . The iterative step of the EMML algorithm can be expressed as x k + 1 j = I (cid:88) i = 1 P ij T i ( x k ) j . ( 22 . 17 ) We see that x k + 1 j is a weighted arithmetic mean of the terms T i ( x k ) j , using the same weights as in the case of SMART . 22 . 6 The MART and EMART Algorithms The MART algorithm has the iterative step x k + 1 j = x kj ( y i / ( Px k ) i ) P ij m − 1 i , ( 22 . 18 ) where i = k ( mod I ) + 1 and m i = max { P ij | j = 1 , 2 , . . . , J } . ( 22 . 19 ) When there are non - negative solutions of the system y = Px , the sequence { x k } converges to the solution x that minimizes KL ( x , x 0 ) [ 42 , 43 , 44 ] . We can express the MART in terms of the weighted KL projections T i ( x k ) ; x k + 1 j = ( x kj ) 1 − P ij m − 1 i ( T i ( x k ) j ) P ij m − 1 i . ( 22 . 20 ) We see then that the iterative step of the MART is a relaxed weighted KL projection onto H i , and a weighted geometric mean of the current x kj and T i ( x k ) j . The expression for the MART in Equation ( 22 . 20 ) suggests a 290 CHAPTER 22 . SMART AND EMML AS AF somewhat simpler iterative algorithm involving a weighted arithmetic mean of the current x kj and T i ( x k ) j ; this is the EMART algorithm . The iterative step of the EMART algorithm is x k + 1 j = ( 1 − P ij m − 1 i ) x kj + P ij m − 1 i T i ( x k ) j . ( 22 . 21 ) Whenever the system y = Px has non - negative solutions , the EMART sequence { x k } converges to a non - negative solution , but nothing further is known about this solution . One advantage that the EMART has over the MART is the substitution of multiplication for exponentiation . Block - iterative versions of SMART and EMML have also been investi - gated ; see [ 42 , 43 , 44 ] and the references therein . 22 . 7 Possible Extensions of MART and EMART As we have seen , the iterative steps of the MART and the EMART are re - laxed weighted KL projections onto the hyperplane H i , resulting in vectors that are not within H i . This suggests variants of MART and EMART in which , at the end of each iterative step , a further weighted KL projection onto H i is performed . In other words , for MART and EMART the new vec - tor would be T i ( x k + 1 ) , instead of x k + 1 as given by Equations ( 22 . 18 ) and ( 22 . 21 ) , respectively . Research into the properties of these new algorithms is ongoing . Chapter 23 Fermi - Dirac Entropy 23 . 1 Chapter Summary The ART and its simultaneous and block - iterative versions are designed to solve general systems of linear equations Ax = b . The SMART , EMML , MART , EM - MART and related methods deal with y = Px , where we require that the entries of P be nonnegative , those of y positive and we want a nonnegative x . In this chapter we present variations of the SMART and EMML that impose the constraints u j ≤ x j ≤ v j , where the u j and v j are selected lower and upper bounds on the individual entries x j . These algorithms were used in [ 161 ] as a method for including in transmission tomographic reconstruction spatially varying upper and lower bounds on the x - ray attenuation . 23 . 2 Modifying the KL distance Simultaneous iterative algorithms employ all of the equations at each step of the iteration ; block - iterative methods do not . For the latter methods we assume that the index set { i = 1 , . . . , I } is the ( not necessarily disjoint ) union of the N sets or blocks B n , n = 1 , . . . , N . We shall require that s nj = (cid:80) i ∈ B n P ij > 0 for each n and each j . Block - iterative methods like ART and MART for which each block consists of precisely one element are called row - action or sequential methods . The SMART , EMML , MART and EM - MART methods are based on the Kullback - Leibler distance between nonnegative vectors . To impose more general constraints on the entries of x we derive algorithms based on shifted KL distances , also called Fermi - Dirac generalized entropies . For a ﬁxed real vector u , the shifted KL distance KL ( x − u , z − u ) is deﬁned for vectors x and z having x j ≥ u j and z j ≥ u j . Similarly , the 291 292 CHAPTER 23 . FERMI - DIRAC ENTROPY shifted distance KL ( v − x , v − z ) applies only to those vectors x and z for which x j ≤ v j and z j ≤ v j . For u j ≤ v j , the combined distance KL ( x − u , z − u ) + KL ( v − x , v − z ) is restricted to those x and z whose entries x j and z j lie in the inter - val [ u j , v j ] . Our objective is to mimic the derivation of the SMART and EMML methods , replacing KL distances with shifted KL distances , to ob - tain algorithms that enforce the constraints u j ≤ x j ≤ v j , for each j . The algorithms that result are the ABMART and ABEMML block - iterative methods . These algorithms were originally presented in [ 45 ] , in which the vectors u and v were called a and b , hence the names of the algorithms . Throughout this chapter we shall assume that the entries of the matrix P are nonnegative . We shall denote by B n , n = 1 , . . . , N a partition of the index set { i = 1 , . . . , I } into blocks . For k = 0 , 1 , . . . let n ( k ) = k ( mod N ) + 1 . The projected Landweber algorithm can also be used to impose the restrictions u j ≤ x j ≤ v j ; however , the projection step in that algorithm is implemented by clipping , or setting equal to u j or v j values of x j that would otherwise fall outside the desired range . The result is that the values u j and v j can occur more frequently than may be desired . One advantage of the AB methods is that the values u j and v j represent barriers that can only be reached in the limit and are never taken on at any step of the iteration . 23 . 3 The ABMART Algorithm We assume that ( Pu ) i ≤ y i ≤ ( Pv ) i and seek a solution of Px = y with u j ≤ x j ≤ v j , for each j . The algorithm begins with an initial vector x 0 satisfying u j ≤ x 0 j ≤ v j , for each j . Having calculated x k , we take x k + 1 j = α kj v j + ( 1 − α kj ) u j , ( 23 . 1 ) with n = n ( k ) , α kj = c kj (cid:81) n ( d ki ) P ij 1 + c kj (cid:81) n ( d ki ) P ij , ( 23 . 2 ) c kj = ( x kj − u j ) ( v j − x kj ) , ( 23 . 3 ) and d kj = ( y i − ( Pu ) i ) ( ( Pv ) i − ( Px k ) i ) ( ( Pv ) i − y i ) ( ( Px k ) i − ( Pu ) i ) , ( 23 . 4 ) 23 . 4 . THE ABEMML ALGORITHM 293 where (cid:81) n denotes the product over those indices i in B n ( k ) . Notice that , at each step of the iteration , x kj is a convex combination of the endpoints u j and v j , so that x kj lies in the interval [ u j , v j ] . We have the following theorem concerning the convergence of the AB - MART algorithm : Theorem 23 . 1 If there is a solution of the system Px = y that satisﬁes the constraints u j ≤ x j ≤ v j for each j , then , for any N and any choice of the blocks B n , the ABMART sequence converges to that constrained solution of Px = y for which the Fermi - Dirac generalized entropic distance from x to x 0 , KL ( x − u , x 0 − u ) + KL ( v − x , v − x 0 ) , is minimized . If there is no constrained solution of Px = y , then , for N = 1 , the ABMART sequence converges to the minimizer of KL ( Px − Pu , y − Pu ) + KL ( Pv − Px , Pv − y ) for which KL ( x − u , x 0 − u ) + KL ( v − x , v − x 0 ) is minimized . The proof is in [ 45 ] . 23 . 4 The ABEMML Algorithm We make the same assumptions as in the previous section . The iterative step of the ABEMML algorithm is x k + 1 j = α kj v j + ( 1 − α kj ) u j , ( 23 . 5 ) where α kj = γ kj / d kj , ( 23 . 6 ) γ kj = ( x kj − u j ) e kj , ( 23 . 7 ) β kj = ( v j − x kj ) f kj , ( 23 . 8 ) d kj = γ kj + β kj , ( 23 . 9 ) e kj = (cid:32) 1 − (cid:88) i ∈ B n P ij (cid:33) + (cid:88) i ∈ B n P ij (cid:32) y i − ( Pu ) i ( Px k ) i − ( Pu ) i (cid:33) , ( 23 . 10 ) 294 CHAPTER 23 . FERMI - DIRAC ENTROPY and f kj = (cid:32) 1 − (cid:88) i ∈ B n A ij (cid:33) + (cid:88) i ∈ B n A ij (cid:32) ( Pv ) i − y i ( Pv ) i − ( Px k ) i (cid:33) . ( 23 . 11 ) We have the following theorem concerning the convergence of the ABE - MML algorithm : Theorem 23 . 2 If there is a solution of the system Px = y that satisﬁes the constraints u j ≤ x j ≤ v j for each j , then , for any N and any choice of the blocks B n , the ABEMML sequence converges to such a constrained solution of Px = y . If there is no constrained solution of Px = y , then , for N = 1 , the ABEMML sequence converges to a constrained minimizer of KL ( y − Pu , Px − Pu ) + KL ( Pv − y , Pv − Px ) . The proof is found in [ 45 ] . In contrast to the ABMART theorem , this is all we can say about the limits of the ABEMML sequences . Open Question : How does the limit of the ABEMML iterative sequence depend , in the consistent case , on the choice of blocks , and , in general , on the choice of x 0 ? Chapter 24 Calculus of Variations 24 . 1 Introduction In optimization , we are usually concerned with maximizing or minimizing real - valued functions of one or several variables , possibly subject to con - straints . In this chapter , we consider another type of optimization problem , maximizing or minimizing a function of functions . The functions them - selves we shall denote by simply y = y ( x ) , instead of the more common notation y = f ( x ) , and the function of functions will be denoted J ( y ) ; in the calculus of variations , such functions of functions are called functionals . We then want to optimize J ( y ) over a class of admissible functions y ( x ) . We shall focus on the case in which x is a single real variable , although there are situations in which the functions y are functions of several variables . When we attempt to minimize a function g ( x 1 , . . . , x N ) , we consider what happens to g when we perturb the values x n to x n + ∆ x n . In order for x = ( x 1 , . . . , x N ) to minimize g , it is necessary that g ( x 1 + ∆ x 1 , . . . , x N + ∆ x N ) ≥ g ( x 1 , . . . , x N ) , for all perturbations ∆ x 1 , . . . , ∆ x N . For diﬀerentiable g , this means that the gradient of g at x must be zero . In the calculus of variations , when we attempt to minimize J ( y ) , we need to consider what happens when we perturb the function y to a nearby admissible function , denoted y + ∆ y . In order for y to minimize J ( y ) , we need J ( y + ∆ y ) ≥ J ( y ) , for all ∆ y that make y + ∆ y admissible . We end up with something anal - ogous to a ﬁrst derivative of J , which is then set to zero . The result is a diﬀerential equation , called the Euler - Lagrange Equation , which must be satisﬁed by the minimizing y . 295 296 CHAPTER 24 . CALCULUS OF VARIATIONS 24 . 2 Some Examples In this section we present some of the more famous examples of problems from the calculus of variations . 24 . 2 . 1 The Shortest Distance Among all the functions y = y ( x ) , deﬁned for x in the interval [ 0 , 1 ] , with y ( 0 ) = 0 and y ( 1 ) = 1 , the straight - line function y ( x ) = x has the shortest length . Assuming the functions are diﬀerentiable , the formula for the length of such curves is J ( y ) = (cid:90) 1 0 (cid:114) 1 + (cid:16) dy dx (cid:17) 2 dx . ( 24 . 1 ) Therefore , we can say that the function y ( x ) = x minimizes J ( y ) , over all such functions . In this example , the functional J ( y ) involves only the ﬁrst derivative of y = y ( x ) and has the form J ( y ) = (cid:90) f ( x , y ( x ) , y (cid:48) ( x ) ) dx , ( 24 . 2 ) where f = f ( u , v , w ) is the function of three variables f ( u , v , w ) = (cid:112) 1 + w 2 . ( 24 . 3 ) In general , the functional J ( y ) can come from almost any function f ( u , v , w ) . In fact , if higher derivatives of y ( x ) are involved , the function f can be a function of more than three variables . In this chapter we shall conﬁne our discussion to problems involving only the ﬁrst derivative of y ( x ) . 24 . 2 . 2 The Brachistochrone Problem Consider a frictionless wire connecting the two points A = ( 0 , 0 ) and B = ( 1 , 1 ) ; for convenience , the positive y - axis is downward . A metal ball rolls from point A to point B under the inﬂuence of gravity . What shape should the wire take in order to make the travel time of the ball the smallest ? This famous problem , known as the Brachistochrone Problem , was posed in 1696 by Johann Bernoulli . This event is viewed as marking the beginning of the calculus of variations . The velocity of the ball along the curve is v = dsdt , where s denotes the arc - length . Therefore , dt = ds v = 1 v (cid:114) 1 + (cid:16) dy dx (cid:17) 2 dx . 24 . 2 . SOME EXAMPLES 297 Because the ball is falling under the inﬂuence of gravity only , the velocity it attains after falling from ( 0 , 0 ) to ( x , y ) is the same as it would have attained had it fallen y units vertically ; only the travel times are diﬀerent . This is because the loss of potential energy is the same either way . The velocity attained after a vertical free fall of y units is √ 2 gy . Therefore , we have dt = (cid:114) 1 + (cid:16) dydx (cid:17) 2 dx √ 2 gy . The travel time from A to B is therefore J ( y ) = 1 √ 2 g (cid:90) 1 0 (cid:114) 1 + (cid:16) dy dx (cid:17) 2 1 √ y dx . ( 24 . 4 ) For this example , the function f ( u , v , w ) is f ( u , v , w ) = √ 1 + w 2 √ v . ( 24 . 5 ) 24 . 2 . 3 Minimal Surface Area Given a function y = y ( x ) with y ( 0 ) = 1 and y ( 1 ) = 0 , we imagine revolving this curve around the x - axis , to generate a surface of revolution . The functional J ( y ) that we wish to minimize now is the surface area . Therefore , we have J ( y ) = (cid:90) 1 0 y (cid:112) 1 + y (cid:48) ( x ) 2 dx . ( 24 . 6 ) Now the function f ( u , v , w ) is f ( u , v , w ) = v (cid:112) 1 + w 2 . ( 24 . 7 ) 24 . 2 . 4 The Maximum Area Among all curves of length L connecting the points ( 0 , 0 ) and ( 1 , 0 ) , ﬁnd the one for which the area A of the region bounded by the curve and the x - axis is maximized . The length of the curve is given by L = (cid:90) 1 0 (cid:112) 1 + y (cid:48) ( x ) 2 dx , ( 24 . 8 ) and the area , assuming that y ( x ) ≥ 0 for all x , is A = (cid:90) 1 0 y ( x ) dx . ( 24 . 9 ) This problem is diﬀerent from the previous ones , in that we seek to optimize a functional , subject to a second functional being held ﬁxed . Such problems are called problems with constraints . 298 CHAPTER 24 . CALCULUS OF VARIATIONS 24 . 2 . 5 Maximizing Burg Entropy The Burg entropy of a positive - valued function y ( x ) on [ − π , π ] is BE ( y ) = (cid:90) π − π log (cid:16) y ( x ) (cid:17) dx . ( 24 . 10 ) An important problem in signal processing is to maximize BE ( y ) , subject to r n = (cid:90) π − π y ( x ) e − inx dx , ( 24 . 11 ) for | n | ≤ N . The r n are values of the Fourier transform of the function y ( x ) . 24 . 3 Comments on Notation The functionals J ( y ) that we shall consider in this chapter have the form J ( y ) = (cid:90) f ( x , y ( x ) , y (cid:48) ( x ) ) dx , ( 24 . 12 ) where f = f ( u , v , w ) is some function of three real variables . It is common practice , in the calculus of variations literature , to speak of f = f ( x , y , y (cid:48) ) , rather than f ( u , v , w ) . Unfortunately , this leads to potentially confusing notation , such as when ∂f∂u is written as ∂f∂x , which is not the same thing as the total derivative of f ( x , y ( x ) , y (cid:48) ( x ) ) , d dxf ( x , y ( x ) , y (cid:48) ( x ) ) = ∂f ∂x + ∂f ∂y y (cid:48) ( x ) + ∂f ∂y (cid:48) y (cid:48)(cid:48) ( x ) . ( 24 . 13 ) Using the notation of this chapter , Equation ( 24 . 13 ) becomes d dxf ( x , y ( x ) , y (cid:48) ( x ) ) = ∂f ∂u ( x , y ( x ) , y (cid:48) ( x ) ) + ∂f ∂v ( x , y ( x ) , y (cid:48) ( x ) ) y (cid:48) ( x ) + ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) y (cid:48)(cid:48) ( x ) . ( 24 . 14 ) The common notation forces us to view f ( x , y , y (cid:48) ) both as a function of three unrelated variables , x , y , and y (cid:48) , and as f ( x , y ( x ) , y (cid:48) ( x ) ) , a function of the single variable x . For example , suppose that f ( u , v , w ) = u 2 + v 3 + sin w , 24 . 4 . THE EULER - LAGRANGE EQUATION 299 and y ( x ) = 7 x 2 . Then f ( x , y ( x ) , y (cid:48) ( x ) ) = x 2 + ( 7 x 2 ) 3 + sin ( 14 x ) , ( 24 . 15 ) ∂f ∂x ( x , y ( x ) , y (cid:48) ( x ) ) = 2 x , ( 24 . 16 ) and d dxf ( x , y ( x ) , y (cid:48) ( x ) ) = d dx (cid:16) x 2 + ( 7 x 2 ) 3 + sin ( 14 x ) (cid:17) = 2 x + 3 ( 7 x 2 ) 2 ( 14 x ) + 14 cos ( 14 x ) . ( 24 . 17 ) 24 . 4 The Euler - Lagrange Equation In the problems we shall consider in this chapter , admissible functions are diﬀerentiable , with y ( x 1 ) = y 1 and y ( x 2 ) = y 2 ; that is , the graphs of the admissible functions pass through the end points ( x 1 , y 1 ) and ( x 2 , y 2 ) . If y = y ( x ) is one such function and η ( x ) is a diﬀerentiable function with η ( x 1 ) = 0 and η ( x 2 ) = 0 , then y ( x ) + (cid:15)η ( x ) is admissible , for all values of (cid:15) . For ﬁxed admissible function y = y ( x ) , we deﬁne J ( (cid:15) ) = J ( y ( x ) + (cid:15)η ( x ) ) , ( 24 . 18 ) and force J (cid:48) ( (cid:15) ) = 0 at (cid:15) = 0 . The tricky part is calculating J (cid:48) ( (cid:15) ) . Since J ( y ( x ) + (cid:15)η ( x ) ) has the form J ( y ( x ) + (cid:15)η ( x ) ) = (cid:90) x 2 x 1 f ( x , y ( x ) + (cid:15)η ( x ) , y (cid:48) ( x ) + (cid:15)η (cid:48) ( x ) ) dx , ( 24 . 19 ) we obtain J (cid:48) ( (cid:15) ) by diﬀerentiating under the integral sign . Omitting the arguments , we have J (cid:48) ( (cid:15) ) = (cid:90) x 2 x 1 ∂f ∂v η + ∂f ∂wη (cid:48) dx . ( 24 . 20 ) Using integration by parts and η ( x 1 ) = η ( x 2 ) = 0 , we have (cid:90) x 2 x 1 ∂f ∂wη (cid:48) dx = − (cid:90) x 2 x 1 d dx ( ∂f ∂w ) ηdx . ( 24 . 21 ) Therefore , we have J (cid:48) ( (cid:15) ) = (cid:90) x 2 x 1 (cid:16) ∂f ∂v − d dx ( ∂f ∂w ) (cid:17) ηdx . ( 24 . 22 ) 300 CHAPTER 24 . CALCULUS OF VARIATIONS In order for y = y ( x ) to be the optimal function , this integral must be zero for every appropriate choice of η ( x ) , when (cid:15) = 0 . It can be shown without too much trouble that this forces ∂f ∂v − d dx ( ∂f ∂w ) = 0 . ( 24 . 23 ) Equation ( 24 . 23 ) is the Euler - Lagrange Equation . For clarity , let us rewrite that Euler - Lagrange Equation using the ar - guments of the functions involved . Equation ( 24 . 23 ) is then ∂f ∂v ( x , y ( x ) , y (cid:48) ( x ) ) − d dx (cid:16) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) (cid:17) = 0 . ( 24 . 24 ) 24 . 5 Special Cases of the Euler - Lagrange Equa - tion The Euler - Lagrange Equation simpliﬁes in certain special cases . 24 . 5 . 1 If f is independent of v If the function f ( u , v , w ) is independent of the variable v then the Euler - Lagrange Equation ( 24 . 24 ) becomes ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) = c , ( 24 . 25 ) for some constant c . If , in addition , the function f ( u , v , w ) is a function of w alone , then so is ∂f∂w , from which we conclude from the Euler - Lagrange Equation that y (cid:48) ( x ) is constant . 24 . 5 . 2 If f is independent of u Note that we can write d dxf ( x , y ( x ) , y (cid:48) ( x ) ) = ∂f ∂u ( x , y ( x ) , y (cid:48) ( x ) ) + ∂f ∂v ( x , y ( x ) , y (cid:48) ( x ) ) y (cid:48) ( x ) + ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) y (cid:48)(cid:48) ( x ) . ( 24 . 26 ) We also have d dx (cid:16) y (cid:48) ( x ) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) (cid:17) = y (cid:48) ( x ) d dx (cid:16) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) (cid:17) + y (cid:48)(cid:48) ( x ) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) . 24 . 6 . USING THE EULER - LAGRANGE EQUATION 301 ( 24 . 27 ) Subtracting Equation ( 24 . 27 ) from Equation ( 24 . 26 ) , we get d dx (cid:16) f ( x , y ( x ) , y (cid:48) ( x ) ) − y (cid:48) ( x ) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) (cid:17) = ∂f ∂u ( x , y ( x ) , y (cid:48) ( x ) ) + y (cid:48) ( x ) (cid:16) ∂f ∂v − d dx ∂f ∂w (cid:17) ( x , y ( x ) , y (cid:48) ( x ) ) . ( 24 . 28 ) Now , using the Euler - Lagrange Equation , we see that Equation ( 24 . 28 ) reduces to d dx (cid:16) f ( x , y ( x ) , y (cid:48) ( x ) ) − y (cid:48) ( x ) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) (cid:17) = ∂f ∂u ( x , y ( x ) , y (cid:48) ( x ) ) . ( 24 . 29 ) If it is the case that ∂f∂u = 0 , then equation ( 24 . 29 ) leads to f ( x , y ( x ) , y (cid:48) ( x ) ) − y (cid:48) ( x ) ∂f ∂w ( x , y ( x ) , y (cid:48) ( x ) ) = c , ( 24 . 30 ) for some constant c . 24 . 6 Using the Euler - Lagrange Equation We derive and solve the Euler - Lagrange Equation for each of the examples presented previously . 24 . 6 . 1 The Shortest Distance In this case , we have f ( u , v , w ) = (cid:112) 1 + w 2 , ( 24 . 31 ) so that ∂f ∂v = 0 , and ∂f ∂u = 0 . We conclude that y (cid:48) ( x ) is constant , so y ( x ) is a straight line . 302 CHAPTER 24 . CALCULUS OF VARIATIONS 24 . 6 . 2 The Brachistochrone Problem Equation ( 24 . 5 ) tells us that f ( u , v , w ) = √ 1 + w 2 √ v . ( 24 . 32 ) Then , since ∂f ∂u = 0 , and ∂f ∂w = w √ 1 + w 2 √ v , Equation ( 24 . 30 ) tells us that (cid:112) 1 + y (cid:48) ( x ) 2 (cid:112) y ( x ) − y (cid:48) ( x ) y (cid:48) ( x ) (cid:112) 1 + y (cid:48) ( x ) 2 (cid:112) y ( x ) = c . ( 24 . 33 ) Equivalently , we have (cid:112) y ( x ) (cid:112) 1 + y (cid:48) ( x ) 2 = √ a . ( 24 . 34 ) Solving for y (cid:48) ( x ) , we get y (cid:48) ( x ) = (cid:115) a − y ( x ) y ( x ) . ( 24 . 35 ) Separating variables and integrating , using the substitution y = a sin 2 θ = a 2 ( 1 − cos 2 θ ) , we obtain x = 2 a (cid:90) sin 2 θdθ = a 2 ( 2 θ − sin 2 θ ) + k . ( 24 . 36 ) From this , we learn that the minimizing curve is a cycloid , that is , the path a point on a circle traces as the circle rolls . There is an interesting connection , discussed by Simmons in [ 191 ] , be - tween the brachistochrone problem and the refraction of light rays . Imagine a ray of light passing from the point A = ( 0 , a ) , with a > 0 , to the point B = ( c , b ) , with c > 0 and b < 0 . Suppose that the speed of light is v 1 above the x - axis , and v 2 < v 1 below the x - axis . The path consists of two straight lines , meeting at the point ( 0 , x ) . The total time for the journey is then T ( x ) = √ a 2 + x 2 v 1 + (cid:112) b 2 + ( c − x ) 2 v 2 . 24 . 6 . USING THE EULER - LAGRANGE EQUATION 303 Fermat’s Principle of Least Time says that the ( apparent ) path taken by the light ray will be the one for which x minimizes T ( x ) . From calculus , it follows that x v 1 √ a 2 + x 2 = c − x v 2 (cid:112) b 2 + ( c − x ) 2 , and from geometry , we get Snell’s Law : sin α 1 v 1 = sin α 2 v 2 , where α 1 and α 2 denote the angles between the upper and lower parts of the path and the vertical , respectively . Imagine now a stratiﬁed medium consisting of many horizontal layers , each with its own speed of light . The path taken by the light would be such that sin αv remains constant as the ray passes from one layer to the next . In the limit of inﬁnitely many inﬁnitely thin layers , the path taken by the light would satisfy the equation sin αv = constant , with sin α = 1 (cid:112) 1 + y (cid:48) ( x ) 2 . As we have already seen , the velocity attained by the rolling ball is v = √ 2 gy , so the equation to be satisﬁed by the path y ( x ) is (cid:112) 2 gy ( x ) (cid:112) 1 + y (cid:48) ( x ) 2 = constant , which is what we obtained from the Euler - Lagrange Equation . 24 . 6 . 3 Minimizing the Surface Area For the problem of minimizing the surface area of a surface of revolution , the function f ( u , v , w ) is f ( u , v , w ) = v (cid:112) 1 + w 2 . ( 24 . 37 ) Once again , ∂f∂u = 0 , so we have y ( x ) y (cid:48) ( x ) 2 (cid:112) 1 + y (cid:48) ( x ) 2 − y ( x ) (cid:112) 1 + y (cid:48) ( x ) 2 = c . ( 24 . 38 ) It follows that y ( x ) = b cosh x − a b , ( 24 . 39 ) for appropriate a and b . 304 CHAPTER 24 . CALCULUS OF VARIATIONS It is important to note that being a solution of the Euler - Lagrange Equa - tion is a necessary condition for a diﬀerentiable function to be a solution to the original optimization problem , but it is not a suﬃcient condition . The optimal solution may not be a diﬀerentiable one , or there may be no optimal solution . In the case of minimum surface area , there may not be any function of the form in Equation ( 24 . 39 ) passing through the two given end points ; see Chapter IV of Bliss [ 22 ] for details . 24 . 7 Problems with Constraints We turn now to the problem of optimizing one functional , subject to a second functional being held constant . The basic technique is similar to ordinary optimization subject to constraints : we use Lagrange multipliers . We begin with a classic example . 24 . 7 . 1 The Isoperimetric Problem A classic problem in the calculus of variations is the Isoperimetric Prob - lem : ﬁnd the curve of a ﬁxed length that encloses the largest area . For concreteness , suppose the curve connects the two points ( 0 , 0 ) and ( 1 , 0 ) and is the graph of a function y ( x ) . The problem then is to maximize the area integral (cid:90) 1 0 y ( x ) dx , ( 24 . 40 ) subject to the perimeter being held ﬁxed , that is , (cid:90) 1 0 (cid:112) 1 + y (cid:48) ( x ) 2 dx = P . ( 24 . 41 ) With f ( x , y ( x ) , y (cid:48) ( x ) ) = y ( x ) + λ (cid:112) 1 + y (cid:48) ( x ) 2 , the Euler - Lagrange Equation becomes d dx (cid:16) λy (cid:48) ( x ) (cid:112) 1 + y (cid:48) ( x ) 2 (cid:17) − 1 = 0 , ( 24 . 42 ) or y (cid:48) ( x ) (cid:112) 1 + y (cid:48) ( x ) 2 = x − a λ . ( 24 . 43 ) Using the substitution t = x − aλ and integrating , we ﬁnd that ( x − a ) 2 + ( y − b ) 2 = λ 2 , ( 24 . 44 ) 24 . 8 . THE MULTIVARIATE CASE 305 which is the equation of a circle . So the optimal function y ( x ) is a portion of a circle . What happens if the assigned perimeter P is greater than π 2 , the length of the semicircle connecting ( 0 , 0 ) and ( 1 , 0 ) ? In this case , the desired curve is not the graph of a function of x , but a parameterized curve of the form ( x ( t ) , y ( t ) ) , for , say , t in the interval [ 0 , 1 ] . Now we have one independent variable , t , but two dependent ones , x and y . We need a generalization of the Euler - Lagrange Equation to the multivariate case . 24 . 7 . 2 Burg Entropy According to the Euler - Lagrange Equation for this case , we have 1 y ( x ) + N (cid:88) n = − N λ n e − ixn , ( 24 . 45 ) or y ( x ) = 1 / N (cid:88) n = − N a n e inx . ( 24 . 46 ) The spectral factorization theorem [ 174 ] tells us that if the denominator is positive for all x , then it can be written as N (cid:88) n = − N a n e inx = | N (cid:88) m = 0 b m e imx | 2 . ( 24 . 47 ) With a bit more work ( see [ 53 ] ) , it can be shown that the desired coeﬃcients b m are the solution to the system of equations N (cid:88) m = 0 r m − k b m = 0 , ( 24 . 48 ) for k = 1 , 2 , . . . , N and N (cid:88) m = 0 r m b m = 1 . ( 24 . 49 ) 24 . 8 The Multivariate Case Suppose that the integral to be optimized is J ( x , y ) = (cid:90) b a f ( t , x ( t ) , x (cid:48) ( t ) , y ( t ) , y (cid:48) ( t ) ) dt , ( 24 . 50 ) 306 CHAPTER 24 . CALCULUS OF VARIATIONS where f ( u , v , w , s , r ) is a real - valued function of ﬁve variables . In such cases , the Euler - Lagrange Equation is replaced by the two equations d dt (cid:16) ∂f ∂w (cid:17) − ∂f ∂v = 0 , d dt (cid:16) ∂f ∂r (cid:17) − ∂f ∂s = 0 . ( 24 . 51 ) We apply this now to the problem of maximum area for a ﬁxed perimeter . We know from Green’s Theorem in two dimensions that the area A enclosed by a curve C is given by the integral A = 1 2 (cid:73) C ( xdy − ydx ) = 1 2 (cid:90) 1 0 ( x ( t ) y (cid:48) ( t ) − y ( t ) x (cid:48) ( t ) ) dt . ( 24 . 52 ) The perimeter P of the curve is P = (cid:90) 1 0 (cid:112) x (cid:48) ( t ) 2 + y (cid:48) ( t ) 2 dt . ( 24 . 53 ) So the problem is to maximize the integral in Equation ( 24 . 52 ) , subject to the integral in Equation ( 24 . 53 ) being held constant . The problem is solved by using a Lagrange multiplier . We write J ( x , y ) = (cid:90) 1 0 (cid:16) x ( t ) y (cid:48) ( t ) − y ( t ) x (cid:48) ( t ) + λ (cid:112) x (cid:48) ( t ) 2 + y (cid:48) ( t ) 2 (cid:17) dt . ( 24 . 54 ) The generalized Euler - Lagrange Equations are d dt (cid:16) 1 2 x ( t ) + λy (cid:48) ( t ) (cid:112) x (cid:48) ( t ) 2 + y (cid:48) ( t ) 2 (cid:17) + 1 2 x (cid:48) ( t ) = 0 , ( 24 . 55 ) and d dt (cid:16) − 1 2 y ( t ) + λx (cid:48) ( t ) (cid:112) x (cid:48) ( t ) 2 + y (cid:48) ( t ) 2 (cid:17) − 1 2 y (cid:48) ( t ) = 0 . ( 24 . 56 ) It follows that y ( t ) + λx (cid:48) ( t ) (cid:112) x (cid:48) ( t ) 2 + y (cid:48) ( t ) 2 = c , ( 24 . 57 ) and x ( t ) + λy (cid:48) ( t ) (cid:112) x (cid:48) ( t ) 2 + y (cid:48) ( t ) 2 = d . ( 24 . 58 ) Therefore , ( x − d ) 2 + ( y − c ) 2 = λ 2 . ( 24 . 59 ) The optimal curve is then a portion of a circle . 24 . 9 . FINITE CONSTRAINTS 307 24 . 9 Finite Constraints Let x , y and z be functions of the independent variable t , with ˙ x = x (cid:48) ( t ) . Suppose that we want to minimize the functional J ( x , y , z ) = (cid:90) b a f ( x , ˙ x , y , ˙ y , z , ˙ z ) dt , subject to the constraint G ( x , y , z ) = 0 . Here we suppose that the points ( x ( t ) , y ( t ) , z ( t ) ) describe a curve in space and that the condition G ( x ( t ) , y ( t ) , z ( t ) ) = 0 restricts the curve to the surface G ( x , y , z ) = 0 . Such a problem is said to be one of ﬁnite constraints . In this section we illustrate this type of problem by considering the geodesic problem . 24 . 9 . 1 The Geodesic Problem The space curve ( x ( t ) , y ( t ) , z ( t ) ) , deﬁned for a ≤ t ≤ b , lies on the surface described by G ( x , y , z ) = 0 if G ( x ( t ) , y ( t ) , z ( t ) ) = 0 for all t in [ a , b ] . The geodesic problem is to ﬁnd the curve of shortest length lying on the surface and connecting points A = ( a 1 , a 2 , a 3 ) and B = ( b 1 , b 2 , b 3 ) . The functional to be minimized is the arc length J = (cid:90) b a (cid:112) ˙ x 2 + ˙ y 2 + ˙ z 2 dt , ( 24 . 60 ) where ˙ x = dxdt . Here the function f is f ( x , ˙ x , y , ˙ y , z , ˙ z ) = (cid:112) ˙ x 2 + ˙ y 2 + ˙ z 2 . We assume that the equation G ( x , y , z ) = 0 can be rewritten as z = g ( x , y ) , that is , we assume that we can solve for the variable z , and that the function g has continuous second partial derivatives . We may not be able to do this for the entire surface , as the equation of a sphere G ( x , y , z ) = x 2 + y 2 + z 2 − r 2 = 0 illustrates , but we can usually solve for z , or one of the other variables , on part of the surface , as , for example , on the upper or lower hemisphere . We then have ˙ z = g x ˙ x + g y ˙ y = g x ( x ( t ) , y ( t ) ) ˙ x ( t ) + g y ( x ( t ) , y ( t ) ) ˙ y ( t ) , ( 24 . 61 ) where g x = ∂g∂x . 308 CHAPTER 24 . CALCULUS OF VARIATIONS Substituting for z in Equation ( 24 . 60 ) , we see that the problem is now to minimize the functional J = (cid:90) b a (cid:113) ˙ x 2 + ˙ y 2 + ( g x ˙ x + g y ˙ y ) 2 dt , ( 24 . 62 ) which we write as J = (cid:90) b a F ( x , ˙ x , y , ˙ y ) dt . ( 24 . 63 ) The Euler - Lagrange Equations are then ∂F ∂x − d dt ( ∂F ∂ ˙ x ) = 0 , ( 24 . 64 ) and ∂F ∂y − d dt ( ∂F ∂ ˙ y ) = 0 . ( 24 . 65 ) We want to rewrite the Euler - Lagrange equations . Lemma 24 . 1 We have ∂ ˙ z ∂x = d dt ( g x ) . Proof : From Equation ( 24 . 61 ) we have ∂ ˙ z ∂x = ∂ ∂x ( g x ˙ x + g y ˙ y ) = g xx ˙ x + g yx ˙ y . We also have d dt ( g x ) = d dt ( g x ( x ( t ) , y ( t ) ) = g xx ˙ x + g xy ˙ y . Since g xy = g yx , the assertion of the lemma follows . From the Lemma we have both ∂ ˙ z ∂x = d dt ( g x ) , ( 24 . 66 ) and ∂ ˙ z ∂y = d dt ( g y ) . ( 24 . 67 ) Using ∂F ∂x = ∂f ∂ ˙ z ∂ ( g x ˙ x + g y ˙ y ) ∂x 24 . 9 . FINITE CONSTRAINTS 309 = ∂f ∂ ˙ z ∂ ∂x ( dg dt ) = ∂f ∂ ˙ z ∂ ˙ z ∂x and ∂F ∂y = ∂f ∂ ˙ z ∂ ˙ z ∂y , we can rewrite the Euler - Lagrange Equations as d dt ( ∂f ∂ ˙ x ) + g x d dt ( ∂f ∂ ˙ z ) = 0 , ( 24 . 68 ) and d dt ( ∂f ∂ ˙ y ) + g y d dt ( ∂f ∂ ˙ z ) = 0 . ( 24 . 69 ) To see why this is the case , we reason as follows . First ∂F ∂ ˙ x = ∂f ∂ ˙ x + ∂f ∂ ˙ z ∂ ˙ z ∂ ˙ x = ∂f ∂ ˙ x + ∂f ∂ ˙ z g x , so that d dt ( ∂F ∂ ˙ x ) = d dt ( ∂f ∂ ˙ x ) + d dt ( ∂f ∂ ˙ z g x ) = d dt ( ∂f ∂ ˙ x ) + d dt ( ∂f ∂ ˙ z ) g x + ∂f ∂ ˙ z d dt ( g x ) = d dt ( ∂f ∂ ˙ x ) + d dt ( ∂f ∂ ˙ z ) g x + ∂f ∂ ˙ z ∂ ˙ z ∂x . Therefore , d dt ( ∂F ∂ ˙ x ) = d dt ( ∂f ∂ ˙ x ) + d dt ( ∂f ∂ ˙ z ) g x + ∂F ∂x , so that 0 = d dt ( ∂F ∂ ˙ x ) − ∂F ∂x = d dt ( ∂f ∂ ˙ x ) + d dt ( ∂f ∂ ˙ z ) g x . ( 24 . 70 ) Let the function λ ( t ) be deﬁned by d dt ( ∂f ∂ ˙ z ) = λ ( t ) G z . From G ( x , y , z ) = 0 and z = g ( x , y ) , we have H ( x , y ) = G ( x , y , g ( x , y ) ) = 0 . Then we have H x = G x + G z g x = 0 , 310 CHAPTER 24 . CALCULUS OF VARIATIONS so that g x = − G x G z ; similarly , we have g y = − G y G z . Then the Euler - Lagrange Equations become d dt ( ∂f ∂ ˙ x ) = λ ( t ) G x , ( 24 . 71 ) and d dt ( ∂f ∂ ˙ y ) = λ ( t ) G y . ( 24 . 72 ) Eliminating λ ( t ) and extending the result to include z as well , we have ddt ( ∂f∂ ˙ x ) G x = ddt ( ∂f∂ ˙ y ) G y = ddt ( ∂f∂ ˙ z ) G z . ( 24 . 73 ) Notice that we could obtain the same result by calculating the Euler - Lagrange Equation for the functional (cid:90) b a f ( ˙ x , ˙ y , ˙ z ) + λ ( t ) G ( x ( t ) , y ( t ) , z ( t ) ) dt . ( 24 . 74 ) 24 . 9 . 2 An Example Let the surface be a sphere , with equation 0 = G ( x , y , z ) = x 2 + y 2 + z 2 − r 2 . Then Equation ( 24 . 73 ) becomes f ¨ x − ˙ x ˙ f 2 xf 2 = f ¨ y − ˙ y ˙ f 2 yf 2 = f ¨ z − ˙ z ˙ f 2 zf 2 . We can rewrite these equations as ¨ xy − x ¨ y ˙ xy − x ˙ y = y ¨ z − z ¨ y y ˙ z − z ˙ y = ˙ f f . The numerators are the derivatives , with respect to t , of the denominators , which leads to log | x ˙ y − y ˙ x | = log | y ˙ z − z ˙ y | + c 1 . 24 . 10 . HAMILTON’S PRINCIPLE AND THE LAGRANGIAN 311 Therefore , x ˙ y − y ˙ x = c 1 ( y ˙ z − z ˙ y ) . Rewriting , we obtain ˙ x + c 1 ˙ z x + c 1 z = ˙ y y , or x + c 1 z = c 2 y , which is a plane through the origin . The geodesics on the sphere are great circles , that is , the intersection of the sphere with a plane through the origin . 24 . 10 Hamilton’s Principle and the Lagrangian 24 . 10 . 1 Generalized Coordinates Suppose there are J particles at positions r j ( t ) = ( x j ( t ) , y j ( t ) , z j ( t ) ) , with masses m j , for j = 1 , 2 , . . . , J . Assume that there is a potential function V ( x 1 , y 1 , z 1 , . . . , x J , y J , z J ) such that the force acting on the j th particle is F j = − ( ∂V ∂x j , ∂V ∂y j , ∂V ∂z j ) . The kinetic energy is then T = 1 2 J (cid:88) j = 1 m j (cid:16) ( ˙ x j ) 2 + ( ˙ y j ) 2 + ( ˙ z j ) 2 (cid:17) . Suppose also that the positions of the particles are constrained by the conditions φ i ( x 1 , y 1 , z 1 , . . . , x J , y J , z J ) = 0 , for i = 1 , . . . , I . Then there are N = 3 J − I generalized coordinates q 1 , . . . , q N describing the behavior of the particles . For example , suppose that there is one particle moving on the surface of a sphere with radius R . Then the constraint is that x 2 + y 2 + z 2 = R 2 . The generalized coordinates can be chosen to be the two angles describing position on the surface , or latitude and longitude , say . We then have ˙ x j = N (cid:88) n = 1 ∂x j ∂q n ˙ q n , with similar expressions for the other time derivatives . 312 CHAPTER 24 . CALCULUS OF VARIATIONS 24 . 10 . 2 Homogeneity and Euler’s Theorem A function f ( u , v , w ) is said to be n - homogeneous if f ( tu , tv , tw ) = t n f ( u , v , w ) , for any scalar t . The kinetic energy T is 2 - homogeneous in the variables ˙ q n . Lemma 24 . 2 Let f ( u , v , w ) be n - homogeneous . Then ∂f ∂u ( au , av , aw ) = a n − 1 ∂f ∂u ( u , v , w ) . ( 24 . 75 ) Proof : We write ∂f ∂u ( au , av , aw ) = lim ∆ → 0 f ( au + a ∆ , av , aw ) − f ( au , av , aw ) a ∆ = a n a ∂f ∂u ( u , v , w ) = a n − 1 ∂f ∂u ( u , v , w ) . Theorem 24 . 1 ( Euler’s Theorem ) Let f ( u , v , w ) be n - homogeneous . Then u∂f∂u ( u , v , w ) + v ∂f ∂v ( u , v , w ) + w ∂f ∂w ( u , v , w ) = nf ( u , v , w ) . ( 24 . 76 ) Proof : Deﬁne g ( a ) = f ( au , av , aw ) , so that g (cid:48) ( a ) = u∂f∂u ( au , av , aw ) + v ∂f ∂v ( au , av , aw ) + w ∂f ∂w ( au , av , aw ) . Using Equation ( 24 . 75 ) we have g (cid:48) ( a ) = a n − 1 (cid:16) u∂f∂u ( u , v , w ) + v ∂f ∂v ( u , v , w ) + w ∂f ∂w ( u , v , w ) (cid:17) . But we also know that g ( a ) = a n f ( u , v , w ) , so that g (cid:48) ( a ) = na n − 1 f ( u , v , w ) . It follows that u∂f ∂u ( u , v , w ) + v ∂f ∂v ( u , v , w ) + w ∂f ∂w ( u , v , w ) = nf ( u , v , w ) . Since the kinetic energy T is 2 - homogeneous in the variables ˙ q n , it follows that 2 T = N (cid:88) n = 1 ˙ q n ∂T ∂ ˙ q n . ( 24 . 77 ) 24 . 11 . STURM - LIOUVILLE DIFFERENTIAL EQUATIONS 313 24 . 10 . 3 Hamilton’s Principle The Lagrangian is deﬁned to be L ( q 1 , . . . , q N , ˙ q 1 , . . . , ˙ q N ) = T − V . Hamilton’s principle is then that the paths taken by the particles are such that the integral (cid:90) t 2 t 1 L ( t ) dt = (cid:90) t 2 t 1 T ( t ) − V ( t ) dt is minimized . Consequently , the paths must satisfy the Euler - Lagrange equations ∂L ∂q n − d dt ∂L ∂ ˙ q n = 0 , for each n . Since the variable t does not appear explicitly , we know that N (cid:88) n = 1 ˙ q n ∂L ∂ ˙ q n − L = E , for some constant E . Noting that ∂L ˙ q n = ∂T ˙ q n , since V does not depend on the variables ˙ q n , and using Equation ( 24 . 77 ) , we ﬁnd that E = 2 T − L = 2 T − ( T − V ) = T + V , so that the sum of the kinetic and potential energies is constant . 24 . 11 Sturm - Liouville Diﬀerential Equations We have seen how optimizing a functional can lead to a diﬀerential equation that must be solved . If we are given a diﬀerential equation to solve , it can be helpful to know if it is the Euler - Lagrange equation for some functional . For example , the Sturm - Liouville diﬀerential equations have the form d dx (cid:16) p ( x ) dy dx (cid:17) + (cid:16) q ( x ) + λr ( x ) (cid:17) y = 0 . This diﬀerential equation is the Euler - Lagrange equation for the constrained problem of minimizing the functional (cid:90) x 2 x 1 (cid:16) p ( x ) ( y (cid:48) ( x ) ) 2 − q ( x ) ( y ( x ) ) 2 (cid:17) dx , subject to (cid:90) x 2 x 1 r ( x ) ( y ( x ) ) 2 dx = 1 . 314 CHAPTER 24 . CALCULUS OF VARIATIONS 24 . 12 Exercises Ex . 24 . 1 Suppose that the cycloid in the brachistochrone problem connects the starting point ( 0 , 0 ) with the point ( πa , − 2 a ) , where a > 0 . Show that the time required for the ball to reach the point ( πa , − 2 a ) is π (cid:113) ag . Ex . 24 . 2 Show that , for the situation in the previous exercise , the time required for the ball to reach ( πa , − 2 a ) is again π (cid:113) ag , if the ball begins rolling at any intermediate point along the cycloid . This is the tautochrone property of the cycloid . Chapter 25 Bregman - Legendre Functions 25 . 1 Chapter Summary In [ 12 ] Bauschke and Borwein show convincingly that the Bregman - Legendre functions provide the proper context for the discussion of Bregman pro - jections onto closed convex sets . The summary here follows closely the discussion given in [ 12 ] . 25 . 2 Essential Smoothness and Essential Strict Convexity Following [ 181 ] we say that a closed proper convex function f is essentially smooth if int D is not empty , f is diﬀerentiable on int D and x n ∈ int D , with x n → x ∈ bd D , implies that | | ∇ f ( x n ) | | 2 → + ∞ . Here int D and bd D denote the interior and boundary of the set D . A closed proper convex function f is essentially strictly convex if f is strictly convex on every convex subset of dom ∂f . The closed proper convex function f is essentially smooth if and only if the subdiﬀerential ∂f ( x ) is empty for x ∈ bd D and is { ∇ f ( x ) } for x ∈ int D ( so f is diﬀerentiable on int D ) if and only if the function f ∗ is essentially strictly convex . Deﬁnition 25 . 1 A closed proper convex function f is said to be a Legen - dre function if it is both essentially smooth and essentialy strictly convex . So f is Legendre if and only if its conjugate function is Legendre , in which case the gradient operator ∇ f is a topological isomorphism with 315 316 CHAPTER 25 . BREGMAN - LEGENDRE FUNCTIONS ∇ f ∗ as its inverse . The gradient operator ∇ f maps int dom f onto int dom f ∗ . If int dom f ∗ = R J then the range of ∇ f is R J and the equation ∇ f ( x ) = y can be solved for every y ∈ R J . In order for int dom f ∗ = R J it is necessary and suﬃcient that the Legendre function f be super - coercive , that is , lim | | x | | 2 → + ∞ f ( x ) | | x | | 2 = + ∞ . ( 25 . 1 ) If the eﬀective domain of f is bounded , then f is super - coercive and its gradient operator is a mapping onto the space R J . 25 . 3 Bregman Projections onto Closed Con - vex Sets Let f be a closed proper convex function that is diﬀerentiable on the nonempty set int D . The corresponding Bregman distance D f ( x , z ) is de - ﬁned for x ∈ R J and z ∈ int D by D f ( x , z ) = f ( x ) − f ( z ) − (cid:104)∇ f ( z ) , x − z (cid:105) . ( 25 . 2 ) Note that D f ( x , z ) ≥ 0 always and that D f ( x , z ) = + ∞ is possible . If f is essentially strictly convex then D f ( x , z ) = 0 implies that x = z . Let K be a nonempty closed convex set with K ∩ int D (cid:54) = ∅ . Pick z ∈ int D . The Bregman projection of z onto K , with respect to f , is P fK ( z ) = argmin x ∈ K ∩ D D f ( x , z ) . ( 25 . 3 ) If f is essentially strictly convex , then P fK ( z ) exists . If f is strictly convex on D then P fK ( z ) is unique . If f is Legendre , then P fK ( z ) is uniquely deﬁned and is in int D ; this last condition is sometimes called zone consistency . Example : Let J = 2 and f ( x ) be the function that is equal to one - half the norm squared on D , the nonnegative quadrant , + ∞ elsewhere . Let K be the set K = { ( x 1 , x 2 ) | x 1 + x 2 = 1 } . The Bregman projection of ( 2 , 1 ) onto K is ( 1 , 0 ) , which is not in int D . The function f is not essentially smooth , although it is essentially strictly convex . Its conjugate is the function f ∗ that is equal to one - half the norm squared on D and equal to zero elsewhere ; it is essentially smooth , but not essentially strictly convex . If f is Legendre , then P fK ( z ) is the unique member of K ∩ int D satisfying the inequality (cid:104)∇ f ( P fK ( z ) ) − ∇ f ( z ) , P fK ( z ) − c (cid:105) ≥ 0 , ( 25 . 4 ) for all c ∈ K . From this we obtain the Bregman Inequality : D f ( c , z ) ≥ D f ( c , P fK ( z ) ) + D f ( P fK ( z ) , z ) , ( 25 . 5 ) for all c ∈ K . 25 . 4 . BREGMAN - LEGENDRE FUNCTIONS 317 25 . 4 Bregman - Legendre Functions Following Bauschke and Borwein [ 12 ] , we say that a Legendre function f is a Bregman - Legendre function if the following properties hold : B1 : for x in D and any a > 0 the set { z | D f ( x , z ) ≤ a } is bounded . B2 : if x is in D but not in int D , for each positive integer n , y n is in int D with y n → y ∈ bd D and if { D f ( x , y n ) } remains bounded , then D f ( y , y n ) → 0 , so that y ∈ D . B3 : if x n and y n are in int D , with x n → x and y n → y , where x and y are in D but not in int D , and if D f ( x n , y n ) → 0 then x = y . Bauschke and Borwein then prove that Bregman’s SGP method converges to a member of K provided that one of the following holds : 1 ) f is Bregman - Legendre ; 2 ) K ∩ int D (cid:54) = ∅ and dom f ∗ is open ; or 3 ) dom f and dom f ∗ are both open . The Bregman functions form a class closely related to the Bregman - Legendre functions . For details see [ 31 ] . 25 . 5 Useful Results about Bregman - Legendre Functions The following results are proved in somewhat more generality in [ 12 ] . R1 : If y n ∈ int dom f and y n → y ∈ int dom f , then D f ( y , y n ) → 0 . R2 : If x and y n ∈ int dom f and y n → y ∈ bd dom f , then D f ( x , y n ) → + ∞ . R3 : If x n ∈ D , x n → x ∈ D , y n ∈ int D , y n → y ∈ D , { x , y } ∩ int D (cid:54) = ∅ and D f ( x n , y n ) → 0 , then x = y and y ∈ int D . R4 : If x and y are in D , but are not in int D , y n ∈ int D , y n → y and D f ( x , y n ) → 0 , then x = y . As a consequence of these results we have the following . R5 : If { D f ( x , y n ) } → 0 , for y n ∈ int D and x ∈ R J , then { y n } → x . Proof of R5 : Since { D f ( x , y n ) } is eventually ﬁnite , we have x ∈ D . By Property B1 above it follows that the sequence { y n } is bounded ; without loss of generality , we assume that { y n } → y , for some y ∈ D . If x is in int D , then , by result R2 above , we know that y is also in int D . Applying result R3 , with x n = x , for all n , we conclude that x = y . If , on the other hand , x is in D , but not in int D , then y is in D , by result R2 . There are two cases to consider : 1 ) y is in int D ; 2 ) y is not in int D . In case 1 ) we have D f ( x , y n ) → D f ( x , y ) = 0 , from which it follows that x = y . In case 2 ) we apply result R4 to conclude that x = y . 318 CHAPTER 25 . BREGMAN - LEGENDRE FUNCTIONS Chapter 26 Coordinate - Free Calculus 26 . 1 Chapter Summary When we study real - valued functions of one or several variables , it is natural to consider the domain of the function to be a subset of the Euclidean space R J , the space of all real column vectors of length J . The inner product on R J is just the usual dot product . When we discuss diﬀerentiation of such functions , it is natural to treat ﬁrst the partial derivatives in the coordinate directions , and then to express the directional derivative in terms of the gradient vector . However , it is useful , for some purposes , to consider more general Euclidean spaces and to formulate the calculus in a coordinate - free way . 26 . 2 Euclidean Spaces We shall use the term Euclidean space to describe any ﬁnite - dimensional inner product space , and denote such a space by the symbol E . In a previous chapter we gave several examples of such spaces ; we recall a few of them now . Example 1 : Let E = R J , with the inner product (cid:104) x , y (cid:105) = J (cid:88) j = 1 x j y j . ( 26 . 1 ) The inner product is the familiar dot product and we have (cid:104) x , y (cid:105) = x · y = y T x = x T y . 319 320 CHAPTER 26 . COORDINATE - FREE CALCULUS The norm is then the usual two - norm (cid:107) x (cid:107) 2 = (cid:112) (cid:104) x , x (cid:105) . ( 26 . 2 ) Example 2 : Let E = R JQ , the space of all real column vectors of length J , with the inner product (cid:104) x , y (cid:105) Q = J (cid:88) j = 1 J (cid:88) k = 1 x k y j Q jk = y T Qx , ( 26 . 3 ) where Q is a symmetric positive - deﬁnite matrix . The inner product can be written as (cid:104) x , y (cid:105) Q = Cx · Cy , where C is the symmetric square root of Q . The Q - norm of x is then the usual norm of Cx ; that is , (cid:107) x (cid:107) Q = (cid:107) Cx (cid:107) 2 . ( 26 . 4 ) Example 3 : Let E = M J , the space of all real J by J matrices , with the inner product (cid:104) A , B (cid:105) = trace ( B T A ) . ( 26 . 5 ) The inner product can be written as (cid:104) A , B (cid:105) = vec ( A ) · vec ( B ) , where vec ( A ) is the vectorization of the matrix A , that is , the represen - tation of A as a single column of length J 2 . The norm of A in M J is the Frobenius norm (cid:107) A (cid:107) F = (cid:107) vec ( A ) (cid:107) 2 . ( 26 . 6 ) The subspace S J of all symmetric members of M J , and the cone S J + + of all positive - deﬁnite members of S J play important roles in semi - deﬁnite programming . Example 4 : Let E be any Euclidean space , with the inner product (cid:104) x , y (cid:105) . Let S be any positive - deﬁnite self - adjoint linear operator on E , and deﬁne the induced inner product to be (cid:104) x , y (cid:105) S = (cid:104) x , Sy (cid:105) . Denote the space E with this new inner product by E S . 26 . 3 . THE DIFFERENTIAL AND THE GRADIENT 321 26 . 3 The Diﬀerential and the Gradient In our chapter on diﬀerentiation , we deﬁned the ( Fr´echet ) derivative of f : R J → R in terms of ∇ f ( x ) and the inner product in R J . When we change the inner product , especially when we change E , the deﬁnition of the derivative must change as well . Now we look at a more general notion of derivative for functions f : E → R , following the exposition in Renegar’s book [ 180 ] . We say that f : E → R is Fr´echet diﬀerentiable at x if there is a linear functional , called the derivative of f at x , or sometimes the diﬀerential of f at x , and denoted f (cid:48) ( x ) , with f (cid:48) ( x ) : E → R , such that lim (cid:107) h (cid:107) 2 → 0 1 (cid:107) h (cid:107) (cid:16) f ( x + h ) − f ( x ) − f (cid:48) ( x ) ( h ) (cid:17) = 0 . Because any linear functional can be represented using the inner product , we can also say that there is vector g ( x ) in E such that lim (cid:107) h (cid:107) 2 → 0 f ( x + h ) − f ( x ) − (cid:104) g ( x ) , h (cid:105) (cid:107) h (cid:107) 2 = 0 . ( 26 . 7 ) Then g ( x ) is called the gradient of f at x , with respect to the given inner product . If g ( x ) is a continuous function of the variable x , then we say that f is continuously diﬀerentiable . When the inner product changes , the gradient must also change , although the derivative remains the same . 26 . 4 An Example in S J We denote by S J + + the subset of S J consisting of all positive - deﬁnite real symmetric J by J matrices Q . Consider the function f : S J + + → R given by f ( Q ) = − log det ( Q ) . ( 26 . 8 ) Proposition 26 . 1 The gradient of f ( Q ) is g ( Q ) = − Q − 1 . Proof : Let ∆ Q be a member of S J . Let γ j , for j = 1 , 2 , . . . , J , be the eigenvalues of the symmetric matrix Q − 1 / 2 ( ∆ Q ) Q − 1 / 2 . These γ j are then real and are also the eigenvalues of the matrix Q − 1 ( ∆ Q ) . We shall consider (cid:107) ∆ Q (cid:107) small , so we may safely assume that 1 + γ j > 0 . Note that (cid:104) Q − 1 , ∆ Q (cid:105) = J (cid:88) j = 1 γ j , since the trace of any square matrix is the sum of its eigenvalues . Then we have f ( Q + ∆ Q ) − f ( Q ) = − log det ( Q + ∆ Q ) + log det ( Q ) 322 CHAPTER 26 . COORDINATE - FREE CALCULUS = − log det ( I + Q − 1 ( ∆ Q ) ) = − J (cid:88) j = 1 log ( 1 + γ j ) . From the submultiplicativity of the Frobenius norm we have (cid:107) Q − 1 ( ∆ Q ) (cid:107) / (cid:107) Q − 1 (cid:107) ≤ (cid:107) ∆ Q (cid:107) ≤ (cid:107) Q − 1 ( ∆ Q ) (cid:107)(cid:107) Q (cid:107) . Therefore , taking the limit as (cid:107) ∆ Q (cid:107) goes to zero is equivalent to taking the limit as (cid:107) γ (cid:107) 2 goes to zero , where γ is the vector whose entries are the γ j . To show that g ( Q ) = − Q − 1 note that lim sup (cid:107) ∆ Q (cid:107)→ 0 f ( Q + ∆ Q ) − f ( Q ) − (cid:104)− Q − 1 , ∆ Q (cid:105) (cid:107) ∆ Q (cid:107) = lim sup (cid:107) ∆ Q (cid:107)→ 0 | − log det ( Q + ∆ Q ) + log det ( Q ) + (cid:104) Q − 1 , ∆ Q (cid:105) | (cid:107) ∆ Q (cid:107) ≤ lim sup (cid:107) γ (cid:107) 2 → 0 (cid:80) Jj = 1 | log ( 1 + γ j ) − γ j | (cid:107) γ (cid:107) 2 / (cid:107) Q − 1 (cid:107) ≤ (cid:107) Q − 1 (cid:107) J (cid:88) j = 1 lim γ j → 0 γ j − log ( 1 + γ j ) | γ j | = 0 . 26 . 5 The Hessian In our previous discussions the Hessian matrix associated with a twice diﬀerentiable function f : R J → R was deﬁned to be the J by J matrix whose entries are the second partial derivatives of f . The Hessian matrix played the role of the second derivative of f . Now we generalize the notion of the Hessian , in much the same way as we just generalized the gradient . We say that f : E → R is twice diﬀerentiable at x if f is continuously diﬀerentiable and there is a linear operator H ( x ) : E → E such that lim (cid:107) ∆ x (cid:107) 2 → 0 (cid:107) g ( x + ∆ x ) − g ( x ) − H ( x ) ∆ x (cid:107) 2 (cid:107) ∆ x (cid:107) 2 = 0 . ( 26 . 9 ) Then H ( x ) is called the Hessian of f at x , with respect to the given inner product . If H is also continuous , then f is said to be twice continuously diﬀerentiable ; then the linear operator H ( x ) is self - adjoint , that is , (cid:104) y , H ( x ) z (cid:105) = (cid:104) H ( x ) y , z (cid:105) , for all y and z in E . 26 . 6 . NEWTON’S METHOD 323 Proposition 26 . 2 Let f : S J + + → R be f ( Q ) = − log det ( Q ) . Then H ( Q ) A = Q − 1 AQ − 1 , for all A in M J . Proof : If ∆ Q is suﬃciently small , then we can write ( Q + ∆ Q ) − 1 = Q − 1 ∞ (cid:88) k = 0 [ − ( ∆ Q ) Q − 1 ] k . Therefore , g ( Q + ∆ Q ) − g ( Q ) − Q − 1 ( ∆ Q ) Q − 1 = − Q − 1 ∞ (cid:88) k = 2 [ − ( ∆ Q ) Q − 1 ] k . Then , from the submultiplicativity of the Frobenius norm , lim sup (cid:107) ∆ Q (cid:107)→ 0 (cid:107) g ( Q + ∆ Q ) − g ( Q ) − Q − 1 ( ∆ Q ) Q − 1 (cid:107) (cid:107) ∆ Q (cid:107) ≤ lim sup (cid:107) ∆ Q (cid:107)→ 0 (cid:16) (cid:107) ∆ Q (cid:107)(cid:107) Q − 1 (cid:107) 3 ∞ (cid:88) k = 0 ( (cid:107) ( ∆ Q ) (cid:107)(cid:107) Q − 1 (cid:107) ) k (cid:17) = 0 . 26 . 6 Newton’s Method Suppose now that f : E → R is twice continuously diﬀerentiable . Let x ∈ E be ﬁxed . The second - order approximation of f in a neighborhood of x is the function q x ( y ) = f ( x ) + (cid:104) g ( x ) , y − x (cid:105) + 1 2 (cid:104) y − x , H ( x ) ( y − x ) (cid:105) . ( 26 . 10 ) Proposition 26 . 3 The gradient of q x at y is g ( x ) + H ( x ) ( y − x ) and the Hessian of q x at y is H ( x ) , for all y in E . Proof : We leave the proof to the reader , as Exercise 26 . 5 . Assume now that H ( x ) is positive - deﬁnite . Then the function q x is strictly convex and has a unique minimizer x + satisfying g ( x ) + H ( x ) ( x + − x ) = 0 . Therefore , x + = x − H ( x ) − 1 g ( x ) , and we write the Newton step as n ( x ) = x + − x = − H ( x ) − 1 g ( x ) . 324 CHAPTER 26 . COORDINATE - FREE CALCULUS For f : E S → R , the gradient is S − 1 g ( x ) , and the Hessian is S − 1 H ( x ) , where g ( x ) is the gradient and H ( x ) the Hessian , with respect to the orig - inal inner product on E . It is a simple matter then to show that the Newton step for any twice continuously diﬀerentiable function f : E S → R is independent of the operator S . 26 . 7 Intrinsic Inner Products Let f : E → R be twice continuously diﬀerentiable . Then f gives rise to a family of inner products by ﬁxing x and letting S = H ( x ) . This inner product , (cid:104) u , v (cid:105) H ( x ) = (cid:104) u , H ( x ) v (cid:105) , ( 26 . 11 ) is called the local inner product . It is easily shown that the local inner product does not depend on which reference inner product we have chosen for E ; that is , if we had used the inner product for E S , the local inner product would be unchanged , since H ( x ) would change appropriately . Note that we are suggesting here that any other inner product on E comes from the original inner product by using a self - adjoint positive - deﬁnite linear operator S ; that is , the new space is E S for some S . We leave it to the reader to prove that this is indeed the case . Because the local inner product is independent of the reference inner product on E , it is said to be an intrinsic inner product . To emphasize this independence , we write the local norm as (cid:107) y (cid:107) x = (cid:112) (cid:104) y , H ( x ) y (cid:105) . ( 26 . 12 ) It is interesting to note that , with respect to the local inner product , the gradient of f at x is g x ( x ) = − n ( x ) and the Hessian at x is H x ( x ) = I . 26 . 8 Self - Concordant Functions A function f : E → R is said to be self - concordant if f is twice continuously diﬀerentiable on some open convex set D f , H ( x ) is positive - deﬁnite for all x in D f , and , for all x in D f and for all y with (cid:107) y − x (cid:107) x < 1 , we have 1 − (cid:107) y − x (cid:107) x ≤ (cid:107) v (cid:107) y (cid:107) v (cid:107) x ≤ 1 1 − (cid:107) y − x (cid:107) x , ( 26 . 13 ) for all non - zero v . Consider the special case of f : R → R . Then , for any t ∈ R we have (cid:107) v (cid:107) t = (cid:112) f (cid:48)(cid:48) ( t ) | v | , 26 . 9 . TWO EXAMPLES 325 for all v ∈ R . Therefore , the property (cid:107) v (cid:107) s (cid:107) v (cid:107) t ≤ 1 1 − (cid:107) s − t (cid:107) t is equivalent to (cid:112) f (cid:48)(cid:48) ( s ) (cid:112) f (cid:48)(cid:48) ( t ) ≤ 1 1 − (cid:112) f (cid:48)(cid:48) ( t ) | s − t | . Therefore , f (cid:48)(cid:48) ( s ) − f (cid:48)(cid:48) ( t ) | s − t | ≤ 2 f (cid:48)(cid:48) ( t ) 3 / 2 − f (cid:48)(cid:48) ( t ) 2 | s − t | ( 1 − (cid:112) f (cid:48)(cid:48) ( t ) | s − t | ) 2 . If f is three - times diﬀerentiable then f (cid:48)(cid:48)(cid:48) ( t ) ≤ 2 f (cid:48)(cid:48) ( t ) 3 / 2 . 26 . 9 Two Examples We give two examples of self - concordant functions . 26 . 9 . 1 The Logarithmic Barrier Function The logarithmic barrier function f ( x ) = − J (cid:88) j = 1 log x j deﬁned for positive vectors , is self - concordant . First of all , (cid:107) y − x (cid:107) x < 1 is equivalent to J (cid:88) j = 1 (cid:16) y j − x j x j (cid:17) 2 < 1 . Then for any vector v in R J we have (cid:107) v (cid:107) 2 y = J (cid:88) j = 1 (cid:16) v j y j (cid:17) 2 = J (cid:88) j = 1 (cid:16) v j x j (cid:17) 2 (cid:16) x j y j (cid:17) 2 ≤ (cid:107) v (cid:107) 2 x max { (cid:16) x j y j (cid:17) | j = 1 , 2 , . . . , J } . Since y j x j ≥ 1 − | y j x j − 1 | ≥ 1 − (cid:107) y − x (cid:107) x , the right - most inequality in ( 26 . 13 ) follows . The left - most inequality follows similarly . 326 CHAPTER 26 . COORDINATE - FREE CALCULUS 26 . 9 . 2 An Extension to S J + + There is a similar logarithmic barrier function deﬁned for all positive - deﬁnite symmetric real J by J matrices Q , given by f ( Q ) = − log det ( Q ) . This function is also self - concordant . For the proof , see [ 180 ] , p . 25 . 26 . 10 Using Self - Concordant Barrier Func - tions The primal problem ( PS ) in linear programming is to minimize the function c T x over all x ≥ 0 with Ax = b . One way to incorporate the restriction that x be a non - negative vector is to employ the logarithmic barrier function . Then , for k = 1 , 2 , . . . , we minimize the function c T x + 1 k f ( x ) , over x with Ax = b to get x = x k . As k → ∞ the sequence x k converges to the solution of the original problem . The diﬃculty with barrier methods is that ﬁnding each x k usually requires an iterative method , such as Newton - Raphson . When the barrier function is self - concordant , as the log barrier function is , the approximation to x k obtained by a single Newton - Raphson step is suﬃciently close to x k to be used in place of x k . Since the Newton - Raphson iterative method works best when the function is quadratic , and so has a zero third derivative , it works nearly as well when the function is nearly quadratic , that is , when the third derivative is small , with respect to the second derivative . That is the meaning of self - concordance . 26 . 11 Semi - Deﬁnite Programming The May 2010 issue of the IEEE Signal Processing Magazine is devoted to articles describing various applications of convex optimization . The article [ 151 ] focuses on quadratically constrained quadratic programs ( QCQP ) . 26 . 11 . 1 Quadratically Constrained Quadratic Programs These problems take the following form : minimize x T Bx , subject to x T F i x ≥ a i , for i = 1 , . . . , I and x T G m x = b m , for m = 1 , . . . , M . Here the matri - ces B , F i and G m are real symmetric J by J matrices , possibly indeﬁnite , which means that the eigenvalues need not be non - negative . Consequently , the QCQP problems need not be convex . 26 . 12 . EXERCISES 327 The Boolean quadratic program ( BQP ) is one example of a QCQP . Here the objective is to minimize x T Bx , subject to x 2 j = 1 , for j = 1 , . . . , J . This problem is known to be NP - hard . Another example of a QCQP is to minimize x T Bx , subject to x T F i x ≥ 1 , where each of the matrices F i is positive - semideﬁnite . Now the feasible region is the exterior of several ellipses . 26 . 11 . 2 Semideﬁnite Relaxation Since x T Bx = trace ( Bxx T ) = trace ( BX ) , with X = xx T , we can formulate the QCQP problems in the Euclidean space E = S J . Now the problem is to minimize (cid:104) B , X (cid:105) , subject to (cid:104) F i , X (cid:105) ≥ a i , and (cid:104) G m , X (cid:105) = b m , over all X in S J of rank one . This last constraint is the primary diﬃculty . The semideﬁnite relaxation ( SDR ) approach is to ignore the rank one constraint initially , solve the more general problem as a semideﬁnite programming problem and then to project the solution into the subset of rank one symmetric matrices . 26 . 11 . 3 Semideﬁnite Programming Let C and A 1 , . . . , A M be real symmetric matrices . Consider the following semi - deﬁnite programming ( SDP ) problem : minimize the function trace ( CQ ) , over all real symmetric positive - deﬁnite matrices Q , subject to the con - straints trace ( A m Q ) ≤ b m , for m = 1 , 2 , . . . , M . This problem is analogous to the ( PS ) problem , and can be solved using the self - concordant logarithmic barrier function f ( Q ) = − log det ( Q ) . 26 . 12 Exercises Ex . 26 . 1 Use the deﬁnition of g ( x ) in Equation ( 26 . 7 ) to show that , when E = R J and the inner product is the usual dot product , the gradient is g ( x ) = ∇ f ( x ) , whose components are the partial derivatives in the J coor - dinate directions . 328 CHAPTER 26 . COORDINATE - FREE CALCULUS Ex . 26 . 2 Use the deﬁnition of g ( x ) in Equation ( 26 . 7 ) to show that , when E = R JQ and f is diﬀerentiable , the gradient of f is g ( x ) = Q − 1 ∇ f ( x ) . Hint : use the fact that (cid:112) λ J (cid:107) ∆ x (cid:107) 2 ≤ (cid:107) ∆ x (cid:107) Q ≤ (cid:112) λ 1 (cid:107) ∆ x (cid:107) 2 , where λ 1 and λ J are the largest and smallest eigenvalues of Q , respectively . Ex . 26 . 3 Use the deﬁnition of the Hessian in equation ( 26 . 9 ) to show that , if E = R J , then the Hessian of f at x is the J by J matrix whose entries are the second partial derivatives of f at x . Ex . 26 . 4 Let f : E → R be twice continuously diﬀerentiable and E = R JQ . Show that the Hessian of f , with respect to the inner product in R JQ , is the matrix Q − 1 H ( x ) , where H ( x ) is the ordinary Hessian matrix deﬁned for E = R J , Ex . 26 . 5 Prove Proposition 26 . 3 . Chapter 27 Quadratic Programming 27 . 1 Chapter Summary The quadratic - programming problem ( QP ) is to minimize a quadratic func - tion , subject to inequality constraints and , often , the nonnegativity of the variables . Using the Karush - Kuhn - Tucker Theorem 11 . 6 for mixed con - straints and introducing slack variables , this problem can be reformulated as a linear programming problem and solved by Wolfe’s Algorithm [ 175 ] , a variant of the simplex method . In the case of general constrained opti - mization , the Newton - Raphson method for ﬁnding a stationary point of the Lagrangian can be viewed as solving a sequence of quadratic programming problems . This leads to sequential quadratic programming [ 163 ] . 27 . 2 The Quadratic - Programming Problem The primal QP problem is to minimize the quadratic function f ( x ) = a + x T c + 1 2 x T Qx , ( 27 . 1 ) subject to the constraints Ax ≤ b , ( 27 . 2 ) and x j ≥ 0 , for j = 1 , . . . , J . Here a , b , and c are given , Q is a given J by J positive - deﬁnite matrix with entries Q ij , and A is an I by J matrix with rank I and entries A ij . To allow for some equality constraints , we say that ( Ax ) i ≤ b i , ( 27 . 3 ) for i = 1 , . . . , K , and ( Ax ) i = b i , ( 27 . 4 ) 329 330 CHAPTER 27 . QUADRATIC PROGRAMMING for i = K + 1 , . . . , I . We incorporate the nonnegativity constraints x j ≥ 0 by requiring − x j ≤ 0 , ( 27 . 5 ) for j = 1 , . . . , J . Applying the Karush - Kuhn - Tucker Theorem to this prob - lem , we ﬁnd that if a regular point x ∗ is a solution , then there are vectors µ ∗ and ν ∗ such that • 1 ) µ ∗ i ≥ 0 , for i = 1 , . . . , K ; • 2 ) ν ∗ j ≥ 0 , for j = 1 , . . . , J ; • 3 ) c + Qx ∗ + A T µ ∗ − v ∗ = 0 ; • 4 ) µ ∗ i ( ( Ax ∗ ) i − b i ) = 0 , for i = 1 , . . . , I ; • 5 ) x ∗ j ν ∗ j = 0 , for j = 1 , . . . , J . One way to solve this problem is to reformulate it as a linear - programming problem . To that end , we introduce slack variables x J + i , i = 1 , . . . , K , and write the problem as J (cid:88) j = 1 A ij x j + x J + i = b i , ( 27 . 6 ) for i = 1 , . . . , K , J (cid:88) j = 1 A ij x j = b i , ( 27 . 7 ) for i = K + 1 , . . . , I , J (cid:88) j = 1 Q mj x j + I (cid:88) i = 1 A im µ i − ν m = − c m , ( 27 . 8 ) for m = 1 , . . . , J , µ i x J + i = 0 , ( 27 . 9 ) for i = 1 , . . . , K , and x j ν j = 0 , ( 27 . 10 ) for j = 1 , . . . , J . The objective now is to formulate the problem as a primal linear - programming problem in standard form . 27 . 3 . AN EXAMPLE 331 The variables x j and ν j , for j = 1 , . . . , J , and µ i and x J + i , for i = 1 , . . . , K , must be nonnegative ; the variables µ i are unrestricted , for i = K + 1 , . . . , I , so for these variables we write µ i = µ + i − µ − i , ( 27 . 11 ) and require that both µ + i and µ − i be nonnegative . Finally , we need a linear functional to minimize . We rewrite Equation ( 27 . 6 ) as J (cid:88) j = 1 A ij x j + x J + i + y i = b i , ( 27 . 12 ) for i = 1 , . . . , K , Equation ( 27 . 7 ) as J (cid:88) j = 1 A ij x j + y i = b i , ( 27 . 13 ) for i = K + 1 , . . . , I , and Equation ( 27 . 8 ) as J (cid:88) j = 1 Q mj x j + I (cid:88) i = 1 A im µ i − ν m + y I + m = − c m , ( 27 . 14 ) for m = 1 , . . . , J . In order for all the equations to hold , each of the y i must be zero . The linear programming problem is therefore to minimize the linear functional y 1 + . . . + y I + J , ( 27 . 15 ) over nonnegative y i , subject to the equality constraints in the equations ( 27 . 12 ) , ( 27 . 13 ) , and ( 27 . 14 ) . Any solution to the original problem must be a basic feasible solution to this primal linear - programming problem . Wolfe’s Algorithm [ 175 ] is a modiﬁcation of the simplex method that guar - antees the complementary slackness conditions ; that is , we never have µ i and x J + i positive basic variables at the same time , nor x j and ν j . 27 . 3 An Example The following example is taken from [ 175 ] . Minimize the function f ( x 1 , x 2 ) = x 21 − x 1 x 2 + 2 x 22 − x 1 − x 2 , subject to the constraints x 1 − x 2 ≥ 3 , 332 CHAPTER 27 . QUADRATIC PROGRAMMING and x 1 + x 2 = 4 . We introduce the slack variable x 3 and then minimize y 1 + y 2 + y 3 + y 4 , subject to y i ≥ 0 , for i = 1 , . . . , 4 , and the equality constraints x 1 − x 2 − x 3 + y 1 = 3 , x 1 + x 2 + y 2 = 4 , 2 x 1 − x 2 − µ 1 + µ + 2 − µ − 2 − ν 1 + y 3 = 1 , and − x 1 + 4 x 2 + µ 1 + µ + 2 − µ − 2 − ν 2 + y 4 = 1 . This problem is then solved using the simplex algorithm , modiﬁed accord - ing to Wolfe’s Algorithm . 27 . 4 Quadratic Programming with Equality Constraints We turn now to the particular case of QP in which all the constraints are equations . The problem is , therefore , to minimize f ( x ) = a + x T c + 1 2 x T Qx , ( 27 . 16 ) subject to the constraints Ax = b . ( 27 . 17 ) The KKT Theorem then tells us that there is λ ∗ so that ∇ L ( x ∗ , λ ∗ ) = 0 for the solution vector x ∗ . Therefore , we have Qx ∗ + A T λ ∗ = − c , and Ax ∗ = b . Such quadratic programming problems arise in sequential quadratic pro - gramming . 27 . 5 . SEQUENTIAL QUADRATIC PROGRAMMING 333 27 . 5 Sequential Quadratic Programming Consider once again the CP problem of minimizing the convex function f ( x ) , subject to g i ( x ) = 0 , for i = 1 , . . . , I . The Lagrangian is L ( x , λ ) = f ( x ) + I (cid:88) i = 1 λ i g i ( x ) . ( 27 . 18 ) We assume that a sensitivity vector λ ∗ exists , so that x ∗ solves our problem if and only if ( x ∗ , λ ∗ ) satisﬁes ∇ L ( x ∗ , λ ∗ ) = 0 . ( 27 . 19 ) The problem can then be formulated as ﬁnding a zero of the function G ( x , λ ) = ∇ L ( x , λ ) , and the Newton - Raphson iterative algorithm can be applied . Because we are modifying both x and λ , this is a primal - dual algorithm . One step of the Newton - Raphson algorithm has the form (cid:18) x k + 1 λ k + 1 (cid:19) = (cid:18) x k λ k (cid:19) + (cid:18) p k v k (cid:19) , ( 27 . 20 ) where (cid:20) ∇ 2 xx L ( x k , λ k ) ∇ g ( x k ) ∇ g ( x k ) T 0 (cid:21) (cid:18) p k v k (cid:19) = (cid:18) −∇ x L ( x k , λ k ) − g ( x k ) (cid:19) . ( 27 . 21 ) The incremental vector (cid:18) p k v k (cid:19) obtained by solving this system is also the solution to the quadratic - programming problem of minimizing the function 1 2 p T ∇ 2 xx L ( x k , λ k ) p + p T ∇ x L ( x k , λ k ) , ( 27 . 22 ) subject to the constraint ∇ g ( x k ) T p + g ( x k ) = 0 . ( 27 . 23 ) Therefore , the Newton - Raphson algorithm for the original minimization problem can be implemented as a sequence of quadratic programs , each solved by the methods discussed previously . In practice , variants of this ap - proach that employ approximations for the ﬁrst and second partial deriva - tives are often used . 334 CHAPTER 27 . QUADRATIC PROGRAMMING Chapter 28 Modiﬁed - Gradient Algorithms 28 . 1 Chapter Summary The ﬁelds of transmission and emission tomographic imaging for medical diagnostics provide us with several examples of iterative algorithms that can be viewed as variations on the theme of gradient - descent or gradient - ascent methods . The modiﬁcations are employed both to guarantee non - negativity of the solution and to accelerate convergence . 28 . 2 Emission Tomography The problem of reconstructing a medical image from single - photon com - puted emission tomography ( SPECT ) data can be viewed as a statistical problem of maximizing a likelihood function . The expectation maximiza - tion maximum likelihood ( EMML ) algorithm is an iterative method for solving this problem . It can be formulated as a feasible - point method , in which the gradient - ascent algorithm is modiﬁed to preserve the necessary non - negativity of the parameters . In SPECT , a radioactive material is introduced into the body of the patient . The material , which is designed to travel to a speciﬁed region of the body , then begins to emit gamma - ray photons , some of which are detected outside the body of the patient by electronic detecting devices , known as gamma cameras . The objective is to image the relative density of the radioactive material at the various locations within the region of interest in the body of the patient . Higher or lower intensity in a particular region may indicate a medical problem , such as a tumor or a weakness in the heart wall . 335 336 CHAPTER 28 . MODIFIED - GRADIENT ALGORITHMS 28 . 3 The Discrete Problem We imagine the two - or three - dimensional region of interest to be composed of J pixels or voxels , within which the density is constant . The density within the j - th pixel is denoted x j ; these unknown x j must be non - negative . It is further assumed that x j is the expected number of photons emitted from the j - th pixel during the scanning time . Each pixel is assumed to be emitting photons independently of the other pixels . We denote by x the J by 1 column vector with entries x j . Outside the body are I detectors , indexed i = 1 , . . . , I . Our data are the positive numbers y i , which equal the number of photons detected at the i - th detector during the scan . We denote by y the I by 1 column vector whose entries are the y i . For each i and each j , we let P ij ≥ 0 be the probability that a photon emitted at the j - th pixel is detected at the i - th detector . In reality , these probabilities will involve not only the geometric relationship between the j - th pixel and the i - th detector , but the anatomy of the patient , as well , since the body of the patient may well absorb or scatter some of the photons we wish to detect . In practice , certain approximations are made , so that we may obtain useful values of the P ij . We let P be the I by J matrix with entries P ij , and assume that , for each j , the column sums s j are positive , where s j = I (cid:88) i = 1 P ij . The problem is then to estimate the x j from the data vector y and the probability matrix P . 28 . 4 Likelihood Maximization From the physics , we are justiﬁed in assuming that the number of photons N j emitted from the j - th pixel is governed by a Poisson probability , so that the probability that N j = n is e − x j x nj / n ! , for n = 0 , 1 , . . . . It follows , with a bit of probability theory , that the quanti - ties y i are statistically independent and also governed by Poisson probabil - ities , with mean value ( Px ) i ; the probability of having counted y i photons at the i - th detector is then e − ( Px ) i ( Px ) y i i / y i ! . The x j can then be viewed as parameters to be estimated . 28 . 5 . GRADIENT ASCENT : THE EMML ALGORITHM 337 A standard way to estimate parameters in statistics is to maximize the likelihood function . In the SPECT problem the likelihood function to be maximized is L ( x ) = I (cid:89) i = 1 e − ( Px ) i ( Px ) y i i / y i ! , ( 28 . 1 ) viewed as a function of the variables x j ≥ 0 . It is convenient to maximize , instead , the logarithm of L ( x ) ; so we maximize log L ( x ) = LL ( x ) = I (cid:88) i = 1 y i log ( Px ) i − ( Px ) i − log y i ! , ( 28 . 2 ) subject to x j ≥ 0 , for j = 1 , . . . , J . 28 . 5 Gradient Ascent : The EMML Algorithm The partial derivative of LL ( x ) , with respect to x j , is ∂LL ∂x j ( x ) = I (cid:88) i = 1 P ij (cid:16) y i ( Px ) i − 1 (cid:17) . ( 28 . 3 ) Therefore , a gradient - ascent algorithm would have the form x k + 1 j = x kj + α k I (cid:88) i = 1 P ij (cid:16) y i ( Px k ) i − 1 (cid:17) ( 28 . 4 ) for some scalars α k > 0 , and with the initial vector x 0 having all positive entries . The problem with this iterative algorithm is that we are not guar - anteed that each x k + 1 j will be positive . To guarantee positivity , it suﬃces to make a minor modiﬁcation to the iteration in Equation ( 28 . 4 ) . Instead , we write x k + 1 j = x kj + x kj s − 1 j I (cid:88) i = 1 P ij (cid:16) y i ( Px k ) i − 1 (cid:17) = x kj s − 1 j I (cid:88) i = 1 P ij y i ( Px k ) i . ( 28 . 5 ) With this modiﬁcation , we clearly have x k + 1 j > 0 for all k and all j . The basic idea of the modiﬁcation is to make the change in x kj small when x kj itself is small , thereby preserving positivity . The iterative algorithm described by Equation ( 28 . 5 ) is the EMML algorithm . It can be shown that the EMML algorithm converges to a maximizer of L ( x ) for every positive starting vector x 0 ( see [ 41 ] , [ 60 ] ) . The EMML algorithm for emission tomography was ﬁrst presented in 1982 by Shepp and Vardi [ 186 ] . The theory of convergence was further developed by others , in [ 144 ] , [ 199 ] , [ 145 ] and [ 39 ] . 338 CHAPTER 28 . MODIFIED - GRADIENT ALGORITHMS 28 . 6 Another View of the EMML Algorithm Maximizing the log likelihood function LL ( x ) = I (cid:88) i = 1 y i log ( Px ) i − ( Px ) i − log y i ! over non - negative vectors x is equivalent to minimizing the Kullback - Leibler distance KL ( y , Px ) = I (cid:88) i = 1 y i log y i − y i log ( Px ) i + ( Px ) i − y i ≥ 0 , ( 28 . 6 ) over the same x . If there is a non - negative vector x with y = Px , then such an x maximizes the likelihood L ( x ) . There may be more than one such x , but we do know that , in this consistent case , the EMML algorithm will converge to a non - negative solution of y = Px . Therefore , we can view the EMML algorithm as a method for ﬁnding an exact or approximate non - negative solution of the system of linear equations y = Px , in which the entries of y are positive , the entries of P are non - negative , and the column sums of P are positive . 28 . 7 A Partial - Gradient Approach Experience has shown that both the EMML and the SMART algorithms can be slow to converge , and much eﬀort has gone into accelerating these methods . One approach that has been fruitful is the so - called block - iterative or partial - gradient method . These methods apply when the function g ( x ) to be minimized has the form g ( x ) = I (cid:88) i = 1 g i ( x ) . Instead of using ∇ g ( x ) at each step of a gradient - descent method , we use ∇ g i ( x ) for only one value of i . We illustrate the partial - gradient approach using the function g ( x ) = KL ( y , Px ) . With g i ( x ) = KL ( y i , ( Px ) i ) , we have ∂g i ∂x j ( x ) = P ij (cid:16) 1 − y i ( Px ) i (cid:17) . A partial - gradient iteration would then have the form x k + 1 j = x kj − α k P ij (cid:16) 1 − y i ( Px ) i (cid:17) , 28 . 8 . THE SIMULTANEOUS MART ALGORITHM 339 for some α k > 0 , k = 0 , 1 , . . . , and i = k ( mod I ) + 1 . Mimicking what we did to get the EMML algorithm previously , we select x k + 1 j = x kj − x kj s − 1 j P ij (cid:16) 1 − y i ( Px ) i (cid:17) . ( 28 . 7 ) We can write this as x k + 1 j = ( 1 − s − 1 j P ij ) x kj + s − 1 j P ij x kj y i ( Px k ) i . ( 28 . 8 ) Since x k + 1 j is a convex combination of x kj and x kj y i ( Px k ) i , it is clearly positive . Notice that when I is large s j may well be much larger than P ij , so that the length of the change away from x kj in Equation ( 28 . 8 ) will be quite small . This will slow down convergence of the algorithm . We can speed up convergence while maintaining a convex combination , and thereby the non - negativity , if we replace the s j with m i = max { P ij | j = 1 , . . . , J } . Then the iterative step becomes x k + 1 j = x kj − x kj m − 1 i P ij (cid:16) 1 − y i ( Px ) i (cid:17) , ( 28 . 9 ) so that x k + 1 j = ( 1 − m − 1 i P ij ) x kj + m − 1 i P ij x kj y i ( Px k ) i . ( 28 . 10 ) Again , the x k + 1 j is a convex combination of x kj and x kj y i ( Px k ) i , and so it is positive . The iterative algorithm described by Equations ( 28 . 8 ) and ( 28 . 10 ) is the EMART algorithm , which has been shown to converge to a non - negative so - lution of y = Px , whenever such solutions exist ( see [ 52 ] , [ 60 ] ) . The EMART is a computationally simpler variant of the MART algorithm . Simulation studies have shown that , when y = Px has non - negative solutions and m i replaces s j , the EMART converges to such a solution of roughly I times faster than the EMML . It is not known if the two algorithms always pro - duce the same solution , when multiple non - negative solutions exist . 28 . 8 The Simultaneous MART Algorithm The Kullback - Leibler distance is not symmetric . Consequently , minimizing KL ( y , Px ) need not be the same as minimizing KL ( Px , y ) . A modiﬁed gradient - descent algorithm , similar to that used to derive the EMML , will give us an iterative algorithm for minimizing KL ( Px , y ) . This algorithm is 340 CHAPTER 28 . MODIFIED - GRADIENT ALGORITHMS a simultaneous version of the MART algorithm encountered previously , and so it is called the SMART algorithm . The MART algorithm was presented in [ 121 ] as a technique for reconstructing medical images from transmission tomographic data . Its simultaneous cousin , the SMART , was discussed originally in [ 93 ] and [ 184 ] , and later in [ 81 ] and [ 39 ] . For notational simplicity , we deﬁne f ( x ) = KL ( Px , y ) . The partial derivative of f ( x ) , with respect to x j , is ∂f ∂x j ( x ) = I (cid:88) i = 1 P ij log (cid:16) ( Px ) i y i (cid:17) . ( 28 . 11 ) Therefore , a gradient - descent method to minimize f ( x ) would have the form x k + 1 j = x kj − α k I (cid:88) i = 1 P ij log (cid:16) ( Px ) i y i (cid:17) . Once again , we have no guarantee that the x k + 1 j will be positive . Suppose we proceed as we did with the EMML , and write x k + 1 j = x kj − x kj s − 1 j I (cid:88) i = 1 P ij log (cid:16) ( Px ) i y i (cid:17) . We still cannot be sure that x k + 1 j will be positive . However , if we write this as x k + 1 j = x kj (cid:16) 1 − s − 1 j I (cid:88) i = 1 P ij log (cid:16) ( Px ) i y i (cid:17)(cid:17) , the inequality 1 − t ≤ e − t suggests replacing the possibly negative factor (cid:16) 1 − s − 1 j I (cid:88) i = 1 P ij log (cid:16) ( Px ) i y i (cid:17)(cid:17) with the positive factor exp (cid:16) s − 1 j I (cid:88) i = 1 P ij log (cid:16) y i ( Px ) i (cid:17)(cid:17) . The resulting iterative step becomes x k + 1 j = x kj exp (cid:16) s − 1 j I (cid:88) i = 1 P ij log (cid:16) y i ( Px ) i (cid:17)(cid:17) . ( 28 . 12 ) 28 . 9 . ALTERNATING MINIMIZATION 341 This is the SMART iteration . Rewriting the right side of Equation ( 28 . 12 ) using products shows that this method is a simultaneous variant of the MART algorithm that uses all the equations in each step , rather than just one equation . The SMART algorithm converges , for any positive starting vector x 0 , to the minimizer of KL ( Px , y ) for which the cross entropy KL ( x , x 0 ) is minimized ( see [ 60 ] ) . Consequently , whenever there are non - negative x with y = Px , the limit of the SMART iteration is that non - negative solution x for which KL ( x , x 0 ) is minimized . Suppose we modify the SMART algorithm and use only one equation at each step , the i - th one , for i = k ( mod I ) + 1 , as in EMART . The resulting iterative step becomes x k + 1 j = x kj exp (cid:16) s − 1 j P ij log (cid:16) y i ( Px ) i (cid:17)(cid:17) = x kj (cid:16) y i ( Px k ) i (cid:17) P ij / s j , which is a version of the MART algorithm . As with the EMART algorithm , when I is large , the exponent P ij s − 1 j can be quite small , causing relatively small changes from one iteration to the next . To prove convergence of the MART we need the exponent not to be greater than one . Therefore , we may again replace s j with m i , as in the EMART algorithm , obtaining x k + 1 j = x kj (cid:16) y i ( Px k ) i (cid:17) P ij / m i . ( 28 . 13 ) When there are non - negative solutions of y = Px , both versions of MART converge to the non - negative solution for which KL ( x , x 0 ) is minimized . The version given by Equation ( 28 . 13 ) converges roughly I times faster than the SMART algorithm [ 52 ] . 28 . 9 Alternating Minimization Judging from the previous sections , in which the EMML and SMART al - gorithms were obtained by clever guessing and approximation , one might well imagine that these algorithms lack a solid theoretical foundation , but this is not the case . Convergence theorems for both of these algorithms can be based on the principle of alternating minimization , as in [ 41 ] . 28 . 9 . 1 The EMML Algorithm Revisited We can derive the EMML algorithm using a method known as alternating minimization . We begin by deﬁning two sets of I by J matrices , denoted R and Q . The set R consists of all matrices r ( x ) having the entries r ( x ) ij = x j P ij y i ( Px ) i , 342 CHAPTER 28 . MODIFIED - GRADIENT ALGORITHMS and the set Q consists of all I by J matrices q ( x ) with the entries q ( x ) ij = x j P ij , where x is any non - negative vector in R J . Both sets are convex . For each member r ( x ) of R we have J (cid:88) j = 1 r ( x ) ij = y i , for each i = 1 , . . . , I . If the intersection of R and Q is not empty and q ( x ) is also in R , then we know that J (cid:88) j = 1 q ( x ) ij = y i , for each i = 1 , . . . , I , so that x is a non - negative solution of y = Px . Conse - quently , the problem of searching for such a solution can be converted into the problem of ﬁnding a member of the intersection of the two convex sets R and Q . For any non - negative vectors x and z the Kullback - Leibler distance KL ( r ( x ) , q ( z ) ) is deﬁned to be KL ( r ( x ) , q ( z ) ) = I (cid:88) i = 1 J (cid:88) j = 1 KL ( r ( x ) ij , q ( z ) ij ) . Beginning with a positive vector x 0 , and taking k = 0 , 1 , . . . , we minimize the distance KL ( r ( x k ) , q ( z ) ) over non - negative z to get x k + 1 . The resulting x k + 1 is the same as that given in Equation ( 28 . 5 ) by the EMML algorithm . Next , we minimize KL ( r ( x ) , q ( x k + 1 ) ) , obtaining r ( x k + 1 ) . Note that KL ( r ( x k ) , q ( x k ) ) = KL ( y , Px k ) , for each k . It follows that the sequence { KL ( y , Px k ) } is decreasing , as k goes to inﬁnity , since KL ( r ( x k ) , q ( x k ) ) ≥ KL ( r ( x k ) , q ( x k + 1 ) ) ≥ KL ( r ( x k + 1 ) , q ( x k + 1 ) ) . ( 28 . 14 ) If there are non - negative solutions of y = Px , then KL ( y , Px k ) will con - verge to zero ; otherwise , it will converge to a positive number and the { x k } will converge to a non - negative minimizer of KL ( y , Px ) . 28 . 9 . 2 The SMART Revisited In a similar manner , we can derive the SMART using alternating min - imization . Now , having obtained x k , we minimize the Kullback - Leibler 28 . 10 . EFFECTS OF NOISY DATA 343 distance KL ( q ( x ) , r ( x k ) ) to get x k + 1 , which turns out to be the same as given by Equation ( 28 . 12 ) . Next , we minimize KL ( q ( x k + 1 ) , r ( x ) ) , obtain - ing r ( x k + 1 ) . Note that KL ( q ( x k ) , r ( x k ) ) = KL ( Px k , y ) , for each k . It follows that the sequence { KL ( Px k , y ) } is decreasing , as k goes to inﬁnity , since KL ( q ( x k ) , r ( x k ) ) ≥ KL ( q ( x k + 1 ) , r ( x k ) ) ≥ KL ( q ( x k + 1 ) , r ( x k + 1 ) ) . ( 28 . 15 ) If there are non - negative solutions of y = Px , then KL ( Px k , y ) will con - verge to zero ; otherwise , it will converge to a positive number and the { x k } will converge to the non - negative minimizer of KL ( Px , y ) for which KL ( x , x 0 ) is minimized [ 41 ] . 28 . 10 Eﬀects of Noisy Data We have seen that , in the SPECT problem , the EMML algorithm seeks a non - negative x for which the measured count data vector y matches the theoretical expected count data vector Px . There is , of course , no reason why these two vectors should match perfectly , so we say that the data is noisy ; we have measurement noise . In addition , the matrix P whose entries provide a description of the probabilistic relationship between the entries of x and the measurements y will never be a perfect description of the scanning process . This results in model noise . The following theorem describes the problem . As previously , we assume that the vector y has positive entries and the matrix P has non - negative entries . If the matrix P and every matrix obtained from P by deleting columns have full rank , we say that P has the full - rank property . Theorem 28 . 1 ( [ 39 ] ) Let P have the full - rank property . If the system y = Px has no non - negative solution , then there is a subset S of { j = 1 , . . . , J } , with cardinality at most I − 1 , such that any non - negative minimizer of the function KL ( y , Px ) is supported on S , and so there is a unique non - negative minimizer of KL ( y , Px ) . The same result holds for the limit of the SMART , when KL ( Px , y ) has no non - negative solution , although there is no proof that the subsets S are the same in both cases . The proof of Theorem 28 . 1 is quite similar to that for Theorem 11 . 9 , and follows from the Karush - Kuhn - Tucker Theorem for convex programming . 344 CHAPTER 28 . MODIFIED - GRADIENT ALGORITHMS Chapter 29 Likelihood Maximization 29 . 1 Statistical Parameter Estimation A fundamental problem in statistics is the estimation of underlying popu - lation parameters from measured data . A popular method for such estima - tion is likelihood maximization ( ML ) . In a number of applications , such as image processing in remote sensing , the reconstruction problem can be re - formulated as a statistical parameter estimation problem in order to make use of likelihood maximization methods . For example , political pollsters want to estimate the percentage of vot - ers who favor a particular candidate . They can’t ask everyone , so they sample the population and estimate the percentage from the answers they receive from a relative few . Bottlers of soft drinks want to know if their process of sealing the bottles is eﬀective . Obviously , they can’t open every bottle to check the process . They open a few bottles , selected randomly according to some testing scheme , and make their assessment of the eﬀec - tiveness of the overall process after opening a few bottles . As we shall see , optimization plays an important role in the estimation of parameters from data . 29 . 2 Maximizing the Likelihood Function Suppose that Y is a random vector whose probability density function ( pdf ) f ( y ; x ) is a function of the vector variable y and is a member of a family of pdf parametrized by the vector variable x . Our data is one instance of Y ; that is , one particular value of the variable y , which we also denote by y . We want to estimate the correct value of the variable x , which we shall also denote by x . This notation is standard and the dual use of the symbols y and x should not cause confusion . Given the particular y we 345 346 CHAPTER 29 . LIKELIHOOD MAXIMIZATION can estimate the correct x by viewing f ( y ; x ) as a function of the second variable , with the ﬁrst variable held ﬁxed . This function of the parameters only is called the likelihood function . A maximum likelihood ( ML ) estimate of the parameter vector x is any value of the second variable for which the function is maximized . We consider several examples . 29 . 2 . 1 Example 1 : Estimating a Gaussian Mean Let Y 1 , . . . , Y I be I independent Gaussian ( or normal ) random variables with known variance σ 2 = 1 and unknown common mean µ . Let Y = ( Y 1 , . . . , Y I ) T . The parameter x we wish to estimate is the mean x = µ . Then , the random vector Y has the pdf f ( y ; x ) = ( 2 π ) − I / 2 exp ( − 1 2 I (cid:88) i = 1 ( y i − x ) 2 ) . Holding y ﬁxed and maximizing over x is equivalent to minimizing I (cid:88) i = 1 ( y i − x ) 2 as a function of x . The ML estimate is the arithmetic mean of the data , x ML = 1 I I (cid:88) i = 1 y i . Notice that E ( Y ) , the expected value of Y , is the vector x all of whose entries are x = µ . The ML estimate is the least squares solution of the overdetermined system of equations y = E ( Y ) ; that is , y i = x for i = 1 , . . . , I . The least - squares solution of a system of equations A x = b is the vector that minimizes the Euclidean distance between A x and b ; that is , it minimizes the Euclidean norm of their diﬀerence , | | A x − b | | , where , for any two vectors a and b we deﬁne | | a − b | | 2 = I (cid:88) i = 1 ( a i − b i ) 2 . As we shall see in the next example , another important measure of distance is the Kullback - Leibler ( KL ) distance between two nonnegative vectors c and d , given by KL ( c , d ) = I (cid:88) i = 1 c i log ( c i / d i ) + d i − c i . 29 . 2 . MAXIMIZING THE LIKELIHOOD FUNCTION 347 29 . 2 . 2 Example 2 : Estimating a Poisson Mean Let Y 1 , . . . , Y I be I independent Poisson random variables with unknown common mean λ , which is the parameter x we wish to estimate . Let Y = ( Y 1 , . . . , Y I ) T . Then , the probability function of Y is f ( y ; x ) = I (cid:89) i = 1 exp ( − x ) x y i / ( y i ) ! . Holding y ﬁxed and maximizing this likelihood function over positive values of x is equivalent to minimizing the Kullback - Leibler distance between the nonnegative vector y and the vector x whose entries are all equal to x , given by KL ( y , x ) = I (cid:88) i = 1 y i log ( y i / x ) + x − y i . The ML estimator is easily seen to be the arithmetic mean of the data , x ML = 1 I I (cid:88) i = 1 y i . The vector x is again E ( Y ) , so the ML estimate is once again obtained by ﬁnding an approximate solution of the overdetermined system of equations y = E ( Y ) . In the previous example the approximation was in the least squares sense , whereas here it is in the minimum KL sense ; the ML estimate is the arithmetic mean in both cases because the parameter to be estimated is one - dimensional . 29 . 2 . 3 Example 3 : Estimating a Uniform Mean Suppose now that Y 1 , . . . , Y I are independent random variables uniformly distributed over the interval [ 0 , 2 x ] . The parameter to be determined is their common mean , x . The random vector Y = ( Y 1 , . . . , Y I ) T has the pdf f ( y ; x ) = x − I , for 2 x ≥ m , f ( y ; x ) = 0 , otherwise , where m is the maximum of the y i . For ﬁxed vector y the ML estimate of x is m / 2 . The expected value of Y is E ( Y ) = x whose entries are all equal to x . In this case the ML estimator is not obtained by ﬁnding an approximate solution to the overdetermined system y = E ( Y ) . Since we can always write y = E ( Y ) + ( y − E ( Y ) ) , 348 CHAPTER 29 . LIKELIHOOD MAXIMIZATION we can model y as the sum of E ( Y ) and mean - zero error or noise . Since f ( y ; x ) depends on x , so does E ( Y ) . Therefore , it makes some sense to consider estimating our parameter vector x using an approximate solution for the system of equations y = E ( Y ) . As the ﬁrst two examples ( as well as many others ) illustrate , this is what the ML approach often amounts to , while the third example shows that this is not always the case , however . Still to be determined , though , is the metric with respect to which the approximation is to be performed . As the Gaussian and Poisson examples showed , the ML formalism can provide that metric . In those overly simple cases it did not seem to matter which metric we used , but it does matter . 29 . 2 . 4 Example 4 : Image Restoration A standard model for image restoration is the following : y = A x + z , where y is the blurred image , A is an I by J matrix describing the linear imaging system , x is the desired vectorized restored image , and z is ( pos - sibly correlated ) mean - zero additive Gaussian noise . The noise covariance matrix is Q = E ( zz T ) . Then E ( Y ) = A x , and the pdf is f ( y ; x ) = c exp ( − ( y − A x ) T Q − 1 ( y − A x ) ) , where c is a constant that does not involve x . Holding y ﬁxed and maxi - mizing f ( y ; x ) with respect to x is equivalent to minimizing ( y − A x ) T Q − 1 ( y − A x ) . Therefore , the ML solution is obtained by ﬁnding a weighted least squares approximate solution of the over - determined linear system y = E ( Y ) , with the weights coming from the matrix Q − 1 . When the noise terms are un - correlated and have the same variance , this reduces to the least squares solution . 29 . 2 . 5 Example 5 : Poisson Sums The model of sums of independent Poisson random variables is commonly used in emission tomography and elsewhere . Let P be an I by J matrix with nonnegative entries , and let x = ( x 1 , . . . , x J ) T be a vector of nonneg - ative parameters . Let Y 1 , . . . , Y I be independent Poisson random variables 29 . 2 . MAXIMIZING THE LIKELIHOOD FUNCTION 349 with positive means E ( Y i ) = J (cid:88) j = 1 P ij x j = ( P x ) i . The probability function for the random vector Y is then f ( y ; x ) = c I (cid:89) i = 1 exp ( − ( P x ) i ) ( ( P x ) i ) y i , where c is a constant not involving x . Maximizing this function of x for ﬁxed y is equivalent to minimizing the KL distance KL ( y , P x ) over non - negative x . The expected value of the random vector Y is E ( Y ) = P x and once again we see that the ML estimate is a nonnegative approximate solution of the system of ( linear ) equations y = E ( Y ) , with the approxi - mation in the KL sense . The system y = P x may not be over - determined ; there may even be exact solutions . But we require in addition that x ≥ 0 and there need not be a nonnegative solution to y = P x . We see from this example that constrained optimization plays a role in solving our problems . 29 . 2 . 6 Example 6 : Finite Mixtures of Probability Vec - tors We say that a discrete random variable W taking values in the set { i = 1 , . . . , I } is a ﬁnite mixture of probability vectors if there are probability vectors f j and numbers x j > 0 , for j = 1 , . . . , J , such that the probability vector for W is f ( i ) = Prob ( W = i ) = J (cid:88) j = 1 x j f j ( i ) . ( 29 . 1 ) We require , of course , that (cid:80) Jj = 1 x j = 1 . The data are N realizations of the random variable W , denoted w n , for n = 1 , . . . , N and the incomplete data is the vector y = ( w 1 , . . . , w N ) . The column vector x = ( x 1 , . . . , x J ) T is the parameter vector of mixture probabilities to be estimated . The likelihood function is L ( x ) = N (cid:89) n = 1 (cid:16) x 1 f 1 ( w n ) + . . . + x J f J ( w n ) (cid:17) , which can be written as L ( x ) = I (cid:89) i = 1 (cid:16) x 1 f 1 ( i ) + . . . + x J f J ( i ) (cid:17) n i , 350 CHAPTER 29 . LIKELIHOOD MAXIMIZATION where n i is the cardinality of the set { n | i n = i } . Then the log likelihood function is LL ( x ) = I (cid:88) i = 1 n i log (cid:16) x 1 f 1 ( i ) + . . . + x J f J ( i ) (cid:17) . With u the column vector with entries u i = n i / N , and P the matrix with entries P ij = f j ( i ) , we see that I (cid:88) i = 1 ( Px ) i = I (cid:88) i = 1 (cid:16) J (cid:88) j = 1 P ij x j (cid:17) = J (cid:88) j = 1 (cid:16) I (cid:88) i = 1 P ij (cid:17) = J (cid:88) j = 1 x j = 1 , so maximizing LL ( x ) over non - negative vectors x with (cid:80) Jj = 1 x j = 1 is equivalent to minimizing the KL distance KL ( u , Px ) over the same vectors . The restriction that the entries of x sum to one turns out to be redundant , as we show now . From the gradient form of the Karush - Kuhn - Tucker Theorem in op - timization , we know that , for any ˆ x that is a non - negative minimizer of KL ( u , Px ) , we have I (cid:88) i = 1 P ij (cid:16) 1 − u i ( P ˆ x ) i (cid:17) ≥ 0 , and I (cid:88) i = 1 P ij (cid:16) 1 − u i ( P ˆ x ) i (cid:17) = 0 , for all j such that ˆ x j > 0 . Consequently , we can say that s j ˆ x j = ˆ x j I (cid:88) i = 1 P ij (cid:16) u i ( P ˆ x ) i (cid:17) , for all j . Since , in the mixture problem , we have s j = (cid:80) Ii = 1 P ij = 1 for each j , it follows that J (cid:88) j = 1 ˆ x j = I (cid:88) i = 1 (cid:16) J (cid:88) j = 1 ˆ x j P ij (cid:17) u i ( P ˆ x ) i = I (cid:88) i = 1 u i = 1 . So we know now that any non - negative minimizer of KL ( u , Px ) will be a probability vector that maximizes LL ( x ) . Since the EMML algorithm min - imizes KL ( u , Px ) , when u i replaces y i , it can be used to ﬁnd the maximum - likelihood estimate of the mixture probabilities . If the set of values that W can take on is inﬁnite , say { i = 1 , 2 , . . . } , then the f j are inﬁnite probability sequences . The same analysis applies to this inﬁnite case , and again we have s j = 1 . The iterative scheme is given by Equation ( 22 . 2 ) , but with an apparently inﬁnite summation ; since only ﬁnitely many of the u i are non - zero , the summation is actually only ﬁnite . 29 . 2 . MAXIMIZING THE LIKELIHOOD FUNCTION 351 29 . 2 . 7 Example 7 : Finite Mixtures of Probability Den - sity Functions For ﬁnite mixtures of probability density functions the problem is a bit more complicated . A variant of the EMML algorithm still solves the problem , but this is not so obvious . Suppose now that W is a random variable with probability density function f ( w ) given by f ( w ) = J (cid:88) j = 1 x j f j ( w ) , ( 29 . 2 ) where the f j ( w ) are known pdf’s and the mixing proportions x j are un - known . Our data is w 1 , . . . , w N , that is , N independent realizations of the random variable W , and y = ( w 1 , . . . , w N ) is the incomplete data . With x the column vector with entries x j , we have the likelihood function L ( x ) = N (cid:89) n = 1 ( J (cid:88) j = 1 x j f j ( w n ) ) , and the log likelihood function LL ( x ) = N (cid:88) n = 1 log ( J (cid:88) j = 1 x j f j ( w n ) ) . We want to estimate the vector x by maximizing LL ( x ) , subject to x j ≥ 0 and x + = (cid:80) Jj = 1 x j = 1 . Let P nj = f j ( z n ) , and s j = (cid:80) Nn = 1 P nj . Then LL ( x ) = N (cid:88) n = 1 log ( Px ) n . With u n = 1 N for each n , we have that maximizing LL ( x ) , subject to x j ≥ 0 and x + = 1 , is equivalent to minimizing KL ( u , Px ) − N (cid:88) n = 1 ( Px ) n , ( 29 . 3 ) subject to the same constraints . Since the non - negative minimizer of the function F ( x ) = KL ( u , Px ) + J (cid:88) j = 1 ( 1 − s j ) x j ( 29 . 4 ) 352 CHAPTER 29 . LIKELIHOOD MAXIMIZATION satisﬁes x + = 1 , it follows that minimizing F ( x ) subject to x j ≥ 0 and x + = 1 is equivalent to minimizing F ( x ) , subject only to x j ≥ 0 . The following theorem is found in [ 48 ] : Theorem 29 . 1 Let y be any positive vector and G ( x ) = KL ( y , Px ) + J (cid:88) j = 1 β j KL ( γ j , x j ) . If s j + β j > 0 , α j = s j ( s j + β j ) − 1 , and β j γ j ≥ 0 for each j , then the iterative sequence generated by x k + 1 j = α j s − 1 j x kj (cid:16) N (cid:88) n = 1 P nj y n ( Px k ) n (cid:17) + ( 1 − α j ) γ j converges to a non - negative minimizer of G ( x ) . With y n = u n = 1 N , γ j = 0 , and β j = 1 − s j , it follows that the iterative sequence generated by x k + 1 j = x kj 1 N N (cid:88) n = 1 P nj 1 ( Px k ) n ( 29 . 5 ) converges to the maximum - likelihood estimate of the mixing proportions x j . This is the same EM iteration presented in McLachlan and Krishnan [ 156 ] , Equations ( 1 . 36 ) and ( 1 . 37 ) . 29 . 3 Alternative Approaches The ML approach is not always the best approach . As we have seen , the ML estimate is often found by solving , at least approximately , the system of equations y = E ( Y ) . Since noise is always present , this system of equations is rarely a correct statement of the situation . It is possible to overﬁt the mean to the noisy data , in which case the resulting x can be useless . In such cases Bayesian methods and maximum a posteriori estimation , as well as other forms of regularization techniques and penalty function techniques , can help . Other approaches involve stopping iterative algorithms prior to convergence . In most applications the data is limited and it is helpful to include prior information about the parameter vector x to be estimated . In the Poisson mixture problem the vector x must have nonnegative entries . In certain ap - plications , such as transmission tomography , we might have upper bounds on suitable values of the entries of x . 29 . 3 . ALTERNATIVE APPROACHES 353 From a mathematical standpoint we are interested in the convergence of iterative algorithms , while in many applications we want usable estimates in a reasonable amount of time , often obtained by running an iterative algorithm for only a few iterations . Algorithms designed to minimize the same cost function can behave quite diﬀerently during the early iterations . Iterative algorithms , such as block - iterative or incremental methods , that can provide decent answers quickly will be important . 354 CHAPTER 29 . LIKELIHOOD MAXIMIZATION Chapter 30 Operators 30 . 1 Chapter Summary In a broad sense , all iterative algorithms generate a sequence { x k } of vec - tors . The sequence may converge for any starting vector x 0 , or may con - verge only if the x 0 is suﬃciently close to a solution . The limit , when it exists , may depend on x 0 , and may , or may not , solve the original problem . Convergence to the limit may be slow and the algorithm may need to be accelerated . The algorithm may involve measured data . The limit may be sensitive to noise in the data and the algorithm may need to be regularized to lessen this sensitivity . The algorithm may be quite general , applying to all problems in a broad class , or it may be tailored to the problem at hand . Each step of the algorithm may be costly , but only a few steps gen - erally needed to produce a suitable approximate answer , or , each step may be easily performed , but many such steps needed . Although convergence of an algorithm is important , theoretically , sometimes in practice only a few iterative steps are used . In this chapter we consider several classes of operators that play important roles in optimization . 30 . 2 Operators For most of the iterative algorithms we shall consider , the iterative step is x k + 1 = Tx k , ( 30 . 1 ) for some operator T . If T is a continuous operator ( and it usually is ) , and the sequence { T k x 0 } converges to ˆ x , then T ˆ x = ˆ x , that is , ˆ x is a ﬁxed point of the operator T . We denote by Fix ( T ) the set of ﬁxed points of T . The convergence of the iterative sequence { T k x 0 } will depend on the properties of the operator T . 355 356 CHAPTER 30 . OPERATORS Our approach here will be to identify several classes of operators for which the iterative sequence is known to converge , to examine the conver - gence theorems that apply to each class , to describe several applied prob - lems that can be solved by iterative means , to present iterative algorithms for solving these problems , and to establish that the operator involved in each of these algorithms is a member of one of the designated classes . 30 . 3 Contraction Operators Contraction operators are perhaps the best known class of operators asso - ciated with iterative algorithms . 30 . 3 . 1 Lipschitz Continuous Operators Deﬁnition 30 . 1 An operator T on R J is Lipschitz continuous , with re - spect to a vector norm | | · | | , or L - Lipschitz , if there is a positive constant L such that | | Tx − Ty | | ≤ L | | x − y | | , ( 30 . 2 ) for all x and y in R J . For example , if f : R → R , and g ( x ) = f (cid:48) ( x ) is diﬀerentiable , the Mean Value Theorem tells us that g ( b ) = g ( a ) + g (cid:48) ( c ) ( b − a ) , for some c between a and b . Therefore , | f (cid:48) ( b ) − f (cid:48) ( a ) | ≤ | f (cid:48)(cid:48) ( c ) | | b − a | . If | f (cid:48)(cid:48) ( x ) | ≤ L , for all x , then g ( x ) = f (cid:48) ( x ) is L - Lipschitz . More generally , if f : R J → R is twice diﬀerentiable and (cid:107)∇ 2 f ( x ) (cid:107) 2 ≤ L , for all x , then T = ∇ f is L - Lipschitz , with respect to the 2 - norm . The 2 - norm of the Hessian matrix ∇ 2 f ( x ) is the largest of the absolute values of its eigenvalues . 30 . 3 . 2 Non - Expansive Operators An important special class of Lipschitz continuous operators are the non - expansive , or contractive , operators . Deﬁnition 30 . 2 If L = 1 , then T is said to be non - expansive ( ne ) , or a contraction , with respect to the given norm . In other words , T is ne for a given norm if , for every x and y , we have (cid:107) Tx − Ty (cid:107) ≤ (cid:107) x − y (cid:107) . 30 . 3 . CONTRACTION OPERATORS 357 Lemma 30 . 1 Let T : R J → R J be a non - expansive operator , with respect to the 2 - norm . Then the set F of ﬁxed points of T is a convex set . Proof : Select two distinct points a and b in F , a scalar α in the open interval ( 0 , 1 ) , and let c = αa + ( 1 − α ) b . We show that Tc = c . Note that a − c = 1 − α α ( c − b ) . We have (cid:107) a − b (cid:107) = (cid:107) a − Tc + Tc − b (cid:107) ≤ (cid:107) a − Tc (cid:107) + (cid:107) Tc − b (cid:107) = (cid:107) Ta − Tc (cid:107) + (cid:107) Tc − Tb (cid:107) ≤ (cid:107) a − c (cid:107) + (cid:107) c − b (cid:107) = (cid:107) a − b (cid:107) ; the last equality follows since a − c is a multiple of ( c − b ) . From this , we conclude that (cid:107) a − Tc (cid:107) = (cid:107) a − c (cid:107) , (cid:107) Tc − b (cid:107) = (cid:107) c − b (cid:107) , and that a − Tc and Tc − b are positive multiples of one another , that is , there is β > 0 such that a − Tc = β ( Tc − b ) , or Tc = 1 1 + β a + β 1 + β b = γa + ( 1 − γ ) b . Then inserting c = αa + ( 1 − α ) b and Tc = γa + ( 1 − γ ) b into (cid:107) Tc − b (cid:107) = (cid:107) c − b (cid:107) , we ﬁnd that γ = α and so Tc = c . The reader should note that the proof of the previous lemma depends heavily on the fact that the norm is the two - norm . If x and y are any non - negative vectors then (cid:107) x + y (cid:107) 1 = (cid:107) x (cid:107) 1 + (cid:107) y (cid:107) 1 , so the proof would not hold , if , for example , we used the one - norm instead . We want to ﬁnd properties of an operator T that guarantee that the sequence of iterates { T k x 0 } will converge to a ﬁxed point of T , for any x 0 , whenever ﬁxed points exist . Being non - expansive is not enough ; the non - expansive operator T = − I , where Ix = x is the identity operator , has the ﬁxed point x = 0 , but the sequence { T k x 0 } converges only if x 0 = 0 . 358 CHAPTER 30 . OPERATORS 30 . 3 . 3 Strict Contractions One property that guarantees not only that the iterates converge , but that there is a ﬁxed point is the property of being a strict contraction . Deﬁnition 30 . 3 An operator T on R J is a strict contraction ( sc ) , with respect to a vector norm | | · | | , if there is r ∈ ( 0 , 1 ) such that | | Tx − Ty | | ≤ r | | x − y | | , ( 30 . 3 ) for all vectors x and y . For strict contractions , we have the Banach - Picard Theorem [ 103 ] . The Banach - Picard Theorem : Theorem 30 . 1 Let T be sc . Then , there is a unique ﬁxed point of T and , for any starting vector x 0 , the sequence { T k x 0 } converges to the ﬁxed point . The key step in the proof is to show that { x k } is a Cauchy sequence , therefore , it has a limit . Corollary 30 . 1 If T n is a strict contraction , for some positive integer n , then T has a ﬁxed point . Proof : Suppose that T n ˆ x = ˆ x . Then T n T ˆ x = TT n ˆ x = T ˆ x , so that both ˆ x and T ˆ x are ﬁxed points of T n . But T n has a unique ﬁxed point . Therefore , T ˆ x = ˆ x . In many of the applications of interest to us , there will be multiple ﬁxed points of T . Therefore , T will not be sc for any vector norm , and the Banach - Picard ﬁxed - point theorem will not apply . We need to consider other classes of operators . These classes of operators will emerge as we investigate the properties of orthogonal projection operators . 30 . 3 . 4 Eventual Strict Contractions Consider the problem of ﬁnding x such that x = e − x . We can see from the graphs of y = x and y = e − x that there is a unique solution , which we shall denote by z . It turns out that z = 0 . 56714329040978 . . . . Let us try to ﬁnd z using the iterative sequence x k + 1 = e − x k , starting with some real x 0 . Note that we always have x k > 0 for k = 1 , 2 , . . . , even if x 0 < 0 . The operator here is Tx = e − x , which , for simplicity , we view as an operator on the non - negative real numbers . 30 . 4 . ORTHOGONAL PROJECTION OPERATORS 359 Since the derivative of the function f ( x ) = e − x is f (cid:48) ( x ) = − e − x , we have | f (cid:48) ( x ) | ≤ 1 , for all non - negative x , so T is non - expansive . But we do not have | f (cid:48) ( x ) | ≤ r < 1 , for all non - negative x ; therefore , T is a not a strict contraction , when considered as an operator on the non - negative real numbers . If we choose x 0 = 0 , then x 1 = 1 , x 2 = 0 . 368 , approximately , and so on . Continuing this iteration a few more times , we ﬁnd that after about k = 14 , the value of x k settles down to 0 . 567 , which is the answer , to three decimal places . The same thing is seen to happen for any positive starting points x 0 . It would seem that T has another property , besides being non - expansive , that is forcing convergence . What is it ? From the fact that 1 − e − x ≤ x , for all real x , with equality if and only if x = 0 , we can show easily that , for r = max { e − x 1 , e − x 2 } , | z − x k + 1 | ≤ r | z − x k | , for k = 3 , 4 , . . . . Since r < 1 , it follows , just as in the proof of the Banach - Picard Theorem , that { x k } is a Cauchy sequence and therefore converges . The limit must be a ﬁxed point of T , so the limit must be z . Although the operator T is not a strict contraction , with respect to the non - negative numbers , once we begin to calculate the sequence of iterates the operator T eﬀectively becomes a strict contraction , with respect to the vectors of the particular sequence being constructed , and so the sequence converges to a ﬁxed point of T . We cannot conclude from this that T has a unique ﬁxed point , as we can in the case of a strict contraction ; we must decide that by other means . We note in passing that the operator Tx = e − x is paracontractive , so that its convergence is also a consequence of the Elsner - Koltracht - Neumann Theorem 30 . 3 , which we discuss later in this chapter . 30 . 3 . 5 Instability Suppose we rewrite the equation e − x = x as x = − log x , and deﬁne Tx = − log x , for x > 0 . Now our iterative scheme becomes x k + 1 = Tx k = − log x k . A few calculations will convince us that the sequence { x k } is diverging away from the correct answer , not converging to it . The lesson here is that we cannot casually reformulate our problem as a ﬁxed - point problem and expect the iterates to converge to the answer . What matters is the behavior of the operator T . 30 . 4 Orthogonal Projection Operators If C is a closed , non - empty convex set in R J , and x is any vector , then , as we have seen , there is a unique point P C x in C closest to x , with respect 360 CHAPTER 30 . OPERATORS to the 2 - norm . This point is called the orthogonal projection of x onto C . If C is a subspace , then we can get an explicit description of P C x in terms of x ; for general convex sets C , however , we will not be able to express P C x explicitly , and certain approximations will be needed . Orthogonal projection operators are central to our discussion , and , in this overview , we focus on problems involving convex sets , algorithms involving orthogonal projection onto convex sets , and classes of operators derived from properties of orthogonal projection operators . 30 . 4 . 1 Properties of the Operator P C Although we usually do not have an explicit expression for P C x , we can , however , characterize P C x as the unique member of C for which (cid:104) P C x − x , c − P C x (cid:105) ≥ 0 , ( 30 . 4 ) for all c in C ; see Proposition 6 . 4 . P C is Non - expansive It follows from Corollary 6 . 1 and Cauchy’s Inequality that the orthogonal projection operator T = P C is non - expansive , with respect to the Euclidean norm , that is , | | P C x − P C y | | 2 ≤ | | x − y | | 2 , ( 30 . 5 ) for all x and y . Because the operator P C has multiple ﬁxed points , P C cannot be a strict contraction , unless the set C is a singleton set . P C is Firmly Non - expansive Deﬁnition 30 . 4 An operator T is said to be ﬁrmly non - expansive ( fne ) if (cid:104) Tx − Ty , x − y (cid:105) ≥ | | Tx − Ty | | 22 , ( 30 . 6 ) for all x and y in R J . Lemma 30 . 2 An operator F : R J → R J is fne if and only if F = 12 ( I + N ) , for some operator N that is ne with respect to the two - norm . Proof : Suppose that F = 12 ( I + N ) . We show that F is fne if and only if N is ne in the two - norm . First , we have (cid:104) Fx − Fy , x − y (cid:105) = 1 2 (cid:107) x − y (cid:107) 22 + 1 2 (cid:104) Nx − Ny , x − y (cid:105) . Also , (cid:107) 1 2 ( I + N ) x − 1 2 ( I + N ) y (cid:107) 22 = 1 4 (cid:107) x − y (cid:107) 2 + 1 4 (cid:107) Nx − Ny (cid:107) 2 + 1 2 (cid:104) Nx − Ny , x − y (cid:105) . 30 . 5 . TWO USEFUL IDENTITIES 361 Therefore , (cid:104) Fx − Fy , x − y (cid:105) ≥ (cid:107) Fx − Fy (cid:107) 22 if and only if (cid:107) Nx − Ny (cid:107) 22 ≤ (cid:107) x − y (cid:107) 22 . Corollary 30 . 2 For m = 1 , 2 , . . . , M , let α m > 0 , with (cid:80) Mm = 1 α m = 1 , and let F m : R J → R J be fne . Then the operator F = M (cid:88) m = 1 α m F m is also fne . In particular , the arithmetic mean of the F m is fne . Corollary 30 . 3 An operator F is fne if and only if I − F is fne . From Equation ( 6 . 25 ) , we see that the operator T = P C is not simply ne , but fne , as well . A good source for more material on these topics is the book by Goebel and Reich [ 118 ] . The Search for Other Properties of P C The class of non - expansive operators is too large for our purposes ; the operator Tx = − x is non - expansive , but the sequence { T k x 0 } does not converge , in general , even though a ﬁxed point , x = 0 , exists . The class of ﬁrmly non - expansive operators is too small for our purposes . Although the convergence of the iterative sequence { T k x 0 } to a ﬁxed point does hold for ﬁrmly non - expansive T , whenever ﬁxed points exist , the product of two or more fne operators need not be fne ; that is , the class of fne operators is not closed to ﬁnite products . This poses a problem , since , as we shall see , products of orthogonal projection operators arise in several of the algorithms we wish to consider . We need a class of operators smaller than the ne ones , but larger than the fne ones , closed to ﬁnite products , and for which the sequence of iterates { T k x 0 } will converge , for any x 0 , whenever ﬁxed points exist . The class we shall consider is the class of averaged operators . In all discussion of averaged operators the norm will be the two - norm . 30 . 5 Two Useful Identities The identities in the next two lemmas relate an arbitrary operator T to its complement , G = I − T , where I denotes the identity operator . These identities will allow us to transform properties of T into properties of G 362 CHAPTER 30 . OPERATORS that may be easier to work with . A simple calculation is all that is needed to establish the following lemma . Lemma 30 . 3 Let T be an arbitrary operator T on R J and G = I − T . Then | | x − y | | 22 − | | Tx − Ty | | 22 = 2 ( (cid:104) Gx − Gy , x − y (cid:105) ) − | | Gx − Gy | | 22 . ( 30 . 7 ) Lemma 30 . 4 Let T be an arbitrary operator T on R J and G = I − T . Then (cid:104) Tx − Ty , x − y (cid:105) − | | Tx − Ty | | 22 = (cid:104) Gx − Gy , x − y (cid:105) − | | Gx − Gy | | 22 . ( 30 . 8 ) Proof : Use the previous lemma . 30 . 6 Averaged Operators The term ‘averaged operator’ appears in the work of Baillon , Bruck and Reich [ 28 , 8 ] . There are several ways to deﬁne averaged operators . One way is based on Lemma 30 . 2 . Deﬁnition 30 . 5 An operator T : R J → R J is averaged ( av ) if there is an operator N that is ne in the two - norm and α ∈ ( 0 , 1 ) such that T = ( 1 − α ) I + αN . Then we say that T is α - averaged . It follows that T is fne if and only if T is α - averaged for α = 12 . Every aver - aged operator is ne , with respect to the two - norm , and every fne operator is av . We can also describe averaged operators T is terms of the complement operator , G = I − T . Deﬁnition 30 . 6 An operator G on R J is called ν - inverse strongly mono - tone ( ν - ism ) [ 119 ] ( also called co - coercive in [ 86 ] ) if there is ν > 0 such that (cid:104) Gx − Gy , x − y (cid:105) ≥ ν | | Gx − Gy | | 2 2 . ( 30 . 9 ) Lemma 30 . 5 An operator T is ne , with respect to the two - norm , if and only if its complement G = I − T is 12 - ism , and T is fne if and only if G is 1 - ism , and if and only if G is fne . Also , T is ne if and only if F = ( I + T ) / 2 is fne . If G is ν - ism and γ > 0 then the operator γG is νγ - ism . Lemma 30 . 6 An operator T is averaged if and only if G = I − T is ν - ism for some ν > 12 . If G is 12 α - ism , for some α ∈ ( 0 , 1 ) , then T is α - av . 30 . 6 . AVERAGED OPERATORS 363 Proof : We assume ﬁrst that there is α ∈ ( 0 , 1 ) and ne operator N such that T = ( 1 − α ) I + αN , and so G = I − T = α ( I − N ) . Since N is ne , I − N is 12 - ism and G = α ( I − N ) is 12 α - ism . Conversely , assume that G is ν - ism for some ν > 12 . Let α = 12 ν and write T = ( 1 − α ) I + αN for N = I − 1 α G . Since I − N = 1 α G , I − N is αν - ism . Consequently I − N is 12 - ism and N is ne . An averaged operator is easily constructed from a given operator N that is ne in the two - norm by taking a convex combination of N and the identity I . The beauty of the class of av operators is that it contains many operators , such as P C , that are not originally deﬁned in this way . As we shall see shortly , ﬁnite products of averaged operators are again averaged , so the product of ﬁnitely many orthogonal projections is av . We present now the fundamental properties of averaged operators , in preparation for the proof that the class of averaged operators is closed to ﬁnite products . Note that we can establish that a given operator is av by showing that there is an α in the interval ( 0 , 1 ) such that the operator 1 α ( A − ( 1 − α ) I ) ( 30 . 10 ) is ne . Using this approach , we can easily show that if T is sc , then T is av . Lemma 30 . 7 Let T = ( 1 − α ) A + αN for some α ∈ ( 0 , 1 ) . If A is averaged and N is non - expansive then T is averaged . Proof : Let A = ( 1 − β ) I + βM for some β ∈ ( 0 , 1 ) and ne operator M . Let 1 − γ = ( 1 − α ) ( 1 − β ) . Then we have T = ( 1 − γ ) I + γ [ ( 1 − α ) βγ − 1 M + αγ − 1 N ] . ( 30 . 11 ) Since the operator K = ( 1 − α ) βγ − 1 M + αγ − 1 N is easily shown to be ne and the convex combination of two ne operators is again ne , T is averaged . Corollary 30 . 4 If A and B are av and α is in the interval [ 0 , 1 ] , then the operator T = ( 1 − α ) A + αB formed by taking the convex combination of A and B is av . Corollary 30 . 5 Let T = ( 1 − α ) F + αN for some α ∈ ( 0 , 1 ) . If F is fne and N is ne then T is averaged . The orthogonal projection operators P H onto hyperplanes H = H ( a , γ ) are sometimes used with relaxation , which means that P H is replaced by the operator T = ( 1 − ω ) I + ωP H , ( 30 . 12 ) 364 CHAPTER 30 . OPERATORS for some ω in the interval ( 0 , 2 ) . Clearly , if ω is in the interval ( 0 , 1 ) , then T is av , by deﬁnition , since P H is ne . We want to show that , even for ω in the interval [ 1 , 2 ) , T is av . To do this , we consider the operator R H = 2 P H − I , which is reﬂection through H ; that is , P H x = 1 2 ( x + R H x ) , ( 30 . 13 ) for each x . Lemma 30 . 8 The operator R H = 2 P H − I is an isometry ; that is , | | R H x − R H y | | 2 = | | x − y | | 2 , ( 30 . 14 ) for all x and y , so that R H is ne . Lemma 30 . 9 For ω = 1 + γ in the interval [ 1 , 2 ) , we have ( 1 − ω ) I + ωP H = αI + ( 1 − α ) R H , ( 30 . 15 ) for α = 1 − γ 2 ; therefore , T = ( 1 − ω ) I + ωP H is av . The product of ﬁnitely many ne operators is again ne , while the product of ﬁnitely many fne operators , even orthogonal projections , need not be fne . It is a helpful fact that the product of ﬁnitely many av operators is again av . If A = ( 1 − α ) I + αN is averaged and B is averaged then T = AB has the form T = ( 1 − α ) B + αNB . Since B is av and NB is ne , it follows from Lemma 30 . 7 that T is averaged . Summarizing , we have Proposition 30 . 1 If A and B are averaged , then T = AB is averaged . 30 . 7 Gradient Operators Another type of operator that is averaged can be derived from gradient operators . Let g ( x ) : R J → R be a diﬀerentiable convex function and f ( x ) = ∇ g ( x ) its gradient . If ∇ g is non - expansive , then , according to Theorem 10 . 20 , ∇ g is fne . If , for some L > 0 , ∇ g is L - Lipschitz , for the two - norm , that is , | | ∇ g ( x ) − ∇ g ( y ) | | 2 ≤ L | | x − y | | 2 , ( 30 . 16 ) for all x and y , then 1 L ∇ g is ne , therefore fne , and the operator T = I − γ ∇ g is av , for 0 < γ < 2 L . From Corollary 13 . 1 we know that the operators P C are actually gradient operators ; P C x = ∇ g ( x ) for g ( x ) = 1 2 ( (cid:107) x (cid:107) 22 − (cid:107) x − P C x (cid:107) 22 ) . 30 . 7 . GRADIENT OPERATORS 365 30 . 7 . 1 The Krasnosel’skii - Mann - Opial Theorem For any operator T that is averaged , convergence of the sequence { T k x 0 } to a ﬁxed point of T , whenever ﬁxed points of T exist , is guaranteed by the Krasnosel’skii - Mann - Opial ( KMO ) Theorem [ 139 , 152 , 172 ] : Theorem 30 . 2 Let T be α - averaged , for some α ∈ ( 0 , 1 ) . Then , for any x 0 , the sequence { T k x 0 } converges to a ﬁxed point of T , whenever Fix ( T ) is non - empty . Proof : Let z be a ﬁxed point of T . The identity in Equation ( 30 . 7 ) is the key to proving Theorem 30 . 2 . Using Tz = z and ( I − T ) z = 0 and setting G = I − T we have | | z − x k | | 2 2 − | | Tz − x k + 1 | | 2 2 = 2 (cid:104) Gz − Gx k , z − x k (cid:105) − | | Gz − Gx k | | 2 2 . ( 30 . 17 ) Since , by Lemma 30 . 6 , G is 12 α - ism , we have | | z − x k | | 22 − | | z − x k + 1 | | 22 ≥ ( 1 α − 1 ) | | x k − x k + 1 | | 22 . ( 30 . 18 ) Consequently the sequence { x k } is bounded , the sequence { | | z − x k | | 2 } is decreasing and the sequence { | | x k − x k + 1 | | 2 } converges to zero . Let x ∗ be a cluster point of { x k } . Then we have Tx ∗ = x ∗ , so we may use x ∗ in place of the arbitrary ﬁxed point z . It follows then that the sequence { | | x ∗ − x k | | 2 } is decreasing ; since a subsequence converges to zero , the entire sequence converges to zero . The proof is complete . A version of the KMO Theorem 30 . 2 , with variable coeﬃcients , appears in Reich’s paper [ 177 ] . An operator T is said to be asymptotically regular if , for any x , the sequence { (cid:107) T k x − T k + 1 x (cid:107) } converges to zero . The proof of the KMO The - orem 30 . 2 involves showing that any averaged operator is asymptotically regular . In [ 172 ] Opial generalizes the KMO Theorem , proving that , if T is non - expansive and asymptotically regular , then the sequence { T k x } converges to a ﬁxed point of T , whenever ﬁxed points exist , for any x . Note that , in the KMO Theorem , we assumed that T is α - averaged , so that G = I − T is ν - ism , for some ν > 12 . But we actually used a somewhat weaker condition on G ; we required only that (cid:104) Gz − Gx , z − x (cid:105) ≥ ν (cid:107) Gz − Gx (cid:107) 2 for z such that Gz = 0 . This weaker property is called weakly ν - ism . 366 CHAPTER 30 . OPERATORS 30 . 8 Aﬃne Linear Operators It may not always be easy to decide if a given operator is averaged . The class of aﬃne linear operators provides an interesting illustration of the problem . The aﬃne operator Tx = Bx + d will be ne , sc , fne , or av precisely when the linear operator given by multiplication by the matrix B is the same . 30 . 8 . 1 The Hermitian Case When B is Hermitian , we can determine if B belongs to these classes by examining its eigenvalues λ : • B is non - expansive if and only if − 1 ≤ λ ≤ 1 , for all λ ; • B is averaged if and only if − 1 < λ ≤ 1 , for all λ ; • B is a strict contraction if and only if − 1 < λ < 1 , for all λ ; • B is ﬁrmly non - expansive if and only if 0 ≤ λ ≤ 1 , for all λ . Aﬃne linear operators T that arise , for instance , in splitting methods for solving systems of linear equations , generally have non - Hermitian linear part B . Deciding if such operators belong to these classes is more diﬃcult . Instead , we can ask if the operator is paracontractive , with respect to some norm . 30 . 9 Paracontractive Operators By examining the properties of the orthogonal projection operators P C , we were led to the useful class of averaged operators . The orthogonal projections also belong to another useful class , the paracontractions . Deﬁnition 30 . 7 An operator T is called paracontractive ( pc ) , with respect to a given norm , if , for every ﬁxed point y of T , we have | | Tx − y | | < | | x − y | | , ( 30 . 19 ) unless Tx = x . Paracontractive operators are studied by Censor and Reich in [ 80 ] . Proposition 30 . 2 The operators T = P C are paracontractive , with respect to the Euclidean norm . 30 . 9 . PARACONTRACTIVE OPERATORS 367 Proof : It follows from Cauchy’s Inequality that | | P C x − P C y | | 2 ≤ | | x − y | | 2 , with equality if and only if P C x − P C y = α ( x − y ) , for some scalar α with | α | = 1 . But , because 0 ≤ (cid:104) P C x − P C y , x − y (cid:105) = α | | x − y | | 22 , it follows that α = 1 , and so P C x − x = P C y − y . When we ask if a given operator T is pc , we must specify the norm . We often construct the norm speciﬁcally for the operator involved , as we did earlier in our discussion of strict contractions , in Equation ( 30 . 60 ) . To illustrate , we consider the case of aﬃne operators . 30 . 9 . 1 Linear and Aﬃne Paracontractions Let the matrix B be diagonalizable and let the columns of V be an eigen - vector basis . Then we have V − 1 BV = D , where D is the diagonal matrix having the eigenvalues of B along its diagonal . Lemma 30 . 10 A square matrix B is diagonalizable if all its eigenvalues are distinct . Proof : Let B be J by J . Let λ j be the eigenvalues of B , Bx j = λ j x j , and x j (cid:54) = 0 , for j = 1 , . . . , J . Let x m be the ﬁrst eigenvector that is in the span of { x j | j = 1 , . . . , m − 1 } . Then x m = a 1 x 1 + . . . a m − 1 x m − 1 , ( 30 . 20 ) for some constants a j that are not all zero . Multiply both sides by λ m to get λ m x m = a 1 λ m x 1 + . . . a m − 1 λ m x m − 1 . ( 30 . 21 ) From λ m x m = Ax m = a 1 λ 1 x 1 + . . . a m − 1 λ m − 1 x m − 1 , ( 30 . 22 ) it follows that a 1 ( λ m − λ 1 ) x 1 + . . . + a m − 1 ( λ m − λ m − 1 ) x m − 1 = 0 , ( 30 . 23 ) 368 CHAPTER 30 . OPERATORS from which we can conclude that some x n in { x 1 , . . . , x m − 1 } is in the span of the others . This is a contradiction . We see from this Lemma that almost all square matrices B are diago - nalizable . Indeed , all Hermitian B are diagonalizable . If B has real entries , but is not symmetric , then the eigenvalues of B need not be real , and the eigenvectors of B can have non - real entries . Consequently , we must con - sider B as a linear operator on C J , if we are to talk about diagonalizability . For example , consider the real matrix B = (cid:20) 0 1 − 1 0 (cid:21) . ( 30 . 24 ) Its eigenvalues are λ = i and λ = − i . The corresponding eigenvectors are ( 1 , i ) T and ( 1 , − i ) T . The matrix B is then diagonalizable as an operator on C 2 , but not as an operator on R 2 . Proposition 30 . 3 Let T be an aﬃne linear operator whose linear part B is diagonalizable , and | λ | < 1 for all eigenvalues λ of B that are not equal to one . Then the operator T is pc , with respect to the norm given by Equation ( 30 . 60 ) . Proof : This is Exercise 30 . 9 . We see from Proposition 30 . 3 that , for the case of aﬃne operators T whose linear part is not Hermitian , instead of asking if T is av , we can ask if T is pc ; since B will almost certainly be diagonalizable , we can answer this question by examining the eigenvalues of B . Unlike the class of averaged operators , the class of paracontractive op - erators is not necessarily closed to ﬁnite products , unless those factor op - erators have a common ﬁxed point . 30 . 9 . 2 The Elsner - Koltracht - Neumann Theorem Our interest in paracontractions is due to the Elsner - Koltracht - Neumann ( EKN ) Theorem [ 107 ] : Theorem 30 . 3 Let T be pc with respect to some vector norm . If T has ﬁxed points , then the sequence { T k x 0 } converges to a ﬁxed point of T , for all starting vectors x 0 . We follow the development in [ 107 ] . Theorem 30 . 4 Suppose that there is a vector norm on R J , with respect to which each T i is a pc operator , for i = 1 , . . . , I , and that F = ∩ Ii = 1 Fix ( T i ) is not empty . For k = 0 , 1 , . . . , let i ( k ) = k ( mod I ) + 1 , and x k + 1 = T i ( k ) x k . The sequence { x k } converges to a member of F , for every starting vector x 0 . 30 . 9 . PARACONTRACTIVE OPERATORS 369 Proof : Let y ∈ F . Then , for k = 0 , 1 , . . . , | | x k + 1 − y | | = | | T i ( k ) x k − y | | ≤ | | x k − y | | , ( 30 . 25 ) so that the sequence { | | x k − y | | } is decreasing ; let d ≥ 0 be its limit . Since the sequence { x k } is bounded , we select an arbitrary cluster point , x ∗ . Then d = | | x ∗ − y | | , from which we can conclude that | | T i x ∗ − y | | = | | x ∗ − y | | , ( 30 . 26 ) and T i x ∗ = x ∗ , for i = 1 , . . . , I ; therefore , x ∗ ∈ F . Replacing y , an arbitrary member of F , with x ∗ , we have that | | x k − x ∗ | | is decreasing . But , a subsequence converges to zero , so the whole sequence must converge to zero . This completes the proof . Corollary 30 . 6 If T is pc with respect to some vector norm , and T has ﬁxed points , then the iterative sequence { T k x 0 } converges to a ﬁxed point of T , for every starting vector x 0 . Corollary 30 . 7 If T = T I T I − 1 · · · T 2 T 1 , and F = ∩ Ii = 1 Fix ( T i ) is not empty , then F = Fix ( T ) . Proof : The sequence x k + 1 = T i ( k ) x k converges to a member of Fix ( T ) , for every x 0 . Select x 0 in F . Corollary 30 . 8 The product T of two or more pc operators T i , i = 1 , . . . , I is again a pc operator , if F = ∩ Ii = 1 Fix ( T i ) is not empty . Proof : Suppose that for T = T I T I − 1 · · · T 2 T 1 , and y ∈ F = Fix ( T ) , we have | | Tx − y | | = | | x − y | | . ( 30 . 27 ) Then , since | | T I ( T I − 1 · · · T 1 ) x − y | | ≤ | | T I − 1 · · · T 1 x − y | | ≤ . . . ≤ | | T 1 x − y | | ≤ | | x − y | | , ( 30 . 28 ) it follows that | | T i x − y | | = | | x − y | | , ( 30 . 29 ) and T i x = x , for each i . Therefore , Tx = x . 370 CHAPTER 30 . OPERATORS 30 . 10 Matrix Norms Any matrix can be turned into a vector by vectorization . Therefore , we can deﬁne a norm for any matrix A by simply vectorizing the matrix and taking a norm of the resulting vector ; the 2 - norm of the vectorized matrix A is the Frobenius norm of the matrix itself , denoted (cid:107) A (cid:107) F . The Frobenius norm does have the property (cid:107) Ax (cid:107) 2 ≤ (cid:107) A (cid:107) F | (cid:107) x (cid:107) 2 , known as submultiplicativity so that it is compatible with the role of A as a linear transformation , but other norms for matrices may not be compatible with this role for A . For that reason , we consider compatible norms on matrices that are induced from norms of the vectors on which the matrices operate . 30 . 10 . 1 Induced Matrix Norms One way to obtain a compatible norm for matrices is through the use of an induced matrix norm . Deﬁnition 30 . 8 Let (cid:107) x (cid:107) be any norm on C J , not necessarily the Eu - clidean norm , (cid:107) b (cid:107) any norm on C I , and A a rectangular I by J matrix . The induced matrix norm of A , simply denoted (cid:107) A (cid:107) , derived from these two vector norms , is the smallest positive constant c such that (cid:107) Ax (cid:107) ≤ c (cid:107) x (cid:107) , ( 30 . 30 ) for all x in C J . This induced norm can be written as (cid:107) A (cid:107) = max x (cid:54) = 0 { (cid:107) Ax (cid:107) / (cid:107) x (cid:107) } . ( 30 . 31 ) We study induced matrix norms in order to measure the distance (cid:107) Ax − Az (cid:107) , relative to the distance (cid:107) x − z (cid:107) : (cid:107) Ax − Az (cid:107) ≤ (cid:107) A (cid:107) (cid:107) x − z (cid:107) , ( 30 . 32 ) for all vectors x and z and (cid:107) A (cid:107) is the smallest number for which this statement can be made . 30 . 10 . 2 Condition Number of a Square Matrix Let S be a square , invertible matrix and z the solution to Sz = h . We are concerned with the extent to which the solution changes as the right side , h , changes . Denote by δ h a small perturbation of h , and by δ z the 30 . 10 . MATRIX NORMS 371 solution of Sδ z = δ h . Then S ( z + δ z ) = h + δ h . Applying the compatibility condition (cid:107) Ax (cid:107) ≤ (cid:107) A (cid:107)(cid:107) x (cid:107) , we get (cid:107) δ z (cid:107) ≤ (cid:107) S − 1 (cid:107)(cid:107) δ h (cid:107) , ( 30 . 33 ) and (cid:107) z (cid:107) ≥ (cid:107) h (cid:107) / (cid:107) S (cid:107) . ( 30 . 34 ) Therefore (cid:107) δ z (cid:107) (cid:107) z (cid:107) ≤ (cid:107) S (cid:107) (cid:107) S − 1 (cid:107)(cid:107) δ h (cid:107) (cid:107) h (cid:107) . ( 30 . 35 ) Deﬁnition 30 . 9 The quantity c = (cid:107) S (cid:107)(cid:107) S − 1 (cid:107) is the condition number of S , with respect to the given matrix norm . Note that c ≥ 1 : for any non - zero z , we have (cid:107) S − 1 (cid:107) ≥ (cid:107) S − 1 z (cid:107) / (cid:107) z (cid:107) = (cid:107) S − 1 z (cid:107) / (cid:107) SS − 1 z (cid:107) ≥ 1 / (cid:107) S (cid:107) . ( 30 . 36 ) When S is Hermitian and positive - deﬁnite , the condition number of S , with respect to the matrix norm induced by the Euclidean vector norm , is c = λ max ( S ) / λ min ( S ) , ( 30 . 37 ) the ratio of the largest to the smallest eigenvalues of S . 30 . 10 . 3 Some Examples of Induced Matrix Norms If we choose the two vector norms carefully , then we can get an explicit description of (cid:107) A (cid:107) , but , in general , we cannot . For example , let (cid:107) x (cid:107) = (cid:107) x (cid:107) 1 and (cid:107) Ax (cid:107) = (cid:107) Ax (cid:107) 1 be the 1 - norms of the vectors x and Ax , where (cid:107) x (cid:107) 1 = J (cid:88) j = 1 | x j | . ( 30 . 38 ) Lemma 30 . 11 The 1 - norm of A , induced by the 1 - norms of vectors in C J and C I , is (cid:107) A (cid:107) 1 = max { I (cid:88) i = 1 | A ij | , j = 1 , 2 , . . . , J } . ( 30 . 39 ) 372 CHAPTER 30 . OPERATORS Proof : Use basic properties of the absolute value to show that (cid:107) Ax (cid:107) 1 ≤ J (cid:88) j = 1 ( I (cid:88) i = 1 | A ij | ) | x j | . ( 30 . 40 ) Then let j = m be the index for which the maximum column sum is reached and select x j = 0 , for j (cid:54) = m , and x m = 1 . The inﬁnity norm of the vector x is (cid:107) x (cid:107) ∞ = max { | x j | , j = 1 , 2 , . . . , J } . ( 30 . 41 ) Lemma 30 . 12 The inﬁnity norm of the matrix A , induced by the inﬁnity norms of vectors in R J and C I , is (cid:107) A (cid:107) ∞ = max { J (cid:88) j = 1 | A ij | , i = 1 , 2 , . . . , I } . ( 30 . 42 ) The proof is similar to that of the previous lemma . Lemma 30 . 13 Let M be an invertible matrix and (cid:107) x (cid:107) any vector norm . Deﬁne (cid:107) x (cid:107) M = (cid:107) Mx (cid:107) . ( 30 . 43 ) Then , for any square matrix S , the matrix norm (cid:107) S (cid:107) M = max x (cid:54) = 0 { (cid:107) Sx (cid:107) M / (cid:107) x (cid:107) M } ( 30 . 44 ) is (cid:107) S (cid:107) M = (cid:107) MSM − 1 (cid:107) . ( 30 . 45 ) Proof : The proof is left as an exercise . In [ 7 ] Lemma 30 . 13 is used to prove the following lemma : Lemma 30 . 14 Let S be any square matrix and let (cid:15) > 0 be given . Then there is an invertible matrix M such that (cid:107) S (cid:107) M ≤ ρ ( S ) + (cid:15) . ( 30 . 46 ) 30 . 10 . MATRIX NORMS 373 30 . 10 . 4 The Euclidean Norm of a Square Matrix We shall be particularly interested in the Euclidean norm ( or 2 - norm ) of the square matrix A , denoted by (cid:107) A (cid:107) 2 , which is the induced matrix norm derived from the Euclidean vector norms . From the deﬁnition of the Euclidean norm of A , we know that (cid:107) A (cid:107) 2 = max { (cid:107) Ax (cid:107) 2 / (cid:107) x (cid:107) 2 } , ( 30 . 47 ) with the maximum over all nonzero vectors x . Since (cid:107) Ax (cid:107) 22 = x † A † Ax , ( 30 . 48 ) we have (cid:107) A (cid:107) 2 = (cid:114) max { x † A † Ax x † x } , ( 30 . 49 ) over all nonzero vectors x . Proposition 30 . 4 The Euclidean norm of a square matrix is (cid:107) A (cid:107) 2 = (cid:113) ρ ( A † A ) ; ( 30 . 50 ) that is , the term inside the square - root in Equation ( 30 . 49 ) is the largest eigenvalue of the matrix A † A . Proof : Let λ 1 ≥ λ 2 ≥ . . . ≥ λ J ≥ 0 ( 30 . 51 ) and let { u j , j = 1 , . . . , J } be mutually orthogonal eigenvectors of A † A with (cid:107) u j (cid:107) 2 = 1 . Then , for any x , we have x = J (cid:88) j = 1 [ ( u j ) † x ] u j , ( 30 . 52 ) while A † Ax = J (cid:88) j = 1 [ ( u j ) † x ] A † Au j = J (cid:88) j = 1 λ j [ ( u j ) † x ] u j . ( 30 . 53 ) It follows that (cid:107) x (cid:107) 22 = x † x = J (cid:88) j = 1 | ( u j ) † x | 2 , ( 30 . 54 ) 374 CHAPTER 30 . OPERATORS and (cid:107) Ax (cid:107) 22 = x † A † Ax = J (cid:88) j = 1 λ j | ( u j ) † x | 2 . ( 30 . 55 ) Maximizing (cid:107) Ax (cid:107) 22 / (cid:107) x (cid:107) 22 over x (cid:54) = 0 is equivalent to maximizing (cid:107) Ax (cid:107) 22 , subject to (cid:107) x (cid:107) 22 = 1 . The right side of Equation ( 30 . 55 ) is then a con - vex combination of the λ j , which will have its maximum when only the coeﬃcient of λ 1 is non - zero . It can be shown that (cid:107) A (cid:107) 22 ≤ (cid:107) A (cid:107) 1 (cid:107) A (cid:107) ∞ ; see [ 60 ] . If S is not Hermitian , then the Euclidean norm of S cannot be calculated directly from the eigenvalues of S . Take , for example , the square , non - Hermitian matrix S = (cid:20) i 2 0 i (cid:21) , ( 30 . 56 ) having eigenvalues λ = i and λ = i . The eigenvalues of the Hermitian matrix S † S = (cid:20) 1 − 2 i 2 i 5 (cid:21) ( 30 . 57 ) are λ = 3 + 2 √ 2 and λ = 3 − 2 √ 2 . Therefore , the Euclidean norm of S is (cid:107) S (cid:107) 2 = (cid:113) 3 + 2 √ 2 . ( 30 . 58 ) Deﬁnition 30 . 10 An operator T is called an aﬃne linear operator if T has the form Tx = Bx + d , where B is a linear operator , and d is a ﬁxed vector . Lemma 30 . 15 Let T be an aﬃne linear operator . Then T is a strict contraction if and only if | | B | | , the induced matrix norm of B , is less than one . Deﬁnition 30 . 11 The spectral radius of a square matrix B , written ρ ( B ) , is the maximum of | λ | , over all eigenvalues λ of B . Since ρ ( B ) ≤ | | B | | for every norm on B induced by a vector norm , B is sc implies that ρ ( B ) < 1 . When B is Hermitian , the matrix norm of B induced by the Euclidean vector norm is | | B | | 2 = ρ ( B ) , so if ρ ( B ) < 1 , then B is sc with respect to the Euclidean norm . 30 . 11 . EXERCISES 375 When B is not Hermitian , it is not as easy to determine if the aﬃne operator T is sc with respect to a given norm . Instead , we often tailor the norm to the operator T . Suppose that B is a diagonalizable matrix , that is , there is a basis for R J consisting of eigenvectors of B . Let { u 1 , . . . , u J } be such a basis , and let Bu j = λ j u j , for each j = 1 , . . . , J . For each x in R J , there are unique coeﬃcients a j so that x = J (cid:88) j = 1 a j u j . ( 30 . 59 ) Then let | | x | | = J (cid:88) j = 1 | a j | . ( 30 . 60 ) Lemma 30 . 16 The expression | | · | | in Equation ( 30 . 60 ) deﬁnes a norm on R J . If ρ ( B ) < 1 , then the aﬃne operator T is sc , with respect to this norm . It is known that , for any square matrix B and any (cid:15) > 0 , there is a vector norm for which the induced matrix norm satisﬁes | | B | | ≤ ρ ( B ) + (cid:15) . There - fore , if B is an arbitrary square matrix with ρ ( B ) < 1 , there is a vector norm with respect to which B is sc . 30 . 11 Exercises Ex . 30 . 1 Show that a strict contraction can have at most one ﬁxed point . Ex . 30 . 2 Let T be sc . Show that the sequence { T k x 0 } is a Cauchy se - quence . Hint : consider | | x k − x k + n | | ≤ | | x k − x k + 1 | | + . . . + | | x k + n − 1 − x k + n | | , ( 30 . 61 ) and use | | x k + m − x k + m + 1 | | ≤ r m | | x k − x k + 1 | | . ( 30 . 62 ) Since { x k } is a Cauchy sequence , it has a limit , say ˆ x . Let e k = ˆ x − x k . Show that { e k } → 0 , as k → + ∞ , so that { x k } → ˆ x . Finally , show that T ˆ x = ˆ x . Ex . 30 . 3 Suppose that we want to solve the equation x = 1 2 e − x . 376 CHAPTER 30 . OPERATORS Let Tx = 12 e − x for x in R . Show that T is a strict contraction , when re - stricted to non - negative values of x , so that , provided we begin with x 0 > 0 , the sequence { x k = Tx k − 1 } converges to the unique solution of the equa - tion . Hint : use the mean value theorem from calculus . Ex . 30 . 4 Prove Lemma 30 . 13 . Ex . 30 . 5 Prove Lemma 30 . 16 . Ex . 30 . 6 Show that , if the operator T is α - av and 1 > β > α , then T is β - av . Ex . 30 . 7 Prove Lemma 30 . 5 . Ex . 30 . 8 Prove Corollary 30 . 2 . Ex . 30 . 9 Prove Proposition 30 . 3 . Ex . 30 . 10 Show that , if B is a linear av operator , then | λ | < 1 for all eigenvalues λ of B that are not equal to one . Ex . 30 . 11 An operator Q : R J → R J is said to be quasi - non - expansive ( qne ) if Q has ﬁxed points , and , for every ﬁxed point z of Q and for every x , we have (cid:107) z − x (cid:107) ≥ (cid:107) z − Qx (cid:107) . We say that an operator R : R J → R J is quasi - averaged if , for some operator Q that is qne with respect to the two - norm and for some α in the interval ( 0 , 1 ) , we have R = ( 1 − α ) I + αQ . Show that the KMO Theorem 30 . 2 holds when averaged operators are re - placed by quasi - averaged operators . Chapter 31 Saddle - Point Problems and Algorithms 31 . 1 Chapter Summary We ﬁrst encountered saddle - point problems in our discussion of convex programming . The ﬁrst form of the Karush - Kuhn - Tucker Theorem 11 . 4 shows that the solution of the convex programming problem can be found by solving for a saddle point of the Lagrangian . In this chapter we consider more general saddle - point problems , show that they can be reformulated as variational inequality problems ( VIP ) for monotone functions , and discuss iterative algorithms for their solution . Throughout this chapter the norm is the two - norm . 31 . 2 Monotone Functions We begin with some deﬁnitions . Deﬁnition 31 . 1 An operator T : R J → R J is monotone if (cid:104) Tx − Ty , x − y (cid:105) ≥ 0 , for all x and y . Deﬁnition 31 . 2 An operator T : R J → R J is strongly monotone if (cid:104) Tx − Ty , x − y (cid:105) ≥ ν (cid:107) x − y (cid:107) 2 , for all x and y . 377 378 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS Let f : R J → R be convex and diﬀerentiable . Then the operator T = ∇ f is monotone . If f ( x ) is convex , but not diﬀerentiable , then B ( x ) = ∂f ( x ) is a monotone set - valued function ; we shall discuss set - valued functions in another chapter . Not all monotone operators are gra - dient operators , as Exercise 31 . 1 will show . In fact , if A is a non - zero , skew - symmetric matrix , then Tx = Ax is a monotone operator , but is not a gradient operator . It is easy to see that if N is ne , then I − N is monotone . Deﬁnition 31 . 3 An operator G : R J → R J is weakly ν - inverse strongly monotone if (cid:104) G ( x ) , x − y (cid:105) ≥ ν (cid:107) G ( x ) (cid:107) 2 , ( 31 . 1 ) whenever Gy = 0 . 31 . 3 The Split - Feasibility Problem The split - feasibility problem ( SFP ) is the following : ﬁnd x in C with Ax in Q , where A is an I by J matrix , and C and Q nonempty , closed convex sets in R J and R I , respectively . The CQ algorithm [ 50 , 51 ] has the iterative step x k + 1 = P C ( I − γA T ( I − P Q ) A ) x k . ( 31 . 2 ) For 0 < γ < 2 ρ ( A T A ) , the sequence { x k } converges to a minimizer , over x in C , of the convex function f ( x ) = 1 2 (cid:107) P Q Ax − Ax (cid:107) 2 , whenever such minimizers exist . From Theorem 13 . 3 we know that the gradient of f ( x ) is ∇ f ( x ) = A T ( I − P Q ) Ax , so the iteration in Equation ( 31 . 2 ) can be written as x k + 1 = P C ( I − γ ∇ f ) x k . ( 31 . 3 ) The limit x ∗ of the sequence { x k } satisﬁes the inequality (cid:104)∇ f ( x ∗ ) , c − x ∗ (cid:105) ≥ 0 , ( 31 . 4 ) for all c in C . 31 . 4 . THE VARIATIONAL INEQUALITY PROBLEM 379 31 . 4 The Variational Inequality Problem Now let G be any monotone operator on R J . The variational inequality problem ( VIP ) , with respect to G and C , denoted VIP ( G , C ) , is to ﬁnd an x ∗ in C such that (cid:104) G ( x ∗ ) , c − x ∗ (cid:105) ≥ 0 , for all c in C . The form of the CQ algorithm suggests that we consider solving the VIP ( G , C ) using the following iterative scheme : x k + 1 = P C ( I − γG ) x k . ( 31 . 5 ) The sequence { x k } solves the VIP ( G , C ) whenever there are solutions , if G is ν - ism and 0 < γ < 2 ν ; this is sometimes called Dolidze’s Theorem , and is proven in [ 51 ] ( see also [ 119 ] ) . A good source for related algorithms is the paper by Censor , Iusem and Zenios [ 78 ] . Recall that G is strongly monotone if (cid:104) G ( x ) − G ( y ) , x − y (cid:105) ≥ ν (cid:107) x − y (cid:107) 2 , for all x and y , and G is L - Lipschitz if (cid:107) G ( x ) − G ( y ) (cid:107) ≤ L (cid:107) x − y (cid:107) . In [ 78 ] the authors mention that it has been shown that , if G is strongly monotone and L - Lipschitz , then the iteration in Equation ( 31 . 5 ) converges to a solution of VIP ( G , C ) whenever γ ∈ ( 0 , 2 ν / L 2 ) . Then we have a strict contraction mapping , a ﬁxed point necessarily exists , and the result follows . But under these conditions , I − γG is also averaged , so the result , except for the existence of ﬁxed points , follows from Dolidze’s Theorem . When G is not ism , there are other iterative algorithms that can be used ; for example , Korpelevich’s algorithm [ 138 ] has been studied extensively . We discuss this method in the next section . 31 . 5 Korpelevich’s Method for the VIP An operator T on R J is pseudo - monotone if (cid:104) Ty , x − y (cid:105) ≥ 0 implies (cid:104) Tx , x − y (cid:105) ≥ 0 . Any monotone operator is pseudo - monotone . Suppose now that G is L - Lipschitz and pseudo - monotone , but not nec - essarily ism . Let γL < 1 , and S = γG . Korpelevich’s algorithm is then x k + 1 = P C ( x k − Sy k ) , ( 31 . 6 ) 380 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS where y k = P C ( x k − Sx k ) . ( 31 . 7 ) The sequence { x k } converges to a solution of VIP ( G , C ) whenever there are solutions [ 138 , 75 ] . 31 . 5 . 1 The Special Case of C = R J In the special case of the VIP ( G , C ) in which C = R J and P C = I , Kor - pelevich’s algorithm employs the iterative steps x k + 1 = x k − Sy k , ( 31 . 8 ) where y k = x k − Sx k . ( 31 . 9 ) Then we have x k + 1 = ( I − S ( I − S ) ) x k . ( 31 . 10 ) If the operator S ( I − S ) is ν - ism for some ν > 12 , then the sequence { x k } converges to a solution of VIP ( G , R J ) whenever there are solutions , accord - ing to the KM Theorem . Note that z solves the VIP ( G , R J ) if and only if 0 ∈ ∂G ( z ) . The KM Theorem is valid whenever G is weakly ν - ism for some ν > 12 . Therefore , we get convergence of this special case of the Korpele - vich iteration by showing that the operator S ( I − S ) is weakly 1 1 + σ - ism , where σ = γL < 1 . Our assumptions are that T = I − S ( I − S ) , S is pseudo - monotone and σ - Lipschitz , for some σ < 1 , and Tz = z . It follows then that S ( I − S ) z = 0 . From (cid:107) Sz (cid:107) = (cid:107) Sz − S ( I − S ) z (cid:107) ≤ σ (cid:107) z − ( I − S ) z (cid:107) = σ (cid:107) Sz (cid:107) , and the fact that σ < 1 , we conclude that Sz = 0 as well . Lemma 31 . 1 Let x be arbitrary , and z = Tz . Then 2 (cid:104) S ( I − S ) x , x − z (cid:105) ≥ ( 1 − σ 2 ) (cid:107) Sx (cid:107) 2 + (cid:107) S ( I − S ) x (cid:107) 2 . ( 31 . 11 ) Proof : Using Sz = S ( I − S ) z = 0 , we write 2 (cid:104) S ( I − S ) x , x − z (cid:105) = 2 (cid:104) S ( I − S ) x − S ( I − S ) z , x − Sx − z + Sz (cid:105) + 2 (cid:104) S ( I − S ) x , Sx (cid:105) = 2 (cid:104) S ( I − S ) x − S ( I − S ) z , ( I − S ) x − ( I − S ) z (cid:105) + 2 (cid:104) S ( I − S ) x , Sx (cid:105) ≥ 2 (cid:104) S ( I − S ) x , Sx (cid:105) . 31 . 5 . KORPELEVICH’S METHOD FOR THE VIP 381 Also , we have (cid:107) S ( I − S ) x (cid:107) 2 − 2 (cid:104) S ( I − S ) x , Sx (cid:105) + (cid:107) Sx (cid:107) 2 = (cid:107) S ( I − S ) x − Sx (cid:107) 2 ≤ σ 2 (cid:107) Sx (cid:107) 2 . Therefore , 2 (cid:104) S ( I − S ) x , x − z (cid:105) ≥ 2 (cid:104) S ( I − S ) x , Sx (cid:105) ≥ ( 1 − σ 2 ) (cid:107) Sx (cid:107) 2 + (cid:107) S ( I − S ) (cid:107) 2 . It follows from ( 31 . 11 ) and Cauchy’s Inequality that 2 (cid:107) Sx (cid:107)(cid:107) S ( I − S ) x (cid:107) ≥ 2 (cid:104) S ( I − S ) x , Sx (cid:105) ≥ ( 1 − σ 2 ) (cid:107) Sx (cid:107) 2 + (cid:107) S ( I − S ) (cid:107) 2 , so that σ 2 (cid:107) Sx (cid:107) 2 ≥ ( (cid:107) Sx (cid:107) − (cid:107) S ( I − S ) x (cid:107) ) 2 . Therefore , ( 1 + σ ) (cid:107) Sx (cid:107) ≥ (cid:107) S ( I − S ) x (cid:107) . From (cid:104) S ( I − S ) x , x − z (cid:105) ≥ 1 − σ 2 2 (cid:107) Sx (cid:107) 2 + 1 2 (cid:107) S ( I − S ) (cid:107) 2 and (cid:107) Sx (cid:107) 2 ≥ 1 ( 1 + σ ) 2 (cid:107) S ( I − S ) x (cid:107) 2 we get (cid:104) S ( I − S ) x , x − z (cid:105) ≥ 1 1 + σ (cid:107) S ( I − S ) x (cid:107) 2 ; in other words , the operator S ( I − S ) is weakly 1 1 + σ - ism . 31 . 5 . 2 The General Case Now we have x k + 1 = Tx k where S = γG and T = P C ( I − SP C ( I − S ) ) . We assume that Tz = z , so that z solves VIP ( G , C ) . The key Proposition now is the following . Proposition 31 . 1 Let G : C → R J be pseudo - monotone and L - Lipschitz , let σ = γL < 1 , and let S = γG . For any k let y k = P C ( I − S ) x k . Then (cid:107) z − x k (cid:107) 2 − (cid:107) z − x k + 1 (cid:107) 2 ≥ ( 1 − σ 2 ) (cid:107) y k − x k (cid:107) 2 . ( 31 . 12 ) The proof of Proposition 31 . 1 follows that in [ 108 ] . The inequality in ( 31 . 12 ) emerges as a consequence of a sequence of inequalities and equa - tions . We list these results ﬁrst , and then discuss their proofs . For conve - nience , we let w k = x k − Sx k . • 1 ) (cid:104) Sy k , y k − x k + 1 (cid:105) ≥ (cid:104) Sy k , z − x k + 1 (cid:105) . 382 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS • 2 ) (cid:104) Sx k − Sy k , x k + 1 − y k (cid:105) ≥ (cid:104) w k − y k , x k + 1 − y k (cid:105) . • 3 ) (cid:107) z − w k | 2 − (cid:107) w k − x k + 1 (cid:107) 2 ≥ (cid:107) z − x k + 1 (cid:107) 2 . • 4 ) (cid:107) z − w k (cid:107) 2 − (cid:107) w k − x k + 1 (cid:107) 2 = (cid:107) z − x k (cid:107) 2 − (cid:107) x k − x k + 1 (cid:107) 2 + 2 (cid:104) Sy k , z − x k + 1 (cid:105) . • 5 ) (cid:107) z − w k (cid:107) 2 − (cid:107) w k − x k + 1 (cid:107) 2 ≤ (cid:107) z − x k (cid:107) 2 − (cid:107) x k − x k + 1 (cid:107) 2 + 2 (cid:104) Sy k , y k − x k + 1 (cid:105) . • 6 ) −(cid:107) x k − x k + 1 (cid:107) 2 + 2 (cid:104) Sy k , y k − x k + 1 (cid:105) = −(cid:107) y k − x k (cid:107) 2 − (cid:107) y k − x k + 1 (cid:107) 2 + 2 (cid:104) w k − y k , x k + 1 − y k (cid:105) . • 7 ) (cid:107) z − x k (cid:107) 2 − (cid:107) z − x k + 1 (cid:107) 2 ≥ (cid:107) y k − x k (cid:107) 2 + (cid:107) y k − x k + 1 (cid:107) 2 − 2 (cid:104) y k − w k , y k − x k + 1 (cid:105) . • 8 ) 2 (cid:104) y k − w k , y k − x k + 1 (cid:105) ≤ 2 γL (cid:107) y k − x k + 1 (cid:107)(cid:107) y k − x k (cid:107) . • 9 ) 2 γL (cid:107) y k − x k + 1 (cid:107)(cid:107) y k − x k (cid:107) ≤ γ 2 L 2 (cid:107) y k − x k (cid:107) 2 + (cid:107) y k − x k + 1 (cid:107) 2 . • 10 ) 2 γL (cid:107) y k − x k + 1 (cid:107)(cid:107) y k − x k (cid:107) ≤ γL ( (cid:107) y k − x k (cid:107) 2 + (cid:107) y k − x k + 1 (cid:107) 2 ) . • 11 ) (cid:107) z − x k (cid:107) 2 − (cid:107) z − x k + 1 (cid:107) 2 ≥ ( 1 − γ 2 L 2 ) (cid:107) y k − x k (cid:107) 2 . • 12 ) (cid:107) z − x k (cid:107) 2 − (cid:107) z − x k + 1 (cid:107) 2 ≥ ( 1 − γL ) ( (cid:107) y k − x k (cid:107) 2 + (cid:107) y k − x k + 1 (cid:107) 2 ) . Inequality 1 ) follows from the fact that z solves the VIP ( G , C ) and is pseudo - monotone , and x k + 1 is in C . To obtain Inequality 2 ) , add and subtract Sx k on the left side of the inner product in 1 ) and use the fact that y k = P C ( I − S ) x k . To get Inequality 3 ) , expand (cid:107) z − x k + 1 (cid:107) 2 = (cid:107) z − w k + w k − x k + 1 (cid:107) 2 , add and subtract x k + 1 and use the fact that x k + 1 = P C w k . To get Equation 4 ) use w k = x k − Sy k and expand . Then Inequality 5 ) follows from 4 ) using Inequality 1 ) . Equation 6 ) is easy . Inequality 7 ) follows from 3 ) , 5 ) and 6 ) . To get Inequality 8 ) , use w k = x k − Sy k , add and subtract Sx k in the left side of the inner product , and use y k = P C ( I − S ) x k . To get Inequality 9 ) , expand ( γL (cid:107) y k − x k (cid:107) − (cid:107) y k − x k + 1 (cid:107) ) 2 . 31 . 6 . ON SOME ALGORITHMS OF NOOR 383 Then 11 ) is immediate , and the Proposition is proved . To get Inequality 10 ) , expand ( (cid:107) y k − x k (cid:107) − (cid:107) y k − x k + 1 (cid:107) ) 2 . Then 12 ) is immediate . We shall use 12 ) in a moment . From Inequality ( 31 . 12 ) , we learn that the sequence { (cid:107) z − x k (cid:107) } is de - creasing , and so the sequence (cid:107) y k − x k (cid:107) } converges to zero . From 12 ) we learn that the sequence { (cid:107) y k − x k + 1 (cid:107) } converges to zero . We know that (cid:107) x k − x k + 1 (cid:107) 2 = (cid:107) x k − y k + y k − x k + 1 (cid:107) 2 = (cid:107) x k − y k (cid:107) 2 + (cid:107) y k − x k + 1 (cid:107) 2 + 2 (cid:104) x k − y k , y k − x k + 1 (cid:105) ≤ (cid:107) x k − y k (cid:107) 2 + (cid:107) y k − x k + 1 (cid:107) 2 + 2 (cid:107) x k − y k (cid:107)(cid:107) x k + 1 − y k (cid:107) , so it follows that { (cid:107) x k − x k + 1 (cid:107) } converges to zero . The sequence { x k } is bounded ; let x ∗ be a cluster point . Then x ∗ is a ﬁxed point ; that is x ∗ = P C ( x ∗ − S ( I − S ) x ∗ ) , so x ∗ solves the VIP ( G , C ) and we can replace z with x ∗ in all the lines above . It follows that { x k } converges to x ∗ . Therefore , the Korpelevich iteration converges whenever there is a solution of the VIP ( G , C ) . We saw that in the special case of P C = I , the operator S ( I − S ) is weakly ν - ism ; it does not appear to be true in the general case that weak ism plays a role . 31 . 6 On Some Algorithms of Noor In this section I comment on two algorithms that appear in the papers of Noor . 31 . 6 . 1 My Conjecture We saw that for the case of C = R J the operator T = I − S ( I − S ) generates a sequence that converges to a ﬁxed point of T . I suspected that the operator P = ( I − S ) 2 = T − S might also work . More generally , I conjectured that the operator Px = P C ( P C ( x − Sx ) − SP C ( x − Sx ) ) = ( P C ( I − S ) ) 2 x ( 31 . 13 ) would work for the general case . Noor [ 168 , 169 , 170 ] considers this and related methods , but does not provide details for this particular algorithm . The conjecture is false , but I can at least show that z = Pz if and only if z solves VIP ( G , C ) . 384 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS Proposition 31 . 2 We have z = Pz if and only if z solves VIP ( G , C ) . Proof : One way is clear . So assume that z = Pz . Let y = P C ( z − Sz ) , so that z = P C ( y − Sy ) . Then for all c ∈ C we have (cid:104) z − y + Sy , c − z (cid:105) ≥ 0 , and (cid:104) y − z + Sz , c − y (cid:105) ≥ 0 . Therefore , (cid:104) Sy , y − z (cid:105) ≥ (cid:107) y − z (cid:107) 2 , and −(cid:104) Sz , y − z (cid:105) ≥ (cid:107) y − z (cid:107) 2 . Adding , we get σ (cid:107) y − z (cid:107) 2 ≥ (cid:107) Sy − Sz (cid:107) (cid:107) y − z (cid:107) ≥ (cid:104) Sy − Sz , y − z (cid:105) ≥ 2 (cid:107) y − z (cid:107) 2 , from which we conclude that y = z . Unfortunately , this algorithm , which is Algorithm 3 . 6 in Noor [ 169 ] , fails to converge , in general , as the following example shows . Let S be the operator on R 2 given by multiplication by the matrix S = (cid:20) 0 a − a 0 (cid:21) , for some a ∈ ( 0 , 1 ) . The operator S is then monotone and a - Lipschitz con - tinuous . With C = R 2 , the variational inequality problem is then equiva - lent to ﬁnding a zero of S . Note that Sz = 0 if and only if z = 0 . The Korpelevich iteration in this case is x k + 1 = Tx k = ( I − S ( I − S ) ) x k . Noor’s Algorithm 3 . 6 now has the iterative step x k + 1 = Px k = ( I − S ) 2 x k . The operator T is then multiplication by the matrix T = (cid:20) 1 − a 2 − a a 1 − a 2 (cid:21) , and the operator P is multiplication by the matrix P = (cid:20) 1 − a 2 − 2 a 2 a 1 − a 2 (cid:21) . 31 . 7 . THE SPLIT VARIATIONAL INEQUALITY PROBLEM 385 For any x ∈ R 2 we have (cid:107) Tx (cid:107) 2 = ( ( 1 − a 2 ) 2 + a 2 ) (cid:107) x (cid:107) 2 < (cid:107) x (cid:107) 2 , for all x (cid:54) = 0 , while (cid:107) Px (cid:107) 2 = ( ( 1 − a 2 ) 2 + 4 a 2 ) (cid:107) x (cid:107) 2 = ( 1 + a 2 ) 2 (cid:107) x (cid:107) 2 . This proves that the sequence x k + 1 = Px k does not converge , generally . 31 . 7 The Split Variational Inequality Prob - lem The split variational inequality problem ( SVIP ) is the following : ﬁnd x ∗ in C such that (cid:104) f ( x ∗ ) , c − x ∗ (cid:105) ≥ 0 , ( 31 . 14 ) for all c ∈ C , and (cid:104) g ( Ax ∗ ) , q − Ax ∗ (cid:105) ≥ 0 , ( 31 . 15 ) for all q ∈ Q . In [ 74 ] the authors present an iterative algorithm for solving the SVIP . The iterative step is x k + 1 = Sx k , where S = U ( I + γA T ( T − I ) A ) , U = P C ( I − λf ) , and T = P Q ( I − λg ) . It is easy to show that x ∗ satisﬁes Equation ( 31 . 14 ) if and only if x ∗ is a ﬁxed point of U , and Ax ∗ satisﬁes Equation ( 31 . 15 ) if and only if Ax ∗ is a ﬁxed point of T . We have the following convergence theorem for the sequence { x k } . Theorem 31 . 1 Let f be ν 1 - ism , g be ν 2 - ism , ν = min { ν 1 , ν 2 } , λ ∈ ( 0 , 2 α ) , and γ ∈ ( 0 , 1 / L ) , where L is the spectral radius of A T A . If the SVIP has solutions , then the sequence { x k } converges to a solution of the SVIP . Take λ < 2 ν . Then the operators I − λf and I − λg are δ - av , for δ = λ 2 ν < 1 . The operator P Q is ﬁrmly non - expansive , so is 12 - av . Then the operator T = P Q ( I − λg ) is φ - av , with φ = δ + 12 . The following lemma is key to the proof of the theorem . 386 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS Lemma 31 . 2 If T is φ - av , for some φ ∈ ( 0 , 1 ) , then the operator A T ( I − T ) A is 12 φL - ism . Proof : We have (cid:104) A T ( I − T ) Ax − A T ( I − T ) Ay , x − y (cid:105) = (cid:104) ( I − T ) Ax − ( I − T ) Ay , Ax − Ay (cid:105) . Since I − T is 12 φ - ism , we have (cid:104) ( I − T ) Ax − ( I − T ) Ay , Ax − Ay (cid:105) ≥ 1 2 φ (cid:107) ( I − T ) Ax − ( I − T ) Ay (cid:107) 2 . From (cid:107) A T ( I − T ) Ax − A T ( I − T ) Ay (cid:107) 2 ≤ L (cid:107) ( I − T ) Ax − ( I − T ) Ay (cid:107) 2 , it follows that (cid:104) ( I − T ) Ax − ( I − T ) Ay , Ax − Ay (cid:105) ≥ 1 2 φL (cid:107) A T ( I − T ) Ax − A T ( I − T ) Ay (cid:107) 2 . Proof of the Theorem : Assume that z is a solution of the SVIP . The operator γA T ( I − T ) A is 1 2 γφL - ism . The operator V will be averaged if γφL < 1 , or γ < 1 φL = 2 ( δ + 1 ) L . ( 31 . 16 ) If γ ≤ 1 L , then the inequality ( 31 . 16 ) holds for all choices of λ < 2 α . In similar iterative algorithms , such as the CQ algorithm and the Landwe - ber algorithm ( see [ 50 , 51 ] ) , the upper bound on γ is 2 L . We can allow γ to approach 2 L here , but only by making δ approach zero , that is , only by taking λ near zero . Since U is also averaged , the operator S is averaged . Since the inter - section of Fix ( U ) and Fix ( V ) is not empty , this intersection equals Fix ( S ) . By the Krasnosel’skii - Mann Theorem , the iteration x k + 1 = Sx k converges to a ﬁxed point x ∗ of S , which is then a ﬁxed point of both U and V . From V ( x ∗ ) = x ∗ it follows that A T ( T − I ) Ax ∗ = 0 . We show that ( T − I ) Ax ∗ = 0 . We know that T ( Ax ∗ ) = Ax ∗ + w , where A T w = 0 . Also T ( Az ) = Az , since z solves the SVIP . Therefore , we have (cid:107) T ( Ax ∗ ) − T ( Az ) (cid:107) 2 = (cid:107) Ax ∗ − Az (cid:107) 2 + (cid:107) w (cid:107) 2 ; but T is non - expansive , so w = 0 and ( T − I ) Ax ∗ = 0 . 31 . 8 . SADDLE POINTS 387 31 . 8 Saddle Points As the title of [ 138 ] indicates , the main topic of the paper is saddle points . The main theorem is about convergence of an iterative method for ﬁnding saddle points . The saddle - point problem can be turned into a case of the variational inequality problem , which is why the paper contains the theorem on convergence of an iterative algorithm for the VIP that we have already discussed . The increased complexity of Korpelevich’s algorithm is not needed if our goal is to minimize a convex function f ( x ) over a closed convex set C , when ∇ f is L - Lipschitz . In that case , the operator 1 L ∇ f is ne , from which it can be shown that it must be fne . Then we can use the averaged operator T = P C ( I − γ ∇ f ) , for 0 < γ < 2 L . Similarly , we don’t need Korpelevich to solve z = Nz , for non - expansive N ; we can use the averaged operator T = ( 1 − α ) I + αN . However , for saddle - point problems , Korpelevich’s method is useful . 31 . 8 . 1 Notation and Basic Facts Let C ⊆ R J and Q ⊆ R I be closed convex sets . Say that u ∗ = ( x ∗ , y ∗ ) ∈ U is a saddle - point for the function f ( x , y ) : U = C × Q → R if , for all u = ( x , y ) ∈ U , we have f ( x ∗ , y ) ≤ f ( x ∗ , y ∗ ) ≤ f ( x , y ∗ ) . ( 31 . 17 ) We make the usual assumptions that f ( x , y ) is convex in x and concave in y , and that the partial derivatives f x ( x , y ) and f y ( x , y ) are L - Lipschitz . Denote by U ∗ the set of all saddle points u ∗ . It can be shown that u ∗ = ( x ∗ , y ∗ ) is a saddle point for f ( x , y ) if and only if (cid:104) f x ( x ∗ , y ∗ ) , x − x ∗ (cid:105) ≥ 0 , for all x ∈ C , and (cid:104) f y ( x ∗ , y ∗ ) , y − y ∗ (cid:105) ≤ 0 , for all y ∈ Q . 31 . 8 . 2 The Saddle - Point Problem as a VIP Deﬁne T : U → R J × R I by Tu = ( f x ( x , y ) , − f y ( x , y ) ) . Then u ∗ ∈ U ∗ if and only if (cid:104) Tu ∗ , u − u ∗ (cid:105) ≥ 0 , 388 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS for all u ∈ U . The operator T is monotone and L - Lipschitz . Therefore , we can ﬁnd saddle points by applying the Korpelevich method for ﬁnding solutions of the VIP . Note that if T is a gradient operator , then we must have f ( x , y ) = h ( x ) − g ( y ) , where h and g are convex functions . Then ( x ∗ , y ∗ ) is a saddle point if and only if x ∗ minimizes h ( x ) over x ∈ C and y ∗ minimizes g ( y ) over y ∈ Q . In this case , the saddle point can be found by solving two independent minimization problems , and Korpelevich’s algorithm is not needed . 31 . 8 . 3 Example : Convex Programming In convex programming ( CP ) we want to minimize a convex function f : R J → R over all x ≥ 0 such that g ( x ) ≤ 0 , where g is also convex . The Lagrangian function is L ( x , y ) = f ( x ) + (cid:104) y , g ( x ) (cid:105) . ( 31 . 18 ) When the problem is super - consistent , we know that x ∗ is a solution of CP if and only if there is y ∗ ≥ 0 such that L ( x ∗ , y ) ≤ L ( x ∗ , y ∗ ) ≤ L ( x , y ∗ ) . ( 31 . 19 ) 31 . 8 . 4 Example : Linear Programming The primary problem of linear programming , in canonical form , denoted PC , is to minimize z = c T x , subject to x ≥ 0 and A T x ≥ b . The Lagrangian is now L ( x , y ) = c T x + y T ( b − A T x ) = c T x + b T y − y T A T x . ( 31 . 20 ) Therefore , x ∗ is a solution if and only if there is y ∗ ≥ 0 such that ( 31 . 19 ) holds for L ( x , y ) given by Equation ( 31 . 20 ) . 31 . 8 . 5 Example : Game Theory In two - person zero - sum matrix games , the entries A mn of the matrix A are the payoﬀs from Player Two ( P2 ) to Player One ( P1 ) when P1 plays strategy m and P2 plays strategy n . Optimal randomized strategies p ∗ and q ∗ for players P1 and P2 , respectively , are probability vectors that satisfy the saddle - point condition f ( q ∗ , p ) ≤ f ( q ∗ , p ∗ ) ≤ f ( q , p ∗ ) , ( 31 . 21 ) where f ( q , p ) = p T Aq for probability vectors p and q . 31 . 9 . EXERCISES 389 We could attempt to ﬁnd the optimal randomized strategies p ∗ and q ∗ using Korpelevich’s saddle point method ; however , the constraint that the p and q be probability vectors may be diﬃcult to implement in the iterative algorithm . There is another way . A standard approach to showing that optimal randomized strategies exist is to convert the problem into a linear programming problem . Specif - ically , we ﬁrst modify A so that all the entries are non - negative . Then we take b and c to have all entries equal to one . We then minimize z = c T x over all x ≥ 0 with A T x ≥ b . Because the entries of A are non - negative , both PC and DC have feasible solutions , and therefore have optimal solu - tions , which we denote by x ∗ and y ∗ . It follows that µ = c T x ∗ = b T y ∗ , so that p ∗ = 1 µ x ∗ and q ∗ = 1 µ y ∗ are probabilities . They are then the optimal randomized strategies . From this , we see that we can reformulate the search for the game - theory saddle point as a search for a saddle point of the Lagrangian for the linear programming problem . Now the constraints are only that x ≥ 0 and y ≥ 0 . 31 . 9 Exercises Ex . 31 . 1 Let T : R 2 → R 2 be the operator deﬁned by T ( x , y ) = ( − y , x ) . Show that T is a monotone operator , but is not a gradient operator . 390 CHAPTER 31 . SADDLE - POINT PROBLEMS AND ALGORITHMS Chapter 32 Set - Valued Functions in Optimization 32 . 1 Chapter Summary Set - valued mappings play an important role in a number of optimization problems . We examine several of those problems in this chapter . We discuss iterative algorithms for solving these problems and prove convergence . 32 . 2 Notation and Deﬁnitions A function f : R J → [ −∞ , + ∞ ] is proper if there is no x with f ( x ) = −∞ and some x with f ( x ) < + ∞ . The eﬀective domain of f , denoted dom ( f ) , is the set of all x for which f ( x ) is ﬁnite . If f is a proper convex function on R J , then the sub - diﬀerential ∂f ( x ) , deﬁned to be the set ∂f ( x ) = { u | f ( z ) ≥ f ( x ) + (cid:104) u , z − x (cid:105) for all z } , ( 32 . 1 ) is a closed convex set , and nonempty for every x in the interior of dom ( f ) . This is a consequence of applying the Support Theorem to the epi - graph of f . We say that f is diﬀerentiable at x if ∂f ( x ) is a singleton set , in which case we have ∂f ( x ) = { ∇ f ( x ) } . If C is a nonempty closed convex subset of R J , then N C ( x ) , the normal cone to C at x , is the empty set , if x is not a member of C , and if x ∈ C , then N C ( x ) = { u | (cid:104) u , c − x (cid:105) ≤ 0 , for all c ∈ C } . ( 32 . 2 ) Let f ( x ) = ι C ( x ) , the indicator function of the set C , which is + ∞ for 391 392 CHAPTER 32 . SET - VALUED FUNCTIONS IN OPTIMIZATION x not in C and zero for x in C . Then ∂ι C ( x ) = N C ( x ) . ( 32 . 3 ) Most of the time , but not always , we have ∂ ( f + g ) ( x ) = ∂f ( x ) + ∂g ( x ) , Consequently , most of the time , but not always , we have N A ∩ B ( x ) = N A ( x ) ∩ N B ( x ) ; ( 32 . 4 ) see Exercise ( 32 . 1 ) . In order for Equation ( 32 . 4 ) to hold , some additional conditions are needed ; for example , it is enough to know that the set A ∩ B has a nonempty interior ( see [ 23 ] , p . 56 , Exercise 10 ) . The mapping that takes each x to ∂f ( x ) is a set - valued function , or multi - valued function . The role that set - valued functions play in optimiza - tion is the subject of this chapter . It is common to use the notation 2 R J to denote the collection of all subsets of R J . 32 . 3 Basic Facts If x ∗ minimizes the function f ( x ) over all x in R J , then 0 ∈ ∂f ( x ∗ ) ; if f is diﬀerentiable , then ∇ f ( x ∗ ) = 0 . The vector x ∗ minimizes f ( x ) over x in C if and only if x ∗ minimizes the function f ( x ) + ι C ( x ) over all x in R J , and so if and only if 0 ∈ ∂f ( x ∗ ) + N C ( x ∗ ) , which is equivalent to (cid:104) u , c − x ∗ (cid:105) ≥ 0 , ( 32 . 5 ) for all u in ∂f ( x ∗ ) and all c in C . If f is diﬀerentiable at x ∗ , then this becomes (cid:104)∇ f ( x ∗ ) , c − x ∗ (cid:105) ≥ 0 , ( 32 . 6 ) for all c in C . Similarly , for each ﬁxed x , y minimizes the function f ( t ) + 1 2 (cid:107) x − t (cid:107) 2 2 if and only if 0 ∈ y − x + ∂f ( y ) , or x ∈ y + ∂f ( y ) . Then we write y = prox f x . If C is a nonempty closed convex subset of R J and f ( x ) = ι C ( x ) , then prox f ( x ) = P C x . 32 . 4 . MONOTONE SET - VALUED FUNCTIONS 393 32 . 4 Monotone Set - Valued Functions Recall that an operator T : R J → R J is monotone if (cid:104) Tx − Ty , x − y (cid:105) ≥ 0 , for all x and y . A set - valued function B : R J → 2 R J is monotone if , for every x and y , and every u ∈ B ( x ) and v ∈ B ( y ) we have (cid:104) u − v , x − y (cid:105) ≥ 0 . A monotone ( possibly set - valued ) function B is a maximal monotone opera - tor if the domain of B cannot be enlarged without the loss of the monotone property . Let f : R J → R be convex and diﬀerentiable . Then the operator T = ∇ f is monotone . If f ( x ) is convex , but not diﬀerentiable , then B ( x ) = ∂f ( x ) is a monotone set - valued function . If A is a non - zero , skew - symmetric matrix , then Tx = Ax is a monotone operator , but is not a gradient operator . 32 . 5 Resolvents Let B : R J → 2 R J be a set - valued mapping . If B is monotone , then x ∈ z + B ( z ) and x ∈ y + B ( y ) implies that z = y , since then x − z ∈ B ( z ) and x − y ∈ B ( y ) , so that 0 ≤ (cid:104) ( x − z ) − ( x − y ) , z − y (cid:105) = −(cid:107) z − y (cid:107) 22 . Consequently , the resolvent operator for B , deﬁned by J B = ( I + B ) − 1 is single - valued , where J B ( x ) = z means that x ∈ z + B ( z ) . If B ( z ) = N C ( z ) for all z , then z = J B ( x ) if and only if z = P C ( x ) , the orthogonal projection of x onto C ; so we have J ∂ι C = J N C = P C = prox ι C . We know that z = prox f x if and only if x − z ∈ ∂f ( z ) , and so if and only if x ∈ ( I + ∂f ) z or , equivalently , z = J ∂f x . Therefore , J ∂f = prox f . As we shall see shortly , this means that prox f is fne . The following theorem is helpful in proving convergence of iterative ﬁxed - point algorithms [ 86 , 49 , 87 ] . 394 CHAPTER 32 . SET - VALUED FUNCTIONS IN OPTIMIZATION Theorem 32 . 1 An operator T : R J → R J is ﬁrmly non - expansive if and only if T = J B for some ( possibly set - valued ) maximal monotone function B . We sketch the proof here . Showing that J B is fne when B is monotone is not diﬃcult . To go the other way , we suppose that T is fne and deﬁne B ( x ) = T − 1 { x } − x , where y ∈ T − 1 { x } means Ty = x . Then J B = T . That this function B is monotone follows fairly easily from the fact that T = J B is fne . 32 . 6 The Split Monotone Variational Inclu - sion Problem Let B 1 : R J → 2 R J and B 2 : R I → 2 R I be set - valued mappings , A : R J → R I a real matrix , and f : R J → R J and g : R I → R I single - valued operators . Using these functions we can pose the split monotone variational inclusion problem ( SMVIP ) . The SMVIP is to ﬁnd x ∗ in R J such that 0 ∈ f ( x ∗ ) + B 1 ( x ∗ ) , ( 32 . 7 ) and 0 ∈ g ( Ax ∗ ) + B 2 ( Ax ∗ ) . ( 32 . 8 ) Let C be a closed , nonempty , convex set in R J . The normal cone to C at z is deﬁned to be the empty set if z is not in C , and , if z ∈ C , to be the set N C ( z ) given by N C ( z ) = { u | (cid:104) u , c − z (cid:105) ≤ 0 , for all c ∈ C } . ( 32 . 9 ) Suppose that C ⊆ R J and Q ⊆ R I are closed nonempty convex sets . If we let B 1 = N C and B 2 = N Q , then the SMVIP becomes the split variational inequality problem ( SVIP ) : ﬁnd x ∗ in C such that (cid:104) f ( x ∗ ) , c − x ∗ (cid:105) ≥ 0 , ( 32 . 10 ) for all c ∈ C , and (cid:104) g ( Ax ∗ ) , q − Ax ∗ (cid:105) ≥ 0 , ( 32 . 11 ) for all q ∈ Q . 32 . 7 . SOLVING THE SMVIP 395 32 . 7 Solving the SMVIP We can solve the SMVIP in a way similar to that used to solve the SVIP , by modifying the CGR algorithm . Now we deﬁne S = U ( I − γA T ( T − I ) A ) , where U = J λB 1 ( I − λf ) , and T = J λB 2 ( I − λg ) , for λ > 0 . It is easy to show that x ∗ satisﬁes Equation ( 32 . 7 ) if and only if x ∗ is a ﬁxed point of U and Ax ∗ satisﬁes Equation ( 32 . 8 ) if and only if Ax ∗ is a ﬁxed point of T . We have assumed that there is a z that solves the SMVIP , so it follows that z is a ﬁxed point of both U and V , where V is given by V = ( I + γA T ( T − I ) A ) . Under the assumption that both B 1 and B 2 are maximal monotone set - valued mappings , we can conclude that both J λB 1 and J λB 2 are fne oper - ators , and so are av operators . It follows that both U and V are averaged , as well , so that S is averaged . Now we can argue just as we did in the proof of convergence of the algorithm for the SVIP that the sequence { S k x 0 } converges to a ﬁxed point of S , which is then a solution of the SMVIP . 32 . 8 Special Cases of the SMVIP There are several problems that can be formulated and solved as special cases of the SMVIP . One example is the split minimization problem . 32 . 8 . 1 The Split Minimization Problem Let f : R J → R and g : R I → R be lower semicontinuous , convex functions , and C and Q nonempty , closed , convex subsets of R J and R I , respectively . The split minimization problem is to ﬁnd x = x ∗ ∈ C that minimizes f ( x ) over all x ∈ C , and such that q = Ax ∗ ∈ Q minimizes g ( q ) over all q ∈ Q . 32 . 9 Exercises Ex . 32 . 1 In R 2 , let A and B be the closed circles with radius one centered at ( − 1 , 0 ) and ( 1 , 0 ) , respectively . Show that N A ∩ B ( ( 0 , 0 ) ) = R 2 , while N A ( ( 0 , 0 ) ) + N B ( ( 0 , 0 ) ) is the x - axis . 396 CHAPTER 32 . SET - VALUED FUNCTIONS IN OPTIMIZATION Chapter 33 Convex Feasibility and Related Problems 33 . 1 Chapter Summary Constraints on x often take the form of inclusion in certain convex sets . These sets may be related to the measured data , or incorporate other as - pects of x known a priori . There are several related problems that then arise . Iterative algorithms based on orthogonal projection onto convex sets are then employed to solve these problems . 33 . 1 . 1 The Convex Feasibility Problem Such constraints can often be formulated as requiring that the desired x lie within the intersection C of a ﬁnite collection { C 1 , . . . , C I } of convex sets . When the number of convex sets is large and the intersection C small , any member of C may be suﬃcient for our purposes . Finding such x is the convex feasibility problem ( CFP ) . 33 . 1 . 2 Constrained Optimization When the intersection C is large , simply obtaining an arbitrary member of C may not be enough ; we may require , in addition , that the chosen x optimize some cost function . For example , we may seek the x in C that minimizes | | x − x 0 | | 22 . This is constrained optimization . 397 398 CHAPTER 33 . CONVEX FEASIBILITY AND RELATED PROBLEMS 33 . 1 . 3 Proximity Function Minimization When the collection of convex sets has empty intersection , we may minimize a proximity function , such as f ( x ) = 1 2 I I (cid:88) i = 1 | | P C i x − x | | 22 . ( 33 . 1 ) When the set C is non - empty , the smallest value of f ( x ) is zero , and is attained at any member of C . When C is empty , the minimizers of f ( x ) , when they exist , provide a reasonable approximate solution to the CFP . According to Theorem 13 . 3 , the function g ( x ) = 1 2 (cid:107) x − P C x (cid:107) 22 is diﬀerentiable and ∇ g ( x ) = x − P C x . If C = { 0 } , then g ( x ) = 12 (cid:107) x (cid:107) 22 has gradient ∇ g ( x ) = x . Just as the function h ( t ) = t 2 is diﬀerentiable for all real t , but the function f ( t ) = | t | is not diﬀerentiable at t = 0 , the function h 0 ( x ) = (cid:107) x (cid:107) 2 is not diﬀerentiable at x = 0 and the function h ( x ) = (cid:107) x − P C x (cid:107) 2 is not diﬀerentiable at boundary points of the set C . We have the following theorem . Theorem 33 . 1 For any x in the interior of C , the gradient of the function h ( x ) = (cid:107) x − P C x (cid:107) 2 is ∇ h ( x ) = 0 . For any x outside C the gradient is ∇ h ( x ) = x − P C x (cid:107) x − P C x (cid:107) 2 . For x on the boundary of C , however , the function h ( x ) is not diﬀerentiable ; any vector u in the normal cone N C ( x ) with (cid:107) u (cid:107) 2 ≤ 1 is in ∂h ( x ) . Proof : The function g ( t ) = √ t is diﬀerentiable for all positive values of t , so the function h ( x ) = (cid:16) (cid:107) x − P C x (cid:107) 22 (cid:17) 1 / 2 is diﬀerentiable whenever x is not in C . Using the Chain Rule , we get ∇ h ( x ) = x − P C x (cid:107) x − P C x (cid:107) 2 . 33 . 1 . CHAPTER SUMMARY 399 For x in the interior of C , the function h ( x ) is identically zero in a neigh - borhood of x , so that the gradient is zero there . The only diﬃcult case is when x is on the boundary of C . First , we assume that u ∈ N C ( x ) and (cid:107) u (cid:107) 2 = 1 . Then we must show that (cid:104) u , y − x (cid:105) ≤ (cid:107) y − P C y (cid:107) 2 . If y is such that the inner product is non - positive , then the inequality is clearly true . So we focus on those y for which the inner product is positive , which means that y lies in the half - space bounded by the hyperplane H , where H = { z | (cid:104) u , z (cid:105) ≥ (cid:104) u , x (cid:105) } . The vector y − P H y is the orthogonal projection of the vector y − x onto the line containing y and P H y , which also contains the vector u . Therefore , y − P H y = (cid:104) u , y − x (cid:105) u , and (cid:107) y − P C y (cid:107) 2 ≥ (cid:107) y − P H y (cid:107) 2 = (cid:104) u , y − x (cid:105) . Now we prove the converse . We assume now that (cid:104) u , y − x (cid:105) ≤ (cid:107) y − P C y (cid:107) 2 , for all y , and show that (cid:107) u (cid:107) 2 ≤ 1 and u ∈ N C ( x ) . If u is not in N C ( x ) , then there is a y ∈ C with (cid:104) u , y − x (cid:105) > 0 , but (cid:107) y − P C y (cid:107) 2 = 0 . Finally , we must show that (cid:107) u (cid:107) 2 ≤ 1 . Let y = x + u , so that P C y = x . Then (cid:104) u , y − x (cid:105) = (cid:104) u , u (cid:105) = (cid:107) u (cid:107) 22 , while (cid:107) y − P C y (cid:107) 2 = (cid:107) y − x (cid:107) 2 = (cid:107) u (cid:107) 2 . It follows that (cid:107) u (cid:107) 2 ≤ 1 . We are used to thinking of functions that are not diﬀerentiable as lacking something . From the point of view of subgradients , not being diﬀerentiable means having too many of something . The gradient of the function f ( x ) in Equation ( 33 . 1 ) is ∇ f ( x ) = x − 1 I I (cid:88) i = 1 P C i x . ( 33 . 2 ) 400 CHAPTER 33 . CONVEX FEASIBILITY AND RELATED PROBLEMS Therefore , a gradient descent approach to minimizing f ( x ) has the iterative step x k + 1 = x k − γ k (cid:16) x k − 1 I I (cid:88) i = 1 P C i x k (cid:17) = ( 1 − γ k ) x k + γ k (cid:16) 1 I I (cid:88) i = 1 P C i x k (cid:17) . ( 33 . 3 ) This is sometimes called the relaxed averaged projections algorithm . As we shall see shortly , the choice of γ k = 1 is suﬃcient for convergence . 33 . 1 . 4 The Moreau Envelope and Proximity Opera - tors Following Combettes and Wajs [ 88 ] , we say that the Moreau envelope of index γ > 0 of the closed , proper convex function f ( x ) is the continuous convex function g ( x ) = inf { f ( y ) + 1 2 γ | | x − y | | 22 } , ( 33 . 4 ) with the inﬁmum taken over all y in R N . In Rockafellar’s book [ 181 ] , and elsewhere , it is shown that the inﬁmum is attained at a unique y , usually denoted prox γf ( x ) . The proximity operators prox γf ( · ) are ﬁrmly non - expansive [ 88 ] and generalize the orthogonal projections onto closed , convex sets , as we now show . Consider the function f ( x ) = ι C ( x ) , the indicator function of the closed , convex set C , taking the value zero for x in C , and + ∞ otherwise . Then prox γf ( x ) = P C ( x ) , the orthogonal projection of x onto C . 33 . 1 . 5 The Split - Feasibility Problem An interesting variant of the CFP is the split - feasibility problem ( SFP ) [ 71 ] . Let A be an I by J ( possibly complex ) matrix . The SFP is to ﬁnd a member of a closed , convex set C in C J for which Ax is a member of a second closed , convex set Q in C I . When there is no such x , we can obtain an approximate solution by minimizing the proximity function g ( x ) = | | P Q Ax − Ax | | 22 , ( 33 . 5 ) over all x in C , whenever such minimizers exist . 33 . 2 Algorithms Based on Orthogonal Pro - jection When the convex sets are half - spaces in two or three dimensional space , we may be able to ﬁnd a member of their intersection by drawing a picture 33 . 2 . ALGORITHMS BASED ON ORTHOGONAL PROJECTION 401 or just by thinking ; in general , however , solving the CFP must be left up to the computer and we need an algorithm . The CFP can be solved using the successive orthogonal projections ( SOP ) method . Algorithm 33 . 1 ( SOP ) For arbitrary x 0 , let x k + 1 = P I P I − 1 · · · P 2 P 1 x k , ( 33 . 6 ) where P i = P C i is the orthogonal projection onto C i . For non - empty C , convergence of the SOP to a solution of the CFP will follow , once we have established that , for any x 0 , the iterative sequence { T k x 0 } converges to a ﬁxed point of T , where T = P I P I − 1 · · · P 2 P 1 . ( 33 . 7 ) Since T is an averaged operator , the convergence of the SOP to a member of C follows from the KM Theorem 30 . 2 , provided C is non - empty . The SOP is useful when the sets C i are easily described and the P i are easily calculated , but P C is not . The SOP converges to the member of C closest to x 0 when the C i are hyperplanes , but not in general . When C = ∩ Ii = 1 C i is empty and we seek to minimize the proximity function f ( x ) in Equation ( 33 . 1 ) , we can use the simultaneous orthogonal projections ( SIMOP ) approach : Algorithm 33 . 2 ( SIMOP ) For arbitrary x 0 , let x k + 1 = 1 I I (cid:88) i = 1 P i x k . ( 33 . 8 ) The operator T = 1 I I (cid:88) i = 1 P i ( 33 . 9 ) is also averaged , so this iteration converges , by Theorem 30 . 2 , whenever f ( x ) has a minimizer . The CQ algorithm is an iterative method for solving the SFP [ 50 , 51 ] . Algorithm 33 . 3 ( CQ ) For arbitrary x 0 , let x k + 1 = P C ( x k − γA † ( I − P Q ) Ax k ) . ( 33 . 10 ) The operator T = P C ( I − γA † ( I − P Q ) A ) ( 33 . 11 ) 402 CHAPTER 33 . CONVEX FEASIBILITY AND RELATED PROBLEMS is averaged whenever γ is in the interval ( 0 , 2 / L ) , where L is the largest eigenvalue of A † A , and so the CQ algorithm converges to a ﬁxed point of T , whenever such ﬁxed points exist . When the SFP has a solution , the CQ algorithm converges to a solution ; when it does not , the CQ algorithm converges to a minimizer , over C , of the proximity function g ( x ) = 12 | | P Q Ax − Ax | | 22 , whenever such minimizers exist . The function g ( x ) is convex and , according to Theorem 13 . 3 , its gradient is ∇ g ( x ) = A † ( I − P Q ) Ax . ( 33 . 12 ) The convergence of the CQ algorithm then follows from Theorem 30 . 2 . In [ 88 ] Combettes and Wars use proximity operators to generalize the CQ algorithm . 33 . 2 . 1 Projecting onto the Intersection of Convex Sets When the intersection C = ∩ Ii = 1 C i is large , and just ﬁnding any member of C is not suﬃcient for our purposes , we may want to calculate the orthogonal projection of x 0 onto C using the operators P C i . We cannot use the SOP unless the C i are hyperplanes ; instead we can use Dykstra’s algorithm or the Halpern - Lions - Wittmann - Bauschke ( HLWB ) algorithm . Dykstra’s algorithm employs the projections P C i , but not directly on x k , but on translations of x k . It is motivated by the following lemma : Lemma 33 . 1 If x = c + (cid:80) Ii = 1 p i , where , for each i , c = P C i ( c + p i ) , then c = P C x . Proof : The proof is an exercise . Dykstra’s Algorithm Dykstra’s algorithm , for the simplest case of two convex sets A and B , is the following : Algorithm 33 . 4 ( Dykstra ) Let b 0 = x , and p 0 = q 0 = 0 . Then let a n = P A ( b n − 1 + p n − 1 ) , ( 33 . 13 ) b n = P B ( a n + q n − 1 ) , ( 33 . 14 ) and deﬁne p n and q n by x = a n + p n + q n − 1 = b n + p n + q n . ( 33 . 15 ) 33 . 3 . EXERCISES 403 Using the algorithm , we construct two sequences , { a n } and { b n } , both converging to c = P C x , along with two other sequences , { p n } and { q n } . Usually , but not always , { p n } converges to p and { q n } converges to q , so that x = c + p + q , ( 33 . 16 ) with c = P A ( c + p ) = P B ( c + q ) . ( 33 . 17 ) Generally , however , { p n + q n } converges to x − c . The Halpern - Lions - Wittmann - Bauschke Algorithm There is yet another approach to ﬁnding the orthogonal projection of the vector x onto the nonempty intersection C of ﬁnitely many closed , convex sets C i , i = 1 , . . . , I . Algorithm 33 . 5 ( HLWB ) Let x 0 be arbitrary . Then let x k + 1 = t k x + ( 1 − t k ) P C i x k , ( 33 . 18 ) where P C i denotes the orthogonal projection onto C i , t k is in the interval ( 0 , 1 ) , and i = k ( mod I ) + 1 . Several authors have proved convergence of the sequence { x k } to P C x , with various conditions imposed on the parameters { t k } . As a result , the algorithm is known as the Halpern - Lions - Wittmann - Bauschke ( HLWB ) al - gorithm , after the names of several who have contributed to the evolution of the theorem ; see also Corollary 2 in Reich’s paper [ 178 ] . The conditions imposed by Bauschke [ 9 ] are { t k } → 0 , (cid:80) t k = ∞ , and (cid:80) | t k − t k + I | < + ∞ . The HLWB algorithm has been extended by Deutsch and Yamada [ 96 ] to minimize certain ( possibly non - quadratic ) functions over the intersection of ﬁxed point sets of operators more general than P C i . Bregman discovered an iterative algorithm for minimizing a more general convex function f ( x ) over x with Ax = b and also x with Ax ≥ b [ 25 ] . These algorithms are based on his extension of the SOP to include projections with respect to generalized distances , such as entropic distances . 33 . 3 Exercises Ex . 33 . 1 Prove Lemma 33 . 1 . 404 CHAPTER 33 . CONVEX FEASIBILITY AND RELATED PROBLEMS Ex . 33 . 2 In R 2 let C 1 be the closed lower half - space , and C 2 the epi - graph of the function g : ( 0 , + ∞ ) → ( 0 , + ∞ ) given by g ( t ) = 1 / t . Show that the proximity function f ( x ) = 2 (cid:88) i = 1 | | P C i x − x | | 22 , ( 33 . 19 ) has no minimizer . Ex . 33 . 3 Let f ( x ) = 12 γ (cid:107) x − P C x (cid:107) 22 , for some γ > 0 . Show that x = prox f ( z ) = ( 1 − α ) z + αP C z , where α = 1 γ + 1 . This tells us that relaxed orthogonal projections are also prox operators . Hint : Use Theorem 13 . 3 to show that x must satisfy the equation z = x + 1 γ ( x − P C x ) . Then show that P C z = P C x . Chapter 34 Fenchel Duality 34 . 1 Chapter Summary The duality between convex functions on R J and their tangent hyperplanes is made explicit through the Legendre - Fenchel transformation . In this chapter we discuss this transformation , state and prove Fenchel’s Duality Theorem , and investigate some of its applications . 34 . 2 The Legendre - Fenchel Transformation Throughout this section f : C ⊆ R J → R is a closed , proper , convex function deﬁned on a non - empty , closed convex set C . 34 . 2 . 1 The Fenchel Conjugate We say that a function h ( x ) : R J → R is aﬃne if it has the form h ( x ) = (cid:104) a , x (cid:105) − γ , for some vector a and scalar γ . If γ = 0 , then we call the function linear . A function such as f ( x ) = 5 x + 2 is commonly called a linear function in algebra classes , but , according to our deﬁnitions , it should be called an aﬃne function . For each ﬁxed vector a in R J , the aﬃne function h ( x ) = (cid:104) a , x (cid:105) − γ is beneath the function f ( x ) if f ( x ) − h ( x ) ≥ 0 , for all x ; that is , f ( x ) − (cid:104) a , x (cid:105) + γ ≥ 0 , or γ ≥ (cid:104) a , x (cid:105) − f ( x ) . ( 34 . 1 ) This leads us to the following deﬁnition , involving the maximum of the right side of the inequality in ( 34 . 1 ) , for each ﬁxed a . 405 406 CHAPTER 34 . FENCHEL DUALITY Deﬁnition 34 . 1 The conjugate function associated with f is the function f ∗ ( a ) = sup x ∈ C ( (cid:104) a , x (cid:105) − f ( x ) ) . ( 34 . 2 ) We then deﬁne C ∗ to be the set of all a for which f ∗ ( a ) is ﬁnite . For each ﬁxed a , the value f ∗ ( a ) is the smallest value of γ for which the aﬃne function h ( x ) = (cid:104) a , x (cid:105) − γ is beneath f ( x ) for x ∈ C . The passage from f to f ∗ is the Legendre - Fenchel Transformation . For example , suppose that f ( x ) = 12 x 2 . The function h ( x ) = ax + b is beneath f ( x ) for all x if ax + b ≤ 1 2 x 2 , for all x . Equivalently , b ≤ 1 2 x 2 − ax , for all x . Then b must not exceed the minimum of the right side , which is − 12 a 2 and occurs when x − a = 0 , or x = a . Therefore , we have γ = − b ≥ 1 2 a 2 . The smallest value of γ for which this is true is γ = 12 a 2 , so we have f ∗ ( a ) = 12 a 2 . 34 . 2 . 2 The Conjugate of the Conjugate Now we repeat this process with f ∗ ( a ) in the role of f ( x ) . For each ﬁxed vector x , the aﬃne function c ( a ) = (cid:104) a , x (cid:105) − γ is beneath the function f ∗ ( a ) if f ∗ ( a ) − c ( a ) ≥ 0 , for all a ∈ C ∗ ; that is , f ∗ ( a ) − (cid:104) a , x (cid:105) + γ ≥ 0 , or γ ≥ (cid:104) a , x (cid:105) − f ∗ ( a ) . ( 34 . 3 ) This leads us to the following deﬁnition , involving the maximum of the right side of the inequality in ( 34 . 3 ) , for each ﬁxed x . Deﬁnition 34 . 2 The conjugate function associated with f ∗ is the function f ∗∗ ( x ) = sup a ( (cid:104) a , x (cid:105) − f ∗ ( a ) ) . ( 34 . 4 ) For each ﬁxed x , the value f ∗∗ ( x ) is the smallest value of γ for which the aﬃne function c ( a ) = (cid:104) a , x (cid:105) − γ is beneath f ∗ ( a ) . 34 . 2 . THE LEGENDRE - FENCHEL TRANSFORMATION 407 Applying the Separation Theorem to the epigraph of the closed , proper , convex function f ( x ) , it can be shown ( [ 181 ] , Theorem 12 . 1 ) that f ( x ) is the point - wise supremum of all the aﬃne functions beneath f ( x ) ; that is , f ( x ) = sup a , γ { h ( x ) | f ( x ) ≥ h ( x ) } . Therefore , f ( x ) = sup a (cid:16) (cid:104) a , x (cid:105) − f ∗ ( a ) (cid:17) . This says that f ∗∗ ( x ) = f ( x ) . ( 34 . 5 ) If f ( x ) is a diﬀerentiable function , then , for each ﬁxed a , the function g ( x ) = (cid:104) a , x (cid:105) − f ( x ) attains its minimum when 0 = ∇ g ( x ) = a − ∇ f ( x ) , which says that a = ∇ f ( x ) . 34 . 2 . 3 Some Examples of Conjugate Functions • The exponential function f ( x ) = exp ( x ) = e x has conjugate exp ∗ ( a ) = (cid:40) a log a − a , if a > 0 ; 0 , if a = 0 ; + ∞ , if a < 0 . ( 34 . 6 ) • The function f ( x ) = − log x , for x > 0 , has the conjugate function f ∗ ( a ) = − 1 − log ( − a ) , for a < 0 . • The function f ( x ) = | x | p p has conjugate f ∗ ( a ) = | a | q q , where p > 0 , q > 0 , and 1 p + 1 q = 1 . Therefore , the function f ( x ) = 12 (cid:107) x (cid:107) 2 is its own conjugate , that is , f ∗ ( a ) = 12 (cid:107) a (cid:107) 2 . • Let A be a real symmetric positive - deﬁnite matrix and f ( x ) = 1 2 (cid:104) Ax , x (cid:105) . Then f ∗ ( a ) = 1 2 (cid:104) A − 1 a , a (cid:105) . 408 CHAPTER 34 . FENCHEL DUALITY • Let i C ( x ) be the indicator function of the closed convex set C , that is , i C ( x ) = (cid:40) 0 , if x ∈ C ; + ∞ , if x / ∈ C . Then i ∗ C ( a ) = sup x ∈ C (cid:104) a , x (cid:105) , which is the support function of the set C , usually denoted σ C ( a ) . • Let C ⊆ R J be non - empty , closed and convex . The gauge function of C is γ C ( x ) = inf { λ ≥ 0 | x ∈ λC } . If C = B , the unit ball of R J , then γ B ( x ) = (cid:107) x (cid:107) 2 . For each C deﬁne the polar set for C by C 0 = { z | (cid:104) z , c (cid:105) ≤ 1 , for all c ∈ C } . Then γ ∗ C = ι C 0 . • Let C = { x | | | x | | 2 ≤ 1 } , so that the function φ ( a ) = (cid:107) a (cid:107) 2 satisﬁes φ ( a ) = sup x ∈ C (cid:104) a , x (cid:105) . Then φ ( a ) = σ C ( a ) = i ∗ C ( a ) . Therefore , φ ∗ ( x ) = σ ∗ C ( x ) = i ∗∗ C ( x ) = i C ( x ) = (cid:40) 0 , if x ∈ C ; + ∞ , if x / ∈ C . 34 . 2 . 4 Inﬁmal Convolution Again The inﬁmal convolution and deconvolution are related to the Fenchel con - jugate ; speciﬁcally , under suitable conditions , we have f ⊕ g = ( f ∗ + g ∗ ) ∗ , and f (cid:9) g = ( f ∗ − g ∗ ) ∗ . See Lucet [ 149 ] for details . 34 . 2 . THE LEGENDRE - FENCHEL TRANSFORMATION 409 34 . 2 . 5 Conjugates and Sub - gradients We know from the deﬁnition of f ∗ ( a ) that f ∗ ( a ) ≥ (cid:104) a , z (cid:105) − f ( z ) , for all z , and , moreover , f ∗ ( a ) is the supremum of these values , taken over all z . If a is a member of the sub - diﬀerential ∂f ( x ) , then , for all z , we have f ( z ) ≥ f ( x ) + (cid:104) a , z − x (cid:105) , so that (cid:104) a , x (cid:105) − f ( x ) ≥ (cid:104) a , z (cid:105) − f ( z ) . It follows that f ∗ ( a ) = (cid:104) a , x (cid:105) − f ( x ) , so that f ( x ) + f ∗ ( a ) = (cid:104) a , x (cid:105) . If f ( x ) is a diﬀerentiable convex function , then a is in the sub - diﬀerential ∂f ( x ) if and only if a = ∇ f ( x ) . Then we can say f ( x ) + f ∗ ( ∇ f ( x ) ) = (cid:104)∇ f ( x ) , x (cid:105) . ( 34 . 7 ) If a = ∇ f ( x 1 ) and a = ∇ f ( x 2 ) , then the function g ( x ) = (cid:104) a , x (cid:105) − f ( x ) attains its minimum value at x = x 1 and at x = x 2 , so that f ∗ ( a ) = (cid:104) a , x 1 (cid:105) − ∇ f ( x 1 ) = (cid:104) a , x 2 (cid:105) − f ( x 2 ) . Let us denote by x = ( ∇ f ) − 1 ( a ) any x for which ∇ f ( x ) = a . Then the conjugate of the diﬀerentiable function f : C ⊆ R J → R can then be deﬁned as follows [ 181 ] . Let D be the image of the set C under the mapping ∇ f . Then , for all a ∈ D , deﬁne f ∗ ( a ) = (cid:104) a , ( ∇ f ) − 1 ( a ) (cid:105) − f ( ( ∇ f ) − 1 ( a ) ) . ( 34 . 8 ) The formula in Equation ( 34 . 8 ) is also called the Legendre Transform . 34 . 2 . 6 The Conjugate of a Concave Function A function g : D ⊆ R J → R is concave if f ( x ) = − g ( x ) is convex . One might think that the conjugate of a concave function g is simply the nega - tive of the conjugate of − g , but not quite . 410 CHAPTER 34 . FENCHEL DUALITY The aﬃne function h ( x ) = (cid:104) a , x (cid:105)− γ is above the concave function g ( x ) if h ( x ) − g ( x ) ≥ 0 , for all x ∈ D ; that is , (cid:104) a , x (cid:105) − γ − g ( x ) ≥ 0 , or γ ≤ (cid:104) a , x (cid:105) − g ( x ) . ( 34 . 9 ) The conjugate function associated with g is the function g ∗ ( a ) = inf x ( (cid:104) a , x (cid:105) − g ( x ) ) . ( 34 . 10 ) For each ﬁxed a , the value g ∗ ( a ) is the largest value of γ for which the aﬃne function h ( x ) = (cid:104) a , x (cid:105) − γ is above g ( x ) . It follows , using f ( x ) = − g ( x ) , that g ∗ ( a ) = inf x ( (cid:104) a , x (cid:105) + f ( x ) ) = − sup x ( (cid:104)− a , x (cid:105) − f ( x ) ) = − f ∗ ( − a ) . 34 . 3 Fenchel’s Duality Theorem Let f ( x ) be a proper convex function on C ⊆ R J and g ( x ) a proper concave function on D ⊆ R J , where C and D are closed convex sets with non - empty intersection . Fenchel’s Duality Theorem deals with the problem of minimizing the diﬀerence f ( x ) − g ( x ) over x ∈ C ∩ D . We know from our discussion of conjugate functions and diﬀerentiability that − f ∗ ( a ) ≤ f ( x ) − (cid:104) a , x (cid:105) , and g ∗ ( a ) ≤ (cid:104) a , x (cid:105) − g ( x ) . Therefore , f ( x ) − g ( x ) ≥ g ∗ ( a ) − f ∗ ( a ) , for all x and a , and so inf x (cid:16) f ( x ) − g ( x ) (cid:17) ≥ sup a (cid:16) g ∗ ( a ) − f ∗ ( a ) (cid:17) . We let C ∗ be the set of all a such that f ∗ ( a ) is ﬁnite , with D ∗ similarly deﬁned . The Fenchel Duality Theorem , in its general form , as found in [ 150 ] and [ 181 ] , is as follows . 34 . 3 . FENCHEL’S DUALITY THEOREM 411 Theorem 34 . 1 Assume that C ∩ D has points in the relative interior of both C and D , and that either the epigraph of f or that of g has non - empty interior . Suppose that µ = inf x ∈ C ∩ D (cid:16) f ( x ) − g ( x ) (cid:17) is ﬁnite . Then µ = inf x ∈ C ∩ D (cid:16) f ( x ) − g ( x ) (cid:17) = max a ∈ C ∗ ∩ D ∗ (cid:16) g ∗ ( a ) − f ∗ ( a ) (cid:17) , where the maximum on the right is achieved at some a 0 ∈ C ∗ ∩ D ∗ . If the inﬁmum on the left is achieved at some x 0 ∈ C ∩ D , then max x ∈ C (cid:16) (cid:104) x , a 0 (cid:105) − f ( x ) (cid:17) = (cid:104) x 0 , a 0 (cid:105) − f ( x 0 ) , and min x ∈ D (cid:16) (cid:104) x , a 0 (cid:105) − g ( x ) (cid:17) = (cid:104) x 0 , a 0 (cid:105) − g ( x 0 ) . The conditions on the interiors are needed to make use of sub - diﬀerentials . For simplicity , we shall limit our discussion to the case of diﬀerentiable f ( x ) and g ( x ) . 34 . 3 . 1 Fenchel’s Duality Theorem : Diﬀerentiable Case We suppose now that there is x 0 ∈ C ∩ D such that inf x ∈ C ∩ D ( f ( x ) − g ( x ) ) = f ( x 0 ) − g ( x 0 ) , and that ∇ ( f − g ) ( x 0 ) = 0 , or ∇ f ( x 0 ) = ∇ g ( x 0 ) . ( 34 . 11 ) Let ∇ f ( x 0 ) = a 0 . From the equation f ( x ) + f ∗ ( ∇ f ( x ) ) = (cid:104)∇ f ( x ) , x (cid:105) and Equation ( 34 . 11 ) , we have f ( x 0 ) − g ( x 0 ) = g ∗ ( a 0 ) − f ∗ ( a 0 ) , from which it follows that inf x ∈ C ∩ D ( f ( x ) − g ( x ) ) = sup a ∈ C ∗ ∩ D ∗ ( g ∗ ( a ) − f ∗ ( a ) ) . This is Fenchel’s Duality Theorem . 412 CHAPTER 34 . FENCHEL DUALITY 34 . 3 . 2 Optimization over Convex Subsets Suppose now that f ( x ) is convex and diﬀerentiable on R J , but we are only interested in its values on the non - empty closed convex set C . Then we redeﬁne f ( x ) = + ∞ for x not in C . The aﬃne function h ( x ) = (cid:104) a , x (cid:105) − γ is beneath f ( x ) for all x if and only if it is beneath f ( x ) for x ∈ C . This motivates our deﬁning the conjugate function now as f ∗ ( a ) = sup x ∈ C (cid:104) a , x (cid:105) − f ( x ) . Similarly , let g ( x ) be concave on D and g ( x ) = −∞ for x not in D . Then we deﬁne g ∗ ( a ) = inf x ∈ D (cid:104) a , x (cid:105) − g ( x ) . Let C ∗ = { a | f ∗ ( a ) < + ∞ } , and deﬁne D ∗ similarly . We can use Fenchel’s Duality Theorem to minimize the diﬀerence f ( x ) − g ( x ) over the intersection C ∩ D . To illustrate the use of Fenchel’s Duality Theorem , consider the problem of minimizing the convex function f ( x ) over the convex set D . Let C = R J and g ( x ) = 0 , for all x . Then f ∗ ( a ) = sup x ∈ C (cid:16) (cid:104) a , x (cid:105) − f ( x ) (cid:17) = sup x (cid:16) (cid:104) a , x (cid:105) − f ( x ) (cid:17) , and g ∗ ( a ) = inf x ∈ D (cid:16) (cid:104) a , x (cid:105) − g ( x ) (cid:17) = inf x ∈ D (cid:104) a , x (cid:105) . The supremum is unconstrained and the inﬁmum is with respect to a linear functional . Then , by Fenchel’s Duality Theorem , we have max a ∈ C ∗ ∩ D ∗ ( g ∗ ( a ) − f ∗ ( a ) ) = inf x ∈ D f ( x ) . 34 . 4 An Application to Game Theory In this section we complement our earlier discussion of matrix games by illustrating the application of the Fenchel Duality Theorem to prove the Min - Max Theorem for two - person games . 34 . 4 . 1 Pure and Randomized Strategies In a two - person game , the ﬁrst player selects a row of the matrix A , say i , and the second player selects a column of A , say j . The second player pays the ﬁrst player A ij . If some A ij < 0 , then this means that the ﬁrst player pays the second . As we discussed previously , there need not be optimal 34 . 4 . AN APPLICATION TO GAME THEORY 413 pure strategies for the two players and it may be sensible for them , over the long run , to select their strategies according to some random mechanism . The issues then are which vectors of probabilities will prove optimal and do such optimal probability vectors always exist . The Min - Max Theorem , also known as the Fundamental Theorem of Game Theory , asserts that such optimal probability vectors always exist . 34 . 4 . 2 The Min - Max Theorem In [ 150 ] , Luenberger uses the Fenchel Duality Theorem to prove the Min - Max Theorem for two - person games . His formulation is in Banach spaces , while we shall limit our discussion to ﬁnite - dimensional spaces . Let A be an I by J pay - oﬀ matrix , whose entries represent the payoﬀs from the second player to the ﬁrst . Let P = { p = ( p 1 , . . . , p I ) | p i ≥ 0 , I (cid:88) i = 1 p i = 1 } , S = { s = ( s 1 , . . . , s I ) | s i ≥ 0 , I (cid:88) i = 1 s i ≤ 1 } , and Q = { q = ( q 1 , . . . , q J ) | q j ≥ 0 , J (cid:88) j = 1 q j = 1 } . The set S is the convex hull of the set P . The ﬁrst player selects a vector p in P and the second selects a vector q in Q . The expected pay - oﬀ to the ﬁrst player is E = (cid:104) p , Aq (cid:105) . Let m 0 = max p ∈ P min q ∈ Q (cid:104) p , Aq (cid:105) , and m 0 = min q ∈ Q max p ∈ P (cid:104) p , Aq (cid:105) . Clearly , we have min q ∈ Q (cid:104) p , Aq (cid:105) ≤ (cid:104) p , Aq (cid:105) ≤ max p ∈ P (cid:104) p , Aq (cid:105) , for all p ∈ P and q ∈ Q . It follows that m 0 ≤ m 0 . We show that m 0 = m 0 . Deﬁne f ( x ) = max p ∈ P (cid:104) p , x (cid:105) , 414 CHAPTER 34 . FENCHEL DUALITY which is equivalent to f ( x ) = max s ∈ S (cid:104) s , x (cid:105) . Then f is convex and continuous on R I . We want min q ∈ Q f ( Aq ) . We apply Fenchel’s Duality Theorem , with f = f , g = 0 , D = A ( Q ) , and C = R I . Now we have inf x ∈ C ∩ D ( f ( x ) − g ( x ) ) = min q ∈ Q f ( Aq ) . We claim that the following are true : • 1 ) D ∗ = R I ; • 2 ) g ∗ ( a ) = min q ∈ Q (cid:104) a , Aq (cid:105) ; • 3 ) C ∗ = S ; • 4 ) f ∗ ( a ) = 0 , for all a in S . The ﬁrst two claims are immediate . To prove the third one , we take a vector a ∈ R I that is not in S . Then , by the separation theorem , we can ﬁnd x ∈ R I and α > 0 such that (cid:104) x , a (cid:105) > α + (cid:104) x , s (cid:105) , for all s ∈ S . Then (cid:104) x , a (cid:105) − max s ∈ S (cid:104) x , s (cid:105) ≥ α > 0 . Now take k > 0 large and y = kx . Since (cid:104) y , s (cid:105) = k (cid:104) x , s (cid:105) , we know that (cid:104) y , a (cid:105) − max s ∈ S (cid:104) y , s (cid:105) = (cid:104) y , a (cid:105) − f ( y ) > 0 and can be made arbitrarily large by taking k > 0 large . It follows that f ∗ ( a ) is not ﬁnite if a is not in S , so that C ∗ = S . As for the fourth claim , if a ∈ S , then (cid:104) y , a (cid:105) − max s ∈ S (cid:104) y , s (cid:105) achieves its maximum value of zero at y = 0 , so f ∗ ( a ) = 0 . Finally , we have min q ∈ Q max p ∈ P (cid:104) p , Aq (cid:105) = min q ∈ Q f ( Aq ) = max a ∈ S g ∗ ( a ) = max a ∈ S min q ∈ Q (cid:104) p , Aq (cid:105) . Therefore , min q ∈ Q max p ∈ P (cid:104) p , Aq (cid:105) = max p ∈ P min q ∈ Q (cid:104) p , Aq (cid:105) . 34 . 5 . EXERCISES 415 34 . 5 Exercises Ex . 34 . 1 Show that the exponential function f ( x ) = exp ( x ) = e x has con - jugate exp ∗ ( a ) = (cid:40) a log a − a , if a > 0 ; 0 , if a = 0 ; + ∞ , if a < 0 . ( 34 . 12 ) Ex . 34 . 2 Show that the function f ( x ) = − log x , for x > 0 , has the conju - gate function f ∗ ( a ) = − 1 − log ( − a ) , for a < 0 . Ex . 34 . 3 Show that the function f ( x ) = | x | p p has conjugate f ∗ ( a ) = | a | q q , where p > 0 , q > 0 , and 1 p + 1 q = 1 . Therefore , the function f ( x ) = 12 (cid:107) x (cid:107) 22 is its own conjugate , that is , f ∗ ( a ) = 12 (cid:107) a (cid:107) 22 . Ex . 34 . 4 Let A be a real symmetric positive - deﬁnite matrix and f ( x ) = 1 2 (cid:104) Ax , x (cid:105) . Show that f ∗ ( a ) = 1 2 (cid:104) A − 1 a , a (cid:105) . Hints : Find ∇ f ( x ) and use Equation ( 34 . 8 ) . 34 . 6 Course Homework Do all the exercises in this chapter . 416 CHAPTER 34 . FENCHEL DUALITY Chapter 35 Non - smooth Optimization 35 . 1 Chapter Summary In this chapter we consider the problem of optimizing functions f that are convex , but possibly non - diﬀerentiable . 35 . 2 Overview Let f : R J → ( −∞ , + ∞ ] be a closed , proper , convex function . When f is diﬀerentiable , we can ﬁnd minimizers of f using techniques such as gradient descent . When f is not necessarily diﬀerentiable , the minimiza - tion problem is more diﬃcult . One approach is to augment the function f and to convert the problem into one of minimizing a diﬀerentiable func - tion . Moreau’s approach uses Euclidean distances to augment f , leading to the deﬁnition of proximal operators [ 181 ] , or proximity operators [ 88 ] . More general methods , using Bregman distances to augment f , have been considered by Teboulle [ 195 ] and by Censor and Zenios [ 82 ] . The interior - point algorithm ( IPA ) is an iterative method for minimizing a convex function f : R J → ( −∞ , + ∞ ] over the set D , the closure of the essential domain of a second convex function h : R J → ( −∞ , + ∞ ] , where D is the set of all x for which h ( x ) is ﬁnite . The IPA is an interior - point algorithm , in the sense that each iterate lies within the interior of D . The IPA generalizes the PMD algorithm of Censor and Zenios [ 82 ] and is related to the proximity operators of Moreau and to the entropic proximal mappings of Teboulle [ 195 ] . 417 418 CHAPTER 35 . NON - SMOOTH OPTIMIZATION 35 . 3 Moreau’s Proximity Operators The Moreau envelope of the function f is the function m f ( z ) = inf x { f ( x ) + 1 2 | | x − z | | 22 } , ( 35 . 1 ) which is also the inﬁmal convolution of the functions f ( x ) and 12 | | x | | 22 . It can be shown that the inﬁmum is uniquely attained at the point denoted x = prox f z ( see [ 181 ] ) . Proposition 35 . 1 The inﬁmum of m f ( z ) , over all z , is the same as the inﬁmum of f ( x ) , over all x . Proof : We use Equation ( 4 . 1 ) . We have inf z m f ( z ) = inf z inf x { f ( x ) + 1 2 | | x − z | 22 } = inf x inf z { f ( x ) + 1 2 | | x − z | 22 } = inf x { f ( x ) + 1 2 inf z | | x − z | | 22 } = inf x f ( x ) . Later , we shall show that the minimizers of m f ( z ) and f ( x ) are the same , as well . The function m f ( z ) is diﬀerentiable and ∇ m f ( z ) = z − prox f z . The point x = prox f z is characterized by the property z − x ∈ ∂f ( x ) . Conse - quently , x is a global minimizer of f if and only if x = prox f x . For example , consider the indicator function of the convex set C , f ( x ) = ι C ( x ) that is zero if x is in the closed convex set C and + ∞ otherwise . Then m f z is the minimum of 12 | | x − z | | 22 over all x in C , and prox f z = P C z , the orthogonal projection of z onto the set C . It then follows that P C z is the gradient of the function g ( z ) = 1 2 ( (cid:107) z (cid:107) 22 − (cid:107) z − P C z (cid:107) 22 ) . We consider two examples in the exercises . If f : R → R is f ( t ) = ω | t | , then prox f ( t ) = t − t | t | ω , ( 35 . 2 ) for | t | ≤ ω , and equals zero , otherwise . The operators prox f : z → prox f z are proximal operators . These oper - ators generalize the projections onto convex sets , and , like those operators , are ﬁrmly non - expansive [ 88 ] . 35 . 3 . MOREAU’S PROXIMITY OPERATORS 419 The conjugate function associated with f is the function f ∗ ( x ∗ ) = sup x ( (cid:104) x ∗ , x (cid:105) − f ( x ) ) . In similar fashion , we can deﬁne m f ∗ z and prox f ∗ z . Both m f and m f ∗ are convex and diﬀerentiable . The support function of the convex set C is σ C ( x ) = sup u ∈ C (cid:104) x , u (cid:105) . It is easy to see that σ C = ι ∗ C . For f ∗ ( z ) = σ C ( z ) , we can ﬁnd m f ∗ z using Moreau’s Theorem ( [ 181 ] , p . 338 ) . Moreau’s Theorem generalizes the decomposition of members of R J with respect to a subspace . Theorem 35 . 1 ( Moreau’s Theorem ) Let f be a closed , proper , convex function . Then m f ( z ) + m f ∗ ( z ) = 1 2 | | z | | 22 ; ( 35 . 3 ) and prox f z + prox f ∗ z = z . ( 35 . 4 ) In addition , we have prox f ∗ z ∈ ∂f ( prox f z ) , prox f ∗ z = ∇ m f ( z ) , and prox f z = ∇ m f ∗ ( z ) . ( 35 . 5 ) Since σ C = ι ∗ C , we have prox σ C z = z − prox ι C z = z − P C z . ( 35 . 6 ) The following proposition illustrates the usefulness of these concepts . Proposition 35 . 2 The minimizers of m f and the minimizers of f are the same . Proof : From Moreau’s Theorem we know that ∇ m f ( z ) = prox f ∗ z = z − prox f z , ( 35 . 7 ) so ∇ m f z = 0 is equivalent to z = prox f z . As Exercise 35 . 1 will show , minimizers of m f and f need not exist , but a minimizer of one is a minimizer of the other . Because the minimizers of m f , when they exist , are also minimizers of f , we can ﬁnd global minimizers of f using gradient descent iterative methods on m f . Let x 0 be arbitrary . For k = 0 , 1 , . . . , let x k + 1 = x k − γ k ∇ m f ( x k ) . ( 35 . 8 ) 420 CHAPTER 35 . NON - SMOOTH OPTIMIZATION We know from Moreau’s Theorem that ∇ m f z = prox f ∗ z = z − prox f z , ( 35 . 9 ) so that Equation ( 35 . 8 ) can be written as x k + 1 = x k − γ k ( x k − prox f x k ) , ( 35 . 10 ) which leads to the Proximal Minimization Algorithm : Algorithm 35 . 1 ( Proximal Minimization ) Let x 0 be arbitrary . For k = 0 , 1 , . . . , let x k + 1 = ( 1 − γ k ) x k + γ k prox f x k . ( 35 . 11 ) Because x k − prox f x k ∈ ∂f ( prox f x k ) , ( 35 . 12 ) the iteration in Equation ( 35 . 11 ) has the increment x k + 1 − x k ∈ − γ k ∂f ( prox f x k ) , ( 35 . 13 ) in contrast to what we would have with the usual gradient descent method for diﬀerentiable f : x k + 1 − x k = − γ k ∇ f ( x k ) . ( 35 . 14 ) If there is z with prox f z = z , then convergence of the sequence { x k } to a ﬁxed point of prox f , and so to a minimizer of f , follows from the KM Theorem 30 . 2 , under the conditions that γ k ≤ r < 1 for all k . If we take γ k = 1 for all k , then x k + 1 = prox f x k , and since prox f is fne , and therefore averaged , convergence follows again from the KM theorem . In practice , fast algorithms for calculating the Fenchel conjugate and the Moreau envelope are needed . See Lucet [ 149 ] for a survey of techniques in convex computational analysis . 35 . 4 Forward - Backward Splitting In [ 88 ] Combettes and Wajs consider the problem of minimizing the func - tion f = f 1 + f 2 , where f 2 is diﬀerentiable and its gradient is L - Lipschitz continuous . The algorithm they present to solve this problem is known as the forward - backward splitting ( FBS ) algorithm . 35 . 4 . FORWARD - BACKWARD SPLITTING 421 35 . 4 . 1 The FBS algorithm The function f is minimized at the point x if and only if 0 ∈ ∂f ( x ) = ∂f 1 ( x ) + ∇ f 2 ( x ) , ( 35 . 15 ) so we have − γ ∇ f 2 ( x ) ∈ γ∂f 1 ( x ) , ( 35 . 16 ) for any γ > 0 . Therefore x − γ ∇ f 2 ( x ) − x ∈ γ∂f 1 ( x ) . ( 35 . 17 ) From Equation ( 35 . 17 ) we conclude that x = prox γf 1 ( x − γ ∇ f 2 ( x ) ) . ( 35 . 18 ) This suggests an algorithm , called the forward - backward splitting ( FBS ) , for minimizing the function f ( x ) . Algorithm 35 . 2 ( Forward - Backward Splitting ) Beginning with an ar - bitrary x 0 , and having calculated x k − 1 , we let x k = prox γf 1 ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) , ( 35 . 19 ) with γ chosen to lie in the interval ( 0 , 2 / L ) . The operator I − γ ∇ f 2 is then averaged . Since the operator prox γf 1 is ﬁrmly non - expansive , we know from the KM Theorem 30 . 2 that the sequence { x k } converges to a minimizer of the function f ( x ) , whenever minimizers exist . It is also possible to allow γ to vary with the k . 35 . 4 . 2 A Simpler Convergence Proof for FBS For each k = 1 , 2 , . . . let G k ( x ) = f ( x ) + 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f 2 ( x , x k − 1 ) , ( 35 . 20 ) where D f 2 ( x , x k − 1 ) = f 2 ( x ) − f 2 ( x k − 1 ) − (cid:104)∇ f 2 ( x k − 1 ) , x − x k − 1 (cid:105) . ( 35 . 21 ) Since f 2 ( x ) is convex , D f 2 ( x , y ) ≥ 0 for all x and y and is the Bregman distance formed from the function f 2 [ 25 ] . The auxiliary function g k ( x ) = 1 2 γ (cid:107) x − x k − 1 (cid:107) 22 − D f 2 ( x , x k − 1 ) ( 35 . 22 ) 422 CHAPTER 35 . NON - SMOOTH OPTIMIZATION can be rewritten as g k ( x ) = D h ( x , x k − 1 ) , ( 35 . 23 ) where h ( x ) = 1 2 γ (cid:107) x (cid:107) 22 − f 2 ( x ) . ( 35 . 24 ) Therefore , g k ( x ) ≥ 0 whenever h ( x ) is a convex function . We know that h ( x ) is convex if and only if (cid:104)∇ h ( x ) − ∇ h ( y ) , x − y (cid:105) ≥ 0 , ( 35 . 25 ) for all x and y . This is equivalent to 1 γ (cid:107) x − y (cid:107) 22 − (cid:104)∇ f 2 ( x ) − ∇ f 2 ( y ) , x − y (cid:105) ≥ 0 . ( 35 . 26 ) Since ∇ f 2 is L - Lipschitz , the inequality ( 35 . 26 ) holds whenever 0 < γ < 1 L . Lemma 35 . 1 The x k that minimizes G k ( x ) over x is given by Equation ( 35 . 19 ) . Proof : Since x k minimizes G k ( x ) we know that 0 ∈ ∇ f 2 ( x k ) + 1 γ ( x k − x k − 1 ) − ∇ f 2 ( x k ) + ∇ f 2 ( x k − 1 ) + ∂f 1 ( x k ) . Therefore , (cid:16) x k − 1 − γ ∇ f 2 ( x k − 1 ) (cid:17) − x k ∈ ∂γf 1 ( x k ) . Consequently , x k = prox γf 1 ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) . A relatively simple calculation shows that G k ( x ) − G k ( x k ) = 1 2 γ (cid:107) x − x k (cid:107) 2 2 + (cid:16) f 1 ( x ) − f 1 ( x k ) − (cid:104) ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) − x k , x − x k (cid:105) (cid:17) . ( 35 . 27 ) Since ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) − x k ∈ ∂γf 1 ( x k ) , it follows that (cid:16) f 1 ( x ) − f 1 ( x k ) − (cid:104) ( x k − 1 − γ ∇ f 2 ( x k − 1 ) ) − x k , x − x k (cid:105) (cid:17) ≥ 0 . 35 . 4 . FORWARD - BACKWARD SPLITTING 423 Therefore , G k ( x ) − G k ( x k ) ≥ 1 2 γ (cid:107) x − x k (cid:107) 22 ≥ g k + 1 ( x ) . ( 35 . 28 ) Therefore , the iteration ﬁts into the SUMMA class . Now let ˆ x minimize f ( x ) over all x . Then G k ( ˆ x ) − G k ( x k ) = f ( ˆ x ) + g k ( ˆ x ) − f ( x k ) − g k ( x k ) ≤ f ( ˆ x ) + G k − 1 ( ˆ x ) − G k − 1 ( x k − 1 ) − f ( x k ) − g k ( x k ) , so that (cid:16) G k − 1 ( ˆ x ) − G k − 1 ( x k − 1 ) (cid:17) − (cid:16) G k ( ˆ x ) − G k ( x k ) (cid:17) ≥ f ( x k ) − f ( ˆ x ) + g k ( x k ) ≥ 0 . Therefore , the sequence { G k ( ˆ x ) − G k ( x k ) } is decreasing and the sequences { g k ( x k ) } and { f ( x k ) − f ( ˆ x ) } converge to zero . From G k ( ˆ x ) − G k ( x k ) ≥ 1 2 γ (cid:107) ˆ x − x k (cid:107) 22 , it follows that the sequence { x k } is bounded and that a subsequence con - verges to some x ∗ ∈ C with f ( x ∗ ) = f ( ˆ x ) . Replacing the generic ˆ x with x ∗ , we ﬁnd that { G k ( x ∗ ) − G k ( x k ) } is decreasing . By Equation ( 35 . 27 ) , it therefore converges to the limit 1 2 γ (cid:107) x ∗ − x ∗ (cid:107) 22 + 1 γ (cid:104) ( prox γf 1 − I ) ( x ∗ − γ ∇ f ( x ∗ ) ) , x ∗ − prox γf 1 ( x ∗ − γ ∇ f ( x ∗ ) ) (cid:105) = 0 . From the inequality in ( 35 . 28 ) , we conclude that the sequence { (cid:107) x ∗ − x k (cid:107) 22 } converges to zero , and so { x k } converges to x ∗ . This completes the proof of convergence of the FBS algorithm . 35 . 4 . 3 The CQ Algorithm as Forward - Backward Split - ting Recall that the split - feasibility problem ( SFP ) is to ﬁnd x in C with Ax in Q . The CQ algorithm minimizes the function g ( x ) = | | P Q Ax − Ax | | 22 , ( 35 . 29 ) over x ∈ C , whenever such minimizers exist , and so solves the SFP when - ever it has solutions . The CQ algorithm minimizes the function f ( x ) = ι C ( x ) + g ( x ) , ( 35 . 30 ) where ι C is the indicator function of the set C . With f 1 ( x ) = ι C ( x ) and f 2 ( x ) = g ( x ) , the function f ( x ) has the form considered by Combettes and Wajs , and the CQ algorithm becomes a special case of their forward - backward splitting method . 424 CHAPTER 35 . NON - SMOOTH OPTIMIZATION 35 . 5 Exercises Ex . 35 . 1 Let f ( x ) = x , for all real x . Compute the function m f ( z ) and show that it has no minimum . Ex . 35 . 2 Let C = [ − 1 , 1 ] . Show that the function P C z is the derivative of the function g ( z ) that is − z − 12 for z < − 1 , 12 z 2 for z in C , and z − 12 for z > 1 . Ex . 35 . 3 Let C be the unit ball in R 2 . Show that the operator P C is the gradient of the function g ( z ) that has the value 12 (cid:107) z (cid:107) 22 for (cid:107) z (cid:107) 2 ≤ 1 , and (cid:107) z (cid:107) 2 for (cid:107) z (cid:107) 2 > 1 . Ex . 35 . 4 Let C be a closed , non - empty convex set in R N . Show that the function g ( x ) = 1 2 ( (cid:107) x (cid:107) 2 2 − (cid:107) x − P C x (cid:107) 2 2 ) has a minimum if and only if x = 0 is in the set C . Hint : use Corollary 13 . 1 . Ex . 35 . 5 Show that prox f z = z if and only if z is a minimizer of the function f . Ex . 35 . 6 Let f ( x ) = | x | for all real x . Use Equation ( 35 . 2 ) to show that the operator prox f is not the orthogonal projection operator onto the set of minimizers of the function f . Ex . 35 . 7 Prove Equations ( 35 . 3 ) and ( 35 . 4 ) . Hint : for Equation ( 35 . 3 ) use Equation ( 4 . 1 ) . 35 . 6 Course Homework Do all the exercises in this chapter . Chapter 36 Generalized Pro jections onto Convex Sets 36 . 1 Chapter Summary The convex feasibility problem ( CFP ) is to ﬁnd a member of the nonempty set C = (cid:84) Ii = 1 C i , where the C i are closed convex subsets of R J . In most applications the sets C i are more easily described than the set C and al - gorithms are sought whereby a member of C is obtained as the limit of an iterative procedure involving ( exact or approximate ) orthogonal or gener - alized projections onto the individual sets C i . In his often cited paper [ 25 ] Bregman generalizes the SOP algorithm for the convex feasibility problem to include projections with respect to a generalized distance , and uses this successive generalized projections ( SGP ) method to obtain a primal - dual algorithm to minimize a convex function f : R J → R over the intersection of half - spaces , that is , over x with Ax ≥ b . The generalized distance is built from the function f , which then must exhibit additional properties , beyond convexity , to guarantee convergence of the algorithm . 36 . 2 Bregman Functions and Bregman Dis - tances The class of functions f that are used to deﬁne the generalized distance have come to be called Bregman functions ; the associated generalized dis - tances are then Bregman distances , which are used to deﬁne generalized projections onto closed convex sets ( see the book by Censor and Zenios [ 83 ] for details ) . In [ 12 ] Bauschke and Borwein introduce the related class 425 426 CHAPTER 36 . GENERALIZED PROJECTIONS ONTO CONVEX SETS of Bregman - Legendre functions and show that these functions provide an appropriate setting in which to study Bregman distances and generalized projections associated with such distances . See the chapter on Bregman - Legendre functions for further details . Bregman’s successive generalized projection ( SGP ) method uses pro - jections with respect to Bregman distances to solve the convex feasibility problem . Let f : R J → ( −∞ , + ∞ ] be a closed , proper convex function , with eﬀective domain D = dom f = { x | f ( x ) < + ∞ } and ∅ (cid:54) = int D . Denote by D f ( · , · ) : D × int D → [ 0 , + ∞ ) the Bregman distance , given by D f ( x , z ) = f ( x ) − f ( z ) − (cid:104)∇ f ( z ) , x − z (cid:105) ( 36 . 1 ) and by P fC i the Bregman projection operator associated with the convex function f and the convex set C i ; that is P fC i z = arg min x ∈ C i ∩ D D f ( x , z ) . ( 36 . 2 ) The Bregman projection of x onto C is characterized by Bregman’s Inequal - ity : (cid:104)∇ f ( P fC x ) − ∇ f ( x ) , c − P fC (cid:105) ≥ 0 , ( 36 . 3 ) for all c in C . 36 . 3 The Successive Generalized Projections Algorithm Bregman considers the following generalization of the SOP algorithm : Algorithm 36 . 1 Bregman’s method of Successive Generalized Pro - jections ( SGP ) : Beginning with x 0 ∈ int dom f , for k = 0 , 1 , . . . , let i = i ( k ) : = k ( mod I ) + 1 and x k + 1 = P fC i ( k ) ( x k ) . ( 36 . 4 ) He proves that the sequence { x k } given by ( 36 . 4 ) converges to a member of C ∩ dom f , whenever this set is nonempty and the function f is what came to be called a Bregman function ( [ 25 ] ) . Bauschke and Borwein [ 12 ] prove that Bregman’s SGP method converges to a member of C provided that one of the following holds : 1 ) f is Bregman - Legendre ; 2 ) C ∩ int D (cid:54) = ∅ and dom f ∗ is open ; or 3 ) dom f and dom f ∗ are both open , with f ∗ the function conjugate to f . In [ 25 ] Bregman goes on to use the SGP to ﬁnd a minimizer of a Breg - man function f ( x ) over the set of x such that Ax = b . Each hyperplane 36 . 4 . BREGMAN’S PRIMAL - DUAL ALGORITHM 427 associated with a single equation is a closed , convex set . The SGP ﬁnds the Bregman projection of the starting vector onto the intersection of the hyperplanes . If the starting vector has the form x 0 = A T d , for some vector d , then this Bregman projection also minimizes f ( x ) over x in the inter - section . Alternating Bregman projections also appears in Reich’s paper [ 179 ] . 36 . 4 Bregman’s Primal - Dual Algorithm The problem is to minimize f : R J → R over the set of all x for which Ax ≥ b . Begin with x 0 such that ∇ f ( x 0 ) = A T u 0 , for some u 0 ≥ 0 . For k = 0 , 1 , . . . , let i = k ( mod I ) + 1 . Having calculated x k , there are three possibilities : a ) if ( Ax k ) i < b i , then let x k + 1 be the Bregman projection onto the hyper - plane H i = { x | ( Ax ) i = b i } , so that ∇ f ( x k + 1 ) = ∇ f ( x k ) + λ k a i , ( 36 . 5 ) where a i is the i th column of A T . With ∇ f ( x k ) = A T u k , for u k ≥ 0 , update u k by u k + 1 i = u ki + λ k , ( 36 . 6 ) and u k + 1 m = u km , ( 36 . 7 ) for m (cid:54) = i . b ) if ( Ax k ) i = b i , or ( Ax k ) i > b i and u ki = 0 , then x k + 1 = x k , and u k + 1 = u k . c ) if ( Ax k ) i > b i and u ki > 0 , then let µ k be the smaller of the numbers µ (cid:48) k and µ (cid:48)(cid:48) k , where ∇ f ( y ) = ∇ f ( x k ) − µ (cid:48) k a i ( 36 . 8 ) puts y in H i , and µ (cid:48)(cid:48) k = u ki . ( 36 . 9 ) Then take x k + 1 with ∇ f ( x k + 1 ) = ∇ f ( x k ) − µ k a i . ( 36 . 10 ) 428 CHAPTER 36 . GENERALIZED PROJECTIONS ONTO CONVEX SETS With appropriate assumptions made about the function f , the sequence { x k } so deﬁned converges to a minimizer of f ( x ) over the set of x with Ax ≥ b . For a detailed proof of this result , see [ 83 ] . Bregman also suggests that this primal - dual algorithm be used to ﬁnd approximate solutions for linear programming problems , where the problem is to minimize a linear function c T x , subject to constraints . His idea is to replace the function c T x with h ( x ) = c T x + (cid:15)f ( x ) , and then apply his primal - dual method to h ( x ) . 36 . 5 Dykstra’s Algorithm for Bregman Pro - jections We are concerned now with ﬁnding the Bregman projection of x onto the intersection C of ﬁnitely many closed convex sets , C i . The problem can be solved by extending Dykstra’s algorithm to include Bregman projections . 36 . 5 . 1 A Helpful Lemma The following lemma helps to motivate the extension of Dykstra’s algo - rithm . Lemma 36 . 1 Suppose that ∇ f ( c ) − ∇ f ( x ) = ∇ f ( c ) − ∇ f ( c + p ) + ∇ f ( c ) − ∇ f ( c + q ) , ( 36 . 11 ) with c = P fA ( c + p ) and c = P fB ( c + q ) . Then c = P fC x . Proof : Let d be arbitrary in C . We have (cid:104)∇ f ( c ) − ∇ f ( c + p ) , d − c (cid:105) ≥ 0 , ( 36 . 12 ) and (cid:104)∇ f ( c ) − ∇ f ( c + q ) , d − c (cid:105) ≥ 0 . ( 36 . 13 ) Adding , we obtain (cid:104)∇ f ( c ) − ∇ f ( x ) , d − c (cid:105) ≥ 0 . ( 36 . 14 ) This suggests the following algorithm for ﬁnding c = P fC x , which turns out to be the extension of Dykstra’s algorithm to Bregman projections . 36 . 5 . DYKSTRA’S ALGORITHM FOR BREGMAN PROJECTIONS 429 Algorithm 36 . 2 ( Bregman - Dykstra ) Begin with b 0 = x , p 0 = q 0 = 0 . Deﬁne b n − 1 + p n − 1 = ∇ f − 1 ( ∇ f ( b n − 1 ) + r n − 1 ) , ( 36 . 15 ) a n = P fA ( b n − 1 + p n − 1 ) , ( 36 . 16 ) r n = ∇ f ( b n − 1 ) + r n − 1 − ∇ f ( a n ) , ( 36 . 17 ) ∇ f ( a n + q n − 1 ) = ∇ f ( a n ) + s n − 1 , ( 36 . 18 ) b n = P fB ( a n + q n − 1 ) , ( 36 . 19 ) and s n = ∇ f ( a n ) + s n − 1 − ∇ f ( b n ) . ( 36 . 20 ) In place of ∇ f ( c + p ) − ∇ f ( c ) + ∇ f ( c + q ) − ∇ f ( c ) , ( 36 . 21 ) we have r n − 1 + s n − 1 = [ ∇ f ( b n − 1 ) + r n − 1 ] − ∇ f ( b n − 1 ) + [ ∇ f ( a n ) + s n − 1 ] − ∇ f ( a n ) , ( 36 . 22 ) and also [ ∇ f ( a n ) + s n − 1 ] − ∇ f ( a n ) + [ ∇ f ( b n ) + r n ] − ∇ f ( b n ) = r n + s n − 1 . ( 36 . 23 ) But we also have r n − 1 + s n − 1 = ∇ f ( x ) − ∇ f ( b n − 1 ) , ( 36 . 24 ) and r n + s n − 1 = ∇ f ( x ) − ∇ f ( a n ) . ( 36 . 25 ) Then the sequences { a n } and { b n } converge to c . For further details , see the papers of Censor and Reich [ 79 ] and Bauschke and Lewis [ 17 ] . In [ 26 ] Bregman , Censor and Reich show that the extension of Dyk - stra’s algorithm to Bregman projections can be viewed as an extension of Bregman’s primal - dual algorithm to the case in which the intersection of half - spaces is replaced by the intersection of closed convex sets . 430 CHAPTER 36 . GENERALIZED PROJECTIONS ONTO CONVEX SETS Chapter 37 Compressed Sensing 37 . 1 Chapter Summary One area that has attracted much attention lately is compressed sensing or compressed sampling ( CS ) [ 98 ] . For applications such as medical imaging , CS may provide a means of reducing radiation dosage to the patient without sacriﬁcing image quality . An important aspect of CS is ﬁnding sparse solutions of under - determined systems of linear equations , which can often be accomplished by one - norm minimization . Perhaps the best reference to date on CS is [ 29 ] . 37 . 2 Compressed Sensing The objective in CS is exploit sparseness to reconstruct a vector f in R J from relatively few linear functional measurements [ 98 ] . Let U = { u 1 , u 2 , . . . , u J } and V = { v 1 , v 2 , . . . , v J } be two orthonormal bases for R J , with all members of R J represented as column vectors . For i = 1 , 2 , . . . , J , let µ i = max 1 ≤ j ≤ J { | (cid:104) u i , v j (cid:105) | } and µ ( U , V ) = max { µ i | i = 1 , . . . , I } . We know from Cauchy’s Inequality that | (cid:104) u i , v j (cid:105) | ≤ 1 , and from Parseval’s Equation J (cid:88) j = 1 | (cid:104) u i , v j (cid:105) | 2 = | | u i | | 22 = 1 . 431 432 CHAPTER 37 . COMPRESSED SENSING Therefore , we have 1 √ J ≤ µ ( U , V ) ≤ 1 . The quantity µ ( U , V ) is the coherence measure of the two bases ; the closer µ ( U , V ) is to the lower bound of 1 √ J , the more incoherent the two bases are . Let f be a ﬁxed member of R J ; we expand f in the V basis as f = x 1 v 1 + x 2 v 2 + . . . + x J v J . We say that the coeﬃcient vector x = ( x 1 , . . . , x J ) is s - sparse if s is the number of non - zero x j . If s is small , most of the x j are zero , but since we do not know which ones these are , we would have to compute all the linear functional values x j = (cid:104) f , v j (cid:105) to recover f exactly . In fact , the smaller s is , the harder it would be to learn anything from randomly selected x j , since most would be zero . The idea in CS is to obtain measurements of f with members of a diﬀerent orthonormal basis , which we call the U basis . If the members of U are very much like the members of V , then nothing is gained . But , if the members of U are quite unlike the members of V , then each inner product measurement y i = (cid:104) f , u i (cid:105) = f T u i should tell us something about f . If the two bases are suﬃciently inco - herent , then relatively few y i values should tell us quite a bit about f . Speciﬁcally , we have the following result due to Cand ` es and Romberg [ 67 ] : suppose the coeﬃcient vector x for representing f in the V basis is s - sparse . Select uniformly randomly M ≤ J members of the U basis and compute the measurements y i = (cid:104) f , u i (cid:105) . Then , if M is suﬃciently large , it is highly probable that z = x also solves the problem of minimizing the one - norm | | z | | 1 = | z 1 | + | z 2 | + . . . + | z J | , subject to the conditions y i = (cid:104) g , u i (cid:105) = g T u i , for those M randomly selected u i , where g = z 1 v 1 + z 2 v 2 + . . . + z J v J . The smaller µ ( U , V ) is , the smaller the M is permitted to be without reducing the probability of perfect reconstruction . 37 . 3 . SPARSE SOLUTIONS 433 37 . 3 Sparse Solutions Suppose that A is a real M by N matrix , with M < N , and that the linear system Ax = b has inﬁnitely many solutions . For any vector x , we deﬁne the support of x to be the subset S of { 1 , 2 , . . . , N } consisting of those n for which the entries x n (cid:54) = 0 . For any under - determined system Ax = b , there will , of course , be at least one solution of minimum support , that is , for which s = | S | , the size of the support set S , is minimum . However , ﬁnding such a maximally sparse solution requires combinatorial optimization , and is known to be computationally diﬃcult . It is important , therefore , to have a computationally tractable method for ﬁnding maximally sparse solutions . 37 . 3 . 1 Maximally Sparse Solutions Consider the problem P 0 : among all solutions x of the consistent system b = Ax , ﬁnd one , call it ˆ x , that is maximally sparse , that is , has the minimum number of non - zero entries . Obviously , there will be at least one such solution having minimal support , but ﬁnding one , however , is a combinatorial optimization problem and is generally NP - hard . 37 . 3 . 2 Minimum One - Norm Solutions Instead , we can seek a minimum one - norm solution x ∗ , that is , solve the problem P 1 : minimize | | x | | 1 = N (cid:88) n = 1 | x n | , subject to Ax = b . Problem P 1 can be formulated as a linear programming problem , so is more easily solved . The big questions are : when does P 1 have a unique solution x ∗ , and when is x ∗ = ˆ x ? The problem P 1 will have a unique solution if and only if A is such that the one - norm satisﬁes | | x ∗ | | 1 < | | x ∗ + v | | 1 , for all non - zero v in the null space of A . 37 . 3 . 3 Why the One - Norm ? When a system of linear equations Ax = b is under - determined , we can ﬁnd the minimum - two - norm solution that minimizes the square of the two - norm , | | x | | 22 = N (cid:88) n = 1 x 2 n , 434 CHAPTER 37 . COMPRESSED SENSING subject to Ax = b . One drawback to this approach is that the two - norm penalizes relatively large values of x n much more than the smaller ones , so tends to provide non - sparse solutions . Alternatively , we may seek the solution x ∗ for which the one - norm , | | x | | 1 = N (cid:88) n = 1 | x n | , is minimized . The one - norm still penalizes relatively large entries x n more than the smaller ones , but much less than the two - norm does . As a result , it often happens that the minimum one - norm solution actually solves P 0 as well . 37 . 3 . 4 Comparison with the PDFT The PDFT approach [ 33 , 34 ] to solving the under - determined system Ax = b is to select weights w n > 0 and then to ﬁnd the solution ˜ x that minimizes the weighted two - norm given by N (cid:88) n = 1 | x n | 2 w n . Our intention is to select weights w n so that w − 1 n is reasonably close to | x ∗ n | ; consider , therefore , what happens when w − 1 n = | x ∗ n | . We claim that ˜ x is also a minimum - one - norm solution . To see why this is true , note that , for any x , we have N (cid:88) n = 1 | x n | = N (cid:88) n = 1 | x n | (cid:112) | x ∗ n | (cid:112) | x ∗ n | ≤ (cid:118)(cid:117)(cid:117)(cid:116) N (cid:88) n = 1 | x n | 2 | x ∗ n | (cid:118)(cid:117)(cid:117)(cid:116) N (cid:88) n = 1 | x ∗ n | . Therefore , N (cid:88) n = 1 | ˜ x n | ≤ (cid:118)(cid:117) (cid:117)(cid:116) N (cid:88) n = 1 | ˜ x n | 2 | x ∗ n | (cid:118)(cid:117) (cid:117)(cid:116) N (cid:88) n = 1 | x ∗ n | ≤ (cid:118)(cid:117)(cid:117)(cid:116) N (cid:88) n = 1 | x ∗ n | 2 | x ∗ n | (cid:118)(cid:117)(cid:117)(cid:116) N (cid:88) n = 1 | x ∗ n | = N (cid:88) n = 1 | x ∗ n | . Therefore , ˜ x also minimizes the one - norm . 37 . 4 . WHY SPARSENESS ? 435 37 . 3 . 5 Iterative Reweighting Let x denote the truth . We want each weight w n to be a good prior estimate of the reciprocal of | x n | . Because we do not yet know x , we may take a sequential - optimization approach , beginning with weights w 0 n > 0 , ﬁnding the PDFT solution using these weights , then using this PDFT solution to get a ( we hope ! ) better choice for the weights , and so on . This sequential approach was successfully implemented in the early 1980’s by Michael Fiddy and his students [ 113 ] . In [ 68 ] , the same approach is taken , but with respect to the one - norm . Since the one - norm still penalizes larger values disproportionately , balance can be achieved by minimizing a weighted - one - norm , with weights close to the reciprocals of the | x ∗ n | . Again , not yet knowing x ∗ , they employ a sequential approach , using the previous minimum - weighted - one - norm so - lution to obtain the new set of weights for the next minimization . At each step of the sequential procedure , the previous reconstruction is used to estimate the true support of the desired solution . It is interesting to note that an on - going debate among users of the PDFT concerns the nature of the prior weighting . Again , let x be the truth . Does w n approximate | x n | − 1 or | x n | − 2 ? This is close to the issue treated in [ 68 ] , the use of a weight in the minimum - one - norm approach . It should be noted again that ﬁnding a sparse solution is not usually the goal in the use of the PDFT , but the use of the weights has much the same eﬀect as using the one - norm to ﬁnd sparse solutions : to the extent that the weights approximate the entries of | x ∗ | − 1 , their use reduces the penalty associated with the larger entries of an estimated solution . 37 . 4 Why Sparseness ? One obvious reason for wanting sparse solutions of Ax = b is that we have prior knowledge that the desired solution is sparse . Such a problem arises in signal analysis from Fourier - transform data . In other cases , such as in the reconstruction of locally constant signals , it is not the signal itself , but its discrete derivative , that is sparse . 37 . 4 . 1 Signal Analysis Suppose that our signal f ( t ) is known to consist of a small number of complex exponentials , so that f ( t ) has the form f ( t ) = J (cid:88) j = 1 a j e iω j t , 436 CHAPTER 37 . COMPRESSED SENSING for some small number of frequencies ω j in the interval [ 0 , 2 π ) . For n = 0 , 1 , . . . , N − 1 , let f n = f ( n ) , and let f be the N - vector with entries f n ; we assume that J is much smaller than N . The discrete ( vector ) Fourier transform of f is the vector ˆ f having the entries ˆ f k = 1 √ N N − 1 (cid:88) n = 0 f n e 2 πikn / N , for k = 0 , 1 , . . . , N − 1 ; we write ˆ f = Ef , where E is the N by N matrix with entries E kn = 1 √ N e 2 πikn / N . If N is large enough , we may safely assume that each of the ω j is equal to one of the frequencies 2 πik and that the vector ˆ f is J - sparse . The question now is : How many values of f ( n ) do we need to calculate in order to be sure that we can recapture f ( t ) exactly ? We have the following theorem [ 66 ] : Theorem 37 . 1 Let N be prime . Let S be any subset of { 0 , 1 , . . . , N − 1 } with | S | ≥ 2 J . Then the vector ˆ f can be uniquely determined from the measurements f n for n in S . We know that f = E † ˆ f , where E † is the conjugate transpose of the matrix E . The point here is that , for any matrix R obtained from the identity matrix I by deleting N − | S | rows , we can recover the vector ˆ f from the measurements Rf . If N is not prime , then the assertion of the theorem may not hold , since we can have n = 0 mod N , without n = 0 . However , the assertion remains valid for most sets of J frequencies and most subsets S of indices ; therefore , with high probability , we can recover the vector ˆ f from Rf . Note that the matrix E is unitary , that is , E † E = I , and , equivalently , the columns of E form an orthonormal basis for C N . The data vector is b = Rf = RE † ˆ f . In this example , the vector f is not sparse , but can be represented sparsely in a particular orthonormal basis , namely as f = E † ˆ f , using a sparse vector ˆ f of coeﬃcients . The representing basis then consists of the columns of the matrix E † . The measurements pertaining to the vector f are the values f n , for n in S . Since f n can be viewed as the inner product of f with δ n , the n th column of the identity matrix I , that is , f n = (cid:104) δ n , f (cid:105) , the columns of I provide the so - called sampling basis . With A = RE † and x = ˆ f , we then have Ax = b , 37 . 4 . WHY SPARSENESS ? 437 with the vector x sparse . It is important for what follows to note that the matrix A is random , in the sense that we choose which rows of I to use to form R . 37 . 4 . 2 Locally Constant Signals Suppose now that the function f ( t ) is locally constant , consisting of some number of horizontal lines . We discretize the function f ( t ) to get the vector f = ( f ( 0 ) , f ( 1 ) , . . . , f ( N ) ) T . The discrete derivative vector is g = ( g 1 , g 2 , . . . , g N ) T , with g n = f ( n ) − f ( n − 1 ) . Since f ( t ) is locally constant , the vector g is sparse . The data we will have will not typically be values f ( n ) . The goal will be to recover f from M linear functional values pertaining to f , where M is much smaller than N . We shall assume , from now on , that we have measured , or can estimate , the value f ( 0 ) . Our M by 1 data vector d consists of measurements pertaining to the vector f : d m = N (cid:88) n = 0 H mn f n , for m = 1 , . . . , M , where the H mn are known . We can then write d m = f ( 0 ) (cid:16) N (cid:88) n = 0 H mn (cid:17) + N (cid:88) k = 1 (cid:16) N (cid:88) j = k H mj (cid:17) g k . Since f ( 0 ) is known , we can write b m = d m − f ( 0 ) (cid:16) N (cid:88) n = 0 H mn (cid:17) = N (cid:88) k = 1 A mk g k , where A mk = N (cid:88) j = k H mj . The problem is then to ﬁnd a sparse solution of Ax = g . As in the previous example , we often have the freedom to select the linear functions , that is , the values H mn , so the matrix A can be viewed as random . 37 . 4 . 3 Tomographic Imaging The reconstruction of tomographic images is an important aspect of med - ical diagnosis , and one that combines aspects of both of the previous ex - amples . The data one obtains from the scanning process can often be 438 CHAPTER 37 . COMPRESSED SENSING interpreted as values of the Fourier transform of the desired image ; this is precisely the case in magnetic - resonance imaging , and approximately true for x - ray transmission tomography , positron - emission tomography ( PET ) and single - photon emission tomography ( SPECT ) . The images one encoun - ters in medical diagnosis are often approximately locally constant , so the associated array of discrete partial derivatives will be sparse . If this sparse derivative array can be recovered from relatively few Fourier - transform val - ues , then the scanning time can be reduced . We turn now to the more general problem of compressed sampling . 37 . 5 Compressed Sampling Our goal is to recover the vector f = ( f 1 , . . . , f N ) T from M linear functional values of f , where M is much less than N . In general , this is not possible without prior information about the vector f . In compressed sampling , the prior information concerns the sparseness of either f itself , or another vector linearly related to f . Let U and V be unitary N by N matrices , so that the column vectors of both U and V form orthonormal bases for C N . We shall refer to the bases associated with U and V as the sampling basis and the representing basis , respectively . The ﬁrst objective is to ﬁnd a unitary matrix V so that f = V x , where x is sparse . Then we want to ﬁnd a second unitary matrix U such that , when an M by N matrix R is obtained from U by deleting rows , the sparse vector x can be determined from the data b = RV x = Ax . Theorems in compressed sensing describe properties of the matrices U and V such that , when R is obtained from U by a random selection of the rows of U , the vector x will be uniquely determined , with high probability , as the unique solution that minimizes the one - norm . Bibliography 1 . Albright , B . ( 2007 ) “An introduction to simulated annealing . ” The College Mathematics Journal , 38 ( 1 ) , pp . 37 – 42 . 2 . Anderson , A . and Kak , A . ( 1984 ) “Simultaneous algebraic reconstruc - tion technique ( SART ) : a superior implementation of the ART algo - rithm . ” Ultrasonic Imaging , 6 pp . 81 – 94 . 3 . Attouch , H . ( 1984 ) Variational Convergence for Functions and Opera - tors , Boston : Pitman Advanced Publishing Program . 4 . Attouch , H . , and Wets , R . ( 1989 ) “Epigraphical analysis . ” Ann . Inst . Poincare : Anal . Nonlineaire , 6 . 5 . Aubin , J . - P . , ( 1993 ) Optima and Equilibria : An Introduction to Non - linear Analysis , Springer - Verlag . 6 . Auslander , A . , and Teboulle , M . ( 2006 ) “Interior gradient and prox - imal methods for convex and conic optimization . ” SIAM Journal on Optimization , 16 ( 3 ) , pp . 697 – 725 . 7 . Axelsson , O . ( 1994 ) Iterative Solution Methods . Cambridge , UK : Cam - bridge University Press . 8 . Baillon , J . - B . , Bruck , R . E . , and Reich , S . ( 1978 ) “On the asymptotic behavior of nonexpansive mappings and semigroups in Banach spaces . ” Houston Journal of Mathematics , 4 , pp . 1 – 9 . 9 . Bauschke , H . ( 1996 ) “The approximation of ﬁxed points of composi - tions of nonexpansive mappings in Hilbert space . ” Journal of Mathe - matical Analysis and Applications , 202 , pp . 150 – 159 . 10 . Bauschke , H . , and Borwein , J . ( 1993 ) “On the convergence of von Neumann’s alternating projection algorithm for two sets . ” Set - Valued Analysis , 1 , pp . 185 – 212 . 439 440 BIBLIOGRAPHY 11 . Bauschke , H . , and Borwein , J . ( 1996 ) “On projection algorithms for solving convex feasibility problems . ” SIAM Review , 38 ( 3 ) , pp . 367 – 426 . 12 . Bauschke , H . , and Borwein , J . ( 1997 ) “Legendre functions and the method of random Bregman projections . ” Journal of Convex Analysis , 4 , pp . 27 – 67 . 13 . Bauschke , H . , and Borwein , J . ( 2001 ) “Joint and separate convexity of the Bregman distance . ” in Inherently Parallel Algorithms in Feasibility and Optimization and their Applications , edited by D . Butnariu , Y . Censor and S . Reich , pp . 23 – 36 , Studies in Computational Mathematics 8 . Amsterdam : Elsevier Publ . 14 . Bauschke , H . , and Combettes , P . ( 2001 ) “A weak - to - strong convergence principle for Fej´er monotone methods in Hilbert spaces . ” Mathematics of Operations Research , 26 , pp . 248 – 264 . 15 . Bauschke , H . , and Combettes , P . ( 2003 ) “Iterating Bregman retrac - tions . ” SIAM Journal on Optimization , 13 , pp . 1159 – 1173 . 16 . Bauschke , H . , Combettes , P . , and Noll , D . ( 2006 ) “Joint minimiza - tion with alternating Bregman proximity operators . ” Paciﬁc Journal of Optimization , 2 , pp . 401 – 424 . 17 . Bauschke , H . , and Lewis , A . ( 2000 ) “Dykstra’s algorithm with Breg - man projections : a convergence proof . ” Optimization , 48 , pp . 409 – 427 . 18 . Becker , M . , Yang , I . , and Lange , K . ( 1997 ) “EM algorithms without missing data . ” Stat . Methods Med . Res . , 6 , pp . 38 – 54 . 19 . Bertero , M . , and Boccacci , P . ( 1998 ) Introduction to Inverse Problems in Imaging Bristol , UK : Institute of Physics Publishing . 20 . Bertsekas , D . P . ( 1997 ) “A new class of incremental gradient methods for least squares problems . ” SIAM J . Optim . , 7 , pp . 913 - 926 . 21 . Bertsekas , D . , and Tsitsiklis , J . ( 1989 ) Parallel and Distributed Com - putation : Numerical Methods . New Jersey : Prentice - Hall . 22 . Bliss , G . A . ( 1925 ) Calculus of Variations Carus Mathematical Mono - graphs , American Mathematical Society . 23 . Borwein , J . and Lewis , A . ( 2000 ) Convex Analysis and Nonlinear Opti - mization . Canadian Mathematical Society Books in Mathematics , New York : Springer - Verlag . 24 . Boyd , S . , and Vandenberghe , L . ( 2004 ) Convex Optimization . Cam - bridge , England : Cambridge University Press . BIBLIOGRAPHY 441 25 . Bregman , L . M . ( 1967 ) “The relaxation method of ﬁnding the common point of convex sets and its application to the solution of problems in convex programming . ” USSR Computational Mathematics and Mathe - matical Physics 7 : pp . 200 – 217 . 26 . Bregman , L . , Censor , Y . , and Reich , S . ( 1999 ) “Dykstra’s algorithm as the nonlinear extension of Bregman’s optimization method . ” Journal of Convex Analysis , 6 ( 2 ) , pp . 319 – 333 . 27 . Browne , J . and A . DePierro , A . ( 1996 ) “A row - action alternative to the EM algorithm for maximizing likelihoods in emission tomogra - phy . ” IEEE Trans . Med . Imag . 15 , pp . 687 – 699 . 28 . Bruck , R . E . , and Reich , S . ( 1977 ) “Nonexpansive projections and re - solvents of accretive operators in Banach spaces . ” Houston Journal of Mathematics , 3 , pp . 459 – 470 . 29 . Bruckstein , A . , Donoho , D . , and Elad , M . ( 2009 ) “From sparse solu - tions of systems of equations to sparse modeling of signals and images . ” SIAM Review , 51 ( 1 ) , pp . 34 – 81 . 30 . Burden , R . L . , and Faires , J . D . ( 1993 ) Numerical Analysis , Boston : PWS - Kent . 31 . Butnariu , D . , Byrne , C . , and Censor , Y . ( 2003 ) “Redundant axioms in the deﬁnition of Bregman functions . ” Journal of Convex Analysis , 10 , pp . 245 – 254 . 32 . Byrne , C . and Fitzgerald , R . ( 1979 ) “A unifying model for spectrum estimation . ” In Proceedings of the RADC Workshop on Spectrum Es - timation , Griﬃss AFB , Rome , NY , October . 33 . Byrne , C . and Fitzgerald , R . ( 1982 ) “Reconstruction from partial in - formation , with applications to tomography . ” SIAM J . Applied Math . 42 ( 4 ) , pp . 933 – 940 . 34 . Byrne , C . , Fitzgerald , R . , Fiddy , M . , Hall , T . , and Darling , A . ( 1983 ) “Image restoration and resolution enhancement . ” J . Opt . Soc . Amer . 73 , pp . 1481 – 1487 . 35 . Byrne , C . and Fitzgerald , R . ( 1984 ) “Spectral estimators that extend the maximum entropy and maximum likelihood methods . ” SIAM J . Ap - plied Math . 44 ( 2 ) , pp . 425 – 442 . 36 . Byrne , C . , Levine , B . M . , and Dainty , J . C . ( 1984 ) “Stable estimation of the probability density function of intensity from photon frequency counts . ” JOSA Communications 1 ( 11 ) , pp . 1132 – 1135 . 442 BIBLIOGRAPHY 37 . Byrne , C . and Fiddy , M . ( 1987 ) “Estimation of continuous object dis - tributions from Fourier magnitude measurements . ” JOSA A 4 , pp . 412 – 417 . 38 . Byrne , C . and Fiddy , M . ( 1988 ) “Images as power spectra ; reconstruc - tion as Wiener ﬁlter approximation . ” Inverse Problems 4 , pp . 399 – 409 . 39 . Byrne , C . ( 1993 ) “Iterative image reconstruction algorithms based on cross - entropy minimization . ” IEEE Transactions on Image Processing IP - 2 , pp . 96 – 103 . 40 . Byrne , C . ( 1995 ) “Erratum and addendum to ‘Iterative image re - construction algorithms based on cross - entropy minimization’ . ” IEEE Transactions on Image Processing IP - 4 , pp . 225 – 226 . 41 . Byrne , C . ( 1996 ) “Iterative reconstruction algorithms based on cross - entropy minimization . ”in Image Models ( and their Speech Model Cousins ) , S . E . Levinson and L . Shepp , editors , IMA Volumes in Mathe - matics and its Applications , Volume 80 , pp . 1 – 11 . New York : Springer - Verlag . 42 . Byrne , C . ( 1996 ) “Block - iterative methods for image reconstruction from projections . ” IEEE Transactions on Image Processing IP - 5 , pp . 792 – 794 . 43 . Byrne , C . ( 1997 ) “Convergent block - iterative algorithms for image re - construction from inconsistent data . ” IEEE Transactions on Image Pro - cessing IP - 6 , pp . 1296 – 1304 . 44 . Byrne , C . ( 1998 ) “Accelerating the EMML algorithm and related it - erative algorithms by rescaled block - iterative ( RBI ) methods . ” IEEE Transactions on Image Processing IP - 7 , pp . 100 – 109 . 45 . Byrne , C . ( 1998 ) “Iterative algorithms for deblurring and deconvolu - tion with constraints . ” Inverse Problems , 14 , pp . 1455 – 1467 . 46 . Byrne , C . ( 2000 ) “Block - iterative interior point optimization methods for image reconstruction from limited data . ” Inverse Problems 16 , pp . 1405 – 1419 . 47 . Byrne , C . ( 2001 ) “Bregman - Legendre multi - distance projection algo - rithms for convex feasibility and optimization . ” in Inherently Paral - lel Algorithms in Feasibility and Optimization and their Applications , edited by D . Butnariu , Y . Censor and S . Reich , pp . 87 - 100 , Studies in Computational Mathematics 8 . Amsterdam : Elsevier Publ . 48 . Byrne , C . ( 2001 ) “Likelihood maximization for list - mode emission to - mographic image reconstruction . ” IEEE Transactions on Medical Imag - ing 20 ( 10 ) , pp . 1084 – 1092 . BIBLIOGRAPHY 443 49 . Byrne , C . , and Censor , Y . ( 2001 ) “Proximity function minimization using multiple Bregman projections , with applications to split feasibil - ity and Kullback - Leibler distance minimization . ” Annals of Operations Research , 105 , pp . 77 – 98 . 50 . Byrne , C . ( 2002 ) “Iterative oblique projection onto convex sets and the split feasibility problem . ” Inverse Problems 18 , pp . 441 – 453 . 51 . Byrne , C . ( 2004 ) “A uniﬁed treatment of some iterative algorithms in signal processing and image reconstruction . ” Inverse Problems 20 , pp . 103 – 120 . 52 . Byrne , C . ( 2005 ) “Choosing parameters in block - iterative or ordered - subset reconstruction algorithms . ” IEEE Transactions on Image Pro - cessing , 14 ( 3 ) , pp . 321 – 327 . 53 . Byrne , C . ( 2005 ) Signal Processing : A Mathematical Approach , AK Peters , Publ . , Wellesley , MA . 54 . Byrne , C . ( 2007 ) Applied Iterative Methods , AK Peters , Publ . , Welles - ley , MA . 55 . Byrne , C . ( 2008 ) “Sequential unconstrained minimization algorithms for constrained optimization . ” Inverse Problems , 24 ( 1 ) , article no . 015013 . 56 . Byrne , C . ( 2009 ) “Block - iterative algorithms . ” International Transac - tions in Operations Research , 16 ( 4 ) , pp . 427 – 463 . 57 . Byrne , C . ( 2009 ) “Bounds on the largest singular value of a matrix and the convergence of simultaneous and block - iterative algorithms for sparse linear systems . ” International Transactions in Operations Research , 16 ( 4 ) , pp . 465 – 479 . 58 . Byrne , C . ( 2013 ) “Alternating minimization as sequential uncon - strained minimization : a survey . ” Journal of Optimization Theory and Applications , electronic 154 ( 3 ) , DOI 10 . 1007 / s1090134 - 2 , ( 2012 ) , and hardcopy 156 ( 3 ) , February , 2013 , pp . 554 – 566 . 59 . Byrne , C . ( 2013 ) “An elementary proof of convergence of the forward - backward splitting algorithm . ” to appear in the Journal of Nonlinear and Convex Analysis . 60 . Byrne , C . ( 2009 ) Applied and Computational Linear Algebra : A First Course , available as a pdf ﬁle at my web site . 61 . Byrne , C . , and Eggermont , P . ( 2011 ) “EM Algorithms . ” in Handbook of Mathematical Methods in Imaging , Otmar Scherzer , ed . , Springer - Science . 444 BIBLIOGRAPHY 62 . Byrne , C . , Censor , Y . , A . Gibali , A . , and Reich , S . ( 2012 ) “The split common null point problem . ” Journal of Nonlinear and Convex Anal - ysis , 13 , pp . 759 – 775 . 63 . Byrne , C . ( 2012 ) “Alternating minimization as sequential uncon - strained minimization : a survey . ” Journal of Optimization Theory and Applications , electronic 154 ( 3 ) , DOI 10 . 1007 / s1090134 - 2 , ( 2012 ) , and hardcopy 156 ( 3 ) , February , 2013 , pp . 554 – 566 . 64 . Byrne , C . ( 2013 ) “An elementary proof of convergence of the forward - backward splitting algorithm . ” to appear in the Journal of Nonlinear and Convex Analysis . 65 . Byrne , C . , and Ward , S . ( 2005 ) “Estimating the largest singular value of a sparse matrix . ” unpublished notes . 66 . Cand ` es , E . , Romberg , J . , and Tao , T . ( 2006 ) “Robust uncertainty prin - ciples : exact signal reconstruction from highly incomplete frequency information . ” IEEE Transactions on Information Theory , 52 ( 2 ) , pp . 489 – 509 . 67 . Cand ` es , E . , and Romberg , J . ( 2007 ) “Sparsity and incoherence in com - pressive sampling . ” Inverse Problems , 23 ( 3 ) , pp . 969 – 985 . 68 . Cand ` es , E . , Wakin , M . , and Boyd , S . ( 2007 ) “Enhancing sparsity by reweighted l 1 minimization . ” preprint available at http : / / www . acm . caltech . edu / emmanuel / publications . html . 69 . Censor , Y . , Bortfeld , T . , Martin , B . , and Troﬁmov , A . “A uniﬁed ap - proach for inversion problems in intensity - modulated radiation ther - apy . ” Physics in Medicine and Biology 51 ( 2006 ) , 2353 - 2365 . 70 . Censor , Y . , Eggermont , P . P . B . , and Gordon , D . ( 1983 ) “Strong under - relaxation in Kaczmarz’s method for inconsistent systems . ” Numerische Mathematik 41 , pp . 83 – 92 . 71 . Censor , Y . and Elfving , T . ( 1994 ) “A multi - projection algorithm using Bregman projections in a product space . ” Numerical Algorithms , 8 221 – 239 . 72 . Censor , Y . , Elfving , T . , Herman , G . T . , and Nikazad , T . ( 2008 ) “On diagonally - relaxed orthogonal projection methods . ” SIAM Journal on Scientiﬁc Computation , 30 ( 1 ) , pp . 473 – 504 . 73 . Censor , Y . , Elfving , T . , Kopf , N . , and Bortfeld , T . ( 2005 ) “The multiple - sets split feasibility problem and its application for inverse problems . ” Inverse Problems , 21 , pp . 2071 - 2084 . BIBLIOGRAPHY 445 74 . Censor , Y . , Gibali , A . , and Reich , S . ( 2010 ) “The split variational inequality problem . ” technical report . 75 . Censor , Y . , Gibali , A . , and Reich , S . ( 2010 ) “The subgradient extra - gradient method for solving variational inequalities in Hilbert space . ” technical report . 76 . Censor , Y . , Gordon , D . , and Gordon , R . ( 2001 ) “Component averag - ing : an eﬃcient iterative parallel algorithm for large and sparse un - structured problems . ” Parallel Computing , 27 , pp . 777 – 808 . 77 . Censor , Y . , Gordon , D . , and Gordon , R . ( 2001 ) “BICAV : A block - iterative , parallel algorithm for sparse systems with pixel - related weighting . ” IEEE Transactions on Medical Imaging , 20 , pp . 1050 – 1060 . 78 . Censor , Y . , Iusem , A . , and Zenios , S . ( 1998 ) “An interior point method with Bregman functions for the variational inequality problem with paramonotone operators . ” Mathematical Programming , 81 , pp . 373 – 400 . 79 . Censor , Y . , and Reich , S . ( 1998 ) “The Dykstra algorithm for Bregman projections . ” Communications in Applied Analysis , 2 , pp . 323 – 339 . 80 . Censor , Y . , and Reich , S . ( 1996 ) “Iterations of paracontractions and ﬁrmly nonexpansive operators with applications to feasibility and op - timization . ” Optimization , 37 , pp . 323 – 339 . 81 . Censor , Y . and Segman , J . ( 1987 ) “On block - iterative maximization . ” J . of Information and Optimization Sciences 8 , pp . 275 – 291 . 82 . Censor , Y . , and Zenios , S . A . ( 1992 ) “Proximal minimization algorithm with D - functions . ” Journal of Optimization Theory and Applications , 73 ( 3 ) , pp . 451 – 464 . 83 . Censor , Y . and Zenios , S . A . ( 1997 ) Parallel Optimization : Theory , Algorithms and Applications . New York : Oxford University Press . 84 . Cheney , W . , and Goldstein , A . ( 1959 ) “Proximity maps for convex sets . ” Proc . Amer . Math . Soc . , 10 , pp . 448 – 450 . 85 . Cimmino , G . ( 1938 ) “Calcolo approssimato per soluzioni dei sistemi di equazioni lineari . ” La Ricerca Scientiﬁca XVI , Series II , Anno IX 1 , pp . 326 – 333 . 86 . Combettes , P . ( 2000 ) “Fej´er monotonicity in convex optimization . ”in Encyclopedia of Optimization , C . A . Floudas and P . M . Pardalos , edi - tors , Boston : Kluwer Publ . 446 BIBLIOGRAPHY 87 . Combettes , P . ( 2001 ) “Quasi - Fej´erian analysis of some optimization algorithms . ” in Inherently Parallel Algorithms in Feasibility and Op - timization and their Applications , edited by D . Butnariu , Y . Censor and S . Reich , pp . 87 - 100 , Studies in Computational Mathematics 8 . Amsterdam : Elsevier Publ . 88 . Combettes , P . , and Wajs , V . ( 2005 ) “Signal recovery by proximal forward - backward splitting . ” Multiscale Modeling and Simulation , 4 ( 4 ) , pp . 1168 – 1200 . 89 . Conn , A . , Scheinberg , K . , and Vicente , L . ( 2009 ) Introduction to Derivative - Free Optimization : MPS - SIAM Series on Optimization . Philadelphia : Society for Industrial and Applied Mathematics . 90 . Csisz´ar , I . ( 1975 ) “I - divergence geometry of probability distributions and minimization problems . ” The Annals of Probability 3 ( 1 ) , pp . 146 – 158 . 91 . Csisz´ar , I . ( 1989 ) “A geometric interpretation of Darroch and Ratcliﬀ’s generalized iterative scaling . ” The Annals of Statistics 17 ( 3 ) , pp . 1409 – 1413 . 92 . Csisz´ar , I . and Tusn´ady , G . ( 1984 ) “Information geometry and alter - nating minimization procedures . ” Statistics and Decisions Supp . 1 , pp . 205 – 237 . 93 . Darroch , J . and Ratcliﬀ , D . ( 1972 ) “Generalized iterative scaling for log - linear models . ” Annals of Mathematical Statistics 43 , pp . 1470 – 1480 . 94 . Dempster , A . P . , Laird , N . M . and Rubin , D . B . ( 1977 ) “Maximum likeli - hood from incomplete data via the EM algorithm . ” Journal of the Royal Statistical Society , Series B 37 , pp . 1 – 38 . 95 . De Pierro , A . and Iusem , A . ( 1990 ) “On the asymptotic behavior of some alternate smoothing series expansion iterative methods . ” Linear Algebra and its Applications 130 , pp . 3 – 24 . 96 . Deutsch , F . , and Yamada , I . ( 1998 ) “Minimizing certain convex func - tions over the intersection of the ﬁxed point sets of non - expansive map - pings . ” Numerical Functional Analysis and Optimization , 19 , pp . 33 – 56 . 97 . Dines , K . , and Lyttle , R . ( 1979 ) “Computerized geophysical tomogra - phy . ” Proc . IEEE , 67 , pp . 1065 – 1073 . 98 . Donoho , D . ( 2006 ) “Compressed sampling” IEEE Transactions on In - formation Theory , 52 ( 4 ) . ( download preprints at http : / / www . stat . stanford . edu / donoho / Reports ) . BIBLIOGRAPHY 447 99 . Dorfman , R . , Samuelson , P . , and Solow , R . ( 1958 ) Linear Programming and Economic Analysis . New York : McGraw - Hill . 100 . Driscoll , P . , and Fox , W . ( 1996 ) “Presenting the Kuhn - Tucker condi - tions using a geometric method . ” The College Mathematics Journal , 38 ( 1 ) , pp . 101 – 108 . 101 . Duﬃn , R . , Peterson , E . , and Zener , C . ( 1967 ) Geometric Program - ming : Theory and Applications . New York : Wiley . 102 . Duda , R . , Hart , P . , and Stork , D . ( 2001 ) Pattern Classiﬁcation , Wiley . 103 . Dugundji , J . ( 1970 ) Topology Boston : Allyn and Bacon , Inc . 104 . Dykstra , R . ( 1983 ) “An algorithm for restricted least squares regres - sion . ” J . Amer . Statist . Assoc . , 78 ( 384 ) , pp . 837 – 842 . 105 . Eggermont , P . P . B . , Herman , G . T . , and Lent , A . ( 1981 ) “Iterative algorithms for large partitioned linear systems , with applications to image reconstruction . ” Linear Algebra and its Applications 40 , pp . 37 – 67 . 106 . Eggermont , P . , and LaRiccia , V . ( 2001 ) Maximum Penalized Likeli - hood Estimation . New York : Springer . 107 . Elsner , L . , Koltracht , L . , and Neumann , M . ( 1992 ) “Convergence of sequential and asynchronous nonlinear paracontractions . ” Numerische Mathematik , 62 , pp . 305 – 319 . 108 . Facchinei , F . , and Pang , J . S . ( 2003 ) Finite Dimensional Variational Inequalities and Complementarity Problems , Volumes I and II . New York : Springer Verlag . 109 . Fang , S - C . , and Puthenpura , S . ( 1993 ) Linear Optimization and Ex - tensions : Theory and Algorithms . New Jersey : Prentice - Hall . 110 . Farkas , J . ( 1902 ) “¨Uber die Theorie der einfachen Ungleichungen . ” J . Reine Angew . Math . , 124 , pp . 1 – 24 . 111 . Farncombe , T . ( 2000 ) “Functional dynamic SPECT imaging using a single slow camera rotation . ” Ph . D . thesis , Dept . of Physics , University of British Columbia . 112 . Fiacco , A . , and McCormick , G . ( 1990 ) Nonlinear Programming : Se - quential Unconstrained Minimization Techniques . Philadelphia , PA : SIAM Classics in Mathematics ( reissue ) . 113 . Fiddy , M . ( 2008 ) private communication . 448 BIBLIOGRAPHY 114 . Fleming , W . ( 1965 ) Functions of Several Variables . Reading , MA : Addison - Wesley . 115 . Gale , D . ( 1960 ) The Theory of Linear Economic Models . New York : McGraw - Hill . 116 . Geman , S . , and Geman , D . ( 1984 ) “Stochastic relaxation , Gibbs dis - tributions and the Bayesian restoration of images . ” IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI - 6 , pp . 721 – 741 . 117 . Gill , P . , Murray , W . , Saunders , M . , Tomlin , J . , and Wright , M . ( 1986 ) “On projected Newton barrier methods for linear programming and an equivalence to Karmarkar’s projective method . ” Mathematical Pro - gramming , 36 , pp . 183 – 209 . 118 . Goebel , K . , and Reich , S . ( 1984 ) Uniform Convexity , Hyperbolic Ge - ometry , and Nonexpansive Mappings , New York : Dekker . 119 . Golshtein , E . , and Tretyakov , N . ( 1996 ) Modiﬁed Lagrangians and Monotone Maps in Optimization . New York : John Wiley and Sons , Inc . 120 . Gordan , P . ( 1873 ) “¨Uber die Auﬂ¨osungen linearer Gleichungen mit reelen Coeﬃcienten . ” Math . Ann . , 6 , pp . 23 – 28 . 121 . Gordon , R . , Bender , R . , and Herman , G . T . ( 1970 ) “Algebraic recon - struction techniques ( ART ) for three - dimensional electron microscopy and x - ray photography . ” J . Theoret . Biol . 29 , pp . 471 – 481 . 122 . Gordon , D . , and Gordon , R . ( 2005 ) “Component - averaged row projec - tions : A robust block - parallel scheme for sparse linear systems . ” SIAM Journal on Scientiﬁc Computing , 27 , pp . 1092 – 1117 . 123 . Gubin , L . G . , Polyak , B . T . and Raik , E . V . ( 1967 ) “The method of projections for ﬁnding the common point of convex sets . ” USSR Com - putational Mathematics and Mathematical Physics , 7 : 1 – 24 . 124 . Hager , W . ( 1988 ) Applied Numerical Linear Algebra , Englewood Cliﬀs , NJ : Prentice Hall . 125 . Hager , B . , Clayton , R . , Richards , M . , Comer , R . , and Dziewonsky , A . ( 1985 ) “Lower mantle heterogeneity , dynamic typography and the geoid . ” Nature , 313 , pp . 541 – 545 . 126 . Herman , G . T . ( 1999 ) private communication . 127 . Herman , G . T . and Meyer , L . ( 1993 ) “Algebraic reconstruction tech - niques can be made computationally eﬃcient . ” IEEE Transactions on Medical Imaging 12 , pp . 600 – 609 . BIBLIOGRAPHY 449 128 . Hildreth , C . ( 1957 ) “A quadratic programming procedure . ” Naval Research Logistics Quarterly , 4 , pp . 79 – 85 . Erratum , ibid . , p . 361 . 129 . Hiriart - Urruty , J . - B . , and Lemar´echal , C . ( 2001 ) Fundamentals of Convex Analysis . Berlin : Springer . 130 . Holte , S . , Schmidlin , P . , Linden , A . , Rosenqvist , G . and Eriksson , L . ( 1990 ) “Iterative image reconstruction for positron emission tomogra - phy : a study of convergence and quantitation problems . ” IEEE Trans - actions on Nuclear Science 37 , pp . 629 – 635 . 131 . Hudson , M . , Hutton , B . , and Larkin , R . ( 1992 ) “Accelerated EM reconstruction using ordered subsets . ” Journal of Nuclear Medicine , 33 , p . 960 . 132 . Hudson , H . M . and Larkin , R . S . ( 1994 ) “Accelerated image reconstruc - tion using ordered subsets of projection data . ” IEEE Transactions on Medical Imaging 13 , pp . 601 – 609 . 133 . Jiang , M . , and Wang , G . ( 2003 ) “Convergence studies on iterative algorithms for image reconstruction . ” IEEE Transactions on Medical Imaging , 22 ( 5 ) , pp . 569 – 579 . 134 . Kaczmarz , S . ( 1937 ) “Angen¨aherte Auﬂ¨osung von Systemen linearer Gleichungen . ” Bulletin de l’Academie Polonaise des Sciences et Lettres A35 , pp . 355 – 357 . 135 . Kalman , D . ( 2009 ) “Leveling with Lagrange : An alternate view of constrained optimization . ” Mathematics Magazine , 82 ( 3 ) , pp . 186 – 196 . 136 . Karmarkar , N . ( 1984 ) “A new polynomial - time algorithm for linear programming . ” Combinatorica , 4 , pp . 373 – 395 . 137 . K¨orner , T . ( 1996 ) The Pleasures of Counting . Cambridge , UK : Cam - bridge University Press . 138 . Korpelevich , G . ( 1976 ) “The extragradient method for ﬁnding saddle points and other problems . ” Ekonomika i Matematcheskie Metody ( in Russian ) , 12 , pp . 747 – 756 . 139 . Krasnosel’skii , M . ( 1955 ) “Two observations on the method of sequen - tial approximations . ” Uspeki Mathematicheskoi Nauki ( in Russian ) , 10 ( 1 ) . 140 . Kuhn , H . , and Tucker , A . ( eds . ) ( 1956 ) Linear Inequalities and Re - lated Systems . Annals of Mathematical Studies , No . 38 . New Jersey : Princeton University Press . 450 BIBLIOGRAPHY 141 . Kullback , S . and Leibler , R . ( 1951 ) “On information and suﬃ - ciency . ” Annals of Mathematical Statistics 22 , pp . 79 – 86 . 142 . Lagarias , J . , Reeds , J . , Wright , M . , and Wright , P . ( 1998 ) “Conver - gence properties of the Nelder - Mead simplex method in low dimen - sions . ” SIAM Journal of Optimization , 9 ( 1 ) , pp . 112 – 147 . 143 . Landweber , L . ( 1951 ) “An iterative formula for Fredholm integral equations of the ﬁrst kind . ” Amer . J . of Math . 73 , pp . 615 – 624 . 144 . Lange , K . and Carson , R . ( 1984 ) “EM reconstruction algorithms for emission and transmission tomography . ” Journal of Computer Assisted Tomography 8 , pp . 306 – 316 . 145 . Lange , K . , Bahn , M . and Little , R . ( 1987 ) “A theoretical study of some maximum likelihood algorithms for emission and transmission tomography . ” IEEE Trans . Med . Imag . MI - 6 ( 2 ) , pp . 106 – 114 . 146 . Leahy , R . and Byrne , C . ( 2000 ) “Guest editorial : Recent development in iterative image reconstruction for PET and SPECT . ” IEEE Trans . Med . Imag . 19 , pp . 257 – 260 . 147 . Lent , A . , and Censor , Y . ( 1980 ) “Extensions of Hildreth’s row - action method for quadratic programming . ” SIAM Journal on Control and Optimization , 18 , pp . 444 – 454 . 148 . Levy , A . ( 2009 ) The Basics of Practical Optimization . Philadelphia : SIAM Publications . 149 . Lucet , Y . ( 2010 ) “What shape is your conjugate ? A survey of compu - tational convex analysis and its applications . ” SIAM Review , 52 ( 3 ) , pp . 505 – 542 . 150 . Luenberger , D . ( 1969 ) Optimization by Vector Space Methods . New York : John Wiley and Sons , Inc . 151 . Luo , Z . , Ma , W . , So , A . , Ye , Y . , and Zhang , S . ( 2010 ) “Semideﬁnite relaxation of quadratic optimization problems . ” IEEE Signal Process - ing Magazine , 27 ( 3 ) , pp . 20 – 34 . 152 . Mann , W . ( 1953 ) “Mean value methods in iteration . ” Proc . Amer . Math . Soc . 4 , pp . 506 – 510 . 153 . Marlow , W . ( 1978 ) Mathematics for Operations Research . New York : John Wiley and Sons . Reissued 1993 by Dover . 154 . Marzetta , T . ( 2003 ) “Reﬂection coeﬃcient ( Schur parameter ) repre - sentation for convex compact sets in the plane . ” IEEE Transactions on Signal Processing , 51 ( 5 ) , pp . 1196 – 1210 . BIBLIOGRAPHY 451 155 . McKinnon , K . ( 1998 ) “Convergence of the Nelder - Mead simplex method to a non - stationary point . ” SIAM Journal on Optimization , 9 ( 1 ) , pp . 148 – 158 . 156 . McLachlan , G . J . and Krishnan , T . ( 1997 ) The EM Algorithm and Extensions . New York : John Wiley and Sons , Inc . 157 . Metropolis , N . , Rosenbluth , A . , Rosenbluth , M . , Teller , A . , and Teller , E . ( 1953 ) “Equation of state calculations by fast computing machines” J . Chem . Phys . 21 , pp . 1087 – 1091 . 158 . Moreau , J . - J . ( 1962 ) “Fonctions convexes duales et points proximaux dans un espace hilbertien . ” C . R . Acad . Sci . Paris S´er . A Math . , 255 , pp . 2897 – 2899 . 159 . Moreau , J . - J . ( 1963 ) “Propri´et´es des applications ‘prox’ . ” C . R . Acad . Sci . Paris S´er . A Math . , 256 , pp . 1069 – 1071 . 160 . Moreau , J . - J . ( 1965 ) “Proximit´e et dualit´e dans un espace hilbertien . ” Bull . Soc . Math . France , 93 , pp . 273 – 299 . 161 . Narayanan , M . , Byrne , C . and King , M . ( 2001 ) “An interior point iterative maximum - likelihood reconstruction algorithm incorporating upper and lower bounds with application to SPECT transmission imag - ing . ” IEEE Transactions on Medical Imaging TMI - 20 ( 4 ) , pp . 342 – 353 . 162 . Nasar , S . ( 1998 ) A Beautiful Mind . New York : Touchstone . 163 . Nash , S . and Sofer , A . ( 1996 ) Linear and Nonlinear Programming . New York : McGraw - Hill . 164 . Nelder , J . , and Mead , R . ( 1965 ) “A simplex method for function min - imization” Computing Journal , 7 , pp . 308 – 313 . 165 . Nesterov , Y . , and Nemirovski , A . ( 1994 ) Interior - Point Polynomial Algorithms in Convex Programming . Philadelphia , PA : SIAM Studies in Applied Mathematics . 166 . von Neumann , J . , and Morgenstern , O . ( 1944 ) Theory of Games and Economic Behavior . New Jersey : Princeton University Press . 167 . Niven , I . ( 1981 ) Maxima and Minima Without Calculus . Mathemati - cal Association of America . 168 . Noor , M . A . ( 1999 ) “Some algorithms for general monotone mixed variational inequalities . ” Mathematical and Computer Modelling , 29 , pp . 1 – 9 . 452 BIBLIOGRAPHY 169 . Noor , M . A . ( 2003 ) “Extragradient methods for pseudomonotone vari - ational inequalities . ” Journal of Optimization Theory and Applica - tions , 117 ( 3 ) , pp . 475 – 488 . 170 . Noor , M . A . ( 2004 ) “Some developments in general variational inequal - ities . ” Applied Mathematics and Computation , 152 , pp . 199 – 277 . 171 . Noor , M . A . ( 2010 ) “On an implicit method for nonconvex variational inequalities . ” Journal of Optimization Theory and Applications , 147 , pp . 411 – 417 . 172 . Opial , Z . ( 1967 ) “Weak convergence of the sequence of successive ap - proximations for nonexpansive mappings . ” Bulletin of the American Mathematical Society , 73 , pp . 591 – 597 . 173 . Ortega , J . , and Rheinboldt , W . ( 2000 ) Iterative Solution of Nonlinear Equations in Several Variables , Classics in Applied Mathematics , 30 . Philadelphia , PA : SIAM , 2000 174 . Papoulis , A . ( 1977 ) Signal Analysis . New York : McGraw - Hill . 175 . Peressini , A . , Sullivan , F . , and Uhl , J . ( 1988 ) The Mathematics of Nonlinear Programming . New York : Springer - Verlag . 176 . Quinn , F . ( 2011 ) “A science - of - learning approach to mathematics edu - cation . ” Notices of the American Mathematical Society , 58 , pp . 1264 – 1275 ; see also http : / / www . math . vt . edu / people / quinn / . 177 . Reich , S . ( 1979 ) “Weak convergence theorems for nonexpansive map - pings in Banach spaces . ” Journal of Mathematical Analysis and Ap - plications , 67 , pp . 274 – 276 . 178 . Reich , S . ( 1980 ) “Strong convergence theorems for resolvents of ac - cretive operators in Banach spaces . ” Journal of Mathematical Analysis and Applications , pp . 287 – 292 . 179 . Reich , S . ( 1996 ) “A weak convergence theorem for the alternating method with Bregman distances . ” Theory and Applications of Nonlin - ear Operators , New York : Dekker . 180 . Renegar , J . ( 2001 ) A Mathematical View of Interior - Point Methods in Convex Optimization . Philadelphia , PA : SIAM ( MPS - SIAM Series on Optimization ) . 181 . Rockafellar , R . ( 1970 ) Convex Analysis . Princeton , NJ : Princeton University Press . BIBLIOGRAPHY 453 182 . Rockmore , A . , and Macovski , A . ( 1976 ) “A maximum likelihood approach to emission image reconstruction from projections . ” IEEE Transactions on Nuclear Science , NS - 23 , pp . 1428 – 1432 . 183 . Schelling , T . ( 1980 ) The Strategy of Conﬂict . Cambridge , MA : Har - vard University Press . 184 . Schmidlin , P . ( 1972 ) “Iterative separation of sections in tomographic scintigrams . ” Nucl . Med . 15 ( 1 ) . 185 . Schroeder , M . ( 1991 ) Fractals , Chaos , Power Laws , W . H . Freeman , New York . 186 . Shepp , L . , and Vardi , Y . ( 1982 ) “Maximum likelihood reconstruction for emission tomography . ” IEEE Transactions on Medical Imaging , MI - 1 , pp . 113 – 122 . 187 . Shermer , M . ( 2008 ) “The Doping Dilemma” Scientiﬁc American , April 2008 , pp . 82 – 89 . 188 . Shieh , M . , Byrne , C . , and Fiddy , M . ( 2006 ) “Image reconstruction : a unifying model for resolution enhancement and data extrapolation : Tutorial . ” Journal of the Optical Society of America , A , 23 ( 2 ) , pp . 258 – 266 . 189 . Shieh , M . , Byrne , C . , Testorf , M . , and Fiddy , M . ( 2006 ) “Iterative image reconstruction using prior knowledge . ” Journal of the Optical Society of America , A , 23 ( 6 ) , pp . 1292 – 1300 . 190 . Shieh , M . , and Byrne , C . ( 2006 ) “Image reconstruction from limited Fourier data . ” Journal of the Optical Society of America , A , 23 ( 11 ) , pp . 2732 – 2736 . 191 . Simmons , G . ( 1972 ) Diﬀerential Equations , with Applications and Historical Notes . New York : McGraw - Hill . 192 . Stevens , S . ( 2008 ) Games People Play . A course on DVD available from The Teaching Company , www . TEACH12 . com . 193 . Stiemke , E . ( 1915 ) “¨Uber positive L¨osungen homogener linearer Gle - ichungen . ” Math . Ann , 76 , pp . 340 – 342 . 194 . Tanabe , K . ( 1971 ) “Projection method for solving a singular system of linear equations and its applications . ” Numer . Math . 17 , pp . 203 – 214 . 195 . Teboulle , M . ( 1992 ) “Entropic proximal mappings with applications to nonlinear programming . ” Mathematics of Operations Research , 17 ( 3 ) , pp . 670 – 690 . 454 BIBLIOGRAPHY 196 . Tucker , A . ( 1956 ) “Dual systems of homogeneous linear relations . ” in [ 140 ] , pp . 3 – 18 . 197 . van der Sluis , A . ( 1969 ) “Condition numbers and equilibration of ma - trices . ” Numer . Math . , 14 , pp . 14 – 23 . 198 . van der Sluis , A . , and van der Vorst , H . A . ( 1990 ) “SIRT - and CG - type methods for the iterative solution of sparse linear least - squares problems . ” Linear Algebra and its Applications , 130 , pp . 257 – 302 . 199 . Vardi , Y . , Shepp , L . A . and Kaufman , L . ( 1985 ) “A statistical model for positron emission tomography . ” Journal of the American Statistical Association 80 , pp . 8 – 20 . 200 . Woeginger , G . ( 2009 ) “When Cauchy and H¨older met Minkowski . ” Mathematics Magazine , 82 ( 3 ) , pp . 202 – 207 . 201 . Wright , M . ( 2005 ) “The interior - point revolution in optimization : his - tory , recent developments , and lasting consequences . ” Bulletin ( New Series ) of the American Mathematical Society , 42 ( 1 ) , pp . 39 – 56 . 202 . Wright , M . ( 2009 ) “The dual ﬂow between linear algebra and opti - mization . ” view - graphs of talk given at the History of Numerical Linear Algebra Minisymposium - Part II , SIAM Conference on Applied Linear Algebra , Monterey , CA , October 28 , 2009 . 203 . Yang , Q . ( 2004 ) “The relaxed CQ algorithm solving the split feasibil - ity problem . ” Inverse Problems , 20 , pp . 1261 – 1266 . Index A T , 96 , 216 A † , 96 LU factorization , 98 QR factorization , 97 S ⊥ , 68 ι C ( x ) , 154 λ max ( S ) , 371 ν - ism , 362 (cid:107) A (cid:107) 1 , 371 (cid:107) A (cid:107) 2 , 373 (cid:107) A (cid:107) F , 25 (cid:107) A (cid:107) ∞ , 372 ρ ( B ) , 374 σ C ( a ) , 408 i C ( x ) , 408 s j , 285 ( SDP ) , 327 Bregman - Legendre function , 317 Accessability Lemma , 77 AF algorithm , 243 aﬀ ( C ) , 69 aﬃne function , 405 aﬃne hull of a set , 69 algebraic reconstruction technique , 221 alternating minimization , 282 , 341 Arithmetic Mean - Geometric Mean In - equality , 16 ART , 216 , 221 auxiliary function , 243 av operator , 362 averaged operator , 195 , 362 Banach - Picard Theorem , 358 basic feasible solution , 105 , 110 basic variable , 95 , 111 basis , 91 BFGS method , 204 bi - section method , 7 binding constraint , 175 block - iterative methods , 338 Bolzano - Weierstrass Theorem , 48 boundary of a set , 66 boundary point , 66 bounded sequence , 47 Brachistochrone Problem , 296 Bregman distance , 155 , 257 , 426 Bregman function , 425 Bregman projection , 426 Bregman’s Inequality , 316 , 426 Broyden class , 204 Burg entropy , 298 canonical form , 106 Cauchy sequence , 48 Cauchy’s Inequality , 64 Cauchy - Schwarz Inequality , 64 CFP , 397 Cholesky Decomposition , 102 clipping operator , 9 closed convex function , 153 closed set , 65 closure of a function , 154 closure of a set , 65 cluster point of a sequence , 66 co - coercive operator , 362 coercive function , 150 complementary slackness , 175 complementary slackness condition , 108 , 178 455 456 INDEX compressed sampling , 187 , 431 compressed sensing , 431 concave function , 409 condition number , 371 conjugate function , 406 conjugate gradient method , 231 , 237 conjugate set , 235 constant - sum game , 127 continuous function , 49 , 148 contraction , 356 converge to inﬁnity , 47 convex combination , 67 , 85 convex feasibility problem , 397 convex function , 75 , 145 convex function of several variables , 153 convex hull , 67 convex programming , 169 convex set , 9 , 67 core of a set , 157 Courant - Beltrami penalty , 252 covariance matrix , 23 CP , 169 CQ algorithm , 218 , 401 critical point , 150 cycloid , 302 DART , 221 Decomposition Theorem , 73 derivative of a function , 321 descent algorithm , 194 DFP method , 204 diﬀerentiable function of several vari - ables , 148 diﬀerential of a function , 321 direct - search methods , 205 direction of unboundedness , 70 directional derivative , 56 distance from a point to a set , 65 Dolidze’s Theorem , 379 dot product , 31 double ART , 221 dual feasibility , 178 dual geometric programming prob - lem , 35 dual problem , 106 dual problem in CP , 182 duality gap , 108 duality gap for CP , 182 Dykstra’s algorithm , 402 eﬀective domain , 76 , 426 eigenvalue , 24 , 96 eigenvector , 24 , 96 eigenvector / eigenvalue decomposition , 24 EKN Theorem , 368 Elsner - Koltracht - Neumann Theorem , 368 EM - MART , 226 EMML algorithm , 225 , 285 , 335 EMVT , 142 entry of a vector , 46 epi ( f ) , 75 epi - graph of a function , 75 essentially smooth , 315 essentially strictly convex , 315 Euclidean distance , 63 Euclidean length , 63 Euclidean norm , 63 Euclidean space , 319 Euler - Lagrange Equation , 300 Ext ( C ) , 70 Extended Mean Value Theorem , 142 exterior - point method , 252 extreme point , 70 Farkas’ Lemma , 79 , 109 FBS , 421 feasible points , 169 feasible set , 105 feasible - point methods , 208 Fenchel conjugate , 406 Fenchel’s Duality Theorem , 411 Fermi - Dirac generalized entropies , 291 ﬁlter gain , 23 INDEX 457 ﬁrmly non - expansive operator , 163 , 360 ﬁxed point , 195 , 355 fne , 163 , 360 forward - backward splitting , 421 Fr´echet derivative , 58 Frobenius norm , 25 , 320 , 370 full - rank property , 184 , 343 functional , 6 , 295 Fundamental Theorem of Game The - ory , 413 Gˆateaux derivative , 57 Gale’s Strong Duality Theorem , 108 gauge function , 167 , 408 generalized AGM Inequality , 17 Geometric Hahn - Banach Theorem , 76 geometric programming problem , 34 glb , 45 gradient , 321 , 322 gradient descent method , 8 Gram - Schmidt method , 236 greatest lower bound , 45 H¨older’s Inequality , 19 Halpern - Lions - Wittmann - Bauschke al - gorithm , 402 , 403 harmonic mean , 30 Helly’s Theorem , 82 Hermitian matrix , 96 Hessian matrix , 149 Hilbert space , 64 HLWB algorithm , 402 hyperplane , 68 incoherent bases , 432 indicator function , 75 , 154 , 400 , 408 induced matrix norm , 370 inf , 45 inferior limit , 50 , 51 inﬁmal convolution , 408 inﬁmal deconvolution , 408 inﬁmum , 45 inner product , 20 , 64 integer programming , 116 interior of a set , 66 interior point , 66 interior - point methods , 9 , 208 Intermediate Value Theorem , 141 intrinsic inner product , 324 inverse barrier function , 248 inverse of a matrix , 93 inverse strongly monotone , 362 invertible matrix , 93 IPA , 260 ism operator , 362 Isoperimetric Problem , 304 IVT , 141 Karush - Kuhn - Tucker Theorem , 174 KKT Theorem , 174 KL distance , 38 , 280 KMO Theorem , 365 Korpelevich’s algorithm , 379 Krasnosel’skii - Mann - Opial Theorem , 365 Krylov subspace , 238 Kullback - Leibler distance , 38 , 280 , 346 Lagrange multiplier , 171 Lagrangian , 171 Landweber algorithm , 217 least squares ART , 234 least squares solution , 217 , 232 least upper bound , 45 least - squares , 253 Legendre function , 315 Legendre transform , 409 Legendre - Fenchel Transformation , 406 level set , 255 likelihood function , 346 lim inf , 50 , 51 lim sup , 50 , 51 limit of a sequence , 46 , 66 lineality space , 158 linear combination , 90 linear convergence , 207 458 INDEX linear function , 405 linear independence , 91 linear manifold , 68 linear programming , 105 Lipschitz continuity , 356 Lipschitz continuous function , 144 , 148 Lipschitz continuous operator , 163 Lipschitz function , 144 , 148 local inner product , 324 logarithmic barrier function , 248 lower semi - continuous function , 52 , 153 LS - ART , 234 lub , 45 MART , 38 , 224 matrix game , 127 matrix inverse , 93 maximum likelihood , 346 Mean Value Theorem , 142 Metropolis algorithm , 211 Min - Max Theorem , 413 minimum norm solution , 216 minimum one - norm solution , 187 minimum two - norm solution , 5 , 187 Minkowski’s Inequality , 20 monotone operators , 377 , 393 Moreau envelope , 400 multi - directional search algorithms , 205 multiplicative algebraic reconstruc - tion technique , 38 , 224 mutually orthogonal vectors , 64 MVT , 142 MVT for integrals , 142 Nash equilibrium , 3 ne , 163 , 356 Nelder - Mead algorithm , 205 Newton step , 323 Newton - Raphson algorithm , 202 , 232 non - expansive operator , 163 non - expansive , 356 non - negative deﬁnite , 24 norm of a vector , 20 norm - constrained least - squares , 253 normal cone , 70 , 391 normal vector , 70 objective function , 1 one - norm , 46 , 85 , 187 open set , 66 operator , 194 operator on R J , 163 order of convergence , 207 orthogonal complement , 68 orthogonal matrix , 24 orthogonal projection , 70 , 360 P´olya - Szeg¨o Inequality , 21 paracontractive , 366 Parallelogram Law , 64 partial derivative , 56 partial - gradient methods , 338 pc , 366 PDFT , 434 PMA , 258 polyhedron , 69 polytope , 69 positive deﬁnite , 24 positive homogeneous function , 158 posynomials , 34 preconditioned conjugate gradient , 239 primal feasibility , 178 primal problem in CP , 169 primal - dual algorithm , 108 , 211 , 333 , 425 projected gradient algorithm , 208 projected Landweber algorithm , 217 proper function , 75 proximal minimization , 258 proximal operator , 417 , 418 proximity function , 398 proximity operator , 400 , 417 QCQP , 326 quadratic convergence , 207 INDEX 459 quadratic programming , 191 , 329 quadratic - loss penalty , 252 quadratically constrained quadratic programs , 326 quasi - Newton methods , 203 quasi - non - expansive , 376 rank of a matrix , 93 rate of convergence , 206 reduced cost vector , 117 reduced gradient algorithm , 209 reduced Hessian matrix , 209 reduced Newton - Raphson method , 209 reduced steepest descent method , 208 regularization , 222 relative interior , 69 resolvent operator , 393 ri ( C ) , 69 Rolle’s Theorem , 141 row - action algorithm , 186 saddle point , 172 , 387 sc , 358 self - adjoint operator , 322 self - concordant function , 203 , 324 semi - continuous convex function , 153 semi - deﬁnite programming , 327 sensitivity vector , 171 Separation Theorem , 76 SFP , 218 , 378 , 400 SGP , 425 , 426 Sherman - Morrison - Woodbury Iden - tity , 118 SIMOP , 401 simplex multipliers , 117 simulated annealing algorithm , 211 simultaneous MART , 225 , 261 simultaneous orthogonal projections , 401 slack variable , 107 Slater point , 169 SMART , 225 , 261 , 285 , 340 SMVIP , 394 SOP , 401 span , 91 spanning set , 91 spectral radius , 374 split monotone variational inclusion , 394 split variational inequality problem , 385 split - feasibility problem , 218 , 378 , 400 standard form , 106 steepest descent algorithm , 196 steepest descent method , 232 strict contraction , 358 strictly convex function , 145 , 153 Strong Duality Theorem , 108 strongly monotone operators , 377 sub - additive function , 158 sub - diﬀerential , 156 sub - gradient , 156 sub - linear function , 158 subdiﬀerential , 391 submultiplicativity , 370 subsequential limit point , 66 subspace , 67 , 90 successive generalized projection method , 425 , 426 successive orthogonal projection method , 401 sup , 45 , 172 super - coercive , 316 super - consistent , 169 superior limit , 50 , 51 support function , 87 , 408 , 419 Support Theorem , 76 supremum , 172 SVIP , 385 symmetric game , 132 symmetric matrix , 96 symmetric square root , 24 Theorems of the Alternative , 78 trace of a matrix , 25 , 31 transpose , 216 transpose of a matrix , 63 Triangle Inequality , 64 460 INDEX two - norm , 46 , 187 , 216 upper semi - continuous function , 52 value of a game , 132 variational inequality problem , 379 vector space , 90 vectorization , 320 VIP , 379 Weak Duality Theorem , 107 weakly ism , 365 , 378 Wolfe’s algorithm , 331 zero - sum games , 127