XXX - X - XXXX - XXXX - X / XX / $ XX . 00 ©20XX IEEE Filtering Impolite Words in Social Network Using Naïve Bayes Classifier Lusiana Teknik Informatika STMIK Amik Riau Pekanbaru , Indonesia lusiana @ stmik - amik - riau . co . id Hijrah Gemini Teknik Informatika STMIK Amik Riau Pekanbaru , Indonesia HijrahGemini @ gmail . com Yoyon Efendi Teknik Informatika STMIK Amik Riau Pekanbaru , Indonesia yoyonefendi @ stmik - amik - riau . ac . id Abstract — The development of information on social networks has been progressing rapidly . Nowadays , just by clicking one button , the user can spread the information throughout social network users . The quick spreaded information sometimes misused by some irresponsible users . These irresponsible users spread impolite words to others or it is just an act of their opinion expression . Those impolite words on social networks have become one of the reasons they are rated as a problem and the existence of these words may interfere the activity of other users . Due to the importance of this research , we created a system to filter impolite words that exist in content . The system uses one of Machine Learning’s methods which can detect and filter words automatically . This system achieve the accuracy of 74 % , the precision of 66 , 67 % , the recall of 70 % and the F - Measure of 68 , 29 % in filtering impolite words . This research provides convenience places to share information and opinion for social network users Keywords — Filtering System , impolite words , Social Network , Naïve Bayes Classifier I . I NTRODUCTION Social networks have evolved very quickly , especially in the interaction between their users . With just one button , a message can be shared to all network users . This easy distribution of information is often misused by some users who disseminate information in the form of disrespectful phrases . In the " Global Threat Report " released in March 2007 , Scansafe reported the results of an analysis of websites frequented by users and stated that 80 % of blog content contained offensive content ranging from the use of vulgar language to pornographic images ( Cheng , 2007 ) Inappropriate usage of offensive phrases should not be uploaded because social media is for all kind of people . So that it can disturb the convenience and activity of other users in social networks , especially in discussion forums . It is also expressed by Zhi Xu and Sencun Zhu in his research entitled Filtering Offensive Language in Online Communities using Grammatical Relations that the presence of inappropriate language in the online community may lead users to leave the forum and will influence the development of the forum ( Xu & Zhu , 2010 ) . In addition , the research also disclosed that the inappropriate language used can be mentally problematic for users , especially for teenagers . This is the reason why the problem is solved . In order to maintain and create the comfort and polite culture among fellow members of the discussion forum required a system that can detect and filter out the phrases which are not polite . So part of the comments and topics that contain irreverent phrases do not appear on discussion forums . Previous research by Trivedi , A . , & Mahida , S . ( 2013 ) uses Naïve Bayes to filter a chat whether the chat is offensive or not and provides a comparison of the ratio of the chat . Another study titled Status and Comment Filing Application on Facebook ( Kusuma W , Sarwosri , & Esti , 2016 ) uses the Naïve Bayes method to filter out negative content on Facebook . In the study built a separate web that can filter the status and comments by taking data that exist on Facebook . The basic idea of this detection system is useful to alert the user that the uploaded content has disrespectful phrases . The detection and filtration of inappropriate phrases is done by using one of the Machine Learning methods of the Naïve Bayes Classifier . Naïve Bayes Classifier is one of the methods that can be used for text classification and is part of supervised learning that requires training data as a reference in the classification . The difference of this study with the research that has been done previously lies in the case studied . The structure of the rest of this paper is as follows . Section 2 briefly discusses the related work . In section 3 of this paper presents the research methods . Result and discussion are presented in Section 4 . Finally , section 5 discusses conclusion and future work . II . R ELATED W ORK Currently , offensive content ( or language ) and shameful are spreading widely by people who do not responsible to social media . While , users of social network are not only adults but also teenagers even children underage . There are many efforts have been done to detect of the offensive language . They deal with cyberbullying content ( Reynolds et al , 2011 ; Dadvar , 2013 ) , inappropriate content especially profanity , insult and object of insults ( Sood et al . , 2012 ; singh , 2015 ; Gitari et al . , 2015 ) , sentence offensiveness prediction and user offensiveness estimation ( Chen et al . , 2012 ) , the hate speech on online ( Warner & Hirschberg , 2012 ; Djuric et al . , 2015 ; Gitari et al . , 2015 ) , hidden group ( Fu et al , 2012 ) , profane language ( Xiang , 2012 ) , flaming words ( Shukla et al , 2012 ) , abusive text messages ( Kansara & Shekokar , 2015 ) , and Offensive comment ( Ismail & Bchir , 2015 ) . Some techniques are applied during the detection of offensive language on social media . The detection of cyberbullying has performed by applying Language - based method ( Reynold et al . , 2011 ) and Support Vector Machine ( Dadvar et al . , 2013 ) . Inappropriate content is like profanity , insults and object of insults can be detect by using Machine Learning approach ( Sood et al . , 2012 ; Singh , 2015 ) . Chen et al ( 2012 ) has used Lexical Syntactic Feature ( LSF ) to detect : ( 1 ) offensive language ( or contents ) with the level of success of precision 98 , 24 % and recall 94 . 34 % . ( 2 ) users who spreading negative content and the level of success of precision 77 . 9 % and recall as much as 77 , 8 % . The hate speech can be detected by applying Continuous Bag of Word ( CBOW ) neural language model ( Djuric et al . , 2015 ) , template - based strategy ( Warner & Hirschberg , 2012 ) , and lexicon - based approach ( Gitari et al . , 2015 ) . Abusive text messages or images is recognized by using Support Vector Machine and Naïve Bayes classifiers ( Kansara & Shekokar , 2015 ) . Offensive comments can also be detected by applying local multi - classifier fusion method ( Ismail & Bchir , 2015 ) . Another challenge of the detection of offensive language is a lack of resources in another language . Most of resources are only in English Language , a chance to detect the use of offensive content in another language is remain exist ( Mohamed Maher Ben Ismail 2015 ) . III . R ESEARCH M ETHOD This section describes the research method will be presented in Fig . 1 . Fig . 1 . The Phrases Filter System Figure 1 describes the phrase filter system : First the text on the topic or comment will go into the system , then the text will be processed by applying pre - processing . Pre - processing is comprised four ( 4 ) processes : ( 1 ) Case Folding . Case folding stage is to change all the uppercase in a document to lowercase . ( 2 ) Tokenizing . Tokenizing is to separate the syllables and also use to eliminate the punctuation . ( 3 ) Stop - word removal . After passing the tokenization , then the un - relevant texts will be removed . ( 4 ) Stemming process . This is a form of Information Retrieval ( IR ) . IR means that to retrieve or transform words to root word . Then the text will go into the extraction stage which use n - gram ( bi - gram ) . Once extracted , the system will perform the calculation process using Naïve Bayes Classifier to classify the text to be positive or negative word . After the calculation process is completed , the text will be classified according to the existing training data . If the text is positive word then the text will be directly uploaded into the discussion forum , whilst if the text identified negative then the text will be filtered . IV . R ESULT AND D ISCUSSION This section demonstrate filtering process of impolite phrases on the discussion forum . a . Text entered into the system . In Table 1 is text whill be tested and filtered on a system . TABLE 1 . Text List Enter Into System No Phrases 1 Kamu terlihat seperti wanita jalang 2 Dasar babi kau ! 3 Kamu memang kurang ajar 4 Anak tidak tahu malu 5 Anak anjing kau ! b . Case Folding . It is presented in Table 2 . TABLE 2 . Case Folding No Case Folding Process 1 kamu terlihat seperti wanita jalang 2 dasar babi kau ! 3 kamu memang kurang ajar 4 anak tidak tahu malu 5 anak anjing kau ! c . Tokenizing . Based on Table 2 is obtained the result as Table 3 . TABLE 3 . Tokenizing Result No Tokenizing Process 1 kamu  terlihat  seperti  wanita  jalang 2 dasar  babi  kau 3 kamu  memang  kurang  ajar 4 anak  tidak  tahu  malu 5 anak  anjing  kau d . Filtering . Table 4 presented the filtering result . TABLE 4 . Filtering Result Filtering Process of each Phrases 1 2 3 4 5 kamu , seperti dasar , kau kamu , memang anak anak , kau e . Stemming . In the test text there is a word that has a affixon ( ex . ter ) so that the word will be returned to the basic form of the word by removing the affixes . The result is presented by Table 5 . TABLE 5 . Stemming Proses Stemming of each Phrases 1 2 3 4 5 lihat wanita jalang babi kurang ajar tidak tahu malu anjing f . n - gram Process . According Table 5 is applying n - gram process . In this n - gram process , bi - gram is used to cut the 2 words so that it looks like Table 6 . TABLE 6 . n - gram Process No . Phrases n - gram Process 1 lihat wanita wanita jalang 2 babi babi 3 kurang ajar 4 tidak tahu tahu malu 5 anjing anjing g . Naïve Bayes Classifier ( NBC ) An initial stage in the NBC process is to calculate the probability of each class of the overall training data . It is noticed that the data train are 806 data with the number of classes as 2 categories of “positive” and “negative” . Here are the probability calculations for “positive” and “negative” classes . From the calculation above , probability value for class “positive” is 0 . 5 . The next step is to classify the test data by using probability value of each class that has been obtained . After getting the probability of each class the next step is to determine the value n , nc , p and m for each existing class and for each term being tested . 1 . Positive Category 2 . Negative Category After the calculation is completed , then the comparison of positive values and negative values are as follows : Vnb = argmax ( v ( positive )  v ( negative ) Maximum value obtained is 0 . 000017380 . 0 . 000017380 . It is a " negative " class value . So that , the conclusion obtained is the test data including the class " negative " . h . Validity Testing Validity testing will search for precision and recall of the system based on test data that has been selected . Prior to the calculation of precision and recall , it required the calculation of true positive , true negative , false positive and false negative from the test data . TABLE 7 . Some Data of The Validity Testing No Sentences Original Value Testing Value 1 Kamu terlihat seperti wanita jalang Negative Negative 2 Kamu memang kurang ajar ! Dasar ga tahu diri . Negative Negative 3 Anjing dan majikannya terlihat kompak . Positive Positive 4 Dasar babi kau ! Negative Positive 5 . Babi itu sangat gemuk . Positive Positive 6 . Anjingmu sangat lucu Positive Positive 7 . Setan selalu menggoda manusia Positive Negative 8 . Setan kau ! Aku terkejut Negative Negative 9 . Anak tidak tahu malu ! Negative Negative 10 . Dasar pelacur murahan ! Negative Negative 11 . Dia anak yang tidak tahu diri ! Negative Negative 12 . Dia anak yang pemalu . Positive Positive 13 . Bajingan itu berulang kali membuatku marah ! Negative Negative 14 . Babi itu haram di makan oleh umat Islam Positive Negative 15 . Anak anjing itu terlihat lucu . Positive Positive 16 . Anak anjing kau ! Negative Negative 17 . Dia bersikap sombong karena orang tuanya kaya . Positive Positive 18 . Anjrit . Sial sekali aku hari ini Negative Negative 19 . Anak itu keras kepala dan sulit diatur . Positive Positive 20 . Dia sudah tidak cantik lagi karena sudah tua . Positive Positive 21 . Kabarnya dia itu anak diluar pernikahan alias anak haram Negative Positive 22 . Kamu bodoh sekali mau menerima dia sebagai temanmu . Negative Negative 23 . Dasar wanita serakah ! Semua mau diembat ! Negative Negative 24 . Wanita yang tinggal di kampung sebelah meninggal kemarin . Positive Positive 25 . Kampungan kau ! Itu saja tidak tau . Negative Positive 26 . Babi merupakan hewan yang diminati di Korea Selatan Positive Negative 27 . Dia memang kurang ajar . Tidak bisa menghormati orang tuanya Negative Negative 28 . Sinting kau ! Jangan ngomong seperti itu sama orang tua Negative Negative 29 . Dasar wanita bayaran ! Berani - beraninya menggoda orang , tidak tau diri ! Negative Negative 30 . Kenapa orang menganggap dia bodoh ? Padahal dia cukup pintar pada bidang lain . Positive Negative 31 . Dasar babi kau ! Negative Positive 32 . Kau bodoh ! Mau saja percaya dia ! Negative Negative 33 . Pengecut bodoh kau ini ! Tidak bisa apa - apa ! Negative Negative 34 . Monyet adalah binatang yang Positive Positive lucu . 35 . Monyet kau ! Tertawa di atas penderitaan orang lain Negative Positive 36 . Anjingnya makan daging di halaman rumah Positive Positive 37 . Kamu brengsek ! main di belakang ku ! Negative Negative 38 . Setan alas ! Kenapa kamu datang ke sini ? Negative Negative 39 . Dia memperkerjakan gigolo di rumahnya ! Negative Negative 40 . Gaya berpakaiannya kampungan . Negative Positive 41 . Kampung halamannya ada di Pekanbaru Positive Negative 42 . Kamu munafik , sok baik ! Negative Negative 43 . Pelacur murahan ! Tidak tau tata krama ! Negative Negative 44 . Anjing si songong ! Segitu aja sombong Negative Negative 45 . Binatang itu suka hidup di alam bebas Positive Positive 46 . Keparat ! Urusi saja urusanmu ! Negative Negative 47 . Aku memang bernasib sial . Positive Negative 48 . Setan terbuat dari api Positive Positive 49 . Monyet itu tertawa bahagia melihatku ! Positive Positive 50 . Kambing kau ! Pemalas mandi ! Negative Positive Based on Table 7 is obtained Table 8 Table 8 . Calculation Validity Prediction Negative Predicton Positive Phrases Positive 23 7 Phrases Negative 6 14 where : True Negative ( TN ) = 23 False Positive ( FP ) = 7 True Positive ( TP ) = 14 False Negative ( FN ) = 6 According Table 8 is done the validity testing to look for recall , precision , accuracy and F - Measure . • Recall . Recall is the percentage of system success in rediscovering information . Recall = ( TP / ( TP + FN ) ) * 100 % = ( 14 / 20 ) * 100 % = 70 % • Precision . Precision is the percentage of accuracy of the information the user requests with the answers provided by the system . Here ' s the calculation of precision on the system : Precision = ( TP / ( TP + FP ) ) * 100 % = ( 14 / 21 ) * 100 % = 66 , 67 % • Accuracy . Accuracy is the percentage of closeness between the predicted value and the actual value . • F - Measure . F - Measure is the average of precision and recall . The result of this test is precision system equal to 66 , 67 % , recall system equal to 70 % , accuracy system equal to 74 % and F - Measure equal to 68 , 29 % . V . C ONCLUSION From the analysis and discussion that the author did in the previous chapters , some conclusions can be drawn ; ( 1 ) by filtering system on discussion forums , disrespectful phrases can be filtered automatically so as to reduce users who use disrespectful phrases in discussion forums , ( 2 ) the system is capable of alerting users before uploading topics containing obscene phrases and it may display information on the probability value of malicious phrases uploaded on discussion forums , ( 3 ) the testing process is done using 806 training data that has accuracy equal to 74 % , precision rate is 66 , 67 % , recall is 70 % and F - Measure is equal to 68 , 29 % with balanced positive data and negative data , ( 4 ) system development can also be done by adding the function of the system in order to filter the text on the image . A CKNOWLEDGMENT We would like to thank the reviewers for their constructive comments , which have helped shape this paper . R EFERENCES [ 1 ] Adriani , M . , Asian , J . , Nazief , B . , & Williams , H . E . ( 2007 ) . Stemming Indonesian : A Confix - Stripping Approach . ACM Transactions on Asian Language Information Processing , 6 ( 4 ) , 1 – 33 . https : / / doi . org / 10 . 1145 / 1316457 . 1316459 . [ 2 ] Cheng , J . 2007 . Report : 80 percent of blogs contain " offensive " content . ars technical . [ 3 ] Chen , Y . , Zhou , Y . , & Xu , H . ( 2012 ) . Detecting Offensive Language in Social Media to Protect Adolescent Online Safety . ASE / IEEE International Conference on Social Computing , 71 – 80 . https : / / doi . org / 10 . 1109 / SocialCom - PASSAT . 2012 . 55 [ 4 ] Dadvar , M . , D . Trieschnigg , R . Ordelman and F . de Jong , 2013 . Improving cyberbullying detection with user context . In Advances in Information Retrieval ( pp . 693 - 696 ) : Springer . [ 5 ] Fu , M . - H . , C . - H . Peng , Y . - H . Ku and K . - R . Lee , 2012 . Hidden community detection based on microblog by opinion - consistent analysis . Paper presented at the Information Society ( i - Society ) , 2012 International Conference on . [ 6 ] Gitari , N . D . , Z . Zuping , H . Damien and J . Long , 2015 . A Lexicon - based Approach for Hate Speech Detection [ 7 ] Ismail , M . M . B . and O . Bchir , 2015 . Insult detection in social network comments using possibilistic based fusion approach . In Computer and Information Science , pp : 15 - 25 . [ 8 ] Kansara , K . B . and N . M . Shekokar , 2015 . A Framework for Cyberbullying Detection in Social Network . [ 9 ] Mohamed Maher Ben Ismail , O . B . ( 2015 ) . " Insult Detection in Social Network Comments Using Possibilistic Based Fusion Approach . " Computer and Information Science , Studies in Computational Intelligence 566 , Springer International Publishing Switzerland [ 10 ] Reynolds , K . , A . Kontostathis and L . Edwards , 2011 . Using machine learning to detect cyberbullying . Paper presented at the Machine Learning and Applications and Workshops ( ICMLA ) , 2011 10th International [ 11 ] Singh , S . , S . Nakhare , K . Nair , R . Shetty , 2015 . A System to Detect Inappropriate Messages in Online Social Networks . World Academy of Science , Engineering and Technology , International Science Index , Mechanical and Mechatronics Engineering . [ 12 ] Sood , S . O . , E . F . Churchill and J . Antin , 2012 . Automatic identification of personal insults on social news sites . Journal of the American Society for Information Science and Technology , 63 ( 2 ) : 270 - 285 . [ 13 ] Shukla , S . S . P . , S . P . Singh , N . S . Parande , A . Khare and N . K . Pandey , 2012 . Flame Detector Model : A Prototype for Detecting Flames in Social Networking Sites . Paper presented at the Computer Modelling and Simulation ( UKSim ) , 2012 UKSim 14th International Conference on . [ 14 ] Trivedi , A . , & Mahida , S . ( 2013 ) . Implementation of Bayesian Theory in Sentence Classification for Online Subjective Test . International Journal of Advanced Research in Computer Science and Software Engineering , 3 ( 12 ) , 439 – 442 . [ 15 ] Xiang , G . , B . Fan , L . Wang , J . Hong and C . Rose , 2012 . Detecting offensive tweets via topical feature discovery over a large scale twitter corpus . Paper presented at the Proceedings of the 21st ACM international conference on Information and knowledge management [ 16 ] Xu , Z . , & Zhu , S . ( 2010 ) . Filtering Offensive Language in Online Communities using Grammatical Relations . Collaboration , Electronic Messaging , Anti - Abuse and Spam Conference .