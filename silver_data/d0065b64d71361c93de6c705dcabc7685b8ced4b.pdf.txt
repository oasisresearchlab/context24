xSLUE : A Benchmark and Analysis Platform for Cross - Style Language Understanding and Evaluation Dongyeop Kang Eduard Hovy Carnegie Mellon University , Pittsburgh , PA , USA { dongyeok , hovy } @ cs . cmu . edu Abstract Every natural text is written in some style . The style is formed by a complex combination of different stylistic factors , including formality markers , emotions , metaphor , etc . Some fac - tors implicitly reﬂect the author’s personality , while others are explicitly controlled by the author’s choices in order to achieve some per - sonal or social goal . One cannot form a com - plete understanding of a text and its author without considering these factors . The fac - tors combine and co - vary in complex ways to form styles . Studying the nature of the co - varying combinations sheds light on stylistic language in general , sometimes called cross - style language understanding . This paper pro - vides a benchmark corpus ( xSLUE ) with an online platform ( http : / / xslue . com ) for cross - style language understanding and evaluation . The benchmark contains text in 15 different styles and 23 classiﬁcation tasks . For each task , we provide the ﬁne - tuned classiﬁer for further analysis . Our analysis shows that some styles are highly dependent on each other ( e . g . , impoliteness and offense ) , and some domains ( e . g . , tweets , political debates ) are stylisti - cally more diverse than others ( e . g . , academic manuscripts ) . We discuss the technical chal - lenges of cross - style understanding and po - tential directions for future research : cross - style modeling which shares the internal repre - sentation for low - resource or low - performance styles and other applications such as cross - style generation . 1 Introduction People often use style in text as a strategic choice for their social interaction ( Hovy , 2018 ) . For ex - ample , in order to show respect to elder people , one may use more polite language than to friends . The strategic use of stylistic text is mainly because style often conveys more information ( e . g . , respect ) than is contained in the literal meaning of the text ( Hovy , 1987 ) . From a sociolinguistic perspective ( Nguyen et al . , 2016 ) , the role of style can be de - ﬁned by its pragmatics aspects and rhetorical goals ( Hovy , 1987 ) or personal and group characteristics of participants ( Biber , 1991 ) . More recently , they are called creative language ( Ji and Knight , 2018 ) in a broader context . Imagine an orchestra performed by a large group of instrumental ensemble . What we only hear at the end is the harmonized sound of complex interact - ing combinations of individual instruments , where the conductor controls their combinatory choices ( e . g . , score , tempo , correctness ) on top of it . Some of the instruments are in the same category such as violin and cello for bowed string type , and horn and trumpet for brass type . Similarly , text as the ﬁnal output reﬂects complex combination of dif - ferent types of styles where each style has its own choice of lexical or syntactic features . Consistent combination of the choices by the speaker ( like a conductor in orchestra performance ) will produce stylistically appropriate text given context . The stylistic choice for text is often triggered by an implicit reﬂection of someone’s characteristics ( e . g . , personality , demographic traits ( Kang et al . , 2019 ) , emotion of the speaker on the topic ( Rashkin et al . , 2019 ) ) or an explicit control for the social goals ( e . g . , the relationship with the hearer , the ﬁg - urative usage of text ( Dobrovol’skij and Piirainen , 2005 ; Glucksberg et al . , 2001 ; Loenneker - Rodman and Narayanan , 2010 ) , pragmatics aspects ( Hovy , 1987 ) ) . Broadly , we call each individual as one speciﬁc style type of language in this work . We computationally compress each individual into a single numerical variable ( e . g . , positive for 1 and negative for 0 in sentiment analysis ) in order to represent its amount contained in the text . However , style is not a single variable , but a combination of multiple variables co - vary in con - junction . For example , a text “a woman needs a a r X i v : 1911 . 03663v1 [ c s . C L ] 9 N ov 2019 Figurative styles humor ( ShortHumor , ShortJoke ) , sarcasm ( SarcGhosh , SARC ) , metaphor ( TroFi , VUA ) Affective styles emotion ( EmoBank , DailyDialog , CrowdFlower ) , of - fense ( HateOffensive ) , romance ( ShortRomance ) , senti - ment ( SentiTreeBank ) Personal styles age ( PASTEL ) , ethnicity ( PASTEL ) , gender ( PASTEL ) , edu - cation level ( PASTEL ) , political view ( PASTEL ) Interpersonal styles formality ( GYAFC ) , politeness ( StanfordPolite ) Table 1 : Our categorization of styles with their bench - mark dataset ( under parenthesis ) used in xSLUE . man like a ﬁsh needs a bicycle” uses a metaphor between two clauses but make the latter not con - tradictory so make the former ironical . Is irony ( or sarcasm ) always a subset of metaphor ? Are these two styles dependent on each other ? Despite the recent advances on various applications of style lan - guage such as style transfer , only a few works pay attention on how different style types ( e . g . , formal - ity , politeness ) co - vary together in textual variation , which styles are interdependent on each other , and how they are systematically composed to produce the ﬁnal text . We call such studies as cross - style language understanding . Due to the co - varying phenomena of styles , some controlled the confounding variables except for the target style to identify ( Nguyen et al . , 2016 ; Bamman et al . , 2014 ; Rabinovich et al . , 2016 ; Kang et al . , 2019 ) . On the other side , a few works studied cross - style dependency , but focusing on the particu - lar group of styles such as demographics ( Preo¸tiuc - Pietro and Ungar , 2018 ) , emotions ( Warriner et al . , 2013 ) , or between metaphor and emotion ( Dankers et al . , 2019 ; Mohammad et al . , 2016 ) . To accelerate more research along this line , we present a benchmark ( xSLUE ) for understanding and evaluating cross - style language which includes following contributions : • provide a theoretical categorization of 15 style types ( Figure 1 ) into four groups : ﬁgurative , af - fective , personal and interpersonal styles . • build an online platform ( http : / / xslue . com ) for comparing systems and easily downloading the dataset . Our benchmark includes 15 different style types ( e . g . , formality , emotion , humor , po - liteness , sarcasm , offense , romance , personal traits ) and 23 classiﬁcation tasks . • share the ﬁne - tuned classiﬁers on each style us - ing the BERT ( Devlin et al . , 2019 ) , showing signiﬁcant improvements over the baselines . • collect an extra diagnostic set ( i . e . , 600 samples of text ) which has multiple values of style types in conjunction annotated by human workers for investigating cross - style behavior of the model . • provide interesting observations of cross - style language : correlations between two styles ( e . g . , impoliteness is related to offense ) and a compar - ison of the diversity across domains ( e . g . , aca - demic papers are stylistically less diverse than tweets ) . We believe our benchmark helps more in - depth study of stylistic language in general , and suggest interesting directions for future research such as cross - style transfer and study on underlying inter - style dependency in textual variation . 2 Related Work Cross - style language understanding . Due to the broad categories of style language , only a few ear - lier works attempted to deﬁne general roles of style and provided theoretical categories of them . For example , Hovy ( 1987 ) categorized styles into prag - matics aspects ( e . g . , relationship between speaker and hearer ) and rhetorical goals ( e . g . , formality , power ) . Biber ( 1991 ) deﬁned several components of conversational situation such as social roles , per - sonal and group characteristics ( e . g . , social class ) , and participants’ relations . However , they are mostly based on theoretical investigation tested on a few example cases without any empirical evidence or scalable analysis to support it . Our study provides the empirical observations to sup - port some of the theories . On the other hands , some recent works attempted to provide empirical evidence of style dependen - cies but in very limited setting : Warriner et al . ( 2013 ) conducted extensive analysis on emotional norms and their correlation in lexical features of text . Chhaya et al . ( 2018 ) studied correlation of formality , frustration , and politeness but on small size of samples ( i . e . , 960 emails ) . Preo¸tiuc - Pietro and Ungar ( 2018 ) focused on correlation across de - mographic information ( e . g . , age , gender , race ) and with some other factors such as emotions . Dankers et al . ( 2019 ) ; Mohammad et al . ( 2016 ) studied the interplay of metaphor and emotion in text . In sar - casm detection , sentiment is also used as a sub - problem for an additional feature ( Liu et al . , 2010 ) . Instead of ﬁnding the dependencies , some prior works controlled the confounding style variables to identify the target style : For example , different demographic attributes ( e . g . , gender , age ) are col - lected in conjunction and controlled on each other ( Nguyen et al . , 2016 ) . Gender type is controlled to study gender - speciﬁc social media analysis ( Bam - man et al . , 2014 ) or develop personalized machine translation systems ( Rabinovich et al . , 2016 ) . Re - cently , six demographic attributes of text ( e . g . , age , gender , political view , education level , ethnicity ) are written in parallel and used for controlled ex - periment in style classiﬁcation and transfer ( Kang et al . , 2019 ) . Evaluation platforms . In terms of platform contributions ( e . g . , benchmark , analysis platform ) , this work is highly motivated by the recent bench - mark , GLUE ( Wang et al . , 2018 ) , for understanding sentence - level textual inference ( e . g . , entailment ) . Similar to the GLUE platform , we provide a bench - mark set of style language as well as newly col - lected datasets ; romantic and humor classiﬁcation . In addition to that , we also provide ( 1 ) the ﬁne - trained classiﬁers using the state - of - the - art contex - tualized word embeddings ( Devlin et al . , 2019 ) , ( 2 ) a diagnostic set of text annotated by human workers for cross - style classiﬁcation , and additional appli - cations such as correlation analysis across styles , style diversity with respect to domains , and more . Comparison with Multilingualism . Another motivation is the spirit of studying multiple lan - guage in conjunction called multilingual ( Edwards , 2002 ) . One major different of multi - stylism with multilingualism is that studying multiple styles is more likely compositional among different styles , while the latter is not except for code - switching case where different languages are used in a mixed way . This is why our work is called cross - style rather than simply multi - style . 3 Categorization of Styles Compared to the prior categorization of style types ( Hovy , 1987 ; Biber , 1991 ) under a sociolinguistic perspective , our study covers more broad categories of styles . We describe what types of styles are stud - ied in this work and provide our theoretical cate - gorization by clustering them into two dimensions : social participation ( from personal to interpersonal ) and content coupledness ( from loosely coupled to tightly coupled on content ) . 3 . 1 Selection of Styles - of - Interest The term style is often used in a mixed manner , while no one actually deﬁnes the exact meaning of it with its overall category . As a bottom - up ap - proach , we survey recent works which describe their work as a style language , and then collect 14 widely - used unique style types : emotion , sen - timent , metaphor , humor , sarcasm , offensiveness , romance , formality , politeness , age , ethnicity , gen - der , political orientation , and education level . The full list of our survey is described in § 4 . 3 . 2 Categorization of Styles politics . age gender formality educa . ethnicity I n t e r p e r s o n a l P e r s o n a l Content coupledness Content decoupledness emotion humor politeness metaphor offense sentiment sarcasm romance Figure 1 : A conceptual grouping of styles : x - axis is the aspect of style’s social participation , while y - axis is the aspect of style’s coupledness on content . We hypothesize two orthogonal aspects of styles ; social participation and content coupledness , and cluster the 14 style types over two dimensions of the aspects ( Figure 1 ) . Social participation means whether a style is related to the speaker ( i . e . , personal ) or the hearer ( i . e . , interpersonal ) in a conversation . This dimen - sion was studied in Biber ( 1991 ) : personal style is the personal characteristics of the speaker ( e . g . , per - sonalities ) , while interpersonal style is the relation - ship with the hearer ( e . g . , friendship ) . In addition to the Biber ( 1991 ) ’s deﬁnition , our view focuses on whether the style affects textual variation im - plicitly or explicitly . While personal styles ( e . g . , age , gender ) are originally given to a person so her or his text implicitly contains the combination of her or his personal styles ( e . g . , age , gender ) ( Kang et al . , 2019 ) , interpersonal styles ( e . g . , friend , en - emy , boss ) are given by their social interactions so the text can be explicitly controlled by the speaker with respect to the hearer . For instance , one may speak more formal words by explicitly controlling the formality of text depending on the person to talk with , while your personal characteristics or demographic traits ( e . g . , ethnicity ) are implicitly contained on your own words without any explicit control . Recently , Calvo and Mac Kim ( 2013 ) dis - tinguished emotion’s ascription between writer’s vs . reader’s perspectives . Content coupledness means how much style is tightly or loosely coupled to the content of orig - inal text . Ficler and Goldberg ( 2017 ) controlled different styles ( e . g . , descriptive , professional ) in text variation , regardless of its coupledness to the semantics of text . However , it is often observed that content words are tightly coupled with its styles ( Kang et al . , 2019 ; Preo¸tiuc - Pietro and Un - gar , 2018 ) . For instance , you can increase or de - crease formality of text regardless of the topic of text , while you may have speciﬁc degree of emo - tion or offensiveness with respect to the certain topic or person . We then project the 13 styles over the two di - mensions , and stretch each style if it aligns with a broad spectrum of each dimension ( Figure 1 ) . The personal styles ( e . g . , age , gender , education level , ethnicity ) are not biased on the content be - cause they are implicitly reﬂected on text . On the hands , formality and politeness are interpersonal but loosely coupled on content , because they are independently used regardless of content . Emo - tion can be either personal or interpersonal , while offense and romance are only related to the other person , and sentiment is tightly coupled with con - tent . The other three styles ; metaphor , sarcasm , and humor are more complex phenomena on top of others , so being stretched over the dimensions . Based on these groupings , we categorize them into four groups : ﬁgurative styles ( i . e . , humor , sar - casm , metaphor ) , affective styles ( i . e . , emotion , of - fense , romance , sentiment ) , personal style ( i . e . , age , ethnicity , gender , education level , political view ) , and interpersonal style ( i . e , formality , politeness ) . Note that our dimensions are driven by simple con - jectures , so there might be better projections and categorization . Instead , our goal is to provide one potential categorization of styles using our own the - ory and then compare it with empirically - observed style clusters in § 6 . 4 xSLUE : A Benchmark for Cross - Style Language Understanding 4 . 1 Dataset for Individual Style Language We choose existing datasets of style language or collect our own if there is no dataset available . Here are the rules of thumbs in our data collection and preprocessing : • we do not use datasets with small samples ( i . e . , ≤ 2 K ) due to its feasibility of training . • we limit our dataset to classify on only single sentence , even though there exist various settings of tasks ( e . g . , context - given sentence ) . • if dataset has its own split , we follow that . Other - wise , we randomly split it by 0 . 9 / 0 . 05 / 0 . 05 ratios for train / valid / test , respectively . • if dataset has only positive samples ( e . g . , ShortHumor ) , we do negative sampling . • due to label imbalance of some datasets , we mea - sure f - score and accuracy for classiﬁcation tasks and Pearson - Spearman correlation for regression tasks . For multi - labels , all scores are macro - averaged . Table 2 summarizes the style types , datasets , and data statistics ( e . g . , sample size , data split , distribu - tion of labels , label balance , domain of text , public availability , and task type ) . We describe more de - tails of our data collection and preprocessing below . Formality . Appropriately choosing the right for - mality in the situation ( e . g . , a person to talk to ) is the key aspect for effective communication ( Hey - lighen and Dewaele , 1999 ) . We use GYAFC dataset ( Rao and Tetreault , 2018 ) which includes both for - mal and informal text collected from web . How - ever , the dataset requires an individual authoriza - tion from the authors , so our benchmark only con - tains the script for preprocessing it to make the same format as other datasets . Humor . Humor ( or joke ) is a social style to make conversation more smooth or make a break . De - tecting humor ( Rodrigo and de Oliveira ; Yang et al . , 2015 ; Chandrasekaran et al . , 2016 ) and enten - dre ( Kiddon and Brun , 2011 ) or generating jokes ( Ritchie , 2005 ; Petrovic and Matthews , 2013 ) had been broadly studied using various linguistic fea - tures . We use the two well - known dataset used in humor detection : ShortHumor 1 which contains 22K humorous sentences collected from six dif - ferent websites 2 and ShortJoke which contains 231K jokes scraped from several websites 3 . To 1 http : / / github . com / CrowdTruth / Short - Text - Corpus - For - Humor - Detection 2 twitter , textﬁles , funnyshortjokes , lanughfactory , goodrid - dlesnow , onelinefun 3 Beside the two , there are many other joke datasets such as ( Pungas , 2017 ; Potash et al . , 2017 ; Rodrigo and de Oliveira ; Mihalcea and Strapparava , 2006 ) , but they do not perfectly ﬁt to our project because of the limited domain or low recall Table 2 : Style types and datasets in xSLUE . Every label in the datasets ranges in [ 0 , 1 ] . # S and # L mean the number of total samples and labels , respectively . ‘ _ ‘ means sub - tasks of the dataset . For dataset with multiple labels , we only show top - ﬁve frequent ones . clsf . denotes classiﬁcation task , and rgrs . regression . We use accuracy and f1 measures for classiﬁcation tasks , and Pearson - Spearman correlation for regression tasks . S TYLE T YPE & Dataset # S Split # L Label ( proportion ) Balance Domain Public Task F ORMALITY GYAFC ( Rao and Tetreault , 2018 ) 224k given 2 formal ( 50 % ) , informal ( 50 % ) Y web N clsf . P OLITENESS StanfPolite ( Danescu - Niculescu - Mizil et al . , 2013 ) 10k given 2 polite ( 49 . 6 % ) , impolite ( 50 . 3 % ) Y web Y clsf . H UMOR ShortHumor 44k random 2 humor ( 50 % ) , non - humor ( 50 % ) Y web Y clsf . ShortJoke 463k random 2 humor ( 50 % ) , non - humor ( 50 % ) Y web Y clsf . S ARCASM SarcGhosh ( Ghosh and Veale , 2016 ) 43k given 2 sarcastic ( 45 % ) , non - sarcastic ( 55 % ) Y tweet Y clsf . SARC ( Khodak et al . , 2017 ) 321k given 2 sarcastic ( 50 % ) , non - sarcastic ( 50 % ) Y reddit Y clsf . SARC _ pol ( Khodak et al . , 2017 ) 17k given 2 sarcastic ( 50 % ) , non - sarcastic ( 50 % ) Y reddit Y clsf . M ETAPHOR VUA ( Steen , 2010 ) 23k given 2 metaphor ( 28 . 3 % ) , non - metaphor ( 71 . 6 % ) N misc . Y clsf . TroFi ( Birke and Sarkar , 2006 ) 3k random 2 metaphor ( 43 . 5 % ) , non - metaphor ( 54 . 5 % ) N news Y clsf . E MOTION EmoBank valence ( Buechel and Hahn , 2017 ) 10k random 1 negative , positive - misc . Y rgrs . EmoBank arousal ( Buechel and Hahn , 2017 ) 10k random 1 calm , excited - misc . Y rgrs . EmoBank dominance ( Buechel and Hahn , 2017 ) 10k random 1 being _ controlled , being _ in _ control - misc . Y rgrs . CrowdFlower 40k random 14 neutral ( 21 % ) , worry ( 21 % ) , happy ( 13 % ) , sad ( 12 % ) , love ( 9 % ) . . N tweet Y clsf . DailyDialog ( Li et al . , 2017 ) 102k given 7 noemotion ( 83 % ) , happy ( 12 % ) , surprise ( 1 % ) , fear ( . 1 % ) , disgust ( . 3 % ) , sad ( 1 % ) , anger ( . 9 % ) N dialogue Y clsf . O FFENSE HateOffensive ( Davidson et al . , 2017 ) 24k given 3 hate ( 6 . 8 % ) , offensive ( 76 . 3 % ) , neither ( 16 . 8 % ) N tweet Y clsf . R OMANCE ShortRomance 2k random 2 romantic ( 50 % ) , non - romantic ( 50 % ) Y web Y clsf . S ENTIMENT SentiBank ( Socher et al . , 2013 ) 239k given 2 positive ( 54 . 6 % ) , negative ( 45 . 4 % ) Y web Y clsf . P ERSONA PASTEL _ gender ( Kang et al . , 2019 ) 41k given 3 Female ( 61 . 2 % ) , Male ( 38 . 0 % ) , Others ( . 6 % ) N caption Y clsf . PASTEL _ age ( Kang et al . , 2019 ) 41k given 8 35 - 44 ( 15 . 3 % ) , 25 - 34 ( 42 . 1 % ) , 18 - 24 ( 21 . 9 % ) , 45 - 54 ( 9 . 2 % ) , 55 - 74 ( 10 . 5 % ) N caption Y clsf . PASTEL _ country ( Kang et al . , 2019 ) 41k given 2 USA ( 97 . 9 % ) , UK ( 2 . 1 % ) N caption Y clsf . PASTEL _ politics ( Kang et al . , 2019 ) 41k given 3 Left ( 42 . 7 % ) , Center ( 41 . 7 % ) , Right ( 15 . 5 % ) N caption Y clsf . PASTEL _ education ( Kang et al . , 2019 ) 41k given 10 Bachelor ( 30 . 6 % ) , Master ( 18 . 4 % ) , NoDegree ( 18 . 2 % ) , HighSchool ( 11 . 0 % ) , Associate ( 9 . 3 % ) . . N caption Y clsf . PASTEL _ ethnicity ( Kang et al . , 2019 ) 41k given 10 Caucasian ( 75 . 6 % ) , NativeAmerican ( 8 . 6 % ) , Hispani - cOrLatino ( 3 . 3 % ) , African ( 5 . 5 % ) , EastAsian ( 2 . 5 % ) . . N caption Y clsf . collect negative samples , we randomly sample neg - ative sentences ( i . e . , non - humorous text ) from the two sources : random sentences from Reddit sum - marization corpus ( Jung et al . , 2019 ) and literal sentences from Reddit corpus ( Khodak et al . , 2017 ) . For ShortJoke , we sample more negative samples with replacement up to the same number of positive ones for the label balance . Politeness . Encoding ( im ) politeness in conversa - tion often plays different roles of social interactions such as power dynamics at workplaces , decisive factor , and strategic use of it in social context ( e . g . , request ) ( Chilton , 1990 ; Holmes and Stubbe , 2015 ; Clark and Schunk , 1980 ) . For example , one can say “if you don’t mind” or “I’m sorry , but” to strate - gically being indirect or apologizing for the impo - sition , respectively ( Lakoff , 1973 ) . We use Stan - ford’s politeness dataset StanfPolite ( Danescu - problem . Niculescu - Mizil et al . , 2013 ) which collects request types of polite text from web such as Stack Ex - change question - answer community 4 . Sarcasm . Sarcasm acts by using words that mean something other than what you want to say , to in - sult someone , show irritation , or simply be funny . Therefore , it is often used interchangeably with irony . The detailed category of its role is summa - rized in ( Joshi et al . , 2017 ) . Detecting sarcastic text is often regarded as a sub - problem for sen - timent analysis ( Liu et al . , 2010 ) . Such ﬁgura - tive nature of sarcasm leads more challenges to identify it in text ( Tepperman et al . , 2006 ; Wal - lace et al . , 2014 ; Wallace , 2015 ) . Sarcasm datasets are collected and annotated in different domains : books ( Joshi et al . , 2016 ) , tweets ( González - Ibánez et al . , 2011 ; Ghosh et al . , 2015 ; Peled and Reichart , 4 http : / / stackexchange . com / about 2017 ; Ghosh and Veale , 2016 ) , reviews ( Filatova , 2012 ) , forums ( Walker et al . , 2012 ) , and Reddit comments ( Khodak et al . , 2017 ) . We choose two of them for the purpose of our project ( e . g . , data size , public availability , and length of text ) : SarcGhosh ( Ghosh and Veale , 2016 ) and SARC version 2 . 0 ( Khodak et al . , 2017 ) 5 . We use the same prepro - cessing scheme in Ili´c et al . ( 2018 ) on SARC . Metaphor . Metaphor is a ﬁgurative language that describes an object or an action by apply - ing to which is not actually applicable . Such ob - ject is often regarded as a representative or sym - bolic thing , especially somewhat abstract . Detect - ing metaphoric text has been studied in different ways : rule - based ( Russell , 1976 ; Martin , 1992 ) , dictionary - based , and recently more computation - based with different factors ( e . g . , discourse , topic transition , emotion ) ( Nissim and Markert , 2003 ; Jang et al . , 2017 ; Mohler et al . , 2013 ) . We use two benchmark datasets 6 : Trope Finder ( TroFi ) ( Birke and Sarkar , 2006 ) and VU Amsterdam VUA Corpus ( Steen , 2010 ) where metaphoric text are annotated by human annotators . Offense . Hate speech is a speech that targets dis - advantaged social groups based on group charac - teristics ( e . g . , race , ethnicity , gender , and sexual orientation ) in a manner that is potentially harm - ful to them ( Jacobs et al . , 1998 ; Walker , 1994 ) . More recently , Davidson et al . ( 2017 ) deﬁned hate speech as language that is used to expressed ha - tred towards a targeted group or is intended to be derogatory , to humiliate , or to insult the mem - bers of group . , which is category of offensive lan - guage in general . We use the HateOffenssive dataset ( Davidson et al . , 2017 ) which includes hate text ( 7 % ) , offensive text ( 76 % ) , and none of them ( 17 % ) . Romance . To the best of our survey , we could not ﬁnd any dataset which includes romantic and non - romantic text . Thus , we crawl romantic text from eleven different web sites ( See Appendix ) , pre - process them by ﬁltering out some noisy , too long , and duplicate text , and then make a new dataset called ShortRomance . Similar to the ShortHumor and ShortJoke , we make the same number of negative samples from the literal Reddit 5 SARC pol is a sub - task for text from politics subreddit . 6 we did not include ( Mohler et al . , 2016 ) because the labels are not obtained from human annotators . sentences ( Khodak et al . , 2017 ) as the same number of the romantic text . Sentiment . Identifying sentiment polarity of an opinion is challenging because of its implicit and explicit presence in text ( Kim and Hovy , 2004 ; Pang et al . , 2008 ) . We use the large scale of an - notated sentiment corpus on movie reviews ; Senti - ment Tree Bank ( Socher et al . , 2013 ) ( SentiBank ) . Emotion . Emotion is a more ﬁne - grained model - ing of sentiment . Modeling emotion can be either categorical or dimensional . While Ekman’s basic six categories of emotions ( Ekman , 1992 ) concep - tualize emotions as discrete states : anger , joy , sur - prise , disgust , fear , and sadness , the dimensional model ( Warriner et al . , 2013 ) considers the states as a small number of independent emotional dimen - sions : Valence ( concept of polarity ) , Arousal ( de - gree of calmness or excitement ) , and Dominance ( perceived degree of control ) ; the VAD model . we use two datasets : one ( i . e . , DailyDialog ( Li et al . , 2017 ) ) from the Ekman’s categorical model and another ( i . e . , EmoBank ( Buechel and Hahn , 2017 ) ) from the VAD’s model . The range for original EmoBank was [ 0 , 5 ] but we normalize it in [ 0 , 1 ] in our benchmark . We also include a large but little noisy emotion - annotated corpus CrowdFlower 7 , which includes not only the Ekman’s categories but also additional categories : enthusiasm , worry , love , fun , hate , relief , and boredom . Persona . Persona is a pragmatics style in group characteristics of the speaker ( Kang et al . , 2019 ) . It is often observed that certain group of persona has a speciﬁc usage of certain textual features . We use the stylistic language dataset written in parallel called PASTEL ( Kang et al . , 2019 ) where multiple types of the author’s personas are given in con - junction . Similar to the emotion datasets , PASTEL also has multiple attributes together ( i . e . , age , gen - der , political view , ethnic , country , education level ) , where most categories are unbalanced . 4 . 2 Diagnostic Set for Cross - Style Language With individual types of style , we may train a clas - siﬁer on each and measure its performance on an individual test set . However , without a shared test set across different styles , we can not measure how different styles are identiﬁed at the same time ( i . e . , cross - style classiﬁcation ) and whether the model 7 http : / / www . crowdflower . com / wp - content / uploads / 2016 / 07 / text _ emotion . csv captures the underlying structure of inter - style vari - ation of text ( See our experiment in § 5 ) . We collect a diagnostic set by annotating appropriate labels of multiple styles at the same time . We prepare two diagnostic set : cross - test set and tweet - dynamic set . • cross - test set is 100 samples randomly chosen from test samples on different style datasets . We have two steps of sampling : First , we ran - domly select 40 test samples from the 15 datasets . Among the 600 test samples , we randomly choose the ﬁnal 100 samples as our ﬁnal cross - test diagnostic samples . Each sample from the cross - test set has its ground - truth label for the style which is sampled from , so we used it for a sanity checking of our annotations . • tweet - diverse set is another 100 samples chosen from random tweets . We ﬁrst collect the top - ranked 300 tweets with high stylistic diversity and another bottom - ranked 300 tweets with less stylistic diversity ( See § 6 . 2 for our deﬁnition and measurement of style diversity ) . Then , we randomly sample 100 tweets from the collection . Using the two sets of diagnostic samples 8 , we then ask human workers to predict the stylistic at - tribute of the text for multiple style types , where three different annotators are assigned on each sample . The detailed instructions and annotation schemes are in Appendix . The ﬁnal label for each style is decided as a discrete label via majority voting over the three annotators and as a continu - ous value by averaging the number of votes . For personal styles ( e . g . , age , gender ) , we also add Don’t Know option to choose in case that its pre - diction is too difﬁcult . In case three votes are all different each other , we did not use the sample in our evaluation 9 . 5 Single and Cross Style Classiﬁcation Setup . In a single - style classiﬁcation , we indi - vidually train a classiﬁer ( or regression model for EmoBank ) on each dataset and predict the label . For a simplicity , we use the pre - trained language model ; uncased Bidirectional Encoder Represen - tations from Transformers ( BERT ) ( Devlin et al . , 2019 ) 10 and ﬁne - tune it on each dataset using two - 8 We will collect additional 400 samples ; 200 for each set , in the ﬁnal version . 9 We will be releasing these ambiguous or controversy cases including the Don’t Know answer as a separate eval - uation set in the future . 10 We have tried different variants of the BERT models such as ‘large - uncased‘ , showing comparable performance . layers of perceptions on top of the pre - trained model . For evaluation , we report both accuracy and f1 - score by macro - averaging due to the label imbalance . For a baseline , we provide a simple majority classiﬁer ( i . e . , taking the majority label from the training set and using the label for prediction on test set ) . In addition , we apply another baseline using Bidirectional LSTM ( BiLSTM ) ( Hochreiter and Schmidhuber , 1997 ) with the pre - trained word embeddings ( Pennington et al . , 2014 ) . We report both human and model performances from the orig - inal paper if given . If the experimental setup is not directly applicable ( e . g . , difference in evaluation metrics ) , we mark them as na . The details of the hyper - parameters are in Appendix . Results . Table 3 ( left ) shows performance on single - style classiﬁcation ( left ) and cross - style clas - siﬁcation ( right ) . The ﬁne - tuned BERT classi - ﬁer outperforms the majority and BiLSTM base - lines on f1 score by the large margins except for SarcGhosh . Especially , BERT shows signiﬁcant improvements on f1 scores on for personal styles . For sarcasm and politeness tasks , our classiﬁers do not outperform the scores in the original pa - pers , which use additional hand - written syntactic features . When classifying multiple styles at the same time called cross - style classiﬁcation ( Table 3 ( right ) ) , single - style classiﬁers did not show compa - rable performance as done in single - style classiﬁca - tion . This is mainly because single - style classiﬁer trained on speciﬁc domain of dataset is biased to the domain and / or the dataset itself may include some annotation artifacts which are not scalable to the held - out samples . More importantly , there is a fundamental difference of cross - style classiﬁcation compared to the single - style classiﬁcation : when predicting multiple styles together , you may con - sider how different styles are dependent on each other , indicating the necessity of an uniﬁed model where multiple styles are jointly trained . Such joint models need to take into account the underlying dependency structure of different styles in classiﬁ - cation task . This may be also applicable to multi - style generation task like you head the harmonized sound of complex combinations of individual in - struments at the end . Table 3 : Single - style and cross - style classiﬁcation . na means not applicable . We use both accuracy and macro - averaged f1 - score ( under parenthesis ) for classiﬁcation tasks . For cross - style classiﬁcation , we only choose one dataset if multiple datasets per style exist . Single - style classiﬁcation Cross - style classiﬁcation cross - test tweet - diverse S TYLE Dataset Majority Original BiLSTM BERT BERT BERT F ORMALITY GYAFC 43 . 3 ( 30 . 2 ) na 76 . 5 ( 76 . 4 ) 88 . 3 ( 88 . 3 ) 64 . 1 ( 63 . 8 ) 75 . 0 ( 55 . 8 ) P OLITE . StanfPolite 56 . 7 ( 36 . 2 ) 83 . 2 62 . 1 ( 61 . 8 ) 66 . 8 ( 65 . 8 ) 80 . 7 ( 80 . 7 ) 84 . 0 ( 45 . 6 ) H UMOR ShortHumor 50 . 0 ( 33 . 3 ) na 88 . 6 ( 88 . 6 ) 97 . 0 ( 97 . 0 ) - - ShortJoke 50 . 0 ( 33 . 3 ) na 89 . 1 ( 89 . 1 ) 98 . 3 ( 98 . 3 ) 52 . 1 ( 41 . 0 ) 63 . 0 ( 54 . 61 ) S ARCASM SarcGhosh 50 . 0 ( 33 . 3 ) na 73 . 0 ( 72 . 6 ) 54 . 4 ( 42 . 4 ) - - SARC 50 . 0 ( 33 . 3 ) 75 . 8 63 . 0 ( 63 . 0 ) 70 . 2 ( 70 . 1 ) 57 . 6 ( 44 . 2 ) 52 . 0 ( 41 . 7 ) SARC _ pol 50 . 0 ( 33 . 3 ) 76 . 0 61 . 3 ( 61 . 3 ) 71 . 8 ( 71 . 7 ) - - M ETAPHOR VUA 70 . 0 ( 41 . 1 ) na 77 . 1 ( 68 . 9 ) 84 . 5 ( 89 . 1 ) 25 . 0 ( 20 . 0 ) 50 . 0 ( 33 . 3 ) TroFi 57 . 2 ( 36 . 4 ) 46 . 3 74 . 5 ( 73 . 9 ) 75 . 7 ( 78 . 9 ) - - E MOTI . EmoBank V / A / D - / - / - na 78 . 5 / 49 . 4 / 39 . 5 81 . 2 / 58 . 7 / 43 . 6 64 . 1 / 23 . 9 / 82 . 6 78 . 0 / 29 . 0 / 77 . 0 CrowdFlower 22 . 4 ( 2 . 8 ) na 31 . 1 ( 12 . 3 ) 36 . 5 ( 21 . 9 ) - - DailyDialog 81 . 6 ( 12 . 8 ) na 84 . 2 ( 27 . 61 ) 84 . 2 ( 49 . 6 ) 47 . 8 ( 19 . 3 ) 69 . 0 ( 22 . 3 ) O FFENSE HateOffens 75 . 0 ( 28 . 5 ) 91 . 0 86 . 6 ( 68 . 2 ) 96 . 6 ( 93 . 4 ) 84 . 7 ( 47 . 27 ) 81 . 0 ( 33 . 6 ) R OMA . ShortRomance 50 . 0 ( 33 . 3 ) na 90 . 6 ( 90 . 6 ) 99 . 0 ( 98 . 9 ) 95 . 6 ( 86 . 3 ) 75 . 0 ( 54 . 6 ) S ENTIMENT SentiBank 50 . 0 ( 33 . 3 ) 87 . 6 82 . 8 ( 82 . 8 ) 96 . 6 ( 96 . 6 ) 88 . 4 ( 88 . 0 ) 85 . 3 ( 70 . 7 ) P ERSONA PASTEL _ gender 62 . 8 ( 25 . 7 ) na 73 . 2 ( 45 . 5 ) 73 . 0 ( 48 . 7 ) 37 . 5 ( 19 . 6 ) 38 . 2 ( 25 . 5 ) PASTEL _ age 41 . 5 ( 7 . 3 ) na 41 . 9 ( 15 . 2 ) 46 . 3 ( 23 . 9 ) 40 . 9 ( 23 . 3 ) 59 . 5 ( 38 . 1 ) PASTEL _ country 97 . 2 ( 49 . 2 ) na 97 . 2 ( 49 . 3 ) 97 . 1 ( 55 . 2 ) 97 . 5 ( 49 . 3 ) 95 . 9 ( 48 . 9 ) PASTEL _ politics 42 . 9 ( 20 . 0 ) na 48 . 5 ( 33 . 5 ) 50 . 9 ( 46 . 1 ) 9 . 0 ( 8 . 3 ) 37 . 5 ( 29 . 3 ) PASTEL _ education 31 . 4 ( 4 . 7 ) na 42 . 4 ( 15 . 0 ) 42 . 5 ( 25 . 4 ) 23 . 2 ( 11 . 7 ) 25 . 6 ( 11 . 1 ) PASTEL _ ethnicity 75 . 4 ( 8 . 5 ) na 82 . 3 ( 17 . 6 ) 81 . 1 ( 25 . 6 ) 59 . 0 ( 15 . 7 ) 34 . 4 ( 16 . 4 ) total 55 . 4 ( 26 . 8 ) 69 . 3 ( 55 . 7 ) 73 . 7 ( 64 . 3 ) 57 . 5 ( 41 . 2 ) 61 . 7 ( 38 . 8 ) 6 Cross - Style Language Understanding We provide useful analyses of style language us - ing xSLUE : ( 1 ) ﬁnding a correlation between two styles , ( 2 ) measuring a stylistic diversity of text , and ( 3 ) ﬁnding which domain of text ( e . g . , aca - demic papers vs tweets ) is stylistically more di - verse . 6 . 1 Cross - Style Correlation Setup . Using the pre - trained classiﬁers on 53 dif - ferent attributes of styles 11 in § 5 , we predict the score of each attribute on new 1 , 000 , 000 tweets crawled 12 using Twitter’s Garden Hose API . We choose tweet as a test bed due to its stylistic di - versity compared to other domains such as news articles or academic papers ( See § 6 . 3 for stylistic diversity across domains ) . We obtain the 53 different style scores across 11 we don’t include some duplicate style attributes such as SarcGhosh and CrowdFlower 12 We use the tweets from 2008 to 2013 ( Kang et al . , 2017 ) , and randomly sample 1M tweets from it . 1 million tweets , then produce a correlation ma - trix between 53 different predicted styles using Euclidean distance measure . With the matrix , we calculate Pearson correlation coefﬁcients using Eu - clidean distance measure across style attributes’ scores ( i . e . , columns ) and produce the ﬁnal 53 × 53 correlation matrix ( Figure 2 ) : we split it into three pieces based on our groupings deﬁned in § 3 : inter - personal and ﬁgurative styles ( top , left ) , affective styles ( bottom , left ) , and personal styles ( right ) . We only contain correlations which are statistically signiﬁcant with p - value < 0 . 05 . Motivation . A basic idea behind this analysis assumes that certain textual features ( e . g . , lexical choices ) which could be detected by the classi - ﬁer , co - occur across multiple styles , giving fre - quent co - occurrence . Compared to the theoretical ( Hovy , 1987 ) or empirical ( Preo¸tiuc - Pietro and Un - gar , 2018 ; Kang et al . , 2019 ) analyses of those fea - tures , our analysis uses surface - level co - occurrence patterns of features across styles with the help from the classiﬁers . Figure 2 : Cross - style correlation . The degree of correlation gradually increases from Red ( i . e . , negative ) , Yellow , to Blue ( i . e . , positive ) , where color intensity is proportional to the correlation coefﬁcients . Correlations with p < 0 . 05 ( conﬁdence interval : 0 . 95 ) are only considered as statistically signiﬁcant . Otherwise , crossed . Age ranges start with X in the personal styles . IMPORTANT : before you interpret anything from these matrices , please be VERY CAREFUL not to make any unethical or misleading claims based on these simple measures . Please read the potential weakness of our experiment below . Best viewed in color . Analysis . From the correlation matrix , we could observe interesting correlations : ( non - humorous text , text with positive sentiment ) , ( non - humorous text , text by Master / Doctorate education ) , ( po - lite text , text with no - emotion ) , ( text with dom - inance : being _ in _ control , text with positive senti - ment ) , ( text with anger emotion , offensive text ) , ( text by Left - Wing political orientation , text by Bachelor / Master education ) , and more . However , we should not blindly trust the corre - lations . For example , there is a highly positive cor - relation between Age ( < 12 ) and Age ( > = 75 ) , which seems to be unreasonable . More than that , we should be VERY CAREFUL not to make any mis - leading interpretation on them , especially some styles related to personal traits . This is not only due to the ethical issues but also several weakness of our experimental design : IMPORTANT : Weakness of our experiment . • Our analysis is not controlled nor causal . In or - der to ﬁnd a causal relation between styles and to control their confounding variables , more sophis - ticated methods such as analysis of covariance ( ANCOVA ) ( Keppel , 1991 ) or prospensity anal - ysis ( Austin , 2011 ) need to be applied . • Do not trust the classiﬁers . Aforementioned re - sults on the style classiﬁcation ( § 5 ) indicate that certain styles ( e . g . , sarcasm , persona styles ) are very difﬁcult to predict , leading the unreliable results of our analysis . To overcome it , a jointly - trained model across different styles is indispens - able to take beneﬁts from the cross - styling . • Each dataset has its own issues . Some dataset is only collected from certain domains ( e . g . , news articles ) , making the classiﬁer biased to it . Some has a very imbalanced distribution over labels . Each data collection may or may not have an - notation artifacts . Some datasets include some noisy text . 6 . 2 Stylistic Diversity of Text In a style transfer , preserving the original mean - ing of text is a challenging issue . Can we change style of any text regardless of its content ? Why do some text be easier to change the style , while others do not ? Can we predict whether text can be stylistically changeable ? We propose a simple technique to rank stylistic diversity of text using the ﬁne - tuned style classiﬁers used in § 5 . Given a text , we ﬁrst calculate the mean and the standard deviation ( std ) over style scores S 1 , . . . , 53 predicted by the classiﬁers . We predict total 1M tweets used in § 6 . 1 , and get 1 M × 2 matrix where its columns are the mean and std over the styles 13 . We sort samples by the mean and take the top ( or bottom ) 10 % samples ﬁrst . Then , we sort the sampled tweets again by the std and take the top ( or bottom ) 10 % samples . The ﬁnal top or bottom ranked samples are called stylistically diverse or less diverse text in our analysis , indicating that the total amounts of style prediction scores and their variations are high ( or less ) . Table 4 : Stylistic diversity of text : sampling 10 % of tweets with the highest ( lowest ) average of style predic - tion scores and then sampling again 10 % tweets with highest ( lowest ) standard deviation , where the former is stylistically diverse ( (cid:52) ) , while the latter is less - diverse ( (cid:53) ) . Some offensive words are replaced by * mark . m ea n s t d f o r m a l hu m o r ou s po lit e s a r ca s ti c m e t a pho r o ff e n s i v e Stylistically diverse text (cid:52) (cid:52) i’m glad i can add hilarity into your life . 32 . 45 . 98 . 99 0 . 99 . 99 0 it was really cool speaking with you to - day i look forward to working for you . 32 . 45 . 99 . 99 . 99 . 99 0 0 i’m * ucking proud of you baby you’ve come a long way . 31 . 45 0 . 99 . 99 0 . 99 . 99 Stylistically less diverse text (cid:53) (cid:53) lip / tongue tingling . 15 . 28 . 01 0 . 02 0 0 0 satellite server is a mess cleaning up . 15 . 28 0 0 . 04 . 01 . 68 0 having beer with and some latin ameri - cans . 14 . 28 0 0 . 28 0 0 0 Analysis . Table 4 shows the top / bottom - ranked stylistically diverse / less - diverse tweets . We only show some labels ( e . g . , formal , humorous ) due to the space limitation . We observe that stylistically diverse text use more emotions and social expres - sions ( e . g . , complaining , greeting ) , while stylisti - cally less diverse text are more literal , factual , and simply describing a thing . Again , some predicted scores are not accurate due to the aforementioned issues of the classiﬁers and dataset itself . We real - ize that the classiﬁers often predict very extreme scores ( e . g . , 0 . 99 , 0 . 01 ) , where its posterior proba - bilities need to calibrated accordingly . More exam - ples on our style diversity and pair - plot distribution of the prediction scores are in Appendix . 13 For simplicity , we remove all literal type labels such as ‘informal’ , ‘non - humorous’ , ‘non - sarcastic’ , ‘impolite’ , ‘non - metaphor’ , ‘negative’ . ‘neither - hate - or - offensive’ , ‘non - romantic’ , and ‘noemotion’ . 6 . 3 Stylistic Diversity across Domains Different domains or genres of text may have their unique patterns of style diversities . For example , text from academic manuscripts may be more lit - eral ( stylistically less - diverse ) , while tweets and other social media posts are stylistically diverse . We sample sentences from different domains 14 ; tweets , academic papers , news articles , novel books , dialogues , movie scripts , and political de - bate 15 . After splitting the text into sentences , we only use maximum 100 , 000 sentences for each do - main . For each domain , we again predict prob - ability scores of each style using the ﬁne - tuned classiﬁers in § 5 , and then average the scores across sentences for individual style . Tweets Reddit News Papers Script Debate 0 0 . 1 0 . 2 0 . 3 hate offensive romantic anger disgust fear happy sad surprise ( a ) Affective styles Tweets Reddit News Papers Script Debate 0 0 . 5 1 1 . 5 2 2 . 5 formal polite humorous sarcastic metaphor ( b ) Interpersonal and ﬁgurative styles Figure 3 : Style diversity on six different domains : tweets , Reddit posts , news articles , academic papers , movie scripts , and political debates . Best viewed in color . Analysis . Figure 3 shows absolute proportion of 14 We use the collection of different domains of summariza - tion corpora ( Jung et al . , 2019 ) 15 We use the full transcripts between Clinton and Trump in 2016 US presidential debates 16 the averaged prediction scores of each style over different domains . For the affective styles in Figure 3 ( a ) , text in academic papers has the least affec - tive styles followed by news articles , while text on social media ( e . g . , tweets , Reddit posts ) has a lot of style divesrsity , showing its correlation with freedom of speech in the domains . Interestingly , text in political debate has two conﬂicting style pair in balance ; hate and happy , but less offensive and anger styles . For the interpersonal and ﬁgurative styles in Fig - ure 3 ( b ) , tweets are most informal . On the other hand , academic papers are very formal and polite . The analysis on personal styles is included in Ap - pendix . 7 Conclusion , Challenges , and Future Directions We build a benchmark for studying cross - style lan - guage understanding and evaluation , where it in - cludes different types of styles and their datasets . Using the state - of - the - art classiﬁers trained on each style dataset , we provide interesting observations ( e . g . , cross - style classiﬁcation , cross - style correla - tion , style diversity across different domains ) as well as our theoretical grouping of style types . We believe our benchmark helps other researchers de - velop more solid systems on various applications of style language . We summarize several challenges we faced and potential future directions in cross - style language understanding . 7 . 1 Challenges More severe semantic drift . The biggest chal - lenge in collecting cross - style dataset ( Kang et al . , 2019 ) or controlling multiple styles in generation ( Ficler and Goldberg , 2017 ) is to diversify style of text but at the same time preserve the meaning , in order to avoid semantic drift . It can be addressed by collecting text in parallel or preserving the meaning using various techniques . In the cross - style setting , multiple styles change at the same time in different parts of text in a complicated way , leading more server semantic drift . Style drift due to the cross - style dependency . We face a new challenge ; style drift , where different styles are coupled together with text so changing one type may affect the others . For example , if we change it to more impolite text given a text , such change tends to make the text more offensive and negative ( See § 6 . 1 ) . In the cross - style transfer or the multi - style generation , we ﬁrst need to un - derstand the underlying dependencies across style types and develop a generative model which can handle the implicit dependencies . Stylistic diversity and content coupledness . In § 6 . 2 and § 6 . 3 , we measure a stylistic diversity by the amount of styles ( i . e . , mean ) and its variance ( i . e . , standard deviation ) . Some believe that con - tent needs to be separated from styles , while our observation shows that they are highly coupled on each other . Studying more in - depth analysis on the relationship between content and style is required for better understanding style language . More careful interpretation is required . In a cross - style language , some style types ( e . g . , per - sonal styles ) are very sensitive so require more care - ful interpretation on their result . We made three weak points about our analysis in § 6 . 1 , in order not to make any misleading points from our analy - sis . Any follow - up research on this direction needs to consider such ethical issues as well as provide potential weakness of their proposed methods . 7 . 2 Future Directions Necessity of cross - style modeling . We have not yet explored any models which can learn the inter - nal dependency structure across styles . Studying such cross - style dependency would help develop the complex combination of different styles in clas - siﬁcation as well as generation . For example , rather than developing multiple classiﬁers for each style , developing an universal classiﬁer on multiple styles is necessary , where their internal representations are shared across styles but individual style has its own predictor . Such cross - style modeling may take advantages from the shared representation like interlingua representation in multilingual setting ( Edwards , 2002 ) . Low - resource and low - performance Styles . In addition , cross - style models will be useful for some styles which have less annotation data ( low - resource style ) or some styles which show very low performance due to the difﬁculty of the style lan - guage ( low - performance style ) . For example , our study shows that detecting sarcasm and metaphor from text is still very difﬁcult , which might be helped by other style types . Cross - styling on other applications . Beside the style classiﬁcation task , our benchmark can be applied to other applications such as style transfer . However , the aforementioned issues such as seman - tic and style drift , cross - style transfer and style - controlled generation might be more challenging without understanding the underlying dependency across styles in a textual variation . Acknowledgements This work would not have been possible without the efforts of the authors who kindly share the style language datasets publicly . We also thank Taehee Jung , Yongjoon Kim , Wei Xu , Shirley A . Hayati , Varun Gangal , Naoki Otani , Dheeraj Rajagopal , Yohan Jo , and Hyeju Jang for their helpful com - ments . References Peter C Austin . 2011 . An introduction to propensity score methods for reducing the effects of confound - ing in observational studies . Multivariate behav - ioral research , 46 ( 3 ) : 399 – 424 . David Bamman , Jacob Eisenstein , and Tyler Schnoe - belen . 2014 . Gender identity and lexical varia - tion in social media . Journal of Sociolinguistics , 18 ( 2 ) : 135 – 160 . Douglas Biber . 1991 . Variation across speech and writ - ing . Cambridge University Press . Julia Birke and Anoop Sarkar . 2006 . A clustering ap - proach for nearly unsupervised recognition of nonlit - eral language . In EACL . Sven Buechel and Udo Hahn . 2017 . Emobank : Study - ing the impact of annotation perspective and repre - sentation format on dimensional emotion analysis . In Proceedings of the 15th Conference of the Euro - pean Chapter of the Association for Computational Linguistics : Volume 2 , Short Papers , pages 578 – 585 . Rafael A Calvo and Sunghwan Mac Kim . 2013 . Emo - tions in text : dimensional and categorical models . Computational Intelligence , 29 ( 3 ) : 527 – 543 . Arjun Chandrasekaran , Ashwin K Vijayakumar , Stanislaw Antol , Mohit Bansal , Dhruv Batra , C Lawrence Zitnick , and Devi Parikh . 2016 . We are humor beings : Understanding and predicting visual humor . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4603 – 4612 . Niyati Chhaya , Kushal Chawla , Tanya Goyal , Projjal Chanda , and Jaya Singh . 2018 . Frustrated , polite , or formal : Quantifying feelings and tone in email . In Proceedings of the Second Workshop on Compu - tational Modeling of People’s Opinions , Personality , and Emotions in Social Media , pages 76 – 86 , New Orleans , Louisiana , USA . Association for Computa - tional Linguistics . Paul Chilton . 1990 . Politeness , politics and diplomacy . Discourse & Society , 1 ( 2 ) : 201 – 224 . Herbert H Clark and Dale H Schunk . 1980 . Polite re - sponses to polite requests . Cognition , 8 ( 2 ) : 111 – 143 . Cristian Danescu - Niculescu - Mizil , Moritz Sudhof , Dan Jurafsky , Jure Leskovec , and Christopher Potts . 2013 . A computational approach to politeness with application to social factors . arXiv preprint arXiv : 1306 . 6078 . Verna Dankers , Marek Rei , Martha Lewis , and Eka - terina Shutova . 2019 . Modelling the interplay of metaphor and emotion through multitask learning . In IJCNLP 2019 . Thomas Davidson , Dana Warmsley , Michael Macy , and Ingmar Weber . 2017 . Automated hate speech detection and the problem of offensive language . In Eleventh international aaai conference on web and social media . Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . Bert : Pre - training of deep bidirectional transformers for language understand - ing . In NAACL . Dmitrij Dobrovol’skij and Elisabeth Piirainen . 2005 . Figurative language : Cross - cultural and cross - linguistic perspectives . Brill . John Edwards . 2002 . Multilingualism . Routledge . Paul Ekman . 1992 . An argument for basic emotions . Cognition & emotion , 6 ( 3 - 4 ) : 169 – 200 . Jessica Ficler and Yoav Goldberg . 2017 . Controlling linguistic style aspects in neural language genera - tion . arXiv preprint arXiv : 1707 . 02633 . Elena Filatova . 2012 . Irony and sarcasm : Corpus gen - eration and analysis using crowdsourcing . In LREC , pages 392 – 398 . Aniruddha Ghosh , Guofu Li , Tony Veale , Paolo Rosso , Ekaterina Shutova , John Barnden , and Antonio Reyes . 2015 . Semeval - 2015 task 11 : Sentiment analysis of ﬁgurative language in twitter . In Pro - ceedings of the 9th International Workshop on Se - mantic Evaluation ( SemEval 2015 ) , pages 470 – 478 . Aniruddha Ghosh and Tony Veale . 2016 . Fracking sar - casm using neural network . In Proceedings of the 7th workshop on computational approaches to sub - jectivity , sentiment and social media analysis , pages 161 – 169 . Sam Glucksberg , Matthew S McGlone , Yosef Grodzin - sky , and Katrin Amunts . 2001 . Understanding ﬁgu - rative language : From metaphor to idioms . 36 . Ox - ford University Press on Demand . Roberto González - Ibánez , Smaranda Muresan , and Nina Wacholder . 2011 . Identifying sarcasm in twit - ter : a closer look . In Proceedings of the 49th An - nual Meeting of the Association for Computational Linguistics : Human Language Technologies : Short Papers - Volume 2 , pages 581 – 586 . Association for Computational Linguistics . Francis Heylighen and Jean - Marc Dewaele . 1999 . For - mality of language : deﬁnition , measurement and behavioral determinants . Interner Bericht , Center â ˘AIJLeo Apostelâ ˘A˙I , Vrije Universiteit Brüssel . Sepp Hochreiter and Jürgen Schmidhuber . 1997 . Long short - term memory . Neural computation , 9 ( 8 ) : 1735 – 1780 . Janet Holmes and Maria Stubbe . 2015 . Power and po - liteness in the workplace : A sociolinguistic analysis of talk at work . Routledge . Eduard Hovy . 1987 . Generating natural language un - der pragmatic constraints . Journal of Pragmatics , 11 ( 6 ) : 689 – 719 . Eduard Hovy . 2018 . Style as a strategic choice for so - cial interaction . personal communication . Suzana Ili´c , Edison Marrese - Taylor , Jorge A Balazs , and Yutaka Matsuo . 2018 . Deep contextualized word representations for detecting sarcasm and irony . arXiv preprint arXiv : 1809 . 09795 . James B Jacobs , Kimberly Potter , et al . 1998 . Hate crimes : Criminal law & identity politics . Oxford University Press on Demand . Hyeju Jang , Keith Maki , Eduard Hovy , and Carolyn Rose . 2017 . Finding structure in ﬁgurative language : Metaphor detection with topic - based frames . In Pro - ceedings of the 18th Annual SIGdial Meeting on Dis - course and Dialogue , pages 320 – 330 . Heng Ji and Kevin Knight . 2018 . Creative language encoding under censorship . In Proceedings of the First Workshop on Natural Language Processing for Internet Freedom , pages 23 – 33 . Aditya Joshi , Pushpak Bhattacharyya , and Mark J Car - man . 2017 . Automatic sarcasm detection : A survey . ACM Computing Surveys ( CSUR ) , 50 ( 5 ) : 73 . Aditya Joshi , Vaibhav Tripathi , Kevin Patel , Pushpak Bhattacharyya , and Mark Carman . 2016 . Are word embedding - based features useful for sarcasm detec - tion ? arXiv preprint arXiv : 1610 . 00883 . Taehee Jung , Dongyeop Kang , Lucas Mentch , and Ed - uard Hovy . 2019 . Earlier isn’t always better : Sub - aspect analysis on corpus and system biases in sum - marization . In Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , Hong Kong . Dongyeop Kang , Varun Gangal , and Eduard Hovy . 2019 . ( male , bachelor ) and ( female , ph . d ) have different connotations : Parallelly annotated stylistic language dataset with multiple personas . In Con - ference on Empirical Methods in Natural Language Processing ( EMNLP ) , Hong Kong . Dongyeop Kang , Varun Gangal , Ang Lu , Zheng Chen , and Eduard Hovy . 2017 . Detecting and explaining causes from text for a time series event . In Con - ference on Empirical Methods on Natural Language Processing . Geoffrey Keppel . 1991 . Design and analysis : A re - searcher’s handbook . Prentice - Hall , Inc . Mikhail Khodak , Nikunj Saunshi , and Kiran Vodrahalli . 2017 . A large self - annotated corpus for sarcasm . arXiv preprint arXiv : 1704 . 05579 . Chloe Kiddon and Yuriy Brun . 2011 . That’s what she said : Double entendre identiﬁcation . In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics : Human Language Tech - nologies : short papers - Volume 2 , pages 89 – 94 . As - sociation for Computational Linguistics . Soo - Min Kim and Eduard Hovy . 2004 . Determining the sentiment of opinions . In Proceedings of the 20th international conference on Computational Lin - guistics , page 1367 . Association for Computational Linguistics . Robin Tolmach Lakoff . 1973 . The logic of politeness : Minding your p’s and q’s . Yanran Li , Hui Su , Xiaoyu Shen , Wenjie Li , Ziqiang Cao , and Shuzi Niu . 2017 . Dailydialog : A manually labelled multi - turn dialogue dataset . arXiv preprint arXiv : 1710 . 03957 . Bing Liu et al . 2010 . Sentiment analysis and subjec - tivity . Handbook of natural language processing , 2 ( 2010 ) : 627 – 666 . Birte Loenneker - Rodman and Srini Narayanan . 2010 . Computational approaches to ﬁgurative language . Cambridge Encyclopedia of Psycholinguistics . James H Martin . 1992 . Computer understanding of conventional metaphoric language . Cognitive sci - ence , 16 ( 2 ) : 233 – 270 . Rada Mihalcea and Carlo Strapparava . 2006 . Learn - ing to laugh ( automatically ) : Computational models for humor recognition . Computational Intelligence , 22 ( 2 ) : 126 – 142 . Saif Mohammad , Ekaterina Shutova , and Peter Tur - ney . 2016 . Metaphor as a medium for emotion : An empirical study . In Proceedings of the Fifth Joint Conference on Lexical and Computational Seman - tics , pages 23 – 33 , Berlin , Germany . Association for Computational Linguistics . Michael Mohler , David Bracewell , Marc Tomlinson , and David Hinote . 2013 . Semantic signatures for example - based linguistic metaphor detection . In Proceedings of the First Workshop on Metaphor in NLP , pages 27 – 35 . Michael Mohler , Mary Brunson , Bryan Rink , and Marc T Tomlinson . 2016 . Introducing the lcc metaphor datasets . In LREC . Dong Nguyen , A Seza Do˘gruöz , Carolyn P Rosé , and Franciska de Jong . 2016 . Computational soci - olinguistics : A survey . Computational linguistics , 42 ( 3 ) : 537 – 593 . Malvina Nissim and Katja Markert . 2003 . Syn - tactic features and word similarity for supervised metonymy resolution . In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1 , pages 56 – 63 . Association for Computational Linguistics . Bo Pang , Lillian Lee , et al . 2008 . Opinion mining and sentiment analysis . Foundations and Trends R (cid:13) in In - formation Retrieval , 2 ( 1 – 2 ) : 1 – 135 . Lotem Peled and Roi Reichart . 2017 . Sarcasm sign : Interpreting sarcasm with sentiment based monolingual machine translation . arXiv preprint arXiv : 1704 . 06836 . Jeffrey Pennington , Richard Socher , and Christopher Manning . 2014 . Glove : Global vectors for word rep - resentation . In Proceedings of the 2014 conference on empirical methods in natural language process - ing ( EMNLP ) , pages 1532 – 1543 . Sasa Petrovic and David Matthews . 2013 . Unsuper - vised joke generation from big data . In ACL ( 2 ) , pages 228 – 232 . Peter Potash , Alexey Romanov , and Anna Rumshisky . 2017 . Semeval - 2017 task 6 : # hashtagwars : Learn - ing a sense of humor . In Proceedings of the 11th International Workshop on Semantic Evalua - tion ( SemEval - 2017 ) , pages 49 – 57 . Daniel Preo¸tiuc - Pietro and Lyle Ungar . 2018 . User - level race and ethnicity predictors from twitter text . In Proceedings of the 27th International Conference on Computational Linguistics , pages 1534 – 1545 . Taivo Pungas . 2017 . A dataset of english plaintext jokes . Ella Rabinovich , Shachar Mirkin , Raj Nath Patel , Lu - cia Specia , and Shuly Wintner . 2016 . Personal - ized machine translation : Preserving original author traits . arXiv preprint arXiv : 1610 . 05461 . Sudha Rao and Joel Tetreault . 2018 . Dear sir or madam , may i introduce the gyafc dataset : Corpus , benchmarks and metrics for formality style transfer . arXiv preprint arXiv : 1803 . 06535 . Hannah Rashkin , Eric Michael Smith , Margaret Li , and Y - Lan Boureau . 2019 . Towards empathetic open - domain conversation models : A new benchmark and dataset . In Proceedings of the 57th Annual Meet - ing of the Association for Computational Linguistics , pages 5370 – 5381 . Graeme Ritchie . 2005 . Computational mechanisms for pun generation . In Proceedings of the 10th Euro - pean Natural Language Generation Workshop , Ab - erdeen , August . Alfredo Láinez Rodrigo and Luke de Oliveira . Sequen - tial convolutional architectures for multi - sentence text classiﬁcation cs224n - ﬁnal project report . Sylvia Weber Russell . 1976 . Computer understanding of metaphorically used verbs . American journal of computational linguistics . Richard Socher , Alex Perelygin , Jean Wu , Jason Chuang , Christopher D Manning , Andrew Ng , and Christopher Potts . 2013 . Recursive deep models for semantic compositionality over a sentiment tree - bank . In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631 – 1642 . Gerard Steen . 2010 . A method for linguistic metaphor identiﬁcation : From MIP to MIPVU , volume 14 . John Benjamins Publishing . Joseph Tepperman , David Traum , and Shrikanth Narayanan . 2006 . " yeah right " : Sarcasm recogni - tion for spoken dialogue systems . In Ninth Interna - tional Conference on Spoken Language Processing . Marilyn A Walker , Jean E Fox Tree , Pranav Anand , Rob Abbott , and Joseph King . 2012 . A corpus for research on deliberation and debate . In LREC , pages 812 – 817 . Samuel Walker . 1994 . Hate speech : The history of an American controversy . U of Nebraska Press . Byron C Wallace . 2015 . Computational irony : A sur - vey and new perspectives . Artiﬁcial Intelligence Re - view , 43 ( 4 ) : 467 – 483 . Byron C Wallace , Laura Kertz , Eugene Charniak , et al . 2014 . Humans require context to infer ironic in - tent ( so computers probably do , too ) . In Proceed - ings of the 52nd Annual Meeting of the Association for Computational Linguistics ( Volume 2 : Short Pa - pers ) , pages 512 – 516 . Alex Wang , Amanpreet Singh , Julian Michael , Felix Hill , Omer Levy , and Samuel R Bowman . 2018 . Glue : A multi - task benchmark and analysis platform for natural language understanding . arXiv preprint arXiv : 1804 . 07461 . Joe H Ward Jr . 1963 . Hierarchical grouping to opti - mize an objective function . Journal of the American statistical association , 58 ( 301 ) : 236 – 244 . Amy Beth Warriner , Victor Kuperman , and Marc Brys - baert . 2013 . Norms of valence , arousal , and dom - inance for 13 , 915 english lemmas . Behavior re - search methods , 45 ( 4 ) : 1191 – 1207 . Diyi Yang , Alon Lavie , Chris Dyer , and Eduard H Hovy . 2015 . Humor recognition and humor anchor extraction . In EMNLP , pages 2367 – 2376 . A Details on ShortRomance ShortRomance text are crawled from the follow - ing websites . The copyright of the messages are owned by the original writer of the websites . • http : / / www . goodmorningtextmessages . com / 2013 / 06 / romantic - text - messages - for - her . html • https : / / www . travelandleisure . com / travel - tips / romantic - love - messages - for - him - and - her • https : / / www . amoramargo . com / en / sweet - text - messages - for - her / • https : / / www . techjunkie . com / best - romantic - text - messages - for - girlfriend / • https : / / liveboldandbloom . com / 10 / relationships / love - messages - for - wife • https : / / www . marriagefamilystrong . com / sweet - love - text - messages / • https : / / pairedlife . com / love / love - messages - for - him - and - her • https : / / truelovewords . com / sweet - love - text - messages - for - him / • https : / / www . serenataflowers . com / pollennation / love - text - messages / • https : / / www . greetingcardpoet . com / 73 - love - text - messages / • https : / / www . wishesmsg . com / heart - touching - love - messages / B Hyper - Parameters For our BERT classiﬁer , we use uncased BERT English model . Both training and testing use 8 size of batching . For the BiLSTM baseline , we use 32 17 size of batching for both training and testing and 256 hidden size for LSTM layer with 300 size of word embedding from GloVe ( Pennington et al . , 2014 ) . The vocabulary size of BiLSTM is same as the maximum vocabulary of BERT model ; 30522 . For both BERT and BiLSTM models , we use same maximum input length 128 . Both training use 2 e − 5 learning rate and 1 . 0 maximum gradient clipping with Adam optimizer with 1 e − 8 epsilon . Also , we use early stopping until the maximum training epochs of 5 . C Details on Diagnostic Set Collection : Annotation Schemes and Details Figure 5 shows snapshots of our annotation plat - form with the detailed instructions . We estimate the execution time of a task as 4 minutes , so pay - ing $ 9 / ( 60 minutes / 3 minutes ) = $ 0 . 4 per task . We make 10 size of batches multiple times and incre - mentally increase the size of batches up to 600 samples . For each batch , we manually checked the quality of outputs and blocked some bad users who abusively answered the questions . 17 32 size shows slightly better performance than smaller sizes like 8 or 16 . Figure 4 : Agglomerative clustering of style types based on the correlation matrix . Best viewed in color . D More Examples on Stylistic diversity Table 5 includes more examples with our stylistic diversity analysis . E Details on Cross - Style Correlation In addition , we cluster style types based on the pair - wise correlation coefﬁcients . Figure 4 shows the agglomerative clusters using Ward clustering algo - rithm ( Ward Jr , 1963 ) where distance is measured using Euclidean distance . We observe some reason - able groupings such as ages ( 35 - 44 , 45 - 54 , 55 - 74 ) negative emotional styles ( anger , digust , sadness , fear ) , positive affective styles ( happiness , domi - nance , valence , positive , polite ) , and more . For more detailed analysis , we also provide the pairplot distribution in Figure 6 . As pointed out earlier , many distribution of single style prediction scores is very skewed to the two extremes ( left for 0 and right for 1 ) , leading the poster calibration issue . Moreover , more causal analysis between styles by controlling the confounding variables is required . Figure 5 : Snapshots of our annotation tasks : general instruction ( top ) and annotation tasks on each style ( bottom ) . F Style Diversity on Personal Styles Figure 7 shows the style diversity on personal styles ( e . g . , gender , political view , age , and education level ) . We ﬁnd some unreasonable cases in debate domain ( Figure 7 ( b ) ) , where its proportion of polit - ical view is extremely biased to the left wing , even though the text is almost equally written by both sides ( i . e . , Clinton and Trump ) . Again , this shows the limitation of our classiﬁer - based analysis . Table 5 : Stylistic diversity of text : sampling 10 % of tweets with the highest ( lowest ) average of style predic - tion scores and then sampling again 10 % tweets with highest ( lowest ) standard deviation , where the former is stylistically diverse ( (cid:52) ) , while the latter is less - diverse ( (cid:53) ) . Some offensive words are replaced by * mark . Text m ea n s t d f o r m a l hu m o r ou s po lit e s a r ca s ti c m e t a pho r h a t e o ff e n s i v e r o m a n ti c po s iti v e a ng e r d i s gu s t f ea r h a pp i n e ss s a dn e ss s u r p r i s e F e m a l e 25 - 34 35 - 44 L e f t W i ng N o D e g r ee H i gh S c hoo l B ac h e l o r C a u ca s i a n H i s p O r L a ti A fr i ca n Stylistically diverse text (cid:52) (cid:52) i’m glad i can add hilarity into your life . 32 . 45 . 98 . 99 0 . 99 . 99 0 0 . 99 . 99 0 0 0 . 99 0 0 . 99 . 97 0 . 99 0 0 . 99 . 99 0 0 sitting with amazing women talking about what we’re grateful for love them . 31 . 45 . 97 . 99 . 94 . 99 0 0 . 99 . 99 . 99 0 0 0 . 97 0 0 . 99 . 98 0 0 0 . 98 0 . 98 0 . 01 the train is a superb opportunity to fall into someone’s lap and meet the love of one’s life . 32 . 45 . 99 . 99 . 99 . 99 . 99 0 0 . 99 . 99 0 0 0 0 0 0 . 99 . 96 . 01 . 99 . 9 0 . 05 . 99 0 0 it was really cool speaking with you today i look forward to working for you . 32 . 45 . 99 . 99 . 99 . 99 0 0 0 . 99 . 99 0 0 0 . 98 0 0 . 95 . 91 . 08 0 0 . 94 0 0 0 . 99 thank god the ap has posted a video of matt da - mon’s feelings on sarah palin my life is com - plete . 31 . 45 0 . 99 . 89 . 99 . 99 0 0 . 99 . 99 0 0 0 . 99 0 0 . 99 . 99 0 . 95 0 0 . 99 . 99 0 0 i’m * ucking proud of you baby you’ve come a long way . 31 . 45 0 . 99 . 99 0 . 99 0 . 99 . 99 . 99 0 0 0 . 99 0 0 0 . 99 0 . 37 0 . 98 0 0 0 . 99 tweeter opens so many new communication channels it’s an absolute pleasure to be so close to the pople that have so much to share . 31 . 45 . 99 . 99 . 93 . 99 . 99 0 0 0 . 99 0 0 0 . 99 0 0 . 99 . 98 . 01 . 99 . 01 0 . 96 0 0 . 89 have i mentioned how excited i am to hang out with this weekend no i am so excited . 3 . 44 0 . 99 . 99 . 99 0 0 . 99 . 99 . 99 0 0 0 . 99 0 0 . 99 . 97 . 02 0 0 . 99 0 0 0 . 99 today i feel thankful for the beautiful things in my life . 32 . 44 . 89 . 99 . 99 . 99 . 05 0 0 . 99 . 99 0 0 0 . 98 0 0 . 99 . 98 . 01 . 94 . 93 . 02 . 01 . 99 0 0 yay my friend just called to tell me everything is set for my birthday this thurs can’t wait at least that’s cheering me up . 3 . 44 0 . 99 . 99 . 99 . 99 0 . 99 0 . 99 0 0 0 . 99 0 0 0 . 98 0 0 0 . 99 0 0 0 . 99 Stylistically less - diverse text (cid:53) (cid:53) lip / tongue tingling . 15 . 28 . 01 0 . 02 0 0 0 0 0 0 0 0 0 0 0 0 0 . 15 . 01 . 27 . 01 . 01 0 . 02 . 02 0 satellite server is a mess cleaning up . 15 . 28 0 0 . 04 . 01 . 68 0 0 0 0 0 0 0 0 0 0 . 94 . 01 . 01 0 0 . 03 0 0 . 06 . 29 having beer with and some latin americans . 14 . 28 0 0 . 28 0 0 0 0 0 . 99 0 0 0 0 0 0 . 93 . 01 . 04 0 . 01 . 39 0 0 . 05 0 new blog post and then there was stillness . 15 . 28 0 0 0 0 0 0 0 0 . 01 0 0 0 . 01 0 0 . 99 . 09 . 49 0 . 02 . 21 . 56 . 1 . 73 . 05 ahh interview in hours . 15 . 28 0 0 . 56 0 0 0 0 0 0 0 0 0 0 0 0 . 99 . 74 0 0 . 06 . 17 0 . 41 . 28 . 03 actually usb 3g card connected via dial - up pro - ﬁle want to share over airport google suggests lots of issues with this conﬁg . 13 . 28 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 92 . 01 0 . 02 . 14 0 0 . 01 . 28 is listening to owen play with the university of oregon duck lips riotous . 14 . 28 0 0 0 0 0 0 0 0 . 02 0 0 0 . 11 0 0 . 06 . 09 . 8 0 . 03 . 07 0 0 . 01 . 94 she may have noticed but you may want to men - tion it just to make sure and to let her know that others think so . 14 . 28 . 05 0 . 02 . 01 0 0 0 0 0 0 0 0 0 0 0 . 99 . 69 . 02 . 01 . 26 . 02 . 02 . 59 0 0 i’m all kinds of culinary . 15 . 28 0 0 0 0 0 0 0 0 . 99 0 0 0 0 0 0 . 46 . 6 . 34 0 . 01 . 01 0 . 91 0 . 07 at home with wine and wife ﬁnally . 14 . 28 0 0 . 09 . 01 0 0 . 63 0 . 99 0 0 0 0 0 0 . 99 . 13 . 2 0 0 . 04 0 . 01 . 29 0 Figure 6 : Pairplot of the pairwise correlation between styles . Best viewed in color . Tweets Reddit News Papers Script Debate 0 0 . 25 0 . 5 0 . 75 1 Female Male Non - binary ( a ) Persona : gender Tweets Reddit News Papers Script Debate 0 0 . 2 0 . 4 0 . 6 0 . 8 LeftWing RightWing ( b ) Persona : political view Tweets Reddit News Papers Script Debate 0 0 . 25 0 . 5 0 . 75 1 < 12 12 - 17 18 - 24 25 - 34 35 - 44 45 - 54 55 - 74 75 < = ( c ) Persona : age Tweets Reddit News Papers Script Debate 0 0 . 25 0 . 5 0 . 75 1 NoDegree HighSchool Bachelor Master Doctorate ( d ) Persona : education level Figure 7 : Style diversity analysis on personal styles .