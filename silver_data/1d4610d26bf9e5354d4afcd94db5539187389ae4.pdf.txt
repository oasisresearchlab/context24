Parallel Global Edge Switching for the Uniform Sampling of Simple Graphs with Prescribed Degrees ∗ Daniel Allendorf ! Goethe University Frankfurt , Germany Ulrich Meyer ! Goethe University Frankfurt , Germany Manuel Penschuck ! Goethe University Frankfurt , Germany Hung Tran ! Goethe University Frankfurt , Germany Abstract The uniform sampling of simple graphs matching a prescribed degree sequence is an important tool in network science , e . g . to construct graph generators or null - models . Here , the Edge Switching Markov Chain ( ES - MC ) is a common choice . Given an arbitrary simple graph with the required degree sequence , ES - MC carries out a large number of small changes , called edge switches , to eventually obtain a uniform sample . In practice , reasonably short runs eﬃciently yield approximate uniform samples . In this work , we study the problem of executing edge switches in parallel . We discuss par - allelizations of ES - MC , but ﬁnd that this approach suﬀers from complex dependencies between edge switches . For this reason , we propose the Global Edge Switching Markov Chain ( G - ES - MC ) , an ES - MC variant with simpler dependencies . We show that G - ES - MC converges to the uniform distribution and design shared - memory parallel algorithms for ES - MC and G - ES - MC . In an empirical evaluation , we provide evidence that G - ES - MC requires not more switches than ES - MC ( and often fewer ) , and demonstrate the eﬃciency and scalability of our parallel G - ES - MC implementation . 2012 ACM Subject Classiﬁcation Mathematics of computing → Random graphs Keywords and phrases Random Graph , Uniform Sampling , Markov Chain , Edge Switching , Paral - lelism Supplementary Material Source code : https : / / github . com / manpen / global - edge - switching . 1 Introduction In network science there are various measures , so - called centralities , to quantify the importance of nodes [ 1 ] . The degree centrality , for instance , suggests that a node’s importance is proportional to its degree , i . e . , the number of neighbors it has ( see also [ 2 ] ) . This leads to the natural question whether graphs with matching degrees share structural properties . While this is not the case in general , a reoccurring task in practice is to quantify the statistical signiﬁcance of some property observed in a network . Given an observed graph with degrees d , a popular null - model is the uniform distribution over all simple graphs G ( d ) with matching degrees [ 3 – 5 ] . In this context , the Edge Switching Markov Chain ( ES - MC ) is a common choice to obtain an approximate uniform sample from G ( d ) . In each so - called edge switch , two edges are selected uniformly at random and modiﬁed by exchanging their endpoints . This process ∗ Accepted manuscript . Link to ﬁnal version : https : / / doi . org / 10 . 1016 / j . jpdc . 2022 . 12 . 010 a r X i v : 2111 . 03005v2 [ c s . D S ] 15 F e b 2023 2 Parallel Global Edge Switching for the Uniform Sampling of Graphs preserves the degrees of all nodes involved . We further keep the graph simple by rejecting all edge switches that introduce self - loops or multi - edges . There exist diﬀerent variants of ES - MC catering to various graph classes ( e . g . Carstens [ 6 ] considers directed / undirected graphs , with / without loops , with / without multi - edges ) . Here , we focus on simple and undirected graphs . It is , however , straight - forward to adopt our ﬁndings to the other cases ( some of which even lead to easier algorithms ) . 1 . 1 Related Work Various methods to obtain a graph from a prescribed degree sequence have been studied [ 7 ] . Havel [ 8 ] and Hakimi [ 9 ] independently lay the foundation for a deterministic linear time generator . The algorithm , however , does not yield random graphs ; while randomizations ( e . g . [ 10 , 11 ] ) are available , they produce non - uniform samples . The Chung - Lu Model [ 12 ] constructs graphs that match the prescribed degrees only in expectation . Under reasonable assumptions [ 7 ] it can be sampled in linear time [ 13 ] . The Conﬁguration Model [ 14 ] outputs a random , but possibly non - simple , graph in linear time ; adding rejection - sampling yields simple graphs in polynomial time if the maximum degree is O (cid:0) √ log n (cid:1) ( cf . [ 15 – 18 ] ) . Eﬃcient and exact uniform generators can be obtained by adding a repair step between the Conﬁguration Model and the rejection - sampling to boost the acceptance probability . Such algorithms are available for several degree sequences classes including bounded regular graphs or power - law sequences with suﬃciently large exponents [ 19 – 21 ] . Further a plethora of Markov Chain Monte - Carlo ( MCMC ) algorithms have been proposed and analyzed ( e . g . [ 22 – 31 ] ) . In comparison to the aforementioned exactly uniform generators , these algorithms allow for larger families of degree sequences , topological restrictions ( e . g . connected graphs [ 24 , 31 ] ) , or more general characterizations ( e . g . joint degrees [ 27 , 28 ] ) . Switch Markov Chains such as ES - MC have been shown to be rapidly mixing for classes of undirected graphs such as bounded - degree or power - law graphs ( c . f . [ 23 , 32 – 37 ] ) . While these bounds remain impractical for everyday use due to the high degrees of the polynomials involved , empirical studies suggest that a number of steps linear in the number of edges yields samples which are suﬃciently uncorrelated to the input graph [ 24 , 38 , 39 ] . The only prior parallelization of ES - MC we are aware of was given by [ 40 ] . While the proposed algorithm has the advantage that it can be used in a distributed setting , it only avoids conﬂicts between edge switches that arise due to concurrent accesses to the same edge . This however is not enough to ensure that the algorithm faithfully implements ES - MC , e . g . the graphs generated by the parallel process diﬀer from the ones generated by a sequential process . To address this issue the authors conduct an empirical error analysis . However , the issue remains that the graphs generated by such a process may not converge to the uniform distribution due to asymmetrical transition probabilities [ 41 ] . In addition , [ 42 ] proposed an external memory parallelization of the Curveball Markov Chain for sampling undirected graphs . Note however , that this algorithm requires sorting as a subroutine , which may be too expensive for usage in internal memory . In contrast to switch Markov Chains , Curveball has also not been shown to be rapidly mixing for undirected graphs , and despite preliminary empirical results [ 42 ] , it remains an open question to relate the mixing times of Curveball and ES - MC for undirected graphs . D . Allendorf , U . Meyer , M . Penschuck and H . Tran 3 1 . 2 Our Contribution We propose the Global Edge Switching Markov Chain ( G - ES - MC ) , a new switch Markov Chain for sampling simple undirected graphs with prescribed degrees and show that it converges to the uniform distribution . This Markov Chain is designed with parallel algorithms in mind and exhibits less complex dependencies between edge switches . Consequently , we describe and analyze an exact shared - memory parallel algorithm for G - ES - MC . In addition , we describe an exact parallel algorithm for ES - MC . In an empirical study , we provide evidence that G - ES - MC mixes faster than or equally well as standard ES - MC , and demonstrate the eﬃciency and scalability of our parallel G - ES - MC implementation . To the best of our knowledge , our implementation outperforms all openly available solutions by up to two orders of magnitude using 32 threads . 1 . 3 Outline The article is structured as follows . Section 2 covers the notation used and the necessary background for our results , such as a deﬁnition of the Edge Switching Markov Chain ( ES - MC ) . In Section 3 , we introduce the Global Edge Switching Markov Chain ( G - ES - MC ) and prove its convergence to the uniform distribution . Section 4 contains a description of our parallel algorithms for ES - MC and G - ES - MC , and a formal analysis of the G - ES - MC algorithm . We discuss implementation details of the parallel G - ES - MC algorithm , as well as sequential and parallel baseline / reference implementations , in Section 5 . In Section 6 , we relate the mixing time of ES - MC and G - ES - MC empirically and investigate the eﬃciency and scalability of our implementations . Section 7 concludes the article with a summary of the results and an outlook on potential future work . 2 Preliminaries 2 . 1 Notation and Deﬁnitions Deﬁne the short - hands [ k . . n ] : = { k , . . . , n } and [ n ] : = [ 1 . . n ] . A graph G = ( V , E ) has n nodes V = { v 1 , . . . , v n } and m undirected edges E . We assume that edges are indexed ( e . g . by their position in an edge list ) and denote the i - th edge of a graph as E [ i ] . Given an undirected edge e = { v i , v j } we denote a directed representation as ~ e . We treat both as the same object and deﬁning one implies the other ; we default to the canonical orientation ~ e = ( v min ( i , j ) , v max ( i , j ) ) whenever the direction is ambiguous . An edge ( v , v ) is called a loop at v ; an edge that appears more than once is called a multi - edge . A graph is simple if it contains neither multi - edges nor loops . Given a graph G = ( V , E ) and a node v ∈ V , deﬁne the degree deg ( v ) = | { u : { u , v } ∈ E } | as the number of edges incident to node v . Let d = ( d 1 , . . . , d n ) ∈ N n be a degree sequence and denote G ( d ) as the set of simple graphs on n nodes with deg ( v i ) = d i for all v i ∈ V . The degree sequence d is graphical if G ( d ) is non - empty . A commonly considered class of graphs are power - law graphs where the degrees follow a power - law distribution . To this end , let Pld ( [ a . . b ] , γ ) refer to an integer Power - law Distribution with exponent − γ ∈ R for γ ≥ 1 and values from the interval [ a . . b ] ; let X be an integer random variable drawn from Pld ( [ a . . b ] , γ ) , then P [ X = k ] ∝ k − γ ( proportional to ) if a ≤ k ≤ b and P [ X = k ] = 0 otherwise . 4 Parallel Global Edge Switching for the Uniform Sampling of Graphs A B X Y A B X Y A B X Y A B X Y e 1 e 5 e 2 Input G e 3 e 5 e 4 σ (cid:0) ( e 1 , e 2 ) , 0 (cid:1) rejected : multi - edge e 3 e 5 e 4 σ (cid:0) ( e 1 , e 2 ) , 1 (cid:1) accepted e 3 e 4 e 2 σ (cid:0) ( e 1 , e 5 ) , 0 (cid:1) rejected : loop Figure 1 Edge Switch on an undirected graph G = ( V , E ) . To avoid ambiguity , we indicate for each e ∈ E the orientation ~ e used in Deﬁnition 1 . 2 . 2 The Edge Switching Markov Chain ( ES - MC ) Deﬁnition 1 ( Edge Switch , ES - MC ) . Let G = ( V , E ) ∈ G ( d ) be a simple undirected graph . We represent an edge switch σ = ( i , j , g ) by two indices i , j ∈ [ m ] and a direction bit g . Then , we compute G 0 ∈ G ( d ) based on σ as follows : 1 . Let e 1 = E [ i ] and e 2 = E [ j ] . 2 . Compute new edges ( ~ e 3 , ~ e 4 ) = τ ( ~ e 1 , ~ e 2 , g ) where τ (cid:0) ( u , v ) , ( x , y ) , g (cid:1) = ( (cid:0) ( u , x ) , ( v , y ) (cid:1) if g = 0 (cid:0) ( u , y ) , ( v , x ) (cid:1) if g = 1 . 3 . Reject if either of e 3 or e 4 is a loop or already exists in E ; otherwise accept and set E [ i ] ← e 3 and E [ j ] ← e 4 . The Edge Switching Markov Chain ( ES - MC ) transitions from state G to state G 0 ∈ G ( d ) by sampling i , j , and g uniformly at random . 4 Observation 1 . Any edge switch σ = ( i , j , g ) that translates G into G 0 can be reversed in a single step , i . e . , there exists an inverse edge switch ˜ σ that translates G 0 back into G . If σ is rejected , it does not alter the graph ( G = G 0 ) . Thus the claim trivially holds with ˜ σ = σ . For an accepted edge switch σ , it is easy to verify that ˜ σ = ( i , j , 0 ) reverses the eﬀects of σ . Further observe that the probability of choosing σ in state G equals the probability of choosing ˜ σ in state G 0 [ 36 ] . 4 3 Global Edge Switching Markov Chain ( G - ES - MC ) Hamann et al . [ 44 ] consider the out - of - order execution of a batch consisting of ‘ edge switches . To this end , they classify the dependencies within the batch that arise if the switches were executed in - order . We adopt this characterization distinguishing between source - and target dependencies : Deﬁnition 2 ( Source / target dependencies ) . Two switches σ 1 = ( i 1 , j 1 , · ) and σ 2 = ( i 2 , j 2 , · ) are source dependent if they share at least one source index , i . e . , { i 1 , j 1 } ∩ { i 2 , j 2 } 6 = ∅ . Two switches ( e 1 , f 1 ) ← σ ( · , · , · ) and ( e 2 , f 2 ) ← σ ( · , · , · ) have a target dependency if they try to produce at least one common edge , i . e . , { e 1 , f 1 } ∩ { e 2 , f 2 } 6 = ∅ ; this dependency is counted even if one or both edge switches are rejected . 4 Source dependencies can be modelled by a balls - into - bins process where edges correspond to bins and each edge switch throws a linked pair of balls into two bins chosen uniformly at random . A source dependency arises whenever a ball falls into a non - empty bin . Czumaj and Lingas [ 45 ] analyse this process in a diﬀerent context . Interpreted for ES - MC , they show that D . Allendorf , U . Meyer , M . Penschuck and H . Tran 5 for ‘ = m the longest source dependency chain has an expected length of Θ ( log m / log log m ) . The distribution of target dependencies , on the other hand , depends on the graph’s degree sequence as the probability that a random edge switch produces the edge { u , v } is proportional to deg ( u ) · deg ( v ) . From an algorithmic point of view , source dependencies are more diﬃcult to deal with if we want to process edge switches out - of - order ( e . g . for parallel execution ) . Since each previous edge switch may or may not change the edge associated with the colliding edge index , the number of possible assignments may grow exponentially in the length of the dependency chain ( if multiple chains cross ) . Consequently , we need to either serialize such edge switches or accommodate all possible assignments . In contrast , target dependencies only imply a binary predicate , namely whether a previous edge switch already introduced the target edge . The above discussion suggests that it is most reasonable to parallelize ES - MC by parallelizing batches of edge switches without source dependencies . Naturally , the scalability of such a parallelization depends on the size of these batches . For ES - MC , each switch selects its source edges uniformly at random , and the probability of a source dependency between two edge switches is Θ ( 1 / m ) . Thus , the expected batch size for ES - MC is Θ ( √ m ) . As the expected batch size for ES - MC is rather small , it is natural to ask if there exist other switch Markov Chains where the size is larger , and which thereby exhibit more parallelism . To answer this question , we deﬁne a global switch 1 — a batch of up to b m / 2 c edge switches where each edge participates in an edge switch exactly once ; conceptually , we place all edges into an urn and iteratively draw without replacement pairs of edges until the urn is empty ; each pair implies an edge switch . It is folklore to encode such a process in a permutation that captures the order of edges drawn [ 7 ] . Similarly to techniques of [ 42 , 46 ] , our proof of Theorem 1 requires a small positive probability that any global switch collapses into a single switch . We implement this by independently rejecting each switch with probability P L . Deﬁnition 3 ( Global Switch , G - ES - MC ) . Let G = ( V , E ) be a simple undirected graph . A global switch is represented by Γ = ( π , ‘ ) where π is a permutation of [ m ] and ‘ an integer with 0 ≤ ‘ ≤ b m / 2 c . The global switch Γ consists of ‘ edge switches σ 1 , . . . , σ ‘ that are executed in sequence , where σ k = ( π ( 2 k − 1 ) , π ( 2 k ) , g k ) and g k = 1 π ( 2 k − 1 ) < π ( 2 k ) , and where 1 denotes the indicator function . The Global Edge Switching Markov Chain ( G - ES - MC ) transitions from graph G using a random global switch Γ = ( π , ‘ ) . To this end , π is drawn uniformly from all permutations on [ m ] and ‘ is drawn from a binomial distribution of b m / 2 c trails with success probability 0 < P L < 1 . 4 By selecting ‘ from a binomial distribution and executing the ﬁrst ‘ edge switches of a random permutation , we simulate b m / 2 c edge switches that are each executed only with probability 1 − P L . Also note , that the direction bits g k = 1 π ( 2 k − 1 ) < π ( 2 k ) are independent and unbiased random bits because the permutation π is drawn uniformly at random . Theorem 1 . Let G ∈ G ( d ) be a simple undirected graph with degree sequence d . The Global Edge Switching Markov Chain started at G converges to the uniform distribution on G ( d ) . 1 We adapt the term global from [ 46 ] where it is used to describe a variant of the Curveball Markov Chain . 6 Parallel Global Edge Switching for the Uniform Sampling of Graphs Proof . Any Markov Chain that is irreducible , aperiodic and symmetric converges to a uniform distribution [ 47 , Th . 7 . 10 ] . We show that G - ES - MC has these three properties . For irreducibility we observe that whenever there exists an edge switch from state A to B , there also exists a global switch from A to B ( e . g . if ‘ = 1 ) . The state graph of ES - MC is therefore a subgraph of the state graph of G - ES - MC . In addition , both Markov Chains share the same set of states , i . e . , the set of all simple graphs with the given degree sequence . Then , since the state graph of ES - MC is already strongly connected [ 48 ] , so is the state graph of G - ES - MC , and thus both Markov Chains are irreducible . For aperiodicity we note that a global switch Γ = ( π , ‘ ) may not alter the graph ( e . g . , if ‘ = 0 ) . Thus each state in the Markov Chain has a self - loop with strictly positive probability mass . This guarantees aperiodicity . It remains to show the symmetry of transition probabilities . Let S AB be the set of global switches Γ that transform graph A into graph B . Then the transition probability P AB from A to B equals the probability of drawing a global switch from S AB , P AB = X Γ ∈S AB P ( Γ ) , where P ( Γ ) is the probability of selecting Γ . A global switch Γ = ( π , ‘ ) is selected by drawing its permutation π and executing ‘ edge switches . In particular , we have P ( Γ ) = 1 m ! | { z } uniform π · (cid:18) b m / 2 c ‘ (cid:19) ( 1 − P L ) ‘ P b m / 2 c− ‘ L | { z } binomially distributed ‘ . Observe that P ( Γ = ( π , ‘ ) ) depends on ‘ , but neither on a speciﬁc choice of π nor the states A and B . Thus the symmetry P AB = P BA follows by establishing a bijection µ AB between any forward global switch Γ = ( π , ‘ ) ∈ S AB and an inverse global switch ˜Γ = ( ˜ π , ‘ ) ∈ S BA with matching ‘ . We construct the bijection µ AB as follows . For a global switch Γ = ( π , ‘ ) that executes the edge switches σ 1 , . . . , σ ‘ with σ k = ( π ( 2 k − 1 ) , π ( 2 k ) , g k ) in sequence , deﬁne the inverse global switch ˜Γ = ( ˜ π , ‘ ) . The global switch ˜Γ executes the inverse edge switches in reverse order , i . e . , ˜ σ ‘ − k + 1 recovers the eﬀect of the forward edge switch σ k . Recall that ( i ) the inverse of an accepted edge switch is given by a direction ﬂag g = 0 , and that ( ii ) the forward direction bit is deﬁned as g k = 1 π ( 2 k − 1 ) < π ( 2 k ) . Thus , if σ k is legal and g k = 1 , we need to switch the order of the edge indices in the inverse switch ˜ σ ‘ − k + 1 . This implies ˜ π on positions [ 2 ‘ ] . In particular , we have for k ∈ [ ‘ ] : (cid:16) ˜ π ( 2 [ ‘ − k + 1 ] − 1 ) , ˜ π ( 2 [ ‘ − k + 1 ] ) (cid:17) = ( (cid:0) π ( 2 k − 1 ) , π ( 2 k ) (cid:1) σ k is illegal or g k = 0 (cid:0) π ( 2 k ) , π ( 2 k − 1 ) (cid:1) σ k is legal and g k = 1 For the unused entries i ∈ [ 2 ‘ + 1 . . m ] choose ˜ π ( i ) = π ( i ) . (cid:74) 3 . 1 Mixing Time of G - ES - MC in relation to ES - MC For simple graphs , the mixing time of variants of ES - MC have been studied for many families of degree sequences ( c . f . [ 23 , 32 – 36 ] ) . Recently , Erdös et al . [ 37 ] provide a survey that uniﬁes many proofs on rapidly mixing Switching Markov chains on diﬀerent types of degree sequences . Furthermore , for bipartite degree sequences a theoretical comparison D . Allendorf , U . Meyer , M . Penschuck and H . Tran 7 between a variant of ES - MC and the more recent Curveball Markov Chain [ 30 ] has been established [ 49 ] . 2 This proved to be the ﬁrst result regarding the mixing time for Curveball Markov Chains . In this subsection we present the comparison framework that was used in [ 49 ] and highlight why it is diﬃcult to apply for a comparison of G - ES - MC with ES - MC . The framework considers a Markov Chain M and its heat - bath variant M heat and relates the second largest eigenvalues of both Markov Chains to then compare the mixing times . For the sake of uniformity we use the same terminology : for an ergodic Markov Chain M = ( Ω , P ) with stationary distribution π where π ( x ) > 0 for all x ∈ Ω , that can be decomposed as P = X a ∈L ρ ( a ) X R ∈R a P R where i ) L is a ﬁnite index set , ii ) ρ a probability distribution over L , iii ) R a = S R ‘ , a a partition of Ω for a ∈ L and where the restriction of a matrix P R to the rows and columns of R = R ‘ , a deﬁnes the transition matrix of an ergodic , time - reversible Markov Chain on R ( and is zero elsewhere ) , with stationary distribution ˜ π R ( x ) = π ( x ) / π ( R ) for x ∈ R . As highlighted , a state transition of M can be thought of as drawing an index a from L and then performing a transition on R . Then , the heat - bath variant M heat of the Markov chain M is given by the transition matrix P heat = X a ∈L ρ ( a ) X R ∈R a 1 · σ R where σ R is a row - vector given by σ R ( x ) = ˜ π R ( x ) if x ∈ R and zero otherwise , and 1 the all - ones column vector . Similar to before , M heat can be thought of ﬁrst drawing an index a from L but then simply drawing a state x in R with probability ˜ π R ( x ) . For our purposes , in order to apply this framework we require a suitable index set L , probability distribution ρ and state space decompositions R a for a ∈ L , such that G - ES - MC is the heat - bath variant M heat of ES - MC . However , in this setting G - ES - MC must by construction already provide a transition matrix 1 · σ R that reﬂects the stationary distribution π up to scaling on all restrictions R for any a . Naturally and analogously to the original proof in [ 49 ] , the choice for L is a set of entries in the adjacency matrix of size m that need to be switched in some order . In this case , any possible order of execution must be reﬂected in R a given the chosen entries provided by the initial choice a . Additionally , a transition to any such possible graph must be uniformly given by σ R which in general does not hold . 4 Parallel Algorithms for ES - MC and G - ES - MC In this section , we describe parallel algorithms for ES - MC and G - ES - MC . Both algorithms rely on ParallelSuperstep , a parallel algorithm that performs a superstep of edge switches σ 1 , . . . , σ ‘ without source dependencies while preserving the observable outcome , i . e . the graph produced is the same as if the switches were performed sequentially . 2 For a general survey on random graph generation we refer the interested reader to the recent survey by Greenhill [ 50 ] . 8 Parallel Global Edge Switching for the Uniform Sampling of Graphs To this end , we detect all edge switches in σ 1 , . . . , σ ‘ that have target dependencies on other switches , and ensure that if a switch σ depends on another switch σ 0 , then σ is decided 3 only after σ 0 is . For our purposes , it is convenient to think in terms of the following two types of target dependencies : An edge switch σ k has an erase dependency via edge e on switch σ p if σ k has e as target edge , σ p has e as source edge and k > p . In this case , σ k will attempt to insert an edge that σ p erases , but since k > p , it may well be the case that σ k is legal , if σ p is legal , and thus we must ensure that σ p is decided before σ k . An edge switch σ k has an insert dependency via edge e on switch σ q if both σ k and σ q have e as target edge and k > q . In this case , σ k will attempt to insert an edge that σ q inserts , but since k > q , it is the case that σ k is illegal , if σ q is legal , and thus we must ensure that σ q is decided before σ k . Observation 2 . Given a graph G = ( V , E ) a superstep of edge switches without source dependencies attempts to remove only edges e ∈ E and does so only once . As a direct consequence all erase dependencies for some edge e ∈ E originate in the same switch σ . Also , for any number of insert dependencies for some edge e at most one switch σ can be successful . 4 Algorithm 1 shows an implementation of ParallelSuperstep in pseudocode . Before performing a superstep , we store the dependencies of the edge switches σ 1 , . . . , σ ‘ in a concurrent hash table T . Then , while attempting to decide a switch , this allows us to lookup the dependencies of the switch and check if the switch is ready to be decided or has unresolved dependencies . A superstep is then performed incrementally during multiple rounds . In each round , we only decide switches that have no dependencies on undecided switches . This in turn resolves the dependencies of all switches that only depend on the decided switches , and as the dependencies cannot be circular , we eventually decide all switches in this way . Then , ﬁnally , once all switches have been decided , the superstep has been performed . We store the dependencies as tuples in a concurrent hash table , and index them by the source or target edge . For each switch σ k , we store four tuples , one for each source and each target edge , containing the edge e , the index k of the switch , the type of operation the switch attempts to perform on the edge t e , k ∈ { erase , insert } and a status ﬂag s k ∈ { undecided , legal , illegal } , that is initially set to undecided . We also use the same data structure to lookup the existence of edges . To this end , we assume that T implicitly stores a tuple ( e , ∞ , erase , illegal ) for each edge that is in the graph , but not a source edge of any switch in the batch , causing a switch that attempts to insert such an edge to be decided as illegal . Now , when attempting to decide a switch σ k , we lookup all tuples where the edge is one of its target edges . By Observation 2 , for each target edge e , there is at most one tuple stored by a switch σ p where t e , p = erase , i . e . that erases the edge . Similarly , for each target edge e , there is at most one tuple stored by a switch σ q , that is legal , and inserts the target edge . Speciﬁcally , at any point , the only tuple that needs to be considered is the tuple with the smallest index q where t e , q = insert and s q 6 = illegal . We then use this information to decide if σ k is legal , illegal , or has to be delayed . If k < p or s p = illegal , then a target edge of the switch σ k is only erased by a later switch σ p , or not erased at all , and thus the switch is illegal . Similarly , if k > q and s q = legal , 3 We say that a single edge switch is decided after we rewire the edges , if it is legal , or reject the switch , if it is illegal . D . Allendorf , U . Meyer , M . Penschuck and H . Tran 9 Algorithm 1 ParallelSuperstep Data : edge list E , superstep of switches S 1 T ← ∅ / / Initialize dependency table T 2 for σ k ∈ S in parallel 3 ( i , j , g ) ← σ k , e 1 ← E [ i ] , e 2 ← E [ j ] 4 Compute target edges ( ~ e 3 , ~ e 4 ) ← τ ( ~ e 1 , ~ e 2 , g ) 5 ∀ e a ∈ { e 1 , e 2 } : T . store ( e a , k , erase , undecided ) 6 ∀ e b ∈ { e 3 , e 4 } : T . store ( e b , k , insert , undecided ) 7 U ← S / / Initialize array U for undecided switches 8 while U not empty do / / Perform superstep S 9 D ← ∅ / / Initialize array D for delayed switches 10 for σ k ∈ S in parallel 11 ( i , j , g ) ← σ k , e 1 ← E [ i ] , e 2 ← E [ j ] 12 Compute target edges ( ~ e 3 , ~ e 4 ) ← τ ( ~ e 1 , ~ e 2 , g ) 13 s k ← legal / / Initialize status s k of σ k 14 for e ∈ { e 3 , e 4 } do / / Lookup dependencies 15 if e is self - loop then 16 s k ← illegal 17 p , s p ← T . lookup ( e , erase ) 18 q , s q ← T . lookup _ min ( e , insert ) 19 if k < p ∨ s p = illegal then 20 s k ← illegal 21 if k > q ∧ s q = legal then 22 s k ← illegal 23 if s k 6 = illegal then 24 if k > p ∧ s p = undecided then 25 s k ← undecided 26 if k > q ∧ s q = undecided then 27 s k ← undecided 28 if s k = legal then 29 E [ i ] ← e 3 , E [ j ] ← e 4 / / Success , rewire the edges 30 else if s k = undecided then 31 D . append ( σ k ) / / Delay the switch until the next round 32 ∀ e a ∈ { e 1 , e 2 } : T . update ( e a , k , erase , s k ) 33 ∀ e b ∈ { e 3 , e 4 } : T . update ( e b , k , insert , s k ) 34 barrier : wait until all switches completed 35 U ← D then a target edge of σ k is already inserted by the earlier switch σ q and thus the switch is illegal . Otherwise , if σ k has an erase or insert dependency , but the status of the other switch is undecided , the switch cannot be decided yet , and must be delayed . In any other case the switch is legal . If the switch is legal , the edges are rewired and the status of the tuples is set to legal . Otherwise , if the switch is illegal , the status of the tuples is set to illegal . Finally , if the switch has unresolved dependencies , we delay it until the next round . 4 . 1 ParES We ﬁrst describe how ParES , a parallelization of ES - MC , can be implemented by using ParallelSuperstep ( see Algorithm 2 ) . The algorithm ﬁrst populates an array R with the requested number of switches r by sampling two edge indices and a direction bit for each switch . The switches in R are then performed during multiple iterations , where each iteration performs a superstep . In each iteration , we let s denote the number of switches that were already performed . We then identify the next superstep by ﬁnding the smallest index t > s of a switch that has a source collision with another switch in the sequence σ s , . . . , σ r . To this end , we insert for each switch σ k two tuples ( i , k ) and ( j , k ) into a concurrent hash set . If for any edge index i , a diﬀerent 10 Parallel Global Edge Switching for the Uniform Sampling of Graphs Algorithm 2 ParES Data : edge list E , requested number of switches r / / Initialize array of requested switches R 1 R ← ∅ 2 for k from 1 to r in parallel 3 Sample edge indices i , j ∼ [ m ] with i 6 = j 4 Sample direction bit g ∼ { 0 , 1 } 5 R [ k ] ← ( i , j , g ) 6 s ← 1 7 while s ≤ r do / / Initialize hash set H 8 H ← ∅ / / Find superstep without source dependencies 9 t ← r + 1 10 for k from s to ( t − 1 ) in parallel / / Check for collision and update lower bound t 11 ( i , j , g ) ← R [ k ] 12 k 0 ← H . insert _ if _ min ( i , k ) 13 k 00 ← H . insert _ if _ min ( j , k ) 14 t 0 ← max { k , k 0 } , t 00 ← max { k , k 00 } 15 t ← min { t , t 0 , t 00 } / / Perform superstep σ s , . . . , σ t − 1 16 S [ k − s + 1 ] ← R [ k ] ∀ s ≤ k ≤ t − 1 17 ParallelSuperstep ( E , S ) 18 s ← t Algorithm 3 ParGlobalES Data : edge list E , requested number of global switches r 1 for i from 1 to r do / / Select random global switch Γ = ( π , ‘ ) 2 Sample random permutation π of [ m ] 3 Sample ‘ ∼ Binom ( b m / 2 c , 1 − P L ) / / Perform global switch 4 S [ k ] ← ( π ( 2 k − 1 ) , π ( 2 k ) , 1 π ( 2 k − 1 ) < π ( 2 k ) ) ∀ 1 ≤ k ≤ ‘ 5 ParallelSuperstep ( E , S ) switch σ k 0 exists which has inserted the same index i , we know that the ﬁrst collision occurs at most at index t 0 = max { k , k 0 } so we set the lower bound to t ← min { t , t 0 } . In addition , if k < k 0 , we replace the tuple ( i , k 0 ) by ( i , k ) to detect further switches k < k 00 < k 0 which may update the lower bound . Once all switches up to the lower bound t have been inserted , we know that σ s , . . . , σ t − 1 is a sequence of edge switches without source dependencies . These edge switches are then performed by using ParallelSuperstep . 4 . 2 ParGlobalES Implementing the parallelization ParGlobalES of G - ES - MC is much simpler ( see Al - gorithm 3 ) . As a global switch Γ contains no source dependencies by deﬁnition , the full algorithm only consists of one loop , which in each iteration selects a random global switch Γ = ( π , ‘ ) and then calls on ParallelSuperstep to perform this switch . 4 . 3 Analysis of ParGlobalES A necessary condition for good scaling of ParGlobalES is that the number of rounds to perform a global switch is small . Note that in practice , the number of rounds depends on the scheduling and assignment of switches to processors . This is because we store the D . Allendorf , U . Meyer , M . Penschuck and H . Tran 11 dependencies in a concurrent hash table : if a switch σ depends on a switch σ 0 , but the processor assigned to σ 0 ﬁnishes writing the result before the processor assigned to σ attempts to decide its switch , then both switches can be decided in the same round , and the dependency will not aﬀect the number of rounds . Similarly , if σ and σ 0 are assigned to the same processor , the dependency will not aﬀect the number of rounds . Still , even for a worst - case scheduler , that always moves dependent switches to the next round , we can show that the expected number of rounds is small for bounded degree graphs , regular graphs , and power - law graphs with suﬃciently high degree exponent . Theorem 2 . Let R denote the number of rounds needed to perform a global switch Γ = ( π , ‘ ) on a graph G = ( V , E ) . If G has m = | E | edges and each node has at most degree d ≤ ∆ , we have R ≤ 4∆ 2 / m in expectation over π . Corollary 1 . If each node in G has at most degree d ≤ √ m , we have R ≤ 4 in expectation over π . Corollary 2 . If G is a d - regular graph , we have R ≤ 4 in expectation over π . Proof . Observe that R < k unless there exists a chain of switches σ ( 1 ) , . . . , σ ( k ) ∈ Γ , so that each switch σ ( r + 1 ) with 1 ≤ r < k depends on switch σ ( r ) and cannot be decided before round r + 1 . There are four ways that σ ( r + 1 ) can depend on σ ( r ) , either ( 1 ) σ ( r ) erases edge e a , and σ ( r + 1 ) inserts e a , or ( 2 ) σ ( r ) inserts edge e b , and σ ( r + 1 ) inserts e b , or ( 3 ) and ( 4 ) , the symmetric cases for the other two edges inserted or erased by σ ( r ) . Recall that a switch σ i ∈ Γ inserts edge e = { u , v } if the permutation π contains an edge incident with u and an edge incident with v in positions 2 i − 1 and 2 i . There are d u and d v such edges , respectively , and as only one assignment of the edges to the positions will give the necessary direction bit g i , each edge must be assigned to one speciﬁc position . Thus , the probability that switch σ i inserts edge e is at most # permutations such that σ i inserts e z } | { d u d v ( m − 2 ) ! m ! | { z } # total permutations = d u d v m ( m − 1 ) ≤ ∆ 2 m ( m − 1 ) ≤ 2∆ 2 m 2 . ( 1 ) Hence , for each switch σ i ∈ Γ , the probability that the switch with the next index σ i + 1 inserts one of the four edges , and depends on σ i , is at most 8∆ 2 / m 2 . Then , in expectation , if switch σ ( r ) has index i , σ ( r + 1 ) has index at least i + m 2 / 8∆ 2 , and since Γ contains only m / 2 switches , each chain has expected length k ≤ 4∆ 2 / m . (cid:74) The following theorem gives a sharper bound for graphs with a skewed degree sequence such as power - law graphs . Theorem 3 . Let R denote the number of rounds needed to perform a global switch Γ = ( π , ‘ ) on a graph G = ( V , E ) , let S = { { u , v } : u , v ∈ V , u 6 = v } denote the set of possible edges , and let P 2 = P e = { u , v } ∈ S ( d u d v / m ( m − 1 ) ) 2 . Then , we have R = O ( P 2 m ) in expectation over π . Proof . For each switch σ i ∈ Γ , the probability that the switch with the next index σ i + 1 inserts a speciﬁc edge e that σ i erases is X e = { u , v } ∈ S 1 e ∈ E m | { z } σ i erases e d u d v m ( m − 1 ) | { z } σ i + 1 inserts e ≤ 1 m X e = { u , v } ∈ S d u d v m ( m − 1 ) ≤ 1 m . ( 2 ) 12 Parallel Global Edge Switching for the Uniform Sampling of Graphs For an insert dependency to arise , σ i + 1 must insert a speciﬁc edge e that σ i inserts , and the probability for this event is given by X e = { u , v } ∈ S d u d v m ( m − 1 ) | { z } σ i inserts e ( d u − 1 ) ( d v − 1 ) ( m − 2 ) ( m − 3 ) | { z } σ i + 1 inserts e = O ( P 2 ) . ( 3 ) Hence , for each switch σ i ∈ Γ , the probability that the switch with the next index σ i + 1 depends on σ i is at most 2 / m + O ( P 2 ) , and as Γ contains m / 2 switches , each dependency chain has expected length O ( P 2 m ) . (cid:74) Lemma 1 . If G is a power - law graph with degree exponent γ > 2 , we have P 2 = O (cid:16) 1 / n + n ( 2 + γ − γ 2 ) / ( γ − 1 ) (cid:17) . Corollary 3 . If G is a power - law graph with degree exponent γ > 1 + √ 2 , we have R = O ( 1 ) in expectation over π . Proof . We will use known properties of power - law graphs to ﬁnd a suitable upper bound on P 2 . Recall that if G is a power - law graph with degree exponent γ > 2 , then G has N d = O ( nd − γ ) nodes with degree d and maximum degree ∆ = O (cid:0) n 1 / ( γ − 1 ) (cid:1) . Rewriting the expression for P 2 as a sum over degree groups yields P 2 = ∆ X i = 1 N i ∆ X j = 1 N j (cid:18) ij m ( m − 1 ) (cid:19) 2 ( 4 ) ≤ ∆ X i = 1 N i ∆ X j = 1 N j i 2 j 2 n 4 ( 5 ) = O   ∆ X i = 1 1 i γ ∆ X j = 1 1 j γ i 2 j 2 n 2   . ( 6 ) Observe that the terms in P 2 where ij < n sum to at most O ( 1 / n ) . For each of the remaining terms , we have ij ≥ n , so we may write their sum as ∆ X i = 1 1 i γ ∆ X j = b ni c 1 j γ i 2 j 2 n 2 . ( 7 ) Now , using j γ > j 2 , and substituting b ni c for j , we see that i γ / n γ is an upper bound on each term of the inner sum over j , and obtain ∆ X i = 1 1 i γ ∆ X j = b ni c 1 j γ i 2 j 2 n 2 ≤ ∆ X i = 1 1 i γ ∆ X j = b ni c i γ n γ ≤ ∆ 2 n γ = O (cid:16) n ( 2 + γ − γ 2 ) / ( γ − 1 ) (cid:17) . ( 8 ) (cid:74) 5 Implementation In this section , we describe the implementation of our sequential and parallel algorithms and the data structures used therein . In addition to the ParGlobalES algorithm described in Section 4 , we implement the following sequential and parallel algorithms . D . Allendorf , U . Meyer , M . Penschuck and H . Tran 13 SeqES : a fast sequential implementation of ES - MC . SeqGlobalES : a sequential implementation of G - ES - MC . NaiveParES : a simplistic parallelization of ES - MC . All algorithms ( including previously existing ones ) are implemented in C + + . 5 . 1 NaiveParES To establish a performance baseline for parallel algorithms , we implement NaiveParES , a simplistic parallelization of ES - MC . Each PU ( processing unit ) performs switches independently while synchronizing implicitly only by preventing concurrent updates of individual edges . To ensure that no edge is erased or inserted twice , we store the edges in a concurrent hash - set using the following semantics : to remove an edge from the set , a ticket has to be acquired ﬁrst ; this can be done by locking an existing edge or by inserting - and - locking a new edge . These operations are implemented using a compare - and - exchange primitive . Concurrent updates to the same edge are sequenced by the hardware . Note that this implementation performs all edge switches that are legal after synchroniza - tion but ignores dependencies between edge switches . In contrast to the exact parallelizations ParES and ParGlobalES , it can thereby deviate from the intended Markov Chain . 5 . 2 Graph and dependency representation Most ES - MC implementations use an adjacency list to store the graph and manipulate it with each switching [ 40 , 51 – 54 ] 4 . This design choice often leads to an easy integration with other algorithms . However , ES - MC requires a graph representation that eﬃciently supports edge insertion , deletion , and existence queries . Unfortunately , an adjacency list cannot support updates and search both in constant time ( cf . the hybrid data structure of [ 54 ] ) . In contrast , hash - sets support all required operations in expected constant time . To this end we ﬁrst identify each possible edge with a unique integer . For instance , if nodes u , v ∈ V are stored as 32 - bit integers , then each possible edge { u , v } ∈ E can be identiﬁed by the 64 - bit integer where the ﬁrst 32 - bits are set equal to the smaller node u < v and the remaining 32 - bits are set equal to the larger node v > u ( recall that we disallow loops ) . To store a graph in a hash set we insert for each edge its unique identiﬁer . Checking if an edge is contained in the graph is possible by checking if its identiﬁer is contained in the hash - set . When performing a legal edge switch , we delete both identiﬁers of the source edges and then insert both identiﬁers of the target edges . From a practical point of view , we require a hash - set implementation that can handle a roughly balanced mix of insertions , deletions , and search queries . After preliminary experiments on various graphs , machines , and hash - set implementations 5 , we ﬁnd that in most cases RobinMap with a maximum load - factor of 1 / 2 is the fastest sequential solution . Observe that for performance reasons , all our implementations use hash - tables where the number of buckets is a power - of - two ; hence the actual load - factor can be lower . Our hash 4 [ 40 ] use a reduced adjacency matrix that only stores one directed edge . [ 53 ] use a diﬀerent MC with the same switchings . [ 54 ] interleave ES - MC with connectivity checks after each edge switching . They use an adjacency list where high - degree nodes store their neighborhoods in individual hash tables . 5 We considered the following hash - sets : https : / / gcc . gnu . org / , https : / / github . com / { Tessil / robin - map , Tessil / hopscotch - map , sparsehash / sparsehash } . 14 Parallel Global Edge Switching for the Uniform Sampling of Graphs function uses the 64bit variant of the crc32 instruction available on x64 processes with SSE 4 . 2 [ 55 ] . Our parallel algorithms require concurrent hash - tables with stable iterators ( i . e . , once an element is placed into a bucket , it is not moved until it gets erased ) . It is folklore that such a data structure can be eﬃciently implemented with open addressing and lock - free compare - and - swap instructions ( cf . [ 56 ] ) . We implement the locking of edges as follows : each edge is kept in an 64bit - wide bucket , where 56 bits are used to store the edge and 8 bit are reserved for locking . To acquire a lock , a PU tries to compare - and - swap its thread id into the lock bits and succeeds only if the bucket previously kept the edge in an unlocked state . This implementations allows us to process graphs with up - to n ≤ 2 28 nodes on P < 256 threads . Observe that these restrictions can be lifted quite easily , as virtually all relevant processors support 128bit compare - and - swap instructions with only moderate performance penalties . 5 . 3 Sampling edges Pseudo - random bits are generated using the MT19937 - 64 variant of the Mersenne Twister [ 57 ] implemented by libstdc + + and translated into unbiased random integers using [ 58 ] . Random permutations are sampled in parallel with an optimized implementation inspired by [ 58 , 59 ] . To sample edges uniformly at random we consider two options : Firstly , we maintain an auxiliary array of edges . In order to sample an edge uniformly at random , we read from a random index — this closely resembles the way we introduced edge switching in the previous chapters . Secondly , the use of open - addressing hash - tables allows us to directly sample from the hash - set by repeatedly drawing random buckets until we hit the ﬁrst non - empty one . While the second option avoids additional memory , it leads to a time trade - oﬀ : while all queries discussed in Section 5 . 2 beneﬁt from a low load - factor L , the sampling time is geometrically distributed with a success probability of L . It , thus , favors a high load - factor . In preliminary experiments , we found that decreasing the load factor to allow faster queries and sampling using an additional array yields up - to 30 % faster overall performance compared to balancing the load factor for both queries and sampling . 5 . 4 Prefetching The rewiring of random edges inherently leads to unstructured accesses to main memory , especially if the graph is represented in a hash set . While [ 44 ] propose an I / O - eﬃcient edge switching implementation for graphs exceeding main memory , their solution requires to repeatedly sort the edge list ( and other data structures ) . In the context of a parallel algorithm , this sorting step alone is more expensive than a global switch using unstructured accesses . We therefore accept the random I / Os and accelerate them using prefetching instructions . To this end , we split all insertion , deletion , and search queries to our hash - sets into two : in a ﬁrst step , we hash the key and identify the bucket in which the item is placed if there is no collision . We then prefetch this bucket as well as its direct successor , and return precomputed values that are required when we carry out the actual operation in a second step . Since we use linear probing hash - sets with a low load factor and a prefetch in advance , we eﬀectively eliminate almost all cache misses if there is suﬃcient time between both steps . To increase this time window , we use a pipeline of four edge switches in diﬀerent progress stages . D . Allendorf , U . Meyer , M . Penschuck and H . Tran 15 2 0 2 − 6 n = 2 7 γ = 2 . 01 G - ES - MC ES - MC γ = 2 . 1 γ = 2 . 2 γ = 2 . 5 2 0 2 − 6 n = 2 10 1 10 100 2 0 2 − 6 n = 2 13 1 10 50 1 10 1 10 supersteps Figure 2 Fraction of non - independent edges as a function of the thinning value k as a multiple of the supersteps for the SynPld dataset where ( n , γ ) ∈ { 2 7 , 2 10 , 2 13 } × { 2 . 01 , 2 . 1 , 2 . 2 , 2 . 5 } . Each data point is represented by its mean value µ ( line ) and its 2 σ error ( shade ) . 6 Experiments In the following , we empirically investigate the mixing times of the Markov Chains and the runtime performances of their derived algorithms . The performance benchmarks are built with GNU g + + - 9 . 3 and executed on a machine equipped with an AMD EPYC 7702P 64 - core processor running Ubuntu 20 . 04 . Our experiments are performed on the following datasets : ( SynGnp ) — We generate G ( n , p ) graphs [ 60 ] ( each edge exists independently with probability p ) for varying node counts n and p . ( SynPld ) — For varying node counts n and degree exponents γ , we generate power - law degree sequences according to the degree distribution Pld ( [ 1 . . ∆ ] , γ ) where the maximum degree is set to ∆ = n 1 / ( γ − 1 ) matching the analytic bound [ 61 ] . Thereafter , the generated sequences are materialized by the Havel - Hakimi algorithm [ 8 , 9 ] . Both steps are performed using NetworKit [ 51 ] . ( NetRep ) — We consider graphs from the network repository [ 62 ] where we exclude the unsuitable categories dimacs , dimacs10 , graph500 ( benchmark graphs ) , dynamic , misc ( unclassiﬁed graphs ) , rand ( synthetic graphs ) and tscc ( temporal graphs ) . To ensure that the graphs are simple and undirected , we perform the following modiﬁcations : all directed edges ( u , v ) are replaced by the undirected edges { u , v } , and self - loops and multi - edges are removed . 6 . 1 Empirical Mixing Time of ES - MC and G - ES - MC Here , we compare the mixing times of ES - MC and the novel G - ES - MC . While we argue in Section 3 that the lack of source dependencies of G - ES - MC improves parallelizability over ES - MC , it is a priori unclear whether this restriction aﬀects the randomization quality of the Markov Chain . In practice , the mixing time is approximated by empirical proxies or estimated by data driven methods [ 63 , 64 ] . The former measures the convergence to the stationary distribution 16 Parallel Global Edge Switching for the Uniform Sampling of Graphs 10 0 10 1 p = 0 . 01 10 3 10 4 10 5 10 6 edges 10 0 10 1 p = 0 . 001 10 0 10 − 1 10 − 2 10 − 3 10 − 4 10 − 5 density G - ES - MC ES - MC ﬁrst superstep with non - independence rate p Figure 3 Scatterplots the NetRep dataset where the x - coordinate either denotes the number of edges m ( left ) or the density m / (cid:0) n 2 (cid:1) ( right ) of a graph with n nodes and m edges . The y - coordinate represents the ﬁrst superstep k at which the mean fraction of non - independent edges drops below either 1 × 10 − 2 ( top ) or 1 × 10 − 3 ( bottom ) . We do not use large primes and numbers with many divisors as thinning values . This yields an uneven ( but inconsequential ) quantization of the y - axis . The outlier that merely requires k = 1 supersteps for both Markov Chains possesses only two unique node degrees . by convergence of its proxy or by some aggregated value . In doing so , the Markov Chain is reﬂected by a projection which may converge faster [ 65 ] . The result depends on the proxy and might be insuﬃcient for other more sensitive proxies . Additionally , it has been observed that common measures , e . g . assortativity coeﬃcients , clustering coeﬃcients , diameter , maximum eigenvalue and triangle count , are less sensitive than data - driven methods [ 44 , 64 ] . Thus , we consider the autocorrelation analysis , an approximate non - parametric method [ 64 ] . The autocorrelation analysis proceeds in two steps . First , execute the Markov Chain for a large number of steps K , and for each possible edge e track in a binary time - series { Z t } whether edge e exists at time t . By its own , { Z t } and its transitions will be correlated [ 63 ] which naturally indicates that a single Markov Chain step is insuﬃcient . Consider now the k - thinned chain { Z kt } which retains every k - th entry of { Z t } . The k - thinned chain will have smaller autocorrelation and begin to resemble independent draws from a distribution for suﬃciently large k . At some point , the thinned time - series should resemble an independent process more than a ﬁrst - order Markov process . To determine which of the models is a better ﬁt , the Bayesian Information Criterion ( BIC ) is computed using the G 2 - statistic [ 66 ] ( see [ 64 ] for details ) . Thus , in a second step , the time - series { Z t } is progressively thinned to determine independent edges for the thinned time - series { Z k t } for increasing values of k . For our purposes , instead of ﬁrst computing the whole time - series { Z t } and then consid - ering increasing thinning values in a post - processing step , we deﬁne a ﬁxed set of thinning values T and aggregate relevant entries of { Z t } on - the - ﬂy for each k ∈ T . While this approach is far less memory - consuming , we cannot recover for each edge the earliest point of time it would have been deemed independent . Instead , for a thinning value k , we report the fraction of edges that would be deemed independent irrespective of a smaller thinning value k 0 < k . In this context , we compare ES - MC and G - ES - MC . In order to visually align the results we deﬁne a superstep for both Markov Chains . To this end , let m / 2 uniform random edge switches and one uniform random global switch be a designated superstep for ES - MC and D . Allendorf , U . Meyer , M . Penschuck and H . Tran 17 G - ES - MC , respectively . This accounts for the fact that one global switch potentially executes m / 2 ( non - uniform ) edge switches . We ﬁrst consider SynPld and generate for each ( n , γ ) ∈ { 2 7 , 2 10 , 2 13 } × { 2 . 01 , 2 . 1 , 2 . 2 , 2 . 5 } forty power - law graphs ( we limit the largest node count to n = 2 13 since the longest individual run already took 18 hours using an Intel Skylake Gold 6148 processor ) . In Figure 2 we report the mean fraction of non - independent edges depending on the number of supersteps for a subset of the node counts and degree exponents . For highly skewed degree sequences , e . g . γ = 2 . 01 , the G - ES - MC performs slightly better than the ES - MC for small supersteps . Increasing the number of supersteps results in matching performances for both . For larger degree exponents γ ≥ 2 . 2 G - ES - MC consistently outperforms ES - MC where the advantage increases with γ . We observe both features for up to two orders of magnitude , and we expect this to hold for even larger values of n . Next we investigate real - world graphs of the NetRep dataset . Due to the high compu - tational cost , we restrict ourselves to graphs with 1000 ≤ m ≤ 800 000 edges . To further reduce the cost , we perform the autocorrelation analysis only for the edges of the initial graph , reducing the memory footprint of each thinning to Θ ( m ) where m is the number of edges . In Figure 3 we present for each graph the ﬁrst reported superstep at which the mean fraction of non - independent edges of at least 15 runs is below a threshold τ . For τ = 1 × 10 − 2 , G - ES - MC seems to consistently outperform ES - MC except for very dense graphs where the performance is similar . The τ = 1 × 10 − 3 is reached by only 46 % of the 594 instances within 30 supersteps . Here , G - ES - MC still outperforms ES - MC on most instances except for moderately dense graphs on which both chains converge signiﬁcantly slower . 6 . 2 Performance Benchmarks In this section , we benchmark our ES - MC and G - ES - MC implementations . In each experiment , we run a subset of the implementations on the same initial graph and measure the average time required to initialize the data structures and perform 20 supersteps ( e . g . 10 switches per edge ) . In practice , common choices [ 24 , 38 , 39 ] are 10 to 30 switches per edge . As G - ES - MC typically requires fewer supersteps ( compare Section 6 . 1 ) , this gives a slight advantage to ES - MC over the G - ES - MC implementations . 6 . 2 . 1 Runtime We compare existing sequential implementations to our solutions and report absolute runtimes . To this end , we benchmark all implementations on a sample of graphs from NetRep and report their runtimes in Table 4 . We select the graphs in this sample to cover a variety of sizes , average degrees and maximum degrees . As some of the networks are quite large , we set a timeout of 1000 seconds . We ﬁrst compare SeqES and SeqGlobalES , our sequential ES - MC and G - ES - MC solutions , with existing implementations from NetworKit [ 51 ] and Gengraph [ 31 ] . Our solutions run 15 - 50 times faster than NetworKit and 5 - 10 times faster than Gengraph . We also observe that SeqGlobalES is faster than SeqES on large graphs , where shuﬄing is more eﬃcient than sampling the edges , whereas SeqES runs faster on small graphs . In conclusion , our sequential implementations provide a meaningful baseline to measure further speed - ups . Next , we report the runtimes of the parallel algorithms . For P = 32 PUs , all parallel implementations run much faster than the sequential implementations . On the largest graph , only the parallel implementations were able to perform 20 supersteps before the 18 Parallel Global Edge Switching for the Uniform Sampling of Graphs Figure 4 Runtimes in seconds on a sample of graphs from NetRep sorted by network size . The left columns lists the graph , number of nodes n , number of edges m and maximum degree d max . The center columns list the sequential and parallel implementations for P = 1 PU . The right columns list the parallel implementations for P = 32 PUs . The best time in each group is indicated by the bold font . A dash ( — ) indicates a runtime of more than 1000 sec . for 20 supersteps . N e t w o r K i t G e n g r a ph S e q E S S e q G l o b a l E S N a i v e P a r E S P a r G l o b a l E S N a i v e P a r E S P a r G l o b a l E S Graph n m d max P = 1 P = 32 soc - twitter - mpi - sws 41 M 1 . 2 B 2 . 9 M — — — — — — 251 397 bn - human - Jung2015 1 . 8 M 146 M 8 . 7 K — — 517 460 448 784 20 . 0 36 . 7 tech - p2p 5 . 7 M 140 M 675 K — — 530 464 477 788 21 . 3 37 . 2 socfb - konect 59 M 92 M 4 . 9 K — — 287 253 228 459 11 . 9 21 . 7 ca - holywood2009 1 M 56 M 11 K — 686 140 112 116 244 8 . 1 11 . 4 inf - road - usa 23 M 28 M 9 619 186 49 . 2 41 . 4 53 . 6 97 . 0 5 . 2 5 . 1 bio - human - gene1 220 K 12 M 7 . 9 K 512 109 12 . 3 12 . 5 18 . 1 32 . 0 1 . 3 2 . 0 web - wikipedia2009 1 . 8 M 4 . 5 M 2 . 6 K 65 . 4 36 . 5 4 . 7 4 . 9 6 . 6 9 . 7 0 . 58 0 . 95 cit - HepTh 22 K 2 . 4 M 8 . 7 K 45 . 0 20 . 4 2 . 2 2 . 3 3 . 4 5 . 3 0 . 25 0 . 47 email - enron - large 33 K 180 K 1 . 3 K 0 . 92 0 . 44 0 . 12 0 . 14 0 . 21 0 . 37 0 . 06 0 . 07 rec - amazon 91 K 120 K 5 0 . 57 0 . 16 0 . 10 0 . 11 0 . 18 0 . 17 0 . 06 0 . 05 timeout . Here , ParGlobalES is up to 12 times faster than SeqGlobalES . On all graphs , ParGlobalES only shows a slowdown of at most 2 compared to the baseline algorithm NaiveParES . In this context , it is important to recall that NaiveParES is not an exact parallelization since it ignores dependencies between edge switches . In Figure 5 , we evaluate SeqES , SeqGlobalES and ParGlobalES on all graphs from NetRep with at least m = 10 4 edges . For each graph , we run SeqES and SeqGlobalES on one PU and ParGlobalES on P = 32 PUs and report the absolute runtimes and the speed - up of ParGlobalES over SeqGlobalES . On all graphs with m > 10 5 , the parallel algorithm is faster than the sequential algorithms and the observed speed - up increases with the size of the graph . 6 . 2 . 2 Scaling We ﬁrst report the self speed - up of ParGlobalES on the sample of graphs from NetRep in dependence of P ( Figure 6 ) . For larger graphs , the maximum speed - up ranges between 20 and 30 using 32 to 64 PUs . On the two smallest graphs , the work is likely too small to be eﬃciently parallelized ( e . g . compare Figure 4 ) . An outlier is the largest graph ( soc - twitter - mpi - sws ) ; a likely explanation for the slightly low speed - up on this graph is that the highly skewed degree sequence increases the number of target dependencies and the synchronization overhead . To measure the inﬂuence of the graph properties on the runtime , we consider synthetic graphs . We ﬁrst consider graphs from SynGnp for various n and p , and plot the runtime as a function of the average degree d = 2 m / n in Figure 7 . The edge probability p seems to have no signiﬁcant eﬀect on the runtime , even in the case where the average degree approaches the possible maximum n − 1 ( bottom - right in the plot ) . This is a consequence of Theorem 2 . As D . Allendorf , U . Meyer , M . Penschuck and H . Tran 19 10 4 10 5 10 6 10 7 10 8 10 9 10 2 10 1 10 0 10 1 10 2 10 3 r un t i m e ( s e c ond s ) SeqES SeqGlobalES ParGlobalES 10 4 10 5 10 6 10 7 10 8 10 9 10 2 10 1 10 0 10 1 10 2 10 3 10 4 10 5 10 6 10 7 10 8 10 9 edges 2 4 6 8 10 12 s peed - up ParGlobalES SeqGlobalES 10 4 10 5 10 6 10 7 10 8 10 9 edges 2 4 6 8 10 12 Figure 5 Scatterplot showing runtimes and speed - ups on NetRep . Top row : runtimes of SeqES and SeqGlobalES on P = 1 PU and ParGlobalES on P = 32 PUs . The color and symbol indicates the algorithm . Bottom row : speed - ups of ParGlobalES over SeqGlobalES . The height of the red dashed line corresponds to a speed - up of 1 . Left column : without prefetching . Right column : with prefetching . 2 8 14 20 26 32 38 44 50 56 62 number of PUs 2 6 10 14 18 22 26 30 s e l f s peed - up soc - twitter - mpi - sws bn - human - Jung2015 tech - p2p socfb - konect inf - road - usa ca - hollywood - 2009 bio - human - gene1 web - wikipedia2009 cit - HepTh email - enron - large rec - amazon Figure 6 Strong scaling of ParGlobalES on a sample of graphs from NetRep for 1 ≤ P ≤ 64 . The line colors indicate the graph and are sorted by graph size . G ( n , p ) graphs are suﬃciently close to regular with high probability , the number of rounds required to perform a global switch is constant regardless of p . Next , we consider power - law graphs from SynPld with degree exponent 3 ≥ γ ≥ 2 . 01 to evaluate the inﬂuence of the degree distribution’s skewness . Note that increasing γ increases 20 Parallel Global Edge Switching for the Uniform Sampling of Graphs 10 1 10 2 10 3 10 4 average degree 10 1 10 0 10 1 10 2 r un t i m e ( s e c ond s ) edges m = 2 28 m = 2 26 m = 2 24 m = 2 22 m = 2 20 m = 2 18 PUs = 64 = 32 Figure 7 Runtime of ParGlobalES on graphs from SynGnp where m ∈ { 2 18 , 2 20 , 2 22 , 2 24 , 2 26 } in dependence of the average degree d = 2 m / n . The color indicates the number of edges and the line style the number of PUs . 2 . 0 2 . 2 2 . 4 2 . 6 2 . 8 3 . 0 degree exponent 1 . 50 1 . 75 2 . 00 2 . 25 2 . 50 2 . 75 r un t i m e ( s e c ond s ) / m 1e 7 nodes n = 2 28 n = 2 26 n = 2 24 PUs = 64 = 32 Figure 8 Runtime per edge of ParGlobalES on graphs from SynPld where n ∈ { 2 24 , 2 26 , 2 28 } in dependence of the degree exponent γ . The color indicates the number of nodes and the line style the number of PUs . the number of edges even when ﬁxing n , therefore we normalize the runtime by dividing by the number of edges . We report the runtime per edge as a function of γ in Figure 8 . We observe an eﬀect both in n and γ . For n ≥ 2 26 , the runtime on 64 PUs increases slightly as γ approaches 2 . This matches the analysis given for Theorem 3 : for graphs with a highly skewed degree sequence , most edge switches will attempt to create the same few edges , causing many target dependencies and more synchronization overhead . 6 . 2 . 3 Rounds per Global Switch Recall that ParGlobalES may delay edge switches to resolve target dependencies . It does so by executing several rounds . To study the performance impact , we execute 20 global switches per graph of NetRep using P = 32 PUs and record the number of rounds per global switch , and the time accumulated on all rounds excluding the ﬁrst one . As reported in Figure 9 , the average number of rounds is low with a mean of 2 . 2 , and the maximum number of rounds we observed was 8 . For all networks with more than 4M edges the ﬁrst round also accounts for more than 99 % of the runtime . This suggests that even in a case where more rounds are required , the performance impact of the following rounds is negligible D . Allendorf , U . Meyer , M . Penschuck and H . Tran 21 10 4 10 5 10 6 10 7 10 8 10 9 number of edges 1 2 3 4 5 6 a v e r a g e r o u n d s p e r g l o b a l s w i t c h rounds per global switch ( left ) fraction of runtime ( right ) 10 − 4 10 − 3 10 − 2 10 − 1 10 0 1 − r u n t i m e o f ﬁ r s t r o u n d r u n t i m e o f a ll r o u n d s Figure 9 Rounds per global switch performed by ParGlobalES on NetRep . Each orange cross corresponds the average number of rounds recorded for a graph ; the blue dots indicate the fractional runtime of all rounds excluding the ﬁrst one . for suﬃciently large graphs . 7 Conclusions We propose G - ES - MC as an ES - MC variant that exhibits more parallelism due to the absence of source dependencies . In addition , we propose ParES and ParGlobalES as exact parallelizations of ES - MC and G - ES - MC . These algorithms avoid possible deviations from the intended random process by accounting for the complex dependencies between edge switches . To the best of our knowledge , they are the ﬁrst exact parallelizations of switch Markov Chains for the uniform sampling of simple undirected graphs . An autocorrelation analysis suggests that G - ES - MC typically requires fewer steps than standard ES - MC to randomize a graph . On P = 32 PUs , our parallel algorithm executes 10 − 12 times faster than our sequential G - ES - MC implementation , and 50 − 100 faster than existing ES - MC implementations . We investigate the number of rounds needed for ParGlobalES to perform a global switch and ﬁnd that very few rounds are required in practice . The experiments on the inﬂuence of graph properties match the theoretical predictions . For regular graphs , the performance is not aﬀected by the density of the graph . For power - law graphs with very small degree exponents γ < 2 . 2 , there is a slight slowdown , due to the increased number of target dependencies . However , in our experiment on over 600 real graphs , this occurs for only very few outliers . We expect that dedicated base cases for small graphs can further reduce the overhead due to the synchronization and concurrent data structures and thereby improve the scaling on such graphs . We are also still interested in analyzing if G - ES - MC is rapidly mixing for any class of undirected graphs . While we expect lower speed - ups than for ParGlobalES , an alternative could be to investigate the scalability of ParES since this algorithm inherits the rapid mixing property of ES - MC . 22 Parallel Global Edge Switching for the Uniform Sampling of Graphs Acknowledgments Extensive calculations on the Goethe - HLR high - performance computer of the Goethe Uni - versity Frankfurt were conducted for this research . The authors would like to acknowledge the CSC team for their support . References 1 Paolo Boldi and Sebastiano Vigna . Axioms for centrality . Internet Math . , 2014 . 2 Albert - László Barabási and Márton Pósfai . Network science . 2016 . 3 G . W . Cobb and Y . - P . Chen . An application of Markov Chain Monte Carlo to community ecology . American Math . Monthly , 110 , 2003 . 4 S . Itzkovitz , R . Milo , N . Kashtan , G . Ziv , and U . Alon . Subgraphs in random networks . Phys . Rev . E , 68 , 2003 . 5 Wolfgang Eugen Schlauch and Katharina Anna Zweig . Inﬂuence of the null - model on motif detection . In ASONAM , 2015 . 6 C . J . Carstens . Topology of Complex Networks : Models and Analysis . PhD thesis , RMIT University , 2016 . 7 Manuel Penschuck , Ulrik Brandes , Michael Hamann , Sebastian Lamm , Ulrich Meyer , Ilya Safro , Peter Sanders , and Christian Schulz . Recent advances in scalable network generation . CoRR , abs / 2003 . 00736 , 2020 . 8 Václav Havel . Poznámka o existenci konečných grafů . Časopis pro pěstování matematiky , 080 , 1955 . 9 Seifollah L . Hakimi . On realizability of a set of integers as degrees of the vertices of a linear graph . i . J . SIAM , 10 , 1962 . 10 Joseph K . Blitzstein and Persi Diaconis . A sequential importance sampling algorithm for generating random graphs with prescribed degrees . Internet Math . , 6 , 2011 . 11 Md Hasanuzzaman Bhuiyan , Maleq Khan , and Madhav Marathe . A parallel algorithm for generating a random graph with a prescribed degree sequence . In IEEE BigData , 2017 . 12 F . Chung and L . Lu . Connected components in random graphs with given expected degree sequences . A . of Comb . , 6 , 2002 . 13 Sebastián Moreno , Joseph J . Pfeiﬀer III , and Jennifer Neville . Scalable and exact sampling method for probabilistic generative graph models . Data Min . Knowl . Discov . , 32 , 2018 . 14 E . A . Bender and E . R . Canﬁeld . The asymptotic number of labeled graphs with given degree sequences . J . of Comb . Theo . A , 1978 . 15 A . Békéssy , P . Békéssy , and J . Komlós . Asymptotic enumeration of regular matrices . Stud . Sci . Math . Hungar . , 7 , 1972 . 16 M . E . J . Newman . Networks : An Introduction . 2010 . 17 B . Bollobás . Random graphs . 1985 . 18 B . Bollobás . A probabilistic proof of an asymptotic formula for the number of labelled regular graphs . Eur . J . Comb . , 1 , 1980 . 19 B . D . McKay and N . C . Wormald . Uniform generation of random regular graphs of moderate degree . J . Algorithms , 11 , 1990 . 20 P . Gao and N . C . Wormald . Uniform generation of random regular graphs . In FOCS , 2015 . 21 A . Arman , P . Gao , and N . C . Wormald . Fast uniform generation of random graphs with given degree sequences . In FOCS , 2019 . 22 M . Jerrum and A . Sinclair . Fast uniform generation of regular graphs . TCS , 73 , 1990 . 23 C . Cooper , M . E . Dyer , and C . S . Greenhill . Sampling regular graphs and a peer - to - peer network . Comb . Probab . Comput . , 2007 . 24 Christos Gkantsidis , Milena Mihail , and Ellen W . Zegura . The Markov Chain simulation method for generating connected power law random graphs . In ALENEX , 2003 . 25 C . S . Greenhill . The switch Markov Chain for sampling irregular graphs . In SODA , 2015 . D . Allendorf , U . Meyer , M . Penschuck and H . Tran 23 26 R . Kannan , P . Tetali , and S . S . Vempala . Simple Markov Chain algorithms for generating bipartite graphs and tournaments . RSA , 1999 . 27 P . Mahadevan , D . V . Krioukov , K . R . Fall , and V . Vahdat . Systematic topology analysis and generation using degree correlations . In SIGCOMM , 2006 . 28 I . Stanton and A . Pinar . Sampling graphs with a prescribed joint degree distribution using Markov Chains . In ALENEX , 2011 . 29 G . Strona , D . Nappo , F . Boccacci , S . Fattorini , and J . San - Miguel - Ayanz . A fast and unbiased procedure to randomize ecological binary matrices with ﬁxed row and column totals . Nature comm . , 2014 . 30 N . D . Verhelst . An eﬃcient MCMC algorithm to sample binary matrices with ﬁxed marginals . Psychometrika , 73 , 2008 . 31 F . Viger and M . Latapy . Eﬃcient and simple generation of random simple connected graphs with prescribed degree sequence . J . Complex Networks , 4 , 2016 . 32 Péter L . Erdős , Sándor Z . Kiss , István Miklós , and Lajos Soukup . Approximate counting of graphical realizations . PLOS ONE , 10 , 2015 . 33 Catherine S . Greenhill and Matteo Sfragara . The switch Markov Chain for sampling irregular graphs and digraphs . TCS , 719 , 2018 . 34 Péter L . Erdős , Catherine Greenhill , Tamás Róbert Mezei , István Miklós , Dániel Soltész , and Lajos Soukup . The mixing time of switch markov chains : A uniﬁed approach . Eur . J . Comb . , 99 , 2022 . 35 Georgios Amanatidis and Pieter Kleer . Rapid mixing of the switch Markov Chain for strongly stable degree sequences . RSA , 57 , 2020 . 36 Pu Gao and Catherine S . Greenhill . Mixing time of the switch Markov Chain and stable degree sequences . Discret . Appl . Math . , 291 , 2021 . 37 Péter L . Erdös , Catherine S . Greenhill , Tamás Róbert Mezei , István Miklós , Daniel Soltész , and Lajos Soukup . The mixing time of switch markov chains : A uniﬁed approach . Eur . J . Comb . , 99 : 103421 , 2022 . 38 R . Milo , N . Kashtan , S . Itzkovitz , M . E . J . Newman , and U . Alon . On the uniform generation of random graphs with prescribed degree sequences . CoRR , abs / cond - mat / 0312028 , 2003 . 39 Jaideep Ray , Ali Pinar , and C . Seshadhri . Are we there yet ? when to stop a Markov Chain while generating random graphs . In WAW , volume 7323 of LNCS , 2012 . 40 Md Hasanuzzaman Bhuiyan , Maleq Khan , Jiangzhuo Chen , and Madhav V . Marathe . Parallel algorithms for switching edges in heterogeneous graphs . J . Parallel Distributed Comput . , 104 , 2017 . 41 D . Allendorf , U . Meyer , M . Penschuck , and H . Tran . Parallel global edge switching for the uniform sampling of simple graphs with prescribed degrees . In 2022 IEEE International Parallel and Distributed Processing Symposium ( IPDPS ) , pages 269 – 279 , Los Alamitos , CA , USA , jun 2022 . IEEE Computer Society . 42 C . J . Carstens , M . Hamann , U . Meyer , M . Penschuck , H . Tran , and D . Wagner . Parallel and I / O - eﬃcient randomisation of massive networks using Global Curveball trades . ESA , 2018 . 43 Santosh Pandey , Lingda Li , Adolfy Hoisie , Xiaoye S Li , and Hang Liu . C - saw : A framework for graph sampling and random walk on gpus . In SC20 : International Conference for High Performance Computing , Networking , Storage and Analysis , pages 1 – 15 . IEEE , 2020 . 44 Michael Hamann , Ulrich Meyer , Manuel Penschuck , Hung Tran , and Dorothea Wagner . I / O - eﬃcient generation of massive graphs following the LFR benchmark . ACM J . Exp . Algorithmics , 23 , 2018 . 45 Artur Czumaj and Andrzej Lingas . On truly parallel time in population protocols . CoRR , abs / 2108 . 11613 , 2021 . 46 Corrie Jacobien Carstens , Annabell Berger , and Giovanni Strona . Curveball : a new generation of sampling algorithms for graphs with ﬁxed degree sequence . CoRR , abs / 1609 . 05137 , 2016 . 47 Michael Mitzenmacher and Eli Upfal . Probability and Computing : Randomized Algorithms and Probabilistic Analysis . 2005 . 24 Parallel Global Edge Switching for the Uniform Sampling of Graphs 48 A . Ramachandra Rao , Rabindranath Jana , and Suraj Bandyopadhyay . A Markov Chain Monte Carlo method for generating random ( 0 , 1 ) - matrices with given marginals . Sankhy¯a : The Indian J . of Statistics A , 58 , 1996 . 49 Corrie Jacobien Carstens and Pieter Kleer . Speeding up switch Markov Chains for sampling bipartite graphs with given degree sequence . In APPROX / RANDOM , volume 116 of LIPIcs , 2018 . 50 Catherine S . Greenhill . Generating graphs randomly . In Konrad K . Dabrowski , Maximilien Gadouleau , Nicholas Georgiou , Matthew Johnson , George B . Mertzios , and Daniël Paulusma , editors , Surveys in Combinatorics , 2021 : Invited lectures from the 28th British Combinatorial Conference , Durham , UK , July 5 - 9 , 2021 , pages 133 – 186 . Cambridge University Press , 2021 . 51 C . L . Staudt , A . Sazonovs , and H . Meyerhenke . Networkit : A tool suite for large - scale complex network analysis . Netw . Sci . , 4 , 2016 . 52 Aric A . Hagberg , Daniel A . Schult , and Pieter J . Swart . Exploring network structure , dynamics , and function using NetworkX . In SciPy , 2008 . 53 A . Lancichinetti and S . Fortunato . Benchmarks for testing community detection algorithms on directed and weighted graphs with overlapping communities . Phys . Rev . E , 80 , 2009 . 54 Fabien Viger and Matthieu Latapy . Fast generation of random connected graphs with prescribed degrees . CoRR , abs / cs / 0502085 , 2005 . 55 Intel Corporation . Intel®64 and IA - 32 Architectures — Software Developer’s Manual — Vol . 2 , 2019 . 56 Tobias Maier , Peter Sanders , and Roman Dementiev . Concurrent hash tables : Fast and general ( ? ) ! ACM Trans . Parallel Comput . , 5 ( 4 ) , 2019 . 57 Makoto Matsumoto and Takuji Nishimura . Mersenne twister : A 623 - dimensionally equidis - tributed uniform pseudo - random number generator . ACM Trans . Model . Comput . Simul . , 8 ( 1 ) , 1998 . 58 D . Lemire . Fast random integer generation in an interval . ACM Trans . Model . Comput . Simul . , 29 , 2019 . 59 P . Sanders . Random permutations on distributed , external and hierarchical memory . Inf . Process . Lett . , 67 , 1998 . 60 E . N . Gilbert . Random Graphs . Ann . Math . Stat . , 30 ( 4 ) , 1959 . 61 P . Gao and N . C . Wormald . Uniform generation of random graphs with power - law degree sequences . In SODA , 2018 . 62 R . A . Rossi and N . K . Ahmed . The network data repository with interactive graph analytics and visualization . In AAAI , 2015 . 63 Isabelle Stanton and Ali Pinar . Constructing and sampling graphs with a prescribed joint degree distribution . ACM J . Exp . Algorithmics , 17 . 64 Jaideep Ray , Ali Pinar , and C . Seshadhri . A stopping criterion for Markov Chains when generating independent random graphs . J . Complex Networks , 3 , 2015 . 65 Annabell Berger and Corrie Jacobien Carstens . Smaller universes for uniform sampling of 0 , 1 - matrices with ﬁxed row and column sums . CoRR , abs / 1803 . 02624 , 2018 . 66 Yvonne M Bishop , Stephen E Fienberg , and Paul W Holland . Discrete multivar . analysis : theo . and practice . 2007 .