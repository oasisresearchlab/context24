1 Behind the Counter : Exploring the Motivations and Barriers of Online Counterspeech Writing Kaike Ping * Computer Science , Virginia Tech , Blacksburg , Virginia , United States , pkk @ vt . edu Anisha Kumar * Computer Science , Virginia Tech , Blacksburg , Virginia , United States , anishak @ vt . edu Xiaohan Ding Computer Science , Virginia Tech , Blacksburg , Virginia , United States , xiaohan @ vt . edu Eugenia Rho # Computer Science , Virginia Tech , Blacksburg , Virginia , United States , eugenia @ vt . edu Current research mainly explores the attributes and impact of online counterspeech , leaving a gap in understanding of who engages in online counterspeech or what motivates or deters users from participating . To investigate this , we surveyed 458 English - speaking U . S . participants , analyzing key motivations and barriers underlying online counterspeech engagement . We presented each participant with three hate speech examples from a set of 900 , spanning race , gender , religion , sexual orientation , and disability , and requested counterspeech responses . Subsequent questions assessed their satisfaction , perceived difficulty , and the effectiveness of their counterspeech . Our findings show that having been a target of online hate is a key driver of frequent online counterspeech engagement . People differ in their motivations and barriers towards engaging in online counterspeech across different demographic groups . Younger individuals , women , those with higher education levels , and regular witnesses to online hate are more reluctant to engage in online counterspeech due to concerns around public exposure , retaliation , and third - party harassment . Varying motivation and barriers in counterspeech engagement also shape how individuals view their own self - authored counterspeech and the difficulty experienced writing it . Additionally , our work explores people ' s willingness to use AI technologies like ChatGPT for counterspeech writing . Through this work we introduce a multi - item scale for understanding counterspeech motivation and barriers and a more nuanced understanding of the factors shaping online counterspeech engagement . CCS CONCEPTS • Human - centered computing • Collaborative and social computing • Empirical studies in collaborative and social computing Additional Keywords and Phrases : Behavior Change , Social Media / Online Communities , Empirical study that tells us about people , Method , Qualitative Methods , Quantitative Methods , Survey 1 INTRODUCTION In today’s digital age , social media platforms serve as key spaces for public discourse [ 37 , 47 , 117 , 160 ] . While these platforms enable swift dissemination of ideas , they also serve as cultivators for hate speech [ 25 , 101 ] , cyberbullying [ 5 ] , and harassment [ 24 , 119 ] . The effectiveness of mitigating online hate through moderation by human moderators and automated systems can vary [ 57 , 61 ] . Deletion or banning users can sometimes disperse rather than dispel hateful speech [ 25 ] , or potentially conflict with First Amendment rights in the United States [ 62 ] . For example , the practice of deplatforming users for sharing hateful views can simply push offenders to less regulated online spaces [ 72 ] . While tech * These authors contributed equally to this work . # Corresponding author . 2 companies continue to combat online hate through traditional moderation methods , limitations in these approaches have led scholars to examine the potential for user - driven counterspeech [ 16 , 42 , 120 , 133 ] . Counterspeech is defined as direct responses to derogatory or harmful content , intended to undermine or refute hateful messages [ 127 , 130 ] . Since 2016 , tech companies like Meta ( Facebook ) , Google ( YouTube ) , and Twitter have partnered with NGOs around the world to foster counterspeech initiatives against online hate [ 86 , 134 ] . Such focus on user - driven counterspeech efforts highlights the significance of individual and community roles in regulating online spaces [ 136 ] . For instance , the transformation of Megan Phelps - Roper , a former member of the extremist Westboro Baptist Church , stands as a testament to the profound impact that counterspeech can have [ 26 ] . Phelps - Roper was a 23 - year - old legal assistant who regularly posted on Twitter on behalf of the Westboro Baptist Church , which is widely considered as a hate group [ 156 ] . In response to her hateful tweets against Jews , David Abitbol , a 50 - year - old Jerusalem - based web developer decided to directly engage with her on the platform . Instead of mirroring her hostility or mocking her , Abitbol responded with humor , empathy , and questions , aiming to humanize those she vilified . His constructive counter engagement not only challenged Phelps - Roper’s antisemitic views , but also led to a complete reversal of her stance [ 107 ] . What started out as a mere tweet in response to a message rooted in hatred gradually undermined and dismantled Phelps - Roper’s convictions . This specific case affirms the powerful role that counterspeech can play to enact positive change against online hate . However , successfully engaging in online counterspeech can pose various challenges for individuals . People may vary in their individual motivations and barriers that affect their decision to engage in counterspeech in the first place . Understanding the factors that drive users like Abitbol , and the barriers preventing broader participation in online counterspeech , remains a significant research gap [ 20 , 45 , 99 ] . 1 . 1 Motivation of Research Questions To date , prior research has primarily focused on understanding the content of online counterspeech [ 43 , 53 , 104 , 134 ] and its impact on the broader social media ecosystem [ 68 ] . There is a dearth of research on what motivates or deters users from participating in it . Our work fills this gap by examining how underlying motivations and barriers influence how often people engage in online counterspeech ( RQ1 ) . Demographic factors , such as age [ 79 , 124 , 155 ] , gender [ 79 , 124 , 151 ] , and race [ 61 , 63 ] are associated with how people interact online . In the context of counterspeech , research has shown that a counter - speaker’s race [ 106 ] can influence how others perceive the effectiveness of the counter - speaker’s attempt to counter a hateful post [ 106 , 137 ] . While such studies are a promising start , there remains a lack of knowledge on how broader demographic variables shape people’s willingness to engage in online counterspeech . Our work addresses this gap by comprehensively examining how demographic factors affect the likelihood of engaging in online counterspeech across a wide variety of topics ( RQ2 ) . Furthermore , how people feel about their counterspeech [ 17 ] , the difficulty experienced when writing it [ 70 ] , and their perception of its effectiveness [ 74 ] , can influence their willingness to respond to online hate . For example , users’ satisfaction with their online counterspeech increases when they feel supported by other users in their efforts to challenge hateful actors [ 17 ] . For others , the process of writing counterspeech can be daunting even with community support . Simply , the sheer difficulty in crafting a counter - message can potentially deter users’ willingness to respond to a perpetrator [ 70 ] . Similarly , the perceived effectiveness of one’s counterspeech may affect user’s willingness to engage in online counterspeech . The belief that one’s words have the power to stop or lessen the offenders ' harmful actions can motivate a proactive stance against online hate [ 74 ] . However , the perceived effectiveness of one ' s counterspeech can vary greatly among individuals , with a multitude of factors influencing their belief in its impact . A 3 myriad of variables may shape why people may be satisfied with their counterspeech , why they find it difficult to write one , and whether they believe it to be effective in mitigating online hate . In this work , we examine these factors , specifically , how motivations and barriers influence users’ experience in responding to hateful posts , namely their perceived satisfaction with their counterspeech , the level of difficulty they experience in writing it , and their perception of its effectiveness ( RQ3 ) . Social media platforms are increasingly adopting artificial intelligence ( AI ) technologies , like large language models ( LLMs ) , to foster more respectful online interactions [ 118 ] . Platforms such as Nextdoor and Quora are now using AI to prompt users to revise potentially provocative or policy - violating posts . For instance , Nextdoor has introduced an OpenAI - powered feature that suggests edits to users ' posts to prevent inflammatory language [ 1 , 109 ] . Although these AI tools aim to cultivate safer online discussions , it remains unclear how users view these interventions and their impact on their interaction with other users . Moreover , users ' pre - existing attitudes towards counterspeech and their reasons for engaging or avoiding confrontation with hateful actors online may affect their readiness to embrace AI assistance . By examining the factors that motivate or discourage users from using AI in counterspeech - writing , we can gain deeper understanding into AI ' s potential to support users in addressing online hate . Our study examines this relationship between individuals ' motivations to engage in counterspeech and their openness to using AI tools for such purposes ( RQ4 ) . In summary , we ask the following research questions : RQ1 . What motivations and barriers influence how often people engage in online counterspeech ? RQ2 . How do demographic variables shape people’s motivations and barriers in online counterspeech engagement ? RQ3 . How do people’s motivations and barriers in online counterspeech engagement influence : a . how satisfied they are with their counterspeech ? b . how difficult they find it to write counterspeech ? c . how they perceive the effectiveness of their counterspeech ? RQ4 . How are people’s motivations and barriers in online counterspeech engagement associated with their willingness to use AI assistance ? To answer these questions , we conducted a pre - registered survey ( N = 458 ) across English - speaking participants in the United States . Our survey examines key motivations and barriers that underlie why people do or do not engage in online counterspeech , how often they write counterspeech on social media , and their willingness to use AI to help them write counterspeech . In addition , in our survey we showed participants three randomly selected hate posts from a pool of 900 online hate speech posts across five topics : race , gender , religion , sexual orientation , and disability . Participants were asked to respond to each of the three hate posts with a counterspeech . We then asked follow - up questions to understand their perceptions and experience of writing counterspeech ( satisfaction , difficulty , and perceived effectiveness of one’s counterspeech ) in response to the hateful posts . 1 . 2 Overview of Research Findings and Contributions Our findings show a significant relationship between exposure to online hate and the likelihood of engaging in online counterspeech . Individuals who have personally encountered online hate are often prompted to use counterspeech as a means to directly confront offenders or as an emotional outlet . In contrast , those less frequently exposed to online hate are more likely to engage in counterspeech to signal inclusion to others ( RQ1 ) . Demographic factors and social media experiences significantly shape one’s motivations and barriers to engage in counterspeech ( RQ2 ) . For instance , younger 4 individuals , women , those with higher education levels , and regular witnesses to online hate report more concerns about public exposure , retaliation from the perpetrator , and additional harassment . Notably , even with these concerns , such individuals still find their self - authored counterspeech more effective and satisfying ( RQ3 ) . This is in stark contrast to those who feel more emotionally burdened when writing counterspeech or those who question their ability to write it effectively ; these respondents often find their self - authored counterspeech less satisfying , more challenging to write , and less effective . This sense of ineffectiveness is further linked to a higher likelihood of turning to AI for assistance in crafting counterspeech ( RQ4 ) . Our results differentiate between users with versus without prior experience using AI tools like ChatGPT . Users with prior experience using AI tools are more inclined to use AI assistance in writing counterspeech to signal inclusivity , but less likely to do so for self - defense . On the other hand , those new to AI tools are more open to using AI for counterspeech writing , especially if they fear retaliation from perpetrators , but this concern does not translate into using AI - mediated counterspeech writing to defend those who are close to them . We contribute to HCI research by offering a comprehensive understanding of the various factors that shape why people do or do not engage in online counterspeech . We developed and validated a multi - item measure for motivations and barriers for engaging in online counterspeech , demonstrating its significant influence on both the experience of writing counterspeech and peoples’ perceptions towards their self - authored counterspeech . These validated measures allow a structured approach for researchers to examine online counterspeech dynamics for future studies . Second , we extended the scholarly discourse on the demographic and experiential factors that motivate or deter people from engaging in online counterspeech . While prior scholarship has mostly focused on counterspeech strategy and content [ 43 , 53 , 104 , 134 ] , our work contributes to the knowledge of how social , demographic , and personal experiences impact people’s counterspeech writing experiences as well as their motivations and barriers to engage in it . By offering insights into how the motivations and barriers for engaging in counterspeech differ among various social groups , our findings can inform the development of counterspeech tools that are tailored to the needs of diverse users [ 103 ] . Finally , we contribute to the understanding of what influences people’s openness to use AI assistance for writing online counterspeech . This contribution is particularly timely as the role of AI in moderating online communities becomes increasingly prominent . Such insights can help tech companies and researchers to better envision the potential applications and limitations of AI in assisting users countering online hate . 2 RELATED WORK 2 . 1 The Role of Counterspeech in Mitigating Online Hate Speech Counterspeech operates through various mechanisms in mitigating online hate [ 22 ] . It can act as a social sanction , increasing the social cost of those who disseminate hate speech and thus discouraging its spread [ 43 , 53 , 134 ] . It can also counter harmful narratives by presenting alternative viewpoints [ 30 , 104 ] . The efficacy of counterspeech is widely debated [ 8 , 104 , 134 ] . Schieb and Preuss ( 2016 ) supports the effectiveness of counterspeech , demonstrating that it can lead to the deletion of hateful posts and even elicit apologies from hateful actors [ 134 ] . Their findings suggest that this effectiveness is amplified when counter - speakers outnumber those spreading hate speech , especially if the online community holds moderate views [ 134 ] . By contrast , Miškolci et al . ( 2018 ) raises questions about the direct impact of counterspeech , that it does not necessarily deter hateful actors from posting hateful content [ 104 ] . However , scholars note that a single counterspeech authored by one user often gains visibility among a wider online audience , thereby serving as a catalyst that inspires onlookers to initiate their own counter - responses [ 104 , 113 ] . The rhetorical style and 5 tone of counterspeech matters too . For example , counterspeech that adopts an empathetic tone has been shown to be particularly effective in leading to offenders deleting their racist and xenophobic tweets [ 62 ] . In addition to tone [ 62 , 106 , 125 , 132 ] , other counterspeech strategies include fact - sharing [ 17 , 112 ] , open denunciation [ 132 , 146 ] , and posing counter - questions [ 125 , 132 , 141 ] . While these studies contribute to the knowledge of counterspeech characteristics and their effectiveness , they often overlook the social and demographic backgrounds of those who use it . Few studies have examined how a counter - speaker ' s race and online presence might influence their impact of counterspeech [ 106 , 137 ] . For instance , Munger et al . experimented on Twitter using bots designed to appear as either black or white individuals with varying levels of online status , as indicated by their follower counts [ 106 ] . Their findings revealed that counterspeech from a high - status white male bot led to a significant reduction in the use of racist slurs by the original hate speech authors . Despite these initial insights , little is known about the motivations and barriers that influence why or how often people engage in online counterspeech . Our work seeks to fill this gap . 2 . 2 Understanding User Motivations and Barriers in Online Counterspeech Engagement The success of counterspeech as a remedy to hate speech lies in individuals ' readiness to act [ 17 , 18 ] . Yet , current research falls short in examining why people decide to engage in counterspeech or opt to stay bystanders . In comparison , bystander motivation and behavior in cyberbullying are well - researched [ 147 ] , offering valuable insights that inform this current study . Researchers highlight strong parallels between bystander reactions to cyberbullying and those faced by people encountering online hate [ 90 , 113 , 129 ] . Hate speech attacks individuals on the basis of social identifiers such as race , gender , and sexual orientation [ 65 , 81 , 135 ] . This differs 1 from cyberbullying , which is characterized by derogating or threatening individuals without necessarily disparaging their social identity [ 152 ] . Despite these differences , the challenges and barriers to countering online hate are similar to those in cyberbullying contexts [ 42 ] —both involve online users witnessing harmful or hateful behavior [ 15 ] and deciding whether to intervene [ 39 ] . Likewise , reasons that might deter an individual from defending a bullied peer—fear of exposure , retaliation , or the emotional toll—are similar to the hesitations one might feel when confronting online hate speech [ 114 ] . Hence , to develop a comprehensive and nuanced understanding of what drives or dissuades people from engaging in online counterspeech , our study synthesizes insights from prior research in bystander motivation in cyberbullying . Drawing on this body of work , we develop asset of survey variables to delve into the motivations and barriers potentially influencing online counterspeech engagement in the following section . 2 . 2 . 1 Motivations for Engaging in Online Counterspeech . M1 . Supporting Kin : Studies show that bystanders are more proactive in countering cyberbullying when they have close emotional or social ties with the victim [ 15 , 39 ] , with a similar trend seen in those countering online hate due to strong connections with friends and family [ 33 ] . M2 . Supporting Others : The motivation to support others in general , as opposed to specific groups or individuals , can be traced back to theories of social responsibility and collective efficacy [ 129 ] . Collective efficacy refers to the belief that one ' s actions can contribute to the greater good , influencing community outcomes [ 58 ] . Studies have shown that people are more likely to engage in prosocial behavior when they perceive a moral obligation toward a broader 1 While a single incident of online hate speech can result in repeated victimization of targets as utterances can have widespread reach on digital platforms , cyberbullying is generally defined to require sustained , long - term exposure on the victim [ 143 , 149 ] . 6 community [ 36 ] . In a study examining prosocial online behavior , researchers demonstrate that collective efficacy drives individuals to engage more frequently in altruistic activities [ 161 ] . Similarly , those who report feeling close to an online community are more likely to defend someone being targeted by online harassment [ 33 , 34 ] . Such findings imply that individuals may engage in counterspeech not just to protect themselves or their kin , but for others as well . M3 . Supporting Self : Engaging in counterspeech can be a deeply personal act [ 126 ] , especially when individuals feel directly targeted or harmed . However , motivations for self - defense are often nuanced . Guo and Johnson ' s study shows that users often underestimate the impact of online hate on themselves compared to its impact on others [ 60 ] . This perception could potentially influence users’ motivation to engage in counterspeech for self - defense , as they may unknowingly downplay the harm directed towards them . Research also shows that personal experiences of online harm or targeted attacks also influence individuals’ decisions to counter online hate [ 144 ] . Considering these complexities , we include " Supporting Self " as a variable for understanding motivations for counterspeech as it aims to capture the reason that might influence individuals to standup for themselves against online hate speech . M4 . Confronting Hate : The urgency to confront hateful or harmful behavior plays a critical role in motivating bystanders to intervene , both in the contexts of online hate speech [ 54 ] and cyberbullying [ 15 ] . For instance , bystanders are more likely to intervene when the bullying behavior is perceived as more severe [ 4 , 41 ] . Similarly , the likelihood of bystanders challenging online harassment directly correlates with how menacing they perceive the harassment to be [ 90 ] . Hence , we include motivation to confront hateful behavior or people as a variable for engaging in online counterspeech . M5 . Educating Ignorance : Researchers have identified ignorance as one of the many factors contributing to the spread of online hate speech , as lack of awareness can lead people to adopt a narrow - minded view of others in society [ 27 ] . Hence , various non - profit and educational organizations [ 16 ] have advocated education as a strategy to counter online hate over banning users or online censorship [ 30 , 150 ] . In line with this , Buerger et al . found that counter - speakers are often motivated to educate perpetrators of online hate as to why their message is harmful [ 18 ] . M6 . Signaling Inclusion : Willingness to engage in counterspeech can often be influenced by a desire to signal inclusion , particularly within online communities [ 54 ] . Empathy emerges as a key factor in this context : research shows that individuals with higher levels of empathy are not only more inclined to stand up against online hate speech to protect the victim [ 129 , 147 ] , but also to signal a sense of inclusion and community cohesion [ 66 , 95 , 147 ] . M7 . Issue Focus : Research shows that bystanders are more likely to intervene when the subject matter directly concerns social groups or issues that are important to them [ 113 ] . For instance , studies have found that bystanders were more willing to confront misogynist hate speech as compared to homophobic hate speech [ 113 ] . This suggests that motivation to engage in counterspeech may depend on issues or topics users are particularly passionate about . M8 . Venting Emotions : Studies show that exposure to online incivility often trigger emotion - focused coping strategies , such as venting [ 98 , 128 ] . Emotional responses , such as anger or frustration , may provoke individuals to " blow off steam " by countering the hate speech they encounter . Carlo et al . further supports this notion , indicating that emotional instability positively correlates with the adoption of emotion - focused coping strategies , which can manifest as aggressive counter responses [ 19 ] . Given these findings , we consider " Venting Emotions " as a potential motivation variable for engaging in online counterspeech . Motivation Variables ( M1 - M8 ) : In the survey , we presented the motivation variables to participants as statements M1 - M8 as shown in Table 1 . Participants were asked to indicate the extent to which each factor motivated them to write counterspeech on social media ( How much do the following factors motivate you to write a counterspeech on social media ? ) with response options ranging from 1 ( None at all ) to 5 ( A great deal ) . 7 Table 1 : Motivation Variables and Questionnaire Items No Motivation Variables Questionnaire Items M1 Supporting Kin When I feel the need to stand up for people I care about ( e . g . , family , close friends ) M2 Supporting Others When I feel the need to stand up for people in general M3 Supporting Self When I feel the need to stand up for myself M4 Confronting Hate When I want to confront a hateful person or behavior M5 Educating Ignorance When I want to educate an ignorant person M6 Signaling Inclusion To signal that I stand for inclusion M7 Issue Focus When it concerns issues or topics I care about M8 Venting Emotions When I want to blow off steam 2 . 2 . 2 Barriers to Writing Counterspeech on Social Media . B1 . Fear of Public Exposure : Fear of public exposure can play a crucial role in bystander inaction , particularly when intervening would mean revealing oneself to a larger online audience [ 15 ] . Studies on online harassment have shown that the larger the audience size , the less inclined bystanders are to take action [ 15 , 64 , 90 , 96 , 111 ] . Similarly , the public nature of online platforms may deter individuals from engaging in online counterspeech due to fear of public exposure . B2 . Fear of Perpetrator Retaliation : Similarly , fear of retaliation from a harasser can significantly influence bystander motivations [ 10 ] . A study by Balakrishnan in 2018 found that 40 % of bystanders chose not to intervene in instances of cyberbullying due to fears of retaliation [ 9 ] . B3 . Fear of Third - Party Harassment : In addition to retaliation from the perpetrator , users also frequently express concerns about harassment from third parties [ 76 , 129 ] , as confronting online hate can also influence the likelihood of becoming a target of hate speech from others [ 33 ] . This phenomenon is supported by Ernst et al . ' s 2017 study , which revealed that counterspeech in YouTube comments often attracted additional hateful remarks from third parties [ 49 ] . B4 . Time Concern : Perceived time investment can deter users from engaging in online conflicts [ 12 , 48 ] . This is reflected in commonly expressed views like " arguing on Facebook is a waste of time " [ 139 ] . Hence , it is plausible that concerns about time commitment could discourage users from engaging in online counterspeech , even if they are otherwise inclined to do so . B5 . Emotional Burden : While positive emotions like empathy have been found to increase bystander intervention in cyberbullying [ 52 , 110 ] , negative emotional burden could deter such actions [ 138 ] . Buerger ' s work on online activists highlights the emotional toll that counter - speaking can exert , especially when users voluntarily undertake these activities [ 17 ] . As a result , for some individuals the emotional cost of online counterspeech can outweigh the perceived benefits , leading to inaction . B6 . Skill Gap : According to social cognitive theory , self - efficacy plays a crucial role in bystander decisions [ 4 , 41 , 157 ] . In cyberbullying , bystanders are more likely to intervene when they feel capable and have the necessary resources to help [ 29 ] . However , bystanders are less likely to act when they think that other bystanders are more competent than themselves [ 85 ] . Likewise , users who feel less equipped to write an effective counterspeech might feel more reluctant to do so . B7 . Engagement Unqualified : Freis et al . and Rudnicki et al . , highlight that bystanders may refrain from intervening if they feel that it is not their place to interject [ 52 , 129 ] . Bystanders are also less likely to act in ambiguous situations [ 85 ] . Similarly , Piliavin et al . ’s work shows that bystanders who witness only the aftermath of a harassment are less likely to intervene than those who see the entire situation unfold , potentially due to feeling less qualified to intervene due to a lack of contextual awareness [ 121 ] . 8 B8 . Engagement Reluctance : A general reluctance to engage in social media discourse can extend to counterspeech , with some individuals more hesitant to enter challenging or confrontational online conversations [ 38 , 124 ] . B9 . Engagement Ineffective : Wong et al . ’s work shows that the perceived effectiveness of an intervention significantly influences bystanders ' willingness to intervene in cases of online harassment [ 4 , 41 , 157 ] . While online counterspeech has been demonstrated to offer support to victims and encourage further counter - responses [ 43 , 53 , 134 ] , there remains skepticism about its ability to genuinely alter the perpetrator ' s attitudes or behaviors [ 8 , 104 , 134 ] . Hence , the perception that one ' s counterspeech may be ineffective could deter one from engaging in such activities . Barrier Variables ( B1 - B9 ) : Similar to the motivation variables , we presented the barrier variables to survey participants as statements B1 - B9 ( Table 2 ) , and asked them to answer the following question : “ How much do the following factors deter you from writing a counterspeech on social media ? ” - with response options ranging from 1 ( None at all ) to 5 ( A great deal ) . Table 2 : Barrier Variables and Questionnaire Items No Barrier Variables Questionnaire Items B1 Fear of Public Exposure I fear being publicly exposed B2 Fear of Perpetrator Retaliation I’m afraid of retaliation from the perpetrator B3 Fear of Third - Party Harassment I’m afraid that I will be harassed by people ( other than the perpetrator ) B4 Time Concern I don’t want to spend time on this B5 Emotional Burden Writing a counterspeech is emotionally burdensome B6 Skill Gap I don’t know how to write an effective counterspeech B7 Engagement Unqualified I feel that it’s not my place to engage in counterspeech B8 Engagement Reluctance I don’t like to engage in social media conversations B9 Engagement Ineffective I feel that my counterspeech would not make a difference 2 . 3 The Role of Artificial Intelligence ( AI ) in Online Counterspeech Engagement The role of AI , particularly LLMs , in counterspeech research has traditionally focused on detecting hateful speech [ 28 , 54 , 68 ] , and generating [ 88 , 122 , 131 , 148 ] , or evaluating [ 40 , 51 , 78 , 162 ] counterspeech . LLMs excel at processing vast amounts of data quickly , alleviating the emotional toll on moderators and users who would otherwise have to detect , respond to , or report hateful online content manually [ 32 , 118 ] . However , these models are nonetheless limited in their capacity to discern subtle nuances [ 13 , 108 ] or cultural contexts [ 75 ] in hate speech , or distinguish between implicit and explicit forms of hate speech [ 84 , 119 ] . These constraints often lead to detection failures , resulting in false positives or negatives [ 61 ] , thus calling the need for better human - AI collaboration in mitigating online hate [ 83 , 84 ] . More recently , researchers have focused on using LLMs to generate human - like counter - responses to hate speech , using various metrics for measuring the quality of AI - generated counterspeech , such as informativeness [ 28 ] , politeness [ 131 ] , and grammatical diversity [ 162 ] . However , the complex nature of hate speech , including subjective perceptions of hate [ 100 ] highlights the need for human - AI collaboration , not only in detecting hate speech , but also responding to it [ 33 ] . Currently , there is a notable lack of research on how people perceive the role of AI assistance with online counterspeech writing . Understanding how users feel about their own counterspeech or what aspects of writing a counterspeech are difficult for them , can better inform the design of AI tools for such purposes . Our research fills this gap by exploring how people’s motivations and barriers influence their willingness to use AI assistance when writing online counterspeech . By doing so , our work aims to contribute to a more comprehensive understanding of AI’s potential role in online counterspeech engagement , and by large , in combating online hate . 9 3 METHODS We conducted a pre - registered survey 2 ( N = 458 ) across English - speaking participants in the U . S . to examine key motivations and barriers that underlie why people do or do not engage in online counterspeech , how often they write counterspeech on social media , and their willingness to use AI to help them write counterspeech . The survey showed participants three different examples of hate speech randomly selected from a topically diverse pool of 900 hateful posts and asked them to respond by writing counterspeech in response to each of the three hate posts . 3 . 1 Selecting Hateful Posts To curate a balanced and representative sample of hate speech for our survey , we sourced hateful posts from three prominent online hate datasets : the ETHOS dataset [ 105 ] , the Multi - Target Counter Narrative Dataset [ 50 ] , and the Multilingual and Multi - Aspect Hate Speech Analysis ( MLMA ) collection [ 116 ] . We randomly selected hateful posts across five commonly occurring topics from the combined corpus : gender , religion , disability , sexual orientation , and race . To avoid over or under representation of a specific topic , we balanced our dataset by manually examining all instances of hate speech posts to ensure topical relevance . This resulted in a total of 900 hateful posts across the five topics : race ( 183 ) , gender ( 183 ) , religion ( 182 ) , sexual orientation ( 182 ) , and disability ( 170 ) . 3 . 2 Survey Design and Variables The survey was designed using Qualtrics and consisted of ( a ) a consent form ( b ) relevant background information about hateful speech and counterspeech , ( c ) three hateful posts and questions pertaining to them , ( d ) questions about past online hate speech experience , frequency of writing counterspeech online , and motivations as well as barriers to writing online counterspeech , ( e ) questions about prior use of ChatGPT , perceived usefulness of ChatGPT , as well as willingness of using such AI tools to aid in counterspeech writing , and finally (  ) demographic and social media use questions . We illustrate the survey flow in Figure 1 . All survey questions are presented in the appendix . The consent form informed participants that they were being invited to a study to evaluate the efficacy of counterspeech to hateful posts on social media , as well as informing them of the potential psychological risks due to the offensive nature of hateful speech . Then , participants were provided with definitions of hateful speech , counterspeech , as well as examples of effective counterspeech . Figure 1 : Flowchart of the Survey Process Following this , participants were shown three unique hateful posts randomly selected from the set of 900 hate posts described in 3 . 1 . For each hateful post , participants were prompted with “ Imagine you are a user of an online group on 2 The survey was preregistered on Open Science Framework ( OSF ) : https : / / osf . io / rzmg3 / ? view _ only = 6b2fd3a3d42b4b25a37f014612fac18a 10 social media . Another user ( perpetrator ) in the group posted the following . Do you consider this post to be hateful ? ” If they answered Yes , participants were also asked to rate the hatefulness of each post using a four - point scale , with the question , “ How hateful do you find this post ? ” Response options ranged from ( 1 ) A little to ( 4 ) A great deal . Participants were then prompted to respond to the hateful post shown . The survey asked , “Please write a counterspeech to this post . The goal is to further reduce hateful behavior from the perpetrator . ” Participants were then asked to rate their satisfaction , perceived difficulty , and perceived effectiveness of each counterspeech they wrote using a five - point Likert scale . While prior research does not provide specific measures for these variables , given their significance in relation to our study , we developed corresponding response measures . Specifically , we asked , “ How satisfied are you with the counterspeech that you ' ve written ? ” ( satisfaction ) , “ How difficult was it to write this counterspeech ? ” , and “ How effective do you think your counterspeech would be in preventing the perpetrator from engaging in further hateful behavior ? ” with response options ranging from 1 - 5 ( extremely dissatisfied - extremely satisfied ; extremely difficulty - extremely easy ; not effective at all - extremely effective ) . Finally , participants answered questions related to motivations and barriers to writing online counterspeech , frequency of writing online counterspeech , and willingness to use ChatGPT to write counterspeech on social media . We did not ask users to use AI in writing their counterspeech in the survey . However , our study serves as an initial examination of whether users are willing to use AI for counterspeech , and the factors that shape this willingness . Table 3 lists all variables included in our survey . We asked participants ' opinions in the rest of the survey using the conventional 5 - point Likert scale , a standard in social science research [ 35 ] , except for binary response questions ( such as prior usage of ChatGPT ) and demographic inquiries . Table 3 : Survey Variables Independent Variables Control Variables Dependent Variables Barriers C1 . Demographics RQ1 B1 : Fear of public exposure Age Frequency of writing online counterspeech B2 : Fear of perpetrator retaliation Gender B3 : Fear of third - party harassment Ethnicity RQ2 B4 : Time concern Education level Satisfaction B5 : Emotional burden Sexual orientation Difficulty B6 : Skill gap Political View Effectiveness B7 : Engagement unqualified C2 . Social Media Behavior & Experience RQ3 B8 : Engagement reluctance Social media commenting frequency Willingness to use ChatGPT to write counterspeech B9 : Engagement ineffective Use of real name on social media Motivations Prior experience of online hate speech target M1 : Supporting kin Frequency of encountering online hate speech M2 : Supporting public C3 . Prior Use & Perception of ChatGPT M3 : Supporting self Prior use of ChatGPT M4 : Confronting hate Perceived usefulness of ChatGPT M5 : Educating ignorance M6 : Signaling inclusion M7 : Issue focus M8 : Venting emotions 3 . 3 Recruitment Participants were recruited via Prolific , limited to U . S . - based , English - speaking adults with approval ratings above 95 % . All participants were warned about potentially harmful content in the survey . Of the initial 536 respondents , we excluded 11 those who failed attention checks or failed to complete the survey , resulting in a final sample of 458 participants . The average survey completion time was 15 minutes with a compensation rate of $ 12 / hour . 3 . 4 Analysis RQ1 What motivations and barriers influence how often people engage in online counterspeech ? To address RQ1 , we performed a linear regression analysis to examine the factors that influence peoples’ frequency of writing counterspeech on social media . The dependent variable was participants’ self - reported frequency of writing counterspeech , which was measured on a five - point Likert scale in response to the question “ How often do you write counterspeech online ? ” The independent variables were the 9 barrier and 8 motivation variables , prior experience being a target of online hate speech , as well as control variables relating to social media behavior and experience as well as demographics . To detect multicollinearity , we also calculated the variance inflation factor ( VIF ) for each independent variable , with a VIF value greater than 5 indicating a serious multicollinearity problem [ 115 ] . RQ2 How do demographic variables shape people’s motivations and barriers in online counterspeech engagement ? To answer RQ2 , we conducted a structural equation model ( SEM ) to investigate the effects of key demographic factors and social media behavior on peoples’ motivations and barriers in engaging in online counterspeech [ 82 ] . We first performed an exploratory factor analysis ( EFA ) using principal axis factoring with oblimin rotation to group the items related to the barriers and motivators into latent variables [ 87 ] . We then conducted a confirmatory factor analysis ( CFA ) using maximum likelihood estimation to test the validity of the model derived from the EFA [ 87 ] . Finally , we performed the SEM using maximum likelihood estimation to estimate the path coefficients and test the hypotheses . We assessed the model fit using chi - square , comparative fit index ( CFI ) , root mean square error of approximation ( RMSEA ) , and standardized root mean square residual ( SRMR ) [ 73 ] . We report the standardized coefficients , standard errors , p - values , and R - squared for each endogenous variable in the model . RQ3 How do people’s motivations and barriers in online counterspeech engagement influence : ( a ) how satisfied they are with their counterspeech , ( b ) how difficult they find it to write counterspeech , and ( c ) how they perceive the effectiveness of their counterspeech ? In our study , the SEM was adapted to include both two - item and one - item variables . Following Bollen ' s ( 1989 ) guidelines [ 14 ] and Daniel ' s ( 2021 ) recommendations [ 97 ] , our model employed Diagonally Weighted Least Squares ( DWLS ) estimators , ensuring methodological soundness for two - item variables . Additionally , following the approach by Hayduk et al . ( 2012 ) [ 67 ] , we used a one - item variable , “time” , to capture its unique influence on engagement in counterspeech . The two - item and one - item approach was methodological , aiming to account for the complexity of counterspeech engagement . Using two - item and one - item variables for latent constructs is not uncommon , as Wright [ 158 , 159 ] , Blalock [ 80 ] , Duncan [ 44 ] , and Heise [ 69 ] have done so . This approach has the benefit of allowing more latent variables to be modeled , enhancing theoretical sophistication , and statistical control [ 67 ] . To address RQ3 , we used the same SEM approach as in RQ2 , but included peoples’ perceived satisfaction , difficulty , and effectiveness towards their self - written counterspeech as key dependent variables . We examined how these dependent variables were related to the barrier and motivation variables . We followed the same approach for model assessment and reporting as in RQ2 . To ensure a comprehensive analysis for RQ3 , we incorporated one - and two - item 12 latent variables such as ' time , ' to discern their unique influence on engagement with counterspeech , despite their lack of association with other variables . This approach is in line with the work of several scholars who have effectively used one to two - item variables for latent constructs , thereby enriching theoretical depth and statistical control in their studies [ 44 , 69 , 80 , 158 , 159 ] . To ensure methodological rigor in our approach , we employed Diagonally Weighted Least Squares ( DWLS ) estimators , as recommended by [ 14 , 97 ] , and conducted robustness checks for our one - item latent variable following the guidelines of [ 67 ] . RQ4 How are people’s motivations and barriers in online counterspeech engagement associated with their willingness to use AI assistance ? To address RQ4 , we conducted a linear regression model to examine the relationship between peoples’ barriers and motivations for engaging in counterspeech on social media and their willingness to use AI technology , such as ChatGPT , for this purpose . Similar to RQ1 , the independent variables consisted of the nine barriers and eight motivation items , while demographic factors as well as social media use and experience variables were used as control variables . The dependent variable was captured via a five - point Likert scale in response to the question , “ If you were writing counterspeech on social media , would you use artificial intelligence technology like ChatGPT to assist you ? ” Given that some participants had no prior use of AI technologies like ChatGPT , we conducted two subgroup analyses : one for participants with prior experience using ChatGPT ( N = 296 ) and another for those without ( N = 162 ) . For those who have used ChatGPT before , an additional control variable for perceived usefulness was included . Qualitative analysis of open responses : Finally , to answer RQ4 with more depth , we analyzed the participants’ open - ended responses to the following , “ Why would or wouldn ' t you use artificial intelligence technology like ChatGPT to help you write a counterspeech ? ” Using an inductive open - coding approach [ 145 ] we first coded the open responses , allowing codes and themes to emerge from the data . We then conducted axial coding to organize and refine the codes and themes to understand how they connected to each other [ 145 ] . We then used memoing to make sense of the emerging codes and connections between codes and themes . Throughout this process , three authors discussed emerging themes and connections between codes and themes , and used Cohen’s kappa to evaluate the inter - rater agreement for the codes across the authors [ 153 ] . 4 RESULTS A total of 458 participants ( 50 . 6 % female , mean age : 40 . 3±13 . 3 ) completed the survey . More demographic details are in Table 1 , Appendix . On average , the length of counter speech authored by the participants was 41 . 6 words . RQ1 results demonstrate that people who have been targets of online hate speech ( targets ) tend to engage in counterspeech on social media more frequently than those who do not have such experience ( non - targets ) . This higher engagement stems from a desire to emotionally vent and to confront hateful persons or behaviors . On the other hand , for those who have never been a target of online hate speech , signaling inclusion is one of the main drivers for engaging in online counterspeech . In RQ2 , we show that motivations and barriers influencing counterspeech engagement can be grouped into five latent variables - Fear , Time Concern , Emotional & Skill Barrier , Engagement Hesitation , and Motivation . People’s demographic backgrounds and social media experiences impact their willingness to engage in online counterspeech across these five latent variables . Specifically , women , highly educated users , and those frequently encountering online hate are less likely to engage due to fear and emotional / skill barriers , while older , more liberal users , and those who have been targeted by online hate exhibit greater overall motivation for counterspeech participation . 13 RQ3 results show that motivations and barriers associated with counterspeech engagement significantly impact people’s writing experience and perception of their own counterspeech . Individuals more apprehensive about writing counterspeech due to retaliation , public exposure , and third - party harassment were more likely to perceive their own writing as effective and satisfying . Conversely , people with greater emotional and skill - related barriers in writing counterspeech were less likely to perceive their counterspeech as effective and also found it more difficult to write counterspeech to the hateful posts shown in the survey . Surprisingly , individuals who scored higher on the Engagement Hesitation latent factor were significantly more likely to perceive their own counterspeech as effective . Finally , RQ4 results demonstrate that prior experience of using AI tools like ChatGPT significantly influences people’s willingness to use such tools to write online counterspeech . People who do versus do not have experience using AI tools also differ in terms of specific motivations and barriers that underly why they would or would not use AI for counterspeech writing . Prior users are more willing to use AI to signal inclusion to others through counterspeech , but not to defend themselves . In contrast , non - users ( those who have never used ChatGPT or similar tools ) are more willing to use AI to help them write counterspeech when they fear retaliation from the perpetrator , but they are less inclined to rely on AI to defend friends and family . We delve more deeply into these differences in our open response analyses in section 4 . 4 . 4 . 1 What motivations and barriers influence how often people engage in online counterspeech ( RQ1 ) ? Our linear regression results ( Table 4 ) show four key factors significantly associated with how frequently individuals engage in counterspeech on social media ( * p < . 05 ; * * p < . 01 ; * * * p < . 001 ) . Notably , having been a target of online hate speech emerged as the strongest predictor that drives people to frequently engage in online counter speech ( b = . 353 , β = . 170 , p < . 001 ) . Individuals who have been a victim of online hate speech in the past engaged in counterspeech on social media significantly more often than those without such experience . Likewise , those who have higher motivation to engage in online counterspeech in order to stand up for others ( other than kin ) engaged in online counterspeech more frequently as well ( b = . 104 , p = . 033 ) . Similarly , a stronger motivation to confront hateful persons or behaviors was also significantly related to increased counterspeech activity ( b = . 123 , p = . 007 ) . On the other hand , reluctance to engage in social media conversations was the strongest negative predictor of how often people engaged in counterspeech on social media ( b = - . 172 , p < . 001 ) , suggesting that peoples’ aversion towards engaging in social media conversations in general trump their desire to intervene . We also controlled for how often participants comment on social media in general , which was positively associated with the frequency of writing counterspeech on social media platforms ( b = . 146 , p < . 001 ) . Demographic factors and other motivation and barrier variables were not statistically significant . 14 Table 4 : Linear Regression Results for Counterspeech Writing Frequency on Social Media ( N = 458 ) B β Std . Error t value VIF M o t i v a t i o n s M1 : Supporting kin 0 . 030 0 . 038 0 . 043 0 . 689 2 . 481 M2 : Supporting others 0 . 104 0 . 134 0 . 049 2 . 134 * 3 . 291 M3 : Supporting self - 0 . 025 - 0 . 033 0 . 038 - 0 . 655 2 . 085 M4 : Confronting hate 0 . 123 0 . 160 0 . 046 2 . 692 * * 2 . 948 M5 : Educating ignorance 0 . 021 0 . 029 0 . 043 0 . 493 2 . 868 M6 : Signaling inclusion 0 . 039 0 . 054 0 . 037 1 . 048 2 . 216 M7 : Issue focus 0 . 002 0 . 002 0 . 047 0 . 033 2 . 782 M8 : Venting emotions 0 . 062 0 . 073 0 . 034 1 . 799 1 . 381 B a rr i e r s B1 : Fear of public exposure 0 . 029 0 . 037 0 . 038 0 . 764 2 . 012 B2 : Fear of perpetrator retaliation - 0 . 018 - 0 . 023 0 . 045 - 0 . 404 2 . 781 B3 : Fear of third - party harassment - 0 . 008 - 0 . 011 0 . 042 - 0 . 194 2 . 750 B4 : Time Concern - 0 . 046 - 0 . 064 0 . 032 - 1 . 417 1 . 703 B5 : Emotional burden 0 . 046 0 . 059 0 . 035 1 . 291 1 . 720 B6 : Skill gap - 0 . 040 - 0 . 048 0 . 035 - 1 . 147 1 . 472 B7 : Engagement unqualified - 0 . 042 - 0 . 052 0 . 038 - 1 . 120 1 . 802 B8 : Engagement reluctance - 0 . 172 - 0 . 241 0 . 032 - 5 . 400 * * * 1 . 665 B9 : Engagement ineffective - 0 . 011 - 0 . 014 0 . 031 - 0 . 339 1 . 507 S N S Past experience of online hate speech target 0 . 353 0 . 170 0 . 077 4 . 586 * * * 1 . 148 Frequency of encountering hateful content 0 . 074 0 . 072 0 . 039 1 . 914 1 . 166 Social media commenting frequency 0 . 146 0 . 144 0 . 040 3 . 611 * * * 1 . 320 Use of real name on social media 0 . 037 0 . 062 0 . 022 1 . 690 1 . 133 D e m o g r a p h i c Age 0 . 000 0 . 004 0 . 003 0 . 097 1 . 209 Gender - 0 . 019 - 0 . 009 0 . 077 - 0 . 241 1 . 203 Ethnicity - 0 . 092 - 0 . 045 0 . 076 - 1 . 216 1 . 154 Education level 0 . 042 0 . 030 0 . 053 0 . 796 1 . 166 Sexual orientation - 0 . 081 - 0 . 033 0 . 097 - 0 . 835 1 . 289 Political views 0 . 052 0 . 060 0 . 034 1 . 507 1 . 304 ( Intercept ) 1 . 078 / 0 . 324 3 . 331 * * / Adjusted R - squared = 0 . 4532 ; 𝐹𝐹 ( 27 , 430 ) = 15 . 03 , 𝑝𝑝 < . 001 Variability in Counterspeech Engagement Among Targets and Non - Targets of Online Hate Speech . Given that people who have been targets of online hate speech ( targets ) in the past tend to engage in counterspeech on social media more frequently than those without such experience ( non - targets ) , we conducted a subgroup analysis to understand how counterspeech motivations and barriers differed between the two groups . We conducted two regression models : non - target group , N = 276 , and target group , N = 182 . Results are shown in Table 5 ( * p < . 05 ; * * p < . 01 ; * * * p < . 001 ) . All VIF values were below 3 . 70 . Targets of Online Hate Speech : Targets engage in counterspeech more often if they have stronger desires to confront hateful persons or behavior ( b = . 165 , p = . 045 ) , or to emotionally vent ( b = . 123 , p = . 029 ) . However , the greater the reluctance to spend time to engage in online counterspeech ( b = - . 115 , p = . 039 ) and the stronger the perception that counterspeech is ineffective in general ( b = - . 125 , p = . 022 ) , the less often do targets engage in counterspeech . Non - Targets of Online Hate Speech : By contrast , non - targets engage in counterspeech more often when they have a strong desire to signal inclusion to others through counterspeech ( b = . 116 , p = . 020 ) . Non - targets also engage in more counterspeech if they frequently encounter online hate ( b = . 105 , p = . 031 ) , and comment more frequently on social media in general ( b = . 176 , p < . 001 ) . These two variables are insignificant for targets . Furthermore , non - targets are less likely to participate in counterspeech if they generally prefer to avoid social media conversations ( b = - . 199 , p < . 001 ) . 15 This variable was not significant for targets . Table 5 : Factors Affecting Counterspeech Writing Frequency in Targets and Non - Targets of Online Hate Speech Non - target group Target group ( n = 276 ) ( n = 182 ) B β t value B β t value M o t i v a t i o n s M1 : Supporting kin 0 . 047 0 . 069 0 . 906 0 . 058 0 . 065 0 . 786 M2 : Supporting others 0 . 094 0 . 135 1 . 514 0 . 115 0 . 135 1 . 383 M3 : Supporting self - 0 . 012 - 0 . 017 - 0 . 247 - 0 . 013 - 0 . 016 - 0 . 205 M4 : Confronting hate 0 . 057 0 . 084 1 . 064 0 . 165 0 . 194 2 . 025 * M5 : Educating ignorance 0 . 040 0 . 061 0 . 783 - 0 . 045 - 0 . 057 - 0 . 598 M6 : Signaling inclusion 0 . 116 0 . 172 2 . 338 * - 0 . 062 - 0 . 086 - 1 . 044 M7 : Issue focus - 0 . 057 - 0 . 077 - 0 . 997 0 . 124 0 . 138 1 . 470 M8 : Venting emotions 0 . 046 0 . 057 1 . 031 0 . 123 0 . 149 2 . 202 * B a rr i e r s B1 : Fear of public exposure 0 . 009 0 . 014 0 . 198 0 . 062 0 . 075 0 . 999 B2 : Fear of perpetrator retaliation - 0 . 056 - 0 . 080 - 0 . 951 0 . 012 0 . 014 0 . 166 B3 : Fear of third - party harassment 0 . 027 0 . 041 0 . 507 - 0 . 037 - 0 . 046 - 0 . 503 B4 : Time Concern - 0 . 021 - 0 . 033 - 0 . 521 - 0 . 115 - 0 . 151 - 2 . 086 * B5 : Emotional burden 0 . 022 0 . 031 0 . 509 0 . 060 0 . 073 0 . 914 B6 : Skill gap 0 . 005 0 . 006 0 . 105 - 0 . 076 - 0 . 090 - 1 . 282 B7 : Engagement unqualified - 0 . 035 - 0 . 047 - 0 . 734 - 0 . 016 - 0 . 020 - 0 . 260 B8 : Engagement reluctance - 0 . 199 - 0 . 316 - 4 . 927 * * * - 0 . 096 - 0 . 123 - 1 . 740 B9 : Engagement ineffective 0 . 072 0 . 108 1 . 894 - 0 . 125 - 0 . 160 - 2 . 309 * S N S Frequency of encountering online hate speech 0 . 105 0 . 110 2 . 169 * 0 . 033 0 . 030 0 . 490 Social media commenting frequency 0 . 176 0 . 190 3 . 532 * * * 0 . 086 0 . 082 1 . 264 Use of real name on social media 0 . 043 0 . 081 1 . 596 0 . 038 0 . 061 1 . 024 D e m o g r a p h i c Age - 0 . 003 - 0 . 048 - 0 . 948 0 . 008 0 . 085 1 . 240 Gender - 0 . 075 - 0 . 041 - 0 . 792 0 . 152 0 . 070 1 . 096 Ethnicity - 0 . 167 - 0 . 092 - 1 . 826 0 . 008 0 . 004 0 . 059 Education level - 0 . 027 - 0 . 022 - 0 . 403 0 . 039 0 . 025 0 . 395 Sexual orientation - 0 . 048 - 0 . 019 - 0 . 358 - 0 . 081 - 0 . 035 - 0 . 555 Political views - 0 . 021 - 0 . 027 - 0 . 495 0 . 178 0 . 187 2 . 980 * * ( Intercept ) 1 . 431 / 3 . 760 * * * 0 . 442 / 0 . 717 Adjusted R - squared 0 . 409 0 . 469 F - test F ( 26 , 249 ) = 8 . 307 , p < . 001 F ( 26 , 155 ) = 7 . 151 , p < . 001 4 . 2 How do demographic variables shape people’s motivations and barriers in online counterspeech engagement ( RQ2 ) ? To answer RQ2 , we conducted a structural equation model ( SEM ) to investigate the effects of key demographic factors and social media behavior on people’s motivations and barriers in engaging in online counterspeech . Prior to constructing our model , we first examined the underlying structure of the motivations and barriers influencing counterspeech engagement using exploratory factor analysis ( EFA ) and confirmatory factor analysis ( CFA ) [ 82 ] . These analyses helped us categorize the individual motivation and barrier variables into broader latent variables ( LV ) as shown in Table 6 . The EFA results revealed a five - factor structure that characterizes the motivations and barriers related to counterspeech . We applied a robust cut - off threshold of 0 . 55 for the factor loadings , following [ 87 ] , and included variable items with strong correlations to the latent variables to ensure that our model was parsimonious and reliable [ 87 ] , eliminating B9 and M8 . The CFA results indicated a good model fit : CFI = 0 . 952 , RMSEA = 0 . 066 ( 90 % CI = [ 0 . 057 , 0 . 076 ] ) . 16 This process resulted in five latent variables associated with counterspeech engagement : Fear - Driven Inhibition ( LV1 ) , Time Concern ( LV2 ) , Emotional and Skill Barriers ( LV3 ) , Engagement Hesitation ( LV4 ) , and Motivation ( LV5 ) – for a description of these latent variables , see section 6 . 3 in Appendix . Table 6 : Factor Loadings for Barriers and Motivations Associated with Writing Counterspeech on Social Media Motivation and Barrier Items LV1 LV2 LV3 LV4 LV5 Fear - Driven Inhibition Time Concern Emotional & Skill Barrier Engagement Hesitation Motivation B a rr i e r s B1 : Fear of public exposure 0 . 694 B2 : Fear of perpetrator retaliation 0 . 882 B3 : Fear of third - party harassment 0 . 848 B4 : Time Concern 1 . 000 B5 : Emotional burden 0 . 653 B6 : Skill gap 0 . 565 B7 : Engagement unqualified 0 . 641 B8 : Engagement reluctance 0 . 593 B9 : Engagement ineffective 0 . 538 M o t i v a t i o n s M1 : Supporting kin 0 . 729 M2 : Supporting others 0 . 842 M3 : Supporting self 0 . 673 M4 : Confronting hate 0 . 815 M5 : Educating ignorance 0 . 793 M6 : Signaling inclusion 0 . 716 M7 : Issue focus 0 . 822 M8 : Venting emotions 0 . 372 4 . 2 . 1 Demographic Characteristics Significantly Influence Motivations and Barriers for Engaging in Online Counterspeech Our SEM analyses examining the effects of key demographic factors on each latent variable ( LV1 – LV5 ) underlying counterspeech motivations and barriers indicated a strong fit . The chi - square test statistic was 501 . 092 with 189 degrees of freedom and p < . 001 . The CFI was 0 . 915 , indicating a good fit . The RMSEA was 0 . 060 , which was within the acceptable range of 0 . 05 to 0 . 08 . Age : Younger participants experienced higher fear - driven inhibition ( b = - . 162 , p = . 001 ) , suggesting that they were more deterred from engaging in counterspeech on social media due to fears of public exposure , perpetrator retaliation , and third - party harassment , compared to their older counterparts . Gender : Similarly , women , compared to men also reported higher fear - driven inhibition related to potential retaliation from perpetrators , public exposure , and third - party harassment ( 𝑏𝑏 = . 228 , 𝑝𝑝 < . 001 ) . Furthermore , women also reported higher emotional and skill - related barriers - namely the emotional toll of engaging in online counterspeech and uncertainties on how to construct effective counter responses ( 𝑏𝑏 = 0 . 298 , 𝑝𝑝 < . 001 ) . Education : Similarly , participants with higher education levels also reported higher levels of fear - driven inhibition ( b = . 194 , p < . 000 ) and higher emotional burden & skill barriers ( b = . 181 , p = . 003 ) than participants with lower education backgrounds . Political views : Participants who were more politically liberal were more motivated to write online counterspeech ( 𝑏𝑏 = . 150 , 𝑝𝑝 = 0 . 001 ) and reported less engagement hesitation ( 𝑏𝑏 = - . 153 , 𝑝𝑝 = 0 . 010 ) compared to their conservative counterparts . 17 4 . 3 How do people’s motivations and barriers in online counterspeech engagement influence : ( a ) how satisfied they are with their counterspeech , ( b ) how difficult they find it to write counterspeech , and ( c ) how they perceive the effectiveness of their counterspeech ( RQ3 ) ? Figure 2 illustrates the results of our second SEM analysis evaluating the impact of the five latent variables ( LV1 - LV5 ) on the three central dependent outcomes : ( a ) participants’ perceived satisfaction with their self - authored counterspeech , ( b ) perceived difficulty in writing the counterspeech , and ( c ) perceived effectiveness of their own counterspeech in mitigating the hate speech they were responding to . Figure 2 : Standardized path coefficients of the structural equation model . We show how the barrier latent variables in red and the motivation latent variable in green affect peoples’ perceived satisfaction , difficulty , and effectiveness of their counterspeech . ( * p < . 05 ; * * p < . 01 ; * * * p < . 001 ) . The resulting fit indices for our SEM model indicated a good fit . The chi - square statistic was 693 . 423 ( p < . 001 , df = 264 ) . The CFI was 0 . 900 . The RMSEA was 0 . 060 ( 90 % CI = [ 0 . 054 , 0 . 065 ] ) , which was within the acceptable range of 0 . 05 to 0 . 08 . The SRMR was 0 . 051 , which was below the cut - off value of 0 . 08 . In addition to controlling for the control variables in Table 3 , we also controlled the model for how hateful the participants perceived the hate speech they were responding to . Below we discuss our results . Fear - Driven Inhibition ( LV1 ) : People who have higher levels of fear of writing counterspeech due to perpetrator retaliation , public exposure , and third - party harassment were significantly more satisfied ( 𝑏𝑏 = . 536 , 𝑝𝑝 = . 022 ) with their self - written counterspeech and perceived their counterspeech to be more effective ( 𝑏𝑏 = . 812 , 𝑝𝑝 = . 019 ) than those who scored lower on the fear - driven inhibition latent variable . One plausible explanation for this is that , due to heightened concerns about negative consequences , users may invest additional effort in crafting their counterspeech [ 140 ] . This extra diligence could translate into increased satisfaction and a stronger belief in the effectiveness of their counterspeech 18 [ 7 ] . Time Concern ( LV2 ) : Time Concern did not yield statistically significant effects on the outcome variables , suggesting that concerns about the time required for writing counterspeech did not notably influence participants ' satisfaction , difficulty , or perceived effectiveness in this context . Emotional and Skill Barriers ( LV3 ) : Those who scored higher on the Emotional and Skill Barriers latent factor were significantly less satisfied with their own counter speech ( b = - 1 . 255 , p = . 002 ) , and experienced more difficulty in writing counterspeech ( b = . 921 , p = . 007 ) in response to the hateful speech they were shown in the survey . These individuals were also significantly less likely to perceive their self - written counterspeech as effective in deterring the hate speech they were responding to ( b = - 1 . 993 , p = . 001 ) . Engagement Hesitation ( LV4 ) : Surprisingly , individuals who scored higher on the Engagement Hesitation latent factor were significantly more likely to perceive their own counterspeech as effective ( b = 1 . 269 , p = . 008 ) . A plausible explanation for this seemingly paradoxical result could be that those who are hesitant to engage in counterspeech due to feeling unqualified to engage , or are reluctant to converse on social media in general , may set a higher threshold for action . In other words , they may only choose to engage when they believe they have something truly impactful to say . As a result , when they do overcome their hesitation and contribute counterspeech , it may be more thoughtfully crafted , and , thus , such individuals may perceive their counterspeech as more effective . Motivation ( LV5 ) : Participants with stronger motivations for crafting counterspeech not only felt more satisfied with their counter responses ( b = . 450 , p < . 001 ) , but also found the writing process less challenging ( b = - . 313 , p = . 001 ) . Additionally , they were more confident in the effectiveness of the counterspeech they wrote in response to the hate speech shown in the survey ( b = . 650 , p < . 001 ) . 4 . 4 How are people’s motivations and barriers in online counterspeech engagement associated with their willingness to use AI assistance ( RQ4 ) ? Results from our first linear regression for RQ4 demonstrate that people who have used ChatGPT ( n = 162 ) in the past are significantly more willing to use AI assistance in writing online counterspeech , compared to those who have never used such tools before ( n = 296 ) ( 𝑏𝑏 = . 472 , 𝑝𝑝 < . 001 ) . For specific details , see Table 2A , Appendix . Hence , similar to RQ1 , we conducted a subgroup analysis between the two groups . Results are shown in Table 7 . People with prior experience using AI tools like ChatGPT : For those who have used ChatGPT in the past , feeling less capable of writing effective counterspeech is a significant motivator for using AI assistance to do so ( 𝑏𝑏 = . 242 , 𝑝𝑝 < . 001 ) . Interestingly , this group is also more willing to use ChatGPT when writing counterspeech to signal inclusion to others ( 𝑏𝑏 = . 145 , 𝑝𝑝 = . 026 ) , but less inclined to use it when engaging in online counterspeech to stand - up for themselves ( 𝑏𝑏 = - . 144 , 𝑝𝑝 = . 039 ) . People who have never used AI tools like ChatGPT : By contrast , among those who have never used ChatGPT , a stronger fear of perpetrator retaliation makes them significantly more willing to use AI for help when writing counterspeech on social media ( 𝑏𝑏 = . 250 , 𝑝𝑝 = . 031 ) . However , non - users are less willing to rely on AI assistance when the purpose of engaging in counterspeech is to defend close kin – family and close friends ( 𝑏𝑏 = - . 265 , 𝑝𝑝 = . 014 ) . Though feeling incapable of writing effective counterspeech is a significant driver for non - users to rely on AI assistance ( 𝑏𝑏 = . 214 , 𝑝𝑝 = . 021 ) , this effect is weaker on non - users compared to those who have used ChatGPT in the past ( 𝑏𝑏 = . 242 , 𝑝𝑝 < . 001 ) . Both prior users and non - users are less willing to use AI for counterspeech writing if they have been targets of online hate speech in the past ( prior users : 𝑏𝑏 = - . 295 , 𝑝𝑝 = . 027 ; non - users : 𝑏𝑏 = - . 426 , 𝑝𝑝 = . 034 ) . Furthermore , political view shows an influence only among prior users , where more liberal views are associated with decreased intention to use AI 19 assistance in crafting counterspeech ( 𝑏𝑏 = - . 168 , 𝑝𝑝 = . 004 ) . Table 7 : Results of Subgroup Analyses for Willingness to Use AI Assistance for Writing Online Counterspeech Non Users of ChatGPT ( n = 162 ) Prior Users of ChatGPT ( n = 296 ) B β t value B β t value M o t i v a t i o n s M1 : Supporting kin - 0 . 265 - 0 . 324 - 2 . 488 * 0 . 085 0 . 093 1 . 134 M2 : Supporting others - 0 . 061 - 0 . 074 - 0 . 556 0 . 092 0 . 103 1 . 010 M3 : Supporting self 0 . 078 0 . 1 0 . 882 - 0 . 144 - 0 . 162 - 2 . 076 * M4 : Confronting hate 0 . 150 0 . 19 1 . 368 - 0 . 095 - 0 . 106 - 1 . 180 M5 : Educating ignorance - 0 . 057 - 0 . 075 - 0 . 562 - 0 . 002 - 0 . 002 - 0 . 020 M6 : Signaling inclusion - 0 . 072 - 0 . 094 - 0 . 772 0 . 145 0 . 178 2 . 238 * M7 : Issue focus 0 . 171 0 . 201 1 . 497 0 . 001 0 . 001 0 . 017 M8 : Venting emotions 0 . 132 0 . 143 1 . 388 - 0 . 053 - 0 . 056 - 0 . 944 B a rr i e r s B1 : Fear of public exposure - 0 . 045 - 0 . 058 - 0 . 450 0 . 087 0 . 097 1 . 366 B2 : Fear of perpetrator retaliation 0 . 250 0 . 315 2 . 179 * 0 . 122 0 . 132 1 . 550 B3 : Fear of third - party harassment - 0 . 069 - 0 . 088 - 0 . 604 - 0 . 058 - 0 . 068 - 0 . 808 B4 : Time Concern 0 . 017 0 . 023 0 . 200 0 . 034 0 . 04 0 . 614 B5 : Emotional burden 0 . 070 0 . 087 0 . 776 - 0 . 064 - 0 . 071 - 1 . 024 B6 : Skill gap 0 . 214 0 . 261 2 . 337 * 0 . 242 0 . 237 4 . 018 * * * B7 : Engagement unqualified - 0 . 114 - 0 . 137 - 1 . 200 0 . 026 0 . 028 0 . 400 B8 : Engagement reluctance 0 . 024 0 . 033 0 . 298 - 0 . 024 - 0 . 028 - 0 . 443 B9 : Engagement ineffective - 0 . 034 - 0 . 046 - 0 . 437 - 0 . 015 - 0 . 018 - 0 . 279 S N S & C h a t G P T Past experience of online hate speech target - 0 . 426 - 0 . 19 - 2 . 147 * - 0 . 295 - 0 . 125 - 2 . 222 * Frequency of encountering online hate speech - 0 . 042 - 0 . 037 - 0 . 431 - 0 . 054 - 0 . 047 - 0 . 817 Social media commenting frequency 0 . 060 0 . 057 0 . 627 0 . 132 0 . 112 1 . 857 Use of real name on social media - 0 . 016 - 0 . 026 - 0 . 299 0 . 008 0 . 011 0 . 208 Perceived usefulness of ChatGPT / / / 0 . 331 0 . 307 5 . 502 * * * D e m o g r a p h i c Age 0 . 003 0 . 039 0 . 438 0 . 006 0 . 071 1 . 262 Gender 0 . 022 0 . 01 0 . 115 - 0 . 005 - 0 . 002 - 0 . 040 Ethnicity 0 . 176 0 . 082 0 . 950 0 . 109 0 . 047 0 . 842 Education level - 0 . 038 - 0 . 026 - 0 . 299 0 . 092 0 . 057 1 . 034 Sexual orientation - 0 . 416 - 0 . 147 - 1 . 534 0 . 115 0 . 042 0 . 724 Political views 0 . 086 0 . 092 0 . 957 - 0 . 168 - 0 . 169 - 2 . 875 * * ( Intercept ) 1 . 477 / 1 . 904 0 . 318 / 0 . 533 R - squared 0 . 2132 0 . 3157 F - test F ( 27 , 137 ) = 1 . 345 , F ( 28 , 267 ) = 4 . 399 , p = . 138 p < . 001 4 . 4 . 1 Qualitative Analysis : Motivations and Reservations for Using AI for Counterspeech Writing Our qualitative analysis of participants’ open responses resulted in a total of six themes associated with why people would or would not use AI assistance for writing online counterspeech . Tables 8 and 9 show the main themes that emerged , along with illustrative examples and the proportion of responses that fell into each theme . We had three raters who independently coded the participants’ open responses into the themes that were identified . The overall Cohen’s kappa coefficient for our analysis was 0 . 854 , with a 95 % confidence interval of 0 . 817 to 0 . 891 . This indicates a very good level of agreement among the raters . Because some user statements contained more than one theme , we coded them into multiple categories . Therefore , the total percentages of the themes exceed 100 % . We discuss each theme in detail below . 20 Table 8 : Reasons for Using AI to Write Online Counterspeech ( 38 . 5 % ) Themes Illustrative Quotes % Efficiency and Convenience • I think it ' s better and faster at putting together coherent sentences that get my point across than myself . • It can save time and effort compared to writing a response from scratch . • It can give me ideas quickly and I can elaborate with my own perspective of the facts . • I think it would save me time and energy , maybe it could help me to better learn the skill so I could use it more . 24 . 7 % Less Emotional Burden • It would take all of the emotional work out of it for me . • It saves you the stress and irritation of having to respond to an ignorant person . • I feel like ChatGPT would be able to refute it with facts and logic in better ways than me , because I feel like counterspeech is an emotional burden on me and I get overwhelmed . • I would probably have the AI help , partially because I just don ' t have the energy for that sort of thing anymore . 11 . 6 % Access to Larger Knowledge Base & Better Articulation • It can help me find the right words and vocabulary to express my thoughts more clearly and eloquently . • It has access to a huge breadth of knowledge that I don ' t , so it can provide data and facts to make my argument stronger . • ChatGPT would be able to assist me with my argument in order to make my counterspeech more effective . • I would use it to help get my statement across in a much clearer way . Also to help me make sure that the information I am writing about is correct . • ChatGPT has a broad database full of statistics and information , and I feel as though it would create the most effective counterspeech because of that . It has nearly all of the information in the world within it , it would certainly make an argument more efficient than I probably could . 2 . 2 % Efficiency and Convenience : Participants emphasized how using AI can “save time and effort compared to writing a response from scratch” , thereby making the writing process faster for them . Some participants also highlighted that AI could help them more easily come up with ideas that they can elaborate on themselves and provide them with useful strategies for writing effective counterspeech that they can use later on . Less Emotional Burden : Many participants highlight that AI tools like ChatGPT could help alleviate many of the negative emotions , such as anger and frustration , that arise when writing counterspeech . For example , one participant notes : “ it can save the stress and irritation of responding to an ignorant person ” . Access to Larger Knowledge Base & Better Articulation : Many participants also underscored the ability of AI to not only help them express themselves more clearly , but also quickly provide supporting evidence for arguments . For example , participants state that AI tools like ChatGPT can help them “ find the right words and vocabulary to express [ their ] thoughts more clearly and eloquently , ” as well as “ provide data and facts to make [ their ] argument stronger ” . Authenticity and Ethical Concerns : The most common reservations for using AI assistance in writing counterspeech are authenticity and ethical concerns . Some voiced feelings of cheating and unease , with one participant stating that “ Using ChatGPT to make counterspeech and then posting it as if it were [ their ] own is lying and unethical at 21 best . ” . Moreover , others expressed worries that AI usage detaches their words from personal ownership , with a participant saying that they would want their counterspeech “ to be in their own words and thoughts ” . Lack of Emotional , Human , or Personal Touch : Many participants raised doubt about AI ' s ability to mimic human emotions such as empathy , with a participant saying that they believe AI “ can use logic but not empathy to write counterspeech ” . Additionally , participants also mentioned AI’s lack of ability to capture their personal experiences or “ fully express what [ they ] want to express ” . Lack of Familiarity or Trust in AI : Many participants also seem to have a general distrust of AI technology , with one participant stating they “ don ' t think ChatGPT and AI in general is quite the ‘do it all’ answer everyone acts like it is ” . Others cite their lack of familiarity with AI tools as the primary reason for their distrust . Moreover , many also recognize that AI may not be “ 100 % accurate or correct” . Table 9 : Reservations Against Using AI to Write Online Counterspeech ( 71 . 7 % ) Themes Illustrative Quotes % Authenticity and Ethical Concerns • If I were being graded for a counterspeech , it would be cheating to have anyone or anything write it for me . • It’s not my voice . It ' s not my perspective . Personally I ' d be ashamed to utilize Artificial Intelligence for counterspeech . • Because then it wouldn ' t even be MY counterspeech . Why would I use AI to write MY opinion ? It ' s stupid . • If my statement were to be judged by others , I would want the statement to be in my own words using my own thoughts . • Using ChatGPT to make counterspeech and then posting it as if it were my own is lying and unethical at best . • I would want to build the skills to effectively and reliably write such speech myself . 33 . 0 % Lack of Emotional , Human , or Personal Touch • This needs human sentiment with human feelings behind them . ChatGPT AI may get there but it’s not there yet . • I think I could write it better because I can use personal experiences and my emotions to hopefully make the perpetrator really think about it . • It can use logic , but not empathy , to write counterspeech . • I would rather tailor my response to be exactly what I’m thinking . I ' m not sure it could fully express what I want to express , and it may lack nuance . • It doesn ' t come from the heart . 26 . 0 % Lack of Familiarity or Trust in AI • I ' m not familiar with it , hence my trust level in its performance is low . • I don ' t think ChatGPT has enough understanding of how internet commenting dynamics work . • I don ' t think ChatGPT and AI in general is quite the " do it all " answer everyone acts like it is . • It’s not always 100 % accurate or correct and could cause issues if you post it as counterspeech and it turns out to be incorrect . • I trust my own words more than a robot ' s . 12 . 7 % 22 5 DISCUSSION 5 . 1 Motivations and Barriers in Online Counterspeech 5 . 1 . 1 Main Deterrent of Online Counterspeech Engagement : General Reluctance to Engage on Social Media RQ1 results show peoples’ general reluctance to engage on social media tends to outweigh other motivations for engaging in online counterspeech . This aligns with prior research in HCI that identifies reluctance towards social media interaction as a contributing factor to online bystander effect [ 39 , 138 , 147 ] . For this reason , while a majority of users observe online harassment , less than a third choose to intervene [ 6 ] . Nevertheless , our findings go a step further by examining key emotional and psychological factors that influence this behavior . 5 . 1 . 2 Main Driver of Online Counterspeech Engagement : Prior Victimization Studies in online bystander intervention show that prior victimization is a key predictor of bystander action [ 129 ] . RQ1 results confirm these insights , demonstrating that having been a target of online hate speech in the past is the strongest predictor that drives people to frequently engage in online counterspeech . We provide further nuance to prior scholarship by showing how counterspeech motivations and barriers in fact , significantly vary between former targets and non - targets . For targets , the perceived ineffectiveness of their counterspeech is the most significant barrier to engaging in counterspeech , while non - targets are primarily deterred by their reluctance to engage on social media in general . These findings are supported by existing work that suggests victims know well when an intervention may or may not be effective due to the memory of their own experiences as well as bystander effects on social media [ 70 , 129 ] . With respect to peoples’ motivations , Costello et al . ( 2016 ) found that past victims of online hate are more than three times as likely to defend fellow victims [ 34 ] . Our results provide context to this research , showing that targets engage in online counterspeech more often when they are primarily motivated to confront a hateful person or their behavior , while this motivation is insignificant for non - targets . 5 . 1 . 3 Multi - Item Survey Scale for Measuring Online Counterspeech Motivations and Barriers While prior research in cyberbullying has created numerous scales to measure bystander motivations [ 139 , 147 ] , most are not generalizable to context of online counterspeech due to differences highlighted in prior research [ 129 ] . Furthermore , such studies are often based on children and adolescents [ 9 , 10 , 114 ] , while our study focuses on adults . To the best of our knowledge , our work is the first to provide a comprehensive set of survey scales for understanding online counterspeech motivation and barriers . Furthermore , as shown in RQ2 , each motivation and barrier scale can be constructed into five key latent variables ( LV1 – LV5 ) . Researchers use these variable items both individually and as latent factors in future studies . 5 . 1 . 4 Demographic Variances in Counterspeech Motivations and Barriers Using our latent variables ( LV1 - LV5 ) , we demonstrate key demographic variances in counterspeech motivations and barriers ( RQ2 ) . We found that age was negatively associated with several barriers , such as fear , emotional and skill barriers , and engagement hesitation , meaning that younger adults are more likely to be deterred by these factors . Our findings are consistent with prior HCI research that highlights nuanced differences in how older versus younger adults perceive online risk [ 56 ] and safety [ 2 , 3 ] . Another notable finding in our work is that women not only face a higher fear of retaliation from the perpetrator and third parties , but also fear being publicly exposed when countering hate through online counterspeech . This aligns with prior research documenting how women cope with online harassment 23 by adopting gendered defensive strategies [ 23 , 92 ] . Particularly , women tend to experience more depression and anxiety after being harassed online , partially explaining their heightened fear of retaliation [ 23 , 108 ] . Moreover , we found that women reported lower self - efficacy in their counterspeech writing skills and greater emotional burden concerns than men . Recent studies suggests how women who are targeted by online harassment become more cautious in expressing their opinions publicly , as they tend to normalize harassment , self - censor , or withdraw from online spaces to avoid further harm [ 23 ] . Our work provides evidence that these factors may deter women from engaging in online counterspeech . In addition , research has shown that more educated individuals may better understand the potential risks and difficulties of public online engagement [ 11 ] . However , our findings show that participants with higher education levels report higher barriers stemming from fear - driven inhibition as well as emotional burden and skill barriers . Concerns of potential risks can prevent more educated individuals from writing counterspeech , even though they may have the necessary skills and knowledge to do so . 5 . 1 . 5 Demographic Factors That Shape Counterspeech Writing Experiences RQ3 results show that compared to other demographic groups , younger , female , more educated users tend to feel more satisfied towards their self - written counterspeech and perceive their counterspeech to be more effective . Interestingly , this group not only encounters hate speech more frequently , but is also more likely to have been a target of online hate speech in the past . Our results also show a positive correlation between the frequency of online hate speech exposure and fear - driven inhibition , meaning that the more often one encounters online hate speech , the stronger their fear - driven inhibitions to engage in counterspeech . As previously discussed , more exposure to online hate may increase peoples’ awareness of the potential threats and challenges of countering it [ 11 , 23 , 94 ] . This may allow individuals to leverage their personal experiences and knowledge [ 62 , 142 ] , leading them to write more satisfying and effective counterspeech . Another explanation is that greater awareness of the potential risks and difficulties in countering online hate may motivate users to put more effort and care into crafting their responses [ 140 ] . This extra diligence could lead to more satisfaction and a stronger belief in the impact of their counterspeech [ 7 ] . Further research could explore these relationships in more depth . 5 . 1 . 6 The Role of AI Assistance in Counterspeech Writing : AI - mediated Counterspeech AI - mediated communication can be defined as interpersonal communication that is not simply transmitted by technology but augmented or even generated by algorithms to achieve specific communicative or relational outcomes [ 75 ] . Since trust is fundamental to human relationships and manifests in collaborative behaviors such as a willingness to depend on and share information , previous research has placed a significant emphasis on examining people ' s perceptions of trustworthiness of messages generated with AI assistance [ 75 , 93 ] . Our qualitative findings provide further nuance to prior research by revealing a tension between individuals ' hesitations and motivations for using AI assistance in crafting online counterspeech . While the primary motivation for adopting such technology is rooted in its utilitarian advantages , reservations predominantly revolve around issues of trust . Most participants expressed distrust in AI ' s ability to accurately convey their emotions as well as the credibility of the information it presents . Given that prior research has found that peoples’ trust in AI generated text decreases as the level of AI agency ( the degree of autonomous content generation and decision - making by AI ) increases , we propose AI - mediated counterspeech as an alternative to AI - generated counterspeech [ 93 , 102 ] . We discuss specific design implications in 5 . 2 . 3 . 24 5 . 2 Design Implications 5 . 2 . 1 Incentivizing Participation Through Recognition Understanding the barriers that deter users from engaging in online counterspeech is a crucial step for developing effective design strategies to encourage proactive participation and intervention in online spaces . People’s reluctance to engage on social media is one of the strongest barriers against participating in online counterspeech ( RQ1 ) . Prior research has shown that incentivizing user contribution through community acknowledgment through badge systems can increase engagement among those who prefer to be lurkers [ 21 ] . For instance , digital badges can function as an award mechanism through visible symbols of achievement and recognition [ 46 , 91 ] . StackOverflow [ 46 ] and Reddit [ 91 ] use a system where users earn badges for varying levels of contribution , such as providing helpful answers or engaging in community moderation . Researchers have shown that these badges not only increase engagement , but also a sense of responsibility and motivation to ensure adherence to community norms in an empathetic manner [ 21 ] . Relatedly , our work shows that confronting hate and supporting others are important motivators for engaging in counterspeech ( RQ1 ) . Building on this , online platforms could introduce badges for users who engage in constructive counterspeech . Visible badges on user profiles could both recognize individual contributions to counterspeech efforts and potentially encourage broader participation within the community to engage in constructive online counterspeech . 5 . 2 . 2 Mitigating Fear Through Personalized Interactions with Others’ Responses to User’s Counterspeech A notable finding in our study is that younger individuals , females , and those who are more educated feel greater fear related to engaging in online counterspeech , and that this fear is correlated with the amount of hateful content they encounter online ( RQ2 ) . To address this , HCI researchers can design personalized features to empower users to manage how they interact with responses , particularly harmful and retaliatory ones , to their counterspeech . Supporting this approach , prior HCI studies have identified a clear preference for personalized content moderation for harmful content , especially among users who have been victims of online hate [ 31 , 123 ] . For instance , transgender Twitter users , who regularly encounter transphobic content online , appreciate the ability to automatically filter out posts containing offensive words specific to their personal preferences , eliminating the need to repetitively mute offenders or posts [ 71 , 77 ] . In the context of reducing fear towards hateful responses to one’s counterspeech , similar design features could be implemented to provide users with a more personalized approach in their ability to moderate responses to their counterspeech , while minimizing exposure to harmful responses from retaliators or third - parties . For example , users could have the choice to either subject these responses to pre - publication moderation or to engage an automatic filtering mechanism based on personally curated keywords for explicitly offensive reactions . Integrating personalized keyword filters or those based on community norms to blur out aggressive or offensive responses to one’s counterspeech could potentially lessen the impact and , consequently , the fear of retaliation , thereby creating a safer and more controlled environment for users to engage in counterspeech . 5 . 2 . 3 Towards Better Understanding of Human - AI Collaboration in Co - Writing Online Counterspeech Research shows that when users work together with AI toward a common goal , they may treat AI as a collaborative partner instead of a tool [ 59 , 154 ] . Similarly , our qualitative analysis in RQ4 show that participants ' willingness to use AI for counterspeech writing was often based on expectations of the AI’s role and the degree of AI involvement in the writing process . For example , many expressed a preference to use AI to help them brainstorm ideas rather than having AI completely write the counterspeech for them . For such users , LLM - powered AI systems may be designed to facilitate 25 brainstorming sessions , by allowing users to input words or phrases as fragments of their thoughts , or details they wish to provide based on personalized experiences . In response , the system may provide feedback and suggestions based on its training and understanding of what is considered constructive counterspeech . Furthermore , participants often indicated overcoming emotional burden or making sure than they do not sound overly angry in their responses as primary reasons for using AI assistance in counterspeech writing . However , despite wanting to use AI for better articulation of their emotions and thoughts , users also expressed concerns around conveying authenticity . Researchers in the HCI community , particularly those focusing on AI - assisted co - writing [ 55 , 89 ] , could examine these issues in future work by exploring ways to design human - AI interactions that can help users convey tone and emotion in their counterspeech , without diminishing the user ' s sense of personal agency and authenticity in their counterspeech writing process . 6 LIMITATIONS While we have randomly assigned hate posts across diverse topics ( gender , religion , disability , sexual orientation , and race ) among our survey participants , we understand that such topics may impact each participant and their responses differently . We recognize this as a limitation of our study , and plan to conduct a more detailed investigation in our future work to understand how these different topics in hate posts affect peoples’ motivations and barriers when it comes to engaging in counterspeech to these posts , as well as their actual counter - responses to topically diverse hate posts . We understand that differences in participants’ primary social media platform of choice may influence their survey responses . Therefore , we included this variable as a control in the linear regressions of RQ1 and RQ4 to verify the impact . However , our analysis revealed that this variable neither altered the significance nor the direction of the regression coefficient ; hence , we moved these results to Table A3 ( Appendix ) and removed this non - significant variable to simplify the regression models in the main text . Finally , participants were asked to write a counterspeech in response to real - life posts containing hate speech in a survey setting , which is different from responding to a hateful post in real life . Hence , this may impact how they write counterspeech in addition to how they evaluate it . 7 CONCLUSION Our work investigates the various motivations and barriers that underly online counterspeech engagement . To this end , we developed and validated a multi - item scale to assess these factors , demonstrating its significant influence on both the experience of writing counterspeech and people’s perceptions towards their self - authored counterspeech . These measures can be used both as individual and latent factors , providing a scale that can be operationalized in future studies in relevant areas of scholarship . Using these latent variables , we demonstrate key demographic variances in counterspeech motivations and barriers , which have not been studied in prior research . Furthermore , we contribute to the emerging understanding of factors influencing people ' s openness to using AI assistance for crafting online counterspeech : while AI can assist in crafting responses , it cannot replace the human element essential for genuinely empathetic and contextually appropriate counterspeech . This finding underscores the necessity of human - AI collaboration , where AI ' s limitations are complemented by human insight and judgment . Our findings can guide tech firms and researchers in better understanding the role of AI in helping users combat hate speech on online platforms . This is especially timely as the implementation of AI technologies in facilitating online discourse is becoming more prominent . 26 REFERENCES [ 1 ] A better ChatGPT app : Poe wants to build the universal AI messaging client : 2023 . https : / / www . theverge . com / 23674656 / poe - ai - chatbot - messaging - app . Accessed : 2023 - 09 - 06 . [ 2 ] Abraham , J . et al . 2022 . Applying Behavioral Contagion Theory to Examining Young Adults’ Participation in Viral Social Media Challenges . ACM Transactions on Social Computing . 5 , 1 – 4 ( Nov . 2022 ) , 3 : 1 - 3 : 34 . DOI : https : / / doi . org / 10 . 1145 / 3538383 . [ 3 ] Ali , S . et al . 2022 . Understanding the Digital Lives of Youth : Analyzing Media Shared within Safe Versus Unsafe Private Conversations on Instagram . Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , Apr . 2022 ) , 1 – 14 . [ 4 ] Allison , K . R . and Bussey , K . 2016 . Cyber - bystanding in context : A review of the literature on witnesses’ responses to cyberbullying . Children and Youth Services Review . 65 , ( Jun . 2016 ) , 183 – 194 . DOI : https : / / doi . org / 10 . 1016 / j . childyouth . 2016 . 03 . 026 . [ 5 ] Ashktorab , Z . and Vitak , J . 2016 . Designing Cyberbullying Mitigation and Prevention Solutions through Participatory Design With Teenagers . Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , May 2016 ) , 3895 – 3905 . [ 6 ] Author , N . 2017 . 3 . Witnessing online harassment . Pew Research Center : Internet , Science & Tech . [ 7 ] Bac , M . 2014 . Opinion expressions under social sanctions . International Review of Law and Economics . 38 , ( Jun . 2014 ) , 58 – 71 . DOI : https : / / doi . org / 10 . 1016 / j . irle . 2014 . 03 . 002 . [ 8 ] Baider , F . 2023 . Accountability Issues , Online Covert Hate Speech , and the Efficacy of Counter‐Speech . Politics and Governance . 11 , 2 ( May 2023 ) , 249 – 260 . DOI : https : / / doi . org / 10 . 17645 / pag . v11i2 . 6465 . [ 9 ] Balakrishnan , V . 2018 . Actions , emotional reactions and cyberbullying – From the lens of bullies , victims , bully - victims and bystanders among Malaysian young adults . Telematics and Informatics . 35 , 5 ( Aug . 2018 ) , 1190 – 1200 . DOI : https : / / doi . org / 10 . 1016 / j . tele . 2018 . 02 . 002 . [ 10 ] Balakrishnan , V . and Fernandez , T . 2018 . Self - esteem , empathy and their impacts on cyberbullying among young adults . Telematics and Informatics . 35 , 7 ( Oct . 2018 ) , 2028 – 2037 . DOI : https : / / doi . org / 10 . 1016 / j . tele . 2018 . 07 . 006 . [ 11 ] Bauman , S . 2023 . Cyberbullying and online harassment : The impact on emotional health and well - being in higher education . Cyberbullying and Online Harms . Routledge . [ 12 ] Billings , M . and Watts , L . A . 2010 . Understanding dispute resolution online : using text to reflect personal and substantive issues in conflict . Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( New York , NY , USA , Apr . 2010 ) , 1447 – 1456 . [ 13 ] Blackwell , L . et al . 2017 . Classification and Its Consequences for Online Harassment : Design Insights from HeartMob . Proceedings of the ACM on Human - Computer Interaction . 1 , CSCW ( Dec . 2017 ) , 24 : 1 - 24 : 19 . DOI : https : / / doi . org / 10 . 1145 / 3134659 . [ 14 ] Bollen , K . A . 1989 . Structural Equations with Latent Variables . John Wiley & Sons . [ 15 ] Brody , N . and Vangelisti , A . L . 2016 . Bystander Intervention in Cyberbullying . Communication Monographs . 83 , 1 ( Jan . 2016 ) , 94 – 119 . DOI : https : / / doi . org / 10 . 1080 / 03637751 . 2015 . 1044256 . [ 16 ] Buerger , C . 2021 . Counterspeech : A Literature Review . [ 17 ] Buerger , C . 2021 . # iamhere : Collective Counterspeech and the Quest to Improve Online Discourse . Social Media + Society . 7 , 4 ( Oct . 2021 ) , 20563051211063843 . DOI : https : / / doi . org / 10 . 1177 / 20563051211063843 . [ 18 ] Buerger , C . 2022 . Why They Do It : Counterspeech Theories of Change . SSRN Electronic Journal . ( 2022 ) . DOI : https : / / doi . org / 10 . 2139 / ssrn . 4245211 . [ 19 ] Carlo , G . et al . 2012 . The interplay of emotional instability , empathy , and coping on prosocial and aggressive behaviors . Personality and Individual Differences . 53 , 5 ( Oct . 2012 ) , 675 – 680 . DOI : https : / / doi . org / 10 . 1016 / j . paid . 2012 . 05 . 022 . [ 20 ] Cavusoglu , H . et al . 2015 . Can Gamification Motivate Voluntary Contributions ? The Case of StackOverflow Q & A Community . Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work & Social Computing ( New York , NY , USA , Feb . 2015 ) , 171 – 174 . [ 21 ] Cavusoglu , H . et al . 2015 . Can Gamification Motivate Voluntary Contributions ? : The Case of StackOverflow Q & A Community . Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work & Social Computing . ( 2015 ) . DOI : https : / / doi . org / 10 . 1145 / 2685553 . 2698999 . [ 22 ] Cepollaro , B . et al . 2023 . Counterspeech . Philosophy Compass . 18 , 1 ( 2023 ) , e12890 . DOI : https : / / doi . org / 10 . 1111 / phc3 . 12890 . [ 23 ] Chadha , K . et al . 2020 . Women’s Responses to Online Harassment . International Journal of Communication . 14 , ( 2020 ) . [ 24 ] Chancellor , S . et al . 2016 . # thyghgapp : Instagram Content Moderation and Lexical Variation in Pro - Eating Disorder Communities . Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing ( New York , NY , USA , Feb . 2016 ) , 1201 – 1213 . [ 25 ] Chandrasekharan , E . et al . 2017 . You Can’t Stay Here : The Efficacy of Reddit’s 2015 Ban Examined Through Hate Speech . Proceedings of the ACM on Human - Computer Interaction . 1 , CSCW ( Dec . 2017 ) , 1 – 22 . DOI : https : / / doi . org / 10 . 1145 / 3134666 . [ 26 ] Chen , A . 2015 . Conversion via Twitter . The New Yorker . [ 27 ] Chetty , N . and Alathur , S . 2018 . Hate speech review in the context of online social networks . Aggression and Violent Behavior . 40 , ( May 2018 ) , 108 – 118 . DOI : https : / / doi . org / 10 . 1016 / j . avb . 2018 . 05 . 003 . [ 28 ] Chung , Y . - L . et al . 2021 . Multilingual Counter Narrative Type Classification . Proceedings of the 8th Workshop on Argument Mining ( 2021 ) , 125 – 132 . [ 29 ] Clark , M . and Bussey , K . 2020 . The role of self - efficacy in defending cyberbullying victims . Computers in Human Behavior . 109 , ( Aug . 2020 ) , 106340 . DOI : https : / / doi . org / 10 . 1016 / j . chb . 2020 . 106340 . [ 30 ] Cohen - Almagor , R . 2011 . Fighting Hate and Bigotry on the Internet . Policy & Internet . 3 , 3 ( 2011 ) , 1 – 26 . DOI : https : / / doi . org / 10 . 2202 / 1944 - 2866 . 1059 . [ 31 ] Cook , C . et al . 2021 . Commercial Versus Volunteer : Comparing User Perceptions of Toxicity and Transparency in Content Moderation Across Social 27 Media Platforms . 3 , ( 2021 ) . DOI : https : / / doi . org / 10 . 3389 / fhumd . 2021 . 626409 . [ 32 ] Cortiz , D . and Zubiaga , A . 2021 . Ethical and technical challenges of AI in tackling hate speech . ( 2021 ) . DOI : https : / / doi . org / 10 . 29173 / irie416 . [ 33 ] Costello , M . et al . 2017 . Confronting Online Extremism : The Effect of Self - Help , Collective Efficacy , and Guardianship on Being a Target for Hate Speech . Social Science Computer Review . 35 , 5 ( Oct . 2017 ) , 587 – 605 . DOI : https : / / doi . org / 10 . 1177 / 0894439316666272 . [ 34 ] Costello , M . et al . 2016 . Virtually Standing Up or Standing By ? Correlates of Enacting Social Control Online . International Journal of Criminology and Sociology . 6 , ( Feb . 2016 ) , 16 – 28 . DOI : https : / / doi . org / 10 . 6000 / 1929 - 4409 . 2017 . 06 . 03 . [ 35 ] Croasmun , J . T . and Ostrom , L . 2011 . Using Likert - Type Scales in the Social Sciences . Journal of Adult Education . 40 , 1 ( 2011 ) , 19 – 22 . [ 36 ] Cuadrado , E . et al . 2016 . Determinants of Prosocial Behavior in Included Versus Excluded Contexts . Frontiers in Psychology . 6 , ( 2016 ) . [ 37 ] Dahlberg , L . 2001 . The Internet and Democratic Discourse : Exploring The Prospects of Online Deliberative Forums Extending the Public Sphere . Information , Communication & Society . 4 , 4 ( Jan . 2001 ) , 615 – 633 . DOI : https : / / doi . org / 10 . 1080 / 13691180110097030 . [ 38 ] DeVito , M . A . et al . 2018 . “Too Gay for Facebook” : Presenting LGBTQ + Identity Throughout the Personal Social Media Ecosystem . Proceedings of the ACM on Human - Computer Interaction . 2 , CSCW ( Nov . 2018 ) , 44 : 1 - 44 : 23 . DOI : https : / / doi . org / 10 . 1145 / 3274313 . [ 39 ] DiFranzo , D . et al . 2018 . Upstanding by Design : Bystander Intervention in Cyberbullying . Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems ( Montreal QC Canada , Apr . 2018 ) , 1 – 12 . [ 40 ] Dinan , E . et al . 2022 . SafetyKit : First Aid for Measuring Safety in Open - domain Conversational Systems . Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) ( 2022 ) , 4113 – 4133 . [ 41 ] Domínguez - Hernández , F . et al . 2018 . A systematic literature review of factors that moderate bystanders’ actions in cyberbullying . Cyberpsychology : Journal of Psychosocial Research on Cyberspace . 12 , 4 ( Dec . 2018 ) . DOI : https : / / doi . org / 10 . 5817 / CP2018 - 4 - 1 . [ 42 ] Douek , E . 2021 . Governing online speech : From " posts - as - trumps " to proportionality and probability . Colum . L . Rev . 121 , ( 2021 ) , 759 . [ 43 ] Dow , M . and Frenett , R . 2014 . One to One Online Interventions A pilot CVE methodology . ( Jan . 2014 ) . [ 44 ] Duncan , O . D . 2014 . Introduction to Structural Equation Models . Elsevier . [ 45 ] Easley , D . and Ghosh , A . 2016 . Incentives , Gamification , and Game Theory : An Economic Approach to Badge Design . ACM Transactions on Economics and Computation . 4 , 3 ( Jun . 2016 ) , 16 : 1 - 16 : 26 . DOI : https : / / doi . org / 10 . 1145 / 2910575 . [ 46 ] Easley , D . and Ghosh , A . 2016 . Incentives , Gamification , and Game Theory : An Economic Approach to Badge Design . ACM Transactions on Economics and Computation . 4 , 3 ( Jun . 2016 ) , 16 : 1 - 16 : 26 . DOI : https : / / doi . org / 10 . 1145 / 2910575 . [ 47 ] Edwards , A . 2002 . Bowling Together . Online Public Engagement in Policy Deliberation , by Stephen Coleman and John Gøtze . Information Polity . 7 , ( Dec . 2002 ) , 247 – 252 . DOI : https : / / doi . org / 10 . 3233 / IP - 2002 - 0021 . [ 48 ] Elsaesser , C . M . et al . 2021 . Avoiding fights on social media : Strategies youth leverage to navigate conflict in a digital era . Journal of Community Psychology . 49 , 3 ( 2021 ) , 806 – 821 . DOI : https : / / doi . org / 10 . 1002 / jcop . 22363 . [ 49 ] Ernst , J . et al . 2017 . Hate beneath the counter speech ? A qualitative content analysis of user comments on YouTube related to counter speech videos . Journal for Deradicalization . 10 ( 2017 ) , 1 – 49 . [ 50 ] Fanton , M . et al . 2021 . Human - in - the - Loop for Data Collection : a Multi - Target Counter Narrative Dataset to Fight Online Hate Speech . Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing ( Volume 1 : Long Papers ) ( Online , Aug . 2021 ) , 3226 – 3240 . [ 51 ] Fortuna , P . et al . 2021 . How well do hate speech , toxicity , abusive and offensive language classification models generalize across datasets ? Information Processing & Management . 58 , 3 ( May 2021 ) , 102524 . DOI : https : / / doi . org / 10 . 1016 / j . ipm . 2021 . 102524 . [ 52 ] Freis , S . D . and Gurung , R . A . R . 2013 . A Facebook analysis of helping behavior in online bullying . Psychology of Popular Media Culture . 2 , 1 ( 2013 ) , 11 – 19 . DOI : https : / / doi . org / 10 . 1037 / a0030239 . [ 53 ] Garland , J . et al . 2020 . Countering hate on social media : Large scale classification of hate and counter speech . arXiv . [ 54 ] Garland , J . et al . 2020 . Impact and dynamics of hate and counter speech online . EPJ Data Science . 11 , ( 2020 ) . DOI : https : / / doi . org / 10 . 1140 / epjds / s13688 - 021 - 00314 - 6 . [ 55 ] Gero , K . I . et al . 2023 . Social Dynamics of AI Support in Creative Writing . Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , Apr . 2023 ) , 1 – 15 . [ 56 ] Ghaiumy Anaraky , R . et al . 2021 . To Disclose or Not to Disclose : Examining the Privacy Decision - Making Processes of Older vs . Younger Adults . Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , May 2021 ) , 1 – 14 . [ 57 ] Gillespie , T . et al . 2023 . Expanding the Debate about Content Moderation : Scholarly Research Agendas for the Coming Policy Debates . [ 58 ] Goddard , R . D . et al . 2004 . Collective Efficacy Beliefs : Theoretical Developments , Empirical Evidence , and Future Directions . Educational Researcher . 33 , 3 ( Apr . 2004 ) , 3 – 13 . DOI : https : / / doi . org / 10 . 3102 / 0013189X033003003 . [ 59 ] Grudin , J . 2022 . From Tool to Partner : The Evolution of Human - Computer Interaction . Springer Nature . [ 60 ] Guo , L . and Johnson , B . G . 2020 . Third - Person Effect and Hate Speech Censorship on Facebook . Social Media + Society . 6 , 2 ( Apr . 2020 ) , 2056305120923003 . DOI : https : / / doi . org / 10 . 1177 / 2056305120923003 . [ 61 ] Haimson , O . L . et al . 2021 . Disproportionate Removals and Differing Content Moderation Experiences for Conservative , Transgender , and Black Social Media Users : Marginalization and Moderation Gray Areas . Proceedings of the ACM on Human - Computer Interaction . 5 , CSCW2 ( Oct . 2021 ) , 466 : 1 - 466 : 35 . DOI : https : / / doi . org / 10 . 1145 / 3479610 . [ 62 ] Hangartner , D . et al . 2021 . Empathy - based counterspeech can reduce racist hate speech in a social media field experiment . Proceedings of the 28 National Academy of Sciences . 118 , 50 ( Dec . 2021 ) , e2116310118 . DOI : https : / / doi . org / 10 . 1073 / pnas . 2116310118 . [ 63 ] Hargittai , E . 2007 . Whose Space ? Differences among Users and Non - Users of Social Network Sites . Journal of Computer - Mediated Communication . 13 , 1 ( Oct . 2007 ) , 276 – 297 . DOI : https : / / doi . org / 10 . 1111 / j . 1083 - 6101 . 2007 . 00396 . x . [ 64 ] Hassan , S . et al . 2018 . Social media influencer and cyberbullying : A lesson learned from preliminary findings . ( 2018 ) . [ 65 ] Hawdon , J . et al . 2017 . Exposure to Online Hate in Four Nations : A Cross - National Consideration . Deviant Behavior . 38 , 3 ( Mar . 2017 ) , 254 – 266 . DOI : https : / / doi . org / 10 . 1080 / 01639625 . 2016 . 1196985 . [ 66 ] Hawdon , J . et al . 2015 . Online extremism and online hate : Exposure among adolescents and young adults in four nations . NORDICOM INFORMATION . 37 , 3 – 4 ( 2015 ) , 29 – 37 . [ 67 ] Hayduk , L . A . and Littvay , L . 2012 . Should researchers use single indicators , best indicators , or multiple indicators in structural equation models ? BMC Medical Research Methodology . 12 , 1 ( Oct . 2012 ) , 159 . DOI : https : / / doi . org / 10 . 1186 / 1471 - 2288 - 12 - 159 . [ 68 ] He , B . et al . 2021 . Racism is a virus : anti - asian hate and counterspeech in social media during the COVID - 19 crisis . Proceedings of the 2021 IEEE / ACM International Conference on Advances in Social Networks Analysis and Mining ( Virtual Event Netherlands , Nov . 2021 ) , 90 – 94 . [ 69 ] Heise , D . R . 1975 . Causal analysis . John Wiley & Sons . [ 70 ] Henson , B . et al . 2020 . There Is Virtually No Excuse : The Frequency and Predictors of College Students’ Bystander Intervention Behaviors Directed at Online Victimization . Violence Against Women . 26 , 5 ( Apr . 2020 ) , 505 – 527 . DOI : https : / / doi . org / 10 . 1177 / 1077801219835050 . [ 71 ] Ho , L . 2022 . Countering Personalized Speech . SSRN Electronic Journal . ( 2022 ) . DOI : https : / / doi . org / 10 . 2139 / ssrn . 4117895 . [ 72 ] Horta Ribeiro , M . et al . 2023 . Deplatforming did not decrease Parler users’ activity on fringe social media . PNAS Nexus . 2 , 3 ( Mar . 2023 ) , pgad035 . DOI : https : / / doi . org / 10 . 1093 / pnasnexus / pgad035 . [ 73 ] Hu , L . and Bentler , P . M . 1999 . Cutoff criteria for fit indexes in covariance structure analysis : Conventional criteria versus new alternatives . Structural Equation Modeling : A Multidisciplinary Journal . 6 , 1 ( Jan . 1999 ) , 1 – 55 . DOI : https : / / doi . org / 10 . 1080 / 10705519909540118 . [ 74 ] Ireland , L . et al . 2020 . Preconditions for guardianship interventions in cyberbullying : Incident interpretation , collective and automated efficacy , and relative popularity of bullies . Computers in Human Behavior . 113 , ( Dec . 2020 ) , 106506 . DOI : https : / / doi . org / 10 . 1016 / j . chb . 2020 . 106506 . [ 75 ] Jakesch , M . et al . 2019 . AI - Mediated Communication : How the Perception that Profile Text was Written by AI Affects Trustworthiness . Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow Scotland Uk , May 2019 ) , 1 – 13 . [ 76 ] Jhaver , S . et al . 2018 . Online Harassment and Content Moderation . ACM Transactions on Computer - Human Interaction ( TOCHI ) . 25 , ( 2018 ) . DOI : https : / / doi . org / 10 . 1145 / 3185593 . [ 77 ] Jhaver , S . et al . 2023 . Personalizing Content Moderation on Social Media : User Perspectives on Moderation Choices , Interface Design , and Labor . Proceedings of the ACM on Human - Computer Interaction . 7 , CSCW2 ( Oct . 2023 ) , 289 : 1 - 289 : 33 . DOI : https : / / doi . org / 10 . 1145 / 3610080 . [ 78 ] Ji , Z . et al . 2023 . Survey of Hallucination in Natural Language Generation . ACM Computing Surveys . 55 , 12 ( Mar . 2023 ) , 248 : 1 - 248 : 38 . DOI : https : / / doi . org / 10 . 1145 / 3571730 . [ 79 ] Joinson , A . N . 2008 . Looking at , looking up or keeping up with people ? motives and use of facebook . Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( New York , NY , USA , Apr . 2008 ) , 1027 – 1036 . [ 80 ] Jr , H . M . B . 2018 . Causal Inferences in Nonexperimental Research . UNC Press Books . [ 81 ] Keipi , T . et al . 2016 . Online Hate and Harmful Content : Cross - National Perspectives . Taylor & Francis . [ 82 ] Kline , R . and St , C . 2022 . Principles and Practice of Structural Equation Modeling . [ 83 ] Lai , V . et al . 2022 . Human - AI Collaboration via Conditional Delegation : A Case Study of Content Moderation . Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , Apr . 2022 ) , 1 – 18 . [ 84 ] Lammerts , P . et al . 2023 . How do you feel ? Measuring User - Perceived Value for Rejecting Machine Decisions in Hate Speech Detection . Proceedings of the 2023 AAAI / ACM Conference on AI , Ethics , and Society ( New York , NY , USA , Aug . 2023 ) , 834 – 844 . [ 85 ] Latané , B . and Darley , J . M . 1970 . The unresponsive bystander : Why doesn’t he help ? Appleton - Century - Crofts . ( 1970 ) . [ 86 ] Laville , S . 2016 . Top tech firms urged to step up online abuse fightback . The Guardian . [ 87 ] Lee , A . L . C . , Howard B . 2013 . A First Course in Factor Analysis . Psychology Press . [ 88 ] Lee , H . et al . 2022 . ELF22 : A Context - based Counter Trolling Dataset to Combat Internet Trolls . Proceedings of the Thirteenth Language Resources and Evaluation Conference ( 2022 ) , 3530 – 3541 . [ 89 ] Lee , M . et al . 2022 . CoAuthor : Designing a Human - AI Collaborative Writing Dataset for Exploring Language Model Capabilities . CHI Conference on Human Factors in Computing Systems ( Apr . 2022 ) , 1 – 19 . [ 90 ] Leonhard , L . et al . 2018 . Perceiving threat and feeling responsible . How severity of hate speech , number of bystanders , and prior reactions of others affect bystanders’ intention to counterargue against hate speech on Facebook . SCM Studies in Communication and Media . 7 , 4 ( Dec . 2018 ) , 555 – 579 . DOI : https : / / doi . org / 10 . 5771 / 2192 - 4007 - 2018 - 4 - 555 . [ 91 ] Lewis , C . 2014 . Irresistible Apps : Motivational Design Patterns for Apps , Games , and Web - based Communities . Apress . [ 92 ] Lindsay , M . et al . 2016 . Experiences of Online Harassment Among Emerging Adults . Journal of Interpersonal Violence . 31 , ( 2016 ) . DOI : https : / / doi . org / 10 . 1177 / 0886260515584344 . [ 93 ] Liu , Y . et al . 2022 . Will AI Console Me when I Lose my Pet ? Understanding Perceptions of AI - Mediated Email Writing . CHI Conference on Human Factors in Computing Systems ( New Orleans LA USA , Apr . 2022 ) , 1 – 13 . [ 94 ] Luong , G . and Charles , S . 2014 . Age differences in affective and cardiovascular responses to a negative social interaction : the role of goals , appraisals , 29 and emotion regulation . Developmental psychology . 50 7 , ( 2014 ) . DOI : https : / / doi . org / 10 . 1037 / a0036621 . [ 95 ] Machackova , H . et al . 2015 . Brief report : The bystander effect in cyberbullying incidents . Journal of Adolescence . 43 , ( Aug . 2015 ) , 96 – 99 . DOI : https : / / doi . org / 10 . 1016 / j . adolescence . 2015 . 05 . 010 . [ 96 ] Madden , C . and Loh , J . ( M . I . ) 2020 . Workplace cyberbullying and bystander helping behaviour . The International Journal of Human Resource Management . 31 , 19 ( Oct . 2020 ) , 2434 – 2458 . DOI : https : / / doi . org / 10 . 1080 / 09585192 . 2018 . 1449130 . [ 97 ] Marques , D . R . 2021 . What Type of Factor Analysis Are You Doing ? Implications for Sleep Medicine Field . Sleep and Vigilance . 5 , 2 ( Dec . 2021 ) , 337 – 338 . DOI : https : / / doi . org / 10 . 1007 / s41782 - 021 - 00173 - 1 . [ 98 ] Masullo Chen , G . and Lu , S . 2017 . Online Political Discourse : Exploring Differences in Effects of Civil and Uncivil Disagreement in News Website Comments . Journal of Broadcasting & Electronic Media . 61 , 1 ( Jan . 2017 ) , 108 – 125 . DOI : https : / / doi . org / 10 . 1080 / 08838151 . 2016 . 1273922 . [ 99 ] Mathew , B . et al . 2020 . Hate begets Hate : A Temporal Study of Hate Speech . Proceedings of the ACM on Human - Computer Interaction . 4 , CSCW2 ( Oct . 2020 ) , 1 – 24 . DOI : https : / / doi . org / 10 . 1145 / 3415163 . [ 100 ] Mathew , B . et al . 2020 . Hate begets Hate : A Temporal Study of Hate Speech . Proceedings of the ACM on Human - Computer Interaction . 4 , CSCW2 ( Oct . 2020 ) , 92 : 1 - 92 : 24 . DOI : https : / / doi . org / 10 . 1145 / 3415163 . [ 101 ] Mathew , B . et al . 2019 . Thou Shalt Not Hate : Countering Online Hate Speech . Proceedings of the International AAAI Conference on Web and Social Media . 13 , ( Jul . 2019 ) , 369 – 380 . DOI : https : / / doi . org / 10 . 1609 / icwsm . v13i01 . 3237 . [ 102 ] McKnight , D . H . et al . 2002 . Developing and Validating Trust Measures for e - Commerce : An Integrative Typology . Information Systems Research . 13 , 3 ( Sep . 2002 ) , 334 – 359 . DOI : https : / / doi . org / 10 . 1287 / isre . 13 . 3 . 334 . 81 . [ 103 ] Meske , C . and Bunde , E . 2023 . Design Principles for User Interfaces in AI - Based Decision Support Systems : The Case of Explainable Hate Speech Detection . Information Systems Frontiers . 25 , 2 ( Apr . 2023 ) , 743 – 773 . DOI : https : / / doi . org / 10 . 1007 / s10796 - 021 - 10234 - 5 . [ 104 ] Miškolci , J . et al . 2020 . Countering Hate Speech on Facebook : The Case of the Roma Minority in Slovakia . Social Science Computer Review . 38 , 2 ( Apr . 2020 ) , 128 – 146 . DOI : https : / / doi . org / 10 . 1177 / 0894439318791786 . [ 105 ] Mollas , I . et al . 2022 . ETHOS : an Online Hate Speech Detection Dataset . Complex & Intelligent Systems . 8 , 6 ( Dec . 2022 ) , 4663 – 4678 . DOI : https : / / doi . org / 10 . 1007 / s40747 - 021 - 00608 - 2 . [ 106 ] Munger , K . 2017 . Tweetment Effects on the Tweeted : Experimentally Reducing Racist Harassment . Political Behavior . 39 , 3 ( Sep . 2017 ) , 629 – 649 . DOI : https : / / doi . org / 10 . 1007 / s11109 - 016 - 9373 - 5 . [ 107 ] N et al . 2017 . Megan Phelps - Roper : If You’re Raised To Hate , Can You Reverse It ? NPR . [ 108 ] Nadim , M . and Fladmoe , A . 2019 . Silencing Women ? Gender and Online Harassment . Social Science Computer Review . 39 , ( 2019 ) . DOI : https : / / doi . org / 10 . 1177 / 0894439319865518 . [ 109 ] Nextdoor Is Integrating Generative AI to Drive Engaging and Kind Conversations in the Neighborhood : 2023 . https : / / finance . yahoo . com / news / nextdoor - integrating - generative - ai - drive - 103000201 . html . Accessed : 2023 - 09 - 06 . [ 110 ] Nickerson , A . B . et al . 2014 . Perceptions of School Climate as a Function of Bullying Involvement . Journal of Applied School Psychology . 30 , 2 ( Apr . 2014 ) , 157 – 181 . DOI : https : / / doi . org / 10 . 1080 / 15377903 . 2014 . 888530 . [ 111 ] Obermaier , M . et al . 2016 . Bystanding or standing by ? How the number of bystanders affects the intention to intervene in cyberbullying . New Media & Society . 18 , 8 ( Sep . 2016 ) , 1491 – 1507 . DOI : https : / / doi . org / 10 . 1177 / 1461444814563519 . [ 112 ] Obermaier , M . et al . 2021 . I’ll be there for you ? Effects of Islamophobic online hate speech and counter speech on Muslim in - group bystanders’ intention to intervene . New Media & Society . ( Aug . 2021 ) , 146144482110175 . DOI : https : / / doi . org / 10 . 1177 / 14614448211017527 . [ 113 ] Obermaier , M . et al . 2023 . Too civil to care ? How online hate speech against different social groups affects bystander intervention . European Journal of Criminology . 20 , 3 ( May 2023 ) , 817 – 833 . DOI : https : / / doi . org / 10 . 1177 / 14773708231156328 . [ 114 ] Obermaier , M . 2022 . Youth on standby ? Explaining adolescent and young adult bystanders’ intervention against online hate speech . New Media & Society . ( Oct . 2022 ) , 14614448221125417 . DOI : https : / / doi . org / 10 . 1177 / 14614448221125417 . [ 115 ] O’brien , R . M . 2007 . A Caution Regarding Rules of Thumb for Variance Inflation Factors . Quality & Quantity . 41 , 5 ( Oct . 2007 ) , 673 – 690 . DOI : https : / / doi . org / 10 . 1007 / s11135 - 006 - 9018 - 6 . [ 116 ] Ousidhoum , N . et al . 2019 . Multilingual and Multi - Aspect Hate Speech Analysis . Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) ( Hong Kong , China , Nov . 2019 ) , 4675 – 4684 . [ 117 ] Papacharissi , Z . 2004 . Democracy online : civility , politeness , and the democratic potential of online political discussion groups . New Media & Society . 6 , ( 2004 ) , 259 – 283 . DOI : https : / / doi . org / 10 . 1177 / 1461444804041444 . [ 118 ] Parker , S . and Ruths , D . 2023 . Is hate speech detection the solution the world wants ? Proceedings of the National Academy of Sciences . 120 , 10 ( Mar . 2023 ) , e2209384120 . DOI : https : / / doi . org / 10 . 1073 / pnas . 2209384120 . [ 119 ] Pater , J . A . et al . 2016 . “Hunger Hurts but Starving Works” : Characterizing the Presentation of Eating Disorders Online . Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing ( New York , NY , USA , Feb . 2016 ) , 1185 – 1200 . [ 120 ] Petterson , A . et al . 2023 . Supporting Social Movements Through HCI and Design . Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , Apr . 2023 ) , 1 – 5 . [ 121 ] Piliavin , J . A . et al . 1976 . Time of Arrival at an Emergency and Likelihood of Helping . Personality and Social Psychology Bulletin . 2 , 3 ( Jul . 1976 ) , 273 – 276 . DOI : https : / / doi . org / 10 . 1177 / 014616727600200314 . [ 122 ] Qian , J . et al . 2019 . A Benchmark Dataset for Learning to Intervene in Online Hate Speech . Proceedings of the 2019 Conference on Empirical Methods 30 in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) ( 2019 ) , 4755 – 4764 . [ 123 ] Reid Chassiakos , Y . L . et al . 2016 . Children and Adolescents and Digital Media . Pediatrics . 138 , 5 ( Nov . 2016 ) , e20162593 . DOI : https : / / doi . org / 10 . 1542 / peds . 2016 - 2593 . [ 124 ] Reuter , C . et al . 2017 . Social Media in Emergencies : A Representative Study on Citizens’ Perception in Germany . Proceedings of the ACM on Human - Computer Interaction . 1 , CSCW ( Dec . 2017 ) , 90 : 1 - 90 : 19 . DOI : https : / / doi . org / 10 . 1145 / 3134725 . [ 125 ] Reynolds , L . and Tuck , H . THE COUNTER - NARRATIVE MONITORING & EVALUATION HANDBOOK . [ 126 ] Richards , R . D . and Calvert , C . 2000 . Counterspeech 2000 : A New Look at the Old Remedy for Bad Speech . Brigham Young University Law Review . 2000 , ( 2000 ) , 553 . [ 127 ] Rieger , D . et al . 2018 . Hate and counter - voices in the Internet : Introduction to the special issue . SCM Studies in Communication and Media . 7 , 4 ( Dec . 2018 ) , 459 – 472 . DOI : https : / / doi . org / 10 . 5771 / 2192 - 4007 - 2018 - 4 - 459 . [ 128 ] Rösner , L . and Krämer , N . C . 2016 . Verbal Venting in the Social Web : Effects of Anonymity and Group Norms on Aggressive Language Use in Online Comments . Social Media + Society . 2 , 3 ( Jul . 2016 ) , 2056305116664220 . DOI : https : / / doi . org / 10 . 1177 / 2056305116664220 . [ 129 ] Rudnicki , K . et al . 2023 . Systematic review of determinants and consequences of bystander interventions in online hate and cyberbullying among adults . Behaviour & Information Technology . 42 , 5 ( Apr . 2023 ) , 527 – 544 . DOI : https : / / doi . org / 10 . 1080 / 0144929X . 2022 . 2027013 . [ 130 ] Ruths , D . R . et al . 2016 . Considerations for Successful Counterspeech . Dangerous Speech Project . [ 131 ] Saha , P . et al . 2022 . CounterGeDi : A Controllable Approach to Generate Polite , Detoxified and Emotional Counterspeech . ( Jul . 2022 ) , 5157 – 5163 . [ 132 ] Saltman , E . et al . 2023 . New Models for Deploying Counterspeech : Measuring Behavioral Change and Sentiment Analysis . Studies in Conflict & Terrorism . 46 , 9 ( Sep . 2023 ) , 1547 – 1574 . DOI : https : / / doi . org / 10 . 1080 / 1057610X . 2021 . 1888404 . [ 133 ] Sasse , J . and Grossklags , J . 2023 . Breaking the Silence : Investigating Which Types of Moderation Reduce Negative Effects of Sexist Social Media Content . Proceedings of the ACM on Human - Computer Interaction . 7 , CSCW2 ( Oct . 2023 ) , 327 : 1 - 327 : 26 . DOI : https : / / doi . org / 10 . 1145 / 3610176 . [ 134 ] Schieb , C . and Preuss , M . 2016 . Governing hate speech by means of counterspeech on Facebook . [ 135 ] Schwertberger , U . and Rieger , D . 2021 . Hass und seine vielen Gesichter : Eine sozial - und kommunikationswissenschaftliche Einordnung von Hate Speech . Hate Speech - Multidisziplinäre Analysen und Handlungsoptionen : Theoretische und empirische Annäherungen an ein interdisziplinäres Phänomen . S . Wachs et al . , eds . Springer Fachmedien . 53 – 77 . [ 136 ] Seering , J . 2020 . Reconsidering Self - Moderation : the Role of Research in Supporting Community - Based Models for Online Content Moderation . Proceedings of the ACM on Human - Computer Interaction . 4 , CSCW2 ( Oct . 2020 ) , 107 : 1 - 107 : 28 . DOI : https : / / doi . org / 10 . 1145 / 3415178 . [ 137 ] Seering , J . et al . 2017 . Shaping Pro and Anti - Social Behavior on Twitch Through Moderation and Example - Setting . Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing ( New York , NY , USA , Feb . 2017 ) , 111 – 125 . [ 138 ] Seo , M . 2020 . Bystanders’ Experience in Cyber Bullying among Adolescents : Focused on Group Chat Room . THE KOREAN JOURNAL OF DEVELOPMENTAL PSYCHOLOGY . 33 , 3 ( Sep . 2020 ) , 65 – 88 . DOI : https : / / doi . org / 10 . 35574 / KJDP . 2020 . 9 . 33 . 3 . 65 . [ 139 ] Shultz , E . et al . 2014 . Cyber - bullying : An exploration of bystander behavior and motivation . Cyberpsychology : Journal of Psychosocial Research on Cyberspace . 8 , 4 ( Dec . 2014 ) . DOI : https : / / doi . org / 10 . 5817 / CP2014 - 4 - 3 . [ 140 ] Siebert , J . and Siebert , J . U . 2023 . Effective mitigation of the belief perseverance bias after the retraction of misinformation : Awareness training and counter - speech . PLOS ONE . 18 , 3 ( Mar . 2023 ) , e0282202 . DOI : https : / / doi . org / 10 . 1371 / journal . pone . 0282202 . [ 141 ] Silverman , T . et al . 2016 . The impact of counter - narratives . Institute for Strategic Dialogue . 54 , ( 2016 ) . [ 142 ] Smeenk , W . et al . 2018 . A systematic validation of the Empathic Handover approach guided by five factors that foster empathy in design . CoDesign . 15 , ( 2018 ) . DOI : https : / / doi . org / 10 . 1080 / 15710882 . 2018 . 1484490 . [ 143 ] Smith , P . K . et al . 2008 . Cyberbullying : its nature and impact in secondary school pupils . Journal of Child Psychology and Psychiatry . 49 , 4 ( 2008 ) , 376 – 385 . DOI : https : / / doi . org / 10 . 1111 / j . 1469 - 7610 . 2007 . 01846 . x . [ 144 ] Soral , W . et al . 2018 . Exposure to hate speech increases prejudice through desensitization . Aggressive Behavior . 44 , ( 2018 ) . DOI : https : / / doi . org / 10 . 1002 / ab . 21737 . [ 145 ] Strauss , A . L . and Corbin , J . M . 1998 . Basics of qualitative research : techniques and procedures for developing grounded theory . Sage Publications . [ 146 ] Stroud , S . R . and Cox , W . 2018 . The Varieties of Feminist Counterspeech in the Misogynistic Online World . Mediating Misogyny : Gender , Technology , and Harassment . J . R . Vickery and T . Everbach , eds . Springer International Publishing . 293 – 310 . [ 147 ] Taylor , S . H . et al . 2019 . Accountability and Empathy by Design : Encouraging Bystander Intervention to Cyberbullying on Social Media . Proceedings of the ACM on Human - Computer Interaction . 3 , CSCW ( Nov . 2019 ) , 118 : 1 - 118 : 26 . DOI : https : / / doi . org / 10 . 1145 / 3359220 . [ 148 ] Tekiroğlu , S . S . et al . 2022 . Using Pre - Trained Language Models for Producing Counter Narratives Against Hate Speech : a Comparative Study . Findings of the Association for Computational Linguistics : ACL 2022 ( 2022 ) , 3099 – 3114 . [ 149 ] Tokunaga , R . S . 2010 . Following you home from school : A critical review and synthesis of research on cyberbullying victimization . Computers in Human Behavior . 26 , 3 ( May 2010 ) , 277 – 287 . DOI : https : / / doi . org / 10 . 1016 / j . chb . 2009 . 11 . 014 . [ 150 ] Ubangha , C . 2016 . Hate Speech in Cyberspace : Why Education is Better than Regulation . [ 151 ] Vashistha , A . et al . 2019 . Threats , Abuses , Flirting , and Blackmail : Gender Inequity in Social Media Voice Forums . Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( New York , NY , USA , May 2019 ) , 1 – 13 . [ 152 ] Wachs , S . et al . 2021 . Online correlates of cyberhate involvement among young people from ten European countries : An application of the Routine Activity and Problem Behaviour Theory . Computers in Human Behavior . 123 , ( Oct . 2021 ) , 106872 . DOI : https : / / doi . org / 10 . 1016 / j . chb . 2021 . 106872 . 31 [ 153 ] Wan , T . et al . 2015 . Kappa coefficient : a popular measure of rater agreement . Shanghai archives of psychiatry . 27 , 1 ( 2015 ) , 62 . [ 154 ] Wang , D . et al . 2021 . Designing AI to Work WITH or FOR People ? Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama Japan , May 2021 ) , 1 – 5 . [ 155 ] Wang , Y . et al . 2015 . Coming of Age ( Digitally ) : An Ecological View of Social Media Use among College Students . Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing ( New York , NY , USA , Feb . 2015 ) , 571 – 582 . [ 156 ] Westboro Baptist Church | History & Facts | Britannica : 2024 . https : / / www . britannica . com / topic / Westboro - Baptist - Church . Accessed : 2024 - 03 - 05 . [ 157 ] Wong , R . Y . M . et al . 2021 . Standing Up or Standing By : Understanding Bystanders’ Proactive Reporting Responses to Social Media Harassment . Information Systems Research . 32 , 2 ( Jun . 2021 ) , 561 – 581 . DOI : https : / / doi . org / 10 . 1287 / isre . 2020 . 0983 . [ 158 ] Wright , S . 1921 . Correlation and causation . ( 1921 ) . [ 159 ] Wright , S . 1934 . The Method of Path Coefficients . The Annals of Mathematical Statistics . 5 , 3 ( 1934 ) , 161 – 215 . [ 160 ] Wright , S . and Street , J . 2007 . Democracy , deliberation and design : the case of online discussion forums . New Media & Society . 9 , 5 ( Oct . 2007 ) , 849 – 869 . DOI : https : / / doi . org / 10 . 1177 / 1461444807081230 . [ 161 ] Zhang , Q . et al . 2023 . Internet altruistic behavior among Chinese early adolescents : Exploring differences in gender and collective efficacy using a latent growth modeling . Current Psychology . ( May 2023 ) . DOI : https : / / doi . org / 10 . 1007 / s12144 - 023 - 04660 - 8 . [ 162 ] Zhu , W . and Bhat , S . 2021 . Generate , Prune , Select : A Pipeline for Counterspeech Generation against Online Hate Speech . Findings of the Association for Computational Linguistics : ACL - IJCNLP 2021 ( 2021 ) , 134 – 149 . 32 8 APPENDICES 8 . 1 Survey Questions This section presents the key questions from the survey ; for the complete list of questions , please refer to the link available on the Open Science Framework ( OSF ) 3 . Screen question : Imagine you are a user of an online group on social media . Another user ( perpetrator ) in the group posted the following : [ hateful post ] . Do you consider this post to be hateful ? ( Yes , No ) Satisfaction : How satisfied are you with the counterspeech that you ' ve written ? ( Extremely dissatisfied , Somewhat dissatisfied , Neither satisfied nor dissatisfied , Somewhat satisfied , Extremely satisfied ) Difficulty : How difficult was it to write this counterspeech ? ( Extremely difficult , Somewhat difficult , Neither easy nor difficult , Somewhat easy , Extremely easy ) Self - perceived effectiveness : How effective do you think your counterspeech would be in preventing the perpetrator from engaging in further hateful behavior ? ( Not effective at all , Slightly effective , Moderately effective , Very effective , Extremely effective ) Prior experience of online hate speech target : Have you been a target of hateful speech on the internet ? ( Yes , No ) Barriers : How much do the following factors prevent you from writing a counterspeech on social media ? ( None at all , A little , A moderate amount , A lot , A great deal )  B1 : I fear being publicly exposed .  B2 : I’m afraid of retaliation from the perpetrator .  B3 : I ' m afraid that I will be harassed by people ( other than the perpetrator ) .  B4 : I don’t want to spend time on this .  B5 : Writing a counterspeech is emotionally burdensome .  B6 : I don’t know how to write an effective counterspeech .  B7 : I feel that it’s not my place to engage in counterspeech .  B8 : I don’t like to engage in social media conversations .  B9 : I feel that my counterspeech would not make a difference . Motivations : How much do the following factors motivate you to write a counterspeech on social media ? ( None at all , A little , A moderate amount , A lot , A great deal )  M1 : When I feel the need to stand up for people I care about ( e . g . , family , close friends ) .  M2 : When I feel the need to stand up for people in general .  M3 : When I feel the need to stand up for myself .  M4 : When I want to confront a hateful person or behavior .  M5 : When I want to educate an ignorant person .  M6 : To signal that I stand for inclusion .  M7 : When it concerns issues or topics I care about .  M8 : When I want to blow off steam . Frequency of writing online counterspeech : How often do you write counterspeech on social media ? ( Never , Rarely , Sometimes , Often , Frequently ) 3 https : / / osf . io / rzmg3 / ? view _ only = 6b2fd3a3d42b4b25a37f014612fac18a 33 Prior use of ChatGPT : Have you used ChatGPT before ? ChatGPT is an artificial intelligence tool that allows you to have human - like conversations by generating human - like responses to text - based inputs . ChatGPT can answer questions , and assist you with tasks such as composing emails , essays , and code . ( Yes , No ) Perceived usefulness of ChatGPT : How useful do you find ChatGPT ? ( Not at all useful , Slightly useful , Moderately useful , Very useful , Extremely useful ) Willingness to use ChatGPT to help write counterspeech : If you were writing a counterspeech on social media , would you use artificial intelligence technology like ChatGPT to help you write it ? Social media platforms : What social media platform do you use most often ? ( Facebook , Instagram , Twitter / X , Linkedin , Reddit , YouTube , TikTok , Snapchat , Other , I don ' t currently use social media ) Social media usage : I have used social media to . ( Stay informed on current events / news , Shop , Learn , Socialize , Entertain myself , Advocate for social issues I care about ) Post frequency : How often did you post on social media ? ( Never , Rarely , Sometimes , Often , Always ) Comment frequency : How often did you comment on content that you encountered on social media ? ( Never , Rarely , Sometimes , Often , Always ) Online Anonymous : Did you use your real name on social media ? ( Never , Rarely , Sometimes , Often , Always ) Social media experience : I encountered the following on social media . ( Never , Rarely , Sometimes , Often , Always )  Content that I disagree with .  Content that I find hateful .  Content that I find controversial . 8 . 2 Description of Latent Variables Fear - Driven Inhibition ( LV1 ) : This latent factor captures a range of fears related to engaging in online counterspeech . It includes concerns about public exposure ( B1 ) , fears of retaliation from the perpetrator ( B2 ) , and fear of harassment from third parties ( B3 ) . Time Concern ( LV2 ) : This one - item latent variable is the barrier associated with time concern in engaging in online counterspeech . Emotional and Skill Barriers ( LV3 ) : This dual - variable factor addresses both the emotional toll and skill - related concerns when engaging in online counterspeech . The factor consists of the emotional burden of engaging in counterspeech ( B5 ) along with uncertainty regarding how to write an effective counterspeech ( B6 ) . Engagement Hesitation ( LV4 ) : This latent variable captures engagement - related barriers in engaging in online counterspeech , which includes feeling unqualified to engage in counterspeech ( B7 ) , and a general reluctance to engage in social media conversations as a reason for not engaging in online counterspeech ( B8 ) . Motivation ( LV5 ) : Except for venting emotions ( M8 ) , this latent variable embodies all motivation variables for engaging in counterspeech – including standing up for kin ( M1 ) , others in general ( M2 ) , and oneself ( M3 ) , confronting hate ( M4 ) , educating the ignorant ( M5 ) , signaling inclusion ( M6 ) , focusing on issues of personal importance ( M7 ) . 8 . 3 Influence of Social Media Platforms We also considered the influence of different social media platforms on counterspeech . We asked participants to indicate which platforms they currently mainly use from a list of 10 options : Facebook , Instagram , Twitter ( X ) , Linkedin , Reddit , YouTube , TikTok , Snapchat , Other , and I don ' t currently use social media . We used Facebook as the reference level . The results are shown in Table A3 . However , we found that these differences were not substantial enough to significantly 34 affect the overall findings . Therefore , we did not include the platform variable in our main analysis . 35 8 . 4 Tables Table A1 . Participant Demographics ( N = 458 ) Factor Category N Age group 18 - 30 138 31 - 60 293 61 - 81 27 Gender Male 226 Female 232 Other or prefer not to answer 0 Ethnicity Majority 234 White 234 Minority 224 Asian 55 Black 110 Hispanic 53 Other 6 Education level Less than high school or high school graduate 65 Some college or 2 - year degree 154 4 - year degree or higher 239 Sexual orientation Heterosexual 359 Non - Heterosexual 99 Political views Very Conservative 28 Conservative 91 Moderate 121 Liberal 134 Very Liberal 84 36 Table A2 . Linear Regression Results of Willingness to Use ChatGPT to Write Counterspeech on Social Media B β Std . Error t value VIF M o t i v a t i o n s M1 : Supporting kin - 0 . 041 - 0 . 046 0 . 061 - 0 . 673 2 . 482 M2 : Supporting others 0 . 023 0 . 027 0 . 070 0 . 336 3 . 292 M3 : Supporting self - 0 . 014 - 0 . 016 0 . 054 - 0 . 258 2 . 085 M4 : Confronting hate - 0 . 010 - 0 . 012 0 . 065 - 0 . 160 2 . 953 M5 : Educating ignorance - 0 . 017 - 0 . 021 0 . 061 - 0 . 277 2 . 870 M6 : Signaling inclusion 0 . 102 0 . 127 0 . 053 1 . 948 2 . 221 M7 : Issue focus 0 . 083 0 . 09 0 . 067 1 . 234 2 . 783 M8 : Venting emotions - 0 . 045 - 0 . 048 0 . 049 - 0 . 930 1 . 382 B a rr i e r s B1 : Fear of public exposure 0 . 071 0 . 082 0 . 054 1 . 320 2 . 012 B2 : Fear of perpetrator retaliation 0 . 187 0 . 211 0 . 065 2 . 891 * * 2 . 788 B3 : Fear of third - party harassment - 0 . 104 - 0 . 124 0 . 061 - 1 . 711 2 . 767 B4 : Time Concern 0 . 021 0 . 026 0 . 046 0 . 458 1 . 705 B5 : Emotional burden - 0 . 076 - 0 . 087 0 . 050 - 1 . 515 1 . 722 B6 : Skill gap 0 . 192 0 . 203 0 . 050 3 . 813 * * * 1 . 484 B7 : Engagement unqualified 0 . 024 0 . 026 0 . 054 0 . 449 1 . 803 B8 : Engagement reluctance 0 . 002 0 . 003 0 . 045 0 . 055 1 . 667 B9 : Engagement ineffective - 0 . 012 - 0 . 015 0 . 045 - 0 . 273 1 . 513 S N S & C h a t G P T Prior use of ChatGPT 0 . 472 0 . 197 0 . 109 4 . 334 * * * 1 . 089 Past experience of online hate speech target - 0 . 375 - 0 . 16 0 . 109 - 3 . 427 * * 1 . 150 Frequency of encountering online hate speech - 0 . 036 - 0 . 031 0 . 055 - 0 . 650 1 . 168 Social media commenting frequency 0 . 087 0 . 076 0 . 057 1 . 515 1 . 320 Use of real name on social media 0 . 007 0 . 011 0 . 031 0 . 237 1 . 138 D e m o g r a p h i c Age 0 . 002 0 . 019 0 . 004 0 . 402 1 . 214 Gender 0 . 020 0 . 009 0 . 110 0 . 185 1 . 219 Ethnicity 0 . 161 0 . 07 0 . 108 1 . 489 1 . 164 Education level 0 . 055 0 . 034 0 . 075 0 . 731 1 . 166 Sexual orientation 0 . 091 0 . 033 0 . 138 0 . 659 1 . 292 Political views - 0 . 118 - 0 . 12 0 . 049 - 2 . 403 * 1 . 308 ( Intercept ) 1 . 029 / 0 . 470 2 . 187 * / Adjusted R - squared = 0 . 4532 ; 𝐹𝐹 ( 27 , 430 ) = 15 . 03 , 𝑝𝑝 < . 001 37 Table A3 . Effects of Social Media Platforms on All Dependent Variables Counterspeech Writing Frequency Willingness to Use AI Assistance B P B P Facebook ( Ref level ) / / / / Instagram 0 . 148 0 . 229 - 0 . 150 0 . 395 Twitter ( X ) 0 . 085 0 . 554 - 0 . 059 0 . 774 Linkedin - 0 . 109 0 . 810 - 0 . 221 0 . 732 Reddit 0 . 124 0 . 432 - 0 . 183 0 . 422 YouTube 0 . 045 0 . 726 - 0 . 094 0 . 608 TikTok - 0 . 131 0 . 369 0 . 127 0 . 542 Snapchat 0 . 144 0 . 659 - 0 . 445 0 . 338 Other - 0 . 430 0 . 248 - 1 . 151 0 . 031 I don ' t currently use social media - 0 . 669 0 . 391 - 0 . 011 0 . 992 ( Intercept ) 1 . 027 / 1 . 135 / 38 Table A4 . Relationship Between Latent Variables and Covariates in the Structural Equation Model IVs Covariates Estimate Std . Est Std . Error z value P - value Fear - Driven Inhibition Age - 1 . 948 - 0 . 162 0 . 616 - 3 . 160 0 . 001 * Gender 0 . 114 0 . 228 0 . 024 4 . 723 0 . 000 * Ethnicity - 0 . 019 - 0 . 040 0 . 022 - 0 . 853 0 . 394 Education level 0 . 136 0 . 194 0 . 034 3 . 994 0 . 000 * Sexual orientation 0 . 025 0 . 064 0 . 019 1 . 359 0 . 174 Political views 0 . 009 0 . 008 0 . 052 0 . 177 0 . 860 Past experience of online hate speech target 0 . 016 0 . 035 0 . 022 0 . 742 0 . 458 Frequency of encountering hateful content 0 . 117 0 . 126 0 . 045 2 . 625 0 . 009 * Social media commenting frequency 0 . 014 0 . 015 0 . 045 0 . 320 0 . 749 Use of real name on social media - 0 . 055 - 0 . 034 0 . 076 - 0 . 718 0 . 473 Time Concern Age 0 . 086 0 . 005 0 . 859 0 . 101 0 . 920 Gender - 0 . 033 - 0 . 047 0 . 032 - 1 . 034 0 . 301 Ethnicity - 0 . 022 - 0 . 031 0 . 032 - 0 . 689 0 . 491 Education level 0 . 082 0 . 081 0 . 047 1 . 762 0 . 078 Sexual orientation 0 . 013 0 . 023 0 . 027 0 . 506 0 . 613 Political views - 0 . 050 - 0 . 031 0 . 075 - 0 . 670 0 . 503 Past experience of online hate speech target 0 . 015 0 . 021 0 . 032 0 . 466 0 . 641 Frequency of encountering hateful content - 0 . 032 - 0 . 023 0 . 063 - 0 . 501 0 . 616 Social media commenting frequency - 0 . 269 - 0 . 190 0 . 067 - 4 . 023 0 . 000 * Use of real name on social media - 0 . 144 - 0 . 059 0 . 110 - 1 . 302 0 . 193 Emotional & Skill Barrier Age - 1 . 270 - 0 . 115 0 . 558 - 2 . 277 0 . 023 * Gender 0 . 096 0 . 298 0 . 023 4 . 108 0 . 000 * Ethnicity - 0 . 034 - 0 . 083 0 . 021 - 1 . 616 0 . 106 Education level 0 . 092 0 . 181 0 . 031 2 . 997 0 . 003 * Sexual orientation - 0 . 002 - 0 . 007 0 . 017 - 0 . 145 0 . 884 Political views 0 . 016 0 . 016 0 . 051 0 . 310 0 . 757 Past experience of online hate speech target 0 . 018 0 . 045 0 . 020 0 . 904 0 . 366 Frequency of encountering hateful content 0 . 069 0 . 085 0 . 041 1 . 699 0 . 089 Social media commenting frequency - 0 . 116 - 0 . 139 0 . 044 - 2 . 608 0 . 009 * Use of real name on social media - 0 . 074 - 0 . 053 0 . 072 - 1 . 031 0 . 303 Engagement Hesitation Age - 1 . 403 - 0 . 124 0 . 624 - 2 . 248 0 . 025 * Gender 0 . 025 0 . 059 0 . 023 1 . 063 0 . 288 Ethnicity - 0 . 009 - 0 . 021 0 . 023 - 0 . 393 0 . 694 Education level 0 . 065 0 . 107 0 . 034 1 . 944 0 . 052 Sexual orientation - 0 . 009 - 0 . 025 0 . 019 - 0 . 461 0 . 645 39 Political views - 0 . 153 - 0 . 134 0 . 055 - 2 . 387 0 . 010 * Past experience of online hate speech target - 0 . 007 - 0 . 017 0 . 022 - 0 . 322 0 . 747 Frequency of encountering hateful content 0 . 022 0 . 027 0 . 045 0 . 500 0 . 617 Social media commenting frequency - 0 . 229 - 0 . 270 0 . 051 - 4 . 513 0 . 000 * Use of real name on social media - 0 . 003 - 0 . 002 0 . 079 - 0 . 037 0 . 970 Motivation Age 0 . 992 0 . 080 0 . 555 1 . 786 0 . 074 Gender 0 . 016 0 . 035 0 . 021 0 . 793 0 . 428 Ethnicity 0 . 020 0 . 043 0 . 021 0 . 969 0 . 332 Education level - 0 . 026 - 0 . 039 0 . 030 - 0 . 868 0 . 385 Sexual orientation 0 . 011 0 . 028 0 . 017 0 . 622 0 . 534 Political views 0 . 170 0 . 150 0 . 050 3 . 401 0 . 001 * Past experience of online hate speech target 0 . 061 0 . 134 0 . 021 2 . 937 0 . 003 * Frequency of encountering hateful content 0 . 163 0 . 181 0 . 042 3 . 859 0 . 000 * Social media commenting frequency 0 . 265 0 . 286 0 . 046 5 . 716 0 . 000 * Use of real name on social media 0 . 142 0 . 090 0 . 071 1 . 988 0 . 047 *