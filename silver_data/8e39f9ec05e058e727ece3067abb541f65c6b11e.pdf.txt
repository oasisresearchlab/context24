A Scalable Collaborative Filtering Framework based on Co - clustering Thomas George Department of Computer Science Texas A & M University tgeorge @ cs . tamu . edu Srujana Merugu Department of Electrical and Computer Engineering University of Texas at Austin merugu @ ece . utexas . edu Abstract Collaborative ﬁltering - based recommender systems have become extremely popular in recent years due to the increase in web - based activities such as e - commerce and online content distribution . Current collaborative ﬁltering ( CF ) techniques such as correlation and SVD based methods provide good accuracy , but are compu - tationally expensive and can be deployed only in static off - line settings . However , a number of practical scenar - ios require dynamic real - time collaborative ﬁltering that can allow new users , items and ratings to enter the sys - tem at a rapid rate . In this paper , we consider a novel CF approach based on a recently proposed weighted co - clustering algorithm [ 1 ] that involves simultaneous clus - tering of users and items . We design incremental and parallel versions of the co - clustering algorithm and use it to build an efﬁcient real - time CF framework . Empiri - cal evaluation demonstrates that our approach provides an accuracy comparable to that of the correlation and matrix factorization based approaches at a much lower computational cost . 1 Introduction The evolution of the internet during the last decade has resulted in an overwhelming increase in web - based activities such as e - commerce and online content dis - tribution where users are often forced to choose from a large number of products or content items . To aid users in the decision making process , it has become important to design recommender systems that automatically iden - tify the likely choices of the users . Collaborative ﬁltering techniques [ 5 ] that predict the preferences of a user from the preferences of other users have been shown to be ef - fective for generating high quality recommendations . A number of CF techniques have been proposed in the literature of which the most popular ones are those based on correlation criteria [ 8 , 3 ] and matrix factoriza - tion [ 9 , 11 ] . The correlation - based techniques use sim - ilarity measures such as Pearson correlation and cosine similarity to determine a neighborhood of like - minded users and then predict the user’s rating for a product as a weighted average of the ratings of the neighbors . On the other hand , the matrix factorization approaches in - clude methods based on SVD [ 9 ] and NNMF [ 11 , 6 ] , which predict the unknown ratings using a low rank ap - proximation of the original ratings matrix . Though both these classes of techniques provide highly accurate pre - dictions , the computationally expensive training com - ponent prohibits frequent re - training . Incremental ver - sions of SVD based on folding - in and exact rank - 1 up - dates [ 10 , 2 ] partially alleviate this problem , but the up - date operations are not very efﬁcient since the effects of partial updates to the ratings matrix are not localized . As a result , the existing CF techniques can only be deployed in static settings where the known preferences do not vary with time . However , a number of practical scenarios such as real - time news personalization require dynamic CF that can handle new users , items and ratings entering the system at a rapid rate . In such situations , it is imper - ative for the recommender system to dynamically adapt its predictions using the new information , which in turn requires a fast and efﬁcient training algorithm . In this paper , we consider a novel CF approach based on a recently proposed weighted Bregman co - clustering algorithm [ 1 ] . The key idea is to simultaneously obtain user and item neighborhoods via co - clustering and gen - erate predictions based on the average ratings of the co - clusters while taking into account the individual biases of the users and items . This approach is similar to the correlation - based techniques in the sense that neighbor - hoods are employed for prediction , the main difference being that both users and items are clustered so that item synonymy ceases to be problem . Further , as in the case of SVD and NNMF , the co - clustering algorithm also op - timizes the approximation error of a low parameter re - construction of the ratings matrix . However , unlike SVD and NNMF , the effects of changes in the ratings matrix are localized in the approximation . Based on the co - clustering approach , we design an ef - ﬁcient real - time CF framework and make two new con - tributions . First , we propose a dynamic CF approach that can support the entry of new users , items and ratings us - ing a hybrid of incremental and batch versions of the co - clustering algorithm . Second , we design a scalable , real - Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 ) 1550 - 4786 / 05 $ 20 . 00 © 2005 IEEE time CF system by developing parallel versions of the co - clustering , prediction and incremental training routines . The rest of the report is organizedas follows : 1 Section 2 contains a formal deﬁnition of the recommendation problem while Section 3 explains the proposed CF ap - proach . Section 4 describes a scalable framework based on parallel co - clustering and ﬁnally , Section 5 provides the results of our empirical evaluation . 2 Problem Deﬁnition We now formulate the recommendation problem in terms of a weighted matrix approximation and motivate the co - clustering approach for solving it . Let be the set of users such that and be the set of items such that . Let be the ratings matrix such that is the rating of the user for the item and let be the ma - trix corresponding to the conﬁdence of the ratings in . In the absence of explicit conﬁdence values , we assume when the rating is known and otherwise . In a static setting , the rating problem involves predict - ing an unknown rating for an existing user and item pair , i . e . , a missing element in . A natural approach to this rating prediction problem is to assume that the matrix has a certain low parameter structure , deduce the param - eters of the structure based on the available ratings so that a certain loss function is minimized , and then use a ma - trix reconstruction based on this structure for predicting the missing values . Usually , the loss function is chosen to be the squared error and the class of chosen structures determines the technique being adopted . For example , when the imposed structure is a low rank approximation , the best approximations are obtained using SVD [ 9 ] ( no constraints ) and NNMF [ 7 ] ( non - negativity constraints ) . However , as mentioned earlier , both these methods are not amenable for incremental training . To address this concern , we consider low param - eter approximations based on simultaneous clustering of users and items in the ratings matrix . Let and denote the user and item clustering where and are number of user and item clusters . The sim - plest approximation scheme based on co - clustering is the one where each missing rating is approximated by the average value in the corresponding co - cluster . In this case , the approximate matrix might not be able to pro - vide accuracy comparable to the SVD and NNMF - based approaches . Hence , we consider a more complex ap - proximation that incorporates the biases of the individ - ual users and items by including the terms ( user average - user cluster average ) and ( item average - item cluster average ) in addition to the co - cluster average . The ap - proximate matrix is given by ( 2 . 1 ) 1 More details on our CF approach can be found in [ 4 ] . where , and are the av - erage ratings of user and item , and , and are the average ratings of the corresponding co - cluster , user - cluster and item - cluster respectively . It can be shown [ 1 ] that is the least squares solution that preserves the user , item and co - cluster averages . We can now pose the recommendation problem as a co - clustering problem where we seek to ﬁnd the optimal user and item clustering such that the approxima - tion error of ( which is a function of ) with respect to the known ratings of is minimized , i . e . , ( 2 . 2 ) where ensures that only the known ratings con - tribute to the loss function . [ 1 ] presents an alternate minimization based algorithm that is guaranteed to pro - vide a locally optimal solution for the co - clustering prob - lem ( 2 . 2 ) . The resulting co - clustering can then be used to compute the various averages required to esti - mate . In case of dynamic scenarios , the ratings matrix varies with time and hence , we require to adapt to the changes in , which can be accomplished efﬁciently since the addition of a new rating affects only the corre - sponding user , item and cluster averages . 3 Collaborative Filtering via Co - clustering In this section , we describe the main components of our CF approach based on co - clustering , viz . , static training , prediction , and incremental training . 3 . 1 Static Training The main objective of the static training component is to compute all the parameters required for fast pre - diction of the unknown ratings . In our co - clustering approach , this essentially involves solving the problem ( 2 . 2 ) using the appropriate instantiation of the Bregman co - clustering algorithm [ 1 ] and estimating the averages , , , and from the optimal co - clustering . The key idea in the algorithm is to assume some initial co - clustering and then alternately optimize over the row ( user ) and column ( item ) cluster - ing till convergence is achieved . Algorithm 1 provides a high level description of the various steps . The clus - ter assignment steps can be implemented efﬁciently by pre - computingthe invariant parts of the update cost func - tions , e . g . , and by using certain properties of the squared loss function . When all the ratings in a co - cluster are unknown , we replace the co - cluster average by the global average value . Assuming Algorithm 1 is implemented efﬁciently , the computational time for obtaining the invariant matrices is linear in the number of non - zeros in and that for the row and column cluster assignments is and Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 ) 1550 - 4786 / 05 $ 20 . 00 © 2005 IEEE Algorithm 1 Static Training via Co - clustering Input : Ratings Matrix , Non - zeros matrix , # row clusters , # column clusters . Output : Locally optimal co - clustering and averages and . Method : 1 . Randomly initialize . repeat 2a . Compute averages and . 2b . Update row cluster assignments 2c . Update column cluster assignments until convergence respectively . Hence , for a constant number of iterations , the overall computation time is where is the number of non - zeros in . Table 1 compares the computational time required for the various CF approaches . In the case of SVD and NNMF , is the rank of the approximation matrix and for correlation - based methods , is the number of neighbors . Table 1 . Comparison of computational times of various CF algorithms . Algorithm Static Training Prediction IncrementalTraining Co - clustering SVD 2 NNMF — Correlation 3 . 2 Prediction In our approach , the unknown ratings are predicted by suitably combining the summary statistics . When the requested rating is for an existing user and item , the pre - diction is determined by ( 2 . 1 ) . When only the user ( or the item ) is new , the predicted value is the item ( or the user ) average , and when both the user and item are new , the predicted value is the global average . 3 . 3 Incremental Training To extend our CF approach to dynamic settings where ratings are being continuously updated , we consider an incremental update mechanism . Since the prediction of the ratings depends only on the summary statistics , up - dating these statistics using the new incoming ratings in - corporates most of the information in the new ratings . When the incoming rating corresponds to a new user 2 for a dense matrix or item , there is no cluster assignment for this new en - tity and hence , we temporarily assign the new entity to a global transitional cluster before updating the cluster averages . During the next run of the co - clustering algo - rithm , the users in the global user cluster and the items in the global item cluster are reassigned to one of regular user and item clusters . 4 Scalable Collaborative Filtering System In this section , we describe a real - time CF system based on the co - clustering approach and explain how it can be implemented efﬁciently using parallel processing . 4 . 1 CF - System Description From Table 1 , we note that the prediction and incre - mental training routines are much faster than the static training process . To shorten the system response time , we consider a system with two processors and where handles the prediction and incremental training and is responsible for the static training . As shown in Figure 1 , processors and respectively own the summary statistics ( ) and the ratings matrix ( ) . Pro - cessor reads during prediction and updates both and during incremental training while performs co - clustering on and updates . To ensure consistency , the data objects and are stored in two parts — ( a ) stable values at the end of co - clustering , and ( b ) increments . P1 P2 A S A Δ Δ New ratings Known ratings SummaryStatistics S Updates to Summary Statistics Co−clustering Incremental Training Prediction Figure 1 . Collaborative Filtering System 4 . 2 Parallel Collaborative Filtering When the ratings matrix and the summary statistics are too large to be stored in the main memory of a single processor , a natural solution is to assume a distributed memory representation for the data objects and paral - lelize the CF operations assigned to and . Parallel Co - clustering ( ) . To parallelize the co - clustering algorithm , we note that there are two main steps in each iteration of the co - clustering algorithm - ( i ) computing the matrix averages , ( ii ) obtaining the row and column cluster assignments , both of which are data parallel to some extent . This inherent parallelism can be exploited by partitioning the rows and columns among Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 ) 1550 - 4786 / 05 $ 20 . 00 © 2005 IEEE Table 2 . MAE for a static scenario on sub - sets of MovieLens Data SVD NNMF CORR COCLUST Mov1Mov2Mov3 the processors so that the step ( ii ) can be completely per - formed in parallel . For step ( i ) , the different processors compute their partial contributions , which are then com - bined to obtain the overall matrix averages . For a dense matrix equally partitioned among processors , the overall computation time is , which corresponds to almost linear speedup assuming and ignoring the communication costs . Parallel Prediction and Incremental Training ( ) . To parallelize the prediction and incremental training routines , we ﬁrst partition the summary statistics among different processors based on the user and item clusters and store the entity - cluster as well as cluster - processor mappings on a speciﬁed root processor . When a rating is requested ( or submitted ) for a particular user and item , the root processor ﬁrst determines the clusters to which these entities belong using the local mappings and directs the request to a slave processor that owns these clusters , which then performs the actual computation . 5 Experimental Results We now present the results of empirical evalua - tion of our CF framework using the MovieLens dataset ( http : / / www . grouplens . org / data ) , which consists of 100 , 000 ratings ( 1 - 5 ) by 943 users on 1682 movies . We compared the performance of our approach with SVD [ 9 ] , NNMF [ 6 ] and classic correlation - based CF techniques [ 8 ] in terms of the prediction accuracy , train - ing time and prediction time for both dynamic and static scenarios . The results presented below highlight the main beneﬁts of our method , i . e . , obtaining reasonable accuracy with lower training time as compared to exist - ing techniques . Detailed experimental results including those involving parallel co - clustering can be found in [ 4 ] . Prediction accuracy vs . Choice of CF algorithm . Table 2 shows the mean absolute error ( MAE ) obtained using various CF algorithms for a static scenario with a ﬁxed training - test ( 80 - 20 % ) split . We note that all the CF algorithms provide approximately the same accuracy Similar results are observed for the dynamic scenario . Training time vs . Data set size . Figure 2 shows the variation of the training time with the size of the dataset ( # known ratings ) for the co - clustering and SVD - based methods 3 on the MovieLens dataset . We observe that 3 We do not report the results for NNMF and correlation methods since there were variations in the implementation . 0 1 2 3 4 5 6 7 8 9 x 10 4 10 −1 10 0 10 1 10 2 # known ratings T r a i n i ng T i m e ( i n s e c ) SVD COCLUST Figure 2 . Training time vs . Data size the co - clustering approach is not only faster , but also more scalable than the SVD - based method in spite of the fact that the SVD - based method uses an optimized LAPACK library . 6 Acknowledgments We would like to acknowledge support from the NSF under grants IIS - 0312471 and DMS - 0216275 . References [ 1 ] A . Banerjee , I . Dhillon , J . Ghosh , S . Merugu , and D . Modha . A generalized maximum entropy approach to bregman co - clustering and matrix approximation . In KDD , pages 509 – 514 , 2004 . [ 2 ] M . Brand . Fast online SVD revisions for lightweight rec - ommender systems . In SDM , pages 37 – 48 , 2003 . [ 3 ] J . S . Breese , D . Heckerman , and C . Kadie . Empirical anal - ysis of predictive algorithms for collaborative ﬁltering . In UAI , pages 43 – 52 , 1998 . [ 4 ] T . George and S . Merugu . A scalable collabora - tive ﬁltering framework based on co - clustering . Tech - nical report , CS Dept . , Texas A & M Univ . , 2005 . url : http : / / students . cs . tamu . edu / icdm05collab . pdf . [ 5 ] J . L . Herlocker , J . A . Konstan , L . G . Terveen , and J . T . Riedl . Evaluating collaborative ﬁltering recommender systems . ACM Trans . Inf . Syst . , 22 ( 1 ) : 5 – 53 , 2004 . [ 6 ] T . Hofmann . Latent semantic models for collaborative ﬁl - tering . ACM Trans . Inf . Sys . , 22 ( 1 ) : 89 – 115 , 2004 . [ 7 ] D . D . Lee and H . S . Seung . Algorithms for non - negative matrix factorization . In NIPS , pages 556 – 562 , 2000 . [ 8 ] P . Resnick , N . Iacovou , M . Suchak , P . Bergstorm , and J . Riedl . GroupLens : An Open Architecture for Collab - orative Filtering of Netnews . In Proc . of ACM Conf . on CSCW , pages 175 – 186 , 1994 . [ 9 ] B . Sarwar , G . Karypis , J . Konstan , and J . Riedl . Ap - plication of dimensionality reduction in recommender systems – a case study . In WebKDD Workshop . , 2000 . [ 10 ] B . Sarwar , G . Karypis , J . Konstan , and J . Riedl . Incre - mental SVD - based algorithms for highly scaleable recom - mender systems . In 5th Intl . Conf . on CIT , 2002 . [ 11 ] N . Srebro and T . Jaakkola . Weighted low rank approxi - mation . In ICML , pages 720 – 728 , 2003 . Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 ) 1550 - 4786 / 05 $ 20 . 00 © 2005 IEEE