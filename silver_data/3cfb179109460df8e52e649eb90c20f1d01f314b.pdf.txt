PSYCI - IOMETRIKA ~ VOL . 24 ~ NO . 2 JUNE , 1959 ON METHODS IN THE ANALYSIS OF PROFILE DATA SAMUEL W . GREENHOUSE AND SEYMOUR GEISSER * NATIONAL INSTITUTE OF MENTAL HEALTH This paper is concerned with methods for analyzing quantitative , non - categorical profile data , e . g . , a battery of tests given to individuals in one or more groups . It is assumed that the variables have a multinormal distribution with an arbitrary variance - covariance matrix . Approximate procedures based on classical analysis of variance are presented , including an adjustment to the degrees of freedom resulting in conservative F tests . These can be applied to the case where the variance - covariance matrices differ from group to group . In addition , exact generalized multivariate analysis methods are discussed . Examples are given illustrating both techniques . Much research in the social sciences is of the multivariate type ; multiple observations are made on individuals who have been sampled from one or more populations . In particular , when the observations are in the form of a battery of tests or a set of items , there is the problem of profile analysis , wherein it is customary to test for differences in the levels and in the shapes of the group profiles . If the variables being observed are assigned to columns and the individuals to rows , the resulting matrix of observations is very suggestive of the data usually analyzed by analysis of variance . Furthermore , since the rows are random and the columns can be considered in almost all instances as fixed , the appropriate model is the mixed model . As is well known , in order that the usually computed ratios of mean squares in this model [ 7 , 14 , 16 ] be exactly distributed as the F distribution , it is necessary that columns ( variables ) , in addition to being normally dis - tributed , have equal variances and be mutually independent or , at most , have equal correlations . But these assumptions seem much too restrictive . In most investigations , it is unrealistic to assume that three or more tests , items , or treatment schedules have the same pairwise correlations or that they have the same variances . It seemed obvious , therefore , that this problem of multiple observations should be considered in its greatest generality , namely , that an individual vector xl , x2 , • . . , x ~ is sampled from a p - variate normal distribution with an arbitrary variance - covariance matrix . Exact procedures for analyzing data of this type have been known for some time and are usually referred to as the generalized multivariate analysis of variance [ 1 , 10 , 12 , 13 , 17 ] . These , however , require considerably more computations than that demanded by the arithmetic of the analysis of • We are indebted to Mrs . Norton French for performing all the calculations appearing in this paper . 95 96 PSYCHOMETRIKA variance . Furthermore , an analysis of variance approach permits the analysis of a set of data which cannot be handled by multivariate procedures , namely , the case where n , the number of random vectors , is less than p , the number of variables . Although these multivariate methods are discussed subsequently and an example is given for the case of two groups , our main purpose is to utilize the simpler , and more familiar , conventional univariate analysis of variance techniques under , the more general assumptions . Our results concern - ing the approximate distributions of the F statistics are based upon thework of Box [ 5 , 6 ] with regard to one group and its extension , by Geisser and Greenhouse [ 8 ] , to several groups . In addition , the latter have found certain adjustments to the approximate tests leading to conservative tests which can be used , when the group sample sizes are the same , in the case of unequal variance - covariance matrices among the groups . It is of interest that Block , Levine , and McNemar [ 2 ] were also primarily concerned with the application of the analysis of variance to the profile problem . They presented F tests for testing the homogeneity of variable ( columns ) means , the homogeneity of over - all group means ( profile levels ) and the equality of profile shapes . However , they assumed equal v . ariance , among the yariables and , since they imply that the F tests are exact , it can only be inferred that they also assumed the variables to be independent or equally correlated . The Problem Our notation is almost identical to that used by Block , Levine , and McNemar . Let p tests , xl , x2 , . . . , x ~ , be given to each of n ~ individuals ( k = 1 , 2 , . . . , g ) in each of g established groups . Assume both the p tests and the g groups to be fixed , i . e . , they are not random elements sampled from larger populations . This model , which fixes interest in the tests and groups under study , conforms to many experimental situations met with in practice . The totality of Np observed scores ( N = ~ = 1 n ~ ) can be classified according to the scheme at the top of the next page . An individual i in group k has the profile ( x ~ i ~ , • ° " , Xlik , { = 1 , • • • , nk individuals in group k 1 , , p variables 1 , , g groups . And the group profile for group k , say , is represented by ( 2 . t ~ , ~ . ~ k , " ' " , ~ . ~ ) . SAMUEL W , GREENHOUSE AND SEYMOUR GEISSER Tests Group Ind . x ~ . . . x ~ . . . x ~ 1 1 xm xz ~ x ~ p ~ 97 nj x , , ~ n x , ~ il x , ~ r ~ Means : Gr . 1 ~ . 1 ~ x . i ~ x - p ~ 1 XHk X ] ik Xlpk Xilk Zi ~ k Xi ~ k nk Xnklk 2¢nkik 3 ~ n ~ : pk Means : Gr . k ~ . 1 ~ ~ . i ~ x . r ~ g 1 Xllg xlig Xzpg ng X ~ ¢1¢ Xn¢ ig Xn cp¢ Means : Gr . g ~ . ig ~ . ¢ ~ ~ . pg ~ - . g Means : All Groups ~ . I . ~ . i . ~ . p - ~ . . . Assume that each individual profile is a random vector sampled from a p - variate normal distribution with an arbitrary variance - covariance matrix , ] F ] ~ P120 - 10 - 2 0 - 2 ' " " P2 ~ 0 - ~ - ~ 0 - 12 0 " 22 • " ' 0 - 2 ~ . • ° , • LpI ~ 0 " IO ' ~ P2 ~ 0 - 20 - ~ * • • 0 " ~ _ 2 I - - 0 - i ~ , 0 " 29 " " " 0 - ~ - J Also assume that the p variables have the same metric . This is necessary to give meaning to the question of whether the group profiles have the same 98 PSYCHOMETRIKA shape , and not because of any statistical considerations . This restriction results in no loss of generality if there already exists a large body of data on these p tests so that the standard deviations can be assumed known . For in this instance , equal metrics can be obtained by standardization of the p test scores . The questions that are most often asked in profile analysis are : ( i ) Are the groups on the same level , i . e . , do the groups arise from popu - lations having the same group means , namely , E ( 2 . . 1 ) = E ( 2 . . 2 ) . . . . . E ( ~ . . ~ ) , where E denotes the expectation ? ( if ) Do the groups have the same shape , i . e . , do the groups arise from populations having parallel group profiles ? Another question that may be asked of these data , although not too frequently in profile analysis , is whether the p tests have the same means . With regard to the question on shape , it becomes necessary to define a statistic which reflects the concept of equally shaped group profiles . In a larger sense , profiles having the same shape can be considered to be parallel curves . As Box [ 4 ] and Block , Levine , and MeNemar [ 2 ] point out , parallelism can be measured by the group - test interaction mean square . That is , if the curves are parallel , the group - test interaction should be zero and the mean square should not differ significantly from an appropriate error mean square . If , on the other hand , the curves have different shapes , the interaction mean square should be significantly greater than the error mean square . This is made clear by reference to two group profiles : : ~ . ~ 1 , 2 . ~ , . . . , : ~ . ~ and : ~ . 12 , X . 22 , " " " , X . ~ 2 • Denote the corresponding differences between group means for each test by dl , d2 , " - " , d ~ . If the two profiles are parallel it is clear that d ~ - - d2 = d ~ . . . . . d ~ . On the other hand , if d ~ = d2 = d . ~ . . . . . d ~ , then the two profiles must be parallel . Hence , a necessary and sufficient condition that the two group profiles possess the same shape is that d ~ = d ~ = d3 . . . . . d ~ . But the equality of these differences is exactly what is meant by no interaction between groups and tests , and the extent to which these differences are unequal corresponds to the existence of the group - test interaction . Therefore a test of the group - test interaction is also a test of whether group profiles have the same shape . Tests o / Significance In the Mixed Model If the p test scores have equal variances and are independent ( or , at SAMUEL W . GREENHOUSE AND SEYMOUR GEISSER 99 most , are equally correlated in pairs ) , so that I i : 0 " " O " ~ 0 = o2 " - - 0 0 " ' " 0 . 2 or Z1 = 0 . 1 . . . , p " , . then the given scheme constitutes the classical mixed model for g samples , with proportionate numbers of observations among the samples . The appro - pilate analysis of variance breakdown is shown in Table 1 . The analysis under either of the above assumptions on the covariance matrix follows along classicM lines . The F1 , F2 , and F3 statistics used to test hypotheses of homogeneity of test ( variable ) means , of group means ( level ) and the nonexistence of a group - test interaction ( equal shapes of group profiles ) , respectively , are exact . If , on the other hand , the validity of these two models is suspect , on the basis either of prior evidence or of a statistical test , the given F ratios are not distributed like the tabulated F distribution . In this situation where the covariance matrix is assumed to be arbitrary and given by % , Roy [ 13 ] , Rao [ 12 ] , and others have approached the problem through the multivariate analysis of variance . However , it is of interest , and possibly of considerable practical importance , to investigate the distribution of the computed F statistics . Tests of Significance ] or Arbitrary Covariance Matrix Geisser and Greenhouse [ 8 ] , in extending to several groups Box ' s work [ 5 , 6 ] rdative to one group , have shown that QI and Q , are each independent of Q ~ , and Q = is independent of Qa . They have also shown that , under the null hypothesis , E ( Q1 ) = A , say , E ( QO = ( g - 1 ) A , E ( Qa ) = ( N - g ) A , and E ( Q2 ) = ( g - 1 ) B , say , E ( Qa ) = ( Y - g ) B . Table 2 gives the mean square ( M . S . ) and the expectations of the mean TABLE i Analysis of Variance Source d . f . Sum of Squares F Tests Groups P - . i ) 2 p - i QI = N ( x . j . . . . j = l g . g - I Q2 = Plnk ( X . . k " x . . . ) 2 k = l Individuals N - g Q3 ( within Groups ) Group x Tests Indiv , x Tests ( within Groups ) ( p - l ) ( g - l ) ( p - l ) ( N - g ) g nk k = li = l g P Q4 llnk xjk k = lj = l - x . j - X . . k + ~ . . . ) 2 q5 = ~ ( Xijk - x . j k - k = li = lj = l xL . k - X . . k ) 2 F 1 = ( N - g ) QI q5 F2 = ( N - g ) Q2 ( g - l ) QS F3 = ( N - g ) Q ~ ~ g - l ) Q5 D ~ ~ 4 O O > Total Np - I k i j SAMUEL W . GREENItOUSE AND SEYMOUR GE1SSER 101 square ( E . M . S . ) for each of the five sources of variation in the analysis of variance . From the results presented in Tables 1 and 2 , it follows that each of the three F ratios , F1 , F ~ , and F3 , is a ratio of two independent mean squares TABLE 2 Analysis of Variance Source M . S . E . M . S . Tests ( p - l ) ' iQl ( p - l ) ' IA Groups ( g - l ) ' IQ2 B Individuals within Groups ( N - g ) ' IQ3 B Groups x Tests ( p - l ) ' l ( g - l ) ' iQ4 ( p - l ) ' iA Individuals x Tests ( p - l ) ' l ( N - g ) ' IQ5 ( p - l ) ' IA within Groups with the same expectations under the null hypothesis . Making use of the fact that each of the quadratic forms involved in the three F statistics is exactly distributed like a linear sum of independent X ~ variables with the same degrees of freedom ( theorem 6 . 1 , Box [ 5 , 6 ] ) , F ~ is approximately dis - tributed like F [ ( p - t ) e , ( p - 1 ) ( N - g ) e ] , / 73 is approximately distributed like F [ ( p - 1 ) ( g - 1 ) e , ( p - 1 ) ( N - g ) e ] , and F2 is exactly distributed like F ( g - - 1 , N - g ) , where 2 - = p ( ( Ttt - - ~ . . ) 2 / ( p _ 1 ) ( ~ E ~ , - - 2pX ~ , = . q - p2 ~ 2 . ) ; at , are the elements of the matrix Z , # , , is the mean of the diagonal terms , 5 , . is the mean of the tth row ( or tth column ) , and 5 is the grand mean . Thus , the effect of the arbitrary variance - covariance matrix , which must be the same from group to group , is to assess the significance of the F1 and Fs statistics in the ordinary tabulated F distribution but with reduced degrees of freedom . The F2 test on group means , it will be noted , remains unchanged from the standard F test since it results from a one - way analysis of variance with all observations having the same variance . The reduction in the degrees of freedom for this approximate test is a function of the elements of the population variance - covariance matrix . This is almost never known , and therefore E will have to be estimated from the sample variances and covariances . However , the effect of using an esti - mated E on the approximate F distributions involved is unknown . Hence , unless the variance - covariance matrix is estimated with a large number of degrees of freedom , use of the conservative test given below is suggested . 102 PSYCHOMETRIKA A Conservative Test The preceding approximate procedure requires some computations on the elements of a known variance - covariance matrix . In many profile problems , the number of tests may be as high as 50 if not more . This results in a 50 × 50 matrix , necessitating some laborious arithmetic . Furthermore , in almost all problems variances and covariances are unknown and the extent to which is changed by using sample estimates has not been investigated . As result it is useful to obtain a lower bound on e ; it can be shown that 1 ~ - - - p - - 1 This minimum value of e is independent of the elements of the variance - covariance matrix . With this new correction to the degrees of freedom , the F1 and F3 stati . stics are now judged for significance by entering the tabulated F distribution with 1 and N - g degrees of freedom and with g - 1 and N - g degrees of freedom respectively . These tests are called conservative since the minimum value of e gives the maximum reduction in degress of freedom . An Example Five groups of mothers , classified into their groups according to some external criteria , were given a maternal attitude questionnaire containing 23 scales . For purposes of this illustration , six of these scales have been selected . Thus p = 6 , g = 5 , and N = 128 . The group profiles and group means are given in Table 3 . The five variance - covariance matrices were first tested for homogeneity . The likelihood ratio test , the multivariate analogue of Bartlett ' s test for TABLE 3 Mean Profiles for Five Groups of Mothers on Selected Scales of a Maternal Attitude Questionnaire * No . of Scale Group Groups Mothers I 3 6 9 13 14 Mean A 59 17 . 02 10 . 97 13 . 24 ii . 47 9 . 80 15 . 44 12 . 99 B 13 17 . 92 13 . 85 17 . 23 14 . O0 12 . 23 17 . 38 15 . 44 C 15 18 . 87 11 . 60 14 . 13 8 . 93 8 . 27 17 . 73 13 . 26 D 32 16 . 75 14 . 47 15 . 41 11 . 78 9 . 91 15 . 94 14 . 04 E 9 18 . 33 10 . 78 13 . 89 14 . 44 12 . 11 18 . 78 14 . 72 All Groups 128 17 . 35 12 . 20 14 . 34 * We are indebted to Dr . Richard Q . Bell of Institute of Mental Health ~ fo ~ permitting example . 11 . 72 10 . 05 16 . 27 13 . 65 the Laboratory of Psychology 3 National us to use part of his data for this SAMUEL W . GREENHOUSE AND SEYMOUR GEISSER 103 homogeneity of variances , can be found in Box [ 3 , 4 ] . ( Kullbaek [ 11 ] derives an equivalent test through information theory . ) The test statistic is 5 M = Nlog ~ I S I - ~ n ~ log ~ [ S ~ I = 112 . 6565 . In the above I S I is the determinant of the pooled variance - covarianee matrix , and I S ~ t is the determinant of the sample variance - covariance matrix in the ith group . Now compute A1 - - 2p2 ~ 3P - - 1 ( ~ ) - ~ 1 N ) = . 17012 , 6 ( p 4 - 1 ) ( g 1 ) , : , n , and fl = ½p ( p + 1 ) ( g - 1 ) = 84 , and enter ( 1 - A1 ) M = 93 . 4 in the x 2 distribution with 84 degrees of freedom . Since the probability of getting this value of x 2 or larger is fairly high , the null hypothesis of equal variance - covariance matrices is not rejected . An estimate of the matrix ~ is given by the pooled variance - covariance matrix S = 3 . 100 . 101 - - . 279 - - . 083 - - . 009 1 . 557 - . 101 5 . 780 1 . 013 - - . 114 - - 1 . 014 . 039 - - . 279 1 . 013 5 . 560 1 . 039 1 . 366 - - . 169 - - . 083 - - . 114 1 . 039 5 . 600 3 . 080 . 258 - - . 009 - - 1 . 014 1 . 366 3 . 080 6 . 820 . 222 1 . 557 . 039 - - . 169 . 258 . 222 5 . 170 . Consider now whether the hypothesis of equal variances and equal covariances is consistent with S . The best estimate of the uniform variance - covariance matrix under this hypothesis is given by I 5 . 3888 . 467 . . . . 4671 k _ . 467 . 467 - - . 5 . 338 - 1 where the diagonal element is an average of the 6 variances in S and the covariance is an average of the 15 [ ½p ( p - 1 ) ] covariances in S . The reason for testing this hypothesis is that if $ 1 is consistent with the data then classical analysis of variance procedures are applicable . The test used is again a likelihood ratio test , also given by Box [ 3 , 4 ] . The test statistic is 104 PSYCHOMETRIKA t S [ 10 , 806 . 42 M = - ( N - g ) log , I S ~ [ = - 123 la ~ 40A 9 = 81 . 956 , where ( N - g ) - - 123 is the degrees of freedom entering into the computation of any element in S or $ 1 • Now compute p ( p + 1 ) 2 ( 2p - 3 ) A1 = 6 ( N - g ) ( p . - - 1 ) ( p ~ q - p - 4 ) = . 01887 , and ] 1 - - ( p2 - b p - - 4 ) / 2 = 19 , and enter ( 1 - A , ) M = 80 . 4 in the x ~ tables with ] ~ = 19 degrees of freedom . The probability of this result is well below . 001 ; the hypothesis of equal variances and equal covariances must be rejected . The analysis of variance yields the numerical results of Table 4 . TABLE 4 Analysis of Variance Source d . f . SS M . S . F Tests 5 5092 . 56 Groups 4 509 . 12 127 . 28 Individuals within Groups 123 948 . 41 7 . 71 Groups x Tests 20 644 . 74 32 . 24 Individuals x Tests 615 2991 . O4 4 . 86 within Groups F 2 = 16 . 5i F 3 = 6 . 63 Of primary interest is the test of the homogeneity of group profiles , which is a test for the existence of the group - test interaction . For this purpose enter the F3 value in the F table with ( g - - 1 ) ( p - - 1 ) e and ( N - g ) ( p - 1 ) e , or with 20e and 615e , degrees of freedom . From the previous formula , and the elements in the S matrix , e is estimated to be . 8194 . Therefore the effective degrees of freedom are 16 and 503 . The observed F3 = 6 . 63 is greater than the . 001 point for F with 15 and 120 degrees of freedom . One therefore rejects the hypothesis of no interaction and concludes that the mean profiles differ in shape from group to group . The conservative test , which of course does not require the computation of e , would enter F3 = 6 . 63 in the F tables with g - - 1 = 4 and N - - g = 123 degrees of freedom . The . 001 point for F with these degrees of freedom is 4 . 95 . In this case , therefore , the conservative test yields the same conclusion SAMUEL W . GREENHOUSE AND SEYMOUR GEISSER 105 as the approximate test , namely , the probability that the group profiles differ in shape due to chance is less than . 001 . The groups clearly differ with regard to levels as can be seen from the very large F ~ value . Other Procedures The foregoing procedures present approximate and conservative tests of significance resulting from the analysis of variance utilizing readily available tables of the F distribution . As mentioned earlier there are available exact procedures in the multivariate analysis of variance . These procedures lead to exact tests of the general hypothesis in multivariate analysis of the equality of vector means among g populations and of the existence of the group - item or group - test interaction of interest in profile analysis . However , all of these procedures require laborious computations involving the inversion of ( p × p ) matrices ( p equal to the number of tests or items ) and the computation of latent roots or the evaluation of determinants . A further complication is the lack of tabled probability values for the appropriate test statistics . Recently , however , distribution tables have appeared relating to the approach of multivariate analysis initially taken by Roy [ 13 ] . Under this view , the distribution of the test statistic is dependent upon the distribution of the maximum characteristic root of certain matrices . The most comprehensive tables or charts thus far available are those given by Heck [ 9 ] . Heck , inciden - tally , specifically considers the problem of profile analysis . The ease for two groups will be developed in some detail to illustrate the principles involved and then the extension to g groups as given by Heek will be summarized briefly . The former situation leads to Hotelling ' s general - ized T 2 statistic and is implied in the literature on multivariate analysis . In the previous notation , x , ; , is an observation on item . i for individual i in group k , and 2 . ; , is the mean of character j in group k . The range of subscripts here is k = 1 , 2 ; j = 1 , 2 , • • . , p ; and i = 1 , 2 , • • • , n , . As before , assume that the random vector x ~ c , ) = ( x , k , . . . , x ~ , ) is N ( ~ c , ) , ~ ) , that is , the p variables have a multivariate normal distribution in population k with mean vector t ~ = ( ~ tk , " ' " , ~ ) and varianee - eovarianee matrix which is common to the g populations . The hypothesis to be tested for g = 2is Transform the p variates in x to p - - 1 variates in y as follows ( seo [ 1 ] , pp . 110 - 112 and [ 12 ] , pp . 239 - 244 ) : LC ~ , - 1 , I " • • C ~ , - I , ~ , _ 1 106 PSYCtIOMETRIKA such that ~ - - ' ~ : = : c ~ = O . The matrix C , subject to the restriction , can be perfectly arbitrary . For example , o C = 0 - 1 . . . 0 0 . . . . subtracts x2 , • , ' , x ~ from the first variate resulting in y : = x ~ - - x ~ , y ~ = x : - - x . ~ , - - . , y ~ _ : = x ~ - - x ~ . Or , i 1 1 . . . . l i : ] C = 1 - 1 p - I - - I . . . . 1 - - 1 - - 1 - - 1 . . . p - - 1 which in effect subtracts from each of the p variates their mean 2 = ( l / p ) ~ _ : x ~ resulting in y : = x : - - 2 , . . . , y ~ _ : = x ~ _ : - - £ Using the first transformation above , the vector y ~ ) = ( y ~ , - - - , Yc ~ - : ) k ) is multivariate normal with mean v ~ ) = ( ~ : ~ , " ' " , ~ c ~ - : ) k ) , v ; ~ = # ~ - ~ ( ; + : ) ~ , and variance - covariance matrix CF , C ' , where the prime denotes the transpose of ~ matrix . After transforming the p x - variates into the p - 1 y - vari ~ tes for each of the n = n ~ - t - n2 individuals , the group means in the y ' s are Y . ll ~ Y . 21 , " * " , y . ( p - - 1 ) l and the pooled sample varianee - covariance matrix in the y ' s , W = [ w , ~ ] , where 1 w , . - - ( Y , , : - - ~ . r , ) ( Y , 81 - - ~ . , : ) n I - ] - n 2 - - 2 i = 1 + ( Y , , , - - ~ . ~ 2 ) ( Y , , 2 - - ~ . , 2 ) , i = 1 and r , s = 1 , 2 , . - . , p - 1 . It is easily seen that the null hypothesis in the x ' s is equivalent to the following hypothesis in the y ' s : ~ . ~ = ~ - ~ ( ; + ~ ) ~ = v ~ 2 = g ~ 2 - - ~ ( ; + : ) 2 , j = 1 , 2 , . . . , ( p - - 1 ) ; i . e . , ~ ( : ) = 7 ( 2 ) • But this is the general hypothesis of multivariate analysis of the equality of mean vectors for two groups and it is well known that the appropriate statistic to test this hypothesis is T 2 . Therefore SAMUEL W . GREENHOUSE AND SEYMOUR GEISSER 107 T 2 _ nln2 ( ( Ic1 ) - 9 ( 2 ) ) ' W - 1 ( ~ 1 ) - 9 ( 2 ) ) ~ , l - ~ " n2 p - I ~ - I _ nln2 ~ . . ~ . w , 8 ( ~ . r 1 _ ~ . ~ = ) ( ~ . , i _ ~ . , = ) , nl " ~ ~ 2 r 8 where w " is element rs in the inverse matrix W - k This statistic has the T 2 distribution with n ~ q - n ~ _ - - 2 degrees of freedom . To test the hypothesis at level a , enter T = ( nl + n ~ - p ) ( n ~ + n = - 2 ) ( p - 1 ) in the F table with p - 1 and n ~ - k n ~ - p degrees of freedom . If T ' ( nl " - k n , - - p ) > F . ( p - - 1 , ni - kn2 - - p ) ( n I " - ~ n 2 - - ~ ) ( p - - 1 ) reiect the hypothesis ; otherwise accept . The general case for g populations , of which the above is a special case , is given by Heck [ 9 ] . The extension is obvious . From the g by p - 1 table of group means , one computes the between groups sums of squares and cross products to obtain the elements of the matrix B , say . Thus element rs of this matrix is b , = - - = - k = l / z = l where r , s = 1 , 2 , . . . , ( p - 1 ) . For the error matrix W , compute similarly the sums of products , so that k = l i = I k = l i k = l In the above formula , ~ . , ~ = n [ ~ ~ ? ~ = ~ y ~ , ~ . The various test statistics proposed are proportional to some function of the product matrix BW - ~ . In the literature on multivariate analysis , there have been three ap - proaches to the distribution problem . Wilks [ 17 ] , starting with the likelihood ratio criterion , derived the test statistic ] I " l - BW - ~ ] - ~ , which is obviously equal to the inverse of the product of the characteristic roots of ( 1 Jr - BW - ~ ) , I being the identity matrix . Hotelling [ 10 ] has proposed the distribution of tr BW - ~ or of the sum of the characteristic roots of BW - ~ . Roy [ 13 ] has proposed the consideration of the distribution of the maximum characteristic root of BW - ~ . For a further discussion of these three points of view consult Anderson ( [ 1 ] , pp . 221 - 224 ) . There are no probability tables available for the first two test statistics although the exact cumulative distribution of the determinantal statistic is given by an infinite series of x2 ' s , the first term of which , for any reasonable N , gives an excellent approximation to the whole 110 PSYCHOMETRIKA rive test provides a procedure which is more than " rough and ready " and yet saves considerable time since it does not require a matrix inversion nor even the computation of a covariance matrix . This is particularly true when p , the number of variables , is large and the number of samples is greater than two . The question of electronic computers is another matter . Given the availability of a classical analysis of variance program and tJae availability of a combined program to carry out the multivariate analysis of variance involving the between samples variance - eovariance matrix , the inverse of the error variance - covariance matrix , and the extraction of the maximum latent root of the product of the two matrices , it is very likely that the former would require less machine time . However , the difference is probably of no practical importance and the exact procedure should be used . A more fundamental question relates to a comparison of the two exact tests involved . Are the multivariate analysis of variance procedures depending upon the distribution of BW - I more powerful against all alternatives than the distribution of the ratio of linear sums of x 2 variatcs ? It is not clear that this is so , particularly with regard to the analysis of profile shapes where the former procedures must reduce the dimensiona ~ ty of the random vector . If one does decide to use the F tests in an analysis , the following series of steps are suggested . After finding the traditional analysis of variance table , first test the appropriate observed F value in the F distribution with full , i . e . , unredueed , degrees of freedom . For Fa , for example , this would beFwith ( p - - 1 ) ( g - 1 ) and ( p - 1 ) ( N - - g ) degrees of freedom . If Fa is smaller than the a critical point , one can stop here , for the null hypothesis will not be rejected with further manipulation of degrees of freedom . If the observed F is significant , then one proceeds to the conservative test where the degrees of freedom are reduced by a factor equal to 1 / ( p - - 1 ) . For F8 , the appropriate F distribution is F ( g - - 1 , N - - g ) . If this test leads to significance at the a level , one can at this point reject the null hypothesis without further testing . However if the conservative test is not significant then it is suggested that the e be estimated from the variance - covariance matrix and the approximate test be carried out . Number of Individuals Less than the Number o ] Variables As indicated in the introduction , in the case of one group , if ( n - - 1 ) < p , or in the case of g groups , if ( N - g ) < p , it is not possible to apply multi - variate procedures . The reason of course is that the error matrix , W , is singular . Such situations are not too uncommon , especially in research in clinical psychology and psychiatry . Clearly the approximate F tests presented are not applicable either since the reduction in degrees of freedom is dependent upon the elements of a singular matrix . However , the conservative test can be applied . SAMUEL W . GREENHOUSE AND SEYMOUR GEISSER 111 Unequal Variance - Covariance Matrices Perhaps one of the most important uses of the conservative test is in the situation where one cannot assume the equality of the unknown variance - covariance matrices in the p - variate normal populations being sampled . For this case , there are no exact procedures available . It will be noted that this case , p = 1 and g = 2 , reduces to the Fisher - Behrens problem . Here , in order for the F statistics to be unbiased , it is necessary to work with equal sample sizes in the groups , i . e . , nl . . . . . ng = n . Therefore , N = Zn , = gn . It can again be shown that the respective numerator and denominator quadratic forms entering into F ~ , F2 , and F3 are independent and have the same expectations . Now , however , when an F distribution is used to approximate these F statistics ( see [ 5 ] , theorem 6 . 1 ) , it turns out that there are different factors reducing the numerator and denominator degrees of freedom , and these in turn differ for the three F statistics . Here again it can be shown that these e ' s have lower limits which when applied to the appropriate degrees of freedom result in a conservative test for assessing the significance of F1 , F ~ , and F . ~ by entering these in the F distribution with 1 and n - - 1 degrees of freedom . It is of interest that the F2 test , when p = 1 and g - 2 , is a conservative test for the various approximate solutions given to the Fisher - Behrens problem of testing the equality of two means with unequal variances ( e . g . , [ 15 ] , p . 295 ) . REFERENCES [ 1 ] Anderson , T . W . Introduction to multivariate statistical analysis . New York : Wiley , 1958 . [ 2 ] Block , J . , Levine , L . , and McNemar , Q . Testing for the existence of psychometric patterns . J . abnorm , soc . Psychol . , 1951 , 45 , 356 - 359 . [ 3 ] Box , G . E . P . A general distribution theory for a class of likelihood criteria . Biomet - rika , 1949 , 36 , 317 - 346 . [ 4 ] Box , G . E . P . Problems in the a ~ nalysis of growth and wear curves . Biometrics , 1950 , 5 , 362 - 389 . [ 5 ] Box , G . E . P . Some theorems on quadratic forms applied in the study of analysis of variance problems : I . Effect of inequality of variance in the one - way classification . Ann . math . Statist . , 1954 , 25 , 290 - 302 . [ 6 ] Box , G . E . P . Some theorems on quadratic forms applied in the study of analysis of variance problems : II . Effects of inequality of variance and of correlation between errors in the two - way classification . Ann . math . Statist . , 1954 , 2S , 484 - 498 . [ 7 ] Eisenhart , C . The assumptions underlying the analysis of variance . Biometrics , 1947 , 3 , 1 - 21 . [ 8 ] Geisser , S . and Greenhouse , S . W . An extension of Box ' s results on the use of the F distribution in multivariate analysis . Anu . math . Statist . , 1958 , 29 , 885 - 891 . [ 9 ] Heek ~ D . L . Some uses of the distribution of the largest root in multivariate analysis . Inst . Statist . Univ . North Carolina ~ Mimco . Ser . No . 194 , 1958 . [ 10 ] Hotelling , H . A generalized T test and measure of multivariate dispersion . Proceedings of the second Berkeley symposium on mathematical statistics and probability . Berkeley : Univ . Calif . Press , 1951 , 23 - 42 . 112 PSYCHOMETRIKA [ 11 ] Kullback , S . An application of information theory to multivariate analysis , II . Ann . math . Statist . , 1956 , 27 , 122 - 146 . [ 12 ] Rao , C . R . Advanced statistical methods in bwmetric research . New York : Wiley , 1952 . [ 13 ] Roy , S . N . On a heuristic method of test construction and its use in multivariate analysis . Ann . math . Statist . , 1953 , 24 , 220 - 238 . [ 14 ] Scheff ~ , H . A " mixed model " for the analysis of variance . Ann . math . Statist . , 1956 , 27 , 23 - 36 . [ 15 ] Welch , B . L . Note on Mrs . Aspin ' s Tables and on certain approximations to the tabled functions . Biometrika , 1949 , 35 , 293 - 296 . [ 16 ] Wilk , M . B . and Kempthorne , 0 . Fixed , mixed , and random models . J . Amer . statist . Ass . , 1955 , 50 , 1144 - 1167 . [ 17 ] Wilks , S . S . Certain generalizations in the analysis of variance . Biometrika , 1932 , 24 , 471 - 494 . Manuscript received 8 / 21 / 58 ReUsed manuscript received 12 / 1 / 58