The Small - World of Human Language Ramon Ferrer i Cancho (cid:3) and Ricard V . Sol(cid:19)e (cid:3) ; + (cid:3) Complex Systems Research Group , FEN - UPC , Campus Nord , B4 - B5 , Barcelona 08034 SPAIN + Santa Fe Institute , 1399 Hyde Park Road , New Mexico 87501 , USA Words in human language interact within sentences in non - random ways , and allow humans to construct an astronomic variety of sentences from a limited number of discrete units . This construc - tion process is extremely fast and robust . The coocurrence of words within sentences re(cid:13)ect language organization in a subttle manner which can be described in terms of a graph of word interactions . Here we show that such graph displays two important features recently found in a disparate number of complex systems : ( a ) The so called small world e(cid:11)ect . In particular , the average distance between two words d ( i . e . the average minimum number of jumps to be made from an arbitrary word to another ) is shown to be d (cid:25) 2 (cid:0) 3 , in spite that the human brain can store many thousands . ( b ) A scale - free distribution of degrees . The known dramatic e(cid:11)ects of disconnecting the most connected vertices in such networks can be identi(cid:12)ed in some language disorders . These observations suggest some unexpected features of language organization that might re(cid:13)ect the evolutionary and social history of lexicons and the origins of their (cid:13)exibility and combinatorial nature . Keywords : Small - world , Scaling , Lexical networks , Human language I . INTRODUCTION The emergence of human language is one of the ma - jor transitions in evolution ( Smith & Sz(cid:127)athm(cid:19)ary , 1997 ) . Living humans posses a unique symbolic mind capable of language which is not shared by any other species . Over two million years of hominid evolution , a coevo - lutionary exchange between languages and brains took place ( Deacon , 1997 ) . This process involved the ( pos - sible sudden ) transition from non - syntactic to syntactic communication ( Nowak & Krakauer , 1999 ; Nowak et al . , 2000 ) . Human language allows the construction of a vir - tually in(cid:12)nite range of combinations from a limited set of basic units . The process of sentence generation is aston - ishingly rapid and robust and indicates that we are able to rapidly gather words to form sentences in a highly reliable fashion . A complete theory of language requires a theoretical understanding of its implicit statistical regularities . The best known of them is the Zipf’s law , which stays that the frequency of words decays as a power function of its rank ( Zipf , 1972 ) . However , in spite of its relevance and universality ( Balasubrahmanyan & Naranan , 1996 ) , such law can be obtained from a variety of mechanisms ( Nico - lis , 1991 ; Simon , 1955 ; Li , 1992 ) and does not provide deep insight about the organization of language . The reason is that information transmission is organized into sentences , made by words in interaction . Human brains store lexicons usually formed by thou - sands of words . Estimates are in the range 10 4 (cid:0) 10 5 words ( Romaine , 1992 ; Miller & Gildea , 1987 ) . Besides , the contents of the lexicon of individuals of the same language vary depending on many factors such as age , geographic location , social context , education and pro - fession . W L FIG . 1 . A possible pattern of wiring in (cid:10) L . Black nodes are common words and white nodes are rare words . Two words are linked if they cooccur signi(cid:12)cantly . Being the primary goal of a lexicon to achieve a sucess - ful communication , there must exist a common lexi - con for sucessful basic communication between speakers , hereafter named a kernel lexicon , to surmount the limi - tations imposed by the factors mentioned above . Obvi - ously , the better candidates to form this lexicon are the 1 most frequent words . Actually , the analysis of multi - speaker corpora shows two di(cid:11)erent regimes dividing words into basic and specialized words ( Ferrer & Sol(cid:19)e , 2000 ) . Words interact in many ways . Some words cooccur with certain words with higher probability than with oth - ers and coocurrence is not of trivial nature , i . e . it is not a straigtforward implication of the known frequency dis - tribution of words . If a text is scrambled the frequency distribution is mantained but its content will not make sense . In this paper we show that the coocurrence of words in sentences relies on the network structure of the lexicon whose properties are analyzed in depth . As we will show in this paper , human language can be described in terms of a graph of word interactions . This graph has some un - expected properties ( shared by other biologic and tech - nologic networks ( Strogatz , 2001 ) ) that might underly its diversity and (cid:13)exibility and open new questions about its origins and organization . II . GRAPH PROPERTIES OF HUMAN LANGUAGE Words cooccur in sentences . Many coocurrences are due to syntactical relationships between words , e . g . head - modi(cid:12)er or dependency relationships ( Mel(cid:20)cuck , 1989 ) . Some others are due to stereotiped expressions or collocations that work together ( e . g . take it esasy , New York ) . We will de(cid:12)ne links as signi(cid:12)cative cooc - currences between words . We do not seek to provide a detailed list of the origins and linguistic interpretation of such signi(cid:12)cative cooccurrences but in showing that they exist and can be captured using quantitative measures of correlation regardless of their nature . A (cid:12)rst approach for estimating the network of the lexicon is to consider that there is a link between every pair of neighbouring words ( at the risk of capturing spurious correlations ) . Let us consider the graph of human language , (cid:10) L , as de(cid:12)ned by (cid:10) L = ( W L ; E L ) , where W L = f w i g ; ( i = 1 ; : : : ; N L ) is the set of N L words and E L = ff w i ; w j gg is the set of edges / connections between words . Here (cid:24) ij = f w i ; w j g indicates that there is an edge ( and thus a link ) between words w i and w j . Two connected words are adjacent and the degree of a given word is the num - ber of edges that connect it with other words . Figure 1 shows how such a network would look like . Recent research on a number biological , social and technological graphs revealed that they share a com - mon feature : the so called small world ( SW ) property ( Watts & Strogatz , 1998 ; Watts , 1999 ; Newman , 2000 ) . Small world graphs have a number of surprising proper - ties that make them specially relevant to understand how interactions among individuals , metabolites or species lead to the robustness and homeostasis observed in na - ture ( Watts & Strogatz , 1998 ) . The SW pattern can be detected from the analysis of two basic statistical properties : the so called clustering coe(cid:14)cient C v and the path length d . Let us consider the set of links (cid:24) ij ( i ; j = 1 ; : : : ; N L ) , where (cid:24) ij = 1 if a link exists and zero otherwise and that the average number of links per word is (cid:22) k . Let us indicate by (cid:0) i = f s i j (cid:24) ij = 1 g the set of nearest neighbors of a word w i 2 W L . The clustering coe(cid:14)cient for this word is de(cid:12)ned as the number of con - nections between the words w j 2 (cid:0) i . By de(cid:12)ning L i = N L X j = 1 (cid:24) ij 2 4 X k 2 (cid:0) i ; j < k (cid:24) jk 3 5 ( 1 ) we have : c v ( i ) = L i (cid:0) j (cid:0) i j 2 (cid:1) so that the clustering coe(cid:14)cient is the average over W L : C v = 1 N L N L X i = 1 c v ( i ) ( 2 ) and measures the average fraction of pairs of neighbors of a node that are also neighbors of each other . The second measure is easily de(cid:12)ned . Given two words w i ; w j 2 W L , let d min ( i ; j ) the minimum path length con - necting these two words in (cid:10) L . The average path length of a word will be de(cid:12)ned as d v ( i ) = 1 N L N L X j = 1 d min ( i ; j ) ( 3 ) and thus the average path length d will be : d = 1 N L N L X i = 1 d v ( i ) ( 4 ) Graphs with Small World structure are highly clus - tered but d will be small . Random graphs ( where nodes are randomly wired ) are not clustered and have also short d ( Watts , 1999 ) . At the other extreme , regular lattices with only nearest - neighbor connections among units , are typically clustered and exhibit long paths . It has been shown , however , that a regular lattice can be transformed into a SW if a small fraction of nodes are rewired to ran - domly chosen nodes . Thus a small degree of disorder generates short paths ( as in the random case ) but retain - ing the regular pattern ( Watts and Strogatz , 1998 ) . For random graphs that C rand v (cid:25) (cid:22) k = N . For SW graphs , d is close to the one expected from random graphs , d rand , with the same (cid:22) k and C v (cid:29) C randv . These two conditions are taken as the standard de(cid:12)nition of SW . SW graphs have been shown to be present in both social and bi - ological networks ( Jeong et al . , 2000 ; Montoya & Sol(cid:19)e , 2 2000 ; Sol(cid:19)e & Montoya , 2000 ; Newman , 2000 ; Strogatz , 2001 ) . Besides , some of these networks also exhibit scal - ing in their degree distribution . In other words , the prob - ability P ( k ) of having a node with degree k scales as P ( k ) (cid:25) k (cid:0) (cid:13) . We have found that the graph of human language displays similar properties . This second prop - erty has been shown to be related with an extremely high stability against perturbations directed to randomly cho - sen nodes and a high fragility when perturbations are di - rected to highly connected ones ( Albert et al . , 2000 ) . As we will show here , (cid:10) L exhibits both SW structure and a power laws in P ( k ) . III . LINK COLLECTION The most correlated words in a sentence are the closest . A decision must be taken about the maximum distance considered for forming links . If the distance is long , the risk of capturing spurious coocurrences increases . If the distance is too short , certain strong coocurrences can be sistematically not taken into account . We decided the maximum distance according to the minimum distance at which most of the coocurrences are likely to happen : (cid:15) Many coocurrences take place at distance 1 , e . g . red (cid:13)owers ( adjective - noun ) , the / this house ( article / determiner - noun ) , stay here ( verb - adverb ) , getting dark ( verb - adjective ) , can see ( modal - verb ) , : : : (cid:15) Many coocurrences take place at distance 2 , e . g . hit the ball ( verb object ) , Mary usually cries ( subject - verb ) , table of wood ( noun - noun through a prepo - sitional phrase ) , live in Boston ( verb - noun ) , : : : Long distance correlations , i . e . at distance greater than two , have been shown to take place in human sen - tences ( Chomsky , 1957 ) . Here we stop our seek at dis - tance two . The reason is fourfold : (cid:15) Considering whatever distance requires an auto - matic procedure for acomplishing the task of cap - turing the relevant links . We do not know of any computational technique that succesfully performs this task for a general case . From the practical point of view , a context of two words is considered to be the lowest distance at which most of the im - provement of disambiguation methods is achieved ( Kaplan , 1955 ; Choueka & Lusignan , 1985 ) . (cid:15) Our method fails to capture the exact relations happening in a particular sentence but captures ( al - most ) every possible type of links . The type of the link is determined by the syntactic categories / roles of the intervening words . Very few types of links ( if any ) are observed at distance greater than 2 and not at lower distances . (cid:15) We are not interested in all the relations happening in a particular sentence . Our goal is to capture as much links as possible through an automatic proce - dure . If the corpus is big enough , the macroscopic properties of the network should emerge . (cid:15) Being syntactic dependencies non - crossing ( Hud - son , 1984 ; Mel(cid:20)cuck , 1989 ) , a long distance syntactic link implies the existence of lower distance syntac - tic links . In contrast , a short distance link do not imply a long - distance link . The technique can be improved by choosing only the pairs of consecutive words whose mutual cooccurrence is larger than the one expected from their chance . This can be measured with the condition p ij > p i p j which de(cid:12)nes the presence of real correlations beyond the ex - pected from a random ordering of words . If a pair of words cooccurs less times than what it would be expected when independence between such words is assumed , the pair is considered to be spurious . Graphs in which this condition is used will be called restricted ( unrestricted otherwise ) . IV . SCALING AND SW PATTERNS The networks resulting from the basic and improved methods will be called , respectively , the unrestricted word network ( UWN ) and the restricted word net - work ( RWN ) . They have N ( UWN ) = 478 ; 773 and N ( RWN ) = 460 ; 902 nodes with E ( UWN ) = 1 : 77 (cid:1) 10 7 and E ( RWN ) = 1 : 61 (cid:1) 10 7 edges , respectively . With av - erage connectivities of (cid:22) k uwn = 74 ; 2 and (cid:22) k rwn = 70 ; 13 , their clustering and path lengths are indicated in Table 1 . Figure 2 shows the distribution of degrees of both the UWN and RWN obtained after processing about 3 = 4 of the million words of the British National Corpus ( about 70 million words ) . The obvious limitations of our meth - ods are overcome by the use of a big amount of data . The distribution of connectivies of UWN and RWN decays with two di(cid:11)erent average exponents each , (cid:13) 1 = (cid:0) 1 : 50 for the (cid:12)rst regime and (cid:13) 2 = (cid:0) 2 : 70 for the second regime , respectively . The exponent in the second regime is simi - lar to that of the so - called Barab(cid:19)asi - Albert ( BA ) model ( (cid:13) BA = (cid:0) 3 ) ( Barab(cid:19)asi & Albert , 1999 ) . The BA model is an independent rediscovery of earlier work by Herbert Si - mon on systems with skewed distributions ( Simon , 1955 ) . Using the rule of preferential attachment , they showed that scale - free distributions are obtained . The rule sim - ply assumes that new nodes in the growing network are preferentially attached to an existing node with a prob - ability proportional to the degree of such node . Furthermore , word networks have small - word features . The average minimum distance between vertices is below 3 3 ( 2 : 63 for the UWN and 2 : 67 for the RWN ) , so reaching whatever vertex involves less than three jumps on av - erage . This is signi(cid:12)cantly important , since the network contains about 4 : 7 (cid:1) 10 5 di(cid:11)erent words . Clustering ( 0 : 687 for the UWN and 0 : 437 for the RWN ) is far from the ran - domness expectation ( 1 : 55 (cid:1) 10 (cid:0) 4 for both the UWN and the RWN ) in both cases . As far as we know , this is the (cid:12)rst time that such a statistically signi(cid:12)cant property has been reported about the organization of human language . In spite of the huge amount of words that can be stored by a given human , whatever word in the lexicon can be reached with less than three intermediate words on average . If a word is reached during communication , jumping to another word requires very few steps . Speed during speech production is important and can be more easily achieved if interven - ing words are close each other in the underlying structure used for the construcion of sentences . On the other hand , richness is another quality of a powerful communication . Although words are preferably choosen from the kernel lexicon , external words are at a short distance , so rich communication based on the word network can be at - tained with little increase in e(cid:11)ort . 10 0 10 1 10 2 10 3 10 4 10 5 10 6 Degree k 10 −10 10 −9 10 −8 10 −7 10 −6 10 −5 10 −4 10 −3 10 −2 10 −1 10 0 P ( k ) Restricted graph Unrestricted graph 10 −8 10 −6 10 −4 10 −2 10 0 10 0 10 2 10 4 10 6 −1 . 50 −2 . 70 0 . 80 0 . 66 f k FIG . 2 . Connectivity distribution for the unrestricted word network ( circles ) and the restricted word network ( squares ) . Points are grouped by powers of two . Inset : average degree as a function of frequency . Degree increases as a function with frequency with exponent 0 . 80 for the (cid:12)rst domain and 0 . 66 for the second one . It is well known that the more frequent a word , the more available it is for production ( Brown & McNeil , 1966 ; Kempen & Huijbers , 1983 ) and comprehension ( Forster & Chambers , 1973 ; Scarborough et al . , 1977 ) processes . This phenomenon is known as the frequency ( referring to the whole individual’s experience ) or re - cency ( referring to the recent individual’s experience ) ef - fect ( Akmajian et al . , 1995 ) . This phenomenon will serve us to show that preferential attachment is very likely to be shaping the scale - free distribution of degrees in a way similar to the BA model . For the most frequent words , k / f 0 : 66 where k is the degree and f is the frequency of the word . We can then recast the frequency e(cid:11)ect in terms of the degree as the higher the degree of a word , the higher its availability . In other words , links including highly con - nected words are preferred . Inset in Figure 2 shows the complete relationship between f and k in RWN . 10 3 10 4 k 10 −4 10 −3 10 −2 10 −1 10 0 P ( k ) 1 . 51 . 752 0 1000 2000 3000 4000 5000 6000 k 0 . 000 0 . 001 0 . 002 0 . 003 P ( k ) −3 . 07 FIG . 3 . Connectivity distribution for the kernel word net - work , formed by the 5000 most connected vertices in RWN . Inset : power law tail for k > k calculated by grouping in powers of 1 : 5 , 1 : 75 and 2 . The exponent of the power tail is (cid:13) KWN (cid:25) (cid:0) 3 , suggesting that preferential attachment is at play . The exponent of UWN and RWN is closer to (cid:13) BA = (cid:0) 3 in the second regime of the distribution which is where the frequency e(cid:11)ect makes much more sense . The kernel lexicon contains words common to the whole community of speakers . Beyond the kernel , a certain word is un - known for one speaker and familiar for the another . The recency e(cid:11)ect then cannot be applied for all the individu - als contributing to shape the underlying lexicon network . It is thus expected that the network formed exclusively by the interaction of kernel words , hereafter referred as the kernel word network ( KWN ) , better agrees with the predictions that can be performed when preferential at - tachment is at play . Figure 3 shows the log - normal ap - pearance of the connectivity distribution . The power tail has exponent (cid:13) KWN (cid:25) (cid:0) 3 , consistent with the Barab(cid:19)asi - Albert model ( Barab(cid:19)asi & Albert , 1999 ) and the di(cid:11)er - ences respect to it require special attention . It is im - portant to notice that the kernel lexicon is a versatile subset of the repertoire of individual speakers . A few thousand words must be able to say everything or almost everything . Even when lexicons become very small , i . e . pidgin languages whose lexicons do not usually exceed about 1 , 000 words ( Romaine , 1992 ) , it has been pointed out they allow to say everything that can be said in a complex lexicon ( e . g . English ) at the expense of high redundancy ( recurring to circumlocution ) . The average 4 connectivity in the kernel is (cid:22) k = 1219 . A (cid:12)rst conse - quence is that words with low connectivity must be rare . Having rather useless words in this critical subset is an enormous waste . Once connected words become frequent in the distribution , the network organizes in a scale - free way . We believe that the scale - freeness is responsible for the ability - to - say - everything of the kernel . A non - trivial network is needed since every word on average is con - nected to 24 % of the rest of the kernel words . V . DISCUSSION We have shown that the graph connecting words in lan - guage exhibits the same statistical features than other complex networks . The short distance between words arising from the SW structure strongly suggests that language evolution might have involved the selection of a given graph of connections between words . Future work should address this problem theoretically , perhaps using an evolutionary language game model ( Nowak & Krakauer , 1999 ; Nowak et al . , 2000 ) where a pay - o(cid:11) as - sociated to the graph structure is introduced . Concern - ing the scaling in P ( k ) and the observed exponents , this pattern also calls for an evolutionary explanation . The word network is the result of a growth process in which new words are added and are likely to be linked to highly connected existing words . If the small - world features derive from optimal navi - gation needs , two predictions can be formulated . First , the existence of words whose main purpose is to speed - up navigation . Second , deriving from the (cid:12)rst , the existence of brain disorders characterized by navigation de(cid:12)cits in which such words are involved . The best candidates for answering the (cid:12)rst question are the so - called particles , a subset of the function words ( e . g . articles , prepositions , conjunctions ) formed by the most frequent among them ( e . g . ant , the , of , : : : ) 1 . These words are characterized by a very low or zero semantic content . Although they are supposed to contribute to the sentence structure , they are not generally crucial for sentence understanding . A compelling test of this statement is that particles are the (cid:12)rst words to be suppressed in telegraphic speech ( Ak - majian et al . , 1995 ) . The answer to the second prediction is agrammatism , a kind of aphasia in which speech is non(cid:13)uent , labored , halting and lacking of function words ( and thus of par - ticles ) . Agrammatism is the only syndrome in which function words are particularly ommited ( Caplan , 1987 ) . Function words are the most connected ones . We suggest that such halts and lack of (cid:13)uency are due to fragility as - sociated to removal of highly connected words . Although scale - free networks are very tolerant to random removal of vertices , if deletion is directed to the most connected vertices the network gets broken into pieces ( Albert et al . , 2000 ) . It is known that function words omission is often ac - companied by substitutions of such words . Patients in which substitutions predominate and speach is (cid:13)uent are said to undergo paragrammatism ( Caplan , 1994 ) . We suggest that paragramatism recovers (cid:13)uency ( i . e . low average word - word distance ) by unapropriately using the remaining highly connected vertices and thus often pro - ducing substitutions of words during discourse . ACKNOWLEDGMENTS Authors want to specially thank G . Miller and F . Di(cid:19)eguez for valuable discussions and are also grateful to D . Krakauer , A . Lloyd , M . Nowak , F . Reina and J . Rosell(cid:19)o for helpful comments . RFC acknowledges the hospitality of the Institute for Advanced Study . This work was supported by the Santa Fe Institute ( RVS ) and grants of the Generalitat de Catalunya ( FI / 2000 - 00393 , RFC ) and the CICYT ( PB97 - 0693 , RVS ) . References Akmajian , A . , Demers , R . A . , Farmer , A . K . , & Harnish , R . M . ( 1995 ) . Linguistics . an introduction to lan - guage and communication . MIT Press . ( Chapter 2 ) Albert , R . , Jeong , H . , & Barab(cid:19)asi , A . - L . ( 2000 ) . Error and attack tolerance of complex networks . Nature , 406 , 378 - 381 . Balasubrahmanyan , V . K . , & Naranan , S . ( 1996 ) . Quan - titative linguistics and complex system studies . Journal of Quantitative Linguistics , 3 ( 3 ) , 177 - 228 . Barab(cid:19)asi , A . - L . , & Albert , R . ( 1999 ) . Emergence of scal - ing in random networks . Science , 286 , 509 - 511 . Brown , R . , & McNeil , D . ( 1966 ) . The " tip of the tongue " phenomenon . Journal of Verbal Learning and Ver - bal Behaviour , 5 , 325 - 337 . Caplan , D . ( 1987 ) . Neurolinguistics and linguistic apha - siology . Cambridge University Press . 1 Accordint to our calculations , the 10 most connected words are and , the , of , in , a , to , ’s , with , by and is . 5 Caplan , D . ( 1994 ) . Language . structure , processing and disorders . The MIT Press . Chomsky , N . ( 1957 ) . Syntactic structures . Mouton . Choueka , Y . , & Lusignan , S . ( 1985 ) . Disambiguation by short contexts . Computers and the Humanities , 19 , 147 - 157 . Deacon , T . W . ( 1997 ) . The symbolic species : the co - evolution of language and the brain . W . W . Norton & Company . Ferrer , R . , & Sol(cid:19)e , R . V . ( 2000 ) . Two regimes in the fre - quency of words and the origin of complex lexicons . Santa Fe Working Paper 00 - 12 - 068 . ( Submited to the Journal of Quantitative Linguistics ) Forster , K . I . , & Chambers , S . M . ( 1973 ) . Lexical access and naming time . Journal of Verbal Learning and Verbal Behaviour , 12 , 627 - 635 . Hudson , R . ( 1984 ) . Word grammar . B . Blackwell . Jeong , H . , Tombor , B . , Albert , R . , Oltvai , Z . N . , & A . - L . Barab(cid:19)asi . ( 2000 ) . The large - scale organization of metabolic networks . Nature , 407 , 651 - 654 . Kaplan , A . ( 1955 ) . An experimental study of ambiguity and context . Mechanical Translation , 2 , 39 - 46 . Kempen , G . , & Huijbers , P . ( 1983 ) . The lexicalization process in sentence production and naming : Indi - rect election of words . Cognition , 14 , 185 - 209 . Li , W . ( 1992 ) . Random texts exhibit zipf’s - law - like word frequency distribution . IEEE Transactions on In - formation Theory , 38 ( 6 ) . Mel(cid:20)cuck , I . ( 1989 ) . Dependencies grammar : Theory and practice . New York , University of New York . Miller , G . A . , & Gildea , P . M . ( 1987 ) . How children learn words . Scienti(cid:12)c American , 257 ( 3 ) . Montoya , J . M . , & Sol(cid:19)e , R . V . ( 2000 ) . Small world patterns in food webs . Santa Fe Working Paper 00 - 10 - 059 . ( Submitted to J . Theor . Biol . ) Newman , M . E . J . ( 2000 ) . Models of the small - world . Journal of Statistical Physics , 101 ( 3 / 4 ) , 819 - 841 . Nicolis , J . S . ( 1991 ) . Chaos and information processing . Singapore : World Scienti(cid:12)c . Nowak , M . A . , & Krakauer , D . C . ( 1999 ) . The evolu - tion of language . Proc . Natl . Acd . Sci . USA , 96 , 8028 - 8033 . Nowak , M . A . , Plotkin , J . B . , & Jansen , V . A . ( 2000 ) . The evolution of syntactic communication . Nature , 404 , 495 - 498 . Romaine , S . ( 1992 ) . The evolution of linguistic com - plexity in pidgin and creole languages . In J . A . Hawkins & M . Gell - Mann ( Eds . ) , The evolution of human languages ( p . 213 - 238 ) . Addison Wesley . Scarborough , D . L . , Cortese , C . , & Scarborough , H . S . ( 1977 ) . Frequency and repetition e(cid:11)ects in lexical memory . Journal of Experimental Psychology : Hu - man Perception and Performance , 3 ( 1 ) , 1 - 17 . Simon , H . A . ( 1955 ) . On a class of skew distribution functions . Biometrika , 42 , 425 - 440 . Smith , J . M . , & Sz(cid:127)athm(cid:19)ary , E . ( 1997 ) . The major tran - sitions in evolution . Oxford University Press . Sol(cid:19)e , R . V . , & Montoya , J . M . ( 2000 ) . Complexity and fragility in ecological networks . Santa Fe Working Paper 00 - 11 - 060 . Strogatz , S . H . ( 2001 ) . Exploring complex networks . Nature , 410 , 268 - 276 . Watts , D . J . ( 1999 ) . Small - worlds . Princeton University Press . Watts , D . J . , & Strogatz , S . H . ( 1998 ) . Collective dynam - ics of ’small - world’ networks . Nature , 393 , 440 - 442 . Zipf , G . K . ( 1972 ) . Human behaviour and the princi - ple of least e(cid:11)ort . an introduction to human ecol - ogy . New York : Hafner reprint . ( 1st edition : Cam - bridge , MA : Addison - Wesley , 1949 ) graph C C random d d random (cid:10) L ( UWN ) 0 : 687 1 : 55 (cid:1) 10 (cid:0) 4 2 : 63 (cid:3) 3 : 03 (cid:10) L ( RWN ) 0 : 437 1 : 55 (cid:1) 10 (cid:0) 4 2 : 67 (cid:3) 3 : 06 TABLE I . Word network patterns . It can be seen that C (cid:29) C random and d (cid:0) d random , consistently with a SW net - work . All values are exact except those marked with (cid:3) , which have been estimated on a random subset of the vertices . 2 6