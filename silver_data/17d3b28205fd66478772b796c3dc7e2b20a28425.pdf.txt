Since January 2020 Elsevier has created a COVID - 19 resource centre with free information in English and Mandarin on the novel coronavirus COVID - 19 . The COVID - 19 resource centre is hosted on Elsevier Connect , the company ' s public news and information website . Elsevier hereby grants permission to make all its COVID - 19 - related research that is available on the COVID - 19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories , such as the WHO COVID database with rights for unrestricted research re - use and analyses in any form or by any means with acknowledgement of the original source . These permissions are granted for free by Elsevier for as long as the COVID - 19 resource centre remains active . Journal Pre - proof A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 Imran Ahmed , Misbah Ahmad , Joel J . P . C . Rodrigues , Gwanggil Jeon , Sadia Din PII : S2210 - 6707 ( 20 ) 30789 - 7 DOI : https : / / doi . org / 10 . 1016 / j . scs . 2020 . 102571 Reference : SCS 102571 To appear in : Sustainable Cities and Society Received Date : 17 September 2020 Revised Date : 14 October 2020 Accepted Date : 19 October 2020 Please cite this article as : { doi : https : / / doi . org / This is a PDF ﬁle of an article that has undergone enhancements after acceptance , such as the addition of a cover page and metadata , and formatting for readability , but it is not yet the deﬁnitive version of record . This version will undergo additional copyediting , typesetting and review before it is published in its ﬁnal form , but we are providing this version to give early visibility of the article . Please note that , during the production process , errors may be discovered which could affect the content , and all legal disclaimers that apply to the journal pertain . © 2020 Published by Elsevier . Sustainable Cities and Society A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 - - Manuscript Draft - - Manuscript Number : SCSI - D - 20 - 03501R1 Article Type : VSI : COVID - 19 Control Keywords : Deep learning ; Social Distancing ; COVID - 19 ; Transfer learning ; Overhead View ; Person Detection Corresponding Author : Gwanggil Jeon Incheon National University incheon , KOREA , REPUBLIC OF First Author : Imran Ahmed Order of Authors : Imran Ahmed Misbah Ahmad Joel J . P . C . Rodrigues Sadia Din Gwanggil Jeon Abstract : The ongoing ( COVID - 19 ) corona virus outbreak has caused a global disaster with its deadly spreading . Due to the absence of effective remedial agents and the shortage of immunizations against the virus , population vulnerability increases . In the current situation , as there are no vaccines available , therefore social distancing is considered an adequate measure ( norm ) against the spread of the pandemic virus . The chances of virus spread can be reduced by minimizing the physical contact among people . Therefore , this work aims to provide a deep learning - based framework for social distance monitoring using an overhead view . The framework employs the YOLOv3 object detection model to detect humans in video sequences . The transfer learning approach is also adopted to enhance the detection accuracy of the model . In this way , a detection model takes advantage of a pre - trained model appended with an extra trained layer using overhead human data set . The detection model identified human with the help of a bounding box . Using the Euclidean distance , the pairwise centroid distances between detected people are measured . To check social distance violations between people , we used an approximation of physical distance to pixel and set a threshold . Suggested Reviewers : Guangji Quan guangji . quan @ gmail . com Yong Fang dr . fang . yong @ gmail . com Marco Anisetti marco . anisetti @ unimi . it Response to Reviewers : Powered by Editorial Manager® and ProduXion Manager® from Aries Systems Corporation J o u r n a l P r e - p r o o f Cover letter for submission of a paper to Sustainable Cities and Society Imran Ahmed , Misbah Ahmad Center of Excellence in Information Technology , Institute of Management Sciences , 1 - A , Sector E - 5 , Phase VII , Hayatabad , Peshawar - Pakistan . imran . ahmed @ imsciences . edu . pk , misbahahmad4872 @ gmail . com . Joel J . P . C . Rodrigues Post - Graduation Program in Electrical Engineering ( PPGEE ) , Federal University of Piauı , Teresina 64049 - 550 , Brazil ; Instituto de Telecomunica¸coes , 1049 - 001 Lisbon , Portugal . joeljr @ ieee . org . Sadia Din Department of Information and Communication Engineering , Yeungnam University , South Korea . saadia . deen @ gmail . com . Gwanggil Jeon Department of Embedded Systems Engineering , Incheon National University , Incheon , Korea . gjeon @ inu . ac . kr . September 18 , 2020 Dear Dr . Editor in Chief , I / We wish to submit a new manuscript entitled “ [ A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 ] ” for consideration by the [ Sustainable Cities and Society ] . I / We confirm that this work is original and has not been published elsewhere nor is it currently under consideration for publication elsewhere . Cover Letter J o u r n a l P r e - p r o o f The ongoing ( COVID - 19 ) corona virus outbreak has caused a global disaster with its deadly spreading . Due to the absence of effective remedial agents and the shortage of immunizations against the virus , population vulnerability increases . In the current situation , as there are no vaccines available , therefore social distancing is considered an adequate measure ( norm ) against the spread of the pandemic virus . The chances of virus spread can be reduced by minimizing the physical contact among people . Therefore , this work aims to provide a deep learning - based framework for social distance monitoring using an overhead view . The framework employs the YOLOv3 object detection model to detect humans in video sequences . The transfer learning approach is also adopted to enhance the detection accuracy of the model . In this way , a detection model takes advantage of a pre - trained model appended with an extra trained layer using overhead human data set . The detection model identified human with the help of a bounding box . Using the Euclidean distance , the pairwise centroid distances between detected people are measured . To check social distance violations between people , we used an approximation of physical distance to pixel and set a threshold . A violation threshold is defined to check if the distance value violates the minimum social distance set or not . Furthermore , a tracking algorithm is used to track people in the video sequence so that the person who is violating the social distance threshold is also being tracked . To evaluate the performance , experiments are carried out on different video sequences . Experimental results reveal that the developed framework efficiently identity people walking too close and violates social distancing ; also , the transfer learning approach improves the overall performance , detection accuracy , and improves false positives . The deep learning detection model YOLOv3 achieves detection accuracy of 92 % without transfer learning , and 95 % with transfer learning , and overall tracking accuracy is 95 % . Please address all correspondence concerning this manuscript to me at [ gjeon @ inu . ac . kr ] . Thank you for your consideration of this manuscript . Sincerely , Gwanggil Jeon J o u r n a l P r e - p r o o f The purpose of this work is to provide a deep learning platform for social distance tracking . The framework uses the YOLOv3 object recognition paradigm to identify humans in video sequences . The transfer learning methodology is implemented to increase the accuracy of the model . The detection algorithm uses a pre - trained algorithm . To estimate social distance violations between people , we used an approximation of physical distance . Highlights J o u r n a l P r e - p r o o f Thank you very much for the review of our manuscript entitled : “A Deep Learning - Based Social Distance Monitoring framework for COVID - 19” . We sincerely appreciate all the valuable comments and suggestions , which helped us to improve the quality of the article . Our responses to the Reviewers’ comments are described below in a point - to - point manner . Appropriated changes , suggested by the Reviewers , has been introduced to the manuscript ( highlighted in blue within the document ) . Reviewer # 1 :  Draw a flowchart from your work flow that briefly shows the process and in the Discussion section . Dear Reviewer , thanks a lot for the valuable suggestion ; in the revised manuscript , we have updated the flowchart . Kindly refer to Figure . 5 .  Compare your results with the results of other researchers . The comparison with other state of the art method is also added . Kindly refer to Figure . 15 Table . 1 .  In the final conclusion , make a new justification for your research . Dear Reviewer , we have added a new justification at the end of the conclusion section .  The introduction should be strengthened and newer sources should be used . Some details should be addressed about Deep Learning parameters . Dear Reviewer , in the revised manuscript , we have updated the introduction section . Also , add some detail to the deep learning parameters . Reviewer # 2 : A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 . The ongoing ( COVID - 19 ) corona virus outbreak has caused a global disaster with its deadly spreading . Due to the absence of effective remedial agents and the shortage of immunizations against the virus , population vulnerability increases . In the current situation , as there are no vaccines available , therefore social distancing is considered an adequate measure ( norm ) against the spread of the pandemic virus . The chances of virus spread can be reduced by minimizing the physical contact among people . Therefore , this work aims to provide a deep learning - based framework for social distance monitoring using an overhead view . The framework employs the YOLOv3 object detection model to detect humans in video sequences . The transfer learning approach is also adopted to enhance the detection accuracy of the model . In this way , a detection model takes advantage of a pre - trained model appended with an extra trained layer using overhead human data set . The detection model identified human with the help of a bounding box . Using the Euclidean distance , the pairwise centroid distances between detected people are Response to Reviewers ( without Author Details ) J o u r n a l P r e - p r o o f measured . To check social distance violations between people , we used an approximation of physical distance to pixel and set a threshold . The work is presented well and it all figures needs to be appropriately maintain the required resolutions . Dear Reviewer , first of all , thank you so much for such valuable and encouraging positive comments . In the revised manuscript , we have updated the resolutions of the images . Reviewer # 3 : The Research Paper has proposed a " A Deep Learning - Based Social Distance Monitoring framework for COVID - 1 . The Model is Ok and paper is Nicely presented , but the paper needs the following Minor Technical Revisions : We want to thank Reviewers for taking the time and effort necessary to review the manuscript . We sincerely appreciate all the valuable comments and suggestions , which helped to improve the manuscript ' s quality . 1 . After Literature review , add in 10 - 15 lines what overall technical gaps are observed in the paper , that led to the design of the proposed framework . Dear Reviewer , thank you for this comment . In the revised manuscript the changes have been incorporated . 2 . Add some Algorithm and Steps of Working of the proposed Model being proposed for Social Distancing . Dear Reviewer , the detailed step by step process of the model has been explained in text with equations and in Fig . 5 . Furthermore , the main working blocks are also discussed in Fig . 6 . 3 . Add some Real - Time Case Study based discussion with regard to the Methodology proposed . Thank you so much for the worthy suggestion ; the real - time application and case study are discussed in the introduction section . Also , we are currently working on another paper related to case studies of COVID - 19 4 . Add 10 - 15 more latest references to the paper . Dear Reviewer , thanks a lot for valuable suggestion the revised manuscript updated with latest references . Kindly refer to Reference Section . J o u r n a l P r e - p r o o f Overall the conceptual methodology of the paper is Nice and Readability of the paper is excellent for end users to understand and researchers can take this paper as base paper to undertake advanced research in this area . Dear Reviewer , we really admire your deep understanding of the area presented in the manuscript . We are really thankful for appreciating our work . Reviewer # 4 : This paper presents a deep learning - based social distance monitoring framework by overhead perspective . A pre - trained YOLOv3 model with transfer learning is provided . The present results are interesting and can be accepted after revision . The following issues must be addressed before the publication of the manuscript : Thank you for providing us this opportunity to further revise our manuscript . We appreciate the very positive and constructive comments from the Reviewer . Major concerns : 1 ． ( a ) Since all information is obtained by camera , how did the authors calculate the tracking accuracy ? Dear Reviewer , the camera is used for only data recording . The tracking algorithm is entirely separate ( not built - in camera ) . We used the centroid tracking algorithm , which mainly used centroid information of bounding box a track multiple people . For details , kindly refer to the methodology section in the paper . ( b ) What does the one hundred percent accurate mean ? Respected Reviewer , we have not made such claim in the paper kindly refer to Fig . 13 and 14 and Performance Evaluation section in the revised manuscript . ( c ) What ' s the reference / real value ? And how to obtain the reference / real value ? Dear Reviewer , we used a manually annotated value against the automatic predicted value by the algorithm in the paper . 2 ． For overhead view perspective , the size of detected bounding box for people located in the center and the boundaries are significantly different . How to keep the accuracy at the same level for the whole detection zone ? Dear reviver , we really appreciate your gravity of knowledge . Actually , you are right that the shape of the person is significantly different from an overhead perspective . The pre - trained algorithm is failing ; that is why transfer learning is adopted in work , and the model is trained on the overhead data set . J o u r n a l P r e - p r o o f 3 ． Why does the training loss fluctuate over time ( Figure 10 ) ? But the training accuracy keeps growing . Dear Reviewer , we really apricate your knowledge in this regard , but as the epoch size increases , the model ' s training accuracy is improved . Same in vice versa , the training improves the loss function . 4 ． As peppered with some grammatical errors and typos , the manuscript should be completely reviewed . Dear Reviewer , the revised manuscript is updated , and grammatical errors and typos mistakes are removed . Minor comments : 5 ． Page 2 , Abstract ： Please avoid using the same word over and over again , such as " check " and " therefore " . The suggestion has been incorporated ; kindly refer to the highlighted section in the revised manuscript . 6 ． Page 3 , Line 15 - 19 . " identity " should be " identify " . Thanks for highlighting our mistake . The suggestion has been incorporated . 7 ． Page 3 , Line 22 - 25 . I suggest a rewrite of the last sentence to make it clear . Dear Reviewer , the suggestion has been incorporated . 8 ． Page 3 , Line 37 . It should be " a pandemic disease " . Dear Reviewer , thanks for highlighting the mistakes ; the changes have been made . 9 ． Page 4 , Figure 1 . A comma symbol is found in the title of Figure . 1 ( b ) . Dear Reviewer , thanks for highlighting the mistakes ; the changes have been made . 10 ． Page 5 , Figure 2 . Size of the " half person " is slightly smaller the " whole person " , and they are not aligned . Dear Reviewer , thanks for highlighting the mistakes ; the changes have been made . 11 ． Page 8 , Line 48 - 49 . " Prem et al . in studied… " should be " Prem et al . studied… " Dear Reviewer , thanks for highlighting the mistakes ; the changes have been made . J o u r n a l P r e - p r o o f 12 ． Page 10 , Line 11 - 13 . The first sentence of Section 3 is grammatically incorrect . Dear Reviewer , thanks for highlighting the mistakes ; the changes have been made . 13 ． Page 11 , Line 8 - 9 . What does COCO represents ? Please give some detail information . Dear Reviewer , thanks for highlighting the mistakes ; the changes have been made . 14 ． Page 11 , Figure 5 . How did the authors obtain the Detected bounding box ( only people ) ? Dear Reviewer , the pre - trained model is trained for different class objects . In this work , we only consider human class and trained the model for human class ; that is why the model automatically detected only people bounding boxes . 15 ． Page 11 , Figure 5 . If two people are closed , which set will the information be added into ? " Yes or No " signs should be labeled . Dear Reviewer the Fig . 5 is updated in the revised manuscript . 16 ． Page 11 , Line 46 - 49 . This sentence is grammatically incorrect , please rewrite it . Dear Reviewer , We have incorporated the suggested changes . 17 ． Page 12 , Figure 6 . This figure is not clear enough . Dear Reviewer , the resolution of Figure . 6 is improved in the revised manuscript . 18 ． Page 14 , Figure 7 . The front size of " a " and " b " is different . Also , the label form should be consistent through the whole manuscript . " ( a ) " and " ( b ) " is used for Figure 4 , but for other Figures , they are labeled as " a , b , c , d… " . Please correct them . Dear Reviewer thank you so much for highlighting the mistake ; we have incorporated the mistakes in the manuscript . 19 ． Page 17 , Figure 8 . The typeface and front size are inconsistent . Dear Reviewer , We have made the font and typeface of Figure . 8 consistent in the revised manuscript . 20 ． Page 22 , Line 26 - 34 . Where do the authors use the symbol " tp , fp , fn… " ? Are there some equations missing ? Dear Reviewer , these parameters are used for calculating the accuracy precision and recall . 21 ． Page 23 , Figure 14 . What ' s the different between accuracy and tracking accuracy ? The same numerical values are found in Figure 13 and 14 . J o u r n a l P r e - p r o o f Dear Reviewer , Detection accuracy refers to accuracy , while the tracking accuracy shows the performance of the tracking algorithm . 22 ． Page 24 , Table 1 . Why the sum of True detection rate and False detection rate are not 100 % ? Dear Reviewer , TPR and FPR don ' t need to be equal to 100 % as per the literature study . J o u r n a l P r e - p r o o f A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 Abstract The ongoing COVID - 19 corona virus outbreak has caused a global disaster with its deadly spreading . Due to the absence of eﬀective remedial agents and the shortage of immunizations against the virus , population vulnerability increases . In the current situation , as there are no vaccines available ; therefore , social distancing is thought to be an adequate precaution ( norm ) against the spread of the pandemic virus . The risks of virus spread can be minimized by avoid - ing physical contact among people . The purpose of this work is , therefore , to provide a deep learning platform for social distance tracking using an overhead perspective . The framework uses the YOLOv3 object recognition paradigm to identify humans in video sequences . The transfer learning methodology is also implemented to increase the accuracy of the model . In this way , the detection algorithm uses a pre - trained algorithm that is connected to an extra trained layer using an overhead human data set . The detection model identiﬁes peoples using detected bounding box information . Using the Euclidean distance , the detected bounding box centroid’s pairwise distances of people are determined . To estimate social distance violations between people , we used an approxima - Preprint submitted to Journal of L A TEX Templates October 14 , 2020 Revised Manuscript with Changes Marked ( without Author Details ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f tion of physical distance to pixel and set a threshold . A violation threshold is established to evaluate whether or not the distance value breaches the min - imum social distance threshold . In addition , a tracking algorithm is used to detect individuals in video sequences such that the person who violates / crosses the social distance threshold is also being tracked . Experiments are carried out on diﬀerent video sequences to test the eﬃciency of the model . Findings in - dicate that the developed framework successfully distinguishes individuals who walk too near and breaches / violates social distances ; also , the transfer learn - ing approach boosts the overall eﬃciency of the model . The accuracy of 92 % and 98 % achieved by the detection model without and with transfer learning , respectively . The tracking accuracy of the model is 95 % . Keywords : Deep Learning , Social Distancing , COVID - 19 , Transfer Learning , Overhead View , Person Detection , YOLOv3 1 . Introduction COVID - 19 originated from Wuhan , China , has aﬀected many countries world - wide since December 2019 . On March 11 , 2020 , the World Health Organiza - tion ( WHO ) announced it a pandemic diseases as the virus spread through 114 countries , caused 4000 deaths and 118 , 000 active cases [ 1 ] [ 2 ] . On October 7 , 2020 , they reported more than 35 , 537 , 491 conﬁrmed COVID - 19 cases , includ - ing 1 , 042 , 798 deaths . The latest number of infected people due to pandemic is shown in Figure . 5 [ 3 ] . Many healthcare organizations , scientists , and medical professionals are searching for proper vaccines and medicines to overcome this deadly virus , although no progress is reported to - date . To stop the virus spread , the global community is looking for alternate ways . The virus mainly spreads in those people ; who are in close contact with each other ( within 6 feet ) for a long period . The virus spreads when an infected person sneezes , coughs , or talks , the droplets from their nose or mouth disperse through the air and aﬀect nearby peoples . The droplets also transfer into the lungs through the respiratory sys - tem , where it starts killing lung cells . Recent studies show that individuals with 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f no symptoms but are infected with the virus also play a part in the virus spread [ 3 ] . Therefore , it is necessary to maintain at least 6 feet distance from others , even if people do not have any symptoms . ( a ) Region wise number of conﬁrmed cases ( October 7 , 2020 ) ( b ) Region wise number of deaths , ( October 7 , 2020 ) . Figure 1 : Latest number conﬁrmed cases and deaths reported by WHO due to pandemic [ 3 ] . Social distancing associates with the measures that overcome the virus’ spread , by minimizing the physical contacts of humans , such as the masses at public places ( e . g . , shopping malls , parks , schools , universities , airports , workplaces ) , evading crowd gatherings , and maintaining an adequate distance between peo - ple [ 4 ] , [ 5 ] . Social distancing is essential , particularly for those people who are at higher risk of serious illness from COVID - 19 . By decreasing the risk of virus transmission from an infected person to a healthy , the virus’ spread and dis - 3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f ease severity can be signiﬁcantly reduced [ 6 ] Figure . 2 . If social distancing is implemented at the initial stages , it can perform a pivotal role in overcoming the virus spread and preventing the pandemic disease’s peak , as illustrated in Figure . 3 [ 7 ] . It can be observed that social distancing can decrease the num - ber of infected patients and reduce the burden on healthcare organizations . It also lowers the mortality rates by assuring that the number of infected cases ( patients ) does not surpass the public healthcare capability [ 8 ] . Figure 2 : Importance of Social distancing . Figure 3 : Eﬀect of social distancing : the peak of pandemic cases is decreasing and meeting with available healthcare capability [ 7 ] . 4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f In the past decades , computer vision , machine learning , and deep learning have shown promising results in several daily life problems . Recent improvement in deep learning allows object detection tasks [ 9 ] more eﬀective . Researchers [ 10 ] , [ 11 ] , [ 12 ] , often utilize these methods to measure social distancing among peo - ple across the moving frames , as seen in Figure . 4 . To determine the distancing between people , clustering and distance - based methods are utilized . From Fig - ure . 4 , it can be be seen that most of the methods are developed using frontal or side view video sequences , which requires a proper camera calibration to map pixels to distance for real easily , measurable units ( i . e . , feet , meters , etc . ) . Sec - ondly , if we assume a top - down approach , i . e . , an overhead view approach , then the distance calculations from the overhead view will lead to a better distance approximation and wide coverage of the wide scene . ( a ) ( b ) ( c ) ( d ) ( e ) ( f ) Figure 4 : Example images from the literature , used for social distance monitoring . ( a ) , ( b ) , & ( c ) [ 10 ] used Faster - RCNN for monitoring social distance ( d ) , & ( e ) [ 11 ] used YOLOv3 with Deepsort to monitor social distancing on Oxford Town Center , and ( f ) [ 12 ] . In this work , we used an overhead view to provide an eﬀective framework for social distance monitoring . Some scholars , e . g . [ 13 ] , [ 14 ] , [ 15 ] , [ 16 ] , [ 17 ] , [ 18 ] , [ 19 ] , and [ 20 ] use an overhead perspective for human detection and tracking . The overhead perspective oﬀers a better ﬁeld of view and overcomes the issues 5 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f of occlusion , thereby playing a key role in social distance monitoring to compute the distance between peoples . It might help overcome computation , communica - tion load , energy consumption , human resource , and installation costs [ 21 ] . This work aims to present a deep learning - based social distance monitoring frame - work for the public campus environment from an overhead perspective . A deep learning model , i . e . , YOLOv3 ( You Only Look Once ) [ 22 ] , is applied for human detection . The current model ( pre - trained on frontal or normal view data sets ) is initially tested on the overhead data set . Transfer learning is also used to improve the eﬃciency of the detection model . To the best of our knowledge , this work could be considered as the ﬁrst eﬀort to use an overhead view per - spective to monitor social distance with transfer learning . The detection model detects humans and gives bounding box information . The detection model de - tects humans and gives bounding box information . After human detection , the Euclidean distance between each detected centroid pair is computed using the detected bounding box and its centroid information . A predeﬁned minimum social distance violation threshold is speciﬁed using pixel to distance assump - tions . To check , either the calculated distance comes under the violation set or not , the estimated information is matched with the violation threshold . The bounding box’s color is formerly initialized as green ; if the bounding box comes under the violation set , its color is updated to red . In addition , the centroid tracking algorithm is used to track a person who violated the social distancing threshold . The key goals of this work are as follows : • To present a deep learning - based social distance monitoring framework using an overhead view perspective . • To deploy pre - trained YOLOv3 for human detection and computing their bounding box centroid information . In addition , a transfer learning method is applied to enhance the performance of the model . The additional train - ing is performed with overhead data set , and the newly trained layer is appended to the pre - trained model . • In order to track the social distance between individuals , the Euclidean 6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f distance is used to approximate the distance between each pair of the centroid of the bounding box detected . In addition , a social distance violation threshold is speciﬁed using a pixel to distance estimation . • Utilizing a centroid tracking algorithm to keep track of the person who violates the social distance threshold . • To assess the performance of pre - trained YOLOv3 by evaluating it on an overhead data set . The output of the detection framework is assessed with and without the transition of learning . Furthermore , the model per - formance is also compared with other deep learning models . The rest of the work discussed in the paper is structured as follows . The related work is presented in Section . 2 . A deep learning - based social distance monitoring framework has been presented in Section . 3 . The overhead view data set used for training and testing during experimentation is brieﬂy discussed in Section . 4 . The detailed analysis of output results and performance evaluation of the model with and without transfer learning is also illustrated in this Section . The con - clusion of the given work with potential future plans is provided in Section . 5 . 2 . Literature Review After the rise of the COVID - 19 pandemic since late December 2019 , Social dis - tancing is deemed to be an utmost reliable practice to prevent the contagious virus transmission and opted as standard practice on January 23 , 2020 [ 23 ] . During one month , the number of cases rises exceptionally , with two thousand to four thousand new conﬁrmed cases reported per day in the ﬁrst week of February 2020 . Later , there has been a sign of relief for the ﬁrst time for ﬁve successive days up to March 23 , 2020 , with no new conﬁrmed cases [ 24 ] . This is because of the social distance practice initiated in China and , latterly , adopted by worldwide to control COVID - 19 . Kylie et al . [ 25 ] investigated the relation - ship between the region’s economic situation and the social distancing strictness . The study revealed that moderate stages of exercise could be allowed for evading 7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f a large outbreak . So far , many countries have used technology - based solutions [ 26 ] to overcome the pandemic loss . Several developed countries are employ - ing GPS technology to monitor the movements of the infected and suspected individuals . [ 8 ] provides a survey of diﬀerent emerging technologies , including Wi - ﬁ , Bluetooth , smartphones , and GPS , positioning ( localization ) , computer vision , and deep learning that can play a crucial role in several practical so - cial distancing scenarios . Some researchers utilize drones and other surveillance cameras to detect crowd gatherings [ 27 ] & [ 28 ] . Until now researchers have done considerable work for detection [ 29 ] , [ 30 ] , & [ 31 ] , some provides an smart healthcare system for pandemic using Internet of Medical Things [ 32 ] , & [ 33 ] . Prem et al . [ 34 ] studied the social distancing impacts on the spread of the COVID - 19 outbreak . The studies concluded that the early and immediate practice of social distancing could gradually reduce the peak of the virus attack . As we all know , that although social distancing is cru - cial for ﬂattening the infection curve , it is an economically unpleasant step . In [ 35 ] , Adolph et al . highlighted the United States of America’s condition during the pandemic . Due to a lack of general support by decision - makers , it was not implemented at an initial stage , starting harm to public health . However , so - cial distancing inﬂuenced economic productivity ; even then , numerous scholars sought alternatives that overcame the loss . Researchers provide eﬀective solutions for social distance measuring using surveil - lance videos along with computer vision , machine learning , and deep learning - based approaches . Punn et al . [ 11 ] proposed a framework using the YOLOv3 model to detect humans and the Deepsort approach to track the detected people using bounding boxes and assigned IDs information . They used an open image data set ( OID ) repository , a frontal view data set . The authors also compared results with Faster - RCNN and SSD . [ 12 ] developed an autonomous drone - based model for social distance monitoring . They trained the YOLOv3 model with the custom data set . The data set is composed of frontal and side view images of limited people . The work is also extended for the monitoring of facial masks . The drone camera and the YOLOv3 algorithm help identify the social distance 8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f and monitor people from the side or frontal view in public wearing masks . Pouw et al . , [ 36 ] suggested an eﬃcient graph - based monitoring framework for phys - ical distancing and crowd management . [ 37 ] performed human detection in a crowded situation . The model is designed for individuals who do not obey a social distance restriction , i . e . , 6 feet of space between them . The authors used a mobile robot with an RGB - D camera and a 2 - D lidar to make collision - free navigation in mass gatherings . From the literature , we concluded that the researcher had done a considerable amount of work for monitoring of social distance in public environments . But , most of the work is focused on the frontal or side view camera perspective . Therefore , in this work , we presented an overhead view social distance moni - toring framework that oﬀers a better ﬁeld of view and overcomes the issues of occlusion , thereby playing a key role in social distance monitoring to compute the distance between peoples . 3 . Social Distance Monitoring Researchers use a frontal or side perspective for social distance monitoring , as discussed in Section . 2 . In this work , a deep learning - based social distance monitoring framework using an overhead perspective has been introduced . The ﬂow diagram of the framework is shown in Figure . 5 . The recorded overhead data set are split into training and testing sets . A deep learning - based detection paradigm is used to detect individuals in sequences . There are a variety of object detection models available , such as [ 38 ] , [ 39 ] , [ 40 ] , [ 41 ] , [ 42 ] and [ 43 ] . Due to the best performance results for generic object detection , in this work , YOLOv3 [ 22 ] is used . The model used single - stage network architecture to estimate the bounding boxes and class probabilities . The model was originally trained on the COCO ( Common objects in context ) data set [ 44 ] . For overhead view person detection , transfer learning is implemented to enhance the detection model’s eﬃciency , and a new layer of overhead training is added with the existing architecture . 9 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 5 : Flow diagram of overhead view social distance monitoring framework . After detection , the bounding box information , mainly centroid information , is used to compute each bounding box centroid distance . We used Euclidean distance and calculated the distance between each detected bounding box of peoples . Following computing centroid distance , a predeﬁned threshold is used to check either the distance among any two bounding box centroids is less than the conﬁgured number of pixels or not . If two people are close to each other and the distance value violates the minimum social distance threshold . The bounding box information is stored in a violation set , as seen in Figure . 5 , and the color of the bounding box is updated / changed to red . A centroid tracking algorithm is adopted for tracking so that it helps in tracking of those people who violate / breach the social distancing threshold . At the output , the model displays the information about the total number of social distancing violations 10 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f along with detected people bounding boxes and centroids . In this work , YOLOv3 is used for human detection as it improves predictive accuracy , particularly for small - scale objects . The main advantage is that it has adjusted network structure for multi - scale object detection . Furthermore , for object classiﬁcation , it uses various independent logistic rather than softmax . The model’s overall architecture is presented in Figure . 6 ; it can be seen that feature learning is performed using the convolutional layers , also called Residual Blocks . The blocks are made up of many convolutional layers and skip connec - tions . The model’s unique characteristic is that it performs detection at three separate scales , as depicted in Figure . 6 . The convolutional layers with a given stride are practiced to downsample the feature map and transfer invariant - sized features [ 22 ] . Three feature maps , as shown in Figure . 6 , are utilized for object detection . Figure 6 : General architecture of YOLOv3 utilized for overhead view human detection . The architecture shown in Figure . 6 is trained using an overhead data set . For that purpose , a transfer learning approach is adopted , that enhance the eﬃ - ciency of the model . With transfer learning , the model is additionally trained without dropping the valuable information of the existing model . Further , the additional overhead data set trained layer is appended with the existing archi - tecture . In this way , the model takes advantage of the pre - trained and newly 11 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f trained information , and both detection results are further deliver better and faster detection results . The architecture shown in Figure . 6 used a single - stage network for the entire input image to predict the bounding box and class probability of detected ob - jects . For feature extraction , the architecture utilizes convolution layers , and for class prediction , fully connected layers are used . During human identiﬁcation , as seen in Figure . 6 , the input frame is divided into a region of S , also called grid cells . These cells are related to bounding box estimation and class probabilities . It predicts the probability of whether the center of the person bounding box is in the grid cell or not . Conf ( p ) = Pr ( p ) × IOU ( pred , actual ) ( 1 ) In Equation . 1 , Pr ( p ) indicates that whether the person present is in the de - tected bounding box or not . The value of Pr ( p ) is 1 for yes and 0 for not . IoU ( pred , actual ) determines the Intersection Over Union of the actual and predicted bounding box . It is deﬁned as [ 22 ] : IoU ( pred , actual ) = areaBoxT ∩ BoxP BoxT ∪ BoxP ( 2 ) Where the ground truth box ( actual ) manually labeled in the training data set represented with BoxT , and the predicted bounding box is displayed as BoxP . area presents the area of intersection . An acceptable area is predicted and decided for each detected person in the input frame . The conﬁdence value is applied after prediction to achieve the optimal bounding box . For each predicted bounding box , h , w , x , y are estimated , where bounding box coordinates are deﬁned by x , y , and width and height are determined by w , h . The model produces the following predicted bounding box values as seen in Figure . 7 and Equation . 3 [ 22 ] : b x = σ ( t x ) + c x b y = σ ( t y ) + c y b w = p w e tw b h = p w h th ( 3 ) 12 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f In Equation . 3 , , b x , b y , b w , b h are predicted coordinate bounding boxes , where the coordinates’ center is represented as x , y and width and height with w , h . t w , t h , t x , t y , deﬁned the network output and c x , c y are used to correspond the top - left coordinates of the grid cell as shown in Figure . 7 , while the p w and p h are width and height of anchors . Figure 7 : Detected coordinates of person bounding box . A threshold value is deﬁned that process the high conﬁdence values and discards the low conﬁdence values . Using non - maximal suppression , the ﬁnal location parameters are derived for the detected bounding box . At last , loss function is calculated , for detected bounding box [ 22 ] . The given loss function is the sum of three functions , i . e . , regression , classiﬁcation , and conﬁdence . At each grid cell , if the object is detected , then the classiﬁcation loss is computed as the squared error of the conditional class probabilities and calculated as [ 22 ] : L cls = S 2 (cid:88) i = 0 1 objij (cid:88) c(cid:15)class 1 obji ( p i ( c ) − p ∗ i ( c ) ) 2 ( 4 ) In Equation . 4 , in grid cell i if the person is detected then 1 objij = 1 , otherwise equals to 0 . The conditional class probabilities for class c in grid cell i are represented as p ∗ i ( c ) . The localization loss estimates the failures in the predicted bounding box sizes and locations . The bounding box containing the detected 13 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f object , i . e . , a person , is added . It is deﬁned as [ 22 ] : L loc = λ coord 1 objij S 2 (cid:88) i = 0 B (cid:88) j = 0 [ ( x i − x ∗ i ) 2 + ( y i − y ∗ i ) 2 + ( √ w i − (cid:112) w ∗ i ) 2 + ( (cid:112) h i − (cid:112) h ∗ i ) 2 ] ( 5 ) In above equation 1 objij is equal to 1 , in case if the j th bounding box in grid cell i is used for object detection , otherwise it is equal to 0 . Instead of predicting simple height and width , the model predicts the square root of the bounding box width and height . In Equation . 5 the scale parameters λ coord is used for predictions of bounding box coordinates and equals to 5 as [ 45 ] . The predicted positions are represented with x i , yi , h i , w i in ith cell of detected bounding box , while the actual positions of bounding box in the i th cell is deﬁned using x ∗ i , y ∗ i , h ∗ i , w ∗ i . The Equation . 5 measures the loss function of predicted bounding box having coordinates value x , y . To represent the possibility of the detected person in the jth bounding box 1 objij is used . The value of λ is constant , the function in Equation . 5 calculates sum over each bounding box , using ( j = 0 to B ) as predictor for each grid cell ( i = 0 to S 2 ) . Finally the conﬁdence loss is calculated that is given in Equation . 6 as [ 22 ] : L conf = S 2 (cid:88) i = 0 B (cid:88) j = 0 1 objij ( C i − C ∗ i ) 2 ( 6 ) Where , the conﬁdence score is deﬁned as C ∗ , for j th bounding box in grid cell i and 1 objij and is equal to 1 in case if in cell i the j th bounding box is responsible for object detection ; otherwise it is equal to 0 . In case if the object is not detected , then the conﬁdence loss is provided as [ 22 ] : L conf = λ noobj S 2 (cid:88) i = 0 B (cid:88) j = 0 1 noobjij ( C i − C ∗ i ) 2 ( 7 ) In Equation . 7 , 1 noobjij is deﬁned as the complement of 1 objij . The bounding box’ conﬁdence score C ∗ in cell i and λ noobj is used to weights down the loss during detecting background . As in most cases detected , bounding boxes do not contain any objects that cause a class imbalance problem ; therefore , the model is more 14 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f frequently trained to detect background rather than detect objects . To solve this , the loss is weight down by a factor λ noobj ( default : 0 . 5 ) . After detecting people in video frames , in the next step , the centroid of each detected person bounding boxes shown as green boxes are used for distance cal - culation , as shown in Figure . 8 ( b ) . The detected bounding box coordinates ( x , y ) are used to compute the bounding box’s centroid . Figure . 8 ( c ) demonstrates ac - Figure 8 : ( a ) Input image , ( b ) detected person bounding boxes using deep learning algorithm , ( c ) compute the centroid of each detected bounding box , and ( d ) ﬁnally , the distance between each pair of the centroid is determined . In the example image , the red lines indicate the distance between each bounding box centroid . cepting a set of bounding box coordinates and computing the centroid . After computing , centroid , a unique ID is assigned to each detected bounding box . In the next step , we measure the distance between each detected centroid using Euclidean distance . For every subsequent frame in the video stream , we ﬁrstly 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f compute bounding box centroids shown in Figure . 8 ( c ) ; and then calculate the distance ( highlighted with red lines ) between each pair of detected bounding box centroids , Figure . 8 ( d ) . The information of each centroid is stored in the form of a list . Based on distance values , a threshold is deﬁned to check if any two people are less than N pixels apart or not . If the distance violates the min - imum social distance set or two people are too close , then the information is added into the violation set . The bounding box color is initialized as green . The information is checked in the violation set ; if the current index exists violation set , the color is updated to red . Furthermore , the centroid tracking algorithm is used to track the detected people in the video sequence . The tracking algorithm also helps to keep track of people who are violating the social distance threshold . At the output , the model displays information about the total number of social distancing violations . 4 . Experiments , Results , and Discussion The detailed descriptions of various experiments carried out in this work are presented in this section . For social distance monitoring , an indoor data set recorded at Institute of Management Sciences , Hayatabad , Peshawar Pakistan is used [ 16 ] & [ 46 ] , containing video sequences captured from the overhead view . The data collection is divided into 70 % and 30 % training and testing , respec - tively . There is no restriction on the mobility of persons throughout the scene . Peoples in the scene move freely ; their visual appearance is aﬀected by radial distance and camera position . From example frames , It can be observed that the human’s visual appearance is not identical , and peoples heights , poses , scales are varying in the data set . For implementation , we used OpenCV . The exper - imental results are divided into two subsections ; ﬁrst , the pre - trained model’s testing results are discussed , while in the second subsection , the results of the detection model after applying transfer learning and training on the overhead data set are explained . For comparison , the model is tested using the same video sequences . The performance evaluation of the model is also made in this 16 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f section , along with a comparison with diﬀerent deep learning models . 4 . 1 . Results of Social Distance monitoring using pre - trained model In Figure . 9 , the testing results of the social distance framework using a pre - trained model [ 22 ] has been visualized . The testing results are evaluated using diﬀerent video sequences . The people in the video sequences are freely moving in the scenes ; it can be seen from sample frames that the individual’s visual ap - pearance is not identical to the frontal or side view ( Figure . 9 ) . The person’s size Figure 9 : Social distance monitoring from an overhead view using a pre - trained detection model . In sample frames , the people in green rectangles are those who maintain the social distancing . The people who violate the social distance threshold are shown red in rectangles . The manually labels yellow positive cross shows miss detections . is also varying at diﬀerent locations , as shown in Figure . 9 . Since the model only 17 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f considers human ( person ) class ; therefore , only an object having an appearance like a human is detected by a pre - trained model . The pre - trained model deliv - ers good results and detects various size person bounding boxes , as shown with green rectangles in Figure . 9 ( a ) , ( b ) & ( c ) . From sample frames of Figure . 9 , people are marked with green rectangles as they maintain a social distancing threshold . The model is also tested for multiple peoples , as depicted in Figure . 9 ( g ) , ( h ) & ( i ) , multiple people are entering in the scene . In sample images , it can be seen that after person detection , the distance between each detected bounding box is measured to check whether the person in the scene violates the social distance or not . In Figure . 9 ( e ) , & ( h ) , two people at the center of the scene are marked with red bounding boxes as they violate or breaches the social distancing threshold . Some miss detections also occur that are manually labeled with a yellow cross in sample frames . From the sample frames , it can be seen that a person is eﬀectively detected at several scene locations . However , in some cases , the person’s appearance is changing ; therefore , the model gives miss detections . The reason for miss detection maybe , as the pre - trained model is applied , and an individual’s appearance from an overhead view is changing , which may be misleading for the model . 4 . 2 . Results of Social Distance monitoring using Transfer Learning . The transfer learning methodology is applied to improve the accuracy of the detection model . Using an overhead data set , the model is additionally trained using 500 sample frames . The epoch size 40 and batch size 64 is set for training of the model . The training loss and accuracy curves are shown in Figure . 10 and in Figure . 11 . A new layer is obtained after training the model ; that is further appended with a pre - trained model . The model is now tested for the same test video sequences , as discussed in the above sub - section . The experimental ﬁndings reveal that transfer learning sig - niﬁcantly increases the detection results , as seen in Figure . 12 . From the sample images , it can be visualized that the model detects the individuals at various scene locations . People with various characteristics are eﬀectively - identiﬁed , 18 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 10 : Training loss of YOLOv3 using overhead view data set . Figure 11 : Training Accuracy of YOLOv3 using overhead view data set . and the social distance between people is also computed , as shown in the sam - ple frames . In sample frames of Figure . 12 ( a ) , ( b ) , & ( c ) , there is no social distance violation found , since all people are marked with green rectangle boxes by the automated framework . While in the sample frame Figure . 12 ( e ) , the vio - lation is detected ; however , the number of people present in the scene is small as compared to Figure . 12 ( b ) , where all people are maintaining social distance , and therefore not a single violation is observed . In Figure . 12 ( d ) , ( e ) & ( f ) , due to close interactions between people , violation is recorded by automated system . The same behavior can be found in Figure . 12 ( g ) , ( h ) , & ( i ) where people are around dozen in both ( g ) & ( h ) and violation in ( h ) is three times as compared 19 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f to ( g ) . In Figure . 12 ( d ) , ( e ) & ( f ) , multiple people are walking , and entering in the scene are detected and monitored . The framework eﬀectively detected the breach of social distance between people and marked the bounding box as red rectangles if people are too close to each other . Figure 12 : Results of social distance monitoring , using transfer learning . It can be seen that the detection performance of the model is improved after transfer learning . In sample frames , the people in green rectangles maintain social distancing while in red rectangles are those who breach / violate the social distance . 4 . 3 . Performance Evaluation Diﬀerent quantitative metrics are used in this work to evaluate the performance of the framework for social distance monitoring using a deep learning model and an overhead perspective . To assess the eﬃciency of the detection model , Precision , Recall , and Accuracy is used . Furthermore , the ﬁndings are also compared with other deep learning models . For estimation of Precision , Recall 20 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f and Accuracy , we used , tp true positive , fp , false positives , tn true negative and fn false - negative . The Accuracy Recall and Precision results are shown in Figure . 13 . It can be analyzed that when the model is additionally trained for overhead view data set , the overall performance of the detection model is improved . The tracking accuracy is also given in Figure . 14 . Figure 13 : Precision , Recall , and Accuracy of model ( YOLOv3 ) with and without transfer learning . We also compared the newly trained YOLOv3 with other deep learning models . The True detection and False detection rate of diﬀerent deep learning models are depicted in Table . 1 . From the results , it can be seen that transfer learning improved the results signiﬁcantly for the overhead view data set . The false detection rate of diﬀerent deep learning models are very small , about 0 . 7 % to 0 . 4 % without any training , which reveals the eﬀectiveness of deep learning models . Diﬀerent pre - trained object detection models are tested on the overhead data set . Although the models were trained on the diﬀerent frontal data sets , they still show good results by achieving an accuracy of 90 % . In Figure . 15 , the comparison results of diﬀerent state of the art detection are shown . 21 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 14 : Tracking Accuracy with pre - trained and trained YOLOv3 detection model . Table 1 : Comparison results of YOLOv3 with other deep learning models . S . No Model True Detection rate False Detection rate 1 . Fast - RCNN ( Pre - trained ) 90 % 0 . 7 % 2 . Faster - RCNN ( Pre - trained ) 92 % 0 . 6 % 3 . Mask - RCNN ( Pre - Trained ) 92 % 0 . 5 % 4 . YOLOv3 ( Pre - trained ) 92 % 0 . 4 % 5 YOLOv3 ( trained Overhead data set ) 95 % 0 . 3 % 22 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 15 : Comparison results of YOLOv3 trained on overhead data set with other methods . 5 . Conclusion and Future Works In this work , a deep learning - based social distance monitoring framework is presented using an overhead perspective . The pre - trained YOLOv3 paradigm is used for human detection . As a person’s appearance , visibility , scale , size , shape , and pose vary signiﬁcantly from an overhead view , the transfer learning method is adopted to improve the pre - trained model’s performance . The model is trained on an overhead data set , and the newly trained layer is appended with the existing model . To the best of our knowledge , this work is the ﬁrst attempt that utilized transfer learning for a deep learning - based detection paradigm , used for overhead perspective social distance monitoring . The detection model gives bounding box information , containing centroid coordinates information . Using the Euclidean distance , the pairwise centroid distances between detected bounding boxes are measured . To check social distance violations between peo - ple , an approximation of physical distance to the pixel is used , and a threshold is deﬁned . A violation threshold is used to check if the distance value violates the minimum social distance set or not . Furthermore , a centroid tracking algo - rithm is used for tracking peoples in the scene . Experimental results indicated that the framework eﬃciently identiﬁes people walking too close and violates 23 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f social distancing ; also , the transfer learning methodology increases the detec - tion model’s overall eﬃciency and accuracy . For a pre - trained model without transfer learning , the model achieves detection accuracy of 92 % and 95 % with transfer learning . The tracking accuracy of the model is 95 % . The work may be improved in the future for diﬀerent indoor and outdoor environments . Diﬀerent detection and tracking algorithms might be used to help track the person or people who are violating or breaches the social distancing threshold . Acknowledgments This work is partially supported by FCT / MCTES through national funds and when applicable co - funded EU funds under the project UIDB / 50008 / 2020 ; and by Brazilian National Council for Scientiﬁc and Technological Development ( CNPq ) via Grant No . 309335 / 2017 - 5 . References [ 1 ] W . H . Organization ( 2020 ( accessed May 02 , 2020 ) ) . URL : https : / / www . who . int / emergencies / diseases / novel - corona - virus - 2019 . [ 2 ] WHO ( Online ; accessed March 12 , 2020 ) . URL : https : / / www . who . int / dg / speeches / detail / 2020 . [ 3 ] W . C . D . C . - . Dashboard ( Online ; accessed August 23 , 2020 ) . URL : https : / / covid19 . who . int / . [ 4 ] N . M . Ferguson , D . A . Cummings , S . Cauchemez , C . Fraser , S . Riley , A . Meeyai , S . Iamsirithaworn , D . S . Burke , Nature 437 ( 2005 ) 209 – 214 . [ 5 ] C . Adlhoch ( March , 2020 ) . URL : " https : / / www . ecdc . europa . eu / sites / default / files / documents / covid - 19 - social - distancing - measuresg - guide - second - update . pdf " . 24 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 6 ] ( Online ; accessed August 18 , 2020 ) . URL : " https : / / www . statista . com / chart / 21198 / effect - of - social - distancing - signer - lab / " . [ 7 ] ( Online ; accessed August 18 , 2020 ) . URL : " https : / / www . health . harvard . edu / diseases - and - conditions / preventing - the - spread - of - the - coronavirus " . [ 8 ] C . T . Nguyen , Y . M . Saputra , N . Van Huynh , N . - T . Nguyen , T . V . Khoa , B . M . Tuan , D . N . Nguyen , D . T . Hoang , T . X . Vu , E . Dutkiewicz , et al . , arXiv preprint arXiv : 2005 . 02816 ( 2020 ) . [ 9 ] A . Brunetti , D . Buongiorno , G . F . Trotta , V . Bevilacqua , Neurocomputing 300 ( 2018 ) 17 – 33 . [ 10 ] D . Yang , E . Yurtsever , V . Renganathan , K . A . Redmill , ¨U . ¨Ozg¨uner , arXiv preprint arXiv : 2007 . 03578 ( 2020 ) . [ 11 ] N . S . Punn , S . K . Sonbhadra , S . Agarwal , arXiv preprint arXiv : 2005 . 01385 ( 2020 ) . [ 12 ] L . Ramadass , S . Arunachalam , Z . Sagayasree , International Journal of Per - vasive Computing and Communications ( 2020 ) . [ 13 ] I . Ahmed , A . Adnan , Cluster Computing ( 2017 ) 1 – 22 . [ 14 ] M . Ahmad , I . Ahmed , F . A . Khan , F . Qayum , H . Aljuaid , International Journal of Distributed Sensor Networks 16 ( 2020 ) 1550147720934738 . [ 15 ] I . Ahmed , S . Din , G . Jeon , F . Piccialli , IEEE Internet of Things Journal ( 2019 ) . [ 16 ] I . Ahmed , M . Ahmad , A . Adnan , A . Ahmad , M . Khan , International Jour - nal of Machine Learning and Cybernetics ( 2019 ) 1 – 12 . [ 17 ] I . Ahmed , A . Ahmad , F . Piccialli , A . K . Sangaiah , G . Jeon , IEEE Internet of Things Journal 5 ( 2018 ) 1598 – 1605 . 25 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 18 ] M . Ahmad , I . Ahmed , K . Ullah , I . Khan , A . Adnan , in : 2018 9th IEEE Annual Ubiquitous Computing , Electronics Mobile Communication Con - ference ( UEMCON ) , pp . 746 – 752 . doi : 10 . 1109 / UEMCON . 2018 . 8796595 . [ 19 ] J . - W . Choi , D . Moon , J . - H . Yoo , ETRI Journal 37 ( 2015 ) 551 – 561 . [ 20 ] C . Migniot , F . Ababsa , Journal of Real - Time Image Processing 11 ( 2016 ) 769 – 784 . [ 21 ] M . Ahmad , I . Ahmed , K . Ullah , I . Khan , A . Khattak , A . Adnan , International Journal of Advanced Computer Science and Applications 10 ( 2019 ) . URL : http : / / dx . doi . org / 10 . 14569 / IJACSA . 2019 . 0100367 . doi : 10 . 14569 / IJACSA . 2019 . 0100367 . [ 22 ] J . Redmon , A . Farhadi , arXiv preprint arXiv : 1804 . 02767 ( 2018 ) . [ 23 ] B . News ( Online ; accessed January 23 , 2020 ) . URL : " https : / / www . bbc . co . uk / news / world - asia - china51217455 , 2020 " . [ 24 ] N . H . C . of the Peoples Republic of China ( Online ; accessed March 20 , 2020 ) . URL : " http : / / en . nhc . gov . cn / 2020 - 03 / 20 / c78006 . htm , 2020 " . [ 25 ] K . E . Ainslie , C . E . Walters , H . Fu , S . Bhatia , H . Wang , X . Xi , M . Baguelin , S . Bhatt , A . Boonyasiri , O . Boyd , et al . , Wellcome Open Research 5 ( 2020 ) . [ 26 ] N . S . Punn , S . K . Sonbhadra , S . Agarwal , medRxiv ( 2020 ) . [ 27 ] M . Robakowska , A . Tyranska - Fobke , J . Nowak , D . Slezak , P . Zuratynski , P . Robakowski , K . Nadolny , J . R . (cid:32)Ladny , Disaster and Emergency Medicine Journal 2 ( 2017 ) 129 – 134 . [ 28 ] A . Harvey , J . LaPlace , Megapixels : Origins , ethics , and privacy implica - tions of publicly available face recognition image datasets , 2019 . [ 29 ] S . P . B . D . L . H . B . R . F . A . S . B . R . R . V . S . A . O . C . F . F . H . D . A . R . d . A . L . R . J . J . P . C . R . Patrick R . S . dos Santos , Lucas B . M . de Souza , 22nd International Conference on E - Health Networking , Applications and 26 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Services ( IEEE Healthcom 2020 ) , Shenzhen , China , December 12 - 15 , 2020 ( 2020 ) . [ 30 ] M . S . Iqbal , I . Ahmad , L . Bin , S . Khan , J . J . Rodrigues , Transactions on Emerging Telecommunications Technologies ( 2020 ) e4017 . [ 31 ] D . G . A . K . R . S . J . J . P . C . R . Yash Chaudhary , Manan Mehta , 22nd In - ternational Conference on E - Health Networking , Applications and Services ( IEEE Healthcom 2020 ) , Shenzhen , China , December 12 - 15 , 2020 ( 2020 ) . [ 32 ] L . G . J . J . P . C . R . Chinmay Chakraborty , Amit Banerjee , Series Studies in Big Data 80 ( 2021 ) 98 – 136 . doi : 10 . 1007 / 978 - 981 - 15 - 8097 - 0 . [ 33 ] B . A . G . L . R . J . Chakraborty , C . , Springer ( 2021 ) . [ 34 ] K . Prem , Y . Liu , T . W . Russell , A . J . Kucharski , R . M . Eggo , N . Davies , S . Flasche , S . Cliﬀord , C . A . Pearson , J . D . Munday , et al . , The Lancet Public Health ( 2020 ) . [ 35 ] C . Adolph , K . Amano , B . Bang - Jensen , N . Fullman , J . Wilkerson , medRxiv ( 2020 ) . [ 36 ] C . A . Pouw , F . Toschi , F . van Schadewijk , A . Corbetta , arXiv preprint arXiv : 2007 . 06962 ( 2020 ) . [ 37 ] A . J . Sathyamoorthy , U . Patel , Y . A . Savle , M . Paul , D . Manocha , arXiv preprint arXiv : 2008 . 06585 ( 2020 ) . [ 38 ] A . Krizhevsky , I . Sutskever , G . E . Hinton , in : Advances in neural informa - tion processing systems , pp . 1097 – 1105 . [ 39 ] K . Simonyan , A . Zisserman , arXiv preprint arXiv : 1409 . 1556 ( 2014 ) . [ 40 ] R . Girshick , J . Donahue , T . Darrell , J . Malik , in : Proceedings of the IEEE conference on computer vision and pattern recognition , pp . 580 – 587 . 27 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 41 ] C . Szegedy , W . Liu , Y . Jia , P . Sermanet , S . Reed , D . Anguelov , D . Erhan , V . Vanhoucke , A . Rabinovich , in : Proceedings of the IEEE conference on computer vision and pattern recognition , pp . 1 – 9 . [ 42 ] R . Girshick , in : Proceedings of the IEEE international conference on com - puter vision , pp . 1440 – 1448 . [ 43 ] S . Ren , K . He , R . Girshick , J . Sun , in : Advances in neural information processing systems , pp . 91 – 99 . [ 44 ] T . - Y . Lin , M . Maire , S . Belongie , J . Hays , P . Perona , D . Ramanan , P . Doll´ar , C . L . Zitnick , in : European conference on computer vision , Springer , pp . 740 – 755 . [ 45 ] J . Redmon , S . Divvala , R . Girshick , A . Farhadi , in : Proceedings of the IEEE conference on computer vision and pattern recognition , pp . 779 – 788 . [ 46 ] I . Ahmed , M . Ahmad , M . Nawaz , K . Haseeb , S . Khan , G . Jeon , Computer Communications 147 ( 2019 ) 188 – 197 . 28 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Title Page ( with Author Details ) J o u r n a l P r e - p r o o f A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 Abstract The ongoing COVID - 19 corona virus outbreak has caused a global disaster with its deadly spreading . Due to the absence of eﬀective remedial agents and the shortage of immunizations against the virus , population vulnerability increases . In the current situation , as there are no vaccines available ; therefore , social distancing is thought to be an adequate precaution ( norm ) against the spread of the pandemic virus . The risks of virus spread can be minimized by avoid - ing physical contact among people . The purpose of this work is , therefore , to provide a deep learning platform for social distance tracking using an overhead perspective . The framework uses the YOLOv3 object recognition paradigm to identify humans in video sequences . The transfer learning methodology is also implemented to increase the accuracy of the model . In this way , the detection algorithm uses a pre - trained algorithm that is connected to an extra trained layer using an overhead human data set . The detection model identiﬁes peoples using detected bounding box information . Using the Euclidean distance , the detected bounding box centroid’s pairwise distances of people are determined . To estimate social distance violations between people , we used an approxima - Preprint submitted to Journal of L A TEX Templates October 14 , 2020 Revised Manuscript without Changes Marked ( without Author Details ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f tion of physical distance to pixel and set a threshold . A violation threshold is established to evaluate whether or not the distance value breaches the min - imum social distance threshold . In addition , a tracking algorithm is used to detect individuals in video sequences such that the person who violates / crosses the social distance threshold is also being tracked . Experiments are carried out on diﬀerent video sequences to test the eﬃciency of the model . Findings in - dicate that the developed framework successfully distinguishes individuals who walk too near and breaches / violates social distances ; also , the transfer learn - ing approach boosts the overall eﬃciency of the model . The accuracy of 92 % and 98 % achieved by the detection model without and with transfer learning , respectively . The tracking accuracy of the model is 95 % . Keywords : Deep Learning , Social Distancing , COVID - 19 , Transfer Learning , Overhead View , Person Detection , YOLOv3 1 . Introduction COVID - 19 originated from Wuhan , China , has aﬀected many countries world - wide since December 2019 . On March 11 , 2020 , the World Health Organiza - tion ( WHO ) announced it a pandemic diseases as the virus spread through 114 countries , caused 4000 deaths and 118 , 000 active cases [ 1 ] [ 2 ] . On October 7 , 2020 , they reported more than 35 , 537 , 491 conﬁrmed COVID - 19 cases , includ - ing 1 , 042 , 798 deaths . The latest number of infected people due to pandemic is shown in Figure . 5 [ 3 ] . Many healthcare organizations , scientists , and medical professionals are searching for proper vaccines and medicines to overcome this deadly virus , although no progress is reported to - date . To stop the virus spread , the global community is looking for alternate ways . The virus mainly spreads in those people ; who are in close contact with each other ( within 6 feet ) for a long period . The virus spreads when an infected person sneezes , coughs , or talks , the droplets from their nose or mouth disperse through the air and aﬀect nearby peoples . The droplets also transfer into the lungs through the respiratory sys - tem , where it starts killing lung cells . Recent studies show that individuals with 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f no symptoms but are infected with the virus also play a part in the virus spread [ 3 ] . Therefore , it is necessary to maintain at least 6 feet distance from others , even if people do not have any symptoms . ( a ) Region wise number of conﬁrmed cases ( October 7 , 2020 ) ( b ) Region wise number of deaths , ( October 7 , 2020 ) . Figure 1 : Latest number conﬁrmed cases and deaths reported by WHO due to pandemic [ 3 ] . Social distancing associates with the measures that overcome the virus’ spread , by minimizing the physical contacts of humans , such as the masses at public places ( e . g . , shopping malls , parks , schools , universities , airports , workplaces ) , evading crowd gatherings , and maintaining an adequate distance between peo - ple [ 4 ] , [ 5 ] . Social distancing is essential , particularly for those people who are at higher risk of serious illness from COVID - 19 . By decreasing the risk of virus transmission from an infected person to a healthy , the virus’ spread and dis - 3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f ease severity can be signiﬁcantly reduced [ 6 ] Figure . 2 . If social distancing is implemented at the initial stages , it can perform a pivotal role in overcoming the virus spread and preventing the pandemic disease’s peak , as illustrated in Figure . 3 [ 7 ] . It can be observed that social distancing can decrease the num - ber of infected patients and reduce the burden on healthcare organizations . It also lowers the mortality rates by assuring that the number of infected cases ( patients ) does not surpass the public healthcare capability [ 8 ] . Figure 2 : Importance of Social distancing . Figure 3 : Eﬀect of social distancing : the peak of pandemic cases is decreasing and meeting with available healthcare capability [ 7 ] . 4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f In the past decades , computer vision , machine learning , and deep learning have shown promising results in several daily life problems . Recent improvement in deep learning allows object detection tasks [ 9 ] more eﬀective . Researchers [ 10 ] , [ 11 ] , [ 12 ] , often utilize these methods to measure social distancing among peo - ple across the moving frames , as seen in Figure . 4 . To determine the distancing between people , clustering and distance - based methods are utilized . From Fig - ure . 4 , it can be be seen that most of the methods are developed using frontal or side view video sequences , which requires a proper camera calibration to map pixels to distance for real easily , measurable units ( i . e . , feet , meters , etc . ) . Sec - ondly , if we assume a top - down approach , i . e . , an overhead view approach , then the distance calculations from the overhead view will lead to a better distance approximation and wide coverage of the wide scene . ( a ) ( b ) ( c ) ( d ) ( e ) ( f ) Figure 4 : Example images from the literature , used for social distance monitoring . ( a ) , ( b ) & ( c ) [ 10 ] used Faster - RCNN for monitoring social distance ( d ) & ( e ) [ 11 ] used YOLOv3 with Deepsort to monitor social distancing on Oxford Town Center , and ( f ) [ 12 ] . In this work , we used an overhead view to provide an eﬀective framework for social distance monitoring . Some scholars , e . g . [ 13 ] , [ 14 ] , [ 15 ] , [ 16 ] , [ 17 ] , [ 18 ] , [ 19 ] , and [ 20 ] use an overhead perspective for human detection and tracking . The overhead perspective oﬀers a better ﬁeld of view and overcomes the issues 5 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f of occlusion , thereby playing a key role in social distance monitoring to compute the distance between peoples . It might help overcome computation , communica - tion load , energy consumption , human resource , and installation costs [ 21 ] . This work aims to present a deep learning - based social distance monitoring frame - work for the public campus environment from an overhead perspective . A deep learning model , i . e . , YOLOv3 ( You Only Look Once ) [ 22 ] , is applied for human detection . The current model ( pre - trained on frontal or normal view data sets ) is initially tested on the overhead data set . Transfer learning is also used to improve the eﬃciency of the detection model . To the best of our knowledge , this work could be considered as the ﬁrst eﬀort to use an overhead view per - spective to monitor social distance with transfer learning . The detection model detects humans and gives bounding box information . The detection model de - tects humans and gives bounding box information . After human detection , the Euclidean distance between each detected centroid pair is computed using the detected bounding box and its centroid information . A predeﬁned minimum social distance violation threshold is speciﬁed using pixel to distance assump - tions . To check , either the calculated distance comes under the violation set or not , the estimated information is matched with the violation threshold . The bounding box’s color is formerly initialized as green ; if the bounding box comes under the violation set , its color is updated to red . In addition , the centroid tracking algorithm is used to track a person who violated the social distancing threshold . The key goals of this work are as follows : • To present a deep learning - based social distance monitoring framework using an overhead view perspective . • To deploy pre - trained YOLOv3 for human detection and computing their bounding box centroid information . In addition , a transfer learning method is applied to enhance the performance of the model . The additional train - ing is performed with overhead data set , and the newly trained layer is appended to the pre - trained model . • In order to track the social distance between individuals , the Euclidean 6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f distance is used to approximate the distance between each pair of the centroid of the bounding box detected . In addition , a social distance violation threshold is speciﬁed using a pixel to distance estimation . • Utilizing a centroid tracking algorithm to keep track of the person who violates the social distance threshold . • To assess the performance of pre - trained YOLOv3 by evaluating it on an overhead data set . The output of the detection framework is assessed with and without the transition of learning . Furthermore , the model per - formance is also compared with other deep learning models . The rest of the work discussed in the paper is structured as follows . The related work is presented in Section . 2 . A deep learning - based social distance monitoring framework has been presented in Section . 3 . The overhead view data set used for training and testing during experimentation is brieﬂy discussed in Section . 4 . The detailed analysis of output results and performance evaluation of the model with and without transfer learning is also illustrated in this Section . The con - clusion of the given work with potential future plans is provided in Section . 5 . 2 . Literature Review After the rise of the COVID - 19 pandemic since late December 2019 , Social dis - tancing is deemed to be an utmost reliable practice to prevent the contagious virus transmission and opted as standard practice on January 23 , 2020 [ 23 ] . During one month , the number of cases rises exceptionally , with two thousand to four thousand new conﬁrmed cases reported per day in the ﬁrst week of February 2020 . Later , there has been a sign of relief for the ﬁrst time for ﬁve successive days up to March 23 , 2020 , with no new conﬁrmed cases [ 24 ] . This is because of the social distance practice initiated in China and , latterly , adopted by worldwide to control COVID - 19 . Kylie et al . [ 25 ] investigated the relation - ship between the region’s economic situation and the social distancing strictness . The study revealed that moderate stages of exercise could be allowed for evading 7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f a large outbreak . So far , many countries have used technology - based solutions [ 26 ] to overcome the pandemic loss . Several developed countries are employ - ing GPS technology to monitor the movements of the infected and suspected individuals . [ 8 ] provides a survey of diﬀerent emerging technologies , including Wi - ﬁ , Bluetooth , smartphones , and GPS , positioning ( localization ) , computer vision , and deep learning that can play a crucial role in several practical so - cial distancing scenarios . Some researchers utilize drones and other surveillance cameras to detect crowd gatherings [ 27 ] & [ 28 ] . Until now researchers have done considerable work for detection [ 29 ] , [ 30 ] , & [ 31 ] , some provides an smart healthcare system for pandemic using Internet of Medical Things [ 32 ] , & [ 33 ] . Prem et al . [ 34 ] studied the social distancing impacts on the spread of the COVID - 19 outbreak . The studies concluded that the early and immediate practice of social distancing could gradually reduce the peak of the virus attack . As we all know , that although social distancing is cru - cial for ﬂattening the infection curve , it is an economically unpleasant step . In [ 35 ] , Adolph et al . highlighted the United States of America’s condition during the pandemic . Due to a lack of general support by decision - makers , it was not implemented at an initial stage , starting harm to public health . However , so - cial distancing inﬂuenced economic productivity ; even then , numerous scholars sought alternatives that overcame the loss . Researchers provide eﬀective solutions for social distance measuring using surveil - lance videos along with computer vision , machine learning , and deep learning - based approaches . Punn et al . [ 11 ] proposed a framework using the YOLOv3 model to detect humans and the Deepsort approach to track the detected people using bounding boxes and assigned IDs information . They used an open image data set ( OID ) repository , a frontal view data set . The authors also compared results with Faster - RCNN and SSD . [ 12 ] developed an autonomous drone - based model for social distance monitoring . They trained the YOLOv3 model with the custom data set . The data set is composed of frontal and side view images of limited people . The work is also extended for the monitoring of facial masks . The drone camera and the YOLOv3 algorithm help identify the social distance 8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f and monitor people from the side or frontal view in public wearing masks . Pouw et al . , [ 36 ] suggested an eﬃcient graph - based monitoring framework for phys - ical distancing and crowd management . [ 37 ] performed human detection in a crowded situation . The model is designed for individuals who do not obey a social distance restriction , i . e . , 6 feet of space between them . The authors used a mobile robot with an RGB - D camera and a 2 - D lidar to make collision - free navigation in mass gatherings . From the literature , we concluded that the researcher had done a considerable amount of work for monitoring of social distance in public environments . But , most of the work is focused on the frontal or side view camera perspective . Therefore , in this work , we presented an overhead view social distance moni - toring framework that oﬀers a better ﬁeld of view and overcomes the issues of occlusion , thereby playing a key role in social distance monitoring to compute the distance between peoples . 3 . Social Distance Monitoring Researchers use a frontal or side perspective for social distance monitoring , as discussed in Section . 2 . In this work , a deep learning - based social distance monitoring framework using an overhead perspective has been introduced . The ﬂow diagram of the framework is shown in Figure . 5 . The recorded overhead data set are split into training and testing sets . A deep learning - based detection paradigm is used to detect individuals in sequences . There are a variety of object detection models available , such as [ 38 ] , [ 39 ] , [ 40 ] , [ 41 ] , [ 42 ] and [ 43 ] . Due to the best performance results for generic object detection , in this work , YOLOv3 [ 22 ] is used . The model used single - stage network architecture to estimate the bounding boxes and class probabilities . The model was originally trained on the COCO ( Common objects in context ) data set [ 44 ] . For overhead view person detection , transfer learning is implemented to enhance the detection model’s eﬃciency , and a new layer of overhead training is added with the existing architecture . 9 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 5 : Flow diagram of overhead view social distance monitoring framework . After detection , the bounding box information , mainly centroid information , is used to compute each bounding box centroid distance . We used Euclidean distance and calculated the distance between each detected bounding box of peoples . Following computing centroid distance , a predeﬁned threshold is used to check either the distance among any two bounding box centroids is less than the conﬁgured number of pixels or not . If two people are close to each other and the distance value violates the minimum social distance threshold . The bounding box information is stored in a violation set , as seen in Figure . 5 , and the color of the bounding box is updated / changed to red . A centroid tracking algorithm is adopted for tracking so that it helps in tracking of those people who violate / breach the social distancing threshold . At the output , the model displays the information about the total number of social distancing violations 10 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f along with detected people bounding boxes and centroids . In this work , YOLOv3 is used for human detection as it improves predictive accuracy , particularly for small - scale objects . The main advantage is that it has adjusted network structure for multi - scale object detection . Furthermore , for object classiﬁcation , it uses various independent logistic rather than softmax . The model’s overall architecture is presented in Figure . 6 ; it can be seen that feature learning is performed using the convolutional layers , also called Residual Blocks . The blocks are made up of many convolutional layers and skip connec - tions . The model’s unique characteristic is that it performs detection at three separate scales , as depicted in Figure . 6 . The convolutional layers with a given stride are practiced to downsample the feature map and transfer invariant - sized features [ 22 ] . Three feature maps , as shown in Figure . 6 , are utilized for object detection . Figure 6 : General architecture of YOLOv3 utilized for overhead view human detection . The architecture shown in Figure . 6 is trained using an overhead data set . For that purpose , a transfer learning approach is adopted , that enhance the eﬃ - ciency of the model . With transfer learning , the model is additionally trained without dropping the valuable information of the existing model . Further , the additional overhead data set trained layer is appended with the existing archi - tecture . In this way , the model takes advantage of the pre - trained and newly 11 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f trained information , and both detection results are further deliver better and faster detection results . The architecture shown in Figure . 6 used a single - stage network for the entire input image to predict the bounding box and class probability of detected ob - jects . For feature extraction , the architecture utilizes convolution layers , and for class prediction , fully connected layers are used . During human identiﬁcation , as seen in Figure . 6 , the input frame is divided into a region of S , also called grid cells . These cells are related to bounding box estimation and class probabilities . It predicts the probability of whether the center of the person bounding box is in the grid cell or not . Conf ( p ) = Pr ( p ) × IOU ( pred , actual ) ( 1 ) In Equation . 1 , Pr ( p ) indicates that whether the person present is in the de - tected bounding box or not . The value of Pr ( p ) is 1 for yes and 0 for not . IoU ( pred , actual ) determines the Intersection Over Union of the actual and predicted bounding box . It is deﬁned as [ 22 ] : IoU ( pred , actual ) = areaBoxT ∩ BoxP BoxT ∪ BoxP ( 2 ) Where the ground truth box ( actual ) manually labeled in the training data set represented with BoxT , and the predicted bounding box is displayed as BoxP . area presents the area of intersection . An acceptable area is predicted and decided for each detected person in the input frame . The conﬁdence value is applied after prediction to achieve the optimal bounding box . For each predicted bounding box , h , w , x , y are estimated , where bounding box coordinates are deﬁned by x , y , and width and height are determined by w , h . The model produces the following predicted bounding box values as seen in Figure . 7 and Equation . 3 [ 22 ] ; b x = σ ( t x ) + c x b y = σ ( t y ) + c y b w = p w e tw b h = p w h th ( 3 ) 12 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f In Equation . 3 , , b x , b y , b w , b h are predicted coordinate bounding boxes , where the coordinates’ center is represented as x , y and width and height with w , h . t w , t h , t x , t y , deﬁned the network output and c x , c y are used to correspond the top - left coordinates of the grid cell as shown in Figure . 7 , while the p w and p h are width and height of anchors . Figure 7 : Detected coordinates of person bounding box . A threshold value is deﬁned that process the high conﬁdence values and discards the low conﬁdence values . Using non - maximal suppression , the ﬁnal location parameters are derived for the detected bounding box . At last , loss function is calculated , for detected bounding box [ 22 ] . The given loss function is the sum of three functions , i . e . , regression , classiﬁcation , and conﬁdence . At each grid cell , if the object is detected , then the classiﬁcation loss is computed as the squared error of the conditional class probabilities and calculated as [ 22 ] ; L cls = S 2 (cid:88) i = 0 1 objij (cid:88) c(cid:15)class 1 obji ( p i ( c ) − p ∗ i ( c ) ) 2 ( 4 ) In Equation . 4 , in grid cell i if the person is detected then 1 objij = 1 , otherwise equals to 0 . The conditional class probabilities for class c in grid cell i are represented as p ∗ i ( c ) . The localization loss estimates the failures in the predicted bounding box sizes and locations . The bounding box containing the detected 13 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f object , i . e . , a person , is added . It is deﬁned as [ 22 ] ; L loc = λ coord 1 objij S 2 (cid:88) i = 0 B (cid:88) j = 0 [ ( x i − x ∗ i ) 2 + ( y i − y ∗ i ) 2 + ( √ w i − (cid:112) w ∗ i ) 2 + ( (cid:112) h i − (cid:112) h ∗ i ) 2 ] ( 5 ) In above equation 1 objij is equal to 1 , in case if the j th bounding box in grid cell i is used for object detection , otherwise it is equal to 0 . Instead of predicting simple height and width , the model predicts the square root of the bounding box width and height . In Equation . 5 the scale parameters λ coord is used for predictions of bounding box coordinates and equals to 5 as [ 45 ] . The predicted positions are represented with x i , yi , h i , w i in ith cell of detected bounding box , while the actual positions of bounding box in the i th cell is deﬁned using x ∗ i , y ∗ i , h ∗ i , w ∗ i . The Equation . 5 measures the loss function of predicted bounding box having coordinates value x , y . To represent the possibility of the detected person in the jth bounding box 1 objij is used . The value of λ is constant , the function in Equation . 5 calculates sum over each bounding box , using ( j = 0 to B ) as predictor for each grid cell ( i = 0 to S 2 ) . Finally the conﬁdence loss is calculated that is given in Equation . 6 as [ 22 ] : L conf = S 2 (cid:88) i = 0 B (cid:88) j = 0 1 objij ( C i − C ∗ i ) 2 ( 6 ) Where , the conﬁdence score is deﬁned as C ∗ , for j th bounding box in grid cell i and 1 objij and is equal to 1 in case if in cell i the j th bounding box is responsible for object detection ; otherwise it is equal to 0 . In case if the object is not detected , then the conﬁdence loss is provided as [ 22 ] ; L conf = λ noobj S 2 (cid:88) i = 0 B (cid:88) j = 0 1 noobjij ( C i − C ∗ i ) 2 ( 7 ) In Equation . 7 , 1 noobjij is deﬁned as the complement of 1 objij . The bounding box’ conﬁdence score C ∗ in cell i and λ noobj is used to weights down the loss during detecting background . As in most cases detected , bounding boxes do not contain any objects that cause a class imbalance problem ; therefore , the model is more 14 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f frequently trained to detect background rather than detect objects . To solve this , the loss is weight down by a factor λ noobj ( default : 0 . 5 ) . After detecting people in video frames , in the next step , the centroid of each detected person bounding boxes shown as green boxes are used for distance cal - culation , as shown in Figure . 8 ( b ) . The detected bounding box coordinates ( x , y ) are used to compute the bounding box’s centroid . Figure . 8 ( c ) demonstrates ac - Figure 8 : ( a ) Input image , ( b ) detected person bounding boxes using deep learning algorithm , ( c ) compute the centroid of each detected bounding box , and ( d ) ﬁnally , the distance between each pair of the centroid is determined . In the example image , the red lines indicate the distance between each bounding box centroid . cepting a set of bounding box coordinates and computing the centroid . After computing , centroid , a unique ID is assigned to each detected bounding box . In the next step , we measure the distance between each detected centroid using Euclidean distance . For every subsequent frame in the video stream , we ﬁrstly 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f compute bounding box centroids shown in Figure . 8 ( c ) ; and then calculate the distance ( highlighted with red lines ) between each pair of detected bounding box centroids , Figure . 8 ( d ) . The information of each centroid is stored in the form of a list . Based on distance values , a threshold is deﬁned to check if any two people are less than N pixels apart or not . If the distance violates the min - imum social distance set or two people are too close , then the information is added into the violation set . The bounding box color is initialized as green . The information is checked in the violation set ; if the current index exists violation set , the color is updated to red . Furthermore , the centroid tracking algorithm is used to track the detected people in the video sequence . The tracking algorithm also helps to keep track of people who are violating the social distance threshold . At the output , the model displays information about the total number of social distancing violations . 4 . Experiments , Results , and Discussion The detailed descriptions of various experiments carried out in this work are presented in this section . For social distance monitoring , an indoor data set recorded at Institute of Management Sciences , Hayatabad , Peshawar Pakistan is used [ 16 ] & [ 46 ] , containing video sequences captured from the overhead view . The data collection is divided into 70 % and 30 % training and testing , respec - tively . There is no restriction on the mobility of persons throughout the scene . Peoples in the scene move freely ; their visual appearance is aﬀected by radial distance and camera position . From example frames , It can be observed that the human’s visual appearance is not identical , and peoples heights , poses , scales are varying in the data set . For implementation , we used OpenCV . The exper - imental results are divided into two subsections ; ﬁrst , the pre - trained model’s testing results are discussed , while in the second subsection , the results of the detection model after applying transfer learning and training on the overhead data set are explained . For comparison , the model is tested using the same video sequences . The performance evaluation of the model is also made in this 16 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f section , along with a comparison with diﬀerent deep learning models . 4 . 1 . Results of Social Distance monitoring using pre - trained model In Figure . 9 , the testing results of the social distance framework using a pre - trained model [ 22 ] has been visualized . The testing results are evaluated using diﬀerent video sequences . The people in the video sequences are freely moving in the scenes ; it can be seen from sample frames that the individual’s visual appearance is not identical to the frontal or side view ( Figure . 9 ) . The person’s Figure 9 : Social distance monitoring from an overhead view using a pre - trained detection model . In sample frames , the people in green rectangles are those who maintain the social distancing . The people who violate the social distance threshold are shown red in rectangles . The manually labels yellow positive cross shows miss detections . size is also varying at diﬀerent locations , as shown in Figure . 9 . Since the model 17 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f only considers human ( person ) class ; therefore , only an object having an appear - ance like a human is detected by a pre - trained model . The pre - trained model delivers good results and detects various size person bounding boxes , as shown with green rectangles in Figure . 9 ( a ) , ( b ) & ( c ) . From sample frames of Figure . 9 , people are marked with green rectangles as they maintain a social distancing threshold . The model is also tested for multiple peoples , as depicted in Fig - ure . 9 ( g ) , ( h ) & ( i ) , multiple people are entering in the scene . In sample images , it can be seen that after person detection , the distance between each detected bounding box is measured to check whether the person in the scene violates the social distance or not . In Figure . 9 ( e ) , & ( h ) , two people at the center of the scene are marked with red bounding boxes as they violate or breaches the social distancing threshold . Some miss detections also occur that are manually labeled with a yellow cross in sample frames . From the sample frames , it can be seen that a person is eﬀectively detected at several scene locations . However , in some cases , the person’s appearance is changing ; therefore , the model gives miss detections . The reason for miss detection maybe , as the pre - trained model is applied , and an individual’s appearance from an overhead view is changing , which may be misleading for the model . 4 . 2 . Results of Social Distance monitoring using Transfer Learning . The transfer learning methodology is applied to improve the accuracy of the detection model . Using an overhead data set , the model is additionally trained using 500 sample frames . The epoch size 40 and batch size 64 is set for training of the model . The training loss and accuracy curves are shown in Figure . 10 and in Figure . 11 . A new layer is obtained after training the model ; that is further appended with a pre - trained model . The model is now tested for the same test video sequences , as discussed in the above sub - section . The experimental ﬁndings reveal that transfer learning sig - niﬁcantly increases the detection results , as seen in Figure . 12 . From the sample images , it can be visualized that the model detects the individuals at various scene locations . People with various characteristics are eﬀectively - identiﬁed , 18 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 10 : Training loss of YOLOv3 using overhead view data set . Figure 11 : Training Accuracy of YOLOv3 using overhead view data set . and the social distance between people is also computed , as shown in the sam - ple frames . In sample frames of Figure . 12 ( a ) , ( b ) , & ( c ) , there is no social distance violation found , since all people are marked with green rectangle boxes by the automated framework . While in the sample frame Figure . 12 ( e ) , the vio - lation is detected ; however , the number of people present in the scene is small as compared to Figure . 12 ( b ) , where all people are maintaining social distance , and therefore not a single violation is observed . In Figure . 12 ( d ) , ( e ) & ( f ) , due to close interactions between people , violation is recorded by automated system . The same behavior can be found in Figure . 12 ( g ) , ( h ) , & ( i ) where people are around dozen in both ( g ) & ( h ) and violation in ( h ) is three times as compared 19 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f to ( g ) . In Figure . 12 ( d ) , ( e ) & ( f ) , multiple people are walking , and entering in the scene are detected and monitored . The framework eﬀectively detected the breach of social distance between people and marked the bounding box as red rectangles if people are too close to each other . Figure 12 : Results of social distance monitoring , using transfer learning . It can be seen that the detection performance of the model is improved after transfer learning . In sample frames , the people in green rectangles maintain social distancing while in red rectangles are those who breach / violate the social distance . 4 . 3 . Performance Evaluation Diﬀerent quantitative metrics are used in this work to evaluate the performance of the framework for social distance monitoring using a deep learning model and an overhead perspective . To assess the eﬃciency of the detection model , Precision , Recall , and Accuracy is used . Furthermore , the ﬁndings are also compared with other deep learning models . For estimation of Precision , Recall 20 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f and Accuracy , we used , tp true positive , fp , false positives , tn true negative and fn false - negative . The Accuracy Recall and Precision results are shown in Figure . 13 . It can be analyzed that when the model is additionally trained for overhead view data set , the overall performance of the detection model is improved . The tracking accuracy is also given in Figure . 14 . Figure 13 : Precision , Recall , and Accuracy of model ( YOLOv3 ) with and without transfer learning . We also compared the newly trained YOLOv3 with other deep learning models . The True detection and False detection rate of diﬀerent deep learning models are depicted in Table . 1 . From the results , it can be seen that transfer learning improved the results signiﬁcantly for the overhead view data set . The false detection rate of diﬀerent deep learning models are very small , about 0 . 7 % to 0 . 4 % without any training , which reveals the eﬀectiveness of deep learning models . Diﬀerent pre - trained object detection models are tested on the overhead data set . Although the models were trained on the diﬀerent frontal data sets , they still show good results by achieving an accuracy of 90 % . In Figure . 15 , the comparison results of diﬀerent state of the art detection are shown . 21 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 14 : Tracking Accuracy with pre - trained and trained YOLOv3 detection model . Table 1 : Comparison results of YOLOv3 with other deep learning models . S . No Model True Detection rate False Detection rate 1 . Fast - RCNN ( Pre - trained ) 90 % 0 . 7 % 2 . Faster - RCNN ( Pre - trained ) 92 % 0 . 6 % 3 . Mask - RCNN ( Pre - Trained ) 92 % 0 . 5 % 4 . YOLOv3 ( Pre - trained ) 92 % 0 . 4 % 5 YOLOv3 ( trained Overhead data set ) 95 % 0 . 3 % 22 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Figure 15 : Comparison results of YOLOv3 trained on overhead data set with other methods . 5 . Conclusion and Future Works In this work , a deep learning - based social distance monitoring framework is presented using an overhead perspective . The pre - trained YOLOv3 paradigm is used for human detection . As a person’s appearance , visibility , scale , size , shape , and pose vary signiﬁcantly from an overhead view , the transfer learning method is adopted to improve the pre - trained model’s performance . The model is trained on an overhead data set , and the newly trained layer is appended with the existing model . To the best of our knowledge , this work is the ﬁrst attempt that utilized transfer learning for a deep learning - based detection paradigm , used for overhead perspective social distance monitoring . The detection model gives bounding box information , containing centroid coordinates information . Using the Euclidean distance , the pairwise centroid distances between detected bounding boxes are measured . To check social distance violations between peo - ple , an approximation of physical distance to the pixel is used , and a threshold is deﬁned . A violation threshold is used to check if the distance value violates the minimum social distance set or not . Furthermore , a centroid tracking algo - rithm is used for tracking peoples in the scene . Experimental results indicated that the framework eﬃciently identiﬁes people walking too close and violates social distancing ; also , the transfer learning methodology increases the detec - 23 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f tion model’s overall eﬃciency and accuracy . For a pre - trained model without transfer learning , the model achieves detection accuracy of 92 % and 95 % with transfer learning . The tracking accuracy of the model is 95 % . The work may be improved in the future for diﬀerent indoor and outdoor environments . Diﬀerent detection and tracking algorithms might be used to help track the person or people who are violating or breaches the social distancing threshold . Acknowledgments This work is partially supported by FCT / MCTES through national funds and when applicable co - funded EU funds under the project UIDB / 50008 / 2020 ; and by Brazilian National Council for Scientiﬁc and Technological Development ( CNPq ) via Grant No . 309335 / 2017 - 5 . References [ 1 ] W . H . Organization ( 2020 ( accessed May 02 , 2020 ) ) . URL : https : / / www . who . int / emergencies / diseases / novel - corona - virus - 2019 . [ 2 ] WHO ( Online ; accessed March 12 , 2020 ) . URL : https : / / www . who . int / dg / speeches / detail / 2020 . [ 3 ] W . C . D . C . - . Dashboard ( Online ; accessed August 23 , 2020 ) . URL : https : / / covid19 . who . int / . [ 4 ] N . M . Ferguson , D . A . Cummings , S . Cauchemez , C . Fraser , S . Riley , A . Meeyai , S . Iamsirithaworn , D . S . Burke , Nature 437 ( 2005 ) 209 – 214 . [ 5 ] C . Adlhoch ( March , 2020 ) . URL : " https : / / www . ecdc . europa . eu / sites / default / files / documents / covid - 19 - social - distancing - measuresg - guide - second - update . pdf " . [ 6 ] ( Online ; accessed August 18 , 2020 ) . URL : " https : / / www . statista . com / chart / 21198 / effect - of - social - distancing - signer - lab / " . 24 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 7 ] ( Online ; accessed August 18 , 2020 ) . URL : " https : / / www . health . harvard . edu / diseases - and - conditions / preventing - the - spread - of - the - coronavirus " . [ 8 ] C . T . Nguyen , Y . M . Saputra , N . Van Huynh , N . - T . Nguyen , T . V . Khoa , B . M . Tuan , D . N . Nguyen , D . T . Hoang , T . X . Vu , E . Dutkiewicz , et al . , arXiv preprint arXiv : 2005 . 02816 ( 2020 ) . [ 9 ] A . Brunetti , D . Buongiorno , G . F . Trotta , V . Bevilacqua , Neurocomputing 300 ( 2018 ) 17 – 33 . [ 10 ] D . Yang , E . Yurtsever , V . Renganathan , K . A . Redmill , ¨U . ¨Ozg¨uner , arXiv preprint arXiv : 2007 . 03578 ( 2020 ) . [ 11 ] N . S . Punn , S . K . Sonbhadra , S . Agarwal , arXiv preprint arXiv : 2005 . 01385 ( 2020 ) . [ 12 ] L . Ramadass , S . Arunachalam , Z . Sagayasree , International Journal of Per - vasive Computing and Communications ( 2020 ) . [ 13 ] I . Ahmed , A . Adnan , Cluster Computing ( 2017 ) 1 – 22 . [ 14 ] M . Ahmad , I . Ahmed , F . A . Khan , F . Qayum , H . Aljuaid , International Journal of Distributed Sensor Networks 16 ( 2020 ) 1550147720934738 . [ 15 ] I . Ahmed , S . Din , G . Jeon , F . Piccialli , IEEE Internet of Things Journal ( 2019 ) . [ 16 ] I . Ahmed , M . Ahmad , A . Adnan , A . Ahmad , M . Khan , International Jour - nal of Machine Learning and Cybernetics ( 2019 ) 1 – 12 . [ 17 ] I . Ahmed , A . Ahmad , F . Piccialli , A . K . Sangaiah , G . Jeon , IEEE Internet of Things Journal 5 ( 2018 ) 1598 – 1605 . [ 18 ] M . Ahmad , I . Ahmed , K . Ullah , I . Khan , A . Adnan , in : 2018 9th IEEE Annual Ubiquitous Computing , Electronics Mobile Communication Con - ference ( UEMCON ) , pp . 746 – 752 . doi : 10 . 1109 / UEMCON . 2018 . 8796595 . 25 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 19 ] J . - W . Choi , D . Moon , J . - H . Yoo , ETRI Journal 37 ( 2015 ) 551 – 561 . [ 20 ] C . Migniot , F . Ababsa , Journal of Real - Time Image Processing 11 ( 2016 ) 769 – 784 . [ 21 ] M . Ahmad , I . Ahmed , K . Ullah , I . Khan , A . Khattak , A . Adnan , International Journal of Advanced Computer Science and Applications 10 ( 2019 ) . URL : http : / / dx . doi . org / 10 . 14569 / IJACSA . 2019 . 0100367 . doi : 10 . 14569 / IJACSA . 2019 . 0100367 . [ 22 ] J . Redmon , A . Farhadi , arXiv preprint arXiv : 1804 . 02767 ( 2018 ) . [ 23 ] B . News ( Online ; accessed January 23 , 2020 ) . URL : " https : / / www . bbc . co . uk / news / world - asia - china51217455 , 2020 " . [ 24 ] N . H . C . of the Peoples Republic of China ( Online ; accessed March 20 , 2020 ) . URL : " http : / / en . nhc . gov . cn / 2020 - 03 / 20 / c78006 . htm , 2020 " . [ 25 ] K . E . Ainslie , C . E . Walters , H . Fu , S . Bhatia , H . Wang , X . Xi , M . Baguelin , S . Bhatt , A . Boonyasiri , O . Boyd , et al . , Wellcome Open Research 5 ( 2020 ) . [ 26 ] N . S . Punn , S . K . Sonbhadra , S . Agarwal , medRxiv ( 2020 ) . [ 27 ] M . Robakowska , A . Tyranska - Fobke , J . Nowak , D . Slezak , P . Zuratynski , P . Robakowski , K . Nadolny , J . R . (cid:32)Ladny , Disaster and Emergency Medicine Journal 2 ( 2017 ) 129 – 134 . [ 28 ] A . Harvey , J . LaPlace , Megapixels : Origins , ethics , and privacy implica - tions of publicly available face recognition image datasets , 2019 . [ 29 ] S . P . B . D . L . H . B . R . F . A . S . B . R . R . V . S . A . O . C . F . F . H . D . A . R . d . A . L . R . J . J . P . C . R . Patrick R . S . dos Santos , Lucas B . M . de Souza , 22nd International Conference on E - Health Networking , Applications and Services ( IEEE Healthcom 2020 ) , Shenzhen , China , December 12 - 15 , 2020 ( 2020 ) . 26 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 30 ] M . S . Iqbal , I . Ahmad , L . Bin , S . Khan , J . J . Rodrigues , Transactions on Emerging Telecommunications Technologies ( 2020 ) e4017 . [ 31 ] D . G . A . K . R . S . J . J . P . C . R . Yash Chaudhary , Manan Mehta , 22nd In - ternational Conference on E - Health Networking , Applications and Services ( IEEE Healthcom 2020 ) , Shenzhen , China , December 12 - 15 , 2020 ( 2020 ) . [ 32 ] L . G . J . J . P . C . R . Chinmay Chakraborty , Amit Banerjee , Series Studies in Big Data 80 ( 2021 ) 98 – 136 . doi : 10 . 1007 / 978 - 981 - 15 - 8097 - 0 . [ 33 ] B . A . G . L . R . J . Chakraborty , C . , Springer ( 2021 ) . [ 34 ] K . Prem , Y . Liu , T . W . Russell , A . J . Kucharski , R . M . Eggo , N . Davies , S . Flasche , S . Cliﬀord , C . A . Pearson , J . D . Munday , et al . , The Lancet Public Health ( 2020 ) . [ 35 ] C . Adolph , K . Amano , B . Bang - Jensen , N . Fullman , J . Wilkerson , medRxiv ( 2020 ) . [ 36 ] C . A . Pouw , F . Toschi , F . van Schadewijk , A . Corbetta , arXiv preprint arXiv : 2007 . 06962 ( 2020 ) . [ 37 ] A . J . Sathyamoorthy , U . Patel , Y . A . Savle , M . Paul , D . Manocha , arXiv preprint arXiv : 2008 . 06585 ( 2020 ) . [ 38 ] A . Krizhevsky , I . Sutskever , G . E . Hinton , in : Advances in neural informa - tion processing systems , pp . 1097 – 1105 . [ 39 ] K . Simonyan , A . Zisserman , arXiv preprint arXiv : 1409 . 1556 ( 2014 ) . [ 40 ] R . Girshick , J . Donahue , T . Darrell , J . Malik , in : Proceedings of the IEEE conference on computer vision and pattern recognition , pp . 580 – 587 . [ 41 ] C . Szegedy , W . Liu , Y . Jia , P . Sermanet , S . Reed , D . Anguelov , D . Erhan , V . Vanhoucke , A . Rabinovich , in : Proceedings of the IEEE conference on computer vision and pattern recognition , pp . 1 – 9 . 27 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f [ 42 ] R . Girshick , in : Proceedings of the IEEE international conference on com - puter vision , pp . 1440 – 1448 . [ 43 ] S . Ren , K . He , R . Girshick , J . Sun , in : Advances in neural information processing systems , pp . 91 – 99 . [ 44 ] T . - Y . Lin , M . Maire , S . Belongie , J . Hays , P . Perona , D . Ramanan , P . Doll´ar , C . L . Zitnick , in : European conference on computer vision , Springer , pp . 740 – 755 . [ 45 ] J . Redmon , S . Divvala , R . Girshick , A . Farhadi , in : Proceedings of the IEEE conference on computer vision and pattern recognition , pp . 779 – 788 . [ 46 ] I . Ahmed , M . Ahmad , M . Nawaz , K . Haseeb , S . Khan , G . Jeon , Computer Communications 147 ( 2019 ) 188 – 197 . 28 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 J o u r n a l P r e - p r o o f Declaration of Interest Statement Title : A Deep Learning - Based Social Distance Monitoring framework for COVID - 19 Authors : Imran Ahmed 1 , Misbah Ahmad 1 , Joel J . P . C . Rodrigues 2 , Gwanggil Jeon 3 , Sadia Din 4 1 Center of Excellence in Information Technology , Institute of Management Sciences , 1 - A , Sector E - 5 , Phase VII , Hayatabad , Peshawar - Pakistan . imran . ahmed @ imsciences . edu . pk , misbahahmad4872 @ gmail . com . 2 Post - Graduation Program in Electrical Engineering ( PPGEE ) , Federal University of Piau´ı , Teresina 64049 - 550 , Brazil ; Instituto de Telecomunica¸c ~ oes , 1049 - 001 Lisbon , Portugal . joeljr @ ieee . org . 3 Department of Embedded Systems Engineering , Incheon National University , Incheon , Korea . gjeon @ inu . ac . kr . 4 Department of Information and Communication Engineering , Yeungnam University , South Korea . saadia . deen @ gmail . com . Conflict of Interest None Declared . Conflict of Interest J o u r n a l P r e - p r o o f