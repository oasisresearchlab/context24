1 Student - AI Creative Writing : Pedagogical Strategies for Applying Natural Language Generation in Schools David James Woo 1 Precious Blood Secondary School , 338 San Ha Street , Chai Wan , Hong Kong net _ david @ pbss . hk https : / / orcid . org / 0000 - 0003 - 4417 - 3686 Yanzhi Wang New York University Steinhardt School of Culture , Education , and Human Development 82 Washington Square E , New York , NY 10003 , United States yzjennyw @ gmail . com Hengky Susanto University of Massachusetts Lowell Department of Computer Science 1 University Avenue , Lowell , MA 01854 hsusanto13 @ gmail . com Abstract AI Natural Language Generation ( NLG ) is a process where computer systems generate human - comprehensible language texts from information . It can become an integral part of a human ' s creative writing process . Importantly , youths can learn to apply NLG in mainstream education and become better prepared for AI - enhanced writing jobs and other writing endeavors . To explore how students apply NLG to creative writing , we designed and implemented the 1st Human - AI Creative Writing Contest in a Hong Kong secondary school . In this contest , each student participant wrote a short story of up to 500 - words using the student ' s own words and words generated by a computer and built on open - source language models . We designed four text generators for the contest as the computer ' s text entry . Additionally , using design - based research , we developed seven workshops where students learned to write with the four text generators and answered reflection questions . In analyzing four students ' short stories and adjudicators ' scores for the stories , we found different strategies in terms of the number and the type of text generator words that students used . Some strategies appeared more sophisticated than others . In analyzing students’ reflections , we found students could describe text generator input and output as units of thought . Besides , students showed preferences for text generators ; and they expressed a range of feelings when writing with text generators . The findings provide design implications not only for NLG application in formal schooling but also suggest pedagogical strategies for AI curriculum . Keywords : artificial intelligence ; natural language processing ; text generation ; creative writing ; short stories 1 Corresponding author 2 1 Introduction Artificial intelligence ( AI ) has referred to machines that can imitate features of human intelligence such as creative work and language interaction ( UNESCO , 2022 ) . AI is expanding into many areas of daily life ( Wang & Cheng , 2021 ) , and it appears that using AI effectively and ethically in everyday life will require new abilities , attitudes and competencies that compose AI literacy ( Long & Magerko , 2020 ) . People must learn the knowledge , skills and attitudes necessary to interact with AI in a responsible , critical and confident way ( Vuorikari et al . , 2022 ) . AI technologies are new to K - 12 schools ( Kim et al . , 2022 ) and AI is a new subject area for K - 12 schools around the world ( UNESCO , 2022 ) . In spite of little historical knowledge about how to conceptualize AI integration in education programs , progress has been made in some directions . Chiu and Chai ( 2020 ) suggested approaching the design of AI curriculum in terms of content , product , process and praxis . Wang and Cheng ( 2021 ) have suggested three different directions for AI in curriculum , learning from AI , learning about AI and learning with AI . Similarly , Kim et al . ( 2022 ) suggested AI in curriculum might develop in three stages : learning about AI ; learning from AI ; and learning together . As for essential outcomes , Ng et al . ( 2022 ) have proposed four cognitive standards : know and understand AI ; use and apply AI ; evaluate and create AI ; and AI ethics . Similarly , Long and Magerko ( 2020 ) and Sanusi et al . ( 2022 ) have proposed core competencies to interact with and to evaluate AI practically and successfully . Although there are claims that AI has been extensively adopted and used in education at an institutional level ( Chen et al . , 2020 ) , in the Asia - Pacific region , AI appears to be under - explored in mainstream school curriculum , particularly at the level of AI learning designs and activities ( Su et al . , 2022 ) . There has been little material evidence to inform student - AI collaboration in the classroom ( Kim et al . , 2022 ) . In Hong Kong , there have been pioneering efforts in mainstream schools to implement AI curriculum that has been effective in increasing students’ self - perceived AI competence , attitude and motivation ( Chiu et al . , 2022 ) . Nonetheless , schools need more guidance to develop AI curriculum and its intended learning outcomes , not least because they must find a place in their existing , crowded curriculum to fit in AI ( Wang & Cheng , 2021 ) . A promising place in which to integrate AI in mainstream school curriculum is through writing . Writing is an ability not only to express oneself and to communicate ( Long & Magerko , 2020 ) , but also to acquire new knowledge and to restructure knowledge in varied disciplines ( Ng et al . , 2022 ) . Furthermore , digital writing comprises many text types and demands a range of skills ( Gayed et al . , 2022 ) so that , for instance , digital story writing has emerged as a powerful pedagogical tool ( Ng et al . , 2022 ) . Besides , since digital writing with AI is on the cusp of mainstream use ( Johnson & Iziev , 2022 ) through such software applications as Grammarly and Google Translate , schools have a responsibility to prepare students for this future of ever - increasing AI - mediated communication ( Hancock , 2020 ) . In this paper we explore students’ application of AI for creative writing in a mainstream school . We ground the user study in the 1st Human - AI Creative Writing Contest , a co - curricular activity which we prosecuted in a Hong Kong secondary school . The contest’s aims were to increase student engagement with the English language and to develop students ' and teachers ' knowledge and skills to learn with AI . The contest required each student participant to compose a short story using the student’s own words and words from AI computer systems . 3 2 Literature Review 2 . 1 AI Natural Language Generation : Language models and applications AI can be considered a field of study ( Chen et al . , 2020 ) , and one of its subfields is natural language generation ( NLG ) , which refers to computer systems that can produce comprehensible human language texts from information ( Gatt & Krahmer , 2018 ) . The computer systems that perform NLG are called language models ( Bender et al . , 2021 ) . Research on these language models has focused on their increasing power because of advances in computer network architecture ( Vaswani et al . , 2017 ) and the models’ training on increasingly large sets of digitized texts ( Gao et al . , 2020 ) , although such training is incurring correspondingly large environment and financial costs ( Bender et al . , 2021 ) . Importantly , although institutions have been training the largest language models and using them for commercial use ( Johnson & Iziev , 2022 ) , a growing number of high - performing language models are freely available for public download ( Zhang et al . , 2020 ) . Examples of large , open - source language models include GPT2 ( Radford et al . , 2019 ) , BERT ( Devlin et al . , 2019 ) , GPT - NEO ( Black et al . , 2021 ) and GPT - J ( Biderman & Raff , 2022 ) . Since mainstream schools have limited financial and material resources ( Chiu & Chai , 2020 ) and since AI’s perceived costs are a barrier to AI in schools ( Zhai et al . , 2021 ; Wang & Cheng , 2021 ) , the application of NLG in schools may depend on these cost - effective language models . Common NLG tasks for language models include question - answering , translation and summarization ( Radford et al . , 2019 ) , but in schools the application of these NLG tasks appears relatively unexplored . This is not least because , like other AI technologies , NLG educational applications such as dialogue - based tutoring systems , paraphrasing tools and chatbots are relatively new so institutions have not adopted them ( Somers et al . , 2021 ) . Likewise , Zhai et al . ( 2021 ) reviewed 100 AI in education studies from 2010 to 2020 and identified only three studies that might be considered NLG . Importantly , research into NLG in education has focused on improving students’ receptive skills , such as reading , through AI . For example , Somer’s et al . ( 2021 ) investigated AI’s potential in automatically assessing students ' conceptual understanding , and Bengoetxea et al . ( 2020 ) built an NLG application to improve Spanish primary and secondary students’ English language literacy through the personalization and adaptation of texts . However , our interest is to explore the application of NLG in education to improve productive skills , namely , for the writing of creative texts that are not replications or copies of existing texts . The next section reviews literature on the application of NLG in creative writing and develops our framework of student - AI creative writing that we apply to students’ writing of short stories in a mainstream school . 2 . 2 Student - AI Creative Writing : A Conceptual Framework We conceptualize creative writing with NLG as a form of human - computer interaction , comprising dimensions of human writing , language models and software ( Yang et al . , 2022 ) . Research into creative writing with NLG is emergent , focusing on genres of writing such as slogans and stories ( Clark et al . , 2018 ) , metaphors ( Gero & Chilton , 2019 ) , news ( Brown et al . , 2020 ) and introductory computer programming assignments ( Biderman & Raff , 2022 ) ; purpose - built software ( See , 2019 ; Kreminski et al . , 2020 ; Gayed et al . , 2022 ) and datasets ( Lee et al . , 2022 ) ; strategies for writing with NLG computer systems ( Calderwood et al . , 2020 ; Yang et al . , 2022 ) ; and types of writers including adult , English foreign language learners ( Gayed et al . , 4 2022 ) , professional novelists ( Calderwood et al . , 2020 ) , professional poets and undergraduate students ( Gero & Chilton , 2019 ) , and graduate students ( Yang et al . , 2022 ) . We focus on a specific process of creative writing with NLG known as text generation , that is , a text - to - text interaction between a human and a computer ( Gatt & Krahmer , 2018 ) , which comprises a language model and software and which we refer to as a text generator . For a human to interact with a text generator , the human first produces text as input for the generator , and the generator then produces text as output according to the input text and the text generator’s language model . In other words , the generator’s output text can be considered the generator’s prediction of words based on the generator’s calculations of all the previous words , that is , the input text ( Liu et al . , 2021 ) ; and it is possible to change the parameters by which the generator predicts words ( Biderman & Raff , 2022 ) . A human can change a generator’s output text by changing the input text . For example , if a human inputs a computer language code description , the generator can output subsequent computer language code ; or if a human inputs an incomplete sentence , the generator can complete the sentence ; or if a human inputs the first few sentences of a story , the generator can output the continuation of that story ( Hugging Face , 2022 ) . Importantly , we conceptualize a human using the same or different input text to interact simultaneously with more than one generator . Compared to previous works , our exploratory user study is unique : it develops knowledge of creative writing with NLG from the perspective of youths , specifically students in formal , secondary education outside the Anglosphere . In this study , we investigate these students’ strategies for creative writing with NLG . To guide our exploration , and informed by Clark et al . ' s ( 2018 ) and Yang et al . ’s ( 2022 ) frameworks for a human’s creative writing with one text generator , we have designed a conceptual framework that models student interactions with text generators to produce short stories ( see Figure 1 ) . First , a student can interact with her short story by adding text , deleting text or substituting text . Or the student can interact with the text generation process by deciding on which text generator ( s ) to use and inputting text directly into a text generator or text generators . After submitting input text , the student reads the text generator output text ( s ) . After that , the student can interact with her short story by selecting output text to include in the short story and editing text in the short story . Otherwise , the student can continue interacting with the text generation process by deciding which text generator ( s ) to use and inputting text directly into a text generator or text generators . Although researchers’ have already explored students’ story writing and AI understanding from a cognitive perspective ( Ng et al . , 2022 ) , there appears a pressing need to design AI curriculum so that AI is engaged in a meaningful socio - emotional interaction with students ( Kim et al . , 2021 ) . Besides , there is little research to understand how a human’s interaction with AI affects students’ attitude , behavior and emotions ( Salas - Pilco , 2020 ) . In this way , we are interested in a more holistic approach to understand student strategy to write with NLG ; therefore , we conceptualize a student’s strategy in terms of cognitive , behavioral and affective domains . We conceptualize these domains as mediating a student’s interactions between text generation and the student’s short story . 5 Fig 1 A conceptual framework for student - AI creative writing 2 . 3 Research Questions Based on the conceptual framework we asked the following research questions : 1 . What patterns of interactions are taken up by students when they interact with text generators in creative writing ? 2 . How does creative writing interactions with NLG affect students ? 3 Material and Methods 3 . 1 Text Generators We operationalized text generators for the study by first selecting some of the largest , most downloaded and most liked open - source text generation language models available on HuggingFace , a repository for open - source language models . We then used software on HuggingFace Spaces , a website that hosts machine learning demonstration applications , to compose text generators . Specifically , each text generator for the study is a specific page on HuggingFace Spaces comprising a user interface built from either Gradio or Streamlit software development kit ( SDK ) , Python programming language and one or more language models . Since an affordance of AI in education is providing individualized learning experiences for students ( Kuleto et al . , 2021 ) , and given free access to the language models , SDKs and website hosting , we built four text generators for the study . Table 1 shows the text generators differ in terms of the number of language models used , the size of language models used measured by the number 6 of parameters , and the maximum length of text generator output . Each generator was given an official name for the study . Figure 2 is a screenshot of the Text Generator GPT - NEO - 1 . 3B on HuggingFace Spaces . 7 Table 1 . A summary of text generators Text Generator Name Next Sentence Generator Next Word Generator Text Generator GPT - Neo - 1 . 3B Text Generator GPT - NEO - 2 . 7B Website https : / / huggingface . co / spac es / Wootang01 / next _ senten ce https : / / huggingface . co / spac es / Wootang01 / word _ gener ator https : / / huggingface . co / spac es / Wootang01 / text _ genera tor https : / / huggingface . co / spaces / Wootang01 / text _ generator _ t wo SDK Gradio Streamlit Gradio Gradio Language Model ( s ) GPT - J 6B ; GPT - Neo 2 . 7B ; GPT2 - Large BERT base model ( uncased ) GPT - Neo 1 . 3B GPT - Neo 2 . 7B Number of parameters 6 billion ; 2 . 7 billion ; 774 million 110 million 1 . 3 billion 2 . 7 billion Maximum Length of Output Unavailable One word 100 characters 100 characters Fine - tuned : No No No No 8 Fig 2 A screenshot of Text Generator GPT - NEO - 1 . 3B 3 . 2 Study Background We prosecuted the study at an all - girls , Catholic secondary school in Hong Kong . The school delivers a mainstream curriculum and serves students between the 44th and 55th percentile of academic achievement for all Hong Kong students . The school primarily delivers instruction to students in Cantonese Chinese language . Student participation in the 1 st Human - AI Creative Writing Contest was voluntary . From February to March 2022 , we recruited students by delivering four , weekly school television announcements to all students , a written advertisement posted to all students through Google Classroom , and a written advertisement posted to the school’s English club members by Whatsapp . We created an official contest website on Google Sites . We recruited using the English language . The contest rules required each student to write a short story with the title of either " Charity begins at home " or “There is some good in the world and it is worth fighting for . ” The story should be no more than 500 words , using the student’s own words and words from text generators . A student could use any of the four text generators as many times as necessary . Importantly , a student had to highlight the student’s own words in red and text generator words in black ( see Figure 3 ) . A student had to write the short story on Google Docs and share the doc with us . The submission deadline was April 7 , 2022 . 9 Fig 3 An excerpt from a student’s short story After the submission deadline , three English language subject matter experts , the school principal , a former English teacher , the school’s English panel head , and the school’s Native English Teacher , judged the contest entries . Each adjudicator was given an anonymized copy of each student’s story with the student’s name removed and indicators of a student’s words and text generator words removed . Each adjudicator was also given an assessment rubric ( see Table 2 ) adapted from the Hong Kong Diploma of Secondary Education ( HKDSE ) examination rubric that is used to assess English language writing and with which the adjudicators were familiar . Although the adapted rubric retains the assessment criteria from the HKDSE rubric and descriptors for those criteria at levels 6 , 4 and 2 , we added an additional AI criterion to our adapted rubric , giving it a weight of 10 % of the total mark . Adjudicators were asked to assess only the three criteria retained from the HKDSE rubric , and not the AI criterion . To facilitate standardization of marking according to the three criteria , the Native English Teacher’s scores for the stories were given to the other adjudicators , alongside his detailed comments on the stories . The adjudicators completed scoring in May 2022 and we announced first place and second place in May 2022 . 10 Table 2 . The contest’s assessment rubric Weight Content Language Organization AI 30 % · Content fulfills the requirements of the question · Almost totally relevant · Most ideas are well developed / supported · Creativity and imagination are shown when appropriate · Shows general awareness of audience · Wide range of accurate sentence structures with a good grasp of simple and complex sentences · Grammar mainly accurate with occasional common errors that do not affect overall clarity · Vocabulary is wide , with many examples of more sophisticated lexis · Spelling and punctuation are mostly correct · Register , tone and style are appropriate to the genre and text - type · Text is organized effectively , with logical development of ideas · Cohesion in most parts of the text is clear · Strong cohesive ties throughout the text · Overall structure is coherent , sophisticated and appropriate to the genre and text - type · Not applicable 20 % · Content just satisfies the requirements of the question · Relevant ideas but may show some gaps or redundant information · Some ideas but not well developed · Some evidence of creativity and imagination · Shows occasional awareness of audience · Simple sentences are generally accurately constructed . · Occasional attempts are made to use more complex sentences . Structures used tend to be repetitive in nature · Grammatical errors sometimes affect meaning · Common vocabulary is generally appropriate · Most common words are spelt correctly , with basic punctuation being accurate · There is some evidence of register , tone and style appropriate to the genre and text - type · Parts of the text have clearly defined topics · Cohesion in some parts of the text is clear · Some cohesive ties in some parts of the text · Overall structure is mostly coherent and appropriate to the genre and text - type · Not applicable 11 10 % · Content shows very limited attempts to fulfill the requirements of the question · Intermittently relevant ; ideas may be repetitive · Some ideas but few are developed · Ideas may include misconception of the task or some inaccurate information · Very limited awareness of audience · Some short simple sentences accurately structured · Grammatical errors frequently obscure meaning · Very simple vocabulary of limited range often based on the prompt ( s ) · A few words are spelt correctly with basic punctuation being occasionally accurate · Parts of the text reflect some attempts to organize topics · Some use of cohesive devices to link ideas · AI words used in long chunks ( more than 1 sentence in length ) and in short chunks ( less than 5 words in length ) . 12 3 . 3 Pre - contest Workshops To achieve the contest’s aims , we designed seven pre - contest workshops from March 1 to April 5 , 2022 . s in - person schooling was suspended in Hong Kong at the time , all workshops were conducted online via Zoom . Each workshop was approximately an hour in length , attendance at these workshops was not compulsory and the workshops were delivered in the English language . Since knowledge on how students write creatively with AI and how to teach AI - mediated creative writing are new , and since classroom materials for these purposes are immature , we developed the workshops following a design - based research ( DBR ) approach , which is used to solve complex , real - world educational problems ( Ford et al . , 2017 ) . On the one hand , each workshop included the same instructional activities : the teacher introducing explicit learning targets and demonstrating achievement of the learning targets ; students’ writing ; and students’ reflecting by answering explicit reflection questions . On the other hand , since we approached each workshop as an iterative cycle of design , implementation and evaluation ( Gravemeijer & Cobb , 2006 ) , we designed a workshop’s learning targets , lesson materials and instructional activities only after implementing and evaluating the previous workshop . In this way , we designed a progression of learning targets ( see Appendix 1 ) , the assessment rubric and the reflection questions that students answered at the end of each workshop ( see Table 3 ) . Table 3 . Workshop reflection questions Workshop no . Number Reflection Question 2 3 4 5 6 7 1 How do you feel writing a short story using your own words and a machine’s words ? ! ! ! ! ! 2 What is your plan to write a short story using your own words and a machine’s words ? ! 3 If you could only use one text generator to write your short story , which would you use ? And why ? ! ! 4 What was your plan today to write a short story using your own words and a machine’s words ? How did you decide which words , sentences or paragraphs to put into a text generator ? How did you decide which AI words , sentences or paragraphs to include in your story ? ! 5 Did you have a goal for today’s session ? If so , what was it ? And did you achieve it ? ! ! ! ! 6 Please share a screenshot of your text generator input and output . Why did you choose that text generator ? How did you decide which words , sentences or paragraphs to put into a text generator ? How did you decide which AI words , sentences or paragraphs to include in your story ? ! ! ! ! 13 7 How did you feel after attending these workshops ? ! 8 What is the most important thing you learned after attending these workshops ? ! 9 What is one thing you would like to have learned in this workshop ? ! 3 . 4 Data Collection We collected several forms of data during contest implementation . As we sought to answer the first research question per a student’s behavioral domain , we collected students’ short stories , which are the product of students’ interactions with text generators . Since we also sought to answer the first research question per a student’s cognitive domain , we collected students’ answers to reflection questions after each workshop . We would also collect these reflections to answer the second research question , which focuses on a student’s affective domain . Since a student wrote her short story and answers to reflection questions on a single Google Doc , we collected not only the stories and reflections but also the version histories of the student’s writing . We collected additional data that would supplement our analysis of students’ stories and reflections : we observed and recorded each workshop and on Google Sheets made notes about the intended learning outcomes , the instructional activities , and the time for each instructional activity ; we collected the Google Slides used for the workshops and the adjudicators’ scores ; and we collected students’ pre - contest and post - contest questionnaires on Google Forms so that we understand students’ demographic and background information . All data were stored on our secure Google Drive . 3 . 5 Data Analysis We used content analysis ( Skalski et al . , 2017 ) and mixed methods to answer the research questions . First , we analyzed the properties of students ' short stories using quantitative methods . We calculated descriptive statistics for the human words and text generator words in each short story . For insights into what patterns of interactions might be useful for AI curriculum in formal schooling , we then compared the descriptive statistics for the stories alongside adjudicators’ scores . We analyzed students’ reflections using qualitative methods , adopting an inductive and deductive thematic analysis ( Braun & Clarke , 2006 ) . We performed the analysis on an Excel spreadsheet comprising all students’ reflections . First , we developed a deductive coding scheme based on our conceptual framework’s theoretical constructs : during an iterative , line by line reading of student reflections , we initial - coded ( Saldana , 2012 ) excerpts where students express their input and output selection processes , text generator selection process or their feelings . For example , to explain students’ text generator input and output processes , we first looked for the key words by which students described their input and output in their answers to the reflection questions . To explain students’ text generator selection process , we first looked for names of the text generators or any reference to a text generator in students’ answers . Then we inductively focus - coded those excerpts , to identify common themes . In this coding process , the first author initial - coded and focus - coded . The second and third authors reviewed the coding scheme , the initial - coding and the focus - coding , and discussed with the first author to resolve coding 14 disparities , to propose new codes and to revise the coding scheme . After the authors agreed on the final codes , they compiled the codes and generated themes for reporting . To support our analysis of the reflections , we referred to the audio and video recordings of the workshops , and the version histories of the students’ Google Docs . 4 Results In this section , we first present background information on the study’s participants . Then we present findings for the first research question , followed by findings for the second research question . When we quote students , we include the workshop number from which we take the quote in parentheses . 4 . 1 Student Background Four students ( N = 4 ) successfully submitted short stories to the contest . They are given the pseudonyms Student H , Student M , Student S and Student W in this paper ( see Table 4 ) . The students range from 12 - years old ( n = 1 ) to 17 - years old ( n = 1 ) and from grade - levels one ( n = 1 ) to five ( n = 2 ) . The school streams students from each grade - level into classes for English lessons according to English language ability and all students had been placed in the highest ability class in their respective grade - levels . All students had recently read storybooks . Two students liked to tell stories , and three students had immediate experience writing short stories . All students planned on further study after completing secondary school . Table 4 . Student profiles Name Student H Student M Student S Student W Age 16 12 15 17 Grade level 5 1 3 5 Birth place Hong Kong Hong Kong Hong Kong Hong Kong Mother highest education level Pre - secondary Secondary Secondary Secondary Father highest education level Secondary Secondary Secondary Secondary Number of siblings > 2 > 2 0 2 Public housing 1 0 0 0 Number of storybooks read during school suspension 2 3 5 1 Number of books read during school suspension 3 7 3 3 Likes to tell stories ( 1 = yes ; 0 . 5 = maybe ) 0 . 5 1 1 0 . 5 15 Preferred modes to tell stories sounds without words ; spoken ; visuals without words handwritten ; typed spoken ; typed ; visuals without words spoken ; typed Number of short stories written during school suspension 2 3 5 0 Post - secondary plans School School School School Why join contest I want to learn and improve my writing skills as well as understand the difference between my writing style and AI writing style . Because Technology is my second hobby I ' ve never used an AI to write with my story and I think it ' s interesting I would like enhance my writing skills contest expectations Probably on the same page , the AI and my writing should be coherent Have fun while writing I hope to get random ideas from the AI while I write I hope that there will be more sentence structure or vocabulary in the short story Number of workshops attended ( workshop number ( s ) ) 4 ( 1 , 2 , 4 , 5 ) 4 ( 1 , 5 , 6 , 7 ) 2 ( 1 , 2 ) 5 ( 1 , 3 , 4 , 5 , 7 ) People whom the student told about the contest family family ( parents ; siblings ) ; friend teachers friend ( Student H ) Home digital devices Laptop / portable computer , Smartphone , Tablet Smartphone , Tablet Laptop / portable computer , Smartphone , Tablet Laptop / portable computer , Smartphone , Tablet Shared home digital devices Laptop / portable computer Desktop computer Laptop / portable computer , Tablet Desktop computer The students joined the voluntary pre - contest workshops ( N = 7 ) and showed different rates of attendance . For example , Student S attended the first two workshops and the fewest number of workshops ( n = 2 ) . In contrast , Student W attended the most ( n = 5 ) , including the first and last workshops . Furthermore , the students had different degrees of ICT access for the contest . Although all students appeared to own their own smartphones , all students had to share either a laptop 16 computer or a desktop computer with family members at home and only one student owned her own laptop computer . 4 . 2 Research Question One 4 . 2 . 1 Short Story Descriptive Statistics Table 5 presents the average of adjudicator’s scores that students received for the short stories . Out of 10 marks , ( N = 10 ) Student S scored the highest total mark ( n = 9 . 66 ) followed by Student W ( n = 9 . 16 ) . Student M scored the lowest total mark ( n = 7 . 88 ) . Importantly , we had defined the AI criterion as using AI words not only in long chunks , that is more than one sentence in length , but also in short chunks , that is , less than five words in length . That all students scored marks for the AI criterion indicates that all students had successfully incorporated at least one long AI chunk or one short AI chunk in their writing . Students S and W scored full marks for the AI criterion ( N = 1 ) , indicating they were able to use AI words in long and short chunks . In contrast , Students H and M scored half marks ( n = . 5 ) , indicating they could use AI words either in long chunks or in short chunks . 17 Table 5 . Scores for students’ short stories Average mark of three adjudicators Criterion ( full mark ) Student H Student M Student S Student W Content ( 3 ) 3 2 . 5 2 . 66 2 . 83 Language ( 3 ) 2 . 33 2 . 5 3 2 . 66 Organization ( 3 ) 2 . 66 2 . 33 3 2 . 66 AI ( 1 ) 0 . 5 0 . 5 1 1 Total 8 . 5 7 . 88 9 . 66 9 . 16 In Table 6 , we present fine - grain properties of the stories , focusing on AI words . The total number of words for a story ranged from Student M’s 270 to Student H’s 542 , which was over the official contest word limit but was permitted after Student H asked for permission to submit a story over the word limit . Student H used the most AI words at 168 but as a percentage of the story , Student M’s 54 % was the highest percentage of AI words in a story . Student M was the only student to write the majority of her story using AI words . Table 6 . A summary of AI words in students’ short stories Descriptor Student H Student M Student S Student W Total no . of words 542 270 495 498 No . of students words ( % of total words ) 374 ( 69 ) 124 ( 46 ) 378 ( 76 ) 436 ( 88 ) No . of AI words ( % of total words ) 168 ( 31 ) 146 ( 54 ) 117 ( 24 ) 62 ( 12 ) No . of AI chunks 9 3 12 6 No . of human chunks 10 4 13 7 No . of long AI chunks 4 3 6 1 No . of short AI chunks 0 0 4 1 Avg . length of AI chunks 19 49 10 10 Based on an examination of the descriptive statistics , we found differences in students’ use of AI words that can be classified into interaction patterns ( see Table 7 ) by the amount of AI words as a percentage of the total words in the story and the type of AI words as indicated by the assessment rubric . 18 Table 7 . Students’ AI - word interaction patterns Types of AI words Complete Incomplete Amount of AI words Majority Student M Minority Student S , Student W Student H Comparing the interaction patterns found from the short stories , it appears Student M’s strategy appeared the least sophisticated : Student M composed the majority of her story using AI words but those words were limited to a few , long chunks . Given the adjudicators’ scores , Student M’s strategy also appears the least successful . In contrast , Student H composed the majority of her story using her own words . Her AI words were limited to long chunks and chunks that can be considered neither long nor short . The strategies of Students S and W appear more sophisticated than those of Students M and W : they composed the majority of their stories using their own words and their AI words composed long chunks , short chunks and chunks that can be considered neither long nor short . Moreover , when comparing the AI chunks of Students S and W , although the students share the same average word length of an AI chunk , Student S’s use of AI chunks appears more sophisticated , not least because Student S used twice as many AI chunks as Student W and Student S used far more long chunks and short chunks than Student W . In sum , although the strategies of Students S and W appeared to achieve more success with the adjudicators than those of Students H and M , Student S’s human - AI creative writing strategy appears the most successful and the most sophisticated . 4 . 2 . 2 Qualitative Findings Figure 4 is a thematic map to present qualitative findings for research question one . We identified two main themes , thought units and sophistication , and four sub - themes by which to understand the input and output selection aspects of student interactions with text generators per conceptual framework Figure 1 . As for the text generator aspect , we identified two main themes , quantity of output and technical . We elaborate these themes in the following sections . 19 Fig 4 The thematic map for research question one 4 . 2 . 2 . 1 Input Text By coding students’ answers to reflection questions , we found Students M , S and W conceptualized their input as units of thought , that is , words with cognitive or semantic function . Moreover , we found differences in the sophistication of students’ conceptualization of input as units of thought . For example , Student M appeared to apply the same unit of thought – a sentence – as input for all workshops . She said , “first I would think of a single sentence about the writing which is incomplete , then I would put it into the generator and let it do its work , ” ( workshop no . three ) and then , “I put a sentence at one time” ( workshop no . seven ) . In fact , in clarifying her input strategy with us , Student M confirmed that she would only enter one sentence as input . On the other hand , a student could conceptualize more than one unit of thought as input . These units of thought appear to be of different sizes . For instance , Student W said , “ I will copy the word or sentence then paste it in the input of the generator” ( workshop no . three ) . Importantly , we found Student S could sequence units of thought , indicating a more sophisticated input strategy . She said , “First , I put the whole paragraph , if the result is not what I look for , I cut it to the last sentence” ( workshop no . three ) . 4 . 2 . 2 . 2 Select Output Text Like with input strategies , we found differences in students’ sophistication of output strategies . Importantly , we found differences in students’ conceptualization of their select output as thought units , not only in size but also in specificity . On the one hand , some students conceptualized selected output in vague or simple thought units . Student H described selected output as “useful words” and “topic” ( workshop no . two ) and later , “ideas” ( workshop no . five ) . Similarly , Student M described selected output as “a machine’s words , ” “words” and “words 20 making sense” ( workshop no . three ) and “the ones that make sense” ( workshop no . seven ) . On the other hand , Students S and W conceptualized selected output in story - specific or larger thought units . Student S described selected output as “a sentence” and “best sentences” ( workshop no . two ) , and “a few sentences” ( workshop no . three ) . Student W described selected output as “a wide variety of ideas” and “AI words or sentence” ( workshop no . three ) , and “a lot of ideas , ” “topic sentence” and “start of the story” ( workshop no . four ) , and “a few words , ” or “details” ( workshop no . seven ) . Given the adjudicators’ scores , students’ strategies to conceptualize input as more than one unit of thought and output in terms of more specific and larger units of thought appear associated with higher scores . In contrast , students’ strategies to conceptualize input as a singular unit of thought and output in terms of more vague and simple thought units appear associated with lower adjudicator scores . 4 . 2 . 2 . 3 Text Generator Selection In workshops two and three , we asked students for their preferences in text generators . We found no one had preferred the Next Word Generator . Students H ( workshop no . two ) , M and W ( workshop no . three ) preferred the Next Sentence Generator . Student S preferred Text Generator GPT - NEO - 1 . 3B ( workshop no . two ) and Text Generator GPT - NEO - 2 . 7B ( workshop no . three ) . Later , in workshops four through seven , we asked students to share screenshots of their using a text generator and to explain why and how they used that generator . Student H shared her use of the Next Sentence Generator ( workshop no . four ) , Student M Text Generator GPT - NEO - 2 . 7B ( workshop no . seven ) and Student W Text Generator GPT - NEO - 1 . 3B ( workshop no . four ) and Next Sentence Generator ( workshop no . seven ) . From students ' answers to the reflection questions and their screenshots , a common reason for using a text generator was its quantity of output . It appears Text Generators GPT - NEO - 1 . 3B and GPT - NEO - 2 . 7B were popular because of their quantity of words . For example , Student S preferred Text Generator GPT - NEO - 1 . 3B and Text Generator GPT - NEO - 2 . 7B because she could , “easily pick out a sentence that I want to use , ” or “the best sentences to use” ( workshop no . two ) . She added , “I usually use the paragraph generator because there’s a few sentences I could use , ” and “I could choose which parts I want and remove” ( workshop no . three ) . Similarly , the Next Sentence Generator appeared popular because of its quantity of output words from three separate language models . Student W said , “I think it’s more convenient and especially for the next sentence generator , it provided some good ideas for me…because it provides a wide variety of ideas” ( workshop no . three ) , and , “It’s because I wanted to involve more details of the story” ( workshop no . seven ) . Student M added , “I would use the sentence generator since the words I will get in return will increase . ” On the other hand , Student H appeared to be the only student to use a text generator because it produced less output . She said , “I would choose the sentence generator because with that I would be on the same page . The topic ( output ) would not be that off . ” A less frequent reason found in the data for using a text generator was technical ease . For instance , Student S said that she would use Text Generator GPT - NEO - 2 . 7B because although it was “a bit laggy…it’s also the fastest generator out of all of them” ( workshop no . three ) . Student M said , “Text Generator GPT - Neo - 1 . 3B didn’t work , only Text Generator GPT - NEO - 2 . 7B worked” ( workshop no . seven ) . 21 4 . 3 Research Question Two Figure 5 is a thematic map to present findings for research question two . To understand the affective domain of student interactions with text generators per conceptual framework Figure 1 , we identified two main themes , feelings and reasons , with three sub - themes for each main theme . We elaborate these themes in the following sections . Fig 5 The thematic map for research question two We found students expressed a range of feelings when co - writing with text generators . We coded these feelings as positive , negative and mixed , that is , comprising both positive and negative feelings . We found some students changed their sentiments from one workshop to the next . For example , Student H felt “neutral” in workshop two and then “confused” by workshop four . Similarly , Student M felt , “quite weird but still understandable , ” “difficult” and “smarter” in workshops three , six and seven , respectively . On the other hand , we found Student S maintained her negative sentiment ( workshop nos . two and three ) and Student W her positive sentiment ( workshop nos . three , four , seven ) from one workshop to the next . We found students attributed some of their feelings to text generator compliance , that is , whether a text generator provided acceptable output to a student . We observed a student express negative sentiment when a text generator did not provide acceptable output to a student . Specifically , Student S said writing a short story was difficult not least because , “the machine ' s words change a lot , ” ( workshop no . two ) and , “ if you have the story planned , the AI might switch it up a bit , sometimes it might help give you new ideas but I have a strict plan with how I want the story to go so it was frustrating” ( workshop no . three ) . Similarly , we observed a student express positive sentiment when a text generator did provide acceptable output . Student H said writing a short story was more “convenient , ” because the text generator , “provided some good ideas for me , ” ( workshop no . three ) and “provided a lot of idea and also the topic sentence or the starting of the story , ” and “can help me to think of the next sentence” ( workshop no . four ) . Furthermore , Student H expressed mixed feelings because at times a text generator was compliant and at other times non - compliant with its output : “I think it was neutral because there were some words that I didn ' t want or expect but there were useful words to help me to make my piece more creative” ( workshop no . two ) . 22 We found students attributed other feelings to unanticipated situations . For example , Student M expressed difficulty ( workshop no . six ) because she claimed she had been writing her story on Google Docs on her iPad , but perhaps because of an unstable Internet connection , Google Docs neither saved any of that writing nor showed it in the version history . At the same time , Student M claimed she could not open hyperlinks on her iPad , be they on Google Docs or on the Google Slides workshop materials . As a result , Student M could not access the text generators on her iPad so she interacted with the text generators on her mobile phone while interacting with her short story on Google Docs on her iPad . In workshop no . seven , Student W expressed positive sentiment because of the teacher’s input , saying , “I feel that it is quite helpful for me since ( the teacher ) provided me with lots of ideas for the short story , guiding me to finish it . ” 5 Discussion and Conclusions The first empirical finding is interaction patterns from students’ short stories . Specifically , short stories with AI words composing less than half of the story but being used in long chunks and short chunks were viewed more favorably in adjudicators’ eyes than short stories with AI words composing more than half of the story but being used only in long chunks . This finding can indicate that AI words are best used to supplement human words , not replace human words . Besides , the different strategies can inform the design of a human - AI writing curriculum as we recommend a less sophisticated strategy could initially be introduced to students , who subsequently learn to refine that strategy , by relying on fewer AI words and making more edits to AI words when writing . This suggestion is also supported by Yang et al . ’s ( 2022 ) finding where most graduate student writers preferred editing when co - writing with a text generator since they could pick what they liked . The second empirical finding is interaction patterns from students’ text generation process . Students could conceptualize input and output text in thought units and students who conceptualized more sophisticated thought units for input and output text scored higher marks on their short stories than students who conceptualized fewer , simpler or vague thought units . This finding indicates that as with graduate students ( Yang et al . , 2022 ) , secondary school students can show a range of mental expectations when they interact with text generators . Importantly , when designing AI curriculum in a classroom writing context , we should consider that NLG tools can play different scaffolding roles for students of different expectations . Our study suggests a text generator can play a supplementary role for students with rigorous expectations of writing , just as professional writers might carefully scrutinize text generator output and be able to produce their own immediate injection of inline text without text generators ( Calderwood , 2020 ) . At the same time , a text generator can play an essential role for students who are unsophisticated writers and who need an immediate injection of text . By playing these different scaffolding roles , text generators , like other NLG tools , can demonstrate pedagogical value in personalizing learning , ( Zhai et al . , 2021 ) interacting with students who show different learning trajectories and different paces to learn AI ( Salas - Pilco , 2020 ) . The third empirical finding is also interaction patterns from students’ text generation process . Students selected text generators based on how they consider text generators’ quantity of output and technical aspects . The conceptualization of students’ selecting from multiple text generators is unique to this study , and this study’s findings can inform text generator design principles for student users . When designing text generators for student use , we recommend a 23 greater quantity of text generator output words from which students can select text . Designers of text generators for students could present a large body of output text to a student per the output interfaces of the Text Generators GPT - NEO - 1 . 3B and GPT - NEO - 2 . 7B , or present more than one body of output text per the Next Sentence Generator output interface . The latter follows Yang et al . ’s ( 2022 ) recommendation to display multiple outputs . Thus , these types of text generator designs should provide many suggestions that writers can swap out or replace frequently ( Calderwood et al . , 2020 ) and that might increase writer productivity ( Lee et al . , 2022 ) . Ultimately , they should provide more structured assistance for learners than traditional word processors ( Gayed et al . , 2022 ) , enabling a high level of student control over human - AI creative writing and catering to a wider range of writers ( Clark et al . , 2018 ) . A final empirical finding is a range of affective feelings , which resonates with other studies ( Clark et al . , 2018 ; Lee et al . , 2022 ) that found users could experience positive and negative feelings from creative writing with NLG . Importantly , these feelings were due to text generator compliance and unanticipated situations in the creative writing process . The former reason could be related to Yang et al . ’s ( 2022 ) findings of two types of users who had different reactions to text generator output based on whether the users had concrete ideas about what they wanted to write . In our study , students who have concrete ideas might consider text generator output less acceptable than students who do not have concrete ideas about what to write . As for the latter reason , since a student found a teacher’s input of ideas quite helpful , for the design of AI curriculum , a teacher plays an essential role to moderate a student’s affective domain for human - AI creative writing in a classroom context . For example , we recommend a teacher help students to interpret text generator output . Besides , a teacher can actively influence a student’s short story writing , input for a text generator and text generator selection process . A teacher can also be a necessary mediator of a student ' s technical difficulties during human - AI creative writing . 5 . 1 Summary In summary , we have delineated a text generation process and text generators as AI NLG learning tools . We have reported exploratory findings on how students apply text generation to creative writing through the 1st Human - AI Creative Writing Contest in a Hong Kong mainstream secondary school . We discovered students’ different strategies for creative writing with text generators . Based on the findings of different strategies , we have suggested pedagogical strategies by which educators might use text generators for creative writing . Furthermore , we have revised our conceptual framework ( see Figure 6 ) to include the input of a teacher and possible error outputs from the text generation process and the short story writing . This conceptual framework can inform the design of pedagogical practice for students’ creative writing with text generators in a classroom and the development of AI curriculum in a school . 24 Fig 6 A conceptual framework for student - AI creative writing 5 . 2 Limitations Although the study is unique in that its sample of secondary school students represent a range of ages and grade - levels and that it is situated outside the Anglosphere , the study is small - scale and exploratory in nature . The findings should not be considered statistical generalizations but theoretical contributions to the design and implementation of creative writing with NLG in schools . Therefore , subsequent research should test these contributions , not least by studying a larger number of students and employing more rigorous instrumentation . Another study limitation is the technical aspects of the text generators . Although the open - source language models used in this study are state - of - the art , some commercial language models are superior at present and we foresee advances in performance for open - source language models . Besides , the open - source language models in this study were neither fine - tuned nor were their default parameters changed . The study of commercial language model use and fine - tuned language model use in mainstream schools appears necessary but remains under - explored . Another study limitation is time as an uncontrolled variable in the study . Although the submission deadline for the contest was set at April 7 , and although each workshop was limited to one hour in length , there were no other time constraints on students’ writing their short stories and interacting with text generators . Perhaps , setting a strict time limit for students to write short stories and to interact with text generators would change results for the composition of AI words in short stories and qualitative results for students’ cognitive and affective domains . In addition , there are socio - technical barriers to replicating the 1st Human - AI Creative Writing Contest in another mainstream school . Although our study has drawn attention to how open - source language models are freely downloadable and can facilitate human - AI creative 25 writing in a mainstream school with limited financial means , most schools even in Hong Kong still lack human knowledge and skills and other resources to design AI curriculum ( Chiu et al . , 2022 ) . To replicate the contest would require a school to have , for instance , not only sufficient personnel who understand the text generation process but also sufficient personnel who might handle the technical aspects of designing , implementing and maintaining text generator hardware and software in schools . Schools will require different strategies to resolve these interconnected barriers ( Wang & Cheng , 2021 ) . They might address these barriers not least by partnering with commercial providers or university experts , or by training their existing personnel or employing new personnel . A final limitation is that this paper has not directly addressed ethics and broader impacts of human - AI creative writing in schools . There is evidence that language models can present a means to carry out academic misconduct because neither the human eye ( Brown et al . , 2022 ) nor plagiarism detection software ( Biderman & Raff , 2022 ) might detect text generator words in a purportedly human - written text . Thus , as research into language models and human - AI creative writing in schools advances , we believe there should be corresponding discussion on the educational leadership and policy implications . 26 6 References Bender , E . M . , Gebru , T . , McMillan - Major , A . , & Shmitchell , S . ( 2021 ) . On the Dangers of Stochastic Parrots : Can Language Models Be Too Big ? & # x1f99c ; Proceedings of the 2021 ACM Conference on Fairness , Accountability , and Transparency , 610 – 623 . https : / / doi . org / 10 . 1145 / 3442188 . 3445922 Bengoetxea , K . , Gonzalez - Dios , I . , & Aguirregoitia , A . ( 2020 ) . LagunTest : A NLP Based Application to Enhance Reading Comprehension . Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties ( READI ) , 63 – 69 . https : / / aclanthology . org / 2020 . readi - 1 . 10 Biderman , S . , & Raff , E . ( 2022 ) . Neural Language Models are Effective Plagiarists ( arXiv : 2201 . 07406 ) . arXiv . https : / / doi . org / 10 . 48550 / arXiv . 2201 . 07406 Black , S . , Gao , L . , Wang , P . , Leahy , C . , & Biderman , S . ( 2021 ) . GPT Neo : Large Scale Autoregressive Language Modeling with Mesh - Tensorflow ( 1 . 0 ) [ Python ] . EleutherAI . https : / / doi . org / 10 . 5281 / zenodo . 5297715 ( Original work published 2020 ) Braun , V . , & Clarke , V . ( 2006 ) . Using thematic analysis in psychology . Qualitative Research in Psychology , 3 ( 2 ) , 77 – 101 . https : / / doi . org / 10 . 1191 / 1478088706qp063oa Brown , T . B . , Mann , B . , Ryder , N . , Subbiah , M . , Kaplan , J . , Dhariwal , P . , Neelakantan , A . , Shyam , P . , Sastry , G . , Askell , A . , Agarwal , S . , Herbert - Voss , A . , Krueger , G . , Henighan , T . , Child , R . , Ramesh , A . , Ziegler , D . M . , Wu , J . , Winter , C . , … Amodei , D . ( 2020 ) . Language Models are Few - Shot Learners ( arXiv : 2005 . 14165 ) . arXiv . https : / / doi . org / 10 . 48550 / arXiv . 2005 . 14165 Calderwood , A . , Qiu , V . , Gero , K . I . , & Chilton , L . B . ( 2018 , March 5 ) . How Novelists Use Generative Language Models : An Exploratory User Study . IUI ’20 : Proceedings of the 25th International Conference on Intelligent User Interfaces . ACM IUI 2020 , Cagliari , Italy . Chen , L . , Chen , P . , & Lin , Z . ( 2020 ) . Artificial Intelligence in Education : A Review . IEEE Access . https : / / doi . org / 10 . 1109 / ACCESS . 2020 . 2988510 Chiu , T . K . F . , & Chai , C . ( 2020 ) . Sustainable Curriculum Planning for Artificial Intelligence Education : A Self - Determination Theory Perspective . Sustainability , 12 ( 14 ) , 5568 . https : / / doi . org / 10 . 3390 / su12145568 Chiu , T . K . F . , Meng , H . , Chai , C . - S . , King , I . , Wong , S . , & Yam , Y . ( 2022 ) . Creation and Evaluation of a Pretertiary Artificial Intelligence ( AI ) Curriculum . IEEE Transactions on Education , 65 ( 1 ) , 30 – 39 . https : / / doi . org / 10 . 1109 / TE . 2021 . 3085878 Clark , E . , Ross , A . S . , Tan , C . , Ji , Y . , & Smith , N . A . ( 2018 ) . Creative Writing with a Machine in the Loop : Case Studies on Slogans and Stories . 23rd International Conference on Intelligent User Interfaces , 329 – 340 . https : / / doi . org / 10 . 1145 / 3172944 . 3172983 Devlin , J . , Chang , M . - W . , Lee , K . , & Toutanova , K . ( 2019 ) . BERT : Pre - training of Deep Bidirectional Transformers for Language Understanding . Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) , 4171 – 4186 . https : / / doi . org / 10 . 18653 / v1 / N19 - 1423 Ford , C . , McNally , D . , & Ford , K . ( 2017 ) . Using Design - Based Research in Higher Education Innovation . Online Learning , 21 ( 3 ) . https : / / doi . org / 10 . 24059 / olj . v21i3 . 1232 Gatt , A . , & Krahmer , E . ( 2018 ) . Survey of the State of the Art in Natural Language Generation : Core tasks , applications and evaluation . Journal of Artificial Intelligence Research , 61 , 65 – 170 . https : / / doi . org / 10 . 1613 / jair . 5477 27 Gayed , J . M . , Carlon , M . K . J . , Oriola , A . M . , & Cross , J . S . ( 2022 ) . Exploring an AI - based writing Assistant’s impact on English language learners . Computers and Education : Artificial Intelligence , 3 , 100055 . https : / / doi . org / 10 . 1016 / j . caeai . 2022 . 100055 Gero , K . I . , & Chilton , L . B . ( 2019 ) . Metaphoria : An Algorithmic Companion for Metaphor Creation . Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems , 1 – 12 . https : / / doi . org / 10 . 1145 / 3290605 . 3300526 Gravemeijer , K . P . E . , & Cobb , P . ( 2006 ) . Design research from a learning design perspective . In J . Akker , K . Gravemeijer , S . McKenney , & N . Nieveen ( Eds . ) , Educational Design Research ( pp . 45 – 85 ) . Taylor and Francis Ltd . Hancock , J . T . , Naaman , M . , & Levy , K . ( 2020 ) . AI - Mediated Communication : Definition , Research Agenda , and Ethical Considerations . Journal of Computer - Mediated Communication , 25 ( 1 ) , 89 – 100 . https : / / doi . org / 10 . 1093 / jcmc / zmz022 Hugging Face . ( n . d . ) . What is Text Generation ? - Hugging Face . Retrieved June 9 , 2022 , from https : / / huggingface . co / tasks / text - generation Johnson , S . , & Iziev , N . ( 2022 , April 15 ) . A . I . Is Mastering Language . Should We Trust What It Says ? The New York Times . https : / / www . nytimes . com / 2022 / 04 / 15 / magazine / ai - language . html Kim , J . , Lee , H . , & Cho , Y . H . ( 2022 ) . Learning design to support student - AI collaboration : Perspectives of leading teachers for AI in education . Education and Information Technologies . https : / / doi . org / 10 . 1007 / s10639 - 021 - 10831 - 6 Kim , S . , Jang , Y . , Kim , W . , Choi , S . , Jung , H . , Kim , S . , & Kim , H . ( 2021 ) . Why and What to Teach : AI Curriculum for Elementary School . Proceedings of the AAAI Conference on Artificial Intelligence , 35 ( 17 ) , 15569 – 15576 . https : / / ojs . aaai . org / index . php / AAAI / article / view / 17833 Kreminski , M . , Dickinson , M . , Mateas , M . , & Wardrip - Fruin , N . ( 2020 ) . Why Are We Like This ? : The AI Architecture of a Co - Creative Storytelling Game . International Conference on the Foundations of Digital Games , 1 – 4 . https : / / doi . org / 10 . 1145 / 3402942 . 3402953 Kuleto , V . , Ilić , M . , Dumangiu , M . , Ranković , M . , Martins , O . M . D . , Păun , D . , & Mihoreanu , L . ( 2021 ) . Exploring Opportunities and Challenges of Artificial Intelligence and Machine Learning in Higher Education Institutions . Sustainability , 13 ( 18 ) , 10424 . https : / / doi . org / 10 . 3390 / su131810424 Lee , M . , Liang , P . , & Yang , Q . ( 2022 ) . CoAuthor : Designing a Human - AI Collaborative Writing Dataset for Exploring Language Model Capabilities . https : / / doi . org / 10 . 1145 / 3491102 . 3502030 Liu , P . , Yuan , W . , Fu , J . , Jiang , Z . , Hayashi , H . , & Neubig , G . ( 2021 ) . Pre - train , Prompt , and Predict : A Systematic Survey of Prompting Methods in Natural Language Processing ( arXiv : 2107 . 13586 ) . arXiv . http : / / arxiv . org / abs / 2107 . 13586 Long , D . , & Magerko , B . ( 2020 ) . What is AI Literacy ? Competencies and Design Considerations . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems ( pp . 1 – 16 ) . Association for Computing Machinery . https : / / doi . org / 10 . 1145 / 3313831 . 3376727 Ng , D . T . K . , Luo , W . , Chan , H . M . Y . , & Chu , S . K . W . ( 2022 ) . Using digital story writing as a pedagogy to develop AI literacy among primary students . Computers and Education : Artificial Intelligence , 3 , 100054 . https : / / doi . org / 10 . 1016 / j . caeai . 2022 . 100054 Radford , A . , Wu , J . , Child , R . , Luan , D . , Amodei , D . , & Sutskever , I . ( 2019 ) . Language Models are Unsupervised Multitask Learners . Undefined . 28 https : / / www . semanticscholar . org / paper / Language - Models - are - Unsupervised - Multitask - Learners - Radford - Wu / 9405cc0d6169988371b2755e573cc28650d14dfe Salas - Pilco , S . Z . ( 2020 ) . The impact of AI and robotics on physical , social - emotional and intellectual learning outcomes : An integrated analytical framework . British Journal of Educational Technology , 51 ( 5 ) , 1808 – 1825 . https : / / doi . org / 10 . 1111 / bjet . 12984 Saldana , J . ( 2012 ) . The Coding Manual for Qualitative Researchers . SAGE Publications . https : / / books . google . com . hk / books ? id = V3tTG4jvgFkC Sanusi , I . T . , Olaleye , S . A . , Oyelere , S . S . , & Dixon , R . A . ( 2022 ) . Investigating learners’ competencies for artificial intelligence education in an African K - 12 setting . Computers and Education Open , 3 , 100083 . https : / / doi . org / 10 . 1016 / j . caeo . 2022 . 100083 See , A . , Pappu , A . , Saxena , R . , Yerukola , A . , & Manning , C . D . ( 2019 ) . Do Massively Pretrained Language Models Make Better Storytellers ? ( arXiv : 1909 . 10705 ) . arXiv . https : / / doi . org / 10 . 48550 / arXiv . 1909 . 10705 Skalski , P . D . , Neuendorf , K . A . , & Cajigas , J . A . ( 2017 ) . The Content Analysis Guidebook ( By pages 201 - 242 ; Second ) . SAGE Publications , Inc . https : / / doi . org / 10 . 4135 / 9781071802878 Somers , R . , Cunningham - Nelson , S . , & Boles , W . ( 2021 ) . Applying natural language processing to automatically assess student conceptual understanding from textual responses . Australasian Journal of Educational Technology , 37 ( 5 ) , 98 – 115 . https : / / doi . org / 10 . 14742 / ajet . 7121 Su , J . , Zhong , Y . , & Ng , D . T . K . ( 2022 ) . A meta - review of literature on educational approaches for teaching AI at the K - 12 levels in the Asia - Pacific region . Computers and Education : Artificial Intelligence , 3 , 100065 . https : / / doi . org / 10 . 1016 / j . caeai . 2022 . 100065 UNESCO . ( 2022 ) . K - 12 AI curricula : A mapping of government - endorsed AI curricula— UNESCO Digital Library ( ED - 2022 / FLI - ICT / K - 12 ; p . 60 ) . https : / / unesdoc . unesco . org / ark : / 48223 / pf0000380602 Vuorikari , R . , Kluzer , S . , & Punie , Y . ( 2022 ) . DigComp 2 . 2 : The Digital Competence Framework for Citizens - With new examples of knowledge , skills and attitudes . https : / / doi . org / 10 . 2760 / 115376 Wang , T . , & Cheng , E . C . K . ( 2021 ) . An investigation of barriers to Hong Kong K - 12 schools incorporating Artificial Intelligence in education . Computers and Education : Artificial Intelligence , 2 , 100031 . https : / / doi . org / 10 . 1016 / j . caeai . 2021 . 100031 Yang , D . , Zhou , Y . , Zhang , Z . , & Li , T . J . - J . ( 2022 ) . AI as an Active Writer : Interaction strategies with generated text in human - AI collaborative fiction writing . Joint Proceedings of the ACM IUI Workshops 2022 , 10 . Yang , Y . , Long , Y . , Sun , D . , Van Aalst , J . , & Cheng , S . ( 2020 ) . Fostering students’ creativity via educational robotics : An investigation of teachers’ pedagogical practices based on teacher interviews . British Journal of Educational Technology , 51 ( 5 ) , 1826 – 1842 . https : / / doi . org / 10 . 1111 / bjet . 12985 Zhai , X . , Chu , X . , Chai , C . S . , Jong , M . S . Y . , Istenic , A . , Spector , M . , Liu , J . - B . , Yuan , J . , & Li , Y . ( 2021 ) . A Review of Artificial Intelligence ( AI ) in Education from 2010 to 2020 . Complexity , 2021 , e8812542 . https : / / doi . org / 10 . 1155 / 2021 / 8812542 Zhang , S . , Roller , S . , Goyal , N . , Artetxe , M . , Chen , M . , Chen , S . , Dewan , C . , Diab , M . , Li , X . , Lin , X . V . , Mihaylov , T . , Ott , M . , Shleifer , S . , Shuster , K . , Simig , D . , Koura , P . S . , Sridhar , A . , Wang , T . , & Zettlemoyer , L . ( 2022 ) . OPT : Open Pre - trained Transformer Language Models . ArXiv : 2205 . 01068 [ Cs ] . http : / / arxiv . org / abs / 2205 . 01068 29 Appendix 1 . Workshop learning targets Workshop No . Number Learning targets 1 2 3 4 5 6 7 1 I can read an example text for a person ' s own words and for AI words . 1 1 1 2 I can locate a text generator and use its features . 1 1 1 1 1 1 1 3 I can open a new Google Doc , name it and share it . 1 1 1 4 I can compose a short story according to the contest rules . 1 1 1 5 I can develop a method to write a short story using my own words and AI words . 1 1 1 1 1 1 1 6 I can express my feelings when writing a short story using AI . 1 1 7 I can evaluate text generators . 1 1 1 1 1 1 8 I can drag and highlight text . 1 1 1 9 I can copy and paste input text . 1 1 1 10 I can copy and paste output text . 1 1 1 11 I can delete text . 1 1 1 12 I can type text . 1 1 1 13 I can change text color . 1 1 1 14 I can capitalize proper nouns and the beginning of a sentence . 1 1 1 15 I can add a space after commas , full stops and question marks . 1 1 1 16 I can indicate paragraphs by indents or line spacing . 1 1 1 17 I can decide on input text 1 18 I can take a screenshot . 1 19 I can integrate my words and a machine’s words in a sentence . 1 20 I can integrate my sentence ( s ) and a machine’s sentence ( s ) in a paragraph . 1 21 I can decide on input text ( e . g . title ; author ; word ; phrase ; sentence ( s ) ; paragraphs 1 22 I can decide on output text ( e . g . word ( s ) ; sentence ( s ) . 1 23 I can edit and integrate AI output text in my story . 1 24 Create the elements and structure of a short story . 1 1 1 25 Plan the characters , time and place for a short story . 1 1 1 26 Plan the events of a short story . 1 1 1 30 27 Plan the sequence of events for a short story according to a short story plot structure . 1 1 1 28 I can decide on content area input text ( e . g . title ; author ; word ; phrase ; topic sentence ( s ) ; paragraph ( s ) ) for text generator 1 1 1 29 I can decide on appropriate text generator output text ( e . g . word ( s ) ; sentence ( s ) ) . 1 1 1 30 I can edit and integrate output text in my story . 1 1 1