A C ONTENT - B ASED N OVELTY M EASURE FOR S CHOLARLY P UBLICATIONS : A P ROOF OF C ONCEPT ∗ Haining Wang Indiana University Bloomington Bloomington , Indiana , USA hw56 @ indiana . edu A BSTRACT Novelty , akin to gene mutation in evolution , opens possibilities for scientific advancement . Despite peer review being the gold standard for evaluating novelty in scholarly communication and resource allocation , the vast volume of submissions necessitates an automated measure of scientific novelty . Adopting a perspective that views novelty as the atypical combination of existing knowledge , we introduce an information - theoretic measure of novelty in scholarly publications . This measure is quantified by the degree of ‘surprise’ perceived by a language model that represents the distribution of scientific discourse . The proposed measure is accompanied by face and construct validity evidence ; the former demonstrates correspondence to scientific common sense , and the latter is endorsed through alignments with novelty evaluations from a select panel of domain experts . Additionally , characterized by its interpretability , fine granularity , and accessibility , this measure addresses gaps prevalent in existing methods . We believe this measure holds great potential to benefit editors , stakeholders , and policymakers , and it provides a confident lens for examining the relationship between novelty and scientific dynamics such as creativity , interdisciplinarity , scientific advances , and more . K eywords Novelty · Measure · Language Model · Information Theory 1 Introduction From alchemy to AlphaFold , the progress of science is undeniable . Much like gene mutation drives evolution , novelty— often seen as the recombination of existing knowledge elements—allows for scientific breakthroughs from known terrain . It also serves as a key criterion for academic institutions and funding agencies , with submissions frequently required to showcase novel findings and insights . For example , in 2022 , the word ‘novel’ appeared in the titles or abstracts of over 8 % of the 1 . 8 million papers published on PubMed . While recognizing novelty is crucial for pushing scientific boundaries , its presence and extent are often judged by subjective assessments of domain experts . In the face of the huge volume of scientific outputs and applications , an automatic measure of scientific novelty can be beneficial for reviewers , editors , stakeholders , and policymakers . The pursuit of an automated measure of scientific novelty , in alignment with human judgment , emerges as both a technical and philosophical imperative . In this study , we conceptualize novelty as ‘atypical combinations of knowledge’ within the framework of information theory , and adopt the information - theoretic measure , surprisal , to evaluate the novelty present in scholarly publications based on their content in the context of current scientific landscapes . Specifically , we treat each word in the main content of a manuscript as a unit of knowledge . The atypicality of a sequence of these units , i . e . , a manuscript , can be calculated based on the sequence’s deviation from a distribution that approximates word distribution in scientific discourse . It enables the identification and measurement of novelty in a bottom - up manner , from the word level onwards . Furthermore , the measure’s numeric values are interpretable due to its information - theoretic nature , a characteristic not ∗ This research was supported in part by Lilly Endowment , Inc . , through its support for the Indiana University Pervasive Technology Institute . a r X i v : 2401 . 03642v1 [ c s . C L ] 8 J a n 2024 A Content - Based Novelty Measure possessed by other existing novelty measures . The measure , code , and data are accessible under a permissive license , available at github . com / Wang - Haining / noveval . 2 Literature Review Historical inquiries have shed light on the defining characteristic of novelty in scholarly publications as the recombination of existing knowledge in atypical ways ( Mayer , 1995 ; Simonton , 2004 ; Bornmann et al . , 2019 ; Godart et al . , 2020 ) . We use the terms ‘originality’ and ‘novelty’ interchangeably in the context of scholarly communication ( Guetzkow et al . , 2004 ) . However , novelty , which is distinct from creativity that often entails both usefulness ( Sternberg and Sternberg , 2011 ; Pichot et al . , 2022 ) and impact ( Fontana et al . , 2020 ; Park et al . , 2023 ) , does not necessarily lead to scientific advances ( Poincaré , 1910 ; Godart et al . , 2020 ) . 2 . 1 Novelty Measures Based on Reference , Keyword , Title , and Abstract Operationalizing knowledge components at the levels of journals ( Uzzi et al . , 2013 ; Lee et al . , 2015 ; Wang et al . , 2017 ; Veugelers and Wang , 2019 ) and documents ( Trapido , 2015 ; Matsumoto et al . , 2021 ; Dahlin and Behrens , 2005 ) , the atypicality is obtained by contrasting observed combinations against local or global co - occurrences found in past literature . Apart from hesitations regarding citing behavior for non - intellectual reasons ( Nigel Gilbert , 1977 ; Nisonger , 2011 ) or casual ones ( Smith , 1981 ; Callaert et al . , 2014 ; Nagaoka and Yamauchi , 2015 ) , the main critique is that the granularity of the knowledge unit is coarse since it is based on the premise of knowledge homogeneity within a journal and also ignores the content of a manuscript . With co - occurrence networks , knowledge units are also operationalized using keywords , where rarely paired keywords ( Tahamtan and Bornmann , 2018 ) and controlled vocabulary ( Boudreau et al . , 2016 ) are used as heuristics to gauge novelty . Semantically divergent titles ( Jeon et al . , 2023 ) and abstracts ( Shibayama et al . , 2021 ) are also considered as indicators of novelty . 2 . 2 Novelty Measures Based on Content Interestingly , the content of a manuscript is rarely examined . A straightforward way to explore the full text of a manuscript is to cast novelty evaluation as a regression task ( Kang et al . , 2018 ; Wang et al . , 2023 ) using discriminative models , perhaps enhanced with reviews from experts ( Kang et al . , 2018 ) and social media ( Li et al . , 2022 ) . However , discriminative models assume that the word distribution in the papers being examined has an independent and identically distributed ( IID ) relationship with respect to the training data . Therefore , it is theoretically untenable for such models to be applied to papers that do not conform to the IID assumption , as this violates the definition of novelty , which entails unconventional distributions of words . Using the concept of terminology life stages and distance in the semantic space of contextual embeddings , Luo et al . ( 2022 ) examine rare combinations of terms in the question and method sections of a paper , while possibly overlooking other sections where novelty may also be present . 2 . 3 Considerations for Designing a Novelty Measure We distill the essential attributes of an effective novelty measure by drawing upon the identified limitations of current measures and incorporating the best practices established within relevant fields . In particular , we find the ‘CORE’ principle to hold significant promise : it advocates for a Content - based novelty measure that is Open , Reproducible , and Explainable . First , novelty , in common sense , resides in a manuscript’s content . Seeking novelty from the content closely mirrors what a human reviewer would do and clearly delineates between the measuring of novelty and interdisciplinarity ( Fontana et al . , 2020 ) . Second , as trust stems from explainability , a numerical value for a measure cannot be relied upon unless it can be adequately interpreted . Explainability is also closely related to the third consideration , context , which is used for contrasting atypicality from commonality . The evaluation of a word’s novelty varies with context ; for example , a discussion on graph theory may be perceived differently in a philosophy journal compared to an applied physics setting ( Runco and Charles , 1993 ; Long , 2014 ; Acar et al . , 2017 ) . Fourth , simply stretching network theories or examining semantic distance does not provide sufficient granularity when investigating whether a snippet of a paper is novel or less so . A smaller knowledge unit can enable a more thorough examination for novelty . Lastly , novelty measures have heavily relied on proprietary citation databases behind paywalls . While useful , the reality that dataset publishers often have vested interests , such as subscriptions , promotions , and language services , presents challenges to the principles of accessibility and transparency in science . An ideal solution would involve releasing measures under permissive licenses , accompanied by all the essential materials required for replication , while avoiding alignment with commercial interests . 2 A Content - Based Novelty Measure 3 An Information - Theoretical Understanding of Novelty in Scholarly Publications Let’s further ground the defining characteristic of novelty , ‘atypical recombination of existing knowledge units , ’ in the language of probability and information theory . First , because a scientific paper primarily includes a sequence of words as its main content used to convey the authors’ intentions , we consider the unit of knowledge to be words , including those composed of the alphabet , punctuation marks , numerals , and special characters . Second , because the narrative is naturally sequential , ‘recombination’ means a sequence of words . Third , ‘atypical’ essentially means that the likelihood of observing a particular event is low . Put together , scientific novelty in a scientific article implies that the joint probability of observing the sequence of words is low in the universe of scientific discourse . In information theory , a low probability indicates a deviation from the expected distribution of a random variable . In this context , the random variable represents the occurrence of each word within the realm of scientific discourse , denoted as P . By measuring a word’s probability relative to P , we assess its deviation from the expected norm in scientific discourse . This deviation is quantified as Shannon information ( Shannon , 1948 ) , or surprisal ( Tribus , 1961 ) for short . The surprisal of a word x from a set of possible words X , given its probability under the distribution P , is computed as its base - 2 logarithm : I ( x ) = − log P ( x ) , x ∈ X ( 1 ) This formula highlights the inverse relationship between probability and surprisal : as the probability of a token decreases , its surprisal increases , indicating a higher level of novelty or unexpectedness in the random variable representing scientific discourse . The cumulative surprisal of a sequence of words x 1 , x 2 , . . . , x n in a manuscript , given their joint probability under the distribution P , is computed as follows : I ( x 1 , x 2 , . . . , x n ) = − log n (cid:89) i = 1 P ( x i ) = − n (cid:88) i = 1 log P ( x i ) ( 2 ) where I ( x 1 , x 2 , . . . , x n ) denotes the cumulative surprisal of the sequence , and P ( x i ) is the probability of each word x i as estimated by the distribution P . In essence , words that are highly probable in P result in lower cumulative or average surprisal values , indicating their commonality in scientific discourse . This scenario mirrors a scientific paper discussing well - established data or theories . Such a paper’s surprisal value is minimal , as it largely reaffirms what the scientific community already knows , offering little to no new information . Conversely , a paper that introduces a novel concept or method significantly deviating from established norms carries a high surprisal value . This indicates a substantial divergence from standard scientific expectations and , consequently , a high degree of novelty in the research . 4 Approximating Scientific Discourse With a Language Model 4 . 1 Language Modeling The novelty of a scientific narrative is gauged by its divergence from the distribution of scientific discourse P . However , since P is not directly observable , we use a surrogate distribution , Q , to approximate typical scientific discourse . Specifically , we operationalized distribution Q using a causal language model , where the probability of the presence of a word is conditioned on the preceding words and is estimated from English Wikipedia . We adopted the Generative Pretrained Transformer ( GPT - 2 ) architecture ( Radford et al . , 2019 ) , employing its smallest model variant with approximately 124 million parameters , and trained it from scratch . 2 . GPT - 2 was selected for its widespread use and the superior ability to model complex language patterns . For ease of understanding , we narrate using ‘words’ as the unit of knowledge . In practice , language models typically use ‘tokens , ’ which correspond to shorter words or sub - words , to effectively capture semantic relationships and address out - of - vocabulary issues . For example , the word ‘bioinformatics’ can be tokenized into ‘bio , ’ ‘inform , ’ and ‘atics , ’ allowing the model to process both familiar and novel terms by breaking them down into recognizable components . Token - level granularity renders models sensitive to subtle signals of novelty . In total , there are 50 , 304 tokens , the combinations of which constitute scientific discourse . 2 Our implementation adhered to the original version , featuring a maximum input length of 1 , 024 tokens , 12 transformer layers , 3 A Content - Based Novelty Measure During training , the parameters of the GPT - 2 Q are updated so as to maximize the probability of observing the next token based on its preceding tokens . If the language model is well - trained , it can serve as a good proxy for scientific discourse . For example , given the history ‘The theory of relativity was proposed by _ _ , ’ we would expect the language model to predict the next token as ‘Albert’ instead of tokens such as ‘Ludwig’ or ‘that . ’ The probability of observing a sequence from the manuscript of interest is a joint probability of the tokens in the sequence : Q ( w 1 : n ) = Q ( x 1 ) Q ( x 2 ) Q ( x 3 ) . . . Q ( x n ) = Q ( x 1 ) Q ( x 2 | x 1 ) Q ( x 3 | x 1 : 2 ) . . . Q ( x n | x 1 : n − 1 ) = n (cid:89) i = 1 Q ( x i | x 1 : i − 1 ) ( 3 ) Note that , in theory , each token’s probability is conditioned on all its preceding tokens ( or history ) . The joint probability can then be readily plugged into Eq . 2 for cumulative surprisal calculation . 4 . 2 Modeling Scientific Discourse We operationalize the proxy distribution of scientific discourse Q using an English Wikipedia corpus . The corpus was created by cleaning a Wikipedia dump that contained all English Wikipedia articles as of March 2022 ( Wikimedia Foundation , 2023 ) . The training set contained approximately 6 . 5 million documents and 4 . 6 billion tokens 3 . Wikipedia articles represent one genre of scientific discourse that offers a wide range of facts , common sense , and established theory in diverse scientific fields ( Patton , 2002 ; Petroni et al . , 2023 ) . They share the explanatory nature of typical scientific manuscripts . Additionally , Wikipedia articles are written by many authors spanning a long period , which may help to account for stylistic and temporal variations in language . Generally , Wikipedia articles are better suited to our goals than scientific corpora that consist only of abstracts or full texts parsed from PDF files . The former fails to provide a more accurate representation of the structure of full - length articles . The latter often contains OCR artifacts and requires further consideration of disciplinary balance , which trades off generalization and specificity . 4 . 3 Notes on Surprisal Calculation The accurate estimation of a surprisal score for a token requires a sufficiently long text , as the probability of the token is conditioned on all its preceding tokens ( Eq . 3 ) . In practice , however , constructing a language model to account for an extremely long context window is computationally expensive , so we adopt a fixed window of 1 , 024 tokens , faithfully mirroring the original GPT - 2 architecture . To achieve reliable estimations , each token’s calculation was conditioned on a history of at least 256 or 512 preceding tokens . 4 5 Assessing Face Validity Using Illustrative Examples Having established the theory of measuring novelty using surprisal derived from a proxy distribution of scientific discourse , our next step is to assess its face validity . To this end , we will start with two token - level examples for illustration in the realm of quantum physics and move to examining surprisal’s capacity to distinguish novelty from two groups of sentences paraphrased from the examples . 5 . 1 A Token - Level Examination The two examples are shown in Figure 1 , each underpinned by the same history of approximately 500 words , differing in only one token : ‘room’ and ‘low . ’ In quantum entanglement research , traditional methods typically focus on low - temperature observations , as quantum states are sensitive to temperature changes , leading to challenges in maintaining entangled states . Consequently , the statement in the bottom - right of Figure 1 , which suggests observing quantum states at room temperature , is theoretically more novel . 12 self - attention heads per layer , and a model dimensionality of 768 . We refrained from applying any dropout or bias terms . 3 We used four A100 GPUs ( 40 GB memory each ) , set a batch size of 16 per GPU , and accumulated 5 gradients before updating the model’s parameters . This results in a total of approximately 0 . 33 million tokens per update . We fixed a total training course of 141 , 000 steps , resulting in a total of approximately 46 billion tokens processed ( ten times the size of the Wikipedia corpus ) . AdamW optimization was used with β 1 = 0 . 9 and β 2 = 0 . 95 . The optimizer had a weight decay rate of 0 . 1 , and the learning rate was reduced from a maximum of 6 e – 4 to a minimum of 6 e – 5 over the training course , with a warm - up period of 2 , 000 steps . The training of each GPT - 2 took approximately 43 hours . 4 An ‘end of document’ symbol ( < | endoftext | > ) is prepended to the start of each document for these calculations . 4 A Content - Based Novelty Measure We calculated the surprisal for the two tokens sharing the same history using the GPT - 2 model trained on Wikipedia data ( i . e . , Q sci ) . The token ‘low’ scores a surprisal of 2 . 58 bits , corresponding to a probability of 0 . 17 ( i . e . , 2 − 2 . 58 ) , is ranked the first among all 50 , 304 tokens in the vocabulary . Whereas the token ‘room’ has a much higher surprisal score of 4 . 42 bits , corresponding to a lower probability of 0 . 05 ( i . e . , 2 − 4 . 42 ) , and is ranked the 6th . This corroborates common sense in quantum entanglement research : doing experiments at low temperatures is commonplace , carrying little novelty , hence higher probability and lower surprisal . Figure 1 : Illustrative examples showing the probability rankings of potential subsequent tokens given a common preceding context . Based on the same history , the GPT - 2 model , trained exclusively on English Wikipedia , predicts the next token as ‘room’ with a probability of 0 . 05 , and ‘low’ with a probability of 0 . 17 , indicating that room - temperature observation in quantum states is more novel . 5 . 2 A Sentence - Level Examination We further tested the face validity at the sentence level using two groups of sentences sharing the same history : each of the two sentences mentioned before was paraphrased twenty times using ChatGPT . The average surprisal score was calculated for each paraphrase in the two groups . Our null hypothesis posited that there would be no significant difference in surprisal scores between the groups , with the expectation that the paraphrases of ‘room - temperature’ sentences would not yield higher scores . A one - tailed Welch’s t - test yielded a t - statistic of 2 . 9 and a p - value of 0 . 003 , with the degrees of freedom approximately 36 . 5 . This finding indicates a significantly higher average surprisal score for room - temperature paraphrases compared to the low - temperature ones , thereby reconfirming the effectiveness of surprisal as a measure of novelty . 6 Assessing Construct Validity Using Known Groups Beyond face validations at the token and sentence levels with synthetic examples , we extend our investigation to ascertain the applicability of surprisal at the section level for measuring novelty in a real - world dataset , using the known - groups technique . Known - groups technique is instrumental in testing construct validity , as it involves comparing two distinct groups expected to differ in the construct being measured ( Portney and Watkins , 1993 ) . In our case , the validity check may operate on two groups of scientific papers , one of which is perceived as more novel than the other by a group of domain experts . Creating a dataset consisting of two comparable groups of papers presents significant challenges due to the multifaceted nature of novelty in academic research ( Guetzkow et al . , 2004 ) . 6 . 1 Authorship Verification Anthology Dataset To make the investigation feasible , we focused on the novelty in methodology and finding sections and developed the Authorship Verification Anthology ( AVA ) dataset . The AVA dataset comprises working notes from a seven - year series of the Authorship Verification task , part of the Conference and Labs of the Evaluation Forum in Digital Text Forensics and Stylometry . The shared task annually challenges global teams using shared datasets and requires teams to publish their working notes , detailing their experiments , models , setups , and data processing . This consistent framework across years ensures a controlled environment for comparing novelty in methodologies and findings sections . We collected all 83 working notes in PDF format and converted them into plain text . Three domain experts independently evaluated each paper using binary scoring to determine the novelty of each working note . The criteria for novelty focused on methodological innovations in feature engineering , algorithms , and model architecture , as well as novelty from the findings , with a knowledge cutoff in mid - 2022 . A conservative threshold was set : papers selected as novel 5 A Content - Based Novelty Measure were those unanimously agreed upon by all raters . The statistics of length distribution and the average surprisal of each manuscript in both groups are shown in Figure 2 . Figure 2 : The left panel presents the distribution of text lengths in the AVA dataset , measured in words . The right panel shows box plots of the average surprisal scores for two groups of papers , one of which is unanimously agreed upon as more novel according to assessments by domain experts . Each paper’s novelty is calculated based on the concatenation of abstract and body text using the model Q sci . We computed the average surprisal of 1 , 024 tokens , each conditioned on at least 256 preceding tokens , because the papers are typically short ( see Fig 2 ) . Finally , 25 out of 80 papers were classified in the novel group , while the remaining ones formed the normal group . 5 . 6 . 2 A Section - Level Examination We conducted a one - tailed Welch’s t - test on two sets of academic manuscripts categorized as ‘novel’ and ‘normal’ , comparing their average surprisal values derived from a GPT - 2 model exposed only to English Wikipedia . We found a t - statistic of 2 . 6 and a p - value of 0 . 005 , with approximately 66 . 3 degrees of freedom , indicating a statistically significant difference in the average surprisal values . The novel papers exhibited higher average surprisal than those in the normal group , suggesting greater novelty in their content . We manually examined the ‘false alarms’—the eight papers with average surprisal values above 5 . 0 that were neverthe - less deemed less novel by our domain experts—to identify potential causes for these anomalies . Two of these papers contain excessive use of in - line mathematical formulas and notations . One paper exhibits non - native , informal English , including instances of directly addressing the audience as ‘you . ’ Three papers , authored by the same research team and reporting a series of incremental improvements on the same method , appear to have their surprisal scores influenced by the consistency in the narrative style of this particular group . The remaining two papers , with average surprisal scores just above the 5 . 0 threshold , are considered marginal cases . 7 Conclusion In this proof - of - concept study , we reported a content - based measure for assessing novelty in scholarly publications , accompanied by a Shannonian explanation beginning at the word level . It is reproducible and openly accessible , supported by face and construct validity evidence . In the next step , we aim to conduct more rigorous validity tests using datasets involving peers from various global regions ( Kang et al . , 2018 ; Bornmann et al . , 2019 ) and in multiple languages . Additionally , we will explore the trade - offs between generalization and disciplinary specificity , along with the caveats associated with its use . References Acar , S . , Burnett , C . , and Cabra , J . F . ( 2017 ) . Ingredients of creativity : Originality and more . Creativity Research Journal , 29 ( 2 ) : 133 – 144 . 5 Three papers were too short for calculation in our setup 6 A Content - Based Novelty Measure Bornmann , L . , Tekles , A . , Zhang , H . H . , and Fred , Y . Y . ( 2019 ) . Do we measure novelty when we analyze unusual combinations of cited references ? A validation study of bibliometric novelty indicators based on f1000prime data . Journal of Informetrics , 13 ( 4 ) : 100979 . Boudreau , K . J . , Guinan , E . C . , Lakhani , K . R . , and Riedl , C . ( 2016 ) . Looking across and looking beyond the knowledge frontier : Intellectual distance , novelty , and resource allocation in science . Management science , 62 ( 10 ) : 2765 – 2783 . Callaert , J . , Pellens , M . , and Van Looy , B . ( 2014 ) . Sources of inspiration ? Making sense of scientific references in patents . Scientometrics , 98 : 1617 – 1629 . Dahlin , K . B . and Behrens , D . M . ( 2005 ) . When is an invention really radical ? : Defining and measuring technological radicalness . research policy , 34 ( 5 ) : 717 – 737 . Fontana , M . , Iori , M . , Montobbio , F . , and Sinatra , R . ( 2020 ) . New and atypical combinations : An assessment of novelty and interdisciplinarity . Research Policy , 49 ( 7 ) : 104063 . Godart , F . , Seong , S . , and Phillips , D . J . ( 2020 ) . The sociology of creativity : Elements , structures , and audiences . Annual Review of Sociology , 46 : 489 – 510 . Guetzkow , J . , Lamont , M . , and Mallard , G . ( 2004 ) . What is originality in the humanities and the social sciences ? American Sociological Review , 69 ( 2 ) : 190 – 212 . Jeon , D . , Lee , J . , Ahn , J . M . , and Lee , C . ( 2023 ) . Measuring the novelty of scientific publications : A fasttext and local outlier factor approach . Journal of Informetrics , 17 ( 4 ) : 101450 . Kang , D . , Ammar , W . , Dalvi , B . , van Zuylen , M . , Kohlmeier , S . , Hovy , E . , and Schwartz , R . ( 2018 ) . A dataset of peer reviews ( PeerRead ) : Collection , insights and NLP applications . In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) , pages 1647 – 1661 . Lee , Y . - N . , Walsh , J . P . , and Wang , J . ( 2015 ) . Creativity in scientific teams : Unpacking novelty and impact . Research policy , 44 ( 3 ) : 684 – 697 . Li , X . , Wen , Y . , Jiang , J . , Daim , T . , and Huang , L . ( 2022 ) . Identifying potential breakthrough research : A machine learning method using scientific papers and twitter data . Technological Forecasting and Social Change , 184 : 122042 . Long , H . ( 2014 ) . More than appropriateness and novelty : Judges’ criteria of assessing creative products in science tasks . Thinking Skills and Creativity , 13 : 183 – 194 . Luo , Z . , Lu , W . , He , J . , and Wang , Y . ( 2022 ) . Combination of research questions and methods : A new measurement of scientific novelty . Journal of Informetrics , 16 ( 2 ) : 101282 . Matsumoto , K . , Shibayama , S . , Kang , B . , and Igami , M . ( 2021 ) . Introducing a novelty indicator for scientific research : validating the knowledge - based combinatorial approach . Scientometrics , 126 ( 8 ) : 6891 – 6915 . Mayer , R . E . ( 1995 ) . The search for insight : Grappling with gestalt psychology’s unanswered questions . In Davidson , J . E . and Sternberg , R . J . , editors , The Nature of Insight . The MIT Press . Nagaoka , S . and Yamauchi , I . ( 2015 ) . The use of science for inventions and its identification : Patent level evidence matched with survey . Technical report , Research Institute of Economy , Trade and Industry ( RIETI ) . Accessed on April 5 , 2023 . Nigel Gilbert , G . ( 1977 ) . Referencing as persuasion . Social studies of science , 7 ( 1 ) : 113 – 122 . Nisonger , T . E . ( 2011 ) . A review and analysis of library availability studies . Library Resources & Technical Services , 51 ( 1 ) : 30 – 49 . Park , M . , Leahey , E . , and Funk , R . J . ( 2023 ) . Papers and patents are becoming less disruptive over time . Nature , 613 ( 7942 ) : 138 – 144 . Patton , J . D . ( 2002 ) . The role of problem pioneers in creative innovation . Communication Research Journal , 14 ( 1 ) : 111 – 126 . Petroni , F . , Broscheit , S . , Piktus , A . , Lewis , P . , Izacard , G . , Hosseini , L . , Dwivedi - Yu , J . , Lomeli , M . , Schick , T . , Bevilacqua , M . , et al . ( 2023 ) . Improving wikipedia verifiability with ai . Nature Machine Intelligence , 5 ( 10 ) : 1142 – 1148 . Pichot , N . , Bonetto , E . , Pavani , J . - B . , Arciszewski , T . , Bonnardel , N . , and Weisberg , R . W . ( 2022 ) . The construct validity of creativity : empirical arguments in favor of novelty as the basis for creativity . Creativity Research Journal , 34 ( 1 ) : 2 – 13 . Poincaré , H . ( 1910 ) . Mathematical creation . The Monist , pages 321 – 335 . 7 A Content - Based Novelty Measure Portney , L . G . and Watkins , M . P . ( 1993 ) . Foundations of Clinical Research : Applications to Practice . Appleton & Lange , Norwalk , Conn . Radford , A . , Wu , J . , Child , R . , Luan , D . , Amodei , D . , Sutskever , I . , et al . ( 2019 ) . Language models are unsupervised multitask learners . OpenAI Blog , 1 ( 8 ) : 9 . Runco , M . A . and Charles , R . E . ( 1993 ) . Judgments of originality and appropriateness as predictors of creativity . Personality and Individual Differences , 15 ( 5 ) : 537 – 546 . Shannon , C . E . ( 1948 ) . A mathematical theory of communication . Bell Systems Technical Journal , 27 : 379 – 423 . Shibayama , S . , Yin , D . , and Matsumoto , K . ( 2021 ) . Measuring novelty in science with word embedding . PloS One , 16 ( 7 ) : e0254034 . Simonton , D . K . ( 2004 ) . Creativity in science : Chance , logic , genius , and zeitgeist . Cambridge University Press . Smith , L . C . ( 1981 ) . Citation analysis . Library Trends , 30 ( 1 ) : 83 – 106 . Sternberg , R . J . and Sternberg , K . ( 2011 ) . Cognitive Psychology . Wadsworth / Cengage Learning . Tahamtan , I . and Bornmann , L . ( 2018 ) . Creativity in science and the link to cited references : Is the creative potential of papers reflected in their cited references ? Journal of informetrics , 12 ( 3 ) : 906 – 930 . Trapido , D . ( 2015 ) . How novelty in knowledge earns recognition : The role of consistent identities . Research Policy , 44 ( 8 ) : 1488 – 1500 . Tribus , M . ( 1961 ) . Thermostatics and Thermodynamics : An Introduction to Energy , Information and States of Matter , with Engineering Applications . D . Van Nostrand Company , Inc . Uzzi , B . , Mukherjee , S . , Stringer , M . , and Jones , B . ( 2013 ) . Atypical combinations and scientific impact . Science , 342 ( 6157 ) : 468 – 472 . Veugelers , R . and Wang , J . ( 2019 ) . Scientific novelty and technological impact . Research Policy , 48 ( 6 ) : 1362 – 1372 . Wang , J . , Veugelers , R . , and Stephan , P . ( 2017 ) . Bias against novelty in science : A cautionary tale for users of bibliometric indicators . Research Policy , 46 ( 8 ) : 1416 – 1436 . Wang , Z . , Zhang , H . , Chen , J . , and Chen , H . ( 2023 ) . Measuring the novelty of scientific literature through contribution sentence analysis using deep learning and cloud model . Available at SSRN 4360535 . Wikimedia Foundation ( 2023 ) . Wikimedia downloads . [ Online ; accessed 01 - Feb - 2023 ] . 8