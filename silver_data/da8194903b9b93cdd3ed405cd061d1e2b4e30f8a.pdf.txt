Proceedings of NAACL - HLT 2013 , pages 697 – 702 , Atlanta , Georgia , 9 – 14 June 2013 . c (cid:13) 2013 Association for Computational Linguistics An Examination of Regret in Bullying Tweets Jun - Ming Xu , Benjamin Burchﬁel , Xiaojin Zhu Department of Computer Sciences University of Wisconsin - Madison Madison , WI 53706 , USA { xujm , burchfie , jerryzhu } @ cs . wisc . edu Amy Bellmore Department of Educational Psychology University of Wisconsin - Madison Madison , WI 53706 , USA abellmore @ wisc . edu Abstract Social media users who post bullying related tweets may later experience regret , potentially causing them to delete their posts . In this pa - per , we construct a corpus of bullying tweets and periodically check the existence of each tweet in order to infer if and when it becomes deleted . We then conduct exploratory analy - sis in order to isolate factors associated with deleted posts . Finally , we propose the con - struction of a regrettable posts predictor to warn users if a tweet might cause regret . 1 Introduction A large body of literature suggests that participants in bullying events , including victims , bullies , and witnesses , are likely to report psychological adjust - ment problems ( Jimerson , Swearer , and Espelage , 2010 ) . One potential source of therapy for these is - sues can be self - disclosure of the experience to an adult or friend ( Mishna and Alaggia , 2005 ) ; exist - ing research suggests that victims who seek advice and help from others report less maladjustment than victims who do not ( Shelley and Craig , 2010 ) . Disclosure of bullying experiences through so - cial media may be a particularly effective mecha - nism for participants seeking support because so - cial media has the potential to reach large audi - ences and because participants may feel less inhi - bition when sharing private information in an on - line setting ( Walther , 1996 ) . Furthermore , there is evidence that online communication stimulates self - disclosure , which leads to higher quality social rela - tionships and increased well - being ( Valkenburg and Peter , 2009 ) . Online disclosure may also present risks for those involved in bullying however , such as re - victimization , embarrassment , and social ostraciza - tion . Evidence exists that some individuals may re - act to these risks retroactively , by deleting their so - cial media posts ( Child et al . , 2011 ; Christoﬁdes , Muise , and Desmarais , 2009 ) . Several relevant mo - tives have been found to be associated with delet - ing posted information , including conﬂict manage - ment , safety , fear of retribution , impression manage - ment , and emotional regulation ( Child , Haridakis , and Petronio , 2012 ) . Our previous work ( Xu et al . , 2012 ) demonstrates that social media can be a valuable data source when studying bullying , and proposes a text categorization method to recognize social media posts describing bullying episodes , bullying traces . To better under - stand , and possibly prevent , user regret after posting bullying related tweets , we collect bullying traces using the same method and perform regular status checks to determine if and when tweets become in - accessible . While a tweet becoming inaccessible does not guarantee it has been deleted , we attempt to leverage http response codes to rule out other com - mon causes of inaccessibility . Speculating that re - gret may be a major cause of deletion , we ﬁrst con - duct exploratory analysis on this corpus and then re - port the results of an off - the - shelf regret predictor . 2 Data Collection We adopt the procedure used in ( Xu et al . , 2012 ) to obtain bullying traces ; each identiﬁed trace contains 697 at least one bullying related keyword and passes a bullying - or - not text classiﬁer . Our data was collected in realtime using the Twitter streaming API ; once a tweet is collected , we query its url ( https : / / twitter . com / USERID / status / TWEETID ) at regular intervals and infer its status from the resulting http response code . We interpret an HTTP 200 response as an indi - cation a tweet still exists and an HTTP 404 response , which indicates the tweet is unavailable , as indicat - ing deletion . A user changing their privacy settings can also result in an HTTP 403 response ; we do not consider this to be a deletion . Other response codes , which appear quite rarely , are treated as anomalies and ignored . All non HTTP 200 responses are re - tried twice to ensure they are not transient oddities . To determine when a tweet is deleted , we at - tempted to access each tweet at time points T i = 5 × 4 i minutes for i = 0 , 1 . . . 7 after the creation time . These roughly correspond to periods of 5 min - utes , 20 minutes , 1 . 5 hours , 6 hours , 1 day , 4 days , 2 weeks , and 2 months . While we assume that user deletion is the main cause of a tweet becoming un - available , other causes are possible such as the cen - sorship of illegal contents by Twitter ( Twitter , 2012 ) . Our sample data was collected from July 31 through October 31 , 2012 and contains 522 , 984 bul - lying traces . Because of intermittent network and computer issues , several multiple day data gaps ex - ist in the data . To combat this , we ﬁlter our data to include only tweets of unambiguous status . If any check within the 20480 minutes ( about two weeks ) interval returns an HTTP 404 code , the tweet is no longer accessible and we consider it deleted . If the 20480 minute or 81920 minute check returns an HTTP 200 response , that tweet is still accessible and we consider it surviving . The union of the surviving and deleted groups formed our cleaned dataset , con - taining 311 , 237 tweets in total . 3 Exploratory Data Analysis A user’s decision to delete a bullying trace may be the result of many factors which we would like to isolate and understand . In this section we will ex - amine several such possible factors . 3 . 1 Word Usage Our dataset contains 331 , 070 distinct words and we are interested in isolating those with a signiﬁcantly higher presence among either deleted or surviving tweets . We deﬁne the odds ratio of a word w r ( w ) = P ( w | deleted ) P ( w | surviving ) , where P ( w | deleted ) is the probability of word w occurring in a deleted tweet , and P ( w | surviving ) is the probability of w appearing in a surviving tweet . In order to ensure stability in the probability estima - tion , we only considered words appearing at least 50 times in either the surviving or deleted corpora . Following ( Bamman , OConnor , and Smith , 2012 ) , we qualitatively analyzed words with ex - treme values of r ( w ) , and found some interesting trends . There was a signiﬁcant tendency for “jok - ing” words to occur with r ( w ) < 0 . 5 ; examples in - clude “xd , ” “haha , ” and “hahaha . ” Joking words oc - cur less frequently in deleted tweets than surviving ones . On the other end of the spectrum , there were no joking words with r ( w ) > 2 . What we found instead were words such as “rip , ” “fat , ” “kill , ” and “suicide . ” While it is relatively clear that joking is less likely to occur in deleted tweets , there was less of a trend among words appearing more frequently in deleted tweets . 3 . 2 Surviving Time Let N be the total number of tweets in our cor - pus , and D ( T i ) be the number of tweets that were ﬁrst detected as deleted at minute T i after creation . Note that D ( T i ) is not cumulative over time : it in - cludes only deletions that occurred in the time inter - val ( T i − 1 , T i ] . Then we may deﬁne the deletion rate at time T i as R T ( T i ) = D ( T i ) N ( T i − T i − 1 ) . In other words , R T ( t ) is the fraction of tweets that are deleted during the one minute period ( t , t + 1 ) . We plot R T vs . t using logarithmic scales on both axes in Figure 1 and the result is a quite strong linear trend . Fitting the plot with a linear regression , we derive an inverse relationship between R T and t of the form R T ( t ) ∝ 1 / t . 698 5 minutes 1 . 5 hours 1 day 2 weeks 1E−7 1E−6 1E−5 1E−4 1E−3 t R T ( t ) Figure 1 : Deletion rate decays over time . This result makes sense ; the social effects of a par - ticular bullying tweet may decay over time , making regret less of a factor . Furthermore , the author may assume an older tweet has already been seen , render - ing deletion ineffective . Additionally , because the drop off in deletion rate is so extreme , we are able to safely exclude deletions occurring after two weeks from our ﬁltered dataset without introducing a sig - niﬁcant amount of noise . Finally , P ∞ t = 0 R T ( t ) gives the overall fraction of deletion , which in our case is around 4 % . 3 . 3 Location and Hour of Creations Some bullying traces contain location meta - data in the form of GPS coordinates or a user - created proﬁle string . We employed a reverse geocoding database ( http : / / www . datasciencetoolkit . org ) and a rule - based string matching method to map these tweets to their origins ( at the state level ; only for tweets within the USA ) . This also allowed us to convert creation timestamps from UTC to local time by mapping user location to timezone . Because many users don’t share their location , we were only able to successfully map 85 , 465 bullying traces to a US state s , and local hour of day h . Among these traces , 3 , 484 were deleted which translates to an overall deletion rate of about 4 % . Let N ( s , h ) be the count of bullying traces cre - ated in state s and hour h . Aggregating these counts temporally yields N S ( s ) = P h N ( s , h ) , while ag - gregating spatially produces N H ( h ) = P s N ( s , h ) . Similarly , we can deﬁne D ( s , h ) , D S ( s ) and D H ( h ) as the corresponding counts of deleted traces . We can now compute the deletion rate R H ( h ) = D H ( h ) N H ( h ) , and R S ( s ) = D S ( s ) N S ( s ) . The top row of Figure 2 shows N H ( h ) , D H ( h ) , and R H ( h ) . We ﬁnd that N H ( h ) and D H ( h ) peak in the evening , indicating social media users are gen - erally more active at that time . The peak of R H ( h ) appears at late night and , while there are multiple potential causes for this , we hypothesize that users may fail to fully evaluate the consequences of their posts when tired . The bottom row of Figure 2 shows N S ( s ) , D S ( S ) , and R S ( s ) . The plot of N S ( s ) shows that bullying traces are more likely to origi - nate in California , Texas or New York which is the result of a population effect . Importantly however , the deletion rate R S ( s ) is not affected by population bias and we see , as expected , that spatial differences in R S ( s ) are small . We performed χ 2 - test to see if a state’s deletion rate is signiﬁcantly different from the national average . We chose the signiﬁcance level at 0 . 05 and used Bonferroni correction for multiple testing . Only four states have signiﬁcantly differ - ent deletion rates from the average : Arizona ( 6 . 3 % , p = 5 . 9 × 10 − 5 ) , California ( 5 . 2 % , p = 2 . 7 × 10 − 7 ) , Maryland ( 1 . 9 % , p = 2 . 3 × 10 − 5 ) , and Oklahoma ( 7 . 1 % , p = 3 . 5 × 10 − 5 ) . 3 . 4 Author’s Role Participants in a bullying episode assume well - deﬁned roles which dramatically affect the view - point of the author describing the event . We trained a text classiﬁer to determine author role ( Xu et al . , 2012 ) , and used it to label each bullying trace in the cleaned corpus by author role : Accuser , Bully , Re - porter , Victim or Other . Table 1 shows that compared to tweets produced by bullies , victims create more bullying traces , pos - sibly due to an increased need for social support on the part of the victim . More importantly , P ( deleted | victim ) is higher than P ( deleted | bully ) , a statis - tically signiﬁcant difference in a two - proportion z - test . Possibly , victims are more sensitive to their au - dience’s reaction than bullies . 3 . 5 Teasing Many bullying traces are written jokingly . We built a text classiﬁer to identify teasing bullying traces ( Xu et al . , 2012 ) and applied it to the cleaned corpus . Table 2 shows that P ( deletion | Teasing ) is much lower than P ( deletion | Not Teasing ) and the differ - ence is statistically signiﬁcant in a two - proportion z - 699 N H ( h ) D H ( h ) R H ( h ) N S ( s ) D S ( s ) R S ( s ) Figure 2 : Counts and deletion rates of geo - tagged bullying traces . Deleted Total P ( deleted | Role ) Accuser 2541 50088 5 . 07 % Bully 1792 30123 5 . 95 % Reporter 11370 147164 7 . 73 % Victim 6497 83412 7 . 79 % Other 41 450 9 . 11 % Table 1 : Counts and deletion rate for different roles . Deleted Total P ( deleted | Teasing ? ) Yes 858 22876 3 . 75 % Not 21383 288361 7 . 42 % Table 2 : Counts and deletion rate for teasing or not . test . It seems plausible that authors are less likely to regret teasing posts because they are less controver - sial and have less potential to generate negative au - dience reactions . This also corroborates our ﬁndings in word usage that joking words are less frequent in deleted tweets . 4 Predicting Regrettable Tweets Once a bullying tweet is published and seen by oth - ers , the ensuing effects are often impossible to undo . Since ill - thought - out posts may cause unexpectedly negative consequences to an author’s reputation , re - lationship , and career ( Wang et al . , 2011 ) , it would be helpful if a system could warn users before a po - tentially regrettable tweet is posted . One straightfor - ward approach is to formulate the task as a binary text categorization problem . We use the cleaned dataset , in which each tweet is known to be surviving or deleted after 20480 min - utes ( about two weeks ) . Since this dataset contains 22 , 241 deleted tweets , we randomly sub - sampled the surviving tweets down to 22 , 241 to force our deleted and surviving datasets to be of equal size . Consequentially , the baseline accuracy of the clas - siﬁer is 0 . 5 . While this does make the problem ar - tiﬁcially easier , our initial goal was to test for the presence of a signal in the data . We then followed the preprocessing procedure in ( Xu et al . , 2012 ) , performing case - folding , anonymization , and tokenization , treating URLs , emoticons and hashtags specially . We also chose the unigrams + bigrams feature representation , only keeping tokens appearing at least 15 times in the cor - pus . We chose to employ a linear SVM implemented in LIBLINEAR ( Fan et al . , 2008 ) due to its efﬁ - ciency on this large sparse text categorization task and a 10 - fold cross validation was conducted to eval - 700 uate its performance . Within the ﬁrst fold , we use an inner 5 - fold cross validation on the training por - tion to tune the regularization parameter on the grid { 2 − 10 , 2 − 9 , . . . , 1 } ; the selected parameter is then ﬁxed for all the remaining folds . The resulting cross validation accuracy was 0 . 607 with a standard deviation of 0 . 012 . While it is statis - tically signiﬁcantly better than the random - guessing baseline accuracy of 0 . 5 with a p - value of 5 . 15 × 10 − 10 , this accuracy is nevertheless too low to be useful in a practical system . One possibility is that the tweet text contains very limited information for predicting inaccessibility ; a user’s decision to delete a tweet potentially depends on many other factors , such as the conversation context and the characteris - tics of the author and audience . In the spirit of exploring additional informative features for deletion prediction , we also used the teasing and author role classiﬁers in ( Xu et al . , 2012 ) , and appended the predicted teasing , and au - thor role labels to our feature vector . This aug - mented feature representation achieved a cross val - idation accuracy of 0 . 606 , with standard deviation 0 . 007 ; not statistically signiﬁcantly different from the text - only feature representation . While it seems that a signal does exist , leveraging it usefully in real world scenarios may prove challenging due to the highly - skewed nature of the data . 5 Discussion There have been several recent works examin - ing causes of deletion in social media . Wang et al . ( 2011 ) qualitatively investigated regret associ - ated with users’ posts on social networking sites and identiﬁed several possible causes of regret . Bamman et al . ( 2012 ) focused on censorship - related deletion of social media posts , identifying a set of sensitive terms related to message deletion through a statisti - cal analysis and spatial variation of deletion rate . Assuming that deletion in social media is indica - tive of regret , we studied regret in a bullying con - text by analyzing deletion trends in bullying re - lated tweets . Through our analysis , we were able to isolate several factors related to deletion , includ - ing word usage , surviving time , and author role . We used these factors to build a regret predictor which achieved statistically signiﬁcant results on this very noisy data . In the future , we plan to explore more factors to better understand deletion behavior and re - gret , including users’ recent posts , historical behav - ior , and other statistics related to their speciﬁc social network . Acknowledgments We thank Kwang - Sung Jun , Angie Calvin , and Charles Dyer for helpful discussions . This work is supported by National Science Foundation grants IIS - 1216758 and IIS - 1148012 . References Bamman , David , Brendan OConnor , and Noah Smith . 2012 . Censorship and deletion practices in chinese so - cial media . First Monday , 17 ( 3 - 5 ) . Child , Jeffrey T . , Paul M . Haridakis , and Sandra Petro - nio . 2012 . Blogging privacy rule orientations , privacy management , and content deletion practices : The vari - ability of online privacy management activity at differ - ent stages of social media use . Computers in Human Behavior , 28 ( 5 ) : 1859 – 1872 . Child , Jeffrey T , Sandra Petronio , Esther A Agyeman - Budu , and David A Westermann . 2011 . Blog scrub - bing : Exploring triggers that change privacy rules . Computers in Human Behavior , 27 ( 5 ) : 2017 – 2027 . Christoﬁdes , Emily , Amy Muise , and Serge Desmarais . 2009 . Information disclosure and control on facebook : are they two sides of the same coin or two different processes ? CyberPsychology & Behavior , 12 ( 3 ) : 341 – 345 . Fan , Rong - En , Kai - Wei Chang , Cho - Jui Hsieh , Xiang - Rui Wang , and Chih - Jen Lin . 2008 . Liblinear : A library for large linear classiﬁcation . The Journal of Machine Learning Research , 9 : 1871 – 1874 . Jimerson , Shane R . , Susan M . Swearer , and Dorothy L . Espelage . 2010 . Handbook of Bullying in Schools : An international perspective . Routledge / Taylor & Francis Group , New York , NY . Mishna , Faye and Ramona Alaggia . 2005 . Weighing the risks : A child’s decision to disclose peer victimization . Children & Schools , 27 ( 4 ) : 217 – 226 . Shelley , Danielle and Wendy M Craig . 2010 . Attri - butions and coping styles in reducing victimization . Canadian Journal of School Psychology , 25 ( 1 ) : 84 – 100 . Twitter . 2012 . The twitter rules . http : / / support . twitter . com / articles / 18311 - the - twitter - rules . 701 Valkenburg , Patti M and Jochen Peter . 2009 . Social consequences of the internet for adolescents a decade of research . Current Directions in Psychological Sci - ence , 18 ( 1 ) : 1 – 5 . Walther , Joseph B . 1996 . Computer - mediated commu - nication impersonal , interpersonal , and hyperpersonal interaction . Communication research , 23 ( 1 ) : 3 – 43 . Wang , Yang , Gregory Norcie , Saranga Komanduri , Alessandro Acquisti , Pedro Giovanni Leon , and Lor - rie Faith Cranor . 2011 . “I regretted the minute I pressed share” : a qualitative study of regrets on face - book . In Proceedings of the Seventh Symposium on Usable Privacy and Security , SOUPS ’11 , pages 10 : 1 – 10 : 16 . ACM . Xu , Jun - Ming , Kwang - Sung Jun , Xiaojin Zhu , and Amy Bellmore . 2012 . Learning from bullying traces in so - cial media . In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Tech - nologies , pages 656 – 666 , Montr´eal , Canada , June . As - sociation for Computational Linguistics . 702