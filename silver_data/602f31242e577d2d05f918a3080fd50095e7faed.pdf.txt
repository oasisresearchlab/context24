2003 IEEE Workshop on Applications of Signal Processing 10 Audio and Acoustics October 19 - 22 , 2003 . New Paltr . Ny FACTORS IN AUTOMATIC MUSICAL GENRE CLASSIFICATION OF AUDIO SIGNALS Tao Li Computer Science Department University of Rochester P . 0 Box 210226 Rochester , NY , 14627 - 0226 , USA taoli @ cs . rochester . edu ABSTRACT Automatic musical genre classification is an important tool for or - ganizing the large collections of music that are becoming available lo the average user . In addition it provides a structured way of evaluating musical content features that doesn’t require extensive user studies . This paper provides a detailed comparative analysis of various factors affecting automatic classification performance such as choice of features and classifiers . Using recent machine learning techniques such as Suppon Vector Machines we improve on previously published results using identical data collections and features . 1 . INTRODUCTION Improvements in audio compression together with increases in hard disk capacity and network bandwidth have made possible the cre - ation of large personal music collections . Digital music distribu - tion is already popular in peer - to - peer file sharing environments and the exchange of music files consumes the majority of internet handwidth . The recording industry although reluctantly is slowly embracing these new technologies while trying to retain copyright control . Once copyright protection can be enforced using tech - niques such as audio fingerprinting [ I ] it is very likely that all of recorded music will he available digitally . This scenario is very likely to happen in the near future . The problems and challenges of organizing these vast amounts of musical information for search - ing and browsing is the topic of the emerging research area of Mu - sic Information Retrieval ( MIR ) ( two good recent overviews of MIR are 12 , 31 ) . The automatic analysis of music stored in audio format is one of the important topics of MIR . The majority of such audio analy - sis techniques make use of numerical features that attempt to cap - ture information about musical content . Musical genres are cat - egorical labels created and used by humans in order to structure the vast universe of music . Although the boundaries that separate them are fuzzy and there is significant overlap , members of a par - ticular genre share characteristics related to the instrumentation , rhythmic smcture and pitch content of the music . Therefore auto - matic musical genre classification provides a good way to evaluate numerical features that attempt to capture musical content . Such features form the basis of any type of audio analysis and retrieval work . In addition automatic genre classification provides an au - tomatic way to stmcture and organize the large number of music files available digitally on the Web . An excellent recent overview of representing musical genre in di ~ ital music distribution is [ 4 ] George Tzanetakis Computer Science Department Carnegie Mellon University Forbes Avenue 5000 Pittsburgh , PA 15221 , USA gtzan @ cs . cmu . edu which covers manual annotation , automatic methods and usage - based methods such as collaborative filtering . In this paper , we provide comparisons of various factors that affect automatic musical genre classification performance . The majority of existing literature in automatic musical genre classifi - cation makes use of traditional statistical panern recognition clas - sifiers such as Gaussian Mixture Models and K - Nearest Neighbors 151 . We investigate the effect of using more recent powerful clas - sification methods such as Support Vector Machines [ 6 ] and report significant improvements in classification accuracy compared to results previously reponed in the literature using identical features and data collections . The obtained results are also comparable to the human genre classification results reported in [ 7 ] . Previous work in the area of automatic musical genre classifi - cation includes : features computed based on wavelet analysis and simple classifiers 181 , visual texture features of spectograms for classification 191 , and a specialized architecture called “Explicit lime Modeling Neural Networks” for genre discrimination [ IO ] . A comparison of audio features with features extracted from anal - ysis of cultural meta - data such as download usage patterns is pre - sented in [ I I ] . A more detailed study of automatic musical genre classification is presented in [ 12 ] . In this work , three different sets of features for representing timbral texture , rhythmic content and pitch content are proposed . For the experiments described in Sec - tion 4 the data collections and features of [ I21 are used and are briefly described in Section 2 . In all these papers , there is little comparative evaluation of different feature combinations and clas - sifiers which is the main goal of this paper . 2 . MUSIC CONTENT FEATURES 2 . 1 . Timbral Texture The features used to represent timbral texture are based on stan - dard features proposed for music - speech discrimination and speech recognition . They consist of a set of 4 features computed based on the Short lime Fourier Transfrom ( STFT ) magnitude spectrum such as the Spectral Centroid ( defined as the first moment of the magnitude spectrum ) as well as the first 5 Mel - Frequency Cepstral Coefficients ( MFCC ) [ I 31 . These features are computed using an analysis window of 20 milliseconds . Means and variances of the features over a larger texture window ( 1 second ) with a hop size of 20 milliseconds are computed resulting in a set of 18 features . An additional feature ( the percentage of low energy frames over the texture window ) results in a timbral texture feature vector of 19 dimensions . These features are described in more detail in [ 12 ] . 0 - 7803 - 7850 - 4 / 03 / $ 17 . 00 0 2003 IEEE 143 2W3 EEE Workshop on Applicauons of Signal Recessing to Audio and Acoustics October 19 - 22 , 2003 . New Paltr , NY BEAT HlSTCGRqM CALCULATION FLOW DIAGRAM Discrete Wavelet Transform Octave Frequency Bands . 1 Full Wave Rectification i : & Multiple Peak Picking : r r I Beat Histogram Figure 1 : Beat Histogram Calculation Diagram 2 . 2 . Rhythmic Content Fkatures The basis of representing rhythmic content is the calculation of a Beat Histogram ( BH ) that shows the distribution of various beat periodicities of the signal . ~ For example a piece with tempo 60 Beats - per - Minute ( BPM ) would exhibit BH peaks at 60 and I20 BPM . The BH is calculate & using periodicity detection in multiple octave channels that are computed using a Discrete Wavelet Trans - form Figure I shows a schematic diagram of the this calculation . In [ 12 ] , six numerical features that attempt to summarize the BH are computed and used for : classification . In additioain this pa - per , the use of the full BH for classification was explored . Figure 2 shows a BH for a piece of Rock music ( notice the peaks at 80 BPM ( main tempo ) and 160 BPM ) . 2 . 3 . Pitch Content Features Similarly , the pitch content features are based on accumulating the results of multiple pitch detection [ 141 in a Pitch Histogram ( PH ) . The histogram provides informations about the pitch class and pitch probability distribution across the file . ( pitch class refers to folding the pitch to the range of one octave - for example A4 = 440Hz and A5 = 880Hz map to the same pitch class A ) . The PH attempts to capture information such , as jazz pieces have on average more chord changes than pieces of country music . Five numerical fea - tures that summarize the PH are proposed in [ I21 and used for classification . In addition , in this paper , the use of the full PH for classification is explored . ' 3 . CLASSIFIERS 3 . 1 . Support Vector Machines Support vector machines ( SVMs ) [ 61 have shown superb perfor - mance at binary classification tasks and handle large dimensional feature vectors better than other classification methods . Basically , Figure 2 : Beat Histogram a Support Vector Machine aims at searching for a hyperplane that separates the positive data points and the negative data points with maximum margin . To extend SVMs for multi - class classification , we use pairwise comparison approaches and multi - class objec - tive functions approaches . In pairwise comparison , a classifier is trained for each possible pair of classes . For K classes , this results in ( IC - 1 ) IC / 2 binary classifiers . Given a new instance , the multi - class classification is then executed by evaluating all ( IC - l ) h7 / Z individual classifiers and assigning the instance to the class which gets the highest number of votes . The idea of multi - class objec - tive function is to directly modify the objeclive function of support vector machine ( SVM ) in such a way that it simultaneously allows the computation of a multi - class classifier . For pairwise compar - ison method , our SVM implementation is based on the LIBSVM [ IS ] . a library for support vector classification and regression . For multi - objective functions , our implementation is based on multi - category Proximal Support Vector Machines ( MPSVM ) [ 16 ] . For experiments involving SVMs , we test them with linear , polyno - mial and radius - based kernels and the results reported are the best among these trials . 3 . 2 . Linear Discriminant Analysis ( LDA ) Discriminant analysis approaches are well known to leam discrim - inative feature transformations in statistical pattern recognition lit - erature and has been successfully used in many classification tasks [ SI . The basic idea of LDA is to find a linear transformation that best discriminate among classes and the classification is then per - formed in the transformed space based on some metric such as Eu - clidean Distances etc . Fisher discriminant analysis finds discrim - inative feature transform as eigenvectors of matrix T = C ; ' Cs where 2 , is the intra - class covariance matrix and e , is the inter - class covariance matrix . Basically T captures both compactness of each class and separations between classes and hence eigenvectors corresponding to largest eigenvalues of T would constitute a dis - criminative feature transform . In our experiments . we use Fisher ' s Linear discriminant Analysis . ~ ~ 144 2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics October 19 - 22 . 2003 . New Paltz , NY . . . . . . _ _ . . . . . . . . . . . . . . . I I MPSVM LOA I . . . . . . , , ~ . - . - . - 2 . _ . . _ - _ _ _ _ . . LOA HUM I Figure 3 : Accuracy comparison of different features Figure 5 : Comparison with previously reported results for auto - matic and human genre classification Figure 4 Accuracy comparison of different methods 4 . EXPERIMENTAL RESULTS For the conducted experiments the following feature subsets and their combinations were used ( the numbers in parentheses indi - cate the dimensionality ) : RT ( 9 ) . MFCC ( 1 01 , Beat ( 6 BH - based ) , Pitch ( 5 PH - based ) , Full Beat ( 300 ) . Full Pitch ( 130 ) . Each genre was represented by 100 sound files resulting in IO * 100 = loo0 feature vectors . ( the genres were : classical , country , disco , hiphop , jazz , rock , blues , reggae , pop , heavy metal ) . The data collection was the same as the one used in [ IZ ] . The features were calculated using MARSYAS , a free software framework for audio analysis ( http : / / marsyas . sourceforge . net ) . Table I compares the classification accuracy of various subsets and their combinations using three classifiers : Pair - wise Support Vector Machines ( SVM ) , Multi - category Proximal Support Vec - tor Machine ( MPSVM ) and Linear Discriminant Analysis ( LDA ) . Figure 3 shows graphically some of the comparisons between dif - ferent subsets of features . Figure 4 compares different classifiers . These results were obtained using IO - fold cross - validation ( the la - beled data is split randomly into 90 % training data and 10 % testing data 100 times and the accuracy of each run was averaged ) . 5 . CONCLUSIONS AND FUTURE WORK From the experimental comparison it can be seen that the relative importance of feature subsets is ( in order of decreasing clasrifica - tion accuracy ) : FFT , MFCC , Pitch , and Beat . This result indicates that Beat features , which incidentally are the most time consuming to calculate . are not as important to classification as the other fea - ture sets . Another interesting result , is that using the Full Beat His - togram and Full Pitch Histogram doesn ' t seem to improve signif - icantly the classification accuracy . This implies that the published Beat and Pitch features of low dimensionality capture most of the classification information contained in the full histograms . The best classification result is given by Linear Discriminant Analysis on the full feature set ( FFT + MFCC + Pitch + Beat ) . For other feature combinations , there seem to be no consistent winners . Moreover , the accuracy results of the three methods do not differ by much . The results of this paper improve significantly the classifica - tion accuracy reported in 1121 . The numbers are directly compa - rable as the same data collection and feature set was used in both works . The best accuracy ( 71 % for the LDA classifier ) is sig - nificantly better than the ( 61 % ) reported in [ I21 for a Gaussian Mixture Model ( GMM ) classifiers with 5 components . In addi - tion our result is indirectly comparable to the 70 % human musi - cal genre classification accuracy reponed in [ 7 ] . Although direct comparisons of these results is not possible due to different data collections , it is clear that automatic performance is not far away from human performance . In addition the results of 171 indicate that genre classification is a hard problem with fuzzy boundaries not only for machines but also for humans . Figure 5 displays these results which indicate that more powerful machine learning classi - fiers can have significant impact in classification performance . . In the future , we are planning to investigate the performance of our classification methods to larger data collections with more genres . In addition to timbre , rhythm and pitch content , two other sources of information that could be useful are melody and singer voice . Although results from melodic analysis and singer iden - tification probably will not be very good they might still provide enough information for genre classification . Finally we are explor - ing hierarchical as well as real - time musical genre classification . 145 2003 IEEE Workshop an Applications of Signal Rocersinp to Audio and Acoustics October 19 - 22 . 2W3 . Neu , Paltz , NY Features \ Methods I SVM I MPSVM I LDA Full Beat Full Pitch I 28 . 3 ( 3 . 36 ) I 28 . 1 ( 4 . 75 ) I 29 . 0 ( 3 . 68 ) c Table 1 : Accuracy ( s1andarddeviation ) table of various methods on various feature sets . SVM denotes pai & ise SVM , Full Beat and Pitch are the full histograms and “other” refers to the 30 - vector feature set ( FFT + MFCC + BEAT + PITCH ) . 6 . REFERENCES [ I ] J . Haitsma and T . Kalker , “A Highly Rohust Audio Finger - printing System , ’’ in Pmc . Int . Conit on Music htfonnarion Retr - ievul ( ISMIR ) , Pyis , France , Oct . 2002 , pp . 107 - 1 15 . [ 2 ] J . Futrelle and S . 1 . pownie , “Interdisciplinary Communi - ties and Research Issues in Music Infomration Retrieval , ’’ in Pmc . In ! . CorlJ : on Music Infonvntion Retrieval ( ISMIRJ , Paris , France , Oct . 2002 , pp . 215 - 221 . 131 F . Pachet , “Content Management for Electronic Music Dis - tribution : The Real Issues : ’ Coetnzurticorions of the ACM , vol . 46 , no . 4 , Apr . 2003 . [ 4 ] J . J . Aucouturier and F . Pachet , ”Musical Genre : a Survey : ‘ Journal of New Music Research , vol . 32 , no . 1 , 2003 . [ Y ] H . Deshpande , R . Singh , and U . Nam , “Classification of Mu - sical Signals in the Visual Domain , ” in Proc . COST G - G Con $ on Digiral Audio Efects ( DAFXJ , Limerick . Ireland , Dec . 2001 . [ IO ] H . Soltau , T . Schultz , M . Westphal , and A . Waibel , “Rcog - nition of Music Types : ’ in Pmc . Int . Conf on Acoustics , Speech and Signal Piwcessing ( ICASSPJ , vol . 2 , May 1998 , [ I I ] B . Whitman and P . Smaragdis , “Combining Musical and Cul - tural Features for Intelligent Style Detection , ’’ in Proc . Im . Conj Music I ~ tfo ~ srorion Retrieval ( ISMIRJ . Paris , France , Oct . 2002 , pp . 47 - 52 . 1121 G . Tzanetakis and P . Cook , “Musical Genre Classification of Audio Signals : ’ IEEE Transactions on Speech and Audio Processing , vol . IO , no . 5 . July 2002 . pp . 1137 - 1140 . 151 K . Fukunag . ~ . I ~ itmdwrm io rtarr ~ riralparrcni rccopnriinri . 1131 S . DJvis and P . Slermcl ~ tcin , ”Expcrimenis in svll . ~ hle . hnscd rccoznition of continuous socech . ” IEEE Trmww ~ ion ~ on 2nd ed Nca York : Ac : & mic I’rc \ \ . 1990 . [ 6 ] V . N . Vapnik , Statistical Leoming Thheo , y . Wdey , New York , 1998 . I [ 7 ] D . Perrot and R . Gjeidigen , “Scanning the dial : An explo - ration of factors in identification of musical style , ” in Proc . Socier ) . forMusicPerceprionandCognition , 1999 . p . 88 , ( ab - stract ) . [ SI T . Lambmu , P . Kudumakis , R . Speller , M . Sandler . and A . Linney , “Classification of Audio Signals using Statisti - cal Features on Time’and Wavelet Transform Domains : ’ in Proc . Int . Cont on Acoustics , Speech and Signol Processing ( ICASSP ) , 1998 . ’ - . . Acoustics . Speech and Signal Processing , vol . 28 , pp . 357 - 366 , Aug . 1980 . [ I41 T . Tolonen and M . Karjalainen , “A Computationally Efficient Multipitch Analysis Model , ” IEEE Trans . on Speech and Au - dio Processing . vol . 8 , no . 6 , pp . 708 - 716 , Nov . 2000 . [ I51 C : C . Chang and C : J . Lin , LIBSVM : a / ibrary for support vector machines , 2001 , software available at http : / / www . csie . ntu . edu . tw / - cjlin / libsvm . [ I61 G . Fung and 0 . Mangasarian , “Proximal support vector ma - chine classifiers , ” in Knowledge Discowry and Datu Mining , 2001 , pp . 7746 . 146