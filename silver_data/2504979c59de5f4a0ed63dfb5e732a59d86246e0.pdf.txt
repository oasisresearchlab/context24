Jason C . Young Ahmer Arif Information School , School of Information , University of Washington University of Texas at Austin Seattle , Washington , USA Austin , Texas , USA It’s About Time : Atending to Temporality in Misinformation Interventions Tamar Wilner Kayo Mimizuka Ayesha Bhimdiwala School of Journalism and Media , School of Journalism and Media , School of Information , University of Texas at Austin University of Texas at Austin University of Texas at Austin Austin , Texas , USA Austin , Texas , USA Austin , Texas , USA ABSTRACT Recent studies in HCI have explored how we might reduce the spread of online misinformation by helping people learn how to evaluate information in more skillful ways . Unfortunately , it isn’t clear that such interventions have been meaningfully integrated into communities . To better understand why this is the case , this paper engages over thirty information professionals ( educators , librarians , and journalists ) who promote digital literacy in BIPOC and rural communities . Our participants describe a temporal mis - match , whereby digital literacy requires time - consuming processes that cannot be accelerated , but institutional and societal pressures demand speed . We also describe strategies that participants envis - aged to cope with this mismatch . This leads us to discuss how the HCI community can better engage with the temporal aspects of digital literacy work , with a view toward expanding the range of solutions we can design to address the misinformation crisis . CCS CONCEPTS • Human - centered computing → Empirical studies in HCI ; Empirical studies in collaborative and social computing . KEYWORDS misinformation , emotions , digital literacy , temporal experience , temporality , sociology of time ACM Reference Format : Tamar Wilner , Kayo Mimizuka , Ayesha Bhimdiwala , Jason C . Young , and Ah - mer Arif . 2023 . It’s About Time : Attending to Temporality in Misinformation Interventions . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( CHI ’23 ) , April 23 – 28 , 2023 , Hamburg , Germany . ACM , New York , NY , USA , 19 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3581068 1 INTRODUCTION There is a growing literature in HCI about designing interventions to reduce the spread of misinformation over social media . One Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 9421 - 5 / 23 / 04 . https : / / doi . org / 10 . 1145 / 3544548 . 3581068 strand of this research involves exploring the design of technolo - gies to promote digital literacy — i . e . equipping social media users with a strong foundation of attitudes , skills and practices to evalu - ate the information around them . Recent work includes designing , for example , lightweight nudges that encourage users to be more mindful of what they share [ 52 ] , tools for supporting refection on misinformation exposure [ 20 , 79 ] , and escape room games using augmented reality [ 35 , 88 ] . This design direction warrants further consideration as we learn more about the challenges surround - ing online misinformation . For example , recent work [ 110 , 116 ] highlights the need to better account for the social context of mis - information when designing digital literacy interventions . This work suggests that interventions against misinformation must not only reduce the supply of misleading content , but also the demand that drives social media users to accept and even seek it out in the frst place . To quote a workshop paper from CHI ‘21 , “Technical solutions that disregard the social structures that lead to the spread of misinformation . . . and provide information assessment without promoting digital literacy are not only limited , they can also be harmful by obfuscating the problem . ” [ 93 ] . In this paper , we extend this work of designing for digital literacy by exploring the limits of existing approaches with a heterogeneous set of actors that we’ve come to call digital literacy interventionists ( or just interventionists here for short ) . These interventionists come from a variety of institutions , including community organizations , public libraries and museums , K16 schools , local journalism orga - nizations , and nonprofts — yet they all share a common interest in using formal and informal education to address misinformation in their communities . Although they don’t necessarily see their job as confronting misinformation , they often intervene to pro - mote trust in public institutions and to teach people digital literacy skills because they care about them . To the best of our knowledge , HCI research has not rigorously engaged with the work of these interventionists in the context of misinformation . Rather , as we will discuss in the Background section , HCI has largely focused on testing solutions with direct users such as students and social me - dia users . This lack of emphasis on interventionists is unfortunate because these stakeholders often serve as important intermediaries between digital literacy solutions and their communities ( e . g . , via school curricula , webinars , library programming , etc . ) . Focusing more on these interventionists can help designers to create digital Wilner et al . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany literacy interventions in more creative and locally contextualized ways . To push HCI in this direction , this paper explores answers to the following question : What can we learn from digital literacy in - terventionists about how to expand the range of solutions that the CHI community can explore in addressing the misinformation crisis ? This question is meant to be generative in nature — our aim is not to analyze the experiences of these interventionists to identify generalizable commonalities or diferences across their practices . Rather , we are seeking to identify fresh design directions and ways to frame the problem of misinformation , with the hope that these new ideas might push forward similarly novel research agendas within HCI . This attempt to expand the horizon of possible inter - ventions is directly responsive to concerns expressed by misinfor - mation scholars , that existing solutions have neither been novel nor radical enough to address the ingenuity of many misinformation campaigns [ 39 , 120 ] . We seek answers to this question by analyzing qualitative data from a series of fve half - day workshops about designing digital literacy interventions to address misinformation . These workshops were part of an initial phase of a convergence research project [ 33 ] so they were intentionally designed to bring people with substan - tially diferent intellectual backgrounds together . The workshops were attended by over thirty information professionals , educators and activists who work in rural communities and Black , Indigenous , and People of Color ( BIPOC ) communities . We prioritized these populations because prior work suggests that misinformation — both online and ofine — has been disproportionately impacting such marginalized communities for decades , and yet , they are often not at the table with a voice when we design solutions [ 22 , 23 , 53 ] . Participants brainstormed new ideas , and critiqued and discussed existing literacy approaches within the context of their communi - ties . Much of what they had to say was connected to a temporal mismatch : where faster systems or actors put pressure on the slower , time - consuming processes needed to properly address misinfor - mation in their communities . We have organized our fndings to take a careful look at this mismatch . We begin by examining why interventionists think addressing misinformation often involves time - consuming processes that cannot be accelerated . We do this by describing how interventionists perceive the social and emotional aspects of misinformation — and the corresponding approaches that interventionists such as themselves must take to help these community members . We then consider some ways in which these approaches are challenged by the systematic imperative to scale up and speed up solutions to misinformation . We follow this by describing some strategies that interventionists discussed or cur - rently use to cope with this temporal mismatch . This leads us to discuss how efectively addressing misinformation necessitates a broader way of dealing with the temporal structures of social life . We consider what role technology might play in this , through shap - ing temporal infrastructures and shifting rhythms and routines . We conclude by noting the considerable challenges that this entails , while sketching out some connections to existing work in HCI that might provide productive paths forward . We believe that these paths point to exciting new research agendas at the intersection of HCI and misinformation studies , which have the potential to produce transformative new solutions to the ongoing threat that misinformation poses to society . 2 BACKGROUND 2 . 1 HCI and Digital Literacy In this paper we build on previous work in HCI and other felds , on the issue of misinformation . We use the term misinformation here to refer to unintentionally inaccurate information ( such as false rumors and gossip ) , as well as disinformation campaigns that are orchestrated to deceive and diminish trust in institutions such as journalism and science [ 50 ] . We have opted to use misinformation as an umbrella term because it is convenient and because it aligns with the lexicon of our workshop participants ( even though it fails to fully capture the complex and multifaceted nature of inaccurate information ) . A growing body of research attests to the HCI community’s interest in addressing the spread of online misinformation . One design direction that is being explored focuses on giving users the tools and skills to identify and correct misinformation . This work includes , for instance , examining how to encourage social media users to fag , flter and fact - check misinformation [ e . g . , 3 , 87 , 89 ] . While learning often constitutes a secondary or implicit dimension in such work , it is also becoming a more fundamental goal in some cases . For example , recent work has focused on helping social media users learn new skills by engaging in refection on misinformation exposure [ 52 ] , practicing mindful behaviors [ 20 ] , and playing educational games [ 4 , 18 , 98 ] . Notably , Chang et al . [ 18 ] suggest that teachers can play a crucial role in translating these misinformation interventions into real - world impact ; their preparation and buy - in can lead to deeper and more efective user engagement . This line of work points to a need for deeper connections be - tween HCI and the felds of digital , information , and media literacy . These felds have developed through diferent scholarly traditions , with scholars frequently promoting various hierarchies between them [ 86 ] . At the same time , these scholars increasingly share a common interest in addressing misinformation by teaching mem - bers of the public how to critically analyze information or content [ 13 ] . Here we will use the term digital literacy to refer to such ed - ucational eforts , and view digital literacy broadly as the abilities needed to efectively judge the accuracy of information and infor - mation sources . This term is useful in that it emphasizes the need for unique skills to tackle misinformation as a digitally mediated issue , and we understand crucial contributions from media and information literacy as falling within digital literacy’s purview . Research on digital literacy can inform the HCI community’s eforts to design more human - centered solutions to misinforma - tion . For example , recent digital literacy studies provide insights into the practices that help people to identify , resist believing , and resist spreading misinformation [ 38 , 41 , 98 ] . Similarly , research on new media habits [ 74 , 111 , 114 ] and refective self - examination [ 56 , 112 ] can help us conceptualize solutions that go beyond just fact - checking information . More broadly , digital literacy educa - tion’s commitments to making the operations of power visible , and grounding inquiry in historical contexts and social diference [ 24 , 48 ] can help the HCI community approach misinformation It’s About Time : Atending to Temporality in Misinformation Interventions from a more critical perspective and avoid reinforcing a problem - atic status quo . However , limitations remain in the ways that digital literacy education is applied to misinformation interventions — including a limiting focus on youth enrolled in formal educational spaces like K12 and college classes . This limitation is signifcant in light of growing calls to include information consumers of all ages [ 96 ] — especially as being older has been associated with viewing and shar - ing misinformation [ 36 , 37 ] . HCI interventions have the potential to expand this focus by extending to informal learning environments and diferent user populations . But this requires deeper engage - ment with community stakeholders who already have expertise in teaching communities about digital literacy . While there are some notable exceptions [ e . g . , 25 , 71 ] , few studies in HCI have en - gaged with the teachers , librarians and local journalists who try to build trust in public information and correct misinformation in their communities . Consequently , there remains much room for understanding what these interventionists do on the ground , and describing the needs and challenges they face , particularly from a design perspective . This paper makes contributions to address this gap while drawing on the perspectives of interventionists ( e . g . , librarians ) who often work with not just traditional students , but also older adults . 2 . 2 Temporal dimensions of misinformation One of the key contributions ofered by our workshop participants , as we will describe below , is the need to better account for time ( or the lack thereof ) when designing misinformation interventions . Time and busyness have , of course , been a topic or dimension in many studies of human - computer - interaction [ see e . g . , 51 , 57 , 66 , 72 , 95 , 113 , 117 ] . Lindley [ 66 ] has described how ‘time’ has been used in varied ways within the HCI literature and within modern Western culture , ranging from mechanical models of time ( i . e . ‘clock - time’ ) to phenomenological models of ‘lived time’ to the temporal ’scraps’ we fnd by exploiting gaps in our schedules ( i . e . ‘plastic time’ ) . More recently , Wiberg and Stolterman [ 117 ] conducted a systematic literature review and identifed a turn to temporality as a design material in the feld . One example of this is a recent focus on the development of slow technologies , which encourage long - term use at a slower pace [ 83 , 84 ] . Other designers have designed and assessed artifacts that encourage users to engage in acts of noticing and self - control by slowing down and adopting a temporal perspective [ 8 , 21 , 47 , 69 ] . In many ways , these design solutions seem to be naturally aligned with understandings of the role of time within misinformation re - search , and therefore of direct relevance to the design of misin - formation interventions . Time has been salient in misinformation research largely because of work in psychology . Psychologists have developed models of how human capabilities shape why we need more ( or less ) time for certain types of tasks . One infuential , and relevant , model is that of dual systems accounts of information processing [ 30 , 55 ] . These accounts maintain that humans engage in two separate types of information processing , depending on the task presented to them . By default , most of the time people rely on what is called System 1 , or ‘fast’ thinking , which is automatic , easy , and relies on our emotions and instincts for heuristics and CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany shortcuts [ 30 , 55 ] . Only when the situation calls for it do people switch to System 2 or ‘slow’ thinking , which is more energy - and time - intensive . System 2 thinking is more efortful , but also more likely to reach accurate conclusions and to incorporate conscious refection [ 30 , 55 ] . Within misinformation studies , research has ex - plicitly linked belief in misinformation to insufcient use of System 2 processing [ 91 , 92 ] . Recent work in misinformation and psychol - ogy has empirically shown that slowing down – through prompts to think about the accuracy of a headline , or open - ended questions asking about experiences with inaccurate information – does im - prove people’s discernment about true and false content [ 90 , 103 ] and reduce intention to share false content [ 32 ] . Scholars have also applied this dual systems account to larger sociotechnical systems [ 29 ] and used this account to explain why ‘slowing down’ can be difcult in modern societies . This work is useful in understanding how social changes have increased our collective susceptibility to misinformation . Much of this research views time as socially constructed , meaning that human rhythms and perceptions of time are shaped by social and economic conven - tions [ 115 ] . Rosa [ 99 , 100 ] , for instance , has noted that in capitalist economies whose central mode of allocation ( for wealth and money , status and recognition , etc . ) is competition , slowing down for indi - viduals and institutions inevitably entails sliding back in the social order . This escalatory logic has accelerated the pace of life and our exposure to massive amounts of information [ 7 ] . Levy [ 62 ] suggests that this “more - faster - better” society leaves people with limited temporal and attentional resources to evaluate information and contemplate important political choices . Moreover , these tempo - ral efects are felt unevenly across society , since underprivileged groups have less say in how they regulate their time budget [ 100 ] . This connects our chronic lack of time and the spread of misinfor - mation to issues of power . In keeping with these views , we have chosen not to adopt a pre - determined defnition of time in this study , but instead have inductively explored the ways in which our participants employ the term to describe their experiences with misinformation and digital literacy . This approach is consistent with the view that time is socially constructed [ 115 ] , and ensures that our design suggestions are deeply tied to the empirical realities of practitioners ( and how they experience time ) . It also helps us avoid technological determinism and foregrounds both the choices that people make in terms of how much time they spend with tech - nology , and the choices they can make to change that temporal relationship . HCI engagements with time have huge potential to intervene in this area by designing interactions that counter our real and perceived feelings of being pressed for time . This potential can be seen in research designing interactions for ‘slowing down’ in online settings . In this research , slowing down is used as a way to address misinformation [ 52 ] , promote self - control [ 67 ] , and more . Specif - cally addressing misinformation , such interventions have taken a number of forms including nudges to think about source credibility [ 9 ] and warnings that a social media post has been disputed by fact - checkers [ 58 ] . But while HCI studies have asked how altering timescales can afect people’s engagement with misinformation , such work has focused on technological interventions to afect end users . Such research commonly emphasizes interventions that oc - cur at the moment of encountering or sharing information online Wilner et al . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany [ 52 ] . Less common are explorations of such issues as they pertain to interventionists working " in real life " with communities . This paper aims to push this scholarship forward by exploring design opportunities with interventionists who promote digital literacy in their communities . Exploring how we might design re - sources for and with these interventionists can help us develop new interactions that connect ‘slowing down’ with people’s everyday lives , and better account for issues of digital equity , users migrating to alternative platforms , and more . We have analyzed the views of interventionists to better describe how temporal pressures ex - acerbate the impacts of misinformation , and undermine existing misinformation interventions . In making these arguments , we will move beyond individual , cognitive accounts of time limitations to consider how time pressures can be negotiated collectively , and refect on the importance of time - cognizant digital literacy inter - ventions for democratic society as a whole . This matters especially now , because the pressures of the COVID - 19 pandemic , the lat - est struggles against racial oppression , and worsening economic conditions make it all the more urgent to take time seriously . 3 METHODS 3 . 1 Data Collection This research is based on data collected from fve half - day work - shops held between November 2021 and April 2022 . The workshops were conducted remotely over Zoom ( www . zoom . us ; except Work - shop 2 , which we experimented with running in a hybrid format ) . The workshops brought together 36 digital literacy interventionists ( i . e . , K - 16 educators , community organizers , local journalists , and librarians ) to ( 1 ) identify gaps and usability concerns with existing educational materials designed to address misinformation ; and ( 2 ) produce design requirements for new interventions . We used work - shops because we wanted to invite multiple perspectives and bring them into conversation with one another to recognize opportunities and challenges across diferent contexts [ 85 , 101 ] . Our participants were recruited using a purposive sampling ap - proach . They were identifed through the professional networks of the broader project team and primarily came from the Southern part and West Coast of the United States . Participants were afliated with libraries , schools , journalism and community organizations that serve BIPOC and / or rural communities , with both kinds of communities represented in each workshop . The project focused on these communities because each is disproportionately targeted and impacted by misinformation ( e . g . [ 2 , 22 ] ) , and yet members of these communities are often underrepresented within the spaces dedicated to designing solutions to misinformation . We have as - signed participants descriptive codes based on their organizational afliations — E for educational institutions ( e . g . K16 schools ) , L for libraries and museums , and J for local journalism organizations , and nonprofts . More details on each workshop participant can also be found in Table 2 within the appendix . The number of participants also grew across the workshops through a snowball sampling process — i . e . , existing participants recommended new participants . At the close of each workshop , institutions and individuals received fnancial compensation as appropriate to support their participation . The workshops were facilitated by a mix of faculty , students , and staf members from two universities , one community college , and one community orga - nization in the United States . Each small discussion group of three to four participants had at least two members of the research team present to serve as a facilitator and note - taker . The workshops focused on diferent aspects of digital literacy ( see Table 1 ) . We designed the workshop activities to promote mu - tual learning — drawing on the idea that participants are experts of their context , while giving them the opportunity to share their lived experiences through diferent activities . For example , activities in - vited participants to write stories , brainstorm new ideas , critique existing designs , and have small - group discussions . Between work - shops , researchers summarized key takeaways and ideas . These key takeaways were used to plan subsequent workshops to ensure continuity of thinking . The ffth workshop specifcally functioned as a form of member check [ 10 ] : researchers synthesized fndings from the prior workshops and shared them back with the work - shop participants to get their reactions . This helped increase the co - ownership of insights and enhanced their trustworthiness [ 10 ] . Additional details on each workshop activity can be found in the appendix . These fve half - day workshops yielded qualitative data in the form of written notes from notetakers , design artifacts from partic - ipants ( e . g . , written stories and post - it notes ) , and video recordings of discussions that were transcribed through Rev ( http : / / rev . com ) . 3 . 2 Analysis We used a constructivist grounded approach to analyze our data [ 19 ] . Our approach is constructivist in that it focuses on the knowl - edge held by participants [ 68 ] and the way that meaning is embod - ied and constructed by the words and actions of participants [ 105 ] . It is a grounded approach in that it takes inspiration from grounded theory , being inductive and building insights directly from data rather than imposing pre - existing theories [ e . g . , 19 ] . Our analysis consisted of six steps . First , using the qualitative analysis software Dedoose ( http : / / dedoose . com ) , we had one author read each transcript and code on a paragraph - by - paragraph basis , creating codes that appeared to refect common trends in the data . Next , we discussed these codes as a research team to fnd agreement on the codes to employ , and frequently collapsed codes to agree on 17 second - level codes or categories . Examples of second - level codes included “learning takes time , ” “needing relationships , ” “po - larization , ” and “time to deal with emotions . ” Then we used this new codebook to code each transcript ( two authors per transcript ) and we discussed the evolution of our categories regularly to maintain agreement on their meaning . Next , we used the online collaboration platform Miro ( http : / / miro . com ) to conduct axial coding , breaking our categories into sub - categories to understand nuances in the data , and comparing across these sub - categories to form relation - ships . Next , we each wrote several memos to explain what we saw as the most important ideas that we identifed in this analysis . Fi - nally , we chose themes from among these draft fndings that we agreed told the most comprehensive and yet data - grounded story about what participants expressed . When making claims in the fndings , we adopted the following convention for addressing the prevalence of a trend in our data without resorting to over - quantifcation . We use the term ’several’ It’s About Time : Atending to Temporality in Misinformation Interventions CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Table 1 : Workshop overview Workshop Participant Topic Count Workshop 1 and 2 ( Nov 2021 ) 26 total ( 5 and Critical and data reasoning skills . Since these 21 ) were the frst workshops , we also focused on establishing rapport and group norms . Workshop 3 ( Jan 2022 ) 22 Skillfully dealing with the psychological and emotional dimensions of misinformation Workshop 4 ( March 2022 ) 16 Broader sociocultural dimensions of misinfor - mation . How misinformation and digital liter - acy intersects with institutional politics and ex - isting histories of suspicion Workshop 5 ( April 2022 ) 21 Synthesizing and refecting on what we learned together through our engagements . or ’some participants’ to refer to data from 3 - 9 participants ; ’many’ to refer to 10 - 17 ; and a majority to refer to 18 or more . These counts may be an under - estimate in some cases because collective behavior like nodding was not part of the data source . 3 . 3 Positionality Statement In this section , we refect on how we as a research team were po - sitioned to collect and interpret our data . We are sharing these refections to support both ourselves and our readers in under - standing the perspectives , strengths , and limitations of our work [ 44 , 64 ] . The paper’s authorship team has some signifcant overlap with the positions of our participants . For example , we are an in - terdisciplinary and racially diverse team of people who have done journalism , taught in rural environments , and conducted partici - patory research with rural and BIPOC communities on the social issues that emerge through engagement with new communication technologies . Between us we hold identities that have helped posi - tion us to make sense of what participants were saying . Moreover , our methodological approach helped ensure that our analysis bene - fted from multiple perspectives . For example , for research results to appear in the discussion they needed to be vetted by everyone on the team to reduce the possibility of narrow or one - sided inter - pretations . One source of potential bias that we have been able to notice is we are all middle - upper class individuals who are invested in higher education and learning . This has shaped how we perceive temporality and the idea of ‘slowing down’ . For example , we noticed feeling more interested in our data when our participants expressed the need for slowing down to make room for refective thinking , and noticed feeling some resistance when they highlighted that some interventions should be quick . We have confronted this bias by stepping back and refecting on the class politics of ‘slowing down’ before revisiting our data with more care . This involved grappling with questions like : Who gets the privilege of ‘slowing down’ ? How is ‘slow living’ rooted in sustainable and anti - work movements , and how can its aesthetics be co - opted by elite interests [ 80 , 94 ] ? It is important to note that our wider research team , including workshop facilitators , also participated in the design and planning discussions of this paper . This wider team consists of over twenty racially diverse individuals and includes both academics from dif - ferent disciplines ( e . g . education , psychology , HCI , information sciences ) and non - academic practitioners ( e . g . community organiz - ers , librarians , schoolteachers ) . Their involvement helped increase our overlap with the positions of our participants during data col - lection and gave us additional opportunities to assess the validity of our interpretations . 3 . 4 Limitations Our recruitment and workshop processes have some limitations that need to be understood to interpret the fndings more efec - tively . First , most of the workshop participants were practitioners from the Southern region and West Coast of the United States , bringing with them particular experiences relevant to those areas . Second , a limitation of using the workshop format was that par - ticipants’ views can be infuenced by social pressure , or may be overshadowed by others who were more vocal , and our data might disproportionately refect those active participants [ 78 ] . Third , the scale and complexity of the workshops resulted in occasional loss of audio data and virtual messages . We mitigated this by drawing on notes written by researchers where necessary , which risks rep - resenting participants’ views less accurately . Fourth , our data is primarily based on the accounts of interventionists and does not fully extend to the perspectives of the community members they serve . Our participants sometimes ofered their own views on how other people in their communities are impacted by misinformation and a lack of time , and we have shared some of these views to illuminate how interventionists understand their own context . But just as teachers can have misconceptions about student experiences , our participants can misunderstand the experiences of their com - munity members . In our future work , we plan to investigate the perspectives of recipients of misinformation interventions . Finally , we note that the research refected in this paper is from the frst phase of a larger and ongoing project , and as such it did not Wilner et al . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany delve deeply into teasing apart the important diferences between how rural and BIPOC interventionists experience misinformation or employ digital literacy solutions . The work instead focused pri - marily on similarities across the two groups , produced through their structural exclusion from solution spaces . While this occasionally resulted in interesting conversations that highlighted diferences between our participants - such as the diferent constraints expe - rienced by teachers and librarians - the resulting data does not allow us to speak confdently or with nuance about diferences between how interventionists from BIPOC or rural communities might choose to shape interventions against misinformation . Also , through our choice of participants , we feel more confdent that rural and BIPOC perspectives had more chance of being refected in our data - but because our participants also hold varied identities as librarians , educators , and journalists , it was usually not possible to disentangle which facet of professional identity may have moti - vated individual statements . The role of rural and BIPOC identity represents an opportunity for future work — one that we are excited to investigate more explicitly by engaging in participatory design with these groups in future stages of our project . 4 FINDINGS Our analysis reveals a fundamental mismatch between the amount of time that it takes to efectively address misinformation and the amount of time that communities have to spend building their digital literacy skills . In the following sections we describe this temporal mismatch in detail , and then describe its implications for designing efective interventions against misinformation . In the frst subsection , we examine our participants’ claims that efective responses to misinformation require refective thinking and trust - ing relationships , both of which require ample time to cultivate . The second subsection then describes the many structural barriers that prevent digital literacy interventionists from taking the time to cultivate those exact same skills and relationships that they feel are needed . It describes how this mismatch – between the time needed and time available to teach digital literacy – creates a time squeeze that undercuts existing digital literacy interventions . The fnal subsection describes temporal design strategies that might make these interventions more successful . This sets us up for fur - ther discussion of how the HCI community might more efectively design solutions to misinformation . 4 . 1 Addressing Misinformation Takes Time . . . A prevalent theme that we found in our analysis was that efective interventions against misinformation require individuals to engage in time - intensive activities . This theme was particularly salient while participants discussed the skills that they feel community members need to resist misinformation , and the corresponding approaches that educators such as themselves must take to help community members acquire those skills . Many participants ex - pressed that conscious critical reasoning skills are essential , in line with the focus of many existing digital literacy interventions . But they also highlighted how emotions and social relationships are important when we evaluate information . A key point they brought up at the end of several group discussions was that misinformation often taps into strong , frantic emotions , pressuring us to make snap judgments and seek out belonging , and thereby undermining the ability to engage in critical reasoning or deeper refection . As evidence of these dynamics , our participants described a range of ways in which social and media contexts pressure commu - nity members to fulfll social and emotional needs , and in turn to think and act quickly . For instance , after a writing activity on news and emotions in Workshop 3 , a college librarian ( L1 ) summarized how widespread feelings of loneliness in our society during the COVID - 19 pandemic , can " drive someone to seek out information” that makes them feel like they belong to a community . Several participants remarked that individuals who feel lonely are disin - centivized from refecting deeply on this information , since such refections could jeopardize these newfound feelings of belonging and imagined community . Similarly , many participants noted that widespread feelings of political polarization and the popularization of sensationalized news has encouraged anger - based responses to controversy . As L2 , who works at a rural , small - sized library , shared , “Looking at news stories and things that we read or things that people say to us , instead of taking pause , we might react frst , instead of thinking about it . We might rant , and if we’re ranting to somebody who agrees with us , then we’re supported in that rant . ” Once again , this demonstrates how feelings – in this case anger and belonging – minimize the likelihood that individuals will pause to refect on the truthfulness of information . Another emotion that was regularly mentioned was that of fear . For example , L3 , who works at a rural library serving patrons with " very mixed " political views , described how discussions of vacci - nation can activate fear and other negative emotions associated with past , negative experiences of the medical establishment such as being given wrong medical advice . They reported that if “we don’t acknowledge those kinds of emotional realities that people have actually faced , we can’t have the discussion about vaccines . ” In other words , there is no advantage to advocating for the exper - tise of doctors or science if we cannot acknowledge a person’s bad experiences with doctors or science . In this context , L3 suggested that an individual is more likely to attempt to fee the conversation – perhaps by frst lashing out emotionally as an escape mechanism – than to take the time to refect on the facts presented to them . L3 went on to generalize some of these arguments , maintain - ing that information ecosystems are so saturated with emotions that it is causing people to generally shut down . In a small - group discussion , they argued that , “We take in one piece of information and then we’re like , ‘I’m not going to hear anything more , I’m just emotional at the moment , ’ and it’s really hard to . . . get to that place where you can actually hear , and process through that heightened elevation of emotion and really absorb content . ” Five of our partic - ipants explicitly noted that these problems are exacerbated by a media environment that makes it very difcult to engage in slower , refective thinking . They described how current technologies make information feel “like a food” ( L4 , a librarian at a college where BIPOC students account for more than half of the population ) that’s “just so fast” ( J1 , a local journalist working at a branch of a national news organization ) . One strand of discussion focused on how these dynamics can create general feelings of anxiety about keeping up with fows o3f information , which become more acute if individuals do try to slow down to be more refective . Summing up this dy - namic in a wider share - out , an executive director at a rural library It’s About Time : Atending to Temporality in Misinformation Interventions ( L5 ) remarked , “Well , and if they’ve got that emotion . . . when they fnally get to some info , they’re not going to evaluate if it’s good or not , they’re just going to be like , ‘Thank God I found some - thing , moving on . ’” These observations suggest that this tendency , to quickly move on after absorbing new information , is not sim - ply a neutral characteristic of our media ecosystems . Instead , this tendency functions to make misinformation more difcult to com - bat by preventing individuals from taking the time to employ the refective and critical reasoning skills needed to do fact checking . In response to these dynamics , participants’ statements urged us to explore how digital literacy interventions might be used to transform individuals’ temporal orientation toward information . If misinformation thrives best when we are only willing to engage quickly with information , then from our perspective it makes sense that interventions should encourage individuals to slow down their engagements with their information environments . However , get - ting people to slow down their thinking requires time , in several ways indicated by participants’ statements . First , a majority of our participants expressed that it takes a great deal of time for digital literacy interventionists to establish trusting relationships with community members . Several partic - ipants argued that a trusting relationship can be vital for them in the struggle to get community members to even consider re - fecting more deeply on their information sources . They explained that this is because individuals are often already used to how they get their information . Their habitual sources are often people or platforms that they spend a great deal of time with , from their Twitter feeds and favorite news shows to their friends and family . One teacher who specialized in media literacy education ( E1 ) , for instance , lamented that it was incredibly difcult to talk to a student about misinformation that had originated in the media and then been reinforced through family discussions . They pointed out that it takes an immense amount of trust to get students to critically refect on information that their family considers truth . Further - more , our participants recognized that refecting on one’s beliefs or habits in this way is likely to produce feelings of vulnerability within individuals . For a person to admit that they could be wrong requires that they put themselves in a vulnerable position . As a teen librarian who works in a semi - rural area ( L6 ) explained , “Maybe they are afraid they look stupid . Or they don’t ft in with their peers if they don’t go with the same beliefs . ” One point brought up in wider discussions was that community members often need to feel that they are in a safe space surrounded by trusted individuals to open themselves up to this vulnerability . Several participants described time - intensive techniques for establishing these feelings of trust with others , including active listening . L7 , a rural librarian , argued that sharing information with patrons also requires “taking the time to listen to them because sometimes all they want to do is just talk and make sure their voice is heard . ” In one breakout room discussion , participant J2 , a journalist and the founder of a nonproft news organization which focuses on community journal - ism , connected this approach to their work in journalism , saying that they are convinced that a key to engagement with audiences is “deep listening with the intent of identifying needs and problems . . . active , ongoing listening , like a teacher would in a classroom . ” Par - ticipant E2 , a high school teacher who works with with signifcant number of BIPOC students , agreed with J2 , and shared that trust CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany requires taking the time to establish two - way vulnerability and openness with their students . They said , “I try to teach them in a way that works for them , which requires a lot of listening . I put myself out there and show who I am , and kids just want you to like them . ” These techniques , in their estimation , can begin to open learners , from K12 students to library patrons , to the possibility of refecting more deeply on their information sources . Second , our participants said time is needed for individuals to learn the skills that they need to more deeply think about and refect on their emotional attachments to and relationships with in - formation . Many participants noted that emotion - and relationship - oriented digital literacy skills may take more time to learn and apply than existing practices such as fact - checking . This is because such skills require a deliberate mode of thinking , refection , and lis - tening . They acknowledged that it can take even more time to help individuals employ these skills in their everyday lives . In discussing techniques and resources necessary for combating misinformation in Workshop 4 , Participant L3 observed , “In a real conversation it takes a little while . . . to build responses , to build change . . . [ and ] to process that [ emotion ] . ” Several participants described the need to help individuals unpack their emotional attachments to informa - tion , a process that involves acknowledging , naming , and refecting on emotions . These interventionists described how they helped in - dividuals to step back from information , to consider and name their emotions . Participant E2 , for instance , suggested how youth and adults alike can beneft from questions about their emotions . They suggested asking questions like , “What emotion are you feeling right now ? Are you sad ? Are you angry ? ” Several participants noted that through such refection , people can learn how the creators of misinformation manipulate them emotionally . Another participant , L3 , described a complementary technique – repacking emotions – whereby learners consider where emotions are coming from to enable more efective questions about how those emotions provoke automatic conclusions . Third , a majority of participants said they need time to design the teaching materials used to help learners acquire these emo - tional skills . According to these interventionists , this is because this approach to digital literacy is quite diferent from traditional approaches used in schools and libraries ; it requires the creation of new activities , exercises , and other learning tools . Participants described how this would require not only their own time , but also time to train other interventionists to use the materials that they have created . Due to the complexity of dealing with emotions , efec - tive teaching also requires a great deal of practice , participants said . As L6 argued , “When you’re faced with [ other people’s ] emotions . . . it’s really hard to get back to those points that were made in all those webinars . So in some ways I think we need practice , and [ currently ] we can’t really practice until the thing happens . ” Participants also discussed the importance of taking time to acknowledge and pro - cess their own emotions , which can be triggered by interactions with the community members that they serve . When brainstorming ideas on better educational materials for the emotional dimensions of media literacy in Workshop 3 , L6 highlighted the need to con - sider not only the emotional labor of their patrons , but also the need to understand “how much doing that [ emotional ] exercise would really take you out of even the academic mindset , because it would just so hit you like personally . ” L6’s remark suggests that Wilner et al . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany efective digital approaches require signifcant time not only while engaged in active teaching , but also before and after that teaching occurs . This raises an important question for digital literacy interven - tionists – do they have the time they need to invest in these slow solutions ? 4 . 2 . . . But We Don’t Have Any Time to Spare Unfortunately , the answer to this question is currently ‘no’ — nearly all of our participants said they did not feel that interventionists or community members had the time necessary to change their tempo - ral relationship to information . Participants’ desires to promote new forms of digital literacy were often accompanied by frustration over how a lack of time was preventing them from actualizing this vision . They described their struggle with an ever - increasing amount of tasks , and a feeling that there was never enough time to slow down . Many participants talked about how this has created pressure to compress digital literacy interventions into sessions that are as short as possible . Comparing this with the need to slow down de - scribed in the last section , we would describe the resulting paradox as a temporal mismatch . This section describes some of the factors that contribute to this pervasive mismatch for interventionists . First , several participants described how institutional policies at their workplace privilege fast and quick outcomes , often colliding with eforts to bring slower practices into the teaching of digital literacy . Concerns about both scarcity of funding and the need to demonstrate success were discussed in all of our workshops , along with how these pressures undermined digital literacy eforts . For instance , several participants expressed that they felt managers and funders did not see the value of work around emotional engagement and social involvement , and as a result , these more time - consuming educational activities were dismissed because their impact could not be easily and quickly measured . When participants’ breakout discussion in Workshop 5 touched upon the topic of what insti - tutional supports could help bolster digital literacy education , J2 expressed frustration over how they are expected to quantify the outcomes of their work to attract funding . They said : “ ( Higher managers and authorities say ) ‘We need all the data to show us that you are fxing [ the problem ] , but we’re not actually going to give you the resources you need to do what you really need to do , ’ which is build the relationships of trust . . . It’s like , ‘well , no , we want you to just do it quickly . And then if not good luck to you’ . ” ( J2 ) Stepping back , we note that many of the institutional dynamics identifed by our participants are consistent with modern shifts in our global capitalist economy , toward a form of neoliberalism defned by privatization , an intensifcation of competition over scarce public funding , and accountability [ 49 , 109 ] . Mitchell [ 73 ] argues that many of these values have fltered into educational institutions via an emphasis on achieving excellence , which is often ( quantitatively ) measured through testing to standards . We also observed that these sorts of resource constraints , and the frustration that accompanies them , were expressed by several par - ticipants who work for institutions reliant on public funding . These participants explained how institutional policy decisions rooted in economic concerns often produce such time pressures , since they are based on the feasibility of achieving quick and publicly visible results which are cost efcient . Participants described institutional conditions including funding cuts , staf shortages , and fear of an - gering the voting public . These conditions increase the amount of work interventionists must do on a daily basis , participants said , contributing to a general sense of exhaustion . They described how there was little room left in their busy lives to devote to extra digital literacy eforts . For example , when discussing resource sharing and collaboration among interventionists , participant E3 ( a history and media literacy teacher at a high school ) expressed that such collab - oration is frustratingly difcult because they are overwhelmed by the amount of work they have to accomplish every day : “Once that lesson’s over , I got 150 kids coming in to - morrow who’s going to need some new stuf . And I have to grade the other stuf they just did . And so it is con - stantly moving . So the more that we can not increase our teacher’s workload the better . . . if it’s something that I have to come and contribute to during the school year , forget about it , ain’t going to happen . ” ( E3 ) Moreover , even if interventionists could fnd time to do this work , political economic conditions make these digital literacy activities riskier . For example , four participants reported that they are disin - centivized from engaging in activities that do not clearly lie within the ofcially defned scope of their job , since these activities could invite further public scrutiny that might endanger funding . For example , E2 remarked that , “I just don’t want to get fred because angry parents are upset about me indoctrinating their children about medical choices that I don’t have any control over . ” In other words , these institutional priorities and constraints highlight how wider social and economic arrangements can add to a sense of time squeeze , by reducing the emotional and temporal resources that interventionists can employ to spend more time on digital literacy . Second , many interventionists described how the community members that they serve are also often too busy to take time out of their days to engage in digital literacy eforts . Comments on this topic pointed to how community members often barely have time to juggle their daily tasks , including jobs , taking care of children , schoolwork , household chores , and commuting , to name a few . It was broadly acknowledged by participants across all fve work - shops that while they might see digital literacy as vital , it is not realistic to expect most community members to view it as a priority . L4 said that the majority of students who visit their library “are like , ‘I mean , I’ll do it , but man , I got a lot of other stuf to do already . ” Similarly , L8 , a teen services coordinator at a rural library , said , “I mean , who on a Thursday night wants to go to the library and learn about media literacy ? ” This highlights that teaching people digital literacy can be frustrating , or even demotivating when digital liter - acy interventions are not valued . E3 described how opportunities to learn digital literacy are often “truncated” to just “a day or a weekend or something . . . [ when ] we all know that the problem is much bigger than that , ” and continued , “That is a frustration . That is a frustration for sure . ” It’s About Time : Atending to Temporality in Misinformation Interventions Importantly , many participants emphasized that these impacts are often felt most acutely by community members who are already marginalized in other ways . For example , some of our participants who work in rural communities noted that individuals there already have even less time to participate in educational opportunities , including digital literacy , because of the structural barriers they have to overcome in their lives . These barriers can take many forms , including difcult working conditions , poor Internet access , a lack of mobility , and more . Recalling a teenage library patron who was heavily reliant on public transportation , L6 said , “I know that’s a barrier for them when they are waiting to participate in things , but they don’t have the support to get there . Sometimes they leave events early because they need to catch a bus . . . they don’t really get to stay the whole time and build that network with the other teens that are at the event . ” Finally , some participants discussed how emerging technologies and practices further fuel these temporal issues . This discussion focused on how the rapid pace of technological advances makes it increasingly difcult for both interventionists and learners to iden - tify , seek , and secure the skills they need to successfully navigate an ever - changing media environment . They described a pressure to constantly update their knowledge to keep up with emerging technologies ( e . g . , new social media platforms , algorithms , bots , deep fakes ) and the social practices and issues that arise through their use . Based on their teaching experiences , three participants noted that although some skills are transferable from one platform to another , exercises and other teaching materials nevertheless need to be overhauled so that they are contextualized to newer information technologies . This can lead interventionists to feeling overwhelmed , as described by participant E3 during a breakout discussion on how to improve existing digital literacy materials : “Two years ago , we didn’t know what TikTok was . . . we might not know what the next thing is . . . it’s too fast moving . . . . We haven’t even [ learned ] how to handle misinformation on YouTube . Right ? So now we’re going to go with TikTok , which is just YouTube on steroids , really . I’m feeling a little like , ‘Oh my God ! ’” ( E3 ) Expanding on this topic , at least two participants brought up how they are forced to constantly refect on whether or not it is worth dedicating precious time to learning about technologies that may soon go obsolete . Participant L1 illustrated this dilemma by saying , “So much of what we ask people to adapt is too ‘fash in the pan . ’” Unfortunately , the lack of time being experienced by intervention - ists is forcing them to make decisions not only about teaching specifc technologies , but also about whether to engage with the topic of digital literacy at all . Taken together , these fndings highlight how a lack of tempo - ral resources undercuts digital literacy eforts , thereby working against eforts to mitigate the spread and impact of misinformation . This , in turn , suggests that one approach for tackling the problem of misinformation might be to design tools and experiences that address the lack of time experienced by interventionists and com - munity members alike . We turn to these possible solutions in the next section . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany 4 . 3 Strategies for Coping with a Temporal Mismatch During workshop design activities , participants critiqued existing digital literacy solutions , discussed how to adapt them to their local context , and brainstormed ideas they would like to execute with each other . In our analysis of these data , we identifed four salient strategies that could be employed to address the time squeeze described above . These strategies include : ( 1 ) keeping it quick , ( 2 ) choosing when to engage , ( 3 ) shifting from giving to making time , and ( 4 ) building upon existing resources . Combined , these strategies could be used to support both interventionists as they look for more time for teaching digital literacy skills , and also community members as they look for more time to learn . We argue that these strategies provide a roadmap for how HCI researchers can design misinformation solutions that account for the pervasive temporal mismatches described by our participants . 4 . 3 . 1 Keeping it quick . The frst , and perhaps most straightforward , strategy proposed by participants was to ‘keep it quick’ – i . e . , to design digital literacy interventions to be short so as not to take up much time . For example , at least six participants brought up ideas like creating short and eye - catching text messages , designing memes to make truths go viral , and implementing quick search activities to make correcting misinformation a fast and convenient endeavor . While brainstorming efective ways to have audiences engage with factual information on social media platforms , J3 , a re - porter for a nonpartisan local media organization , argued , " making the information digestible for a certain platform is really impor - tant . . . for example , making [ Instagram ] stories with a couple of sentences and allow people to click really fast . " Several participants suggested these endeavors could then be embedded throughout existing spaces or programming with which community members engage , such that they are regularly exposed to digital literacy re - sources without needing to take a lot of time out of their days or put in a lot of efort . As L8 phrased it , “it would be interesting to make small enough bites for people just to be able to chew on , to learn about all that [ digital literacy ] stuf . ” Their phrasing is particularly apropos for our examination of time , since it is important that these small ‘bites’ are nonetheless substantial enough that learners will continue to ‘chew on’ them over time . 4 . 3 . 2 Choosing when to engage . Another strategy is to encour - age interventionists to be more deliberate about when and how to engage with community members . This strategy was particu - larly salient for participants when discussing emotionally - charged disagreements that they have had with community members . For example , during a breakout discussion in Workshop 4 about social and cultural barriers that may make digital literacy education more difcult to implement , L6 shared an unpleasant experience of deal - ing with an angry patron who came to their library to argue about masks being unhealthy : “I don’t even have the time to build a connection with this person . For me , it’s contextual : there are some people that I think we can approach with those hard topics and discover how to do that through those relationships . Then there are some [ where ] I’m not the right person Wilner et al . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany and this [ library ] is probably not the right place for this [ argument / conversation ] . ” ( L6 ) Participant L6’s vignette illustrates the importance of making inten - tional choices about where and when to try to confront misinfor - mation . Several participants suggested that they can save both time and emotional energy if they are able to recognize situations in which their attempts at an educational intervention will not change the minds or habits of others . To put it another way , avoiding these types of confrontations may allow them to conserve their time for future interventions that may be more efective . Of course , making these choices skillfully is not always straightforward ( and , we note , this skill itself requires time to learn ! ) . Several participants noted that they would like tools to support them in making these choices . They also indicated that they would like tools that help them to minimize negative impacts in situations where they choose not to intervene . A communication studies and news librarian serving a diverse student population ( L9 ) , for instance , argued that librari - ans and teachers need additional tools for helping to de - escalate confict because “I know we’re not tasked with getting in long , drawn out conversations regardless of points of view with people . ” In other words , these tools can help them to at least reduce the likelihood of community members creating harm with unchecked misinformation . 4 . 3 . 3 Shifing from Giving to Making Time . A third strategy that came up during brainstorming was about incentives to encourage community members to place digital literacy higher on their to - do lists . One cluster of ideas to do this involved extrinsic forms of motivation , such as by paying people to ‘give’ their time to engage in digital literacy training . For example , two participants shared approaches such as giving gift cards , cash stipends , and free meals to encourage community members to participate in educational interventions about misinformation . In other suggestions , participants looked for ways to harness in - trinsic forms of motivation . One strand of ideas focused on aligning digital literacy interventions with the existing to - do lists of com - munity members , to encourage those individuals to ‘make’ time for learning digital literacy skills . For example , E4 drew on their experience as a rural community organizer to talk about how they attach interventions to the daily routines of community members . They shared , “When I need people to take a technology survey or a speed test , I go to where they have time . So , I spend my time at the laundromats . That’s where you meet people that have to be waiting on the dryer , just like everybody else . ” L6 noted the importance of designing library services that naturally ft into the normal rhythms of patrons’ daily lives . L6 explained , “It has to be convenient to them : the time , is it on their way home from something that they are normally doing . . . is it going to be on bus routes or things like that ? ” These quotes highlight how interventionists can understand their communities’ experiences with time and try to meet people where they are . We see this strategy as pointing to the need to design digital literacy for the needs and routines of diferent communities . We also note that the strategy demonstrates the value of taking a bottom - up approach to piecing together the diferent needs of the community members before designing solutions for them . In other words , it directs our attention to take a user - centered approach in tailoring digital literacy , which takes time because we need to understand contextual resources enabled within each community . 4 . 3 . 4 Building Upon Existing Resources . Finally , all of our partici - pants expressed interest in collaborating and in leveraging existing resources to cope with their lack of time . Throughout our work - shops participants exchanged resources like Mike Caulfeld’s SIFT method [ 14 ] , Ryan Dowd’s toolkit for solving confict with empathy [ 28 ] , and more . Building on the power of sharing resources , a group of teachers suggested the creation of a software system inspired by recipe apps , which they named Tasty Education . Tasty Education , according to our participants , would provide educational materials to confront misinformation in ways that support reuse of digital literacy resources in diferent contexts . As one of the teachers ( E2 ) explained , “I want to create a place where educators can go to access lots of resources for teaching about bad information . This should include resources for diferent age groups and subjects . ” An important point made by several participants was that they need support to better ft sharing and collaborating practices into their busy routines . Furthermore , they noted that adapting existing educational materials can be a time - intensive activity , and is not always straightforward . While there are plenty of existing resources , participants argued that they often fail to meet the information needs of practitioners ( e . g . , the resources lack explanation of how many students an activity is for , what materials are required , or what were the outcomes in the original context ) . According to two participants , this is further exacerbated by not having enough time for collaborating and sharing resources with others . For instance , during a breakout discussion about supporting collaboration and resource sharing , E1 explained the time famine they faced in sharing their lesson materials : “It is important to have a space for collaboration , but also so many teachers do not have the time to post stuf [ on an online forum ] . When I was working in the schools , I was coming up with all this stuf [ lesson materials ] , and maybe if there had been a place that made it really easy for me to post something . . . I was not doing it because I was busy all day every day . . . ” ( E1 ) We interpret the above quote by E1 to mean that they are motivated to share their educational resources with other educators , but re - quire more support and sense of a community working on similar lessons . Similarly , other participants expressed a desire to reuse materials that have proven successful in other contexts , but emphasized that adapting those materials to their own libraries or classrooms takes time . This highlights the need for designing tools that support adaptive work in digital literacy . These tools should draw on the existing expertise of the practitioners who are already working with community members . Additionally , we would argue that this strategy demonstrates the need to align adaptive work with existing HCI eforts , such as design after design [ 97 ] , remixing from scratch [ 42 ] , and reusable learning objects [ 11 ] . With the temporal mismatch in mind , this section shares four strategies for coping with the time squeeze in designing educa - tional interventions for misinformation . Some of the strategies are CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany It’s About Time : Atending to Temporality in Misinformation Interventions straightforward : participants wanted to keep digital literacy inter - ventions quick , incentivize members such as paying them for their time , and manage time by choosing when to engage with commu - nity members . However , our participants went further and thought of creative strategies . They included making time and building upon existing resources . Individually , our participants have been doing digital literacy work in their own spaces . Nonetheless , they have also highlighted the need to collaborate with other practitioners and leverage local and contextual knowledge and practices from one space and tailor them for other spaces . 5 DISCUSSION Our empirical fndings have highlighted a temporal mismatch — the gap between the time required for digital literacy to develop , and the time available to community members and practitioners . Designing interventions that help communities with this temporal mismatch is important because as scholars like danah boyd have persuasively argued , addressing misinformation requires more than verifying facts , “It’s going to require a cultural change about how we make sense of information , whom we trust , and how we understand our own role in grappling with information” [ 26 ] . Our participants repeatedly highlighted how bringing about a cultural change such as boyd describes will require emotional and social relationships that are difcult to cultivate and manage when there is a lack of time . While it is neither possible nor desirable to generalize from the particularities of our participants’ experiences , participants’ sentiments do inspire us to propose fresh design directions that fulfll boyd’s call for cultural change . The lack of time available for addressing misinformation emo - tionally and socially matters to our participants , because they see people in their communities turning to misinformation online partly to seek out emotional and social fulfllment . These insights are widely confrmed within the literature on the political economy of social media platforms , which describes how sites like Facebook are designed to tap into the emotions of users to subtly infuence them for commercial purposes [ 7 , 70 ] . Platforms may arguably at - tempt to minimize the amount of time their users spend refecting on their decisions . But as the results show , successful digital liter - acy solutions must empower individuals to manage their emotions sufciently to make better decisions . This type of refection takes time on the part of both interventionists and those learning the digital literacy skills . Unfortunately the two most cited approaches to combating misinformation are policy actions and technology solutions that tend to focus on narrow epistemic issues , and omit discussions of emotion altogether [ 60 ] . Aligning with our partici - pants’ views , scholars have found that these common solutions can actually increase polarization by giving oxygen to feelings that one is combating an enemy [ e . g . , 12 , 31 , 77 , 120 ] . Building on this view , we suggest that the HCI community needs to do our best to put resources in the hands of on - the - ground interventionists to help them increase the civic capacity of local in - person communities and undercut the emotional economy driv - ing misinformation . That is , we need to support interventionists in the work of building the long - term social infrastructure [ 61 ] — such as routines and processes — that help them work with com - munities to address misinformation . We’d suggest that the work of interventionists is an important and necessary complement to more technologically - focused eforts to address misinformation . While all sorts of practitioners lack sufcient time to do their jobs in the way they’d like , and community members lack time for all sorts of activities , the mismatch our participants described in digital literacy feels particularly poignant because digital literacy work can be understood as care work [ 65 , 106 ] . In this work , interven - tionists help community members care for themselves emotionally , not only through resisting misinformation but through processing the emotions that misinformation stirs up . This work involves in - terventionists building the social infrastructure that can allow for the facilitation of care , including interventionists’ ability to care for themselves as they carry out digital literacy work [ 61 , 106 ] . As Semaan [ 106 ] describes , it’s not just having infrastructure that’s important — the act of making infrastructure ( i . e . infrastructuring ) can become a site for challenging important societal norms . Here we argue for such infrastructuring to take a particular form : the confrontation and shaping of temporal infrastructure , in order to meet the challenge of limited time frames for digital literacy work . Designers , too , can play an important role in this infrastructur - ing work alongside interventionists . As designers think creatively about how to shape such work given the time constraints that both interventionists and community members face , our participants’ comments and suggestions lead to the idea of two timescales for this care work . On the one hand , we might make more progress if we focus on providing care for the community in pockets of time that are shorter than normal , with ‘normal’ here being the con - ventional rhythms that we inherit from our social and economic conventions ( e . g the nine - to - fve work rhythm or the temporal rhythms of formal higher education ) . On the other hand — or in addition — perhaps we need to focus on a longer form of care work that pushes back on wider social norms , thus enabling the ’slowing down’ that our participants say is a necessary part of addressing misinformation . 5 . 1 Designing for Shorter Timescales : Laundromat Engagements During their brainstorming , participants highlighted the impor - tance of designing for everyday environments where they can con - nect with community members and take advantage of the smaller , idle moments in people’s schedules , such as around their commutes , in hallway conversations , and even in laundromats . Participants noted that attending to time is particularly important when dealing with marginalized groups , such as BIPOC and rural communities . Such groups face even more time restrictions , compared with those who are more privileged , and thus fnding these ’scraps’ in people’s schedules becomes even more important . We were intrigued by participants’ ideas because we did not think of hallways or laundromats as places where community members would have time to learn about misinformation or digital literacy . However , our participants explained that these ‘in - between’ spaces aford a certain kind of engagement . Meeting people at laundromats , for instance , can turn a routine mundane activity into something more meaningful . Interactions in these spaces also , by their nature , have to be more lightweight . This can help engage community members who might otherwise balk at the idea of spending their CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany time on literacy around misinformation , and can free them up to disengage if the topic starts to feel too emotionally burdensome . In efect , spaces like the laundromat serve as a metaphor for a certain kind of interaction and design opportunity . Such engagements are decidedly diferent from technological " keep it quick " initiatives previously ofered by HCI scholars , in that here we focus on in - person engagements that carry advantages through their emotional and social dimensions . While these engagements are short on an in - person time scale - say fve to 60 minutes - these are actually quite long interactions compared with online nudges [ e . g . , 9 ] . We can also think of short time - scale interactions as instances of “everyday design , ” which addresses seemingly mundane actions in collective spaces [ 27 ] . This is another orienting framework we can use to start the cultivation of social circumstances from which new alternatives can grow . When we bring our attention to everyday environments like the laundromat , we begin to see the potential for addressing misinformation that lies in the small pockets of time in people’s ordinary lives . We can draw on HCI research that aims for users to interact in lightweight ways to support interventionists on these shorter timescales [ e . g . , 34 , 45 , 118 ] . We also see certain afnities , for example , between this direction and research on sup - porting civic engagement in everyday politics [ 16 , 43 , 59 ] , refection through short , playful experiences [ e . g . , 54 , 75 , 76 ] , as well as design approaches like assets - based design and participatory design that emphasize community development and local capacities [ e . g . , 46 ] . This type of work can and should be more explicitly connected to misinformation studies , to understand how it might be used to undercut the emotional economy of misinformation . Another way to think about designing for shorter timescales is that while direct engagement between interventionists and commu - nity members may be brief , the community members may continue to refect over a longer period , considering the ideas from the inter - vention and gradually integrating techniques into their information consumption . As participant L8 said , interventionists might pro - vide " bites for people just to be able to chew on . " To facilitate this , interventions might draw on emotionally resonate symbols , im - agery , or even memes to make certain ideas or practices ‘sticky’ [ 1 ] . One could similarly imagine an intervention , such as a game , that challenges a community member to employ an easy digital literacy skill throughout their day , and then later prompts them to refect on how this practice shaped their relationship to information over time . Refecting on the limits of this design direction , we can note that it risks reinforcing a culture of busyness . For example , we can imagine how designing technologies to exploit even the little pock - ets of time could add to a sense of acceleration by increasing the legitimate claims being made on our time budgets . And yet , design - ing resources to help digital literacy unfold on shorter timescales is important for building inclusion . For instance , meeting people where they are can help include people from social classes that have less say in how they regulate their time budget . This is in keeping with Mike Caulfeld’s observation that it is essential to craft digital literacy “for mortals , ” where less can be more for both busy practitioners and community members [ 15 ] . However , it is important to recognize that designing for shorter timescales cannot be the whole solution by itself , which leads us to discussing our second design direction . Wilner et al . 5 . 2 Designing for Longer Timescales : Digital Sabbath Our participants argued that not all approaches to addressing mis - information in their communities are equally ‘speedable’ , meaning that not all interventions will ft temporally within the in - between spaces discussed in the last section . They suggested , for example , that if individuals are to develop their own insights into their in - formation habits , then they need to occasionally be able to step outside of the ‘normal’ rhythm of their media habits and refect on those habits or try out new practices . However , unlike with the solutions presented in the last section , our participants generally ( and understandably ) found it harder to identify approaches that might produce such time within the busy lives of the community members that they serve . This , though , presents an opportunity for the HCI community to creatively draw on existing work to help digital literacy interventionists tackle this problem . Specifcally , the design challenge asks us to create interventions that ( 1 ) help people carve out and use longer periods of time for contemplation and ex - perimentation , but ( 2 ) that also remain approachable and accessible . It also asks us to consider how we might work with interventionists to build socio - technical systems that support diferent temporal experiences , and thus caring for others . There are existing lines of work in the HCI literature that could help sketch out important design directions . For example , HCI researchers have designed ambient displays to support users in greater self - awareness and refection [ 102 , 108 ] . One can imagine adapting such work to give users opportunities to refect on their mood before and after engaging with their social media feed . We can also look to slow technologies that are designed to provoke longer - term interactions and to provide experiences more than solv - ing an immediate need [ 40 , 81 ] . A notable example is Odom’s work on the photobox [ 82 , 84 ] which illustrates how such technologies can provoke users to become more mindful about how they share and consume photographs . Such work could be extended to support digital literacy eforts around the sharing and consumption of news . More broadly , we can see synergies between this goal of slowing down and refecting on information habits with research that fo - cuses on supporting technology minimization and non - use [ e . g . , 5 , 6 , 17 , 104 ] . Drawing on Young [ 120 ] , we can note that the eforts we propose to support temporal agency and refexivity might not directly engage misinformation at all , but could instead be lateral to it . One useful metaphor here might be the notion of ‘digital sab - bath , ’ which originally derives from the religious practice within Judaism 1 to take a day of from daily labor and consumption [ 107 ] . In the context of digital literacy , taking a sabbath would suggest that people occasionally temper their information consumption , thereby creating sanctuaries in time in which our engagement with media technology is slower , and can become more considered [ 62 , 63 ] . Just as a rabbi helps facilitate the experience of the sabbath for a congregation , so the care work of our interventionists can help people to encounter and learn from their digital sabbaths . And following Semaan’s [ 106 ] conceptualization of care work , we can even imagine the efects of these interventions rippling outward , 1 Exodus 20 : 8 - 11 CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany It’s About Time : Atending to Temporality in Misinformation Interventions from the immediate community to society as a whole . If commu - nity members begin to reshape their relationship with information and time , this may then afect the way they then talk about these concepts with their friends , family , and associates . Again , we can see this idea of Sabbath as a metaphor and in - spiration for designing certain kinds of interactions . Designing to support community members in this way can point us to ambient interactions that might unfold over a long period of time , such as a day , but would not necessarily require them to directly invest their energy into an intense activity . Instead , caring solutions could support them in cultivating a state of mindfulness about how their information environment is afecting their mood . Similarly , the idea of Sabbath suggests designing for occasional engagement ( such as once a month ) to help community members step back and bring balance to their day - to - day news and information consumption habits . We can also draw inspiration from the deeply communal nature of Sabbath to explore avenues of social and emotional ful - fllment in these refective engagements . This could involve , for example , designing a tool that helps community members work with interventionists to explore alternative ways of reading news , ones that aford more emotional peer - support and opportunities to practice ‘slow’ thinking . As with our short , laundromat - style engagements , we think the idea of a digital sabbath is particularly useful for the rural and BIPOC communities that our participants work with . This design direction can push back on the structural conditions of misinfor - mation by recovering what Levy [ 62 ] calls “endangered practices” : taking the time to think , refect , listen , and cultivate empathy and trust within communities . When people are pressed for time by conditions such as long commutes or multiple jobs , refection and contemplation likely becomes even more endangered . It thus be - comes even more important for interventionists to work with these communities to create the caring infrastructure for practices such as the digital sabbath . We recognize that these directions , which we ofer as starting points , pose important challenges . How can we cultivate the deeply personal connections necessary for such care work with commu - nities that are already deeply suspicious of academics ? And how can these design ideas be scaled ? What role can policy and aca - demic funders play in supporting misinformation research that engages with the phenomenon only indirectly , especially in light of the political economy of academic funding ? These questions don’t bear easy answers , but given what we have learned from our participants about misinformation in their communities and the temporal aspects of their digital literacy work , they are well worth examining . 6 CONCLUSION In this study , we sampled the views of information professionals ( educators , librarians , and journalists ) who address misinformation and promote digital literacy in rural and BIPOC communities . We did this to answer the following question : what can we learn from such digital literacy interventionists about how to expand the range of solutions that the CHI community can explore in addressing the misinformation crisis ? Our answer in this paper is that our col - lective ability to address misinformation in socially - situated and long - term ways is shaped by broader temporal structures that are often invisible . Rich and challenging possibilities for HCI might lie in community - engaged projects that augment or contend these existing structures to nurture the circumstances that can repair our information environment . This approach challenges misinforma - tion researchers to focus our attention on not just digital spaces , but also the mundane moments in our everyday environments . Doing so can help us look beyond large - scale content verifcation and fnd new , unexpected , and otherwise overlooked interaction possibili - ties for addressing misinformation that lie within the sedimented social processes of ordinary life . Embracing these possibilities may help us to address not just misinformation , but also to expand the social resilience [ 119 ] and temporal agency of the communities with whom our lives are intertwined . ACKNOWLEDGMENTS This research was supported by National Science Foundation Grant 2137519 . We would like to thank our broader research project team , including students , community researchers , staf , and faculty from across the Black Brilliance Research Project , Seattle Central Col - lege , University of Texas at Austin , and University of Washington . We are especially grateful to all the information professionals who participated in our workshops , including professionals from : AARP Washington , Asotin County Library , Burlington Public Library , Dal - las Free Press , Fort Worth Report , KISA Public Radio , KUOW Public Radio , Microsoft , North Olympic Library System , North Seattle College , Pacifc Science Center , Seattle Central College , Seattle Pub - lic Schools , Smithville Public Library , Southerly , Teachers for an Informed Public , Texas Tribune , Unidad Media Group , University of Texas at Austin , University of Washington Libraries , Whatcom County Library System , World Changers Media International Foun - dation and Active Centralized Empowerment , Yakima Community Foundation , and Yakima Valley Libraries ( and the many other par - ticipants who chose to remain anonymous ) . Finally , we also wish to thank David Levy and Jennifer Turns , as well our anonymous reviewers , for their thoughtful feedback on earlier drafts . REFERENCES [ 1 ] Sara Ahmed . 2013 . The Cultural Politics of Emotion . Routledge . [ 2 ] Donald J . Alcendor . 2021 . Targeting COVID vaccine hesitancy in rural commu - nities in Tennessee : Implications for extending the COVID - 19 pandemic in the South . Vaccines 9 , 11 ( 2021 ) , 1279 . https : / / doi . org / 10 . 3390 / vaccines9111279 [ 3 ] Jennifer Allen , Cameron Martel , and David G . Rand . 2022 . Birds of a feather don’t fact - check each other : Partisanship and the evaluation of news in Twitter’s Birdwatch crowdsourced fact - checking program . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 245 , 19 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3502040 [ 4 ] Melisa Basol , Jon Roozenbeek , and Sander van der Linden . 2020 . Good news about bad news : Gamifed inoculation boosts confdence and cognitive immunity against fake news . Journal of Cognition 3 , 1 ( 2020 ) , 1 – 9 . https : / / doi . org / 10 . 5334 / joc . 91 [ 5 ] Eric P . S . Baumer , Phil Adams , Vera D . Khovanskaya , Tony C . Liao , Madeline E . Smith , Victoria Schwanda Sosik , and Kaiton Williams . 2013 . Limiting , leaving , and ( re ) lapsing : An exploration of Facebook non - use practices and experiences . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Paris , France ) ( CHI ’13 ) . Association for Computing Machinery , New York , NY , USA , 3257 – 3266 . https : / / doi . org / 10 . 1145 / 2470654 . 2466446 [ 6 ] Eric P . S . Baumer and M . Six Silberman . 2011 . When the implication is not to design ( technology ) . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Vancouver , BC , Canada ) ( CHI ’11 ) . Association for Computing Machinery , New York , NY , USA , 2271 – 2274 . https : / / doi . org / 10 . 1145 / 1978942 . 1979275 CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany [ 7 ] W . Lance Bennett and Steven Livingston . 2020 . The Disinformation Age : Politics , Technology , and Disruptive Communication in the United States . Cambridge University Press . https : / / doi . org / 10 . 1017 / 9781108914628 [ 8 ] Marit Bentvelzen , Paweł W Woźniak , Pia S . F . Herbes , Evropi Stefanidi , and Jasmin Niess . 2022 . Revisiting refection in HCI : Four design resources for technologies that support refection . Proceedings of the ACM on Interactive , Mobile , Wearable and Ubiquitous Technologies 6 , 1 ( 2022 ) , 1 – 27 . https : / / doi . org / 10 . 1145 / 3517233 [ 9 ] Md Momen Bhuiyan , Michael Horning , Sang Won Lee , and Tanushree Mitra . 2021 . NudgeCred : Supporting news credibility assessment on social media through nudges . In Proceedings of the ACM on Human - Computer Interaction , Vol . 5 . Association for Computing Machinery , New York , NY , USA , Article 427 , 30 pages . https : / / doi . org / 10 . 1145 / 3479571 [ 10 ] Linda Birt , Suzanne Scott , Debbie Cavers , Christine Campbell , and Fiona Walter . 2016 . Member checking : A tool to enhance trustworthiness or merely a nod to validation ? Qualitative Health Research 26 , 13 ( 2016 ) , 1802 – 1811 . https : / / doi . org / 10 . 1177 / 1049732316654870 [ 11 ] Tom Boyle . 2003 . Design principles for authoring dynamic , reusable learning objects . Australasian Journal of Educational Technology 19 , 1 ( 2003 ) , 46 – 58 . https : / / doi . org / 10 . 14742 / ajet . 1690 [ 12 ] Jack Bratich . 2020 . Civil society must be defended : Misinformation , moral panics , and wars of restoration . Communication , Culture and Critique 13 , 3 ( Mar 2020 ) , 311 – 332 . https : / / doi . org / 10 . 1093 / ccc / tcz041 [ 13 ] Natasha Casey and Spencer Brayton . 2018 . Media and information literacy in a higher education environment : An overview and case study . In Handbook of research on media literacy in higher education environments . IGI Global , 60 – 76 . https : / / doi . org / 10 . 4018 / 978 - 1 - 5225 - 4059 - 5 . ch004 [ 14 ] Mike Caulfeld . 2019 . SIFT ( The four moves ) . https : / / hapgood . us / 2019 / 06 / 19 / sift - the - four - moves / [ 15 ] Mike Caulfeld . 2021 . Information literacy for mortals . Project Information Literacy Provocation Series 1 , 5 ( 2021 ) , 1 – 9 . https : / / projectinfolit . org / pubs / provocation - series / essays / information - literacy - for - mortals . html [ 16 ] Silvia Cazacu , Nicolai Brodersen Hansen , and Ben Schouten . 2020 . Empow - erment approaches in digital civics . In 32nd Australian Conference on Human - Computer Interaction ( Sydney , NSW , Australia ) ( OzCHI ’20 ) . Association for Computing Machinery , New York , NY , USA , 692 – 699 . https : / / doi . org / 10 . 1145 / 3441000 . 3441069 [ 17 ] Marta E . Cecchinato , John Rooksby , Alexis Hiniker , Sean Munson , Kai Lukof , Luigina Ciolf , Anja Thieme , and Daniel Harrison . 2019 . Designing for digital wellbeing : A research & practice agenda . In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland UK ) ( CHI EA ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 8 . https : / / doi . org / 10 . 1145 / 3290607 . 3298998 [ 18 ] Yoo Kyung Chang , Ioana Literat , Charlotte Price , Joseph I Eisman , Jonathan Gardner , Amy Chapman , and Azsaneé Truss . 2020 . News literacy education in a polarized political climate : How games can teach youth to spot misinformation . The Harvard Kennedy School ( HKS ) Misinformation Review 1 , 4 ( 2020 ) . https : / / doi . org / 10 . 37016 / mr - 2020 - 020 [ 19 ] Kathy Charmaz . 2014 . Constructing Grounded Theory . SAGE . [ 20 ] Guangyu Chen , Paolo Ciuccarelli , and Sara Colombo . 2022 . VisualBubble : Exploring how refection - oriented user experiences afect users’ awareness of their exposure to misinformation on social media . In CHI Conference on Human Factors in Computing Systems Extended Abstracts ( New Orleans , LA , USA ) ( CHI EA ’22 ) . Association for Computing Machinery , New York , NY , USA , 1 – 7 . https : / / doi . org / 10 . 1145 / 3491101 . 3519615 [ 21 ] Justin Cheng , Akshay Bapat , Gregory Thomas , Kevin Tse , Nikhil Nawathe , Jeremy Crockett , and Gilly Leshed . 2011 . GoSlow : Designing for slowness , refection and solitude . In CHI ’11 Extended Abstracts on Human Factors in Computing Systems ( Vancouver , BC , Canada ) ( CHI EA ’11 ) . Association for Computing Machinery , New York , NY , USA , 429 – 438 . https : / / doi . org / 10 . 1145 / 1979742 . 1979622 [ 22 ] Brandi Collins - Dexter . 2020 . Canaries in the coal mine : COVID - 19 misinformation and black communities . Technical Report . Cambridge , MA , USA . https : / / doi . org / 10 . 37016 / TASC - 2020 - 01 [ 23 ] Jeanette Covington . 2010 . Crime and Racial Constructions : Cultural Misinforma - tion about African Americans in Media and Academia . Lexington Books . [ 24 ] Dawn H . Currie and Deirdre M . Kelly . 2022 . Pop Culture and Power : Teaching Media Literacy for Social Justice . University of Toronto Press . [ 25 ] Dharma Dailey and Kate Starbird . 2017 . Social media seamsters : Stitching platforms & audiences into local crisis infrastructure . In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing ( Portland , Oregon , USA ) ( CSCW ’17 ) . Association for Computing Machinery , New York , NY , USA , 1277 – 1289 . https : / / doi . org / 10 . 1145 / 2998181 . 2998290 [ 26 ] danah boyd . 2017 . Did media literacy backfre ? Retrieved Sept 14 , 2022 from https : / / points . datasociety . net / did - media - literacy - backfre - 7418c084d88d [ 27 ] Audrey Desjardins and Ron Wakkary . 2013 . Manifestations of everyday design : Guiding goals and motivations . In Proceedings of the 9th ACM Conference on Creativity & Cognition ( Sydney , Australia ) ( C & C ’13 ) . Association for Computing Wilner et al . Machinery , New York , NY , USA , 253 – 262 . https : / / doi . org / 10 . 1145 / 2466627 . 2466643 [ 28 ] Ryan J . Dowd . 2018 . The librarian’s guide to homelessness : Advice for managers and leaders . Retrieved Sept 14 , 2022 from https : / / americanlibrariesmagazine . org / 2018 / 06 / 01 / librarians - guide - homelessness [ 29 ] Martin J . Eppler and Jeanne Mengis . 2004 . The concept of information overload : A review of literature from organization science , accounting , marketing , MIS , and related disciplines . The Information Society 20 , 5 ( 2004 ) , 325 – 344 . https : / / doi . org / 10 . 1080 / 01972240490507974 [ 30 ] Jonathan St . B . T . Evans . 2012 . Dual - Process Theories of Deductive Reasoning : Facts and Fallacies . Oxford University Press New York . 115 – 133 pages . https : / / doi . org / 10 . 1093 / oxfordhb / 9780199734689 . 013 . 0008 [ 31 ] Johan Farkas and Jannick Schou . 2018 . Fake news as a foating signifer : Hege - mony , antagonism and the politics of falsehood . Javnost - The Public 25 , 3 ( 2018 ) , 298 – 314 . https : / / doi . org / 10 . 1080 / 13183222 . 2018 . 1463047 [ 32 ] Lisa K . Fazio . 2020 . Pausing to consider why a headline is true or false can help reduce the sharing of false news . The Harvard Kennedy School ( HKS ) Misinformation Review 1 , 2 ( 2020 ) . https : / / doi . org / 10 . 37016 / mr - 2020 - 009 [ 33 ] National Science Foundation . 2022 . Learn about convergence research . Re - trieved September 14 , 2022 from https : / / beta . nsf . gov / funding / learn / research - types / learn - about - convergence - research [ 34 ] Sarah E . Fox , Samantha Shorey , Franchesca Spektor , and Daniela K . Rosner . 2020 . Crafting everyday resistance through lightweight design . In Proceedings of the 2020 ACM Designing Interactive Systems Conference ( Eindhoven , Netherlands ) ( DIS ’20 ) . Association for Computing Machinery , New York , NY , USA , 101 – 113 . https : / / doi . org / 10 . 1145 / 3357236 . 3395571 [ 35 ] Lindsay Grace and Bob Hone . 2019 . Factitious : Large scale computer game to fght fake news and improve news literacy . In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland UK ) ( CHI EA ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 8 . https : / / doi . org / 10 . 1145 / 3290607 . 3299046 [ 36 ] Nir Grinberg , Kenneth Joseph , Lisa Friedland , Briony Swire - Thompson , and David Lazer . 2019 . Fake news on Twitter during the 2016 U . S . presidential election . Science 363 , 6425 ( 2019 ) , 374 – 378 . https : / / doi . org / 10 . 1126 / science . aau2706 [ 37 ] Andrew Guess , Jonathan Nagler , and Joshua Tucker . 2019 . Less than you think : Prevalence and predictors of fake news dissemination on Facebook . Science Advances 5 , 1 ( 2019 ) , eaau4586 . https : / / doi . org / 10 . 1126 / sciadv . aau4586 [ 38 ] Andrew M . Guess , Michael Lerner , Benjamin Lyons , Jacob M . Montgomery , Brendan Nyhan , Jason Reifer , and Neelanjan Sircar . 2020 . A digital media literacy intervention increases discernment between mainstream and false news in the United States and India . Proceedings of the National Academy of Sciences 117 , 27 ( 2020 ) , 15536 – 15545 . https : / / doi . org / 10 . 1073 / pnas . 1920498117 [ 39 ] Joshua Habgood - Coote . 2019 . Stop talking about fake news ! Inquiry 62 , 9 - 10 ( 2019 ) , 1033 – 1065 . https : / / doi . org / 10 . 1080 / 0020174X . 2018 . 1508363 [ 40 ] Lars Hallnäs and Johan Redström . 2001 . Slow technology – designing for refection . Personal Ubiquitous Computing 5 , 3 ( Jan 2001 ) , 201 – 212 . https : / / doi . org / 10 . 1007 / PL00000019 [ 41 ] Michael Hameleers . 2022 . Separating truth from lies : Comparing the efects of news media literacy interventions and fact - checkers in response to political nisinformation in the US and Netherlands . Information , Communication & Society 25 , 1 ( 2022 ) , 110 – 126 . https : / / doi . org / 10 . 1080 / 1369118X . 2020 . 1764603 [ 42 ] Yue Han and Jefrey V . Nickerson . 2013 . Remix networks in scratch . In Workshop on Information in Networks . https : / / ssrn . com / abstract = 2326304 [ 43 ] Mike Harding , Bran Knowles , Nigel Davies , and Mark Rouncefeld . 2015 . HCI , civic engagement & trust . In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems ( Seoul , Republic of Korea ) ( CHI ’15 ) . Association for Computing Machinery , New York , NY , USA , 2833 – 2842 . https : / / doi . org / 10 . 1145 / 2702123 . 2702255 [ 44 ] Sandra G . Harding . 2004 . The Feminist Standpoint Theory Reader : Intellectual and Political Controversies . Psychology Press . [ 45 ] Richard H . R . Harper . 2010 . Texture : Human Expression in the Age of Communi - cations Overload . Cambridge , MA : MIT Press . https : / / doi . org / 10 . 7551 / mitpress / 7856 . 003 . 0001 [ 46 ] Christina Harrington , Sheena Erete , and Anne Marie Piper . 2019 . Deconstructing community - based collaborative design : Towards more equitable participatory design engagements . 3 , CSCW , Article 216 ( Nov 2019 ) , 25 pages . https : / / doi . org / 10 . 1145 / 3359318 [ 47 ] Dan Hawkins , Jason Procyk , and Carman Neustaedter . 2014 . Postulater : Slowing the pace of media sharing . In Proceedings of the 2014 Companion Publication on Designing Interactive Systems ( Vancouver , BC , Canada ) ( DIS Companion ’14 ) . Association for Computing Machinery , New York , NY , USA , 89 – 92 . https : / / doi . org / 10 . 1145 / 2598784 . 2602790 [ 48 ] Renee Hobbs . 2021 . Media Literacy in Action : Questioning the Media . Rowman & Littlefeld Publishers . [ 49 ] Marnie Holborow . 2013 . What is neoliberalism ? : Discourse , ideology and the real world . In Neoliberalism and Applied Linguistics , David Block , John Gray , and Marnie Holborow ( Eds . ) . Routledge , Chapter 2 , 14 – 32 . It’s About Time : Atending to Temporality in Misinformation Interventions CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany [ 50 ] Caroline Jack . 2017 . Lexicon of lies : Terms for problematic information . Data & Society 3 , 22 ( 2017 ) , 1094 – 1096 . https : / / datasociety . net / pubs / oh / DataAndSociety _ LexiconofLies . pdf [ 51 ] Steven J . Jackson , David Ribes , Ayse Buyuktur , and Geofrey C . Bowker . 2011 . Collaborative rhythm : Temporal dissonance and alignment in collaborative scientifc work . In Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work ( Hangzhou , China ) ( CSCW ’11 ) . Association for Computing Machinery , New York , NY , USA , 245 – 254 . https : / / doi . org / 10 . 1145 / 1958824 . 1958861 [ 52 ] Farnaz Jahanbakhsh , Amy X . Zhang , Adam J . Berinsky , Gordon Pennycook , David G . Rand , and David R . Karger . 2021 . Exploring lightweight interventions at posting time to reduce the sharing of misinformation on social media . In Proceedings of the ACM on Human - Computer Interaction , Vol . 5 . ACM New York , NY , USA , 1 – 42 . https : / / doi . org / 10 . 1145 / 3449092 [ 53 ] Jessica Jaiswal , Caleb LoSchiavo , and David C . Perlman . 2020 . Disinformation , misinformation and inequality - driven mistrust in the time of COVID - 19 : Lessons unlearned from AIDS denialism . AIDS and Behavior 24 , 10 ( 2020 ) , 2776 – 2780 . https : / / doi . org / 10 . 1007 / s10461 - 020 - 02925 - y [ 54 ] Charlene Jennett , Ioanna Iacovides , Anna L . Cox , Anastasia Vikhanova , Emily Weigold , Layla Mostaghimi , Geraint Jones , James Jenkins , Sarah Gallacher , and Yvonne Rogers . 2016 . Squeezy green balls : Promoting environmental awareness through playful interactions . In Proceedings of the 2016 Annual Symposium on Computer - Human Interaction in Play ( Austin , Texas , USA ) ( CHI PLAY ’16 ) . Association for Computing Machinery , New York , NY , USA , 389 – 400 . https : / / doi . org / 10 . 1145 / 2967934 . 2968102 [ 55 ] Daniel Kahneman . 2011 . Thinking , Fast and Slow . Macmillan . [ 56 ] Jason Kawall . 2021 . Patience , love of truth , and navigating online media in an age of distraction . In Virtues , Democracy , and Online Media , Nancy E . Snow and Maria Silvia Vaccarezza ( Eds . ) . Routledge , 115 – 133 . [ 57 ] Sejal Khatri , Aaron Shaw , Sayamindu Dasgupta , and Benjamin Mako Hill . 2022 . The social embeddedness of peer production : A comparative qualitative analysis of three Indian language Wikipedia editions . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 128 , 18 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3501832 [ 58 ] Jan Kirchner and Christian Reuter . 2020 . Countering fake news : A comparison of possible solutions regarding user acceptance and efectiveness . In Proceedings of the ACM on Human - Computer Interaction , Vol . 4 . Association for Computing Machinery , New York , NY , USA , Article 140 , 27 pages . https : / / doi . org / 10 . 1145 / 3415211 [ 59 ] Matthias Korn and Amy Voida . 2015 . Creating friction : Infrastructuring civic engagement in everyday life . In Proceedings of The Fifth Decennial Aarhus Con - ference on Critical Alternatives ( Aarhus , Denmark ) ( CA ’15 ) . Aarhus University Press , Aarhus N , 145 – 156 . https : / / doi . org / 10 . 7146 / aahcc . v1i1 . 21198 [ 60 ] Vasilis Koulolias , Gideon Mekonnen Jonathan , Miriam Fernandez , and Dimitris Sotirchos . 2018 . Combating Misinformation : An Ecosystem in Co - creation . Tech - nical Report . OECD Publishing , Brussels , Belgium . https : / / ica - it . org / index . php / resources / publications / 434 - combating - misinformation [ 61 ] Charlotte P . Lee , Paul Dourish , and Gloria Mark . 2006 . The human infrastructure of cyberinfrastructure . In Proceedings of the 2006 20th Anniversary Conference on Computer Supported Cooperative Work ( Banf , Alberta , Canada ) ( CSCW ’06 ) . Association for Computing Machinery , New York , NY , USA , 483 – 492 . https : / / doi . org / 10 . 1145 / 1180875 . 1180950 [ 62 ] David M . Levy . 2006 . More , faster , better : Governance in an age of overload , busyness , and speed . First Monday ( 2006 ) . https : / / doi . org / 10 . 5210 / fm . v0i0 . 1618 [ 63 ] David M . Levy . 2016 . Mindful Tech : How to Bring Balance to Our Digital Lives . Yale University Press . [ 64 ] Calvin A . Liang , Sean A . Munson , and Julie A . Kientz . 2021 . Embracing four tensions in human - computer interaction research with marginalized people . In ACM Transactions on Computer - Human Interaction , Vol . 28 . Association for Computing Machinery , New York , NY , USA , Article 14 , 47 pages . https : / / doi . org / 10 . 1145 / 3443686 [ 65 ] Ann Light and Yoko Akama . 2014 . Structuring future social relations : The politics of care in participatory practice . In Proceedings of the 13th Participatory Design Conference : Research Papers - Volume 1 ( Windhoek , Namibia ) ( PDC ’14 ) . Association for Computing Machinery , New York , NY , USA , 151 – 160 . https : / / doi . org / 10 . 1145 / 2661435 . 2661438 [ 66 ] Siân E . Lindley . 2015 . Making time . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing ( Vancouver , BC , Canada ) ( CSCW ’15 ) . Association for Computing Machinery , New York , NY , USA , 1442 – 1452 . https : / / doi . org / 10 . 1145 / 2675133 . 2675157 [ 67 ] Kai Lukof , Ulrik Lyngs , Stefania Gueorguieva , Erika S . Dillman , Alexis Hiniker , and Sean A . Munson . 2020 . From ancient contemplative practice to the App Store : Designing a digital container for mindfulness . In Proceedings of the 2020 ACM Designing Interactive Systems Conference ( Eindhoven , Netherlands ) ( DIS ’20 ) . Association for Computing Machinery , New York , NY , USA , 1551 – 1564 . https : / / doi . org / 10 . 1145 / 3357236 . 3395444 [ 68 ] A . Jon Magoon . 1977 . Constructivist approaches in educational research . Re - view of Educational Research 47 , 4 ( 1977 ) , 651 – 693 . https : / / doi . org / 10 . 3102 / 00346543047004651 [ 69 ] Gabriela Marcu , Anind K . Dey , Sara Kiesler , and Madhu Reddy . 2016 . Time to refect : Supporting health services over time by focusing on collaborative refection . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing ( San Francisco , California , USA ) ( CSCW ’16 ) . Association for Computing Machinery , New York , NY , USA , 954 – 964 . https : / / doi . org / 10 . 1145 / 2818048 . 2820079 [ 70 ] Noortje Marres . 2018 . Why we can’t have our facts back . Engaging Science , Technology , and Society 4 ( 2018 ) , 423 – 443 . https : / / doi . org / 10 . 17351 / ests2018 . 188 [ 71 ] Melinda McClure Haughey , Meena Devii Muralikumar , Cameron A . Wood , and Kate Starbird . 2020 . On the misinformation beat : Understanding the work of investigative journalists reporting on problematic information online . In Proceedings of the ACM on Human - Computer Interaction , Vol . 4 . Association for Computing Machinery , New York , NY , USA , Article 133 , 22 pages . https : / / doi . org / 10 . 1145 / 3415204 [ 72 ] Pamela Mead and Chris Pacione . 1996 . Time and space . Interactions 3 , 2 ( mar 1996 ) , 68 – 77 . https : / / doi . org / 10 . 1145 / 227181 . 227188 [ 73 ] Katharyne Mitchell . 2003 . Educating the national citizen in neoliberal times : From the multicultural self to the strategic cosmopolitan . Transactions of the Institute of British Geographers 28 , 4 ( 2003 ) , 387 – 403 . https : / / doi . org / 10 . 1111 / j . 0020 - 2754 . 2003 . 00100 . x [ 74 ] Susan Moeller , Elia Powers , and Jessica Roberts . 2012 . «The world unplugged» and «24 hours without media» : Media literacy to develop self - awareness regard - ing media . Comunicar . Media Education Research Journal 20 , 39 ( 2012 ) , 45 – 52 . https : / / doi . org / 10 . 3916 / C39 - 2012 - 02 - 04 [ 75 ] Ine Mols , Elise van den Hoven , and Berry Eggen . 2016 . Technologies for ev - eryday life refection : Illustrating a design space . In Proceedings of the TEI ’16 : Tenth International Conference on Tangible , Embedded , and Embodied Interaction ( Eindhoven , Netherlands ) ( TEI ’16 ) . Association for Computing Machinery , New York , NY , USA , 53 – 61 . https : / / doi . org / 10 . 1145 / 2839462 . 2839466 [ 76 ] Ine Mols , Elise van den Hoven , and Berry Eggen . 2020 . Everyday life refection : Exploring media interaction with Balance , Cogito & Dott . In Proceedings of the Fourteenth International Conference on Tangible , Embedded , and Embodied Inter - action ( Sydney NSW , Australia ) ( TEI ’20 ) . Association for Computing Machinery , New York , NY , USA , 67 – 79 . https : / / doi . org / 10 . 1145 / 3374920 . 3374928 [ 77 ] Linda Monsees . 2020 . ‘A war against truth’ - understanding the fake news controversy . Critical Studies on Security 8 , 2 ( 2020 ) , 116 – 129 . https : / / doi . org / 10 . 1080 / 21624887 . 2020 . 1763708 [ 78 ] David L . Morgan . 1996 . Focus Groups as Qualitative Research . Sage Publications . [ 79 ] Sean Munson , Stephanie Lee , and Paul Resnick . 2021 . Encouraging reading of diverse political viewpoints with a browser widget . Proceedings of the Inter - national AAAI Conference on Web and Social Media 7 , 1 ( Aug 2021 ) , 419 – 428 . https : / / doi . org / 10 . 1609 / icwsm . v7i1 . 14429 [ 80 ] Ted Nordhaus and Alex Smith . 2021 . The problem With Alice Waters and the “slow food” movement . Retrieved Dec 6 , 2022 from https : / / jacobin . com / 2021 / 12 / organic - local - industrial - agriculture - farm - to - table / [ 81 ] William Odom , Richard Banks , Abigail Durrant , David Kirk , and James Pierce . 2012 . Slow technology : Critical refection and future directions . In Proceedings of the Designing Interactive Systems Conference ( Newcastle Upon Tyne , United Kingdom ) ( DIS ’12 ) . Association for Computing Machinery , New York , NY , USA , 816 – 817 . https : / / doi . org / 10 . 1145 / 2317956 . 2318088 [ 82 ] William Odom , Mark Selby , Abigail Sellen , David Kirk , Richard Banks , and Tim Regan . 2012 . Photobox : On the design of a slow technology . In Proceedings of the Designing Interactive Systems Conference ( Newcastle Upon Tyne , United Kingdom ) ( DIS ’12 ) . Association for Computing Machinery , New York , NY , USA , 665 – 668 . https : / / doi . org / 10 . 1145 / 2317956 . 2318055 [ 83 ] William Odom , Ron Wakkary , Jeroen Hol , Bram Naus , Pepijn Verburg , Tal Amram , and Amy Yo Sue Chen . 2019 . Investigating slowness as a frame to design longer - term experiences with personal data : A feld study of Olly . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland UK ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 16 . https : / / doi . org / 10 . 1145 / 3290605 . 3300264 [ 84 ] William T . Odom , Abigail J . Sellen , Richard Banks , David S . Kirk , Tim Regan , Mark Selby , Jodi L . Forlizzi , and John Zimmerman . 2014 . Designing for slowness , anticipation and re - visitation : A long term feld study of the Photobox . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Toronto , Ontario , Canada ) ( CHI ’14 ) . Association for Computing Machinery , New York , NY , USA , 1961 – 1970 . https : / / doi . org / 10 . 1145 / 2556288 . 2557178 [ 85 ] Rikke Ørngreen and Karin Levinsen . 2017 . Workshops as a research method - ology . Electronic Journal of E - learning 15 , 1 ( 2017 ) , 70 – 81 . https : / / fles . eric . ed . gov / fulltext / EJ1140102 . pdf [ 86 ] Stefanie Panke . 2015 . Digital literacy : An interview with Doug Belshaw . Retrieved Jan 27 , 2023 from https : / / www . aace . org / review / digital - literacy - an - interview - with - doug - belshaw / [ 87 ] Orestis Papakyriakopoulos and Ellen Goodman . 2022 . The impact of Twitter labels on misinformation spread and user engagement : Lessons from Trump’s election tweets . In Proceedings of the ACM Web Conference 2022 ( Virtual Event , CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Wilner et al . Lyon , France ) ( WWW ’22 ) . Association for Computing Machinery , New York , NY , USA , 2541 – 2551 . https : / / doi . org / 10 . 1145 / 3485447 . 3512126 [ 88 ] Irina Paraschivoiu , Josef Buchner , Robert Praxmarer , and Thomas Layer - Wagner . 2021 . Escape the fake : Development and evaluation of an augmented reality escape room game for fghting fake news . In Extended Abstracts of the 2021 Annual Symposium on Computer - Human Interaction in Play ( Virtual Event , Austria ) ( CHI PLAY ’21 ) . Association for Computing Machinery , New York , NY , USA , 320 – 325 . https : / / doi . org / 10 . 1145 / 3450337 . 3483454 [ 89 ] Sungkyu Park , Jamie Yejean Park , Hyojin Chin , Jeong - han Kang , and Meeyoung Cha . 2021 . An experimental study to understand user experience and perception bias occurred by fact - checking messages . In Proceedings of the Web Conference 2021 ( Ljubljana , Slovenia ) ( WWW ’21 ) . Association for Computing Machinery , New York , NY , USA , 2769 – 2780 . https : / / doi . org / 10 . 1145 / 3442381 . 3450121 [ 90 ] Gordon Pennycook , Ziv Epstein , Mohsen Mosleh , Antonio A . Arechar , Dean Eckles , and David G . Rand . 2021 . Shifting attention to accuracy can reduce misinformation online . Nature 592 , 7855 ( Apr 2021 ) , 590 – 595 . https : / / doi . org / 10 . 1038 / s41586 - 021 - 03344 - 2 [ 91 ] Gordon Pennycook and David G . Rand . 2019 . Lazy , not biased : Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning . Cognition 188 ( 2019 ) , 39 – 50 . https : / / doi . org / 10 . 1016 / j . cognition . 2018 . 06 . 011 [ 92 ] Gordon Pennycook and David G . Rand . 2021 . The psychology of fake news . Trends in Cognitive Sciences 25 , 5 ( 2021 ) , 388 – 402 . https : / / doi . org / 10 . 1016 / j . tics . 2021 . 02 . 007 [ 93 ] Lara S . G . Piccolo , Diotima Bertel , Tracie Farrell , and Pinelopi Troullinou . 2021 . Opinions , intentions , freedom of expression , . . . , and other human aspects of misinformation online . In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI EA ’21 ) . Asso - ciation for Computing Machinery , New York , NY , USA , Article 84 , 5 pages . https : / / doi . org / 10 . 1145 / 3411763 . 3441345 [ 94 ] Laura Pitcher . 2022 . Slow living is inherently anti - capitalist , but the aesthetic is not . Retrieved Dec 6 , 2022 from https : / / i - d . vice . com / en / article / 93a3we / slow - living - tiktok - trend [ 95 ] Jörgen Rahm - Skågeby and Lina Rahm . 2022 . HCI and deep time : Toward deep time design thinking . Human – Computer Interaction 37 , 1 ( 2022 ) , 15 – 28 . https : / / doi . org / 10 . 1080 / 07370024 . 2021 . 1902328 [ 96 ] Päivi Rasi , Hanna Vuojärvi , and Susanna Rivinen . 2021 . Promoting media literacy among older people : A systematic review . Adult Education Quarterly 71 , 1 ( 2021 ) , 37 – 54 . https : / / doi . org / 10 . 1177 / 0741713620923755 [ 97 ] Johan Redström . 2008 . RE : Defnitions of use . Design Studies 29 , 4 ( 2008 ) , 410 – 423 . https : / / doi . org / 10 . 1016 / j . destud . 2008 . 05 . 001 [ 98 ] Jon Roozenbeek and Sander Van der Linden . 2019 . Fake news game confers psy - chological resistance against online misinformation . Palgrave Communications 5 , 1 ( 2019 ) , 1 – 10 . https : / / doi . org / 10 . 1057 / s41599 - 019 - 0279 - 9 [ 99 ] Hartmut Rosa . 2013 . Social Acceleration . Columbia University Press . [ 100 ] Hartmut Rosa . 2016 . De - synchronization , dynamic stabilization , dispositional squeeze : The problem of temporal mismatch . In The Sociology of Speed : Digital , Organizational , and Social Temporalities , Judy Wajcman and Nigel Dodd ( Eds . ) . Oxford University Press , Chapter 2 , 25 – 41 . https : / / doi . org / 10 . 1093 / acprof : oso / 9780198782858 . 003 . 0003 [ 101 ] Daniela K . Rosner , Saba Kawas , Wenqi Li , Nicole Tilly , and Yi - Chen Sung . 2016 . Out of time , Out of place : Refections on design workshops as a research method . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing ( San Francisco , California , USA ) ( CSCW ’16 ) . Association for Computing Machinery , New York , NY , USA , 1131 – 1141 . https : / / doi . org / 10 . 1145 / 2818048 . 2820021 [ 102 ] Kavous Salehzadeh Niksirat , Chaklam Silpasuwanchai , Mahmoud Mohamed Hussien Ahmed , Peng Cheng , and Xiangshi Ren . 2017 . A framework for interac - tive mindfulness meditation using attention - regulation process . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems ( Denver , Colorado , USA ) ( CHI ’17 ) . Association for Computing Machinery , New York , NY , USA , 2672 – 2684 . https : / / doi . org / 10 . 1145 / 3025453 . 3025914 [ 103 ] Nikita A . Salovich and David N . Rapp . 2021 . Misinformed and unaware ? Metacognition and the infuence of inaccurate information . Journal of Ex - perimental Psychology : Learning , Memory , and Cognition 47 , 4 ( 2021 ) , 608 . https : / / doi . org / 10 . 1037 / xlm0000977 [ 104 ] Christine Satchell and Paul Dourish . 2009 . Beyond the user : Use and non - use in HCI . In Proceedings of the 21st Annual Conference of the Australian Computer - Human Interaction Special Interest Group : Design : Open 24 / 7 ( Melbourne , Aus - tralia ) ( OZCHI ’09 ) . Association for Computing Machinery , New York , NY , USA , 9 – 16 . https : / / doi . org / 10 . 1145 / 1738826 . 1738829 [ 105 ] Thomas A Schwandt . 1994 . Constructivist , interpretivist approaches to human inquiry . In The Landscape of Qualitative Research : Theories and Issues , Norman K Denzin and Yvonna S Lincoln ( Eds . ) . SAGE Publishing , United States , Chapter 7 , 118 – 137 . [ 106 ] Bryan Semaan . 2019 . ’Routine infrastructuring’ as ’building everyday resilience with technology’ : When disruption becomes ordinary . 3 , CSCW , Article 73 ( Nov 2019 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3359175 [ 107 ] Judith Shulevitz . 2011 . The Sabbath World : Glimpses of a Diferent Order of Time . Random House Trade Paperbacks . [ 108 ] Jaime Snyder , Mark Matthews , Jacqueline Chien , Pamara F . Chang , Emily Sun , Saeed Abdullah , and Geri Gay . 2015 . MoodLight : Exploring personal and social implications of ambient display of biosensor data . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing ( Vancouver , BC , Canada ) ( CSCW ’15 ) . Association for Computing Machinery , New York , NY , USA , 143 – 153 . https : / / doi . org / 10 . 1145 / 2675133 . 2675191 [ 109 ] Matthew Sparke . 2013 . Introducing Globalization : Ties , Tensions , and Uneven Integration ( 1st ed . ) . John Wiley & Sons . [ 110 ] Kate Starbird , Ahmer Arif , and Tom Wilson . 2019 . Disinformation as col - laborative work : Surfacing the participatory nature of strategic information operations . In Proceedings of the ACM on Human - Computer Interaction , Vol . 3 . Association for Computing Machinery , New York , NY , USA , Article 127 , 26 pages . https : / / doi . org / 10 . 1145 / 3359229 [ 111 ] Joëlle Swart . 2021 . Tactics of news literacy : How young people access , evaluate , and engage with news on social media . New Media & Society ( 2021 ) , 1 – 17 . https : / / doi . org / 10 . 1177 / 14614448211011447 [ 112 ] Catherine Tebaldi and Kysa Nygreen . 2022 . Opening or impasse ? Critical media literacy pedagogy in a posttruth era . Cultural Studies < – > Critical Methodologies 22 , 2 ( 2022 ) , 143 – 153 . https : / / doi . org / 10 . 1177 / 15327086211065810 [ 113 ] John C . Thomas , Yue Pan , Thomas Erickson , Eli Blevis , Catherine Letondal , and Aurélien Tabard . 2013 . Avec le temps ! Time , tempo , and turns in human - computer interaction . In CHI ’13 Extended Abstracts on Human Factors in Comput - ing Systems ( Paris , France ) ( CHI EA ’13 ) . Association for Computing Machinery , New York , NY , USA , 3303 – 3306 . https : / / doi . org / 10 . 1145 / 2468356 . 2479672 [ 114 ] Emily K . Vraga and Melissa Tully . 2021 . News literacy , social media behaviors , and skepticism toward information on social media . Information , Communication & Society 24 , 2 ( 2021 ) , 150 – 166 . https : / / doi . org / 10 . 1080 / 1369118X . 2019 . 1637445 [ 115 ] Judy Wajcman . 2014 . Pressed for Time . University of Chicago Press . [ 116 ] Alicia Wanless and Michael Berk . 2020 . The audience is the amplifer : Par - ticipatory propaganda . In The SAGE Handbook of Propaganda , Paul Baines , Nicholas O’Shaughnessy , and Nancy Snow ( Eds . ) . SAGE Publications Ltd , 85 – 104 . https : / / doi . org / 10 . 4135 / 9781526477170 [ 117 ] Mikael Wiberg and Erik Stolterman . 2021 . Time and temporality in HCI research . Interacting with Computers 33 , 3 ( Oct 2021 ) , 250 – 270 . https : / / doi . org / 10 . 1093 / iwc / iwab025 [ 118 ] Marisol Wong - Villacres , Aakash Gautam , Wendy Roldan , Lucy Pei , Jessa Dickin - son , Azra Ismail , Betsy DiSalvo , Neha Kumar , Tammy Clegg , Sheena Erete , Emily Roden , Nithya Sambasivan , and Jason Yip . 2020 . From needs to strengths : Opera - tionalizing an assets - based design of technology . In Conference Companion Publi - cation of the 2020 on Computer Supported Cooperative Work and Social Computing ( Virtual Event , USA ) ( CSCW ’20 Companion ) . Association for Computing Ma - chinery , New York , NY , USA , 527 – 535 . https : / / doi . org / 10 . 1145 / 3406865 . 3418594 [ 119 ] Jason C . Young . 2019 . Rural digital geographies and new landscapes of social resilience . Journal of Rural Studies 70 ( 2019 ) , 66 – 74 . https : / / doi . org / 10 . 1016 / j . jrurstud . 2019 . 07 . 001 [ 120 ] Jason C . Young . 2021 . Disinformation as the weaponization of cruel optimism : A critical intervention in misinformation studies . Emotion , Space and Society 38 ( 2021 ) , 100757 . https : / / doi . org / 10 . 1016 / j . emospa . 2020 . 100757 A APPENDIX A . 1 Additional Information on Workshop Participants Table 2 describes our workshop participants . To construct these descriptions we used information like ofcial job titles and how participants described themselves and their organizations on their websites and during the workshops . To improve readability , we as - signed participants codes based on their primary job ( E for educator , L for librarian , J for journalism and media ) . Participant Participant Description Workshops Attended E1 E2 E3 E4 E5 E6 E7 E8 E9 E10 E11 J1 J2 J3 J4 J5 J6 J7 J8 J9 J10 L1 L2 L3 L4 L5 L6 Program supervisor specialized in media literacy overseeing statewide public K – 12 education on U . S . West Coast High school teacher who works with a signifcant BIPOC stu - dent population History and media literacy teacher at a high school on U . S . West Coast Director of pre K - 12 engagement at a nonproft educational organization serving diverse community members on U . S . West Coast Educator at an independent , non - proft science center on U . S . West Coast , serving K - 8 learners Teacher and program coordinator at an organization of teachers and librarians dedicated to bringing digital media literacy skills to their students and communities on U . S . West Coast Education supply coordinator at an independent , non - proft science center on U . S . West Coast , serving K - 8 learners Vice president at an independent , non - proft science center on U . S . West Coast . , serving K - 8 learners Media literacy educator and flmmaker at a community radio organization on U . S . West Coast , serving diverse audiences Language arts / journalism teacher at a public school on U . S . West Coast Teacher at a public school on U . S . West Coast A local journalist working at a national outlet’s branch in South - ern U . S . A journalist and the founder of a nonproft news organization which focuses on community journalism and advocates for local media collaboration Reporter for nonpartisan media organization in Southern U . S . Project manager working on projects for election integrity on U . S . West Coast Media / journalism professional at a non - proft foundation in Midwest of the U . S . Founder of an independent , nonproft media organization in Southern U . S . with a mission to work with African American communities CEO and publisher at a nonproft , nonpartisan news organiza - tion in Southern U . S . Co - founder of a media marketing company in Southern U . S . Journalist at an international media organization based in the U . S . Environmental journalist at an independent nonproft media organization in Southern U . S . Reference and instruction librarian who serves students and public patrons with a wide variety of backgrounds in terms of national origin , language , and age Library director at a rural , small - sized library Director at a rural library where patrons are , in their view , politically " very mixed " Faculty librarian at a college where BIPOC students account for more than half of the population Executive director at a rural library on U . S . West Coast Teen librarian at a small library in a semi - rural area 3 , 4 2 , 3 , 4 , 2 , 3 , 4 , 2 2 , 3 , 4 , 2 , 5 2 2 3 2 3 1 , 3 , 4 , 2 2 , 3 , 5 3 , 4 , 5 1 1 1 1 1 3 2 , 3 , 4 , 2 , 3 , 4 , 2 , 5 2 , 3 , 4 2 , 3 , 4 , 5 5 5 5 5 5 5 Continued on next page It’s About Time : Atending to Temporality in Misinformation Interventions CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Table 2 : Workshop Participants CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Wilner et al . Table 2 – continued from previous page Participant Participant Description Workshops Attended L7 L8 L9 L10 Public services director at a rural library on U . S . West Coast Teen services coordinator at a rural library on U . S . West Coast Communication studies and news librarian serving a diverse student population on U . S . West Coast Library assistant at a large K - 12 school system on U . S . West Coast 2 , 3 , 4 , 5 2 , 3 , 4 , 5 2 , 3 , 4 , 5 2 L11 L12 Director of advocacy and community innovations at a rural library serving Hispanic / Latino population Librarian who works at a rural , small , non - proft library in Southern U . S . 3 , 4 2 , 3 , 4 , 5 L13 Librarian at a four - year public university library serving U . S . national and international students in Southern U . S . 2 , 3 , 5 L14 L15 Public library services director at a rural library serving His - panic / Latino population Library director at a public library on U . S . West Coast 4 , 5 5 It’s About Time : Atending to Temporality in Misinformation Interventions CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany A . 2 Additional Information on Workshop Activities Table 3 describes the workshop activities we mentioned in the methods section . Table 3 : Workshop activities Workshop Activity # 1 Activity # 2 Workshop 1 and 2 ( Nov 2021 ) To learn about the participants’ context . The participants discussed prompts like : What do you like about each other’s stories ? What questions do the stories raise for you ? Engage and critique existing approaches on critical ( data ) reasoning ( e . g . , museum exhibit ) and how it might be adapted to ft in the participant’s context . The participants discussed prompts like : What are your general reactions to these approaches ? Are they useful and engaging in your community ? Workshop 3 ( Jan 2022 ) To capture participants’ reactions to a classroom exercise and to understand how they navigate strong emotions when reading repulsive news . The participants discussed the following prompts , e . g . , This exercise focuses on neg - ative emotions . Are there other emotions — like positive ones — that seem relevant given the bad information you see in your community ? To understand how our participants’ communities deal with emotions when they encounter problematic infor - mation . To meet activity # 2 goals , participants were asked prompts on the following lines : Describe the situation in which you encountered problematic information - who was involved , what happened , where and when did it happen , how did people behave ? Workshop 4 ( March 2022 ) The frst activity focused on understanding the socio - cultural barriers to education and learning and socio - cultural assets that can be leveraged when doing edu - cational work . The participants discussed the following prompts , e . g . , how do social and cultural barriers within your community make education and learning more dif - fcult ? The second activity focused on understanding how we might create efective online communities of practice - a term by which we mean helpful groups of people and resources in a professional and shared context – to address problematic information while considering the social / historical / political context . The participants dis - cussed the following prompts , e . g . , What are the impor - tant things to consider when creating an online commu - nity for professionals who are combating bad information like you ? Workshop 5 ( April 2022 ) To present key takeaways which we had synthesized from the discussions in the previous workshops . To engage participants in a free writing exercise to describe what more they could add to the key takeaways and discuss in breakout sessions . To identify ideas and projects that participants would like to implement in collaboration with the members of the research team . Participants were asked prompts on the following lines : “Provide a general description of the tool / approach ; Describe the goal ( s ) of the tool / approach ; Identify who in your community or organization would be involved . ”