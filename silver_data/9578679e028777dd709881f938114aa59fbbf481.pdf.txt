A Comparison of String Distance Metrics for Name - Matching Tasks William W . Cohen ∗† Pradeep Ravikumar ∗ Stephen E . Fienberg ∗†‡ ∗ Center for Automated Learning and Discovery † Center for Computer and Communications Security ‡ Department of Statistics Carnegie Mellon University Carnegie Mellon University Carnegie Mellon University Pittsburgh PA 15213 Pittsburgh PA 15213 Pittsburgh PA 15213 wcohen @ wcohen . com pradeepr @ cs . cmu . edu fienberg @ stat . cmu . edu Abstract Using an open - source , Java toolkit of name - matching methods , we experimentally compare string distance metrics on the task of matching entity names . We inves - tigate a number of different metrics proposed by differ - ent communities , including edit - distance metrics , fast heuristic string comparators , token - based distance met - rics , and hybrid methods . Overall , the best - performing method is a hybrid scheme combining a TFIDF weight - ing scheme , which is widely used in information re - trieval , with the Jaro - Winkler string - distance scheme , which was developed in the probabilistic record linkage community . Introduction The task of matching entity names has been explored by a number of communities , including statistics , databases , and artiﬁcial intelligence . Each community has formulated the problem differently , and different techniques have been pro - posed . In statistics , a long line of research has been conducted in probabilistic record linkage , largely based on the sem - inal paper by Fellegi and Sunter ( 1969 ) . This paper for - mulates entity matching as a classiﬁcation problem , where the basic goal is to classify entity pairs as matching or non - matching . Fellegi and Sunter propose using largely unsupervised methods for this task , based on a feature - based representation of pairs which is manually designed and to some extent problem - speciﬁc . These proposals have been , by and large , adopted by subsequent researchers , al - though often with elaborations of the underlying statisti - cal model ( Jaro 1989 ; 1995 ; Winkler 1999 ; Larsen 1999 ; Belin & Rubin 1997 ) . These methods have been used to match individuals and / or families between samples and cen - suses , e . g . , in evaluation of the coverage of the U . S . decen - nial census ; or between administrative records and survey data bases , e . g . , in the creation of an anonymized research data base combining tax information from the Internal Rev - enue Service and data from the Current Population Survey . In the database community , some work on record match - ing has been based on knowledge - intensive approaches Copyright c (cid:176) 2003 , American Association for Artiﬁcial Intelli - gence ( www . aaai . org ) . All rights reserved . ( Hernandez & Stolfo 1995 ; Galhardas et al . 2000 ; Raman & Hellerstein 2001 ) . However , the use of string - edit dis - tances as a general - purpose record matching scheme was proposed by Monge and Elkan ( Monge & Elkan 1997 ; 1996 ) , and in previous work , we proposed use of the TFIDF distance metric for the same purpose ( Cohen 2000 ) . In the AI community , supervised learning has been used for learning the parameters of string - edit distance metrics ( Ristad & Yianilos 1998 ; Bilenko & Mooney 2002 ) and combining the results of different distance functions ( Te - jada , Knoblock , & Minton 2001 ; Cohen & Richman 2002 ; Bilenko & Mooney 2002 ) . More recently , probabilistic ob - ject identiﬁcation methods have been adapted to matching tasks ( Pasula et al . 2002 ) . In these communities there has been more emphasis on developing “autonomous” match - ing techniques which require little or or no conﬁguration for a new task , and less emphasis on developing “toolkits” of methods that can be applied to new tasks by experts . Recently , we have begun implementing an open - source , Java toolkit of name - matching methods which includes a va - riety of different techniques . In this paper we use this toolkit to conduct a comparison of several string distances on the tasks of matching and clustering lists of entity names . This experimental use of string distance metrics , while similar to previous experiments in the database and AI com - munities , is a substantial departure from their usual use in statistics . In statistics , databases tend to have more structure and speciﬁcation , by design . Thus the statistical literature on probabilistic record linkage represents pairs of entities not by pairs of strings , but by vectors of “match features” such as names and categories for variables in survey databases . By developing appropriate match features , and appropriate statistical models of matching and non - matching pairs , this approach can achieve better matching performance ( at least potentially ) . The use of string distances considered here is most useful for matching problems with little prior knowledge , or ill - structured data . Better string distance metrics might also be useful in the generation of “match features” in more struc - tured database situations . Methods Edit - distance like functions Distance functions map a pair of strings s and t to a real number r , where a smaller value of r indicates greater sim - ilarity between s and t . Similarity functions are analogous , except that larger values indicate greater similarity ; at some risk of confusion to the reader , we will use this terms inter - changably , depending on which interpretation is most natu - ral . One important class of distance functions are edit dis - tances , in which distance is the cost of best sequence of edit operations that convert s to t . Typical edit operations are character insertion , deletion , and substitution , and each op - eration much be assigned a cost . We will consider two edit - distance functions . The sim - ple Levenstein distance assigns a unit cost to all edit opera - tions . As an example of a more complex well - tuned distance function , we also consider the Monger - Elkan distance func - tion ( Monge & Elkan 1996 ) , which is an afﬁne 1 variant of the Smith - Waterman distance function ( Durban et al . 1998 ) with particular cost parameters , and scaled to the interval [ 0 , 1 ] . A broadly similar metric , which is not based on an edit - distance model , is the Jaro metric ( Jaro 1995 ; 1989 ; Winkler 1999 ) . In the record - linkage literature , good results have been obtained using variants of this method , which is based on the number and order of the common characters between two strings . Given strings s = a 1 . . . a K and t = b 1 . . . b L , deﬁne a character a i in s to be common with t there is a b j = a i in t such that i − H ≤ j ≤ i + H , where H = min ( | s | , | t | ) 2 . Let s (cid:48) = a (cid:48) 1 . . . a (cid:48) K (cid:48) be the characters in s which are common with t ( in the same order they appear in s ) and let t (cid:48) = b (cid:48) 1 . . . b (cid:48) L (cid:48) be analogous ; now deﬁne a transposition for s (cid:48) , t (cid:48) to be a position i such that a (cid:48) i (cid:54) = b (cid:48) i . Let T s (cid:48) , t (cid:48) be half the number of transpositions for s (cid:48) and t (cid:48) . The Jaro similarity metric for s and t is Jaro ( s , t ) = 1 3 · (cid:181) | s (cid:48) | | s | + | t (cid:48) | | t | + | s (cid:48) | − T s (cid:48) , t (cid:48) | s (cid:48) | (cid:182) A variant of this due to Winkler ( 1999 ) also uses the length P of the longest common preﬁx of s and t . Letting P (cid:48) = max ( P , 4 ) we deﬁne Jaro - Winkler ( s , t ) = Jaro ( s , t ) + P (cid:48) 10 · ( 1 − Jaro ( s , t ) ) The Jaro and Jaro - Winkler metrics seem to be intended pri - marily for short strings ( e . g . , personal ﬁrst or last names . ) Token - based distance functions Two strings s and t can also be considered as multisets ( or bags ) of words ( or tokens ) . We also considered several token - based distance metrics . The Jaccard similarity be - tween the word sets S and T is simply | S ∩ T | | S ∪ T | . TFIDF or 1 Afﬁne edit - distance functions assign a relatively lower cost to a sequence of insertions or deletions . cosine similarity , which is widely used in the information retrieval community can be deﬁned as TFIDF ( S , T ) = (cid:88) w ∈ S ∩ T V ( w , S ) · V ( w , T ) where TF w , S is the frequency of word w in S , N is the size of the “corpus” , IDF w is the inverse of the fraction of names in the corpus that contain w , V (cid:48) ( w , S ) = log ( TF w , S + 1 ) · log ( IDF w ) and V ( w , S ) = V (cid:48) ( w , S ) / (cid:112)(cid:80) w (cid:48) V (cid:48) ( w , S ) 2 . Our imple - mentation measures all document frequency statistics from the complete corpus of names to be matched . Following Dagan et al ( 1999 ) , a token set S can be viewed as samples from an unknown distribution P S of tokens , and a distance between S and T can be computed based on these distributions . Inspired by Dagan et al we considered the Jensen - Shannon distance between P S and P T . Letting KL ( P | | Q ) be the Kullback - Lieber divergence and letting Q ( w ) = 1 2 ( P S ( w ) + P T ( w ) ) , this is simply Jensen - Shannon ( S , T ) = 1 2 ( KL ( P S | | Q ) + KL ( P T | | Q ) ) Distributions P S were estimated using maximum likelihood , a Dirichlet prior , and a Jelenik - Mercer mixture model ( Laf - ferty & Zhai 2001 ) . The latter two cases require parameters ; for Dirichlet , we used α = 1 , and for Jelenik - Mercer , we used the mixture coefﬁcient λ = 0 . 5 . From the record - linkage literature , a method proposed by Fellegi and Sunter ( 1969 ) can be easily extended to a token distance . As notation , let A and B be two sets of records to match , let C = A ∩ B , let D = A ∪ B , and for X = A , B , C , D let P X ( w ) be the empirical probability of a name containing the word w in the set X . Also let e X be the empirical probability of an error in a name in set X ; e X , 0 be the probability of a missing name in set X ; e T be the probability of two correct but differing names in A and B ; and let e = e A + e B + e T + e A , 0 + e B , 0 . Fellegi and Sunter propose ranking pairs s , t by the odds ratio log ( Pr ( M | s , t ) Pr ( U | s , t ) ) where M is the class of matched pairs and U is the class of unmatched pairs . Letting AGREE ( s , t , w ) denote the event “ s and t both agree in containing word w ” , Fellegi and Sunter note that under cer - tain assumptions Pr ( M | AGREE ( s , t , w ) ) ≈ P C ( w ) ( 1 − e ) Pr ( U | AGREE ( s , t , w ) ) ≈ P A ( w ) · P B ( w ) ( 1 − e ) If we make two addition assumptions suggested by Fellegi and Sunter , and assume that ( a ) matches on a word w are independent , and ( b ) that P A ( w ) ≈ P B ( w ) ≈ P C ( w ) ≈ P D ( w ) , we ﬁnd that the incremental score for the odds ratio associated with AGREE ( s , t , w ) is simply − log P D ( w ) . In information retrieval terms , this is a simple un - normalized IDF weight . Unfortunately , updating the log - odds score of a pair on discovering a disagreeing token w is not as sim - ple . Estimates are provided by Fellegi and Sunter for P ( M | ¬ AGREE ( s , t , w ) ) and P ( U | ¬ AGREE ( s , t , w ) ) , but the error parameters e A , e B , . . . do not cancel out – instead one is left with a constant penalty term , independent of w . Departing slightly from this ( and following the intu - ition that disagreement on frequent terms is less important ) we introduce a variable penalty term of k log P D ( w ) , where k is a parameter to be set by the user . In the experiments we used k = 0 . 5 , and call this method SFS distance ( for Simpliﬁed Fellegi - Sunter ) . Hybrid distance functions Monge and Elkan propose the following recursive matching scheme for comparing two long strings s and t . First , s and t are broken into substrings s = a 1 . . . a K and t = b . . . b L . Then , similarity is deﬁned as sim ( s , t ) = 1 K K (cid:88) i = 1 L max j = 1 sim (cid:48) ( A i , B j ) where sim (cid:48) is some secondary distance function . We con - sidered an implementation of this scheme in which the sub - strings are tokens ; following Monge and Elkan , we call this a level two distance function . We experimented with level two similarity functions which used Monge - Elkan , Jaro , and Jaro - Winkler as their base function sim (cid:48) . We also considered a “soft” version of TFIDF , in which similar tokens are considered as well as tokens in S ∩ T . Again let sim (cid:48) be a secondary similarity function . Let CLOSE ( θ , S , T ) be the set of words w ∈ S such that there is some v ∈ T such that dist (cid:48) ( w , v ) > θ , and for w ∈ CLOSE ( θ , S , T ) , let D ( w , T ) = max v ∈ T dist ( w , v ) . We deﬁne SoftTFIDF ( S , T ) = (cid:88) w ∈ CLOSE ( θ , S , T ) V ( w , S ) · V ( w , T ) · D ( w , T ) In the experiments , we used Jaro - Winkler as a secondary distance and θ = 0 . 9 . “Blocking” or pruning methods In matching or clustering large lists of names , it is not com - putationally practical to measure distances between all pairs of strings . In statistical record linkage , it is common to group records by some variable which is known a priori to be usually the same for matching pairs . In census work , this grouping variable often names a small geographic region , and perhaps for this reason the technique is usually called “blocking” . Since this paper focuses on the behavior of string match - ing tools when little prior knowledge is available , we will use here knowledge - free approaches to reducing the set of string pairs to compare . In a matching task , there are two sets A and B . We consider as candidates all pairs of strings ( s , t ) ∈ A × B such that s and t share some substring v which appears in at most a fraction f of all names . In a clus - tering task , there is one set C , and we consider all candi - dates ( s , t ) ∈ C × C such that s (cid:54) = t , and again s and t share some not - too - frequent substring v . For purely token - based Name Src M / C # Strings # Tokens animal 1 M 5709 30 , 006 bird1 1 M 377 1 , 977 bird2 1 M 982 4 , 905 bird3 1 M 38 188 bird4 1 M 719 4 , 618 business 1 M 2139 10 , 526 game 1 M 911 5 , 060 park 1 M 654 3 , 425 fodorZagrat 2 M 863 10 , 846 ucdFolks 3 M 90 454 census 4 M 841 5 , 765 UVA 3 C 116 6 , 845 coraATDV 5 C 1916 47 , 512 Table 1 : Datasets used in experiments . Column 2 indi - cates the source of the data , and column 3 indicates if it is a matching ( M ) or clustering ( C ) problem . Origi - nal sources are 1 . ( Cohen 2000 ) 2 . ( Tejada , Knoblock , & Minton 2001 ) 3 . ( Monge & Elkan 1996 ) 4 . William Winkler ( personal communication ) 5 . ( McCallum , Nigam , & Ungar 2000 ) communication ) methods , the substring v must be a token , and otherwise , it must be a character 4 - gram . Using inverted indices this set of pairs can be enumerated quickly . For the moderate - size test sets considered here , we used f = 1 . On the matching datasets above , the token blocker ﬁnds between 93 . 3 % and 100 . 0 % of the correct pairs , with an average of 98 . 9 % . The 4 - gram blocker also ﬁnds between 93 . 3 % and 100 . 0 % of the correct pairs , with an average of 99 . 0 % . Experiments Data and methodology The data used to evaluate these methods is shown in Ta - ble 1 . Most been described elsewhere in the literature . The “coraATDV” dataset includes the ﬁelds author , title , date , and venue in a single string . The “census” dataset is a syn - thetic , census - like dataset , from which only textual ﬁelds were used ( last name , ﬁrst name , middle initial , house num - ber , and street ) . To evaluate a method on a dataset , we ranked by distance all candidate pairs from the appropriate grouping algorithm . We computed the non - interpolated average precision of this ranking , the maximum F1 score of the ranking , and also in - terpolated precision at the eleven recall levels 0 . 0 , 0 . 1 , . . . , 0 . 9 , 1 . 0 . The non - interpolated average precision of a rank - ing containing N pairs for a task with m correct matches is 1 m (cid:80) Nr = 1 c ( i ) δ ( i ) i , where c ( i ) is the number of correct pairs ranked before position i , and δ ( i ) = 1 if the pair at rank i is correct and 0 otherwise . Interpolated precision at recall r is the max i c ( i ) i , where the max is taken over all ranks i such that c ( i ) m ≥ r . Maximum F1 is max i > 0 F 1 ( i ) , where F 1 ( i ) is the harmonic mean of recall at rank i ( i . e . , c ( i ) / m ) and precision at rank i ( i . e . , c ( i ) / i ) . 0 . 5 0 . 55 0 . 6 0 . 65 0 . 7 0 . 75 0 . 8 0 . 85 0 . 9 0 . 95 1 0 . 5 0 . 55 0 . 6 0 . 65 0 . 7 0 . 75 0 . 8 0 . 85 0 . 9 0 . 95 1 M a x F 1 o f TF I D F MaxF1 of other vs Jaccardvs SFS vs Jensen - Shannony = x 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 A v g P r e c o f TF I D F AvgPrec of other vs Jaccardvs SFS vs Jensen - Shannony = x 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 2 0 . 4 0 . 6 0 . 8 1 P r e c i s i on Recall TFIDF Jensen - ShannonSFSJaccard Figure 1 : Relative performance of token - based measures . Left , max F1 of methods on matching problems , with points above the line y = x indicating better performance of TFIDF . Middle , same for non - interpolated average precision . Right , precision - recall curves averaged over all matching problems . Smoothed versions of Jensen - Shannon ( not shown ) are comparable in performance to the unsmoother version . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 m a x F 1 o f M on ge - E l k an max F1 of other distance metric vs Levenstein vs SmithWatermanvs Jaro vs Jaro - Winklery = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 a v g P r e c o f M onge - E l k an avgPrec of other distance metric vs Levenstein vs SmithWatermanvs Jaro vs Jaro - Winklery = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 2 0 . 4 0 . 6 0 . 8 1 P r e c i s i on Recall Monge - Elkan Levenstein Smith - WatermanJaro Jaro - Winkler Figure 2 : Relative performance of edit - distance measures . Left and middle , points above ( below ) the line y = x indicating better ( worse ) performance for Monge - Elkan , the system performing best on average . Results for matching We will ﬁrst consider the matching datasets . As shown in Figure 1 , TFIDF seems generally the best among the token - based distance metrics . It does slightly better on average than the others , and is seldom much worse than any other method with respect to interpolated average precision or maximum F1 . As shown in Figure 2 , the situation is less clear for the edit - distance based methods . The Monge - Elkan method does best on average , but the Jaro and Jaro - Winkler methods are close in average performance , and do noticably better than Monge - Elkan on several problems . The Jaro variants are also substantially more efﬁcient ( at least in our imple - mentation ) , taking about 1 / 10 the time of the Monge - Elkan method . ( The token - based methods are faster still , averaging less than 1 / 10 the time of the Jaro variants . ) As shown in Figure 3 , SoftTFIDF is generally the best among the hybrid methods we considered . In general , the time for the hybrid methods is comparable to using the un - derlying string edit distance . ( For instance , the average matching time for SoftTFIDF is about 13 seconds on these problems , versus about 20 seconds for the Jaro - Winkler method , and 1 . 2 seconds for pure token - based TFIDF . ) Finally , Figure 4 compares the three best performing edit - distance like methods , the two best token - based methods , and the two best hybrid methods , using a similar method - ology . Generally speaking , SoftTFIDF is the best overall distance measure for these datasets . Results for clustering It should be noted that the test suite of matching problems is dominated by problems from one source—eight of the eleven test cases are associated with the WHIRL project— and a different distribution of problems might well lead to quite different results . For instance , while the token - based methods perform well on average , they perform poorly on the census - like dataset , which contains many misspellings . As an additional experiment , we evaluated the four best - performing distance metrics ( SoftTFIDF , TFIDF , SFS , and Level 2 Jaro - Winkler ) on the two clustering problems , which are taken from sources other than the WHIRL project . Ta - ble 2 shows MaxF1 and non - interpolated average precision for each method on each problem . SoftTFIDF again slightly outperforms the other methods on both of these tasks . UVA CoraATDV Method MaxF1 AvgPrec MaxF1 AvgPrec SoftTFIDF 0 . 89 0 . 91 0 . 85 0 . 914 TFIDF 0 . 79 0 . 84 0 . 84 0 . 907 SFS 0 . 71 0 . 75 0 . 82 0 . 864 Level2 J - W 0 . 73 0 . 69 0 . 76 0 . 804 Table 2 : Results for selected distance metrics on two clustering problems . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 m a x F 1 o f S o ft TF I D F max F1 of other distance metric vs Level2 Levenstein vs Level2 Monge - Elkan vs Level2 Jaro vs Level2 Jaro - Winklery = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 a v g P r e c o f S o ft TF I D F avgPrec of other distance metric vs Level2 Levenstein vs Level2 Monge - Elkan vs Level2 Jaro vs Level2 Jaro - Winklery = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 2 0 . 4 0 . 6 0 . 8 1 P r e c i s i on Recall SoftTFIDF Level2 Jaro - Winkler Level2 Jaro Level2 Levenstein Level2 Monge - Elkan Figure 3 : Relative performance of hybrid distance measures on matching problems , relative to the SoftTFIDF metric , which performs best on average . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 m a x F 1 o f S o ft TF I D F max F1 of other distance metric vs Monge - Elkanvs Jaro vs Jaro - Winklervs TFIDFvs SFS vs Level2 Jaro - Winklery = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 a v g P r e c o f S o ft TF I D F avgPrec of other distance metric vs Monge - Elkanvs Jaro vs Jaro - Winklervs TFIDFvs SFS vs Level2 Jaro - Winklery = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 2 0 . 4 0 . 6 0 . 8 1 P r e c i s i on Recall SoftTFIDF Level2 Jaro - WinklerTFIDFSFS Monge - ElkanJaro Jaro - Winkler Figure 4 : Relative performance of best distance measures of each type on matching problems , relative to the SoftTFIDF metric . Learning to combine distance metrics Another type of hybrid distance function can be obtained by combining other distance metrics . Following previous researchers ( Tejada , Knoblock , & Minton 2001 ; Cohen & Richman 2002 ; Bilenko & Mooney 2002 ) we used a learning scheme to combine several of the distance functions above . Speciﬁcally , we represented pairs as feature vectors , using as features the numeric scores of Monge - Elkan , Jaro - Winkler , TFIDF , SFS , and SoftTFIDF . We then trained a binary SVM classiﬁer ( using SVM Light ( Joachims 2002 ) ) using these features , and used its conﬁdence in the “match” class as a score . Figure 5 shows the results of a three - fold cross - validation on nine of the matching problems . The learned combina - tion generally slightly outperforms the individual metrics , including SoftTFIDF , particularly at extreme recall levels . Note , however , that the learned metric uses much more in - formation : in particular , in most cases it has been trained on several thousand labeled candidate pairs , while the other metrics considered here require no training data . Concluding remarks Recently , we have begun implementing an open - source , Java toolkit of name - matching methods . This toolkit includes a variety of different techniques , as well as the infrastructure to combine techniques readily , and evaluate them systemat - ically on test data . Using this toolkit , we conducted a com - parison of several string distances on the tasks of matching and clustering lists of entity names . Many of these were techniques previously proposed in the literature , and some are novel hybrids of previous methods . We compared these accuracy of these methods for use in an automatic matching scheme , in which pairs of names are proposed by a simple grouping method , and then ranked ac - cording to distance . Used in this way , we saw that the TFIDF ranking performed best among several token - based distance metrics , and that a tuned afﬁne - gap edit - distance metric pro - posed by Monge and Elkan performed best among several string edit - distance metrics . A surprisingly good distance metric is a fast heuristic scheme , proposed by Jaro ( Jaro 1995 ; 1989 ) and later extended by Winkler ( Winkler 1999 ) . This works almost as well as the Monge - Elkan scheme , but is an order of magnitude faster . One simple way of combining the TFIDF method and the Jaro - Winkler is to replace the exact token matches used in TFIDF with approximate token matches based on the Jaro - Winkler scheme . This combination performs slightly bet - ter than either Jaro - Winkler or TFIDF on average , and oc - casionally performs much better . It is also close in perfor - mance to a learned combination of several of the best metrics considered in this paper . Acknowledgements The preparation of this paper was supported in part by Na - tional Science Foundation Grant No . EIA - 0131884 to the National Institute of Statistical Sciences and by a contract from the Army Research Ofﬁce to the Center for Computer 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 m a x F 1 o f l ea r ned m e t r i c max F1 of other distance metric vs Monge - Elkan vs Jaro - Winklervs TFIDFvs SFS vs SoftTFIDFy = x 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 a v g P r e c o f l ea r ned m e t r i c avgPrec of other distance metric vs Monge - Elkan vs Jaro - Winklervs TFIDFvs SFS vs SoftTFIDFy = x 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 0 0 . 2 0 . 4 0 . 6 0 . 8 1 P r e c i s i on Recall SoftTFIDF Learned metric Figure 5 : Relative performance of best distance measures of each type on matching problems , relative to a learned combination of the same measures . and Communications Security with Carnegie Mellon Uni - versity . References Belin , T . R . , and Rubin , D . B . 1997 . A method for calibrating false - match rates in record linkage . In Record Linkage – 1997 : Proceedings of an International Workshop and Exposition , 81 – 94 . U . S . Ofﬁce of Management and Budget ( Washington ) . Bilenko , M . , and Mooney , R . 2002 . Learning to combine trained distance metrics for duplicate detection in databases . Technical Report Technical Report AI 02 - 296 , Artiﬁcial Intel - ligence Lab , University of Texas at Austin . Available from http : / / www . cs . utexas . edu / users / ml / papers / marlin - tr - 02 . pdf . Cohen , W . W . , and Richman , J . 2002 . Learning to match and cluster large high - dimensional data sets for data integration . In Proceedings of The Eighth ACM SIGKDD International Confer - ence on Knowledge Discovery and Data Mining ( KDD - 2002 ) . Cohen , W . W . 2000 . Data integration using similarity joins and a word - based information representation language . ACM Transac - tions on Information Systems 18 ( 3 ) : 288 – 321 . Dagan , I . ; Lee , L . ; and Pereira , F . 1999 . Similarity - based models of word cooccurrence probabilities . Machine Learning 34 ( 1 - 3 ) . Durban , R . ; Eddy , S . R . ; Krogh , A . ; and Mitchison , G . 1998 . Biological sequence analysis - Probabilistic models of proteins and nucleic acids . Cambridge : Cambridge University Press . Fellegi , I . P . , and Sunter , A . B . 1969 . A theory for record linkage . Journal of the American Statistical Society 64 : 1183 – 1210 . Galhardas , H . ; Florescu , D . ; Shasha , D . ; and Simon , E . 2000 . An extensible framework for data cleaning . In ICDE , 312 . Hernandez , M . , and Stolfo , S . 1995 . The merge / purge problem for large databases . In Proceedings of the 1995 ACM SIGMOD . Jaro , M . A . 1989 . Advances in record - linkage methodology as applied to matching the 1985 census of Tampa , Florida . Journal of the American Statistical Association 84 : 414 – 420 . Jaro , M . A . 1995 . Probabilistic linkage of large public health data ﬁles ( disc : P687 - 689 ) . Statistics in Medicine 14 : 491 – 498 . Joachims , T . 2002 . Learning to Classify Text Using Support Vec - tor Machines . Kluwer . Lafferty , J . , and Zhai , C . 2001 . A study of smoothing methods for language models applied to ad hoc information retrieval . In 2001 ACM SIGIR Conference on Research and Development in Information Retrieval ( SIGIR ) . Larsen , M . 1999 . Multiple imputation analysis of records linked using mixture models . In Statistical Society of Canada Proceed - ings of the Survey Methods Section , 65 – 71 . Statistical Society of Canada ( McGill University , Montreal ) . McCallum , A . ; Nigam , K . ; and Ungar , L . H . 2000 . Efﬁcient clus - tering of high - dimensional data sets with application to reference matching . In Knowledge Discovery and Data Mining , 169 – 178 . Monge , A . , and Elkan , C . 1996 . The ﬁeld - matching problem : algorithm and applications . In Proceedings of the Second Inter - national Conference on Knowledge Discovery and Data Mining . Monge , A . , and Elkan , C . 1997 . An efﬁcient domain - independent algorithm for detecting approximately duplicate database records . In The proceedings of the SIGMOD 1997 workshop on data min - ing and knowledge discovery . Pasula , H . ; Marthi , B . ; Milch , B . ; Russell , S . ; and Shpitser , I . 2002 . Identity uncertainty and citation matching . In Advances in Neural Processing Systems 15 . Vancouver , British Columbia : MIT Press . Raman , V . , and Hellerstein , J . 2001 . Potter’s wheel : An interac - tive data cleaning system . In The VLDB Journal , 381 – 390 . Ristad , E . S . , and Yianilos , P . N . 1998 . Learning string edit distance . IEEE Transactions on Pattern Analysis and Machine Intelligence 20 ( 5 ) : 522 – 532 . Tejada , S . ; Knoblock , C . A . ; and Minton , S . 2001 . Learning ob - ject identiﬁcation rules for information integration . Information Systems 26 ( 8 ) : 607 – 633 . Winkler , W . E . 1999 . The state of record linkage and cur - rent research problems . Statistics of Income Division , In - ternal Revenue Service Publication R99 / 04 . Available from http : / / www . census . gov / srd / www / byname . html .