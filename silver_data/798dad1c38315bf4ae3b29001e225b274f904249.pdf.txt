Cyber Situation Awareness as Distributed Socio - Cognitive Work Michael Tyworth a * , Nicklaus A . Giacobe a , Vincent Mancuso a a College of Information Sciences & Technology / The Pennsylvania State University , 101M IST Building , University Park , PA 16802 ABSTRACT A key challenge for human cybersecurity operators is to develop an understanding of what is happening within , and to , their network . This understanding , or situation awareness , provides the cognitive basis for human operators to take action within their environments . Yet developing situation awareness of cyberspace ( cyber - SA ) is understood to be extremely difficult given the scope of the operating environment , the highly dynamic nature of the environment and the absence of physical constraints that serve to bound the cognitive task 23 . As a result , human cybersecurity operators are often “flying blind” regarding understanding the source , nature , and likely impact of malicious activity on their networked assets . In recent years , many scholars have dedicated their attention to finding ways to improve cyber - SA in human operators . In this paper we present our findings from our ongoing research of how cybersecurity analysts develop and maintain cyber - SA . Drawing from over twenty interviews of analysts working in the military , government , industrial , and educational domains , we find that cyber - SA to be distributed across human operators and technological artifacts operating in different functional areas . 1 . INTRODUCTION A key challenge for human cybersecurity operators is to develop an understanding of what is happening within , and to , their network . This understanding , or situation awareness , provides the cognitive basis for human operators to take action within their operating environments . Yet developing situation awareness of cyberspace – or cyber - SA – is understood to be extremely difficult given the scope of the operating environment , the highly dynamic nature of the environment and the absence of physical constraints that serve to bound the cognitive task 23 . As a result , human cybersecurity operators are often “flying blind” in terms of their understanding of the source , nature , and likely impact of malicious activity on their networked assets . In recent years , many scholars have dedicated their attention to finding ways to improve cyber - SA in human operators . In this paper we present findings from our ongoing research on cyber - SA . Analysis of over twenty interviews of analysts working in the military , government , industrial , and educational sectors , reveals cyber - SA to be distributed across human operators and technological artifacts operating in different functional areas . Operators within these domains typically have limited awareness of the state of other domains and this limited awareness degrades their own internal - domain awareness . The development of tools acting as boundary objects that facilitate cross boundary information sharing is likely to improve both intra - and inter - domain SA . This paper begins with a discussion of situation awareness theory and cyber - SA as a cognitive phenomenon . Particular attention is paid to how situation awareness theory has been applied to cybersecurity research and some of the issues that have arisen . The paper then details the research design , data collection and analysis ; followed by presentation of the findings and their implications for future research . 1 . 1 . Situation Awareness & Cyber Situation Awareness Situation awareness ( SA ) is a cognitive phenomenon that has received widespread attention in cognitive science , human factors , and human - computer interaction scholarship . In lay terms , situation awareness is the understanding of what is going on around you . Situation awareness has been studied in multiple contexts including aircraft piloting 8 , air traffic control 10 , ship navigation 19 , emergency response 4 , C4i systems 13 and surgical teams 2 . Situation awareness is more precisely defined by cognitive theory . The most widely adopted theoretical definition of SA is Endsley’s 9 “3 - Level” model which describes SA as an internal cognitive state that can exist at one of three levels : the perception of task - salient cues in the environment ( Level 1 ) ; the comprehension of the meaning of those cues ( Level 2 ) , and the projection of what action to take to achieve a * mtyworth @ ist . psu . edu ; phone : 000 - 814 - 867 - 2154 ; ist . psu . edu Cyber Sensing 2012 , edited by Igor V . Ternovskiy , Peter Chin , Proc . of SPIE Vol . 8408 , 84080F · © 2012 SPIE · CCC code : 0277 - 786X / 12 / $ 18 · doi : 10 . 1117 / 12 . 919338 Proc . of SPIE Vol . 8408 84080F - 1 tsk . yd , m Foco ' Er w Ir±lv1 Fcfoi ¼ SITUA ION AWANES5 cw C , liøP ! I L J p DlAOJ , aOI 1IJ * J1Sf . k , fl Cl ' I I 2 / desired future environmental state based on that comprehension ( Level 3 ) . For example , an intrusion detection analyst who detects a host on the network “beaconing” ( transmitting data a regular interval ) to an unknown host outside the network can be thought of as having Level 1 SA ( perception ) . If the analyst correct determines whether the activity is malicious or benign they have Level 2 SA ( comprehension ) . Finally , if the analyst takes the correct action based on their comprehension – blocking the traffic if malicious / allowing if benign – they have achieved Level 3 SA ( projection ) . The higher the level of SA , the more likely the human operators is to take the appropriate action ; conversely a lack of SA is associated with operator error 26 , 33 . Figure 1 The " 3 - Level " Model of Situation Awareness ( Endsley 1995 , 2000 ) The 3 - Level model of SA has been described as the cognitive perspective of SA 29 . Stanton et al . describe the Endsley model of SA as the cognitive perspective because it locates SA as occurring strictly within the mind of the human operator . Technologies mediate human SA but do not have SA . Though the cognitive perspective is by far the most widely adopted perspective of SA , Stanton et al . identify two other theoretical perspective of SA : ( 1 ) the technological perspective ; and ( 2 ) the distributed perspective . The technological perspective of SA is the converse of the cognitive perspective : The technological perspective holds that SA is located in technological artifacts in the form of information . For example , most smart phones today house information about their location ( via GPS ) , their status , the local time , remaining battery life , etc . The analytical focus of research that adopts the technological perspective of SA is on extracting the SA in the artifact and on how best to represent that stored information in a way that is useful to the human operator . The distributed perspective of SA incorporates elements of distributed cognition theory and treats SA as distributed across both human actors and technological artifacts comprising a larger socio - technical system ; the extent to which SA is shared is determined by the amount of overlap there is task overlap . Thus the distributed perspective of SA represents a systems level ( rather than individual or technological ) perspective with an analytical focus on the ways in which information is represented , transformed , and manipulated across the system ( rather than on perception , comprehension , and projection ) 30 . 1 . 2 . Cyber Situation Awareness ( cyber - SA ) Cyber situation awareness – or cyber - SA – is term that has been coined by cybersecurity researchers to describe SA of cyberspace as it relates to cybersecurity . What cyber - SA is exactly , however , remains unclear . Some scholars have argued that cyber - SA is a unique form of situation awareness because of the unique characteristics of the operating environment : a rapid rate of environmental change , an overwhelming volume of information , and the lack of physical world constraints 34 , 35 . Others have described cyber - SA in terms of what the human operator should be aware of . For Proc . of SPIE Vol . 8408 84080F - 2 example , Barford et al . 3 describe SA as consisting of awareness of “the current situation , impact of the attack , evolution of the situation , adversary behavior , basis for situation , the quality of the available information , and any plausible future situations . ” Others define cyber - SA in terms of categories of awareness such as ‘health of the network , ’ ‘potential risks , ’ and ‘sources of data 22 . ’ In practice however , cyber - SA and ‘traditional’ SA are treated as conceptually indistinct . Most cybersecurity research on SA directly adopts the Endsley model ; defining SA as perception , comprehension , and projection . Some have extended this definition to incorporate specific features of the cyber environment / cybersecurity task 22 , 32 ; but from at the cognitive level , SA is still limited to perception , comprehension and projection . There are two likely reasons for the popularity of the 3 - Level model of SA in cybersecurity research . First , as discussed previously , the 3 - Level model is well suited to quantitative measurement , and therefore provides a basis for assessing system performance . Second , the 3 - Level model is conceptually very similar to the JDL Data Fusion Process model which informs much of the work on cybersecurity . The conceptual ambiguity regarding cyber - SA poses at least three challenges . First , if the cyber - environment is unique in the cognitive challenges it pose then we should expect that SA , as a cognitive phenomenon , should be different from SA in other operating environments such as aviation . Second , some conceptualizations of cyber - SA conflate concepts . Consider for example the aspects of cyber - SA described by Barford et al : ‘impact of the attack , ’ ‘evolution of the situation’ and ‘quality of information’ all describe situation assessment rather than situation awareness . Finally , as discussed earlier , the 3 - Level model is the cognitive perspective of SA in which SA is located exclusively within the human mind . Yet much of the literature uses the 3 - Level model to describe system performance – the technological perspective 3 . Indeed , in much of this literature the human operator is an abstract concept that is acknowledged but not evaluated . The human operator , however , is fundamental to any cybersecurity system . The most advanced cybersecurity operations require human operators to make decisions about the nature of network activity . User activity is often the main point of entry for malware and point of exposure to networked assets . Human adversaries – be they individuals , groups , organizations , or nation states – are the producers of malware , originators of attacks , and are motivated for many reasons . Given the centrality of human socio - cognitive work to cybersecurity , a human - in - the - loop perspective is critical to studying and understanding cyber - SA . A human - in - the - loop perspective seeks to understand the human operators within the broader socio - technical system . It is this perspective that guided this research . 2 . RESEARCH DESIGN This research employs the Living Laboratory Framework ( LLF ) to guide data collection and analysis . The LLF is a problem - based , ecological , approach to cognitive engineering that seeks to inform theory and produce experimental findings grounded in real - world context ; then applying those findings to the design and evaluation of information and communications technologies 24 . Laboratory - based experimental research allows for the controlled study of the underlying cognitive phenomena while empirical field work provides an understanding of how the socio - cognitive work is performed in practice . 2 . 1 . The Living Laboratory Framework There are four activities that comprise the Living Laboratory Framework : ( 1 ) ethnography , ( 2 ) knowledge elicitation , ( 3 ) experiments using scaled - world simulations , and ( 4 ) the development and evaluation of reconfigurable prototypes . Ethnographic observation is used to capture cognition and collaboration ‘in the wild ( Michael D . McNeese , 1996 ) . ’ Ethnographic study consists of the investigator ( s ) observing users of systems in their actual work settings in an effort to understand the critical ways in which context impacts the interpretation of work and information . Insights gained during ethnographic observation are then used to guide more structured cognitive fieldwork and the development of high - fidelity scenarios for use in the scaled - world simulator . Knowledge elicitation – or cognitive fieldwork – supports the modeling and testing of both theory and technology 21 . Collection of contextual data is done using established cognitive field research tools such as concept mapping and cognitive task analyses . Data collected in the field is used to inform both theory development and the development of realistic scenarios for use in scaled - world simulations where participants engage in ambiguous , incompletely understood situations of the type we find in cybersecurity . Findings from experiments using the simulations serve as a basis for the development or modification of ICT prototypes , which can then be reintroduced into the field for evaluation . Proc . of SPIE Vol . 8408 84080F - 3 1Ethnog aphic Study Knowledge Elicitation Theory models < - 1 / Problem - based Appach Reconfigurable Prototypes } Practice i . . , Scaled World ' Simulations Figure 2 - The Living Laboratory Framework ( McNeese , 1996 ) Since many of the other portions of the Living Lab Framework rely on qualitative methods , it can be difficult to hone in on specific constructs that may be of interest . It is very difficult to use valid field measurements to extrapolate an understanding of what is going on , without interrupting the operational workflow . Moreover , during interviews , one is forced to rely on retrospective accounts and the collection of data in a non - controllable environment in which there are numerous potential confounds that can occur simultaneously . Scaled - world simulations allow researchers to mimic the real environment and control for particular things that they are interested on . Additionally , scaled - world experiments are typically conducted in a laboratory setting , which allow for richer data to be collected via observations , performance measures , surveys and interviews . Finally , reconfigurable prototypes are developed based on the findings from the prior three activities and reintroduced to the field for evaluation . 2 . 2 Data Collection Data collection for this research consisted of 23 semi - structured interviews of cybersecurity professionals and ethnographic observation of United States Military Academy cadets competing in the 2011 Cyber - Defense Exercise run by the National Security Agency . Semi - structured interviews are an established knowledge - elicitation technique and are useful for directed inquiry into a particular subject while simultaneously providing the flexibility to pursue emergent subjects that are of interest 5 , 27 , 28 . Interviews were one - hour in duration . The interview protocol consisted of 23 questions designed to elicit data in four areas of activity : routine work activity ; the cognitive processes associated with cybersecurity work ; the data , information , and technological tools used in cybersecurity operations ; and the influence of organizational context ( e . g . , culture , policy , work environment ) on cybersecurity operations . Domain # of Interviews Military 14 Government 4 Education 5 Table 1 Interviews Quantified One goal of the data collection was to get as broad a perspective on cybersecurity operations as possible on the assumption that different organizational domains would likely have unique cybersecurity concerns . To achieve this goal , informants were chosen from three different organizational domains : military , government , and education . In addition to providing a broader picture of cybersecurity work than could be attained by taking subjects from a single domain , selecting subjects from multiple domains served to triangulate data sources ; thus reducing the subjective bias of any one informant and increasing the validity the findings 16 , 17 . In addition to performing semi - structured interviews we conducted ethnographic observations of the United States Military Academy participating in the 2011 Cyber Defense Exercise ( CDX ) . Our ethnographic observations were conducted by three researchers over a period of two days . The research team members focused their observations on cyber - SA dynamics ( perception , comprehension , and projection ) among individual team members ; the information technologies the cadets relied on the most to detect , analyze , and understand intrusions ; and intergroup communication Proc . of SPIE Vol . 8408 84080F - 4 ntrusion Detection Threat Analysis cyLandscape Operations related to intrusion detection and response . After each observation session the team debriefed and compared notes . All data was digitally codes and transcribed using nVivo qualitative analysis software . 3 . FINDINGS Two findings emerged from our analysis of the knowledge elicitation and ethnographic data . First , cyber - SA is distributed across individuals and technological agents in different operational domains . Second , improving cross - domain cyber - SA requires effective ‘boundary objects’ to facilitate collaboration among individuals who may not share an operational language . 3 . 1 . Cyber - SA is distributed , incomplete , and domain - specific Analysis of the interview data revealed cyber - SA to be distributed across different operational domains ; is specific to the operational domain ; and is often incomplete . Most research on cyber - SA has focused on intrusion detection ; yet the interviews revealed that intrusion detection is only one component of a larger cybersecurity system . Four operational domains were identified in the data : intrusion detection , policy and management , threat landscape analysis , and operations . Operators in these domains tended to have limited , domain - specific , situation awareness . For example , the IDS analysts interviewed consistently observed that their lack of knowledge about the other operational domains – in the threat landscape analysis and operations domains – reduced their effectiveness at preventing unauthorized traffic from passing across their network . One analyst described how their lack of knowledge of the physical layout of the network they were monitoring hampered their ability to identify unknown traffic as benign or malicious . IDS analysts also complained that a better understanding of the threat landscape would help them be more proactive in searching for unclassified malicious activity on their networks . Similarly , the policymakers that were interviewed complained that they often had difficulty ascertaining how much malicious activity was being directed towards their network because the IDS analysts only reported successful breaches of the network Figure 3 Functional Domains of Cybersecurity In all operational domains , human operators were reliant upon both software agents and their human colleagues to develop an understanding of what was happening on the network . For example , IDS agents relied upon logs from their sensors to develop a picture of what was flowing across the network ; but also regularly had to collaborate with their colleagues and the managers of the networks to determine the nature of unknown traffic . Similarly , forensic analysts use a combination of log data and the user’s description of system behavior to investigate the nature of the compromise and correct solution . This reliance upon both technological agents and human collaborators was also visible within the cadet CDX team . Cadets would regularly identify traffic or a file that appeared suspicious and seek confirmation from their colleagues , often from different operational areas . Proc . of SPIE Vol . 8408 84080F - 5 With operators working in different functional domains and having domain - specific SA , the challenge is to develop processes and technologies that facilitate inter - domain collaboration 25 . The interviews revealed that these ‘boundary objects’ are underdeveloped or ineffective in today’s environment . 3 . 2 . Effective boundary objects are necessary for cross - domain cyber - SA The functional domains of cybersecurity are separated by both physical and virtual boundaries . Human operators working in these domains can be considered communities of practice ; each with their own knowledge , terminologies , and practices . These communities of practice are rarely collocated in large enterprises , and may not even work for the same organizations . The boundaries separating the functional domains are opaque ; and task - salient information is only able to only partially pass through the boundaries . As a result , individuals’ domain - specific cyber - SA is degraded as a result of lacking key information or knowledge from other domains . Boundary objects are a way for these communities of practice to collaborative work and hence share cyber - SA . Boundary objects theory describes how different communities of practice , with their own terminologies , foci , and understandings are able to collaborate on scientific work 31 . Boundary objects theory posits that communities of practice are able to collaborate because there are objects that span the boundaries of the community that are at once rigid enough in form to be commonly understood by all communities , and plastic enough to be uniquely understood by each community . Star originally proposed four archetype boundary objects : repositories ( such as libraries & database ) , forms , terrain with coincident boundaries ( such as maps ) , and ideal / platonic objects such as models . Central to the concept of a boundary object was that there was in all boundary objects some degree of standardization that allowed the object to be commonly understood by different communities by establishing common terminology . Since it was introduced , boundary object theory has been applied to the study of computer - supported cooperative work , aircraft maintenance , product design , and inter - organizational information sharing 1 , 12 , 18 , 20 . In the settings we examined , task - salient information crosses domain boundaries typically in the form of standardized reports . The reports codified incident information in a standardized form that was then used in unique ways by operators in the different functional domains . Intrusion detection analysts used the standardized reports in three ways . One , the report served as a way to track the status of an incident . Two , the report was how the analysts communicated to their customers and their own management team information about incidents of malicious activity that has been identified . Three , in archived form , the reports served as a knowledge repository that could be consulted by analysts researching suspicious , but previously unidentified traffic . Standardized forms are useful boundary objects but ultimately are limited in at least three ways . First , standardized forms take time to complete and represent the situation as it was in the past rather than present . Second , as discussed previously , standardized reports were typically filed only when an actual intrusion occurred . Indeed there was strong cultural pressure on analysts to not file reports for relatively trivial matters . Yet , as our informants revealed , there is much to be learned from routine activity or blocked intrusions that go unreported . Third , standardized reports are fixed in form and thus are not conducive to customized representation and manipulation . Our research suggests that cybersecurity requires customizability rather than standardization across boundaries , echoing Lee’s 18 earlier argument for viewing boundary objects as boundary - negotiating artifacts . The individuals working in the different functional domains need access to information in other domains , but in a way that they can customize to their own operational purposes . For example , the policymaker needs information on intrusion activity but at a much higher level than that which the intrusion detection analysts need . Similarly , administrators working in the operational domain need information about the latest exploits and vulnerabilities of the type available on open source intelligence websites but in actionable form rather than in the signature form useful to IDS analysts . Proc . of SPIE Vol . 8408 84080F - 6 u . . ' , . S $ M2 21120 lst0cM . Im . LI l0IRC2L II % ULER II IIIfl0tSLfr - WI I WI II . SRC # d . ER S * l0 . fl 4 ) 20 L . tfr ' I M b , afl . c ' J - - - - - - - _ _ _ I - Figure 4 - Prototype Visual Analytics Toolkit for Cybersecurity Drawing on the insights gained from the knowledge elicitation and ethnographic data , work has begun on developing a prototype visual - analytic tool capable that fuses data from different operational domains and presents in both standard and domain - specific form 14 . Based on the GeoViz Toolkit , the visualization fuses data from both hard and soft sensors and presents it in multiple formats dependent on user needs . Experiments are currently being designed to assess the impact of the visualization tool on users’ abilities to develop and maintain cyber - SA . 4 . IMPLICATIONS FOR FUTURE RESEARCH The findings presented here have at least three implications for future cyber - SA research . One the distributed nature of cybersecurity and cyber - SA suggests that the distributed perspective of SA may more accurately capture the nature of cyber - SA . In particular , the distributed perspective’s analytical emphasis on capturing the flow of information and awareness through the larger system would seem to closely resemble what we observed . It should be noted , however , that our findings do not imply that the 3 - Level model , or cognitive perspective , should be abandoned . Certainly the 3 - Level model has great utility for continued research on intrusion detection and threat identification . Rather , we suggest that a distributed perspective in complement to a cognitive perspective may yield the greatest insight into cyber - SA as a cognitive phenomenon . Second , the breakdown in information flows across organizational boundaries suggests that focusing exclusively on a single domain such as intrusion detection will limit our ability to understand and improve cybersecurity as it is practiced . More importantly , it is critical that in order to improve cybersecurity practice , we develop a better understanding of the socio - cognitive work of the human actor in cybersecurity operations . Finally , these findings suggest that there is opportunity to positively impact cybersecurity practice through the development of information visualizations capable of presenting cross - domain information for domain specific purposes . This finding echoes those of prior work 6 , 7 , 11 , 15 . If cybersecurity is to change from being a largely reactive endeavor to a proactive defense , better access to real time data by analysts in all operational domains will be critical . Proc . of SPIE Vol . 8408 84080F - 7 REFERENCES [ 1 ] M . S . Ackerman and C . Halverson , " Organizaitonal Memory : Processes , Boundary Objects , and Trajectories , " Proc . 32nd Annual Hawaii International Conference on System Sciences ( HICSS ' 99 ) , ( 1999 ) . [ 2 ] J . E . Bardram , et al . , " AwareMedia : a shared interactive display supporting social , temporal , and spatial awareness in surgery , " Proc . Proceedings of the 2006 Conference on Computer Supported Cooperative Work , 109 - 118 ( 2006 ) . [ 3 ] P . Barford , et al . , [ Cyber SA : Situational Awareness for Cyber Defense - Issues and Research ] , Springer , New York , 3 - 14 ( 2010 ) . [ 4 ] A . Blandford and W . Wong , " Situation awareness in emergency medical dispatch , " International Journal of Human - Computer Studies , 61 ( 4 ) , 421 - 452 ( 2004 ) . [ 5 ] N . J . Cooke , " Varieties of knowledge elicitation techniques , " International Journal of Human - Computer Studies , 41 ( 6 ) , 801 - 849 ( 1994 ) . [ 6 ] A . D ' Amico and M . Kocka , " Information assurance visualizations for specific stages of situational awareness and intended uses : lessons learned , " Proc . IEEE Workshop on Visualization for Computer Security ( VizSEC 05 ) , 107 - 112 ( 2005 ) . [ 7 ] A . D ' Amico and M . Larkin , " Methods of visualizing temporal patterns in and mission impact of computer security breaches , " Proc . DARPA Information Survivability Conference & Exposition II , 2001 ( DISCEX ' 01 ) , 343 - 351 vol . 1 ( 2001 ) . [ 8 ] M . R . Endsley , " A survey of situation awareness requirements in air - to - air combat fighters , " The International Journal of Aviation Psychology , 3 ( 2 ) , 157 - 168 ( 1993 ) . [ 9 ] M . R . Endsley , " Toward a Theory of Situation Awareness in Dynamic Systems , " Human Factors : The Journal of the Human Factors and Ergonomics Society , 37 ( 1 ) , 32 - 64 ( 1995 ) . [ 10 ] M . R . Endsley and M . D . Rodgers , " Situation awareness information requirements analysis for en route air traffic control , " Proc . Proceedings of the Human Factors and Ergonomics Society Annual Meeting October 1994 38 , 71 - 75 ( 1994 ) . [ 11 ] R . F . Erbacher , et al . , " A multi - phase network situational awareness cognitive task analysis , " Information Visualization , 9 ( 3 ) , 204 - 219 ( 2010 ) . [ 12 ] K . R . Fleischmann , " Boundary Objects with Agency : A Method for Studying the Design - Use Interface , " The Information Society , 22 ( 2 ) , 77 - 87 ( 2006 ) . [ 13 ] H . French and A . Hutchinson , " Measurement of situation awareness in a C4ISR experiment , " Proc . 2002 Command and Control Research and Technology Symposium , 11 - 13 ( 2002 ) . [ 14 ] N . Giacobe and S . Xu , " Geovisual Analytics for Cyber Security : Adopting GeoViz Toolkit , " Proc . IEEE Symposium on Visual Analytics Science and Technology ( VAST ) , 315 - 316 ( 2011 ) . [ 15 ] M . Gregoire and L . Beaudoin , " Visualisation for Network Situational Awareness in Computer Network Defence " , Visualization and the Common Operational Picture , < http : / / www . rto . nato . int / abstracts . asp > ( June , 2010 ) . [ 16 ] E . P . Jack and A . S . Raturi , " Lessons learned from methodological triangulation in management research , " Management Research News , 29 ( 6 ) , 345 - 357 ( 2006 ) . Proc . of SPIE Vol . 8408 84080F - 8 [ 17 ] T . D . Jick , " Mixing Qualitative and Quantitative Methods : Triangulation in Action , " Administrative Science Quarterly , 24 ( 4 ) , 602 ( 1979 ) . [ 18 ] C . P . Lee , " Boundary Negotiating Artifacts : Unbinding the Routine of Boundary Objects and Embracing Chaos in Collaborative Work , " Computer Supported Cooperative Work , 16 ( 307 - 339 ( 2007 ) . [ 19 ] J . D . Lee and T . F . Sanquist , " Augmenting the operator function model with cognitive operations : Assessing the cognitive demands of technological innovation in ship navigation , " Systems , Man and Cybernetics , Part A : Systems and Humans , IEEE Transactions on , 30 ( 3 ) , 273 - 285 ( 2000 ) . [ 20 ] W . G . Lutters and M . S . Ackerman , " Beyond Boundary Objects : Collaborative Reuse in Aircraft Technical Support , " Computer Supported Cooperative Work , 16 ( 3 ) , 341 - 372 ( 2007 ) . [ 21 ] A . M . MacEachren , et al . , " GeoCollaborative Crisis Management : Designing Technologies to Meet Real - World Needs , " Proc . 7th Annual National Conference on Digital Goernment Research ( dg . o . 2005 ) , 71 - 72 ( 2006 ) . [ 22 ] S . Mahoney , et al . , " A Cognitive Task Analysis for Cyber Situational Awareness , " Proceedings of the Human Factors and Ergonomics Society Annual Meeting , 54 ( 4 ) , 279 - 283 ( 2010 ) . [ 23 ] E . McMillan and M . Tyworth , [ An Alternative Framework for Research on Situational Awareness in Computer Network Defense ] , IGI Global , New York , 5 , 71 - 85 ( 2012 ) . [ 24 ] M . D . McNeese , et al . , " Advancing Socio - Technical Systems Design Via the Living Laboratory , " Proceedings of the Human Factors and Ergonomics Society Annual Meeting , 44 ( 12 ) , 2 - 610 - 2 - 613 ( 2000 ) . [ 25 ] J . Okolica , et al . , " Developing Systems for Cyber Situational Awareness " , < http : / / www . csc . latech . edu / Web % 20Attachments / 2009 - crw - proceedings . pdf # page = 52 > ( 2012 ) . [ 26 ] C . Perrow , [ Normal Accidents : Living with High - Risk Technologies ] , Princeton University Press , Princeton , NJ , ( 1999 ) . [ 27 ] B . H . Russell , [ Social research methods : qualitative and quantitative approaches ] , Sage Publications , Thousand Oaks , Calif . , ( 2000 ) . [ 28 ] J . P . Spradley , [ The ethnographic interview ] , Holt , Rinehart and Winston , New York , ( 1979 ) . [ 29 ] N . A . Stanton , et al . , " Is situation awareness all in the mind ? , " Theoretical Issues in Ergonomics Science , 11 ( 1 - 2 ) , 29 - 40 ( 2009 ) . [ 30 ] N . A . Stanton , et al . , " Distributed situation awareness in dynamic systems : theoretical development and application of an ergonomics methodology , " Ergonomics , 49 ( 12 - 13 ) , 1288 - 1311 ( 2006 ) . [ 31 ] S . L . Star , [ The Structure of Ill - Structured Solutions : Boundary Objects and Heterogeneous Distributed Problem Solving ] , Morgan Kaufman , Menlo Park , CA , 36 - 54 ( 1989 ) . [ 32 ] G . P . Tadda and J . S . Salerno , [ Overview of Cyber Situation Awareness ] , Springer US , 2 , 15 - 35 ( 2010 ) . [ 33 ] J . Wise , " What Really Happened Aboard Air France 447 " , Popular Mechanics , December 6 , 2011 , < http : / / www . popularmechanics . com / technology / aviation / crashes / what - really - happened - aboard - air - france - 447 - 6611877 > ( December 10 , 2011 ) . [ 34 ] S . J . Yang , et al . , " Intrusion activity projection for cyber situational awareness , " Proc . IEEE International Conference on Intelligence and Security Informatics ( ISI 2008 ) , 167 - 172 ( 2008 ) . [ 35 ] S . J . Yang , et al . , " High level information fusion for tracking and projection of multistage cyber attacks , " Information Fusion , 10 ( 1 ) , 107 - 121 ( 2009 ) . Proc . of SPIE Vol . 8408 84080F - 9