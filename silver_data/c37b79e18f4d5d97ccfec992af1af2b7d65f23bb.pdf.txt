Conceptual Combination with PUNC Dermot Lynott , Georgios Tagalakis and Mark T . Keane Department of Computer Science , University College Dublin , National University of Ireland Abstract . Noun - noun compounds play a key role in the growth of language . In this article we present a system for Producing and Understanding Noun - Noun Com - pounds ( PUNC ) . PUNC is based on the Constraint theory of conceptual combination and the C 3 model . The new model incorporates the primary constraints of the Con - straint theory in an integrated fashion , creating a cognitively plausible mechanism of interpreting noun - noun phrases . It also tries to overcome algorithmic limitations of the C 3 model in being more e(cid:14)cient in its computational complexity , and deal with a wider span of empirical phenomena , such as dimensions of word familiarity . We detail the model , including knowledge representation and interpretation pro - duction mechanisms . We show that by integrating the constraints of the Constraint theory of conceptual combination and prioritizing the knowledge available within a concept’s representation , PUNC can not only generate interpretations that re(cid:13)ect those produced by people , but also mirror the di(cid:11)erences in processing times for understanding familiar , similar and novel word combinations . Keywords : conceptual combination , diagnosticity , familiarity , plausibility , infor - mativeness , noun - noun compounds 1 . Introduction Conceptual combinations are manifested in everyday language through compound phrases ( e . g . , trash cookies , sausage meat , jail job ) . These combinations have received special attention in Cognitive Science be - cause of their relevance to compositionality , language generativity and language change in general ( see Clark and Hecht , 1982 ; Coulson , 2001 ; Estes and Glucksberg , 2000 ) . Research in this (cid:12)eld has thrown up a number of competing models of conceptual combination , each of which tries to capture the main empirical phenomena in the (cid:12)eld . In the next section we review two current theories of conceptual combination before concentrating on the Constraint theory and a new algorithmic instantiation of that theory : PUNC ( Producing and Under - standing Noun - Noun Compounds ) . PUNC uses the primary constraints of the Constraint theory ( diagnosticity , informativeness and plausibil - ity ) to generate a set of interpretations for any noun - noun compound , ranking them by their overall goodness . PUNC also deals with a wider span of empirical phenomena , including e(cid:11)ects of familiarity on the comprehension process . c (cid:13) 2004 Kluwer Academic Publishers . Printed in the Netherlands . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 1 2 Lynott , Tagalakis and Keane 2 . Background Literature There are three main theories that endeavor to explain the compre - hension of novel compounds ; the Dual - Process theory ( Wisniewski , 1996 ; Wisniewski , 1997 ; Wisniewski and Love , 1998 ) , the Competition Among Relations in Nominals theory ( Gagn(cid:19)e and Shoben , 1997 ; Shoben and Gagn(cid:19)e , 1997 ) and the Constraint theory ( Costello and Keane , 1997 ; Costello and Keane , 2000 ; Keane and Costello , 2001 ) . Each of these the - ories propose di(cid:11)erent mechanisms and di(cid:11)erent interactions between the modi(cid:12)er and head concepts ( i . e . , the (cid:12)rst and second elements of a compound , respectively ) of a noun - noun compound . The Dual - Process approach ( Wisniewski , 1996 ; Wisniewski , 1997 ; Wisniewski and Love , 1998 ) is designed to account for the two major categories of interpretation that people produce to compounds ; rela - tional and property interpretations . The Dual - Process theory proposes two mechanisms for understanding noun - noun compounds . The (cid:12)rst is a scenario creation and concept specialization process that gives rise to interpretations that are linked by a relation ( e . g . , a robin snake is \ a snake that eats robins " , where the head concept snake is specialized by the modi(cid:12)er concept robin using the head’s slot eats things ) . The second is a process of analogy and alignment ( cf . Forbus et al . , 1994 ; Keane et al . , 1994 ) that gives rise to interpretations that involve transferring a property or a set of properties from one concept ( typically from the modi(cid:12)er ) to the other concept ( typically to the head ; e . g . , a robin snake is \ a snake with a red breast " , where the property of having a red breast is transferred from robin to snake ) . Unfortunately , Wisniewski ( 1996 , 1997 ) has never produced an implemented model of Dual - Process the - ory and have left open the methods by which processing might switch between the interpretation strategies . The Competition Among Relations in Nominals ( CARIN ) model ( Gagn(cid:19)e and Shoben , 1997 ; Gagn(cid:19)e , 2000 ; Shoben and Gagn(cid:19)e , 1997 ) proposes that the relations used in interpretations are selected from a set of thematic relations that are associated with the modi(cid:12)er word from previous known compounds . For example , chocolate dog is readily understood as \ a dog made of chocolate " because made of is strongly associated with the word chocolate from many previously - known com - pounds ( e . g . , chocolate bar , chocolate cake , chocolate egg ) . The CARIN model makes predictions on ease of understanding novel compounds , based on a corpus analysis of the relations between the constituents of previously encountered compounds . This information is then encoded in a mathematical choice model . This model also posits that property - based interpretations are rare , more di(cid:14)cult to understand and that people are far more likely to produce interpretations that use relations ; AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 2 Conceptual Combination with PUNC 3 what Tagalakis and Keane ( manuscript in submission ) have called \ the relational prominence hypothesis " . While CARIN is very interesting , it has a narrow focus and does not explain how initial or new relational interpretations arise . Also , the relational prominence it assumes has proven to be a very controversial issue ( see Bock and Clifton , 2000 ; Costello and Keane , 1997 ; Tagalakis and Keane , 2003 ; Wisniewski and Love , 1998 ) . The Constraint theory of conceptual combination overcomes many of the obstacles of the previous models by proposing a unitary uni - (cid:12)cation mechanism to generate interpretations ( Costello and Keane , 1997 ; Costello and Keane , 2000 ; Costello and Keane , 2001 ; Keane and Costello , 2001 ) . It can account for the production of both relational and property interpretations from a unitary generative mechanism that produces all possible interpretations that are subsequently (cid:12)ltered by the constraints of diagnosticity , plausibility , and informativeness . Fur - thermore , the theory has been fully implemented and has been shown to parallel many aspects of people’s behavior . In the following section , we give an overview of the Constraint theory and the C 3 model , detailing its advantages over previous theories , but also its shortcomings . 3 . The Constraint Theory The Constraint theory is a computational - level theory for the con - ceptual combination of noun - noun compounds ( Costello and Keane , 1997 ; Costello and Keane , 2000 ; Costello and Keane , 2001 ; Keane and Costello , 2001 ) . It assumes that there is a generated space of possible meanings based on combining the predicates of the two noun concepts in all possible ways . The interactions of three constraints of diagnos - ticity , plausibility , and informativeness dictate the acceptability of the interpretations produced . Diagnosticity relates to the salience of the features of a concept . A concept’s diagnostic features best distinguish that concept from other concepts . For example , has wings is a more diagnostic feature of birds than has legs , since many creatures have legs but far fewer have wings . Diagnostic features facilitate the activation of the concepts involving these features . For example , using the feature has a trunk would call to mind elephants more easily than using the feature is grey ( Costello , 2002 ) . For this reason diagnostic features are often employed in peo - ple’s interpretations for novel compounds . The diagnosticity constraint requires that a good interpretation must , to some extent , contain diag - nostic predicates of both constituent concepts of a compound phrase . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 3 4 Lynott , Tagalakis and Keane For example , diagnosticity predicts that \ prickly (cid:12)sh " is a better in - terpretation than \ green (cid:12)sh " for the compound cactus (cid:12)sh , because prickly is a more diagnostic property of the concept cactus than its property of being green ( cf . Franks , 1995 ; Sloman et al . , 1998 ) . The plausibility constraint requires that interpretations describe some object that could plausibly exist . This means that interpretations are required to contain information that is consistent with prior experience . For example , an interpretation that refers to an entity that already exists will be completely plausible , since all of the information in the interpretation overlaps completely with a previously encountered in - stance . In this way , the plausibility of interpretations is determined by the degree to which they overlap with prior knowledge . For example , two candidate interpretations for the compound angel pig could be \ a pig with wings attached to its tail " and \ a pig with wings attached to its torso " . The latter would be considered more plausible as it is more consistent with our prior experience . Things that have wings usually have them attached to the torso , and not to their tails . In this way , plau - sibility overlaps produced interpretations with prior experience ( i . e . , speci(cid:12)c instances stored in memory ) to judge their overall goodness . Finally , the informativeness constraint requires that an acceptable interpretation should convey some new information above and beyond information of the constituent concepts . For example , to say that a bed pencil is \ a pencil made of wood " would be judged as an uninformative interpretation , as most pencils are already made of wood . In this way , interpretations adhere to important pragmatic principles ( see Grice , 1975 ) . 4 . The C 3 Model : Algorithmic Design and Limitations The C 3 model is an implementation of the Constraint theory . The model generates a space of possible meanings by forming all possible subsets of key predicates in both concepts , also taking into account a number of possible uni(cid:12)cations of them . For two concepts , with a handful of predicates , it can generate several thousand possible inter - pretations . The model then uses constraint - satisfaction techniques to (cid:12)lter out the best interpretations from this set . There are three main stages to the model’s processing cycle . First , it calculates the diagnos - ticity of a feature by comparing it the features of all other concepts in memory . For instance , if the feature prickly occurred only once ( e . g . , in the concept cactus ) then it would have a high diagnosticity score for that concept . By contrast , the feature green would have a lower diagnosticity score as it occurs in many concepts related to plants . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 4 Conceptual Combination with PUNC 5 Then a set of partial interpretations is generated based on subsets of selected diagnostic predicates of the head and modi(cid:12)er concepts . These partial interpretations are then (cid:13)eshed out by adding further predicates from similar concepts in memory . An interpretation is scored as being completely plausible if it overlaps entirely with some stored instance in the knowledge base . During this stage these partial interpretations are also elaborated with additional properties from relevant concepts in the knowledge base , but only if these additions increase the plausibility of the interpretation . At this point , each interpretation has been assigned an acceptability score based on its combined diagnosticity and plau - sibility scores . Finally , informativeness is implemented as a post - hoc (cid:12)ltering process that acts to remove interpretations from this set that do not convey a requisite amount of new information ( see Costello and Keane , 2000 , for details ) . The model tends to generate quite acceptable interpretations for the compounds , considering the inherent incompleteness of its knowledge base . Furthermore , Costello and Keane ( 2000 ) have shown that it does a good job of capturing the sort of interpretations that people tend to produce . However , C 3 is limited because it does not take into account human - like , e(cid:14)cient reasoning techniques . For example , in computing plausibil - ity C 3 compares each candidate interpretation against every concept in its knowledge base . A good model would have some way of limiting this extensive comparison process , constraining its generativity . C 3 gener - ates approximately 4 , 000 unique interpretations for a given compound , with the entire process taking from several hours to days . Obviously it would not be feasible to examine every single interpretation generated , so for simulation purposes a threshold on the overall goodness is usually set so that only the top 10 interpretations are output once processing is complete . But even with such a cut - o(cid:11) point the amount of computation required is excessive 1 . Furthermore , the model does not have natural extensions to obvious empirical phenomena and does not take experience with previous com - pounds into account . It is like a (cid:12)rst principles planner with no memory of previous plans . For example , a familiar compound ( like chocolate egg ) would be treated exactly the same way as a novel compound ( like water egg ) . Yet , it is obvious that people do not act in this way . A familiar compound is understood very quickly by some sort of fast lexical access , whereas an unfamiliar compound might require considerable re(cid:13)ection 1 For example , a simulation process for producing the 10 most acceptable inter - pretations of 24 compound phrases took almost 3 weeks running on a Macintosh LC III ( 25 MHz 68030 processor , main memory size of 33 MB , running Mac OS 7 . 6 and Macintosh Common Lisp 3 . 0 ) . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 5 6 Lynott , Tagalakis and Keane ( Tagalakis and Keane , 2003 ) . Such a compound can be stored in the mental lexicon as a single unit together with its interpretation and be recalled instantly , on demand . Familiarity e(cid:11)ects can also be manifested when people encounter a compound that is , while still novel , nonetheless similar to some existing compound . Similarity between two conceptual structures ( compounds ) is perceived relative to structure - mapping between those conceptual representations and can be de(cid:12)ned as a function of their alignable commonalities , their alignable di(cid:11)erences and their non - alignable dif - ferences ( see Markman and Gentner , 1993 ) . For example , in the familiar bullet train the shape and speed properties of the head train are instan - tiated to the values fast and streamlined having being mapped from the modi(cid:12)er bullet . When a novel compound is encountered with the same modi(cid:12)er and a similar head , like bullet car , a priming e(cid:11)ect occurs and the meaning can get rapidly constructed using the known bullet train interpretation . Hence , people will tend to understand a bullet car as \ a very fast car " and / or as \ a car shaped like a bullet " . Similarly , when a novel compound is encountered with a similar modi(cid:12)er and the same head , like missile train , a priming e(cid:11)ect occurs and the meaning can get again swiftly constructed using the known bullet train interpretation . So , a missile train will be understood as \ a very fast train " and / or as \ a train shaped like a missile " . These sorts of e(cid:11)ects seem to invite some form a distributed account of memory . Typically , theories of distributed memory focus on semantic similarity to explain priming facilitation e(cid:11)ects . An underlying assump - tion is that priming is proportional to semantic relatedness . If there is a feature overlap and the meanings are similar then the processing requirements are few ( see Thompson - Schill et al . , 1998 ) . Indeed , similar concepts can prime each other and lead to quicker response times as it has been demonstrated by McRae and Boisvert ( 1998 ) . Additionally , Shoben ( 1993 ) has pointed out that some novel compounds appear to be understood by analogy to known compounds . For example , Iran - gate will not make probably any sense without recourse to Water - gate , as the X - gate construction has come to mean \ political scandal that goes right to the top on an issue associated with X " ( see also Keane et al . , 1994 ) . From what has been said so far , it is clear that familiarity due to similarity and semantic - relatedness is a phenomenon that cannot be ignored by models of conceptual combination . In the context of C 3 , it is unclear whether this factor should be handled as a new constraint or be an emergent feature of the actions of the existing constraints . We believe that familiarity is best handled as an emergent feature , as it seems to arise naturally from the behavior of the known constraints . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 6 Conceptual Combination with PUNC 7 We have seen already that acceptable interpretations are constructed through the constrained application of diagnosticity , plausibility and informativeness . First , the diagnostic , distinctive predicates of the con - stituent concepts of the novel compound and the familiar compound are compared and selected , as in the example above . Second , plausibility will be satis(cid:12)ed as it works o(cid:11) prior knowledge ; namely , that of the known compound . If a familiar noun - noun compound is plausible then a similar novel noun - noun must be plausible too , by default ( i . e . , in the absence of contradictory semantic information ) . Following the same line of argument , the informativeness constraint would be naturally met . 5 . The PUNC Model The PUNC model is an implementation of the Constraint Theory that seeks to improve upon C 3 by reducing the amount of processing re - quired , while still producing interpretations that parallel those pro - duced by people . PUNC retains each of the three constraints of diagnos - ticity , informativeness and plausibility , but treats them not as separate processes but as intrinsic aspects of the interpretation process . The model also incorporates familiarity as a mechanism for understanding word combinations . We detail the knowledge represented in PUNC and how this knowledge can be meshed to generate interpretations . We also discuss how these changes improve PUNC’s performance compared to the C 3 model . 5 . 1 . Knowledge Representation in PUNC PUNC uses a simple ontology to represent knowledge associated with each concept . This knowledge encoded includes diverse information such as a taxonomic concept hierarchy , diagnostic features of concepts , and non - taxonomic relations of concepts to other concepts including semantic links . For example , the concept cactus is represented by di - agnostic features such as has spikes , grows in the desert , can conserve water . Since cactus also inherits features from plant , the feature re - lations can grow or can be eaten are also part of the concept’s gloss . Similarly , any concept that inherits from creature will have the feature can eat things , so speci(cid:12)c instances of creatures will also be able to eat things . Each feature is weighted by its importance relative to the concept ; so , has spikes is weighted as being one of the most important features of cactus ( e . g . , a weighting of 1 ) , while grows in the desert is weighted as being of slightly less importance ( e . g . , a weighting of 3 ) . Finally , static \ links " between concepts that are semantically similar have been de(cid:12)ned . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 7 8 Lynott , Tagalakis and Keane The establishment of links between similar concepts was based on the judgments of 3 independent people ( with an agreement 90 % - 100 % ) . The judges were blind to the purpose of the study . The knowledge base was made available to them and it was explained to them that ( i ) we assumed that similarity between two concepts is related to their feature overlap and feature di(cid:11)erences , ( ii ) that comparison between taxonomically - related concepts was not meaningful ( e . g . , similarity be - tween cactus and plant does not really make sense ) , and ( iii ) that they should try to give a \ yes " ( similar ) or \ no " ( not similar ) reply to concept pairs presented based on their intuition and on the assumption that the overall similarity of two concepts can be considered out of context as a weighted average of their similarities computed from di(cid:11)erent perspectives ( see Lin , 1998 ) . The PUNC knowledge base for single concepts was coded with - out reference to speci(cid:12)c compounds or interpretations that could be produced to them . So , weightings currently represent intuitive values for each feature of a concept , arrived at through consensus between three raters . Features that are inherited from a parent concept are not as diagnostic to the child concept ( e . g . , can photosynthesize is less diagnostic of cactus than it is of plant ) . Indeed , during classi(cid:12)cation of category members people learn to attend more to those features that help to distinguish the categories ( e . g . , Kruschke 1994 ) . Also , in general , the more abstract a concept , the lower its information content is ( cf . Resnik , 1998 ) . Therefore , inherited features are always weighted relative to the diagnostic features already present in the child concept . For example , if the feature can conserve water had a diagnosticity score of 4 , then any feature inherited from plant would have a weighting of 5 or more . Since PUNC merely represents features that are important to each concept , the knowledge represented is quite diverse , but it is all treated in the same fashion . For example , the feature has spikes ( a property ) is important for cactus , whereas the concept vet might have the feature treats animals ( a role ) or the concept chess might have the feature strategic or tactical ( a more subjective property ) . Of course the im - portance of a feature for a particular concept can change from one situation to another or from one person’s perspective to another’s , but this knowledge base gives a snapshot of this knowledge and how these concepts relate to one another . Familiar , lexicalized compounds are stored as single units in the knowledge base with hard - coded interpretations that are retrieved in - stantly \ as - is " . When there are several familiar interpretations for a given compound all of them are represented in a (cid:12)xed order of pref - erence based on separate empirical analyses of people’s interpretation AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 8 Conceptual Combination with PUNC 9 Figure 1 . PUNC’s retrieval of interpretations for compounds identi(cid:12)ed as familiar . judgements ( Lynott and Keane , manuscript in submission ; Tagalakis and Keane , 2003 ) . Each of these interpretations is structured as a se - quence of strings in the scope of the head concept . The string sequence contains a number of variable places for diagnostic features , predicates of the head concept bound to (cid:12)xed values , and a description of the connecting relation between head and modi(cid:12)er . The interpretations are by de(cid:12)nition highly plausible and informative . The constituents of these compounds are also encoded in the knowledge base , in the same fashion as other concepts ( i . e . , with the diagnostic knowledge associated with them ) , so they can also be used as elements for novel combinations as well . 5 . 2 . Algorithmic Design and Productions of Interpretations with PUNC The input to PUNC is a noun - noun combination and the output is a list of possible interpretations for that combination , ranked in terms of their overall goodness . But before a new interpretation is produced , the given compound is checked against known compounds in the knowledge base . If a match is found , the meaning can be retrieved wholesale from mem - ory and output as an interpretation . If it not found , its interpretation ( s ) is ( are ) retrieved and the results are printed out ( Figure 1 ) . If no exact match is found in the knowledge base , the compound may match with known compounds that either have the same modi(cid:12)er and a similar head or the same head and a similar modi(cid:12)er . If this occurs , then a quick construction method is attempted . This method tries to create an \ interpretation environment " for a new compound by taking into account possible familiarity e(cid:11)ects due to concepts similar to it . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 9 10 Lynott , Tagalakis and Keane Figure 2 . PUNC’s \ quick construction method " for producing interpretations for presented compounds when familiar , composite concepts similar to them are found in the knowledge base . If the two modi(cid:12)ers are found to be the same and the two heads similar , an insertion process takes place . The new head concept re - places the head of the familiar compound ( s ) and a uni(cid:12)cation process is initiated . The uni(cid:12)cation process tries to (cid:12)ll / replace the overlapping , diagnostic variables / values of the head concept of the new compound with those of the head concept of the familiar compound ( s ) , which are bound to concrete values . If the two heads are found to be the same and the two modi(cid:12)ers similar , an analogous procedure is carried out . The new modi(cid:12)er concept replaces the modi(cid:12)er of the familiar compound ( s ) and a uni(cid:12)cation process tries to (cid:12)ll / replace the overlapping , diagnostic variables / values of the modi(cid:12)er concept of the new compound with those of the modi(cid:12)er concept of the familiar compound ( s ) ( see again subsection 4 for examples of this type of familiarity emerging due to similarity and adaptation ) . If one or both of these two methods succeed , the interpretation ( s ) is ( are ) then output to the user ( Figure 2 ) . Familiar idiomatic compounds with semantically opaque , (cid:12)xed meanings are not considered 2 . 2 An idiom is recognized as a single unit and has a di(cid:11)erent meaning from the meaning of its individual words . Some idioms can accommodate some interchange - able synonyms or closely related words with di(cid:11)erent senses and still retain their prominent meaning or a similar one ( e . g . , home stretch is a quite familiar compound meaning \ the last part of the journey or race " ; a similar meaning for home strain can also be obtained ( cf . Gazdar et al . , 1985 ) . ) . Other compounds , though , cannot tolerate interchangeability with synonyms or related words without losing their prominent meaning or without becoming completely meaningless ( e . g . , health nut is \ a person who eats health foods and does exercises to become healthy " ; health seed is unlikely to be understood along the same lines - especially out of context ) . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 10 Conceptual Combination with PUNC 11 If PUNC fails to (cid:12)nd an exact or similar match for the presented compound , it attempts to construct a set of possible interpretations from scratch . The multiple interpretations produced for each com - pound parallel those normally produced by people 3 . It achieves this through a meshing of the available knowledge from the modi(cid:12)er into the knowledge of the head concept . When knowledge is meshed it can give rise to possible interactions between the head and modi(cid:12)er concepts , or to the transfer of some features of the modi(cid:12)er concept to the head . Each concept consists of a collection of features and relations to other concepts . PUNC compares the features of the modi(cid:12)er concept to those of the head to establish whether elements of both can be meshed . A simpli(cid:12)ed description of featural knowledge represented for the concepts cactus and beetle and two of their hypernyms ( plant and insect , respectively ) is given in Table I . We will use these descriptions to illustrate how knowledge is meshed to create interpretations . Since each feature encoded has an associated diagnosticity weight - ing , PUNC processes features in descending order of diagnosticity . Firstly , PUNC examines each feature in the modi(cid:12)er to see if it can be meshed with the head’s features to create interpretations . Secondly , it examines if the modi(cid:12)er itself can be used to ful(cid:12)ll some role in the knowledge represented in the head concept . As a starting point , PUNC uses the knowledge of the head concept as the core for each interpretation that is produced . This core is then altered or augmented by whatever new features are introduced from the modi(cid:12)er . For the compound cactus beetle , PUNC (cid:12)rstly looks at the modi(cid:12)er’s representation and attempts to create a unique interpretation using each piece of knowledge . For example , the feature is spiky from cactus is taken and compared to the features of the head concept . If this feature is considered informative ( i . e . , if it does not already exist in the head concept ) , then it can be used to create an interpretation . The is spiky knowledge from cactus is then meshed with the existing representation of beetle forming a representation for the interpretation , which contains all of the diagnostic features of the head concept . The newly incorporated information ( is spiky ) is elevated to being the most diagnostic feature of this new representation , and as such can be used to create a gloss of the new representation of \ a beetle that is spiky " . This 3 The two most common types of interpretation produced by people are described as property - based and relation - based . Property - based interpretations occur when a property of the modi(cid:12)er is transferred to the head ( e . g . , bee beetle as \ a yellow and black striped beetle " ) . Relation - based interpretations occur when some relation links the head and modi(cid:12)er concepts ( e . g . , cookery magazine as \ a magazine that is about cookery " ) . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 11 12 Lynott , Tagalakis and Keane Table I . Simpli(cid:12)ed description of featural knowledge for the con - cepts cactus and beetle and two of their hypernyms ( plant and insect , respectively ) . Concept Features and Weight Hypernym cactus ( hasSpikes ) = 1 plant ( hasLocation desert ) = 2 ( canConserveWater ) = 3 beetle ( hasBitingMouthParts ) = 1 insect ( hasWingsFormingHornyCovers ) = 2 plant ( hasColour green ) = 1 organism eat ( xxx plant ) = 2 ( hasShape plant ) = 3 ( canPhotosynthesise ) = 4 insect ( hasLegs 6or8 ) = 1 invertebrate ( isCreepy ) = 2 ( hasAntennae ) = 3 ( hasSize small ) = 4 interpretation distinguishes this beetle from other types of beetle . In this way PUNC outputs both a representation of the interpretation and a text description of the interpretation . In the same way that PUNC produces \ a beetle that is spiky " , it will also generate the interpreta - tions \ a beetle that is found in deserts " and \ a beetle that can conserve water " . In some cases the knowledge being meshed from the modi(cid:12)er can con(cid:13)ict with knowledge that already exists in the head’s representa - tion . For example , when PUNC compares the knowledge \ is green " from cactus to the knowledge of beetle , there is a clash , because is black is represented as being the color of beetles . In incorporating this knowledge from the modi(cid:12)er PUNC overrides the information that was in the head to create a representation for \ a beetle that is green " . At this point , PUNC examines whether there are features in the head concept that can incorporate the modi(cid:12)er itself to form an in - terpretation ( as opposed to speci(cid:12)c features of the modi(cid:12)er concept , as above ) . For example , there may be actions that the head concept can perform on other concepts ( e . g . , eats , plays , hunts , etc . ) . From cactus , the feature can be eaten is compared to the head concept , and AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 12 Conceptual Combination with PUNC 13 Figure 3 . PUNC’s production of interpretations and with ordered scores of goodness ( the lower the score , the better the interpretation ) for novel compounds . PUNC can mesh this with the knowledge from beetle that it can eat things . This reciprocal relationship gives rise to a representation for the interpretation \ a beetle that eats cacti " . On the other hand , PUNC will also encounter the knowledge can be eaten in both concepts , but it does not create the interpretation \ a beetle that can be eaten " , as that feature is already present in beetle and so the resulting interpretation would be uninformative . Another example of where the modi(cid:12)er itself becomes part of an interpretation is in the compound cactus magazine . The concept magazine contains the feature can be about something , and so PUNC meshes this feature with the modi(cid:12)er itself to produce a representation for \ a magazine that is about cacti " . Similarly , cactus magazine could also be \ a magazine that is made from cactus " as mag - azines can be made from di(cid:11)erent things . Incorporating the modi(cid:12)er itself in this way gives rise to a variety of interpretations depending on the features present in the head . Each interpretation that is produced by PUNC has an overall good - ness score calculated , based on the diagnosticity of the features used to produce the interpretation , and the level of plausibility of the inter - pretation ( as was used by the C 3 model ) . This is discussed further in the next subsection . Using the above mechanism that meshes knowledge of the modi(cid:12)er and head concepts , PUNC can produce a variety of interpretation types that have been described in the literature , such as property - based ( e . g . , \ a hat that has yellow and black stripes " ) , relation - based ( e . g . , \ a beetle that eats sugar " ) and conjunctions ( e . g . , \ a bird that is also a pet " ) . These interpretations account for the vast majority of interpretations AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 13 14 Lynott , Tagalakis and Keane produced by people and PUNC provides an e(cid:14)cient mechanism for generating them . 5 . 3 . Improvements on C 3 Model Overall , PUNC is much more e(cid:14)cient than C 3 as it reduces the amount of processing necessary to produce a set of psychologically plausible interpretations . C 3 implements diagnosticity by comparing a given feature to all other concepts in the knowledge base . The frequency of occurrence of this feature in the knowledge base determines its level of diagnosticity ( i . e . , if it occurs only once for a concept , it would by highly diagnostic for that concept ) . While C 3 computed all of the diagnosticity weights for the concepts in its knowledge base , PUNC assigns standardized weights based on the intuitions of multiple raters . Each concept has its predicates encoded in decreasing order of diagnosticity , thus giving us a partial ordering of the relative goodness of the predicates in the concept . Indeed , it has been shown that diagnostic features are more available to people than non - diagnostic features ( Giora , 1999 ; Grice , 1975 ; Rosch , 1975 ) . By processing the highly diagnostic features of the head and modi(cid:12)er (cid:12)rst , PUNC produces better interpretations (cid:12)rst , with poorer interpretations generally occurring later in the pro - cessing stages . This closely re(cid:13)ects how people produce compounds , since communicative goals generally require people to produce good interpretations (cid:12)rst ( Lynott and Keane , manuscript in submission ) . In C 3 , plausibility is implemented directly through a process that compares the partial interpretation to all known related concepts . It then attempts to enhance the overall plausibility of an interpretation by incorporating extra features from the head and modi(cid:12)er concepts , so as to increase the size of the overlap with stored instances . Plausibility in PUNC , on the other hand , is an implicit part of the entire combination process . PUNC avoids retroactively assessing the plausibility in two ways . Firstly , PUNC considers the type of interaction between the two concepts at the point of producing an interpretation . Secondly , it uses the knowledge of the head concept as the core for each interpreta - tion produced . This means that its overlap with existing concepts is maximized from the outset . Additionally , the model looks at plausible interactions between the concepts involved , which also contributes to the overall goodness of an interpretation . For example , in the compound ballet mother , ballet is represented as a dance , and dances have the feature to be performed . The concept mother inherits from both woman and person and so performs is one possible feature that a person can have . Because these features of the two concepts mesh perfectly , the AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 14 Conceptual Combination with PUNC 15 interpretation of \ a mother who performs ballet " is deemed highly plausible . On the other hand , if the compound being interpreted was ballet dog , the interpretation \ a dog that performs ballet " would not receive a high plausibility scoring since dogs do not typically perform ballet , although the interpretation is still possible . Di(cid:11)erent interactions between the concepts give rise to di(cid:11)erent levels of plausibility for an interpretation . In obviating the need for post - hoc checks , PUNC provides an e(cid:14)cient mechanism for integrating plausibility into the interpretation process . Informativeness in C 3 is implemented as a distinct stage in the pro - cess of constructing interpretations . Once an interpretation has been produced , it is examined for redundant information . For example , if a generated interpretation for pencil bed were \ a bed that is made of wood " , it would be rejected as being uninformative , since made of wood is an encoded predicate of bed . However , at this stage , C 3 has already carried out needless processing to get to this point . By contrast , in PUNC , informativeness is implemented as an inherent part of the interpretation process . PUNC does not consider default information ( like made of wood ) as part of its interpretations and generates only interpretations that are considered informative in the (cid:12)rst place . Thus , if a feature of the modi(cid:12)er will add no new information to the head concept , it will not be used to form an interpretation . Finally , we have already seen that C 3 does not take familiarity into account in processing compounds . PUNC handles familiarity by by - passing the normal interpretation - production mechanism and directly accessing meanings of familiar , lexicalized compounds . Also , the model takes into account emerging familiarity due to similarity and semantic relatedness between familiar and novel compounds - a dimension of conceptual combination and pragmatic consideration that has actually been ignored by all existing models of conceptual combination . 5 . 4 . Model Testing and Evaluation For familiar compounds , the model \ searches and retrieves " their inter - pretations . The interpretations that have been encoded are those that people produced most frequently in Tagalakis and Keane ( 2003 , Exper - iment 3 ) . Therefore , evaluation of the quality of interpretations PUNC provides for familiar compounds is not an issue . Also , the system checks for semantic links between concepts and employs , when appropriate , a simple \ search and replace " procedure . 93 % of the interpretations produced with this method are meaningful . To examine PUNC’s performance for novel compounds we used two sets of interpretations for noun - noun compounds ; one from Costello AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 15 16 Lynott , Tagalakis and Keane and Keane ( 2000 ) ( e . g . , whale seal , viper slug ) and one from ( Lynott and Keane , manuscript in submission ) ( e . g . , carrot bomb , bee hat ) . In both of these studies , people were asked to provide what they thought would be plausible interpretations for a list of novel compounds . Participants’ responses were collated and ranked by their frequency of production . We took the same set of compounds that were presented to those participants ( 40 in total ) and input them into the PUNC model . For each compound PUNC returns an ordered set of interpretations and representations for each interpretation , which we could then compare to participants’ responses . The overall ranking of an interpretation is calculated using both the diagnosticity of the information being incorporated from the head and modi(cid:12)er and the plausibility of the interaction between the compound’s constituents 4 . We found that in 77 % of cases the most frequently produced inter - pretation by people was produced by PUNC as the highest ranking interpretation . For example , for the compound plate paper , the in - terpretation that was ranked highest by PUNC was \ paper that is used to make plates " , which matched the most frequently produced interpretation by participants . For some compounds , PUNC’s highest ranking interpretation was not the interpretation produced most often by people , but was still among the set of interpretations people pro - duced . For example , bee hat meaning \ a hat that is worn by a bee " was considered the best interpretation by PUNC , but it was only the third most frequently produced interpretation by participants . If we compare all of the interpretations produced by PUNC that were also produced by people , there is a strong correlation between PUNC’s goodness score ( the lower the goodness score , the better the interpretation ) and the frequency of production of participants’ interpretations ( the higher the frequency score , the better the interpretation ) ( r = (cid:0) 0 : 81 ; N = 261 ; p < : 001 ) . To examine PUNC’s e(cid:14)ciency , the CPU time for algorithms execu - tion was measured on a x86 - based PC , with 500 MHz PIII processor , main memory size of 256 MB , running MS Windows 2000 Professional and JDK 1 . 4 . 1 . We identi(cid:12)ed three main conditions ; interpretations retrieved for familiar compounds ( Fcc ) , interpretations produced with a quick construction method when the input phrases were novel but in certain aspects similar to familiar compounds ( Scc ) , and interpretations generated for novel compounds bearing no relations to familiar ones ( Ncc ) . For each condition , 30 di(cid:11)erent , random word combinations were 4 Goodness Score = ( Plausibility / 10 ) * ( ( Head Diagnosticity * 0 . 55 ) + ( Mod - i(cid:12)er Diagnosticity * 0 . 45 ) ) . This calculation gives slightly more importance to the modi(cid:12)er’s information , as this has been shown to have a greater bearing on resultant interpretations ( Gagn(cid:19)e and Shoben , 1997 ) . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 16 Conceptual Combination with PUNC 17 Figure 4 . Mean Execution Time ( CPU Time ) in msecs for familiar compounds ( Fcc ) , novel compounds but similar to familiar ones found in the Knowledge Base ( Scc ) and novel compounds with no similarity links to any familiar compounds in the Knowledge Base ( Ncc ) . processed . The results were recorded and analyzed using an one - way ANOVA . The mean time in milliseconds for processing phrases was : MD Fcc = 10 : 43 ; SD = 1 : 19 ; MD Scc = 15 : 06 ; SD = 3 : 88 ; MD Ncc = 56 : 66 ; SD = 32 : 41 ( Figure 4 ) . The overall di(cid:11)erence across conditions was reliable , F ( 2 ; 87 ) = 54 : 68 ; p < : 001 . Fisher’s LSD post - hoc test indicated signif - icant di(cid:11)erence between the means of Ncc and Fcc ( MD = 46 : 23 ; p < : 001 ) and the means of Ncc and Scc ( MD = 41 : 60 ; p < : 001 ) . These metrics mirror the results of Tagalakis and Keane ( 2003 ) , who report reliably shorter comprehension times due to familiarity . These results demonstrate that the PUNC system is capable of modelling a range of empirical data , including the frequency of production of interpre - tations , and the di(cid:11)erences in processing times between novel , similar and lexicalized compounds . 6 . Discussion We have described a model based on the core constraints of the Con - straint theory ( Costello and Keane , 2000 ) . We have shown how the Constraint theory can be implemented in a manner that closely re(cid:13)ects AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 17 18 Lynott , Tagalakis and Keane the degrees of processing required by people to produce acceptable interpretations for a variety of compound types . Through a considera - tion for compound familiarity and a prioritizing of feature availability , PUNC successfully re(cid:13)ects several aspects of human performance re - lated to conceptual combinations . Clearly , the Constraint theory needs to be developed in several directions . First , it needs to be able to deal with a wider range of empirical phenomena , such as those we have reported here on familiarity . Second , the C 3 model , which implements the theory , needs to be updated with the new requirement and become more e(cid:14)cient in its computational complexity . The PUNC model aims to meet these challenges and makes an important leap from a largely computational - level implementation to a more human - like approach for conceptual combinations . It may appear on the surface that there are similarities between the processes employed by the PUNC model and those of the Concept Specialization model ( Cohen and Murphy , 1984 ; Murphy , 1988 ) , but in fact there are radical di(cid:11)erences between the two . First , a major shortcoming of the Concept Specialization model is that it cannot pro - duce property - based interpretations . The Concept Specialization model generates interpretations by (cid:12)lling slots in the head concept with the modi(cid:12)er name ; for example , robin hawk could be interpreted as \ a hawk that preys on robins " , by (cid:12)lling the preys slot in the schema representation of hawk with the modi(cid:12)er name . However , it does not allow for properties of the modi(cid:12)er to be instantiated into the head representation . This means that while the interpretation \ a hawk with a red breast " is readily generated by PUNC , the Concept Specialization model cannot produce it . PUNC allows for a much greater role for the modi(cid:12)er and its constituent information , thus having greater scope and variation in the interpretations it produces . Second , the knowledge encoded in the Concept Specialization model is very general in nature and does not allow for certain aspects of a concept to be more impor - tant than any other . Conversely , in PUNC the relative importance of information to a concept ( e . g . , its diagnosticity ) impacts on both the ease with which an interpretation is produced and its overall good - ness . PUNC o(cid:11)ers a model with far greater scope , yet with processing requirements controlled by the tenets of the Constraint theory . Future work will be aimed at moving to more complete computa - tional solution for conceptual combination . This will involve a formal speci(cid:12)cation of the constraints , including the newly introduced famil - iarity factor , and the interactions between each one . Furthermore , a concern for many cognitive models is in using an appropriate and representative knowledge base . Our framework needs to provide an ad - equate ontology and knowledge representation of concepts . Inheritance AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 18 Conceptual Combination with PUNC 19 relations , abstract concepts and similarity relations between concepts have been de(cid:12)ned , but the knowledge base requires a wider scope and full empirical testing of each of these aspects . For example , one needs to know which features are most salient and useful in describing a concept . Machine Learning techniques may prove to be useful for discovering discriminating features and ranking the diagnosticity of a feature ( see Blum and Langley , 1997 , for a review of advances on the problem of selecting relevant features in Machine Learning ) . Such an approach could complement our selection and weighting methods . Also , lexical - semantic databases built according to psycholinguistic principles like WordNet ( Miller , 1994 ) could be utilized as knowledge representation and ontology tools . Future development will also consider how the PUNC system should be used to predict the compounds that people create in order to capture particular object descriptions . Acknowledgements The work presented here has been part - funded by a grant to the (cid:12)rst author from the Irish Research Council for Science , Engineering and Technology ( IRCSET ) , a grant to the second author by University College Dublin ( UCD ) and a grant to the third author from Science Foundation Ireland ( SFI ) . References Blum , A . and Langley , P . : 1997 , ‘Selection of Relevant Features and Examples in Machine Learning’ . Arti(cid:12)cial Intelligence 97 , 245 { 271 . Bock , J . B . and C . Clifton Jr . : 2000 , ‘The Role of Salience in Conceptual Combination’ . Memory & Cognition 28 , 1378 { 1386 . Clark , E . V . and B . F . Hecht : 1982 , ‘Learning to Coin Agent and Instrument Nouns’ . Cognition 12 , 1 { 24 . Cohen , B . and G . L . Murphy : 1984 , ‘Models of Concepts’ . Cognitive Science 8 , 27 { 58 . Costello , F . J . : 2002 , ‘Investigating Creative Language : People’s Choice of Words in the Production of Noun - Noun Compounds’ . In : W . D . Gray and C . D . Schunn ( eds . ) : Twenty - Fourth Annual Conference of the Cognitive Science Society . Mahwah , NJ : Lawrence Erlbaum Associates , pp . 232 { 237 . Costello , F . J . and M . T . Keane : 1997 , ‘Polysemy in Conceptual Combination : Testing the Constraint Theory of Combination’ . In : M . G . Shafto and P . Langley ( eds . ) : Proceedings of the Nineteenth Annual Conference of the Cognitive Science Society . Hillsdale , NJ : Lawrence Erlbaum Associates , pp . 137 { 142 . Costello , F . J . and M . T . Keane : 2000 , ‘E(cid:14)cient Creativity : Constraint - Guided Conceptual Combination’ . Cognitive Science 24 , 299 { 349 . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 19 20 Lynott , Tagalakis and Keane Costello , F . J . and M . T . Keane : 2001 , ‘Testing Two Theories of Conceptual Combi - nation : Alignment versus Diagnosticity in the Comprehension and Production of Combined Concepts’ . Journal of Experimental Psychology : Learning , Memory , and Cognition 27 , 255 { 271 . Coulson , S . : 2001 , Semantic Leaps : Frame Shifting and Conceptual Blending in Meaning Construction . New York and Cambridge : Cambridge University Press . Estes , Z . and S . Glucksberg : 2000 , ‘Interactive Property Attribution in Concept Combination’ . Memory & Cognition 28 , 28 { 34 . Forbus , K . D . , R . W . Ferguson , and D . Gentner : 1994 , ‘Incremental Structure Map - ping’ . In : A . Ram and K . Eiselt ( eds . ) : Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society . Hillsdale , NJ : Lawrence Erlbaum Associates , pp . 283 { 288 . Franks , B . : 1995 , ‘Sense Generation ; A \ Quasi - Classical " Approach to Concepts and Concepts Combination’ . Cognitive Science 19 , 441 { 505 . Gagn(cid:19)e , C . L . : 2000 , ‘Relation - Based Combinations Versus Property - Based Combi - nations : A Test of the CARIN Theory and Dual - Process Theory of Conceptual Combination’ . Journal of Memory and Language 42 , 365 { 389 . Gagn(cid:19)e , C . L . and E . J . Shoben : 1997 , ‘In(cid:13)uence of Thematic Relations on the Comprehension of Modi(cid:12)er - Noun Combinations’ . Journal of Experimental Psychology : Learning , Memory , and Cognition 23 , 71 { 87 . Gazdar , G . , E . Klein , G . Pullum , and I . Sag : 1985 , Generalized Phrase Structure Grammar . Cambridge , MA : Harvard University Press . Giora , R . : 1999 , ‘On the Priority of Salient Meanings : Studies of Literal and Figurative Language’ . Journal of Pragmatics 31 , 919 { 929 . Grice , H . P . : 1975 , ‘Logic and Conversation’ . In : P . Cole and J . L . Morgan ( eds . ) : Syntax and Semantics ( vol . 3 ) : Speech Acts . New York : Academic Press , pp . 41 { 58 . Keane , M . and F . Costello : 2001 , ‘Setting Limits on Analogy : Why Conceptual Combination is not Structural Alignment’ . In : D . Gentner , K . J . Holyoak , and B . Kokinov ( eds . ) : The Analogical Mind : A Cognitive Science Perspective . Cambridge , MA : MIT Press , pp . 287 { 312 . Keane , M . T . , T . Ledgeway , and S . R . S . Du(cid:11) : 1994 , ‘Constraints on Analogical Mapping : A Comparison of Three Models’ . Cognitive Science 18 , 387 { 438 . Kruschke , J . K . : 1992 , ‘ALCOVE : An Exemplar - based Connectionist Model of Category Learning’ . Psychological Review 99 , 1922 { 1944 . Lin , D . : 1998 , ‘An Information - Theoretic De(cid:12)nition of Similarity’ . In : J . Shav - lik ( ed . ) : Proceedings of the Fifteenth International Conference on Machine Learning . San Francisco , CA : Morgan Kaufmann , pp . 296 { 304 . Markman , A . B . and D . Gentner : 1993 , ‘Structural Alignment during Similarity Comparisons’ . Cognitive Psychology 25 , 431 { 467 . McRae , K . and S . Boisvert : 1998 , ‘Automatic Semantic Similarity Priming’ . Journal of Experimental Psychology : Learning , Memory , and Cognition 24 , 558 { 572 . Miller , G . A . : 1994 , ‘Nouns in WordNet : A Lexical Inheritance System’ . International Journal of Lexicography 4 , 245 { 264 . Murphy , G . L . : 1988 , ‘Comprehending Complex Concepts’ . Cognitive Science 12 , 529 { 562 . Resnik , P . : 1998 , ‘Semantic Similarity in a Taxonomy : An Information - Bases Mea - sure and its Application to Problems of Ambiguity in Natural Language’ . Journal of Arti(cid:12)cial Intelligence Research 11 , 95 { 130 . Rosch , E . : 1975 , ‘Family Resemblances : Studies in the Internal Structure of Categories’ . Cognitive Psychology 7 , 573 { 605 . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 20 Conceptual Combination with PUNC 21 Shoben , E . J . : 1993 , ‘Non - Predicating Conceptual Combinations’ . The Psychology of Learning and Motivation 29 , 391 { 409 . Shoben , E . J . and C . L . Gagn(cid:19)e : 1997 , ‘Thematic Relations and the Creation of Combined Concepts’ . In : T . B . Ward , S . M . Smith , and J . Vaid ( eds . ) : Creative Thought : An Investigation of Conceptual Structures and Processes . Washington , DC : American Psychological Association , pp . 31 { 50 . Sloman , S . A . , B . C . Love , and W . - K . Ahn : 1998 , ‘Feature Centrality and Conceptual Combination’ . Cognitive Science 22 , 189 { 228 . Tagalakis , G . and M . T . Keane : 2003 , ‘Modelling the Understanding of Noun - Noun Compounds : The Role of Familiarity’ . In : F . Schmalhofer , R . M . Young , and G . Katz ( eds . ) : Proceedings of the European Cognitive Science Conference 2003 . Mahwah , NJ : Lawrence Erlbaum Associates , pp . 319 { 324 . Thompson - Schill , S . L . , K . J . Kurtz , and J . D . E . Gabrieli : 1998 , ‘E(cid:11)ects of Semantic and Associative Relatedness on Automatic Priming’ . Journal of Memory and Language 38 , 440 { 458 . Wisniewski , E . J . : 1996 , ‘Construal and Similarity in Conceptual Combination’ . Journal of Memory and Language 35 , 434 { 453 . Wisniewski , E . J . : 1997 , ‘When Concepts Combine’ . Psychonomic Bulletin & Review 4 , 167 { 183 . Wisniewski , E . J . and B . C . Love : 1998 , ‘Relations versus Properties in Conceptual Combination’ . Journal of Memory and Language 38 , 177 { 202 . AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 21 AIReview04 . tex ; 29 / 01 / 2004 ; 18 : 50 ; p . 22