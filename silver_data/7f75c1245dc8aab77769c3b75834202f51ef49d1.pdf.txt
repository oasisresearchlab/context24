Examining the beneﬁts and challenges of using audience response systems : A review of the literature Robin H . Kay * , Ann LeSage 1 University of Ontario Institute of Technology , Faculty of Education , 2000 Simcoe St . North , Oshawa , Ontario , Canada L1H 7L7 a r t i c l e i n f o Article history : Received 18 January 2009 Received in revised form 3 May 2009 Accepted 4 May 2009 Keywords : Audience response systems Personal response system Electronic voting system Student response system Review Attitude Learning Assessment a b s t r a c t Audience response systems ( ARSs ) permit students to answer electronically displayed multiple choice questions using a remote control device . All responses are instantly presented , in chart form , then reviewed and discussed by the instructor and the class . A brief history of ARSs is offered including a dis - cussion of the 26 labels used to identify this technology . Next a detailed review of 67 peer - reviewed papers from 2000 to 2007 is offered presenting the beneﬁts and challenges associated with the use of an ARS . Key beneﬁts for using ARSs include improvements to the classroom environment ( increases in attendance , attention levels , participation and engagement ) , learning ( interaction , discussion , contingent teaching , quality of learning , learning performance ) , and assessment ( feedback , formative , normative ) . The biggest challenges for teachers in using ARSs are time needed to learn and set up the ARS technology , creating effective ARS questions , adequate coverage of course material , and ability to respond to instan - taneous student feedback . Student challenges include adjusting to a new method of learning , increased confusion when multiple perspectives are discussed , and negative reactions to being monitored . It is con - cluded that more systematic , detailed research is needed in a broader range of contexts . Crown Copyright (cid:2) 2009 Published by Elsevier Ltd . All rights reserved . 1 . Introduction 1 . 1 . Overview An Audience Response System ( ARS ) allows an entire class to respond to multiple choice questions displayed on a screen . After students click in their responses using remote devices , the results are instantly collected , summarized and presented to the class in visual format , usually a histogram . Responses are always anonymous to peers , but the teacher can associate ARS devices with individual students for test - ing purposes . With feedback from the class , an instructor is provided with an opportunity to orchestrate peer or classroom discussion about concepts being covered . ARSs have been used to improve student interaction , engagement , and attention ( e . g . , Draper & Brown , 2004 ; Hin - de & Hunt , 2006 ) , increase attendance ( e . g . , Bullock et al . , 2002 ) , stimulate peer and class discussion ( e . g . , Pelton & Pelton , 2006 ) , provide feedback for both students and instructors in order to improve instruction ( e . g . , Caldwell , 2007 ) , and improve learning performance ( e . g . , El - Rady , 2006 ) . The purpose of this review is to provide a current , comprehensive synthesis of research on ARSs from 2000 to 2007 in order to guide educators and future researchers . Previous research reviews ( Caldwell , 2007 ; Fies & Marshall , 2006 ; Judson & Sawada , 2002 ; Simpson & Oliver , 2007 ) are somewhat dated and / or limited in coverage and scope . Key topics encompassed in the current review include the history of ARSs , labeling and terminology , previous literature reviews , beneﬁts and challenges when using ARSs , and suggestions for further investigation . 1 . 2 . History of ARSs When ARSs were ﬁrst introduced at Stanford University in 1966 , they were expensive , did not function well , and were difﬁcult to use ( Abrahamson , 2006 ; Judson & Sawada , 2002 , 2006 ) . In 1985 , a much less expensive prototype , known as Classtalk I , was tested and 0360 - 1315 / $ - see front matter Crown Copyright (cid:2) 2009 Published by Elsevier Ltd . All rights reserved . doi : 10 . 1016 / j . compedu . 2009 . 05 . 001 * Corresponding author . Tel . : + 1 905 721 8668x2679 . E - mail address : robin . kay @ uoit . ca ( R . H . Kay ) . 1 Tel . : + 1 905 721 8668x2886 . Computers & Education 53 ( 2009 ) 819 – 827 Contents lists available at ScienceDirect Computers & Education journal homepage : www . elsevier . com / locate / compedu generally well received by students and teachers at Christopher Newport University . Although ARSs became commercially available from 1992 to 1999 ( Abrahamson , 2006 ; Beatty , 2004 ) , the cost was still too prohibitive for widespread distribution . In 1999 , a new generation of more affordable , infrared ARSs became available . Extensive use of ARSs began in 2003 ( Abrahamson , 2006 ; Judson & Sawada , 2002 , 2006 ) and today , numerous secondary schools , colleges and universities use this tool ( Abrahamson , 2006 ) . 1 . 3 . Labeling and terminology A comprehensive review of the literature reveals no less than 26 different labels for ARSs ( see Kay ( 2008a ) for a complete list ) . The most commonly used terms include : audience response system ( n = 17 papers ) , personal response system ( n = 7 papers ) , electronic voting sys - tem ( n = 5 papers ) , and student response system ( n = 4 papers ) . One key issue with inconsistent labeling is the difﬁculty it poses in locating and staying current with the latest research . For example , four relatively recent reviews on ARSs ( Caldwell , 2007 ; Fies & Marshall , 2006 ; Simpson & Oliver , 2007 ) referenced 16 – 25 studies per review , yet this quantity represents only one quarter to one third of the peer - re - viewed articles available on ARSs from 2000 to 2007 . 1 . 4 . Previous literature reviews Four literature reviews have been completed on ARSs ( Caldwell , 2007 ; Fies & Marshall , 2006 ; Judson & Sawada , 2002 ; Simpson & Oliver , 2007 ) . Judson and Sawada ( 2002 ) provided a summary of ARS use up until 1998 , but their review included only eight peer - reviewed references . Because prevalent use of ARSs began after 2003 , Judson and Sawada’s ( 2002 ) analysis is dated . Fies and Marshall ( 2006 ) examined methods used to assess ARSs , however their review included only 16 peer - reviewed studies , only two of which two were published after 2004 . Therefore , some of their conclusions are questionable . For example , they claimed that few studies reported the use of ARSs for formative assessment , yet since 2004 , 16 new studies have been completed where formative assessment was em - ployed . A more recent review by Simpson and Oliver ( 2007 ) analyzed more than 40 papers . However , only 17 of the articles cited were from peer - reviewed journals , with the majority of the results based on ﬁve key references . In addition , the impact ARSs on learning was not studied in detail . The most current and comprehensive review was conducted by Caldwell ( 2007 ) who analyzed 25 peer - reviewed articles , many of which were published after 2000 . Caldwell’s analysis focussed on identifying the primary users of ARSs , articulating the rationale for using ARSs , exploring questioning strategies used with ARSs , and identifying best practices . Nevertheless , few details were offered with respect to the impact of ARSs on student learning . In summary , it is argued that a more comprehensive review of the ARS literature is needed in order to present a more current and rep - resentative summary of beneﬁts and challenges experienced when using this new technology . 2 . Method 2 . 1 . Studies examined 2 . 1 . 1 . Overview Several measures were taken to address some the shortcomings of previous ARS research reviews . First , a comprehensive search of peer - reviewed journals , but not conference papers or reports , was completed based on the 26 labels for ARSs ( Kay , 2008a ) . This approach uncov - ered a total of 67 papers and chapters . Given that previous literature reviews included no more than 25 peer - reviewed papers , one can be reasonably assured that the current review of ARSs is comprehensive . Of the 67 studies examined , 64 were performed between 2000 and 2007 , with 49 articles published since 2004 . Thirty - six studies col - lected data about attitudes , and 24 focussed on learning . Regarding methodology , 20 of the studies were survey - based , 12 were case stud - ies , 13 offered theoretical analyses , eight presented qualitative data , and the remaining articles provided speciﬁc or general reviews of ARS use . See Kay ( 2008c ) for a complete list of the articles included in this review . 2 . 1 . 2 . Context of using ARSs Before examining the beneﬁts and challenges of using ARSs , it is informative to understand the context in which these tools have been used . The sample populations for the 67 studies reviewed in this paper were predominantly undergraduate students ( n = 49 studies ) , with only 5 papers investigating professionals or faculty use , three examining middle school students , and one looking at secondary school class - rooms . Eighteen studies were in the domain of science , eight in medicine , six in mathematics or computer science , four in engineering , four in business , and three in social science or law . The remaining studies covered a variety of subject areas including law , and philosophy . Sam - ple size ranged from 14 to 2684 students . Seventy - six percent of the 34 studies that did report sample size examined over 80 students with an overall mean of 308 . In summary , the conclusions from the current review reﬂect the attitudes and learning efforts of undergraduate students who were studying science - or mathematics - based subject areas in relatively large classes . 2 . 1 . 3 . Data analysis The methodology of each of the studies in this paper was analyzed based on the following elements : student population , sample size , subject area , data collection type , reliability and validity of data collection tools , and the identiﬁcation of the study’s area of focus ( attitude and / or learning ) . Each study was also analyzed based on the following categories : rationale or theory for using ARSs , context of use , and beneﬁts and challenges associated with using an ARS . Kay ( 2008b ) provides a detailed description of the coding of variables used in this study . It should be noted that a meta - analysis was not completed because ( a ) only 10 studies used formal statistics to evaluate data , ( b ) only four studies offered reliability estimates for data collection tools , ( c ) only one study presented validity information and ( d ) a meaningful comparison of these studies was restricted by the narrow range of subject areas covered . 820 R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 3 . Results and discussion 3 . 1 . Beneﬁts to using ARSs 3 . 1 . 1 . Overall attitudes According to Judson and Sawada ( 2002 ) , prior to 1992 , student attitudes toward ARSs were very positive , although much of the evidence presented was based on informal student feedback . However , more recent studies have offered considerable quantitative and qualitative evidence indicating that students are positive about the use of ARSs in higher education ( Caldwell , 2007 ; Durbin & Durbin , 2006 ; Fies & Marshall , 2006 ; Hu et al . , 2006 ; Simpson & Oliver , 2007 ) . In the literature review completed for this paper , 36 out of the 38 articles that examined attitudes toward ARSs reported that students and / or teachers had positive perceptions of the technology . In addition , the major - ity of students reported that the technology was easy to learn and use ( d’Inverno , Davis , & White , 2003 ; Elliott , 2003 ; Hinde & Hunt , 2006 ; Jones , Connolly , Gear , & Read , 2001 ; Pelton & Pelton , 2006 ; Pradhan , Sparano , & Ananth , 2005 ; Sharma , Khachan , Chan , & O’Byrne , 2005 ; Siau , Sheng , & Nah , 2006 ) . It is critical , however , to focus on the speciﬁc beneﬁts of ARSs in order to truly determine whether the technology is a viable instruction tool . These beneﬁts will be presented within three categories ( classroom environment , learning , and assessment ) and are summarized in Table 1 . 3 . 1 . 2 . Classroom environment beneﬁts 3 . 1 . 2 . 1 . Attendance . Attendance in higher education classrooms is unpredictable at best ( Burnstein & Lederman , 2001 ; Greer & Heaney , 2004 ) . In order to improve attendance , ARSs have been introduced at several universities . Multiple studies have found that attendance does improve when an ARS is used , provided it is linked to a portion of a student’s ﬁnal mark . Dramatic increases in attendance occur when 15 % of a student’s grade is associated with ARS participation ( Burnstein & Lederman , 2001 ; Greer & Heaney , 2004 ) . However , Caldwell ( 2007 ) observed that 5 % of a student’s grade was sufﬁcient motivation to improve regular classroom attendance . Ideally an instructor would prefer that students attend class because they felt that using an ARS helped improve the learning process , but only two studies reported increased attendance when grades were not associated with ARS use ( El - Rady , 2006 ; Preszler , Dawe , Shuster , & Shuster , 2007 ) . It is worth noting that even though attendance may increase with ARS use , students do not necessarily support this practice . Greer and Heaney ( 2004 ) observed that students were displeased about being forced to attend class in order to gain academic credit for ARS participation . It is possible that using external rewards to increase classroom attendance may be effective , but could undermine the process of creating a positive learning environment . 3 . 1 . 2 . 2 . Attention . It is self evident that students need to be focussed and paying attention when content is presented during a lecture . What may not be obvious is that during a lecture , attention may diminish after only 20 min ( d’Inverno et al . , 2003 ; Jackson , Ganger , Bridge , & Ginsburg , 2005 ) . Given that a typical higher education class lasts from 50 min to 3 h , it is inevitable that some information will be lost . One technique for addressing student attention deﬁcits during a class is to present ARS questions at 20 min intervals , there - by requiring students to shift their attention and actively participate in the learning process . The success of this approach has been con - ﬁrmed by numerous studies which have reported that higher education students are more attentive when an ARS is used during lectures ( Bergtrom , 2006 ; Burnstein & Lederman , 2001 ; Caldwell , 2007 ; d’Inverno et al . , 2003 ; Draper & Brown , 2004 ; Elliott , 2003 ; Horowitz , 2006 ; Jackson et al . , 2005 ; Jones et al . , 2001 ; Latessa & Mouw , 2005 ; Siau et al . , 2006 ; Slain , Abate , Hidges , Stamatakis , & Wolak , 2004 ) . 3 . 1 . 2 . 3 . Anonymity and participation . Students can respond to ARS questions without being judged by their peers , a tutor , or the instructor . Anonymity allows all students to be active members of the classroom community and participate in the learning process without recrim - ination ( Banks , 2006 ; Durbin & Durbin , 2006 ) . A number of researchers have reported that students appreciate this feature ( Banks , 2006 ; Caldwell , 2007 ; Draper & Brown , 2004 ; Hu et al . , 2006 ; Jones et al . , 2001 ; Siau et al . , 2006 ; Simpson & Oliver , 2007 ; Stuart , Brown , & Draper , 2004 ) . In addition , substantial evidence indicates that using an ARS increases student participation when compared to classrooms where an ARS was not used ( Bullock et al . , 2002 ; Caldwell , 2007 ; Draper & Brown , 2004 ; Greer & Heaney , 2004 ; Jones et al . , 2001 ; Siau et al . , 2006 ; Stuart et al . , 2004 ; Uhari , Renko , & Soini , 2003 ; Van Dijk , Van Den Berg , & Van Keulen , 2001 ) . 3 . 1 . 2 . 4 . Engagement . Students have reported being more interested or engaged in concepts presented and discussed using an ARS ( Berg - trom , 2006 ; Hu et al . , 2006 ; Preszler et al . , 2007 ; Simpson & Oliver , 2007 ) . However , detailed information for why students are engaged has not been collected to date . While it is assumed that students are more engaged because they are actively involved in the learning pro - cess , one alternative explanation might that they are having fun using a remote control device and observing other students’ responses . More comprehensive , qualitative research is required to explore plausible explanations for increased student engagement with ARS use . 3 . 1 . 3 . Learning beneﬁts 3 . 1 . 3 . 1 . Interaction . Numerous studies suggest that frequent and positive interaction occurs when ARSs are used ( Banks , 2006 ; Beatty , 2004 ; Bergtrom , 2006 ; Caldwell , 2007 ; Elliott , 2003 ; Freeman , Bell , Comerton - Forder , Pickering , & Blayney , 2007 ; Kennedy , Cutts , & Draper , 2006 ; Sharma , Khachan , Chan , & O’Byrne , 2005 ; Siau et al . , 2006 ; Slain et al . , 2004 ; Stuart et al . , 2004 ; Trees & Jackson , 2007 ) . Speciﬁcally , researchers have reported greater articulation of student thinking ( Beatty , 2004 ) , more probing questions , an increased focus on student needs ( Beatty , 2004 ; Siau et al . , 2006 ) , effective peer - to - peer discussions ( Bergtrom , 2006 ; Caldwell , 2007 ; Kennedy et al . , 2006 ) , and active learning ( Elliott , 2003 ; Kennedy et al . , 2006 ; Slain et al . , 2004 ; Stuart et al . , 2004 ) . 3 . 1 . 3 . 2 . Discussion . A few researchers have noted that use of an ARS increases the quantity and quality of class discussions , particularly when employed with a strategy known as ‘‘peer instruction” ( Beatty , 2004 ; Brewer , 2004 ; Draper & Brown , 2004 ; Jones et al . , 2001 ; Nicol & Boyle , 2003 ) . Peer instruction occurs when a teacher presents a question using an ARS , collects student responses and presents responses from the class , but does not provide the correct answer . Instead , the class is instructed to discuss possible solutions in pairs and then stu - dents are provided with the opportunity to vote a second time . After the second vote , the issues are resolved through class discussion and R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 821 clariﬁcations from the instructor . The research indicates that students feel they are better able to discuss and calibrate their understanding of speciﬁc concepts when peer instruction is employed ( Draper & Brown , 2004 ) . 3 . 1 . 3 . 3 . Contingent teaching . One of the key beneﬁts of using an ARS is that instruction can be modiﬁed based on student feedback gathered throughout a class ( Brewer , 2004 ; Caldwell , 2007 ; Cutts , 2006 ; Draper & Brown , 2004 ; Elliott , 2003 ; Greer & Heaney , 2004 ; Hinde & Hunt , 2006 ; Jackson et al . , 2005 ; Kennedy & Cutts , 2005 ; Poulis , Massen , Robens , & Gilbert , 1998 ; Stuart et al . , 2004 ) . If feedback from a majority of students indicates that confusion or misconceptions are evident , an experienced instructor can offer alternative explanations of the con - cepts in question . In essence , using an ARS changes a relatively static one - way transmission of information into a dynamic , interactive lec - ture guided by student input ( Kennedy & Cutts , 2005 ) . 3 . 1 . 3 . 4 . Learning performance . A strong argument can be made for the use of ARSs in the classroom based on anecdotal and experimental evidence with respect to learning performance . Extensive qualitative research suggests that learning performance increases as a result of using ARSs ( Brewer , 2004 ; Caldwell , 2007 ; Carnaghan & Webb , 2007 ; Horowitz , 2006 ; Hu et al . , 2006 ; Kennedy & Cutts , 2005 ; Latessa & Mouw , 2005 ; Poulis et al . , 1998 ; Schackow , Milton , Loya , & Friedman , 2004 ) . In addition , many experimental studies report that classes using ARSs signiﬁcantly outperform those using traditional lecture formats ( Bullock et al . , 2002 ; El - Rady , 2006 ; Fagan , Crouch , & Mazur , 2002 ; Kaleta & Joosten , 2007 ; Kennedy & Cutts , 2005 ; Pradhan et al . , 2005 ; Preszler et al . , 2007 ; Schackow et al . , 2004 ; Slain et al . , 2004 ) . 3 . 1 . 3 . 5 . Quality of learning . Numerous studies claim that higher education students report that they learn more when an ARS is used ( Elliott , 2003 ; Greer & Heaney , 2004 ; Hatch , Jensen , & Moore , 2005 ; Nicol & Boyle , 2003 ; Pradhan et al . , 2005 ; Preszler et al . , 2007 ; Siau et al . , 2006 ; Slain et al . , 2004 ; Stuart et al . , 2004 ; Uhari et al . , 2003 ) . Some students prefer hearing explanations of ARS questions from their peers who have a similar language and therefore can explain problems and solutions more effectively than the instructor ( Caldwell , 2007 ; Nicol & Table 1 Summary of audience response system beneﬁts . Beneﬁt Description Evidence Classroom environment beneﬁts Attendance Students go to class more Burnstein and Lederman ( 2001 ) , Caldwell ( 2007 ) , and Greer and Heaney ( 2004 ) Attention Students are more focused in class Bergtrom ( 2006 ) , Burnstein and Lederman ( 2001 ) , Caldwell ( 2007 ) , d’Inverno et al . ( 2003 ) , Draper and Brown ( 2004 ) , Elliott ( 2003 ) , Jackson et al . ( 2005 ) , Jones et al . ( 2001 ) , Latessa and Mouw ( 2005 ) , Siau et al . ( 2006 ) , and Slain et al . ( 2004 ) Anonymity All students participate anonymously Caldwell ( 2007 ) , Draper and Brown ( 2004 ) , Jones et al . ( 2001 ) , Siau et al . ( 2006 ) , Simpson and Oliver ( 2007 ) , and Stuart et al . ( 2004 ) Participation Students participate with peers more in class to solve problems Bullock et al . ( 2002 ) , Caldwell ( 2007 ) , Draper and Brown ( 2004 ) , Greer and Heaney ( 2004 ) , Jones et al . ( 2001 ) , Siau et al . ( 2006 ) , Stuart et al . ( 2004 ) , Uhari et al . ( 2003 ) , and Van Dijk et al . ( 2001 ) Engagement Students are more engaged in class Bergtrom ( 2006 ) , Caldwell ( 2007 ) , Draper and Brown ( 2004 ) , Latessa and Mouw ( 2005 ) , Preszler et al . ( 2007 ) , Siau et al . ( 2006 ) , and Simpson and Oliver ( 2007 ) Learning beneﬁts Interaction Students interact more with peers to discuss ideas Beatty ( 2004 ) , Bergtrom ( 2006 ) , Caldwell ( 2007 ) , Elliott ( 2003 ) , Freeman et al . ( 2007 ) , Kennedy et al . ( 2006 ) , Sharma , Khachan , Chan , and O’Byrne ( 2005 ) , Siau et al . ( 2006 ) , Slain et al . ( 2004 ) , Stuart et al . ( 2004 ) , Trees and Jackson ( 2007 ) , and Van Dijk et al . ( 2001 ) Discussion Students actively discuss misconceptions to build knowledge Beatty ( 2004 ) , Brewer ( 2004 ) , Draper and Brown ( 2004 ) , Jones et al . ( 2001 ) , and Nicol and Boyle ( 2003 ) Contingent teaching Instruction can be modiﬁed based on feedback from students Brewer ( 2004 ) , Caldwell ( 2007 ) , Cutts ( 2006 ) , Draper and Brown ( 2004 ) , Elliott ( 2003 ) , Greer and Heaney ( 2004 ) , Hinde and Hunt ( 2006 ) , Jackson et al . ( 2005 ) , Kennedy and Cutts ( 2005 ) , Poulis et al . ( 1998 ) and Stuart et al . ( 2004 ) Learning performance Learning performance increases as a results of using ARS Bullock et al . ( 2002 ) , El - Rady ( 2006 ) , Fagan et al . ( 2002 ) , Kaleta and Joosten ( 2007 ) , Kennedy and Cutts ( 2005 ) , Pradhan et al . ( 2005 ) , Preszler et al . ( 2007 ) , Schackow et al . ( 2004 ) and Slain et al . ( 2004 ) Quality of learning Qualitative difference when learning with ARS ( e . g . , better explanations , thinking about important concepts , resolving misconceptions ) Caldwell ( 2007 ) , d’Inverno et al . ( 2003 ) , Draper and Brown ( 2004 ) , Elliott ( 2003 ) , Greer and Heaney ( 2004 ) , and Nicol and Boyle ( 2003 ) Assessment beneﬁts Feedback Students and teacher like getting regular feedback on understanding Abrahamson ( 2006 ) , Cline ( 2006 ) , Draper et al . ( 2002 ) , McCabe ( 2006 ) , and Pelton and Pelton ( 2006 ) Formative Assessment is done that improves student understanding and quality of teaching Beatty ( 2004 ) , Bergtrom ( 2006 ) , Brewer ( 2004 ) , Bullock et al . ( 2002 ) , Caldwell ( 2007 ) , Draper and Brown ( 2004 ) Dufresne and Gerace ( 2004 ) , Elliott ( 2003 ) , Greer and Heaney ( 2004 ) , Hatch et al . ( 2005 ) , Jackson et al . ( 2005 ) , Siau et al . ( 2006 ) , Simpson and Oliver ( 2007 ) , and Stuart et al . ( 2004 ) Compare Students compare their ARS responses to class responses Burton ( 2006 ) , Caldwell ( 2007 ) , Draper and Brown ( 2004 ) , Hinde and Hunt ( 2006 ) and Simpson and Oliver ( 2007 ) 822 R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 Boyle , 2003 ) . Other students claim that using an ARS pushes them to think more about the important concepts ( Draper & Brown , 2004 ; Greer & Heaney , 2004 ) . Still others believe that the use of an ARS helps them discover and resolve misconceptions ( d’Inverno et al . , 2003 ) . The one drawback noted by several instructors is that not as many concepts can be addressed when using an ARS ( Caldwell , 2007 ; Elliott , 2003 ) . However , many of these same instructors acknowledge that reduced content coverage is more than compensated for by the depth of material that students truly understand ( Elliott , 2003 ) . In summary , using an ARS appears to emphasize the depth of student understanding , not the amount of material ‘‘covered” . 3 . 1 . 4 . Assessment beneﬁts 3 . 1 . 4 . 1 . Feedback . In a regular classroom , feedback can be acquired by multiple means , including a show of hands , asking volunteers to share answers , use of small individual whiteboards to display answers , or using coloured cards to represent multiple choice responses ( Abrahamson , 2006 ; Cline , 2006 ; Draper , Cargill , & Cutts , 2002 ; McCabe , 2006 ; Pelton & Pelton , 2006 ) . However these methods have nota - ble disadvantages . A show of hands , for example , is limited because it is difﬁcult to obtain a quick , accurate sense of class understanding , particularly in a large lecture . Furthermore , some students are inclined to copy the responses of others . In addition , when hands are low - ered , the data is lost ( Abrahamson , 2006 ; Pelton & Pelton , 2006 ) . Also , relying on volunteers is somewhat restrictive because , only the con - ﬁdent students raise their hands ( Banks , 2006 ; Burton , 2006 ; Slain et al . , 2004 ) . Note also that with a show of hands or asking volunteers to respond , anonymity is lost . Whiteboards and coloured cards are more anonymous , but amalgamating responses is a relatively slow process . Using an ARS helps improve the feedback process by guaranteeing anonymity , quickly and efﬁciently collecting and summarizing stu - dent responses , and preventing students from copying the answers from their peers . Finally , with ARSs , students are required to think about a question or problem and then commit to an answer . It has been argued that this commitment to a response is particularly impor - tant when students are required to articulate and defend their answers in a peer - instruction format ( Abrahamson , 2006 ; Beatty , 2004 ; Hake , 1998 ; Pradhan et al . , 2005 ) . 3 . 1 . 4 . 2 . Formative assessment . Formative assessment is used to determine student understanding of concepts without grades , in order to identify misconceptions and alter the course of classroom instruction . Without a tool like an ARS , it is somewhat challenging to calibrate overall student understanding of concepts while they are presented in class . Regular use of an ARS can offer real - time feedback to both instructors and students as to how well concepts are being understood . As stated earlier , experienced teachers can quickly modify expla - nations or mode of instruction ( contingent teaching ) or students can gauge and discuss their understanding with their peers ( peer - instruc - tion ) . Extensive evidence suggests that using an ARS helps provide effective formative assessment ( Beatty , 2004 ; Bergtrom , 2006 ; Brewer , 2004 ; Bullock et al . , 2002 ; Caldwell , 2007 ; Draper & Brown , 2004 ; Dufresne & Gerace , 2004 ; Elliott , 2003 ; Greer & Heaney , 2004 ; Hatch et al . , 2005 ; Jackson et al . , 2005 ; Siau et al . , 2006 ; Simpson & Oliver , 2007 ; Stuart et al . , 2004 ) . 3 . 1 . 4 . 3 . Compare responses with other students . After ARS feedback is presented to the class students are able to compare their understand - ing with their fellow classmates . There is some evidence to suggest that students like to see how well they are doing relative to their peers ( Burton , 2006 ; Caldwell , 2007 ; Draper & Brown , 2004 ; Hinde & Hunt , 2006 ; Simpson & Oliver , 2007 ) . It is unclear from the research to date , though , why students like to compare responses . It could be that the use of an ARS promotes a competitive atmosphere , a goal that may not promote a strong sense of community . Alternatively , some students may want to monitor their progress , while others may want assurance that they are not alone in their misunderstanding of key concepts . More research is needed to determine whether student appeal for com - parison with peers is a positive or negative inﬂuence on developing a classroom community . 3 . 2 . Challenges to using ARSs Three categories of challenges were predominant in the ARS literature : technology , teacher , and student - based . Each of these challenges are discussed in detail below and summarized in Table 2 . 3 . 2 . 1 . Technological challenges Two main technology - based difﬁculties were reported when using ARSs . First , when students were responsible for purchasing their own remote devices , they did not consistently bring them to class or they were lost . Because of the class dependence on ARSs , students without remote devices were unable to fully participate ( Caldwell , 2007 ; Reay , Bao , Li , Warnakulasooriya , & Baugh , 2005 ) . Second , a more critical technological issue occurred when remote devices did not function properly or the signal was not received by the instructor’s computer . This was a particularly stressful experience when students were being evaluated ( El - Rady , 2006 ; Hatch et al . , 2005 ; Sharma , Khachan , Chan , & O’Byrne , 2005 ; Siau et al . , 2006 ) . Thus , for an ARS to be a successful learning tool , the technology has to function consistently and efﬁ - ciently . Two possible solutions to the above mentioned technology problems include supplying students with remote devices in every class rather than relying on students to bring them ( Reay et al . , 2005 ) and using radio frequency devices which are more reliable than the less expensive infrared models . 3 . 2 . 2 . Teacher - centred challenges 3 . 2 . 2 . 1 . Responding to student feedback . One anticipated beneﬁt of ARSs was to collect feedback from students throughout a lecture so that the teacher could adjust instructional strategies when necessary . Limited research has been done examining how well this approach works in practice . As Abrahamson ( 2006 ) notes , it is one thing to ﬁnd out that students do not understand a concept – it is quite another to in - stantly adjust teaching style and offer a better explanation . Relatively inexperienced teachers may have difﬁculty using contingent teaching and frustration may ensue ( Hu et al . , 2006 ) . It may be that peer - instruction , which involves greater student involvement when concepts are not understood , is an easier strategy to use with ARSs . 3 . 2 . 2 . 2 . Coverage . One of the main concerns about using an ARS on a regular basis is coverage of content . Considerable research indicates that teachers , and sometimes students , believe that less content is addressed when using an ARS ( Beatty , 2004 ; Beatty , Gerace , Leonard , & Dufresne , 2006 ; Burnstein & Lederman , 2001 ; Burton , 2006 ; Caldwell , 2007 ; Cutts , 2006 ; d’Inverno et al . , 2003 ; Draper & Brown , 2004 ; R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 823 Fagan et al . , 2002 ; Freeman et al . , 2007 ; Hatch et al . , 2005 ; Horowitz , 2006 ; Sharma , Khachan , Chan , & O’Byrne , 2005 ; Siau et al . , 2006 ; Slain et al . , 2004 ; Steinhert & Snell , 1999 ; Stuart et al . , 2004 ) . Responding to higher level questions that target misconceptions can take signif - icantly more time than merely presenting material in a lecture format . In addition , the time required to set up the ARS , hand out the remote controls at the beginning of the class , and collect remote controls at the end of the class can be signiﬁcant ( Hatch et al . , 2005 ; Hu et al . , 2006 ; Stuart et al . , 2004 ) . Moreover , some studies report that class wide discussion takes too much time and that it is easy to drift away from the main ideas being addressed ( Nicol & Boyle , 2003 ; Reay et al . , 2005 ) . Some researchers have reported that concepts covered in a traditional lecture may not be understood as well as concepts learned in an ARS - based classroom ( Beatty et al . , 2006 ; Caldwell , 2007 ) . One way to cover subject matter not addressed in class is to require students to do more outside reading and class preparation ( Bergtrom , 2006 ; Bullock et al . , 2002 ; Burnstein & Lederman , 2001 ; Caldwell , 2007 ; Slain et al . , 2004 ) . Research to date is limited with respect to evaluating how well this strategy works . 3 . 2 . 2 . 3 . Developing questions . Writing good ARS questions can be a demanding task for instructors . Researchers agree that the most effective questions have the following characteristics : they address a speciﬁc learning goal , make students aware of opinions other than their own , uncover misconceptions and confusions , explore ideas in a new context , and elicit a wide range of responses ( Caldwell , 2007 ; Crouch & Mazur , 2001 ; Miller , Santana - Vega , & Terrell , 2006 ; Tanner & Allen , 2005 ) . Unfortunately there are very few collections of ARS questions available in most ﬁelds , so instructors have to develop original questions , a process that is very time consuming ( Allen & Tanner , 2005 ; Beatty et al . , 2006 ; Boyle , 2006 ; El - Rady , 2006 ; Fagan et al . , 2002 ; Freeman et al . , 2007 ; Horowitz , 2006 ; Paschal , 2002 ; Robertson , 2000 ) . 3 . 2 . 3 . Student - centered challenges 3 . 2 . 3 . 1 . New method of learning . Some students may respond negatively to the use of an ARS simply because the rules for learning have changed . A switch of teaching methods from lecturing to ARS questioning can lead to stress , frustration , and resistance in the beginning ( Beatty , 2004 ; Boyle , 2006 ; Fagan et al . , 2002 ) . In addition , some students are distracted by the use of an ARS ( Siau et al . , 2006 ) . Still others question their ability to direct their own learning with this tool ( Allen & Tanner , 2005 ) . Finally , as discussed previously , some students indi - cate that less content is covered when using the ARS approach ( Allen & Tanner , 2005 ) . While resistance to using ARSs is relatively uncom - mon ( Fagan et al . , 2002 ) , it is important note these concerns . Trees and Jackson ( 2007 ) reported that using an ARS requires more cognitive energy and cooperation from students . This type of ex - tended effort may not be readily accepted by all students , particularly those who are accustomed to and more comfortable with relatively passive lectures . More research is needed , though , to determine whether students adapt to and accept the additional cognitive effort that may be required when using an ARS . The popularity of ARSs and the positive impact on learning suggests that the extra effort required may not be a signiﬁcant barrier ( Caldwell , 2007 ; Fies & Marshall , 2006 ; Judson & Sawada , 2002 , 2006 ; Simpson & Oliver , 2007 ) . 3 . 2 . 3 . 2 . Increased confusion in discussions . Not all discussions run smoothly when an ARS is used . Some students dominate group discussions ( Nicol & Boyle , 2003 ) and the debate of different perspectives and solutions can increase student confusion ( Nicol & Boyle , 2003 ; Reay et al . , 2005 ) . Furthermore , some students feel that ARS - based discussion distracts them from the concepts being presented in a lesson ( Draper & Table 2 Summary of audience response system challenges . Challenge Description Evidence Technology - based challenges Bringing remotes Students forgot or lost remotes and could not participate in class Caldwell ( 2007 ) and Reay et al . ( 2005 ) ARS did not work Remote devices did not function properly El - Rady ( 2006 ) , Hatch et al . ( 2005 ) , Sharma , Khachan , Chan , and O’Byrne ( 2005 ) , Siau et al . ( 2006 ) Teacher - based challenges Responding to student feedback Less experienced teachers cannot adjust to student feedback Abrahamson ( 2006 ) and Hu et al . ( 2006 ) Coverage Cover less course content if ARS is used Beatty ( 2004 ) , Beatty et al . ( 2006 ) , Burnstein and Lederman ( 2001 ) , Caldwell ( 2007 ) , d’Inverno et al . ( 2003 ) , Burton ( 2006 ) , Cutts ( 2006 ) , Draper and Brown ( 2004 ) , Fagan et al . ( 2002 ) , Freeman et al . ( 2007 ) , Hatch et al . ( 2005 ) , Sharma , Khachan , Chan , and O’Byrne ( 2005 ) , Siau et al . ( 2006 ) , Slain et al . ( 2004 ) , Steinhert and Snell ( 1999 ) , and Stuart et al . ( 2004 ) Developing questions Time consuming to create ARS questions Allen and Tanner ( 2005 ) , Beatty et al . ( 2006 ) , Boyle ( 2006 ) , El - Rady ( 2006 ) , Fagan et al . ( 2002 ) , Freeman et al . ( 2007 ) , Horowitz ( 2006 ) , Paschal ( 2002 ) and Robertson ( 2000 ) Student - based challenges New method Students ﬁnd it difﬁcult to shift to a new way of learning Allen and Tanner ( 2005 ) , Beatty ( 2004 ) , Fagan et al . ( 2002 ) and Siau et al . ( 2006 ) Discussion Discussion leads to confusion or wasting time Draper and Brown ( 2004 ) , Nicol and Boyle ( 2003 ) , and Reay et al . ( 2005 ) Effort Too much effort is required by students when using ARSs Trees and Jackson ( 2007 ) Summative assessment Using ARS for tests may not be popular with students Caldwell ( 2007 ) and Kay ( 2008 ) Attendance for grades Students do not like ARSs used for monitoring attendance Caldwell ( 2007 ) Identifying students Students want to remain anonymous Abrahamson ( 2006 ) Negative feedback Students feel bad when receiving negative feedback Carnaghan and Webb ( 2007 ) 824 R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 Brown , 2004 ) or view class discussion as intimidating and a source of anxiety ( Nicol & Boyle , 2003 ) . Even though these problems have not been widely reported , more information is needed about creating effective discussion that is focussed , non - threatening , and efﬁcient . 3 . 2 . 3 . 3 . Being monitored . There is some evidence to suggest that students react negatively to being monitored by ARSs . Key problem areas include summative assessment , attendance , eliminating anonymity , and reaction to negative feedback . Each of these challenges will be dis - cussed in turn . Summative assessment , or the evaluation of student performance based on formal grades , has been used extensively with ARSs in high - er education ( Fies & Marshall , 2006 ) , although little research has been conducted on the impact of this practice . Some evidence suggests that students do not enjoy using ARSs for grades ( Caldwell , 2007 ) . In a recent paper ( Kay , LeSage , & Knaack , in press ) , secondary school students did not like using ARSs for tests . However , when ARSs were used for formative assessment , students were signiﬁcantly more moti - vated and cognitively engaged . More research , though , is needed to examine the impact of summative assessment and ARSs on learning . As stated earlier , ARSs have been used in some higher education classes to monitor attendance . While not widely reported , some stu - dents resented being scrutinized and disapproved of grades being attached to ARS participation ( Caldwell , 2007 ) . Another unfortunate reaction to monitoring is that students brought multiple remote devices to class to record attendance for missing classmates , a practice reported 20 – 58 % of the time ( Caldwell , 2007 ) . It could be argued that an effective learning environment should provide inherent learning incentives so that students want to attend . Attaching a grade to attendance using an ARS may cultivate resistance and undermine the goal of developing an effective learning environment . While students clearly appreciate the anonymity associated with using ARSs ( Caldwell , 2007 ; Draper & Brown , 2004 ; Jones et al . , 2001 ; Siau et al . , 2006 ; Simpson & Oliver , 2007 ; Stuart et al . , 2004 ) , the reasons why students feel more comfortable when they cannot be iden - tiﬁed are unclear at this point . One study reported that some students are less conﬁdent about using an ARS when their names are asso - ciated with a speciﬁc remote device . Abrahamson ( 2006 ) identiﬁed one possible reason for this reticence – students do not like being watched over by ‘‘big brother” . In small classes , perhaps at the middle and secondary school level , it may be necessary to monitor progress so that teachers can provide individual attention to students . However , in large classes , individual attention is not a realistic goal and , other than attendance and participation , there may be little reason to remove anonymity . One ﬁnal monitoring concern about using ARSs is that students who respond incorrectly may feel uncomfortable , particularly when a majority of the class is correct . Carnaghan and Webb ( 2007 ) were the only researchers to report this phenomenon . It is possible that the speciﬁc teaching strategy used with an ARS may inﬂuence how students react to getting answers right or wrong . For example , if cooper - ation and articulation of ideas is emphasized instead of getting a correct answer , students may feel less insecure about incorrect answers . The goal of peer instruction , for example , is to uncover and discuss misconceptions , so reasoning is more valued than choosing the right answer . 4 . Future research 4 . 1 . Methodology for investigating ARSs A number of authors have argued that there are several key problems with current research on ARSs including : a lack of systematic research , a bias toward using anecdotal , qualitative data , excessive focus on attitudes as opposed to learning and cognitive processes , and samples derived from limited educational settings . Each of these limitations will be discussed . 4 . 1 . 1 . Lack of systematic research Several authors ( Caldwell , 2007 ; Fies & Marshall , 2006 ; Freeman et al . , 2007 ) have noted that research on ARSs has been largely unsys - tematic . However , it is not clear what these authors mean by ‘‘systematic” . In the current review , a number of studies have been conducted in a thoughtful , planned manner where the learning impact of ARSs was calibrated ( Bullock et al . , 2002 ; Fagan et al . , 2002 ; Kennedy & Cutts , 2005 ; Paschal , 2002 ; Pradhan et al . , 2005 ; Rao & DiCarlo , 2000 ; Schackow et al . , 2004 ) . However , data collection instruments are noticeably lacking in reliability and validity analysis . Only four studies reported estimates of validity and reliability ( Penuel , Boscardin , Masyn , & Crawford , 2007 ; Schackow et al . , 2004 ; Siau et al . , 2006 ; Trees & Jackson , 2007 ) . Therefore it is necessary to improve data collection pro - cedures and perhaps focus future studies on speciﬁc measurable goals . 4 . 1 . 2 . Bias toward qualitative research Several authors have maintained that the majority of ARS data collected to date is anecdotal or qualitative ( Fies & Marshall , 2006 ; Kaleta & Joosten , 2007 ; Schackow et al . , 2004 ) . An analysis of data collection techniques used in the current review partially supports this claim . Almost half the data collected was qualitative , however , 29 % used surveys , and 11 % assessed learning performance . However , both qual - itative and quantitative data is needed to fully understand the use and impact of ARSs , so triangulation of methods might be a desirable direction for future research efforts . 4 . 1 . 3 . Attitude vs . learning Some researchers have noted that the majority of ARS investigations consist of broad assessments of attitude and / or anecdotal obser - vations ( Carnaghan & Webb , 2007 ; Kennedy & Cutts , 2005 ; Siau et al . , 2006 ; Simpson & Oliver , 2007 ) . Indeed , 54 % of the 67 studies in the current review examined attitudes toward ARSs . On the other hand , over one third examined learning and learning performance . However , no studies could be found examining the actual cognitive processes involved when students are involved in ARS - stimulated discussion ( Kennedy et al . , 2006 ; Penuel , Abrahamson , & Roschelle , 2006 ) . Clearly this is an untapped area for further ARS investigation . 4 . 1 . 4 . Limited educational settings The wide - spread implementation of ARSs has only been observed in the past ﬁve to seven years , with the majority of use occurring at the tertiary level . It is speculated that the cost of ARSs is only now becoming affordable in the K - 12 domain . In the current review , of the 61 R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 825 studies where data was collected , 59 looked at higher education or professionals with the primary focus on mathematics and science . A reasonable argument could be made that there is a need for a broader range of settings to be examined including K - 12 classrooms and non mathematics / science - based courses ( Fies & Marshall , 2006 ) in order to fully understand the educational impact of ARSs . 4 . 1 . 5 . Future research opportunities A review of 67 peer - reviewed articles and chapters has revealed key beneﬁts and challenges with respect to using ARSs . However , with any new area of research , there are often many questions left unanswered . These questions provide at least four directions for future researchers . First , more detailed research is needed to determine why speciﬁc beneﬁts and challenges inﬂuence the use of ARSs . For example , what is engaging about an ARS and is increased interaction superﬁcial or meaningful in terms of learning ? Does resistance to using ARSs translate into a long term negative impact on learning ? Second , more research is needed on analysing the impact of speciﬁc types of questions on creating student - centred , knowledge - rich learning that builds classroom community . There is considerable research to suggest that questions that focus on misconceptions are effec - tive , but what about application questions or case study problems ? To what extent does formative feedback inﬂuence student acquisition of concepts ? Third , the context of ARS use needs to be expanded to include social science subject areas and K - 12 classrooms . It is unclear whether ARSs are best suited for more technical subjects or whether a different set of strategies needs to be used for smaller classes and younger students . Broadening the research scope of investigation should provide important data on the use and effectiveness of ARSs in different learning environments . Finally , more research is needed on individual differences in the use of ARSs . Focussing on gender , grade level , age , and learning style would be a viable starting point . There is considerable data on individual differences in the use of other technologies , so it is important to determine if these differences extend to the use of ARSs . From a practical and ethical perspective , it is essential that we identify potential students that would be negatively affected by the use of ARSs so that we can accommodate these individuals . References Abrahamson , L . ( 2006 ) . A brief history of networked classrooms : Effects , cases , pedagogy , and implications . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 1 – 25 ) . Hershey , PA : Information Science Publishing . Allen , D . , & Tanner , K . ( 2005 ) . Infusing active learning into the large - enrolment biology class : Seven strategies , from the simple to complex . Cell Biology Education , 4 , 262 – 268 . Banks , D . A . ( 2006 ) . Reﬂections on the use of ARS with small groups . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 373 – 386 ) . Hershey , PA : Information Science Publishing . Beatty , I . ( 2004 ) . Transforming student learning with classroom communication systems . EDUCAUSE Research Bulletin , 2004 ( 3 ) , 1 – 13 . < http : / / www . educause . edu / ir / library / pdf / ERB0403 . pdf > . Retrieved 03 . 11 . 07 . Beatty , I . D . , Gerace , W . J . , Leonard , W . J . , & Dufresne , R . J . ( 2006 ) . Designing effective questions for classroom response system teaching . American Journal of Physics , 74 ( 1 ) , 31 – 39 . Bergtrom , G . ( 2006 ) . Clicker sets as learning objects . Interdisciplinary Journal of Knowledge and Learning Objects , 2 . < http : / / ijklo . org / Volume2 / v2p105 - 110Bergtrom . pdf > . Retrieved 03 . 11 . 07 . Boyle , J . ( 2006 ) . Eight years of asking questions . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 289 – 304 ) . Hershey , PA : Information Science Publishing . Brewer , C . A . ( 2004 ) . Near real - time assessment of student learning and understanding in biology courses . BioScience , 54 ( 11 ) , 1034 – 1039 . Bullock , D . W . , LaBella , V . P . , Clinghan , T . , Ding , Z . , Stewart , G . , & Thibado , P . M . ( 2002 ) . Enhancing the student – instructor interaction frequency . The Physics Teacher , 40 , 30 – 36 . Burnstein , R . A . , & Lederman , L . M . ( 2001 ) . Using wireless keypads in lecture classes . The Physics Teacher , 39 ( 1 ) , 8 – 11 . Burton , K . ( 2006 ) . The trial of an audience response system to facilitate problem - based learning in legal education . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 265 – 276 ) . Hershey , PA : Information Science Publishing . Caldwell , J . E . ( 2007 ) . Clickers in the large classroom : Current research and best - practice tips . Life Sciences Education , 6 ( 1 ) , 9 – 20 . Carnaghan , C . , & Webb , A . ( 2007 ) . Investigating the effects of group response systems on student satisfaction , learning , and engagement in accounting education . Issues in Accounting Education , 22 ( 3 ) , 391 – 409 . Cline , K . S . ( 2006 ) . Classroom voting in mathematics . Mathematics Teacher , 100 ( 2 ) , 100 – 104 . Crouch , C . H . , & Mazur , E . ( 2001 ) . Peer instruction : Ten years of experience and results . American Journal of Physics , 69 ( 9 ) , 970 – 977 . Cutts , Q . ( 2006 ) . Practical lessonsfrom four years of usingan ARSin every lecture of a large class . InD . A . Banks ( Ed . ) , Audience response systems inhigher education ( pp . 65 – 79 ) . Hershey , PA : Information Science Publishing . D’Inverno , R . , Davis , H . , & White , S . ( 2003 ) . Using a personal response system for promoting student interaction . Teaching Mathematics and Its Applications , 22 ( 4 ) , 163 – 169 . Draper , S . W . , & Brown , M . I . ( 2004 ) . Increasing interactivity in lectures using an electronic voting system . Journal of Computer Assisted Learning , 20 ( 2 ) , 81 – 94 . Draper , S . W . , Cargill , J . , & Cutts , Q . ( 2002 ) . Electronically enhanced classroom interaction . Australian Journal of Educational Technology , 18 , 13 – 23 . Dufresne , R . J . , & Gerace , W . J . ( 2004 ) . Assessing - to - learn : Formative assessment in physics instruction . The Physics Teacher , 42 , 428 – 433 . Durbin , S . M . , & Durbin , K . A . ( 2006 ) . Anonymous polling in a engineering tutorial environment : A case study . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 116 – 126 ) . Hershey , PA : Information Science Publishing . Elliott , C . ( 2003 ) Using a personal response system in economics teaching . International Review of Economics Education , 1 ( 1 ) , < http : / / www . economicsnetwork . ac . uk / iree / i1 / elliott . htm > . Retrieved 03 . 11 . 07 . El - Rady , J . ( 2006 ) . To click or not to click : That’s the question . Innovate Journal of Online Education , 2 ( 4 ) . < http : / / www . innovateonline . info / index . php ? view = article & id = 171 > . Retrieved 03 . 11 . 07 . Fagan , A . P . , Crouch , C . H . , & Mazur , E . ( 2002 ) . Peer instruction : Results from a range of classrooms . The Physics Teacher , 40 ( 4 ) , 206 – 209 . Fies , C . , & Marshall , J . ( 2006 ) . Classroom response systems : A review of the literature . Journal of Science Education and Technology , 15 ( 1 ) , 101 – 109 . Freeman , M . , Bell , A . , Comerton - Forder , C . , Pickering , J . , & Blayney , P . ( 2007 ) . Factors affecting educational innovation with in class electronic response systems . Australasian Journal of Educational Technology , 23 ( 2 ) , 149 – 170 . Greer , L . , & Heaney , P . J . ( 2004 ) . Real - time analysis of student comprehension : An assessment of electronic student response technology in an introductory earth science course . Journal of Geoscience Education , 52 ( 4 ) , 345 – 351 . Hake , R . R . ( 1998 ) . Interactive - engagement versus traditional methods : A six - thousand - student survey of mechanics text data for introductory physics courses . American Journal of Physics , 66 ( 1 ) , 64 – 74 . Hatch , J . , Jensen , M . , & Moore , R . ( 2005 ) . Manna from heaven or clickers from hell . Journal of College Science Teaching , 34 ( 7 ) , 36 – 39 . Hinde , K . , & Hunt , A . ( 2006 ) . Using the personal response system to enhance student learning : Some evidence from teaching economics . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 140 – 154 ) . Hershey , PA : Information Science Publishing . Horowitz , H . M . ( 2006 ) . ARS evolution : Reﬂections and recommendations . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 53 – 63 ) . Hershey , PA : Information Science Publishing . Hu , J . , Bertol , P . , Hamilton , M . , White , G . , Duff , A . , & Cutts , Q . ( 2006 ) . Wireless interactive teaching by using keypad - based ARS . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 209 – 221 ) . Hershey , PA : Information Science Publishing . Jackson , M . , Ganger , A . Ac . , Bridge , P . D . , & Ginsburg , K . ( 2005 ) . Wireless handheld computers in the undergraduate medical curriculum . Medical Education Online , 10 ( 5 ) . < http : / / www . med - ed - online . org / pdf / t0000062 . pdf > . Retrieved 03 . 11 . 07 . 826 R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 Jones , C . , Connolly , M . , Gear , A . , & Read , M . ( 2001 ) . Group integrative learning with group process support technology . British Journal of Educational Technology , 32 ( 5 ) , 571 – 581 . Judson , E . , & Sawada , D . ( 2002 ) . Learning from past and present : Electronic response systems in college lecture halls . Journal of Computers in Mathematics and Science Teaching , 21 ( 2 ) , 167 – 181 . Judson , E . , & Sawada , D . ( 2006 ) . Audience response systems : Insipid contrivances or inspiring tools ? In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 26 – 39 ) . Hershey , PA : Information Science Publishing . Kaleta , R . , & Joosten , T . ( 2007 ) . Student response systems : A University of Wisconsin system study of clickers . EDUCAUSE Research Bulletin , 2007 ( 10 ) , 1 – 12 . Kay , R . H . ( 2008a ) . Appendix A – Labels used to describe audience response systems . < http : / / faculty . uoit . ca / kay / papers / arsrev / AppendixA _ Labels . pdf > . Retrieved 25 . 11 . 08 . Kay , R . H . ( 2008b ) . Appendix B – Coding of research papers reviewed for ARS strategy paper . < http : / / faculty . uoit . ca / kay / papers / arsrev / AppendixB _ Coding . pdf > . Retrieved 25 . 11 . 08 . Kay , R . H . ( 2008c ) . Appendix C – List of studies reviewed for ARS strategy paper . < http : / / faculty . uoit . ca / kay / papers / arsrev / AppendixC2 . pdf > . Retrieved 25 . 11 . 08 . Kay , R . H . , LeSage , A . , & Knaack , L . ( in press ) . Examining the use of audience response systems in secondary school classrooms : A formative analysis . Journal of Interactive Learning Research . Kennedy , G . E . , & Cutts , Q . I . ( 2005 ) . The association between students’ use of electronic voting systems and their learning outcomes . Journal of Computer Assisted Learning , 21 ( 4 ) , 260 – 268 . Kennedy , G . E . , Cutts , Q . , & Draper , S . W . ( 2006 ) . Evaluating electronic voting systems in lectures : Two innovative methods . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 155 – 174 ) . Hershey , PA : Information Science Publishing . Latessa , R . , & Mouw , D . ( 2005 ) . Use of audience response system to augment interactive learning . Family Medicine , 37 ( I ) , 12 – 14 . < http : / / www . stfm . org / fmhub / fm2005 / January / Robyn12 . pdf > . Retrieved 03 . 11 . 07 . McCabe , M . ( 2006 ) . Live assessment by questioning in an interactive classroom . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 276 – 288 ) . Hershey , PA : Information Science Publishing . Miller , R . L . , Santana - Vega , E . , & Terrell , M . S . ( 2006 ) . Can good questions and peer discussion improve calculus instruction ? PRIMUS , 16 ( 3 ) , 1 – 9 . Nicol , D . J . , & Boyle , J . T . ( 2003 ) . Peer instruction versus class - wide discussion in large classes : A comparison of two interaction methods in the wired classroom . Studies in Higher Education , 28 ( 4 ) , 457 – 473 . Paschal , C . B . ( 2002 ) . Formative assessment in physiology teaching using a wireless classroom communication system . Advances in Physiology Education , 26 ( 4 ) , 299 – 308 . Pelton , L . F . , & Pelton , T . ( 2006 ) . Selected and constructed response systems in mathematics . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 175 – 186 ) . Hershey , PA : Information Science Publishing . Penuel , W . R . , Abrahamson , L . , & Roschelle , J . ( 2006 ) . Theorizing the transformed classroom : Sociocultural interpretation of the effects of audience response systems in higher education . In D . A . Banks ( Ed . ) , Audience response systems in higher education ( pp . 187 – 208 ) . Hershey , PA : Information Science Publishing . Penuel , W . R . , Boscardin , C . K . , Masyn , K . , & Crawford , V . M . ( 2007 ) . Teaching with student response systems in elementary and secondary education settings : A survey study . Educational Technology , Research and Development , 55 ( 4 ) , 315 – 346 . Poulis , J . , Massen , C . , Robens , E . , & Gilbert , M . ( 1998 ) . Physics lecturing with audience paced feedback . American Journal of Physics , 66 ( 5 ) , 439 – 441 . Pradhan , A . , Sparano , D . , & Ananth , C . V . ( 2005 ) . The inﬂuence of an audience response system on knowledge retention : An application to resident education . American Journal of Obstetrics and Gynecology , 193 ( 5 ) , 1827 – 1830 . Preszler , R . W . , Dawe , A . , Shuster , C . B . , & Shuster , M . ( 2007 ) . Assessment of the effects of student response systems on student learning and attitudes over a broad range of biology courses . CBE - Life Sciences Education , 6 ( 1 ) , 29 – 41 . Rao , S . P . , & DiCarlo , S . E . ( 2000 ) . Peer instruction improves performance on quizzes . Advances in Physiology Education , 24 ( 1 ) , 51 – 55 . Reay , N . W . , Bao , L . , Li , P . , Warnakulasooriya , R . , & Baugh , G . ( 2005 ) . Toward the effective use of voting machines in physics lectures . American Journal of Physics , 73 ( 6 ) , 554 – 558 . Robertson , L . J . ( 2000 ) . Twelve tips for using a computerised interactive audience response system . Medical Teacher , 22 ( 3 ) , 237 – 239 . Schackow , T . E . , Milton , C . , Loya , L . , & Friedman , M . ( 2004 ) . Audience response system : Effect on learning in family medicine residents . Family Medicine , 36 , 496 – 504 . Sharma , M . D . , Khachan , J . , Chan , B . , & O’Byrne , J . ( 2005 ) . An investigation of the effectiveness of electronic classroom communication systems in large lectures . Australasian Journal of Educational Technology , 21 ( 2 ) , 137 – 154 . Siau , K . , Sheng , H . , & Nah , F . ( 2006 ) . Use of classroom response system to enhance classroom interactivity . IEEE Transactions on Education , 49 ( 3 ) , 398 – 403 . Simpson , V . , & Oliver , M . ( 2007 ) . Electronic voting systems for lectures then and now : A comparison of research and practice . Australasian Journal of Educational Technology , 23 ( 2 ) , 187 – 208 . Slain , D . , Abate , M . , Hidges , B . M . , Stamatakis , M . K . , & Wolak , S . ( 2004 ) . An interactive response system to promote active learning in the doctor of pharmacy curriculum . American Journal of Pharmaceutical Education , 68 ( 5 ) , 1 – 9 . Steinhert , Y . , & Snell , L . S . ( 1999 ) . Interactive lecturing : Strategies for increasing participation in large group presentations . Medical Teacher , 21 ( 1 ) , 37 – 42 . Stuart , S . A . J . , Brown , M . I . , & Draper , S . W . ( 2004 ) . Using an electronic voting system in logic lectures : One practitioner’s application . Journal of Computer Assisted Learning , 20 ( 2 ) , 95 – 102 . Tanner , K . , & Allen , D . ( 2005 ) . Approaches to biology teaching and learning : Understanding the wrong answers – Teaching toward conceptual change . Cell Biology Education , 4 , 112 – 117 . Trees , A . R . , & Jackson , M . H . ( 2007 ) . The learning environment in clicker classrooms : Student processes of learning and involvement in large university courses using student response systems . Learning , Media and Technology , 32 ( 1 ) , 21 – 40 . Uhari , M . , Renko , M . , & Soini , H . ( 2003 ) . Experiences of using an interactive audience response system in lectures . BMC Medical Education , 3 ( 12 ) , 1 – 6 . Van Dijk , L . A . , Van Den Berg , G . C . , & Van Keulen , H . ( 2001 ) . European Journal of Engineering Education , 26 ( 1 ) , 15 – 28 . R . H . Kay , A . LeSage / Computers & Education 53 ( 2009 ) 819 – 827 827