Exploring the Performance of Generative AI Tools in Electrical Engineering Education Zhaofeng Zhong School of Electrical Engineering and Computer Science University of Queensland Brisbane , Australia zhaofeng . zhong @ uq . net . au Chamith Wijenayake School of Electrical Engineering and Computer Science University of Queensland Brisbane , Australia c . wijenayake @ uq . edu . au Chamira U . S . Edussooriya Department of Electronic and Telecommunication Engineering University of Moratuwa Moratuwa , Sri Lanka chamira @ uom . lk Abstract —This paper explores the use cases and performance of generative artificial intelligence ( AI ) tools in the context of Electrical Engineering education . A summary of commonly used generative AI tools in Engineering education is provided along with a review of their use cases from recent literature . The performances of the generative AI tools GPT - 3 . 5 , GPT - 4 and Google Bard are examined using custom - made question sets in two representative courses : Digital Logic Design and Digital Signal Processing . The paper highlights that GPT4 achieves over 50 % accuracy in both courses and generative AI tools are more effective at solving standalone concept questions than analytical or numerical questions . I . I NTRODUCTION Generative artificial intelligence ( AI ) has become a widely used tool that enhances both professional tasks and daily life . It has the capacity to autonomously generate various types of content , including text , code , images , and video [ 1 ] , [ 2 ] . The text - based generative AI tools accept text as input and produce text , code , image and video as output . These tools may be classified into four categories based on the output modality : text , code , image , and video generators . Text generators can interactively answer user questions with realistic and creative text content . On the other hand , code generators provide automated code suggestions that improve productivity for more efficient work . Image and video gen - erators are more difficult to train compared to their text and code generators due to the complexity of image and video resources . Therefore , many generative AI platforms for image and video generation are still under development , such as the VQGAN - CLIP system developed by OpenAI and the Make - A - Video project by Meta AI . We present a comparison of some popular generative AI tools based on their use cases in Table I . All of these generative AI tools are beneficial to academic educators . If educators ask GPT - 4 to generate a mind map for digital signal processing ( prompt : ”Can you create a mind map for digital signal processing ( DSP ) ? ” ) , it provides a table for planning a DSP course including Basics , Signal Types , Core Concepts , Transforms , Filters , Systems , Applications , and Software & Hardware . Furthermore , Simplified employs the image generator in presentation design . This application could help teachers to generate an initial version of a course PowerPoint based on text prompts . Fig . 1 : The answer of GPT - 4 for the question “Can you briefly summarize the advantages and disadvantages of an FIR filter ? ” . On the other hand , students can also benefit from generative AI tools . In a DSP course , teachers may only teach the details about digital FIR filters . Students may require a summary to remember the benefits and negatives of finite - duration impulse response ( FIR ) filters to prepare for a quiz or an exam . There - fore , they can ask GPT - 4 that “Can you briefly summarize the advantages and disadvantages of the FIR filter ? ” . GPT - 4 generated the text shown in Figure . 1 , which can be useful from a student perspective in creating summaries for revising the detailed technical content learnt during the classes . The generative AI tools can also guide students to study programming by offering basic template codes for various tasks . Not only in the cases of standard programming , but also in uses cases such as hardware description languages used to describe a digital system , AI tools can generate fairly accurate and efficient code segments . For instance , students can ask GPT - 4 : “Can you write a VHDL code for an FIR filter ? ” . GPT - 4 provided a code template and explained how the code achieves users’ requirements . In addition , GPT - 4 also guide students on how to customize this code to adjust the bit widths , 2023 I EEE I n t e r n a ti on a l C on f e r e n ce on T eac h i ng , A ss e ss m e n t a nd L ea r n i ng f o r E ng i n ee r i ng ( T A LE ) | 978 - 1 - 6654 - 5331 - 8 / 23 / $ 31 . 00 © 2023 I EEE | DO I : 10 . 1109 / T A LE 56641 . 2023 . 10398370 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . TABLE I : Popular generative AI tools classified based on the output modality . Text - to - X Generator Generative AI tool Description Example use cases OpenAI GPT - 4 ( https : / / openai . com / product / gpt - 4 ) GPT - 4 is the latest version of ChatGPT . It is better at generating realistic and creative text to answer users’ questions . Google Bard ( https : / / bard . google . com / ? hl = en GB ) Bard is a conversational AI chatbot like GPT - 4 . However , it has internet to real - time access to Google’s search engine . Text Microsoft Bing ( https : / / www . bing . com / ) Bing is a web search engine that uses AI to help users searching answers . Students : - Personal tutoring - Exam preparation Educators : - Lesson planning - Assessment design GitHub Copilot ( https : / / github . com / features / copilot ) Copilot is developed by GitHub and OpenAI . It can suggest code for various programming languages because it trained by public repositories . Code Tabnine ( https : / / www . tabnine . com / install ) Tabnine can learn users’ coding styles and suggest code in this style . Students : - Coding suggestion Educators : - Programming template DALL - E 2 ( https : / / openai . com / product / dall - e - 2 ) DALL - E 2 is developed by OpenAI . It is better at generating realistic , detailed , and creative images . Image Simplified ( https : / / simplified . com / ) Simplified is easier to use with a user - friendly interface . It provides various applications . Students : - Visualization of Concepts Educators : - Power point template Synthesia ( https : / / www . synthesia . io / ) Convert text into speech video of the avatar speaking the text in various languages . Video MetaAI Make - A - Video ( https : / / makeavideo . studio / ) A state - of - the - art system that generates creative and realistic video from the text description . Students : - Project presentations number of taps and coefficient of FIR filter for their specific needs . These capabilities enable students to understand the code template and how to use it for different cases . While the field of generative AI tools and its impact on Engineering Education is still at relative early stages with rapid growth , in this paper , we provide an early exploration of uses cases and accuracy of AI tools in two representative subjects in Electrical Engineering : Digital Logic Design and Digital Signal Processing . We first provide a brief review of the most common generative AI tools in Engineering Education and recent literature around them . II . R ELATED W ORKS Despite being widely popular with the introduction of ChatGPT a few months ago , several articles have already been published on the different faces of generative AI tools in the context of education due to their impressive and unprecedented capabilities . Table . II summarizes 16 related works under four categories . The paper [ 3 ] presents a review on the utilisation of generative AI tools by educators for their pedagogy whereas the paper [ 4 ] critically analyse how generative AI tools co - exist as a transformative resource in the future of education . In [ 5 ] , authors presents potential benefits of generative AI tools ( in particularly , ChatGPT ) in promoting teaching and learning , for examples , promotion of personalized and inter - active learning . Furthermore , limitations of genraitve AI tools , such as generating wrong information , are also highlighted . The paper [ 6 ] provides a comprehensive review on ChatGPT with underlying technology , applications , and challenges on different fields of education including Science , Technology , Engineering , and Mathematics ( STEM ) education . The paper [ 7 ] specifically discuss the generative AI tools in engineering education . Researchers and educators can better understand the poten - tial applications of generative AI by evaluating its performance in education . Several previous works investigate the perfor - mance and limitations of generative AI . The papers [ 8 ] – [ 11 ] evaluate various generative AI tools by different educational assessments . Both [ 9 ] , [ 10 ] compare the newest GPT4 and the old ChatGPT ( GPT - 3 . 5 ) on multiple - choice questions to indicate that GPT4 has better accuracy than ChatGPT . Authors in [ 11 ] indicate that ChatGPT has better performance on the early level ( first - year ) courses than the third - year courses . Generative AI is not only able to understand and answer the multiple - choice questions but also able to write creative paper works for assessments as shown in [ 8 ] , [ 12 ] . These include case studies , programming assignments , academic essays , and term papers . This unprecedented capability of genraitve AI tolls dramatically increase the difficulty of identifying aca - demic integrity in education . Academic integrity is an important concern of using gen - erative AI in education . Therefore , the performance of de - tecting AI - generated content has been a critical functionality of plagiarism detectors . [ 14 ] indicated that only 20 % ( 10 out of 50 ) 500 words essays written by ChatGPT have similarity larger than 20 % by using Turnitin and iThenticate . As GPT4 explodes in 2023 , [ 15 ] concludes that Turnitin only detected 12 ( 54 % ) out of 22 GPT4 - generated essays and faculty academic staff also identified 12 as potentially AI - generated . According to the performance of faculty and Turnitin to detect the GPT4 - generated essays , it recommended that universities should develop a better program to identify AI - generated content to Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . TABLE II : A brief summary of the related works on the generative AI tools in the context of education . Categorises Papers Descriptions Educators : G . Cooper [ 3 ] W . M . Lim et al . [ 4 ] Discuss the strategies to utilise generative AI by educators for their pedagogy and critically analyse how generative AI co - exist as a transformative resource in the future of education . Students : D . Baidoo - Anu and L . Ansah [ 5 ] Generative AI is beneficial for students to provide personalized and interactive learning and guide for assessments . General review of generative AI in education Engineering Education : C . Zhang et al . [ 6 ] J . Qadir [ 7 ] Explore the applications of ChatGPT techniques in STEM education . Academic integrity D . R . E . Cotton , P . A . Cotton , and J . R . Shipway [ 13 ] M . Khalil and E . Er [ 14 ] M . Perkins et al . [ 15 ] Employ various similarity detectors to identify contents generated through generative AI tools and provide suggestions to prevent plagiarism in university education . A . Khademi [ 12 ] Investigate the reliability of ChatGPT and Bard in understanding and rating the complexity of writing prompts . G . Currie et al . [ 11 ] Evaluates the capability of GPT - 3 . 5 on assisting the written assignments and exams on medical imaging . K . Malinka et al . [ 8 ] Explore the potential impact of ChatGPT on university education by evaluating the effectiveness and usability of ChatGPT for completing exams , programming assignments , and term papers . R . Ali et al . [ 9 ] Assess the performance of three generative AI tools ( ChatGPT ( GPT - 3 . 5 ) , GPT - 4 and Google Bard ) by a question bank for neurosurgery oral boards examination preparation . Assessment V . Pursnani , Y . Sermet , and I . Demir [ 10 ] Investigate the performance of ChatGPT and GPT - 4 based model on the exam of Fundamentals of Engineering Environmental . It enhances the accuracy of models by non - invasive prompt modifications . O . Aydın and E . Karaarslan [ 16 ] Summarize and classify a large number of generative AI tools . S . Wollny et al . [ 17 ] Identify 74 papers related to generative AI tools and theire applications in education . Others Y . K . Dwivedi et al . [ 18 ] Review the benefits and limitations of generative conversational AI in different fields , including marketing , education , hospitality , tourism etc . detect plagiarism . Due to the performance of these plagia - rism detectors , universities may adopt strategies to prevent academic dishonesty . [ 13 ] suggests that universities can guide students to use generative AI tools in an ethical approach and suggest staff design assessments to prevent or minimise the impact of generative AI tools . Although using generative AI tools in universities causes both opportunities and risks , universities can develop a better plagiarism checker and adopt new strategies both for educators and students to prevent the risk to academic integrity . III . E VALUATION OF G ENERATIVE AI T OOLS A GAINST E XAMPLE C ONCEPT I NVENTORIES We examined the performance of the generative AI tools GPT - 3 . 5 , GPT - 4 and Google Bard with custom made concept inventories for two example courses : Digital Logic Design and DSP . The concept inventories were created to contain 25 multiple choice questions for each course , spanned over three categories namely , standalone concepts , linking several concepts and numerical / analytical questions . For each course , the concept inventory contained 10 standalone concept ques - tions , which are typically at the lower levels of Blooms taxonomy , requiring students to have a basic understanding of the underlying concept . Each concept inventory also contained 9 questions which require linking of several concepts together to obtain the answer , followed by 6 numerical / analytical Fig . 2 : Overall performance of AI tools in example concept invento - ries in Digital Logic Design and Digital Signal Processing courses . questions which are typically at the higher levels of Blooms taxonomy . These question sets were then fed to GPT - 3 . 5 , GPT - 4 and Google Bard by following some pre - processing to create the appropriate prompts as required by the tools . All these questions are created using Microsoft Word so that the text - based questions and answers can be directly copied to AI tools as input prompts . For questions with mathematical equations or symbols , Microsoft Word automatically converts them to LaTeX format which is understandable by these AI tools . However , these AI tools cannot read the figures and piece - wise functions . Thus , the figures ( e . g . , an impulse response of a discrete - time system ) and piece - wise functions ( e . g . , a mag - nitude response of an ideal discrete - time filter ) are converted Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 3 : Comparison of AI tools on quesations acroos three categories . Fig . 4 : Comparison of three categories in GPT3 . 5 , GPT4 and Bard . into discrete - time sequences and plain text descriptions . To evaluate the performance of AI tools , their responses need to be analysed to identify whether it is correct or not . The answers are only considered correct if they provide both correct options and reasonable solution steps . IV . R ESULTS All the results were collected in June 2023 . The testing result of the three AI models on the two example courses are shown in Fig . 2 . On both Digital Systems and DSP question sets , GPT4 achieves the highest accuracy at 84 % and 52 % , respectively . GPT3 . 5 performs better than Bard on the Digital System but worse than Bard in DSP course . The average accuracy of the digital system ( 68 % ) is higher than DSP at 34 . 7 % . The DSP course usually is a higher - level ( third year ) course than the digital system ( second year ) , so the difficulty of the course could affect the accuracy of AI models . In Fig . 3 , question sets for the two courses are combined together and divided into three categories as standalone con - cepts , linking concepts and analytical / numerical . It is obvious that GPT4 has the highest accuracy across the three types of questions and GPT3 . 5 has similar or slightly higher accuracy than Google Bard . According to Fig . 4 , all AI models achieve the highest accuracy on standalone concept questions ( i . e . , typically lower levels in the Blooms taxonomy ) and the lowest accuracy on analytical / numerical questions , which require critical thinking . In this sense , the AI model behaviours like a human in problem - solving because their accuracy drops for higher level courses and types of questions requiring critical thinking and problem solving . Fig . 5 : Digital system - Linking Concept problems : Q9 Fig . 6 : Digital signal processing - Linking Concept problems : Q20 Figs . 5 , 6 , 7 and 8 are selected examples from the Digital Systems and DSP courses . Fig . 5 presents a linking concept question in the Digital System course . GPT3 . 5 includes the start state ( 000 ) at the end of the sequence so it requires 6 D flip - flops . On the contrary , Bard missed the last state ( 111 ) in the sequence . Only GPT4 is able to answer this question cor - rectly . Furthermore , Fig . 6 presents a linking concept question Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 7 : Digital system - Analytical / Programming problems : Q4 in the DSP course with a picture of the impulse response . The picture is manually interpreted in the text description ( i . e . , h [ n ] = [ 0 , 1 , − 2 , 4 , − 2 , 1 , 0 ] ) before using generative AI tools . Only GPT 4 uses the correct formula to calculate the group delay . Fig . 7 is an analytical programming question , and only GPT4 provides the correct answer and reasonable explanation . GPT3 . 5 and Bard provide the same wrong answer mis - interpreting the edge trigger in the VHDL code , However , GPT3 . 5 provides a relatively more detailed explanation than that provided by Bard . Fig . 8 presents a standalone concept question in the DSP course , and only GPT4 choose the correct option with reasonable explanation . The complete question sets employed for the evaluation with AI - generated answers can be accessed at https : / / drive . google . com / drive / folders / 15zCWcAxy0qxChePlGKxjuBKxFDxUi63I ? usp = sharing V . D ISCUSSION According to Figs . 2 and 3 , the generative AI tools demon - strate different performance for the two subjects and the types of questions , which require different levels of cognitive skills . Generative AI tools have a higher impact on lower - level courses that introduce the basic concepts . Educators need to pay more attention in lower - level courses , for ex - ample , by detecting generative AI - induced plagiarism and guiding students to effectively utilise generative AI tools , only after establishing solid understanding of basic concepts . Since the recent generative AI tools still have difficulty in Fig . 8 : Digital signal processing - Standalone Concept questions : Q3 answering analytical / numerical questions , depending on the learning outcomes , educators could increase the occupancy of these questions in assessments to avoid students directly copy - pasting answers from generative AI tools . However , it probably increases the complexity of assessments . Another solution is to assess students using generative AI tools . It requires students to examine the solutions given by generative AI tools and provide explanations and feedback , instead of directly answering the question . Regardless of how generative AI tools are employed , educators always need to critically evaluate and employ any generative AI tools based on the specific teaching context . Teaching experience and the understanding of students are still crucial in education . Ample opportunities are there from students’ perspective of using generative AI tools in their learning . These include preparation of study guides , summarising content for exam preparation , obtaining practice questions and answers , identi - fying common misconceptions and so on . As such , students should be educated on how to effectively use the power of generative AI tools to enhance their learning . The current study is limited in its scope in terms of the num - ber of courses involved as well as the breadth of the concept inventories used . Future work is needed to expand the current concept inventory tests and extend to more subjects across Electrical Engineering to better understand the opportunities and challenges of generative AI tools . Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . VI . C ONCLUSION This paper provided an early evaluation of common gen - erative AI tools - GPT3 . 5 , GPT4 and Google Bard against concept inventories from two examples of Electrical Engineer - ing courses . In these two question sets , GPT4 model achieves the highest accuracy of 84 % and 52 % , which indicates that the generative AI tools have sufficient capability to provide qualified answers to most questions in a standard test setup . In the comparative analysis of three question categories , the accuracy of standalone concept questions is slightly higher than that of linking concept questions . The performance of three generative AI tools significantly decreases in solving analytical and numerical questions , which requires increased critical thinking . R EFERENCES [ 1 ] M . Jovanovic and M . Campbell , “Generative artificial intelligence : Trends and prospects , ” Computer , vol . 55 , no . 10 , pp . 107 – 112 , Oct . 2022 . [ 2 ] R . Peres , M . Schreier , D . Schweidel , and A . Sorescu , “On ChatGPT and beyond : How generative artificial intelligence may affect research , teaching , and practice , ” International Journal of Research in Marketing , vol . 40 , no . 2 , pp . 269 – 275 , Jun . 2023 . [ 3 ] G . Cooper , “Examining science education in chatgpt : An exploratory study of generative artificial intelligence , ” Journal of Science Education and Technology , vol . 32 , pp . 1 – 9 , 03 2023 . [ 4 ] W . M . Lim , A . Gunasekara , J . L . Pallant , J . I . Pallant , and E . Pechenkina , “Generative ai and the future of education : Ragnar¨ok or reformation ? a paradoxical perspective from management educators , ” The International Journal of Management Education , vol . 21 , no . 2 , p . 100790 , 2023 . [ Online ] . Available : https : / / www . sciencedirect . com / science / article / pii / S1472811723000289 [ 5 ] D . Baidoo - Anu and L . Ansah , “Education in the era of generative artificial intelligence ( ai ) : Understanding the potential benefits of chatgpt in promoting teaching and learning , ” 03 2023 . [ 6 ] C . Zhang , C . Zhang , C . Li , Y . Qiao , S . Zheng , S . K . Dam , M . Zhang , J . U . Kim , S . T . Kim , J . Choi , G . - M . Park , S . - H . Bae , L . - H . Lee , P . Hui , I . S . Kweon , and C . S . Hong , “One small step for generative ai , one giant leap for agi : A complete survey on chatgpt in aigc era , ” 2023 . [ 7 ] J . Qadir , “Engineering Education in the Era of ChatGPT : Promise and Pitfalls of Generative AI for Education , ” ”12” ”2022” . [ Online ] . Available : ”https : / / www . techrxiv . org / articles / preprint / Engineering Education in the Era of ChatGPT Promise and Pitfalls of Generative AI for Education / 21789434” [ 8 ] K . Malinka , M . Pereˇs´ıni , A . Firc , O . Hujˇn´ak , and F . Januˇs , “On the educational impact of chatgpt : Is artificial intelligence ready to obtain a university degree ? ” 2023 . [ 9 ] R . Ali , O . Y . Tang , I . D . Connolly , J . S . Fridley , J . H . Shin , P . L . Z . Sullivan , D . Cielo , A . A . Oyelese , C . E . Doberstein , A . E . Telfeian , Z . L . Gokaslan , and W . F . Asaad , “Performance of chatgpt , gpt - 4 , and google bard on a neurosurgery oral boards preparation question bank , ” medRxiv , 2023 . [ Online ] . Available : https : / / www . medrxiv . org / content / early / 2023 / 04 / 12 / 2023 . 04 . 06 . 23288265 [ 10 ] V . Pursnani , Y . Sermet , and I . Demir , “Performance of chatgpt on the us fundamentals of engineering exam : Comprehensive assessment of proficiency and potential implications for professional environmental engineering practice , ” 2023 . [ 11 ] G . Currie , C . Singh , T . Nelson , C . Nabasenja , Y . Al - Hayek , and K . Spuur , “Chatgpt in medical imaging higher education , ” Radiography , vol . 29 , no . 4 , pp . 792 – 799 , 2023 . [ Online ] . Available : https : / / www . sciencedirect . com / science / article / pii / S1078817423001177 [ 12 ] A . Khademi , “Can ChatGPT and bard generate aligned assessment items ? a reliability analysis against human performance , ” 1 , vol . 6 , no . 1 , may 2023 . [ Online ] . Available : https : / / doi . org / 10 . 37074 % 2Fjalt . 2023 . 6 . 1 . 28 [ 13 ] D . R . E . Cotton , P . A . Cotton , and J . R . Shipway , “Chatting and cheating : Ensuring academic integrity in the era of chatgpt , ” Innovations in Education and Teaching International , vol . 0 , no . 0 , pp . 1 – 12 , 2023 . [ Online ] . Available : https : / / doi . org / 10 . 1080 / 14703297 . 2023 . 2190148 [ 14 ] M . Khalil and E . Er , “Will chatgpt get you caught ? rethinking of plagiarism detection , ” 2023 . [ 15 ] M . Perkins , J . Roe , D . Postma , J . McGaughran , and D . Hickerson , “Game of tones : Faculty detection of gpt - 4 generated content in uni - versity assessments , ” 2023 . [ 16 ] O . Aydın and E . Karaarslan , “Is chatgpt leading generative ai ? what is beyond expectations ? ” 01 2023 . [ 17 ] S . Wollny , J . Schneider , D . Di Mitri , J . Weidlich , M . Rittberger , and H . Drachsler , “Are we there yet ? - a systematic literature review on chatbots in education , ” Frontiers in Artificial Intelligence , vol . 4 , 2021 . [ Online ] . Available : https : / / www . frontiersin . org / articles / 10 . 3389 / frai . 2021 . 654924 [ 18 ] Y . K . Dwivedi , N . Kshetri , L . Hughes , E . L . Slade , A . Jeyaraj , A . K . Kar , A . M . Baabdullah , A . Koohang , V . Raghavan , M . Ahuja , H . Albanna , M . A . Albashrawi , A . S . Al - Busaidi , J . Balakrishnan , Y . Barlette , S . Basu , I . Bose , L . Brooks , D . Buhalis , L . Carter , S . Chowdhury , T . Crick , S . W . Cunningham , G . H . Davies , R . M . Davison , R . D´e , D . Dennehy , Y . Duan , R . Dubey , R . Dwivedi , J . S . Edwards , C . Flavi´an , R . Gauld , V . Grover , M . - C . Hu , M . Janssen , P . Jones , I . Junglas , S . Khorana , S . Kraus , K . R . Larsen , P . Latreille , S . Laumer , F . T . Malik , A . Mardani , M . Mariani , S . Mithas , E . Mogaji , J . H . Nord , S . O’Connor , F . Okumus , M . Pagani , N . Pandey , S . Papagiannidis , I . O . Pappas , N . Pathak , J . Pries - Heje , R . Raman , N . P . Rana , S . - V . Rehm , S . Ribeiro - Navarrete , A . Richter , F . Rowe , S . Sarker , B . C . Stahl , M . K . Tiwari , W . van der Aalst , V . Venkatesh , G . Viglia , M . Wade , P . Walton , J . Wirtz , and R . Wright , “Opinion paper : “so what if chatgpt wrote it ? ” multidisciplinary perspectives on opportunities , challenges and implications of generative conversational ai for research , practice and policy , ” International Journal of Information Management , vol . 71 , p . 102642 , 2023 . Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply .