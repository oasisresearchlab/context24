Learning orientation - invariant representations 1 enables accurate and robust morphologic profiling of 2 cells and organelles 3 James Burgess 1 , Jeffrey J . Nirschl 2 , Maria - Clara Zanellati 3 , Sarah Cohen 3 , and Serena 4 Yeung 4 5 1 Institute for Computational & Mathematical Engineering , Stanford University 6 2 Department of Pathology , School of Medicine , Stanford University 7 3 Department of Cell Biology and Physiology , University of North Carolina at Chapel Hill 8 4 Department of Biomedical Data Science , Stanford University 9 ABSTRACT 10 Cell and organelle morphology are driven by diverse genetic and environmental factors and thus accurate quantification of cellular phenotypes is essential to experimental cell biology . Representation learning methods for phenotypic profiling map images to feature vectors that form an embedding space of morphological variation useful for clustering , dimensionality reduction , outlier detection , and supervised learning problems . Morphology properties do not change with orientation , and thus we argue that representation learning methods should encode this orientation invariance . We show that prior methods are sensitive to orientation , which can lead to suboptimal clustering . To address this issue , we develop O2 - VAE , an unsupervised learning method that learns robust , orientation - invariant representations . We use O2 - VAE to discover novel morphology subgroups in segmented cells and mitochondria , detect outlier cells , and rapidly characterise cellular shape and texture in large datasets , including in a newly generated synthetic benchmark . 11 Introduction 12 Microscopy is the foundation of modern cell biology . High - throughput image - based assays have become essential for genetic 13 screens and discovery - based biological research 1 , drug profiling 2 , and creating cellular and subcellular atlases 3 , 4 . Accurately 14 quantifying cell and organelle morphology is essential to characterising changes in structure and function as a result of genetic 15 or environmental perturbation . Representation learning enables rapid morphology quantification by mapping images to vector 16 representations which form an embedding space . These representations are useful for clustering , dimensionality reduction , 17 outlier detection , and feature learning . The geometric and morphologic properties of cells and organelles do not change 18 with orientation , and thus ideal feature representations should be orientation - invariant . However , existing methods to learn 19 representations do not enforce orientation invariance . Thus , similar but rotated shapes are not guaranteed to be close in the 20 embedding space , which may result in inaccurate or suboptimal clustering or analysis . 21 Classical approaches to learning morphologic representations without supervision include principal component analysis 22 ( PCA ) 5 , 6 , 7 , Fourier and spherical basis functions 5 , 8 , and deformation techniques 9 ; they are only able to model binary segmenta - 23 tion masks . More recently neural - network ( NN ) based autoencoders ( AE ) 10 , 11 , 12 , also unsupervised , have been used to model 24 arbitrary biological images including segmented shapes , grayscale images , and multi - channel images 8 , 13 , 14 . Other works use 25 autoencoders with additional self - supervised loss functions 15 , 16 . These approaches tend to be sensitive to orientation : rotating 26 or flipping the image will change its position in embedding space 5 , 8 , 13 which may reduce accuracy of tasks like clustering . 27 This is usually mitigated by image ‘pre - alignment’ to a canonical pose using rigid body transformations 5 , 8 . However , we show 28 that the image pre - alignment strategy fails to consistently produce similar feature representations for similar shapes , which 29 poses problems for downstream analyses like clustering . 30 Given the above issues , we develop a framework for modifying autoencoder models 10 , 11 , 12 that leverage recent advances 31 in geometric deep learning 17 , 18 , 19 . We constrain the architecture of the neural network encoder to guarantee that output 32 representations are invariant to input image orientation . This obviates the need for pre - alignment and ensures related shapes 33 have similar feature representations , which may improve downstream tasks that use these features . However the orientation 34 invariant encoder causes the reconstructed image to be misaligned with the input , which we correct by searching for the optimal 35 alignment in Fourier space 20 , 21 . In this paper , we develop and experiment with O2 - VAE , which implements our orientation 36 invariance framework on the variational autoencoder ( VAE ) 11 , 12 . Our approach is compatible with other unsupervised and 37 self - supervised autoencoder methods that extend the AE and VAE 13 , 14 , 8 , 15 , 16 . 38 We use O2 - VAE representations on biological data for clustering , visualisation , outlier detection , and feature learning . 39 First , we generate and publicly release a synthetic dataset of grayscale cells with systematically varying shape and cytoplasm 40 texture classes . Since labelled morphology datasets are rare , this is a useful baseline for other researchers . Using this labelled 41 dataset , we show how the learned embedding space organises cell images based on morphology : first into coarse shape followed 42 by fine shape details and then texture . We continue to explore the learned embeddings on cell segmentations and discover 43 that normal fillopodia are lost in lamin - A - deficient mouse embryonic fibroblasts ( MEFs ) 7 , suggesting roles for lamin outside 44 of nuclear shape . In human induced pluripotent stem cells ( hiPSCs ) 22 we detect mitosis cells without supervision , identify 45 outliers , estimate how cell shapes may deform , and rapidly profile shape variation in the large dataset . Next we generate a new 46 dataset of hIPSCs with six tagged organelles 23 and train O2 - VAE representations on mitochondria with more complex shapes . 47 Using these profiles , we identify mitochondrial morphology groups , and we quantify how shape correlates with inter - organelle 48 contact rates . Moving beyond segmentation - only data , we take grayscale nuclei images undergoing mitosis 24 , and show that 49 modelling texture improves the morphologic profiles . Finally , we show that compared to existing autoencoder models , O2 - VAE 50 representations better separate distinct morphology classes for datasets with available labels . We release O2 - VAE code and 51 example applications at https : / / github . com / jmhb0 / o2vae / . 52 Results 53 O2 - VAE enforces orientation invariant representations 54 We develop O2 - VAE , an unsupervised representation learning method for biological images based on VAEs 10 , 11 , 12 that learns 55 the same feature representation for all orientations of a given image ( Fig . 1a ) . Conventional VAEs map images into a compressed 56 vector representation using neural network encoders , which is then decoded to reconstruct the original image . These encoders 57 are sensitive to input image orientation . Instead , we use O ( 2 ) - equivariant convolutional layers that are constrained so that 58 rotations and reflections in the input correspond to rotations and reflections in their output . By stacking O2 - equivariant layers , 59 followed by spatial pooling , the encoder is O ( 2 ) - invariant 25 , 18 , 19 ( Fig . 1a ) . We then use a regular deconvolutional decoder 26 to 60 decode the representation to an image . However , since the encoder maps all image orientations to the same representation 61 vector , the output reconstruction may be misaligned with the input . We re - orient the input to align with the reconstruction , 62 which can be done efficiently by transforming both images to polar - Fourier space , and interpreting their cross - correlogram 20 63 ( Methods ) . The loss function has two terms : reconstruction error between re - oriented input and output ; and a constraint on 64 representations that encourage a smooth embedding space ( Methods ) . The framework can be extended to enforce translation - 65 invariant representations 27 , enforce scale - invariant representations 28 , and to model invariance in 3d shapes 29 , 30 . It can also be 66 integrated with other VAE models . 67 Image pre - alignment fails to enforce orientation - invariant embedding spaces 68 Existing representation learning methods are sensitive to image orientation : rotating or flipping the image changes its 69 representation 7 , 8 , 5 , 9 , 31 , 13 , 32 , 33 . As an example , we train a VAE 11 , 12 , 8 , 5 on a synthetic dataset with two distinct classes ( Fig . 2a ) . 70 The representations form nested circles in embedding space ( Fig . 2a middle ) , and the location in embedding space corresponds 71 to both class and orientation ( Fig . 2a right ) : they are sensitive to image orientation . Naive k - means clustering fails in this simple 72 example because many class 1 shapes are far from each other , but close to class 0 shapes . One solution is to pre - align input 73 images to a canonical orientation , as demonstrated for cell data in Fig . 2b . Pre - alignment is the standard approach for limiting 74 orientation - sensitivity of representations 8 , 5 ( Methods ) . 75 We test whether pre - aligning images before training a VAE - called ‘prealgin - VAE’ - reduces orientation sensitivity ( Fig . 2c ) . 76 Using hiPSCs and four Human Protein Atlas cell lines 3 , we identify similar - image pairs and measure their embedding space 77 distance . If the pairs are not in each other’s k - nearest - neighbours , their representations are too separated , which is an ‘embedding 78 error’ ( we use k = 100 , but the conclusions hold for other ‘k’ - Supplementary 1 ) . Prealign - VAE 8 , 13 has more errors than 79 O2 - VAE ( Fig . 2d ) . Fig . 2e shows image pairs that are errors for prealign - VAE but not O2 - VAE . They are pre - aligned globally 80 but are not well - aligned with each other . Next we show that embedding errors lead to errors in analysis . Using similar image 81 pairs , we test whether the pairs are grouped together by clustering ; if not , they are ‘clustering errors’ ( Methods ) . O2 - VAE has 82 fewer cluster consistency errors than prealign - VAE ( Fig . 2f ) . In Supplementary 1 , we explain the cause of alignment failures , 83 and argue that these issues are likely to persist for any pre - alignment algorithm . Furthermore , we suggest that pre - alignment is 84 likely much harder for other grayscale images , and mutli - channel images . 85 Learning shape representations 86 One challenge for evaluating unsupervised image - based profiling in cell biology is the paucity of benchmarks with class 87 labels and systematic variation over shape or texture parameters . To address this , we generate and release a benchmark 88 dataset of synthetic cell shapes 34 sampled from parameterised distributions with a known population mean eccentricity and 89 2 / 15 Figure 1 : O2 - VAE learns orientation - invariant representations of cells and organelles a The O2 - VAE model . An input image to the orientation invariant encoder produces the same output vector for any input orientation . In the box labelled ‘encoder’ each layer of the convolutional encoder is constrained to be orientation - equivariant with a final spatial pooling layer to produce an orientation - invariant learned representation vector of cell phenotype . During training , the representation is decoded using a separate neural network decoder , which is trained to reconstruct the input . By design , the learned representation is orientation invariant and thus the reconstruction orientation may differ from the input . In the box labelled ‘realignment’ , we efficiently estimate and correct the misalignment using Fourier transform - based methods . We use a loss function ( not shown ) that promotes accurate reconstruction while constraining the distribution of representations . b O2 - VAE can be trained on any image including : binary , grayscale , and multi - channel images . The learned representation vector or phenotypic profile can be used for downstream analysis ; four representative tasks are shown with each dot corresponding to an image in embedding space . For discretely - varying shapes , objects form separated clusters ; for continuously - varying shapes , data can be visualised with dimensionality reduction ; outlier data will be far from most other data ; in feature learning , the representations are re - used for a separate task , for example learning supervised classification ( decision boundary pictured ) . contour randomness ( Fig . 3a ) . Sampling shape parameters from a distribution ensures cellular heterogeneity similar to real data 90 where cells in a class have varying eccentricity but the population - level mean is known . We learn O2 - VAE representations 91 of this data , which we dimensionally reduce using UMAP 35 ( Fig . 3a ) . This shows that macro shape is the dominant factor of 92 embedding space variation ( Fig . 3a ) 35 , which is confirmed by PCA reductions ( Supplementary 2 ) . Similarly , both the UMAP 93 and the distance matrix between class centroids show that varying eccentricity ( macro shape ) corresponds to larger distances in 94 embedding space than varying surface randomness ( fine - grained shape ) . 95 Next , we show that O2 - VAE representations can be used for clustering or other downstream tasks . Using a Gaussian 96 Mixture Model ( GMM ) with k = 8 clusters , we identify cluster ‘prototypes’ 36 by finding the vector centroid of each group 97 and reconstructing an image using the decoder . Due to the intentional heterogeneity of the synthetic cells , the cluster purity is 98 68 . 6 % , which is increased to 87 % if considering only mild to moderate cell contour irregularity . Manual review of the classes 99 with high cell randomness show a diverse morphology that , at times , can resemble multiple different eccentricity or randomness 100 groups ( Supplementary 2 ) . GMM has superior purity scores compared with k - means ( − 12 % ) and agglomerative clustering 101 ( − 15 % ) . Fig . 3c also shows cluster ‘prototypes’ 36 , which are generated by passing the cluster centroid embedding through the 102 decoder . Prototypes for groups with high surface randomness have blurred boundaries . 103 Next , we model cell segmentations from a real dataset of hiPSCs from the Allen cell collection 22 . Since there are no class 104 labels , we propose three tests to verify that the learned representations are meaningful ( Fig . 3b ) . The O2 - VAE reconstructs 105 the input images , demonstrating that morphological features are recovered from the vector representation . In the orientation - 106 invariance test , we rotate and flip the image , but the reconstructed image has the same orientation ; in Supplementary 2 we 107 quantitatively show that this invariance holds for the whole dataset . In the last panel of Fig . 3b , each row is the 5 - nearest 108 neighbours from the first image , demonstrating that small distance in embedding space corresponds to morphological similarity . 109 Large image - based microscopy screens require methods to rapidly summarise populations and identify prototypical 110 morphology groups for exploratory analysis . We train O2 - VAE on the large Allen hiPSC dataset of interphase cells and nuclei 22 111 with scale - normalisation ( Fig . 3c ; without normalisation in Supplementary 2 ) to show the utility of O2 - VAE for visualising 112 continuous shape variation . The learned representations allow clustering by shape and rapid quantification of group frequencies , 113 however , cluster boundaries are only approximate for data with continuous variation . GMM clustering with k = 8 gives clusters 114 with samples that are similar , but prototypes that are diverse . Cluster frequency charts ( Fig . 3d ) summarise the population shape 115 3 / 15 Figure 2 : Existing shape space methods are sensitive to orientation , which is not resolved by image pre - alignment a We train a VAE on a synthetic two - class dataset of ellipses ( left panel ) . The classes separate in the embedding space forming nested circles ( colored by class , middle panel ) . Review and plots of sample images from the space ( right panel ) show that orientation is encoded along the circumference of the nested circles , which means that objects with similar shape but different orientation are highly - separated ( right panel ) . b Result of a pre - processing algorithm to ‘pre - align’ 2d segmented hiPSCs . Given a dataset ( left ) , rotate and flip images ( middle ) so that objects with similar shape are aligned with each other ( right ) . This would help ensure they have similar learned representations . c We design a test to check whether similar - shaped image pairs have similar embeddings . We identify similar - shape pairs ( Methods ) , then we identify ‘embedding errors’ , which are similar - shape pairs that are separate in shape space . d For 5 cell datasets , we compare error rates between models : prealign - VAE , which relies on pre - alignment has more errors than O2 - VAE ( ours ) which does not rely on pre - alignment ( one value per group , so no error bars ) . e We show examples of image pairs that are ‘embedding errors’ for prealignment - based methods but not for O2 - VAE . They have bad pairwise alignment after pre - alignment . We show UMAPs for prealign - VAE and O2 - VAE and draw lines between the embeddings of the shown examples . f If similar - shaped pairs are not grouped by clustering , it is a ‘clustering consistency error’ . Pre - align based methods have higher errors than O2 - VAE ( one value per group , so no error bars ) . distribution ( Fig . 3d ) . We also summarise the dataset with dimensionality reduction approaches ( Supplementary 2 ) . 116 Leveraging shape representations for biological discovery 117 One application of unsupervised cell profiling is biological discovery and hypothesis - generating research . Here , we show that 118 O2 - VAE representations can be used to discover novel subgroups . We model mouse embryonic fibroblasts ( MEFs ) 7 , with 119 two genetic conditions : wild - type ( LMNA + / + ) and lamin - deficient ( LMNA - / - ) ; and three environmental conditions : ‘circular’ , 120 ‘triangular’ , and control ‘not constrained’ micropatterns . Images are scale - normalised , trained on O2 - VAE , and clustered with 121 GMM , k = 10 ( Fig . 4a ) . LMNA + / + cells in all pattern groups have clearly dominant shape clusters ( peaks at specific prototypes ) , 122 but this is lost in LMNA - / - conditions , which have flatter distributions across clusters . This suggests that LMNA + / + has a role in 123 maintaining cell shape consistency . Environmental micropatterning with circles and triangles clearly influences shape : LMNA + / + 124 and , to a lesser extent LMNA - / - are strongly constrained to circular and triangular prototypes respectively . We identify groups 125 with filopodia spikes branching from thin ( cluster 2 ) or thick ( cluster 7 ) cells . Filopodial cells have lower frequency in LMNA - / - 126 cells , which is consistent with recent studies showing LMNA levels modulate cell morphology and filopodial projections 37 . We 127 verify previously reported findings 7 that LMNA - / - cells with triangular shapes are more ‘blunt’ , and that nuclei in LMNA - / - cells 128 are more rounded ( Supplementary 3 ) . A prior work using outline - PCA on this data did not identify the filopodia groups 7 . 129 We jointly model cell and nucleus hiPSCs from the Allen dataset 22 to detect mitosis cells which are often filtered in data 130 preprocessing . The UMAP of O2 - VAE representations in Fig . 4d shows that mitosis cells are clearly separated from normal 131 cells . Using this approach to label mitosis phases has 89 % accuracy , and 99 % accuracy for mitosis states other than prophase 132 ( Supplementary 3 ) . Prior work detected mitosis cells using a 3D classifier with 5000 annotations 22 , but our results suggest 133 unsupervised approaches could replace supervised methods or supplement them by assisting annotation . Next we measure 134 representation quality using ‘linear probing’ 38 , a common evaluation measure 39 of the discriminability of different classes 135 when labels are available ( Methods ) . O2 - VAE representations have better probing scores ( 0 . 7 ) than prealign - VAE ( 0 . 58 ) and 136 VAE ( 0 . 56 ) . Furthermore , we leverage the representation space to suggest plausible shape deformations 8 , 40 by taking two 137 shapes ( Fig . 4c , row edges ) and sampling intermediate points in the embedding space ( row images ) . Then , we use a GMM 138 model to identify cell and nucleus outliers ( Fig . 4b ) , which are likely bad segmentations or cells in mitosis . 139 4 / 15 Figure 3 : Shape representations in synthetic and real cellular data characterise population variation for exploratory analysis a Synthetic dataset and its embedding space : ( Top panel ) Samples from our synthetic cellular shape dataset with varying eccentricity ( columns ) and contour randomness ( rows ) , for 9 classes . ( Second panel ) Distance matrix between robust means of class centroids in embedding space ; classes with different eccentricity are further than classes with different contour randomness . ( Third panel ) UMAP of embedding space colored by eccentricity and ( fourth panel ) randomness ; these show that eccentricity classes are more separated than contour randomness classes . b For real hiPSCs cell shapes without class labels 22 , we use model quality evaluation tests . ( Left panel ) Reconstructions : the original image next to its reconstruction , which should recover the important morphological features . ( Middle panel ) Orientation tests : an image in many orientations ( left column ) should reconstruct images in a canonical orientation ( right column ) . ( Right panel ) k - nearest neighbours : the first column is sampled images ; adjacent images are the ‘most similar’ according to the model’s shape space . c Still using hiPSCs , we learn a shape space for cells ( left ) and nucleus ( right ) segmentation masks , and do GMM clustering with 8 clusters . ( Left ) ‘prototypes’ , reconstructions of the cluster centroid ; ( middle ) samples ; ( right ) cluster frequencies . This communicates morphology variation in the data ( as well as dimensionality reduction in Supplementary 2 ) . While prior works mostly model cells 7 , 8 , 5 , 9 , 31 , 13 , 32 , 41 , we show how O2 - VAE can learn representations of organelles with 140 complex shapes . First , we train O2 - VAE on mitochondria from the Allen hiPSC collection 22 and perform GMM clustering 141 with k = 14 . In Fig . 4e we show cluster prototypes and prevalence of clusters normalised by area and frequency . We observe 142 four superclusters : round puncta ( clusters 10 - 13 ) , small tubes ( 7 - 9 ) , larger tubes ( 5 - 6 ) , small networks ( 0 - 1 ) and large networks 143 ( 2 - 4 ) . The clusters within the puncta and tube superclasses have different thicknesses . We found that large nets were relatively 144 rare , which is consistent with previous literature describing fragmented mitochondria in iPSCs 42 . Next , we explored whether 145 shape groups identified with O2 - VAE representations can provide insight into the physiology of mitochondria with various 146 morphologies . Mitochondria interact with multiple other organelles via membrane contact sites . These organelle contacts 147 have different functions : for example , mitochondria - endoplasmic reticulum ( ER ) contacts are associated with mitochondrial 148 biogenesis and cell proliferation , while mitochondria - lysosome contacts are implicated in mitochondrial remodelling by 149 autophagy 43 . We generated a new dataset of hiPSCs with markers for lysosomes , peroxisomes , Golgi , ER , nucleus , and lipid 150 droplets . Organelles were imaged simultaneously using multispectral imaging , as described in Valm et al 23 . We measure 151 instances of contact with mitochondria for each labelled organelle ( Fig . 4f - g ) . The dataset is small , so we reuse the O2 - VAE 152 model previously trained on the Allen dataset . We extract representations and cluster with GMM , k = 14 . In Fig . 4g we report 153 per - organelle contact rates , which shows significant variation between mitochondria shape clusters . For example , large nets 154 5 / 15 had particularly high contact rates with lysosomes . Therefore , while large nets are rare ( Fig . 4e ) , they may still represent a 155 significant fraction of the mitochondria interacting with lysosomes ( Fig . 4g ) . 156 Learning joint shape and texture representations and leveraging them for biological discovery 157 Whereas previous approaches such as outline - PCA predominantly focus on binary masks , O2 - VAE models both shape and 158 texture by encoding arbitrary grayscale images . We extend our synthetic cell dataset by adding texture ( low , medium , and high ) 159 as a third factor of variation ( Fig . 5a ) . First we learn a dataset with constant shape ( the same eccentricity and randomness ) but 160 variable texture , and the learned representations separate texture classes well ( Supplementary 4 ) . Then , we learn an embedding 161 space for a dataset with varying eccentricity and texture in Fig . 5a ( nine classes ) . The UMAP and class distance matrix show 162 that eccentricity is the dominant factor of variation over texture . Extending to the dataset with varying contour randomness ( 27 163 classes ) , the learned embedding space separates the shape classes but only somewhat separates texture ; the dominant factors 164 of variation are eccentricity , then randomness , and then texture ( Supplementary 4 ) . Fig . 5b shows linear probing scores and 165 cluster purity for each factor of variation separately . The representations learned by O2 - VAE are consistently more effective at 166 separating texture classes compared with prealign - VAE and VAE . However the scores are much lower than for shape , suggesting 167 there is space to improve texture models . 168 Switching to a real dataset of HeLa Kyoto nuclei undergoing mitosis 24 , the classes separate in the embedding space ( Fig . 5c ) . 169 Modelling textural details as well as shape enhances representation quality : O2 - VAE representations have higher linear probing 170 scores when trained on grayscale rather than segmentation images ( Fig . 5d ) . Furthermore , O2 - VAE has superior linear probing 171 scores than prealign - VAE and VAE . 172 Discussion 173 Representation learning is a powerful approach for generating phenotypic profiles of cells and organelles , which can be 174 leveraged for biological discovery . We show that failure to encode orientation invariance can lead to suboptimal representations 175 and errors in downstream analysis , which can be mitigated by O2 - VAE . We characterise the structure of O2 - VAE embedding 176 spaces for both shape and texture to demonstrate the robust and meaningful learned representations . We demonstrate their 177 utility for analysing and summarising multiple real - world datasets of cells and organelles . Overall , O2 - VAE learns better 178 representations compared to alternative VAEs for applications where evaluation labels are available . Since there are few labelled 179 datasets for representation evaluation , we generate and release a synthetic dataset with varying shape and texture . 180 Our work extends and complements recent representation learning models based on autoencoders in the unsupervised 14 , 13 181 and self - supervised 15 , 16 settings . Since we only constrain the encoder representations and we automatically re - align the 182 reconstruction , O2 - VAE can be combined with other methods that change the architecture or loss . Our approach can also be 183 extended to enforce other invariances , including translation 29 , axial rotation 44 , and scale 28 . It can be extended to model 3d 184 images 29 , 44 . We experimented on centred objects , but O2 - VAE is extensible to model complex biological images including 185 protein localisation micrographs or electron micrographs . 186 Although the challenges of pre - alignment was one motivation for developing O2 - VAE , we also hypothesised that orientation 187 invariance improves representation quality more generally . We have empirical evidence to support this hypothesis : on the 188 simulated datasets , O2 - VAE has better linear probing scores of texture and contour randomness ; the margins are high and 189 not well explained by pre - align errors . Further , prior work shows that orientation - invariant encoders have better performance 190 for supervised models on biological and medical data 45 , 46 , 47 , despite supervised learning having more techniques to enforce 191 invariance ( e . g . data augmentation ) . There are also theoretical arguments supporting this idea : a central idea in geometric deep 192 learning is that enforcing known data invariances in neural networks should improve representations 48 , 25 . 193 We acknowledge that O2 - VAE may not be appropriate for all use cases . Pre - alignment can sometimes work well , for 194 example where there are meaningful landmarks for alignment 5 . Some analyses may draw insights despite imperfect pre - 195 alignment , in which case major axis alignment - which aligns objects only up to flips - may be sufficient or preferred for 196 simplicity 22 . For basic shapes , simple metrics like area and perimeter may be adequate . Although it may be difficult to train 197 O2 - VAE with very small datasets , models pre - trained on large datasets can transfer to similar but smaller datasets , for example 198 we trainsferred mitochondria representations from the Allen collection to our multi - organelle dataset 22 . Finally , while our 199 method requires some familiarity with deep learning , we provide example Python notebooks for using O2 - VAE . 200 Computer vision methods developed for natural images have driven many recent advances in bioimaging , but these 201 approaches do not leverage the inherent structure and symmetry in biological images . We show that by taking advantage of 202 these properties and encoding orientation invariance into O2 - VAE , we improve the learned representations and subsequent 203 performance on downstream tasks . We believe that existing and future morphologic profiling methods will also be improved by 204 encoding this invariance . More generally , we hope that our work stimulates interest in the question of how algorithms from the 205 machine learning community can be adapted and improved for biology applications by incorporating expert domain knowledge 206 and the intrinsic properties of the data . 207 6 / 15 Figure 4 : O2 - VAE representations identify meaningful biological subgroups of cells and nuclei a We train O2 - VAE on mouse embryonic fibroblasts 7 cultured on three micropatterned substrates : circular , triangular , or control ( no micropattern ) ; and two treatment groups : wildtype ( LMNA - / - ) and lamin - deficient ( LMNA - / - ) . ( Top chart ) GMM clustering with k = 10 : ( top , left ) prototypes of cluster centroid reconstructions ; ( top , middle ) cluster samples ; ( top , right ) heatmap of relative cluster frequencies per group . ( Bottom ) highlighting two group differences . Loss of LMNA ( −− ) correlates with reduced filopodia , a novel finding not identified by prior methods . Low LMNA ( −− ) groups have lower prevalence of triangular classes that have sharp edges . b ( Left ) example cell + nucleus multistructure hiPSCs 22 , and ( right ) UMAP of embedding space coloured by mitosis class . Mitosis cells separate from normal cells : this is an unsupervised detection method . c Interpolations of cell and multistructure hiPSCs are candidate shape deformations . Images at row edges are real cells . We sample points between their embeddings and reconstruct them to form the other images . d Fitting a GMM to learned representations enables detection of outliers for cells and nuclei in hiPSCs ; they are likely bad segmentations or in mitosis and can be filtered in preprocessing . e Mitochondria in Allen cell collection data clustered with GMM , k = 14 . ( Left ) cluster prototypes , ( middle ) samples , and ( right ) prevalence in terms of count and normalised by area . f Example cell with pseudo - coloured segmentation masks with other organelles , that have many contacts ( overlapping organelle pixels in white ) . g For hiPSC data , clustering with GMM and k = 14 ( cluster samples and prevalence in Supplementary 3 ) . Contact rates of each mitochondrial shape group with each organelle , which is the percentage of mitochondria in the group in contact with that organelle . ‘Aggregate’ is the contact rate over all clusters . Supplementary Fig . 4g shows results per sub - experiment . 7 / 15 Figure 5 : Modelling grayscale images enables joint representations of shape and texture a Synthetic dataset and its embedding space : ( Top ) Samples from our synthetic cellular shape and texture dataset with varying eccentricity ( columns ) and Perlin texture ( rows ) , for 9 classes . ( Second panel ) Distance matrix between robust means of class centroids in embedding space ; classes with different eccentricity are more separated than classes with different texture . ( Third panel ) UMAP of embedding space colored by eccentricity and ( fourth panel ) texture ; these show that eccentricity classes are more separated than texture clases . b Linear probing scores measure representation quality by simulating a classification task on the embedding space . For three experiments modelling texture or texture and shape jointly , O2 - VAE has better texture representation scores ( see Methods ) . c Sample data of real nuclei with mitosis phase classes after min - max scaling 24 . d UMAP of representations have good separation of classes , with some mixing of interphase and prophase cells . e Representation quality ( linear probing ) scores for all mitosis classes and the three challenging classes ( interphase , prophase , prometaphase ) . O2 - VAE representations perform better than VAE baselines . O2 - VAE representations are better when modelling texture and shape jointly ( using grayscale images ) compared with shape only ( using segmentation images ) . 8 / 15 Data Availability 208 The synthetic dataset generated for this study is publicly available at DOI : https : / / zenodo . org / record / 7388245 # . Y4k10ezMJqs . 209 Synthetic cell shapes and textures were generated using a modified version of SimuCell v1 . 0 in MATLAB R2020a . The data is 210 released under CC BY - SA 4 . 0 . 211 The multi - organelle iPSC dataset generated for this paper is available upon reasonable request . 212 Public datasets were used in accordance with the dataset license and can be found at the links below : 213 • Allen Cell : https : / / www . allencell . org / data - downloading . html 214 • Human Protein Atlas : https : / / www . proteinatlas . org / about / download 215 • Cell Pose : http : / / www . cellpose . org / dataset 216 • Mouse embryonic fibroblasts ( MEFs ) dataset https : / / github . com / kukionfr / Micropattern _ MEF _ LMNA _ Image 217 • HeLa Kyoto CellCognition : https : / / open . quiltdata . com / b / allencell / packages / aics / pipeline _ integrated _ single _ cell 218 Code Availability 219 We release our code for use by the community at https : / / github . com / jmhb0 / o2vae / . This repository contains documentation and 220 example python notebooks for training models and analysing representations . 221 Methods 222 PCST : Profiling Cell Shape and Texture ( PCST ) benchmark 223 Synthetic cells were generated using a modified version of SimuCell version 1 . 0 34 in MATLAB R2020a following the guidelines 224 in the SimuCell example scripts . For each image , one cell was centered on a black background of a 512x512x3 image . Cells 225 were synthesized using parameterized distributions of cell / nucleus radius , eccentricity , cell shape contour irregularities ( aka cell 226 randomness ) , base fluorescence intensity per object , and texture . All parameters were fixed except for those systematically 227 varied , which included cell eccentricity ( 0 . 05 , 0 . 6 , 0 . 8 ) , cell randomness ( 0 . 1 , 0 . 2 , 0 . 4 ) , and Perlin texture length scale ( 2 , 4 , 228 6 ) . All combinations of cell eccentricity and cell randomness produce 9 unique shape groups . When texture is incorporated , 229 there are 27 unique conditions representing all combinations of shape and texture parameters . A total of 15 , 000 images were 230 generated for each condition . Each image was assigned a unique random seed , which was set before and during synthesis to 231 ensure shape and texture were controlled across conditions . This created " triples " or images across three conditions which have 232 two parameters constant and only one parameter varied . For example , conditions 1 , 2 , and 3 have constant eccentricity 0 . 5 and 233 cell randomness 0 . 1 with variable Perlin length scale . The same seed was set for image 1 across conditions 1 , 2 , and 3 and thus 234 the cell will have identical size and cell contour irregularities with variable texture . Additional information on the interpretation 235 of the parameters as well as detailed description of all settings can be found in the source code and dataset . 236 Multi - organelle iPSC data : cells and culture conditions 237 Previously generated human iPSCs ( KOLF2 . 1J ) inducibly expressing neurogenin2 49 were incubated at 37 ◦ C , 5 % CO 2 and 238 cultured under feeder - free conditions in StemFlex medium ( Gibco A3349401 ) on Vitronectin ( VTN - N Recombinant Human 239 Protein , Truncated , Gibco A14700 ) . The cells were passaged using ReLeSR enzyme - free stem cell selection and passaging 240 medium in the absence of Rho - associate kinase ( ROCK ) inhibitor . 241 Multi - organelle iPSC data : Seeding , transfection , and labeling 242 The cells were split as colonies using ReLeSR and seeded in chambered coverglass for high resolution microscopy ( Thermo 243 Scientific , Nunc ™ Lab - Tek ™ II Chambered Coverglass # 1 . 5 , 155379 ) . Transfection was done one day post - splitting . Approx - 244 imately 20 minutes before transfection , media was replaced with Essential 8 ( Gibco , A1517001 ) . The transfection mix was 245 prepared in Opti - MEM 1X ( Gibco 31985070 ) with 0 . 5 µ l of Lipofectamine Stem Reagent ( Invitrogen , STEM00001 ) , and 500 ng 246 of total DNA divided as follows : 167 ng of pEIF1a : : Transposase ( gifted by Dr . Michael Ward ) , and 333 ng of organelle markers : 247 lysosomes [ pEIF1a : : LAMP1 : : mTurquoise ] , mitochondria [ pEIF1a : : Cox8 ( 1 - 26 ) : : eGFP ] , Golgi [ pEIF1a : : Sit : : OxVenus ] , peroxi - 248 somes [ pEIF1a : : mOrange2 : : SKL ] , endoplasmic reticulum [ pEIF1a : : Sec61 β : : mApple ] ( Twist Technologies ) . The mix was 249 applied dropwise and cells were incubated for four hours before the media was changed back to StemFlex and supplemented 250 with BODIPY ™ 665 / 676 ( 80 ng ) for the staining of lipids ( Invitrogen , B3932 ) . Prior to imaging , a media change was performed . 251 9 / 15 Multi - organelle iPSC data : live microscopy 252 Images were acquired on a Zeiss 880 laser scanning confocal microscope equipped with a 32 - channel multi - anode spectral 253 detector ( Carl Zeiss ) in lambda mode at 8 . 9 nm bins ( collecting wavelengths 410 - 695 ) , with 63 × / 1 . 4 NA objective lens , 254 and a 2 . 2 × zoom . All fluorophores were excited simultaneously using 405 , 458 , 514 , 594 , and 633 nm lasers , with a 255 458 / 514 / 561 / 633 nm main beam splitter . Z - stacks were acquired with 50 % overlapping 1 . 2 µ n slices , at a scan speed of 256 1 . 90s / frame . Live imaging was performed with stable 5 CO 2 at 37 ◦ C , and each imaging session was not longer than 1 - 2hrs . 257 Images of multiply labelled cells were subjected to linear unmixing using Zen Software ( Carl Zeiss ) by using single fluorophore 258 reference spectra as previously reported 23 . 259 Data processing : public datasets 260 The Allen Cell hiPSCs dataset 22 was downloaded from here , which has cell and nucleus segmentations , and mitosis annotations 261 as described in 22 , 50 . We crop the 3D cell area , and choose the middle z - slice as the 2d cell representation . For Allen 262 mitochondria datasets , we use this same z - slice . We sample 10 , 000 cells , and when training O2 - VAE models , we randomly 263 assigned 20 % to the held out validation set . For mitochondria , we sample segmentations from the same z - slice , and follow the 264 same sampling procedure . 265 For Human Protein Atlas data , immunofluorescence images and cell segmentation masks were downloaded from the here 3 . 266 We used the following cell lines : A549 , A431 , SK - MEL - 30 , and SiHa . 267 The mouse embryonic fibroblast ( MEFs ) dataset was generated and described in 7 . In brief , MEFs were cultured on circle or 268 triangular fibronectin micropattern surfaces to enforce cell morphology constraints versus control , non - patterned surfaces . Cell 269 segmentation masks were generated using a custom pipeline combining an ilastik v1 . 3 . 3 51 pixel classifier with CellProfiler 270 v4 . 2 52 . The segmentation results were reviewed by a cell biologist to ensure accuracy . 271 The HeLa Kyoto nuclei images are from the CellCognition project 24 . We use the H2B - RFP tagged channel that is provided 272 already segmented and cropped , and we use the provided train / validation splits . 273 For all cells images , the object was centred using the arithmetic mean of pixels , then cropped to 512 pixels to cover the 274 largest objects , and resized to have side pixel length of 64 , 128 , or 256 . Multichannel cell and nucleus objects were centred 275 based on the cell shape . For datasets with ‘scale - normalisation’ , the scale measure is axis _ major _ length property from 276 the regionprops function in scikit - image 53 , and we resize objects using the torchvision 54 resize function . 277 Data processing : segmentation of fluorescent multichannel organelle dataset 278 Organelle channels are segmented using the Allen Cell and Structure Segmenter 50 . We use the ‘classic’ filter - based workflow 279 starting with the recommended parameters , and updating them based on visual inspection . 280 Model component : Orientation invariant encoder 281 The orientation invariant - encoder is constructed similarly to the models presented in 19 . We use O ( 2 ) - equivariant steerable 282 CNN layers from the e2cnn library 19 , specifically with gated nonlinearities as proposed in 29 and recommended by 19 . We 283 stack six equivariant blocks , where each block is has an equivariant convolutional layer , a batch normalisation layer , 55 and 284 ELU nonlinearity 56 . We then spatially pool ( average ) each feature channel to dimension 1 : aggregating spatially over an 285 equivariant function makes that function invariant . We reshape the input to a vector , and pass it through one fully connected 286 layer . The output is shape 2 d , where d is representation dimension . Note that due to discretisation and feature downsampling , it 287 is not possible to guarantee perfect invariance in O ( 2 ) , which is why we validate that the learned model really is invariant ( see 288 Methods - Representation Quality Tests ) . 289 Model component : Realigning reconstruction with the input 290 Reconstructed images are misaligned with the input because the encoder destroys orientation information . We rotate and 291 reflect the input image - called image registration - to best align with the reconstruction ( Fig . 1a ) . This is done efficiently using 292 Fourier space methods 20 , and we provide an implementation in PyTorch 54 to register a batch of images in parallel on a GPU 293 ( see https : / / github . com / jmhb0 / ) . For both images , we transform to polar coordinates , take their Fourier transforms , and then 294 compute their cross - correlation . The point of maximum activation of the cross - correlogram in polar coordinates corresponds to 295 the re - alignment angle . We perform the same process on the reflection of the first image , and if the resulting correlogram has 296 higher correlation , we use the reflected input image , otherwise we choose the non - reflected image . 297 A simpler realignment algorithm can also be used : choose an angle increment ( e . g . θ = 1 ◦ ) and create 360 / θ rotated copies 298 of the input image . Then simply measure the correlation of each rotated copy and choose the one with highest correlation . This 299 is simpler and possibly less prone to numerical errors , but it consumes much more memory ( that scales with the square of 300 image width ) , and therefore requires very small batch sizes and slower training . 301 10 / 15 The O2 - VAE model 302 The O2 - VAE follows the variational autoencoder framework 11 , 12 ( Fig . 1a ) . The image is passed through the orientation invariant 303 encoder ( described above ) to form a vector bottleneck layer with dimension 2 d . As in the original VAE 11 , this vector is the 304 parameters of a Gaussian distribution with diagonal covariance . The d − dimensional ‘mean vector’ is the ‘image representation’ . 305 We sample a vector from this Gaussian and pass it through a ( not - orientation - invariant ) deconvolutional decoder 26 with 5 , 6 , or 306 7 blocks for image sizes 64 , 128 , and 256 respectively . Each block has a transposed convolution layer , a batch norm layer and 307 an ELU nonlinearity . The decoder output is the reconstruction . We realign the input image to align with the reconstruction 308 ( described above ) . 309 In training , we apply a reconstruction loss that penalises pixel - wise distance to to the input and reconstruction ; we use 310 binary cross entropy for segmentations and mean square error for grayscale images . We also use the VAE distribution loss that 311 penalises the KL divergence between the bottleneck distribution and an isotropic Gaussian 11 , and we weight this loss term by β . 312 We use β = 0 . 01 and embedding dimensions d = 128 for all models trained in this paper . We use the Adam optimiser 57 with 313 learning rate 10 − 3 , which we train until the loss on the held - out validation set converges . 314 Testing orientation sensitivity with synthetic data 315 For tests in Fig . 2a , the ellipses dataset is generated with 1000 images each in classes 0 and 1 . Class 0 objects has minor axis 316 radius of 10 and a major axis radius sampled uniformly between 15 and 17 . Class 1 objects have minor axis radius 10 and major 317 axis radius uniformly sampled between 23 and 25 . The objects are centred in a 62 × 62 pixel image , and randomly rotated . 318 Half the data is assigned to the train and half to a held - out validation set . All analyses ( figures and clustering results ) are done 319 on the test set . The trained model is the same as the O2 - VAE ( described above ) , except the encoder is a 6 - layer ( non - invatiant ) 320 convolutional encoder , and we do not re - align the input with the reconstruction . We train with the more standard β = 1 for 200 321 epoch when the validation loss converged . We use only a d = 2 representation to allow direct visualisation of the representation 322 space . We also test embedding dimensions , { 4 , 16 , 32 , 128 } ; in higher dimensions the results are inconsistent : k - means clustering 323 scores either below 55 % or 100 % , and the results are unstable between different runs of the same model with different random 324 seed . 325 Pre - alignment algorithms 326 Prior works do pre - alignment in a one or two - stage process 5 , 8 ( Figure in Supplementary 1 ) . There is variation in the details , but 327 we use the following procedure . In the first stage , the ‘major - axis’ is computed and aligned to the y - axis . One definition of 328 the ‘major axis’ is the major axis of the first order ellipse that has the same second moments as the binary image , which we 329 compute using scikit - image 53 . An alternative definition is the first primary component from a PCA , where the input data are the 330 flattened x - y coordinates of either the image pixels or of evenly - spaced points along the shape outline . Both approaches require 331 a segmentation to compute the angle . 332 The major axis alignment only determines orientation up to flips in the x or y axis , so a second stage updates the final 333 orientation . The approach is to register each cell against a single reference . For some cells , the objects may have a ‘natural’ 334 orientation ( e . g . the outline of Drosophila 5 ) which can be used as a reference . But when no orientation is known , a common 335 choice is the mean cell over all images . For each image , we choose the flip that minimises the image cross - correlation with the 336 mean cell . After choosing the flip for each image , the mean cell will be different , so this process is repeated iteratively until the 337 average cross - correlation loss converges , which took fewer than 30 iterations for our datasets . 338 Quantifying embedding errors 339 We first identify ‘high - confidence similar object pairs’ . Since we do not have a measure for semantic similarity , we use a 340 pixel - based measure as a proxy . For centred images ( x , y ) with image dimensions ( m , n ) , their cross correlation ( or root mean 341 squared error ) is RMSE ( x , y ) = (cid:113)(cid:0) 1 m · n ∑ i , j ( x i , j − y i , j ) 2 (cid:1) . This score will be larger for larger shapes : if one edge of the cell 342 is perturbed , then more pixels will be different between image pairs if the object is larger . We therefore normalise it with 343 C = (cid:112) max { s ( x ) , s ( y ) } , where s ( · ) is the number of object pixels , ( which we justify further in Supplementary 1 ) . This is the 344 normalised root mean square error , or NRMSE . We register x and y by finding the rotation and flip of y , called ˆ y , that minimises 345 the NRMSE , which we compute using the same procedure described in ‘Realigning reconstruction with the input’ . We define 346 the set of high - confidence pairs as those having NRMSE below a threshold . By choosing a conservative threshold , this approach 347 for identifying semantically similar pairs has low false positive rate , but since it is a proxy measure , the false negative rate 348 may be high . This is the best result we can achieve without ground truth labels for semantic similarity . We choose a range of 349 thresholds for the clustering experiment , and we show sample pairs in Supplementary 1 to verify that threshold is reasonable . 350 To measure ‘embedding errors’ , we label the nearest neighbors to each image . For image pair ( x i , y i ) , the neighbour 351 separation score k i means either x i is the k i th nearest neighbour to y i or vice versa ( whichever is smaller ) . For a threshold , t , a 352 ‘high confidence similar pair’ has an embedding errors if k i > t . We choose t = 100 for experiments and plot this for many t 353 11 / 15 in Supplementary 1 , which shows the conclusions are consistent across t . This order - based metric of similarity is preferable 354 to a distance based metric because we want to compare different representation spaces , and the notion of distance in one 355 space does not transfer to another . We repeat this for O2 - VAE and prealign - VAE . Next we measure ‘clustering errors’ , where 356 a ‘high confidence similar pair’ is assigned a different cluster . Since clustering is sensitive to hyperparameters , we perform 357 many experiments : two clustering methods ( k - means and Gaussian mixture model ) , six values of k , { 10 , 12 , 14 , 16 , 18 , 20 } , four 358 thresholds for ‘high confidence’ NRMSD , and 20 random seeds . We compute clustering error rate for each experiment and then 359 report on the average . This establishes that differences in error rates are general , and not a result specific to hyperparameter 360 choices . 361 Representation space quality tests 362 The verification tests in Fig . 3b do not require access to labels , so they are useful in real analyses to check that the embedding 363 space is meaningful . The reconstruction test simply samples an image , computes the reconstruction , and re - aligns the objects 364 ( described above ) . The kNN test sample images and displays the images with nearest Euclidean distance in embedding space . 365 Both these tests require the judgement of an experimenter to asses whether important features are present ( in reconstructions ) , 366 and whether pairs of objects really are similar ( in kNN ) . Since they require manual inspection , we recommend sampling 367 uniformly across the data . 368 The qualitative orientation test samples an image , makes rotated and reflected copies , and outputs the image reconstruction 369 without re - alignment . A properly orientation - invariant encoder destroys orientation information , so we expect that non - aligned 370 reconstructions are all the same . A second quantitative test ( in Supplementary 2 ) is more comprehensive and directly tests the 371 representations themselves . We rotate the object in increments of θ = 20 on the original and reflected images , then measure 372 the Euclidean distance between these embeddings at each orientation . Since discretisation effects cause some representation 373 difference , they will not have identical embeddings , but they should be very close . The test is passed if the biggest embedding 374 distance between different orientations is less than the embedding distance to every other image in the dataset . In practice 375 this test may fail by a very small distance margin if the data have duplicates or near - duplicates , in which case we recommend 376 permitting a small distance margin . We observed this problem for MEFs data that had collected the same cell in different 377 images , and for mitochondria data where some small round puncta had identical segmentation masks . We found that this 378 quantitative test passed in trained O2 - VAE models , but did not always pass in untrained models . This suggests that that the 379 orientation - invariance , which can only be approximately enforced by the architecture , is strengthened by the training procedure , 380 especially through the orientation invariant reconstruction loss . 381 Clustering , dimensionality reduction , and outlier detection 382 We perform GMM and k - means clustering of representations in sckit - learn 58 . We determine k experimentally , by choosing 383 it large enough to have coherent clusters with relatively low variance ( which is judged by qualitative comparison of cluster 384 samples ) . For example , this required k = 14 for mitochondria , but only k = 10 for MEFs . Because computation complexity 385 for fitting GMMs scales cubically with dimension , d , we use PCA to reduce to 32 dimensions , which retains at least 90 % of 386 explained variance for all our experiments . For figures , we reorder clusters so that similar shapes are near to each other . We 387 implement this by agglomerative clustering over cluster centroids with sckikit - learn 58 , and then by taking the ordering of the 388 resulting dendrogram . This aids interpretability , for example in Fig . 4d , the mitochondria superclusters have their subclusters 389 ordered together , though this procedure does not always put similar shape groups close ( which is not possible in the general case 390 for a 1d ordering ) . For displaying cluster samples , we perform multiple approaches . The easiest approach is uniform sampling . 391 Another approach is to get a score for ‘cluster confidence’ , and display a spread of ‘low’ and ‘high’ confidence samples . The 392 ‘cluster confidence’ for GMM clustering is the probability score , and for k - means it is the negative of the clustering objective . 393 By showing a range of low - and high - confidence objects , we can asses cluster coherence . For example , this revealed the 394 k - means clustering of mitochondria latent spaces tended to assign large networks to many clusters ( with low confidence ) that 395 had very different shapes . 396 For PCA axis traversals , we perform PCA over image embeddings with sckikit - learn 58 . Row i is formed by sampling the 397 data centre , and then sampling embedding space points in the range [ − 2 σ , 2 σ ] along that PC , where σ is the standard deviation 398 of data projected to that PC . UMAP reductions are computed using the official Python implementation 35 . Visualisations of 399 shape in the 2d reduced space ( Supplementary 3 ) is done by sampling grid points in the 2d plane , and finding the nearest real 400 image in the dataset . 401 For outlier detection ( Fig . 4d ) , we take a probabilistic approach 59 by fitting a 20 - component GMM to representations , and 402 using the probability under the model as an outlier score . For mitosis detection ( Fig . 4b ) , the outliers are determined simply 403 by manual inspection of the UMAP reduced data to 2d . In our experiments , varying UMAP hyperparameters gave consistent 404 predictions . 405 12 / 15 Testing representation quality with linear probing 406 Linear probing is a very common technique for evaluating representation quality for deep learning models 38 . We randomly 407 split data into 80 % train and 20 % test sets , and then fit a logistic regression classifier with L2 regularisation to the train set 408 using sckikit - learn 58 . We evaluate the classifier on the test data ; we report the F1 score for each class , and the macro - average F1 409 score across classes . In Results , we use linear probing in two ways . For datasets with labels for ground truth classes ( groups for 410 simulated data ; multistructure cell and nucleus in mitosis ; grayscale in mitosis ) we probe using these labels . Where there are 411 labels for each generative factor ( eccentricity , contour randomness , Perlin texture ) , we perform separate tests where data is 412 labelled by only one generative factor at a time . This allows us to measure , for example , the separability of representations 413 based on eccentricity independently from texture . 414 Organelle prevalence and contact frequencies 415 In Fig . 4e , we report cluster prevalence by summing the total area from all mitochondria in that cluster ( ‘area’ ) and then counting 416 the mitochondria ( ‘frequency’ ) . Then for Fig . 4g , we take all pairs of organelles , for example all mitohconria and all lysosomes 417 in a cell , and measure the minimum distance between pixels in those objects . An object is ‘in contact’ with another object if 418 its separation is smaller than 2 pixels . For example the contact frequency of mitochondria with lysosome in cluster 1 is the 419 total number of cluster 1 mitochondria that contact a lysosome divided by the total number of cluster 1 mitochondria . The 420 conclusions reported in Results were consistent over threshold ranges from 0 to 4 . 421 References 422 1 . Boutros , M . , Heigwer , F . & Laufer , C . Microscopy - based high - content screening . Cell 163 , 1314 – 1325 ( 2015 ) . 423 2 . Chandrasekaran , S . N . , Ceulemans , H . , Boyd , J . D . & Carpenter , A . E . Image - based profiling for drug discovery : due for a 424 machine - learning upgrade ? Nat . Rev . Drug Discov . 20 , 145 – 159 ( 2021 ) . 425 3 . Thul , P . J . et al . A subcellular map of the human proteome . Science 356 , eaal3321 ( 2017 ) . 426 4 . Cho , N . H . et al . OpenCell : Endogenous tagging for the cartography of human cellular organization . Science 375 , eabi6983 427 ( 2022 ) . 428 5 . Pincus , Z . & Theriot , J . Comparison of quantitative methods for cell - shape analysis . J . microscopy 227 , 140 – 156 ( 2007 ) . 429 6 . Keren , K . et al . Mechanism of shape determination in motile cells . Nature 453 , 475 – 480 ( 2008 ) . 430 7 . Phillip , J . M . , Han , K . - S . , Chen , W . - C . , Wirtz , D . & Wu , P . - H . A robust unsupervised machine - learning method to quantify 431 the morphological heterogeneity of cells and nuclei . Nat . protocols 16 , 754 – 774 ( 2021 ) . 432 8 . Ruan , X . & Murphy , R . F . Evaluation of methods for generative modeling of cell and nuclear shape . Bioinformatics 35 , 433 2475 – 2485 ( 2019 ) . 434 9 . Rohde , G . K . , Ribeiro , A . J . , Dahl , K . N . & Murphy , R . F . Deformation - based nuclear morphometry : Capturing nuclear 435 shape variation in hela cells . Cytom . Part A : The J . Int . Soc . for Anal . Cytol . 73 , 341 – 350 ( 2008 ) . 436 10 . Hinton , G . E . & Salakhutdinov , R . R . Reducing the dimensionality of data with neural networks . science 313 , 504 – 507 437 ( 2006 ) . 438 11 . Kingma , D . P . & Welling , M . Auto - encoding variational bayes . arXiv preprint arXiv : 1312 . 6114 ( 2013 ) . 439 12 . Rezende , D . J . , Mohamed , S . & Wierstra , D . Stochastic backpropagation and approximate inference in deep generative 440 models . In International conference on machine learning , 1278 – 1286 ( PMLR , 2014 ) . 441 13 . Chan , C . K . , Hadjitheodorou , A . , Tsai , T . Y . - C . & Theriot , J . A . Quantitative comparison of principal component analysis 442 and unsupervised deep learning using variational autoencoders for shape analysis of motile cells . bioRxiv ( 2020 ) . 443 14 . Zaritsky , A . et al . Interpretable deep learning of label - free live cell images uncovers functional hallmarks of highly - 444 metastatic melanoma . BioRxiv ( 2020 ) . 445 15 . Kobayashi , H . , Cheveralls , K . C . , Leonetti , M . D . & Royer , L . A . Self - supervised deep learning encodes high - resolution 446 features of protein subcellular localization . Nat . methods 1 – 9 ( 2022 ) . 447 16 . Wu , Z . et al . Dynamorph : self - supervised learning of morphodynamic states of live cells . Mol . Biol . Cell mbc – E21 ( 2022 ) . 448 17 . Cohen , T . & Welling , M . Group equivariant convolutional networks . In International conference on machine learning , 449 2990 – 2999 ( PMLR , 2016 ) . 450 18 . Worrall , D . E . , Garbin , S . J . , Turmukhambetov , D . & Brostow , G . J . Harmonic networks : Deep translation and rotation 451 equivariance . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 5028 – 5037 ( 2017 ) . 452 19 . Weiler , M . & Cesa , G . General e ( 2 ) - equivariant steerable cnns . Adv . Neural Inf . Process . Syst . 32 ( 2019 ) . 453 20 . Reddy , B . S . & Chatterji , B . N . An fft - based technique for translation , rotation , and scale - invariant image registration . 454 IEEE transactions on image processing 5 , 1266 – 1271 ( 1996 ) . 455 21 . Lohit , S . & Trivedi , S . Rotation - invariant autoencoders for signals on spheres . arXiv preprint arXiv : 2012 . 04474 ( 2020 ) . 456 22 . Viana , M . P . et al . Robust integrated intracellular organization of the human ips cell : where , how much , and how variable . 457 BioRxiv 2020 – 12 ( 2021 ) . 458 13 / 15 23 . Valm , A . M . et al . Applying systems - level spectral imaging and analysis to reveal the organelle interactome . Nature 546 , 459 162 – 167 ( 2017 ) . 460 24 . Held , M . et al . Cellcognition : time - resolved phenotype annotation in high - throughput live cell imaging . Nat . methods 7 , 461 747 – 754 ( 2010 ) . 462 25 . Cohen , T . et al . Equivariant convolutional networks . ( 2021 ) . 463 26 . Zeiler , M . D . , Krishnan , D . , Taylor , G . W . & Fergus , R . Deconvolutional networks . In 464 2010 IEEE Computer Society Conference on computer vision and pattern recognition , 2528 – 2535 ( IEEE , 2010 ) . 465 27 . Lenc , K . & Vedaldi , A . Understanding image representations by measuring their equivariance and equivalence . In 466 Proceedings of the IEEE conference on computer vision and pattern recognition , 991 – 999 ( 2015 ) . 467 28 . Sosnovik , I . , Szmaja , M . & Smeulders , A . Scale - equivariant steerable networks . arXiv preprint arXiv : 1910 . 11093 ( 2019 ) . 468 29 . Weiler , M . , Geiger , M . , Welling , M . , Boomsma , W . & Cohen , T . S . 3d steerable cnns : Learning rotationally equivariant 469 features in volumetric data . Adv . Neural Inf . Process . Syst . 31 ( 2018 ) . 470 30 . Geiger , M . et al . github . com / e3nn / e3nn , DOI : 10 . 5281 / zenodo . 3723557 ( 2020 ) . 471 31 . Johnson , G . R . , Buck , T . E . , Sullivan , D . P . , Rohde , G . K . & Murphy , R . F . Joint modeling of cell and nuclear shape 472 variation . Mol . Biol . Cell 26 , 4046 – 4056 ( 2015 ) . 473 32 . Johnson , G . R . , Donovan - Maiye , R . M . & Maleckar , M . M . Building a 3d integrated cell . bioRxiv 238378 ( 2017 ) . 474 33 . Bepler , T . , Zhong , E . , Kelley , K . , Brignole , E . & Berger , B . Explicitly disentangling image content from translation and 475 rotation with spatial - vae . Adv . Neural Inf . Process . Syst . 32 ( 2019 ) . 476 34 . Rajaram , S . , Pavie , B . , Hac , N . E . , Altschuler , S . J . & Wu , L . F . Simucell : a flexible framework for creating synthetic 477 microscopy images . Nat . methods 9 , 634 – 635 ( 2012 ) . 478 35 . McInnes , L . , Healy , J . & Melville , J . Umap : Uniform manifold approximation and projection for dimension reduction . 479 arXiv preprint arXiv : 1802 . 03426 ( 2018 ) . 480 36 . Hastie , T . , Tibshirani , R . , Friedman , J . H . & Friedman , J . H . The elements of statistical learning : data mining , inference , and prediction , 481 vol . 2 ( Springer , 2009 ) . 482 37 . Bell , E . S . et al . Low lamin a levels enhance confined cell migration and metastatic capacity in breast cancer . Oncogene 483 1 – 20 ( 2022 ) . 484 38 . Zhang , R . , Isola , P . & Efros , A . A . Colorful image colorization . In European conference on computer vision , 649 – 666 485 ( Springer , 2016 ) . 486 39 . Bengio , Y . , Courville , A . & Vincent , P . Representation learning : A review and new perspectives . 487 IEEE transactions on pattern analysis machine intelligence 35 , 1798 – 1828 ( 2013 ) . 488 40 . Zhong , E . D . , Bepler , T . , Berger , B . & Davis , J . H . Cryodrgn : reconstruction of heterogeneous cryo - em structures using 489 neural networks . Nat . methods 18 , 176 – 185 ( 2021 ) . 490 41 . Schmidt , U . , Weigert , M . , Broaddus , C . & Myers , G . Cell detection with star - convex polygons . In 491 International Conference on Medical Image Computing and Computer - Assisted Intervention , 265 – 273 ( Springer , 2018 ) . 492 42 . Lisowski , P . , Kannan , P . , Mlody , B . & Prigione , A . Mitochondria and the dynamic control of stem cell homeostasis . 493 EMBO reports 19 , e45432 ( 2018 ) . 494 43 . Kleele , T . et al . Distinct fission signatures predict mitochondrial degradation or biogenesis . Nature 593 , 435 – 439 ( 2021 ) . 495 44 . Cesa , G . , Lang , L . & Weiler , M . A program to build e ( n ) - equivariant steerable cnns . In 496 International Conference on Learning Representations ( 2021 ) . 497 45 . Veeling , B . S . , Linmans , J . , Winkens , J . , Cohen , T . & Welling , M . Rotation equivariant cnns for digital pathology . In 498 International Conference on Medical image computing and computer - assisted intervention , 210 – 218 ( Springer , 2018 ) . 499 46 . Winkels , M . & Cohen , T . S . 3d g - cnns for pulmonary nodule detection . arXiv preprint arXiv : 1804 . 04656 ( 2018 ) . 500 47 . Razzak , M . I . , Imran , M . & Xu , G . Efficient brain tumor segmentation with multiscale two - pathway - group conventional 501 neural networks . IEEE journal biomedical health informatics 23 , 1911 – 1919 ( 2018 ) . 502 48 . Bronstein , M . M . , Bruna , J . , Cohen , T . & Veliˇckovi´c , P . Geometric deep learning : Grids , groups , graphs , geodesics , and 503 gauges . arXiv preprint arXiv : 2104 . 13478 ( 2021 ) . 504 49 . Pantazis , C . B . et al . A reference induced pluripotent stem cell line for large - scale collaborative studies . Biorxiv 2021 – 12 505 ( 2022 ) . 506 50 . Chen , J . et al . The allen cell and structure segmenter : a new open source toolkit for segmenting 3d intracellular structures 507 in fluorescence microscopy images . BioRxiv 491035 ( 2020 ) . 508 51 . ilastik : interactive machine learning for ( bio ) image analysis . DOI : 10 . 1038 / s41592 - 019 - 0582 - 9 ( 2019 ) . 509 52 . Stirling , D . R . et al . CellProfiler 4 : improvements in speed , utility and usability . BMC Bioinforma . 22 , 433 ( 2021 ) . 510 53 . Van der Walt , S . et al . scikit - image : image processing in python . PeerJ 2 , e453 ( 2014 ) . 511 54 . Paszke , A . et al . Pytorch : An imperative style , high - performance deep learning library . In 512 Advances in Neural Information Processing Systems 32 , 8024 – 8035 ( Curran Associates , Inc . , 2019 ) . 513 14 / 15 55 . Ioffe , S . & Szegedy , C . Batch normalization : Accelerating deep network training by reducing internal covariate shift . In 514 International conference on machine learning , 448 – 456 ( PMLR , 2015 ) . 515 56 . Clevert , D . - A . , Unterthiner , T . & Hochreiter , S . Fast and accurate deep network learning by exponential linear units ( elus ) . 516 arXiv preprint arXiv : 1511 . 07289 ( 2015 ) . 517 57 . Kingma , D . P . & Ba , J . Adam : A method for stochastic optimization . arXiv preprint arXiv : 1412 . 6980 ( 2014 ) . 518 58 . Pedregosa , F . et al . Scikit - learn : Machine learning in Python . J . Mach . Learn . Res . 12 , 2825 – 2830 ( 2011 ) . 519 59 . Ruff , L . et al . A unifying review of deep and shallow anomaly detection . Proc . IEEE 109 , 756 – 795 ( 2021 ) . 520 Acknowledgements 521 We thank our colleagues Kuan - Chieh Wang and Aditya Grover for insightful discussions and feedback . We thank Bill Skarnes 522 for providing KOLF2 . 1 cells . 523 Funding 524 We acknowledge support from : a Chan Zuckerberg Initiative Neurodegeneration Collaborative Pairs Award ( SY and SC , 525 2021 - 235009 ) ; a Chan Zuckerberg Biohub Investigator Award ( SY ) ; a Stanford Alzheimer Disease Research Center NIH grant 526 # P30AG066515 ( JJN ) ; and a National Institute of General Medical Sciences grant R35GM133460 ( SC and MCZ ) . 527 Author contributions statement 528 JB : Conceptualization , Formal analysis , Methodology , Software , Visualization , Writing - Original Draft , Writing - Review & 529 Editing . JJN : Data Generation , Software , Supervision , Validation , Writing - Review & Editing . MCZ : Data Curation . SC : Data 530 Curation , Supervision . SY : Conceptualisation , Resources , Supervision , Writing - Review & Editing . All authors reviewed and 531 provided feedback on the manuscript . 532 15 / 15