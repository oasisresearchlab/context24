Collaboratively Mitigating Racial Disparities in Automated Speech Recognition and Language Technologies with African American English Speakers Community - Collaborative and Equity - Centered Approaches Toward Designing Inclusive Natural Language Systems Jay L . Cunningham University of Washington , Human Centered Design and Engineering , Seattle , WA , USA jaylcham @ uw . edu ABSTRACT Automated speech recognition ( ASR ) systems that rely on natural language processing ( NLP ) techniques are becoming increasingly prevalent within people’s everyday lives . From virtual assistants integrated into mobile devices ( e . g . Apple’s Siri ) , smart home assis - tants ( e . g . Google’s Nest ; Amazon’s Alexa / Echo ) , and vehicles ( e . g . Apple’s CarPlay ; Android Auto ) ; to software tasks such as automatic translation , automatic captioning , automatic subtitling and even hands - free computing , ASR systems are core components of IoT ( In - ternet of things ) devices and applications . However , scholars have begun to show that with these increasing innovations and system capabilities , emerges fairness - related harms of user experiences and racial disparities that negatively impact African American speak - ers of African American Vernacular English ( AAVE ) . As users of ASR , AAVE speakers’ language is less accurately recognized and processed , leading to inequitable interactions among this ethnolect community . My graduate research seeks to address this challenge by developing and validating community - collaborative methods to innovate responsible approaches toward designing more represen - tative and equitable ASR language technologies that accommodate African American speakers of AAVE . CCS CONCEPTS • Human - centered computing → Collaborative and social com - puting ; Empirical studies in collaborative and social computing ; KEYWORDS Human Computer Interaction ( HCI ) , Responsible Artificial Intel - ligence ( AI ) , Natural Language Processing , Inclusive Design , Par - ticipatory Design , Co - Design , Community - Based Participatory Re - search , Action Research , Equity Centered Design ACM Reference Format : Jay L . Cunningham . 2023 . Collaboratively Mitigating Racial Disparities in Automated Speech Recognition and Language Technologies with African AmericanEnglishSpeakers : Community - CollaborativeandEquity - Centered Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 9422 - 2 / 23 / 04 . https : / / doi . org / 10 . 1145 / 3544549 . 3577057 Approaches Toward Designing Inclusive Natural Language Systems . In Ex - tended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ( CHI EA ’23 ) , April 23 – 28 , 2023 , Hamburg , Germany . ACM , New York , NY , USA , 5 pages . https : / / doi . org / 10 . 1145 / 3544549 . 3577057 1 DOCTORAL RESEARCH OVERVIEW AND GOALS I am a fourth - year doctoral candidate in the Department of Human Centered Design & Engineering ( HCDE ) at the University of Wash - ington , advised by Professors Dr . Julie Kientz and Dr . Daniela Rosner . With a background in software engineering , product management , and UX research , I am passionate about responsibility / fairness in AI / ML systems and user experiences through inclusive design and algorithmic / design justice . My doctoral research investigates the integration of human - centered design methods with community - collaboration and equity - centered approaches to explore and ad - dress the sociotechnical implications of race , culture , identity & power and the intersection of intelligent systems and machines . My graduate work aims to advance and sustain responsible design prac - tices that can lead to more inclusive and equitable user experiences in automated speech recognition and language technologies , with a critical lens on African American English - speaking communities . My doctoral research and education is supported by the National Science Foundation Graduate Research Fellowship ( NSF - GRFP ) , the Gates Millennium Scholars Program ( GMSP - UNCF ) , the National GEM Consortium Ph . D . Engineering and Science Fellowship ( GEM ) , and the Google Award for Inclusion Research ( AIR ) . 2 BACKGROUND AND MOTIVATION The HCI research and design communities have long been con - cerned with the impacts of technology on marginalized groups and communities [ 19 ] . From the development of intelligent facial recog - nition systems [ 5 ] , prison sentencing technology , hiring algorithms , and healthcare algorithms , artificial intelligence ( AI ) heavily relies on machine learning ( ML ) to make critical decisions on the ways in which people can live [ 35 ] . These systems are becoming increas - ingly ubiquitous in the lives of us all and in doing so , we must be prepared to grapple with the intended and unintended implications of them [ 28 ] . Even with the altruistic promise of AI to help detect and reduce human bias and prejudice , there exists consequences of AI’s “blind - spots” as outlined by scholars Kate Crawford and Ryan Calo [ 9 ] . These blind - spots , while broad in categorization , can be seemingly summed as the overlooked , under - evaluated , and CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany Jay Cunningham even chauvinistic tendencies of technology researchers , designers , and practitioners to study , innovate , and build technical artifacts without understanding the downsides of interactive systems and intelligent machines [ 9 ] . Such systems often reinforce and over - whelmingly benefit the position of those in power who tend to be white , educated , and male [ 9 ] . And at the promise of so - called “inno - vation , ” conventional technology design practices themselves " may perpetuate forms of institutional racism and bias , ” enabling and legitimizing racialized forms of inequity , as indicated by O’Leary , et al . [ 38 ] . Structural issues like anti - blackness , violence against women , and queer - phobia all contribute to patterns of social exclusion and are all being undertaken through development of AI ; even when the intent is to mediate or interrupt their impacts , there exists emerging works that focus on the absurdity of solving such issues with technical devices [ 6 , 20 ] . To date , we’ve increasingly seen the growing contributions among HCI and design scholars highlighting the ways in which these technologies can negatively impact gender minorities , people of color , and other under - represented groups [ 12 , 14 , 32 ] . Scholars like Ruha Benjamin [ 1 ] , Safiya Noble [ 24 ] , Ihudiya Ogbonnaya - Ogburu et al . [ 25 ] , Alex Hanna [ 16 ] and so many others characterize a technology design space perpetuating such harms by proposing over - reaching , under - performing , and paradoxically problem - making solutions [ 10 ] . Complementing this range of work , interdisciplinary design scholars have brought an intersectional lens to questions of equity [ 15 , 27 ] , citing design as a resource for alternative forms of world - building [ 4 , 36 ] The issues of fairness and accountability have been further echoed by corporate ethics boards and civic leaders , with the grow - ing calls for ethics in AI through both practice and legislation . And in further response , technology , and data equity organizations like AI Now , the Algorithmic Justice League , Partnership on AI , and the Design Justice Network are collectively working to highlight and address such disparities through civic engagement and research . Yet despite this rich body of critical analysis , the HCI field contin - ues to struggle with inclusive approaches that effectively address the pervasive and lasting inequitable consequences of racism , bias , sexism , and discrimination perpetuated through AI . And failure to effectively address this invites the potential to wreak havoc on the lives of minority communities and vulnerable groups as they interact with applications and software that we use daily [ 22 ] . As asserted by critical technology scholar Arnold Pacey [ 26 ] and reiterated by Crawford and Calo [ 9 ] : “Artificial intelligence presents a cultural shift as much as a technical one . This is similar to technological inflection points of the past , such as the introduction of the printing press or the railways . Autonomous systems are changing workplaces , streets and schools . We need to ensure that those changes are beneficial , before they are built further into the infrastructure of everyday life” [ 26 ] . And with the rapid emergence of the Internet of Things ( IoT ) , smart devices , and voice - controlled virtual assistants like Amazon’s Echo Alexa , Google Home , and Apple’s Siri as well as various other media and data consumption devices , addressing algorithmic bias , accessibility , access , and inclusion has never been more urgent than now [ 18 , 37 ] . 3 RESEARCH OBJECTIVES , GOALS , AND QUESTIONS The issues surrounding responsibility , fairness , and equity in au - tomated speech recognition ( ASR ) systems have been well docu - mented in human - computer interaction ( HCI ) , artificial intelligence ( AI ) , machine learning ( ML ) , natural language processing ( NLP ) , and design research [ 2 , 21 , 23 ] . Notably , the usability of these systems heavily reliant upon language ML models trained on textual data and acoustic models trained on audio data . When the developed language models are trained on Standard [ ized ] American English ( SAE ) also known as Mainstream U . S . English ( MUSE ) ( often de - noted as the dominant variety of English in the United States ) , they perpetuate white , cis - normative , speech as preferable and socially acceptable [ 33 ] . This practice further echoes the practices and atti - tudes of racial majorities and MUSE groups , who often denigrate , reject , or discredit other minoritized varieties of spoken and even written English [ 30 , 34 ] . Sociolinguist scholars suggest such pat - terns may contribute to further denigrating historical language varieties like African American Vernacular English ( AAVE ) ( that are typically defined by race / ethnic groups ) by categorizing them as ungrammatical and linguistically less meaningful than other forms of American speech , despite their important legacy in shaping American culture [ 29 ] . To this damaging effect , current approaches to technology development based on user - centered technology de - sign currently face hurdles with recruitment and representation that may continue to re - entrench white , cis - normative perspectives within study designs [ 1 , 3 , 11 ] Given these existing and potential challenges , I pose two primary research questions toward my outlined research agenda : • What are the strengths and pitfalls of existing ASR system design processes , including the decisions NLP / ML technolo - gists make that shape experiences of fairness and bias among underrepresented language variety users ? • How might researchers from academia and industry de - velop and employ collaborative - participatory approaches with African American community members — involving their voices and perspectives early and often in the product development process — to address many of the challenges African Americans ( AAVE speakers ) face when using voice technology ? 4 RESEARCH APPROACH , METHODS , AND RATIONALE To explore these questions , my research team and I will engage in a multi - phase research agenda that seek to prioritize principles of Design Justice in our pursuit of centering people who have been normally marginalized by design [ 8 ] . This work will seek to advance research on equitable and inclusive ASR system design through collaborative approaches across three phases : ( 1 ) understanding the norms and pitfalls in how ASR systems are designed , including the decisions that NLP / ML technologists make that contribute dispari - ties among underrepresented language variety users ; ( 2 ) partnering with local community organizations such as the King County Equity Now ( KCEN ) and the Africatown Community Landtrust ( ACLT ) , whose missions center on advocating , liberating , and empowering Black communities , to engage in community - based participatory Collaboratively Mitigating Racial Disparities in Automated Speech Recognition and Language Technologies with African American English Speakers CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany research ( CBPR ) toward informing best practices within ASR sys - tem design ; and ( 3 ) co - designing ASR and NLP prototypes with African American speakers of AAVE that inform the development of techniques for mitigating racial disparities in those systems [ 7 , 13 ] . In Phase 1 , our research team will engage NLP / ML technolo - gists in interviews and focus groups to qualitatively understand the strengths and pitfalls of ASR system design and the decisions designers make that contribute to implications for disparities and bias among underrepresented language variety users . I expect to recruit 25 - 30 practitioners for interviews and invite roughly 20 - 25 for 4 - 5 focus groups by leveraging existing relationships with NLP / ML industry technologists ( engineers , product managers , and researchers ) , while recruiting additional practitioners from a range of backgrounds based on product / system development experience , education , and demographics . I will conduct individual 60 - minute virtual semi - structured interviews with these technologists , fol - lowed by comprehensive in - person focus groups ( including both existing interviewees and additional contacts , as needed ) to further contextualize normative practices that language system designers take that reveal implications for fairness related harms and bias in ASR systems . This phase will contribute empirical findings that illuminate design thinking processes . In Phase 2 , our research team will leverage our existing partner - ships with two social justice and advocacy organizations in Seattle ( King County ) , WA : 1 ) KCEN , a nonprofit focused on nurturing Black communities that own and control the resources and sys - tems that impact Black lives ; and 2 ) ACLT a non - profit providing equitable access to educational , technical and financial opportu - nities through technology development projects like the William Gross Center for African American Innovation . Drawing lessons from Phase 1 , and building on our existing partnerships , I will use this phase to develop a shared set of values , goals , and activi - ties for Phase 3 . I will ensure mutual gains for all stakeholders by continuing our essential work to build rapport , share project moti - vations , and learn how human - centered design processes ( within our department , university , and academic field ) can support our partners’ missions and aims [ 17 ] . I expect this support to take varied forms , including resources ( monetary , equipment / technology , sup - plies , etc . ) , advocacy ( visibility , ads , marketing ) , time ( volunteering , serving alongside organizations , pro - bono design / research ) , own - ership ( study data , workshop artifacts , rights to disclose , reports ) . Extending our prior work to develop equitable and participatory ap - proaches [ 10 , 13 , 31 , 38 ] , I will work with our partners to collectively define workshop conditions ( locations , occurrences , dates / times , engagement norms ) to ensure integrity and respect throughout our engagement with organizations . In Phase 3 , I will use findings from Phase 2 to iteratively develop a series of community - based participatory research ( CBPR ) “co - design” workshops aimed at addressing issues of fairness within ASR systems with AAVE speakers . The workshops will directly involve participants who are stakeholders of our partner organiza - tions ( KCEN , ACLT ) who identify as African American speakers of AAVE . These participants will be positioned as co - design / research collaborators on our research team . The partner organizations will support recruitment by disseminating the study opportunity , re - cruiting participants , and ensuring sustainable engagement with our research team . During each workshop , I ( Jay Cunningham ) as the research team lead and a designated peer leader nominated by the respective partner organization will co - facilitate a dialogue on the topic of mitigating bias and racial disparities of user experience in ASR and language systems for AAVE speakers . The outcomes of this phase will focus on producing a process for collecting high - quality , natural voice data for ML modeling that accurately repre - sents the language of speakers . The co - facilitators will follow these critical conversations with an action - forward co - design session to explore and create language system prototypes that enable fair , equitable , and sustainable solutions that benefit all stakeholders . The workshops will take place over two academic quarters ( roughly 20 weeks ) within Seattle neighborhood locations most suitable for the organization’s members ( community centers , churches , schools , etc . ) I aim to recruit and retain 10 - 15 members from each partner organization , appropriately compensating individual participants weekly for their collaborative engagement and by financially sup - porting our partner organizations . Data analysis will be conducted in collaboration with our partner organization to validate our find - ings . In turn , the findings from the community - based participatory research / design collaboration will be published in an academic jour - nal and publicly circulated in a format well - suited for the partner organizations . Lastly , as collective co - research group , we’ll best determine next steps for research and development that prompts sustainability in this critical effort to design language systems that are more responsible and inclusive . 5 RESULTS AND CONTRIBUTIONS TO DATE Studies are currently underway or are in the process of being de - signed that aligns with this critical research agenda . My graduate research advisors Dr . Daniela Rosner , Dr . Julie Kientz , and I was awarded as recipients of the 2022 Google , LLC Award for Inclusive Research ( AIR ) for the agenda proposed in this research statement . 6 EXPECTED NEXT STEPS , DISCUSSION , CHALLENGES Results from this three - phase study include : 1 ) informing prac - tices of community - centered participation by understanding the experiences AAVE speakers ; 2 ) developing collaborative research techniques with Black community organizations that help design more fair and equitable interaction experiences for AAVE users of language tech , 3 ) informing the public ( Black AAVE speakers ) of the adverse effects of racial disparities and to seek its elimination through increased technical knowledge collaborative partnerships with ML designers / researchers . Over the past decade , efforts to understand the intersection of equity + technology have become more prioritized by academic , industry , non - profit , and government institutions [ 1 ] . Collectively , scholars , technologists , and designers alike seek to address design , development , and deployment of intelligent machines and their impacts on minority , marginalized , and vulnerable communities [ 10 , 11 , 19 ] . As an emerging responsible AI / ML UX researcher , I am holistically interested in understanding how complexities of technology design approaches , automated intelligent machines ( AI / ML / NLP ) , and interactive systems impact , marginalize , and engage with underrepresented communities . The intended con - tributions of my graduate research will include : 1 ) Empirical CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany Jay Cunningham findings of the ways in which diverse language users ( with an emphasis on Black American communities ) are impacted by techni - cal designs of language technologies , 2 ) Integrating and extending current human - centered design and participatory methodologi - cal frameworks as interventions toward more responsible and fair interactive language systems , and 3 ) Using novel equitable and inclusive approaches to design language technologies that directly influence technology practice and contribute exemplary techno - logical artifacts . The collective broader impact advances technical design as tools of liberation and justice for underrepresented and marginalized language communities , not limited to and including speakers of ethnolect / sociolinguistic varieties ( e . g . , AAVE speakers ) , atypical speech ( e . g . , speech disabilities , speech impediments ) , and non - native English accents / dialects . ACKNOWLEDGMENTS This research is directly funded by the following awards : National Science Foundation , Graduate Research Fellowship Pro - gram ( Grant no : 1762114 | University of Washington ) Google , LLC . , Award for Inclusion Research ( AIR ) REFERENCES [ 1 ] Ruha Benjamin . 2019 . Race after technology : Abolitionist tools for the new jim code . Social forces ( 2019 ) . [ 2 ] Steven Bird . 2020 . Decolonising Speech and Language Technology . In Proceedings of the 28th International Conference on Computational Linguistics , International Committee on Computational Linguistics , Barcelona , Spain ( Online ) , 3504 – 3519 . DOI : https : / / doi . org / 10 . 18653 / v1 / 2020 . coling - main . 313 [ 3 ] Su Lin Blodgett , Solon Barocas , Hal Daumé III , and Hanna Wallach . 2020 . Lan - guage ( Technology ) is Power : A Critical Survey of “Bias” in NLP . In Proceed - ings of the 58th Annual Meeting of the Association for Computational Linguis - tics , Association for Computational Linguistics , Online , 5454 – 5476 . DOI : https : / / doi . org / 10 . 18653 / v1 / 2020 . acl - main . 485 [ 4 ] Kirsten Bray and Christina Harrington . 2021 . Speculative Blackness : Considering Afrofuturism in the Creation of Inclusive Speculative Design Probes . In Design - ing Interactive Systems Conference 2021 , ACM , Virtual Event USA , 1793 – 1806 . DOI : https : / / doi . org / 10 . 1145 / 3461778 . 3462002 [ 5 ] Joy Buolamwini and Timnit Gebru . 2018 . Gender Shades : Intersectional Accu - racy Disparities in Commercial Gender Classification . In Proceedings of the 1st Conference on Fairness , Accountability and Transparency , PMLR , 77 – 91 . Retrieved March 14 , 2022 from https : / / proceedings . mlr . press / v81 / buolamwini18a . html [ 6 ] Cathy O’Neil . 2016 . Weapons of Math Destruction : How Big Data Increases Inequal - ity and Threatens Democracy . Crown , New York . Retrieved March 14 , 2022 from http : / / offcampus . lib . washington . edu / login ? ; url = https : / / search . ebscohost . com / login . aspx ? direct = true & db = nlebk & AN = 1109940 & site = ehost - live [ 7 ] Ned Cooper . 2022 . A Systematic Review and Thematic Analysis of Community - Collaborative Approaches to Computing Research . ( 2022 ) , 18 . [ 8 ] Sasha Costanza - Chock . 2018 . Design Justice : Towards an Intersectional Feminist Framework for Design Theory and Practice . Social Science Research Network , Rochester , NY . Retrieved April 13 , 2020 from https : / / papers . ssrn . com / abstract = 3189696 [ 9 ] Kate Crawford and Ryan Calo . 2016 . There is a blind spot in AI research . Nature 538 , 7625 ( October 2016 ) , 311 – 313 . DOI : https : / / doi . org / 10 . 1038 / 538311a [ 10 ] Jay L . Cunningham , Gabrielle Benabdallah , Daniela K . Rosner , and Alex S . Taylor . 2022 . On the Grounds of Solutionism : Ontologies of Blackness and HCI . ACM Trans . Comput . - Hum . Interact . ( August2022 ) . DOI : https : / / doi . org / 10 . 1145 / 3557890 [ 11 ] Jay L . Cunningham , Sydney T . Nguyen , Julie A . Kientz , and Daniela Rosner . 2022 . The Cost of Culture : An Analysis of Cash App and the Financial Inclusion of Black American Communities . In Designing Interactive Systems Conference ( DIS ’22 ) , Association for Computing Machinery , New York , NY , USA , 612 – 628 . DOI : https : / / doi . org / 10 . 1145 / 3532106 . 3533569 [ 12 ] Jessie Daniels . 2013 . Race and racism in Internet Studies : A review and critique . New Media & Society 15 , 5 ( August 2013 ) , 695 – 719 . DOI : https : / / doi . org / 10 . 1177 / 1461444812462849 [ 13 ] Catherine D’Ignazio , Erhardt Graeff , Christina N . Harrington , and Daniela K . Rosner . 2020 . Toward Equitable Participatory Design : Data Feminism for CSCW amidst Multiple Pandemics . In Conference Companion Publication of the 2020 on Computer Supported Cooperative Work and Social Computing , ACM , Virtual Event USA , 437 – 445 . DOI : https : / / doi . org / 10 . 1145 / 3406865 . 3418588 [ 14 ] Catherine D’Ignazio and Lauren F . Klein . 2020 . Data Feminism . MIT Press . [ 15 ] Sheena Erete , Aarti Israni , and Tawanna Dillahunt . 2018 . An intersectional approach to designing in the margins . interactions 25 , 3 ( April 2018 ) , 66 – 69 . DOI : https : / / doi . org / 10 . 1145 / 3194349 [ 16 ] AlexHanna , EmilyDenton , AndrewSmart , andJamilaSmith - Loud . 2020 . Towards a critical race methodology in algorithmic fairness . In Proceedings of the 2020 Conference on Fairness , Accountability , and Transparency ( FAT * ’20 ) , Association for Computing Machinery , Barcelona , Spain , 501 – 512 . DOI : https : / / doi . org / 10 . 1145 / 3351095 . 3372826 [ 17 ] Christina Harrington , Sheena Erete , and Anne Marie Piper . 2019 . Deconstructing Community - Based Collaborative Design : Towards More Equitable Participatory Design Engagements . Proc . ACM Hum . - Comput . Interact . 3 , CSCW ( November 2019 ) , 1 – 25 . DOI : https : / / doi . org / 10 . 1145 / 3359318 [ 18 ] ChristinaNHarrington , RadhikaGarg , AmandaWoodward , andDimitriWilliams . 2022 . “It’s Kind of Like Code - Switching” : Black Older Adults’ Experiences with a Voice Assistant for Health Information Seeking . ( 2022 ) , 15 . [ 19 ] Christina N . Harrington , Brittany Johnson , Denae Ford , and Angela D . R . Smith . 2021 . Designing for the black experience . interactions 28 , 5 ( September 2021 ) , 22 – 27 . DOI : https : / / doi . org / 10 . 1145 / 3477095 [ 20 ] Michael Huesemann and Joyce Huesemann . 2011 . Techno - Fix : Why Technology Won’t Save Us Or the Environment . New Society Publishers . [ 21 ] Allison Koenecke , Andrew Nam , Emily Lake , Joe Nudell , Minnie Quartey , Zion Mengesha , Connor Toups , John R . Rickford , Dan Jurafsky , and Sharad Goel . 2020 . Racial disparities in automated speech recognition . Proc . Natl . Acad . Sci . U . S . A . 117 , 14 ( April 2020 ) , 7684 – 7689 . DOI : https : / / doi . org / 10 . 1073 / pnas . 1915768117 [ 22 ] Rebecca Ann Lind . 2019 . Race / Gender / Class / Media : Considering Diversity Across Audiences , Content , and Producers . Taylor & Francis Group , Milton , UNITED KINGDOM . Retrieved February 22 , 2022 from http : / / ebookcentral . proquest . com / lib / washington / detail . action ? docID = 5720590 [ 23 ] Zion Mengesha , Courtney Heldreth , Michal Lahav , Juliana Sublewski , and Elyse Tuennerman . 2021 . “I don’t Think These Devices are Very Culturally Sensitive . ”— Impact of Automated Speech Recognition Errors on African Americans . Frontiers in Artificial Intelligence 4 , ( 2021 ) . Retrieved December 6 , 2022 from https : / / www . frontiersin . org / articles / 10 . 3389 / frai . 2021 . 725911 [ 24 ] Safiya Umoja Noble . 2018 . Algorithms of oppression . New York University Press . [ 25 ] IhudiyaFindaOgbonnaya - Ogburu , AngelaD . R . Smith , AlexandraTo , andKentaro Toyama . 2020 . Critical Race Theory for HCI . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems , ACM , Honolulu HI USA , 1 – 16 . DOI : https : / / doi . org / 10 . 1145 / 3313831 . 3376392 [ 26 ] Arnold Pacey . 1983 . The culture of technology . The MIT Press . Retrieved March 5 , 2022 from http : / / hdl . handle . net / 2027 / heb . 01153 [ 27 ] Joyojeet Pal . 2017 . CHI4Good or Good4CHI . In Proceedings of the 2017 CHI Con - ferenceExtendedAbstractsonHumanFactorsinComputingSystems , ACM , Denver Colorado USA , 709 – 721 . DOI : https : / / doi . org / 10 . 1145 / 3027063 . 3052766 [ 28 ] Nassim Parvin and Anne Pollock . 2020 . Unintended by Design : On the Political Uses of “Unintended Consequences . ” Engaging Science , Technology , and Society 6 , ( August 2020 ) , 320 – 327 . DOI : https : / / doi . org / 10 . 17351 / ests2020 . 497 [ 29 ] John R . Rickford , Greg J . Duncan , Lisa A . Gennetian , Ray Yun Gou , Rebecca Greene , Lawrence F . Katz , Ronald C . Kessler , Jeffrey R . Kling , Lisa Sanbonmatsu , Andres E . Sanchez - Ordoñez , Matthew Sciandra , Ewart Thomas , and Jens Ludwig . 2015 . Neighborhood effects on use of African - American Vernacular English . Proceedings of the National Academy of Sciences 112 , 38 ( September 2015 ) , 11817 – 11822 . DOI : https : / / doi . org / 10 . 1073 / pnas . 1500176112 [ 30 ] John R . Rickford and Sharese King . 2016 . LANGUAGE AND LINGUISTICS ON TRIAL : HEARINGRACHELJEANTEL ( ANDOTHERVERNACULARSPEAKERS ) IN THE COURTROOM AND BEYOND . Language 92 , 4 ( 2016 ) , 948 – 988 . [ 31 ] Dawn K . Sakaguchi - Tang , Jay L . Cunningham , Wendy Roldan , Jason Yip , and Julie A . Kientz . 2021 . Co - Design with Older Adults : Examining and Reflecting on Collaboration with Aging Communities . Proc . ACM Hum . - Comput . Interact . 5 , CSCW2 ( October 2021 ) , 362 : 1 - 362 : 28 . DOI : https : / / doi . org / 10 . 1145 / 3479506 [ 32 ] Angela D . R . Smith , Alex A . Ahmed , Adriana Alvarado Garcia , Bryan Dosono , IhudiyaOgbonnaya - Ogburu , YolandaRankin , AlexandraTo , andKentaroToyama . 2020 . What’s Race Got To Do With It ? Engaging in Race in HCI . In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems , ACM , Honolulu HI USA , 1 – 8 . DOI : https : / / doi . org / 10 . 1145 / 3334480 . 3375156 [ 33 ] Rachael Tatman . Effects of Talker Dialect , Gender & Race on Accuracy of Bing Speech and YouTube Automatic Captions . Google Docs . Retrieved March 30 , 2022 from https : / / drive . google . com / file / d / 1 - KguIOU0B9CFBli9nN9U9ZintWLVufry / view ? usp = embed _ facebook [ 34 ] Alicia Beckford Wassink , Cady Gansen , and Isabel Bartholomew . 2022 . Uneven success : automatic speech recognition and ethnicity - related dialects . Speech Communication 140 , ( May 2022 ) , 50 – 70 . DOI : https : / / doi . org / 10 . 1016 / j . specom . 2022 . 03 . 009 [ 35 ] Sarah Myers West , Meredith Whittaker , and Kate Crawford . DISCRIMINATING SYSTEMS . 33 . [ 36 ] Woodrow W Winchester . Engaging the Black Ethos : Afrofuturism as a Design Lens for Inclusive Technological Innovation . 8 . [ 37 ] 2019 . Is Siri a Little Bit Racist ? Recognizing and Confronting Algorithmic Bias in Emerging Media . Routledge . DOI : https : / / doi . org / 10 . 4324 / 9781351630276 - 55 Collaboratively Mitigating Racial Disparities in Automated Speech Recognition and Language Technologies with African American English Speakers CHI EA ’23 , April 23 – 28 , 2023 , Hamburg , Germany [ 38 ] WhoGetstoFuture ? | Proceedingsofthe2019CHIConferenceonHumanFactors in Computing Systems . Retrieved January 10 , 2023 from https : / / dl . acm . org / doi / abs / 10 . 1145 / 3290605 . 3300791