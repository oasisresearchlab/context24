Posing Fundable Questions in Mathematics and Science Education K . D . King 1 & R . J . Ochsendorf 1 & G . E . A . Solomon 1 & F . C . Sloane 1 Received : 22 October 2019 / Accepted : 27 March 2020 / # This is a U . S . Government work and not under copyright protection in the US ; foreign copyright protection may apply 2020 Abstract In this article , the authors describe critical issues related to the pursuit of rigorous and innovative research in the fields of mathematics and science education . The paper is framed to help researchers consider aspects of both their research project and their research proposal . The authors describe features of high - quality and fundable research projects and whether the research is intended to support descriptive , design - oriented , or causal interpretation . They discuss the critical role of grounding proposed research in existing literatures ; attending to relevant research from associated fields ; and posing research questions that are clear , specific , and feasibly addressable . The goals of the research should cohere with the methodological and analytic design proposed . The authors also discuss the multidisciplinary nature of research that has implications for practice in general and for educational practice more specifically . The authors touch on the characteristics of more and less successful interdisciplinary research teams , especially those that draw from education , cognitive science , methodology , educational psychology , the learning sciences , and relevant STEM disciplinary fields . Examples of STEM education research questions from different genres of research are considered and the authors describe how the questions themselves give rise to specific design choices , methodologies , measures , study samples , and analytical models as well as how they can reflect the disciplinary orientations of the researchers . Implications of these issues for successful educational research grant proposal writing are discussed . Keywords Federalfunding . Mathematicseducation . Scienceeducation . Researchdesign . Research questions As program directors in the Directorate for Education and Human Resources at the US National Science Foundation ( NSF ) , a critical aspect of our work is making International Journal of Science and Mathematics Education https : / / doi . org / 10 . 1007 / s10763 - 020 - 10088 - 4 This paper is dedicated to the memory of Dr . Karen D . King , who passed away on December 24 , 2019 * R . J . Ochsendorf rochsend @ nsf . gov 1 National Science Foundation , Alexandria , VA , USA ( 2020 ) 18 ( Suppl 1 ) : S25 – S36 Published online : 20 April 2020 recommendations about what research in mathematics and science education to fund ( or , as is far more often the case , what not to fund ) . In this paper , we describe critical issues related to the pursuit of rigorous and innovative research in the fields of Science , Technology , Engineering , and Mathematics ( STEM ) learning and education and issues related to getting funded to do that work . Our insights are derived from what we see from our unusual perspective on both the proposal writing and review processes as well as our view of how principal investigators ( PIs ) view their programs of research and justify why they think those programs are important . Journal editors have a similarly broad view of their fields , except that they are reading work that has been completed rather than work that the PI hopes to undertake in the near future . We understand , only too well , that writing proposals for research funding is a peculiar facet of North American academic culture , though it is becoming increas - ingly common around the world . It is also important at all career levels . Whereas doctoral students in most European universities generally receive fiscal support ( tuition and stipend ) for a specific period from their own governments , doctoral students in most US universities — if they are not to pay for their educations using their own dimes — generally rely on faculty members to generate the fiscal resources to support their learning . For faculty members , those external resources often come from the federal government , foundations , or university endowments . When the US federal government is involved , the funding of graduate students can come in the form of competitive scholarships or research fellowships . In either case , the deci - sion to allocate finite federal resources is associated with specific research projects ( presented as proposals for research ) that have usually been adjudicated through a peer review process . We highlight these features because we , the authors , all work for the US federal government as part of this adjudication system . And though our narrative is that of program officers in a US federal funding agency , our insights have been gained through our own research experiences , our many years of government service , and our profes - sional interactions with colleagues who work at other funding bodies around the world , both private and governmental ( e . g . , Science Foundation Ireland ; the Wellcome Trust , United Kingdom ; German Research Foundation [ DFG ] ; Netherlands Organisation for Scientific Research [ NWO ] ; the Centre for Research in Pedagogy and Practice at Nanyan Technological University , Singapore ; and the James S . McDonnell Foundation , to name but a few ) . Moreover , the questions we address are common to STEM education research design more broadly and occur at many times during a researcher ’ s career : in proposals for a master ’ s thesis , proposals for dissertation research , proposals for postdoctoral study , and proposals for research funding . In considering the issues facing researchers seeking funding , we find it useful to distinguish between a research project and a research proposal . By research proposal , we mean the actual document a PI puts together that makes the case for support by a specific funding agency . The research project is the work that lies behind and is described by the research proposal . This is what the PI wants to do , at least to the extent that the various aspects of the work have been thought through and developed . Obviously , what goes into making a good research project and what goes into making a good research proposal bear more than a passing resemblance , but they are not identical . We discuss these each in turn . Let us begin with the former . K . D . King et al . S26 The Research Project What we call the research project , as we introduced above , is the actual work that a scientist hopes to get funding to do . It is what lies behind the submitted research proposal and what the reviewers and program officers attempt to divine and evaluate . In this section , we describe critical features of fundable research projects as often captured in the ways that research questions are framed and presented . We begin with a brief recap of the push for a more empirical orientation that has occurred in education research over the last few decades . The movement toward evidence - based policy has gained considerable momentum and persists today ( Institute of Education Sciences & National Science Foundation , 2013 ; National Mathematics Advisory Panel [ NMAP ] , 2008 ; National Research Council [ NRC ] , 2002 ; Slavin , 2002 ) . Underlying this shift are critical assumptions : that education previously suffered from a shortage of rigorous research and a weak evidentiary base ; that a move toward “ scientifically based ” research would lead to carefully warranted claims about what works in education ; and that the gathering of stronger evidence would guide reform efforts , help to close achievement gaps , and improve the educational outcomes of students . US federal funding agencies embraced many of these assumptions . They underlie , for example , the creation in 1999 of the Research on Learning and Education ( ROLE ) research funding program at NSF and the creation in 2002 of the Institute of Education Sciences ( IES ) at the US Department of Education and its programs such as Cognition and Student Learning . These arguments were forcefully presented to the American Educational Research Association ( AERA ) community in 2003 as part of this move toward more scientifically based research in education ( Whitehurst , 2003 ) . Similar sentiments with respect to scientific research in education were conveyed around the same time in a US National Academies of Science report , Scientific Research in Education ( NRC , 2002 ) . A set of key recommendations were provided to frame for the field the principles of research in education . Those recommendations were : & Pose significant questions that can be investigated empirically . & Link research to relevant theory . & Use methods that permit direct investigation of the question . & Provide a coherent and explicit chain of reasoning . & Replicate and generalize across studies . & Disclose research to encourage professional scrutiny and critique ( p . 52 , 2003 ) . Although all these principles and recommendations are critical and very much interre - lated , of particular interest here is the first principle . What does it mean to pose “ significant ” questions ? What does it mean to pose questions that can be “ investigated empirically ? ” Beginning with a clear , specific , and researchable question is critical to the scientific process in any field , especially education . Here we discuss these issues in the context of proposing and conducting high - quality , fundable research projects in math and science education . Posing Fundable Questions in Mathematics and Science Education S27 Features of Fundable Questions Proper Grounding of Questions in Prior Research and Theory . Questions should be grounded in prior research and make explicit connections to what is known or not known in each area of research . A research question is important either as it relates to advancing fundamental understanding ( either basic or use - inspired basic research ) or as it relates to a problem of use or practice 1 ( e . g . , Stokes , 1997 ) . In either case , an appropriate and systematic review of relevant literature , along with the theoretical grounding of the research questions , provides the context within which the importance of the questions being posed is to be understood . Potentially Transformative Questions . Projects in math and science education often attempt only incremental advances on prior findings by pursuing similar lines of inquiry year after year , perhaps following on in the same footsteps of one ’ s academic advisors . For some academics , there is a tendency to surround oneself with like - minded researchers who attend the same conferences , read and publish in the same journals , and cite the same articles . Grounding one ’ s research in the prior literature can delimit its value when that literature is overly narrow . To be sure , one can argue not only that incremental research is the most common kind but also that it provides a necessary foundation for more transformative or revolutionary advances . Nonetheless , there is the danger of diminishing returns , of knowing more and more about less and less . Some of the most significant recent advances in science have come from large multidisciplinary teams of scholars working on enormously complex problems across fields ( e . g . , LIGO and Event Horizon Telescope discoveries ; cf . Casadevall & Fang , 2013 ) which speaks to the realized promise of team science ( Ahmadpoor & Jones , 2019 ; Wuchty , Jones , & Uzzi , 2007 ) . Education researchers should not shy away from meaningful collaboration and engagement with cognitive and developmental psychol - ogists , data scientists , neuroscientists , economists , and computer scientists . This could include attending conferences outside of their STEM education circles of comfort , submitting and reviewing for journals that are adjacent to their own , and partnering with “ outsiders ” to address questions from different perspectives and pose new ways of thinking about some of the most significant problems in education . The recent National Academies report ( NRC , 2015 ) , Enhancing the Effectiveness of Team Science , set forth recommendations for what constitutes effective team science ( e . g . , composition , col - laboration , professional development of researchers , and leadership ) . We believe that education , like other fields , can benefit from a stronger commitment to multidisciplin - ary team science , posing transformative and significant research questions and breaking new ground in our field . Indeed , calls for such efforts reaching across disciplinary boundaries have been made repeatedly over the last several decades . There is evidence that the turn of the last century represented something of a watershed moment , with a marked increase in citations between research in education and those in allied fields such as Cognitive Science and Educational Psychology ( Youtie , Solomon , Carley , 1 Some foundations focus on only one category of research . At NSF , programs exist to support both kinds of research . For example , the EHR Core Research ( ECR ) program supports fundamental research on learning , workforce development , and broadening participation in all the STEM disciplines . Programs like Discovery Research preK - 12 ( DRK - 12 ) , Advancing Informal STEM Learning ( AISL ) , and Innovations in Undergrad - uate STEM Education ( IUSE ) support research and development that is more applied in nature . K . D . King et al . S28 Kwon & Porter , 2017 ) . Of course , working across disciplinary lines can be fraught with a host of practical as well as intellectual challenges ( Cummings & Kiesler , 2005 ) , but there is evidence that educational research that bridges between fields tends to be more influential and longer lasting than research that does not ( Kwon , Solomon , Youtie & Porter , 2017 ) . Specific and Clear Constructs . Strong research questions should make clear the key dependent variables of interest along with the study subjects of interest . It is often the case that research questions will not be sufficiently specific about the constructs of interest ( e . g . , STEM teacher knowledge , student outcomes , quality of STEM instruc - tion ) or specify the study populations from which samples are drawn . In many cases , the constructs included are entirely too broad to conceptualize , let alone measure . Take , for example , a PI who is interested in the “ quality of STEM instruction . ” There certainly do exist instructional quality measures for use in specific STEM education settings . However , the inclusion of such a broad construct in a research question is neither sufficiently specific nor could it be reliably measured in the context of a given study . Going back to the 2002 NRC report , it is difficult to imagine that such a broad construct could be investigated empirically in a meaningful way . Rather , a narrowing of the instructional quality construct would be warranted . Some suggestions are provided in Table 1 ( e . g . , promotion of student discourse , use of formative assessment ) . Of course , the identification and narrowing of a construct is always driven by relevant theory , the nature of the program under investigation , and perhaps the measurement options available . From Fundable Questions to Appropriately Aligned Methods Research questions ought to be directly connected to the chosen methods of the proposed study . This is not a novel idea and should certainly be well emphasized in the methods course sequence of doctoral programs in education . However , we often see Table 1 Features of suboptimal research questions and possible revisions Research question Possible revisions 1 . To what extent do teacher outcomes mediate the effect on student outcomes ? Does teachers ’ implementation fidelity mediate the relationship between program x and students ’ science learning ? orDoes teachers ’ pedagogical content knowledge mediate the relationship between program x and students ’ science learning ? 2 . Does professional development program X improve the quality of teachers ’ STEM instruction ? Does professional development program X improve high school science teachers ’ promotion of student discourse ? orDoes professional development program X improve high school science teachers ’ promotion of student argumentation from evidence ? Posing Fundable Questions in Mathematics and Science Education S29 challenges with respect to the mapping between the level of research question and the learning model or theory that is the focus of the research . This issue has been more thoroughly unpacked by Sloane ( 2008 ) and Sloane and Wilkins ( 2017 ) , but some emphasis now is worthwhile . It is often the case that mathematics and science educa - tion researchers will ground their studies and their research questions in theories of learning that reside predominantly at the student level . However , while conducting the research in classrooms and schools , the studies will implement approaches , collect data , and then aggregate that data to the group level and look for mean differences ( e . g . , class , grade , or school ) . The choice of the student as the theoretical , sampling , and analytic unit is typically justified in the proposals ’ methods as necessary to generate sufficient power in the research design . However , for the many reasons outlined by Sloane and Wilkins ( 2017 ) , this is problematic as often the proposed quantitative analyses examine average student achievement regardless of classroom ( or school assignment ) , making a mockery of the original power argument . In sum , looking at 400 students nested in 16 classrooms is not the same as looking at 400 students drawn randomly from a well - specified population or looking at 16 classrooms drawn at random populated by 400 students . At one level of analysis ( i . e . , individual students ) , the sample size is 400 . At the other level of analysis ( i . e . , classrooms ) , the sample size is 16 . The implication of this for research projects is that research questions should make explicit the connections between the unit of interest ( e . g . , student , classroom , school ) and the level at which the inference will be drawn . It is not unusual for researchers to be unaware of the level of inference their own work licenses and then to make claims in published work that are not supported by their design . For more basic or fundamental research questions , it is important to frame the studies on the individual and then infer back to the individual , as we may be trying to build on theories about individuals and their learning in a specific domain . The first research question in Table 2 is an example of such a question , as the study uses a nationally representative sample of students ( from the Early Childhood Longitudinal Study ) to address questions about the relationship between executive function and children ’ s later academic performance . The question is at the level of the student and it maps cleanly to the analytical and inferential models in the study ( Morgan , Farkas , Wang , Hillemeier , Oh & Maczuga , 2019 ) . For more applied questions that may be more focused on students and their experiences in classrooms and schools , research will likely need to more explicitly focus on the social context of schooling and learning ( e . g . , groups ) . With recent standards movements in STEM disciplines , students are increasingly asked to engage in the social practices of “ authentic ” science and mathematics . As an example , a proposal may aim to develop a new professional development approach focused on teachers and their instruction . Although the program may be derived and supported by theories of student and adult learning , the research questions and focus might more appropriately be focused on the extent to which the professional development experience affects classroom behaviors of teachers and students alike ( e . g . , student discourse , argumentation from evidence ; as shown in the second example of Table 1 ) . In cases like this , the focus of the questions , the observations , the analysis , and the inferences should be about how the new approach is affecting groups of learner behavior in classrooms mediated by teacher behaviors . K . D . King et al . S30 The Research Proposal NSF receives thousands of proposals every year in the area of STEM education focusing on learners of all ages and all learning contexts across its research programs . Far more proposals are not fundable than are fundable . Our advice in this section is largely drawn from our experiences working across NSF programs , but it applies broadly . There are challenges to writing a research proposal in getting across to a set of reviewers what are the aspects of the proposed research project that make it worth funding . Some of these challenges are of particular relevance to funding in mathematics and science education research . Challenges and Advice Our first piece of advice is that investigators should submit their proposals to the appropriate program . This may seem obvious , but even seasoned PIs can be surprised at the extent to which programs vary in their emphases , and that in turn has implications for how different proposals fare in review , which have implications for a range of decisions that PIs make in writing the actual proposal . PIs have a limited number of pages in which to describe their projects ( for most NSF programs , the project descrip - tion can be no more than 15 pages ) . That means PIs will have to make decisions about when to be specific and when to be vague in describing aspects of the project . PIs have to be vague about something . A critical question for a reviewer is whether they are being vague about the right things . Are they being vague about critically important components on which the success of the project hinges ( e . g . , theoretical grounding , specific research questions that can be addressed empirically , the manner and types and quality of data to be collected , how the analysis plan will support the appropriate warranting of claims , to name but a few ) ? Can reviewers assume that what is not detailed will be done correctly or does this sin of omission suggest to the reviewers that the PI does not have sufficient expertise or has not engaged the design deeply enough ? For example , a proposal might describe a series of fMRI scans of students while they engage mathematics problems , but perhaps say nothing about the brain regions of interest or the statistics and methods used to interpret the scans or perhaps not specify the math content under investigation . Reviewers may ask whether the level of detail given is sufficient to judge the quality of the proposal or whether the omissions suggest Table 2 Exemplar research questions from NSF - funded published research studies Research question Citation 1 . Do executive function deficits in kindergarten increase children ’ s risk of experiencing repeated academic difficulties from first to third grade ? Morgan et al . , 2019 2 . What do teachers share within Pinterest ? How do they make sense of curated curricula ? Hu , Torphy , Opperman , Jansen & Lo , 2018 3 . What were the trends and patterns of Black teacher retention in NC as compared with that of White teachers ? How did these trends and patterns vary depending on teachers ’ effectiveness ( controlling for subject matter and school conditions ) ? Sun , 2018 Posing Fundable Questions in Mathematics and Science Education S31 serious flaws in the research plan . This is true of how much to say about the methods and analyses as well as how thorough and extensive the background literature review should be . Something must be left out , but is it the right something ? There is no single answer to this question , and to some extent the answer is different for proposals submitted to different programs . Where the funding program falls on the continuum of basic ( or fundamental ) research to practice or use ( e . g . , Stokes , 1997 ) has a host of implications for the PI for both research design and proposal exposition . A fundamental research program ( e . g . , NSF ’ s ECR program ) is intended to support research projects that primarily advance the research literature . Such projects are not expected to have a direct or immediate impact on practice . By contrast , a more applied education research program , such as DRK - 12 at NSF or the Cognition and Student Learning program at the Institute of Education Sciences , will be expected to have a more near - term impact and implica - tions for practice . One would expect space to be allocated differently in proposals sent to these different programs . For example , a PI may choose to argue differently for the importance of the work or the specific methodology being employed depending on the research program . Whether a fundamental cognitive research project or a more applied research and development project , it is in the PI ’ s interest to make clear how the work described in the proposal is connected to the greater mission of the funding program ( e . g . , ECR or DRK - 12 ) . For example , even though , as mentioned above , the outcome of an ECR project need not directly influence practice , it would behoove the PI to make it clear why a proposal reviewer would think the research is important . The proposal should answer the question “ So what ? ” The PI of a fundamental research project might , therefore , make clear the broader arc of influence by which the work might eventually influence practice . The PI could describe how the output of the project has implications , for example , for another set of necessary fundamental studies ( whether to be conducted by the PI ’ s team or by others ) and how the outcomes of that program of research has implications for other more applied research , which would then feed into research on implementation and perhaps so on into practice . The potential significance of the proposed work for STEM educational practice , however long term and indirect , should be clear . It should be clear to the reviewers and the program staff why the goal of the project described in the proposal is important . An additional challenge faced by PIs submitting proposals to STEM education research funding programs is that education is inherently multidisciplinary . Education research as a field is not monolithic . That means funding programs can vary greatly in the disciplinary backgrounds of the awards in their portfolios , in the backgrounds of the reviewers evaluating the proposals , and in the program directors managing the review process . Thus , the nature and clarity of the exposition is that much more important . Decisions about how much space to allocate to methodology , to proposed analyses and expected outcomes , to dissemination , to a review of the background literature , and even to the significance of the research question are likely to be very different depending on the disciplinary background of the expected audience . A reviewer with a background similar to that of the PI , who conducts research on the very topic addressed by the PI , would clearly expect a different ( likely more concise ) justification of the importance of the topic and different literature coverage than would a reviewer from a different field who not only might not know the specific literature being cited but might not have even K . D . King et al . S32 been aware that the research topic had a literature . The former reviewer would expect to see a proposal making the explicit case for how the proposed project would specifically advance the field and attend to details in the methods and analyses , whereas the latter reviewer would likely look to a justification for why one would even consider doing the work . In some funding programs , the panel reviewers might all be from a particular field ( e . g . , a proposal on undergraduate biology education might be reviewed primarily by biologists ) whereas , in others , such as ECR , the panels themselves are usually multidisciplinary with , for example , a biology education researcher sitting next to a statistician sitting next to a teacher educator sitting next to a cognitive neuroscientist . Each reviewer might have expertise relevant to some aspect of a proposal and expect that aspect to be described in a manner worthy of funding . Add to the above the fact that a feature of education is that these multiple relevant literatures and the communities of researchers they represent have often had little to no systematic interaction ( Solomon , Youtie , Carley & Porter , 2019 ; Youtie et al . 2017 ) . The same question might be addressed in multiple literatures ( e . g . , research on the learning of Darwinian evolution exists in the biology education , cognitive science , and biology literatures , often without significant cross citation ) . As we have seen over the years in our experience managing review panels , one sure way to draw the ire of reviewers is to ignore the existence of their disciplinary literatures . Indeed , making the claim in a proposal that yours is the first work on a particular topic is almost a guarantee that your proposal will be reviewed by someone whose life ’ s work is on precisely that topic . You must describe your project in sufficient detail to satisfy a reviewer with expert experience in your specific area that your work will advance the field while perhaps also convincing another reviewer — who might never previously have even thought about your question and is unfamiliar with the relevant literature — that the work is important and worth funding . Oh , and you have only 15 pages in which to do so . Good luck ! Foregrounding the Significance of Your Research To address much of the advice noted above , we strongly suggest that the PI craft what might be considered a significance section . A well - written significance section high - lights the fundamental value of the proposed research and serves to draw in the reviewer . The questions the research study will address should be featured with their justification in this section . The reviewers must find the logic of the section to be coherent , convincing , and sound ; the ideas exciting ; and the scope reasonable within the timeframe and budget you will later propose . The section should be linked to the specific aims , questions , or hypotheses of the study or set of studies to be conducted , and these should follow closely in the proposal . It should also precede the literature review and theoretical grounding . A common error in proposals is that the literature reviewed is not connected to the research questions as presented . Or the review is of a too narrow slice of the literature and does not include competing views or findings from one ’ s own field or outside fields that are directly relevant . This only serves to undermine a reader ’ s sense of the greater importance of the proposed work . Writing a carefully crafted and purposeful signifi - cance section is a non - trivial activity and the PI should spend the necessary time in preparation of such a section . Posing Fundable Questions in Mathematics and Science Education S33 Engage the Bigger Picture . One way to refine the thinking about the significance of the research is to step outside your own discipline and immediate needs . Take a broad and long - term view of your research . This outside perspective is necessary when examining the potential value of the research . Start the process with a clear , precise , and accurate summary statement before you pen your significance section . When examining the various drafts of the significance section , we suggest that you : & Examine the proposed research from both a broad and narrow disciplinary viewpoint . & Ask what researchers inside versus outside your chosen field would perceive as its greatest contribution . & Consider both the empirical and theoretical contributions that may result from the proposed line of inquiry . & Identify and contrast basic and applied uses of the data to be collected . & Consider how you expect others to use your research results . & Place these potential contributions of the research on a timeline , keeping in mind that the significance of a research project will change over time and with foresee - able developments in technology . & Be self - critical . Ask how an impartial reader might dispute the claims you have made for the significance of the work . & Give a draft to colleagues whom you respect but disagree with . You do not have to come to their way of thinking , but your draft should stand up to their criticisms . & Give a draft to colleagues from fields which you think should be interested in the output of you project ( e . g . , further down the continuum toward practice ) . Do they understand what you think is important about the work ? Do they care ? Addressing these questions through a series of drafts will better allow the writer to build a convincing significance section and to understand the value the research could bring to multiple audiences . Significant questions support knowledge generation in a sub - stantive area , are examined through the appropriate collection of data , and are analyzed with methodological clarity so that the research claims to be made are warranted . The goal of a research proposal is to persuade a committee of scholars ( a peer group ) that a research study is worth conducting . In closing , we note that writing for a peer review competition is an art that differs from the research work itself . There are clear rules that all writers must adhere to as well as agreements about what makes for good science , but there are also unspoken customs , norms , and needs that govern the selection process itself . As we have attempted to describe above , these can vary greatly by discipline , funding program , funding institu - tion , and nation . Successful proposal writers learn them . Eventually . Our final piece of advice : A declined proposal does not ( necessarily ) mean that the PI should go away forever . Even the most excoriating reviews could simply mean that that particular set of reviewers , reading that particular exposition of the underlying research project , did not like it in comparison to a particular set of other proposals appearing before the panel at that particular time , given that particular agency ’ s budget . It could well be that your actual research project is sound but that your exposition in the proposal missed the target . You were vague or unclear about the wrong things — things important to the diverse reviewers and to the specific program that you submitted to . Or K . D . King et al . S34 it could be that the reviewers correctly pointed out serious flaws in your project that , if corrected , would make it significantly stronger and more apt to be funded . In either case , if the research is important and worth doing , the proposal is worth revising . Acknowledgments We acknowledge the many scholarly and intellectual contributions of our dear friend and colleague , Dr . Karen King . Many of the ideas presented in this paper were shaped and sharpened over the years through our conversations with Karen . Her contributions to STEM education research include her scholarship in mathematics education , her national leadership , her distinguished federal service , and her mentoring of young researchers . We hope this paper serves as a unique bookend to her career of service through its potential for ongoing constructive impact , especially for young scholars . We thank two anonymous reviewers for their helpful critiques . Finally , we thank Dr . Jinfa Cai , the special issue editor , for his feedback and timely support . Compliance with Ethical Standards Disclaimer This material is based upon work supported while serving at the National Science Foundation . Robert J . Ochsendorf and Gregg E . A . Solomon were supported by the Foundation ’ s IRD program . Any opinion , findings , and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation . References Ahmadpoor , M . , & Jones , B . F . ( 2019 ) . Decoding team and individual impact in science and invention . Proceedings of the National Academies of Science , 116 ( 28 ) , 13885 – 13890 . https : / / doi . org / 10 . 1073 / pnas . Casadevall , A . , & Fang , F . C . ( 2013 ) . Is the Nobel prize good for science ? The FASEB Journal , 27 ( 12 ) , 4682 – 4690 . Cummings , J . N . , & Kiesler , S . ( 2005 ) . Collaborative research across disciplinary and organizational bound - aries . Social Studies of Science , 35 ( 5 ) , 703 – 722 . Hu , S . , Torphy , K . T . , Opperman , A . , Jansen , K . , & Lo , Y . J . ( 2018 ) . What do teachers share within socialized knowledge communities : A case of Pinterest . Journal of Professional Capital and Community , 3 ( 2 ) , 97 – 122 . Institute of Education Sciences & National Science Foundation . ( 2013 ) . Common guidelines for education research and development . Washington , DC : Institute of Education Sciences and National Science Foundation . Kwon , S . , Solomon , G . E . A . , Youtie , J . , & Porter , A . L . ( 2017 ) . A measure of knowledge flow between specific fields : Implications of interdisciplinarity for impact and funding . PLoS One , 12 ( 10 ) , e0185583 . https : / / doi . org / 10 . 1371 / journal . pone . 0185583 . Morgan , P . L . , Farkas , G . , Wang , Y . , Hillemeier , M . M . , Oh , Y . , & Maczuga , S . ( 2019 ) . Executive function deficits in kindergarten predict repeated academic difficulties across elementary school . Early Childhood Research Quarterly , 46 , 20 – 32 . National Mathematics Advisory Panel . ( 2008 ) . Foundations for success : The final report of the National Mathematics Advisory Panel . Washington , DC : US Department of Education . National Research Council . ( 2002 ) . Scientific research in education . Washington , DC : National Academies Press . National Research Council . ( 2015 ) . Enhancing the effectiveness of team science . Washington , DC : National Academies Press . Slavin , R . E . ( 2002 ) . Evidence - based education policies : Transforming educational practice and research . Educational Researcher , 31 ( 7 ) , 15 – 21 . Sloane , F . C . ( 2008 ) . Randomized trials in mathematics education : Recalibrating the proposed high water - mark . Educational Researcher , 37 ( 9 ) , 624 – 630 . Sloane , F . C . , & Wilkins , J . L . M . ( 2017 ) . Aligning statistical modeling with theories of learning in mathematics education research . In J . Cai ( Ed . ) , Compendium for research in mathematics education ( pp . 183 – 207 ) . Reston , VA : National Council of Teachers of Mathematics . Posing Fundable Questions in Mathematics and Science Education S35 Solomon , G . E . A . , Youtie , J . , Carley , S . , & Porter , A . L . ( 2019 ) . What people learn about How People Learn : An analysis of citation behavior and the multidisciplinary flow of knowledge . Research Policy , 48 ( 9 ) . https : / / doi . org / 10 . 1016 / j . respol . 2019 . 103835 . Stokes , D . E . ( 1997 ) . Pasteur ' s quadrant : Basic science and technological innovation . Washington , DC : Brookings Institution Press . Sun , M . ( 2018 ) . Black teachers ’ retention and transfer patterns in North Carolina : How do patterns vary by teacher effectiveness , subject , and school conditions ? AERA Open , 4 ( 3 ) , 2332858418784914 . Whitehurst , G . J . ( 2003 ) . The Institute of Education Sciences : New wine , New Bottles . A paper presented at the annual meeting of the American Education Research Association , Chicago , IL . Wuchty , S . , Jones , B . F . , & Uzzi , B . ( 2007 ) . The increasing dominance of teams in the production of knowledge . Science , 316 , 1036 . Youtie , J . , Solomon , G . E . A . , Carley , S . , Kwon , S . , & Porter , A . L . ( 2017 ) . Crossing borders : A citation analysis of connections between Cognitive Science and Educational research … and the fields in between . Research Evaluation , 26 , 242 – 255 . https : / / doi . org / 10 . 1093 / reseval / rvx020 . K . D . King et al . S36