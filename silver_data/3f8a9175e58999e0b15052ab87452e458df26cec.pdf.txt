E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” Jimmy Moore University of Utah jimmy @ cs . utah . edu Pascal Gofﬁn Asvito Digital AG ppjgoffin @ gmail . com Jason Wiese University of Utah wiese @ cs . utah . edu Miriah Meyer University of Utah miriah @ cs . utah . edu A BSTRACT Personal informatics research helps people track personal data for the purposes of self - reﬂection and gaining self - knowledge . This ﬁeld , however , has predominantly focused on the data collection and insight - generation elements of self - tracking , with less attention paid to ﬂexible data analysis . As a result , this inattention has led to inﬂexible analytic pipelines that do not reﬂect or support the diverse ways people want to engage with their data . This paper contributes a review of personal informatics and visualization research literature to expose a gap in our knowledge for designing ﬂexible tools that assist people engaging with and analyzing personal data in personal contexts , what we call the personal informatics analysis gap . We explore this gap through a multistage longitudinal study on how asthmatics engage with personal air quality data , and we report how participants : were motivated by broad and diverse goals ; exhibited patterns in the way they explored their data ; engaged with their data in playful ways ; discovered new insights through serendipitous exploration ; and were reluctant to use analysis tools on their own . These results present new opportunities for visual analysis research and suggest the need for fundamental shifts in how and what we design when supporting personal data analysis . K eywords Personal visualization , Personal visual analytics , Personal informatics , Interview methods . 1 Introduction Personal informatics research focuses on tools and tech - nologies that help people to collect and make sense of personally relevant data for the purposes of self - reﬂection and gaining self - knowledge [ 1 ] . The ﬁeld builds on increas - ingly available and ubiquitous technology for capturing data about our everyday lived experience , and is driven by the idea that data will help us make better , smarter deci - sions about how we live our lives . Personal informatics researchers study how and why people engage with per - sonal data in a broad range of application areas , including ﬁtness [ 2 , 3 , 4 , 5 ] , indoor air quality [ 6 , 7 , 8 , 9 , 10 , 11 , 12 ] , health [ 13 , 14 , 15 ] , and time management [ 16 , 17 ] . Researchers have characterized the stages people go through when collecting and engaging with their personal This is the authors’ preprint version of this paper . License : CC - By Attribution 4 . 0 International . Please cite the follow - ing reference : Jimmy Moore , Pascal Gofﬁn , Jason Wiese , Miriah Meyer . Exploring the personal informatics analysis gap : “There’s a lot of bacon” . TVCG Special Issue on the 2021 IEEE Visualization Conference ( VIS ) , to appear , 2021 . data [ 1 , 18 ] , in part to classify and assess research efforts across them . A recent survey of over 500 personal infor - matics publications shows , however , that the ﬁeld focuses more on designing tools that support data collection and reﬂection , and less on tools to support sense - making and analysis [ 19 ] . Existing personal informatics tools that do support analysis do so in a speciﬁc way : they remove the analysis burden of data processing and task operationaliza - tion by baking - in speciﬁc analysis workﬂows . These work - ﬂows are designed by personal informatics researchers [ 20 ] , not the people who are collecting and analyzing their personal data , resulting in tools that do not always reﬂect the ways people want to engage with or think about their data [ 4 ] . As a result , a gap exists between the capabilities personal informatics tools support for helping people to engage with personal data , and the range of tasks people want to perform on the data they collect . This gap presents an opportunity for the visualization com - munity , who have already thought deeply about ways to support people engaging with data , to make an impact in this space . Research in visual analytics has focused on supporting people working with data . This work , how - ever , is tailored for domain experts working in professional contexts [ 21 , 22 ] who bring motivations , skills , and ex - periences to data analysis that cannot be assumed about people in personal contexts [ 20 ] . On the other hand , per - a r X i v : 2108 . 03761v1 [ c s . H C ] 8 A ug 2021 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 sonal visual analytics has emerged to unify several threads of visualization research that “empower everyday people through exploring data” within personal contexts [ 20 ] . De - spite consolidating several research areas focused on non - professional contexts , most approaches are not designed to support in - depth analysis of personal data . This sub - ﬁeld is instead primarily oriented toward promoting data awareness , exploration , or social sharing . We refer to the lack of attention to ﬂexible analytic tools for supporting people to engage with their personal data as the personal informatics analysis gap . We explore this gap using a new interview method [ 23 ] that we conducted as part of a multistage longitudinal study on how asthmat - ics engage with personal air quality data [ 6 ] . This work reports on what we found when probing the personal infor - matics analysis gap within the context of our longitudinal study : participants were motivated by broad and diverse goals ; exhibited patterns in the way they explored their data ; engaged with their data in playful ways ; discovered new insights through serendipitous exploration ; and were reluctant to use analysis tools on their own . These results expose new opportunities for visualization research and suggest the need for fundamental shifts in how and what we design for when supporting personal data analysis . The speciﬁc contributions of this work are twofold . First , we identify the existence of the personal informatics analy - sis gap through a review of personal informatics and visu - alization literature , and validate it through our experiences of attempting to design visual analysis tools in our longitu - dinal study . Second , we offer three design considerations for the visualization community to help bridge this gap , informed by the results of data engagement interviews we conducted with our participants . These contributions point to new opportunities for the visualization community to design for people engaging with their personal data . In the next section , we characterize the personal informat - ics analysis gap in more detail , drawing on our review of the personal informatics and visualization literature . We describe our own journey encountering and exploring the personal informatics analysis gap in the context of a lon - gitudinal study with seven asthmatic families in section 3 and outline our ﬁndings from observing how participants engaged with their data in section 4 . We propose three de - sign recommendations for exploring this space in section 5 , and conclude with ideas for future work in section 6 . 2 Identifying the personal informatics analysis gap In this section , we review literature from the personal informatics and visualization communities , with a focus on how each contributes to our understanding of supporting people engaging with their personal data . Through this literature analysis , we observe gaps in knowledge and argue that the culmination of these constitutes the personal informatics analysis gap . 2 . 1 Personal informatics tools Personal informatics is a research area in human - computer interaction that focuses on the “tools and technologies that help people to collect personally relevant data for the pur - poses of self - reﬂection and gaining self - knowledge” [ 1 ] . Interpreting and reﬂecting on personal data in any meaning - ful way requires a deep , contextual awareness of people’s lives . This knowledge is critical for drawing interesting conclusions or insightful discoveries . Those lacking the same situated knowledge of someone’s social contexts , rou - tines , and priorities are unable to correctly interpret their logged personal data , much less meaningfully analyze or make recommendations from them [ 24 , 25 ] . Personal informatics emerged from the quantiﬁed self movement with early tools designed to help users gain self - insights by tracking single facets of their lives , such as their diet [ 26 ] or physical activity [ 27 ] . Subsequent research found that reﬂecting on single data streams lim - ited the kinds of insights people could derive from their data [ 28 ] . Thus , systems for tracking multiple facets of people’s lives emerged to help sustain user engagement and improve insight generation [ 1 , 29 , 4 , 30 ] . This shift , however , imposes a greater analytic complexity that users ﬁnd unmanageable [ 31 , 32 , 33 ] . Attempts to curb this com - plexity either seek to prioritize smaller , more manageable tracking tasks as a way to narrow the design and problem spaces , or implement analytic pipelines that automatically detect and present potentially interesting correlations based on statistical analysis [ 32 , 33 ] . These solutions involve ﬁxed processing pipelines that give the user little control over the kinds of analysis or types of insights afforded to them [ 20 ] , and result in frustration with receiving obvi - ous insights [ 28 ] , or having to review too many potential correlations [ 33 ] . One step toward supporting more interactive and ex - ploratory personal data analysis involves a technique known as data cuts [ 4 ] . Cuts refer to subsets of data , chosen by underlying features , that support detailed and potentially interesting comparisons . In building a tool to support analysis of cuts , Epstein et al . developed a set of predeﬁned cuts based on a survey of the kinds of questions users had of their personal data . User evaluations of these cuts found them to be effective at supporting some of their questions , but the predeﬁned cuts failed to meet everyone’s needs or preferences for engaging their data . These ﬁnd - ings echo those in other studies that attempt to automate insights [ 33 , 28 ] , and led the authors to recommend that " designs do not attempt to limit cuts based on stated goals and instead offer a variety of cuts " [ 4 ] . What remains unclear , however , is how to design for arbitrary and ﬂex - ible analysis , especially in the context of open - ended or ill - deﬁned goals . Alongside system design , personal informatics research has also developed models to describe the ways and rea - sons people track personal data [ 1 , 18 ] . The stage - based model for personal informatics systems [ 1 ] classiﬁes how people self - track in practice , and outlines an iterative ﬁve - 2 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 Figure 1 : The lived informatics model of personal infor - matics [ 18 ] . A recent survey of over 500 personal informat - ics publications [ 19 ] found researchers focus primarily on the collection and reﬂection stages ( green ) of the tracking and acting cycle , and less on the integration stage ( orange ) , where data is combined , transformed , and analyzed . stage process for users pursuing goal - oriented behavior change : preparation , collection , integration , reﬂection , and action stages . Later , the lived informatics model [ 18 ] revised the stage - based model to reﬂect a more inclusive classiﬁcation of people’s tracking behaviors and motiva - tions ( Figure 1 ) . Speciﬁcally , it acknowledges users’ de - cisions of whether and how to track personal data , their ability to lapse and resume self - tracking practices , and to track or review personal data for non - goal - oriented mo - tivations . These models are foundational in the personal informatics community , and guide how researchers de - velop and study systems that help people improve aspects of their lives . Personal informatics research , however , is not uniformly distributed over these model stages . A recent retrospec - tive survey of over 500 personal informatics publications found considerable research that addresses barriers in the collection and reﬂection stages , but with signiﬁcantly less focus on integration [ 19 ] ( Figure 1 ) . The integration stage remaining understudied — the stage where data are com - bined , transformed , and analyzed — echoes other ﬁndings on the inherent difﬁculties with supporting these function - alities [ 33 ] . Tackling this challenge requires more attention and research efforts to raise greater awareness on these dis - parities ; this work is a step in that direction . OBSERVATION 1 : Personal informatics leverages peo - ple’s deep contextual knowledge to collect and reﬂect on personal data , but requires further study to develop ﬂexible analysis tools that empower people to engage with their personal data in unique ways . 2 . 2 Flexible visual analysis tools Visualization research has a long history of developing tools to help people productively engage with data , but largely targets those working in professional contexts . De - veloping visual analysis tools for use in professional set - tings stems from two core threads of research : the design of bespoke tools for domain experts , and the creation of powerful and ﬂexible systems for data analysts . A proliferation of bespoke tools for supporting rich visual analysis across a broad range of ﬁelds stems from the vi - sualization research community’s embrace of a call for “collaborating closely with domain experts who have ap - propriate driving tasks in data - rich ﬁelds to produce tools and techniques that solve clear real - world needs” [ 34 ] . The dominant research approach behind the design and development of these tools is visualization design study , an approach to problem - driven visualization research that emphasizes designing visual analysis tools in close col - laboration with domain experts [ 22 ] . Design study is now a standard method for conducting visualization research inquiry , informed by validation methods [ 35 ] , process mod - els [ 22 , 36 , 37 ] , rigor criteria [ 38 ] , and guiding scenarios [ 39 ] . Published research papers reporting on design studies cover a range of application areas , but they all focus on developing analysis tools for domain experts working with data . None report on collaborations outside a professional context . Research into visualization systems for data analysts arises from the signiﬁcant increase in the number of profession - als whose primary task is data analysis . Various interview studies focus on how data analysts do their work , and offer characterizations of their overall analysis process within the organizational context [ 40 ] ; their patterns of ex - ploratory data analysis [ 41 ] ; their impediments to efﬁcient data analysis [ 42 ] ; their roles within software development teams [ 43 ] ; and their unique considerations when working with cloud architectures [ 44 ] . These studies extend and modernize earlier research on intelligence analysts’ work practices [ 45 , 46 , 47 , 48 ] by seeking to understand the sense - making and information - foraging processes of data analysts [ 49 , 50 ] . The results of these studies inform a growing ecosystem of tools for data wrangling [ 51 , 52 ] , interactive visual analysis [ 53 , 54 ] , and visualization recommendations [ 55 , 56 , 57 ] . These tools for professionals require users to translate their questions into accompanying analysis tasks and make appropriate decisions based on visualizations that they see [ 58 , 59 ] . People without these skills , however , struggle to use visualization tools effectively [ 60 , 61 , 59 ] . Gen - erally speaking , people engaging with data in personal contexts tend to have less time , training , patience , moti - vation , capabilities , and crisply actionable tasks for their personal data than do professional analysts [ 20 ] . OBSERVATION 2 : Visual analytics research excels at designing ﬂexible data analysis tools for experts working in professional contexts , but does not target personal contexts , where existing tools do not easily transfer to the needs , skills , and motivations of people exploring their own data . 2 . 3 Everyday visual analysis Visualization’s growing use and consumption in every - day contexts has spurred new research into making data 3 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 accessible and understandable to everyone . Everyday vi - sualization encompasses multiple use - cases and research goals , with early work in this space exploring ways to en - gage people with new visualization techniques [ 62 , 63 ] , democratize visualization [ 64 , 65 , 66 , 67 ] , and empower people through exploring data [ 68 , 20 , 69 ] . This commu - nity has since expanded its scope to investigating physical - izations for awareness or goal - setting [ 70 , 71 , 72 , 73 , 74 ] , engagement with personal data in the home [ 75 ] , and even emotional connection to personal data when mapped to living artifacts [ 76 , 77 ] . Engaging with data in personal contexts fundamentally differs from engagement in more professional contexts encountered in standard visual analytics research . The subﬁelds of personal visualization and personal visual ana - lytics emerged to formalize the personal context , identify - ing the “different motivations , priorities , role expectations , environments , or time and resource budgets as compared to professional situations” [ 20 ] . This distinction was made to unite largely independent research communities within visualization and personal informatics that , by virtue of focusing on nonprofessional situations , extends to cover a broad range of use - cases and data scopes . Huang et al . [ 20 ] recognize that this breadth “subsumes many related ﬁelds” , yet , despite its size , recent work identiﬁes a lack of signiﬁ - cant activity in this space . In a recent article on reaching broader audiences with data visualization , Lee et al . ac - knowledge that “only a limited number of researchers have continued to work at the intersection of visualization and personal informatics” [ 78 ] . Although recent work incorporates personal agency into visual interaction mechanisms [ 79 ] , or explores proof - of - concept tools to support self - reﬂection in controlled lab studies [ 80 ] , it does not incorporate participants’ personal data as a part of the analysis process . The overwhelming majority of research occurring within personal contexts remains rooted in exploration , awareness , or social sharing . Everyday visualization has yet to deploy truly ﬂexible , scalable , or in - depth data analysis capabilities for personal data . OBSERVATION 3 : The democratized analysis goals of everyday visualization aim to empower people to explore data , but this ﬁeld has yet to design for ﬂexible , in - depth analysis of personal data 2 . 4 The personal informatics analysis gap We characterize the personal informatics analysis gap as a lack of focused research and design of systems that al - low people to ﬂexibly analyze their personal data . Any solution that overcomes this gap must acknowledge and incorporate people’s personal and contextual knowledge , support ﬂexible analysis that covers a variety of different circumstances and goals , and empower people to deeply and richly engage with their personal data . Although the ﬁelds of personal informatics , visual analytics , and every - day visualization contribute individual strengths toward bridging this gap , no one ﬁeld has yet to focus on it : • Personal informatics research excels at develop - ing systems that support users to collect and re - ﬂect on their personal data , but lacks ﬂexible anal - ysis tools for personal data . • Visual analytics research excels at developing ﬂexible and customized analysis tools , but these tools are tailored for professional contexts that are difﬁcult to transfer to personal contexts . • Everyday visualization excels at empowering peo - ple to explore data in personal contexts , but has yet to prioritize systems that support in - depth analysis of personal data . Enlisting each ﬁeld’s strength affords an opportunity for de - veloping new approaches to learn how people engage with personal data , and for designing new tools and systems that will support them in doing so . Personal informatics’ experience with collecting and acting on personal data can be augmented by visual analytics’ background in cus - tomized analysis environments , and brought together with the everyday analysis goal of personal empowerment . Uniting these ﬁelds will help researchers consolidate exist - ing design knowledge , experience , guidance , and methods to more effectively design visual analysis tools that support people engaging with their personal data . In the rest of this paper , we report on our explorations of the personal informatics analysis gap that drew upon expertise from each of these ﬁelds during a three - year longitudinal study of asthmatic families . 3 Methods Our own journey exploring the personal informatics analy - sis gap unfolds over a three - year longitudinal study work - ing with asthmatic study participants ( Figure 2 ) . This study explored how data about the air quality in the participants’ homes might support them in making changes to their daily activities to improve their respiratory health . In the ﬁrst research stage ( S1 ) , six families each received a wireless air quality sensing system consisting of three air quality monitors that participants could place in and around their home . These sensors measured and logged the concen - tration of airborne particulate matter of their immediate environments each minute , and streamed their data to an interactive interface hosted on a tablet device . A prior report provides additional details on the deployment and hosted system , along with evidence that developing ﬂex - ible systems supported study participants engaging with their data in personal ways [ 6 ] . This ﬁrst stage focused on how participants engaged with an air quality sensing system in their homes over a long - term deployment . We had planned to analyze transcripts from interviews conducted throughout the deployment in order to develop design requirements for an improved vi - sualization interface based on the kinds of analysis the 4 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 Figure 2 : Longitudinal study timeline . Research stage S1 involved six long - term ﬁeld deployments of a wireless air quality sensing system [ 6 ] to determine how participants would interact with it over time . Stage S2 applied a creative visualization - opportunities workshop [ 81 ] to collect further information on what participants wanted to do with their data . We conducted data engagement interviews [ 23 ] in stage S3 to observe how participants engaged with their data . participants did , or wanted to do , during S1 . Having tai - lored S1 for studying how participants used their air quality measurement system , however , and not collecting data on what they wanted to do with it , we lacked insight into how to design such a system . To correct for this , we conducted a creative visualization - opportunities workshop [ 81 ] ( S2 ) to characterize participants’ goals and motivations for engag - ing their personal air quality data . The workshop outcomes , however , captured a diverse range of high - and low - level goals that only expanded the possible design space , instead of informing new possibilities . Participants’ breadth of questions further prevented us from knowing what it was they would do , or would know what to do , with their data . Despite having applied a range of visualization design methods to understand what our participants needed , we were no closer to a viable design . As we reﬂected on our overall approach , we began to re - alize that these standard practices for eliciting analysis goals and design requirements had been developed in col - laboration with domain experts who work closely with data in professional contexts . Consequently , these tactics were unsuccessful when used with our participants , whose deployments prevented them from deeply engaging with their personal air quality data , or even fully knowing what information was logged and stored . Participants’ lack of experience in engaging with their data put us at a disadvan - tage when applying techniques that presumed this level of collaborator knowledge . Once we began to consider how participants’ inexperience with their own data inﬂuenced our design challenges , a gap began to emerge between what we , as visualization designers , were trained to do , versus what was effective for engaging our target users . We have come to call this the personal informatics anal - ysis gap . Realizing this gap — both through literature and our own experiences — changed our design thinking and motivated us to develop a new interview technique designed speciﬁcally to engage people with their personal data , which we call the data engagement interview [ 23 ] . We conducted data engagement interviews with each of our study participants in S3 and report on those interview outcomes in this work . 3 . 1 Data engagement interviews In order to explore the personal informatics analysis gap , we developed a novel interview method called the data engagement interview [ 23 ] . This interview method incor - porates a dedicated data analyst as part of the interview team for providing real - time visual data analysis of the participant’s personal data during the interview . The in - terview is structured to take participants through different types of data engagement , providing researchers opportu - nities to observe how people operationalize their questions , which analysis tasks they engage with , and what they ﬁnd interesting and informative in their data . We conducted seven data engagement interviews in the S3 stage of our longitudinal study . In these interviews , we integrated daily EPA Air Quality Index classiﬁcations 1 , approved access to participants’ asthma health surveys collected through the parent medical study [ 82 ] , and addi - tional environmental data streams including ambient tem - perature and humidity as external contextualizing data . Joining these data streams provided a rich set of analysis opportunities for our participants to be able to contextual - ize their indoor air quality data streams . All participant interviews proceeded from semi - structured scripts to ensure meeting primary goals while affording us the ﬂexibility to more deeply explore participants’ mo - 1 https : / / www . airnow . gov / aqi / 5 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 tivations and thought processes , as necessary . The data engagement interview protocol was cleared by our univer - sity’s institutional review board and is available in supple - mental materials . All interview participants received a $ 20 Amazon gift card . 3 . 2 Participants We retained all seven study participants from S1 [ 6 ] for the data engagement interviews due to their prior experience and engagement with reviewing personal indoor air quality data . These participants were themselves asthmatic ( P1 , P2 , P4a , P5 , P6 ) or primary caregivers to asthmatic chil - dren ( P2 , P3 , P4 ) , and they were chosen from a concurrent university - run medical study involving asthmatic families [ 82 ] . We included participant P4’s teenage daughter , P4a , as an additional study participant given her signiﬁcant en - gagement throughout this study . Other participant family members also contributed feedback and suggestions dur - ing the data engagement interviews but were otherwise not involved . Participants were alike in that asthma had impacted their lives , but the extent and degree to which they were af - fected was entirely unique . The individualized aspect of participants’ asthma sensitives and severity inﬂuenced how they engaged with their data , and what they sought from it . Participant P1 , an asthmatic sensitive to pollen and other outdoor irritants , used her air quality system as a personal planning tool to stay inside when outdoor particu - late concentrations were high . Participants P3 and P4 are primary caregivers to asthmatic children and wanted to use their data to provide a healthy home environment for their family . Participants P5 and P6 are adult asthmatics who already understood their symptoms and were interested to explore how environmental factors affected their sensitivi - ties . Participant P4a , our youngest study member , was less concerned with the health impacts of air quality and more curious to see how air quality affected those around her at a community level . Participant P2 is medically disabled as a result of her severe asthma and was interested in how the data could improve her quality of life . Due to her health complications , however , she remained hesitant to interpret or act on any personal data . Instead , she preferred to re - ceive personalized advice from medical professionals on ways she could improve her living space . 3 . 3 Data analysis The 7 data engagement interviews generated 8 . 9 hours of interview audio . The interview audio was transcribed and analyzed through several rounds of afﬁnity mapping and group discussion between the authors in S3 . After reporting on a number of ﬁndings in a companion paper [ 23 ] , we pitched additional results in a pre - paper talk to our research group to collect feedback on our ideas . These additional results focused on implications for designing within the personal informatics analysis gap . Afterwards , the authors performed an additional round of discussion to settle on the ﬁnal set of results and implications presented in this work . 4 Results In this section , we present results from our analysis of the data engagement interviews . These results illustrate the varied ways that participants approached , analyzed , and engaged with their personal data . 4 . 1 Diverse goals and questions All our participating families received the same deploy - ment , collected the same types of measurements , and had the same interest in improving their families’ respiratory health . Yet , despite these similarities , the speciﬁc ques - tions our participants brought to their data engagement interviews , and the types of insights they acquired , were surprisingly diverse . Participants’ data analysis goals covered a myriad of top - ics : P2 : What’s going to be the best vacuum cleaner to help keep dust down ? P4a : I’d like to compare my data with other people’s data to see how people were affected by outdoor air quality , near me or in the valley . P5 : Can I anticipate days I shouldn’t go outside ? P6 : Should I move ? The analysis approaches the participants took were equally diverse . For example , P1’s interest in reviewing her air quality data stemmed from wanting to understand whether periods of poor outdoor air quality impacted her indoor air quality . These discussions unfolded as she and her hus - band jointly explored data together , but became a broader conversation on indoor and outdoor air quality dynamics after witnessing how their personal activities impacted their living spaces . In contrast , P3 and P4 each chose to step through their air quality data spike - by - spike to see what annotations were associated with the most promi - nent outliers . These explorations evolved into discussions about the proportions of spikes associated with particular activities or locations . Reframing their air quality events by faceting on its underlying properties changed the way both participants came to see their indoor air quality . Fi - nally , in a third example , P4a was less curious about her air quality measurements and preferred to compare her weekly health survey responses against those of other par - ticipants . This comparison served as a mechanism to de - termine whether her respiratory issues were more likely triggered by widespread environmental conditions – which she presumed would equally affect other participants – as opposed to personal behaviors , and affect only her . Even though we collected questions and goals from only seven participants , their diverse personal interests cover 6 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 a wide range of analysis needs . The questions require integrating data over different locations ( Q : How does outdoor air quality compare across the valley ? ) ; timescales ( Q : What tends to be the worst time for my indoor air quality ? ) ; participants ( Q : How does my indoor air quality compare to other participants ? ) ; and data sources ( Q : Can I correlate my air quality data to my health surveys ? ) . This diversity in analysis needs poses a signiﬁcant challenge for designing a tool that is capable of supporting them all . 4 . 2 Pattern of exploration Despite the varied data streams and integrations that our participants’ diverse questions demanded , we did see a generalized pattern in how they explored their data . This pattern was consistent regardless of their underlying mo - tivations or enthusiasm , and often ﬁrst appeared after we brought up an overview of their data early in the interview : Interviewer : What would you like to start with ? What’s the ﬁrst thing you want to see ? P2 : I’d like to just . . . okay , let’s glance at this great , big , huge , orange [ spike ] . Did we mark what that was ? If so , what was it ? Large and visibly prominent spikes were a common dis - traction when reviewing participant data , and one of the most frequently requested features to explore : P3 : I think I would start with the bad peaks . I mean like this [ spike ] right here , this [ high magnitude spike ] . Some of these higher ones . Other outliers in the data also piqued participants’ inter - est , such as those in their self - tracked health surveys or memories of notable air quality events : P6 : I’m really looking for any outliers in the [ survey ] results . . . Let’s look at that big outlier on , I guess , in January . P1 : It might be easy to jump to a day like that , where we know 4 th of July is going to have ﬁreworks . Seeing these outliers in their data motivated participants to pause or modify their initial interview goals in favor of investigating the underlying events that caused them . They speculated about what might have led to the data feature : P3 : That [ spike ] was a huge ﬁre in Spanish Fork . You could smell it everywhere , it was terrible . P5 : That’s pretty interesting . [ These spikes ] make me wonder if it was all through the house , the fact that they’re pretty similar . Participants then asked to contextualize the data features with additional data streams to help validate their specu - lations or better understand what they were seeing . For example , both P2 and P3 wanted to use their text annota - tions to understand which behaviors were inﬂuencing the indoor air quality spikes they noticed : P2 : I’d be curious to see what our annotations are on the highest spikes . . . think you can do that ? P3 : Being able to match my annotations with the larger spikes would be helpful to ﬁnd patterns . For P5 , however , reviewing his data uncovered unexpected late - night spikes that emerged during the last week of his deployment , and he requested a different type of contextu - alizing data stream : P5 : Can you overlay the temperatures ? Outside , like the outside temp ? P5’s interest in incorporating his outside temperature mea - surements was a proxy for determining whether these peri - odic spikes may have been due to his furnace kicking on and off during cold temperatures . As we analyzed participants’ interviews , we began to recog - nize a recurring pattern regarding the sorts of data elements that caught their attention , and their method of investigat - ing these elements . The participants would : 1 ) discover a prominent feature in their data , either through visual inspection or reﬂecting on their experiential knowledge ; 2 ) determine if the feature warranted further inspection , and if so , attempt to correlate it with features in other data streams ; and 3 ) speculate about underlying factors and potential behavior changes . In her data engagement interview , participant P3 distin - guished between health - or air quality - motivated work - ﬂows , yet ultimately described the same exploration pat - tern : P3 : I mean this is an air quality thing , right ? So if it were me , I would start with the air quality . When am I having a spike ? I would then look at the spikes , and then from that I would try to correlate : On those days , what happened to cause a spike ? Was anybody ill ? Did we have an asthma attack ? And try and do that . I think that’s the direction I would go , because I’m thinking of it as an air quality thing . If it were sick thing [ where ] I’m trying to make [ my son ] healthier , I think I would start with his asthma data , and then go the other direction . So I think it just depends on which approach I would take . This exploration pattern naturally emerged in all of our participant interviews , regardless of their prior preparation or motivation , and independent of whichever particular feature they chose to enter their personal data . Air quality measurement spikes , key dates , personal associations or memories , text annotations , and survey response outliers were the most frequent subjects that drew the participants’ attention in their interviews . 4 . 3 Playful engagements Our longitudinal study enrolled parents struggling to con - trol the symptoms of severe asthma in their children and themselves . They participated because of their hopes that 7 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 data about the air quality in their homes could improve the health of the asthmatics in their households — a seri - ous undertaking with clear implications for the health and well - being of their families . Nonetheless , their engage - ments with the deployed system , and with their data , led to numerous moments of play . For example , some of the participants’ self - tracked annota - tions captured how repetitive data entry gave way to playful antagonism toward their deployments and data entry . In our interview with P4a , she admitted to her increasingly deprecating annotations about her mom : P4a : Towards the end I think I got a little more joke - y with it – “oh you know , mamma’s been cooking again . ” Before it was “mom burnt the chicken . ” Now it’s “noth - ing new is happening now ! ” Similarly , P1 explained why some of her annotations per - soniﬁed the deployed system’s alert mechanism : P1 : We did start putting snarky remarks in some of the comments [ laughs ] . You probably noticed ! There was a while where my oven had burnt pizza on the bottom , and every time we turned the oven on [ the alert ] was like " HEY ! ! HEY ! ! HEY ! ! ! " And I was just like “yep , still haven’t cleaned my oven ! You want to come clean my oven ? ’Cause I still haven’t cleaned my oven . ” [ laughs ] Cooking annotations were prominent in each participants’ dataset and occupied the majority of discussion around household behaviors , with a special focus on bacon : P2 : That’s me , burning the bacon . P5 : Oh , and you have where I put in that we were cook - ing bacon : “Me cooking bacon . “ P3 : We did the same thing over and over again . Bacon . [ laughs ] I think that 90 % of our annotations are probably bacon . I like bacon ! [ laughs ] P3 was especially amused to see how often bacon was present in her data , bringing it up multiple times throughout her data engagement interview . These amusements turned into deeper engagements with her data : P3 : I’m looking at [ my data ] and there’s a lot of bacon . . . If I notice that every single spike is because we’re cooking bacon , then I might think , is that a problem ? What is it that cooking bacon puts in the air ? Is that a bad thing , or , the smell’s a good thing , right ? It’s a good thing . Unlike most of the participants , P2 was much more difﬁ - cult to engage in the data review process due her lack of conﬁdence in her analytic abilities , and a stated preference for having medical professionals interpret her information . As the most severe asthmatic in our study , P2 was also overly cautious to make any behavioral changes due to the perceived consequences of incorrectly interpreting her data . These facts made it all the more surprising when P2 also got drawn into her data through exploring her spikes and cooking annotations . Like others , she , too , began cracking wry jokes about burning food and cooking bacon : P2 : That’s me , burning the bacon . . . I’m real good in the kitchen , I can tell you that ! Every one of our data engagement interviews captured moments of play . Participants’ interpretations of what they were seeing in their data , ﬁltered through their self - deprecating , sarcastic humor , revealed insights into the challenges of balancing health with other priorities : Interviewer : what’s interesting for you here ? Husband : . . . my painting P1 : You were spraying [ ﬁgurines ] on the 23rd . . . Being a geek is hazardous to your health ! Husband : Sorry , had a D & D coming up . These exchanges illustrate the overall playfulness we wit - nessed when engaging people with their data . This sense of play that emerged when exploring personal data highlights a broader dynamic within each participant’s deployment . Our existing rapport , plus the potential for seeing their data in new ways , made participants excited to dive into their data and learn new things . This excitement manifested itself differently for each participant , but a playful sense of curiosity helped pull people into their data and unpack what they had to show . 4 . 4 Serendipitous discoveries Participants’ concurrent enrollment in a national asthma study [ 82 ] and our own visualization design experience primed us to assume that they would be goal - oriented when it came to engaging their data at each stage of the longitudinal study . Much of what we observed in the data engagement interviews , however , was productive free - form exploration , often facilitated by playful engagements . For example , P3 used her annotations as a way to self - experiment with her cooking habits to uncover which kind of cooking oil produced the fewest spikes during her de - ployment [ 6 ] . During her data engagement interview , how - ever , her playful interest in bacon gave way to a broader exploration of her cooking habits . This exploration led P3 to a different view of activities that affected her indoor air quality : P3 : I remember making the connection between the olive oil and the [ spikes ] . And I also knew that it was kind of every time we cooked bacon there was a [ spike ] . But I guess I didn’t realize how many of them , overall , were actually cooking episodes . . . Like “cooking pancakes” , “cooking eggs” , “ [ my daughter ] burning the tortillas” . It’s all cooking . Most other participants also experienced similar realiza - tions after idly exploring their data . P4 came unprepared for her interview without considering what she wanted to 8 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 explore ahead of time . Yet , when reviewing her data during the interview , unexpected spikes caught her attention : P4 : It seems like most of [ the spikes ] are actually in [ P4a’s ] bedroom , which surprised me . In contrast , P5 came to the interview with the goal of ﬁnding connections between his indoor air quality and respiratory health . However , unexpected spikes distracted him : P5 : Oh , and I have no idea what would be in the room making it that high . Why would there be a spike in the bedroom , and not downstairs ? Following this discovery , he proceeded to spend over half of the interview attempting to ﬁnd possible sources of his mysterious , nightly indoor air quality spikes . P2 , who was the least willing to engage with her data , was also drawn in by reviewing spikes and their annotations . She saw that many of her air quality spikes were from cooking , and she became unexpectedly invested in understanding the extent of cooking spikes in her data : P2 : I bet that [ spike ] is cooking , too . If it’s not I’m going to be surprised . The data engagement interviews gave participants the time and space to stumble upon unexpected and surprising ob - servations , often leading to new insights . Despite our attempts to conduct goal - oriented analysis — by explicitly priming participants ahead of each interview to discuss their analysis goals — the most productive outcomes came from serendipitous discoveries . 4 . 5 Reluctance to personally analyze Participants’ levels of engagement during their interviews — and throughout the longitudinal study — were as var - ied as their questions . Some participants enthusiastically engaged with their data , some were reluctant but still tena - cious , and others were difﬁcult to motivate at all . Regard - less of their level of engagement , however , every partic - ipant stopped short of advocating for a tool that would allow them to analyze their data in similar ways as the data engagement interview . We asked each participant how likely they would be to use an idealized tool that offered the same ﬂexible features . Other than the teenage partici - pant ( P4a ) who felt she “might use it , ” all other participants were pessimistic : P1 : As a busy mom with small children , I just don’t have the time . P6 : I could do it , I just don’t know how often I would . P2 : I don’t know that I would ever just pull it up and look at it for data’s sake . . . I can take it back to my doctor . Participants’ reluctance to engage with personal data is consistent with ﬁndings in other informatics disciplines . P2’s preference for having her personal health data inter - preted by medical professionals echos similar ﬁndings in other chronic health management research [ 83 ] , and recent work shows even Division 1 collegiate athletes , with ac - cess to vast stores of personal data and dedicated analysts , also resist engaging with their data for various reasons [ 84 ] . Both these contexts bear a resemblance to our own participants’ circumstances as asthmatics living in a region that experiences some of the worst air quality days in the world [ 85 ] , lending evidence to broader , more complex challenges . 5 Discussion We have outlined the personal informatics analysis gap through a careful review of personal informatics and visual analytics literature . This review shows how personal informatics research leverages people’s deep contextual knowledge to collect and reﬂect on personal data , but re - quires further study to develop versatile analysis tools that empower them to engage with their personal data in unique ways ; how visual analytics excels at designing ﬂexible data analysis tools for trained domain experts working in professional contexts , complicating their transferability to personal contexts and less experienced users ; and how the democratized analysis goals of everyday visualization seek to empower people in exploring data , but whose ﬁeld has yet to design for ﬂexible , in - depth analysis of personal data . The complementary strengths of these three ﬁelds points the way toward opportunities for designing new tools and developing new methods that bridge the personal informatics analysis gap . Reﬂecting on our experiences exploring the personal in - formatics analysis gap reveals a number of visualization design opportunities : entry points as an immediate design recommendation for facilitating engagement with personal data ; a play - based approach to challenge the traditional goal - oriented nature of visualization design in personal contexts ; and a reconsideration of whether designing new tools is even the most productive way to support people in analyzing their personal data . We offer these ideas as a starting point for thinking differently about how we design for personal contexts , and to highlight the opportunities for the visualization community to make an impact in this space . 5 . 1 Design for entry points In subsection 4 . 2 , we discuss the common exploration pat - terns that we observed throughout the data engagement interviews . Participants often ﬁxated on the same kinds of visually prominent features within their plotted data — like spikes or outliers — as well as performing the same explo - ration tactics when engaging with their data , in ways that bear a resemblance to established sense - making process models of intelligence analysts [ 45 ] . Because participants shared these similarities regardless of their prior prepara - tion or general interest in reviewing their data , designing 9 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 for these tendencies could provide valuable insights into ways designers could make interfaces more engaging , es - pecially in personal contexts . These engagement and exploration patterns are examples of what the design community calls entry points [ 86 ] , which are “a point of physical or intentional entry into a design” [ 87 ] . Rogers et al . identify the utility of entry points for interactive interfaces , recommending that de - signers incorporate them into their designs as a way to “think about the coordination and sequencing of actions and the kinds of feedback to provide in relation to how objects are positioned and structured at an interface” [ 88 ] . As an invitation to action , entry points bear a resemblance to affordances [ 89 , 90 ] . In the same way that affordances indicate potential interaction mechanisms to users , entry points provide hints for what can be done with engaging data [ 91 ] . As a concept , entry points describe an intuitive way for inviting users into a system or interface . Google Maps , for example , uses a device’s location to generate an initial view as a way to experience its interface . Recent visualization tools explicitly implement entry points for investigating how people explore interactive visualizations [ 92 ] , as well to facilitate rich conversations and exploration , encourage engagement with data , and make visualizations or datasets feel relevant to a wider audience [ 93 ] . These approaches serve to help orient and engage people with unfamiliar tools or data sets [ 94 ] , but the visualization community has largely overlooked entry points as a formalized construct to engage people with their personal data . Existing theoretical work on entry points in the design com - munity details how to design entry points into a system . The design literature recommends establishing “points of prospect” to give an overview of the different ways people can engage with their data , and “progressive lures” to in - crementally bring them into their data [ 87 ] . This approach can lower barriers to entry and invite progressively deeper inspection . Data engagement interviews [ 23 ] can also ben - eﬁt from considering entry points as a design element by helping to prioritize which analytic capabilities researchers should support . Human - computer interaction research into entry points can also help with determining the kinds of entry points different types of personal data may support . Tailoring interactions that reﬂect how people think of a particular data source may help lure them in to freely explore , and improve their overall chances for ﬁnding interesting parts of their data . For example , Choe et al . support basic tempo - ral cuts for reviewing logged physical activity data within their Visualized Self web application [ 95 ] , which users in their study found helpful and compelling . Time Lattice [ 96 ] generalizes this concept to support interactive analysis and comparisons for large - scale and distributed sensor data over a broader set of user - selectable constraints . Entry points like these can allow for more meaningful ex - ploration of self - tracked data in the context of supporting comparisons for how personal data vary across speciﬁc constraints or conditions , whether these are temporal ( Q : What time of year is typically worst for air quality ? ) , geo - graphic ( Q : What part of the state has the best air quality ? ) , relative ( Q : What’s the air quality like when other people are sick ) , absolute ( Q : How many days were above the red air quality cutoff ? ) , or a mixture of these , and more . Systems supporting these approaches stand to better reﬂect how people think of their data and their lives , especially when compared to the static , linear time series plots typi - cally provided for reviewing personal data . The ability to seek or see one’s self in data plays a signiﬁ - cant role how people engage with and experience visualiza - tions [ 97 ] . More generally , any guidelines for developing engaging visualization systems will require a better un - derstanding of what compels someone to start exploring visualizations of their data . As a concept , entry points of - fer a promising approach to help address the shortcomings behind the personal informatics analysis gap . Understand - ing what users ﬁnd interesting or engaging in their data can help designers lower barriers and improve usability by identifying compelling entry points into those datasets or visualizations . Furthermore , researching entry points in personal contexts can help formalize ways people engage with personal data , along with common priorities , interests , or data characteristics they ﬁnd especially relevant across different use - cases . 5 . 2 Design for play We approached the data engagement interviews with a goal - oriented mindset , expecting our participants to come prepared with their own goals and approaches for analyz - ing their data . We asked participants to think about what they wanted to know about their data ahead of their inter - views , and we structured the start of the interview to probe into their speciﬁc questions . Despite our attempts to prime our participants , some were disinterested in deﬁning a goal and digging into their data as we detail in subsection 4 . 5 . This lack of enthusiasm may have posed problems for more traditional , retrospective think - aloud interview methods , but the opportunity to directly engage with their personal data in the data engagement interview led each partici - pant — even those who were prepared with analytic goals — to quickly distract themselves in playful ways as we guided them to examine their data . As we discussed in sub - section 4 . 4 , participants preferred to freely explore their data , but not in the ways the visualization literature de - scribes data exploration . Although Brehmer & Munzner’s task typology [ 98 ] deﬁnes exploration as “searching for characteristics” , the explorations of our participants had less to do with clear searching objectives , and more to do with stumbling into serendipitous discoveries . We had attempted to promote a goal - oriented experience , but this playful and open - ended exploration was what kept peo - ple engaged with their data and what motivated them to proceed through their interviews . 10 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 This type of playful engagement is traditionally overlooked in visualization research in favor of more goal - oriented behavior . The visualization community’s focus on goals perhaps comes as a consequence of a decades - long framing of visualization as a vehicle for cognitive ampliﬁcation and insight generation [ 99 ] . Fun and enjoyment are secondary considerations , if they are considered at all . Prior work on ways to design for fun further codify this prioritization with recommendations to consider fun and enjoyment only after “the functionality and usability have been accommodated in the design“ [ 100 ] . Our ﬁndings provide evidence that people engage with their data in productive ways through play , and lends support for prioritizing play as a ﬁrst - class design requirement . Play , and the dynamics that give rise to or inﬂuence play , have been studied at length in human - computer interaction and design ﬁelds . Prior work shows people are likely to engage in activities seen as fun or playful , such as interac - tive ﬁlters on social media [ 101 ] , or experiences that elicit curiosity from their ambiguous or unspeciﬁed outcomes [ 102 , 103 ] . Designs that prioritize play and entertainment lead to more engaging experiences [ 104 ] , as do interfaces that are designed through processes that include situated play design [ 105 ] , ludic design [ 106 ] , and playiﬁcation [ 107 ] . Bertran et al . describe how situated play design can inform early aspects of a design process by identifying design targets and inspiration based on their capacity for playful experiences [ 105 ] . This design approach also rec - ommends engaging users within these contexts to explore how their play is integrated with their activities , and to use these dynamics as design targets that can be further reﬁned with iterative prototyping [ 108 ] . Elements of ludic design similarly recommend promoting curiosity and minimizing externally deﬁned goals as a way to embrace ambiguity and break away from the requirements of meeting partici - pants’ every need [ 106 ] . Playiﬁcation [ 107 , 109 ] advocates designing for playful and intrinsically compelling expe - riences over more extrinsically gamiﬁed elements , like scores , that apply game mechanics to nonplayful activities [ 110 ] . Our observations that participants were naturally given to playful engagements and open - ended exploration when engaging their data , and reluctant to engage with an ex - trinsically goal - oriented analysis tool , resonates with the motivations for play - based design processes . We speculate that characterizing people’s naturally playful behaviors can help inform design elements for developing more engaging experiences in personal contexts . This focus , however , requires that the visualization community re - evaluate its goal - oriented design bias and explore what playfulness means within personal contexts . What is fun in the context of exploring personal data , and what does it mean to make something fun enough to engage users ? This framing highlights alternative motivations that prioritize fun and enjoyment as ﬁrst - class design criteria . 5 . 3 Reconsider designing tools In our previous work , we provided evidence that data en - gagement interviews were productive and allowed our par - ticipants to learn new things from their data [ 23 ] . In sub - section 4 . 3 and subsection 4 . 4 of this paper , we further validate this interview method with additional evidence on how people were able to playfully engage with their data and explore in open - ended ways to arrive at serendip - itous discoveries , regardless of their level of preparation or interest . We also described in subsection 4 . 1 that the interviews exposed a set of diverse goals and questions that our participants had , complicating the design space for potential visual analysis tools . Furthermore , in subsec - tion 4 . 5 , we detail how the majority opinion among our participants was that they were unlikely to analyze per - sonal data on their own , from a lack of time ( P1 ) , interest ( P6 ) , relevance ( P3 , P4 , P5 ) , or conﬁdence ( P2 ) . Finally , although we succeeded at engaging participants with their data , we were unsuccessful at focusing participants’ data engagements toward goal - oriented data analysis . Instead , efforts to encourage goal - oriented review fell apart , with participants engaging in open - ended exploration once they got into their data . This ﬁnding suggests that any tool de - signed for our participants would need to be very ﬂexible , but not overly complicated ; and even if we developed such a tool , it remains unclear whether our participants would be motivated to use it . Designing tools to support people engaging with per - sonal data is a difﬁcult and time - intensive process , and requires deep , contextual knowledge for reaching reliable or meaningful interpretations [ 24 ] . These requirements raise doubts about how a designer can expect to know what is important within people’s data or the ways it can relate to their diverse goals . These concerns are further compounded when any applied analysis may inadvertently obscure or remove information that users may ﬁnd relevant or important [ 111 ] . Furthermore , if designing for personal data is difﬁcult from its reliance on personal knowledge , and the people who have this personal knowledge are the same ones who – for various reasons – cannot or will not afford the time to engage with their data , where does this leave us ? If asthmatics living in an area that experiences some of the worst air pollution in the world [ 85 ] cannot be motivated to engage with their personal air quality data , what hope do we have of mobilizing anyone in open - ended personal visual analytics ? We question whether it makes sense to expend our time and resources to develop potentially complex and design - intensive tools for small user groups that often struggle to translate these tools to other contexts . Taken to extremes , a truly generalized analysis tool capable of approaching these requirements runs the risk of reinventing Tableau or Excel — an overwhelming design proposition in its own right . Given the diverse breadth of participants’ questions throughout our longitudinal study , we pose the argument that any standalone visual solution may be impractical or impossible to provide . 11 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 In spite of these challenges , our data engagement inter - views were especially productive at engaging people in ex - ploring their data . This observation leads us to ask : What if the solution is not another tool , but something wholly different ? What if the antidote to increasingly sophisti - cated and customized visual analysis tools is an investment in communal systems or infrastructures that allows peo - ple to cooperatively share their data with dedicated data experts ? These social systems could help offset the in - tellectual burdens of traditional visual analytics systems and enable those experienced with sophisticated tools to collaborate alongside people with personal data to leverage the strengths of each community : computation and context . This idea is not new , and previous work has outlined some logistics and challenges of this approach [ 112 ] , yet more work is needed to understand ways to attract and sustain professional attention ; motivate people to volunteer their time and expertise ; and manage resources , systems , and structures that could make this a reality . We cannot design new ways to support people engaging with their data using the same thinking that created the personal informatics analysis gap in the ﬁrst place . Instead , this gap offers an opportunity for the visualization com - munity to develop new methods for exploring the gap and new designed futures to bridge it . 6 Conclusion This work draws attention to the personal informatics anal - ysis gap through a review of personal informatics and visual analytics literature and our own experiences work - ing with asthmatics over a multiyear indoor air quality sensing project . The gap describes a lack of attention to ﬂexible analytic systems for supporting people engaging with their personal data , and could beneﬁt pulling from the research strengths of personal informatics , visual analytics , and everyday visualization ﬁelds : the strength of personal informatics research for developing systems that support users to collect and reﬂect on personal data ; the strength of visual analytics research for developing ﬂexible and customized analysis tools ; and the strength of everyday visualization research for empowering people to explore data in personal contexts . Designing within the personal informatics analysis gap re - quires new thinking and approaches compared to existing methods . We believe this work points to a previously un - tapped research space with a wide rage of design opportuni - ties for the visualization community , and one that stands to be approached from multiple perspectives . Broadening de - sign thinking beyond rigid , goal - oriented tools to consider alternative priorities like designing for exploration , play , and more collaborative systems can leverage the strengths and skills of analytic professionals to help people get the most from their data . Acknowledging the personal infor - matics analysis gap exists — and taking steps to explore it — is an important ﬁrst step in addressing the present limitations for gaining deeper insights into what people want to do with their data . We offer this work as call to the community to explore the personal informatics analysis gap through careful , qualitative work that unpacks personal data engagement and explores design opportunities that challenge normative visualization design . Acknowledgements Many thanks to : our study participants for sticking with us all these years ; Greg Furlich for his indispensable real - time data analysis ; the Visualization Design Lab members for constructive criticism on multiple drafts and research pitches ; and our reviewers for their thoughtful and detailed feedback . This work was supported by the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health under Award Number U54EB021973 . The content is the sole responsibility of the authors and does not necessarily represent the ofﬁcial views of the National Institutes of Health . References [ 1 ] Ian Li , Anind Dey , and Jodi Forlizzi . A stage - based model of personal informatics systems . In Proceed - ings of the SIGCHI conference on human factors in computing systems , pages 557 – 566 , 2010 . [ 2 ] Sunny Consolvo , Katherine Everitt , Ian Smith , and James A Landay . Design requirements for technolo - gies that encourage physical activity . In Proceed - ings of the SIGCHI conference on Human Factors in computing systems , pages 457 – 466 , 2006 . [ 3 ] Sunny Consolvo , David W McDonald , Tammy Toscos , Mike Y Chen , Jon Froehlich , Beverly Har - rison , Predrag Klasnja , Anthony LaMarca , Louis LeGrand , Ryan Libby , et al . Activity sensing in the wild : a ﬁeld trial of ubiﬁt garden . In Proceed - ings of the SIGCHI conference on human factors in computing systems , pages 1797 – 1806 , 2008 . [ 4 ] Daniel Epstein , Felicia Cordeiro , Elizabeth Bales , James Fogarty , and Sean Munson . Taming data com - plexity in lifelogs : exploring visual cuts of personal informatics data . In DIS ’14 , pages 667 – 676 . ACM . [ 5 ] Matthew Mauriello , Michael Gubbels , and Jon E Froehlich . Social fabric ﬁtness : the design and evaluation of wearable e - textile displays to support group running . In Proceedings of the SIGCHI Con - ference on Human Factors in Computing Systems , pages 2833 – 2842 , 2014 . [ 6 ] Jimmy Moore , Pascal Gofﬁn , Miriah Meyer , Philip Lundrigan , Neal Patwari , Katherine Sward , and Jason Wiese . Managing in - home environments through sensing , annotating , and visualizing air quality data . Proceedings of the ACM on Interac - tive , Mobile , Wearable and Ubiquitous Technologies ( IMWUT ) ( Ubicomp ’18 ) , 2 ( 3 ) , Sept 2018 . 12 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 [ 7 ] Sunyoung Kim and Eric Paulos . inair : measuring and visualizing indoor air quality . In UBICOMP ’09 , pages 81 – 84 . [ 8 ] Sunyoung Kim and Eric Paulos . Inair : sharing in - door air quality measurements and visualizations . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 1861 – 1870 , 2010 . [ 9 ] Sunyoung Kim , Eric Paulos , and Jennifer Mankoff . inair : a longitudinal study of indoor air quality mea - surements and visualizations . In Proceedings of the SIGCHI Conference on Human Factors in Comput - ing Systems , pages 2745 – 2754 , 2013 . [ 10 ] Biyi Fang , Qiumin Xu , Taiwoo Park , and Mi Zhang . Airsense : an intelligent home - based sensing system for indoor air quality analytics . In UBICOMP ’16 , pages 109 – 119 . [ 11 ] Sidhant Gupta , M . S . Reynolds , and S . N . Patel . Elec - triSense : single - point sensing using EMI for elec - trical event detection and classiﬁcation in the home . Proceedings of the 12th ACM international con - ference on Ubiquitous computing , pages 139 – 148 , 2010 . [ 12 ] Tim Campbell , Eric Larson , Gabe Cohn , Jon Froehlich , Ramses Alcaide , and Shwetak N . Patel . Wattr : A method for self - powered wireless sensing of water activity in the home . In UBICOMP ’10 , pages 169 – 172 , New York , NY , USA , 2010 . ACM . [ 13 ] Christopher C Tsai , Gunny Lee , Fred Raab , Gre - gory J Norman , Timothy Sohn , William G Griswold , and Kevin Patrick . Usability and feasibility of pmeb : a mobile phone application for monitoring real time caloric balance . Mobile networks and applications , 12 ( 2 - 3 ) : 173 – 184 , 2007 . [ 14 ] Chia - Fang Chung , Qiaosi Wang , Jessica Schroeder , Allison Cole , Jasmine Zia , James Fogarty , and Sean A Munson . Identifying and planning for indi - vidualized change : Patient - provider collaboration using lightweight food diaries in healthy eating and irritable bowel syndrome . Proceedings of the ACM on interactive , mobile , wearable and ubiquitous technologies , 3 ( 1 ) : 7 , 2019 . [ 15 ] Chia - Fang Chung , Elena Agapie , Jessica Schroeder , Sonali Mishra , James Fogarty , and Sean A Munson . When personal tracking becomes social : Examining the use of instagram for healthy eating . In Proceed - ings of the 2017 CHI Conference on human factors in computing systems , pages 1674 – 1687 , 2017 . [ 16 ] S Tejaswi Peesapati , Victoria Schwanda , Johnathon Schultz , Matt Lepage , So - yae Jeong , and Dan Cosley . Pensieve : supporting everyday reminis - cence . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 2027 – 2036 , 2010 . [ 17 ] Janne Lindqvist , Justin Cranshaw , Jason Wiese , Ja - son Hong , and John Zimmerman . I’m the mayor of my house : examining why people use foursquare - a social - driven location sharing application . In Pro - ceedings of the SIGCHI conference on human fac - tors in computing systems , pages 2409 – 2418 , 2011 . [ 18 ] Daniel A Epstein , An Ping , James Fogarty , and Sean A Munson . A lived informatics model of personal informatics . In UBICOMP ’15 , pages 731 – 742 . ACM . [ 19 ] Daniel A . Epstein , Clara Caldeira , Mayara Costa Figueiredo , Xi Lu , Lucas M . Silva , Lucretia Williams , Jong Ho Lee , Qingyang Li , Simran Ahuja , Qiuer Chen , Payam Dowlatyari , Craig Hilby , Sazeda Sultana , Elizabeth V . Eikey , and Yunan Chen . Mapping and taking stock of the personal informatics literature . IMWUT ’20 , 4 ( 4 ) , 2020 . [ 20 ] Dandan Huang , Melanie Tory , Bon Adriel Aseniero , Lyn Bartram , Scott Bateman , Sheelagh Carpendale , Anthony Tang , and Robert Woodbury . Personal Vi - sualization and Personal Visual Analytics . IEEE Transactions on Visualization and Computer Graph - ics , 21 ( 3 ) : 420 – 433 , mar 2015 . [ 21 ] Yuet Ling Wong , Krishna Madhavan , and Niklas Elmqvist . Towards characterizing domain experts as a user group . IEEE BELIV’18 , pages 1 – 10 . [ 22 ] Michael Sedlmair , Miriah Meyer , and Tamara Mun - zner . Design study methodology : Reﬂections from the trenches and the stacks . IEEE TVCG ’12 , 18 ( 12 ) : 2431 – 2440 . [ 23 ] Jimmy Moore , Pascal Gofﬁn , Jason Wiese , and Miriah Meyer . An interview method for engage - ment with personal sensor data . arXiv : 2107 . 11441 [ cs . HC ] , Jul . 2021 . [ 24 ] Peter Tolmie , Andy Crabtree , Tom Rodden , James Colley , and Ewa Luger . “this has to be the cats” : Per - sonal data legibility in networked sensing systems . In CSCW ’16 , pages 491 – 502 . ACM . [ 25 ] Joel E Fischer , Andy Crabtree , Tom Rodden , James A Colley , Enrico Costanza , Michael O Jewell , and Sarvapali D Ramchurn . Just whack it on until it gets hot : Working with iot data in the home . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , pages 5933 – 5944 . ACM , 2016 . [ 26 ] Katie A Siek , Kay H Connelly , Yvonne Rogers , Paul Rohwer , Desiree Lambert , and Janet L Welch . When do we eat ? an evaluation of food items in - put into an electronic food monitoring application . IEEE PervasiveHealth ’06 , pages 1 – 10 . [ 27 ] James J Lin , Lena Mamykina , Silvia Lindtner , Gre - gory Delajoux , and Henry B Strub . Fish’n’steps : Encouraging physical activity with an interactive computer game . In UBICOMP ’06 , pages 261 – 278 . Springer . [ 28 ] Frank Bentley , Konrad Tollmar , Peter Stephenson , Laura Levy , Brian Jones , Scott Robertson , Ed Price , 13 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 Richard Catrambone , and Jeff Wilson . Health mashups : Presenting statistical patterns between wellbeing data and context in natural language to promote behavior change . ACM Transactions on Computer - Human Interaction ( TOCHI ) , 20 ( 5 ) : 1 – 27 , 2013 . [ 29 ] Hamed Haddadi and Ian Brown . Quantiﬁed self and the privacy challenge . Technology Law Futures , 6 , 2014 . [ 30 ] Jason Wiese , Sauvik Das , Jason I Hong , and John Zimmerman . Evolving the ecosystem of personal behavioral data . Human – Computer Interaction , 32 ( 5 - 6 ) : 447 – 510 , 2017 . [ 31 ] Eun Kyoung Choe , Nicole B Lee , Bongshin Lee , Wanda Pratt , and Julie A Kientz . Understanding quantiﬁed - selfers’ practices in collecting and explor - ing personal data . In Proceedings of the SIGCHI conference on human factors in computing systems , pages 1143 – 1152 , 2014 . [ 32 ] Simon L Jones . Exploring correlational informa - tion in aggregated quantiﬁed self data dashboards . UBICOMP / ISWC ’15 Adjunct , pages 1075 – 1080 . [ 33 ] Simon L Jones and Ryan Kelly . Dealing with infor - mation overload in multifaceted personal informat - ics systems . Human – Computer Interaction , 33 ( 1 ) : 1 – 48 , 2018 . [ 34 ] Tamara Munzner , Chris Johnson , Robert Moorhead , Hanspeter Pﬁster , Penny Rheingans , and Terry S Yoo . Nih - nsf visualization research challenges re - port summary . IEEE Computer Graphics and Ap - plications , 26 ( 2 ) : 20 – 24 , 2006 . [ 35 ] T . Munzner . A nested model for visualization design and validation . IEEE Transactions on Visualization and Computer Graphics , 15 ( 6 ) : 921 – 928 , 2009 . [ 36 ] Sean McKenna , Dominika Mazur , James Agutter , and Miriah Meyer . Design activity framework for visualization design . IEEE TVCG ’14 , 20 ( 12 ) : 2191 – 2200 . [ 37 ] Nina McCurdy , Jason Dykes , and Miriah Meyer . Action design research and visualization design . In Proceedings of the Sixth Workshop on Beyond Time and Errors on Novel Evaluation Methods for Visu - alization , pages 10 – 18 , 2016 . [ 38 ] Miriah Meyer and Jason Dykes . Criteria for rigor in visualization design study . IEEE TVCG ’19 , 26 ( 1 ) : 87 – 97 . [ 39 ] Michael Sedlmair . Design study contributions come in different guises : Seven guiding scenarios . In BELIV ’16 , page 152 – 161 , New York , NY , USA . [ 40 ] Sean Kandel , Andreas Paepcke , Joseph M Heller - stein , and Jeffrey Heer . Enterprise data analysis and visualization : An interview study . IEEE TVCG ’12 , 18 ( 12 ) : 2917 – 2926 . [ 41 ] Sara Alspaugh , Nava Zokaei , Andrea Liu , Cindy Jin , and Marti A . Hearst . Futzing and Moseying : Interviews with Professional Data Analysts on Ex - ploration Practices . IEEE TVCG ’19 , 25 ( 1 ) : 22 – 31 . [ 42 ] Eser Kandogan , Aruna Balakrishnan , Eben M Haber , and Jeffrey S Pierce . From data to insight : work practices of analysts in the enterprise . IEEE computer graphics and applications , 34 ( 5 ) : 42 – 50 , 2014 . [ 43 ] Miryung Kim , Thomas Zimmermann , Robert De - Line , and Andrew Begel . The emerging role of data scientists on software development teams . In ICSE ’16 , pages 96 – 107 . ACM . [ 44 ] Danyel Fisher , Rob DeLine , Mary Czerwinski , and Steven Drucker . Interactions with big data analytics . interactions , 19 ( 3 ) : 50 – 59 , 2012 . [ 45 ] Peter Pirolli and Stuart Card . The sensemaking pro - cess and leverage points for analyst technology as identiﬁed through cognitive task analysis . In Pro - ceedings of international conference on intelligence analysis , volume 5 , pages 2 – 4 . McLean , VA , USA , 2005 . [ 46 ] Paula Cowley , Lucy Nowell , and Jean Scholtz . Glass box : An instrumented infrastructure for sup - porting human interaction with information . In IEEE ICSS ’15 , pages 296c – 296c . [ 47 ] Emily S Patterson , Emilie M Roth , and David D Woods . Predicting vulnerabilities in computer - supported inferential analysis under data over - load . Cognition , Technology & Work , 3 ( 4 ) : 224 – 237 , 2001 . [ 48 ] William Wright , David Schroh , Pascale Proulx , Alex Skaburskis , and Brian Cort . The sandbox for analysis : concepts and methods . In Proceedings of the SIGCHI conference on Human Factors in computing systems , pages 801 – 810 , 2006 . [ 49 ] Peter Pirolli and Stuart Card . Information foraging . Psychological review , 106 ( 4 ) : 643 , 1999 . [ 50 ] Daniel M Russell , Mark J Steﬁk , Peter Pirolli , and Stuart K Card . The cost structure of sensemaking . In Proceedings of the INTERACT’93 and CHI’93 conference on Human factors in computing systems , pages 269 – 276 , 1993 . [ 51 ] Sean Kandel , Andreas Paepcke , Joseph Hellerstein , and Jeffrey Heer . Wrangler : Interactive visual spec - iﬁcation of data transformation scripts . In Proceed - ings of the SIGCHI Conference on Human Factors in Computing Systems , pages 3363 – 3372 , 2011 . [ 52 ] Alex Bigelow , Carolina Nobre , Miriah Meyer , and Alexander Lex . Origraph : interactive network wran - gling . In IEEE VAST ’19 , pages 81 – 92 . [ 53 ] Michael Bostock , Vadim Ogievetsky , and Jeffrey Heer . D 3 data - driven documents . IEEE TVCG ’11 , 17 ( 12 ) : 2301 – 2309 . [ 54 ] Jock Mackinlay . Automating the design of graphical presentations of relational information . TOG ’86 , 5 ( 2 ) : 110 – 141 . 14 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 [ 55 ] Kanit Wongsuphasawat , Dominik Moritz , Anushka Anand , Jock Mackinlay , Bill Howe , and Jeffrey Heer . Voyager : Exploratory analysis via faceted browsing of visualization recommendations . IEEE TVCG ’15 , 22 ( 1 ) : 649 – 658 . [ 56 ] Kanit Wongsuphasawat , Dominik Moritz , Anushka Anand , Jock Mackinlay , Bill Howe , and Jeffrey Heer . Towards a general - purpose query language for visualization recommendation . HILDA ’16 , pages 1 – 6 . [ 57 ] Jock Mackinlay , Pat Hanrahan , and Chris Stolte . Show me : Automatic presentation for visual analy - sis . IEEE TVCG ’07 , 13 ( 6 ) : 1137 – 1144 . [ 58 ] Robert A Amar and John T Stasko . Knowledge precepts for design and evaluation of information visualizations . IEEE TVCG ’05 , 11 ( 4 ) : 432 – 442 . [ 59 ] Bum chul Kwon , Brian Fisher , and Ji Soo Yi . Vi - sual analytic roadblocks for novice investigators . In IEEE VAST ’11 , pages 3 – 11 . [ 60 ] Po - Ming Law , Rahul C Basole , and Yanhong Wu . Duet : Helping data analysis novices conduct pair - wise comparisons by minimal speciﬁcation . IEEE TVCG ’18 , 25 ( 1 ) : 427 – 437 . [ 61 ] Lars Grammel , Melanie Tory , and Margaret - Anne Storey . How information visualization novices con - struct visualizations . IEEE transactions on visu - alization and computer graphics , 16 ( 6 ) : 943 – 952 , 2010 . [ 62 ] Martin Wattenberg . Visualizing the stock market . In CHI’99 extended abstracts on Human factors in computing systems , pages 188 – 189 , 1999 . [ 63 ] Martin Wattenberg . Baby names , visualization , and social data analysis . In IEEE INFOVIS ’05 . , pages 1 – 7 . [ 64 ] Fernanda B Viegas , Martin Wattenberg , Frank Van Ham , Jesse Kriss , and Matt McKeon . Manyeyes : a site for visualization at internet scale . IEEE TVCG ’07 , 13 ( 6 ) : 1121 – 1128 . [ 65 ] Jeffrey Heer , Fernanda B Viégas , and Martin Wat - tenberg . Voyagers and voyeurs : Supporting asyn - chronous collaborative visualization . Communica - tions of the ACM , 52 ( 1 ) : 87 – 97 , 2009 . [ 66 ] Catalina M Danis , Fernanda B Viegas , Martin Wat - tenberg , and Jesse Kriss . Your place or mine ? visu - alization as a community component . In Proceed - ings of the SIGCHI conference on Human factors in computing systems , pages 275 – 284 , 2008 . [ 67 ] Jeffrey Heer and Danah Boyd . Vizster : Visualizing online social networks . In INFOVIS ’05 , pages 32 – 39 . IEEE . [ 68 ] Samuel Huron , Sheelagh Carpendale , Alice Thudt , Anthony Tang , and Michael Mauerer . Constructive visualization . In DIS ’14 , pages 433 – 442 . ACM . [ 69 ] Michael J Danziger . Information visualization for the people . PhD thesis , Massachusetts Institute of Technology , Department of Comparative Media Studies , 2008 . [ 70 ] Rohit Ashok Khot , Jeewon Lee , Deepti Aggarwal , Larissa Hjorth , and Florian ’Floyd’ Mueller . Tasty - Beats : Designing palatable representations of phys - ical activity . In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , pages 2933 – 2942 , New York , NY , USA , apr 2015 . ACM . [ 71 ] Rohit Ashok Khot , Florian Mueller , and Larissa Hjorth . SweatAtoms : Materializing physical ac - tivity . ACM International Conference Proceeding Series , 2013 . [ 72 ] Simon Stusak , Aurelien Tabard , Franziska Sauka , Rohit Ashok Khot , and Andreas Butz . Activity sculptures : Exploring the impact of physical visual - izations on running activity . IEEE Transactions on Visualization and Computer Graphics , 20 ( 12 ) : 2201 – 2210 , 2014 . [ 73 ] Alice Thudt , Uta Hinrichs , Samuel Huron , and Shee - lagh Carpendale . Self - reﬂection and personal physi - calization construction . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , pages 1 – 13 , 2018 . [ 74 ] Alice Thudt , Dominikus Baur , Samuel Huron , and Sheelagh Carpendale . Visual Mementos : Reﬂecting Memories with Personal Data . IEEE TVCG ’16 , 22 ( 1 ) : 369 – 378 . [ 75 ] Steven Houben , Connie Golsteijn , Sarah Gallacher , Rose Johnson , Saskia Bakker , Nicolai Marquardt , Licia Capra , and Yvonne Rogers . Physikit : Data Engagement Through Physical Ambient Visualiza - tions in the Home . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Sys - tems , pages 1608 – 1619 , New York , NY , USA , may 2016 . ACM . [ 76 ] David Holstius , John Kembel , Amy Hurst , Peng - Hui Wan , and Jodi Forlizzi . Infotropism : living and robotic plants as interactive displays . In Proceed - ings of the 5th conference on Designing interactive systems : processes , practices , methods , and tech - niques , pages 215 – 221 , 2004 . [ 77 ] Fadi Botros , Charles Perin , Bon Adriel Aseniero , and Sheelagh Carpendale . Go and Grow . In Pro - ceedings of the International Working Conference on Advanced Visual Interfaces , pages 112 – 119 , New York , NY , USA , jun 2016 . ACM . [ 78 ] Bongshin Lee , Eun Kyoung Choe , Petra Isenberg , Kim Marriott , John Stasko , and Theresa - Marie Rhyne . Reaching Broader Audiences With Data Visualization . IEEE Comp . Gr . & App . , 40 ( 2 ) : 82 – 90 , ’20 . [ 79 ] Philipp Koytek , Charles Perin , Jo Vermeulen , Elis - abeth André , and Sheelagh Carpendale . MyBrush : 15 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 Brushing and Linking with Personal Agency . IEEE TVCG ’18 , 24 ( 1 ) : 605 – 615 . [ 80 ] Bon Adriel Aseniero , Charles Perin , Wesley Willett , Anthony Tang , and Sheelagh Carpendale . Activity River : Visualizing Planned and Logged Personal Activities for Reﬂection . ACM International Con - ference Proceeding Series , 2020 . [ 81 ] Ethan Kerzner , Sarah Goodwin , Jason Dykes , Sara Jones , and Miriah Meyer . A framework for creative visualization - opportunities workshops . IEEE TVCG ’18 , 25 ( 1 ) : 748 – 758 . [ 82 ] National Institute of Biomedical Imaging Bioengi - neering . Pediatric Research Using Integrated Sensor Monitoring Systems , 2015 . [ 83 ] Lena Mamykina , Elizabeth Mynatt , Patricia David - son , and Daniel Greenblatt . Mahi : investigation of social scaffolding for reﬂective thinking in diabetes management . In Proceedings of the SIGCHI Con - ference on Human Factors in Computing Systems , pages 477 – 486 , 2008 . [ 84 ] Samantha Kolovson , Calvin Liang , Sean A Mun - son , and Kate Starbird . Personal data and power asymmetries in us collegiate sports teams . Proceed - ings of the ACM on Human - Computer Interaction , 4 ( GROUP ) : 1 – 27 , 2020 . [ 85 ] Utah Physicians for a Healthy Environment . Slc – ranked among the worst globally for air quality , https : / / www . uphe . org / 2020 / 09 / 14 / slc - ranked - among - the - worst - globally - for - air - quality / . Accessed : 2021 - 03 - 19 . [ 86 ] David Kirsh . The context of work . Hu - man – Computer Interaction , 16 ( 2 - 4 ) : 305 – 322 , 2001 . [ 87 ] William Lidwell , Kritina Holden , and Jill Butler . Universal principles of design . Rockport Pub , 2010 . [ 88 ] Y . Rogers . New theoretical approaches for human - computer interaction . Annual review of information science and technology , 38 ( 1 ) : 87 – 143 , ’04 . [ 89 ] James J Gibson . The ecological approach to visual perception . hills - dale . NJ : Lawrence , 1986 . [ 90 ] Donald A Norman . Affordance , conventions , and design . interactions , 6 ( 3 ) : 38 – 43 , 1999 . [ 91 ] Peter Thorvald . Triggers , entry points , and affor - dances : How to improve their cognitive congenial - ity , 2006 . [ 92 ] Tanja Blascheck , Lindsay Macdonald Vermeulen , Jo Vermeulen , Charles Perin , Wesley Willett , Thomas Ertl , and Sheelagh Carpendale . Exploration strategies for discovery of interactivity in visualiza - tions . IEEE TVCG ’19 , 25 ( 2 ) : 1407 – 1420 . [ 93 ] Jagoda Walny , Sarah Storteboom , Richard Pusch , Steven Munsu Hwang , Søren Knudsen , Sheelagh Carpendale , and Wesley Willett . Pixelclipper : Sup - porting public engagement and conversation about visualizations . IEEE Comp . Gr . & App . ’20 , 40 ( 2 ) : 57 – 70 . [ 94 ] Eva Hornecker , Paul Marshall , and Yvonne Rogers . From entry to access : How shareability comes about . In DPPI ’07 , page 328 – 342 . ACM . [ 95 ] Eun Kyoung Choe , Bongshin Lee , Haining Zhu , Nathalie Henry Riche , and Dominikus Baur . Un - derstanding self - reﬂection : how people reﬂect on personal data through visual data exploration . Per - vasiveHealth ’17 , pages 173 – 182 . [ 96 ] Fabio Miranda , Marcos Lage , Harish Doraiswamy , Charlie Mydlarz , Justin Salamon , Yitzchak Lock - erman , Juliana Freire , and Claudio T Silva . Time lattice : A data structure for the interactive visual analysis of large time series . Comp . Gr . Forum , 37 ( 3 ) : 23 – 35 , 2018 . [ 97 ] Evan M Peck , Soﬁa E Ayuso , and Omar El - Etr . Data is personal : Attitudes and perceptions of data visualization in rural pennsylvania . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems , pages 1 – 12 , 2019 . [ 98 ] Matthew Brehmer and Tamara Munzner . A multi - level typology of abstract visualization tasks . IEEE transactions on visualization and computer graph - ics , 19 ( 12 ) : 2376 – 2385 , 2013 . [ 99 ] Mackinlay Card . Readings in information visual - ization : using vision to think . Morgan Kaufmann , 1999 . [ 100 ] Ben Shneiderman . Designing for fun : How can we design user interfaces to be more fun ? Interactions , 11 ( 5 ) : 48 – 50 , September 2004 . [ 101 ] Naa Amponsah Dodoo and Seounmi Youn . Snap - ping and chatting away : Consumer motivations for and outcomes of interacting with snapchat ar ad lens . Telematics and Informatics , 57 : 101514 , 2021 . [ 102 ] Joseph Tu and Ekaterina Durmanova . Curioscape : A curiosity - driven escape room board game . CHI PLAY ’20 : Extended Abstracts , pages 94 – 97 . [ 103 ] Harry Slater . [ update ] the cu - riosity cube diaries - volume 1 , https : / / www . pocketgamer . com / articles / 046406 / update - the - curiosity - cube - diaries - volume - i / , accessed : 2021 - 03 - 21 . Accessed : 2021 - 03 - 21 . [ 104 ] Sebastian Deterding . Situated motivational affor - dances of game elements : A conceptual model . CHI ’11 Gamiﬁcation Workshop , ( July ) , 2011 . [ 105 ] Ferran Altarriba Bertran , Elena Márquez Segura , Jared Duval , and Katherine Isbister . Chasing play potentials : Towards an increasingly situated and emergent approach to everyday play design . pages 1265 – 1277 , ’19 . [ 106 ] William W Gaver , John Bowers , Andrew Boucher , Hans Gellerson , Sarah Pennington , Albrecht Schmidt , Anthony Steed , Nicholas Villars , and 16 M OORE ET AL . ; E XPLORING THE PERSONAL INFORMATICS ANALYSIS GAP : “T HERE ’ S A LOT OF BACON ” ; 2021 Brendan Walker . The drift table : designing for ludic engagement . CHI EA’04 , pages 885 – 900 . [ 107 ] Aaron Scott . How playcentric research methods are contributing to new understanding and opportunities for design . The Routledge companion to design research , pages 400 – 414 , 2014 . [ 108 ] Steven P Dow , Kate Heddleston , and Scott R Klem - mer . The efﬁcacy of prototyping under time con - straints . In ACM conf . on Creativity and cognition ’09 , pages 165 – 174 . [ 109 ] Mattia Thibault . Play as a modelling system - a semi - otic analysis of the overreaching prestige of games . In GamiFIN , pages 105 – 110 , 2017 . [ 110 ] Sebastian Deterding , Dan Dixon , Rilla Khaled , and Lennart Nacke . From game design elements to gamefulness : Deﬁning " gamiﬁcation " . In Proceed - ings of the 15th International Academic MindTrek Conference : Envisioning Future Media Environ - ments , MindTrek ’11 , page 9 – 15 , New York , NY , USA , 2011 . Association for Computing Machinery . [ 111 ] Guy H Orcutt , Harold W Watts , and John B Ed - wards . Data aggregation and information loss . The American Economic Review ’68 , 58 ( 4 ) : 773 – 787 . [ 112 ] Jeffrey Heer and Maneesh Agrawala . Design consid - erations for collaborative visual analytics . INFOVIS ’08 , 7 ( 1 ) : 49 – 62 . 17