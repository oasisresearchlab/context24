P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . A Learning Agreement for Generative AI Use in University Courses : A Pilot Study Marc Beardsley 1 , Ishari Amarasinghe 1 , Emily Theophilou 1 , Milica Vujovic 1 , and Davinia Hern´andez - Leo 1 1 Aﬃliation not available March 18 , 2024 Abstract The rapidly evolving landscape of Generative AI ( GenAI ) tools necessitate continuous vigilance and adaptation by educators . This dynamism requires stakeholders to stay up to date with developments to address emerging issues eﬀectively , creating complexity in managing the responsible and ethical use of GenAI . This paper presents a pilot study involving the use of student learning agreements for governing GenAI use in a ﬁrst - year engineering degree course . The learning agreement contains ethical and social considerations students agree to make if they decide to use GenAI in the course . As part of the pilot study , pre - post surveys and student artefacts – a group assignment adapted to accommodate GenAI use – were analysed . Results show that the vast majority of students were in favour of the learning agreement approach both at the start and upon completion of the course . However , 7 of 17 groups did not use GenAI in their assignment . Of the 10 groups that did , only 1 acknowledged GenAI limitations in adherence with the learning agreement . A thematic analysis of student suggestions for improving the learning agreement approach include suggestions for making the agreement easier to understand and adhere to ( e . g . , providing speciﬁc examples , reengaging with the agreement during the course ) . Overall , ﬁndings suggest that learning agreements have the potential to oﬀer an interface through which student decision - making can be supported and interactions among students , educators , researchers , and policy makers related to the ethical and societal challenges of GenAI can take place . 1 . Introduction Generative AI ( GenAI ) is disrupting education . GenAI refers to a broader set of technologies that can generate new and unique content , in various formats such as text , images , audio , code , text , simulations , 3D objects , and videos ( Moorhouse et al . , 2023 ) . The concept of GenAI is closely tied to Large Language Models ( LLMs ) , which are explicitly designed to facilitate the creation of text - based materials . The advent of free , relatively easy - to - use , online LLM based conversational interfaces such as ChatGPT has quickly transformed students’ use of AI in education . Speciﬁcally , tools such as ChatGPT can automatically generate text in response to a human prompt and have raised implications for assessments ( Sharples , 2022 ) . As a result , many educators worry about new forms of academic dishonesty as students can simply copy and paste content generated by these technologies potentially engaging in uncredited use of AI - generated text , misrepresenting one’s abilities , and neglecting essential learning processes ( Padillah , 2023 ; Mohammadkarimi , 2023 ; Habib et al . , 2024 ) . Hence , use of GenAI by students can undermine principles of fairness in education and diminish the value of personal achievements ( Padillah , 2023 ) . Ethical concerns related to the use of GenAI such as bias , accessibility , and privacy have also been raised ( Sabzalieva & Valentini , 2023 ) . The issue of bias in produced content is a signiﬁcant ethical challenge ( Ferrer et al . , 2021 ; Zhou , et al . , 2023 ) as the models learn from data , and if that data reﬂects societal biases , the 1 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . generated content can introduce or reinforce these biases in its outputs ( Akter et al . , 2021 ) . Another concern is the potential for inequality arising from varying resources and prior knowledge required to access and utilise advanced functionalities of AI language models eﬀectively ( Ng et al . , 2021 ) . The digital divide , already a societal challenge , could be worsened as those with more resources and technical know - how could disproportionately beneﬁt from these technologies . There are also concerns related to individual privacy and intellectual property rights . Using AI language models involves processing vast amounts of user data ( Gupta et al . , 2023 ) and copyrighted materials – but often without adequate notiﬁcation or consent ( Lucchi , 2023 ) . The need for data input to train and ﬁne - tune these models presents a risk to individual privacy , with questions arising about the security and responsible handling of sensitive information ( Wu et al . , 2023 ) by the private enterprises oﬀering public access to GenAI technologies . In response , several universities attempted to temporarily restrict or ban access to GenAI tools ( Moorhouse et al . , 2023 ) . However , concerns have been raised about the impact of restricting access in academic contexts , considering the impact on students’ AI literacy and their readiness for a society increasingly powered by artiﬁcial intelligence ( Chiu , 2024 ; Chiu 2023 ) . Further , the disruptiveness of GenAI does not rest solely with its potential to interfere with student learning but also in its promise for enhancing student learning and the eﬀectiveness of educators . A comprehensive guide on using ChatGPT and Artiﬁcial Intelligence in higher education published by UNESCO explains how AI tools used both by students and educators can enhance learning experiences . The authors of the guide present diverse roles AI can fulﬁl such as those of a personal tutor , co - designer , and motivator ( Sabzalieva & Valentini , 2023 ) . Furthermore , Miao ( 2021 ) highlights the importance of collaborative intelligence between humans and machines and describes four main areas in which there are emerging and potential applications of AI in education : ( 1 ) Education management and delivery , ( 2 ) Learning and assessment , ( 3 ) Empowering teachers and improving teaching , and ( 4 ) Promoting lifelong learning . Recognizing opportunities for disruption becomes essential for not only improving the eﬀectiveness of education but also for preparing students with the skills required for employment in a world increasingly inﬂuenced by AI integration ( Alekseeva , et al , 2021 ) . The rapidly evolving landscape of GenAI tools , with frequent releases of new tools and improvements to existing ones , necessitate continuous vigilance and adaptation ( Gill et al . , 2022 ) . This dynamism requires stakeholders to stay up to date with developments to address emerging issues eﬀectively , creating additional complexity in managing the responsible and ethical use of GenAI . As society faces these concerns , there is a need to ﬁnd a balance that allows the beneﬁts of advanced AI language models to be received while addressing the associated ethical and societal challenges . Considering the opportunities , concerns , and the immediacy of the disruption to university education , a process is needed that can gather insights into how AI is being used , assess whether such uses are eﬀective or not , and bring stakeholders together to deﬁne acceptable uses of AI in education ( Beardsley et al . , 2024 ) . Student learning agreements may oﬀer a ﬂexible , student - centred approach that gathers informative data while providing opportunities for students to become more thoughtful in their decision making related to the use of innovative technologies such as GenAI . 1 . 1 . Learning agreements Learning agreements ( LA ) , learning plans or student contracts , strive to be transformative educational tools that aim to place students in control of their learning journeys ( Clear et al . , 2016 ) . LAs provide incremental steps through which students assume ownership of their learning , fostering a sense of accountability , com - munity belonging , and shared expectations with their teachers ( Nielsen et al . , 2022 ) . Interchangeable with learning partnerships , LAs can be used to shape sustainable learning environments and partnerships ( Wallis , 2013 ) . Predominantly appearing in medical education literature , LAs are often integrated into time - schedule agreements for medical students ( Ahuja et al . , 2013 ) . The aim is to have students formulate speciﬁc learning agreements early in their training placements and continuously review progress throughout their placement periods ( McKee , 2008 ) . LAs have also been used in workplace learning , particularly in work - based higher education settings . Studies , mainly concentrated in the UK , highlight LAs role in fostering socially respon - sible approaches to professional development within workplace settings ( Wallis , 2013 ) . LAs or contracts for internships , particularly in the context of sociology students’ internships ( Parilla & Hesser , 1998 ) and for 2 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . facilitating student mobility and exchange programs ( Bustamante et al . , 2010 ) demonstrate the adaptability and versatility of LAs across various educational and professional contexts . The multifaceted application of learning agreements spans medical education , workplace learning , mobility programs , and internships , show - casing their role in empowering student - centred learning , fostering partnerships , and ensuring the alignment of educational objectives with diverse learning contexts . 1 . 2 . University guidelines on GenAI use Following ChatGPT’s availability , interest in the educational implications of GenAI surged . In early 2023 , UNESCO released a report on GenAI in higher education ( Miao & Holmes , 2023 ) , outlining several guidelines . Soon after , many universities formulated their own guidelines for teachers and students regarding its use ( e . g . , see sources [ 1 ] to [ 5 ] in Table 1 ) . It is common in the existing guidelines to introduce a general description of GenAI technology along with cases of tools , usually with an emphasis on ChatGPT . Ideas for learning tasks that illustrate how GenAI oﬀers opportunities for enhanced learning tasks ( e . g . , opportunities for immediate feedback on written text ) are then elaborated on . The guides also alert about risks and ethical implications , highlighting issues related to bias , reliability , and privacy . Interestingly , some guides oﬀer strategies to teachers for adapting assessment tasks to ensure students remain engaged in active learning , even when utilising these tools . This involves encouraging connections to personal experiences and reﬂections , data collection , and detailed accounts of how GenAI tools have been applied in completing assignments ( e . g . , University of Tartu guidelines for using AI chatbots for teaching and studies , 2023 ) . ) . However , these guidelines typically stop short of oﬀering speciﬁc course policies , leaving these decisions to individual educators . Generally , they reference the university’s existing or expanded ethics policies , which build upon traditional plagiarism procedures . However , these procedures are challenging to apply when GenAI tools are used by students to replace their expected learning actions ( Hern´andez - Leo , 2023 ) , as detection of GenAI use is problematic ( Farrokhnia et al . , 2023 ) . Hence , it may be worthwhile exploring an alternate approach that can line up with established university academic integrity policies yet is ﬂexible in its application to allow the individual educator to adapt it to their course needs and the current technological landscape . Further , a learning agreement - driven approach can better engage student decision making and motivational processes , aligning with self - determination theory – autonomy , competence , relatedness ( Deci et al . , 2017 ) – especially when executed in the context of group work . This article presents a pilot study involving the use of a learning agreement for GenAI use that was im - plemented into a university course for ﬁrst - year students in an engineering degree programme during the 2023 - 24 academic year . The learning agreement approach involved instructors and students agreeing upon ground rules for AI use at the onset of a course via a multi - page online form . The motivation of the work was to explore whether a learning agreement can be an acceptable tool for governing student use of GenAI in university coursework . As such , the research questions being explored are : R1 . Would ﬁrst - year students be accepting of a course learning agreement on GenAI use ? R2 . Would students adhere to the terms of the learning agreement in their group assignment ? R3 . After experiencing a course learning agreement , how would students improve on its use ? To address these questions , the article contributes the following : ( a ) A learning agreement for GenAI use in university courses and literature supporting its terms ; ( b ) A description of modiﬁcations made to the course design to account for student use of GenAI and the terms of the learning agreement ; ( c ) Results of a pre - post study exploring changes in student awareness and use of GenAI tools , beliefs related to how such tools should be used in university learning , and thoughts on a learning agree - ment for GenAI use approach ; ( d ) An analysis of student adherence to terms of the learning agreement on a key course assignment ; and ( e ) Findings from an analysis of student suggestions to improve the learning agreement approach adopted . 2 . Methodology This study follows a design - based research methodology ( DBR ) ( Anderson & Shattuck , 2012 ) and applies a mixed methods design . DBR has been selected as there are plans to iterate upon the design of the learning 3 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . agreement in subsequent academic years . 2 . 1 . Participants Participants were engineering degree program students enrolled in a ﬁrst - year general studies course at a university in Spain that consented to sharing their data ( female = 26 , male = 56 , other = 01 , prefer not to say = 01 , M - age = 18 . 17 , SD - age = 1 . 37 ) . The general studies course , Introduction to Information and Communication Technology ( ITIC ) , serves to introduce the university and engineering studies . Topics include : an overview of the study program , transversal competences at the level of higher education ( learning to learn , teamwork , written and oral communication ) , academic integrity , an overview of the ICT sector , and codes of ethics and professional conduct in engineering . The course includes plenary sessions that introduce content and include interactive discussion led by professors , and seminar sessions for more active student learning . Seminars activities vary from short individual and group tasks to debates , and the elaboration and presentation of a group written article about the future ( and ethical implications ) of a technology of their choice . A revision of the course was done in 2023 - 2024 to account for the availability of GenAI tools . 2 . 1 . Pre - post survey As part of this study , participants completed two online surveys ( Google Form ) while in class . The pre - survey was completed during the ﬁrst week of the ﬁrst trimester of the 2023 - 24 academic year . The survey contained 7 items rated on a 5 - point Likert scale ( 1 = Strongly disagree , 5 = Strongly agree ) related to awareness , use , and beliefs about GenAI and learning agreements ; and 6 related open - ended questions . After 8 weeks , in the latter half of the ﬁnal class of the course , students completed a post - survey . The post - survey contained 6 items rated on a 5 - point Likert scale related to awareness , use , and beliefs about GenAI , 4 items rated on a 5 - point Likert scale related to the usefulness of the learning agreement , 1 required open - ended question on improving the learning agreement , and 2 optional open - ended questions . 2 . 2 . Learning agreement for GenAI use The content for the learning agreement came from a cursory review of university policies on GenAI use and scientiﬁc literature on AI use in education . Five key themes were identiﬁed to include in the learning agreement . Table 1 presents a summary of the sources relating to each theme . The learning agreement was presented to students as a Google Form with 9 sections . The ﬁrst section presented the purpose of the learning agreement as a participatory process , We want to help you gain experience in using innovative technologies ( that can beneﬁt your future career ) in a responsible manner – and for you to help us improve our deﬁnition of what responsible use means . The second and third sections provided instructions for completing the form and collecting student information – and included the following text to describe the intention of the agreement : Students are encouraged to use AI tools to contribute to their learning in the course ( i . e . , as learning aids or to help produce designated assignments ) . However , students using such tools are only permitted to do so in accordance with the terms outlined in this form . A failure to do so may result in a violation of university rules for academic integrity and risk suspension / expulsion from the university . Sections four to eight contained the key themes as shown in Table 1 and converted them into agreement items ( i . e . , choice selections to be made by students ) . For example , item 1 relating to the ﬁrst theme presents a checkbox with the text , I understand that in this ITIC course AI tools cannot be used during assessment and opinion survey tasks unless speciﬁed otherwise by your instructor . Table 1 Themes included in the Student Learning Agreement for Governing GenAI Use in University Courses Theme Description Sources 1 . Not for assessments Assessments help us understand whether students have learned course material . Opinion surveys help us understand your views on topics . The use of AI for assessment and opinion survey tasks can defeat the purpose of such tasks . However , AI tools may be useful when gathering information to support your studying for these assessments ( prior to starting the assessment tasks ) . If you are not sure whether AI tools can be used for a speciﬁc assignment , please ask your instructor . [ 1 ] [ 2 ] [ 3 ] [ 7 ] 2 . Declared and described use AI tools can be used to assist in the completion of key course assignments ( article , debate , presentation ) and other assignments explicitly designated by your instructors . However , any AI tool usage must be declared and described in your submitted assignments . [ 1 ] [ 2 ] [ 5 ] [ 8 ] [ 9 ] [ 10 ] 3 . Appropriate citations Any content ( text , image , data ) from an AI tool must be cited according to APA standards . This applies to in - text citations and references ( e . g . paraphrasing , quoting , or incorporating any content from an AI tool into your own work ) . For example , if you copy and paste AI - generated text directly to your assignment , you must add quotations around the text , ”the inﬂuence of beavers on their environment can be both constructive and destructive , contingent on the particular context” ( OpenAI , 2023 ) . [ 2 ] [ 4 ] [ 5 ] [ 6 ] [ 11 ] 4 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . 4 . Responsible use AI tools are known to have limitations and may have problematic ethical origins and / or intentions . 1 ) Biases : Biases in datasets used to train AI can perpetuate social inequalities and injustices . 2 ) Privacy : Datasets used to train AI may violate data privacy and intellectual property rights . AI tools may also collect , store , and use user data for undisclosed purposes . 3 ) Misinformation : AI tools are known to fabricate facts and can be used to spread disinformation . 4 ) Power and responsibility : Popular AI tools are closed ( not transparent ) , proprietary models that consume massive amounts of resources ( natural , ﬁnancial ) and have the power to shape public opinion . [ 2 ] [ 4 ] [ 7 ] [ 11 ] [ 12 ] [ 13 ] [ 14 ] [ 15 ] Informed use Usage of AI tools involves the sharing of personal data and , possibly , intellectual property with third parties . Conﬁdential information should never be inputted into an AI tool as entered content may become part of the tool’s dataset and appear in response to other prompts . [ 2 ] [ 4 ] [ 7 ] [ 11 ] [ 12 ] [ 15 ] Note . References for sources : [ 1 ] Generative AI Policy Guidance , n . d . ; [ 2 ] ChatGPT and Generative AI in the Classroom – Oﬃce of the Vice - Provost , Innovations in Undergraduate Education , n . d . ; [ 3 ] UCLb , 2023 ; [ 4 ] Guidance for the Use of Generative AI – UCLA Center for the Advancement of Teaching , n . d . ; [ 5 ] University of Tartu guidelines for using AI chatbots for teaching and studies . ( 2023 , April 28 ) . [ 6 ] LibGuides : References , Citations and Avoiding Plagiarism : Acknowledging and Referencing AI , n . d . ; [ 7 ] Sabzalieva & Valentini , 2023 ; [ 8 ] Gatrell , et al , 2024 ; [ 9 ] Tang , et al , 2023 ; [ 10 ] Flanagin , et al , 2023 ; [ 11 ] McAdoo , T . , n . d ; [ 12 ] Bozkurt et al . , 2023 ; [ 13 ] Miao & Holmes , 2021 ; [ 14 ] Hryciw , et al , 2023 ; [ 15 ] Akgun & Greenhow , 2022 . 2 . 3 . Course design modiﬁcations for GenAI use Considering the availability of GenAI tools , some sessions , assignments , and related grading criteria in the course were redesigned to oﬀer room for accommodating the opportunities of GenAI while also attempting to mitigate its risks . Firstly , a plenary session dedicated to the code of ethics of the university and academic integrity was redesigned to include an introduction to GenAI . The session provided insights into how it operates , fostered a discussion on the opportunities it presents in enhancing learning , while addressing challenges and risks associated with its use . Secondly , the assignment description and related grading criteria for the group written article was modiﬁed to require an appendix in which groups were to a ) Declare databases ( e . g . , ACM Digital Library ) and tools used ( including any AI tools ) to assist the completion of the article , with a description of how they were used . If AI tools were not used , groups were to include a reﬂection explaining the reasons . Additionally , groups were to explain how feedback from peers , their tutor , and ( if apply ) AI tools were considered . Finally , the content of a seminar session to scaﬀold the elaboration of the group written article was redesigned . During the session tutors introduced students to GenAI tools and prompts to generate the feedback , e . g . ChatGPT to check coherence , Grammarly to check grammar , Elicit to search for additional evidence . Groups also received feedback from tutors and peers – and were given the choice of whether to take advantage of GenAI tools for improving their drafts . 2 . 4 . Procedure and data analysis During the ﬁrst week of the trimester , students completed the online pre - survey and learning agreement form prior to attending a plenary lecture that introduced GenAI and Academic Integrity . The terms of the learning agreement were discussed in the lecture and students were able to change their learning agreement form responses following the lecture . In week 6 , students were encouraged to use GenAI during a 2 - hour seminar class to receive personalised feedback on the key assignment ( group written article ) . In week 9 , the key assignment was delivered by students and student groups made formal presentations of their group articles . Following the presentations , students completed the post - survey . Python was used to analyse the quantitative data and thematic analysis was used for qualitative data ( O’Connor & Joﬀe , 2020 ) . 3 . Results 3 . 1 . Course artefacts ( adherence ) A requirement of the group written article was to include in the appendices of the article a description of AI tools used . The requirement was written as follows , Declaration of the databases and tools used ( including any AI tools ) , when applied to assist the completion of the article , with a description of how they were used . If AI tools have not been used , include a reﬂection explaining the reasons . Further , items 2 - 4 of the learning agreement required students to include speciﬁc information in their reporting of AI tool use . Item 2 : The appendix must ( 1 ) document what tool ( s ) were used , ( 2 ) how the tools were used ( i . e . , prompts used ) , and ( 3 ) how the results from the AI tools were incorporated into the submitted work . Item 5 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . 3 : Any content ( text , image , data ) from an AI tool must be cited according to APA standards ( https : / / libguides . mcmaster . ca / cite - gen - ai / apa ) . This applies to in - text citations and references ( i . e . para - phrasing , quoting , or incorporating any content from an AI tool into your own work ) . Item 4 : I am obliged to use AI tools in a responsible manner . This means that as part of the appendix I submit with course assignments , I must explicitly comment on actions taken to mitigate and / or acknowledge the known limitations of the AI tools . In the course a total of 17 group written articles were submitted . To rate compliance , two raters reviewed the article appendices and rated them for compliance using the following 4 - point scale : ‘nothing’ ( 0 ) with no text relating to the speciﬁc item , ‘incomplete’ ( 1 ) with text relating to the speciﬁc item but addressing less than half of what was requested , ‘partially complete’ ( 2 ) with text that addressed more than half but not all of what was requested , and ‘complete’ ( 3 ) the text fully addressed what was requested in the learning agreement item . In total , 51 ratings were performed and there was high agreement with initial ratings ( 86 . 27 % ) . Disagreements were resolved through discussion . Table 2 shows the results of group written article adherence to the items in the learning agreement . Results suggest that students adhered to the article requirement but not the learning agreement terms . Although , it should be noted that a score of zero was assigned when no speciﬁc text addressed the item in the student artefact . The zero score does not distinguish the cases in which students did not feel it was necessary to add speciﬁc text . For example , 7 of the 17 groups declared that they did not use GenAI to support their work . Hence , it is possible that they did not feel obliged to elaborate on Item 3 ( Appropriate citations ) and Item 4 ( Responsible usage ) . Only 1 of the 10 groups that did declare use of GenAI provided prompts used via a link to a ChatGPT thread , and none of these groups cited OpenAI in their text or as part of their listed references . Also , only 1 of the 10 groups explicitly acknowledged GenAI limitations , including biases in the training data , the reliability of AI - generated content , and fairness in AI - powered writing systems . Table 2 Adherence to the Learning Agreement in Student Artefacts ( Group Article Assignment ) Item 2 : Declaration Item 3 : Citation Item 4 : Responsible Use Nothing ( 0 ) 0 100 % ( 17 ) 70 . 6 % ( 12 ) Incomplete ( 1 ) 17 . 6 % ( 3 ) 0 11 . 8 % ( 2 ) Partially complete ( 2 ) 41 . 2 % ( 7 ) 0 5 . 9 % ( 1 ) Complete ( 3 ) 41 . 2 % ( 7 ) 0 11 . 8 % ( 2 ) In reviewing reasons provided by the 7 groups for not using GenAI , one group mentioned not using GenAI for content generation due to its perceived deﬁciency in understanding human values thereby hindering its utility for the assignment . Speciﬁcally , they stated : ”The ethical implications of AI require a deep under - standing of human values and moral complexities . AI lacks the ability to make moral decisions , empathise with others , and understand context . A human perspective is essential for understanding complex social and ethical issues . ” A second group expressed concerns that relying on AI for writing assistance would compro - mise essential skills , such as writing proﬁciency . Speciﬁcally , they stated : ”Developing a set of basic skills independent of AI technology is crucial . Writing is a valuable skill that should be developed and maintained . ” The other 5 groups did not provide reasons . 3 . 2 . Pre - post survey ﬁndings The ﬁnal sample size of the pre - post surveys was 53 . This is a decrease from the initial sample size of 73 due to students not completing both pre - and post - surveys . In this sample , the mean age of the students was 17 . 98 years old , and the SD was 0 . 91 . The majority of the students were Spanish ( 94 . 34 % ) with a small number of students coming from Africa ( 1 student ) , South America ( 1 student ) and Asia ( 1 student ) . The ﬁnal sample is composed of 60 . 4 % male students and 39 . 6 % female students . Students completed these questionnaires at the start and end of the course . During the course they were encouraged to utilise GenAI 6 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . tools to help them with their work . The analysis of their responses ( see Figure 1 ) reveals notable shifts in attitudes towards GenAI , reﬂecting the impact of hands - on experience and exposure during the course . Results show that students reported a signiﬁcant increase in their familiarity with GenAI tools ( mPre = 3 . 09 , SD = 0 . 9 ; mPost = 3 . 91 , SD = 0 . 88 , p < 0 . 05 ) . Students reported a signiﬁcant increase in their use of GenAI tools to assist with their schoolwork ( mPre = 2 . 85 , SD = 1 . 3 , mPost = 3 . 57 , SD = 1 . 2 , p < 0 . 05 ) . A signiﬁcant increase in the belief that students should have the option to use GenAI tools in university courses was identiﬁed ( mPre = 3 . 60 , SD = 0 . 9 ; mPost = 4 . 13 , SD = 0 . 81 , p < 0 . 05 ) . However , there was no signiﬁcant change in the belief that students should have the option to opt out of using GenAI in class ( mPre = 3 . 53 , SD = 1 . 14 ; mPost = 3 . 92 , SD = 1 . 02 , p > 0 . 05 ) . A signiﬁcant increase was observed in students’ plans to use GenAI to support their learning in university courses ( mPre = 3 . 13 , SD = 0 . 94 ; mPost = 3 . 74 , SD = 0 . 94 , p < 0 . 05 ) . Students did not exhibit a signiﬁcant change in their belief that grading criteria should diﬀer for students using AI tools versus those who do not ( mPre = 2 . 43 , SD = 1 . 26 ; mPost = 2 . 53 , SD = 1 . 19 , p > 0 . 05 ) . Lastly , students expressed a signiﬁcant decrease in the belief that each course should have a learning agreement related to the use of GenAI ( mPre = 4 . 45 , SD = 0 . 77 ; mPost = 4 . 00 , SD = 0 . 85 , p < 0 . 05 ) . Although , student ratings still averaged 4 out of 5 on a Likert scale in the post survey suggesting continued support for the learning agreement approach . Figure 1 Results of the 7 pre - post closed questions ( 5 - point Likert scale ) on Generative AI 3 . 3 . Thematic analysis of student suggestions Students’ responses to “How can the learning agreement and its use in this course be made more useful 7 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . for future years ? ” were analysed following a thematic approach . Two authors of the study coded the text responses following a codebook ( Table 3 ) . In the following we report the inter - rater agreement for each code individually using Cohen’s Kappa at the end of the ﬁrst round of coding across nine codes / categories . e . g . , Improve clarity k = 0 . 562 ( Moderate agreement ) ; More class discussion k = 0 . 586 ( Moderate agreement ) ; No modiﬁcations k = 0 ( No agreement ) ; More student - centred k = 0 ( No agreement ) ; More strictly enforced k = 0 . 382 ( Fair agreement ) ; Adapt to the context k = 1 . 00 ( Almost perfect agreement ) ; Keep it updated k = 0 . 465 ( Moderate agreement ) ; Other k = 1 . 00 ( Almost perfect agreement ) ; Easier to read k = 0 . 633 ( Almost perfect agreement ) . As it can be seen , No modiﬁcations and More student - centred codes did not reach agreement between the two coders at the end of the ﬁrst round of coding . Improve clarity , More class discussion , Keep it updated codes reached Moderate agreement . More strictly enforced code reached a Fair agreement . All disagreements were thoroughly discussed and resolved during a second round of coding to reach a consensus . Results of the thematic analysis reveal that a relatively high number of students indicated that no modi - ﬁcations are required ( 16 . 67 % ) , a few students did not provide an opinion ( 3 . 33 % ) , some felt that strictly enforcing the terms of the existing agreement would improve it ( 8 . 33 % ) , while others mentioned the need to keep adapting the learning agreement to the context of speciﬁc courses and current societal views on GenAI ( 5 % ) . 51 . 66 % of suggested improvements related to helping students better understand and adhere to the learning agreement . Examples include improving the clarity ( 28 . 33 % ) of the learning agreement with speciﬁc examples , providing additional time in class to discuss it in more detail ( 18 . 33 % ) , incorporating regular reviews and updates to the learning agreement to facilitate adherence ( 3 . 33 % ) , and making the text more concise to increase readability ( 1 . 67 % ) . 11 . 67 % of suggested improvements related to better supporting student autonomy and participation in deﬁning and applying the learning agreement . In other words , they suggest making the learning agreement more student - centred rather than teacher - centred ( 11 . 67 % ) . Table 3 Coding Scheme used to analyse students’ post - activity questionnaire responses Code Explanation Count Improve clarity Provide speciﬁc examples of accepted and not accepted uses as well as limitations . E . g . , Although I think it is useful enough , maybe the way to improve it would be by making this learning agreement more speciﬁc . Specifying on what is correct and what is not . So students can avoid misunderstandings . 17 ( 28 . 33 % ) More class discussion Allocate more time to discuss this topic in class . E . g . , Maybe it should be talked a little bit more in class and put more examples to make it more useful for students . 11 ( 18 . 33 % ) No modiﬁcations No modiﬁcations are needed to the existing learning agreement . E . g . , I believe it was very well explained , and I don’t think it should be modiﬁed . 10 ( 16 . 67 % ) 8 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . More student - centred Make it more student - centred by shifting the focus towards individual student goals and needs . E . g . , It could improve by giving students more margin to decide how they want to do their work to appeal to their creativity . 7 ( 11 . 67 % ) More strictly enforced Enforce the terms of the agreement . E . g . , I think that if everything is clearly stated and sanctions are imposed more strictly it will be more useful for everyone . 5 ( 8 . 33 % ) Adapt to the context Update the learning agreement between courses so that the ”new” learning agreement has been adapted to changes in technology , society , course goals , etc . E . g . , Adapting to the situation of the moment and to what you’re applying it ; it’s impossible to have a learning agreement for everything , it must have some diﬀerences between them so they are better applied . 3 ( 5 % ) Facilitate adherence Come back to the learning agreement regularly in the course to help students update it and / or ensure they are adhering with it . E . g . , What it can be done is to incorporate a system for regular reviews and updates of the learning agreement . This allows us to track our progress , make necessary adjustments , and ensure we are on the right path towards achieving our goals . 2 ( 3 . 33 % ) Other No suggestions given . E . g . , I don’t know 2 ( 3 . 33 % ) Improve readability Make the text easier and quicker to read . E . g . , From my point of view , it is ﬁne and well - clariﬁed . However , it could be easier and quicker to read , it could go more directly to the main point . 1 ( 1 . 67 % ) 4 . Discussion A recent publication ( Author , 2024 ) presented an analysis of the pre - survey responses . Results show inequal - ity in the level of familiarity with and prior use of GenAI by students . Furthermore , students expressed a 9 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . desire for autonomy in being able to choose whether to use GenAI or not , with the vast majority agreeing that students should retain an option to opt out of its use . Finally , most were uncertain whether they were going to use GenAI or not in the course , perhaps due to a lack of certainty over what types of uses were permitted . In the end , 58 . 8 % of the groups declared using GenAI in the group written article . A recent study of 6 , 300 university students in Germany found that 63 . 4 % of students reported using AI - based tools for their studies ( von Garrel & Mayer , 2023 ) which is consistent with our ﬁndings when considering that the rate in our study was not for individual use but for use within a speciﬁc group assignment . While two - ﬁfths of the groups declared not using GenAI , overall , students reported a signiﬁcant increase in their familiarity with GenAI tools , their use of GenAI tools to assist with their schoolwork , and in their plans to use GenAI to support their future learning at the university . This aligns with ﬁndings from previous work , where students acknowledge ChatGPT , as a valuable complementary learning resource and describe it as helpful for learning ( S´anchez - Reina et al . , 2024 ; Shoufan , 2023 ) . Also , by the end of the course , no signiﬁcant changes were found in student beliefs related to students having the option to opt out of using GenAI in class , nor to beliefs that grading criteria should diﬀer for students using AI tools versus those who do not . In relation to the ﬁrst research question , R1 . Would ﬁrst - year students be accepting of a course learning agreement on GenAI use ? , pre - survey results show the vast majority of students supported the use of a course learning agreement for governing GenAI in higher education ( M = 4 . 45 , SD = . 77 ) . Most utterances ( 86 . 1 % ) related to either preventing students from being unfairly disadvantaged or helping students learn to use AI properly as reported by Beardsley et al . ( 2024 ) which provide insights into student expectations of the learning agreement . At the end of the course , student support had decreased signiﬁcantly but still averaged 4 out of 5 on a Likert scale ( M = 4 . 00 , SD = . 85 ) , suggesting continued support for the learning agreement approach but , perhaps , a failure to meet student expectations . In relation to the second research question , R2 . Would students adhere to the terms of the learning agreement in their group assignment ? , all student groups did make a declaration involving technologies used , yet none felt the need to cite their use of GenAI tools , and only 1 of the 10 groups that did declare use of GenAI acknowledged its limitations as agreed upon in the learning agreement . Hence , it appears students did not adhere to all items in the learning agreement – especially items 3 and 4 . Findings related to the third research question , R3 . After experiencing a course learning agreement , how would students improve on its use ? , provide insight into possible reasons for low adherence for these items . The lack of speciﬁc examples of what is not permitted , class time for further discussion of issues related to the learning agreement , and opportunities to re - engage with the learning agreement may have contributed to the lower post rating – as these were suggestions for improvement . Additionally , several utterances related to student motivation to adhere to the learning agreement with some ( 8 . 33 % ) suggesting a stricter enforcement of the learning agreement terms being needed while others ( 11 . 67 % ) suggesting the approach should be more participative and supportive of student autonomy . The latter aligning more closely with self - determination theory and nicely encapsulated by one student’s response , The focus of the learning agreement should be on the student’s goals and needs , rather than on the instructor’s expectations . Also , making it more accountable , where the student should be responsible for meeting the goals that they have set for themselves , and the instructor should be responsible for providing the support that the student needs to achieve those goals . 4 . 1 . Limitations Findings of this study are inherently bound to a speciﬁc context and time frame , inﬂuencing the generali - zability of results . First and foremost , the study’s insights are derived from a ﬁrst - year university course , thereby reﬂecting the attitudes and experiences of students at a particular stage in their academic journey . Students’ perceptions and acceptance of GenAI , as well as their engagement with the learning agreement , are likely inﬂuenced by their previous experiences , including their exposure to similar technologies during their high school education . Attitudes toward GenAI use in educational settings are dynamic and likely to evolve over time . The period during which this study was conducted saw students transitioning from an environment where GenAI tools might have been banned to one where such technologies are increasingly embraced , not only in higher education but potentially in future high school settings as well . This evolution 10 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . suggests that the study’s ﬁndings , while insightful for the current cohort , may not fully encapsulate the changing landscapes of GenAI acceptance and use among incoming students . Additionally , the reliance on a single course for data collection limits the ability to draw broader conclusions about the eﬀectiveness and reception of the learning agreement across diverse academic disciplines and educational contexts . 4 . 2 . Future work Beyond ChatGPT , other GenAI tools and models such as Midjourney , Stable Diﬀusion and DALL - E 2 that automatically generate videos , and images within minutes ; Eleven Labs that transforms text into audio ; and Magic Write that assist creative writing ( Peres et al . , 2023 ) , can potentially inﬂuence students’ everyday use of AI to assist their coursework . The full potential of GenAI in general and speciﬁcally on education is still unknown and underpins a need to investigate its impact in a manner that considers students’ points of view ( Gaˇsevi´c et al . , 2023 ) and their development . Accordingly , eﬀorts to better align and assess the eﬀectiveness of the learning agreement from a self - determination theory perspective should be explored . For example , the UNESCO guide providing an overview of how ChatGPT works and can be used in higher education , highlights the importance of autonomy in suggesting that guidance on “how and when ChatGPT can be used ( and when it cannot ) . . . should be negotiated with students and teachers , not imposed on them” ( Sabzalieva & Valentini , 2023 ; p . 13 ) . Investigating eﬀects on student feelings of autonomy in comparison to other ways of communicating academic integrity and course policies can be explored . The same UNESCO guide suggests that GenAI should relate to course learning outcomes to help students understand how it “can support their learning and what expectations there are for them” ( Sabzalieva & Valentini , 2023 ; p . 13 ) . Thereby , helping students develop a competence around ﬁguring out how it can best serve their needs and around what uses align with their value systems . Future work can investigate the eﬀectiveness of diﬀerent learning agreement designs and implementations in terms of impact on student decision making – and pair the use of learning agreements with approaches to help students make more thoughtful decisions ( Arvai et al . , 2004 ) related to GenAI use . This support of thoughtful decision making can also explore and assess how eﬀective learning agreements are as tools for raising awareness of ethical concerns as identiﬁed by researchers , policy makers , and the public . Concerns such as discrimination – and the need for transparency and accountability ( Nguyen et al . , 2023 ; Akgun & Greenhow , 2022 ; Miao & Holmes , 2021 ) ; an increasing digital divide – accessibility limits due to internet availability and / or regional access restrictions ( Sabzalieva & Valentini , 2023 ; Miao & Holmes , 2021 ) ; concentration of power and abuse of power ( Sabzalieva & Valentini , 2023 ) ; surveillance and intrusiveness ( Miao & Holmes , 2021 ; Akgun & Greenhow , 2022 ) ; loss of autonomy ( Nguyen et al . , 2023 ; Akgun & Greenhow , 2022 ) ; obstructing holistic competencies ( Chan & Hu , 2023 ) ; and lack of ecological sustainability ( Nguyen et al . , 2023 ) . In relation to the last aspect of self - determination theory , relatedness , future work can compare learning agreement construction and use at individual and group levels to investigate the impact of relatedness on student decision making and understanding of the ethical concerns related to GenAI use . Finally , the design and implementation of the learning agreement can be improved following the suggestions made by students which align with research related to improving the eﬀectiveness of another type of agreement , informed consent forms . Improving readability , including causal explanations , and supporting understanding with enhanced discussions can help overcome cases in which student prior knowledge of the items in the learning agreement are impoverished ( Beardsley et al . , 2019 ) . 5 . Conclusion The motivation of this work was to explore whether a learning agreement can be an acceptable tool for governing student use of GenAI in university coursework . Results of the pilot study , with students rating the learning agreement approach favourably at the end of the course , suggest that despite the ﬂaws in how it was implemented , a learning agreement has potential to serve this role . Furthermore , the design of the learning agreement and course modiﬁcations presented oﬀer a ﬂexible path through which students can be brought to engage with ethical discussions surrounding the use of GenAI in a situated and relevant manner . Such agreements can go beyond university guidelines as they can be used to both scaﬀold educator adaptations 11 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . of guidelines to match course needs and the rapidly changing technological landscape and communicate the adaptations to students in an actionable manner . All in all , learning agreements have the potential to oﬀer an interface through which student decision - making can be supported and interactions among students , educators , researchers , and policy makers related to the ethical and societal challenges of GenAI can take place . Acknowledgements This work has been partially funded by UPF’s PlaCLIK ( E2023015714 ) , Erasmus + ( KA220 - SCH - 92001A07 ) , the Government of Catalonia ( SGR 00930 ) , Spanish Ministry ( PID2020 - 112584RB - C33 granted by MICIN / AEI / 10 . 13039 / 501100011033 ) . DHL ( Serra H´unter ) acknowledges the support by ICREA ( Aca - demia ) . References Ahuja , J . ( 2009 ) . Evaluating the learning experience of non medical prescribing students with their designated medical practitioners in their period of learning in practice : results of a survey . Nurse Education Today , 29 ( 8 ) , 879 - 885 . https : / / doi . org / 10 . 1016 / j . nedt . 2009 . 05 . 004 Akgun , S . & Greenhow , C . Artiﬁcial intelligence in education : Addressing ethical challenges in K - 12 settings . AI Ethics 2 , 431 – 440 ( 2022 ) . https : / / doi . org / 10 . 1007 / s43681 - 021 - 00096 - 7 Alekseeva , L . , Azar , J . , Gine , M . , Samila , S . , & Taska , B . ( 2021 ) . The demand for AI skills in the labor market . Labour Economics , 71 , 102002 . https : / / doi . org / 10 . 1016 / j . labeco . 2021 . 102002 Arvai , J . L . , Campbell , V . E . , Baird , A . , & Rivers , L . ( 2004 ) . Teaching students to make better decisions about the environment : Lessons from the decision sciences . The Journal of Environmental Education , 36 ( 1 ) , 33 - 44 . https : / / doi . org / 10 . 3200 / JOEE . 36 . 1 . 33 - 44 Beardsley , M . , Amarasinghe , I . , & Hern´andez - Leo , D . ( 2024 ) . Toward a Learning Agreement for Generative AI Use : First - Year University Student Perspectives . In Proceedings of the 17th International Conference on Computer - Supported Collaborative Learning - CSCL 2024 . Beardsley , M . , Santos , P . , Hern´andez - Leo , D . , & Michos , K . ( 2019 ) . Ethics in educational technology re - search : Informing participants on data sharing risks . British Journal of Educational Technology , 50 ( 3 ) , 1019 - 1034 . https : / / doi . org / 10 . 1111 / bjet . 12781 Bozkurt , A . , Xiao , J . , Lambert , S . , Pazurek , A . , Crompton , H . , Koseoglu , S . , Farrow , R . , Bond , M . , Nerantzi , C . , Honeychurch , S . & Bali , M . , 2023 . Speculative futures on ChatGPT and generative artiﬁcial intelligence ( AI ) : A collective reﬂection from the educational landscape . Asian Journal of Distance Education , 18 ( 1 ) . https : / / www . asianjde . com / ojs / index . php / AsianJDE / article / view / 709 Bustamante , M . F . , Pascual , R . F . , & Aguilera , S . G . ( 2010 , November ) . New learning and teaching strategies in an European higher education context . In 2010 International Conference on Education and Management Technology ( pp . 260 - 262 ) . IEEE . https : / / doi . org / 10 . 1109 / ICEMT . 2010 . 5657658 ChatGPT and Generative AI in the Classroom – Oﬃce of the Vice - Provost , Innovations in Undergraduate Education . ( n . d . ) . https : / / www . viceprovostundergrad . utoronto . ca / strategic - priorities / digital - learning / special - initiative - artiﬁcial - intelligence / Chan , C . K . , & Hu , W . ( 2023 ) . Students’ voices on Generative AI : Perceptions , beneﬁts , and chal - lenges in Higher Education . International Journal of Educational Technology in Higher Education , 20 ( 1 ) . https : / / doi . org / 10 . 1186 / s41239 - 023 - 00411 - 8 12 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . Chiu , T . K . ( 2024 ) . Future research recommendations for transforming higher education with generative AI . Computers and Education : Artiﬁcial Intelligence , 6 , 100197 . https : / / doi . org / 10 . 1016 / j . caeai . 2023 . 100197 Chiu , T . K . ( 2023 ) . The impact of Generative AI ( GenAI ) on practices , policies and research di - rection in education : A case of ChatGPT and Midjourney . Interactive Learning Environments , 1 - 17 . https : / / doi . org / 10 . 1080 / 10494820 . 2023 . 2253861 Clear , T . , McDermott , R . , Parsjo , E . , Cajander , A . , Daniels , M . , & Lagerqvist , N . ( 2016 , October ) . A framework for writing learning agreements . In 2016 IEEE Frontiers in Education Conference ( FIE ) ( pp . 1 - 8 ) . IEEE . https : / / doi . org / 10 . 1109 / FIE . 2016 . 7757718 Deci , E . L . , Olafsen , A . H . , & Ryan , R . M . ( 2017 ) . Self - determination theory in work organizations : The state of a science . Annual Review of Organizational Psychology and Organizational Behavior , 4 , 19 - 43 . https : / / doi . org / 10 . 1146 / annurev - orgpsych032516 - 113108 Farrokhnia , M . , Banihashem , S . K . , Noroozi , O . , & Wals , A . ( 2023 ) . A SWOT analysis of ChatGPT : Implications for educational practice and research . Innovations in Education and Teaching International , 1 - 15 . https : / / doi . org / 10 . 1080 / 14703297 . 2023 . 2195846 Flanagin , A . , Bibbins - Domingo , K . , Berkwits , M . , & Christiansen , S . L . ( 2023 ) . Nonhuman “authors” and implications for the integrity of scientiﬁc publication and medical knowledge . Journal of the American Medical Association , 329 ( 8 ) , 637 – 639 . https : / / doi . org / 10 . 1001 / jama . 2023 . 1344 Gaˇsevi´c , D . , Siemens , G . , & Sadiq , S . ( 2023 ) . Empowering learners for the age of artiﬁcial intelligence . Computers and Education : Artiﬁcial Intelligence , 4 , 100130 . Gatrell , C . , Muzio , D . , Post , C . , & Wickert , C . ( 2024 ) . Here , there and Everywhere : On the Responsible Use of Artiﬁcial Intelligence ( AI ) in Management Research and the Peer - Review Process . Journal of Management Studies . https : / / doi . org / 10 . 1111 / joms . 13045 Generative AI Policy Guidance . ( n . d . ) . Oﬃce of Community Standards . https : / / communitystandards . stanford . edu / generative - ai - policy - guidance Guidance for the use of Generative AI – UCLA Center for the Advancement of Teaching . ( n . d . ) . https : / / teaching . ucla . edu / resources / ai _ guidance / Gupta , M . , Akiri , C . , Aryal , K . , Parker , E . , Praharaj , L . , ( 2023 ) ‘From chatgpt to threat - gpt : Impact of generative AI in cybersecurity and privacy’ , IEEE Access , 11 , pp . 80218 – 80245 . http : / / doi . org / 10 . 1109 / access . 2023 . 3300381 Habib , S . , Vogel , T . , Anli , X . , & Thorne , E . ( 2024 ) . How does generative artiﬁcial intelligence impact student creativity ? . Journal of Creativity , 34 ( 1 ) , 100072 . https : / / doi . org / 10 . 1016 / j . yjoc . 2023 . 100072 Hern´andez - Leo , D . ( 2023 ) ChatGPT and Generative AI in Higher Education : user - centered perspectives and implications for learning analytics , LASI Spain , Madrid , https : / / ceur - ws . org / Vol - 3542 / paper2 . pdf Hryciw , B . N . , Seely , A . J . , & Kyeremanteng , K . ( 2023 ) . Guiding principles and proposed classiﬁcation system for the responsible adoption of artiﬁcial intelligence in scientiﬁc writing in medicine . Frontiers in Artiﬁcial Intelligence , 6 . https : / / doi . org / 10 . 3389 % 2Ffrai . 2023 . 1283353 LibGuides : References , citations and avoiding plagiarism : Acknowledging and referencing AI . ( n . d . ) . https : / / library - guides . ucl . ac . uk / referencing - plagiarism / acknowledging - AI Lucchi , N . ( 2023 ) . ChatGPT : a case study on copyright challenges for generative artiﬁcial intelligence systems . European Journal of Risk Regulation , 1 - 23 . https : / / doi . org / 10 . 1017 / err . 2023 . 59 McAdoo , T . ( n . d . ) . How to cite ChatGPT . https : / / apastyle . apa . org . https : / / apastyle . apa . org / blog / how - to - cite - chatgpt 13 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . McKee , R . F . ( 2008 ) . The intercollegiate surgical curriculum programme ( ISCP ) . Surgery ( Oxford ) , 26 ( 10 ) , 411 - 416 . https : / / doi . org / 10 . 1016 / J . MPSUR . 2008 . 08 . 007 Miao , F . , & Holmes , W . ( 2021 ) . Artiﬁcial Intelligence and Education . Guidance for Policy - makers . https : / / doi . org / 10 . 54675 / PCSP7350 Miao , F . , & Holmes , W . ( 2023 ) . Guidance for generative AI in education and research . https : / / www . unesco . org / en / articles / guidance - generative - ai - education - and - research Moorhouse , B . L . , Yeo , M . A . , & Wan , Y . ( 2023 ) . Generative AI tools and assessment : Gui - delines of the world’s top - ranking universities . Computers and Education Open , 5 , 100151 . htt - ps : / / doi . org / 10 . 1016 / j . caeo . 2023 . 100151 Nielsen , J . C . , Skrubbeltrang , L . S . , Olesen , J . S . , & Karen , D . ( 2022 ) . Cooperation between schools and elite sports . How are schools aﬀected from engaging in athletic talent development ? . International Studies in Sociology of Education , 31 ( 3 ) , 325 - 346 . https : / / doi . org / 10 . 1080 / 09620214 . 2020 . 1847167 Nguyen , A . , Ngo , H . N . , Hong , Y . , Dang , B . , & Nguyen , B . P . T . ( 2023 ) . Ethical princip - les for artiﬁcial intelligence in education . Education and Information Technologies , 28 ( 4 ) , 4221 - 4241 . https : / / doi . org / 10 . 1007 / s10639 - 022 - 11316 - w O’Connor , C . , & Joﬀe , H . ( 2020 ) . Intercoder reliability in qualitative research : debates and practical guidelines . International Journal of Qualitative Methods , 19 , 1609406919899220 . htt - ps : / / doi . org / 10 . 1177 / 1609406919899 Padillah , R . ( 2023 ) ‘Ghostwriting : A reﬂection of academic dishonesty in the Artiﬁcial Intelligence Era’ , Journal of Public Health [ Preprint ] . https : / / doi . org / 10 . 1093 / pubmed / fdad169 Parilla , P . F . , & Hesser , G . W . ( 1998 ) . Internships and the sociological perspective : Applying principles of experiential learning . Teaching Sociology , 310 - 329 . https : / / doi . org / 10 . 2307 / 1318771 Peres , R . , Schreier , M . , Schweidel , D . , & Sorescu , A . ( 2023 ) . On ChatGPT and beyond : How generative arti - ﬁcial intelligence may aﬀect research , teaching , and practice . International Journal of Research in Marketing , 40 ( 2 ) , 269 – 275 . https : / / doi . org / 10 . 1016 / j . ijresmar . 2023 . 03 . 001 Tang , A . , Li , K . K . , Kwok , K . O . , Cao , L . , Luong , S . , & Tam , W . ( 2023 ) . The importance of transparency : Declaring the use of generative artiﬁcial intelligence ( AI ) in academic writing . Journal of Nursing Scholarship . https : / / doi . org / 10 . 1111 / jnu . 12938 Sabzalieva , E . , & Valentini , A . ( 2023 ) . ChatGPT and artiﬁcial intelligence in higher education : quick start guide . https : / / eduq . info / xmlui / handle / 11515 / 38828 S´anchez - Reina , R . , Theophilou , E . , Ognibene , D . , & Hern ` andez - Leo , D . ( 2023 ) . ”Shall we rely on bots ? ” Stu - dents’ adherence to the integration of ChatGPT in the classroom . In HELMeTO 2023 Book of Abstracts ( pp . 128 - 130 ) . Sharples , M . ( 2022 ) . Automated essay writing : An AIED opinion . International Journal of Artiﬁcial Intelli - gence in Education , 32 ( 4 ) , 1119 - 1126 . https : / / doi . org / 10 . 1007 / s40593 - 022 - 00300 - 7 Shoufan , A . ( 2023 ) . Exploring Students’ Perceptions of CHATGPT : Thematic Analysis and Follow - Up Sur - vey . IEEE Access . https : / / doi . org / 10 . 1109 / ACCESS . 2023 . 3268224 UCL . ( 2023 , September 18 ) . Using generative AI ( GenAI ) in learning and teaching . Tea - ching & Learning . https : / / www . ucl . ac . uk / teaching - learning / publications / 2023 / sep / using - generative - ai - genai - learning - and - teaching UCL . ( 2023b , September 25 ) . Using AI tools in assessment . Teaching & Learning . https : / / www . ucl . ac . uk / teaching - learning / generative - ai - hub / using - ai - tools - assessment 14 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . University of Tartu guidelines for using AI chatbots for teaching and studies . ( 2023 , April 28 ) . https : / / ut . ee / sites / default / ﬁles / 2023 - 05 / university _ of _ tartu _ guidelines _ for _ using _ ai _ chatbots _ - for _ teaching _ and _ studies _ 28 _ april _ 2023 _ pdf . pdf von Garrel , J . , & Mayer , J . ( 2023 ) . Artiﬁcial Intelligence in studies—use of ChatGPT and AI - based tools among students in Germany . Humanities and Social Sciences Communications , 10 ( 1 ) , 1 - 9 . https : / / doi . org / 10 . 1057 / s41599 - 023 - 02304 - 7 Wallis , E . ( 2013 ) . Learning agreements and socially responsible approaches to professional and human resource development in the United Kingdom . In Union Learning Representatives ( pp . 73 - 88 ) . Routled - ge . https : / / doi . org / 10 . 1080 / 13674580802328111 Zhou , J . , Zhang , Y . , Luo , Q . , Parker , A . G . , & De Choudhury , M . ( 2023 , April ) . Synthetic lies : Understanding ai - generated misinformation and evaluating algorithmic and human solutions . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( pp . 1 - 20 ) . https : / / doi . org / 10 . 1145 / 3544548 . 3581318 Appendix Learning Agreement for GenAI - v1 ( 1st Year Engineering Degree Course ) Introduction : Innovations aﬀect how we learn , work , and live . Recent innovations such as generative artiﬁcial intelligence ( AI ) may lead to more rapid changes than we have previously experienced ( e . g . , ChatGPT , Bard , DALL - E – see a recent list of tools ) . In this course , we hope to support your lifelong learning . We want to help you gain experience in using innovative technologies ( that can beneﬁt your future career ) in a responsible manner – and for you to help us improve our deﬁnition of what responsible use means . WHY ? Despite the promises of recent innovations such as AI tools , there are a number of concerns . ( 1 ) Learners may use AI to do their assignments without learning the material . This does not support lifelong learning . ( 2 ) Learners may use AI in a manner that worsens societal problems such as inequality , distrust , polarization . ( 3 ) Learners may use AI in a manner that unintentionally violates ( University ) rules for academic integrity and risk suspension / expulsion from the university . WHAT ? This form is a learning agreement . Its aim is to clarify the course rules and expectations surrounding the responsible use of AI tools so that all students and instructors share a common understanding . Instructions Read through this form carefully and submit an initial version prior to class ( B1 - 3 ) . In class , ask questions to clarify any points of confusion . Your instructor will lead a discussion on the form . At the end of class , submit a ﬁnal version ( you can edit your initial submission to make a ﬁnal version of your learning agreement ) . Agreement terms Students are encouraged to use AI tools to contribute to their learning in the course ( i . e . , as learning aids or to help produce designated assignments ) . However , students using such tools are only permitted to do so in accordance with the terms outlined in this form . A failure to do so may result in a violation of university rules for academic integrity and risk suspension / expulsion from the university . In the ( Course Name ) course , I am only permitted to use innovative technologies to assist with my course work if I agree to all 5 terms in this form : ( 1 ) Not for assessments , ( 2 ) Declared and described usage , ( 3 ) Appropriate citations , ( 4 ) Responsible usage , ( 5 ) Informed usage . For each item , mark your selection : [ ] I understand that in this ( Course Name ) course AI tools cannot be used during assessment and opinion survey tasks unless speciﬁed otherwise by your instructor . [ ] I would like to discuss this further in class . 15 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . Item # 1 : Not for Assessments Assessments help us understand whether students have learned course material . Opinion surveys help us understand your views on topics . The use of AI for assessment and opinion survey tasks can defeat the purpose of such tasks . However , AI tools may be useful when gathering information to support your studying for these assessments ( prior to starting the assessment tasks ) . If you are not sure whether AI tools can be used for a speciﬁc assignment , please ask your instructor . - In the ( Course Name ) course , I am not to use AI tools when taking assessments ( e . g . , quiz , test - taking ) or completing opinion surveys . The use of AI tools in these circumstances will be treated as if I am getting help or copying another person which are violations of ( University’s ) academic integrity policy . Item # 2 : Declared and described usage AI tools can be used to assist in the completion of key course assignments ( article , debate , presentation ) and other assignments explicitly designated by your instructors . However , any AI tool usage must be declared and described in an appendix submitted with your assignments . - In the ( Course Name ) course , whenever an AI tool is used , the use of the tool must be declared and described in an appendix submitted with the course assignment . The appendix must ( 1 ) document what tool ( s ) were used , ( 2 ) how the tools were used ( i . e . , prompts used ) , and ( 3 ) how the results from the AI tools were incorporated into the submitted work . Item # 3 : Appropriate citations and references Any content ( text , image , data ) from an AI tool must be cited according to APA standards ( https : / / libguides . mcmaster . ca / cite - gen - ai / apa ) . This applies to in - text citations and references ( i . e . para - phrasing , quoting , or incorporating any content from an AI tool into your own work ) . For example , if you copy and paste AI - generated text directly to your assignment , you must add quotations around the text , ”the inﬂuence of beavers on their environment can be both constructive and destructive , contingent on the particular context” ( OpenAI , 2023 ) . APA citation format : Author / Developer . ( Year ) . Model name ( Version ) [ Large language model ] . URL Example : OpenAI . ( 2022 ) . ChatGPT ( December 20 version ) [ Large Language model ] . https : / / chat . openai . com / In the ( Course Name ) course , if I fail to appropriately cite AI tools , it will be considered a form of plagiarism and a violation of ( University’s ) academic integrity policy . Item # 4 : Responsible usage AI tools are known to have limitations and may have problematic ethical origins and / or intentions . Biases : Biases in datasets used to train AI can perpetuate social inequalities and injustices . Privacy : Datasets used to train AI may violate data privacy and intellectual property rights . AI tools may also collect , store , and use user data for undisclosed purposes . Misinformation : AI tools are known to fabricate facts and can be used to spread disinformation . Power and responsibility : Popular AI tools are closed ( not transparent ) , proprietary models that consume massive amounts of resources ( natural , ﬁnancial ) and have the power to shape public opinion . In the ( Course Name ) course , I am obliged to use AI tools in a responsible manner . This means that as part of the appendix I submit with course assignments , I must explicitly comment on actions taken to mitigate and / or acknowledge the known limitations of the AI tools . Item # 5 : Informed usage Usage of AI tools involves the sharing of personal data and , possibly , intellectual property with third parties . Conﬁdential information should never be inputted into an AI tool as “all content entered may become part of the tool’s dataset and may inadvertently resurface in response to other prompts” . In the ( Course Name ) course , I have the option to use AI tools , but I do not have to use them if I am not comfortable with sharing data with third parties . 16 P o s t e d o n 18 M a r 20 24 | CC - B Y - S A 4 | h tt p s : / / d o i . o r g / 10 . 36227 / t ec h r x i v . 171078030 . 08340862 / v 1 | e - P r i n t s p o s t e d o n T ec h R x i v a r e p r e li m i n a r y r e p o rt s t h a t a r e n o t p ee r r e v i e w e d . T h e y s h o u l d n o t b . . . Final page AI innovations are evolving rapidly . It is our aim to co - create ( with you ) guidelines for how to best integrate AI into university coursework . Please share any additional thoughts you have about this agreement below . 17