Creative Zombie Apocalypse : A Critique of Computer Creativity Evaluation Fania Raczinski Institute of Creative Technologies De Montfort University The Gateway Leicester , LE1 9BH Email : fania . raczinski @ dmu . ac . uk Dave Everitt Institute of Creative Technologies De Montfort University The Gateway Leicester , LE1 9BH Email : dave . everitt @ dmu . ac . uk Abstract —Using algorithms to generate creative work is a well - established transdisciplinary practice that spans several ﬁelds . Accessible and popular coding tools such as Processing and Open Frameworks , as well as the rise of hack spaces have signiﬁcantly contributed to increased activity in this ﬁeld . However , beyond art - technology curation and historical contextualisation , evalua - tion of the resulting artefacts is in its infancy , although several general models of creativity—and its evaluation—exist . There is a perceived distinction between human and computer creativity , whereas we argue that they are effectively the same thing . Computers are made and programmed by people , so it makes sense to measure the creativity of the human inﬂuence behind the machine , rather than viewing computers as truly autonomous entities . By concatenating and enhancing existing models of creativity , we propose a framework that takes these issues into account , with a view to evaluating creative work that uses the computer as a medium more effectively . Index Terms —Creativity , creative computing , evaluation I . I NTRODUCTION Although using computers to generate creative work has its foundations in the 1950s [ 1 ] , John Maeda’s Design By Numbers [ 2 ] and from around 2010 a slew of similar ini - tiatives followed Processing’s lead . However , due in part to the niche position of artists working with technology , and also because such activity was overlooked or ignored until relatively recently by arts bodies and critics , formal evaluation of the creativity in such work lagged behind . In this context humans simply use computers as tools for their creativity—no matter how autonomous the machine output may appear , or how far it travels from the original intentions of the programmer , its origins nevertheless reside in the humanly - authored code that produces the output . This is overlooked in anthropomorphic approaches that regard computers as being capable of creativity in their own right . Computer output cannot be conceptually separated from the craft / skill / intention of the programmer , even when the results are unexpected or accidental . The illusion of creativity can be produced by introducing randomness , serendipity , etc . but this is not the same as the intuitive decision - making that drives human creativity . Hypothetical “zombies” ( popularised by philosopher David Chalmers [ 3 ] ) are entities that appear identical to humans in every way but lack conscious experience . We now borrow this term and apply it to computers which appear creative but lack real autonomous intent . Further , creativity and the subjective properties associated with it , lack a universally accepted deﬁnition . As a hu - man quality it has deﬁnitions that don’t necessarily lend themselves to be applied to computers . However , there are several important theories and evaluation frameworks con - cerning human and computer creativity , and these are the basis for our work . Creativity has been studied at various levels ( neurological , cognitive , and holistic / systemic ) , from different perspectives ( subjective and objective ) and existing research has identiﬁed speciﬁc characteristics ( combinational , exploratory and transformative ) . Some aspects , like novelty and value , recur in many models of creativity but some , like relevance and variety , rarely appear ; while other terms are problematic when it comes to computing . Computer systems are generally evaluated against functional requirements and performance speciﬁcations , but creativity should be seen as a continuum , there is no clear cut - off point or Boolean answer to say precisely when a person or piece of software has become creative or not . “The expression of our language systems in com - puter code confers no semantic understanding au - tonomously on the computer system . The computer system only acts as a tool for transferring symbols and communicating meaning between humans . ” [ 4 ] True Artiﬁcial Intelligence and true Computational Cre - ativity are equally elusive . For a computer to become truly intelligent and therefore creative , it would need to break out of the programming procedures by which it operates . Yet it is bound to follow rules , no matter how emergent the outcome . The paradox is that it needs to recognise its contraints in order to break free from them . Yet programatically deﬁning yet more rules to allow that to happen—even when those rules enable machine learning—is tautological ! II . E MERGING D ISCIPLINES Initiatives that aim at a more rigorous understanding of computing and creativity have given rise to several ﬁelds , each 2016 IEEE Symposium on Service - Oriented System Engineering 978 - 1 - 5090 - 2253 - 3 / 16 $ 31 . 00 © 2016 IEEE DOI 10 . 1109 / SOSE . 2016 . 30 270 having its own terminology and approach , but with signiﬁcant overlaps . The two main disciplines directly related to creativity and technology that have emerged in recent years are as follows . “Creative Computing” tries to reconcile the objective precision of computer systems with the subjective ambiguity of human creativity [ 5 ] and has an overarching theme of unite and conquer , i . e . drawing from a wide range of transdisciplinary knowledge to tackle a problem ( as opposed to the principle of divide and conquer in computer science , which divides bigger problems down into smaller and easier parts ) [ 6 ] . The main challenge , Andrew Hugill and Hongji Yang argue , is for technology to become “more adaptive , smarter and better engineered to cope with frequent changes of direction , incon - sistencies , irrelevancies , messiness and all the other vagaries that characterise the creative process” [ 5 ] . In part , these issues are due to the transdisciplinary nature of Creative Computing ; factors such as common semantics , standards , requirements and expectations are typical challenges . Hugill and Yang therefore argue that creative software should be ﬂexible and able to adapt to ever - changing requirements , evaluated and re - written continuously , and it should be cross - compatible . “Computational Creativity” has emerged from within Artiﬁ - cial Intelligence ( AI ) research . Simon Colton and Geraint Wig - gins argue that AI falls within a problem - solving paradigm : “an intelligent task , that we desire to automate , is formulated as a particular type of problem to be solved” , whereas “in Computational Creativity research , we prefer to work within an artefact generation paradigm , where the automation of an intelligent task is seen as an opportunity to produce something of cultural value” [ 7 ] . They further explain that it models , simulates , replicates or enhances human creativity using a computer . III . E XISTING T HEORIES OF C REATIVITY Richard Mayer identiﬁed ﬁve big questions of human creativity research and different approaches with their own methodologies and goals [ 8 ] ; is creativity : 1 ) a property of people , products , or processes ? 2 ) a personal or social phenomenon ? 3 ) common or rare ? 4 ) domain - general or domain - speciﬁc ? 5 ) quantitative or qualitative ? These questions form a nice introduction to the four main theories of creativity which inspired our work . The Four P model by Mel Rhodes [ 9 ] identiﬁed four elements of creativity : ( 1 ) the person —personality , intellect , temperament , physique , traits , habits , attitudes , self - concept , value systems , defence mechanisms and behaviour , ( 2 ) the process —motivation , perception , learning , thinking and com - munication , ( 3 ) the press —relationship between human beings and their environment and ( 4 ) the product —a thought which has been communicated to other people in the form of words , paint , clay , metal , stone , fabric , or other material . Rhodes highlights the importance of a holistic view on creativity through these four areas of study , which he hoped would become the basis of a uniﬁed theory of creativity . Ross Mooney independentely identiﬁed four aspects of creativity which he called the environment , person , process and product ( as cited in [ 10 ] ) . Margaret Boden deﬁned three types of creativity : ( 1 ) combi - national —making unfamiliar combinations of familiar ideas , juxtaposition of dissimilar , bisociation , deconceptualisation , ( 2 ) exploratory —exploration of conceptual spaces , notic - ing new things in old spaces and ( 3 ) transformational — transformation of space , making new thoughts possible by altering the rules of old conceptual space [ 11 ] . Boden also differentiates between two levels of creativity , a personal one and a historical one . Psychological creativity ( “P - creativity” ) is a personal kind of creativity that is novel in respect to an individual , while historical creativity ( “H - creativity” ) is fundamentally novel in respect to the whole of human history . James Kaufman and Ronald Beghetto deﬁned the Four C model of creativity [ 12 ] . They are Big - C —eminent accom - plishments , Pro - c —professional expertise , Little - c —everyday innovation and Mini - c —transformative learning . The concepts of the uppercase C and lowercase c loosely correspond to Boden’s H and P creativity , which in turn could be interpreted as objective and subjective creativity . Henri Poincar´e suggested a Four Stage model [ 13 ] ( formu - lated by Graham Wallas [ 14 ] ) . The four stages are preparation , incubation , illumination and veriﬁcation . This is reminiscent of George P´olya’s description of the problem solving process [ 15 ] —understand , plan , carry out , look back . Bipin Indurkhya argued that there are two main cognitive mechanisms of creativity : juxtaposition of the dissimilar , and deconceptualization . He said that we are constrained by as - sociations in the concept networks we inherit and learn in our lifetime , but that computers do not have these conceptual associations and therefore have an advantage when it comes to creative thinking [ 16 ] . IV . E XISTING E VALUATION F RAMEWORKS Evaluating human creativity objectively seems problematic ; evaluating computer creativity at all seems even harder . There are many debates across the disciplines involved . Taking theories on human creativity and directly applying them to machines seems logical but may be the wrong ( anthropomor - phic ) approach . Adapting Mayer’s ﬁve big questions [ 8 ] to machines does not seem to capture the real issues at play . Instead of asking if creativity is a property of people , products , or processes we might ask if it is a property of any or all of the following : • programmers ( and collaborators ) • users ( audiences and participants ) • machines ( this is problematic until the posited AI singu - larity [ 17 ] ) • products ( i . e . does a program output material that can be judged to be creative ) • processes ( e . g . a Processing sketch , or in a self - modifying / learning program ) 271 For instance , is the programmer the only creative agent , or are users ( i . e . audiences or participants in interactive work ) able to modify the system with their own creative input ? Similarly for any instance of machine creativity , we might ask if it is : • local ( e . g . limited to a single machine or program ? ) • networked ( i . e . interacts with other predeﬁned machines ) • web - based ( e . g . is distributed and / or open to interactions , perhaps via an API ) For example , discussions from computational creativity of - ten focus on very basic questions such as “whether an idea or artefact is valuable or not , and whether a system is acting creatively or not” [ 18 ] . Pease , Winterstein and Colton have argued that creativity may be seen as output minus input [ 19 ] . The output in this case is the creative product but the input is not the process . Rather , it is the inspiring set ( comprised of explicit knowledge such as a database of information and implicit knowledge input by a programmer ) of a piece of software . Simon Colton speciﬁes that “the degree of creativity in a program is partly determined by the number of novel items of value it produces . Therefore we are interested in the set of valuable items produced by the program which exclude those in the inspiring set . ” [ 20 ] . Alison Pease et al . also suggest that all creative products must be novel and valuable [ 19 ] and provide several measures that take into consideration the context , complexity , archetype , surprise , perceived novelty , emotional response and aim of a product , although the measurement of these qualities isn’t explicitely described . In terms of the creative process itself they only discuss randomness as a measurable approach . Else - where , Pease et al . discuss using serendipity as an approach [ 21 ] . Graeme Ritchie supports the view that creativity in a computer system must be measured “relative to its initial state of knowledge” [ 22 ] . He identiﬁes three main criteria for creativity as novelty , quality and typicality , although he argues that “novelty and typicality may well be related , since high novelty may raise questions about , or suggest a low value for , typicality” [ 22 ] , [ 23 ] . He proposes several evaluation criteria which fall under the following categories : basic suc - cess , unrestrained quality , conventional skill , unconventional skill , avoiding replication and various combinations of those [ 22 ] . Dan Ventura later suggested the addition of variety and efﬁciency to Ritchie’s model [ 24 ] . It should be noted that output minus input might easily be misinterpreted as “product minus process” , however , that is not the case . In fact , Pease , Winterstein and Colton argue that “the process by which an item has been generated and evaluated is intuitively relevant to attributions of creativity” , and that “two kinds of evaluation are relevant ; the evaluation of the item , and evaluation of the processes used to generate it” [ 19 ] . If a machine simply copies an idea from its inspiring set then it just cannot be considered creative and needs to be disqualiﬁed , so to speak . Simon Colton came up with an evaluation framework called the creative tripod [ 25 ] , [ 26 ] . The tripod consists of three behaviours a system or artefact should exhibit in order to be called creative . The three legs represent skill , appreciation , and imagination and three different entities can sit on it , namely the programmer , the computer and the consumer . Colton argues that if “the software has been skillful , apprecia - tive and imaginative , then , regardless of the behaviour of the consumer or programmer , the software should be considered creative” . As such a product can be considered creative if it appears to be creative . If all three behaviours are not exhibited , however , it should not be considered creative . “Imagine an artist missing one of skill , appre - ciation or imagination . Without skill , they would never produce anything . Without appreciation , they would produce things which looked awful . Without imagination , everything they produced would look the same . ” [ 25 ] Davide Piffer suggests that there are three dimensions of human creativity that can be measured , namely novelty , use - fulness / appropriateness and impact / inﬂuence [ 27 ] . As an example of how this applies to measuring a person’s creativity he proposes “citation counts” . While this idea perhaps works well for measuring scientiﬁc impact , it seems questionable whether popularity or social status can be a valid measure of creative quality . Anna Jordanous proposed 14 key components of creativity ( which she calls an “ontology of creativity” ) [ 28 ] , from a linguistic analysis of creativity literature which identiﬁed words that appeared signiﬁcantly more often in discussions of creativity compared to unrelated topics . These are active involvement and persistence , generation of results , uncer - tainty , domain competence , general intellect , independence and freedom , intention and emotional involvement , originality , progression and development , social interaction and commu - nication , spontaneity / subconscious processing , thinking and evaluation , value , variety , divergence and experimentation . Jor - danous also argued that “evaluation of computational creativity is not being performed in a systematic or standard way” [ 29 ] ; an issue which further confuses the problem of objective eval - uation . To remedy this she proposes a “Standardised Procedure for Evaluating Creative Systems” ( SPECS ) [ 30 ] : 1 ) Identify a deﬁnition of creativity that your system should satisfy to be considered creative . 2 ) Using Step 1 , clearly state what standards you use to evaluate the creativity of your system . 3 ) Test your creative system against the standards stated in Step 2 and report the results . The SPECS model essentially means that we cannot evalu - ate a creative computer system objectively , unless steps 1 and 2 are predeﬁned and publically available for external assessors to execute step 3 . Creative evaluation can therefore be seen as a move from subjectivity to objectivity , i . e . deﬁning subjective criteria for objectively evaluating a product in terms of the initial criteria . “For transparent and repeatable evaluative prac - tice , it is necessary to state clearly what standards are 272 used for evaluation , both for appropriate evaluation of a single system and for comparison of multiple systems using common criteria . ” [ 30 ] This is further strengthened by Richard Mayer stating that we need a “clearer deﬁnition of creativity” [ 8 ] and Linda Candy arguing for “criteria and measures [ for evaluation ] that are situated and domain speciﬁc . ” [ 31 ] Candy draws inspiration for the evaluation of ( interactive ) creative computer systems from Human Computer Interaction ( HCI ) research . The focus of evaluation in HCI has been on usabilty , she says , which may not be as useful in creativity research . She argues that in order to successfully evaluate an artefact , the practitioner needs to have “the necessary informa - tion including constraints on the options under consideration” [ 31 ] . Evaluation happens at every stage of the process ( i . e . from design → implementation → operation ) . Some of the key aspects of evaluation highlighted by Candy are aesthetic ap - preciation , audience engagement , informed considerations and reﬂective practice . She then goes on to introduce the “Multi - dimensional Model of Creativity and Evaluation” ( MMCE ) [ 31 ] with four main elements of people , process , product and context similar to some of the models of creativity we have seen above ( e . g . the Four P model ) . V . T HOUGHTS AND C RITIQUE “The uncodiﬁable must be reduced to the cod - able in the robot . In reducing a complex moral decision ( tacit , intuitive , deriving knowledge from maturity ) to the execution of a set of coded in - structions , we are throwing away vast stretches of knowledge , socialisation and learning not only built up in the individual , but also in the community and the history of that community , and replacing it with some na¨ıve ‘yes’ or ‘no’ decisions . ” [ 4 ] Neil McBride’s observation is echoed by Indurkhya , who argues that because computers don’t make decisions based on personal or cultural concepts ( even when these are included in code ) , they are more likely to make connections that humans will perceive as “creative leaps” [ 16 ] . These leaps appear creative only because we are athropomorphising not only the output , but in some cases even also the intent behind it , as if this originated in the computer itself rather than as an output from algorithmic processes . This phenomenon is most apparent in the “uncanny valley” created by those areas of robotics that seek to create human companions , or where the intent is to imbue the computer with a personality . This is even the case for simple web interfaces , let alone computers that might mimic human creativity : “Automatic , mindless anthropomorphism is likely to be activated when anthropomorphic cues are present on the interface . [ . . . ] it is noteworthy that anthropomorphic cues do not have to be fancy in order to elicit human - like attributions . ” [ 32 ] The phenomenon of ascribing human qualities to non - human artefacts and machines depends on the prior associ - ations ( concept networks ) humans have with certain activities , including creativity . It leads to metaphorical statements such as “this interface is friendly” , “a bug snuck into my code” or “the computer is being creative” , and appears in media article head - lines such as “Patrick Tresset’s robots draw faces and doodle when bored” [ 33 ] , as if there were conscious intent behind the code generating such activity in Tresset’s sketching bot Paul . This tendency has implications for the aimed - for objectivity when evaluating certain creative computing projects , one the most well - established being Harold Cohen’s AARON , artist - authored software that produces an endless output of images in his own unique style . While documenting the process of coding his system , Cohen asked : “How far could I justify the claim that my com - puter program—or any other computer program—is , in fact , creative ? I’d try to address those questions if I knew what the word ‘creative’ meant : or if I thought I knew what anyone else meant by it . [ . . . ] ‘Creative’ is a word I do my very best never to use if it can be avoided . [ . . . ] AARON is an entity , not a person ; and its unmistakable artistic style is a product of its entitality , if I may coin a term , not its personality . ” [ 34 ] He goes on to outline four elements of behaviour X ( his placeholder for creativity ) : ( 1 ) emergence produced from the complexity of a computer program , ( 2 ) awareness of what has emerged , ( 3 ) willingness to act upon the implications of what has emerged , and ( 4 ) knowledge of the kind manifest in expert systems . He identiﬁes three of these properties as programmable ( within limits ) , but “as to the second element , the program’s awareness of properties that emerge , unbidden and unanticipated , from its actions . . . well , that’s a problem . ” [ 34 ] , and concludes that “it may be true that the program can be written to act upon anything the programmer wants , but surely that’s not the same as the individual human acting upon what he wants himself . Isn’t free will of the essence when we’re talking about the appearance of behaviour X in people ? ” . In other words , a decision tree in computing is not the same as a human decision - making process . As for whether his life’s work is autonomously creative : “I don’t regard AARON as being creative ; and I won’t , until I see the program doing things it couldn’t have done as a direct result of what I had put into it . That isn’t currently possible , and I am unable to offer myself any assurances that it will be possible in the future . On the other hand I don’t think I’ve said anything to indicate deﬁnitively that it isn’t possible . ” [ 34 ] In the same manner as in the ﬁeld of computer ethics , i . e . “the ethics of the robot must be the ethics of the maker” [ 4 ] , the creative computer must ultimately be a product of the creativity of the programmer . To hijack Barthes’ conclusion in “The Death of the Author” : the birth of the truly creative computer must be ransomed by the death of the programmer [ 35 ] —in other words , a truly creative computer must be able to act without human input , yet any computer process presumes 273 TABLE I O BJECTIVE C RITERIA OF C REATIVITY Criteria Note Product Algorithmic sketch , poetry , audio , interactive installation Process Procedural , Experimental , Heuristic , Systems - based Purpose Accidental , Conceptual , Interactive , Time - based Person Skill , Aesthetic values , Inﬂuences , Collaborations Place Culture , Social environment , Education , Peers a signiﬁcant amount of human input in order to produce such so - called autonomous behaviour , so the question is whether that behaviour can ever be regarded as truly autonomous—no matter how independant it appears to be . Initiatives like the Human Brain Project suggest that we are far from the capacity to reproduce the level of operations necessary to even mimic a human brain “the 1 PFlop machine at the J¨ulich Supercomputing Centre could simulate up to 100 million neurons—roughly the number found in the mouse brain . ” [ 36 ] . Even if it were possible today to scale this up to the human brain , would the result be an entity capable of truly intelligent creative activity , or would it actually be a zombie ? Current evaluation methodologies in creative computing disciplines have concentrated on only a handful of the facets previously discussed , for example studying only the creative end - product itself ( out of context ) , only judging it by its objective novelty , assigning an arbitrary thresholds , etc . This also includes the assumption that machines “mimic” humans and are therefore not judged at their full potential . For example we generally do not take into account the differences between humans and machines or , more precicely , the differences between the human brain and computer processors . In fact , it could be said that we are in danger of limiting computers so that they appear more human . VI . O UR P ROPOSED F RAMEWORK All of the theories of creativity and its evaluation mentioned above have value , but each alone may be incomplete and contain overlaps . There is a misconception that creativity can be measured objectively and quantiﬁably , but given the issues discussed above , it is unlikely that any system will yield truly accurate measurements in practice , even if such accuracy were possible . As J¨urgen Schmidhuber suggests in the quote below , evaluation of creativity always happens from a subjective standpoint , originating in either the individual , or in the enveloping culture of which they are part . “Any objective theory of what is good art must take the subjective observer as a parameter . ” [ 37 ] We therefore propose two facets of a new fuzzy approach that aims to obtain a more honest measure of the subjective judgements implied when evaluating creativity : 1 ) a set of scales that can be used to approximate a “rating” for the creative value of an artefact , 2 ) a set of criteria to be considered using the scales above . TABLE II S UBJECTIVE S CALES FOR C REATIVITY Keyword Scale Novelty Established ↔ Novel Value Playful ↔ Purposive Quality Minimal ↔ Complex Purpose Emotive ↔ Thoughtful Spatial Universal ↔ Speciﬁc Temporal Instant ↔ Persistent Ephemeral Accidental ↔ Experimental The criteria listed in table I should be considered objec - tively , while the scales in table II are judged subjectively . The set of scales is directly derived from the various frameworks for evaluating creativity reviewed in the previous sections . An overview of recurring keywords in existing approaches suggests the following distillation of seven groups : Novelty originality , newness , variety , typicality , imag - ination , archetype , surprise Value usefulness , appropriateness , appreciation , rel - evance , impact , inﬂuence Quality skill , efﬁciency , competence , intellect , accept - ability , complexity Purpose intention , communication , evaluation , aim , in - dependence Spatial context , environment , press Temporal persistence , results , development , progression , spontaneity Ephemeral serendipity , randomness , uncertainty , experi - mentation , emotional response The “5 P’s”— Product , Process , Purpose , Person , Place — are all components of any creative artefact ( see table I ) . This evaluation framework can apply to any kind of creativ - ity , from the traditional arts to digital works to computational creativity . Because the scale element allows for the mea - surement of subjective qualities , it circumvents binary yes / no or check - box approaches and therefore makes it possible to gather quantitative values from the subjective judgements involved in evaluating creativity in general . The terms on each end of the scales are suggestions only and should not be taken as value judgements . Rather , they should be adapted for each project individually . Numeric values can be assigned to the scales if needed according to speciﬁc evaulative requirements . A . An example application Below is an example assessment for a hypothetical piece of art : PRODUCT : Established —————x— – Novel Playful ———— – x—— Purposive Minimal — - x————— - Complex Emotive — - x————— - Thoughtful 274 Universal ————— - x— - Speciﬁc Instant ———— – x—— Persistent Accidental ———— - x—— - Experimental PROCESS : Established —x————— – Novel Playful ————x—— – Purposive Minimal —— – x———— Complex Emotive —— - x———— - Thoughtful Universal ————— - x— - Speciﬁc Instant ————— - x— - Persistent Accidental ————x—— – Experimental PURPOSE : Established ——x———— – Novel Playful ———— - x—— - Purposive Minimal —x————— – Complex Emotive ————— - x— - Thoughtful Universal ————— – x— Speciﬁc Instant —————— - x - Persistent Accidental —————x— – Experimental PERSON : Established —x————— – Novel Playful ————— – x— Purposive Minimal —x————— – Complex Emotive ————— - x— - Thoughtful Universal — - x————— - Speciﬁc Instant ———— – x—— Persistent Accidental ———x——— – Experimental PLACE : Established —x————— – Novel Playful ——————x – Purposive Minimal ——————x – Complex Emotive —————x— – Thoughtful Universal ————— – x— Speciﬁc Instant ————— - x— - Persistent Accidental – x—————— Experimental Ideally , these scales would need to be applied by several people during the evaluation process , generating an intuitive assessment of the various values ( e . g . Playful—Purposive ) for each of the criteria ( e . g . Product ) . VII . C ONCLUSION Creativity is a transdisciplinary activity and is apparent in many diverse ﬁelds , yet it is often studied from within a single discipline within which other perspectives and theories can be overlooked . Therefore , creative evaluation is subjective , and involves an emotional component related to the satisfaction of a set of judgements . These judgements are mutable when subjected to personal , social and cultural inﬂuence , so we can only try to evaluate a creative activity objectively via approximisations . True AI and Computational Creativity are equally elusive . Just as the Turing Test [ 38 ] is ﬂawed ( because it is designed to fool humans into thinking a machine is a person , but only through mimickry ) , the view that something is creative because it appears creative is similarly ﬂawed . This is the premise behind by John Searle’s Chinese Room Argument [ 39 ] where an individual with a map of English to Chinese symbols can appear to someone outside the room to “know” Chinese . By inference , just because a computer program appears to produce a creative output , this doesn’t mean that it is inherently creative—it just follows the rules that produce output from a human creation in an automated manner . To take this further , we could even state that machines programmed to mimick human creativity and produce artefacts that appear creative are—in the philosophical manner deﬁned by David Chalmers— Zombies [ 3 ] . Similarly Douglas Hofstadter argues that minds cannot be reduced to their physical building blocks ( or their most basic rules ) in his “Conversation with Einstein’s Brain” [ 40 ] . This school of thought is employed to demonstrate that mind is not just physical brain . We are introducing it here to argue that computers do not consciously create as do humans , because they are not conscious . Edsger Dijkstra pointed out that computer science is in - fantalised [ 41 ] and there is a danger that the same thing is happening to creativity research . In other words , it may be an over - simpliﬁcation to reduce creativity down to a four step process , or a product that is novel , valuable and of high quality . A framework that makes the evaluation of creativity appear to be a matter of checking boxes is surely missing the subjective nature of creativity . The real picture is far more interwoven and—although creativity may spring from a ﬁnite set of causes—these can interact in a complex manner that cannot be assessed so neatly . “User of tools are much more prevelant than makers of tools . This imbalance has traditionally been rooted in the vast difference in skill levels required for using a tool compared to making a tool : To use a tool on a computer , you need to do little more than point and click . To create a tool , you must understand the arcane art of computer programming . A strange reverse phenomenon is in motion today : As programming becomes easier and more accesible , the tools for expression are becoming more complex and diffuclt to use . Programming tools are increas - ingly oriented toward ﬁll - in - the - blank approaches to the construction of code , making it easy to create programs but resulting in software with less origi - nality and fewer differentiating features . ” [ 42 ] To sum up our approach : rather than a linear or cyclic series , or criteria that can be answered in a binary manner ( i . e . present or not ) we propose scales or spectra to aid in the evaluation of a creative artefact of any kind , by applying a series of overlapping principles that encourages a more intuitive assessment . The next stage for this approach would be to test the eval - 275 uation framework with real - world examples and individuals responsible for creative output or its assessment , for instance : artists , dancers , musicians , arts administrators , critics , curators and commentators . If anything that falls short of true computational creativity is considered a zombie , then as long as computers continue to be regarded as autonomously creative , we may already be trapped in a zombie apocalypse . R EFERENCES [ 1 ] L . Candy and E . Edmonds , Eds . , Interacting : Art , Research and the Creative Practitioner . Libri Publishing , 2011 . [ 2 ] J . Maeda , Design by Numbers . MIT Press , 2001 . [ 3 ] D . Chalmers , The Conscious Mind . Oxford University Press , 1996 . [ 4 ] N . McBride , “A Robot Ethics : The EPSRC Principles and the Ethical Gap , ” in AISB / IACAP World Congress 2012 Framework for Respon - sible Research and Innovation in AI , no . July , 2012 , pp . 10 – 15 . [ 5 ] A . Hugill and H . Yang , “The creative turn : new challenges for com - puting , ” International journal of Creative Computing , vol . 1 , no . 1 , pp . 4 – 19 , 2013 . [ 6 ] H . Yang , “Editorial , ” International journal of Creative Computing , vol . 1 , no . 1 , pp . 1 – 3 , 2013 . [ 7 ] S . Colton and G . A . Wiggins , “Computational Creativity : The Final Frontier ? ” in Proceedings of the 20th European Conference on Artiﬁcial Intelligence . IOS Press , 2012 , pp . 21 – 26 . [ 8 ] R . E . Mayer , “Fifty Years of Creativity Research , ” in Handbook of Creativity , R . J . Sternberg , Ed . Cambridge University Press , 1999 , ch . 22 , pp . 449 – 460 . [ 9 ] M . Rhodes , “An analysis of creativity , ” The Phi Delta Kappan , vol . 42 , no . 7 , pp . 305 – 310 , 1961 . [ 10 ] R . J . Sternberg , Handbook of creativity . Cambridge University Press , 1999 . [ 11 ] M . Boden , The Creative Mind : Myths and Mechanisms . Routledge , 2003 . [ 12 ] J . C . Kaufman and R . A . Beghetto , “Beyond big and little : The four c model of creativity , ” Review of General Psychology , vol . 13 , no . 1 , pp . 1 – 12 , 2009 . [ 13 ] H . Poincar´e , The Value of Science , S . J . Gould , Ed . Modern Library , 2001 . [ 14 ] G . Wallas , The Art of Thought . Jonathan Cape , 1926 . [ 15 ] G . P´olya , How To Solve It , 2nd ed . Princeton University Press , 1957 . [ 16 ] B . Indurkhya , “Computers and creativity , ” 1997 , unpublished manuscript . Based on the keynote speech ’On Modeling Mechanisms of Creativity’ delivered at Mind II : Computational Models of Creative Cognition . [ 17 ] J . Schmidhuber , “New millennium ai and the convergence of history , ” 2006 . [ 18 ] A . Pease and S . Colton , “On impact and evaluation in Computational Creativity : A discussion of the Turing Test and an alternative proposal , ” in Proceedings of the AISB , 2011 . [ 19 ] A . Pease , D . Winterstein , and S . Colton , “Evaluating Machine Creativ - ity , ” in Proceedings of ICCBR Workshop on Approaches to Creativity , 2001 , pp . 129 – 137 . [ 20 ] S . Colton , A . Pease , and G . Ritchie , “The Effect of Input Knowledge on Creativity , ” 2001 . [ 21 ] A . Pease , S . Colton , R . Ramezani , J . Charnley , and K . Reed , “A Discussion on Serendipity in Creative Systems , ” in Proceedings of the 4th International Conference on Computational Creativity , vol . 1000 . University of Sydney , 2013 , pp . 64 – 71 . [ 22 ] G . Ritchie , “Some Empirical Criteria for Attributing Creativity to a Computer Program , ” Minds and Machines , vol . 17 , no . 1 , pp . 67 – 99 , 2007 . [ 23 ] —— , “Assessing creativity , ” in AISB ’01 Symposium on Artiﬁcial Intelligence and Creativity in Arts and Science . Proceedings of the AISB’01 Symposium on Artiﬁcial Intelligence and Creativity in Arts and Science , 2001 , pp . 3 – 11 . [ 24 ] D . Ventura , “A Reductio Ad Absurdum Experiment in Sufﬁciency for Evaluating ( Computational ) Creative Systems , ” in 5th International Joint Workshop on Computational Creativty , 2008 . [ 25 ] S . Colton , “Creativity versus the perception of creativity in computa - tional systems , ” in In Proceedings of the AAAI Spring Symp . on Creative Intelligent Systems , 2008 . [ 26 ] —— , “Computational Creativity , ” AISB Quarterly , pp . 6 – 7 , 2008 . [ 27 ] D . Piffer , “Can creativity be measured ? An attempt to clarify the notion of creativity and general directions for future research , ” Thinking Skills and Creativity , vol . 7 , no . 3 , pp . 258 – 264 , 2012 . [ 28 ] A . K . Jordanous and B . Keller , “Weaving creativity into the Semantic Web : a language - processing approach , ” in Proceedings of the 3rd International Conference on Computational Creativity , 2012 , pp . 216 – 220 . [ 29 ] A . K . Jordanous , “Evaluating Evaluation : Assessing Progress in Compu - tational Creativity Research , ” in Proceedings of the Second International Conference on Computational Creativity , 2011 . [ 30 ] —— , “Evaluating Computational Creativity : A Standardised Procedure for Evaluating Creative Systems and its Application , ” Ph . D . dissertation , University of Sussex , 2012 . [ 31 ] L . Candy , “Evaluating Creativity , ” in Creativity and Rationale : Enhanc - ing Human Experience by Design , J . Carroll , Ed . Springer , 2012 . [ 32 ] Y . Kim and S . S . Sundar , “Anthropomorphism of computers : Is it mindful or mindless ? ” Computers in Human Behavior , vol . 28 , no . 1 , pp . 241 – 250 , 2012 . [ 33 ] M . Brown . ( 2011 , Jun ) Patrick tressets robots draw faces and doodle when bored ( wired uk ) . [ Online ] . Available : http : / / www . wired . co . uk / news / archive / 2011 - 06 / 17 / sketching - robots [ 34 ] H . Cohen . ( 1999 ) Colouring without seeing : A problem in machine creativity . [ Online ] . Available : http : / / www . kurzweilcyberart . com / aaron / hi essays . html [ 35 ] R . Barthes , “The death of the author , ” Aspen 5 , 6 , 1967 , the birth of the reader must be ransomed by the death of the Author . [ Online ] . Available : http : / / www . ubu . com / aspen / aspen5and6 / threeEssays . html # barthes [ 36 ] R . Walker , “The Human Brain Project , ” HBP - PS Consortium , Tech . Rep . , 2012 . [ 37 ] J . Schmidhuber , “Developmental robotics , optimal artiﬁcial curiosity , creativity , music , and the ﬁne arts , ” Connection Science , vol . 18 , no . 2 , pp . 173 – 187 , 2006 . [ 38 ] A . Turing , “Computing Machinery and Intelligence , ” Mind , vol . 59 , pp . 433 – 460 , 1950 . [ Online ] . Available : http : / / loebner . net / Prizef / TuringArticle . html [ 39 ] J . Searle , “Minds , Brains , and Programs , ” Behavioral and Brain Sci - ences , vol . 3 , no . 3 , pp . 417 – 457 , 1980 . [ 40 ] D . Hofstadter , “A Conversation with Einstein’s Brain , ” in The Mind’s I , D . Hofstadter and D . Dennett , Eds . Basic Books , 1981 , ch . 26 , pp . 430 – 460 . [ 41 ] E . W . Dijkstra , “On the cruelty of really teaching computing science , ” 1988 . [ Online ] . Available : http : / / www . cs . utexas . edu / users / EWD / transcriptions / EWD10xx / EWD1036 . html [ 42 ] J . Maeda , Creative Code . Thames & Hudson , 2004 . 276