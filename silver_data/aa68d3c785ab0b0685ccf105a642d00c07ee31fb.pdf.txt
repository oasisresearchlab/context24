Evaluation of Sketch - Based and Semantic - Based Modalities for Mockup Generation TOMMASO CALÒ , Politecnico di Torino , Italy LUIGI DE RUSSIS , Politecnico di Torino , Italy Design mockups are essential instruments for visualizing and testing design ideas . However , the process of generating mockups can be time - consuming and challenging for designers . In this article , we present and evaluate two different modalities for generating mockup ideas to support designers in their work : ( 1 ) a sketch - based approach to generate mockups based on hand - drawn sketches , and ( 2 ) a semantic - based approach to generate interfaces based on a set of predefined design elements . To evaluate the effectiveness of these two approaches , we conducted a series of experiments with 13 participants in which we asked them to generate mockups using each modality . Our results show that sketch - based generation was more intuitive and expressive , while semantic - based generative AI obtained better results in terms of quality and fidelity . Both methods can be valuable tools for UI designers looking to increase their creativity and efficiency . CCS Concepts : • Human - centered computing → Graphical user interfaces ; Interface design prototyping ; • Computing method - ologies → Machine learning ; Computer vision . Additional Key Words and Phrases : machine learning , web elements , user interface , convolutional neural network ACM Reference Format : Tommaso Calò and Luigi De Russis . 2023 . Evaluation of Sketch - Based and Semantic - Based Modalities for Mockup Generation . In Proceedings of . ACM , New York , NY , USA , 10 pages . 1 INTRODUCTION AND MOTIVATION User interface designers face daily challenges in creating designs that are effective , usable , and innovative . They often draw inspiration from existing design samples to come up with new ideas [ 9 ] . There are two main types of resources that support this process of finding inspiration [ 10 ] . The first type are design gallery platforms , such as Dribbble [ 2 ] and Behance [ 1 ] , which allow designers to browse through a collection of designs and find examples that are interesting or useful for their work . The second type are design inspirational tools that suggest examples based on certain types of design input , such as a sketch or an existing design , using algorithms to determine image similarity [ 3 , 17 , 24 , 27 ] . While these approaches can be helpful in finding inspiration , they have limitations . Browsing through design galleries can be overwhelming and lead to a shift in design ideas away from the original focus , while relying too much on examples with similar styles can lead to design fixation and hinder the originality of the work [ 13 , 19 ] . To find a balance between targeted and serendipitous inspiration , Mozaffari et al . [ 20 ] proposed a style - based generative adversarial network ( StyleGAN ) trained on a large dataset of existing interface designs . It generates a diverse yet focused set of examples based on a preliminary design input . While it can generate a diverse range of interface mockups , the user control is limited to injecting style into the latent space of the model . In other words , the user can specify certain style Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . © 2023 Association for Computing Machinery . Manuscript submitted to ACM 1 a r X i v : 2303 . 12709v1 [ c s . H C ] 22 M a r 2023 , Calò and De Russis attributes ( such as color and texture ) for the model to incorporate , but has little control over the specific layout or design elements of the mockup . A better approach would allow designers to explicitly specify the desired layout and other design elements , rather than relying on the model to randomly generate these elements based on style injection . This would enable a more targeted and precise design process , as designers can focus on specific aspects of the mockup rather than being limited to injecting style into the model . In this paper , we aim to achieve this goal by exploring two distinct AI - assisted modalities for mockup generation : one based on sketches , and the other based on semantic - colored drawings . Sketch - based mockup generation involves the use of hand - drawn sketches to represent the desired design . Semantic - colored drawing - based mockup generation , instead , involves the use of detailed , colored drawings that convey specific design elements . The choice of these two modalities was based on a careful review of the literature , indicating that sketching and semantic drawing are commonly used in the design process due to their ability to balance precision and speed [ 5 , 18 , 21 ] . Sketch - based mockup generation allows for quick exploration of ideas while semantic - colored drawing - based mockup generation provides more accuracy in representing the final product . To achieve this , we used the Pix2Pix [ 33 ] model for sketch - based mockup generation and the SPADE [ 22 ] model for semantic - colored drawing - based mockup generation . The Pix2Pix model is well suited for sketch - based mockup generation because it is a conditional GAN that has been proven to be effective in generating high - quality images from sketches [ 30 ] . Similarly , the SPADE model is well suited for semantic colored drawing - based mockup generation as it is a GAN that is trained to generate images from semantic maps , it allows for more control over specific design elements , which is crucial for conveying accurate representations of the final product . We evaluate the two modalities of mockup generation in terms of their expressivity , time demand , ease , and intuitiveness . By analyzing the advantages and disadvantages of both sketch - based and semantic - colored drawing - based mockup generation , we aim to empower designers to select the most appropriate modality for their particular design project and boost their creative potential . 2 RELATED WORKS Inspiration has long been of interest to researchers in the field of psychology . Thrash et al . [ 28 , 29 ] were among the first to systematically study inspiration , identifying three categories : motivation ( i . e . , goal - oriented self - initiation ) , evocation ( i . e . , impulsive reactions to stimuli ) , and transcendence ( i . e . , feeling of gaining superior , more elegant or novel ideas than those generated willfully ) . These studies have generally focused on how designers access and utilize existing design artifacts . For instance , Eckert and Stacey [ 7 ] found that knitwear designers used a variety of sources for inspiration , including artifacts with intriguing shapes , patterns , and colors , as well as their own previous work . Researchers have also explored how industrial and user interaction designers are inspired by existing design artifacts . Bonnardel [ 4 ] found that in the context of product design , “the emergence of new ideas results from analogy - making . ” Herring et al . [ 11 ] conducted in - depth interviews with web , graphic , and product designers and identified common approaches and challenges they faced in retrieving , storing , and disseminating design examples . Gonçalves et al . [ 8 ] surveyed students and industrial designers to understand their sources and methods of inspiration and found that professional industrial designers used a wider variety of approaches compared to students . The literature has also identified several issues with common inspirational methods , including the risk of “design fixation” from exposure to a homogenous set of examples and the impact of timing on the quantity and quality of ideas . In recent years , Artificial Intelligence ( AI ) has emerged as a potential tool for supporting and enhancing the creative inspiration process [ 26 ] . AI systems can be trained to generate ideas and outputs based on a set of rules or guidelines , enabling the efficient production of a wide range of options , and providing a variety of applications and systems to support professionals in various visual art fields , such as graphic design [ 31 ] , UI design [ 32 ] , webtoon [ 14 ] , digital 2 Evaluation of Sketch - Based and Semantic - Based Modalities for Mockup Generation , art [ 34 ] , and new media art [ 23 ] . To ensure a balance between human control and computer automation [ 25 ] , some AI systems have employed a “human - in - the - loop” approach , which allows for collaboration between humans and AI . Overall , AI has been seen as a helpful tool in the design process , aiding in ideation and generating a variety of output efficiently . Our work compares two modalities , sketches and semantic - colored drawings , to generate user interface mockups and build upon previous knowledge in several ways . First , the use of sketches as a modality builds upon previous research on the use of visual representations in the design process [ 16 ] . Studies have shown that sketches can be used to quickly generate and communicate design ideas , allowing designers to explore a wide range of possibilities in a relatively short amount of time . Additionally , sketches are often used as a way to capture informal , early - stage design ideas , which can then be refined and developed further [ 15 ] . Second , the use of semantic - colored drawings [ 12 , 35 ] , where each color represents a UI element category , allows for a clear representation of the design elements and their relationships . The two modalities work together towards the goal of allowing designers to quickly generate and communicate ideas using sketches , while also leveraging the power of color coding to represent the design elements and their relationships . Both modalities combine the benefits of computer automation and human control [ 26 ] enabling the efficient production of a wide range of options while maintaining high fidelity to the original design idea . Fig . 1 . An example of the same user interface represented in the sketch - based and semantic - based modalities . On the left , we can see a hand - drawn sketch of the user interface ( A ) , with various elements such as buttons , text fields , and icons depicted in a freeform manner . On the right , we can see the same user interface represented in the semantic - based modality ( B ) . These elements are filled with different colors , with each color representing a specific design element such as buttons , text fields , and icons . 3 STUDY : EVALUATING GENERATION MODALITIES This study aimed to evaluate the semantic drawing - to - mockup and sketch - to - mockup modalities in terms of time demand , ease , creative expressivity , and intuitiveness . The study was conducted with 13 human - computer interaction students from the first - year master’s program in computer engineering . The participants were asked to use both modalities to create a mockup of a mobile application and then rate their experience with each modality on various 3 , Calò and De Russis dimensions . The results of the study provide insights into the strengths and weaknesses of each modality and can inform the design and development of mobile applications in the future . 3 . 1 Participants The study was conducted with 13 participants who gave their consent to participate in the study . All participants were studying Human - Computer Interaction ( HCI ) as part of their curriculum . It is important to note that all participants in the study had received training in UI design and programming as part of their curriculum , indicating that they had at least some level of experience in this area . The sample consisted of 2 female and 11 male participants , with an age range of 23 to 25 years old . Given that the sample is relatively small , it can be considered an exploratory study . Future studies should replicate and expand the study on a larger sample to generalize the findings . The study aimed to be a first step to understanding the differences between the two modalities . 3 . 2 Procedure Participants were asked to complete a two - phase task requiring them to design a mobile user interface by sketching and semantically drawing it . The task was designed to evaluate the participants’ abilities in terms of time demand ( time to complete ) , expressiveness ( how well the modality conveyed their idea ) , intuitiveness ( in understanding the modality ) , and ease of use ( of the modality ) . In the first phase , participants were sent a document containing instructions on how to complete the task . They were asked to design a mobile user interface and sketch in a given frame . While participants were allowed to use their preferred digital drawing tool in the study to ensure a more natural and intuitive design process , future studies may consider restricting the use of digital drawing tools to a single option to better control for potential variations in user experience . After sketching , participants were instructed to semantically draw the user interface . The order of the tasks was chosen based on the natural progression of a typical design process in which initial , unstructured ideas and concepts are often followed by more concrete iterations . This allowed us to evaluate the strengths and weaknesses of each modality in facilitating the design process , rather than comparing the effectiveness of one modality over the other . An example from the experiment , showcasing the same user interface represented in both sketch and semantic - drawing form , can be seen in Figure 1 . Once the participants had completed the task , they were asked to rate their experience in terms of the above dimensions on a Likert scale . Participants were also asked to provide motivation for their ratings . In the second phase , the participants’ drawings were processed by a network ( see “implementation” below ) , and users were asked two additional questions about the quality of the obtained results and how the results respected the imagined user interface . The participants were asked to rate the quality of the results obtained from the network on a Likert scale , and to provide feedback on how well the results corresponded to their imagined user interface . 3 . 3 Implementation To translate sketches and semantic colored drawing to mockups , we use two deep learning models : Pix2pix [ 33 ] and SPADE [ 22 ] trained on RICO [ 6 ] dataset . Pix2pix is the model we used to generate realistic mockups from sketches , while SPADE is the model we used to generate mockups from semantic - colored drawings , an illustration of the framework used to generate mockups can be found in Figure 2 . The trained models are available for download at HIDDENLINK 1 for the reproducibility of results . 1 Temporary link for preserving the anonimity during the peer - review phase . 4 Evaluation of Sketch - Based and Semantic - Based Modalities for Mockup Generation , Fig . 2 . Illustration of how Pix2pix [ 33 ] translates between sketches and real mockups domains . A generator is trained to generate mockups from sketches ( 1 ) and a discriminator is trained simultaneously to distinguish between the real and generated mockups ( 2 ) . A Reconstruction loss , in addition , measures how close the generated mockup is to the real target mockup ( 3 ) . The only difference with SPADE [ 22 ] is that in the latter a SPatially - Adaptive Normalization module is added to optimize the translation of semantic maps . 3 . 3 . 1 Dataset . In this study , we used the RICO dataset [ 6 ] for both semantic drawing - to - mockup and sketch - to - mockup modalities . The RICO dataset is a publicly available dataset of hand - drawn sketches and corresponding semantic representations of mobile app user interfaces . It is composed of a total of approximately 20k sketches and 60k semantic representations . The dataset is designed to be a benchmark for evaluating the performance of deep learning models for mobile app user interface generation . To ensure the quality of the data , we corrected the colors in the semantic representation that were corrupted and released the corrected version of the dataset on the same GitHub repository . This was done to ensure that the results of the study were not affected by any errors or inconsistencies in the data . We found the RICO dataset to be particularly useful for our study as it provided a large and diverse set of sketches and semantic representations of mobile app user interfaces . 3 . 3 . 2 Sketch - to - mockup . Pix2pix is a model that uses a conditional generative adversarial network ( cGAN ) to generate images . It consists of two networks : a generator and a discriminator . In our case , the generator takes as input a sketch and generates the corresponding mockup , while the discriminator receives both the generated image and the target image and tries to distinguish between the two . The two networks are trained simultaneously , with the generator trying to fool the discriminator and the discriminator trying to classify the images correctly . 3 . 3 . 3 Semantic drawing - to - mockup . SPADE ( Semantic Image Synthesis with SPatially - Adaptive Normalization ) is a model that uses a style - based generator architecture to generate images from semantic colored drawings . It consists of a generator network that takes as input a semantic - colored drawing and generates a corresponding image , and a discriminator network that receives both the generated image and the target image and tries to distinguish between the two . The generator network includes SPatially - Adaptive Normalization ( SPADE ) layers that adapt the normalization parameters of the generator based on the input semantic map , optimizing the image synthesis for semantic map inputs . 5 , Calò and De Russis This is achieved through the use of a separate normalization network , which takes the input image and a set of spatial locations as input and produces the normalization parameters for each location . 4 PRELIMINARY RESULTS Table 1 . Comparison of sketch - to - mockup and semantic drawing - to - mockup modalities on intuitiveness , ease , time demand , and expressiveness , as well as the quality and fidelity of the generated mockups , on a 1 to 5 Likert scale . Sketch - to - mockup Semantic drawing - to - mockup Intuitiveness 4 . 54 ± 0 . 78 3 . 15 ± 1 . 28 Ease of use 3 . 38 ± 1 . 04 3 . 69 ± 1 . 25 Time Demand 3 . 54 ± 1 . 13 3 . 77 ± 1 . 09 Expressiveness 4 . 15 ± 0 . 55 3 . 38 ± 1 . 12 Quality 1 . 50 ± 0 . 58 2 . 75 ± 0 . 50 Fidelity 3 . 38 ± 2 . 20 3 . 60 ± 0 . 55 The study compares the sketch and semantic drawing modalities by gathering participant feedback on their level of intuitiveness , ease of use , and time demand during the generation process , as well as the quality and fidelity of the generated mockups . The results of the survey provide insight into how participants perceive these modalities and their relative strengths and weaknesses . Numerical results are reported in Table 1 . Intuitiveness : The results of the comparison between the sketch and semantic drawing modalities to input an AI for generating mockups show that the sketch generation score for intuitiveness is generally higher than the semantic generation score . Most participants ( 11 out of 13 ) gave a score of 5 for the sketch generation , indicating that they found it fully intuitive . In contrast , only two participants gave a score of 5 for the semantic generation , with the majority of participants ( 8 out of 13 ) giving a score of 3 or lower . One of the main motivations for participants finding the sketch generation more intuitive is that it allows them to “show others what you have in mind” and “represent at a higher level each part of the layout” ( participant 1 , 6 ) . Another motivation is that it is easier to “imagine the layout” ( participant 9 ) and “pour the idea in mind into drawings” ( participant 10 ) with the sketch generation . However , some participants had issues with the semantic generation , finding it “difficult due to the rules about the colors” ( participant 4 ) and “not so clear how it can be useful” ( participant 1 ) . Participant 12 also found semantic generation less intuitive stating that it is not simple for everyone to understand . Conversely , some participants found the semantic generation to be more intuitive , with participant 10 stating that it is more intuitive as it has a “map ( indication ) about element types” which makes things “much easier to demonstrate graphically” . Ease of use : The results of the comparison between the sketch and semantic drawing modalities for ease of use indicate that there is no statistical significance between the mean ease of use of the two methods . Most participants ( 7 out of 13 ) gave a score of 3 or lower for the sketch generation , indicating that they found it to be difficult to use . One of the main motivations for participants finding sketch generation difficult to use is that it requires “drawing skills and tools” ( participant 9 ) and “some drawing skills are needed to convey information in a reasonable and clear way” ( participant 1 ) . Additionally , some participants found it difficult to use the mouse to draw ( participants 3 , 4 , 11 ) and some participants found it difficult to use because they had to use different devices to complete the task ( participant 13 ) . Participants found the semantic modality difficult to use because it " needs to remember the colors according to 6 Evaluation of Sketch - Based and Semantic - Based Modalities for Mockup Generation , the legend " ( participant 9 ) , while on the other hand , some participants found it easy to use because it “only requires squares and rectangles” ( participant 4 ) and is “just a mechanical exercise” ( participant 3 ) . Participant 10 also found the semantic generation easy to use because it is “much more descriptive” and “easier regarding positioning the items” as compared to sketch generation . Time demands : When it comes to time demand , participants had mixed opinions on the time efficiency of sketch and semantic drawing modalities . The main motivation for participants finding the sketch generation quicker is that it allows them to represent the layout at a higher level and it is easier to imagine the layout and that “only took me some minutes to complete” ( participant 5 ) . However , some participants experienced challenges with the sketch generation , citing issues with tools such as “difficulty drawing with a mouse” ( participant 10 ) and “difficulty in getting a decent result” ( participant 3 ) . On the other hand , the semantic generation was perceived as less time demanding by some participants , with participant 8 stating that it is “the quickest one because it’s similar to sketch generation but with even fewer details to represent” and participant 3 finding it “fairly quick to draw what I was thinking in the semantic way” . However , other participants found it to be more time demanding , with participant 1 stating that they “spent very much time in finding a software to draw colored squares” and participant 12 stating that “it can take a long time because there is often a difference between ideas and reality . ” Expressivity : The results of the comparison between the sketch and semantic drawing modalities for expressivity show that the expressivity score for the sketch generation is generally higher than the semantic generation score . Most participants ( 10 out of 13 ) gave a score of 4 or 5 for the sketch generation , indicating that they found it to be fully expressive . The majority of participants ( 7 out of 13 ) gave a score of 3 or lower for the semantic generation , indicating that they found it to be less expressive . Some of the main motivations for participants finding the sketch generation to be more expressive is that it “makes it easiest to describe how you want the final result to look like” ( participant 3 ) and “irons out some ambiguity” ( participant 5 ) . Participants also found it to be expressive because it allows them to “draw almost everything” ( participant 5 ) and “the alignments and the position of the items are easier to express” ( participant 6 ) . On the other hand , some participants found the semantic generation to be less expressive because it “just conveys information with colored and filled squares that don’t reflect very well the actual elements” ( participant 1 ) and it is “too restrictive” ( participant 4 ) . Participants also found it difficult to “define the role of each component” ( participant 7 ) . Overall , the results suggest that participants generally find the sketch generation to be more expressive for inputting mockups into an AI , but some participants also found the semantic generation to be useful , particularly for its ability to convey information through color - name association . Quality and fidelity of the generated mockups : Results indicate that the quality of the generated mockup for the sketch - to - mockup modality is higher than for the semantic drawing - to - mockup modality with a mean of 2 . 75 and 1 . 50 respectively . In terms of fidelity to the original idea , the sketch - to - mockup modality also scores higher with a mean of 3 . 60 compared to 3 . 38 for the semantic drawing - to - mockup modality . However , this difference is not as large as for the quality of the generated mockup but still statistically significant . In summary , the results indicate that the sketch - to - mockup modality generally performs better in terms of quality of the generated mockup and fidelity to the original idea compared to the semantic drawing - to - mockup modality , an example is reported in Figure 3 . However , it is worth noting that these results should be taken with caution as it is based on a small sample size , and it would be beneficial to have more data and a larger sample size to make more robust conclusion . 7 , Calò and De Russis Fig . 3 . An example of two mockups generated through semantic - drawing modality ( left ) and sketch modality ( right ) . The image demonstrates the improved resulting quality and reduced presence of artifacts achieved through the use of semantic - drawing modality . Additional Comments . In analyzing the additional comments , it is clear that there are different preferences for the best method of inputting AI to generate mockups . Participant 7 suggests that the sketch generation modality is the best , but that the problem of describing components’ function can be solved by adding a color convention to the sketch generation . This suggests that the participant values the intuitiveness and expressivity of the sketch generation modality , but also recognizes the benefits of using a semantic approach for describing the function of components . Participant 8 also prefers the sketch generation modality , citing its ability to describe the interface in more detail than the semantic method . Participant 11 suggests that an hybrid solution between the sketch and semantic modality may be a good option . Participant 11 recognizes the limitations of both modalities , specifically the lack of semantic meaning in the sketch generation and the difficulty of representing specific shapes in the semantic method , and suggests that combining them may provide the best solution . Participant 12 believes that the best method depends on the context . They also believe that there is no one method that is better than others , but they are complementary and useful to provide a complete description . 5 CONCLUSIONS AND FUTURE WORK The paper evaluated the sketch and semantic drawing modalities by gathering user feedback on their level of intuitiveness , ease of use , and time demand during the generation process , as well as the quality and fidelity of the generated mockups . The results of the study indicate that users generally found the sketch generation to be more intuitive and expressive compared to the semantic generation . The study provides insight into how users perceive these modalities and their relative strengths and weaknesses and can help inform future design decisions for AI mockup generation tools . Many users have suggested that a possible way to optimize the interaction between the user and the system would be to combine the two approaches , taking advantage of the strengths of each modality while minimizing their weaknesses . For example , by using sketching to quickly and intuitively create a rough prototype , and semantic drawing to add more detailed and expressive design elements , designers would have a more flexible and powerful tool for creating their mockups . Additionally , this approach could help designers to express their ideas and designs more easily and accurately , which may result in a better final product . 8 Evaluation of Sketch - Based and Semantic - Based Modalities for Mockup Generation , In conclusion , a mixed approach that combines sketching and semantic drawing could be a promising solution for generating mockups of mobile applications and additional research should explore this possibility . REFERENCES [ 1 ] 2022 . Behance - Search Projects : Photos , videos , logos , illustrations and branding . https : / / www . behance . net https : / / www . behance . net . [ 2 ] 2022 . Dribbble - Discover the World’s Top Designers and Creative . https : / / dribbble . com / https : / / dribbble . com / . [ 3 ] Farnaz Behrang , Steven P . Reiss , and Alessandro Orso . 2018 . GUIfetch : Supporting App Design and Development through GUI Search . In Proceedings of the 5th International Conference on Mobile Software Engineering and Systems ( Gothenburg , Sweden ) ( MOBILESoft ’18 ) . Association for Computing Machinery , New York , NY , USA , 236 – 246 . https : / / doi . org / 10 . 1145 / 3197231 . 3197244 [ 4 ] Nathalie Bonnardel . 1999 . Creativity in design activities : The role of analogies in a constrained cognitive environment . In Proceedings of the 3rd conference on Creativity & cognition . 158 – 165 . [ 5 ] Tommaso Calò and Luigi De Russis . 2022 . Style - Aware Sketch - to - Code Conversion for the Web . In Companion of the 2022 ACM SIGCHI Symposium on Engineering Interactive Computing Systems ( Sophia Antipolis , France ) ( EICS ’22 Companion ) . Association for Computing Machinery , New York , NY , USA , 44 – 47 . https : / / doi . org / 10 . 1145 / 3531706 . 3536462 [ 6 ] Biplab Deka , Zifeng Huang , Chad Franzen , Joshua Hibschman , Daniel Afergan , Yang Li , Jeffrey Nichols , and Ranjitha Kumar . 2017 . Rico : A Mobile App Dataset for Building Data - Driven Design Applications . In Proceedings of the 30th Annual Symposium on User Interface Software and Technology ( UIST ’17 ) . [ 7 ] Claudia Eckert and Martin Stacey . 2000 . Sources of inspiration : a language of design . Design Studies 21 , 5 ( 2000 ) , 523 – 538 . https : / / doi . org / 10 . 1016 / S0142 - 694X ( 00 ) 00022 - 3 [ 8 ] M Gonçalves , C Cardoso , and P Badke - Schaub . 2014 . What inspires designers ? Preferences on inspirational approaches during idea generation . Des Stud 35 ( 1 ) : 29 – 53 . [ 9 ] Milene Gonçalves , Carlos Cardoso , and Petra Badke - Schaub . 2013 . What inspires designers ? Preferences on inspirational approaches during idea generation . Design Studies 35 ( 01 2013 ) . https : / / doi . org / 10 . 1016 / j . destud . 2013 . 09 . 001 [ 10 ] Scarlett R . Herring , Chia - Chen Chang , Jesse Krantzler , and Brian P . Bailey . 2009 . Getting Inspired ! Understanding How and Why Examples Are Used in Creative Design Practice . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Boston , MA , USA ) ( CHI ’09 ) . Association for Computing Machinery , New York , NY , USA , 87 – 96 . https : / / doi . org / 10 . 1145 / 1518701 . 1518717 [ 11 ] Scarlett R Herring , Chia - Chen Chang , Jesse Krantzler , and Brian P Bailey . 2009 . Getting inspired ! Understanding how and why examples are used in creative design practice . In Proceedings of the SIGCHI conference on human factors in computing systems . 87 – 96 . [ 12 ] Seunghoon Hong , Dingdong Yang , Jongwook Choi , and Honglak Lee . 2018 . Inferring semantic layout for hierarchical text - to - image synthesis . In Proceedings of the IEEE conference on computer vision and pattern recognition . 7986 – 7994 . [ 13 ] David Jansson and Steven Smith . 1991 . Design fixation . Design Studies 12 ( 01 1991 ) . https : / / doi . org / 10 . 1016 / 0142 - 694X ( 91 ) 90003 - F [ 14 ] Hyung - Kwon Ko , Subin An , Gwanmo Park , Seung Kwon Kim , Daesik Kim , Bohyoung Kim , Jaemin Jo , and Jinwook Seo . 2022 . We - Toon : A Communication Support System between Writers and Artists in Collaborative Webtoon Sketch Revision . In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology ( Bend , OR , USA ) ( UIST ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 76 , 14 pages . https : / / doi . org / 10 . 1145 / 3526113 . 3545612 [ 15 ] J . A . Landay and B . A . Myers . 2001 . Sketching interfaces : toward more human interface design . Computer 34 , 3 ( 2001 ) , 56 – 64 . https : / / doi . org / 10 . 1109 / 2 . 910894 [ 16 ] James A . Landay and Brad A . Myers . 1995 . Interactive Sketching for the Early Stages of User Interface Design . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Denver , Colorado , USA ) ( CHI ’95 ) . ACM Press / Addison - Wesley Publishing Co . , USA , 43 – 50 . https : / / doi . org / 10 . 1145 / 223904 . 223910 [ 17 ] Brian Lee , Savil Srivastava , Ranjitha Kumar , Ronen Brafman , and Scott R . Klemmer . 2010 . Designing with Interactive Example Galleries . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Atlanta , Georgia , USA ) . Association for Computing Machinery , New York , NY , USA , 2257 – 2266 . https : / / doi . org / 10 . 1145 / 1753326 . 1753667 [ 18 ] Yuheng Li , Haotian Liu , Qingyang Wu , Fangzhou Mu , Jianwei Yang , Jianfeng Gao , Chunyuan Li , and Yong Jae Lee . 2023 . GLIGEN : Open - Set Grounded Text - to - Image Generation . CVPR ( 2023 ) . [ 19 ] Richard Marsh , Joshua Landau , and Jason Hicks . 1996 . How Examples May ( and May Not ) Constrain Creativity . Memory and Cognition 24 ( 09 1996 ) , 669 – 680 . https : / / doi . org / 10 . 3758 / BF03201091 [ 20 ] Mohammad Amin Mozaffari , Xinyuan Zhang , Jinghui Cheng , and Jin L . C . Guo . 2022 . GANSpiration : Balancing Targeted and Serendipitous Inspiration in User Interface Design with Style - Based Generative Adversarial Network . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 537 , 15 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517511 [ 21 ] Taesung Park , Ming - Yu Liu , Ting - Chun Wang , and Jun - Yan Zhu . 2019 . Semantic Image Synthesis with Spatially - Adaptive Normalization . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 9 , Calò and De Russis [ 22 ] Taesung Park , Ming - Yu Liu , Ting - Chun Wang , and Jun - Yan Zhu . 2019 . Semantic Image Synthesis With Spatially - Adaptive Normalization . 2019 IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) ( 2019 ) , 2332 – 2341 . [ 23 ] HanQiao , VivianLiu , andLydiaChilton . 2022 . InitialImages : UsingImagePromptstoImproveSubjectRepresentationinMultimodalAIGeneratedArt . In CreativityandCognition ( Venice , Italy ) . AssociationforComputingMachinery , NewYork , NY , USA , 15 – 28 . https : / / doi . org / 10 . 1145 / 3527927 . 3532792 [ 24 ] Daniel Ritchie , Ankita Arvind Kejriwal , and Scott R . Klemmer . 2011 . D . Tour : Style - Based Exploration of Design Example Galleries . In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology ( Santa Barbara , California , USA ) . Association for Computing Machinery , New York , NY , USA , 165 – 174 . https : / / doi . org / 10 . 1145 / 2047196 . 2047216 [ 25 ] Ben Shneiderman . 2020 . Human - Centered Artificial Intelligence : Reliable , Safe & Trustworthy . International Journal of Human – Computer Interaction 36 , 6 ( 2020 ) , 495 – 504 . https : / / doi . org / 10 . 1080 / 10447318 . 2020 . 1741118 arXiv : https : / / doi . org / 10 . 1080 / 10447318 . 2020 . 1741118 [ 26 ] B . Shneiderman . 2022 . Human - Centered AI . Oxford University Press . [ 27 ] Amanda Swearngin , Mira Dontcheva , Wilmot Li , Joel Brandt , Morgan Dixon , and Amy J . Ko . 2018 . Rewire : Interface Design Assistance from Examples . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems ( Montreal QC , Canada ) . Association for Computing Machinery , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3173574 . 3174078 [ 28 ] Todd Thrash and Andrew Elliot . 2003 . Inspiration as a Psychological Construct . Journal of personality and social psychology 84 ( 05 2003 ) , 871 – 89 . https : / / doi . org / 10 . 1037 / 0022 - 3514 . 84 . 4 . 871 [ 29 ] Todd M Thrash , Emil G Moldovan , Victoria C Oleynick , and Laura A Maruskin . 2014 . The psychology of inspiration . Social and personality psychology compass 8 , 9 ( 2014 ) , 495 – 510 . https : / / doi . org / 10 . 1111 / spc3 . 12127 [ 30 ] Nannan Tian , Yuan Liu , Bo Wu , and Xiaofeng Li . 2021 . Colorization of Logo Sketch Based on Conditional Generative Adversarial Networks . Electronics 10 , 4 ( 2021 ) . https : / / doi . org / 10 . 3390 / electronics10040497 [ 31 ] Michihiko Ueno and Shin’ichi Satoh . 2021 . Continuous and Gradual Style Changes of Graphic Designs with Generative Model . Association for Computing Machinery , New York , NY , USA , 280 – 289 . https : / / doi . org / 10 . 1145 / 3397481 . 3450666 [ 32 ] Bryan Wang , Gang Li , Xin Zhou , Zhourong Chen , Tovi Grossman , and Yang Li . 2021 . Screen2Words : Automatic Mobile UI Summarization with Multimodal Learning . 498 – 510 . https : / / doi . org / 10 . 1145 / 3472749 . 3474765 [ 33 ] Ting - Chun Wang , Ming - Yu Liu , Jun - Yan Zhu , Andrew Tao , Jan Kautz , and Bryan Catanzaro . 2017 . High - Resolution Image Synthesis and Semantic Manipulation with Conditional GANs . 2018 IEEE / CVF Conference on Computer Vision and Pattern Recognition ( 2017 ) , 8798 – 8807 . [ 34 ] Paulina Yurman and Anuradha Venugopal Reddy . 2022 . Drawing Conversations Mediated by AI . In Creativity and Cognition ( Venice , Italy ) ( C & C ’22 ) . Association for Computing Machinery , New York , NY , USA , 56 – 70 . https : / / doi . org / 10 . 1145 / 3527927 . 3531448 [ 35 ] Peihao Zhu , Rameen Abdal , Yipeng Qin , and Peter Wonka . 2020 . Sean : Image synthesis with semantic region - adaptive normalization . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition . 5104 – 5113 . 10