Collaborative Exploration and Sensemaking of Big Environmental Sound Data Tshering Dema , Margot Brereton , Jessica L . Cappadonna , Paul Roe , Anthony Truskinger & Jinglan Zhang Computer Human Interaction , Science and Engineering Faculty , Queensland University of Technology , 2 George St , Brisbane , QLD 4000 , , Australia ( Phone : + 61 7 3138 2240 ; E - mail : t3 . dema @ qut . edu . au ) Abstract . Many ecologists are using acoustic monitoring to study animals and the health of ecosystems . Technological advances mean acoustic recording of nature can now be done at a relatively low cost , with minimal disturbance , and over long periods of time . Vast amounts of data are gathered yielding environmental soundscapes which requires new forms of visuali - zation and interpretation of the data . Recently a novel visualization technique has been designed that represents soundscapes using dense visual summaries of acoustic patterns . However , little is known about how this visualization tool can be employed to make sense of soundscapes . Understanding how the technique can be best used and developed requires collaboration between interface , algorithm designers and ecologists . We empirically investi - gated the practices and needs of ecologists using acoustic monitoring technologies . In particular , we investigated the use of the soundscape visualization tool by teams of ecologists researching endangered species detection , species behaviour , and monitoring of ecological areas using long duration audio recordings . Our ﬁ ndings highlight the opportunities and challenges that ecologists face in making sense of large acoustic datasets through patterns of acoustic events . We reveal the characteristic processes for collaboratively generating situated accounts of natural places from soundscapes using visualization . We also discuss the biases inherent in the approach . Big data from nature has different characteristics from social and informational data sources that comprise much of the World Wide Web . We conclude with design implications for visual interfaces to facilitate collaborative exploration and discovery through soundscapes . Keywords : Collaborative sensemaking , Environmental soundscapes , Boundary object , Visualization , Collaborative exploration , Soundmarks , Interfaces , Big data 1 . Introduction With changes in landscape and growing fragmentation of natural landscapes , mon - itoring biodiversity and ecosystems changes have been asserted as global priorities ( Butchart et al . 2010 ; Newbold et al . 2015 ; Venter et al . 2016 ) . Ecologists assert the need to monitor the environment at a higher temporal and spatial resolution ( Newbold et al . 2015 ) . Technology research has thus begun to explore new forms of monitoring and ways of summarising and interpreting the large amount of acoustic data emanating from networks of environmental sensors . This paper investigates collaborative exploration and sensemaking of big environmental acoustic data using © Springer Science + Business Media Dordrecht 2017 Computer Supported Cooperative Work ( CSCW ) ( 2017 ) 26 : 693 – 731 DOI 10 . 1007 / s10606 - 017 - 9286 - 9 a new visualization tool . A growing body of work in CSCW / CHI is investigating practices and design of Apps and interfaces for environmental data gathering and curation work , largely drawing upon practices of citizen science ( Rotman et al . 2012 ; Wiggins and Crowston 2011 ) . These studies primarily focus on people gathering and sharing snippets of audio or image data about nature in distributed locations . The advantage of this approach is that it collects data from diverse sources and allows many people to interact with nature . Such approaches have led to large repositories of data that have been utilised in scienti ﬁ c research such as eBird ( Lagoze 2014 ) . The disadvantage of such approaches is that human presence in gathering the data may impact the behaviours of species and the piecemeal nature of the data limits understanding of the local context over time ( Chamberlain and Grif ﬁ ths 2013 ) . Acoustic recording is an attractive monitoring approach because sound recorders can be left out in the wild for long durations , non - invasively ‘ eavesdropping on ecosystems ’ ( Servick 2014 ) . Acoustic recorders are de - ployed to investigate many aspects of nature , including monitoring of species that are rare or elusive , animal behaviour , or large - scale environmental health monitoring . The prevalence of using acoustic recorders to capture long - duration sound recordings has led to the emergence of a new ﬁ eld of science , called soundscape ecology ( Pijanowski et al . 2011 ) . Every place has a unique soundscape , which is de ﬁ ned as the composition of all sound , both natural and man - made , emanating from a landscape over spatial and temporal scales ( Pijanowski et al . 2011 ) . However , even a single acoustic recorder at a single site collects a large amount of data : a huge soundscape . Although big data is collected and archived in many domains little is known about how people make sense of the re - represented aspects of the world through data visualizations ( Lycett 2013 ) . For environmental audio data , analysis is the pertinent issue ; although terabytes of data can be easily collected and stored , there is too much sound to listen to . Analysis of acoustic data is challenging , whether by manually reviewing recordings or using automatic recognition techniques ( Potamitis 2014 ) . For example , an ecologist would typically take 8 minutes to listen to and annotate a busy one - minute recording . Fully automated analyses of all acoustic events are impractical due to the highly unstructured nature of the wild acoustic data ( Truskinger et al . 2013 ) . Further , de ﬁ ning an animal vocalisation to a speci ﬁ c call type loses all other information that is co - occurring in nature . This paper presents an empirical investigation of how ecologists make sense of the environmental acoustic patterns through a novel visualization interface . The design of the visualization tool is unique as it renders acoustic patterns based on the shared acoustic properties of events at different time scales . The technical details of the visualization technique are described in ( Towsey et al . 2014 ) . The visualization technique was developed by computer scientists and , as yet , there have been no studies on how ecologists make sense of the acoustic patterns or 694 Dema Tshering et al . how they relate them to acoustic phenomena in nature . Our investigation is aimed to understand this . The work presented here is part of an ongoing longitudinal study of practices and needs in ecological acoustic monitoring work with ecologists and acoustic specialists working on different ecological investigations . Our ﬁ ndings are informed by scoping interviews with 12 ecologists , several collaborative investigations in which a CSCW / computer science researcher worked with ecologists using the visualization tool on their data ( 16 sessions with 8 different ecologists ) , and two design workshops that brought together people with different expertise ( acoustic specialists , ecologists , computer scientists , and novices ) to make sense of soundscape patterns . Analysing a soundscape of a place generates a situated account of that place by human analysts identifying various acoustic events . The term B situated account ^ emphasizes the fact that an account is generated in a particular context on data from a particular place . This context of the account generation includes the various actors , and their motivations for exploring the visualization , their knowledge of the place , typical species , ecological phenomena , the phenomena that are noticed , the dynamics of the discussion about the data , and trajectory of exploration . The situation of the place where the recording is made involves the habitat and species that are present , weather phenomena , species behaviours and acoustic events that may be particular to a site . The placement of the microphone , how vocal the species are , and other environmental sounds affect what is recorded . Soundscapes can be represented at various scales , with a screen summarising sound from a whole year , month , day , or showing it as it occurs naturally at the highest resolution . Macro - views tend to show shifts in various acoustic phenomena in the wild ( such as weather events ) rather than pointing to individual species . The nature of environmental sound data is quite different from traditional big scienti ﬁ c data ; in particular environmental sound data is continuous and with little explicit structure . There are no nodes or links as are typically found in graph theoretic representations of text , web , and genomic data . People interpreting sound representations must look for points of interests and make associations themselves . There is however some innate structure to sound data that comes from its physical characteristics of frequency ( pitch ) , amplitude ( loudness ) , and time , together with associated characteristics such as acoustic energy distribution in time . These characteristics are the bases of acoustic indices : summary values of sound data . There are theories that species have evolved to populate different frequen - cy bands in order to make themselves heard ( Krause 1993 ) . Further , repre - sentations are read against a background of ecological knowledge , including relationships between organisms themselves , between organisms and their physical environments and between organisms and the ﬂ uxes of matter and energy through biological systems ( Annenberg Learner 2017 ) . Collaborative Exploration and Sensemaking of Environmental Acoustics 695 Furthermore , sensemaking of acoustic data demands collaboration across a variety of specialists to make sense of it . Aspects of temporality in environmental sound data are largely unexplored because methods and tools have hitherto not been available to explore it at scale . Our contributions to CSCW are as follows : & We present a unique case study on how ecologists make sense of acoustic patterns in their long duration environmental recordings through a novel visualization interface : soundscape visualization . & We characterise the key processes of sensemaking using soundscape visualizations , notably : orientation through colour and structure ; pattern sensemaking and situated knowledge ; soundmarks and interrelation between patterns ; Challenges of weather effects and biases of proximity . & We characterize the interpretative ﬂ exibility of the visual artefact by different experts and its use for drawing design insights through collaborative sensemaking . & We suggest design of support features to enhance collaborative sensemaking in this domain . In what follows , we ﬁ rst review related work in sensemaking and big data , collaborative visualization and human - environmental data interaction in the CSCW / HCI community . Next , we detail the research methods used in this study followed by key ﬁ ndings drawn in the study . Finally , we discuss the broader design implications and suggestions on big data analysis and techniques for enhancing collaborative sensemaking in this domain . 2 . Related work : sensemaking and collaborative visualization of big data 2 . 1 . Sensemaking and big data Sensemaking is broadly de ﬁ ned as the process through which people develop meanings from the interplay of actions and interpretations ( Weick 1995 ) . Weick portrays sensemaking as an experience that is B ongoing , instrumental , relational , subtle , and social ^ ( Weick et al . 2005 , p . 1 ) in an organizational context . Early studies highlighted the importance of representation design , learning loop complexity , the need to understand how we process new information and the value of stored information ( Russell et al . 1993 ; Kidd 1994 ; Qu and Furnas 2005 ; Whittaker 2008 ) . Paul and Reddy ( 2010 ) conceptualized collaborative sensemaking as making sense of information found together . Their ethnographic study in a hospital emer - gency department identi ﬁ ed three occasions for collaborative sensemaking : ambig - uous information ; role - based distribution of tasks , and lack of expertise . They also highlighted three important characteristics of collaborative sensemaking : pri - oritization of information , sensemaking trajectories , and activity awareness . Likewise , Tao and Tombros ( 2013 ) investigated the collaborative sensemaking behaviour of online information searchers studying sensemaking 696 Dema Tshering et al . strategies , sharing of information , construction of shared representations , and sharing of task progress . Lau et al . ( 2014 ) asserted the need for collaborative sensemaking for big data analysis to bring together machine capability and human intelligence . Argenta et al . ( 2014 ) identi ﬁ ed four important aspects of sensemaking in a big data environment : i ) what is to be analysed ii ) veracity of data iii ) tools that support analyst to sense and also interact with the big data environment iv ) human aspects such as individual vs . group sensemaking . Chan et al . ( 2016 ) conducted a comparative study of sensemaking for crowd ideation under different conditions of prior ideas and resources available for sensemaking . They found that automated sensemaking improved idea generation however proposed the need of further investigation to understand human sensemaking aspects indepth . Big data requires the support of tools to mediate and glean information from it . The design of tools to re - represent data is often contextual to its domain and source . While much focus is on human generated texts , social network and genomic data , we are investigating a new area of environmental acoustic data , which is largely considered as something remote and out there . Latour ’ s monadic views on data in the social sciences rejects aggregate views and individual views as separate entities but rather seeks out overlap - ping interesting points of view taken severally ( Latour et al . 2012 ) . Dörk et al . ’ s . ( Dörk et al . 2014 ) B information ﬂ aneur ^ highlights exploratory and creative characteristics of information navigation in the Web . We aim to further investigate how monadic exploration ( Latour et al . 2012 ) is at play in the sensemaking of acoustic data visualization at different timescales . What are the implications for tool design ? Should effort be invested into building automated techniques or be invested to support sensemaking of acoustic phenomena in the wild , and how ? How can the ﬁ ndings through the sensemaking inform the design of the representational artefact itself ? 2 . 2 . Sensemaking and collaboration Prior studies in CSCW / HCI have asserted the need to support collaborative analysis and sensemaking in various contexts of use . Fisher et al . ( 2012 ) examined distributed sensemaking in a web - search - based sensemaking task and found that use and sharing of knowledge maps from multiple iterations helped the quality of sensemaking by later users . Goyal et al . ( 2014 ) designed and evaluated an implicit sharing tool for crime analysis and found that it improved the task performance of the collaborators . Further , Goyal and Fussell ( 2016 ) investigated collaborative sensemaking through an interface that provided additional clues and insights to the crime analysts . Their ﬁ ndings highlighted there is a need to balance between real - time information sharing versus data accuracy for distributed sensemaking . Collaborative Exploration and Sensemaking of Environmental Acoustics 697 2 . 3 . Collaborative visualization and big data Visualization tools are used to abstract and provide insights into complex and large datasets . Isenberg et al . ( 2011 ) has de ﬁ ned collaborative visualization as B the shared use of computer - supported visual representations of data by more than one person with the common goal of contribution to joint information processing activities ^ . She asserted the importance of collaborative visualization for iterative analysis and sensemaking of the data . Recent work by Ludwig et al . ( 2015 ) has focused on the collaborative aspects of visualization for understanding and analysing mobile data . The magnitude and opacity of long duration environmental acoustic datas are largely considered to be technical challenge and little work has been done through a CSCW lens . We aim to investigate visual sensemaking of acoustic patterns in the context of different ecological investigations in order to understand how the visualization tool can be used collaboratively between different groups of experts . While recording and storage is no longer an issue due to technological advances , analysis , extraction , and interpretation of acoustic information from large datasets requires human collaboration ( Cottman - Fields et al . 2014 ) . When discussing the value of big data , Boyd and Crawford ( 2011 , p . 2 ) pointed out : Big Data is fundamentally networked . Its value comes from the patterns that can be derived by making connections between pieces of data , about an individual , about individuals in relation to others , about groups of people , or simply about the structure of information itself . Boyd and Crawford speak in the context of people and social networked data and their key assertion is about the relational properties of big data and the patterns of phenomena that it reveals . In the context of acoustic data , the nature of connection is different from nodal networks . Long duration acoustic recordings are represented through a temporal soundscape visualization interface . The temporality of the data anchors acoustic phenomena within the frequency - time domain for a particular place or habitat . As such , the data visualization tool ( as in Figure 1 ) acts as a boundary object between people with different expertise and knowledge . Star ( 1989a , b ) describes boundary objects as those objects that create a shareable context across different functional settings . From this perspective , the visualization tool is the central element of our inquiry but we also wish to understand the broader actor - network within which use of the boundary object is situated . 3 . Research methods Our study is informed by a series of empirical investigations . The initial inquiry took place through scoping interviews with 12 ecologists who are currently using long duration acoustic recordings for their investigations . Scoping interviews are a useful 698 Dema Tshering et al . method for grounding and re ﬁ ning the initial understandings , assumptions , and concepts of a research team working in a new ﬁ eld ( Robertson et al . 2012 ) . The 12 ecologists had varying level of experiences in using acoustic monitoring technolo - gies ( Table 1 ) . We undertook ﬁ eld visits during acoustic recorder deployment at different locations with ecologists ( Figure 2 ) . Each interview was between 40 to 50 minutes and included a review of long - duration acoustic data ( Figure 3a ) . All interviews were audio recorded and tran - scribed , and were then analysed using thematic analysis . This method was chosen because thematic analysis is considered as one of the most general and useful qualitative approaches to identify themes and relationships from within data ( Braun and Clarke , Virginia and Clarke 2006 ) . As the study progressed , the primary investigator was engaged closely with eight different ecologists researching endan - gered or elusive species detection , species monitoring and behaviour , and large - scale comparisons of two ecological areas using acoustics . This has allowed the primary investigator to gain an insider ’ s account of the practice starting from acoustic recorder deployment to data representation and decoding work . Observation notes and audio recordings from initial scoping interviews and screen recordings of our joint investigation into their data were analysed . Each collaborative investigation lasted between 45 and 60 minutes . The soundscape visualization inter - face is hosted on the Ecosounds workbench and collaborators could all join in as a member to any project . Screen and audio recordings were gathered for each obser - vation ( Figure 3b ) . The ﬁ rst workshop aimed to investigate how people make sense of the visual representations from a year - long acoustic dataset in a group setting and Figure 1 . Acoustic data visualization at multiple temporal resolutions : a ) 4 months data navigation bar . b ) 24 hour view with 1 pixel per 60 seconds resolution ( macro - visual interface ) . c ) 30 seconds view with 1 pixel per 0 . 02 second resolution ( micro - view interface ) at listening pace . The y - axis represents frequency ( 0 to 11 kHz ) . Collaborative Exploration and Sensemaking of Environmental Acoustics 699 Table 1 . Participants ’ experiences and current ongoing acoustic work in ecology . ID Ecologicalworkexperience Current work and acoustic related ecological investigations Participation in Scoping Interview ( SI ) and Collab - orative Investigation ( CI ) P1 More than 10 years A biologist with work experiences in curating animal sound archives and monitoring vocal faunal using acoustics to investigate biodiversity and environmental health . SI P2 8 year A herpetologist who studies amphibian diversity and behaviour . She is using acoustics to understand frog community behaviour and call patterns through long duration acoustic recordings . SI and 3CI P3 4 years A forest of ﬁ cer and his roles include conservation activities within a park and community development . He has deployed acoustic recorders in the park to study species richness and diversity . SI ( through skype ) and CI P4 More than 30 years A senior ecologist who focuses on environment conservation and species behavioural studies . She has also worked closely with local community to conserve White - bellied Heron habitat . SI P5 10 years A conservation biologist who works on habitat modelling and ecosystem classi ﬁ cation . He is currently doing research to understand migratory patterns of birds . As an avid birder he has also recorded over 700 wild bird species . SI and 4 Cis ( through skype ) P6 15 years An ecologist and has been a birder since childhood . She is working on acoustic detection of a critically endangered bird species in her local region by collaborating with local people . SI and 3 CIs P7 28 years A senior ecologist who studies koalas and collects acoustic recordings from multiple habitat areas during his ﬁ eld surveys every year . He is interested in studying koala population dynamics by investigating koala bellowing frequency over time SI and CI P8 & P9 4 years and 3 years Two herpetologists who are using acoustic monitoring technologies for frog sibling behaviour in diverse habitat structure . Their project is aimed to help habitat restoration program . SI ( continued on next page ) 700 Dema Tshering et al . investigated the collaborative work of people with different backgrounds and exper - tise . Data used was collected from two ecological areas near Brisbane , Australia . There were eight participants ( three ecologists and ﬁ ve acoustic specialists ) in the ﬁ rst sensemaking workshop ( Figure 4a ) . The second workshop focused on collaborative sensemaking and interpretation of a month - long soundscape from the nesting site of a critically endangered species in Bhutan . The second workshop had eight participants ( three ecologists of the target species and ﬁ ve novices who are interested in the species monitoring ) ( Figure 4b ) . Both the workshops lasted 2 to 3 hours . The soundscape tool that we used was designed primarily to visualise acoustic daily summaries , without particular attention to collaborative use . However , through Table 1 . ( continued ) ID Ecologicalworkexperience Current work and acoustic related ecological investigations Participation in Scoping Interview ( SI ) and Collab - orative Investigation ( CI ) P10 5 years A forestry of ﬁ cer and a keen birder who is interested in using acoustic sensors for monitoring individual bird species and their behaviour . He is interested in carrying out acoustic surveys in his area . SI and CI ( through skype ) P11 2 years A soundscape researcher and is interested in using acoustics and statistics to compare the soundscape of two habitats through long duration environmental recordings . SI & 2 CIs P12 20 years A conservation and landscape ecologist with extensive experience researching ﬂ ora and fauna in desert habitats and is currently comparing ﬁ eld bird survey data to the number of species vocalizations captured in long - duration acoustic recordings . SI & CI ( through skype Figure 2 . a ) Acoustic recorder deployment to monitor an endangered species in Bhutan . b ) Site visit with local collaborators in Bhutan . Collaborative Exploration and Sensemaking of Environmental Acoustics 701 the two design workshops , we were able to draw design insights that support collaborative sensemaking . 4 . Findings We discuss the key ﬁ ndings under three subsections . First , we discuss the motiva - tions and perspectives of ecologists working with large amounts of environmental acoustic recordings . Second , we characterize the key processes in visual sensemaking with examples and excerpts from different aspects of the sensemaking work across three different case studies . Finally , we discuss our ﬁ ndings from two collaborative sensemaking workshops . Figure 3 . a ) Initial interview with a participant using the visualization interface . b ) Observation of visual sensemaking work by a computer scientist and a herpetologist at their workplace . Figure 4 . a ) A Collocated design workshop with group of ecologists and acoustic specialists to make sense of yearlong data from two ecological areas near Brisbane , Australia . b ) Collocated group workshop with ecologists and conservationists interested in endangered species monitoring in Bhutan . 702 Dema Tshering et al . 4 . 1 . Ecologists ’ motivations and perspectives on big acoustic data The soundscape as a novel territory . Ecologists generally regard their ecological investigations through acoustics to be ‘ exciting ’ , ‘ promising ’ and ‘ a whole new way to look at nature ’ . Participant P12 commented : I guess it is taking ecologists into quite a novel territory . Rarely are we in a situation where we have more data , getting more data means more time in the ﬁ eld , and getting data in one ﬁ eld means we are not at other sites . With acoustics , we can effectively have data from all sites at the same price . This was echoed by other participants when they shared their motivation for using acoustics . P10 commented that acoustic monitoring will complement their ﬁ eld survey data by allowing them to know beyond simply whether a species is present or absent . P3 expressed her expectation as follows : Considering the rugged terrains , it is hard to reach all the potential habitats of heron by physical survey . We hope the acoustic sensors will be of great use in monitoring the species through its call . This will really complement our existing efforts to conserve the species . Another conservation biologist , P7 , who is using long duration sound recordings for detection of endangered species , commented : Acoustic data is an enormous wealth of data and through the data collected for monitoring one species , we can also understand cohabiting species and weather conditions at the habitat area throughout the day . Collaboration on both data collection and analysis . Collaboration is regarded as essential in acoustic monitoring practices by most participants . It was considered as impossible to collect and analyse data without the shared expertise and skills from different people . The visual tool mediates the representation of acoustic data by summarizing sound events in the long duration audio recordings . However , it is not intelligible without human experts collaborating to build the context of need and insights for each investigation . A conservation biologist ( P1 ) with more than 10 years of experience with acoustic research commented : Strength of collaboration are shared experiences of people from different background and it is important for complex problems such as this which requires computing power as well as analytical and domain knowledge of complex call types . Collaborative Exploration and Sensemaking of Environmental Acoustics 703 Participant P2 shared similar experiences and emphasized the collaborative work needed for both data collection and analysis of the huge amounts of acoustic data . In most cases , the ecologists collaborate with local people in selecting deployment sites and maintaining acoustic recorders . Once the data is gathered , ecologists collaborate with IT specialists and technologists for management and analysis of their big acoustic data . Another participant , P6 , who has been collecting data for more than six months , expressed the importance of collaboration in such work : If there was no collaboration , I would not be doing this on my own . I have more than a terabyte of data altogether from thirteen potential habitats of my species . I collaborate with local people as they know the place better and also with the acoustic specialists and technologists for my data management and rendering . The ecologist is working with a team to investigate the calling behaviour of the elusive Eastern bristlebirds by ﬁ rst recording captive birds in the hope that this will help the team to locate and protect the small wild population remaining in the species northern range . This interview excerpt between the ecologist and the researcher ( identi ﬁ ed as R ) demonstrates how speci ﬁ c acoustic ﬁ ndings are recorded and shared with other collaborators : P6 : This is an Eastern bristlebird call but this is just one call type . It has a lot more call types . So far , I know 10 call types . They are relatively similar . Do you know what I mean ? R : Hmm … actually no I don ’ t understand . Could you tell me more ? P6 : I mean it ’ s got distinctly high pitch in this aviary data , as there are a few birds in there [ in the aviary ] for sure and we know the distance of the recorder from the birds . See , these are noisy miner calls ( Figure 5 ) and sometimes they just go on for 3 minutes like this . Here is the whipbird and here are my bird calls . R : So you don ’ t need to listen to it anymore P6 : No , I don ’ t but I am afraid how it will be in other wild data , as the call intensity will vary and so the pattern may not be so distinct . So you see there are many birds calling here and you see how it is a complex case . [ The ecologist copies the url of the page in a Google and / or excel spreadsheet for sharing it with collaborators or for later reference ] R : So you will revisit this later 704 Dema Tshering et al . P6 : Oh yeah , I have seen this pattern only today . I will look at that minute again . It is a discovery and I will also share the link with my collaborators . When they encounter a new unknown call or event in the data , the sound event link is send around through email to other ﬁ eld experts or local people for species identi ﬁ cation . This re ﬂ ects that learning about nature is a collaborative exercise and knowledge is situated in the process of discovery . For instance , when a bird specialist ﬁ nds frog calls in her data from the wild , she will send that data link to other frog ecologists . We observed that acoustic monitoring work was creating a network of situated knowledge ( Suchman 2003 ) across humans and digital artefacts . 4 . 2 . Visual sensemaking of nature sound patterns through the visualization interface We discuss our ﬁ ndings on visual sensemaking of acoustic patterns with speci ﬁ c examples and excerpts from three case studies . First , we provide an overview of the three case studies , ongoing acoustic monitoring projects in which participants P6 , P5 , and P11 are involved . The ecologists have varying knowledge of the visualization , diverse backgrounds and varying experience of using acoustics for ecological investigation . In all the case studies , the ecologist led the sensemaking of their data with the computer scientist following thorough ( Table 2 ) . 4 . 2 . 1 . Orienting features of the acoustic space Initial orientation - dramatic colour shifts . One of the ﬁ rst ways that participants orient to the visualization is by noticing the dramatic shifts in colour . When looking at P6 ’ s data , these shifts can be seen during transitions between day and night , with reddish pink colour ‘ tracks ’ often appearing and representing cricket chirps in night hours ; whereas daylight hours ( 6 : 00 to 17 : 00 ) are ﬁ lled with green lines that represent mostly birds calling , according to P6 ( Figure 6 ) . Drilling down to detailed views : time indicates start and end of phenomena . After noticing the dramatic shifts , indicating day and night , attention focuses on distinct patterns . For instance , in case study one the ecologist ( P6 ) selected a minute in the strongest pink segment at night time between 1 : 00 to 2 : 00 morning hours ( Figure 7 ) . Figure 5 . Calls of Eastern bristlebird with Noisy miner at a detailed spectrogram . The x - axis represents time ( 0 to 30 s ) and the y - axis , frequency ( 0 to 11 kHz ) . Collaborative Exploration and Sensemaking of Environmental Acoustics 705 Then she navigated to a 30 - s standard grey - scale spectrogram where she could view detailed granular acoustic signatures as well as listen to the associated audio clip . She then made her best attempt to determine what calls seen and heard in the micro or detailed spectrogram ( grey - scale ) were likely to represent the particular pattern being Table 2 . Description of three case studies that informed visual sensemaking of acoustic patterns . Ecological case study using acoustics Duration of recordings Purpose CSCW / Comp - uter Science Researcher + Case study 1 : Search for an elusive endangered species , Eastern bristlebird in Northern habitat range in Queensland 6 months across different sites By reviewing acoustic recordings from an aviary , she hopes to learn about Eastern bristlebird call variability , which calls are used most , and when . This information will help the team search for calls of the species more effectively when looking through recordings from other potential habitats . P6 Case study 2 : Acousticmonitoring of Critically EndangeredWhite - bellied Her - on during breeding season in Bhutan 2 months continuous audio recordings Continuous acoustic recordings from the nesting site of the critically endangered species are gathered to understand the species vocalization types , calling behaviour , and other co - habiting species calls . The ecologists and the researcher have spent long hours navi - gating and making sense of the patterns on a one to one basis . P5 , P3 , and P10 ( remote co - investigations using skype shared screens ) Case study 3 : Comparison of two ecological areas near Brisbane Yearlong recordings ( total of 26 months for two sites ) Our third investigation involves working with a soundscape researcher and data analyst who has rich ﬁ eld knowledge of her ecological areas and is aiming to compare long duration soundscapes from two different locations . She has learned more than 50 species calls from her acoustic data . P11 706 Dema Tshering et al . inspected in the macro visual interface ( coloured ) . A list of patterns explored is detailed in Table 3 . Figure 6 . A 24 - hour soundscape visualization of acoustic recordings from Eastern bristlebird aviaries collected on May 30th 2015 . X - axis is time in hours ( 0 to 24 hour ) , and Y - axis is frequency in hertz ( 0 to 11 kHz ) . The three acoustic indices ( Acoustic complexity index , Temporal entropy , and No . of events ) are mapped to red , green , and blue colour channels . Algorithms are used to calculate acoustic indices or summary statistics of particular aspects of sounds . The entropy index depicted by green during the day correlates to mostly birds calling and the combination of Acoustic complexity index and No of events , depicted by pink and purple are predominately crickets chirping . Figure 7 . 24 hour soundscape on 30th May ( 15 : 00 to 15 : 00 next day ) showing how the summary pattern maps to 30 - s detailed spectrograms of the Eastern bristlebird aviary . All representations have y - axis of 0 to 11 kHz . Reddish - pink lines represent insect chirps in the 24 h soundscape . The 30 s spectrograms from the night hours show strong and faint insect chirps . The 30 s spectrogram from the day shows Eastern bristlebird calls ( see Table 3 for more pattern details ) . Collaborative Exploration and Sensemaking of Environmental Acoustics 707 Patterns within a pattern : Noticing temporal shifts within a pattern . Once the ecologist ( P6 ) bracketed a particular pattern to investigate ( Figure 7 ) , she further noticed how the pattern within the pink track varied from strong solid pink at times to blotchy pink dots at other times . These changes in pattern shape emphasized by colour intensity were used to further understand the dynamics of a particular event that had been noticed : I know crickets call at night and I listen to the audio to con ﬁ rm that those pink patterns are crickets . However , the cricket patterns do not show up the same throughout the night . It changes in the intensity of pink and other times it does not show up at all . I am not sure why that happens . The pink track is completely not there some nights and I wonder if it has to do with temperature , barometric pressure , or some other reason . Sensemaking began with awareness of what species were present and calling in the world through the re - represented soundscape and then beginning to notice each pattern by the shape and colour it carried . Having identi ﬁ ed a pattern to species relation , one was better able to see more instances of that species calling . One could also recognize unidenti ﬁ ed features of the soundscape and begin to investigate features of unknown calls so that yet more aspects of the sound were revealed . It is a generative process . Table 3 . Examples of pattern description with respect to colour , location , time and associated interpretations ( related to Figure 7 ) . Pattern Colour Frequencyrange Time Interpretations Narrowlongtracks Pinkishpurpleandblue at times 3 to 5 kHz 17 : 30 to 6 next day Insect tracks Solidblocks of pinktracks Strongintensity pink 4 kHz Intermittent for few hours at night Call intensity of a particular insect species increasing Vertical stripes Green 2 to 12 kHz 5 : 30 to 17 : 30 h Bird calls of multiple species Faint blue spread Blue 0 to 2 kHz Intermittent , stronger in the evening Vehicle Faint insect tracks Pink line withblue background 3 . 5 to 4 . 5 kHz Faint blue with narrow pink line Faint insect calls 708 Dema Tshering et al . 4 . 2 . 2 . Situated knowledge and sensemaking The ecologist through many interactions with patterns that appeared and faded in the background over time generated a situated account of the phenomena . Then in making sense of the acoustic phenomena in the real world , she ( P6 ) imagined the habitat based on the time of the event , other bird or frog species she heard , and through her recollection of experiences . It is through the assimilation of prior knowledge of patterns , lived experiences in the ﬁ eld , and what the representation reveals that phenomena are interpreted . Con ﬁ rming individuality of the species acoustic signature at the micro view . We observed that the detailed view of the spectrogram is used for con ﬁ rming the pattern tracer or the underlying sound producer . Navigating to the standard spectrogram , inspecting the individual acoustic signatures and listening to the audio clip for a few 30 s clips in a row helps the ecologist con ﬁ rm the source of a particular pattern . In the ﬁ rst case study , the soundscape visualization during the day time mostly appeared as green vertical lines due to the compression of similar sounds in every minute . The individual subtle characteristics were not legible , however individuality of species signatures were not lost as the ecologist preferred to work at the micro view where she could distinguish her species . She commented : All these bird calls appear as green in the visual interface and therefore it is hard to pick out my target species at this compressed resolution . However , I know my bird call at the detailed spectrogram level . Of the many other birds in my data , noisy miners , lorikeets , and laughing kookaburra appear a lot in my data . Then on closer examination , we found that birds with a persistent call signature and duration were tracing vivid patterns in the soundscape visualization such as Laughing kookaburras and Bell miners ( Figure 9 ) . Clues on collective temporal phenomena at the macro view . A few interesting discoveries were realized when the ecologist ( P6 ) was exploring the acoustic recordings from the aviaries . The ecologist shared that when she was looking at the detailed standard spectrogram view , Eastern bristlebirds were found to have a more diverse acoustic repertoire then previously realized . She commented that she found this by manually reviewing over 30 daylight hours of standard spectrograms and listening to associated acoustic record - ings . The ecologist has identi ﬁ ed more than 10 different calls for Eastern bristlebirds so far out of 3615 annotated in her data . This revealed a need to show the annotations of detailed views to the summary view so that sensemaking is aided in the ongoing work . One interesting pattern the visualization revealed was that birds at the aviary ‘ called more at dusk than at dawn , though any birder will tell you birds call more at dawn ’ , as indicated by the high amounts of green Collaborative Exploration and Sensemaking of Environmental Acoustics 709 colouration at dusk relative to dawn ( Figure 8 ) . This provides a clue about its calling behaviour that could potentially help in acoustic detection of the species in other wild data . Acoustic events that last longer in time show up in macro views . Potential habitats of wild Eastern bristlebirds also revealed interesting patterns . Each habitat has a unique environmental context with different vegetation structure and species assemblages , and these differences are represented as distinct patterns in visualizations of each habitat . Examining the soundscape visualisation from one wild Eastern bristlebird habitat , the ecologist P6 commented , ‘ I have a blue band that goes all across the day and they are distinctly showing up like the insects in the other site . ’ She explained this solid blue line at 3KHz was the Bell miner calling obnoxiously all day long ( Figure 9 ) . Although Eastern bristlebird calls were dif ﬁ cult to see in the soundscape visual - ization due to their complex calling behaviour and habitat type , white - bellied Heron calls were easily detectable due to the bird ’ s unique call signature and tendency to call when other birds are relatively quiet and its habitat type ( Figure 10 ) . Ambiguous mappings : Dif ﬁ culties in spotting differences . While the coloured pat - terns worked for some species , it was hard to trace out clearly a particular species in an environment when it was intimately sharing the acoustic space with many other bird species . For example , in a minute of audio recording , you may ﬁ nd 3 to 5 other species calling together when looking at a standard spectrogram . When the data is complex and busy , it becomes hard to retain the subtle differences in call structures through the pre - calculated indices of the long - duration summary view . The sound - scape of the Eastern bristle bird aviary mapped all strong acoustic events to green and the subtle mapping of the red index to the bird ’ s particular call type was dif ﬁ cult to notice . This reveals a need for further characterization of indices that are unique to the species call . Progressive understanding of patterns . To understand the sensemaking process further , we investigated a totally new site with P6 ( Figure 11 ) . It is a 24 - hour visual summary from an entirely unfamiliar site in the Northern Territory of Australia , recorded on January 25th 2015 . The ﬁ rst comment by the ecologist was : Figure 8 . 24 - hour visualization of June 1st 2015 showing that dusk chorus is more intense than dawn chorus at the Eastern bristlebird aviary site . 710 Dema Tshering et al . This site is so different compared to my sites and has so much going on at night . See how the night time patterns are so compelling . It would be interesting to know what the habitat is like . The ecologist was seen to build knowledge of patterns in the multi - dimensional acoustic space ( Frequency , Time , Colour mapped to acoustic indices ) , re ﬁ ning her prior knowledge of acoustic patterns . In the ﬁ rst case study , the ecologist had drawn a direct link between colour and individual species or other environmental sound . … to me , green is bird . All bird calls appear as green here and it is hard to distinguish which one species is which . At this site , I have Lorikeets , Noisy miners , King parrots , Eastern whipbirds , Pied currawong , and Torresian crows . However upon closer investigation of the new habitat soundscape , she was seen to re ﬁ ne her understanding to colour being a primary indicator to track the dynamics of a particular acoustic phenomenon . She was curious to compare the strong orange Figure 9 . 24 hour visualization of a potential Bristlebird habitat site showing patterns of a particular bird species , Bell miner calls with narrow blue tracks throughout daylight time . Figure 10 . a ) Soundscape visualization of 24 hour , recorded on 3rd April , 2016 at a nesting site of a critically endangered White - bellied heron b ) 30 s view of the image depicting White - bellied Heron calls at 5 : 03 in the low frequency range at detailed resolution . Collaborative Exploration and Sensemaking of Environmental Acoustics 711 pattern that gradually fades into green at 1 to 2 kHz , below what she called , ‘ cricket pink tracks ’ . She then compared the orange patterns with green patterns at different spots by navigating to the detailed spectrogram interface , listened to few minutes from each time period , and learned that ‘ not all green are birds , nor are all frogs orange ’ . Rather the shifting colours were learned to relate to changing acoustic phenomena . In this way , sensemaking of acoustic data through the macro - micro linked visualization interfaces helped develop progressive understanding of speci ﬁ c acoustic events through the shifting patterns ( both in terms of colour , shape and location in the frequency bands ) in the representations . Each new place reveals its unique acoustic patterns based on the soundscape composed of animals , climatic changes , and man - made sounds . Although each new place has its contextual differ - ences , the visualization tool provides suf ﬁ cient coherence that it can show the contextual differences between the visual summaries of different soundscapes . A better sense of the acoustic patterns of a particular habitat is thus formed . Learning to see animal behaviours and activities . Upon looking at the different soundscape ( Figure 11 ) with a herpetologist ( a frog specialist , P2 ) , the ecologist Figure 11 . Patterns noticed in 24 Hours visual summary of Jan 25 , 2014 from Umbakumba , Groote Eylandt , Northern Territory , Australia . Each acoustic event is shown in detailed spectrogram view ( 30 s resolution , grey - scale ) . Y - axis for all images is frequency in hertz ( 0 to 11 kHz ) . 712 Dema Tshering et al . identi ﬁ ed frequency bands of 3 to 4 kHz where a particular frog species chorus occurred . Focussing there , they observed the dynamics in colour to realise that combinations of red and green indices represented a strong frog chorus . With the colour dynamics of that pattern in mind , the ecologist then navigated from one day to another inspecting the frog calling behaviour , predicting that it would likely fade soon when the frog ’ s breeding season ended . This insight enabled the ecologist to watch the chorusing pattern of frogs during night time over many days . This shows that activity of the same frog species could be understood through the change in colour of the patterns occurring between 3 to 4 kHz , with the number of individual calls made in a minute changing the pattern colour from intense orange to green . Considering appropriation of the representation . During the co - investigation of species detection at the macro view by the ecologist ( P6 ) and computer scientist , the ecologist pointed out the individual species call in the detailed view and also identi ﬁ ed calls of all other species that were co - occurring in her data . Upon closer examination , we noticed that a particular call type of the target species was tracing some vivid patterns ( a bridge - like shape ) , mostly during the afternoon of most days . This call type was clouded with the persistent patterns of noisy miner ( Figure 12 ) . The ecologist ( P6 ) would then try to understand the variation in call types during different times of the day . However , it is hard to discern easily as the bristlebird has more than 10 call types . It was then understood that whenever the bridge - like consistent pattern showed up again in other days , it would be a good clue of the particular call type of the target species . Figure 12 . A 24 hour visual summary view and 30 - s standard spectrogram demonstrating that species such as noisy miners frequently use a particular call consistently ( within the white lines ) distinct from the target species Eastern bristlebird , which has high pitch and acoustic complexity . Collaborative Exploration and Sensemaking of Environmental Acoustics 713 From the ecologist ’ s account , the computer scientist learned what makes the target species subtly different from other bird calls that are also attributed mostly by the green index ( i . e . , entropy index which is a strong concentrated energy value calcu - lated per minute ) , which helps the computer scientist understand the mapping to speci ﬁ c acoustic indices . Such discussions lead to design appropriation of the representation such that it can augment the search for a particular species . Can we hide other persistently calling patterns such as that of noisy miner in order to help reveal the target species better ? In each case study , joint focus on the artefact led to co - learning of the soundscape context . Often , new calls and call patterns in nature were found in the recordings . Simultaneously a situated account of all actors , both human and non - human ( species whose calls are captured in the data , the artefact design , and the interpreters ’ knowledge ) was enacted . Arbitrariness of colour mapping . There is a learning loop in the sensemaking of acoustic patterns and the effort required depends on the complexity of the visual summary . It is rare to ﬁ nd a one to one mapping of colour to species , because colours mostly relate to shifts in acoustic phenomena . Therefore , mapping of multiple features is usually required to make sense of what ’ s going on . In many cases , it is hard to conceive this notion . The representation revealed acoustic events based on their shared features of event time , location in the frequency bands , and acoustic characteristics . However , in most cases , the ﬁ rst question is what do these colours mean ? In tracing the multiple combinations of colour , you encounter many interest - ing phenomena in the wild , some of which are iconic to the underlying acoustic signature over time . 4 . 2 . 3 . Co - discovering soundmarks and interrelations between patterns Soundmarks are de ﬁ ned as the community sound which is unique and possesses qualities which bring out the vitality of a particular landscape ( Schafer 1993 ) . Figure 13 shows the key soundmarks ( i . e . , the prominent acoustic patterns in the visualization ) that are easily picked up as the ecologist navigates through the soundscape visualization of White - bellied Heron nesting sites in the second case Figure 13 . Examples of key soundmarks found in the White - bellied Heron soundscape . From left to right : Heavy rain and wind , Striated prinia ( A bird species in Bhutan ) , Crickets , Unknown , Multiple insects , White - bellied Heron at the low frequency , and Cicadas 714 Dema Tshering et al . study . Through co - investigation , we learned how the events are mapped to different acoustic indices . Paying attention to the subtle differences in similar soundmarks . In many cases , the ecologist often picked a pattern by its colour ﬁ rst and then used the shape and texture of the pattern to make further distinctions . In the second case study , the ecologist ( P5 ) commented that although Striated prinia ( a bird species ) and strong rain both appear as vertical pink strikes , we could see that the bird call pattern was more complex in structure than the ﬁ ne strikes of the strong rain pattern ( Figure 14 ) . Using multiple dimensions such as colour , location , and shape of the pattern ; visual analysis draws out the subtle differences in similar patterns such as between rain and the bird . As the ecologist looked at the detailed acoustic signature of striated prinia , its resemblance to rain was found to be due to similar acoustic complexity index values in the patterns . Assimilating prior knowledge in pattern sensemaking . In acoustically searching for a particular target species , prior ﬁ eld knowledge of the animal ’ s call type and behav - iour is needed . The heron ’ s low frequency call and its known behaviour of mostly calling in the early morning were used to detect the species . The acoustic recordings also provided clues to habitat characteristics , such as the presence of persistent callers like striated prinia and cicadas , as well weather indications of rain and wind . Through many co - investigations of the data , awareness of the species that were calling in each context was generated . Noticing , con ﬁ rming , and then navigating further . Once the ecologists discover a speci ﬁ c pattern to identify a species call , they trace through their data focusing only on the speci ﬁ c pattern . For instance , in case study 2 , the ecologist was observed to Figure 14 . A comparison of how ( a ) heavy rain and ( b ) Striated prinia call appear as similar patterns at the macro view and detailed spectrogram view . y - axis for all images are from 0 to 11 kHz . Collaborative Exploration and Sensemaking of Environmental Acoustics 715 focus only on the heron call patterns at the low frequency range between 1 to 2 kHz which appears as green small strikes , and quickly navigates gazing only at that region to ﬁ nd more green patterns in each day . The search does not stop until the selected pattern shifts . The shift can be due to a change in timing of appearance , change in frequency , or change in colour in the same region . Navigating at scale . In the third case study , the soundscape analyst makes sense of common visual patterns , being able to browse through data at scale of a whole year calling out seasonal and weather changes . She quickly navigated through the visu - alization of her data that showed periods of heavy rain indicated by with pink strikes , as well as windy days that were indicated by a lot of blue streaks . She added , ‘ Whenever the wind is gustier , the intensity of blue grows higher ’ . Then pointing to a colourful patch around 5 : 00 , she remarked , ‘ that ’ s a morning chorus , it might be more than one species calling . Sometimes a single species can be picked up but other times it is hard . ’ As she navigated through the soundscapes , and paused on encoun - tering unusually colourful days or unusually black days . She commented on how the effect of wet microphones over many days of rain affected the recordings . This experienced soundscape researcher narrates her description of patterns in relation to weather information , insect tracks , and other acoustic events like a story . These observations demonstrated how the visual cues are ﬁ rst noticed , learned , and used in their interpretations of acoustic patterns . The visualization enables learning through shifting phenomena . For someone who has 26 months of audio recordings from two different ecological areas , the visualization tool allows her to perform a rapid temporal , visual survey and drill down to the detailed acoustic patterns of interest . This is said to have greatly reduced the opacity issue of working with terabytes of data . 4 . 2 . 4 . Challenges of weather effects and biases of proximity Distortion effects - cicadas hogging the microphone . As we navigate through the visualization of long duration audio recordings with the soundscape researcher in case study 3 , she commented on the key soundmarks such as rain , strong wind , morning chorus , insects , and day time strong activity through the visual interface . She commented on a particular day in her recordings : All the blue patches during the day time are cicadas . The green patterns at night are insects . There are some days in my data where cicadas are very close to the microphone and they take the whole frequency range and create cicada wave patterns . Sound clipping and unknowns in the data . Another distinct pattern that was picked up was intermittent sound clipping of unknown cause and also some high frequency patterns which could be some insects or echolocating bats that can be seen but not 716 Dema Tshering et al . heard . On this data , we try to change the blue index to spectral power index and then blue highlights wherever there is strong persistent energy rather than indicating no of events ( Figure 15 ) . However , a change in index was observed to be hard to comprehend as it drastically changes the patterns and it was hard to immediately understand how the patterns changed . This in essence requires beginning again to learn to interpret the patterns in the visualization in a new way , using all of the strategies described earlier , including initial orientation ( e . g . night vs . day ) , colour mappings , frequency range , persistent patterns , and other clues of acoustics . It is beyond the scope of this paper to describe the user experience of shifting the acoustic indices as it is a topic needing further research . 4 . 3 . Findings from collaborative sensemaking workshops We now discuss the ﬁ ndings from the two sensemaking workshops . The aim of these workshops was to draw out design opportunities for using the soundscape visuali - zation tool for collaborative sensemaking of long duration environmental acoustic recordings . We outline the details of the two workshops in Table 4 . We then discuss the key ﬁ ndings . In both cases , in order to reduce the technical constraints of working through each day at a time and to show longer duration acoustic patterns at one time to the group , we used printed representations ( paper screens ) for each workshop . 4 . 3 . 1 . Soundscape visualization as a boundary object between experts In the ﬁ rst workshop , the two groups examined the large - scale temporal soundscapes from different perspectives with the soundscape visualization acting as a boundary object that brought coherence to the discussions . The acoustic specialists and computer scientists looked at the representation from a design perspective of why one representation is more distinctive than the other and how the colours used affected the representation . They annotated their interpretations and questions on the paper screen ( Figure 16 ) . Once a person noticed a pattern , the group tried to collaborate and interpret the data based on their prior encounter with similar patterns , knowledge of indices , and interrelations with other patterns . For instance , when they found a blackish blue patch in the midst of a red pattern , which they interpreted as Figure 15 . Transformed view of the soundscape visualization to include power index instead of the number of events index set to blue colour . Collaborative Exploration and Sensemaking of Environmental Acoustics 717 rain , at a few spots in the dataset , they questioned the behaviour of the Acoustic Complexity Index and whether it was representing well what was happening , ( i . e . was it really rain and should it turn black there ? ) , even though they did not have reason to believe any other event was causing the change in representation . The acoustic specialist group speculated what the few instances of black patch and striking cyan colour patterns were , and then invited participants from the ecologist group over to verify their speculations . Rare cyan distinct patterns in the Table 4 . Outline of two collaborative sensemaking workshop and participants detail . Workshop Materials Participants Workshop 1 : Collaborative investigation into a yearlong soundscape representation of two ecological areas in Queensland Paper screens of yearlong soundscape visualization of two sites using two different sets of acoustic indices . Each of these indices set show different aspects of energy distribution in the frequency - time domain relating to different events in the data . 8 participants who has varying knowledge of acoustics , technology and ecological background . Group A : 3 acoustic Specialists ( and 1 computer scientist ( abbreviated as A1 , A2 , A3 and CS1 respectively ) Group B : 2 ecologists , 1 acoustic and ecological researcher and 1 computer scientist ( abbreviated as E1 , E2 , E3 , & CS2 respectively . Workshop 2 : Collaborative sensemaking of acoustic patterns of White - bellied Heron 30 days printed visual representations , markers for annotation , a large a large computer screen to enable visualizing and listening to any particular pattern during the session . 8 participants comprising of 3 Heron ecologists and 5 conservationists who are not familiar with the target species . Figure 16 . Group participants interpreting and annotating yearlong soundscape representations . 718 Dema Tshering et al . representation were caused by the technically ampli ﬁ ed microphone during long duration rainy days and the blackish brown patches were insect sounds neutralizing rain events . The change in rain representation had indeed been triggered by some other sound events while it was raining . CS1 : Look at this one . What could these be ? A1 : It is a one - time event in a year so it may be strong wind . From my experience with desert data , strong wind appears that way . CS1 : It cannot be wind since this pattern appears only in these three days in the whole year . I don ’ t agree with you . A1 : Well there is always an answer to science . I think we should ask [ another participant by name ] to explain what ’ s happening here … . could you tell us what ’ s happening here in this striking pattern bit before we have big ﬁ ght here . E1 : It was the time where I had the microphone problem and there was three days of weird patterns and then the red bit on the 28 th is rain . A2 : What are these black holes in the data ? E1 : There are these black and blue small patches in the middle of the rain and I saw that those are insects . Sometimes there are black patches in the middle of the rain due to insects . Look at this one right here . A4 : ACI ( the acoustic index that maps to red ) is high when there is high variation from time to time . When a high ACI event meets with some low ACI event , these overlapping events lowers the ACI value . E1 : It is great to discuss this here as I noticed these black patches myself and did not know what was really happening . The visualization thus acted as a boundary object enabling the acoustic knowledge of the structure and strength of sound events of the computer scientists to be mapped to the ecologists ’ ecological knowledge about the likelihood of particular species being present . The most vivid patterns that were noticed and discussed were those of rain , frogs and crickets as they were frequent and always lasted for a longer duration than other types of acoustic events – most bird calls lasted for only a few seconds at a time . In both the groups , the interpretative work was richly informed by their prior experiences and expertise . The visualization as boundary object ( Star 1989 , 2010 ) , could be interpreted differently by experts with different backgrounds and yet was Collaborative Exploration and Sensemaking of Environmental Acoustics 719 able to maintain coherence in the discussions . Both groups oriented to happenings in the representation through colour and structure of patterns , and then brought their relevant disciplinary knowledge to bear to help decipher the clues in the representa - tion . Our ﬁ ndings revealed the interpretative ﬂ exibility as well as the integrity of the representation of datasets from different sites using the soundscape representation . Through these different interpretations of the representation by different people , we are able to gain better design insights into how the visualization can be used across various contexts and needs . 4 . 3 . 2 . Need for system features to support collaborative annotation and sensemaking In a collocated setting of both the workshops , it was easy for participants to annotate their interpretations , doubts , and further questions on the common paper ‘ screen ’ so that others could view , learn from or question the accumulated annotations . However the current online system only allows annotations of individual species names or sound events at the micro - level ( detailed view of spectrograms ) and these do not surface up to the macro - view , neither does it support any free - text annotations . This feature to support artefact awareness is deemed crucial in collaborative tasks such as the one described here . Prior research has suggested that sharing of cues and knowledge through annotation helps in collaborative tasks ( Gutwin et al . 1995 ; Tee et al . 2009 ; and Goyal et al . ( 2013 ) ) . Several long - term users of the system pointed out how tedious it was to annotate at the detailed view , taking approximately 8 min to annotate a busy 1 minute recording . Support for artefact awareness to enable annotation and awareness of annotations at the macro as well as the micro level is needed to enable people to learn about or be aware of datasets that are annotated in asynchronous work done by different collaborators . Designing such annotation approaches can support collaborative sensemaking between ecologists , acoustics analysts , and computer scientists . 4 . 3 . 3 . Implications on subtle design features such as colour mapping It was remarked how the change in indices and colour mapping can be confusing after someone is oriented to a set of colours and relating patterns to speci ﬁ c events . For example , the ﬁ rst representation mapped the red colour to acoustic complexity index whereas in the second representation ; red is mapped to background noise . These changes in colour mapping were not intuitive as the ﬂ ip in colour mapping made it harder to relate to the pattern sensemaking as it appeared different for the same dataset . This momentum carried by colour in the conceptualizations of interpreters has strong implications for the way colour is used in the representational logic . E2 expressed that , ‘ Some indices really help us show the events while others mute the representations . It is not easy to comprehend that the same colour will now mean something else . This must be handled carefully ’ . She added , ‘ It is easier to think in terms of red is rain and if we ﬂ ip red to show background , it is confusing to know or understand the patterns . When the colour coding changed , it was hard to reset the 720 Dema Tshering et al . colour coding in our mind . ’ While it seems obvious that colour mappings should be consistent , the ways in which colours will map to particular sounds is not predictable a priori . Such design issues were only identi ﬁ ed from working with ecologists who have been using the visualization tool for some time . For instance , if they are used to associating brighter colour to louder and more complex sound events then setting background noise index ( which only shows sound events below a certain low threshold ) to red ﬂ ips the representation completely . 4 . 3 . 4 . Collaborative analysis and interpretation of acoustic data In the second workshop , after a short training depicting the bird call type and patterns in the soundscape visualization , the participants ﬂ ipped through stack of data to gain familiarity of the soundscape of the Heron habitat . Novice partic - ipants asked ﬁ eld ecologists for more information on the bird ’ s calling behav - iour , and breeding season activities . One novice participant veri ﬁ ed his patterns by listening , and then volunteered to verify the pattern of heron calls for others as they found them . The participants compared the possible patterns that are likely to be the target species in each other ’ s data . If they encounter the same pattern at a different timing , they gather more facts about the species through the ﬁ eld experts . Such as ‘ will it call for a long time like for 2 hours ? ’ and ‘ when is the breeding season ? ’ and ‘ what do you think is happening when it calls thirty times in an hour ? ’ Collectively , they build their understanding of the species through what the visuals show , and through probing each other to understand species behaviour further . A lot of stories of the bird are being told in the process . Here is an excerpt from an ecologist ( E3 ) trying to answer some of the above questions : During nesting , it will call only if there is threat and disturbances and avoid calling as much and take turn between the partners . On April 17 th , if the exchange for incubation takes a long time , the egg would have laid and they must be calling each other to take turn at the nest . Both parents will not call for 2 to 3 days to avoid predators it seems . However , if one partner does not come back in 3 to 4 hours , then the one in the nest will call to swap roles . By April end to May , once the chicks are 40 days and above , both parents will leave for feeding and parents will only come back for feeding . We observed rich collaboration in human data analysis work . It was interesting how each pair annotated their data and also con ﬁ rmed with other pairs to interpret the pattern by marking ‘ yes ’ , ‘ no heron ’ or ‘ likely ’ by focusing only in the low frequency range of the representations . The collaborative work , which involved expert expla - nations and cross - referencing and comparison of annotations , went beyond the actual sensemaking of a speci ﬁ c pattern or identi ﬁ cation of an individual species calls to , in effect , building a whole collaborative strategy for generating awareness and knowl - edge of the environment . Collaborative Exploration and Sensemaking of Environmental Acoustics 721 The group detected heron calls in 10 out of 30 days in 20 minutes , indicating that with some species it may be possible to ﬁ nd them quickly in a large dataset . However to make a claim here would require far greater quantitative analysis and scrutiny . Rather , we emphasize how the group consisting of experts and novices collaborated sharing both identi ﬁ cation of calls and knowledge of species behaviour , which taken together enabled them to draw out rich information about the species in its habitat . The visualization artefact in this case was acting as the boundary object between novices , computer scientists , and Heron ecologists . We observed richer social aspects of collaborative sensemaking in these workshops than the co - investigation of the same dataset described in the previous section . Therefore , we suggest that this visualization tool , which was initially designed for indi - vidual use has wider scope and opportunities as a collaborative tool rather than accepting it as a ﬁ xed form of sound representation with a ﬁ xed con ﬁ guration . As Ludwig et al . ( 2015 ) pointed out : The idea behind collaborative visualization resulted from the need to overcome the traditional design of single - user visualization systems and to allow the collec - tive exploration and analysis of large data sets through visualization . 4 . 4 . Summary of ﬁ ndings in sensemaking Our ﬁ ndings characterise the key processes of sensemaking identi ﬁ ed over several collaborative sessions and draw design implications that highlight the opportunities and challenges of interpreting acoustic phenomena in the wild through the visuali - zation interface : & Orientation : Generally , users ’ ﬁ rst orient to the representational space through shifts in colours and the frequency range and are found to drill down to the micro or the detailed view upon noticing shifting patterns or upon noticing subtle changes within the same pattern as they navigate further . & Pattern sensemaking and situated knowledge : In this process , users assimilate prior knowledge with the knowledge that is enacted through their interaction with patterns to make sense of particular phenomenon . & Soundmarks and interrelation between patterns : Each place has a unique soundscape and through the soundscape visualization interface , co - investigators interpreted the soundmarks and further investigated interrelations between similar appearing acoustic patterns in nature . & Challenges of weather effects and biases of proximity : Through collabo - rative exploration of long duration data , challenges of weather effects and biases of proximity of certain insects to the recorder are identi ﬁ ed . & Visualization artefact as a boundary object between experts : design insights are gained through the different interpretations of patterns brought to 722 Dema Tshering et al . fore by computer scientists , ecologists , and acoustic specialists on the acoustic representation . 5 . Discussion and conclusion We now discuss our ﬁ ndings highlighting the immersive and exploratory qualities of the visualization interface . We discuss all of the actors in the network and how agency is shared among them . We pay particular attention to the soundscape visualization , which the human interpreters use as a boundary object to connect their different disciplinary understandings . We discuss the agency of the visualization itself and the underlying algorithms . Finally , we discuss broader implications for big data analysis work , automation and the need for tool support to enable collaborative sensemaking in this domain . 5 . 1 . The immersive and exploratory qualities of the soundscape visualization We have presented an account of sensemaking of visual acoustic data from a variety of ecological projects . What stood out in all cases was the explorative and immersive quality of the visualization . When the data is brought back and re - represented , there is a whole sensemaking process for exploring , interpreting , and extracting new information from it . This includes moments of confusion , perplexity , and awe because the patterns encoun - tered are often being seen for the ﬁ rst time . As people make sense together and navigate through the temporal acoustic map or rather soundscape of a particular place , we observe immersive experiences reminiscent of an ‘ information ﬂ aneur ’ ( Dörk et al . 2011 ) . Analogous to an ‘ urban ﬂ aneur ’ who leisurely walks through streets and squares interpreting and re - imagining the city , the information ﬂ aneur explores , re ﬂ ects and imagines , rather than being driven solely by goal driven information seeking and representation approaches . Drawing upon cognitive , per - ceptual and affective aspects of information , the information ﬂ aneur gradually shifts between horizontal exploration and vertical immersion , depending on information encounters and personal interests . We see similar behaviours with soundscape visualizations . However , Dörk et al . ’ s ‘ information ﬂ aneur ’ is conceptualised from an individual perspective and does not consider the broader aspects of community sensemaking . Moreover , the information contemplated by Dörk et al . relates to browsing the web and texts , which , while complex and multifaceted has a different character from information distilled from nature . The visual representation itself depends upon ( i ) the actors recorded at that remote site in the wild ( which includes all kinds of acoustic events both living and geo - physical sounds based on the landscape and weather conditions ) and ( ii ) the artefact design based on the indices formulated to summarise the sound . The human inter - preters then bring their own knowledge to bear collaboratively as they create Collaborative Exploration and Sensemaking of Environmental Acoustics 723 accounts of the representations and what is happening at the site . It is the classic semiotic triad of object , sign and interpretant ( Peirce 1903 ) , but now the object is big data ( the acoustic recording of the actors at the site ) , the signs are complex ( the soundscape visualization ) and there are multiple interpretants ( collaborators ) . Although the soundscape visualizations are compelling , their interpretation relies upon ecologists ’ situated experiences and knowledge . Most ecologists would still want to go to the physical site and examine it at times to check their assumptions . Understanding between site and soundscape visualization is iterative in the manner that Brown et al . ( 1989 ) observed with complex machines and their manuals , ‘ in an intriguing way , you need the machine to understand the manual , as much as you need the manual to understand the machine . ’ 5 . 2 . The appeal and limits of automation With the recorded data , it is possible to search for particular species using automatic ‘ recognisers ’ . Recognisers use algorithms to search data and return a binary ‘ found ’ or ‘ not found ’ outcome . Sometimes the algorithms are directly coded . Alternatively they can be devised from training data using machine learning methods , such that how they actually work becomes more of a black box . Automated species recogni - tion techniques are widely used in target species call detection ( Frommolt and Tauchert 2013 ; Digby et al . 2013 ) because they utilise computational power to process large amounts of data quickly . However , they face challenges with respect to accuracy , both false positives and false negatives . The results are also isolated from other data , relations and phenomena that humans can detect in their organic approach to problem solving . As Rost asserted , there is B a need to take a qualitative look at big data ^ such that faulty assumptions are avoided ( Rost et al . 2013 ) . This is because automation searches for features that can be seen digitally , but is blind to important contextual information that cannot be seen digitally . We propose that qualitative approaches to big data must be incorporated within the largely quanti ﬁ ed practices , as this will allow tracing out richer and more meaningful information from the big data . Associatively , it provokes us to think about how to design forward to support such work . How can we engage more people in collaborative and exploratory interaction with big data through visualization ? And where does manual interpretive work intersect with automated tasks ? We do not have the concrete answers to all of these questions but further qualitative examination of approaches to big data representation and interpretation can help to guide ap - proaches . Foremost , maintaining traceability of data is important so that relating phenomena and the actors ( human and nonhuman ) can be accounted for . 5 . 3 . Agencies at the interfaces of big datasets We turn now to consider agency in more detail . Examining the collaborative sensemaking process reveals the shared agencies and the relational role of each actor . 724 Dema Tshering et al . The partial and interrelated roles of actors must be understood in order to understand how to design for recon ﬁ guration or appropriation in each context . From an actor network perspective ( Latour 2005 ) , the key actors are the human interpreters , the visual artefact , and the sound producers in any particular habitat area . Human interpreters with different backgrounds bring in their expertise and skills to draw out different aspects of the data shown in the representation . Ecologists relate to their ﬁ eld experiences and to the features of landscape , weather , season , and common species as they make sense of the patterns . The interpretations are unique to each project and evolve as the interpreters interact and learn the pattern language , inter - relate patterns with patterns and patterns with lived experiences , and pose further questions . In this way , the interpreters ’ sensemaking loop goes beyond the mere macro - micro linking of patterns in the data to assimilation of prior knowledge and experiences and collaborative analysis of acoustic patterns with the help of other experts . The visualization tool attributes its own agency through being able to show large amounts of sound succinctly . However , the colour mappings of the acoustic indices ( that are calculated on the sound occurring within a time unit and mapped to red , green , and blue ) and the logic of each index calculation allow certain events to be shown more than the others . The ecologists in the design workshops noted the B complex behaviour of the representation ^ . For example , P2 discovered that the chorus representation for one frog species is different from the chorus of another species in terms of colour . The colour displayed is a result of both con ﬁ guration choices and the formulated calculations on the data , but how these will play out in the ﬁ nished representations is dif ﬁ cult to predict a priori . The agency of the tool and its underlying algorthims is thus asserted during the process of sensemaking by what it reveals , and it may then be tweaked to reveal a new perspective . In this network of actors , we argue that the producers of sound at a particular place ( animals , geophysical such as rain , wind and river , man - made activities ) also have their own agency in appearing or disappearing in the representation based on their natural regimes and behavioural patterns . The placement of recording equipment and the weather also affects what is recorded and later shared and seen . Thus , agency is shared in an actor network that involves many interfaces and partial knowledges ( Suchman 2010 ) . In this network of actors , we must also consider that people who might potentially harm a species or environment may want access to environmental data . Monitoring is asymmetric allowing humans to eavesdrop on other species . Anonymizing various aspects of data such as exact locations may be necessary , depending upon the nature of the data , in order to ensure species are not disadvantaged by the privileged agency that is given to humans through interfaces . This triggers us to re ﬂ ect on the real concept of shared agency between actors ( both human and nonhuman ) as we collectively work towards seeking ecological balance of shared resources . Speci ﬁ c to this study , it reminds us to pay attention to all actors that contribute to acoustic sensing and representation work . Collaborative Exploration and Sensemaking of Environmental Acoustics 725 5 . 4 . Alignment of research motivations to representations The three case studies showed how data is interpreted differently , depending on the researchers ’ motivations , knowledge and the representation . While there are some commonalities in strategy , such as using colour shifts to orient to changes etc . , here we focus on the intersection between researchers ’ motivations and the representation . We also observe how different interpre - tations of the same representation can be used to appropriate or adjust the representation , to meet the needs and motivations of the researcher . In the ﬁ rst case study , the target species was clouded by all other species that were simultaneously appearing as green during the daytime in the one day summary soundscape . The ecologist thus preferred to work at the detailed individual acoustic signature level across a group of collaborators who help her with identi ﬁ cation and annotations . The collaborative investigation into the data brought out subtle features of the target species that can help in recon ﬁ guring the representation . In the second case study , the representation privileged the target species ’ calls as the species has a unique location in the soundscape in the low frequency range . The bird ’ s call characteristics and calling behaviour complemented the representational logic . Thus , a situated account of the behaviour of the species and the soundmarks of its habitat was more easily derived , with collaborative sensemaking supported by the human actors as well as the representation . The third case study revealed how the representation helped in understanding data sanity and proximity biases of small insects to the recorder . It also highlighted the advantages of being an B information ﬂ aneur ^ , exploring the data without a speci ﬁ c narrow search but discovering and learning new species through their acoustic phenomena and underlying footprints . The alignment of researcher motivations and knowledge to what the representation is able to reveal in ﬂ uences whether representations are useful or need to be recon ﬁ gured . 5 . 5 . Design recommendations for collaborative soundscape visualization tools Long duration acoustic recording provides a large amount of complex information that hitherto has not been obtainable . Ecologists want this information and relish the challenge of relating it to their own knowledge and knowledge of context that they can gain themselves in embodied ways . Datasets are now so large that they require technical and networked means of representation to reveal the salient characteristics of environmental data , so that it can be interpreted collaboratively by researchers with different domain knowledge , according to their motivations . Thus , the research question becomes how best to design tools for representing and exploring complex recorded information . The case studies all showed that sensemaking is an iterative and progressive process and that supporting collaboration of people to discuss and interpret plausible phenomena in the representations drew out meaningful contextual information . 726 Dema Tshering et al . Immersed in the patterns of big data , investigators are able to focus on the phenom - ena that are enacted by many entities rather than looking at individuals in isolations or symbolic representations of statistical summaries of big data . Our three case studies and collaborative workshops with use of long duration soundscape visuali - zation lead us to design recommendations for better supporting collaborative work with big environmental data : 1 . For target species study , the visualization should allow appropriation and recon ﬁ guration of the representation so that researchers can best gain insights into their speci ﬁ c questions . 2 . Recording of sensemaking notes should be enabled at the various timescales of data , so that people can see easily where others have annotated , even when looking at different timescales . This enables awareness of who else is examining the data and enables learning from each other ’ s interpretations and discussion of particular patterns that are observed as unusual . 3 . Sensemaking notes could possibly be tagged and displayed under different categories of interpretation , hypothesis , and questions ( as these were used by people in the group work ) . Pre - de ﬁ ned categories can cause dif ﬁ culties as can open tagging , so this needs further design consideration . 4 . People need to compare interrelated patterns based on other dimensions such as by time , frequency bands or by colour . As suggested in our ﬁ ndings , support is needed to allow collaborators ( ecologists , acoustic analysts , novices ) to learn new calls or patterns through each other ’ s work and to trigger interest through visual summaries of team work . Ways to visualize the ongoing annotation summaries are also needed . Such awareness of collaborative activities will trigger interest and promote learning through each other ’ s work . As we have shown , understanding environmental sound data involves exploratory navigation across patterns of sound at different levels of abstraction , sometimes requiring interface recon ﬁ guration . This echoes Latour et al . ’ s ( 2012 ) call for methods that are B between the views of individuals and views of aggregates ^ in order to follow through stronger , wider , and longer lasting associations in phenom - enon than a view of either individual or aggregates separately . The visualization tools presented here take a step towards scalable and ﬂ uid tools for environmental exploration that maintain a collaborative agenda ( Light et al . 2015 ) . 5 . 6 . In conclusion This paper has characterised the collaborative sensemaking process of big environ - mental sound data through a new soundscape visualization interface . The study revealed that it is much easier to explore big environmental audio data through the new soundscape visualizations , which show the data at different timescales , than has hitherto been possible . The summary views help to orient ecologists to major features of the data , such as weather , night and day etc . , vocal species and other clues . Just as Collaborative Exploration and Sensemaking of Environmental Acoustics 727 ecologists use habitat as an indication of which species are present , common visual patterns of sound called soundmarks have potential to indicate the species present in big audio data . Knowledge of how to read soundscape representations is still emerging as the technique is developed . Collaborative sensemaking proceeds through macro - micro linking of patterns in the data and assimilation of prior knowledge and experiences of multiple experts . This in turn informs re ﬁ nement of the representations for more targeted analysis . We elaborate the agency in the actor network and in particular the agency of the algorithms and interfaces . We closed by presenting design recommendations for further improving collaborative tools for exploration and analysis of big environ - mental acoustic data . 6 . Acknowledgements We would like to thank all our collaborators who contributed in this research . Thank you to the northern working group members of the Eastern Bristlebird Recovery Team and land holders , as well as the Wildlife Preservation Society of Queensland , whom have supported bristlebird acoustics research . We also thank all our collabo - rators in Bhutan including the White - bellied heron conservation members at Royal Society for Nature Protection who contributed and took part in the sensemaking workshop in Bhutan . Special thanks go to Yvonne Philips for allowing use of her yearlong soundscape representations in the workshop and to Dr . Michael Towsey for overall technical support . References Annenberg Learner ( 2017 ) . The Habitable Planet : A Systems Approach to Environmental Science . https : / / www . learner . org / courses / envsci / . Accessed March 20 2017 . Argenta , Chris , Benson Jordan , Nathan Bos , Susannah B F Paletz , William Pike , and Aaron Wilson ( 2014 ) . Sensemaking in Big Data Environments . HCBDR ‘ 14 : Proceedings of the 2014 Workshop on Human Centered Big Data Research , Raleigh , NC , USA , 1 – 3 April 2014 . New York : ACM Press , pp . 53 – 55 . Boyd , Danah , and Kate Crawford . ( 2011 ) . Six Provocations for Big Data . A Decade . In Internet Time : Symposium on the Dynamics of the Internet and Society . 21 September 2011 . pp . 1 – 17 . http : / / softwarestudies . com / cultural _ analytics / Six _ Provocations _ for _ Big _ Data . pdf . Brown , John Seely , Allan Collins , and Paul Duguid ( 1989 ) . Situated Learning and the Culture of Learning . Education Researcher , vol . 18 , no . 1 , February 1989 , pp . 32 – 42 . Butchart , Stuart H . M . , Matt Walpole , Ben Collen , Arco van Strien , Jörn P . W . Scharlemann , Rosamunde E . A . Almond , Jonathan E . M . Baillie , et al ( 2010 ) . Global Biodiversity : Indicators of Recent Declines . Science , vol . 328 , no . 5982 , May 2010 , pp . 1164 – 1168 . Chamberlain , Alan ; and Chloe Grif ﬁ ths ( 2013 ) . Moths at Midnight : Design Implications for Supporting Ecology - Focused Citizen Science . MUM ‘ 13 : Proceedings of the 12th International Conference on Mobile and Ubiquitous Multimedia , Luleå , Sweden , 2 – 5 December , 2013 , New York : ACM Press , art . 25 . 728 Dema Tshering et al . Chan , Joel , Steven Dang , and Steven P Dow ( 2016 ) . Comparing Different Sensemaking Approaches for Large - Scale Ideation . CHI ‘ 16 : Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , San Jose , CA , 7 - 12 May 2016 , New York : ACM Press , pp . 2717 – 2728 . Cottman - Fields , Mark , Margot Brereton , Jason Wimmer , and Paul Roe ( 2014 ) . Collaborative Extension of Biodiversity Monitoring Protocols in the Bird Watching Community . PDC ‘ 14 : Proceedings of the 13th Participatory Design Conference , Windhoek , Namibia , 6 - 10 October , 2014 , New York : ACM Press , pp . 111 – 114 . Digby , Andrew , Michael Towsey , Ben D . Bell , and Paul D . Teal ( 2013 ) . A practical comparison of manual and autonomous methods for acoustic monitoring . Methods in Ecology and Evolution , vol . 4 , no . 7 , July 2013 , Bristish Ecological Society , pp . 675 – 683 . Dörk , Marian , Sheelagh Carpendale , and Carey Williamson ( 2011 ) . The Information Flaneur . CHI ' 11 : Proceedings of the 2011 Annual Conference on Human Factors in Computing Systems , Vancouver , BC , 7 - 12 May 2011 , Newyork : ACM Press , pp . 1215 – 1224 . Dörk , Marian ; Rob Comber ; and Martyn Dade - Robertson ( 2014 ) . Monadic Exploration : Seeing the Whole through Its Parts . CHI ' 14 : Proceedings of the 32nd Conference on Human Factors in Computing Systems , Toronto , Canada , 26 April – 1 May 2014 . New York : ACM Press , pp . 1535 – 1544 . Fisher , Kristie , Scott Counts , and Aniket Kittur ( 2012 ) . Distributed Sensemaking : Improving Sensemaking by Leveraging the Efforts of Previous Users . CHI ‘ 12 : Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , Austin , Texas , 5 – 10 May 2012 , New York : ACM Press , pp . 247 – 256 . Frommolt , Karl - Heinz , and Klaus - Henry Tauchert ( 2013 ) . Applying bioacoustic methods for long - term monitoring of a nocturnal wetland bird . Ecological Informatics , vol . 14 , December 2013 , pp . 4 – 12 . Goyal , Nitesh , and Susan R Fussell ( 2016 ) . Effects of Sensemaking Translucence on Distributed Collaborative Analysis . CSCW ‘ 16 : Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing , San Francisco , CA , USA , 27 February – 2 March , 2016 . New York : ACM Press . pp . 288 – 302 . Goyal , Nitesh , Gilly Leshed ; Dan Cosley , and Susan R . Fussell ( 2014 ) . Effects of Implicit Sharing in Collaborative Analysis . CHI ‘ 14 : Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems , Toronto , Canada , 26 April – 1 May , 2014 , New York : ACM Press , pp . 129 – 138 . Goyal , Nitesh , Gilly Leshed , and Susan R Fussell ( 2013 ) . Effects of Visualization and Note - Taking on Sensemaking and Analysis . CHI ‘ 13 : Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , Paris , France , 27 April – 2 May 2013 , New York : ACM Press , pp . 2721 – 2724 . Gutwin , Carl , Gwen Stark , and Saul Greenberg ( 1995 ) . Support for Workspace Awareness in Educational Groupware . CSCL ’ 95 : Proceedings of the First International Conference on Computer Support for Collaborative Learning , Indiana Univ . , Bloomington , Indiana , USA , 17 - 20 October , 1995 , Hillsdale , New Jersey : Lawrence Erlbaum Associates Inc . pp . 147 – 56 . Isenberg , Petra , Niklas Elmqvist , Jean Scholtz , Daniel Cernea , Kwan - Liu Ma , and Hans Hagen ( 2011 ) . Collaborative visualization : De ﬁ nition , challenges , and research agenda . Information Visualization , vol . 10 , no . 4 , October 2011 , pp . 310 – 326 . Kidd , Alison ( 1994 ) . The Marks Are on the Knowledge Worker . CHI ' 94 : Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , Boston , Massachusetts , 24 - 28 April 1994 , New York : ACM Press , pp . 186 – 191 . Collaborative Exploration and Sensemaking of Environmental Acoustics 729 Krause , Bernard L . ( 1993 ) . The Niche Hypothesis : A Virtual Symphony of Animal Sounds , the Origins of Musical Expression and the Health of Habitats . The Soundscape Newsletter , June , 1993 , pp . 6 – 10 . http : / / wfae . proscenia . net / library / newsletter / SNL6 . PDF Lagoze , Carl ( 2014 ) . eBird : Curating Citizen Science Data for Use by Diverse Communities . International Journal of Digital Curation , vol . 9 , no . 1 , February 2014 , pp . 71 – 82 . Latour , Bruno ( 2005 ) . Reassembling the social : An introduction to actor - network theory . Oxford University Press . Latour , Bruno , Pablo Jensen , Tommaso Venturini , Sébastian Grauwin , and Dominique Boullier ( 2012 ) . The Whole Is Always Smaller than Its Parts ’ - a Digital Test of Gabriel Tardes ’ Monads . British Journal of Sociology , vol . 63 , no . 4 , December 2012 , pp . 590 – 615 . Lau , Lydia ; Fan Yang - Turner ; and Nikos Karacapilidis ( 2014 ) . Requirements for big data analytics supporting decision making : A Sensemaking Perspective , In Mastering Data - Intensive Collabora - tion and Decision Making , Big Data Studies , Vol . 5 , Springer International Publishing . pp . 49 – 70 . Light , Ann , Margot Brereton , and Paul Roe ( 2015 ) . Some Notes on the Design of B World Machines . ^ OzCHI ‘ 15 : In Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction , Melbourne , Australia , 7 - 10 December 2015 , New York : ACM Press , pp . 289 – 293 . Ludwig , Thomas ; Tino Hilbert ; and Volkmar Pipek ( 2015 ) . Collaborative Visualization for Supporting the Analysis of Mobile Device Data . ECSCW 2015 : Proceedings of the 14th European Conference on Computer Supported Cooperative Work , Oslo , Norway , 19 - 23 September 2015 , Cham : Springer International Publishing . pp . 305 – 316 . Lycett , Mark . ( 2013 ) . Data ﬁ cation : making sense of ( big ) data in a complex world . European Journal of Information Systems , vol . 22 , no . 4 , July 2013 , Cham : Springer . pp . 381 – 386 . Newbold , Tim , Lawrence N Hudson , Samantha L L Hill , Sara Contu , Igor Lysenko , Rebecca A Senior , Luca Borger , et al ( 2015 ) . Global effects of land use on local terrestrial biodiversity . Nature , vol . 520 , no . 7545 , April 2015 , Nature Publishing Group . pp . 45 – 50 . Paul , Sharoda A , and Madhu C Reddy ( 2010 ) . Understanding Together : Sensemaking in Collaborative Information Seeking . CSCW ‘ 10 : In Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work , Savannah , Georgia , USA , 6 - 10 February 2010 , New York : ACM Press . pp . 321 – 330 . Peirce , Charles Sanders ( 1903 ) . Peirce on Signs : Writings on Semiotic . UNC Press Books , 1991 . Pijanowski , Bryan C . , Luis J . Villanueva - Rivera , Sarah L . Dumyahn , Almo Farina , Bernie L . Krause , Brian M . Napoletano , Stuart H . Gage , and Nadia Pieretti ( 2011 ) . Soundscape Ecology : The Science of Sound in the Landscape . Bio Science , vol . 61 , no . 3 , March 2011 , Oxford University Press . pp . 203 – 216 . Potamitis , Ilyas ( 2014 ) . Automatic Classi ﬁ cation of a Taxon - Rich Community Recorded in the Wild . PLoS ONE , vol . 9 , no . 5 , May 2014 , pp . 1 – 12 . Qu , Yan , and George W Furnas ( 2005 ) . Sources of Structure in Sensemaking . CHI EA ‘ 05 : Proceedings of Extended Abstracts in Human Factors in Computing Systems , Portland , Oregon , USA , 2 – 7 April 2005 . New York : ACM Press . pp . 1989 – 1892 . Robertson , Toni , Margot Brereton , Frank Vetere , and Steve Howard ( 2012 ) . Knowing Our Users : Scoping Interviews in Design Research with Ageing Participants . OzCHI ‘ 12 , Melbourne , Australia , 26 - 30 November , 2012 . New York : ACM Press . pp . 517 – 520 . Rost , Mattias ; Louise Barkhuus ; Henriette Cramer ; and Barry Brown ( 2013 ) . Representation and Communication : Challenges in Interpreting Large Social Media Datasets . In CSCW ‘ 13 : Proceedings of the 2013 conference on Computer Supported Cooperative Work , San Antonio , Texas , 23 - 27 February 2013 , New York : ACM Press . Rotman , Dana , Jenny Preece , Jen Hammock , Kezee Procita , Derek Hansen , Cynthia Parr , Darcy Lewis , and David Jacobs ( 2012 ) . Dynamic Changes in Motivation in Collaborative Citizen - Science Projects . In CSCW ’ 12 : Proceedings of the ACM 2012 Conference on Computer Supported 730 Dema Tshering et al . Cooperative Work , Seattle , Washington , 11 - 15 February 2012 , New York : ACM Press . pp . 217 – 226 . Russell , Daniel M , Mark J Ste ﬁ k , Peter Pirolli , and Stuart K Card ( 1993 ) . The Cost Structure of Sensemaking . CHI ‘ 93 : In Proceedings of the INTERCHI ‘ 93 Conference on Human Factors in Computing Systems , Amsterdam , The Netherlands , 24 - 29 April 1993 , New York : ACM Press , pp . 269 – 276 . Schafer , R . Murray ( 1993 ) . The Soundscape : Our Sonic Environment and the Tuning of the World . Rochester : Inner Traditions / Bear & Co . Servick , Kelly ( 2014 ) . Eavesdropping on Ecosystems . Science , vol . 343 , no . 6173 , February 2014 , pp . 834 – 37 . Star , Susan L . ( 1989 ) . The Structure of Ill - Structured Solutions : Boundary Objects and Heterogeneous Distributed Problem Solving . Distributed Arti ﬁ cial Intelligence . San Francisco : Morgan Kaufmann Publishers Inc . pp . 37 – 54 . Star , Susan L . ( 2010 ) . This is Not a Boundary Object : Re ﬂ ections on the Origin of a Concept . Science , Technology & Human Values , vol . 35 , no . 5 , September 2010 , pp . 601 – 617 . Suchman , Lucy ( 2003 ) . Located Accountabilities in Technology Production . Scandinavian Journal of Information Systems , vol . 14 , no . 2 , September 2002 , pp . 91 – 105 Suchman , Lucy ( 2010 ) . Agencies at the Interface : Expanding Frames and Accountable Cuts . CHI ‘ 10 : In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , Atlanta , Georgia , USA , 10 – 15 April , 2010 , New York : ACM Press . Tao , Yihan , and Anastasios Tombros ( 2013 ) . An Exploratory Study of Sensemaking in Collaborative Information Seeking . ECIR ’ 13 : In Proceedings of the 35th European Conference on Advances in Information Retrieval , Moscow , Russia 24 – 27 March , Berlin , Heidelberg : Springer - Verlag . pp . 26 – 37 Tee , Kimberly , Saul Greenberg , and Carl Gutwin ( 2009 ) . Artifact Awareness through Screen Sharing for Distributed Groups . International Journal of Human Computer Studies , vol . 67 , no . 9 , pp . 677 – 702 . Towsey , Michael , Liang Zhang , Mark Cottman - Fields , Jason Wimmer , Jinglan Zhang , and Paul Roe ( 2014 ) . Visualization of Long - Duration Acoustic Recordings of the Environment . Procedia Computer Science , vol . 29 . pp . 703 – 712 . Truskinger , Anthony ; Mark Cottman - ﬁ elds ; Daniel Johnson ; and Paul Roe ( 2013 ) . Rapid Scanning of Spectrograms for Ef ﬁ cient Identi ﬁ cation of Bioacoustic Events in Big Data , 2013 I . E . 9th International Conference on eScience , Beijing , China , 22 – 25 October 2013 . IEEE , pp . 270 – 277 . Venter , Oscar , Eric W Sanderson , Ainhoa Magrach , James R Allan , Jutta Beher , Kendall R Jones , Hugh P Possingham , et al ( 2016 ) . Sixteen Years of Change in the Global Terrestrial Human Footprint and Implications for Biodiversity Conservation . Nature Communications , vol . 7 , no . 12558 , August 2016 , Virginia , Braun and Victoria Clarke ( 2006 ) . Using Thematic Analysis in Psychology . Qualitative Research in Psychology , vol . 3 , no . 2 , May 2006 , pp . 77 – 101 . Weick , Karl E . , Kathleen M Sutcliffe , and David Obstfeld ( 2005 ) Organizing and the Process 16 , no . 4 , July - August 2005 , pp . 409 – 421 . Weick , Karl E . ( 1995 ) . Sensemaking in Organizations . Thousand Oaks , CA : SAGE Publications . Whittaker , Steve ( 2008 ) . Making Sense of Sense making . In T . Erickson and D . W . McDonald ( eds ) : HCI Remixed : Re ﬂ ections on Works That Have In ﬂ uenced the HCI Community . Cambridge , Massachusetts , London , MIT Press . pp . 173 - 178 Wiggins , Andrea , and Kevin Crowston ( 2011 ) . From Conservation to Crowdsourcing : A Typology of Citizen Science . HICSS ‘ 11 : In Proceedings of the 2011 44th Hawaii International Conference on System Sciences . Washington , DC : IEEE Computer Society , pp . 1 - 10 . Collaborative Exploration and Sensemaking of Environmental Acoustics 731