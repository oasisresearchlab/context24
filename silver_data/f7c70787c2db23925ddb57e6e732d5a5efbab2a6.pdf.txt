Who breaks early , looses : goal oriented training of deep neural networks based on port Hamiltonian dynamics Julian Burghoff Department of Mathematics & IZMD University of Wuppertal Wuppertal , Germany burghoff @ math . uni - wuppertal . de Marc Heinrich Monells Department of Mathematics University of Wuppertal Wuppertal , Germany marc . heinrich monells @ uni - wuppertal . de Hanno Gottschalk Institute of Mathematics TU - Berlin Berlin , Germany gottschalk @ math . tu - berlin . de Abstract —The highly structured energy landscape of the loss as a function of parameters for deep neural networks makes it necessary to use sophisticated optimization strategies in order to discover ( local ) minima that guarantee reasonable performance . Overcoming less suitable local minima is an important prerequisite and often momentum methods are employed to achieve this . As in other non local optimization procedures , this however creates the necessity to balance be - tween exploration and exploitation . In this work , we suggest an event based control mechanism for switching from exploration to exploitation based on reaching a predeﬁned reduction of the loss function . As we give the momentum method a port Hamiltonian interpretation , we apply the ’heavy ball with friction’ interpretation and trigger breaking ( or friction ) when achieving certain goals . We benchmark our method against standard stochastic gradient descent and provide experimental evidence for improved performance of deep neural networks when our strategy is applied . Index Terms —neural nets • momentum • goal oriented search • port Hamilton systems 1 . Introduction The success of deep neural networks ( DNN ) signiﬁ - cantly depends on the cheap computation of gradients using back - propagation enabling gradient based minimization of the loss functions . As the parameter count of DNN ranges between several tens of thousand in small classiﬁcation networks to several billion in large scale generative models , there seems to be no alternative to the use of gradients . However , gradient based optimization is beset with the problem of local minima , of which the energy landscape of DNN offers plenty . Exploitation of a local minimum with gradient descent comes with guarantees for progress relative to previous optimization steps , but does not guar - antee a decent level of performance . In order to go more global , momentum methods have therefore been introduced to overcome local minima . As compared to gradient descent , momentum based methods have more parameters to adjust . Besides the strength of the inertial forces controlled by the ’mass’ pa - rameter , a ’friction’ parameter has to be determined , which is responsible for slowing down the search motion and bringing it to rest , ultimately . Finally , the learning rate needs to be controlled throughout the progress of the optimization process , like in gradient descent . The complexity in setting and controlling the aforemen - tioned hyper - parameters can be alleviated by an interpreta - tion of the optimization process in physical terms as already indicated by the physical connotations of ’mass’ and ’fric - tion’ . It has been recently proposed to cast the optimization process in a port Hamiltonian framework , which makes the convergence of the optimization process to a stationary point transparent via energy based considerations , where loss is connected to potential and momentum to kinetic energy , whereas ’friction’ accounts for energy dissipation and inter - dicts motion at high pace for unlimited time . It is clear that the friction / energy dissipation parameter is essential for the ( non ) locality of the optimization process : if high , friction essentially damps out all momentum and the procedure essentially ’just ﬂows down the hill’ as for gradient descent , resulting in low exploration and high exploitation . If low , the motion will go on essentially un - damped and not rest and thereby explore all of the accessible parameter space . Exploration is high , and exploitation is low in this setting . Then , parameter settings can be modiﬁed over time or controlled adaptively as a part of the optimization algo - rithm is a familiar thought . The physics based intuition of port Hamiltonian systems can be helpful in the design of such adaptive strategies . Here we suggest a simple , event based adaptive parameter selection strategy that starts the optimization in an exploratory phase with low friction and turns over to exploitation by ’heavy breaking’ , once the po - tential energy ( i . e . the loss function ) is sufﬁciently reduced . Sufﬁciency is pre - deﬁned as the minimum reduction goal of the optimization , which can be set , e . g . , as the reduction of the loss obtained in previous trials . In this paper , we show that the proposed strategy actually works for some classical examples in deep learning and improves the optimization loss and also the test accuracy for a standard , Le - Net - 5 [ 1 ] based architectures on two well known academic classiﬁcation tasks solved by deep a r X i v : 2304 . 07070v1 [ c s . L G ] 14 A p r 2023 learning , namely the CIFAR10 [ 2 ] and the FashionMNIST [ 3 ] data - sets . In order to focus on the optimization only , we do not employ data augmentation or pre - training and thereby do not achieve SOTA performance in our experiments . We however consistently achieve an advantage over the widely used stochastic gradient descent as a benchmark . We also observe consistent gains in performance after ’heavy breaking’ is ﬁnally triggered . Our paper is organized as follows : in Section 2 we give an overview over related work and in Section 3 we present the port Hamiltonian view on gradient based optimization with momentum and energy dissipation . Our experimental setup as well as our results are documented in Section 4 . In the ﬁnal Section 5 we present our conclusions and give an outlook to future research . 2 . Related Work The fact that neural networks with parameter counts ranging from some tenth of thousands to several hundreds of billions can actually be trained , largely depends on the cheap computation of gradients , see [ 4 , 5 ] for original work and [ 6 ] for a recent reference . Gradient based optimization itself has been studied since the days of Newton , see e . g . [ 7 , 8 ] . In the context of deep learning , the formation of randomly sub - sampled mini - batches is necessary as big data often exceeds the working memory available [ 9 ] . One has therefore to pass over to the stochastic gradient descent method ( SGD ) [ 10 , 11 ] . One of the problems in neural network training is the complex , non convex structure of the energy landscapes [ 12 ] . This makes it necessary to avoid local minima , which is mostly done by the momentum method [ 13 – 15 ] . From a theoretical side , momentum can be understood as a dis - cretized version of a second order ordinary differential equa - tion , which also provides theoretical insight to convergence to critical points [ 16 – 18 ] , see also [ 19 – 21 ] for recent exten - sions . The momentum method has recently be cast in a modern port Hamiltonian language [ 22 – 24 ] . Port Hamiltonian sys - tems [ 25 ] are particularly suited to understand the long time behviour and hence convergence properties of momentum based methods . For a long time , the control of hyperparemeters in the training of neural networks has been a topic of interest in the deep learning community [ 26 ] . While learning rate schedules [ 27 , 28 ] determine the setting for one speciﬁc parameter upfront , it has also been proposed to modify the dissipation parameter in momentum based optimization [ 17 , 29 , 30 ] . Other strategies , like the much used ADAM algorithm , rely on adaptive parameter control [ 31 , 32 ] . One speciﬁc adaptive strategy however much less con - sidered is the goal oriented search , where one pre - deﬁnes the target value to achieve during optimization , see e . g . [ 33 ] . In our work , we thus make the following contributions : • For the ﬁrst time , we use the port Hamiltonian language in the training of reasonably deep neural networks in contracst to [ 22 , 23 ] where networks are shallow . • We also introduce an adaptive , goal oriented strategy for the control of the friction constant , which goes in the opposite direction as [ 17 , 29 , 30 ] but is well - motivated in terms of combining exploration and exploitation in one algorithm . • We show experimentally for standard deep learn - ing problems in image recognition that this strat - egy consistently produces improvements over ﬁxed - parameter strategies . We also provide a considerable amount of ablation studies related to our parameter settings . 3 . The Goal Oriented PHS Method The simple gradient descent algorithm to minimize a differentiable loss function L ( θ ) , namely θ k + 1 = θ k − α ∇ θ L ( θ k ) can be seen as a ﬁrst order Euler discretization of the gradient ﬂow ˙ θ ( t ) = −∇ θ L ( θ ) , θ ( 0 ) = θ 0 . ( 1 ) It is well known that under adequate conditions on L ( θ ) , the ﬂow θ ( t ) converges for t → ∞ to a critical point θ ∗ with ∇ θ L ( θ ∗ ) = 0 , see e . g . [ 22 , 23 ] . Likewise , the gradient descent algorithm converges for k → ∞ to a critical point , provided the step length α is suitably controlled , confer [ 16 , 17 ] . As mentioned in the introduction , the problem with gradient descent in the context of highly non - convex loss functions L ( θ ) , as especially in the context of the training of deep neural networks [ 6 ] , lies in the fact that gradient ﬂows and gradient descent algorithms get stuck in local minima . To over come the strict locality of gradient ﬂow and gradient descent , momentum based methods have been in - troduced . The update rule of gradient descent is changed to θ k + 1 = θ k + α 1 mp k p k + 1 = p k − α γ mp k − α ∇ θ L ( θ ) ( 2 ) where m , γ > 0 are parameters called mass and friction coefﬁcient . p k is the so - called momentum at iteration k . In fact , ( 2 ) can be understood as the discretized version of the following Hamiltonian set of equations ˙ θ ( t ) = 1 mp ( t ) ˙ p ( t ) = − γ mp ( t ) − ∇ θ L ( θ ) ( 3 ) with initial conditions θ ( 0 ) = θ 0 and p ( 0 ) = p 0 . To understand the global properties of the Hamiltonian dynamics , it is convenient to deﬁne a state variable x ( t ) = (cid:16) θ ( t ) p ( t ) (cid:17) and the Hamiltonial function H ( x ) = (cid:107) p (cid:107) 2 2 m + L ( θ ) and a the symplectic matrix J = (cid:18) 0 − 1 1 0 (cid:19) as well as a symmetric , positive resistive matrix J = (cid:18) 0 0 0 γm (cid:19) so that we can rewrite ( 3 ) in the compact , port - Hamiltonian form ˙ x ( t ) = ( J − R ) ∇ x H ( x ) . ( 4 ) Using the chain - rule , ( 4 ) and ∇ x H ( x ( τ ) ) (cid:62) J ∇ x H ( x ( τ ) ) = 0 by the skew - symmetry of J , it is now easy to see that the following inequality holds for the dissipated total ’energy’ measured by H ( x ) , where (cid:107) p (cid:107) 2 2 m takes the role of kinetic energy and the loss L ( θ ) the role of potential energy H ( x ( t ) ) − H ( x ( 0 ) ) = − (cid:90) t 0 ∇ x H ( x ( τ ) ) (cid:62) R ∇ x H ( x ( τ ) ) d τ . ( 5 ) From this exposition it is intuitive , and in fact can be proven mathematically [ 16 , 17 ] , that due to dissipation the state x ( t ) ultimately has to come to a rest , if L ( θ ) is bounded from below . Thus , if the stationary points x ∗ with ∇ x H ( x ∗ ) = 0 of the system are isolated , x ( t ) will asymptotically converge to a stationary point . Furthermore , for x ∗ = (cid:16) θ ∗ p ∗ (cid:17) , we ﬁnd p ∗ = 0 and ∇ θ L ( θ ∗ ) = 0 , hence the θ - component of stationary points are in one to one correspondence to the critical points of the original optimization problem . Energy dissipation ( 5 ) thus is the key component that de - termines how fast x ( t ) comes to rest , which conceptually is corresponding to convergence of the optimization algorithm . Apparently , the matrix R and thus the friction coefﬁcient γ controls dissipation . In fact , if γ ≈ 0 , essentially no energy is lost and the dynamics x ( t ) will either move on for a very long time , or , in very rare cases , get to rest on a local maximum or saddle point . This perpetual motion through the accessible part of the ’phase space’ can be seen as an exploitative strategy . In contrast , if γ gets large , the friction essentially dis - perses energy and momentum and the motion of x ( t ) be - haves highly viscous , i . e . determined by the equality − γ mp ( t ) − ∇ θ L ( θ ) ≈ 0 ⇔ ˙ θ ( t ) ≈ − 1 γ ∇ θ L ( θ ) , ( 6 ) from which we see that in this high viscosity regime the port Hamiltonian ﬂow essentially behaves like gradient de - scent ( with a modiﬁed step length ) . Despite working with momentum , we are thus back in the exploitation phase of local minima . The idea of this article is to use this physics based intuition to efﬁciently control the behavior of our port Hamiltonian optimization strategy in a goal oriented search . We thus propose to ’keep on moving’ as long as we have not yet reached a predeﬁned reduction of the initial loss function L ( θ 0 ) . In many cases , it is known that L ( θ ) is lower bounded by zero , and we can thus demand a 90 % , 95 % . . . reduction in L ( x ( t ) ) , before we , upon reaching this target , instantaneously increase the value of γ in order to switch over from the low - viscous exploration phase to high - viscous exploitation . In this sense , our proposed optimiza - tion algorithm resembles the ’chicken game’ : who breaks too early , looses . 10 1 10 0 10 1 10 2 10 3 10 4 10 5 Mass 0 . 2 0 . 4 0 . 6 0 . 8 A cc u r a c y 10 4 10 3 10 2 10 1 10 0 10 1 Friction Figure 1 : Selecting hyperparameters of learning rate ( here : α = 0 . 1 ) , mass and friction based on the accuracy on the Fahion - MNIST dataset Before we come to the implementation and numerical tests of this strategy in deep learning , we discuss some peculiarities of the loss function in this case . We would like to learn a conditional probability density p ( y | x , θ ) from data independently sampled from the same distribution { ( y i , x i ) } ni = 1 , where x i is some input and y i takes values in some prescribed label space C = { c 1 , . . . , c q } . In applica - tions in image recognition , p ( y | x , θ ) often consists of several stacked convolutional and fully connected layers and an ultimate softmax layer , cf . [ 6 ] . The ’cross entropy’ / negative log likelihood loss is given by L ( θ ) = − 1 n n (cid:88) i = 1 log p ( y i | x i , θ ) . ( 7 ) The numerical problem to implement ( 7 ) directly lies in the memory constraints that do not permit to load the entire data set { ( y i , x i ) } ni = 1 in the working memory . Therefore , mini batches B j , i . e . small random subsets of { 1 , . . . , n } are drawn and an update step of the parameters θ k and the associated momentum is executed for a loss L B j ( θ ) with the original data set replaced by { ( y i , x i ) } i ∈ B j . Nevertheless , as in image classiﬁcation oftentimes the batch | B j | is quite large ( (cid:39) 10 ) , L B j ( θ ) and L ( θ ) tend do behave similar by the law of large numbers . In our numerical experiments , we therefore observe the behavior of the algorithm in accor - dance with intuition . 4 . Experiments and results For our experiments , we use a Convolutional Neural Net ( CNN ) similar to the Le - Net - 5 [ 1 ] which consists of two convolutional , one pooling and two fully connected layers as it is shown in ﬁgure 2 and has a total of 44 , 426 weights . For implementation we are using the PyTorch framework [ 34 ] . This network is chosen as it is a widely used standard 6 32 16 16 120 84 1 Figure 2 : Neural Net architecture which is similar to Le - Net - 5 . Orange are convolutional layers with a ﬁlter size of 5 , red is the pooling layer and fully connected layers are violet . architecture , although it is not eligible to compete with more sophisticated ResNet [ 35 ] or Transformer [ 36 ] architectures . Furthermore , in order to focus on training exclusively , the networks are trained from scratch on the data sets and we use neither pre - training nor augmentation . The training is performed with respect to the usual cross - entropy loss without regularization . On the hardware - side , we use a workstation with an Intel ( R ) Core ( TM ) i7 - 6850K 3 . 6GHz and two Nvidia TI - TAN Xp graphic units with 12GB VRAM each for our experiments . For a comparison with SGD and PHS , i . e . the traditional momentum method , we test our goal oriented PHS search on the two data sets CIFAR10 and FashionMNIST intro - duced above . We furthermore run trainings for a number of different learning rates α and for several settings for the mass and baseline friction parameter . To establish which parameter settings are rewarding , we consider the accuracies of the PHS for different learning rates ( 0 . 0001 ≤ α ≤ 0 . 1 ) , that can be achieved when mass and friction are included . This is shown in Figure 1 for the example of α = 0 . 1 on the Fashion - MNIST dataset . As one can already see , the trainings for many parameter settings work signiﬁcantly worse or not at all . Therefore , only experiments that lie in a parameter range leading to reasonable results are included in our result tables . Concerning goal orientation , we aim at an reduction of the initial loss of 65 % to 90 % and then increase the friction signiﬁcantly by a factor between 5 and 99 . The results are given in Tables 1 for CIFAR10 and 2 for FashionMNIST . As can be seen in ﬁgure 3a , the accuracy of the method is consistantly improved by breaking after reaching the goal , and the subsequent occurrence of overﬁtting ( as happens with the PHS ) is avoided . The increase in test accuracy lies α Optimizer Fric Mass Acc 0 . 1 SGD / / 64 . 82 % 0 . 1 PHS 0 . 1 100 66 . 45 % 0 . 1 Goal - Oriented ( breaking at 0 . 65 with factor 49 ) 0 . 1 100 67 . 1 % 0 . 1 PHS 0 . 01 100 63 . 52 % 0 . 1 Goal - Oriented ( breaking at 0 . 9 with factor 99 ) 0 . 01 100 65 . 52 % 0 . 01 SGD / / 63 . 53 % 0 . 01 PHS 0 . 1 25 66 . 01 % 0 . 01 Goal - Oriented ( breaking at 0 . 7 with factor 10 ) 0 . 1 25 66 . 49 % 0 . 01 PHS 0 . 01 25 62 . 98 % 0 . 01 Goal - Oriented ( breaking at 0 . 7 with factor 50 ) 0 . 01 25 63 . 44 % 0 . 001 SGD / / 65 . 05 % 0 . 001 PHS 1 0 . 25 66 . 0 % 0 . 001 Goal - Oriented ( breaking at 0 . 7 with factor 20 ) 1 0 . 25 66 . 37 % 0 . 001 PHS 0 . 1 0 . 25 62 . 93 % 0 . 001 Goal - Oriented ( breaking at 0 . 85 with factor 50 ) 0 . 1 0 . 25 63 . 54 % 0 . 0001 SGD / / 64 . 43 % 0 . 0001 PHS 10 0 . 001 65 . 76 % 0 . 0001 Goal - Oriented ( breaking at 0 . 68 with factor 5 ) 10 0 . 001 66 . 39 % 0 . 0001 PHS 1 0 . 001 62 . 24 % 0 . 0001 Goal - Oriented ( breaking at 0 . 8 with factor 100 ) 1 0 . 001 63 . 56 % TABLE 1 : Comparison of training results with SGD , PHS and Goal - Oriented approaches for the CIFAR - 10 dataset . α Optimizer Fric Mass Acc 0 . 1 SGD / / 90 . 04 % 0 . 1 PHS 0 . 1 10 90 . 36 % 0 . 1 Goal - Oriented ( breaking at 0 . 15 with factor 50 ) 0 . 1 10 91 . 02 % 0 . 1 PHS 0 . 01 10 83 . 31 % 0 . 1 Goal - Oriented ( breaking at 0 . 55 with factor 20 ) 0 . 01 10 87 . 19 % 0 . 01 SGD / / 90 . 26 % 0 . 01 PHS 1 0 . 1 90 . 49 % 0 . 01 Goal - Oriented ( breaking at 0 . 2 with factor 10 ) 1 0 . 1 90 . 98 % 0 . 01 PHS 0 . 1 0 . 1 83 . 28 % 0 . 01 Goal - Oriented ( breaking at 0 . 5 with factor 5 ) 0 . 1 0 . 1 86 . 47 % 0 . 001 SGD / / 89 . 61 % 0 . 001 PHS 10 0 . 01 90 . 34 % 0 . 001 Goal - Oriented ( breaking at 0 . 15 with factor 5 ) 10 0 . 01 90 . 8 % 0 . 001 PHS 1 0 . 01 90 . 13 % 0 . 001 Goal - Oriented ( breaking at 0 . 17 with factor 50 ) 1 0 . 01 90 . 77 % 0 . 0001 SGD / / 88 . 86 % 0 . 0001 PHS 10 0 . 001 90 . 17 % 0 . 0001 Goal - Oriented ( breaking at 0 . 2 with factor 100 ) 10 0 . 001 90 . 54 % 0 . 0001 PHS 1 0 . 001 89 . 6 % 0 . 0001 Goal - Oriented ( breaking at 0 . 185 with factor 100 ) 1 0 . 001 90 . 12 % TABLE 2 : Comparison of training results with SGD , PHS and Goal - Oriented approaches for the FashionMNIST dataset . 0 20 40 60 80 100 Epochs 0 . 725 0 . 750 0 . 775 0 . 800 0 . 825 0 . 850 0 . 875 0 . 900 A cc u r a c y ( a ) α = 0 . 1 , friction = 0 . 1 , mass = 10 on Fashion - MNIST . 0 20 40 60 80 100 Epochs 0 . 60 0 . 65 0 . 70 0 . 75 0 . 80 0 . 85 0 . 90 A cc u r a c y ( b ) α = 0 . 01 , friction = 1 , mass = 0 . 1 on Fashion - MNIST . 0 20 40 60 80 100 Epochs 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 A cc u r a c y ( c ) α = 0 . 1 , friction = 0 . 1 , mass = 100 on CIFAR - 10 . 0 25 50 75 100 125 150 175 200 Epochs 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 A cc u r a c y ( d ) α = 0 . 01 , friction = 0 . 1 , mass = 25 on CIFAR - 10 . Figure 3 : History of the accuracies over the epochs depending on the choosable hyperparameters learning rate α , friction and mass . PHS in orange , Goal - oriented approach in blue . around and in many cases above 0 . 5 % throughout parameter settings and the two data sets employed , as documented in Table 1 for CIFAR10 and Table 2 for FashionMNIST . The history of the test accuracy over the iteration count of the optimization procedure is shown in Figure 3 for two example conﬁgurations of each dataset . As we observe , the sudden ’breaking’ exploits a local minimum better and avoids overﬁtting ( as it can be especially seen in ﬁgure 3a ) , i . e . the decrease of the ordinary PHS method in the further pursuit of the optimization . Interestingly , this hints that overﬁtting rather is a ’global’ phenomenon associated with ongoing exploration , whereas exploitation of the local minimum seems less beset from overﬁtting issues . This is consistent with our observation that the training loss after ’breaking’ quickly converges , whereas the training loss for SGD or PHS is further reduced . This suggest that the onset of overﬁtting could thus also be a useful triggering event for ’breaking’ instead of goal orientation , as employed here . 5 . Discussion and Outlook In our paper , we have introduced a new goal oriented strategy for the training of deep neural networks . By the physics - motivated interpretation of momentum in a port Hamiltonian framework , we explained how different settings for the friction / dissipation correspond to an exploration or exploitation phase in the progress of optimization . By switching from exploration to exploitation when a certain minimal reduction of the loss function of a deep neural network is achieved , we obtain improved classiﬁcation ac - curacy of image classiﬁcation networks as compared with simple stochastic gradient descent or a momentum based optimization with ﬁxed friction . The outlined strategy can be extended in several ways . First , for the case where the minimal reduction is never achieved for a long time , the exploitation phase could be executed nevertheless starting from the best parameter set - ting found so far , or the target could be adjusted . This will robustify our algorithm . Second , after a ﬁrst exploitation phase , a re - acceleration could be executed , e . g . by an exter - nal force or ’port’ , so that multiple promising local minima can be visited . Acknowledgements : The authors thank Onur T . Doganay , Kathrin Klamroth , Matthias Rottmann and Claudia Totzeck for interesting discussions . This work is partially funded by the German Federal Ministry for Economic Affairs and Climate Action , within the project “KI Delta Learning” , grant no . 19A19013Q . References [ 1 ] Y . LeCun , L . Bottou , Y . Bengio , and P . Haffner , “Gradient - based learning applied to document recognition , ” Proceed - ings of the IEEE , vol . 86 , no . 11 , pp . 2278 – 2324 , 1998 . [ 2 ] A . Krizhevsky , G . Hinton , et al . , “Learning multiple layers of features from tiny images , ” 2009 . [ 3 ] H . Xiao , K . Rasul , and R . Vollgraf , “Fashion - mnist : A novel image dataset for benchmarking machine learning al - gorithms , ” CoRR , vol . abs / 1708 . 07747 , 2017 . arXiv : 1708 . 07747 . [ Online ] . Available : http : / / arxiv . org / abs / 1708 . 07747 . [ 4 ] P . J . Werbos , “Applications of advances in nonlinear sensi - tivity analysis , ” in System Modeling and Optimization : Pro - ceedings of the 10th IFIP Conference New York City , USA , August 31 – September 4 , 1981 , Springer , 2005 , pp . 762 – 770 . [ 5 ] Y . LeCun , L . Bottou , Y . Bengio , and P . Haffner , “Gradient - based learning applied to document recognition , ” Proceed - ings of the IEEE , vol . 86 , no . 11 , pp . 2278 – 2324 , 1998 . [ 6 ] I . Goodfellow , Y . Bengio , and A . Courville , Deep learning . MIT press , 2016 . [ 7 ] M . S . Bazaraa , H . D . Sherali , and C . M . Shetty , Nonlinear Programming – Theory and Algorithms , 3rd . Wiley , 2006 . [ 8 ] S . Wright , J . Nocedal , et al . , “Numerical optimization , ” Springer Science , vol . 35 , no . 67 - 68 , p . 7 , 1999 . [ 9 ] M . Li , T . Zhang , Y . Chen , and A . J . Smola , “Efﬁcient mini - batch training for stochastic optimization , ” in Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining , 2014 , pp . 661 – 670 . [ 10 ] D . Saad , “Online algorithms and stochastic approxima - tions , ” Online Learning , vol . 5 , no . 3 , p . 6 , 1998 . [ 11 ] S . Shalev - Shwartz and S . Ben - David , Understanding ma - chine learning : From theory to algorithms . Cambridge uni - versity press , 2014 . [ 12 ] S . Becker , Y . Zhang , et al . , “Geometry of energy landscapes and the optimizability of deep neural networks , ” Physical review letters , vol . 124 , no . 10 , p . 108 301 , 2020 . [ 13 ] Y . Nesterov , “A method for unconstrained convex mini - mization problem with the rate of convergence o ( 1 / kˆ 2 ) , ” in Doklady an ussr , vol . 269 , 1983 , pp . 543 – 547 . [ 14 ] G . Goh , “Why momentum really works , ” Distill , vol . 2 , no . 4 , e6 , 2017 . [ 15 ] N . Qian , “On the momentum term in gradient descent learn - ing algorithms , ” Neural networks , vol . 12 , no . 1 , pp . 145 – 151 , 1999 . [ 16 ] A . Antipin , “Second order proximal differential systems with feedback control , ” Differential Equations , vol . 29 , pp . 1597 – 1607 , 1993 . [ 17 ] H . Attouch , Z . Chbani , J . Peypouquet , and P . Redont , “Fast convergence of inertial dynamics and algorithms with asymptotic vanishing viscosity , ” Mathematical Program - ming , vol . 168 , pp . 123 – 175 , 2018 . [ 18 ] B . Polyack , “Some methods of speeding up the convergence of iterative methods , ” Z . Vylist Math . Fiz . , vol . 4 , pp . 1 – 17 , 1964 . [ 19 ] P . Ochs , Y . Chen , T . Brox , and T . Pock , “IPiano : Inertial proximal algorithm for non - convex optimization , ” SIAM Journal on Imaging Sciences , vol . 7 , pp . 1388 – 1419 , 2014 . [ 20 ] P . Ochs , “Local convergence of the heavy - ball method and iPiano for non - convex optimization , ” Journal of Optimiza - tion Theory and Applications , vol . 177 , pp . 153 – 180 , 2018 . [ 21 ] P . Ochs and T . Pock , “Adaptive Fista for non - convex optimization , ” SIAM Journal on Optimization , vol . 29 , pp . 2482 – 2503 , 2019 . [ 22 ] S . Massaroli , M . Poli , F . Califano , A . Faragasso , J . Park , A . Yamashita , and H . Asama , “Port – hamiltonian approach to neural network training , ” in 2019 IEEE 58th Conference on Decision and Control ( CDC ) , IEEE , 2019 , pp . 6799 – 6806 . [ 23 ] M . Poli , S . Massaroli , A . Yamashita , H . Asama , and J . Park , “Port - hamiltonian gradient ﬂows , ” in ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations , 2020 . [ 24 ] N . B . Kovachki and A . M . Stuart , “Continuous time analy - sis of momentum methods , ” Journal of Machine Learning Research , vol . 22 , pp . 1 – 40 , 2021 . [ 25 ] A . Van Der Schaft , D . Jeltsema , et al . , “Port - hamiltonian systems theory : An introductory overview , ” Foundations and Trends® in Systems and Control , vol . 1 , no . 2 - 3 , pp . 173 – 378 , 2014 . [ 26 ] Y . Bengio , “Practical recommendations for gradient - based training of deep architectures , ” Neural Networks : Tricks of the Trade : Second Edition , pp . 437 – 478 , 2012 . [ 27 ] C . Darken and J . Moody , “Note on learning rate schedules for stochastic optimization , ” Advances in neural informa - tion processing systems , vol . 3 , 1990 . [ 28 ] C . Darken , J . Chang , J . Moody , et al . , “Learning rate schedules for faster stochastic gradient search , ” in Neu - ral networks for signal processing , Citeseer , vol . 2 , 1992 , pp . 3 – 12 . [ 29 ] A . Cabot , H . Engler , and S . Gadta , “On the long time behavior of second order differential equations with asymp - totically small dissipation , ” Transactions of the American Mathematical Society , vol . 361 , pp . 5983 – 6017 , 2009 . [ 30 ] A . Chambolle and C . Dossal , “On the convergence of the iterates of the “fast iterative shrinkage / thresholding algo - rithm” , ” J . Optim . Theory Appl . , vol . 166 , pp . 968 – 982 , 2015 . DOI : 10 . 1007 / s10957 - 015 - 0746 - 4 . [ 31 ] D . P . Kingma and J . Ba , “Adam : A method for stochastic optimization , ” arXiv preprint arXiv : 1412 . 6980 , 2014 . [ 32 ] S . Bock and M . Weiß , “A proof of local convergence for the adam optimizer , ” in 2019 international joint conference on neural networks ( IJCNN ) , IEEE , 2019 , pp . 1 – 8 . [ 33 ] A . Sobester , A . Forrester , and A . Keane , Engineering design via surrogate modelling : a practical guide . John Wiley & Sons , 2008 . [ 34 ] A . Paszke , S . Gross , F . Massa , A . Lerer , J . Bradbury , G . Chanan , T . Killeen , Z . Lin , N . Gimelshein , L . Antiga , A . Desmaison , A . Kopf , E . Yang , Z . DeVito , M . Raison , A . Tejani , S . Chilamkurthy , B . Steiner , L . Fang , J . Bai , and S . Chintala , “Pytorch : An imperative style , high - performance deep learning library , ” in Advances in Neural Informa - tion Processing Systems 32 , Curran Associates , Inc . , 2019 , pp . 8024 – 8035 . [ Online ] . Available : http : / / papers . neurips . cc / paper / 9015 - pytorch - an - imperative - style - high - performance - deep - learning - library . pdf . [ 35 ] K . He , X . Zhang , S . Ren , and J . Sun , “Deep residual learning for image recognition , ” in Proceedings of the IEEE conference on computer vision and pattern recognition , 2016 , pp . 770 – 778 . [ 36 ] A . Vaswani , N . Shazeer , N . Parmar , J . Uszkoreit , L . Jones , A . N . Gomez , Ł . Kaiser , and I . Polosukhin , “Attention is all you need , ” Advances in neural information processing systems , vol . 30 , 2017 .