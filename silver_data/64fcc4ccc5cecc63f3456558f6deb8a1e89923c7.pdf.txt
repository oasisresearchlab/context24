PubGraph : A Large - Scale Scientiﬁc Knowledge Graph Kian Ahrabian , Xinwei Du , Richard Delwin Myloth , Arun Baalaaji Sankar Ananthan , and Jay Pujara University of Southern California , Information Sciences Institute , Marina del Rey CA 90292 , USA { ahrabian , xinweidu , myloth , arunbaal , jpujara } @ usc . edu Abstract . Research publications are the primary vehicle for sharing scientiﬁc progress in the form of new discoveries , methods , techniques , and insights . Unfortunately , the lack of a large - scale , comprehensive , and easy - to - use resource capturing the myriad relationships between publi - cations , their authors , and venues presents a barrier to applications for gaining a deeper understanding of science . In this paper , we present PubGraph , a new resource for studying scientiﬁc progress that takes the form of a large - scale knowledge graph ( KG ) with more than 385M entities , 13B main edges , and 1 . 5B qualiﬁer edges . PubGraph is com - prehensive and uniﬁes data from various sources , including Wikidata , OpenAlex , and Semantic Scholar , using the Wikidata ontology . Beyond the metadata available from these sources , PubGraph includes outputs from auxiliary community detection algorithms and large language mod - els . To further support studies on reasoning over scientiﬁc networks , we create several large - scale benchmarks extracted from PubGraph for the core task of knowledge graph completion ( KGC ) . These benchmarks present many challenges for knowledge graph embedding models , includ - ing an adversarial community - based KGC evaluation setting , zero - shot inductive learning , and large - scale learning . All of the aforementioned resources are accessible at https : / / pubgraph . isi . edu / and released un - der the CC - BY - SA license . We plan to update PubGraph quarterly to accommodate the release of new publications . Keywords : Scientiﬁc Knowledge Graphs · Knowledge Graph Comple - tion · Inductive Learning 1 Introduction Scientiﬁc progress takes many forms , from discovering new species to repurpos - ing extant models for novel tasks . Innovation in science has been studied from a variety of perspectives , including the combination of scholarly domains [ 12 , 28 ] , sociological factors [ 8 ] , and analogical reasoning [ 13 , 17 ] . However , many studies of this phenomenon have been limited due to the diﬃculty in ﬁnding and using large - scale data for the domain . In this paper , we address this obstacle by in - troducing PubGraph , a knowledge graph ( KG ) with new resources and bench - marks , enabling the study of scientiﬁc research at scale using structural patterns a r X i v : 2302 . 02231v2 [ c s . A I ] 19 M a y 2023 2 K . Ahrabian et al . in citation and collaboration networks . PubGraph also provides a unique op - portunity to compare models on core tasks such as transductive and inductive knowledge graph completion ( KGC ) . PubGraph is a large - scale multi - relational KG built on top of the OpenAlex catalog [ 23 ] and the Wikidata [ 29 ] ontology . It consists of more than 385M en - tities , comprising authors , institutions , sources , papers , and concepts , and more than 13B main edges and 1 . 5B qualiﬁer edges among those entities . PubGraph captures temporal information , allowing the study of scientiﬁc works’ dynamics . Additionally , it also connects the scholarly articles available in OpenAlex to their counterparts in the Semantic Scholar Academic Graph ( S2AG ) [ 30 ] and Wiki - data through external ids . Moreover , besides the metadata information available in OpenAlex , PubGraph provides outputs from auxiliary community detection algorithms and large language models to further assist future studies of scien - tiﬁc articles . Fig . 1 illustrates an overview of PubGraph schema . In this paper , we describe the methodology used to construct PubGraph , i . e . , the ontological choices made for mapping OpenAlex to Wikidata , the model choices to extract outputs from auxiliary models , and the entity resolution procedure for mapping OpenAlex articles to S2AG and Wikidata . One of the essential parts of studying scientiﬁc progress is understanding and reasoning about connections between ideas and discoveries . However , there is a shortage of benchmarks that could be used to study such topics . In the past , citations have proven to be crucial in studying publications and their im - pact [ 22 ] . Prior works have also studied tasks on citations such as intent classi - ﬁcation [ 5 , 11 , 16 ] , recommendation [ 3 , 9 ] , and prediction [ 7 , 20 ] . In this work , we introduce new large - scale benchmarks for ﬁnding connections among scientiﬁc works framed as a KGC task . The KGC task requires models to predict a target entity , given a source entity and a relation . The aim of this task is to support the study of citations from a structural perspective in both transductive , i . e . , all nodes are known , and inductive , i . e . , evaluation nodes are unseen , settings . Moreover , we also identify a community - based adversarial evaluation setting that mitigates the inﬂuence of random negative sampling in the evaluation phase of large - scale KGs . The contributions of this work are summarized as follows : 1 . Introducing PubGraph , a billion - scale , multi - relational KG built on top of the OpenAlex catalog 2 . Mapping the OpenAlex metadata to Wikidata ontology 3 . Connecting two other large - scale scholarly metadata repositories , S2AG and Wikidata , to make PubGraph a unifying and comprehensive resource 4 . Introducing large - scale extrapolated KGC benchmarks for KG models in both transductive and inductive settings 5 . Identifying challenging adversarial evaluation settings for KGC benchmarks 2 Building PubGraph The primary source for creating PubGraph is the metadata in the OpenAlex catalog that we map to the Wikidata ontology . OpenAlex is an open - source cat - PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 3 Fig . 1 . Overview of PubGraph schema . Legend . Colors : Blue → Main entity , Yellow → Boolean attribute , Purple → Multi attribute , and Green → New attribute ; Shapes : Rounded rectangle → Entity attribute , and Rectangle → Regular attribute . alog of scholarly entities that provides metadata for works , authors , institutions , sources , publishers , and concepts . Moreover , we add connections to both S2AG and Wikidata repositories to provide a more unifying resource for the researchers . 4 K . Ahrabian et al . Furthermore , we provide outputs from auxiliary models to further enrich Pub - Graph for future studies . The rest of this section is organized as follows : Sec . 2 . 1 introduces the mapping procedure from OpenAlex metadata to Wikidata ontology , Sec . 2 . 2 describes the implemented procedure to connect S2AG and Wikidata with OpenAlex along with some statistics of the resolution , and Sec . 2 . 3 presents the model choices for auxiliary outputs included in PubGraph . 2 . 1 Mapping to Wikidata Ontology To transform the OpenAlex dump ( taken on April 9th , 2023 ) into PubGraph , we follow the well - known and well - studied Wikidata ontology . Speciﬁcally , we create a mapping between metadata information from the OpenAlex dump to Wikidata properties . Using Wikidata enables broader adoption of the KG and clear semantics for entities and relationships . Table 1 presents the mapping from OpenAlex metadata to Wikidata proper - ties . These mappings are selected such that they best describe the metadata ﬁeld . Here , we explain the ontological design choices that we made for the mapping : 1 . abstract → P7535 : Due to the absence of a one - to - one match , we use P7535 ( scope and content ) , which is deﬁned as “a summary statement providing an overview of the archival collection . ” 2 . author position → P1545 : Since this ﬁeld deﬁnes an order of the authors , we use P1545 ( series ordinal ) , which is deﬁned as the “position of an item in its parent series ( most frequently a 1 - based index ) . ” 3 . ﬁrst page + last page → P304 : Since OpenAlex uses two diﬀerent ﬁelds to present this information , we merge them into one attribute to be aligned with the Wikidata ontology . 4 . score → P4271 : Since this ﬁeld indicates the relatedness of two concepts as produced by a model , it matches the deﬁnition of P4271 ( rating ) deﬁned as “qualiﬁer to indicate a score given by the referenced source indicating the quality or completeness of the statement . ” 5 . descriptor ui + qualiﬁer ui → P1038 : Since OpenAlex uses two diﬀerent ﬁelds to present this information , we merge them into one attribute to be aligned with the Wikidata ontology . 6 . apc usd → P2555 : Since this ﬁeld describes a “source’s article processing charge in US Dollars” , we match it to P2555 ( fee ) deﬁned as “fee or toll payable to use , transit or enter the subject . ” 7 . relationship → P1039 : Since this ﬁeld describes the relation between two institutions , we use P1039 ( kinship to subject ) deﬁned as “qualiﬁer of " rela - tive " ( P1038 ) to indicate less usual family relationships . ” 8 . location → P1433 : Since this ﬁeld describes the publishing location of a work , we match it with P1433 ( published in ) . 9 . latitude + longitude → P625 : Since OpenAlex uses two diﬀerent ﬁelds to present this information , we merge them into one attribute to be aligned with the Wikidata ontology . PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 5 Table 1 . OpenAlex metadata mapping to properties covered by Wikidata ontology . OpenAlex Metadata WikiData Property OpenAlex Metadata WikiData Property abstract P7535 author P50 author position P1545 institution P1416 landing page url P973 pdf url P953 license P275 version P9767 volume P478 issue P433 ﬁrst page + last page P304 concept P921 score P4271 year P585 created date P571 doi P356 mag P6366 pmid P698 pmcid P932 descriptor ui + qualiﬁer ui P9340 oa status P6954 oa url P2699 publication date P577 referenced work P2860 title P1476 type P31 updated date P5017 works count P3740 display name P2561 display name alternatives P4970 orcid P496 scopus P1153 twitter P2002 wikipedia P4656 last known institution P1416 abbreviated title P1813 alternate titles P1476 apc usd P2555 country code P297 homepage url P856 host organization P749 issn - l P7363 issn P236 fatcat P8608 associated institution P1416 relationship P1039 display name acronyms P1813 homepage url P856 geonames city id P1566 latitude + longitude P625 ror P6782 grid P2427 international display name P4970 language P9753 level P1545 alternate titles P4970 hierarchy level P1545 parent publisher P749 location P1433 ancestor P4900 related concept P921 corpus id P8299 10 . level → P1545 and hierarchy level → P1545 : Since there is no Wikidata property to describe a position in a hierarchy , we use the closest property P1545 ( series ordinal ) , which is deﬁned as the “position of an item in its parent series ( most frequently a 1 - based index ) . ” 6 K . Ahrabian et al . Table 2 . OpenAlex metadata mapping to properties not covered by Wikidata ontology . OpenAlex Metadata New Property OpenAlex Metadata New Property best oa location P _ best _ oa _ location cited by count P _ total _ cited _ by _ count cited by count P _ cited _ by _ count primary location P _ primary _ location 2yr mean citedness P _ impact _ factor h - index P _ h _ index i10 - index P _ i10 _ index wikidata P _ wikidata umls aui P _ umls _ aui community id P _ community _ id Table 3 . OpenAlex boolean metadata mapping to edges using Wikidata ontology . OpenAlex Metadata Edge OpenAlex Metadata Edge is corresponding P31 → Q36988860 is oa P31 → Q232932 is paratext P31 → Q853520 is retracted P31 → Q45182324 is in doaj P31 → Q1227538 Table 4 . OpenAlex entity type mapping to edges using Wikidata ontology . OpenAlex Metadata Edge OpenAlex Metadata Edge work P31 → Q13442814 author P31 → Q482980 source P31 → Q1711593 institution P31 → Q178706 concept P31 → Q115949945 publisher P31 → Q2085381 For the metadata with no suitable parallel property , we create new ones to keep the KG as complete as possible , as showcased in Table 2 . Note that for “cited by count” , OpenAlex provides both yearly and total values ; hence , the reason for having two diﬀerent new properties . Moreover , for metadata with a boolean type , we add a new edge ( main or qualiﬁer ) when true . Table 3 presents the edges representing each boolean metadata with all the relations and entities taken from the Wikidata repository . This choice was made to maintain a better semantic composure and avoid creating new properties in the KG . For example , there is no property in Wikidata for “is paratext” ; however , there exists an paratext entity ( Q853520 ) . Hence , instead of creating new property such as P _ is _ paratext , we can create a new edge when “is paratext” is true to this entity with relation P31 ( instance of ) . Finally , we also add “instance of” edges to indicate the type of each entity as classiﬁed by OpenAlex , as presented in Table 4 . Given its ﬂexibility to represent attributed graphs , we use RDF ∗ as the graph representation for PubGraph ( as illustrated in Fig . 1 ) . PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 7 Fig . 2 . Distribution of publication years in the 2000 - 2023 period for OpenAlex , S2AG , and Wikidata . Note that only ∼ 128 . 3M out of the ∼ 211 . 5M papers in S2AG have publication dates and are included . Fig . 3 . Coverage of S2AG and Wikidata papers after entity resolution in the 2000 - 2023 period . 2 . 2 S2AG and WikiData Entity Resolution To make PubGraph a more unifying and comprehensive resource , we opt to con - nect works in OpenAlex to two other large - scale repositories of scholarly meta - data : S2AG ( taken on April 11th , 2023 ) and Wikidata ( taken on April 28th , 2023 ) . Fig . 2 showcases the distribution of publication years in the 2000 - 2023 period for the works available in these three repositories . During this analysis , we noticed that only ∼ 128 . 3M out of the ∼ 211 . 5M papers in S2AG have pub - lication dates . This ﬁnding further highlights the importance of a unifying and comprehensive resource . To this end , we follow a two - step procedure . First , we match entities based on the following IDs : DOI , MAG , PMID , and PMCID . For S2AG , this results in ∼ 197 . 6M out of ∼ 211 . 5M unique papers being matched to OpenAlex works , roughly providing a 93 . 4 % coverage . For Wikidata , this results in ∼ 33 . 2M out of ∼ 38 . 9M unique papers being matched to OpenAlex works , roughly providing an 85 . 4 % coverage . Then , among the remaining unmatched entities , we run an exact title search and only keep one - to - one mappings . For S2AG , this step further increases the number of matched unique papers to ∼ 199 . 2M , roughly providing a 94 . 2 % cov - 8 K . Ahrabian et al . erage . For Wikidata , this step further increases the number of matched unique papers to ∼ 36 . 4M , roughly providing a 93 . 6 % coverage . Fig . 3 provides a cov - erage distribution over the 2000 - 2023 period for both S2AG and Wikidata . As evident from this distribution , the coverage of both data sources seems to be rel - atively unbiased toward the time of publication . We believe the Wikidata drop from 2021 onward is due to the low number of papers available in the platform in the period , and the S2AG drop is due to the potential delays in adding recent publications . Moreover , regarding more recent data , Wikidata seems to beneﬁt drastically from adding new entities through external sources . We plan to im - prove our entity resolution heuristic using other metadata , such as authors , to cover more entities in future releases . 2 . 3 Auxiliary Outputs Community Detection Besides sharing scientiﬁc ﬁndings , scholarly articles represent the research interests of their authors . Therefore , by referencing each other’s publications , authors create communities of shared interests . To enable the study of these communities , we provide the results obtained from the Leiden community detection algorithm [ 26 ] as auxiliary outputs for papers in PubGraph . To this end , we ﬁrst extract the full citation network from all the publication - publication links . Then , we tune the Leiden algorithm 1 on the extracted citation network with the following parameters : quality function ∈ { Modular , RBER , Signiﬁcance , Surprise } , maximum papers per community ∈ { 300k , 500k } , and number of communities ∈ { 3000 , 4000 , 5000 , 6000 } . To evaluate the communi - ties’ quality , we use a purity proxy metric extracted from the ancestral graph of the concepts connected to the publications in OpenAlex . Speciﬁcally , we count the number of children for each root concept and select the largest root concept for each community . Then , we calculate the percentage of the papers that are children of that root concept as the proxy metric . Figure 4 illustrates our results on diﬀerent numbers of communities . Based on our experiments , the highest quality communities are produced by the following parameters : quality func - tion = Signiﬁcance , maximum papers per community = 300k , and number of communities = 3000 . Large Language Models PubGraph was developed to enable researchers to study scholarly works from a graph perspective . Through PubGraph , it is pos - sible to learn representations for papers using graph - based methods , which then could be used for various downstream tasks . Orthogonal to this relational and structural information , are textual information based on scholarly works’ con - tent . When available , textual features complement the graph - based features and can improve the performance of the models [ 2 ] . Recently , many large language models ( LLM ) have been introduced to tackle the problem of generating representations for scientiﬁc documents [ 1 , 6 ] . These pre - trained models are speciﬁcally tuned for scientiﬁc data and could be used to 1 https : / / github . com / vtraag / leidenalg PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 9 Fig . 4 . Analysis of the eﬀect of the number of communities on the quality of commu - nities . A higher area under the curve ( AUC ) indicates more pure communities . generate low - dimensional embeddings for input documents . In this work , to fur - ther enable multi - view studies of PubGraph , we provide embeddings generated by LLMs for all the papers . These embeddings also save resources for researchers who want to use textual information . To this end , ﬁrst , we obtain a representing text by concatenating the title and the abstract of each work . This approach allows us to cover all the works with at least one of these attributes available , improving the general coverage of this data . Then , we run the representing text through the SciNCL model [ 21 ] to obtain the embeddings , with each generated embedding being a 768 - dimensional vector . All the generated embeddings are released with an index to match the corresponding papers . 3 Knowledge Graph Completion Traditionally , knowledge graph embedding ( KGE ) models [ 25 , 27 ] have been eval - uated in an interpolated , transductive KGC setting where all entities , e . g . , pa - pers and authors , are known . However , one of the challenging aspects of study - ing scientiﬁc progress is dealing with new publications which require inference over unseen samples . A better - aligned evaluation setting for this purpose is the extrapolated , inductive setting . An inductive setting requires models to make predictions over previously unseen entities . While KGs capture the structure 10 K . Ahrabian et al . Fig . 5 . Overview of the training and evaluation scheme . Intra - period current links ( black ) are used for training in all experiment settings . Intra - period future links ( red ) are used for evaluation in both validation and testing phases in all experiment settings . Exo - period links ( dotted blue ) are used in the training phase in transductive settings ; however , in inductive settings , these links are only used as auxiliary links during the evaluation phase . Auxiliary links establish connections between seen training nodes and unseen evaluation nodes . necessary for this setting , many models do not address this use case . Moreover , extrapolated prediction requires train and test sets to be partitioned by a tem - poral threshold , so model predictions are for a future time epoch . In this work , we introduce new resources and benchmarks in the extrapo - lated setting for both inductive and transductive models , framing the research question as a KGC task and supporting the study of this problem from a purely structural standpoint at diﬀerent scales and across various models . Moreover , we also introduce a community - based adversarial evaluation setting to 1 ) mitigate the inﬂuence of random negative sampling ( due to the scale ) in the evaluation phase and 2 ) maintain the same level of diﬃculty as evaluated on all of the enti - ties . Fig . 5 presents an overview of the training and evaluation schemes for the KGC benchmarks in both transductive and inductive settings . The rest of this section is organized as follows : Sec . 3 . 1 describes the methodology used to create PG - X benchmarks , Sec . 3 . 2 presents a data quality analysis over the extracted samples , and Sec . 3 . 3 presents a set of adversarial evaluation settings for the KGC tasks . 3 . 1 Building PG - X Benchmarks The full PubGraph KG contains a vast amount of information in the form of lit - eral values and sparse properties that are not easily usable by many KG models . We extract subsets of PubGraph , designated as PG - X , to create easier - to - use benchmarks for KG models . To extract PGs from the transformed data , we ﬁrst remove all the publications with no citations that do not cite any other papers PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 11 Table 5 . Statistics of PG - X benchmarks splits . Benchmark # Training ( Validation ) # Training ( Testing ) # Validation # Test PG - 1M 18 . 2M 20 . 5M 265k 146k PG - 10M 269 . 0M 305 . 9M 3 . 1M 2 . 3M PG - Full 1 . 88B 2 . 17B 28 . 1M 26 . 3M Table 6 . Validity and completeness metrics of sampled KGs . Metric PG - 1M PG - 10M PG - Full Mutual Citations 0 . 03 % 0 . 04 % 0 . 06 % Authorship Completeness 99 . 97 % 99 . 97 % 99 . 92 % Venue Completeness 92 . 37 % 90 . 25 % 75 . 34 % Institution Completeness 81 . 45 % 71 . 21 % 45 . 77 % to get PG - Full . Since these nodes are disconnected from other publications , this step mitigates the sparsity problem and reduces the KG size by a large margin . Given the enormous size of the PG - Full , we create two small and medium - sized sub - KGs to allow future studies at diﬀerent scales . To this end , we use snowball sampling [ 10 ] to extract PG - 1M and PG - 10M with 1M and 10M publi - cation nodes , respectively . After sampling , we remove any publication without a publication date . Next , we extract all the “cites work ( P2860 ) , ” “author ( P50 ) , ” “published in ( P1433 ) , " and “aﬃliation ( P1416 ) " links for the sampled publi - cations . We ensure to include all the available author , source , and institution links from the sampled publications in the benchmarks . Finally , we split all the benchmarks temporally , using all the publications before 2017 for training , 2017 up until 2020 for validation , and 2020 onward for testing . Table 5 presents the statistics on the extracted splits of each benchmark . 3 . 2 Data Quality To evaluate the quality of the extracted benchmarks , we check the validity and completeness of our KGs . For validity , we look for potential mutual citations , cases where two papers reference each other , violating strict temporal order . This artifact may appear when articles have several revisions , but OpenAlex only reports the earliest publication date . For completeness , we calculate publication - author , publication - source , and author - institution relations completeness . Table 6 showcases these metrics on the extracted KGs . As evident from the metrics , all the benchmarks exhibit an extremely low mutual citations percentage which is evidence of their quality . Moreover , the small and medium - sized KGs exhibit higher completeness metrics which we attribute to the forced inclusion of all authors , venues , and institutions links . 12 K . Ahrabian et al . Table 7 . Negative sampling results on the PG - 1M benchmark . Variation # Negative Samples MRR Hits @ 1 Hits @ 10 Time ( Seconds ) Random 1000 0 . 723 0 . 608 0 . 918 588 ( CPU ) Entity Type 1000 0 . 560 0 . 418 0 . 826 655 ( CPU ) Time Constrained 1000 0 . 577 0 . 449 0 . 817 601 ( CPU ) Community 1000 0 . 076 0 . 023 0 . 167 1008 ( CPU ) Full ∼ 3 . 38M 0 . 015 0 . 000 0 . 036 81987 ( GPU ) Fig . 6 . Analysis of the eﬀect of negative samples count on the model’s performance measured by MRR . 3 . 3 Adversarial Evaluation Setting One of the most common strategies to evaluate KGC on large - scale graphs is to sample a ﬁxed number of negative samples for each positive sample during the evaluation phase . However , this strategy is prone to exhibiting inﬂated per - formance due to having no control over the diﬃculty of the sampled nodes . Moreover , calculating the evaluation metrics on the complete set of samples becomes increasingly more expensive as the size of the KG grows . Hence , we propose three alternative strategies for negative sampling during the evaluation phase . These strategies aim to ﬁnd an eﬃcient method to be used as a proxy for complete metric calculations . Our proposed strategies are as follows : PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 13 1 . Entity Type : This is the most straightforward strategy in which we only sample candidate nodes with the same type as the target node . For example , in our case , we only sample from the publications . 2 . Time Constrained : Building upon our ﬁrst strategy , we further add the constraint of only sampling candidate nodes from the nodes within the evalu - ation period . Intuitively , these unseen ( inductive ) or less seen ( transductive ) nodes will pose more problems for the model during the evaluation phase . 3 . Community : Given a target node , we sample candidate nodes only from its community . This strategy relies on the auxiliary outputs , i . e . , communities , generated as described in Sec . 2 . 3 . We hypothesize that these nodes pose the most diﬃculty for the model during the evaluation phase . To test the proposed strategies , we train a ComplEx [ 27 ] model using the DGL - KE toolkit [ 31 ] . We tune the hyper - parameters of our model using the following set of values : embedding dimensions ∈ { 50 , 100 , 200 , 400 } , learning rate ∈ { 0 . 003 , 0 . 01 , 0 . 03 , 0 . 1 , 0 . 3 } , number of negative samples ∈ { 128 , 256 , 512 , 1024 , 2048 } , and regularization coeﬃcient ∈ { 0 . 0 , 1e - 9 , 1e - 8 , 1e - 7 , 1e - 6 , 1e - 5 } . Table 7 presents the results of our experiments with the aforementioned neg - ative sampling strategies in the evaluation phase . The reported times are for one evaluation run over the complete testing set of the PG - 1M benchmark ( ∼ 147K samples ) . As evident from these results , the community - based method is the best proxy to the full metrics calculation while still being signiﬁcantly time eﬃcient . Even if we factor in the 11 . 5 hours ( 41400 seconds ) that it takes to learn commu - nities for all the 91M publications , the diﬀerence in computation time becomes much more signiﬁcant when we have to repeat the evaluation process over and over again , e . g . , for validation , ﬁne - tuning , etc . Moreover , the full metrics are calculated on a GPU which is far more eﬃcient than the calculations on the CPU . It is important to note that the community - based method is helpful in evaluation settings where the ground truth is known ; however , in settings where the ground truth is unknown , e . g . , a deployed model , there is no workaround to complete ranking computations as we have to consider all the entities regardless . We further analyze the eﬀect of the number of negative samples on the model’s performance . Figure 6 presents the result of our experiments with vary - ing numbers of negative samples on all the introduced strategies . As expected , the model’s performance rapidly drops with the increase of negative samples . Moreover , the community - based negative sampling results act as an excellent proxy at 5k negative samples and seem to converge to the full variation around 10k negative samples . This ﬁnding is further evidence of the eﬀectiveness of this method . 4 Related Works 4 . 1 Scientiﬁc Knowledge Graphs In recent years , a wide range of scientiﬁc KGs ( SKG ) have emerged in the re - search community . Examples of these SKGs are Scholia [ 19 ] , ORKG [ 24 ] , Ope - nAIRE [ 18 ] , and MAG240M [ 14 ] . Each of the aforementioned SKGs has diﬀerent 14 K . Ahrabian et al . Table 8 . Comparison between PubGraph and the existing SKGs . SKG # Articles Source Ontology Embeddings Community External Links ( Other Sources ) Scholia 39M Wikidata Wikidata (cid:55) (cid:55) (cid:55) ORKG 25k Curated Proprietary (cid:55) (cid:55) (cid:55) OpenAIRE 164M Curated Proprietary (cid:55) (cid:55) (cid:55) MAG240M 121M MAG Proprietary (cid:51) (cid:55) (cid:55) PubGraph 250M OpenAlex Wikidata (cid:51) (cid:51) (cid:51) Table 9 . Statistics of extracted benchmarks compared to the existing large - scale KGC benchmarks . As evident , PG - Full has more than 2x nodes and 3 . 6x edges compared to the largest existing benchmarks . Benchmark # Nodes # Edges # Relations ogbl - citation2 [ 15 ] 2 , 927 , 963 30 , 561 , 187 1 Freebase [ 4 ] 86 , 054 , 151 338 , 586 , 276 14 , 824 WikiKG90Mv2 [ 14 ] 91 , 230 , 610 601 , 062 , 811 1 , 315 PG - 1M 3 , 378 , 202 22 , 442 , 976 4 PG - 10M 25 , 312 , 490 315 , 225 , 337 4 PG - Full 184 , 126 , 885 2 , 201 , 239 , 147 4 characteristics that make them unique and interesting to the community . Table 8 compares PubGraph with the existing SKGs across various properties . As evident from this table , PubGraph is built on a more grounded ontology and provides much more information and artifacts compared to other SKGs . 4 . 2 Large Scale KGC Benchmarks KGC is one of the most common tasks deﬁned on KGs . Recent eﬀorts [ 14 , 15 ] have shifted toward introducing more large - scale benchmarks for KGC ; however , there is still a shortage of benchmarks for large - scale graph learning . We believe the PG - X benchmarks introduced in this paper can help mitigate this shortage . Table 9 showcases the statistics of the sampled KGs along with a comparison to existing large - scale KGC benchmarks in the literature . As evident from the numbers , PG - X benchmarks provide an opportunity to evaluate KG models on larger ( 2x nodes and 3 . 6x edges ) and more ﬂexible ( 3 . 3M to 184M range ) benchmarks . 5 Conclusion and Future Work In this work , we introduced PubGraph , a new large - scale resource in the form of a KG built on Wikidata ontology and extracted from the OpenAlex cata - PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 15 log with more than 13B edges and 385M nodes . As presented through diﬀerent comparisons , PubGraph provides a much - needed unifying and comprehensive re - source for researchers to study scientiﬁc progress that connects multiple sources . PubGraph also enables the study of scientiﬁc documents from distinct perspec - tives through the information extracted from auxiliary community detection algorithms and large language models . Moreover , we created three KGC bench - marks with varying sizes to enable future studies at diﬀerent scales and for both transductive and inductive settings . Finally , we identiﬁed a set of challenging ad - versarial evaluation settings for the introduced benchmarks that overcome the common downfall of large - scale KGC evaluation settings . As for future directions for PubGraph , one direction is to improve the coverage of connections to exter - nal sources . Moreover , it is possible to bring in more external data sources , e . g . , SKGs such as Scholia , and link them with PubGraph . Finally , another venue is to add other metadata that is of interest to the community , such as awards and grants , which further enables researchers to study these events in the larger context . Acknowledgements This work was funded by the Defense Advanced Research Projects Agency with award W911NF - 19 - 20271 and with support from a Keston Exploratory Research Award . Resource Availability Statement : The source code for building PubGraph , along with a data schema , is available from GitHub , released under the CC - BY - SA license 2 . All the introduced benchmarks and resources are publicly accessible and released under the CC - BY - SA license 3 . Due to the sheer size of the resources ( > 2TB ) , we could not host the data in any commonly used platform and had to resort to self - provisioned servers . References 1 . Beltagy , I . , Lo , K . , Cohan , A . : SciBERT : A pretrained language model for scientiﬁc text . In : Proceedings of the 2019 Conference on Empirical Methods in Natural Lan - guage Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) . pp . 3615 – 3620 . Association for Computational Lin - guistics , Hong Kong , China ( Nov 2019 ) . https : / / doi . org / 10 . 18653 / v1 / D19 - 1371 , https : / / aclanthology . org / D19 - 1371 2 . Berrebbi , D . , Huynh , N . , Balalau , O . : Graphcite : Citation intent classiﬁcation in scientiﬁc publications via graph embeddings . In : Companion Proceedings of the Web Conference 2022 . pp . 779 – 783 ( 2022 ) 3 . Bhagavatula , C . , Feldman , S . , Power , R . , Ammar , W . : Content - based citation rec - ommendation . arXiv preprint arXiv : 1802 . 08301 ( 2018 ) 2 https : / / github . com / usc - isi - i2 / isi - pubgraph 3 https : / / pubgraph . isi . edu / 16 K . Ahrabian et al . 4 . Bollacker , K . , Evans , C . , Paritosh , P . , Sturge , T . , Taylor , J . : Freebase : a collabo - ratively created graph database for structuring human knowledge . In : Proceedings of the 2008 ACM SIGMOD international conference on Management of data . pp . 1247 – 1250 ( 2008 ) 5 . Cohan , A . , Ammar , W . , Van Zuylen , M . , Cady , F . : Structural scaﬀolds for cita - tion intent classiﬁcation in scientiﬁc publications . arXiv preprint arXiv : 1904 . 01608 ( 2019 ) 6 . Cohan , A . , Feldman , S . , Beltagy , I . , Downey , D . , Weld , D . : SPECTER : Document - level representation learning using citation - informed transformers . In : Proceed - ings of the 58th Annual Meeting of the Association for Computational Lin - guistics . pp . 2270 – 2282 . Association for Computational Linguistics , Online ( Jul 2020 ) . https : / / doi . org / 10 . 18653 / v1 / 2020 . acl - main . 207 , https : / / aclanthology . org / 2020 . acl - main . 207 7 . Cohan , A . , Feldman , S . , Beltagy , I . , Downey , D . , Weld , D . S . : Specter : Document - level representation learning using citation - informed transformers . arXiv preprint arXiv : 2004 . 07180 ( 2020 ) 8 . De Vaan , M . , Stark , D . , Vedres , B . : Game changer : The topology of creativity . American Journal of Sociology 120 ( 4 ) , 1144 – 1194 ( 2015 ) 9 . Färber , M . , Sampath , A . : Hybridcite : A hybrid model for context - aware citation recommendation . In : Proceedings of the ACM / IEEE Joint Conference on Digital Libraries in 2020 . pp . 117 – 126 ( 2020 ) 10 . Goodman , L . A . : Snowball sampling . The annals of mathematical statistics pp . 148 – 170 ( 1961 ) 11 . Gururangan , S . , Marasović , A . , Swayamdipta , S . , Lo , K . , Beltagy , I . , Downey , D . , Smith , N . A . : Don’t stop pretraining : adapt language models to domains and tasks . arXiv preprint arXiv : 2004 . 10964 ( 2020 ) 12 . Hofstra , B . , Kulkarni , V . V . , Munoz - Najar Galvez , S . , He , B . , Jurafsky , D . , Mc - Farland , D . A . : The diversity – innovation paradox in science . Proceedings of the National Academy of Sciences 117 ( 17 ) , 9284 – 9291 ( 2020 ) 13 . Hope , T . , Chan , J . , Kittur , A . , Shahaf , D . : Accelerating innovation through analogy mining . In : Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . pp . 235 – 243 ( 2017 ) 14 . Hu , W . , Fey , M . , Ren , H . , Nakata , M . , Dong , Y . , Leskovec , J . : Ogb - lsc : A large - scale challenge for machine learning on graphs . arXiv preprint arXiv : 2103 . 09430 ( 2021 ) 15 . Hu , W . , Fey , M . , Zitnik , M . , Dong , Y . , Ren , H . , Liu , B . , Catasta , M . , Leskovec , J . : Open graph benchmark : Datasets for machine learning on graphs . Advances in neural information processing systems 33 , 22118 – 22133 ( 2020 ) 16 . Jurgens , D . , Kumar , S . , Hoover , R . , McFarland , D . , Jurafsky , D . : Measuring the evolution of a scientiﬁc ﬁeld through citation frames . Transactions of the Associa - tion for Computational Linguistics 6 , 391 – 406 ( 2018 ) 17 . Kang , H . B . , Qian , X . , Hope , T . , Shahaf , D . , Chan , J . , Kittur , A . : Augmenting scien - tiﬁc creativity with an analogical search engine . ACM Transactions on Computer - Human Interaction ( 2022 ) 18 . Manghi , P . , Bardi , A . , Atzori , C . , Baglioni , M . , Manola , N . , Schirrwagen , J . , Principe , P . : The openaire research graph data model ( Apr 2019 ) . https : / / doi . org / 10 . 5281 / zenodo . 2643199 , https : / / doi . org / 10 . 5281 / zenodo . 2643199 19 . Nielsen , F . Å . , Mietchen , D . , Willighagen , E . : Scholia and scientometrics with wiki - data . In : Scientometrics 2017 . pp . 237 – 259 ( November 2017 ) . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 70407 - 4 _ 36 , https : / / arxiv . org / pdf / 1703 . 04222 PubGraph : A Large - Scale Scientiﬁc Knowledge Graph 17 20 . Ostendorﬀ , M . , Rethmeier , N . , Augenstein , I . , Gipp , B . , Rehm , G . : Neighborhood contrastive learning for scientiﬁc document representations with citation embed - dings . arXiv preprint arXiv : 2202 . 06671 ( 2022 ) 21 . Ostendorﬀ , M . , Rethmeier , N . , Augenstein , I . , Gipp , B . , Rehm , G . : Neighborhood contrastive learning for scientiﬁc document representations with citation embed - dings . In : Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing . pp . 11670 – 11688 . Association for Computational Linguis - tics , Abu Dhabi , United Arab Emirates ( Dec 2022 ) , https : / / aclanthology . org / 2022 . emnlp - main . 802 22 . Price , D . J . D . S . : Networks of scientiﬁc papers : The pattern of bibliographic ref - erences indicates the nature of the scientiﬁc research front . Science 149 ( 3683 ) , 510 – 515 ( 1965 ) 23 . Priem , J . , Piwowar , H . , Orr , R . : Openalex : A fully - open index of scholarly works , authors , venues , institutions , and concepts . arXiv preprint arXiv : 2205 . 01833 ( 2022 ) 24 . Stocker , M . , Oelen , A . , Jaradeh , M . Y . , Haris , M . , Oghli , O . A . , Heidari , G . , Hussein , H . , Lorenz , A . L . , Kabenamualu , S . , Farfar , K . E . , et al . : Fair scientiﬁc information with the open research knowledge graph . FAIR Connect 1 ( 1 ) , 19 – 21 ( 2023 ) 25 . Sun , Z . , Deng , Z . H . , Nie , J . Y . , Tang , J . : Rotate : Knowledge graph embedding by relational rotation in complex space . arXiv preprint arXiv : 1902 . 10197 ( 2019 ) 26 . Traag , V . A . , Waltman , L . , Van Eck , N . J . : From louvain to leiden : guaranteeing well - connected communities . Scientiﬁc reports 9 ( 1 ) , 1 – 12 ( 2019 ) 27 . Trouillon , T . , Welbl , J . , Riedel , S . , Gaussier , É . , Bouchard , G . : Complex embed - dings for simple link prediction . In : International conference on machine learning . pp . 2071 – 2080 . PMLR ( 2016 ) 28 . Uzzi , B . , Mukherjee , S . , Stringer , M . , Jones , B . : Atypical combinations and scien - tiﬁc impact . Science 342 ( 6157 ) , 468 – 472 ( 2013 ) 29 . Vrandečić , D . , Krötzsch , M . : Wikidata : a free collaborative knowledgebase . Com - munications of the ACM 57 ( 10 ) , 78 – 85 ( 2014 ) 30 . Wade , A . D . : The semantic scholar academic graph ( s2ag ) . In : Companion Proceed - ings of the Web Conference 2022 . pp . 739 – 739 ( 2022 ) 31 . Zheng , D . , Song , X . , Ma , C . , Tan , Z . , Ye , Z . , Dong , J . , Xiong , H . , Zhang , Z . , Karypis , G . : Dgl - ke : Training knowledge graph embeddings at scale . In : Proceed - ings of the 43rd International ACM SIGIR Conference on Research and Develop - ment in Information Retrieval . pp . 739 – 748 ( 2020 )