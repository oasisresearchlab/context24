Learning Models of Relational Stochastic Processes Sumit Sanghai and Pedro Domingos and Daniel Weld University of Washington , Seattle WA 98195 , USA sanghai , pedrod , weld @ cs . washington . edu Abstract . Processes involving change over time , uncertainty , and rich relational structure are common in the real world , but no general algorithms exist for learn - ing models of them . In this paper we show how Markov logic networks ( MLNs ) , a recently developed approach to combining logic and probability , can be applied to time - changing domains . We then show how existing algorithms for parameter and structure learning in MLNs can be extended to this setting . We apply this ap - proach in two domains : modeling the spread of research topics in scienti(cid:2)c com - munities , and modeling faults in factory assembly processes . Our experiments show that it greatly outperforms purely logical ( ILP ) and purely probabilistic ( DBN ) learners . 1 Introduction Stochastic processes involving the creation and modi(cid:2)cation of objects and relations over time are widespread , but relatively poorly studied . Examples of such systems in - clude social networks , manufacturing processes , bioinformatics , natural language , etc . . Until recently , graphical models like DBNs and HMMs were the most powerful rep - resentations for reasoning about stochastic sequential phenomena . However , modeling relational domains using these graphical models requires exhaustively representing all possible objects and the relations among them . Such a model is both hard to learn and dif(cid:2)cult to understand . For example , consider a social network such as an evolving scienti(cid:2)c community . One might wish to model the spread of topics across the various groups of researchers . This might mean discovering rules such as (cid:147)An author’s interest in topics in the future is in(cid:3)uenced by the interests of his main collaborators and the communities in which he has recently participated . (cid:148) Such rules , being probabilistic , cannot be encoded using pure (cid:2)rst - order logic . But a DBN or an HMM would require a model for each individual researcher , and wouldn’t generalize from one author to another . In recent years , researchers have made progress combining (cid:2)rst - order logic with probabilistic representations . Models such as probabilistic relational models ( PRMs ) [ 6 ] , Bayesian logic programs ( BLPs ) [ 15 ] , and Markov logic networks ( MLNs ) [ 23 ] are promising . However , these models lack the dynamism of DBNs and HMMs . Sanghai et al . propose dynamic probabilistic relational models ( DPRMs ) [ 24 ] and relational dy - namic Bayesian networks ( RDBNs ) [ 25 ] for modeling relational stochastic processes , but no learning methods have been proposed for these models , limiting their applicabil - ity . This paper makes the following contributions : (cid:150) We de(cid:2)ne dynamic Markov logic networks ( DMLNs ) , a novel extension of MLNs , which handles time - changing data . Because they support arbitrary (cid:2)rst - order logi - cal expressions , DMLNs can conveniently express more than DPRMs and RDBNs . Further , they do not need to avoid cycles which signi(cid:2)cantly simpli(cid:2)es modeling . (cid:150) We present the (cid:2)rst learning algorithm for time - changing , relational , uncertain do - mains . Learning DMLNs is relatively easy , requiring only straightforward modi(cid:2) - cations to the MLN learner . (cid:150) We apply DMLN learning in two domains : the evolution of research topics in high - energy physics and fault modeling of mechanical assembly plans . Our experiments show that DMLNs greatly outperform a purely probabilistic approach ( DBN learn - ing ) and a purely logical approach ( ILP ) . In the next section , we cover necessary background . Then , we introduce DMLNs and describe the learning methods for them . Finally , we report our experimental results and conclude with a discussion of related and future work . 2 Background A Markov network ( also known as Markov random (cid:2)eld ) is a model for the joint distri - bution of a set of variables X = ( X 1 ; X 2 ; : : : ; X n ) [ 21 ] . It is composed of an undirected graph G on the variables and a set of non - negative potential functions (cid:30) k for the state of each clique in the graph . The joint distribution represented by a Markov network is given by P ( X = x ) = 1 Z Y k (cid:30) k ( x f k g ) ( 1 ) where x f k g is the state of the k th clique ( i . e . , the state of the variables that appear in that clique ) . Z , known as the partition function , is given by Z = P x 2 X Q k (cid:30) k ( x f k g . Markov networks are often conveniently represented as log - linear models , with each clique potential replaced by an exponentiated weighted sum of features of the state : P ( X = x ) = 1 Z exp 0 @ X j w j f j ( x ) 1 A ( 2 ) A feature may be any real - valued function of the state . This paper will focus on binary features , f j ( x ) 2 f 0 ; 1 g . In the most direct translation from the potential - function form ( Equation 1 ) , there is one feature corresponding to each possible state x f k g of each clique , with its weight being log (cid:30) k ( x f k g ) . This representation is exponential in the size of the cliques . However , we are free to specify a much smaller number of features ( e . g . , logical functions of the state of the clique ) , allowing for a more compact representation than the potential - functionform , particularly when large cliques are present . MLNs take advantage of this . 2 . 1 First Order Logic A (cid:2)rst - order knowledge base ( KB ) is a set of sentences or formulas in (cid:2)rst - order logic [ 9 ] . Formulas are constructed using four types of symbols : constants , variables , func - tions , and predicates . Constant symbols represent objects in the domain of interest . Variables range over the objects in the domain . Function symbols represent mappings 2 from tuples of objects to objects . Predicate symbols represent relations among objects in the domain or attributes of objects . A term is any expression representing an object in the domain . An atomic formula or atom is a predicate symbol applied to a tuple of terms . A ground term is a term containing no variables . A ground atom or ground predicate is an atomic formula all of whose arguments are ground terms . Formulas are recursively constructed from atomic formulas using logical connectives and quanti - (cid:2)ers . Any KB may be mechanically transformed into clausal form (cid:151) a conjunction of clauses , a clause being a disjunction of literals . A possible world or Herbrand interpre - tation assigns a truth value to each possible ground atom . In (cid:2)nite domains , (cid:2)rst - order KBs can be propositionalized by replacing each universally ( existentially ) quanti(cid:2)ed formula with a conjunction ( disjunction ) of all its groundings . 2 . 2 Markov Logic Networks A (cid:2)rst - order KB can be seen as a set of hard constraints on the set of possible worlds : if a world violates even one formula , it has zero probability . The basic idea in MLNs is to soften these constraints : when a world violates one formula in the KB it is less probable , but not impossible . The fewer formulas a world violates , the more probable it is . Each formula has an associated weight that re(cid:3)ects how strong a constraint it is : the higher the weight , the greater the difference in log probability between a world that satis(cid:2)es the formula and one that does not , other things being equal . De(cid:2)nition 1 . [ 23 ] A Markov logic network L is a set of pairs ( F i ; w i ) , where F i is a (cid:2)rst - order logical clause and w i is a real number . Together with a (cid:2)nite set of constants C = f c 1 ; c 2 ; : : : ; c j C j g , it de(cid:2)nes a Markov network M L ; C ( Equations 1 and 2 ) as follows : 1 . M L ; C contains one binary node for each possible grounding of each predicate appearing in L . The value of the node is 1 if the ground predicate is true , and 0 otherwise . 2 . M L ; C contains one feature for each possible grounding of each formula F i in L . The value of this feature is 1 if the ground formula is true , and 0 otherwise . The weight of the feature is the w i associated with F i in L . Thus there is an edge between two nodes of M L ; C iff the corresponding ground predicates appear together in at least one grounding of one formula in L . An MLN can be viewed as a template for constructing Markov networks . From De(cid:2)nition 1 and Equations 1 and 2 , the probability distribution over possible worlds x speci(cid:2)ed by the ground Markov network M L ; C is given by P ( X = x ) = 1 Z exp F X i = 1 w i n i ( x ) ! ( 3 ) where F is the number formulas in the MLN and n i ( x ) is the number of true groundings of F i in x . As formula weights increase , an MLN increasingly resembles a purely logi - cal KB , becoming equivalent to one in the limit of all in(cid:2)nite weights . In this paper we focus on MLNs whose formulas are largely function - free clauses and assume domain 3 closure , ensuring that the Markov networks generated are (cid:2)nite [ 23 ] . In this case the groundings of a formula are obtained simply by replacing its variables with constants in all possible ways . For example , if C = f Anna ; Bob g , the formula 8 x Smokes ( x ) ) Cancer ( x ) in the MLN L yields the features Smokes ( Anna ) ) Cancer ( Anna ) ( or : Smokes ( Anna ) _ Cancer ( Anna ) in clausal form ) and Smokes ( Bob ) ) Cancer ( Bob ) in the ground Markov net . 3 Modeling Relational Stochastic Processes Traditionally , graphical models like dynamic Bayesian networks ( DBNs ) , hidden Markov models ( HMMs ) , etc . , have been used to model joint distribution of variables involved in complex stochastic processes . These models employ the (cid:2)rst - order Markovian as - sumption ( not to be confused with (cid:2)rst - order logic ) wherein the state at any point in time only depends on the immediately preceding state . They also assume that the pro - cess is stationary , i . e . , the transition models for all time slices are identical . They have been quite successful in practice , [ 19 ] , but they cannot be used to compactly model complex domains with multiple classes , objects and relationships (cid:151) especially if ob - jects and relations are created or modi(cid:2)ed over time as a result of actions or system evolution . To model such domains one wishes for a representation for modeling se - quential stochastic processes , which includes the representational power of (cid:2)rst - order logic . Although , (cid:2)rst - order probabilistic models such as Markov logic networks , proba - bilistic relational models , Bayesian logic programs and others combine uncertainty with (cid:2)rst - order logic , they lack the dynamism to model relational stochastic processes . Recently , dynamic probabilistic relational models ( DPRMs ) [ 24 ] and relational dy - namic Bayesian networks ( RDBNs ) [ 25 ] have been proposed to capture this dynamism . DPRMs and RDBNs are based on Bayesian extensions of (cid:2)rst - order logic like prob - abilistic relational models ( PRMs ) and relational Bayesian networks ( RBNs ) . DPRMs ( and RDBNs ) are de(cid:2)ned as a pair ( M 0 ; M ! ) , where M 0 is a PRM ( or an RBN ) which represents the distribution over the initial state X 0 , much like an MLN does , and M ! is a PRM ( RBN ) which captures the transition distribution P ( X t + 1 j X t ) , i . e . , the dis - tribution over the next current given the current state . The models M 0 and M ! , being extensions of Bayesian networks , form a directed acyclic graph on the predicates . Each predicate node contains a set of parent predicates and a conditional model which is a CPT in DPRMs and a (cid:2)rst order probability tree in RDBNs . Sanghai et al . have applied RDBNs and DPRMs to detect faults in manufacturing assembly processes , but they do not give any techniques for learning these models . In theory , techniques used to learn PRMs , and ILP techniques could be used to learn DPRMs and the (cid:2)rst - order probability trees in RDBNs , however this approach has not been validated . We now present an extension of MLNs for modeling dynamic domains , such that the learning problem can be cast as an instance of learning the structure or parameter of an MLN . This equips us with ready - made techniques for learning relational stochastic processes . We empirically demonstrate the effectiveness of these learning methods . 3 . 1 Dynamic Markov Logic Networks In a relational stochastic process , the world is not static . A ground predicate can be true or false depending on the time step t . To model a dynamic relational domain we use the following approach : 4 1 . Instead of standard (cid:2)rst - order predicates , we use (cid:3)uents - a special form of predicate having an additional time argument . Time is modeled as a non - negative integer variable . Each predicate in the network is now of the form R ( x 1 ; : : : ; x n ; t ) where t denotes time . 2 . Our model includes a successor function succ ( t ) , which maps the integer t , repre - senting time , to t + 1 , i . e . , succ ( 0 ) = 1 , succ ( 1 ) = 2 and so on . 3 . We de(cid:2)ne a dynamic Markov logic network ( DMLN ) to be a set of weighted for - mulas de(cid:2)ned on the (cid:3)uents . 4 . Each formula in the DMLN contains exactly one variable denoting a time slice , and constants may not be used as a (cid:3)uent’s time argument . For example , we disallow formulae such as : 8 Auth , Topic , t , t’ : Writes ( Auth , Topic , t ) = > Writes ( Auth , Topic , t’ ) 5 . Each term , in each formula in the DMLN , is restricted to at most one application of the succ function , i . e . , a term such as succ ( succ ( t ) ) is disallowed . This ensures do - main closure and precludes a ground predicate at time t to depend on other ground predicates at time t (cid:0) 2 or before . Given the domain of constants , i . e . , the objects at each time slice , the DMLN will give rise to a ground Markov network whose nodes correspond to the grounding of the predicates ( (cid:3)uents ) for each time slice . Proposition 1 . The DMLN thus de(cid:2)ned , along with the restrictions on the formulas , obeys the (cid:2)rst - order Markovian assumption and is stationary . DMLNs have some important advantages over RDBNs and DPRMs , especially when learning . (cid:150) Compared to DPRMs and RDBNs , modeling dynamic relational domains is easier with DMLNs , since one may assert any (cid:2)rst - order formula [ 23 ] . For e . g . , the rule 8 A1 , Topic , t 9 A2 CoAuthor ( A1 , A2 , t ) ^ Interests ( A2 , Topic , t ) = > Interests ( A1 , Topic , t ) is easily expressible using DMLNs , but not so using DPRMs or RDBNs . (cid:150) As a consequence , background knowledge can be easily incorporated in a DMLN by adding (cid:2)rst - order formulas with or without weights . Incorporating background knowledge into DPRMs or RDBNs is much more cumbersome and opaque , be - cause it (cid:2)rst has to be converted to full CPTs or trees , with the corresponding blow - up in complexity . (cid:150) While learning DPRMs and RDBNs , one has to avoid cycles (cid:151) a messy and time intensive complication [ 26 ] . Since DMLNs are undirected , there is no such need . (cid:150) DMLNs are easier to maintain than DPRMs or RDBNs because weighted formu - las are ( exponentially ) more compact than CPTs or trees , which suffer from the well - known replication problem . First - order formulas can use boolean features to represent a probability distribution compactly whereas CPTs or decision trees may require redundant tests ( for example isomorphic subtrees ) to represent the same . 5 3 . 2 Learning DMLNs As is common in graphical models , we divide learning DMLNs into two separate prob - lems : ( a ) parameter learning and ( b ) structure learning . The weights of a DMLN can be learned in the same manner as in MLNs , by max - imizing the likelihood of a relational database [ 23 ] . ( A closed - world assumption is made , whereby all ground atoms not in the database are assumed false . ) However , as in Markov networks , this requires computing the expected number of true groundings of each formula , which can take exponential time . Although this computation can be done approximately using Markov chain Monte Carlo inference [ 21 ] , Richardson and Domingos found this to be too slow . Instead , they maximized the pseudo - likelihood of the data , an alternative measure widely used in areas like spatial statistics and natu - ral language [ 4 ] . If x is a possible world ( relational database ) and x l is the l th ground atom’s truth value , the pseudo - log - likelihood of x given weights w is log P (cid:3) w ( X = x ) = n X l = 1 log P w ( X l = x l j MB x ( X l ) ) ( 4 ) where MB x ( X l ) is the state of X l ’s Markov blanket in the data ( i . e . , the truth values of the ground atoms co - occuring with it in some ground formula ) . Computing the pseudo - likelihood and its gradient does not require inference , and is therefore much faster . 3 . 3 Structure learning in DMLNs In theory one can learn a fully general DMLN for any relational stochastic process . In other words , one could use a single large example to store a history of the entire relational process and learn a DMLN which does not obey the (cid:2)rst - order Markovian restrictions . However , this might lead to an unituitive model and costly inference . In addition , if the number of time slices is large , the domain size of the time variable increases , causing rules involving the time variable to become complex and tedious to learn . However , we can make certain restrictions on the formulas learned and also equip the learner with background knowledge making the task easier . We divide the structure learning procedure into distinct classes depending on the information provided to the learner : Learning DMLNs with a Markovian assumption : Like learning in a DBN , we can split the domain into multiple examples . Each example , corresponding to a time in - stance t , is a pair of states at time t and t + 1 . When learning , one can avoid rules which only involve predicates at time t . A model learned in this way is automatically (cid:2)rst - order Markovian and stationary . Learning in presence of background knowledge : The learner is provided with a set of formulas as background knowledge and it is forced to either modify existing rules or add a small number of additional rules so as to maximize the likelihood of the data . Learning with templates : In inductive logic programming ( ILP ) systems learning be - comes practical only when combined with a language and search bias . For example , when learning a relational stochastic process involving actions , one might want to make sure that each rule contains at least one action . This restriction can be speci(cid:2)ed using templates . Other forms of bias include restricting the number of variables or predicates allowed in a formula , de(cid:2)ning an order on the predicates to be considered during search , 6 creating new predicates and rules for them , and labeling predicates as input or output predicates . All of these cases can be handled by appropriately extending the MLN learning techniques [ 17 ] , as we now show . Although it may seem surprising , these methods work quite well in practice ! No other special learning techniques are needed . The structure learned is the one that maximizes the pseudo - likelihoodof the database [ 17 ] . The algorithm starts with an empty set of clauses and greedily adds or modi(cid:2)es clauses that give the best pseudo - likelihood . At every iteration , weights for all candi - date structures are learned . To do this , the weights are initialized to their values from the previous iteration and they quickly converge to the optimum . Each new candidate clause is obtained by adding or removing predicates from already present clauses , or (cid:3)ipping the signs of the predicates . One of two search techniques is used : ( i ) a beam search where a set of b best clauses is selected and modi(cid:2)ed until the pseudo - likelihood ceases to improve , and (cid:2)nally the clause which gives the best pseudo - likelihoodis added , or ( ii ) shortest - (cid:2)rst search where all good clauses of a smaller length l are added before adding any of a higher length . The above algorithm may be combined with the (cid:2)rst - order Markovian assumption and templates to learn DMLNs . 3 . 4 Inference in DMLNs To use a learned model , one requires fast inference techniques . In this paper , we only apply our learned model to infer a distribution over the immediately succeeding time step . Additionally , in our examples , all the state variables are observed . Thus , we may use a simple Monte Carlo Markov chain ( MCMC ) algorithm for inference . Particle (cid:2)ltering [ 5 ] is one of the most popular and ef(cid:2)cient techniques for state monitoring in dynamic systems and applying it to DMLNs is an item for future work . 4 Experiments In this section we learn DMLNs for two domains in an effort to answer the following questions about methods for learning models of relational stochastic processes . Q1 Are DMLNs superior to purely logical approaches such as ILP ? Q2 Do DMLNs outperform purely probabilistic methods such as DBN learning ? Q3 Can rules that model the dynamics of a relational world be learned and do such rules give superior performance than pure parameter learning ? Q4 Does enforcingthe Markovian assumption improve the accuracy of a learned DMLN ? Q5 Do templates help in learning better DMLNs ? We investigate these questions by applying our algorithms on problems in two do - mains : ( a ) modeling the spread of research topics in the theoretical high - energy Physics community , and ( b ) modeling faults in factory assembly processes . 4 . 1 Evolution of Topics in High - Energy Physics For our (cid:2)rst domain we use the dataset from the KDDCup 2003 [ 8 ] which is a collec - tion of papers from the theoretical high energy physics ( hep - th ) area of arXiv . org . This dataset consists of 30 , 000 papers authored by 9 , 000 scientists over 10 years . We 7 0 0 . 05 0 . 1 0 . 15 0 . 2 0 . 25 0 . 3 0 . 35 0 . 4 0 . 45 0 . 5 DMLN LastYear Gradient Avg DBN ILP L og - L i k e li hood ( - v e ) Fig . 1 . DMLNs have lower error than the other approaches , when predicting the interests of an author . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 P r ec i s i on Recall DMLNLastYearGradientAvgDBNILP Fig . 2 . DMLNs have higher precision across the recall spectrum when predicting author - topic distribution . restrict the author - set to scientists who have published at least 10 papers . To identify the topics of the papers we run the burst - detection algorithm [ 16 ] on the words appear - ing in the titles and abstracts of the papers . We intersect the top (cid:147)bursty(cid:148) words with words appearing in highly - cited papers and choose the top (cid:2)fty . Thus , each paper may be associated with multiple topics . In addition , we cluster both authors and journals using K - means , adding a relation connecting them to their clusters . We organize this dataset into constants of different types , e . g . , Author , Paper , Journal , etc . , and predicates , e . g . , Author - of , Has - Topic , Cites , etc . Our task is modeling the evolution of topic popularity over time . Speci(cid:2)cally , we wish to predict the distribution of an author’s paper topics for one year , given the dis - tribution over previous years along with citation patterns , and the interests of scienti(cid:2)c communities in which she publishes . We compare DMLNs with (cid:2)ve alternative methods : a purely logical approach (cid:150) the CLAUDIEN ILP engine [ 22 ] , a purely probabilistic method ( DBN learning ) , and three approaches that use only statistics concerning the author’s topic distribution in previ - ous years . These latter approaches include predicting the most recent topic distribution 8 ( LastYear ) , predicting the average of distributions across the last few years ( Avg ) , and predicting the gradient of the topic distributions over the last few years ( Gradient ) . We used three test sets , the topic distribution for years 2000 , 2001 and 2002 , always using a training set comprised of the data up to the test year . Our results were similar for all three years , so we report results only for 2002 . We compared structure learning with and without backgroundknowledge . The knowl - edge consists of rules such as an author’s interests are in(cid:3)uenced by collaborators , highly - cited authors from the same community and topic patterns ( i . e , bursting , etc . ) , and the fact that topics spread between journals in the same cluster . We used these rules (cid:2)rst as the complete structure ( i . e . , we only did parameter learning ) and then as back - ground knowledge ( here we learned additional rules ) . Learning DMLNs without back - ground knowledge does better than CLAUDIEN , DBN learning and the other methods , but the difference is insigni(cid:2)cant . Both knowledge - based approaches did well , and we report on the latter approach , which was marginally better . We present our results by plotting both the negative log - likelihood 1 of the predic - tions ( Figure 1 ) and the precision - recall curves ( Figure 2 ) . Each measure has its own advantage . The negative log - likelihood measures the quality of the probability estimates whereas the precision - recall curves are insensitive to the large number of true negatives ( i . e . , ground predicates that are false and predicted to be false ) . The (cid:2)gures show clearly that DMLNs learned with background knowledge surpass all other approaches in this domain . 4 . 2 Faults in Manufacturing Assembly Plans 0 0 . 05 0 . 1 0 . 15 0 . 2 0 . 25 0 . 3 0 . 35 0 . 4 0 . 45 0 . 5 DMLN ILP DBN Markovian Templates L og - li k e li hood ( - v e ) Fig . 3 . DMLNs with Markovian assumption and templates outperform the other algorithms when learning the action rules on the assembly process dataset . For our second test , we use a completely - observable version of Sanghai et al . ’s ( [ 24 ] ) manufacturingdomain , itself a probabilistic enhancement of the AIPS - 2000 Plan - ning Competition Schedule World domain [ 2 ] . An example in this domain is an execu - 1 To compute the log - likelihood for the statistics - based techniques we use the fraction of the papers that an author writes on a topic as the probability measure . 9 tion trace of an assembly plan comprised of actions such as Paint , Polish , Bolt , etc . ) . There are three classes of objects : Plate , Bracket and Bolt , with propo - sitional attributes such as weight , shape , color , surface type , hole size and hole type , and relations for the parts to which they are attached . Actions are performed at every time step , but they are fault - prone ; for example , a Weld action may fail or may weld two incorrect objects based on their similarity to the original objects . This gives rise to uncertainty in the domain and the corresponding dependence model for the various attributes . Given the simulated execution trace of a plan in this domain , we wish to use learning to recover each action’s exact fault model . Since it is clear that DMLN parameter learning would excel in this domain if given a good set of rules , we compare DMLN learning ( with no background knowledge ) to CLAUDIEN and DBN learning . Our goal is to answer questions Q3 , Q4 and Q5 by learning structure in various settings , i . e . , without any help , splitting the examples into time slice pairs , and using templates . We consider a template that makes the following restrictions : 1 ) at most one action predicate per clause , 2 ) only negated action predicates in clauses , 3 ) at most (cid:2)ve predicates per clause , and 4 ) biasing the search towards shorter clauses . Figure 3 shows the negative log - likelihood of unbiased DMLN learning , DMLNs with a Markovian assumption , and DMLNs with templates (cid:151) compared with ILP and DBN learning (cid:151) when applied to a 1000 step assembly plan with 100 objects . These results illustrate the ability of DMLNs to learn both the relational structure and the prob - abilistic parameters of a time changing process . DBNs have the disadvantage that they separately learn rules for each ground predicate , while CLAUDIEN has the disadvan - tage that it gives inaccurate probability predictions . DMLNs combine the capabilities of each . We also note that templates and rules obeying the (cid:2)rst - order Markovian assump - tion lead to improved learning . Figure 4 shows the performance of our DMLN methods , when applied to plans of varying length . As expected , every algorithm improves with an increasing number of time slices . The DMLN structure learning algorithm took around 7 hours on the hep - th data and 5 hours on the assembly data . CLAUDIEN was allowed to run for a maximum of 15 hours on both the datasets . 5 Related Work Relational Markov models ( RMMs ) [ 1 ] and logical hidden Markov models ( LOHMMs ) [ 14 ] are extensions of HMMs to (cid:2)rst - order domains and can be viewed as special cases of DMLNs . Dynamic object - oriented Bayesian networks ( DOOBNs ) [ 7 ] combine DBNs with OOBNs , but no learning algorithms for them have been proposed . While researchers have worked on temporal prediction in relational domains like social networks [ 8 ] , the algorithms are domain speci(cid:2)c and do not explicitly represent uncertainty . Successful models have been proposed , e . g . , preferential attachment [ 3 ] and their extensions such as cascade models [ 11 , 13 ] , cGraph [ 18 ] and blogspace mod - eling [ 12 ] . DMLNs allow the easy speci(cid:2)cation of more complex models using (cid:2)rst - order formulae . Learning probabilistic , relational , planning rules has also received attention [ 20 ] . Their application - speci(cid:2)c techniques may be viewed in terms of DMLN learning . For 10 0 0 . 05 0 . 1 0 . 15 0 . 2 0 . 25 0 . 3 0 . 35 0 . 4 0 200 400 600 800 1000 1200 1400 1600 1800 2000 L og - li k e li hood ( - v e ) Number of time slices DMLN : General DMLN : Markovian DMLN : Templates Fig . 4 . The performance of all DMLN learning algorithms improves with increasing plan lengths . example , the heuristic of learning preconditions before effects can be expressed with templates . In contrast to DMLNs , their learner is restricted to Horn clauses . Further - more , they have only demonstrated their system learning from plans with a very small number of objects . In recent years , much research has focused on combining uncertainty with (cid:2)rst - order logic ( or some subset of it ) [ 10 ] . In that respect , MLNs are most similar to re - lational Markov networks ( RMNs ) [ 26 ] . RMNs use SQL queries as clique templates and have a feature for each state of the clique . MLNs generalize RMNs by providing a more powerful language for constructing features ( (cid:2)rst - order logic instead of conjunc - tive queries ) , and by allowing uncertainty over arbitrary relations ( not just attributes of individual objects ) . The approach presented in this paper could be extended to RMNs however the RMN models would have the same limitations as mentioned above . 6 Conclusions and Future Work This paper makes three main contributions . First , we extend Markov logic networks to represent time - varying processes . The result , dynamic Markov logic networks ( DMLNs ) , has several advantages over previous models of relational stochastic processes . Mainly , DMLN modeling is simple and convenient (cid:151) one may assert any (cid:2)rst - order logical formula as a soft constraint , e . g . as background knowledge . In contrast DPRMs and RDBNs only support a subset of logic , leading to cumbersome encodings . Second , we describe the (cid:2)rst learning method for stochastic , relational time - changing domains . Learning DMLNs requires only straightforward extensions to an existing MLN learner illustrating the power of this approach . Third , we present experiments demonstrating the effectiveness and simplicity of DMLN learning in two domains : the spread of research topics in the scienti(cid:2)c commu - nity of high - energy physics and fault modeling of factory assembly plans . Our results show that DMLNs are more accurate than both a purely probabilistic approach ( DBN learning ) and a purely logical approach ( ILP ) . Additional experiments show the bene(cid:2)ts of learning with templates and a (cid:2)rst - order Markovian assumption . Directions for future work include handling continuous variables , learning in the presence of missing data , modeling and learning object creation and deletion , and ap - plying DMLNs to other complex real - world problems . 11 References 1 . C . Anderson , P . Domingos , and D . Weld . Relational Markov models and their application to adaptive Web navigation . In KDD’02 , 2002 . 2 . F . Bacchus . The AIPS - 2000 planning competition . AI Magazine , 22 ( 3 ) : 47(cid:150)56 , 2001 . 3 . A . Barabasi and R . Albert . Emergence of scaling in random networks . Science , 286 , 1999 . 4 . J . Besag . Statistical analysis of non - lattice data . The Statistician , 24 : 179(cid:150)195 , 1975 . 5 . A . Doucet , N . de Freitas , and N . Gordon , editors . Sequential Monte Carlo Methods in Prac - tice . Springer , New York , 2001 . 6 . N . Friedman , L . Getoor , D . Koller , and A . Pfeffer . Learning probabilistic relational models . In Proceedings of Sixteenth International Joint Conference on Arti(cid:2)cial Intelligence , 1999 . 7 . N . Friedman , D . Koller , and A . Pfeffer . Structured representation of complex stochastic systems . In Proceedings of Fifteenth National Conference on Arti(cid:2)cial Intelligence , 1998 . 8 . Johannes Gehrke , Paul Ginsparg , and Jon M . Kleinberg . Overview of the 2003 KDD Cup . SIGKDD Explorations , 2003 . 9 . M . Genesereth and N . Nilsson . Logical Foundations of Arti(cid:2)cial Intelligence . Morgan Kauf - mann Publishers , Inc . , Los Altos , CA , 1987 . 10 . L . Getoor and D . Jensen , editors . Proceedings of the IJCAI - 2003 Workshop on Learning Statistical Models from Relational Data . IJCAII , Acapulco , Mexico , 2003 . 11 . J . Goldenberg , B . Libai , and E . Muller . Talk of the network : A complex systems look at the underlying process of word - of - mouth . Marketing Letters , 12 : 211(cid:150)223 , 2001 . 12 . Daniel Gruhl , R . Guha , David Liben - Nowell , and Andrew Tomkins . Information diffusion through blogspace . In WWW ’04 , 2004 . 13 . David Kempe , Jon Kleinberg , and Eva Tardos . Maximizing the spread of in(cid:3)uence through a social network . In KDD ’03 , pages 137(cid:150)146 . ACM Press , 2003 . 14 . K . Kersting , T . Raiko , S . Kramer , and L . De Raedt . Towards discovering structural signatures of protein folds based on logical hidden Markov models . In PSB’03 , 2003 . 15 . Kristian Kersting and Luc De Raedt . Bayesian logic programs . In ILP - 2000 , 2000 . 16 . Jon Kleinberg . Bursty and hierarchical structure in streams . In KDD ’02 , 2002 . 17 . S . Kok and P . Domingos . Learning the structure of Markov logic networks ( tech . rept . ) , 2004 . Dept . Comp . Sci . & Eng . , Univ . Washington , Seattle . 18 . J . Kubica , A . Moore , D . Cohn , and J . Schneider . Finding underlying connections : A fast graph - based method for link analysis and collaboration queries . In ICML’03 , 2003 . 19 . K . Murphy . Dynamic Bayesian networks : representation , inference and learning . PhD thesis , University of California Berkeley , 2002 . 20 . Hanna Pasula , Luke S . Zettlemoyer , and Leslie Pack Kaelbling . Learning probabilistic rela - tional planning rules . In ICAPS’04 , 2004 . 21 . S . D . Pietra , V . D . Pietra , and J . . Lafferty . Inducing features of random (cid:2)elds . IEEE Trans - actions on Pattern Analysis and Machine Intelligence , 19 ( 4 ) , 1997 . 22 . L . De Raedt and L . Dehaspe . Clausal discovery . Machine Learning , 26 ( 2 - 3 ) : 99(cid:150)146 , 1997 . 23 . M . Richardson and P . Domingos . Markov logic networks , 2004 . Conditionally accepted for publication in Machine Learning , http : / / www . cs . washington . edu / homes / pedrod / mln . pdf . 24 . S . Sanghai , P . Domingos , and D . Weld . Dynamic probabilistic relational models . In IJ - CAI’03 , 2003 . 25 . S . Sanghai , P . Domingos , and D . Weld . Relational dynamic Bayesian networks . Journal of Arti(cid:2)cial Intelligence Research , 2005 . http : / / www . cs . washington . edu / homes / sanghai / rdbn . pdf . 26 . B . Taskar , P . Abbeel , and D . Koller . Discriminative probabilistic models for relational data . In UAI’02 , 2002 . 12