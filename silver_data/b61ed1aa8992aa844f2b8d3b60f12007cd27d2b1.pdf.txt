BlackBox Toolkit : Intelligent Assistance to UI Design Vinoth Pandian Sermuga Pandian Fraunhofer FIT - UCC Sankt Augustin , Germany pandian @ ﬁt . fraunhofer . de Sarah Suleri Fraunhofer FIT - UCC Sankt Augustin , Germany suleri @ ﬁt . fraunhofer . de Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . Copyright held by the owner / author ( s ) . CHI’20 , Workshop on Artiﬁcial Intelligence for HCI : A Modern Approach , April 25 – 30 , 2020 , Honolulu , HI , USA . https : / / sites . google . com / view / ai4hci / accepted - papers Abstract User Interface ( UI ) design is an creative process that in - volves considerable reiteration and rework . Designers go through multiple iterations of different prototyping ﬁdelities to create a UI design . In this research , we propose to mod - ify the UI design process by assisting it with artiﬁcial intel - ligence ( AI ) . We propose to enable AI to perform repetitive tasks for the designer while allowing the designer to take command of the creative process . This approach makes the machine act as a black box that intelligently assists the designers in creating UI design . We believe this approach would greatly beneﬁt designers in co - creating design solu - tions with AI . Author Keywords UI Element Dataset , Neural Networks , Deep Learning , Sketch Detection , Sketch Recognition , Blueprints , UI Lay - out , Prototyping CCS Concepts • Computing methodologies → Object detection ; • Human - centered computing → Graphical user interfaces ; User interface design ; Interface design prototyping ; User centered design ; a r X i v : 2004 . 01949v2 [ c s . H C ] 7 A p r 2020 Introduction The user interface ( UI ) acts as the bridge between a human and a machine . It acts as a translator mediating between " Just as the In - dustrial Revolution freed up a lot of humanity from physical drudgery I think AI has the potential to free up humanity from a lot of the mental drudgery . " – Andrew Ng two worlds : one disorderly , irrational , but adept at noticing patterns ; another structured , analytical , however inept in pattern - ﬁnding ( as of now ) . A UI designer is an architect who designs this bridge between man and machine . The most important job of a UI designer is not to ﬁnd a balance between both worlds ; instead , reduce the mental load of the one with issues and emotions and try to ﬁt it into the conﬁnements and restrictions placed by the other . This task of designing such interfaces is strenuous . Among the numerous ways of creating user interfaces to satisfy both the worlds involved , the most commonly used technique is user - centered design . In user - centered design , users are kept at the heart of de - sign , and designers attempt to satisfy their needs by an - alyzing the usage context , user needs , and requirements before starting the design process . Then during the design process , designers go through multiple ﬁdelities of proto - types . Starting from low - ﬁdelity ( lo - ﬁ ) freehand sketches to medium - ﬁdelity ( me - ﬁ ) digital images and ﬁnally to high - ﬁdelity ( hi - ﬁ ) interactive screens or code . The different ﬁdeli - ties have their strengths and weaknesses . For example , lo - ﬁ is cheap and supports ideating different designs quickly ; however , it does not do justice to the ﬁnal look - and - feel of the system . Similarly , me - ﬁ contains the most necessary information and is quicker to create than hi - ﬁ ; however , it is hard to create multiple design variations compared to lo - ﬁ . Hi - ﬁ resembles the ﬁnal product , but the workload of cre - ating such a system is humongous , and it is hard to create multiple design modiﬁcations to test the system . Several researchers attempt to solve the issues in this de - sign process . After the advancements of AI , one solution is to automate this whole process - the designers sketch a UI , and then the machine analyses the sketch and generates the hi - ﬁ code . This interesting approach , however , has one major ﬂaw . The whole system acts like a transformer to the designer who enters their sketch and gets a correspond - ing code with no control over tweaking the intricate design details . As a solution , we approach the same problem do - main and propose two solutions . Our goal is to enable the machine to perform repetitive tasks for the designer while allowing the designer to take command of the creative pro - cess . This approach makes the machine act as a black box that intelligently assists the designers in UI design . The machine’s role in our proposed design process is no differ - ent from the apprentices of renaissance art maestros . The apprentice’s task to assist the artist in preparing materials and executing the less critical and quite tedious decora - tive parts of frescoes or statues . We believe this approach would greatly beneﬁt designers where AI and human co - create creative solutions . Research Focus Our focus in this research is on how to move designers as the drivers of creativity and let AI assist designers in the UI design process . Our primary research question in this research is , " How can we automate the UI design process while allowing UI designers to control the design details . " We address this question by using artiﬁcial intelligence to automate the transformation of different ﬁdelities of UI de - sign . In the following sections , we expand on each of our proposed solutions , the challenges we faced with imple - mentation and the beneﬁt of that solution . MetaMorph MetaMorph is a UI element detector , created with a Deep Neural Network ( DNN ) object detection model [ 5 ] . Meta - Morph detects constituent UI element categories and their position from a lo - ﬁ sketch using a ﬁne - tuned RetinaNet object detection model trained with a dataset of 125 , 000 synthetically generated lo - ﬁ sketches . Challenge & Solution The major challenge in creating MetaMorph was the dataset . We required a large scale lo - ﬁ sketch dataset , which was non - existent . Therefore , we collected UI element sketches from 350 participants using paper and digital question - naires . Then we processed this data and labeled it to cre - ate the UISketch dataset 1 [ 4 ] . This dataset contains 5 , 917 sketches of 19 UI elements . However , this labeled dataset is only useful for classifying UI elements ; but , a UI element detector would need ground truth of both the identity and location of UI elements in a lo - ﬁ sketch . Figure 1 : Sample generated synthetic data As a solution , we created Syn 2 , a large - scale synthetic dataset containing 125 , 000 synthetically generated lo - ﬁ sketches [ 4 ] . To create Syn , we randomly chose UI ele - ments from the labeled UISketch dataset and stitched them in random locations with random scaling ( Figure 1 ) . This random allocation of elements in an image is similar to the pre - processing and data augmentation techniques used in improving detection metrics of object detection models . We used Syn to train the MetaMorph UI element detector . We then collected 200 lo - ﬁ sketches to evaluate Meta - Morph . The evaluation results indicate that MetaMorph detects UI elements from lo - ﬁ sketches with 63 . 5 % mAP . MetaMorph 3 is available as an open web API 4 . We have also open - sourced the UISketch dataset and Syn . Figure 2 : Usage of MetaMorph to detect lo - ﬁ elements and transforming them to me - ﬁ in Eve 1 https : / / www . kaggle . com / vinothpandian / uisketch 2 https : / / www . kaggle . com / vinothpandian / syn - dataset 3 https : / / metamorph . designwitheve . com / 4 http : / / api . metamorph . designwitheve . com / Beneﬁts By detecting the UI elements present in a lo - ﬁ sketch , the lo - ﬁ prototype can be converted to me - ﬁ or hi - ﬁ instead of fully automating the process ( Figure 2 ) . MetaMorph en - abled us to create Eve , a prototyping workbench [ 5 ] where a designer can sketch or upload a lo - ﬁ , which will be con - verted to me - ﬁ and later to hi - ﬁ by means of UI element detection . Eve enables the designer to control the styling of the UI in me - ﬁ and progress it to hi - ﬁ android XML code . Blu Blu is a tool that generates UI layout information from UI screenshots . With the detected information , it enables con - version of UI screenshots to blueprints and editable vector graphics [ 3 ] . Herring et al . demonstrate the beneﬁts and role of design examples in different aspects of the UI design process [ 2 ] . In this research , we expand on this idea , and from a UI design example screenshot , we detect UI element categories , positions , grouping information , and layout us - ing deep neural networks . Challenge & Solution We faced two signiﬁcant challenges in implementing Blu : dataset and layout detection . Fortunately , as a solution to dataset issue , Deka et al . col - lected a large scale android UI screenshot dataset , RICO [ 1 ] . RICO contains 72k UI screenshots with UI element hi - erarchy and semantic annotations . However , RICO was annotated using an automated approach ; therefore , the an - notations are sometimes mislabelled . If RICO is directly used as training data of a DNN , these mistakes propagate and provide inadequate results . Therefore , we had to re - annotate the elements and layout information for a subset of RICO to train Blu . Another challenge in creating Blu is identifying the layout in - formation . A UI designer by education and practice groups and aligns UI elements while creating a me - ﬁ prototype . They group UI elements mostly based on gestalt laws . This layout information further helps the front - end developers to create the hi - ﬁ with the constraints placed on them by programming languages and development environments . However , there is no algorithmic way to automate the layout of UI elements using gestalt law yet . To solve this issue , we are attempting to automate the alignment process algorith - mically based on gestalt laws . Figure 3 : UI screen ( left ) and its respective blueprint ( middle ) and UI layout tree ( right ) created using Blu . Beneﬁts Blu reduces the rework of UI designers for starting a de - sign from scratch [ 3 ] . It also assists designers to generate blueprints of UI design and convey the design information to developers . To demonstrate Blu , we created a web applica - tion 5 that utilizes the annotations from RICO and generates a blueprint ( Figure 3 ) . This web app helps to convey the design and layout information of UI screen . Summary & Future work In this paper , we presented our research on utilizing AI to assist designers in the UI designing process . We introduce the ﬁrst two of our tools ( MetaMorph and Blu ) from our pro - posed solution , BlackBox toolkit . This research is an ex - ploration of applying bleeding - edge AI research in human - computer interaction domain . This ongoing research is at its incipient phase with two tools . Further , we are planning to ideate and implement similar tools , such as generating UIs and automatic detection of accessibility issues in UIs . By this research , we are looking forward to a future where humans and AI collaborate in creative tasks similar to the analytical tasks . 5 https : / / blu . blackbox - toolkit . com / REFERENCES [ 1 ] B Deka , Z Huang , C Franzen , J Hibschman , D Afergan , Y Li , J Nichols , and R Kumar . 2017 . Rico : A Mobile App Dataset for Building Data - Driven Design Applications . In Proceedings of the 30th Annual ACM Symposium on UIST ( UIST ’17 ) . ACM , New York , NY , USA , 845 – 854 . DOI : http : / / dx . doi . org / 10 . 1145 / 3126594 . 3126651 [ 2 ] S R . Herring , C C Chang , J Krantzler , and B P . Bailey . 2009 . Getting Inspired ! Understanding How and Why Examples Are Used in Creative Design Practice . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’09 ) . ACM , New York , NY , USA , 87 – 96 . DOI : http : / / dx . doi . org / 10 . 1145 / 1518701 . 1518717 [ 3 ] VPS Pandian , S Suleri , and M Jarke . 2020a . Blu : What GUIs Are Made Of . In Proceedings of the 25th International Conference on IUI Companion ( IUI ’20 ) . ACM , New York , NY , USA , 81 – 82 . DOI : http : / / dx . doi . org / 10 . 1145 / 3379336 . 3381497 [ 4 ] VPS Pandian , S Suleri , and M Jarke . 2020b . Syn : Synthetic Dataset for Training UI Element Detector From Lo - Fi Sketches . In Proceedings of the 25th International Conference on IUI Companion ( IUI ’20 ) . ACM , New York , NY , USA , 79 – 80 . DOI : http : / / dx . doi . org / 10 . 1145 / 3379336 . 3381498 [ 5 ] S Suleri , VPS Pandian , S Shishkovets , and M Jarke . 2019 . Eve : A Sketch - Based Software Prototyping Workbench . In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI EA ’19 ) . ACM , New York , NY , USA , Article Paper LBW1410 , 6 pages . DOI : http : / / dx . doi . org / 10 . 1145 / 3290607 . 3312994