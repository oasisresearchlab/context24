Effort and Accuracy in Choice Author ( s ) : Eric J . Johnson and John W . Payne Source : Management Science , Vol . 31 , No . 4 ( Apr . , 1985 ) , pp . 395 - 414 Published by : INFORMS Stable URL : http : / / www . jstor . org / stable / 2631455 Accessed : 08 / 06 / 2009 11 : 06 Your use of the JSTOR archive indicates your acceptance of JSTOR ' s Terms and Conditions of Use , available at http : / / dv1litvip . jstor . org / page / info / about / policies / terms . jsp . JSTOR ' s Terms and Conditions of Use provides , in part , that unless you have obtained prior permission , you may not download an entire issue of a journal or multiple copies of articles , and you may use content in the JSTOR archive only for your personal , non - commercial use . Please contact the publisher regarding any further use of this work . Publisher contact information may be obtained at http : / / www . jstor . org / action / showPublisher ? publisherCode = informs . Each copy of any part of a JSTOR transmission must contain the same copyright notice that appears on the screen or printed page of such transmission . JSTOR is a not - for - profit organization founded in 1995 to build trusted digital archives for scholarship . We work with the scholarly community to preserve their work and the materials they rely upon , and to build a common research platform that promotes the discovery and use of these resources . For more information about JSTOR , please contact support @ jstor . org . INFORMS is collaborating with JSTOR to digitize , preserve and extend access to Management Science . http : / / dv1litvip . jstor . org MANAGEMENT SCIENCE Vol . 31 , No . 4 , April 1985 Printed in U . S . A EFFORT AND ACCURACY IN CHOICE * ERIC J . JOHNSON AND JOHN W . PAYNE Graduate School of Industrial Administration , Carnegie - Mellon University , Pittsburgh , Pennsylvania 15213 Fuqua School of Business , Duke University , Durham , North Carolina 27706 Individuals often use several different strategies such as the expected value rule , conjunctive rule , and elimination - by - aspects , to make decisions . It has been hypothesized that strategy selection is , in part , a function of ( 1 ) the ability of a strategy to produce an accurate response and ( 2 ) the strategy ' s demand for mental resources or effort . We examine effort and accuracy and their role in strategy selection . Several strategies that may be used to make choices under risk are simulated using a production system framework . This framework allows the estimation of the effort required to use the strategy in a choice environment , while simultaneously measuring its accuracy relative to a normative model . A series of Monte - Carlo studies varied several aspects of the choice environments , including the complexity of the task and the presence or absence of dominated alternatives . These simulations identify strategies which approximate the accuracy of normative procedures while requiring substantially less effort . These results , however , are highly contingent upon characteristics of the task environment . The potential of production system models in understanding task effects in decisions is stressed . ( DECISION MAKING ; SIMULATION ; HEURISTICS ) Introduction One of the major findings of years of decision research is that an individual uses many different cognitive processes ( strategies ) in making a decision , contingent on task demands . It has been suggested that the selection among decision strategies by an individual is , in part , a function of the strategy ' s accuracy , and the strategy ' s effort , that is its demand for mental resources ( Beach and Mitchell 1978 , Johnson 1979 , Klayman 1983 , Russo and Dosher 1983 , Shugan 1980 , Thorngate 1980 ) . A view of strategy selection as involving benefits and costs has several appealing aspects . The assumption of calculated rationality on the part of the decision maker ( March 1978 ) can be maintained once the costs of the decision process itself are included in the assessment of rationality . Even errors , such as intransitive preferences , may be seen as the outcome of a rational process . As Tversky ( 1969 ) has noted : It seems impossible to reach any definite conclusions concerning human rationality in the absence of a detailed analysis of the sensitivity of the criterion and the cost involved in evaluating the alternatives ( pp . 45 - 46 ) . In addition , because the costs and benefits of decision strategies will vary between tasks , the perspective of costs and benefits may partially explain contingent decision behavior ( Payne 1982 ) . A major difficulty in examining this perspective has been the lack of a conceptually appropriate measure of effort that is easy to calculate . This paper proposes an approach to measuring the effort associated with decision processes based on produc - tion system models and Monte - Carlo simulation . A second major problem with the cost - benefit perspective has been the lack of agreement on how to measure accuracy . The use of computer simulation has the advantage of making it easy to examine * Accepted by Arie Y . Lewin ; received May 23 , 1983 . This paper has been with the authors 3 months for 2 revisions . 395 0025 - 1909 / 85 / 3 1 04 / 0395 $ 01 1 . 25 Copyright ? 1985 , The Institute of Management Sciences 396 ERIC J . JOHNSON AND JOHN W . PAYNE multiple measures of accuracy . In addition , this approach allows the estimation of effort and accuracy as a function of changes in the task environment . We will argue that production system models are a reasonable framework for exploring how decision strategies may be learned and for guiding the design of decision support systems ( Keen and Scott - Morton 1978 ) . Task Analysis The task involves decisions under risk . Such a task is representative of a large number of real - world decision situations that involve uncertain outcomes . Previous work examining the accuracy of heuristics by Thorngate ( 1980 ) concerns risky choice . A risky choice problem consists of three basic components : ( 1 ) The alternatives available to the decision maker , ( 2 ) Events or contingencies that relate actions to outcomes , and ( 3 ) The values associated with the outcomes . These informational elements , along with a goal statement ( such as " choose the preferred alternative " ) , represent the heart of the risky choice task environment presented to a decision maker . The decision maker ' s internal representation of this task environment is the individ - ual ' s problem space , containing the solution ( i . e . the preferred alternative ) which must be identified ( Newell and Simon 1972 ) . Risky choice heuristics can be defined as rules which systematically simplify search through the problem space by disregarding some elements of the problem space . Alternative simplifications represent different heuristics : A decision maker can , for example , choose to ignore certain alternatives , either by deciding that an acceptable alternative has already been found ( satisficing ) or by eliminating an alternative from future consideration because of an objectionable outcome , such as a ruinous loss . Other simplifications consist of selective examination of the outcomes . The Maximin choice procedure suggests that a decision maker evaluates alternatives by examining only the outcome for each alternative with the lowest payoff . The alternative with the highest minimum payoff is selected . Decision makers might also ignore some of the event information present in the problem space . Thorngate ( 1980 ) describes the equiprobable procedure , which ignores probabilities , selecting the alternative with the highest average payoff . Other simplifications can occur in the process of combining attributes , such as calculating differences in payoffs and probabilities , as suggested by the additive difference rule ( Tversky 1969 ) . Actual choice behavior is probably not a straightforward execution of one choice strategy or another . Bettman ( 1979 ) suggests that choice may be more constructive . That is , " choice heuristics may not be stored in their entirety in memory , but may exist only as fragments - subparts which are put together constructively at the time of processing , at the time of making a decision or a choice " ( Bettman 1979 , p . 33 ) . Nonetheless , we feel that identifying the characteristics of prototypical strategies such as Maximin and Elimination - by - aspects ( Tversky 1972 ) is a useful first step in understanding why a decision maker utilizes different strategies as a function of task demands ( Payne 1982 ) . ' Measuring Accuracy Quality of choice can be defined by consistencies in preference , e . g . , transitivity . In the case of risky choice , however , more specific criteria have been suggested . The expected utility rule ( EU ) , for example , builds on principles of consistency to provide a specific mechanism for combining value and belief information into a decision . A ' Other characteristics besides the accuracy and effort of choice heuristics , may influence strategy use , for example , justification ( Slovic , Fischhoff , and Lichtenstein 1982 ) . EFFORT AND ACCURACY IN CHOICE 397 special case of the EU rule is maximization of expected value ( EV ) . The main advantage of EV as a choice rule is that the values of an individual decision maker are not required to operationalize the rule . Previous work on accuracy of heuristics by Thorngate ( 1980 ) adopted this EV criterion . Using a Monte - Carlo simulation , Thorngate determined the proportion of decisions for which several heuristics selected the alternative with the highest expected value . For purposes of comparison with Thorngate ' s results , we adopted the same measure of accuracy , and term it proportion accurate choices ( PAC ) . A limitation of Thorngate ' s measure of accuracy , and consequently of our - PAC measure , is its insensitivity to near misses , such as the selection of an alternative near the best in expected value . We therefore adopt an additional measure of accuracy that compares the relative performance of heuristics , in terms of EV , to a strict expected value rule and to a baseline response of random choice , which involves no search of the problem space : EVHeuristic Choice EVRandom Choice Relative Performance = EEV - EV ( 1 ) Optimal Choice Random Choice This measure of relative performance is bounded with a value of 1 . 00 for the expected value maximization strategy , and 0 . 0 for random selection . The measure has the property that it controls for the chance of an accurate response as a function of number of alternatives , as well as reflecting the relative sizes of errors made by heuristics for each set of alternatives . The EV rule is just a special case of maximization of expected utility strategy for risky choice . Consequently , we also examine the accuracy of heuristics using a third set of measures based on the expected utility strategy with utility defined by a power function U ( x ) = X213 ( Kahneman and Tversky 1982 ) . Finally , we examine a fourth measure of accuracy that is independent of the form of the value or utility functions . That measure is based on the frequency of selection of dominated alternatives ( Grether and Wilde 1982 ) . The number of times a dominated alternative ( an alternative inferior to another on all attributes ) is selected by a heuristic is a useful metric in that it is clear choice error . However , the prevalence of choice sets containing dominated alternatives is not readily apparent . In summary , we measure decision accuracy based on ( 1 ) The proportion of accurate choices , i . e . , those with maximum EV , and ( 2 ) relative performance , which reflects the degree of improvement in EV over a random choice , ( 3 ) expected utility and ( 4 ) dominance - based measures of accuracy . Measuring Effort Mental effort has a long and venerable history as a theoretical construct in cognitive psychology ( Kahneman 1973 , Navon and Gopher 1979 , Thomas 1983 ) . In the context of decision making , Russo and Dosher ( 1983 ) define effort as the total use of cognitive resources required to complete the task . We adopt that definition of effort . Attempts to compare decision rules in terms of an effort metric are just beginning . Shugan ( 1980 ) suggested that effort or " the cost of thinking " could be captured by " a measurable ( i . e . well - defined and calculable ) unit of thought . " He proposes the binary comparison of two alternatives on an attribute as that basic unit . The more compari - sons made , the more effortful the choice . Unfortunately , Shugan ' s use of the binary comparison as a fundamental unit of effort restricts his analysis to certain decision rules . An important contribution of Shugan ' s work , however , is ( 1 ) the notion that decomposing decision strategies into components can provide estimates of their relative costs , and ( 2 ) the observation that the effort required by a choice rule can be 398 ERIC J . JOHNSON AND JOHN W . PAYNE affected by task characteristics such as the covariance between attributes ( see also Wright 1977 ) . Huber ( 1980 ) and Johnson ( 1979 ) expand this notion of decomposing choice strategies into a set of components . Drawing on ideas of Newell and Simon ( 1972 ) they independently suggest that heuristic strategies can be constructed from a small set of elementary information processes ( EIP ' s ) . Thus a decision rule or strategy could be thought of as a sequence of events , such as reading the values of two alternatives on an attribute , comparing them , etc . Chase ( 1978 ) provides a more general discussion of using the EIP concept in the analysis of information processing . The EIP ' s described by Huber ( 1980 ) and Johnson ( 1979 ) for decision strategies are similar to those postulated for other cognitive tasks such as mental arithmetic ( Dan - sereau 1969 ) and problem solving ( Newell and Simon 1972 ) . A hope of those advancing the concept of EIP ' s is that there exists a small set of elementary processes common to a variety of tasks ( Chase , 1978 ) . Our measure of decision effort builds on the Newell and Simon ( 1972 ) proposal that effort be measured in terms of the number of elementary information processes used to select an option . A relationship has been shown between the number of EIP ' s predicted by models and response times for a variety of cognitive tasks ( Card , Moran and Newell 1980 ; Carpenter and Just 1975 ) . However , note that we are not proposing a complete theory of mental effort . Instead , we focus on a measure of effort for decision strategies that may allow us to better understand when such strategies will be used . Production Systems as Models : Combining Accuracy and Effort The decomposition of decision heuristics into component processes yields insight into the relative complexity of these rules . At the same time , the assumptions necessary to derive simple closed form expressions for estimating effort greatly limit the decision tasks that can be examined ( Johnson 1979 ) . Thus , although a detailed picture of each decision rule is obtained , the picture applies to a small class of possible decision problems . Another way of estimating effort is to implement heuristics as formal symbolic systems which can be simulated on a computer . One framework is a production system ( Newell and Simon 1972 ) , which consists of a set of productions , a task environment , and a working memory . The productions specify a set of actions ( EIP ' s ) and the conditions under which they occur . These are expressed as a ( condition ) - > ( action ) pair , and the actions specified in a production are performed ( fire ) only when the condition side is satisfied by matching the contents of working memory . Working memory is a set of symbols , both those read from the external environment , and those deposited by the actions performed by previous productions . The set of productions possessed by an individual can be thought of as being part of long - term memory . Arguments for the value of production systems as a representation of human cognitive processes and further descriptions of production systems are presented by Newell ( 1980 ) . Production rules also are often used to represent knowledge in expert or artificial intelligence systems designed to aid human judgments ( Duda and Shortliffe 1983 ) . Table 1 lists the set of elementary processes , similar to those described by Johnson ( 1979 ) and Huber ( 1980 ) , which were used in building the production system represen - tations of the choice rules . Figure 1 contains the production system representation of the expected value rule , which selects the alternative with the highest expectation from the set . This production system contains three productions , each of which performs the actions listed on the right - hand side of the figure only when the condition on the EFFORT AND ACCURACY IN CHOICE 399 TABLE I Primitive Operations Used in Simulation READ Read an alternative ' s value on an attribute into STM . COMPARE Compare two alternatives on an attribute DIFFERENCE Calculate the size of the difference of two alternatives for an attribute . ADD Add the values of an attribute in STM . PRODUCT Weight one value by another ( Multiply ) . ELIMINATE Remove an alternative from consideration . MOVE Go to next element of external environment . CHOOSE Announce preferred alternative and stop process . left - hand side is true . Thus , at the beginning of the decision , only the third production would be true , and the production system would then READ the payoff for the first alternative into working memory , MOVE its attention to the probability of that outcome , READ it , and use the PRODUCT operator to weight the payoff by its probability . This result is then ADDed to a running sum for the alternative , and attention is then MOVEd to the next payoff . This production continues to be applied until all outcomes have been examined . Now the second production fires , and COMPAREs this alternative to the best found until now , and marks the winner as the current best alternative found . This process repeats until all alternatives have been examined , and the condition side of the first production in the list becomes true , announcing that the alternative which is the current best alternative has been chosen . It is worth noting about this production system and its components that although expectation - based decision rules are generally thought to be very effortful , the rule can be implemented without making large demands on working memory . This is accom - plished by combining the partial results as soon as possible ( note the ADD operation in Figure 1 ) . All the decision rules we discuss operate similarly , and do not store results in long - term memory . Additionally , all are designed to minimize the number of operations . Because human decision makers may not necessarily adopt this technique , our implementations represent minimum estimates of the effort required to use each strategy . For example , variations of the strategies that would use long - term memory operations would lead to greater estimates of effort . Also adjustment of values of probabilities implied by the product operator , for example , may not involve a literal multiplication of two numbers , rather they may be combined by some analogical process which adjusts the value of one quantity given another ( Lopes 1982 ) . Several conflict resolution mechanisms have been proposed to select a production to execute if more than one is true . Our implementations simply assume that the first production in the list whose condition side is matched fires . These elementary processes are similar to ( if at the end of alternatives ) then ( CHOOSE alternative which is currently the best ) ( if at the end of the outcomes ) then ( COMPARE the Current Alternative to the current best ; winner becomes current best ) ( if not at the end then ( READ the outcome ' s payoff ; of the outcomes ) MOVE to the probability ; READ the outcome ' s probability ; PRODUCT the probability times the payoff ; ADD the Result to the Current Alternative ; MOVE to the next outcome ' s payoff ) FIGURE 1 . The Expected Value Rule . 400 ERIC J . JOHNSON AND JOHN W . PAYNE those found in studies of other cognitive tasks , where estimates of the time required for each operation have been made . Implementating production systems as computer programs is straightforward . Through Monte - Carlo techniques , it is possible to observe the choice that would be made by each rule over many trials , as done by Thorngate ( 1980 ) , while simulta - neously counting the number of mental operations required by each heuristic . Simulation Heuristics We examine six heuristics which make quite different simplifications of the problem space for risky choice . These rules clearly differ along several dimensions , such as the method used to integrate probability and payoff information . However , they also differ markedly in the amount of available information that they consider . A priori , we might expect this to be an important determinant of both the accuracy and the effort resulting from their use . At one extreme is the Expected Value rule , which does not simplify the problem space at all . The selection of an alternative is based on complete search of the available information . The Equiprobable heuristic similarly examines all the alterna - tives and all outcomes . It , however , ignores one of the two attributes of an outcome , its probability , implicitly treating all events as equally likely . To choose a lottery , the Equiprobable heuristic adds the payoffs for the outcomes of each alternative , and chooses the alternative with the highest total . This heuristic is similar to an equal weight model . The Most Likely heuristic , in contrast , examines only one outcome for each alternative , the outcome with the highest probability of occurrence , and selects the alternative with the largest payoff for this outcome . Thus , this rule searches each event to find the most - likely outcome , and examines only the payoff associated with that event . This heuristic is similar to a lexicographic rule . The Maximin heuristic ignores probabilities entirely and selects the alternative with the largest minimum payoff . This heuristic is related to the conjunctive rule . Elimination - by - aspects is a choice rule proposed by Tversky ( 1972 ) . We implement a version discussed by Thorngate ( 1980 ) which attends only to payoff information . Each payoff of a gamble is compared to a cutoff equal to the mean payoff . If a payoff is less than the cutoff , the gamble is eliminated from further consideration . The rule terminates when either ( 1 ) one alternative remains or ( 2 ) all attributes have been considered , and one must choose randomly from the remaining alternatives . Note that the Elimination - by - aspects rule ignores probabilities entirely , and performs only partial search of the payoff informa - tion . Finally , the Random choice rule serves as a baseline , simply choosing an alternative at random with no search . 2 Task and Context Variables The terms task variables and context variables have often been used interchangeably in the literature . We adopt the following distinction : Task variables are those asso - ciated with general characteristics of the decision problem , such as the number of alternatives , which are not dependent on the particular values of the objects of the decision sets . Context variables , in contrast , are associated with the particular values of the objects , such as the correlation between attributes ( Payne 1982 ) . Other possible distinctions between task and context are discussed by Einhorn and Hogarth ( 1981 ) . 2A listing of the production system representation for all rules but the random and the source code written in PASCAL is available from either author or the editorial office of Management Science , 290 Westminster Street , Providence , Rhode Island 02903 . EFFORT AND ACCURACY IN CHOICE 401 A frequently explored task variable is the complexity of the decision problem , usually manipulated through variation in the number of alternatives and outcomes presented by the choice problem . We vary the number of risky alternatives and outcomes at levels of 2 , 4 , and 8 . These levels match previous behavioral and simulation research ( Payne 1976 , Thorngate 1980 ) . We expect the decision strategies to show differential increases in effort as tasks become more complex ( Johnson 1979 ) . We also expect decreases in the accuracy of heuristics as the complexity increases ( Thorn - gate 1980 ) . This makes variations in task complexity particularly interesting : It may be possible , for example , to identify heuristic rules which remain relatively effortless , and substantially accurate , as tasks become more complex . Context effects have received considerably less attention than task effects in decision research . In part , this is because there is little systematic theory to guide the explora - tion of the impact of context on the accuracy and effort of choice rules . Indeed , previous work has made general statements about the viability of some decision rules based upon results obtained from a single context . For example , Thorngate ( 1980 ) suggests that probability information may be relatively unimportant in making accu - rate risky choices : A wide variety of decision heuristics will usually produce optimal , or close to optimal results and can thus be termed relatively efficient . The . . . equiprobable heuristic deserves further comment . . . its high efficiency suggests that ' good ' choices can very often be made with scant regard for the subtleties of accurate probability estimation procedures ( pp . 223 - 224 ) . Because this generalization is based upon a single context , it should be viewed with some caution . The probabilities in a risky choice must , by definition , sum to 1 . Within this constraint , the variance of the distribution of probabilities can vary from a minimum of 0 when all outcomes are equally likely ( p = 1 / m for all m outcomes ) to a maximum of 1 / m - 1 / m2 when one of the m events is certain ( p = 1 ) , the rest impossible ( p = 0 ) . Thorngate ' s method for constructing gambles ensured that the variance in the probability distribution would be small relative to the variance in payoffs . Since expected value is the product of these two quantities , it is not surprising that probability information had little impact on the performance of his rules . Further , since the tendency of Thorngate ' s method to produce low variance in probabilities increases exponentially with the number of outcomes , we should be particularly cautious in interpreting his results for more complex environments . In the simulation we implement another method of probability generation which produces larger vari - ances in the probability distributions . Characteristics of the two methods are discussed in the Appendix . Another context variable which can vary between choice sets is the presence or absence of dominated alternatives . Although random generation itself can produce dominated alternatives , it has been argued that decision makers ignore them , effec - tively reducing the size of the choice set ( Keeney and Raiffa 1976 ) . On the other hand , dominated alternatives can impact choice ( Huber , Payne and Puto 1982 ) . It has also been suggested that the success of one simplified strategy , the equal weighting of attributes , is dependent upon the presence of dominated alternatives ( McClelland 1978 ) . In the simulations that follow , we examine decision sets with dominated alternatives present and those with dominated alternatives removed . Method Each of the six decision rules was applied to 200 randomly generated decision problems in each of 36 conditions defined by a 3 ( Number of Alternatives ) by 3 402 ERIC J . JOHNSON AND JOHN W . PAYNE ( Number of Outcomes ) by 2 ( Variance of Probabilities ) by 2 ( Presence or Absence of Dominated Alternatives ) factorial . After each trial the alternative selected was re - corded along with a tally of each elementary operation used by the decision rule . Payoffs were randomly selected from a uniform distribution bounded by 0 and 1000 by the multiplicative congruence method using the IMSL subroutine GGUBS . Proba - bilities were generated by one of two methods : The low - variance condition replicates Thorngate ' s ( 1980 ) procedure . The required number of deviates , m , was generated from a uniform distribution and divided by the sum , normalizing the sum to 1 . 0 . In contrast , the high variance method first selected a deviate from range 0 , 1 . Each subsequent deviate was randomly selected from the interval ( 0 , 1 - pi ) where pi are the previously generated deviates . When m - 1 probabilities had been generated the procedure halted and the mth probability was set to 1 - pi . The presence or absence of dominated alternatives was manipulated by testing for the presence of first - order stochastic dominance . First order stochastic dominance describes a relation between two risky alternatives , A and B that ensures that A will always produce a higher utility than B for a decision maker with a finite , monotoni - cally increasing utility function . It is analogous to simple dominance for riskless choice . A detailed description of the alternative generation procedure is available in the Appendix . Note that despite the widely differing characteristics of the four cells created by the two types of context effects , all cells will have the - same mean payoff and probability , and that the correlation between payoffs and probabilities will be close to 0 . The differences due to context effects are reflected in the variance of the probabilities , and in the covariation of the payoffs across gambles . All initialization , execution , and recording routines for the simulation are written in PASCAL , with the exception of random number generation performed by the Fortran language IMSL subroutines . 2 Analysis The significance of the results was established by an analysis of variance of the cell means based upon the 200 trials . This five way ANOVA analyzed the task effects , that is , number of alternatives ( 2 , 4 or 8 ) , and number of outcomes ( 2 , 4 or 8 ) and the context effects , that is the presence or absence of dominated alternatives and variance of probabilities ( low or high ) . The final factor in the design was decision rule . For some dependent measures the cells in the analysis contained constants , and subse - quently no within - cell variance . For example , the Expected Value strategy always chose the correct answer , resulting in a proportion of correct choice equal to 1 . 0 . To provide an analysis which did not violate the assumption of homogeneous within - cell variance , we used an error - term based upon the within - cell variances of the noncon - stant cells . Although the resulting test is conservative , the experimental design provides sufficient power for hypothesis testing . While the large number of trials ensures stable estimates , it also provides overwhelm - ing statistical significance for many effects . Accordingly , in reporting results it be - comes more important to examine the size of each effect relative to the others . Since all factors use the same error term , the magnitude of the F statistic is an index of the size of effects and is a linear function of other measures such as w2 . Results The two dependent measures , accuracy and effort , will be discussed sequentially , and we will then discuss their relationship . For each measure , we will start with the low - variance , dominated alternative condition , the cell which most closely replicates EFFORT AND ACCURACY IN CHOICE 403 Thorngate ' s ( 1980 ) results , and then discuss the results for the remaining experimental conditions . The Accuracy of Heuristics Table 2 presents the proportion of accurate choices , i . e . the proportion of trials in which each heuristic selects the gamble with the highest expected value , while Table 3 presents their relative performance , i . e . the percent improvement in expected value relative to a random choice . The low - variance , dominance present cell , labeled ( 1 ) in the tables , resembles the task environment used by Thorngate , and our results closely replicate his . The equiprobable rule , for example , appears to be quite accurate . A decision maker using such a heuristic in this task environment will select the best option about 75 % of the time ( see Table 2 ) and will average almost 90 percent of the expected value provided by the normative model relative to random choice see Table 3 . In general , the heuristics demonstrate impressive accuracy in this task environment . Note , however , that increases in task complexity have different effects upon the various rules . Increasing the number of outcomes , for example , does not affect the level of absolute and relative accuracy of the equiprobable heuristic . Other rules , in contrast , show decreases in accuracy as the number of outcomes increases . The results for the two EV - based measures of accuracy , Tables 2 and 3 , tend to agree on the ranking of the heuristics with respect to accuracy . Absolute and relative measures of accuracy based on expected utility maximization with utility defined by a power function ( Kahneman and Tversky 1982 ) showed a similar pattern of results . Other utility functions are , of course , possible . Nonetheless , our results do not appear to be limited to just expected value based measures . A different view of heuristics emerges , however , when the variance of the probabili - ties , relative to the payoffs , increases . For the high variance , dominated alternatives present condition , labeled ( 2 ) in the tables , the Most Likely heuristic is now the most TABLE 2 Proportion of Accurate Choices ' Task Conditions Context Choice Number of Alternatives Number of Outcomes2 Condition Rule 2 4 8 2 4 8 1 . Low Variance Equiprobable 0 . 84 0 . 76 0 . 65 0 . 77 0 . 74 0 . 73 Dominated Most Likely 0 . 78 0 . 64 0 . 48 0 . 77 0 . 60 0 . 53 Alternatives Maximin 0 . 73 0 . 56 0 . 46 0 . 69 0 . 58 0 . 48 EBA3 0 . 63 0 . 51 0 . 36 0 . 58 0 . 49 0 . 43 2 . High Variance Equiprobable 0 . 77 0 . 60 0 . 46 0 . 73 0 . 59 0 . 50 Dominated Most Likely 0 . 86 0 . 75 0 . 62 0 . 78 0 . 75 0 . 70 Alternatives Maximin 0 . 68 0 . 47 0 . 34 0 . 65 0 . 48 0 . 35 EBA 0 . 63 0 . 47 0 . 29 0 . 57 0 . 41 0 . 36 3 . Low Variance Equiprobable 0 . 68 0 . 39 0 . 21 0 . 46 0 . 42 0 . 39 No Dominated Most Likely 0 . 72 0 . 52 0 . 38 0 . 61 0 . 53 0 . 48 Alternatives Maximin 0 . 58 0 . 30 0 . 09 0 . 25 0 . 34 0 . 38 EBA 0 . 56 0 . 24 0 . 12 0 . 28 0 . 33 0 . 32 4 . High Variance Equiprobable 0 . 58 0 . 35 0 . 20 0 . 42 0 . 38 0 . 32 No Dominated Most Likely 0 . 81 0 . 65 0 . 55 0 . 68 0 . 65 0 . 68 Alternatives Maximin 0 . 50 0 . 23 0 . 06 0 . 23 0 . 27 0 . 30 EBA 0 . 50 0 . 27 0 . 13 0 . 30 0 . 29 0 . 31 Expected Value 1 . 00 1 . 00 1 . 00 1 . 00 1 . 00 1 . 00 Random 0 . 50 0 . 25 0 . 13 0 . 29 0 . 29 0 . 29 ' Percent of EV Maximization Choices . 2Differences exceeding 0 . 02 are significant , a priori , 0 . 047 a posteriori , p < 0 . 05 . 3Eiiainb - set Rule . 404 ERIC J . JOHNSON AND JOHN W . PAYNE TABLE 3 Relative Performance of Heuristics ' Task Conditions Context Choice Number of Alternatives Number of Outcomes Condition Rule 2 4 8 2 4 82 1 . Low Variance Equiprobable 0 . 83 0 . 90 0 . 88 0 . 91 0 . 86 0 . 84 Dominated Most Likely 0 . 75 0 . 75 0 . 72 0 . 88 0 . 77 0 . 57 Alternatives Maximin 0 . 54 0 . 67 0 . 69 0 . 81 0 . 63 0 . 45 EBA 3 0 . 35 0 . 55 0 . 58 0 . 63 0 . 52 0 . 32 2 . High Variance Equiprobable 0 . 68 0 . 65 0 . 71 0 . 81 0 . 67 0 . 49 Dominated Most Likely 0 . 93 0 . 94 0 . 93 0 . 91 0 . 87 0 . 87 Alternatives Maximin 0 . 52 0 . 56 0 . 59 0 . 82 0 . 53 0 . 32 EBA 0 . 38 0 . 46 0 . 50 0 . 62 0 . 45 0 . 27 3 . Low Variance Equiprobable 0 . 46 0 . 35 0 . 23 0 . 42 0 . 39 0 . 23 No Dominated Most Likely 0 . 60 0 . 61 0 . 56 0 . 67 0 . 62 0 . 48 Alternatives Maximin 0 . 18 0 . 11 0 . 00 0 . 00 0 . 13 0 . 16 EBA 0 . 16 0 . 10 0 . 03 0 . 10 0 . 18 0 . 01 4 . High Variance Equiprobable 0 . 26 0 . 25 0 . 13 0 . 38 0 . 20 0 . 07 No Dominated Most Likely 0 . 83 0 . 86 0 . 77 0 . 83 0 . 82 0 . 81 Alternatives Maximin 0 . 05 0 . 03 0 . 00 0 . 02 0 . 04 0 . 00 EBA 0 . 12 0 . 14 0 . 00 0 . 14 0 . 10 0 . 02 Expected Value 1 . 00 1 . 00 1 . 00 1 . 00 1 . 00 1 . 00 Random 0 . 00 0 . 00 0 . 00 0 . 00 0 . 00 0 . 00 | Percentage of Expected Value Gained over Random Choice . 2Differences exceeding 0 . 016 are significant , a priori , 0 . 036 a posteriori , p < 0 . 05 . 3Elimination - by - Aspects . accurate , while the Equiprobable heuristic displays a marked decrease in accuracy . Similarly , the Most Likely rule now appears to be the only rule which remains accurate as the number of outcomes increases . These results suggest that Thorngate ' s findings are of limited generality . The unimportance of probability information is not apparent in this context where a rule which considers probability information , the Most Likely , is superior to a rule which does not , such as the Equiprobable . These results are particularly important in light of the suggestion made by Beach ( 1983 ) that Thorn - gate ' s results justify deemphasizing the importance of probabilities in decision aids . The effect of our other context manipulation , the removal of dominated alternatives , is dramatically demonstrated in Tables 2 and 3 , conditions ( 3 ) and ( 4 ) . The Maximin and Elimination - by - aspects heuristics , which were reasonably accurate in the presence of dominated alternatives , now perform at near chance levels . Note also the effect of increases in the number of alternatives and outcomes . As can be seen in the tables , the removal of dominated alternatives increases the impact of task effects on several of the heuristics . Why is this the case ? We conclude that the accuracy of some of the heuristics in the presence of dominated alternatives is due , at least in part , to their ability to screen truly inferior alternatives . Almost all the choice strategies examined successfully avoid dominated alternatives . The only rules selecting a dominated alternative with any frequency were the Random and Elimination - by - aspects . When dominated alterna - tives are removed , the heuristics ( except the Most Likely heuristic ) do not improve much on random selection . The analyses of variance conducted upon both dependent measures , proportion of accurate choices ( Table 2 ) and relative expected value ( Table 3 ) , confirm the signifi - cance of the observed differences . The ANOVA ' s showed a significant , p < 0 . 0001 , effect of rules , number of alternatives and outcomes , and context manipulations . In EFFORT AND ACCURACY IN CHOICE 405 addition , the interactions of rules with number of alternatives , number of outcomes , and both context variables , were significant for both dependent measures , p < 0 . 0001 . These analyses also allow the computation of confidence intervals for the two mea - sures . Both a priori ( simple t - test ) and a posteriori ( Tukey ' s method for pairwise comparisons ) confidence intervals are noted in each table . In summary , the results support Thorngate ' s suggestion that heuristic rules can approximate the performance of normative procedures , they are not supportive of his suggestion that the accuracy of a heuristic is generalizable . The " right " heuristic to use in a choice task seems to be strongly influenced by context effects . A decision maker trying to maximize accuracy using heuristic strategies would need to know ( 1 ) several heuristics and ( 2 ) the appropriate conditions for their use . Thus , like Newell and Simon ( 1972 , p . 139 ) , we conclude that " the effectiveness of particular heuristics is a function of the problem space . " Effort and Heuristics The simulation yields a count of the numbers of each of the elementary processes listed in Table 4 . To discuss the overall effort of any choice procedure , however , we need to develop some meaningful procedure for aggregation . We consider two possible schemes for combining the component counts into an overall index : First , if each heuristic contains approximately equal proportions of each elementary information process , their sum would generate a convenient estimate of overall effort ( Newell and Simon 1972 , p . 130 ) . The ordering of the strategies on this index will be invariant over various estimates of the effort required by individual operations . Second , we could use empirical estimates of effort for each elementary process , and weight the tally by the estimates . One source of such estimates is previous research attempting to parameterize the time necessary to execute similar EIPs . Work in mental arithmetic suggests that simple ADDs and PRODUCTs are well described as fact - retrieval processes . While the time required to perform each is somewhat dependent upon the size of the operands , university students typically average between 0 . 8 and 1 . 1 seconds to perform single digit multiplications or additions ( Dansereau 1969 ) . Dansereau suggests that 0 . 3 seconds may be required to encode single digits , an operation analogous to our READ parameter . Comparison between two digits ( similar to the COMPARE operator ) may take 0 . 3 seconds . While there is no direct analogy to the ELIMINATE operator , similar operations in psycholinguistics ( the marking of a relation ) take between 0 . 1 and 0 . 4 seconds ( Chase 1978 ) . The MOVE operator is similar to an eye fixation which has a typical duration of about 0 . 23 seconds ( Russo 1978 ) . These approximations suggest that equal weighting of each elementary operation may not seriously misrepresent TABLE 4 Average Number of Production Operators Utilized by Each Rule Choice Operators ' Rule Moves Read Product Add Eliminate Comparison Total Equiprobable 52 . 9 21 . 7 0 21 . 8 0 6 . 7 103 . 1 Most Likely 66 . 9 26 . 4 0 0 0 20 . 8 114 . 1 Maximin 52 . 9 21 . 7 0 0 0 26 . 4 101 . 1 Elimination - by - Aspects 10 . 0 7 . 7 0 0 3 . 8 6 . 7 28 . 2 Expected Value 52 . 9 43 . 6 21 . 8 21 . 7 0 4 . 7 144 . 7 Random 1 . 8 0 0 0 0 0 1 . 8 ' CHOOSE is not listed since it is constant ( 1 ) for all rules . 406 ERIC J . JOHNSON AND JOHN W . PAYNE TABLE 5 Total EIP ' s by Task Complexity Task Condition Number of Alternatives Number of Outcomes Choice Rule 2 4 8 2 4 8 Equiprobable 43 . 3 86 . 7 173 . 3 51 . 3 88 . 7 163 . 3 Most Likely 48 . 3 97 . 7 196 . 3 64 . 3 106 . 7 163 . 3 Maximin 43 . 3 86 . 7 173 . 3 51 . 3 88 . 7 163 . 3 Elimination - 9 . 1 23 . 9 51 . 1 26 . 0 28 . 6 29 . 4 by - aspects Expected Value 62 . 0 124 . 0 248 . 0 70 . 0 126 . 0 238 . 0 Random 0 . 5 ' 1 . 5 3 . 5 1 . 8 1 . 8 1 . 8 ' Differences exceeding 0 . 074 are significant at p < 0 . 05 a priori , 0 . 134 a posteriori . effort costs . To explore the sensitivity of these effort estimates to the weights applied to each operator , we compared an equal weight estimate to one based upon the empirical estimates : Effort = 0 . 3 * READ + 0 . 23 * MOVE + 0 . 3 * ELIMINATE + 0 . 3 * COMPARISON + 0 . 9 * ADD + 1 . 2 * MULT . The resulting high correlation , r = 0 . 97 , suggests that the parameterless , equal weighting model is sufficient to describe these simplified decision tasks . Table 5 displays the total number of operations required by each rule as a function of the number of alternatives and the number of outcomes . It is apparent from Table 5 that the rules differ in the impact of increasing task complexity upon effort . For example , Elimination - by - aspects is the least effortful of the nonrandom choice proce - dures at all levels of complexity , while the Expected Value rule is always the most effortful . The other heuristics we examine , such as the Maximin , Equiprobable and the Most Likely , require approximately equal , intermediate amounts of effort . Increases in the amount of information presented to the decision maker affect these heuristics differently : Some rules increase in effort more rapidly than others . For example , Elimination - by - aspects is practically unaffected by an increase in the number of outcomes ( 26 . 0 operators for two outcomes , 29 . 4 for eight ) , while the Expected Value rule shows a large increase ( 70 . 0 vs . 238 . 0 ) . In general , the effort required to use the heuristics increases more slowly than the effort required to use Expected Value . Elimination - by - aspects requires only 42 more operators when the number of alterna - tives increases from 2 to 8 . For the Equiprobable rule the equivalent increase in 130 operations . Expected Value requires 186 additional operators . Thus , all other things being equal , the Expected Value rule may seem less attractive , relative to the other rules , as the number of alternatives or outcomes in a choice set increases . This matches empirical results reported in Payne and Braunstein ( 1978 ) . Finally , it is worth noting that the two heuristics that are quite accurate relative to expected value , the Equiprob - able and the Most Likely , require substantially less effort than Expected Value , suggesting that these may be attractive strategies to a decision - maker willing to trade some accuracy for effort . A striking feature of the effort estimates not apparent from Table 5 is their invariance across context effects . The effort levels associated with many of the strategies are unaltered by changes in the variance of the probabilities or by the removal of dominated alternatives . This implies that a decision maker who minimizes effort will be relatively insensitive to context effects in the selecting strategies . On the other hand , the accuracy of this set of choice rules is strongly affected by context . This EFFORT AND ACCURACY IN CHOICE 407 suggests the hypothesis that effort is greatly affected by task variables and not by context variables , while accuracy is greatly affected by context variables and less so by task variables . This is strongly confirmed by the results of the ANOVA . Although the analysis shows that the impact of the task effects and their interactions are all quite significant , F > 10 , 000 in many cases , the effects of the context effects and their interactions are much smaller , F < 22 . Trading Accuracy and Effort Central to a cost - benefit analysis of strategy selection is the existence of an accuracy - effort tradeoff , a continuum of rules in which increases in effort result in increases in accuracy . The estimates of accuracy and effort provided by the simulation allow the construction of such a display , shown in Figure 2 . The figure shows the results from the low variance and high variance , dominance present contexts averaged over task variables . Drawn for each context is a line connecting the strategies which , for a given level of total effort , are the most accurate in terms of relative performance ( see Table 3 ) . Strategies not on this line are dominated and are inferior ( in terms of accuracy and effort ) to those on the frontier . The differences between the two frontiers illustrate an important point : The rules which describe an accuracy - effort tradeoff vary with context . The equiprobable rule decreases greatly in accuracy when the variance of probabilities increases , without a commensurate decrease in effort . As a consequence it falls far below the efficient frontier . It is interesting to note that these shifts seem to result from context effects rather than changes in task effects . An examination of the data shows that the set of efficient strategies does not vary as the number of alternatives or outcomes change . However , as Figure 2 shows , the set does change with the variance manipulation . This yields an interesting implication for a cost - benefit perspective . Inherent in this perspective is the idea that the importance of the decision will affect the choice of the decision rule . The more important the decision , the more effort a decision maker will expend ( moving to the upper left of the accuracy - effort curve ) . However , the current data suggest that the curve is not consistent across task environments . Relatively subtle changes in context , such as the variability in probabilities , or the presence of domi - nated alternatives , should change preferences for choice strategies . Expe ted Utility 100 Mos i lU ~ y + 90 Equiprob a 0 * 80 0 Most - Likely 0 > 70 - Equiprobable + , 6 Maximin E U 60 - , , ] 50 - beaximin + * . EB ~ W 30 - EB 40 - 30 - 204 Effort 0 Low Variance + High Variance FIGURE 2 408 ERIC J . JOHNSON AND JOHN W . PAYNE Discussion We need to interpret the results of the simulation with some caution . Although we have examined several task environments , many more task and context variations can be investigated . These should include nonrisky and dynamic choice environments . As we have shown , the accuracy and effort associated with a heuristic are sensitive to task environments . For example , the Equiprobable and Most Likely rules reversed in their rank in accuracy as a function of the variance in probabilities . There are , however , several generalizations that are suggested by our results : First , the data show that heuristics , in at least some task environments , can approximate the accuracy of normative rules with substantial savings in effort . Second , no single heuristic will do well across all contexts . Instead , if decision makers strive to maintain a high level of accuracy with a minimum of effort , they would choose from a repertoire of strategies . Finally , our results suggest that task effects tend to have greater influence on effort while context effects tend to have greater influence on accuracy . Combined Decision Rules The present paper has treated each decision rule as one that would be uniquely applied to a decision problem . There is evidence , however , that decision makers will employ strategies that combine rules . For example , Payne ( 1976 ) reports that subjects faced with choice task involving a large number of alternatives will first use an elimination - by - aspects process to eliminate alternatives . When the choice problem is reduced to a smaller set of alternatives ( e . g . , two ) , decision makers shift to a more compensatory decision process ( see also Montgomery and Svenson 1976 ; Wright and Barbour 1977 ) . We examined one such combined rule . This rule used elimination - by - aspects until only three alternatives remained , then calculated expected value of the alternatives on their unexamined attributes . This rule showed some improvement over simple elimina - tion by aspects , choosing the alternative with the highest expected value 15 % more often . Most importantly , when compared to the other heuristics this rule shows much slower increases in effort when the number of alternatives increases . While the equiprobable heuristic shows a four - fold increase in effort as the number of alterna - tives increases ( 43 . 3 vs . 173 . 3 ) , the equivalent increase for the phased rule is less than two - fold ( 39 . 3 vs . 59 . 7 ) . Thus the combined rule has two attractive aspects : ( 1 ) it increases the accuracy of the elimination strategy while ( 2 ) maintaining that strategy ' s relatively low effort in large choice sets . More research on combined decision strategies seems warranted . Task Effects and Production System Models In a recent view of decision research , Einhorn and Hogarth ( 1981 ) note that " The most important empirical results in the period under review have shown the sensitivity of judgment and choice to seemingly minor changes in tasks " ( p . 61 ) . In addition to its descriptive interest , the lack of invariance in decision behavior across seemingly similar tasks is a concern to those attempting to improve decision performance . At the least , the lack of invariance raises questions about the validity of the judgmental inputs needed to operationalize the normative procedures . ( See Hershey , Kunreuther and Schoemaker 1982 for examples of biases in the assessment of utility functions . ) The major theme of this paper is that decomposing common decision strategies into component processes ( EIP ' s ) and simulating them as production systems may offer a way to identify and understand the potential impact of task variables on decision behavior . The present study shows that increasing numbers of alternatives affect differently the effort associated with expectation and elimination - by - aspects strategies . If effort is a consideration in strategy selection , it should not come as a surprise that EFFORT AND ACCURACY IN CHOICE 409 choice behavior is sensitive to the number of alternatives ( see Olshavsky 1979 ; Payne 1976 ; Payne and Braunstein 1978 for empirical evidence and Klayman 1983 for additional evidence from a computer simulation ) . Although not investigated in this paper , manipulation of information formats provides additional examples of the potential value of decomposing strategies into EIP ' s . Huber ( 1980 ) , for instance , reports that the display of information in a verbal form ( e . g . , very good or poor ) as opposed to a numerical form ( e . g . , 8 on a nine - point scale ) reduces the use of strategies containing concatenation or summing types of EIP ' s . Huber explains the result by suggesting that before concatenation " can be performed on verbal information , it somehow has to be transformed , e . g . , by counting the verbal steps between two verbal lables " ( p . 192 ) . The transformation process is assumed to involve additional effort ( EIP ' s ) and therefore reduces the attractiveness of strategies involving concatenation or summation under verbal displays . Important display effects are also reported by Bettman and Kakkar ( 1977 ) , Payne and Braunstein ( 1978 ) , Russo ( 1977 ) , Yates , Jagacinski , and Faber ( 1978 ) among others . Many of these effects may be understood in terms of the impact of display variables upon the effort required by EIP ' s such as READ and MOVE . Finally , a result readily apparent in Table 4 is that decision rules make differential use of the various operators . For example , only the Expected Value and Equiprobable heuristics use the arithmetic operations ADD and PRODUCT . This suggests that strategies may be affected differently when an operator becomes more effortful . If the outcomes of a gamble were described by three - digit numbers , for example , the literature would suggest that these arithmetic operators would be much more cumbersome , while other operators such as comparisons would be only minimally affected . This should make rules that depend on arithmetic operators like Expected Value or Equiprobable more effortful relative to rules that utilize comparisons such as Elimination - by - aspects . From a cost - benefit perspective , this makes the former rules less attractive relative to the latter . The importance of task variables in the design of messages which inform people about risk ( Slovic , Fischhoff and Lichtenstein 1981 ) and in the design of decision support systems ( Keen and Scott - Morton 1978 ) is clear . Researchers need to continue to conduct experiments identifying task and context effects . In addition , researchers should begin to explore the impact of various types of processing aids on decisions . We believe such research would be facilitated by the decomposition of decision strategies into sets of productions that can be studied under various task conditions through Monte - Carlo simulation . Validation One method of validating estimates of accuracy and effort would be indirect , through the correct prediction of the impact of task and context effects upon the selection of decision rules . The current framework is compatible with several existing results in the literature . Nonetheless , much more direct tests of the degree of corre - spondence between the efficient strategies for a given decision problem identified by our simulations and the actual strategies people use need to be conducted . A variety of process tracing techniques may prove useful in such studies ( Bettman 1979 , Payne 1976 ) . An important feature of production system representations of decision strategies is the close mapping between the firing of a production and a number of process tracing measures of behavior . Another approach to validation would use elementary operations to explain and predict decision related behavior such as the total time required to make a decision or self - reports of cognitive effort . The success of these attempts depends upon : 1 . The serial nature of human information processing in higher level cognitive tasks , and 410 ERIC J . JOHNSON AND JOHN W . PAYNE 2 . The assumption that each mental operation , on average , possesses a characteristic amount of effort . Although such assumptions are clearly false for some cognitive tasks , such as highly practiced visual search , their validity for decision tasks is an empirical question . To conduct this research , we must first decompose decision strategies and tally the elementary operations required by each strategy . These estimates can then be used in a regression model to explain both total decision time and self - reports of effort . There are two interrelated manipulations which might allow us to estimate effort : 1 . Subjects could be instructed to use a given rule , and the simulations ' estimates of effort would predict latency and reports of effort . A pilot study by John Conery using a similar procedure is reported in Russo and Dosher ( 1983 ) . 2 . Observe , through process tracing techniques , such as verbal reports or informa - tion search , the strategies used by untrained decision makers , and infer which elemen - tary processes are used . Whichever method is used , we would hope that such estimates both fit the data well and are consistent across different tasks . Note that this analysis does not necessarily predict that decision latency and self - reports of effort will necessarily agree . Two cognitive processes which require the same amount of time may require quite different levels of mental effort ( Kahneman 1973 ) . Thus a comparison may take about as long as an addition , but require less cognitive resources or attention . Subjects may report that comparison intensive rules such as the Most Likely are less effortful than addition - intensive rules , such as the Equiprobable , even though the rules may have identical latencies . Deciding How to Choose and Learning Accuracy / Effort Tradeoffs Part of the concern with accuracy and effort is motivated by the role these concepts may play in strategy selection . As Einhorn and Hogarth ( 1981 ) note : " The wide range of strategies one can use in any given situation poses important questions about how one decides how to choose " ( p . 69 ) . Accuracy and effort are just some of the considerations which may help determine a decision maker ' s selection of strategy . Strategies themselves may be viewed as multidimensional objects ( Einhorn and Ho - garth 1981 ) , and include additional considerations such as justifiability , speed of decision , and awareness of conflict . Such a perspective suggests several obvious questions about strategy selection : ( 1 ) Which dimensions are most important ? ( 2 ) Is strategy selection itself compensatory or noncompensatory ? ( 3 ) When , and how often , does the evaluation of potential strategies occur ? Let us examine , in closing , these questions in light of the simulation results and current literature in decision making . As discussed in the preceding section , there are phenomena that appear consistent with the view that decision makers are influenced by effort . There is less evidence demonstrating the influence of accuracy . ( See Klein 1983 for a discussion of how utility considerations may guide strategy use . ) Because the most accurate decision procedure , maximization of expected utility , is often not used in choice , it is difficult to argue that accuracy dominates rule selection . A cost - benefit model implies a compensatory tradeoff between accuracy and effort that should be related to the importance of the decision . With sufficient incentive , decisions may involve the use of expected value maximization . However , the use of heuristic strategies seems to persist , even in situations involving substantial incentives ( Grether and Plott 1979 , Lichtenstein and Slovic 1973 ) . An alternate viewpoint is that effort and information processing limitations repre - sent constraints which limit the strategies that can be adopted . Simon ( 1981 ) , for example , views a decision maker as using heuristics and satisficing " not because he prefers less to more , but because he has no choice ( p . 36 ) . " It is important to note , EFFORT AND ACCURACY IN CHOICE 411 however , that the concepts underlying a process of expected utility maximization , while quite demanding of the information processor , are not inconsistent with our current understanding of human cognition . Such processes , however , could well require inordinate amounts of time , and , in practice , be impossible for the unaided decision maker . Processing constraints , therefore , may impose severe limitations upon the strategies and thereby provide a boundary for the feasible region in which accuracy - effort tradeoffs could be made . The ultimate status of the cost - benefit perspective awaits further research , but it may be necessary to modify the notion to include an upward bound upon processing capacity . One difficulty with the idea that people deliberately decide how to choose is a potential infinite regress : One has to decide how to choose to decide how to choose . . . . A more reasonable perspective is that such decisions are not made often but that the relationship between task and context effects and the efficiency of a decision strategy is learned over time . For example , a decision maker may learn over time that the screening phase will substantially reduce effort in large choice sets . This knowledge can exist as part of the conditions which must be met for a production to fire . More generally , a decision maker may develop over time a task specific strategy that is highly accurate while requiring substantially less information processing than a normative rule . Klein ( 1983 ) also suggests that a decision maker ' s use of heuristics may be related to learning about the nature of task environments . The potential importance of learning in understanding contingent decision behavior makes a production system representation especially useful . As Simon ( 1981 ) notes : " what makes production systems especially attractive for modeling is that it is relatively easy to endow them with learning capabilities - to build so called adaptive production systems " ( p . 121 ) . Such an approach to strategy selection must come to grips with the nature of outcome feedback in risky choice . Seldom is such feedback immediately available , and in a risky choice , there is no deterministic link between the outcome obtained and the alternative selected . Even if outcome feedback is available , learning may be hampered because the feedback is related to the alternative selected ( Einhorn and Hogarth 1978 ) . In the extreme , it has been argued that learning seldom occurs even under optimal presentation of outcome feedback ( Brehmer 1980 ) . If outcome feedback is such a problematic mechanism for learning , how else might decision makers change strategies ? In addition to outcome feedback , the decision maker has access to a fairly rich data base about the course of their own decision processes . This process feedback could provide information necessary for strategy change . By noticing possible shortcuts in past and current decisions , the decision maker could induce less effortful choice procedures . For example , a decision maker might induce the Most Likely heuristic by noticing that certain outcomes seem much more probable than others . To evaluate the impact of this change the decision maker might check that the output of the new heuristic is consistent with several general principles of choice . For example , the decision maker might check that the new procedure does not select dominated alternatives , and that it selects alternatives that have satisfactory levels of the other outcomes . Like a problem solver that has induced a new strategy or mental addition , the decision maker evaluates the strategy change by examining the answer for consistency with previous procedures . The notion that learning occurs on the basis of trace information has been discussed in other cognitive tasks by Anzai and Simon ( 1979 ) . Summary This paper uses production system models and computer simulation to explore the accuracy and effort of various decision strategies in different choice environments . The results show that heuristic strategies can be highly accurate while substantially reduc - 412 ERIC J . JOHNSON AND JOHN W . PAYNE ing effort relative to normative procedures . The accuracy and effort of strategies , however , is highly contingent on characteristics of the choice task . This result provides a partial explanation for the finding of contingent decision behavior ( Payne 1982 ) . However , the extent to which decision makers actually tradeoff effort and accuracy , and do so optimally , are open empirical questions . Much more research is required to understand more completely the selection among decision strategies and how one may learn the relationships between task demands and the accuracy / effort properties of choice strategies . 3 Appendix : Description of Context Manipulations The context effects manipulated in the simulation study can be viewed as changes in the distribution of two random variates : p , the probabilities and X the payoffs . This Appendix describes the two versions of each variate which yield the 2 x 2 factorial utilized in the simulation . Each gamble consists of M events , and since the probabilities sum to 1 , the mean of any distribution of probability will be / M . Subsequently , the average correlation between all pairs of probabilities pi , pi , i , j9 will be - I / ( M - 1 ) , and the variance of the distribution can range from a minimum of 0 ( allpi = 1 / M ) to a maximum of l / M - I / M2 ( for example one pi = 1 , the rest 0 ) . Although no closed form exists for the probability generation method used by Thorngate ( 1980 ) , an expansion of the Taylor series results in the approximation 1 / 3M2 . The alternative method used here possesses a variance of ( M - I ) / M3 . Subse - quently , the two methods yield radically different distributions , and these differences increase with increases in the number of outcomes . For example , the variance in probabilities for the levels used in the current simulation would be : Maximum Possible Low Variance High Variance Variance M 2 0 . 083 0 . 125 0 . 250 4 0 . 021 0 . 046 0 . 187 8 0 . 005 0 . 014 0 . 109 Thus , Thorngate ' s results , equivalent to our low variance environment , may be of limited generality . His method of generalizing probabilities resulted in distributions of low variance , and the range of probabilities incorporated in the resultant gamble become quite small as M increased . All payoffs in the current simulation are drawn from a uniform distribution , range 0 to 1000 . To remove stochastically dominated alternatives we used a rejection method . However , dominance is frequent with increases in N , the number of gambles in a choice set . Consequently , to improve the efficiency of generating gambles , we first ensured that the payoffs of all alternatives avoided simple dominance : i . e . for all pairs of gambles , a and b , a had a higher payoff than b on at least one outcome , while b had a higher payoff than a on another outcome . While this maintains the same mean and variance of the distribution of probabilities , it does introduce a correlation between the Xi of the alternatives . For all pairs of alternatives the correlation between payoffs will be - I / ( M - 1 ) . Probabilities are then assigned to the gambles and the choice sets were then examined to ensure that no gamble was first - order stochastic dominant over another . If such a pair existed , the choice set was rejected and a new one created . Since payoffs are independent of probabilities , the average expected value of all gambles generated ( and the expected value of a random choice ) is ( 1 / M ) L 1pix ; or $ 500 . The average maximum will vary , however , as a function of the variance of p and x . References ANZAI , Y . AND H . A . SIMON , " The Theory of Learning by Doing , " Psychological Rev . , 86 ( 1979 ) , 441 - 451 . BEACH , L . R . , " Muddling Through : A Response to Yates and Goldstein , " Organizational Behavior and Human Performance , 31 ( 1983 ) , 47 - 53 . AND T . R . MITCHELL , " A Contingency Model for the Selection of Decision Strategies , " Acad . Management Rev . , 3 ( 1978 ) , 439 - 449 . 3We would like to thank Jim Bettman , Hillel Einhorn , Josh Klayman , Howard Kunreuther , and J . Edward Russo for their comments on an earlier draft , Ethan Bradford for programming assistance , and Maureen Lahiff and Larry Maloney for helpful discussion . This research was supported by a contract from the Engineering Psychology Program of the Office of Naval Research . EFFORT AND ACCURACY IN CHOICE 413 BETTMAN , J . R . , An Information Processing Theory of Consumer Choice , Addison - Wesley , Reading , Mass . , 1979 . AND P . KAKKAR , " Effects of Information Presentation Format on Consumer Information Acquisi - tion Strategies , " J . of Consumer Res . , 3 ( 1977 ) , 233 - 240 . BREHMER , B . , " In One Word : Not from Experience , " Acta Psychologica , 45 ( 1980 ) , 223 - 241 . CARD , S . K . , T . P . MORAN AND A . NEWELL , " Computer Text Editing : An Information Processing Analysis of a Routine Cognitive Skill , " Cognitive Psychol . , 12 ( 1980 ) , 32 - 74 . CARPENTER , P . A . AND M . A . JUST , " Sentence Comprehension : A Psycholinguistic Processing Model of Verification , " Psychological Rev . , 82 ( 1975 ) , 45 - 73 . CHASE , W . , " Elementary Information Processes , " In W . K . Estes ( Ed . ) , Handbook of Learning and Cognitive Processes , Vol . 5 , Erlbaum , Hillsdale , N . J . , 1978 . DANSEREAU , D . F . , " An Information Processing Model of Mental Multiplication , " unpublished Ph . D . dissertation , Carnegie - Mellon University , 1969 . DUDA , R . 0 . AND E . H . SORTLIFFE , " Expert Systems Research , " Science , 220 , ( 1983 ) , 261 - 268 . EINHORN , H . J . AND R . M . HOGARTH , " Behavioral Decision Theory : Processes of Judgment and Choice , " Annual Review Psychology , 32 ( 1981 ) , 52 - 88 . AND , " Confidence in Judgment : Persistence of the Illusion of Validity , " Psychological Rev . , 85 ( 1978 ) , 395 - 416 . GRETHER , D . M . AND C . R . PLOTT , " Economic Theory of Choice and the Preference Reversal Phenome - non , " Amer . Econom . Rev . , 69 ( 1979 ) , 623 - 638 . AND L . L . WILDE , " The Information Overload Hypothesis , " California Institute of Technology , 1982 . HERSHEY , J . C . , H . C . KUNREUTHER AND P . J . H . SCHOEMAKER , " Bias in Assessment Procedures for Utility Functions , " Management Sci . , 28 ( 1982 ) , 936 - 54 . HUBER , J . , J . W . PAYNE AND C . PUTO , " Adding Asymmetrically Dominated Alternatives : Violations of Regularity and the Similarity Hypothesis , " J . Consumer Res . , 9 ( 1982 ) , 90 - 98 . HUBER , O . , " The Influence of Some Task Variables on Cognitive Operations in an Information - Processing Decision Model , " Acta Psychologica , 45 ( 1980 ) , 187 - 196 . JOHNSON , E . , " Deciding How to Decide : The Effort of Making a Decision , " Unpublished manuscript , University of Chicago , 1979 . KAHNEMAN , D . , Attention and Effort , Prentice - Hall , Englewood Cliffs , N . J . , 1973 . AND A . TVERSKY , " The Psychology of Preferences , " Scientific Amer . , ( 1982 ) , 160 - 170 . KEEN , P . G . W . AND M . S . SCOTr - MORTON , Decision Support Systems : An Organizational Perspective , Addison - Wesley , Reading , Mass . , 1978 . KEENEY , R . L . AND H . RAIFFA , Decisions with Multiple Objectives : Preferences and Value Tradeoffs , John Wiley , New York , 1976 . KLAYMAN , J . , " Simulation of Six Decision Strategies : Comparisons of Search Patterns , Processing Character - istics , and Response to Task Complexity , " Unpublished manuscript , University of Chicago , 1983 . KLEIN , N . M . , " Utility and Decision Strategies : A Second Look at the Rational Decision Maker , " Organizational Behavior and Human Performance , 31 ( 1983 ) , 1 - 25 . LICHTENSTEIN , S . AND P . SLOVIC , " Response - Induced Reversals of Preference in Gambling : An Extended Replication in Las Vegas , " J . Experimental Psychol . , 101 ( 1973 ) , 16 - 20 . LOPES , L . L . , " Toward a Procedural Theory of Judgment , " Unpublished manuscript , University of Wisconsin , 1982 . MARCH , J . G . , " Bounded Rationality , Ambiguity , and the Engineering of Choice , " Bell J . Econom . , 9 ( 1978 ) , 587 - 608 . MCCLEELAND , G . H . , Equal versus Differential Weighting for Multiattribute Decisions : There Are No Free Lunches , Institute of Behavioral Science , University of Colorado , Boulder , 1978 . MONTGOMERY , H . AND 0 . SVENSON , " On Decision Rules and Information Processing Strategies for Choices among Multiattribute Alternatives , " Scandinavian J . Psychol . , 17 ( 1976 ) , 283 - 291 . NAVON , D . AND D . GOPHER , " On the Economy of the Human - Processing System , " Psychological Rev . , 86 ( 1979 ) , 214 - 255 . NEWELL , A . , " Harpy , Production Systems and Human Cognition , " in R . Cole ( Ed . ) , Perception and Production of Fluent Speech , Erlbaum , Hillsdale , N . J . , 1980 . AND H . A . SIMON , Human Problem Solving , Prentice - Hall , Englewood Cliffs , N . J . , 1972 . OLSHAVSKY , R . W . , " Task Complexity and Contingent Processing in Decision Making : A Replication and Extension , " Organizational Behavior and Human Performance , 24 ( 1979 ) , 300 - 316 . PAYNE , J . W . , " Task Complexity and Contingent Processing in Decision Making : An Information Search and Protocol Analysis , " Organizational Behavior and Human Performance , 16 ( 1976 ) , 366 - 387 . " Contingent Decision Behavior , " Psychological Bull . , 92 ( 1982 ) , 382 - 402 . AND M . L . BRAUNSTEIN , " Risky Choice : An Examination of Information Acquisition Behavior , " Memory & Cognition , 22 ( 1978 ) , 17 - 44 . Russo , J . E . , " The Value of Unit Price Information , " J . Marketing Res . , 14 ( 1977 ) , 193 - 201 . 414 ERIC J . JOHNSON AND JOHN W . PAYNE , " Adaption of Cognitive Processes to the Eye Movement System , " in J . Senders , D . Fisher , & R . Monty ( Eds . ) , Eye Movement and the Higher Psychological Functions , Erlbaum , Hillsdale , N . J . , 1978 . AND B . A . DOSHER , " Strategies for Multiattribute Binary Choice , " J . Experimental Psychol . : Learning , Memory , and Cognition , 9 ( 1983 ) , 676 - 696 . SHUGAN , S . M . , " The Cost of Thinking , " J . Consumer Res . , 7 ( 1980 ) , 99 - 111 . SIMON , H . A . , The Sciences of the Artificial , ( 2nd Ed . ) , MIT , 1981 . SLOVIC , P . , B . FISCHHOFF AND S . LICHTENSTEIN , " Informing the Public about the Risks from Ionizing Radiation , " Health Physics , 41 ( 1981 ) , 589 - 598 . - , AND , " Response Mode , Framing , and Information Processing Effects in Risk Assessment , " in R . Hogarth ( Ed . ) , New Directions for Methodology of Social and Behavioral Science : The Framing of Questions and Consistency of Response , Jossey - Bass , San Francisco , Cal . , 1982 . SVENSON , O . , " Process Descriptions of Decision Making , " Organizational Behavior and Human Performance , 23 ( 1979 ) , 86 - 112 . THOMAS , E . A . C . , " Notes on Effort and Achievement - Oriented Behavior , " Psychological Rev . , 90 ( 1983 ) , 1 - 20 . THORNGATE , W . , " Efficient Decision Heuristics , " Behavioral Sci . , 25 ( 1980 ) , 219 - 225 . TVERSKCY , A . , " Intransitivity of Preferences , " Psychological Rev . , 76 ( 1969 ) , 31 - 48 . " Elimination by Aspects : A Theory of Choice , " Psychological Rev . , 79 ( 1972 ) , 281 - 299 . WRIGHT , P . , " Decision Times and Processes on Complex Problems , " unpublished manuscript , Stanford University , 1977 . AND F . BARBOUR , " Phased Decision Strategies : Sequels to an Initial Screening , " in Martin K . Starr and Milan Zeleny ( Eds . ) , Multiple Criteria Decision Making , North Holland , Amsterdam , 1977 . YATES , J . F . , C . M . JAGACINSKI AND M . D . FABER , " Evaluation of Partially Described Multiattribute Options , " Organizational Behavior and Human Performance , 21 ( 1978 ) , 240 - 251 .