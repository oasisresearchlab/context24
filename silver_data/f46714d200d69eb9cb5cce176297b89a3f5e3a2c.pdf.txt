An Introduction to Convolutional Neural Networks Keiron O’Shea 1 and Ryan Nash 2 1 Department of Computer Science , Aberystwyth University , Ceredigion , SY23 3DB keo7 @ aber . ac . uk 2 School of Computing and Communications , Lancaster University , Lancashire , LA1 4YW nashrd @ live . lancs . ac . uk Abstract . This document provides a brief introduction to Convolutional Neural Networks ( CNNs ) , discussing recently published papers and newly form tech - niques in developing these brilliantly fantastic image recognition models . This introduction assumes you are familiar with the workings of neural networks and have some background in Artiﬁcial Intelligence . 1 Introduction Convolutional Neural Networks ( CNNs ) are analogous to traditional Artiﬁcial Neural Networks ( ANNs ) such as Feedforward Neural Networks ( FNN ) , Restricted Boltzmann Machines ( RBMs ) and Recurrent Neural Networks ( RNN ) in that they are comprised of neurons ( or units ) that self - optimise their weights and biases through learning . Each neuron will receive an input , perform a scalar product and will most likely follow it with a non - linear function the basis of countless Neural Networks . From the input raw image vectors to the ﬁnal output of the class score , the entire of the network will still express a single perceptive score function . The last fully - connected layer will contain a loss function , and all of the regular tips and tricks developed for traditional Artiﬁcial Neural Networks still apply . The only difference between CNNs and other ANNs is that CNNs are mostly used in the ﬁeld of pattern recognition within images . This then allows us to encode image - speciﬁc features into the architecture , as to make the forward function a lot more adept whilst furthering reducing the parameters required to implement the network . 2 CNN architecture To understand the basis of CNNs , its important to understand the basics of traditional forms of ANN . ANNs are comprised of at least three layers . Firstly the network will receive an input of single vector form to the input layer , and reconstruct it through a series of hidden layers . Hidden layers contain a set of fully - connected neurons , which simply means that all neurons within that layer are connected to the previous layer and not to any other neurons within the same layer . The last fully - connected layer is the output layer , whose goal is to ( usually ) classify through calculation of class scores . a r X i v : 1511 . 08458v1 [ c s . N E ] 26 N ov 2015 2 . CNN ARCHITECTURE One of the largest limitations of traditional forms of ANN is that they tend to strug - gle with full images . Common machine learning benchmarking datasets such as the MNIST database of handwritten digits are suitable for most forms of ANN , with an image dimensionality of just 28x28 . With this dataset a single fully - connected neuron in the initial hidden layer will contain 3 , 072 weights ( 28 × 28 × 3 ) , which is fairly work - able but when you consider an input of a more considerate size such as a 1280 × 720 full - coloured image , this would calculate to over 2 . 7 million weights on each neuron , or in other words , a computational nightmare ! So to mitigate against this computational problem CNNs base their architecture on the basis that the input is comprised of vectorised images , and this then focuses the prob - lem domain to a simplify the architecture and in turn reduce computational complexity . Neurons of a CNN differ completely to those found in the standard ANNs in that they are arranged in three dimensions , width , height and depth . Using our previous MNIST example , the input images consist of an input vector of activations , with a dimensional - ity of 28 × 28 × 3 , a CNN architecture will only connect to a small region of the layer before it instead of every single one in a fully - connected manner . The output layer will only have a dimensionality of 1 × 1 × 10 as we just need to reduce the full image into a single vector of class scores , situated along the depth dimension . 2 . 1 CNN Layers Every single layer within a CNN transforms a vector of activations through a differen - tiable function . To do this we will utilise three main types of layers , found speciﬁcally in CNNs . These are convolutional layers , pooling layers and fully - connected layers . When these layers are stacked , we have formed a full CNN architecture . So , to take the MNIST example deﬁned previously we will conceptualise a simplistic CNN for handwritten digit classiﬁcation . Our input layer is comprised of the raw pixel values of the image , which is an image of 28x28 dimensionality and each pixel’s RGB channel . The input will then go through a convolutional layer which will then calculate the output of neurons that are connected to local regions in the input as to compute a scalar product between their associated weights and regions , resulting in a decreased vector . The rectiﬁed linear unit ( ReLU ) layer will continue to apply an elementwise ac - tivation function such as sigmoid to the vector , before continuing onward to the pooling layer . The pooling layer simply performs downsampling along the width and height of the input again reducing the size of the vector . Finally , the vector will be fed into the fully - connected layers resulting in a vector of size 1x1x10 , where each of the 10 classes correspond to a class score for classiﬁcation . Through the use of the stochastic gradient descent algorithm , we are able to ensure that the class scores are consistent with the labels used whilst training . Through this simple method of transformation , CNNs are able to transform the original input layer by layer from the input raw image vector to their ﬁnal corresponding class scores . Both the ReLU and pooling layers dont require any further parameter optimisa - tion , whereas the remaining convolutional and fully - connected layers do . 2 2 . CNN ARCHITECTURE Fig . 1 . Activations of the ﬁnal convolutional layer of a simplistic deep CNN , after training on the MNIST database of handwritten digits . If you look carefully , you can see how the network has successfully picked up on characteristics unique to speciﬁc numeric characters . However , knowing the overview of how CNNs operate isnt going to be sufﬁcient to implement a CNN with real world data . Its imperative to not only understand the in - dividual layers , but the ﬁne points of the parameters and how they communicate with other layers too . 2 . 2 Convolutional layer As the name implies , the convolutional layer plays a vital role in how CNNs operate . Its output can be described as neurons arranged in a three - dimensional vector . The con - volutional layers parameters focus around a set of small spatial learnable ﬁlters which extends through the full depth of the input vector . As the vector passes through this layer , we convolve each ﬁlter through the width and height of the input thus producing a two dimensional activation map of the ﬁlter . During this ﬁltering stage , we are con - stantly computing the scalar product between the new input to the ﬁlter and the initial input . The network will learn ﬁlters that activate when they match a speciﬁc feature at whatever position being ﬁltered . The activation functions are then stacked along the depth dimension to form the full output vector . This full output vector may be consid - ered as the output of a neuron of which focuses on a section of the input , and shares parameters with the neurons in the same activation map . As noted earlier , images arent ideal input data for traditional forms of ANN . To mitigate against this , we connect each neuron to a local region of the prior vector effectively splitting the input up . The extent of this connectivity is known as the receptive ﬁeld of the neuron , and is set through hyperparameters . Regardless of the size of the input , the extent of the connectivity along the depth is always directly equal to the depth of the input vector ; as its important to ensure that the connections are always full along the entire depth of the corresponding vector . 3 2 . CNN ARCHITECTURE So , with our MNIST database of handwritten digits our input vector has a size of 28 × 28 × 3 ( height x width x RGB channels ) . Provided the receptive ﬁeld is of size 3 × 3 , every neuron in the convolutional layer would have 27 ( 3 × 3 × 3 ) direct connections to the input layer . Now that we understand the input of the convolutional layer , we move onto the output of the layer and how they are calculated . The output of the convolutional layer is comprised of a vector featuring depth , stride and zero - padding . The depth of the output vector controls the number of neurons in the convolutional layer that directly connects to the same region of the input vector . This isnt too dissimilar to traditional ANNs , which feature multiple neurons in a hidden layer that all focus at the same input . All of these neurons will then learn to activate for different features in the input . In CNNs , the ﬁrst convolutional layer will take the input as the raw image , and then different neurons found across the depth set may ﬁre in the presence of a previously located feature . 0 0 0 0 0 0 0 0 0 1 1 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 - 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 - 4 Input Vector Kernel Destination Pixel Fig . 2 . A visual representation of a convolutional layer . The centre element of the kernel is placed over the input vector , of which is then calculated and replaced with a weighted sum of itself and any nearby pixels . The stride assigns depth columns around the height and width dimensions . If the stride is set to 1 , then we will earmark a new depth column of neurons to a position only 1 unit apart . This may lead to overlapping between the columns , resulting in large output vectors . Vice versa , by increasing the stride receptive ﬁelds are less likely to overlap also decreasing the size of the output vectors and reducing complexity . 4 2 . CNN ARCHITECTURE Although not always required , zero - padding is the method of padding the inputs dimen - sionality on the border of the input vector with zeros . This allows us to control the size of the output values , and more importantly , maintain the size of the input vector . To calculate the spatial size of the output vector we can use the following formula : ( V − R ) + 2 Z S + 1 ( 1 ) Where V is the input vector size , R represents the receptive ﬁeld size of the convolu - tional layers neurons , S being the stride , and Z being the amount of zero padding being used on the border . If the result of this function is not equal to an integer , then the strides are incorrectly set stopping the neurons from ﬁtting across the input vector neatly . In 2012 , Krizhevsky et all won the ImageNet challenge . The challenge involved clas - sifying 1 . 3 million high resolution images into 1 , 000 different classes . These images were scaled down to resolutions of 227 × 227 and fed into a deep CNN . It used neu - rons with a receptive ﬁeld size of 11 , stride of 4 and no zero padding . By using the formula above , we are able to calculate the output as 55 ( 227 − 11 + 0 ÷ 4 + 1 ) , and since the convolutional layer had a depth of 96 - totaling to 290 , 400 neurons in the ﬁrst convolutional layer ( 55 × 55 × 96 ) . Having over 290 thousand neurons over a single layer isnt ideal , each neuron has 363 weights ( 11 × 11 × 3 ) and a single bias . This calculates to over 105 million parameters on the ﬁrst convolutional layer alone . Parameter sharing is a method which allows us to control the number of parameters a layer can contain and is a heavily used technique in Convolutional Neural Networks . Parameter sharing is based upon the inference that if a patch feature is useful to compute at another patch , then it can also be used to calculate at a different position . For example , if we take a two - dimensional slice of the depth of the vector , we will constrain the neurons of each depth to use the same weight and bias - massively reducing the number of unique weights . All neurons will now be using the same shared parameters when training . During backpropagation each neuron in the volume will calculate the gradient for its unique weight , but all gradients will be added up across each depth set and update just a single set of weights per set of depths . Provided that the neurons in a set of depths are using the same weights , then the for - ward pass of the convolutional layer through each set of depths can be calculates an an convolution of the neurons weights with the input vector . The set of weights to each depth is often referred to as a ﬁlter , which is convolved with the input . This results in an activation map , of which are stacked together along the depth set to produce the output of the convolutional layer . 5 3 . RECIPE FOR CREATING CNNS 2 . 3 Pooling layer Pooling layers aim to reduce the spatial size of the convolutional layers output , in order to mitigate against overﬁtting through signiﬁcantly reducing the amount of parameters and computation complexity in the network . Pooling layers operate separately on each depth set of the convolutional layers output and resizes it in accordance its height and width through the use of the max function . This is referred to max - pooling . Standard max - pooling layers contain ﬁlters of size 2 × 2 applied with a stride of 2 for every depth set of the input . This results in a 75 % reduction of activation functions , whilst maintaining the total depth dimensionality of output from the convolutional layer . It is commonplace to place pooling layers between successive convolutional layers . There isnt any set way as how to set the hyperparameters , but having pooling sizes with larger than the recommended receptive ﬁelds could severely impede the activation functions . An alternative to max - pooling is what’s known as general - pooling . General - pooling is where the pooling units also perform functions beyond what is expected of max - pooling , functions such as L2 - normalisation pooling and the more antiquated average pooling . 2 . 4 Fully - connected layer A fully - connected layer contains neurons of which are fully - connected to the activa - tions of the previous layer , a feature seen in traditional ANNs . The activations are then calculated with a matrix multiplication followed by an offset set by the bias . As both convolutional and fully - connected layers still calculate scalar products , it is possible to convert between them . 3 Recipe for creating CNNs Despite the relatively small number of layers required to form a CNN , there is no set way of formulating a CNN architecture . That being said , it would be idiotic to simply throw together a few of these layers together and hope they work and expect it to work . CNNs usually follow a common architecture that stacks a few convolutional layers , followed by pooling layers . This pattern is then repeated until the input image has been fully converged to a small size . Another common CNN architecture is to stack two convolutional layers before each pooling layer . This is a good idea if you are working with extensively deep neural networks , as stacking multiple convolutional layers allows for more complex features of the input vector to arise . 6 3 . RECIPE FOR CREATING CNNS Fig . 3 . A common form of CNN architecture in which convolutional layers are stacked between ReLus continuously before being passed through the pooling layer , before going between one or many fully connected ReLus . Another common practice is to stack up small convolutional layers , as opposed to hav - ing a single large convolutional layer . For example , if you were to stack three convo - lutional layers on top of each other with a receptive ﬁeld of 3 × 3 . Each neuron of the ﬁrst convolutional layer will have a 3 × 3 view of the input vector . A neuron on the second convolutional layer will then have a 5 × 5 view of the input vector . A neuron on the third convolutional layer will then have a 7 × 7 view of the input vector . As these stacks feature non - linearities which in turn allows us to express stronger features of the input with fewer parameters . However , it is important to understand that this does come with a distinct memory allocation problem - especially when making use of the backpropagation algorithm . There are however common guidelines of how to size our architectures . . . – The input layer should be recursively divisible by two . Common numbers include 32 × 32 , 64 × 64 , 96 × 96 , 128 × 128 and 224 × 224 . – Opposed to a singular convolutional layer with large ﬁlters ( a large ﬁlter could be considered as anything equal or over 5 × 5 ) , it is best to make use of many convolutional layers with smaller ﬁlter sizes . – Whilst using small ﬁlters , set stride to one and make use of zero - padding as to ensure that the convolutional layers do not reconﬁgure any of the dimensionality of the input . The amount of zero - padding to be used should be calculated by taking one away from the receptive ﬁeld size and dividing by two . – CNNs are extremely powerful machine learning algorithms , however they can be horrendously resource - heavy . An example of this problem could be in ﬁltering a large image ( anything over 128 × 128 could be considered large ) , so if the input is 227 × 227 ( as seen with ImageNet ) and we’re ﬁltering with 64 kernels each with a zero padding of then we’ll end up with three activation vectors of size 227 × 227 × 64 - which calculates to roughly 10 million activations - or 70 megabytes of memory per image . In this case you have two options . Firstly , you can reduce the spatial dimensionality of the input images by resizing the raw images to something a little 7 3 . RECIPE FOR CREATING CNNS less heavy . Alternatively , you can go against everything we stated earlier in this document and opt for larger ﬁlter sizes with a larger stride ( 2 , as opposed to 1 ) . In addition to the few rules - of - thumb outlined above , it is also important to acknowledge a few ’tricks’ about generalised ANN training techniques . The authors suggest a read of Geoffrey Hinton’s Practical Guide to Training Restricted Boltzmann Machines . References 1 . Ciresan , D . , Meier , U . , Schmidhuber , J . : Multi - column deep neural networks for image clas - siﬁcation . In : Computer Vision and Pattern Recognition ( CVPR ) , 2012 IEEE Conference on . pp . 3642 – 3649 . IEEE ( 2012 ) 2 . Ciresan , D . C . , Meier , U . , Masci , J . , Maria Gambardella , L . , Schmidhuber , J . : Flexible , high performance convolutional neural networks for image classiﬁcation . In : IJCAI Proceedings - International Joint Conference on Artiﬁcial Intelligence . vol . 22 , p . 1237 ( 2011 ) 3 . Cires¸an , D . C . , Meier , U . , Gambardella , L . M . , Schmidhuber , J . : Convolutional neural network committees for handwritten character classiﬁcation . In : Document Analysis and Recognition ( ICDAR ) , 2011 International Conference on . pp . 1135 – 1139 . IEEE ( 2011 ) 4 . Hinton , G . : A practical guide to training restricted boltzmann machines . Momentum 9 ( 1 ) , 926 ( 2010 ) 5 . Hinton , G . E . , Srivastava , N . , Krizhevsky , A . , Sutskever , I . , Salakhutdinov , R . R . : Im - proving neural networks by preventing co - adaptation of feature detectors . arXiv preprint arXiv : 1207 . 0580 ( 2012 ) 6 . Karpathy , A . , Toderici , G . , Shetty , S . , Leung , T . , Sukthankar , R . , Fei - Fei , L . : Large - scale video classiﬁcation with convolutional neural networks . In : Computer Vision and Pattern Recognition ( CVPR ) , 2014 IEEE Conference on . pp . 1725 – 1732 . IEEE ( 2014 ) 7 . Krizhevsky , A . , Sutskever , I . , Hinton , G . E . : Imagenet classiﬁcation with deep convolutional neural networks . In : Advances in neural information processing systems . pp . 1097 – 1105 ( 2012 ) 8 . LeCun , Y . , Bottou , L . , Bengio , Y . , Haffner , P . : Gradient - based learning applied to document recognition . Proceedings of the IEEE 86 ( 11 ) , 2278 – 2324 ( 1998 ) 9 . Nebauer , C . : Evaluation of convolutional neural networks for visual recognition . Neural Net - works , IEEE Transactions on 9 ( 4 ) , 685 – 696 ( 1998 ) 10 . Simard , P . Y . , Steinkraus , D . , Platt , J . C . : Best practices for convolutional neural networks applied to visual document analysis . In : null . p . 958 . IEEE ( 2003 ) 11 . Zeiler , M . D . , Fergus , R . : Stochastic pooling for regularization of deep convolutional neural networks . arXiv preprint arXiv : 1301 . 3557 ( 2013 ) 12 . Zeiler , M . D . , Fergus , R . : Visualizing and understanding convolutional networks . In : Com - puter Vision – ECCV 2014 , pp . 818 – 833 . Springer ( 2014 ) 8