Heuristic and Special Case Algorithms for Dispersion Problems Author ( s ) : S . S . Ravi , D . J . Rosenkrantz and G . K . Tayi Reviewed work ( s ) : Source : Operations Research , Vol . 42 , No . 2 ( Mar . - Apr . , 1994 ) , pp . 299 - 310 Published by : INFORMS Stable URL : http : / / www . jstor . org / stable / 171673 . Accessed : 08 / 08 / 2012 18 : 05 Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use , available at . http : / / www . jstor . org / page / info / about / policies / terms . jsp . JSTOR is a not - for - profit service that helps scholars , researchers , and students discover , use , and build upon a wide range of content in a trusted digital archive . We use information technology and tools to increase productivity and facilitate new forms of scholarship . For more information about JSTOR , please contact support @ jstor . org . . INFORMS is collaborating with JSTOR to digitize , preserve and extend access to Operations Research . http : / / www . jstor . org HEURISTIC AND SPECIAL CASE ALGORITHMS FOR DISPERSION PROBLEMS S . S . RAVI , D . J . ROSENKRANTZ and G . K . TAYI University at Albany - SUNY , Albany , New York ( Received August 1991 ; revision received June 1992 ; accepted June 1992 ) The dispersion problem arises in selecting facilities to maximize some function of the distances between the facilities . The problem also arises in selecting nondominated solutions for multiobjective decision making . It is known to be NP - hard under two objectives : maximizing the minimum distance ( MAX - MIN ) between any pair of facilities and maximizing the average distance ( MAX - AVG ) . We consider the question of obtaining near - optimal solutions . For MAX - MIN , we show that if the distances do not satisfy the triangle inequality , there is no polynomial - time relative approximation algorithm unless P = NP . When the distances satisfy the triangle inequality , we analyze an efficient heuristic and show that it provides a performance guarantee of two . We also prove that obtaining a performance guarantee of less than two is NP - hard . For MAX - AVG , we analyze an efficient heuristic and show that it provides a performance guarantee of four when the distances satisfy the triangle inequality . We also present a polynomial - time algorithm for the 1 - dimensional MAX - AVG dispersion problem . Using that algorithm , we obtain a heuristic which provides an asymptotic performance guarantee of ir / 2 for the 2 - dimensional MAX - AVG dispersion problem . M any problems in location theory deal with the placement of facilities on a network to mini - mize some function of the distances between facilities or between facilities and the nodes of the network ( Handler and Mirchandani 1979 ) . Such problems model the placement of " desirable " facilities such as warehouses , hospitals , and fire stations . However , there are situations in which facilities are to be located to maximize some function of the distances between pairs of nodes . Such location problems are referred to as dispersion problems ( Chandrasekharan and Daughety 1981 , Kuby 1987 , Erkut and Neuman 1989 , 1990 , and Erkut 1990 ) because they model situations in which proximity of facilities is undesirable . One example of such a situation is the distribution of business franchises in a city ( Erkut ) . Other examples of dispersion problems arise in the context of placing " undesirable " ( also called obnoxious ) facilities , such as nuclear power plants , oil storage tanks , and ammu - nition dumps ( Kuby 1987 , Erkut and Neuman 1989 , 1990 , and Erkut 1990 ) . Such facilities need to be spread out to the greatest possible extent so that an accident at one of the facilities will not damage any of the others . The concept of dispersion is also useful in the context of multiobjective decision making ( Steuer 1986 ) . When the number of nondominated solutions is large , a decision maker may be interested in selecting a manageable collection of solutions which are dispersed as far as possible with respect to the objective function values . Other applications of facil - ity dispersion are discussed in Erkut ( 1990 ) and Erkut and Neuman ( 1989 , 1990 ) . Analytical models for the dispersion problem assume that the given network is represented by a set V = { vI , v2 , . . . , Vn } of n nodes with nonnegative distance ( also called edge weight ) between every pair of nodes . The distances are assumed to be symmetric and so the network can be thought of as an undirected complete graph on n nodes with a nonnegative weight on each edge . The weight of the edge { vi , vjI ( i $ j ) is denoted by w ( vi , vj ) . We assume that w ( vi , vi ) = 0 for 1 s i s n . The objective of the dispersion problem is to locate p facilities ( p s n ) among the n nodes of the network , with at most one facility per node , such that some function of the distances between facilities is maximized . Two of the optimality criteria considered in the literature ( Kuby 1987 , Erkut 1990 , and Erkut and Neuman 1989 ) are MAX - MIN ( i . e . , maximize the minimum distance between a pair of facilities ) and MAX - AVG ( i . e . , maximize the average distance between a pair of facilities ) . Under either criterion , the problem is known to be NP - hard , even when the distances satisfy the triangle inequality ( Wang and Kuo 1988 , Hansen and Moon 1988 , and Erkut 1990 ) . Subject classifications : Analysis of algorithms : computational complexity . Facilities / equipment planning : discrete location . Programming : heuristic . Area of review : OPTIMIZATION . Operations Research 0030 - 364X / 94 / 4202 - 0299 $ 01 . 25 Vol . 42 , No . 2 , March - April 1994 299 ? 1994 Operations Research Society of America 300 / RAVI , ROSENKRANTZ AND TAYI Although many researchers have studied the disper - sion problem ( see Erkut and Neuman 1989 for a survey and an extensive bibliography ) , except for White ( 1991 ) , the question of whether there are effi - cient heuristics with provably good performance has not been addressed . This question forms the main focus of this paper . We show that if the distances do not satisfy the triangle inequality , then for any con - stant K 3 1 , no polynomial time algorithm can pro - vide a performance guarantee of K for the MAX - MIN dispersion problem unless P = NP . When the dis - tances satisfy the triangle inequality , we analyze a known heuristic and prove that it provides a perfor - mance guarantee of 2 for the MAX - MIN dispersion problem . This is an improvement over the perfor - mance guarantee of 3 proven in White ( 1991 ) using a different heuristic . ( This improvement was obtained independently by White 1992 . ) We also show that no polynomial - time algorithm can provide a perfor - mance guarantee of less than 2 unless P = NP . We also analyze an efficient heuristic for the MAX - AVG dis - persion problem with triangle inequality , and prove that it provides a performance guarantee of 4 . An efficient algorithm for the 1 - dimensional MAX - MIN dispersion problem is presented in Wang and Kuo . We provide an efficient algorithm for the 1 - dimensional MAX - AVG dispersion problem . We also show how this algorithm can be used to obtain a heuristic with an asymptotic performance guarantee of 1 . 571 for the 2 - dimensional MAX - AVG dispersion problem . The remainder of this paper is organized as follows . Section 1 contains the formal definitions and a dis - cussion of the previous work on the dispersion prob - lem . Sections 2 and 3 address the dispersion problem under the MAX - MIN and MAX - AVG criteria , respectively . Section 4 presents our results for the 1 - and 2 - dimensional dispersion problems . Section 5 contains tables which summarize prior results , our contributions , and open problems . 1 . DEFINITIONS AND PREVIOUS WORK We begin with the specifications of the MAX - MIN and MAX - AVG dispersion problems in the format of Garey and Johnson ( 1979 ) . MAX - MIN Facility Dispersion ( MMFD ) Instance : A set V = Iv1 , v2 , . . . , VnI of n nodes , a nonnegative distance w ( vi , v ; ) for each pair vi , v ; of nodes , and an integer p such that 2 < p < n . Requirement : Find a subset P = Ivil , vi2 , . . . , of V with I PI = p , such that the objective function f ( P ) = minxpA w ( x , y ) } is maximized . MAX - AVG Facility Dispersion ( MAFD ) Instance : As in MMFD . Requirement : Find a subset P = { vil , vi2 , . . . , vij of V with I PI = p , such that the objective function g ( P ) = 2 W ( X , A ) P ( P - 1 ) XyeP is maximized . The objective function for MAFD has the above form because the number of edges among the nodes in P is p ( p - 1 ) / 2 . Note that maximizing the average distance is equivalent to maximizing the sum of the distances . We point out that maximizing the average would sometimes produce solutions which are far from the optimum with respect to the MAX - MIN criterion and vice versa . The distances specified in an instance of MMFD or MAFD satisfy the triangle inequality if for any three distinct nodes vi , vj , and Vk , w ( vi , vJ ) + w ( vj , VOk ) w ( vi , Vk ) . The set P of nodes at which an algorithm places the p facilities is called a placement . Given a placement P for an MMFD instance , the quantity f ( P ) defined by f ( P ) = minIw ( x , y ) j ( 1 ) xYEP is called the solution value corresponding to P . Simi - larly , given an MAFD instance and a placement P , the solution value g ( P ) corresponding to P is defined by 2 g ( P ) = i w ( x , y ) . ( 2 ) p - 1 ) XJYEP Both MMFD and MAFD are known to be NP - hard , even when the edge weights satisfy the triangle inequality ( Wang and Kuo 1988 , Hansen and Moon 1988 , and Erkut 1990 ) . Much of the work on the dispersion problem reported in the literature ( see the bibliography in Erkut and Neuman 1989 ) falls into two categories . Papers in the first category deal with branch - and - bound algorithms and heuristics ( see Kuby 1987 , Erkut , Baptie and von Hohenbalken 1990 , Erkut 1990 , Erkut and Neuman 1989 , 1990 , and the references cited therein ) . However , except for White ( 1991 ) , only experimental studies of the per - formance of the heuristics have been reported . White ( 1991 ) presents a heuristic for MMFD when the nodes are points in d - dimensional Euclidean space and the distance between a pair of points is their Euclidean RAVI , ROSENKRANTZ AND TAYI / 301 distance . He shows that the heuristic always produces a placement whose solution value is within a factor of 3 of the optimum solution value . In the next section , we improve that result by considering a different heuristic which guarantees a placement whose solu - tion value is within a factor of 2 of the optimal solution value for any instance of MMFD in which the dis - tances satisfy the triangle inequality . We also show that unless P = NP , no polynomial - time algorithm can provide a better performance guarantee . Papers in the second category deal with restricted versions and variants of MMFD and MAFD . For example , 1 - and 2 - dimensional versions of MMFD were studied by Wang and Kuo . They present a poly - nomial algorithm for the 1 - dimensional MMFD and prove that the 2 - dimensional MMFD is NP - hard . We note that problems MMFD and MAFD defined above are discrete in nature because each facility must be placed at one of the given nodes . Researchers have also considered continuous versions of the dispersion problems ( Church and Garfinkel 1978 , Chandrasekharan and Daughety 1981 , and Tamir 1991 ) where facilities may be placed at any point on the edges of a given network . In Chandrasekharan and Daughety a polynomial algorithm is presented for the continuous version of MMFD on tree networks . Church and Garfinkel present a polynomial algorithm for locating one facility on an edge of a connected ( but not necessarily complete ) network to maximize a weighted sum of the distances from the facility to the nodes of the network . Tamir presents an improved algorithm for the same problem . In addition , he estab - lishes the NP - hardness of the continuous versions of MMFD and MAFD and presents results concerning performance guarantees for the continuous version of MMFD . Dasarathy and White ( 1980 ) assume the nodes of the network to be points in k - dimensional space and consider the problem of finding a point within a given convex polyhedron to maximize the minimum Euclidean distance between the point and the nodes . They present polynomial algorithms for k = 2 and k = 3 . For k = 2 , this problem is referred to as the largest empty circle ( LEC ) in the computa - tional geometry literature ( see subsection 6 . 4 of Preparata and Shamos 1985 ) . The LEC problem can be solved in O ( n log n ) time , which is known to be optimal ( Preparata and Shamos ) . A problem similar to LEC but with a different distance function is studied in Melachrinoudis and Cullinane ( 1986 ) . A weighted version of the problem for k = 2 is studied in Erkut and Oncu ( 1991 ) . For a discussion of other variants , we refer the reader to Erkut and Neuman ( 1989 , 1990 ) . In this paper , we consider only the discrete versions of the dispersion problems . Our focus is on the analy - sis of heuristics for MMFD and MAFD . By a heuristic we mean a polynomial - time approximation algorithm which produces feasible , but not necessarily optimal , solutions . Heuristics are commonly classified as abso - lute or relative depending on the types of performance guarantees that can be established for them ( Horowitz and Sahni 1984 ) . An absolute approximation algo - rithm guarantees a solution that is within an additive constant of the optimal value for every instance of the problem . A relative approximation algorithm guar - antees a solution that is within a multiplicative con - stant of the optimal value for every instance of the problem . It is easy to show , using the technique pre - sented in Garey and Johnson ( pp . 138 - 139 ) , that there are no absolute approximation algorithms for MAFD or for MMFD , unless P = NP . So we restrict our attention to the study of relative approximation algorithms . 2 . NEAR - OPTIMAL SOLUTIONS TO MAX - MIN FACILITY DISPERSION We first consider MMFD without requiring the dis - tances to satisfy the triangle inequality and prove a negative result concerning relative approximation algorithms . Theorem 1 . If the distances are not required to satisfy the triangle inequality , then there is no polynomial - time relative approximation algorithm for MMFD unless P = NP . Proof . Suppose that A is a polynomial - time approxi - mation algorithm which provides a performance guar - antee of K , 1 for MMFD . We show that A can be used to devise a polynomial - time algorithm for a problem which is known to be NP - complete . This contradicts the assumption that P ? NP and , hence , will establish the theorem . The known NP - complete problem used here is CLIQUE , whose definition is as follows ( Garey and Johnson ) . Problem CLIQUE Instance : An undirected graph G ( N , E ) and a positive integer J < INI . Question : Does G contain a clique of size : J ( i . e . , is there a subset N ' C N such that I N ' 1 > J and every pair of vertices in N ' is joined by an edge in E ) ? Consider an arbitrary instance of CLIQUE defined by a graph G ( N , E ) and integer J . Let n = INI and 302 / RAvI , ROSENKRANTZ AND TAYI N = { XI , x2 , . . . , Xn We construct an instance of MMFD ( without triangle inequality ) as follows . The node set V = { v1 , v2 , . . . , Vn of the MMFD instance is in one - to - one correspondence with N . The number of facilities p is set equal to J and the distances are defined as follows . Let w ( v , , vj ) = K + 1 if { xi , xj ; is in E ; otherwise , let w ( vi , v ; ) = 1 . Clearly , this construc - tion can be carried out in polynomial time . We will show that for the resulting MMFD instance , the solu - tion value of a placement produced by A is greater than 1 iff G has a clique of size J . Suppose that G has a clique of size J . Let $ xi , xi2 , . . . , xiJ denote the vertices of the clique . Consider the placement P = { Ivi , vi2 , . . . , viJ . By our definition of the distances , the weight of every edge in P is equal to K + 1 . Therefore , the solution value of the placement P is also K + 1 . Since A provides a performance guarantee of K , the solution value of the placement returned by A is at least ( K + 1 ) / K , which is greater than 1 . Now suppose that G does not have a clique of size J . In this case , notice that no matter which subset of p = J nodes is chosen as the placement , there will always be at least one pair of nodes vi and v ; with w ( vi , v > ) = 1 . Therefore , the solution value correspond - ing to any placement is at most 1 . In particular , the solution value of a placement produced by A is also at most 1 . Thus , by merely comparing the solution value of the placement produced by A with 1 , we can solve an arbitrary instance of the CLIQUE problem . This completes the proof . Even though Theorem 1 provides a strong negative result , it is not applicable in many practical situations because distances often satisfy the triangle inequality . Therefore , it is of interest whether there is an efficient relative approximation algorithm for MMFD when the distances satisfy the triangle inequality ( MMFD - TI ) . The remaining theorems in this section precisely characterize the performance guarantees obtainable for MMFD - TI . A greedy heuristic ( which we call GMM ) for MMFD - TI is shown in Figure 1 . This heuristic is essentially the same as the " furthest point outside the neighborhood " heuristic , described in Steuer ( Chapter 1 1 ) , using a different format . An experimen - tal study of the performance of this heuristic is carried out in Erkut and Neuman ( 1990 ) . In describing this heuristic , we use P to denote the set of nodes at which GMM places the p facilities . The heuristic begins by initializing P to contain a pair of nodes in V which are joined by an edge of maximum weight . Subse - quently , each iteration of GMM chooses a node v Step 1 . Let vi and uj be the endpoints of an edge of maximum weight . Step 2 . P - { xtu , vj } . Step 3 . while ( P1 < p ) do begin a . Find a node v E V - P such that min { w ( , v ' ) } is maximum among the nodes in V - P . b . Pe - P tt } end Step 4 . Output P . Figure 1 . Details of heuristic GMM . from V - P such that the minimum distance from v to a node in P is the largest among all the nodes in V - P . In each step , ties are broken arbitrarily . Heuristic GMM terminates when I P I = p . The solu - tion value of the placement P produced by GMM is equal to minx and w ( x , y ) I . We now present an example to illustrate the GMM heuristic . Consider an MMFD - TI instance with five nodes ( denoted by Vt , V2 , V3 , V4 , and V5 ) and let p = 3 . The edge weights which satisfy the triangle inequality are : w ( v1 , v2 ) = 3 , W ( V2 , V3 ) = W ( V2 , V4 ) = W ( V2 , V5 ) = 1 , and all other edges are of weight 2 . To begin , GMM will place two of the facilities at vt and v2 because w ( v1 , v2 ) = 3 is the maximum edge weight . Now , no matter where the third facility is placed , the solution value of the placement is 1 because each of the remain - ing nodes ( V3 , V4 , and v5 ) has an edge of weight 1 to v2 . However , an optimal placement consists of the three nodes V3 , V4 , and vs and has a solution value of 2 . Thus , for this example , the solution value produced by GMM differs from the optimal value by a factor of 2 . Our next theorem shows that the performance of GMM is never worse . ( This result was obtained independently by White 1992 . ) Moreover , we will also show ( Theorem 3 ) that unless P = NP , no polynomial - time heuristic can provide a better performance guarantee . Theorem 2 . Let I be an instance of MMFD - TI . Let OPT ( I ) and GMM ( I ) denote , respectively , the solution values of an optimal placement and that produced by GMMfor the instance L Then OPT ( I ) / GMM ( I ) < 2 . Proof . Consider the set - valued variable P in the description of GMM . Let f ( P ) = minxyp w ( x , y ) } . We will show by induction that the condition f ( P ) 3 _ : OPT ( I ) 12 ( 3 ) holds after each addition to P . Since GMM ( I ) = f ( P ) after the last addition to P , the theorem then follows . Since the first addition inserts two nodes joined by RAVI . ROSENKRANTZ AND TAYI / 303 an edge of the largest weight into P , ( 3 ) clearly holds after the first addition . So , assume that the condition holds after k additions to P for some k - 1 . We will prove that the condition holds after the ( k + l ) st addition to P as well . To that end , let P * = { v * , v ! , . . . , vI } denote an optimal placement . For convenience , we use / * for OPT ( I ) . The following observation is an immediate consequence of the definition of the solution value corresponding to a placement for an MMFD instance . Observation 1 . For every pair vi , v7 of distinct nodes in P * , w ( v ' , v * ) > 1 * . Let Pk = { x1 , x2 , . . . , Xk + II denote the set P after k additions . ( Note that I Pk I = k + 1 , because the first addition inserts two nodes into P . ) Since GMM adds at least one more node to P , the following is a trivial observation . Observation 2 . PkI = k + 1 < p . For each vi E P * ( I < i s p ) , define S * = { E VI w ( v0 ' , u ) < 1 * / 2 } . That is , SP ' is the set of all nodes whose distances from vi * are less than 1 * / 2 . The following claim provides two useful properties of these sets . Claim I a . For 1 < i < p , SP ' is nonempty . b . For i # 1 , SP ' and Sj * are disjoint . Proof of Claim 1 Part a : This is obvious , because vi * E S # ' for 1 < i < p . Part b : Suppose that S # n Sj * f 0 for some i # j . Let u E SP ' U Si * . Thus , w ( v # , u ) < 1 * / 2 and w ( vj * , u ) < 1 * / 2 . By Observation 1 , w ( v ' , vj * ) , 1 * . These three inequalities together imply that the triangle inequality does not hold for the three nodes u , vi * and vj * . Claim lb follows . We now continue with the main proof . Since Pk has less than p nodes ( Observation 2 ) and there are p disjoint sets So * , St , . . . , Sp * , there must be at least one set , say Sr * ( for some r , 1 < r < p ) , such that Pk n Sr * - 0 . Therefore , by the definition of S * , we must have for each u E Pk , w ( vr * , u ) : 1 * / 2 . Since rV * is available for selection by GMM , and GMM selects a node v E V - Pk for which minced pkw ( v , v ' ) is a maximum among the nodes in V - Pk , it follows that ( 3 ) holds even after the ( k + 1 ) st addition to P . This completes the proof of Theorem 2 . Our next theorem shows that if P ? NP , GMM provides the best possible performance guarantee obtainable in polynomial time for MMFD - TI . Theorem 3 . If P $ NP , no polynomial - time relative approximation algorithm can provide a performance guarantee of ( 2 - e ) for any e > O for MMFDT - TI . Proof . We use a construction similar to that presented in the proof of Theorem 1 , except that the edge weights are chosen as follows . Let w ( vi , v ; ) = 2 - e / 2 if { xi , xj ; is in E ; otherwise , let w ( vi , vj ) = 1 . Using the fact that 0 < e < 1 , it is easy to verify that the resulting distances satisfy the triangle inequality . The proof that the solu - tion value of a placement produced by A for MMFD - TI is greater than 1 if G has a clique of size J is virtually the same as that of Theorem 1 . 3 . NEAR - OPTIMAL SOLUTIONS TO MAX - AVG FACILITY DISPERSION In this section , we discuss a relative approximation algorithm for MAFD under the triangle inequality assumption ( MAFD - TI ) . This heuristic , which we call GMA , is shown in Figure 2 . It is identical to the GMM heuristic of Figure 1 , except that in Step 3a , we choose a node v E V - P for which Zv ' eP w ( v , v ' ) is maximum among all the nodes in V - P . Note that the solution value of the placement P produced by GMA is equal to 2 / p ( p - 1 ) X , 3EP w ( x , y ) . An experimental study of this heuristic is carried out in Erkut and Neuman ( 1990 ) . We focus on deter - mining the performance guarantee provided by this heuristic . Our next theorem shows that GMA is indeed a relative approximation algorithm for MAFD - TI . Before presenting that theorem , we introduce some notation which will also be used in Section 4 . Let A and B be disjoint subsets of V . Define W ( A ) = X , , y w ( x , y ) and W ( A , B ) = xeA , yEB w ( x , y ) . ( Note that W ( A , B ) = W ( B , A ) . ) Also , for x E A , let W ( x , B ) = Z , , B w ( x , y ) . We now Step 1 . Let v ; and oj be the endpoints of an edge of maximum weight . Step 2 . P < - { vi , o ; } . Step 3 . while ( JP1 < p ) do begin a . Find a node v E V - P such that X : w ( vo , v ' ) is maximum EP among the nodes in V - P . b . PNP { P } . end Step 4 . Output P . Figure 2 . Details of heuristic GMA . 304 / RAVI , ROSENKRANTZ AND TAYI give two lemmas which are used several times in the proof of the performance bound for the GMA heuris - tic . The first is an immediate consequence of the pigeon hole principle ( Roberts 1984 ) . Lemma 1 . Let A and B be nonempty and disjoint subsets of V . Then there is a node x E A such that W ( x , B ) > W ( A , B ) / IA 1 Lemma 2 . Given an instance of MAFD - TI , let A and B be nonempty and disjoint subsets of V with I B I : 2 . Then W ( A , B ) : IA I W ( B ) / ( IB I - 1 ) . Proof . Let v be an arbitrary node in A . Let I B I = t and B = lb , , b2 , . . . , b1 [ . Since t = IBI : 2 , there is at least one edge in B . For each edge bin , bjl in B ( i # 1 ) , we have by the triangle inequality , w ( v , bi ) + w ( v , bj ) , w ( b , bj ) 1 < i < js t . ( 4 ) If we sum the inequalities shown in ( 4 ) , the left - hand side of the sum is ( t - 1 ) W ( v , B ) because each edge weight w ( v , bi ) ( 1 s i - t ) appears exactly ( t - 1 ) times in the sum . The right - hand side of the sum is simply W ( B ) . Therefore , we get ( t - 1 ) W ( v , B ) > W ( B ) , or W ( v , B ) - W ( B ) / ( t - 1 ) = W ( B ) / ( IBI - 1 ) . ( 5 ) Since inequality ( 5 ) holds for each v E A , we get W ( A , B ) - Al W ( B ) / ( IBI - 1 ) . Theorem 4 . Let I be an instance of MAFD - TI . Let OPT ( I ) and GMA ( I ) denote , respectively , the solution values of an optimal placement and that produced by GMA for the instance L Then OPT ( I ) / GMA ( I ) < 4 . Proof . We show by induction that after each addition , the average weight of an edge in P is at least OPT ( I ) / 4 . The statement is clearly true after the first addition ( which brings two nodes into P ) because an edge of maximum weight is added to P . So , assume that p > 3 and the statement holds after k additions for some k > 1 . We will prove that the statement holds after the ( k + 1 ) st addition as well . For convenience , we use / * for OPT ( I ) . Let Pk denote the set P after k additions . We have the follow - ing two - part observation . The first part is due to the fact that GMA adds at least one more node to P . The second is an immediate consequence of the inductive hypothesis . Observation 3 a . W ( Pk ) = k + 12 / P - * / . b . W ( Pk ) : , ; k ( k + 1 ) / 2 1 * / 4 . To prove the inductive hypothesis for Pk , 1 , it suffices to show that there is a node x E V - Pk such that W ( x , Pk ) > ( k + 1 ) 1 * / 4 , because this condition in conjunction with Observation 3b implies that the average edge weight is at least 1 * / 4 after the ( k + 1 ) st addition to P as well . We now state this condition formally as a claim and present its proof . Claim 2 . There is a node x E V - Pk such that W ( x , Pk ) > ( k + 1 ) 1 * / 4 . Proof of Claim 2 . Let P * denote the set of p nodes in an optimal placement . By the definition of 1 * , we have W ( P * ) = p ( P - 1 ) 1 * ( 6 ) 2 We have two cases to consider , depending upon whether or not Pk and P * are disjoint . Case 1 . ( Pk and P * are disjoint . ) We apply Lemma 2 with Pk as the set A and P * as the set B . ( We can do so because Pk and P * are disjoint and I P * I = p > 3 . ) We get W ( Pk , P * ) > I Pk I W ( P * ) / ( P - 1 ) ( 7 ) = ( k + 1 ) pl * 12 ( using 6 ) . Since W ( Pk , P * ) = W ( P * , Pk ) , we have W ( P * , Pk ) > ( k + 1 ) pl * 12 . Now , by Lemma 1 , there must be a node x E P * such that W ( x , Pk ) > W ( P * , Pk ) / P > ( k + 1 ) 1 * / 2 ( using 7 ) . Thus , the node x satisfies a condition which is even stronger than that required by Claim 2 . Case 2 . ( Pk and P * are not disjoint . ) Let Y = P * n Pk and let X = P * - Y . Since Y is nonempty , we must have : IXI < p - 1 . ( 8 ) Since X and Y are disjoint and P * = X U Y , we have W ( P * ) = AP - 1 ) I * 2 = W ( X ) + W ( Y ) + W ( X , Y ) . ( 9 ) We have two subcases depending on IlXI . Case 2a . ( IXI < 1 . ) Note that X ? 0 , otherwise , Y = P * = Pk and so IPkl = p , contradicting Observation la . Therefore , in this subcase , we need to consider only the possibility that IXI = 1 . Then , Pk = Y and so Pk consists of p - 1 nodes from P * . Let x be the RAVI , ROSENKRANTZ AND TAYI / 305 node in X . Since GMA selects a node v E V - Pk for which XV ' epk w ( v , v ' ) is a maximum among the nodes in V - Pk , and x is available for selection , it follows that GMA will produce an optimal solution in this subcase . Case 2b . ( IXI > 1 ( i . e . , IXI , 2 ) . ) Here , from ( 9 ) , we can conclude that either W ( X ) : W ( P * ) / 2 or W ( Y ) + W ( X , Y ) - W ( P * ) / 2 . We consider these two possibilities separately . Case 2b . i . ( W ( X ) > W ( P * ) / 2 ) We use Lemma 2 with Pk as set A and X as set B ( we can do so because IXI > 2 ) toget W ( X , Pk ) = W ( Pk , X ) > ( k l + 1 ) W ( X ) ( k + 1 IXI - ) W ( P * ) / 2 ( k + 1 ) pp - 1 ) 1 * / 4 ( using 6 ) . ( 10 ) From Lemma 1 , there is a node x E X such that W ( x , Pk ) > W ( X , Pk ) / lXI . Combining this observa - tion with ( 10 ) , we get APp - 1 ) ( ) * 4 W ( X , Pk ) IXI ( IXI - 1 ) ( ) 1 * 14 . Since p - 1 > IXI ( from 8 ) , the quantity p ( p - 1 ) / ( IXI ( IXI - 1 ) ) is greater than 1 . Therefore , we get W ( x , Pk ) > ( k + 1 ) 1 * / 4 as required . Case b . ii . ( W ( Y ) + W ( X , Y ) > W ( P * ) / 2 ) First note that if I Yi = 1 , then W ( Y ) = 0 and so W ( X , Y ) > W ( P * ) / 2 . Since Y C Pk and the edge weights are nonnegative , we must have W ( X , Pk ) > W ( X , Y ) . Therefore , W ( X , Pk ) 2 W ( P * ) / 2 = p ( p - 1 ) 1 * / 4 , and by Lemma 1 , there must be a node x E X such that W ( X , Pk ) A | P - 1 * / 4 > pl * / 4 ( from 8 ) > ( k + 1 ) 1 * / 4 ( from observation la ) and so Claim 2 holds when I Yl = 1 . Therefore , for the remainder of this proof , we assume that I Yi > 2 . Since in this subcase we are assuming that W ( Y ) + W ( X , Y ) > W ( P * ) / 2 , and as observed above , W ( X , Y ) < W ( X , Pk ) , we have W ( > W ( P ) - W ( X , Pk ) ( 11 ) 2 Let Q = Pk - Y . Note that Q and Y are disjoint and so IQI = IPkI - Iyl = ( k + 1 ) - IYI . We apply Lemma 2 with Q as the set A and Y as set B ( recall that I YI : 2 ) . We get ( k + 1 - | y ) ( 2 W ( Q , Y ) ( I YI ) w ( Y ) ( 12 ) ( I YI - 1 ) Since Pk = Q U Y and the sets Q and Y are disjoint , we also have , W ( Pk ) ? W ( Y ) + W ( Q , Y ) W ( Y ) IY - l + l ] ( from 12 ) - W ( ( Y ) I l ) ( 13 ) We now apply Lemma 2 with X as the set A and Pk as the set B . We get , W ( X , Pk ) > XI W ( Pk ) / ( IPkI - 1 ) = I Xl W ( Pk ) / k ( from Observation la ) > IXI W ( Y ) / ( I YI - 1 ) ( from 13 ) 1 ( I Y [ W ( P * ) / 2 - W ( X , Pk ) ] ( from ( ll ) ( 14 ) Rearranging ( 14 ) we get , WKX Pk ) 1X + JYJ 1 I > 1 | X Yl W ( P * ) 12 . Noting that IXI + I Y = P * I = p , substituting for W ( P * ) from ( 6 ) , and eliminating the common denom - inator I YI - 1 , we get W ( X , Pk ) ( p - 1 ) I XI p ( p - 1 ) 1 * / 4 . That is , W ( X , Pk ) I XI pl * / 4 . From this inequality and Lemma 1 , we conclude that there must be node x E X such that W ( x , Pk ) , pl * / 4 > ( k + 1 ) 1 * / 4 ( from Observation la ) . This completes the proof of Claim 2 and also that of Theorem 4 . Theorem 4 shows that the performance guarantee provided by GMA is no worse than 4 . However , the guarantee may well be less . The following result shows that the guarantee cannot be less than 2 . Theorem 5 . For any instance I of MAFD - TI , let OPT ( I ) and GMA ( I ) denote , respectively , the solution values of an optimal placement and that produced by GMA for the instance L For any e > 0 , there is an instance I , for which OPT ( IE ) / GMA ( IJ ) > 2 - e . 306 / RAVI , ROSENKRANTZ AND TAYI Proof . Consider the MAFD instance I described below . This instance has a total of 2p nodes and p facilities are to be located . For convenience in descrip - tion , we partition the set of 2p nodes into three sets called X , Y , and Z . The set X has p nodes ( denoted by xi , x2 , . . . , xp ) , the set Y has p - 2 nodes ( denoted by Yi , Y2 , . . . , YP - 2 ) , and Z has two nodes ( denoted by z1 and z2 ) . The edge weights are chosen as follows . For any distinct nodes xi and xj E X , w ( xi , xj ) = 2 . Also w ( z1 , z2 ) = 2 . All other edge weights are 1 . It is straightforward to verify that the distances satisfy the triangle inequality . The set X is an optimal placement and its solution value ( OPT ( I ) ) is 2 ( because every edge in X has a weight of 2 ) . We can force GMA to place the first two facilities at z1 and z2 because w ( zI , Z2 ) = 2 is a maximum edge weight . It is easy to verify that in the subsequent ( p - 2 ) steps , GMA can be forced to choose all the ( p - 2 ) nodes from the set Y . Thus , we force GMA to return Z U Y as the placement . The solution value ( GMA ( I ) ) correspond - ing to this placement is given by GMA ( I ) = 2 + ) P p - 1 ) 2 because in the placement , one edge ( namely , that between z , and z2 ) is of weight 2 and each remaining edge is of weight 1 . A bit of simplification shows that GMA ( I ) = 1 + 2 / ( p ( p - 1 ) ) . The ratio OPT ( I ) / GMA ( I ) is given by OPT ( I ) 2 GMA ( I ) 1 + 2 / ( p ( p - 1 ) ) Clearly , the ratio can be made arbitrarily close to 2 by choosing p to be sufficiently large . 4 . DISPERSION PROBLEMS IN ONE AND TWO DIMENSIONS The 1 - dimensional dispersion problems are restricted versions of MMFD and MAFD , where the node set V consists of a set of n points ( denoted by xl , x2 , . . . , xn ) on a line . Thus w ( xi , xj ) = Ixi - xjl . We denote these problems by 1D - MMFD and 1D - MAFD , respectively . Similarly , in the case of the 2 - dimensional dispersion problems ( denoted by 2D - MMFD and 2D - MAFD , respectively ) , the node set V is a set of n points in , 2 and the distance between a pair of points is the Euclidean distance . It is known that 1D - MMFD can be solved in polynomial time using a dynamic programming approach and that 2D - MMFD is NP - hard ( Wang and Kuo ) . Accord - ingly , we consider 1D - MAFD and 2D - MAFD in this subsection . 4 . 1 . A Polynomial - Time Algorithm for 1D - MAFD Our polynomial - time algorithm for 1D - MAFD is also based on a dynamic programming approach . It runs in O ( max { n log n , pnj ) time . In the development of the dynamic programming formulation for this prob - lem , we use the notation introduced in Section 3 . In studying the formulation , the reader should bear in mind that maximizing the average distance is equiv - alent to maximizing the sum of the distances . We begin by sorting the points into increasing order . Let V = { x , , x2 , . . . , x " } denote the points in sorted order . Consider a point x ; and an integer k s min ( j , p ) . For each such combination of xj and k , the dynamic programming algorithm considers choosing k points from { xl , x2 , . . . , xjI to maximize a certain quantity described below . Let C = A U B be a set of p points consisting of a subset A C { xi , . . . , xj such that IA l = k , and a subset B C Ixjl , . . . , x " } such that I B I = p - k . For each pair of points xu in A and x , in B , we have w ( xU , xv ) = w ( xj , xU ) + W ( xj , xe ) . ( 15 ) If we sum ( 15 ) over the points in B , we get W ( xu , B ) = ( p - k ) w ( xj , xu ) + W ( xj , B ) . ( 16 ) If we sum ( 16 ) over the points in A , we get W ( A , B ) = ( p - k ) W ( xj , A ) + kW ( xj , B ) . ( 17 ) Hence , W ( C ) = W ( A U B ) = W ( A ) + W ( B ) + W ( A , B ) = W ( A ) + ( p - k ) W ( xj , A ) + W ( B ) + kW ( xj , B ) . ( 18 ) The optimization goal of 1D - MAFD is to maximize W ( C ) . Suppose that for a given k , we want to choose a set C maximizing W ( C ) , but subject to the constraint that A contains k points and B contains p - k points . Equation ( 18 ) shows that under this constraint , the choice of B has no effect on the choice of A . For a given subset A 5 xi , . . , xjI such that IA I = k , define fkj ( A ) = W ( A ) + ( p - k ) W ( xj , A ) . ( 19 ) Let OPTkj be a k - element subset of lx1 , . . . , xj4 that maximizesfkj . Note that OPTp , , is the solution to the 1D - MAFD problem instance . The dynamic program - ming algorithm computes all the values of fkj ( OPTkj ) , and then uses these values to find an optimal solution to the 1D - MAFD instance . The algo - rithm finds the values of fk , j ( OPTk , j ) by considering RAVI , ROSENKRANTZ AND TAYI / 307 increasing values of j . For a given value of j , the algorithm considers increasing values of k . Now consider how to compute fkj ( OPTkj ) . Note that OPTkj either includes the point xj or excludes it . if xi 4 OPTk , j , then OPTkj must be OPTk , j ] 1 , for which we have , using ( 19 ) , fkj ( OPTk , j } I ) = W ( OPTkj1l ) + ( p - k ) W ( x , , OPTk , j11 ) = W ( OPTk , j - 1 ) + ( p - k ) W ( x , - 1 , OPTk , j X ) + k ( p - k ) ( xj - xj - ) = fk , j - , ( OPTk , j - l ) + k ( p - k ) ( xj - x - 1 ) . ( 20 ) If xj E OPTk , j , then OPTk , j must be OPTk1 , , j1l Ufjxf , and again using ( 19 ) we have , fk , j ( OPTk - l , j - l U fxj ) = W ( OPTk - l , j1 , ) + ( p - k ) ( W ( xj - 1 , OPTklj _ 1 ) + ( k - 1 ) ( x - xj - x ) ) + W ( xj - 1 , OPTklj _ 1 ) ? ( k - ) ( xj - xj , ) = W ( OPTk - l , 1j _ ) + ( p - k + 1 ) W ( Xj1 , OPTkjlj1l ) + ( k - l ) ( p - k + 1 ) ( xj - x , - , ) = fk - , 1j - l ( OPTk - 1 , j - l ) + ( k - l1 ) ( p - k + l1 ) ( x , - xj - , ) . ( 21 ) Equations ( 20 ) and ( 21 ) show that given the sets OPTkjI and OPTklj - 1 , and the values of fk , j - l ( OPTk , j - 1 ) and fk - , j - l ( OPTk - lj - l ) , we can com - pute OPTkj andfkj ( OPTkj ) . To complete the dynamic programming formulation , we note that the boundary conditions are OPToj = 0 , foj ( OPToj ) = 0 ( 1 j < n ) , OPT1 , I = Ixi 1 , and fi , I ( OPT , , 1 ) = 0 . The details of the algorithm are shown in Figure 3 . The algorithm first computes ( Step 4 ) the entries of the array F ( which corresponds to the function f in the above dynamic programming formulation ) and then uses these entries to construct an optimal placement P ( Step 5 ) . This implementation obviates the need for the sets OPTkj used in the formulation . The running time of the algorithm is O ( n log n ) for sorting plus O ( pn ) to carry out the dynamic program - ming ( there are O ( pn ) entries to compute , and each entry can be computed in constant time ) . Thus , the overall running time is O ( max ( n log n , pn ) ) . The above discussion is summarized in the follow - ing theorem which will be used in the next subsection . Theorem 6 . An optimal solution to any instance of 1D - MAFD given by a set V of n points and an integer p < n can be obtained in O ( maxf n log n , pnj ) time . 4 . 2 . A Heuristic for 2D - MAFD It is open whether 2D - MAFD is NP - hard . Note that GMA ( Section 3 ) provides a performance guarantee of 4 for 2D - MAFD . Here , we first present a heuristic for 2D - MAFD which provides a performance guar - antee of 4 ( , I2 - 1 ) - 1 . 657 and then show how this heuristic can be modified to obtain another heuristic which provides an asymptotic performance guarantee of r / 2 - 1 . 571 . These heuristics use our polynomial algorithm for 1D - MAFD . We assume that an instance of 2D - MAFD is given by a set V = lVI , v2 , . . . , v " ) of n points ( where each point vi is specified by a pair of coordinates ( xi , yi ) ) and an integer p < n . The steps of this heuristic ( called PROJECTL4 ) are shown in Figure 4 . The perfor - mance guarantee provided by PROJECTL4 is indi - cated in the following theorem . Theorem 7 . Let I be an instance of 2D - MAFD . Let OPT ( I ) and PROJECTA4 ( I ) denote , respectively , the solution values of an optimal placement and that pro - duced by PROJECTL4 for the instance I . Then OPT ( I ) / PROJECTI4 ( I ) < 4 ( V / - 1 ) . Proof . Recall that maximizing average distance is equivalent to maximizing the sum of the distances . So we will present the proof in terms of the sum of the distances between pairs of points . Let P * be an optimal placement . For convenience , we use the term edge to refer to the line segment between a pair of ( distinct ) points in P * . For an edge e E P * , let l ( e ) denote its length ( i . e . , the Euclidean distance between the end points of e ) . Note that OPT ( I ) = Zeep * l ( e ) . Given an edge e , let lx ( e ) , ly ( e ) , l , ( e ) , and lw ( e ) denote the magnitudes of the projections of e on the X , Y , V and W axes , respectively . We have the following claim . Claim 3 . lx ( e ) + ly ( e ) + lQ ( e ) + lw ( e ) , ( 1 + V2 ) l ( e ) . Proof of Claim 3 . Since we are considering the sum of the projections , assume without loss of generality that the angle 0 of e with respect to the X axis is between 00 and 450 , as shown in Figure 5 . From that figure , we have lx ( e ) = l ( e ) cos 0 , ly ( e ) = l ( e ) sin 0 , lQ ( e ) = l ( e ) cos ( 45 ? - 0 ) , and lw ( e ) = l ( e ) sin ( 45 ? - 0 ) . 308 / RAVI , ROSENKRANTZ AND TAYI ( * - - In the following , array F represents the function f in the formulation . - - * ) Step 1 . Sort the given points , and let { x , x2 , x , } denote the points in increasing order . Step 2 . for j : = I to n do F [ OJ ] - - 0 ; Step 3 . F [ 1 , 1 ] - 0 . Step 4 . ( * - - Compute the value of an optimal placement - forj = 2 to n do for k : = I to min ( p , j ) do begin tI - F [ k , j - 1 ] + k ( p - k ) ( xj - xj - ) ; t2 - F [ k - I , j - I ] + ( k - I ) ( p - k + I ) ( xj - xj I ) ; if tl > t2 , then ( * - - do not include xj - F [ k , J ] < t - else ( * - - Include xj - F [ k , J ] < - t2 ; end ; Step 5 . ( * - - Construct an optimal placement - P - { xx } ; k - p ; j - - n ; while k > I do begin if F [ k , J ] = F [ k - I , j - 1 ] + ( k - 1 ) ( p - k + I ) ( xj - xj - 1 ) , then ( * - - xj to be included in optimal placement - begin P < - P u { xj ; k - k - I ; end ; j * - j - I ; end ; Step 6 . Output P . Figure 3 . Details of the algorithm for 1D - MAFD . Step 1 . Obtain the projections of the given set V of points on each of the four axes defined by the equations y = 0 ( X axis ) , y = X ( Vaxis ) , { = 0 ( Yaxis ) , and y = - { ( W ~ axis ) . Step 2 . Find optimal solutions to each of the four resulting instances of I D - MAFD . Step 3 . Return the placement corresponding to the best of the four solutions found in Step 2 . Figure 4 . Details of heuristic PROJECT _ 4 . W Y v Let s ( e ) = l , ( e ) + ly ( e ) + l , ( e ) + lw ( e ) . Using well known trigonometric identities and the fact that sin 450 = cos 45 ? = I / N / , it is not difficult to verify that _ _ _ _ _ _ _ _ _ _ _ 0 - s ( e ) = l ( e ) [ sin 0 + ( 1 + . / 2 ) cos 0 ] . ( 22 ) From ( 22 ) , it is easy to verify that the minimum value of s ( e ) occurs when 6 = 00 or 0 = 450 and that this minimum value is ( 1 + 2I5 ) I ( e ) . This completes the proof of Claim 3 . We now continue with the main proof . Note that Figure 5 . Proof of claim 1 . Claim 3 holds for each edge in P * . So if we sum up RAVI , ROSENKRANTZ AND TAYI / 309 the result of Claim 3 over all the edges in P * , we get E Ix ( e ) + ly ( e ) + I ( e ) + lw ( e ) eEP * ( 1 + A ) I ( e ) eEP * - ( 1 + V ) OPT ( I ) . ( 23 ) If we let Sx = Caps lx ( e ) , and use analogous defini - tions for S , So , and SW , we get from ( 23 ) , Sx + Sy + S , + S , , ( 1 + V ; 2 ) OPT ( I ) . ( 24 ) From the last inequality , it follows that max ( Sx , Sy , Sun S ) + N / 2 ) OPT ( I ) . ( 25 ) Since PROJECU4 chooses the best placement from optimal solutions for the four 1D - MAFD instances , it follows that PROJECT14 ( I ) , max ( Sx , Sy , Sv , Sw ) . We thus have from inequality ( 25 ) , OPT ( I ) PROJECT . A ( I ) 4 / ( 1 + VJ ) = 4 ( 12 - 1 ) as indicated in the statement of the theorem . The performance guarantee provided by PROJECT4 is approximately 1 . 657 . By projecting the given set of points on more axes , it is possible to achieve an asymptotic performance guarantee of ir / 2 ~ 1 . 57 1 , as shown below . Theorem 8 . Let I be an instance of 2D - MAFD and let OPT ( I ) denote the solution value of an optimal placement for L Then , for any fixed e > 0 there is a polynomial - time approximation algorithm P , which produces a placement with solution value PE ( I ) such that OPT ( I ) / PE ( I ) < ( Xr / 2 + e ) . Proof . Given e > 0 , let k be the smallest even positive integer satisfying the condition k tan ( r / 2k ) s r / 2 + E . ( 26 ) Such a k exists because limka k tan ( r / 2k ) = r / 2 , and this limit is approached from above . Algorithm P , first projects the given set of points on k axes ( denoted by X1 , X2 , . . . , Xk ) such that the angle between any pair of successive axes is ink . It then solves the 1D - MAFD problem on each of the k axes and outputs the best of the placements found . In view of ( 26 ) , Theorem 8 would follow by proving that OPT ( I ) / Pe ( I ) is bounded by k tan ( r / 2k ) . The proof is very similar to that of Theorem 7 . Let P * denote an optimal placement and consider an edge e of length l ( e ) in P * . Without loss of generality , let 0 ( O < 0 < ir / k ) be the angle of e with respect to the X1 axis . Let li ( e ) denote the magnitude of the projec - tion of e on the Xi axis ( 1 < i < k ) , and let s ( e ) = Xk = , li ( e ) . It is easy to verify that - k12 k12 - 1 - s ( e ) = I ( e ) [ cos ( r r / k - 0 ) + E cos ( rir / k + 0 ) ] . ( 27 ) Tedious , but straightforward , calculations show that s ( e ) = 1 ( e ) [ sin 0 + sin ( r / k - 0 ) ] ( 28 ) From ( 28 ) , it is easy to verify that the minimum value of s ( e ) occurs when 0 = 0 or 0 = ir / k and that this minimum value is l ( e ) / tan ( r / 2k ) . Thus s ( e ) ; I ( e ) / tan ( r / 2k ) . The remainder of the proof to show that OPT ( I ) / P , ( I ) < k tan ( r / 2k ) is virtually the same as of Theorem 7 ( keeping in mind that the number of axes is k instead of 4 ) . We note that Theorem 8 generalizes the bound of Theorem 7 in that choosing e = 4 ( V2 - 1 ) - ir / 2 ( ~ 0 . 086 1 ) leads to projection on k = 4 axes . Also , to achieve a performance guarantee of 1 . 571 ( an approx - imate value of gr / 2 ) , 80 projections are needed ; in general , the number of projections goes to oo , as e approaches 0 . 5 . CONCLUSIONS The results of this paper , prior results , and open problems are summarized in two tables . Table I shows the complexity results for solving these problems opti - mally , while Table II shows performance guarantee results for heuristics . In these tables , prior results are indicated through appropriate citations ; our results are indicated by specifying the corresponding theorems . ACKNOWLEDGMENT An extended abstract containing some of the results in this paper appears in the Proceedings of the 1991 Workshop on Algorithms and Data Structures ( WADS - 9 1 ) , Ottawa , Canada , August 1991 . The research of the first author was supported by NSF grant CCR - 89 - 05296 , and the research of the second author was supported by NSF grants CCR - 88 - 03278 and CCR - 90 - 06396 . The research of the third author was supported by the Faculty Research Award Program of the University at Albany . We thank Professor Binay K . Bhattacharya ( Simon Fraser University , Burnaby , Canada ) for bringing the paper by Wang and Kuo ( 1988 ) to our attention . We 310 / RAVI , ROSENKRANTZ AND TAYI Table I Complexity Results for Dispersion Problems Problem MAX - MIN MAX - AVG General NP - hard NP - hard ( Erkut 1990 ) ( Hansen and Moon 1988 ) Triangle Inequality NP - hard NP - hard ( Erkut 1990 ) ( Hansen and Moon 1988 ) ID Version 0 ( max I pn , n log nJ ) 0 ( max I pn , n log n ) ( Wang and Kuo 1988 ) ( Theorem 6 ) 2D Version NP - hard Open ( Wang and Kuo 1988 ) Table II Performance Guarantee Results for NP - hard Dispersion Problems MAX - MIN MAX - AVG Upper Bound Lower Bound Upper Bound Lower Bound ( Best Known ( Intrinsic Limit , ( Best Known ( Intrinsic Limit , Problem Guarantee ) Assuming P # NP ) Guarantee ) Assuming P # NP ) General - No guaranteed ratio Open Open ( Theorem 1 ) Triangle Inequality 2 2 4 Open ( Theorem 2 ) ( Theorem 3 ) ( Theorem 4 ) 2D Version 2 Open 7r / 2 asymp . Open ( Theorem 2 ) ( Theorem 8 ) are indebted to the referees for their careful reading of our manuscript and their valuable comments . In par - ticular , one of the referees suggested presenting the conclusions in Section 5 in the form of tables . REFERENCES CHURCH , R . L . , AND R . S . GARFINKEL . 1978 . Locating an Obnoxious Facility on a Network . Trans . Sci . 12 , 107 - 118 . CHANDRASEKHARAN , R . , AND A . DAUGHETY . 1981 . Lo - cation on Tree Networks : p - Centre and n - Dispersion Problems . Math . Opns . Res . 6 , 50 - 57 . DASARATHY , B . , AND L . J . WHITE . 1980 . A Maxmin Location Problem . Opns . Res . 28 , 1385 - 1401 . ERKUT , E . 1990 . The Discrete p - Dispersion Problem . Eur . J . Opnl . Res . 46 , 48 - 60 . ERKUT , E . , AND S . NEUMAN . 1989 . Analytical Models for Locating Undesirable Facilities . Eur . J . Opnl . Res . 40 , 275 - 291 . ERKUT , E . , AND S . NEUMAN . 1990 . Comparison of Four Models for Dispersing Facilities . INFOR 29 , 68 - 85 . ERKUT , E . , AND T . S . ONCU . 1991 . A Parametric 1 - Maximin Location Problem . J . Opnl . Res . , Soc . 42 , 49 - 55 . ERKUT , E . , T . BAPTIE AND B . VON HOHENBALKEN . 1990 . The Discrete p - Maxian Location Problem . Comput . and Opns . Res . 17 , 51 - 61 . GAREY , M . R . , AND D . S . JOHNSON . 1979 . Computers and Intractability : A Guide to the Theory of NP - Completeness . W . H . Freeman , San Francisco . HANDLER , G . Y . , AND P . B . MIRCHANDANI . 1979 . Loca - tion on Networks : Theory and Algorithms . MIT Press , Cambridge , Mass . HANSEN , P . , AND I . D . MOON . 1988 . Dispersing Facilities on a Network . Presentation at the TIMS / ORSA Joint National Meeting , Washington , D . C . HOROWITZ , E . , AND S . SAHNI . 1984 . Fundamentals of Computer Algorithms . Computer Science Press , Rockville , Maryland . KUBY , M . J . 1987 . Programming Models for Facility Dispersion : The p - Dispersion and Maxisum Disper - sion Problems . Geog . Anal . 19 , 315 - 329 . MELACHRINOUDIS , E . , AND T . P . CULLINANE . 1986 . Locating an Undesirable Facility With a Minimax Criterion . Eur . J . Opnl . Res . 24 , 239 - 246 . PREPARATA , F . P . , AND SHAMOS , M . I . 1985 . Computa - tional Geometry : An Introduction . Springer - Verlag , New York . ROBERTS , F . S . 1984 . Applied Combinatorics . Prentice - Hall , Englewood Cliffs , New Jersey . STEUER , R . E . 1986 . Multiple Criteria Optimization : Theory and Application . John Wiley , New York . TAMIR , A . 1991 . Obnoxious Facility Location on Graphs . SIAM J . Disc . Math . 4 , 550 - 567 . WHITE , D . J . 1991 . The Maximal Dispersion Problem and the ' First Point Outside the Neighborhood ' Heuristic . Comput . and Opns . Res . 18 , 43 - 50 . WHITE , D . J . 1992 . The Maximal Dispersion Problem . J . Applic . Math . in Bus . and Ind . ( to appear ) . WANG , D . W . , AND Y . S . Kuo . 1988 . A Study of Two Geometric Location Problems . Infor . Proc . Letts . 28 , 281 - 286 .