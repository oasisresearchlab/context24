Analysis and Design of Optimization Algorithms via Integral Quadratic Constraints Laurent Lessard Benjamin Recht Andrew Packard Abstract This manuscript develops a new framework to analyze and design iterative opti - mization algorithms built on the notion of Integral Quadratic Constraints ( IQC ) from robust control theory . IQCs provide suﬃcient conditions for the stability of compli - cated interconnected systems , and these conditions can be checked by semideﬁnite programming . We discuss how to adapt IQC theory to study optimization algorithms , proving new inequalities about convex functions and providing a version of IQC theory adapted for use by optimization researchers . Using these inequalities , we derive upper bounds on convergence rates for the gradient method , the heavy - ball method , Nes - terov’s accelerated method , and related variants by solving small , simple semideﬁnite programming problems . We also brieﬂy show how these techniques can be used to search for optimization algorithms with desired performance characteristics , establish - ing a new methodology for algorithm design . Keywords . Convex optimization , ﬁrst - order methods , Nesterov’s method , heavy - ball method , proximal gradient methods , semideﬁnite programming , integral quadratic con - straints , control theory . 1 Introduction Convex optimization algorithms provide a powerful toolkit for robust , eﬃcient , large - scale optimization algorithms . They provide not only eﬀective tools for solving optimization algorithms , but are guaranteed to converge to accurate solutions in provided time bud - gets [ 23 , 26 ] , are robust to errors and time delays [ 11 , 22 ] , and are amendable to declarative modeling that decouples the algorithm design from the problem formulation [ 2 , 7 , 16 ] . However , as we push up against the boundaries of the convex analysis framework , try to build more complicated models , and aim to deploy optimization systems in highly complex environments , the mathematical guarantees of convexity start to break . The standard proof techniques for analyzing convex optimization rely on deep insights by experts and are devised on an algorithm - by - algorithm basis . It is thus not clear how to extend the toolkit to more diverse scenarios where multiple objectives—such as robustness , accuracy , and speed—need to be delicately balanced . This paper marks an attempt at providing a systematized approach to the design and analysis optimization algorithms using techniques from control theory . Our strategy is to adapt the notion of an integral quadratic constraint from robust control theory [ 19 ] . These constraints link sequences of inputs and outputs of functions , and are ideally suited to proving algorithmic convergence . We will see that for convex functions , we can derive these constraints using only the standard ﬁrst - order characterization of convex functions , and that these inequalities will be suﬃcient to reduce the analysis of ﬁrst - order methods to 1 a r X i v : 1408 . 3595v1 [ m a t h . O C ] 15 A ug 2014 the solution of a very small semideﬁnite program . Our IQC framework puts the analysis of algorithms in a uniﬁed proof framework , and to enables new analyses of algorithms by minor perturbations of existing proofs . This new system aims to simplify and automate the analysis of optimization programs , and perhaps to open new directions for algorithm design . Our methods are inspired by the recent work of Drori and Teboulle [ 6 ] . In their manuscript , the authors propose writing down the ﬁrst - order convexity inequality for all steps of an algorithmic procedure . They the derive a semideﬁnite program that ana - lytically veriﬁes very tight bounds for the convergence rate for the gradient method , and numerically precise bounds for convergence of Nesterov’s method and other ﬁrst - order methods . The main drawback of the Drori and Teboulle approach is that the size of the semideﬁnite program scales with the number of time steps desired . Thus , it becomes computationally laborious to analyze algorithms that require more than a few hundred iterations . Integral quadratic constraints will allow us to circumvent this issue . A typical example of one of our semideﬁnite programs might have a 3 × 3 positive semideﬁnite decision variable , 3 scalar variables , a 5 × 5 semideﬁnite cone constraint , and 4 scalar constraints . Such a problem can be solved in less than 10 milliseconds on a laptop with standard solvers . We are able to analyze a variety of methods in our framework . We show that these techniques certify the standard rates of convergence for the gradient method applied to strongly convex functions . We show that we can numerically estimate the performance of Nesterov’s method to within a factor of 1 . 4 of the best known upper bounds for strongly convex functions . We show how our system fails to certify the stability of the popular heavy - ball method of Polyak for strongly convex functions whose condition number is larger than 12 . Based on this analysis , we are able to construct a one - dimensional strongly convex function whose condition number is 16 and prove analytically that the heavy - ball method fails to ﬁnd the global minimum of this function . This suggests that our tools can also be used as a way to guide the construction of counterexamples . We show that our methods extend immediately to the projected and proximal variants of all the ﬁrst order methods we analyze . We also show how to extend our analysis to functions that are convex but not strongly convex , and provide bounds on convergence that are within a logarithmic factor of the best upper bounds . We also demonstrate that our methods can bound convergence rates when the gradient is perturbed by relative deterministic noise . We show how diﬀerent parameter settings lead to very diﬀerent degradations in performance bounds as the noise increases . Finally , we turn to algorithm design . Since our semideﬁnite program takes as input the parameters of our iterative scheme , we can search over these parameters . For simple two - step methods , our algorithms are parameterized by 3 parameters , and we show how we can derive ﬁrst - order methods that achieve nearly the same rate of convergence as Nesterov’s accelerated method but are more robust to noise . The manuscript is organized as follows . We begin with a discussion of discrete - time dynamical system and how common optimization algorithms can be viewed as feedback interconnections between a known linear system with an uncertain nonlinear component . We then turn to show how quadratic Lyapunov functions can be used to certify rates of convergence for optimization problems and can be found by semideﬁnite program - ming . This immediately leads to the notion of an integral quadratic constraint . Another contribution of this work is a new form of IQC analysis geared speciﬁcally toward rate - of - convergence conclusions , and accessible to optimization researchers . We also discuss their history in robust control theory and how they can be derived . With these basic IQCs in hand , we then turn to analyzing the gradient method and Nesterov method , their 2 projected and proximal variants , and their robustness to noise . We discuss one possible brute - force technique for designing new algorithms , and how we can outperform existing methods . Finally , we conclude with many directions for future work . 1 . 1 Notation and conventions Common matrices . The d × d identity matrix and zero matrix are denoted I d and 0 d , respectively . Subscripts are omitted when they are to be inferred by context . Convex functions . For a given 0 < m < L , we deﬁne S ( m , L ) to be the set of functions f : R d → R that are continuously diﬀerentiable , strongly convex with parameter m , and have Lipschitz gradients with parameter L . In other words , f satisﬁes m (cid:107) x − y (cid:107) 2 ≤ ( ∇ f ( x ) − ∇ f ( y ) ) T ( x − y ) ≤ L (cid:107) x − y (cid:107) 2 for all x , y ∈ R d Norms and sequences . We deﬁne (cid:96) n 2e to be the set of all semi - inﬁnite sequences ( x 0 , x 1 , . . . ) , where x k ∈ R n . We sometimes omit n and simply write (cid:96) 2e when the superscript is clear from context . The notation (cid:107) · (cid:107) : R n → R denotes the standard 2 - norm . The subset (cid:96) 2 ⊂ (cid:96) 2e consists of all square - summable sequences . In other words , x ∈ (cid:96) 2 if and only if (cid:80) ∞ k = 0 (cid:107) x k (cid:107) 2 is convergent . 2 Optimization algorithms as dynamical systems A linear dynamical system is ξ k + 1 = Aξ k + Bu k ( 2 . 1 ) y k = Cξ k + Du k . ( 2 . 2 ) Here u k ∈ R d is the input to the system and y k ∈ R d is the output . ξ k ∈ R m is the state of the system , and , when u k = 0 , ξ k is suﬃcient information to predict all future outputs y k . We can write such dynamical systems compactly with the notation (cid:34) A B C D (cid:35) stacking the components into a block matrix . We can connect this linear system in feedback with a nonlinearity ∆ by deﬁning the rule ξ k + 1 = Aξ k + Bu k ( 2 . 3a ) y k = Cξ k + Du k ( 2 . 3b ) u k = ∆ ( y k ) ( 2 . 3c ) In this case , the output is transformed by the nonlinear map ∆ : R d → R d and is then used as the input to the linear system . In this paper , we will be interested in when the interconnected nonlinearity has the form ∆ ( y ) = ∇ f ( y ) where f ∈ S ( m , L ) . In particular , we will cast algorithms designed to solve the optimization problem minimize x ∈ R n f ( x ) ( 2 . 4 ) 3 as dynamical systems and see how this new viewpoint can give us insights into convergence analysis . Later in the paper , we will also consider variants of ( 2 . 4 ) where the decision variable x is constrained or f is non - smooth . Standard ﬁrst order methods such as the Gradient method , heavy - ball method , and Nesterov’s accelerated method , can all be cast in the form ( 2 . 3 ) . In all cases , the non - linearity is the mapping ∆ ( z ) = ∇ f ( z ) . The state transition matrices diﬀer for each algorithm . The algorithm for the Gradient method can be expressed as (cid:34) A B C D (cid:35) = (cid:34) I d − αI d I d 0 d (cid:35) . To verify this , just plug in the deﬁnitions : ξ k + 1 = ξ k − αu k y k = ξ k u k = ∇ f ( y k ) Eliminating y k and u k and renaming ξ to x yields x k + 1 = x k − α ∇ f ( x k ) which is the familiar gradient method . Nesterov’s accelerated method for strongly convex functions is given by the dynamical system (cid:34) A B C D (cid:35) =   ( 1 + β ) I d − βI d − αI d I d 0 d 0 d ( 1 + β ) I d − βI d 0 d   Verifying that this is equivalent to Nesterov’s method takes only slightly more eﬀort than it did for the gradient method . The equations now read ξ ( 1 ) k + 1 = ( 1 + β ) ξ ( 1 ) k − βξ ( 2 ) k − αu k ( 2 . 5a ) ξ ( 2 ) k + 1 = ξ ( 1 ) k ( 2 . 5b ) y k = ( 1 + β ) ξ ( 1 ) k − βξ ( 2 ) k ( 2 . 5c ) u k = ∇ f ( y k ) ( 2 . 5d ) Note that ( 2 . 5b ) asserts that the partial state ξ ( 2 ) is a delayed version of the state ξ ( 1 ) . Substituting ( 2 . 5b ) into ( 2 . 5a ) gives the simpliﬁed system ξ ( 1 ) k + 1 = ( 1 + β ) ξ ( 1 ) k − βξ ( 1 ) k − 1 − αu k y k = ( 1 + β ) ξ ( 1 ) k − βξ ( 1 ) k − 1 u k = ∇ f ( y k ) Eliminating u k and renaming ξ ( 1 ) to x yields the common form of Nesterov’s method x k + 1 = y k − α ∇ f ( y k ) y k = ( 1 + β ) x k − βx k − 1 . The heavy - ball method is given by (cid:34) A B C D (cid:35) =   ( 1 + β ) I d − βI d − αI d I d 0 d 0 d I d 0 d 0 d   One can check by similar analysis that the above system is equivalent to the update rule x k + 1 = x k − α ∇ f ( x k ) + β ( x k − x k − 1 ) . 4 2 . 1 How do we prove an algorithm converges ? Convergence analysis of convex optimization algorithms typically follows a two step pro - cedure . First one must show that the algorithm has a ﬁxed point that solves the op - timization problem in question . Then , one must verify that from a reasonable starting point , the algorithm converges to this optimal solution at a speciﬁed rate . In dynamical systems , such proofs are called stability analysis . By writing common ﬁrst order methods as dynamical systems , we can unify their stability analysis . For a general problem with minimum occurring at y (cid:63) , we must have that at optimality ∇ f ( y (cid:63) ) = 0 , y (cid:63) = Cξ (cid:63) , and ξ (cid:63) = Aξ (cid:63) In particular , note that if we want an algorithm to work for any convex function f , y (cid:63) = Cξ (cid:63) and ξ (cid:63) = Aξ (cid:63) must have a solution for all y (cid:63) . This implies that A must have an eigenvalue of 1 . If the blocks of A are diagonal as in the gradient , Heavy - Ball , or Nesterov methods shown above , then the eigenvalue of 1 will have a geometric multiplicity of at least d . Proving that all paths lead to the optimal solution requires more eﬀort and is the majority of what is studied below . Before we proceed for general convex f , it is instructive to study what happens for quadratic f . 2 . 2 Quadratic problems Suppose f is a convex , quadratic function f ( x ) = 12 x T Qx − p T x + r where mI d (cid:22) Q (cid:22) LI d in the positive deﬁnite ordering . The gradient of f is simply ∇ f ( x ) = Qx − p and the optimal solution is x (cid:63) = Q − 1 p . What happens when we run a ﬁrst order method on a quadratic problem ? Assume throughout this section that D = 0 . Plugging the deﬁnitions of x (cid:63) and ∇ f equations back into ( 2 . 3 ) , we have the feedback interconnection ξ k + 1 − ξ (cid:63) = ( A + BQC ) ( ξ k − ξ (cid:63) ) Let T = A + BQC denote the closed - loop state transition matrix . A necessary and suﬃcient condition for ξ k to converge to ξ (cid:63) is that the spectral radius of T is strictly less than 1 . Recall that the spectral radius of a matrix M is deﬁned as the largest magnitude of the eigenvalues of M . We denote the spectral radius by ρ ( M ) . It is a fact that ρ ( M ) = lim k →∞ (cid:107) M k (cid:107) 1 / k and hence , lim k →∞ (cid:107) ξ k − ξ (cid:63) (cid:107) 1 / k ≤ ρ ( T ) . So the spectral radius also determines the rate of convergence of the algorithm . With only bounds on the eigenvalues of Q , we can provide conditions under which the algorithms above converge for quadratic f . 5 Proposition 1 . Let f : R d → R be a convex quadratic function f ( x ) = 12 x T Qx − p T x + r with mI d (cid:22) Q (cid:22) LI d . Let κ = L / m . Then 1 . The gradient method with α = 2 L + m converges and ρ ( A + BQC ) ≤ κ − 1 κ + 1 . 2 . Nesterov’s accelerated method with α = 1 L and β = √ κ − 1 √ κ + 1 converges and ρ ( A + BQC ) ≤ 1 − κ − 1 / 2 . 3 . The heavy - ball method with α = 4 ( √ L + √ m ) 2 and β = √ κ − 1 √ κ + 1 converges and ρ ( A + BQC ) ≤ (cid:16) √ κ − 1 √ κ + 1 (cid:17) 1 / 2 . All of these results are proven by elementary linear algebra . For completeness , we include the full proofs in Appendix A . Unfortunately , the above approach does not generalize to the case where f is a more general convex function . However , a diﬀerent characterization of stability does generalize and will be described in Section 3 . It turns out that for linear systems , stability is equivalent to the feasibility of a particular semideﬁnite program . We will see in the sequel that similar semideﬁnite programs can be used to certify stability of nonlinear systems . Theorem 2 . For T ∈ R d × d , ρ ( T ) < ρ if and only if there exists a P (cid:23) 0 satisfying T T PT − ρ 2 P ≺ 0 . The use of LMIs to characterize stability of a linear time - invariant system dates back to Lyapunov [ 18 ] , and we give a more detailed account of this history in Section 3 . 4 . The proof of Theorem 2 is elementary , and we include it here for completeness . Proof . If ρ ( T ) < ρ , then the matrix P = ∞ (cid:88) k = 0 ρ − 2 k ( T k ) T ( T k ) is well deﬁned , positive semideﬁnite , and satisﬁes T T PT − ρ 2 P ≺ 0 . Conversely , assume the LMI has a solution and let λ be an eigenvalue of T with corresponding eigenvector ξ . Then 0 > ξ ∗ T T PTξ − ρ 2 ξ ∗ Pξ = ( | λ | 2 − ρ 2 ) ξ ∗ Pξ But since ξ ∗ Pξ ≥ 0 , we must have that | λ | < ρ . Now suppose we are studying the dynamical system ξ k + 1 = Tξ k . Then , if there exists a P (cid:23) 0 satisfying T T PT − ρ 2 P ≺ 0 , we have ξ T k + 1 Pξ k + 1 < ρ 2 ξ T k Pξ k along all trajectories . If ρ < 1 , then the sequence of ξ k converges linearly to zero . Iterating this inequality down to ξ 0 , we see that ξ T k Pξ k < ρ 2 k ξ T 0 Pξ 0 which implies that (cid:107) ξ k (cid:107) ≤ (cid:112) cond ( P ) ρ k (cid:107) ξ 0 (cid:107) . where cond ( P ) is the condition number of P . This provides a non - asymptotic convergence analysis of the dynamical system . In what follows , we will generalize this semideﬁnite programming approach to yield feasibility problems that are suﬃcient to characterize 6 when the closed loop system ( 2 . 3 ) converges and which provide bounds on the distance to optimality as well . The function V ( ξ ) = ξ T Pξ is called a Lyapunov function for the dynamical system . This function strictly decreases over all trajectories and hence certiﬁes that the algorithm is stable , i . e . , converges to nominal values . The conventional method for proving stability of an electromechanical system is to show that some notion of total energy always decreases over time . Lyapunov functions provide a convenient mathematical formulation of this notion of total energy . The question for the remainder of the paper is how can we search for Lyapunov functions that guarantee algorithmic convergence when f is not quadratic . To understand our search strategy , we now brieﬂy segue into how this problem is commonly approached in control theory . 3 Searching for Lyapunov functions with integral quadratic constraints When the function being minimized is quadratic , its gradient is aﬃne , and the inter - connected dynamical system is a simple linear diﬀerence equation , whose stability and convergence rate is analyzed solely in terms of eigenvalues of the closed - loop system . When the cost function is not quadratic , the gradient update is not an aﬃne function , and hence we need to employ a new analysis technique . One technique that is popular in the control theory literature is to use integral quadratic constraints ( IQCs ) to capture features of the behavior of partially - known components . The idea behind IQCs can be explained by an analogy to the quadratic case . Suppose there exists a matrix M ( not necessarily positive deﬁnite ) such that by the known prop - erties of f , (cid:20) z 1 − z 2 ∇ f ( z 1 ) − ∇ f ( z 2 ) (cid:21) T M (cid:20) z 1 − z 2 ∇ f ( z 1 ) − ∇ f ( z 2 ) (cid:21) ≥ 0 ( 3 . 1 ) for all points z 1 and z 2 . Suppose further that there exists a matrix P (cid:31) 0 satisfying (cid:2) A B (cid:3) T P (cid:2) A B (cid:3) − (cid:20) ρ 2 P 0 0 0 (cid:21) + (cid:20) C 0 0 I (cid:21) T M (cid:20) C 0 0 I (cid:21) (cid:22) 0 . ( 3 . 2 ) Then , if we multiply both sides of ( 3 . 2 ) by (cid:20) ξ k − ξ (cid:63) u k − u (cid:63) (cid:21) we get the inequality ( ξ k + 1 − ξ (cid:63) ) T P ( ξ k + 1 − ξ (cid:63) ) − ρ 2 ( ξ k − ξ (cid:63) ) T P ( ξ k − ξ (cid:63) ) + (cid:20) y k − y (cid:63) u k − u (cid:63) (cid:21) T M (cid:20) y k − y (cid:63) u k − u (cid:63) (cid:21) ≤ 0 ( 3 . 3 ) for all k . Multiplying each equation ( 3 . 3 ) by ρ − 2 k and then summing over k , it follows that ( ξ t − ξ (cid:63) ) T P ( ξ t − ξ (cid:63) ) − ρ 2 t ( ξ 0 − ξ (cid:63) ) T P ( ξ 0 − ξ (cid:63) ) + t − 1 (cid:88) k = 0 ρ − 2 k (cid:20) y k − y (cid:63) u k − u (cid:63) (cid:21) T M (cid:20) y k − y (cid:63) u k − u (cid:63) (cid:21) ≤ 0 7 Now , using ( 3 . 1 ) and the fact that u k = ∇ f ( y k ) , the ﬁnal sum must be nonnegative . Hence we can drop it , revealing that ( ξ t − ξ (cid:63) ) T P ( ξ t − ξ (cid:63) ) ≤ ρ 2 t ( ξ 0 − ξ (cid:63) ) T P ( ξ 0 − ξ (cid:63) ) . An inequality of the form t − 1 (cid:88) k = 0 ρ − 2 k (cid:20) z k − z (cid:63) ∇ f ( z k ) − ∇ f ( z (cid:63) ) (cid:21) T M (cid:20) z k − z (cid:63) ∇ f ( z k ) − ∇ f ( z (cid:63) ) (cid:21) ≥ 0 ( 3 . 4 ) is a special form of an Integral Quadratic Constraint ( IQC ) . We will show in what follows that it is often possible to construct IQCs for function classes such that ( 3 . 4 ) holds for all sequences z (cid:63) , z 0 , . . . , z t ∈ R d . That is , IQCs provide constraints involving multiple points in R d . The constraint ( 3 . 4 ) is a sum over of quadratic functions of the test points . The term IQC was introduced in a seminal paper by Megretski and Rantzer [ 19 ] . Since they focused on analyzing continuous time dynamical systems their constraints involved integrals—rather than sums—of quadratic functions of test points . As we saw by this above discussion , if a partially - speciﬁed component satisﬁes some IQCs , then we could formulate suﬃcient conditions for algorithm convergence . We now turn to develop this theory in full generality . 3 . 1 What is an IQC ? IQCs provide a convenient framework for analyzing interconnected dynamical systems that contain components that are noisy , uncertain , or otherwise diﬃcult to model . The idea is to replace this troublesome component by a quadratic constraint on its inputs and outputs that is known to be satisﬁed by all possible instances of the component . If we can certify that the newly constrained system performs as desired , then the original system must do so as well . Suppose φ : (cid:96) 2e → (cid:96) 2e is the troublesome function we wish to analyze . The equation u = φ ( y ) can be represented using a block diagram , as in Figure 1 . φ u y Figure 1 : Block - diagram representation of the map φ . Although we do not know φ exactly , we assume that we have some knowledge of the constraints it imposes on the pair ( y , u ) . For example , suppose it is known that φ satisﬁes the following properties : 1 . φ is memoryless : φ ( y 0 , y 1 , . . . ) = ( φ 0 ( y 0 ) , φ 1 ( y 1 ) , . . . ) for some φ k : R d → R d . 2 . Each component of φ is L - Lipschitz : (cid:107) φ k ( y 1 ) − φ k ( y 2 ) (cid:107) ≤ L (cid:107) y 1 − y 2 (cid:107) for all y 1 , y 2 ∈ R d and for all k . The properties above imply that if u = φ ( y ) , then for all k , ( u k − u (cid:63) ) T ( u k − u (cid:63) ) ≤ L 2 ( y k − y (cid:63) ) T ( y k − y (cid:63) ) . Here , ( y (cid:63) , u (cid:63) ) is any input - output pair of signals that will serve as a reference . In matrix form , this is (cid:20) y k − y (cid:63) u k − u (cid:63) (cid:21) T (cid:20) L 2 I d 0 d 0 d − I d (cid:21) (cid:20) y k − y (cid:63) u k − u (cid:63) (cid:21) ≥ 0 for k = 0 , 1 , 2 , . . . ( 3 . 5 ) 8 Note that ( 3 . 5 ) is rather special in that the quadratic coupling of ( y , u ) is pointwise ; it only manifests itself as separate quadratic constraints on each ( y k , u k ) . It is possible to specify more general quadratic constraints that couple diﬀerent k values . To do this , we introduce auxiliary sequences z , ζ ∈ (cid:96) 2e together with a map Ψ characterized by the matrices ( A Ψ , B y Ψ , B u Ψ , C Ψ , D y Ψ , D u Ψ ) and the recursion ζ 0 = 0 ζ k + 1 = A Ψ ζ k + (cid:2) B y Ψ B u Ψ (cid:3) (cid:20) y k u k (cid:21) , z k = C Ψ ζ k + (cid:2) D y Ψ D u Ψ (cid:3) (cid:20) y k u k (cid:21) ( 3 . 6 ) The equations ( 3 . 6 ) deﬁne a map z = Ψ ( y , u ) . We then consider the quadratic forms z T k Mz k for some matrix M . Therefore , each choice of ( Ψ , M ) characterizes a sequence of quadratic forms on ( y , u ) . When written as constraints , these generalized quadratic forms are called IQCs , and we consider four types . Deﬁnition 3 . Suppose u = φ ( y ) and z = Ψ ( y , u ) where Ψ is a given linear map . Let z (cid:63) be a point in R d . We say that the operator φ satisﬁes the 1 . Pointwise IQC deﬁned by ( Ψ , M , z (cid:63) ) if ( z k − z (cid:63) ) T M ( z k − z (cid:63) ) ≥ 0 for k = 0 , 1 , . . . 2 . Hard IQC deﬁned by ( Ψ , M ) if (cid:80) kt = 0 ( z t − z (cid:63) ) T M ( z t − z (cid:63) ) ≥ 0 for k = 0 , 1 , . . . 3 . ρ - Hard IQC deﬁned by ( Ψ , M ) if (cid:80) kt = 0 ρ − 2 t ( z t − z (cid:63) ) T M ( z t − z (cid:63) ) ≥ 0 for k = 0 , 1 , . . . 4 . IQC deﬁned by ( Ψ , M ) if (cid:80) ∞ t = 0 ( z t − z (cid:63) ) T M ( z t − z (cid:63) ) ≥ 0 ( and always converges ) Note that the example ( 3 . 5 ) is a pointwise IQC where Ψ is the identity map z = ( y , u ) . In general however , Ψ makes it possible for z k to depend on a combination of ( y 0 , . . . , y k , u 0 , . . . , u k ) . Such examples will be described in Section 3 . 3 . Note that the IQCs deﬁned above satisfy { all pointwise IQCs } ⊂ { all ρ - hard IQCs } ⊂ { all hard IQCs } ⊂ { all IQCs } in the sense for example that if φ satisﬁes a pointwise IQC deﬁned by ( Ψ , M ) , then it must also satisfy all ρ - hard IQCs using that same ( Ψ , M ) , and so on . The notions of hard IQC and the more general IQC ( sometimes called soft IQC ) were introduced in [ 19 ] and their relationship is discussed in [ 36 ] . These concepts are useful in proving that a dynamic system is stable , but do not directly allow for the derivation of useful bounds on convergence rates . Finally , note that z (cid:63) is some nominal value of the output of Ψ that can be tuned to certify diﬀerent ﬁxed points of the uncertain block . The deﬁnitions of pointwise and ρ - hard are new , and were created for the purpose of better characterizing convergence rates , as we will see in Section 3 . 2 . 3 . 2 Stability and performance results In this section , we show how using IQCs allows us to prove that iterative algorithms converge , and to bound the rate of convergence . In both cases , the certiﬁcation re - quires solving a tractable convex program . We note that the original work on IQCs [ 19 ] only proved stability ( boundedness ) . Some other works have addressed exponential sta - bility [ 12 , 33 , 34 ] , but the emphasis of these works is on proving the existence of an exponential decay rate , and so the rates constructed are very conservative . We require less conservative exponential rates , and this is reﬂected in the inclusion of ρ in the LMI of our main result , Theorem 4 . 9 Suppose G is a map u (cid:55)→ y described by the recursion G : ξ k + 1 = Aξ k + Bu k y k = Cξ k ( 3 . 7 ) where ( A , B , C ) are matrices of appropriate dimensions . As in Section 2 , G is the iterative algorithm we wish to analyze , and using the general formalism of Section 3 . 1 , φ is the nonlinear map ( y 0 , y 1 , . . . ) (cid:55)→ ( u 0 , u 1 , . . . ) that characterizes the feedback . Of course , this subsumes the special case of interest in which u k = ∇ f ( y k ) for each k . The variable z can be interpreted as a ﬁltered version of the signals u and y . These equations can be represented using a block - diagram , as in Figure 2a . G ξ φ Ψ ζ z u y ( a ) An auxiliary system Ψ produces z , a ﬁltered version of the signals y and u . G ξ Ψ ζ u y z x ( b ) The nonlinearity φ is replaced by a con - straint on z , so we may remove φ entirely . Figure 2 : Feedback interconnection between a system G and a nonlinearity φ . An IQC is a constraint on ( y , u ) satisﬁed by φ . We only analyze the constrained system and so we may remove the φ block entirely . Consider the dynamics of G and Ψ from ( 3 . 7 ) and ( 3 . 6 ) , respectively . Upon eliminating y , the recursions may be combined to obtain (cid:20) ξ k + 1 ζ k + 1 (cid:21) = (cid:20) A 0 B y Ψ C A Ψ (cid:21) (cid:20) ξ k ζ k (cid:21) + (cid:20) BB u Ψ (cid:21) u k z k = (cid:2) D y Ψ C C Ψ (cid:3) (cid:20) ξ k ζ k (cid:21) + D u Ψ u k ( 3 . 8 ) More succinctly , ( 3 . 8 ) can be written as x k + 1 = ˆ Ax k + ˆ Bu k z k = ˆ Cx k + ˆ Du k where we deﬁned x k : = (cid:20) ξ k ζ k (cid:21) ( 3 . 9 ) The system ( 3 . 9 ) is represented in Figure 2b by the dashed box . Our main result is as follows . Theorem 4 ( Main result ) . Consider the block interconnection of Figure 2a . Suppose G is given by ( 3 . 7 ) and φ satisﬁes a ρ - hard IQC deﬁned by ( Ψ , M , z (cid:63) ) where Ψ is given by ( 3 . 6 ) and 0 ≤ ρ ≤ 1 . Assume x (cid:63) is a ﬁxed point of this dynamical system . Deﬁne ( ˆ A , ˆ B , ˆ C , ˆ D ) as in ( 3 . 8 ) – ( 3 . 9 ) . Consider the following LMI . (cid:20) ˆ A T P ˆ A − ρ 2 P ˆ A T P ˆ B ˆ B T P ˆ A ˆ B T P ˆ B (cid:21) + λ (cid:2) ˆ C ˆ D (cid:3) T M (cid:2) ˆ C ˆ D (cid:3) (cid:22) 0 ( 3 . 10 ) If ( 3 . 10 ) is feasible for some P (cid:31) 0 and λ ≥ 0 , then for any x 0 , we have (cid:107) x k − x (cid:63) (cid:107) 22 ≤ cond ( P ) ρ 2 k (cid:107) x 0 − x (cid:63) (cid:107) 22 for all k where cond ( P ) is the condition number of P . 10 Proof . Let x , u , z ∈ (cid:96) 2e be a set of sequences that satisﬁes ( 3 . 9 ) . Suppose ( P , λ ) is a solution of ( 3 . 10 ) . Suppose z (cid:63) and u (cid:63) are the values of z and u associated with the ﬁxed point x (cid:63) . Multiply ( 3 . 10 ) on the left and right by (cid:2) ( x k − x (cid:63) ) T ( u k − u (cid:63) ) T (cid:3) and its transpose , respectively . The result is ( x k + 1 − x (cid:63) ) T P ( x k + 1 − x (cid:63) ) − ρ 2 ( x k − x (cid:63) ) T P ( x k − x (cid:63) ) + λ ( z k − z (cid:63) ) T M ( z k − z (cid:63) ) ≤ 0 ( 3 . 11 ) Multiply each equation in ( 3 . 11 ) by ρ − 2 k and sum them for k = 0 , 1 , . . . , t − 1 . The sum telescopes , and using the fact that ( Ψ , M ) is ρ - hard , we are left with ( x t − x (cid:63) ) T P ( x t − x (cid:63) ) ≤ ρ 2 t ( x 0 − x (cid:63) ) T P ( x 0 − x (cid:63) ) Therefore (cid:107) x k − x (cid:63) (cid:107) 2 ≤ cond ( P ) ρ 2 k (cid:107) x 0 − x (cid:63) (cid:107) 2 , as required . We now comment on several issues related to Theorem 4 . Pointwise and hard IQCs . Theorem 4 can easily be adapted to other types of IQCs . 1 . If the pointwise IQC deﬁned by some ( Ψ , M ) is satisﬁed , then so is the ρ - hard IQC deﬁned by the same ( Ψ , M ) , and for any ρ . Therefore , we may apply Theorem 4 directly and ignore the ρ - hardness constraint . The smallest ρ that makes ( 3 . 10 ) feasible will correspond to the best exponential rate we can guarantee . 2 . Hard IQCs are the same as ρ - hard IQCs with ρ = 1 . Therefore , if the LMI ( 3 . 10 ) is feasible , Theorem 4 guarantees that (cid:107) x k (cid:107) 22 ≤ cond ( P ) (cid:107) x 0 (cid:107) 22 . In other words , the iterates are bounded ( but not necessarily convergent ) . 3 . If a ρ 1 - hard IQC is satisﬁed , then so is the ρ - hard IQC for any ρ ≥ ρ 1 . Also , if ( 3 . 10 ) is feasible for some ρ 2 , it will also be feasible for any ρ ≥ ρ 2 . Therefore , if we use a ρ 1 - hard IQC and ( 3 . 10 ) is feasible for ρ 2 , then the smallest exponential rate we can guarantee is ρ = max ( ρ 1 , ρ 2 ) . Multiple IQCs . Theorem 4 can also be generalized to the case where φ satisﬁes multi - ple IQCs . Simply redeﬁne the matrices ( ˆ A , ˆ B , ˆ C , ˆ D ) in a manner analogous to ( 3 . 9 ) , but where the output is now ( z ( 1 ) k , . . . , z ( r ) k ) . Instead of ( 3 . 10 ) , use (cid:20) ˆ A T P ˆ A − ρ 2 P ˆ A T P ˆ B ˆ B T P ˆ A ˆ B T P ˆ B (cid:21) + (cid:2) ˆ C ˆ D (cid:3) T   λ 1 M 1 . . . λ r M r   (cid:2) ˆ C ˆ D (cid:3) (cid:22) 0 ( 3 . 12 ) Where λ 1 , . . . , λ r ≥ 0 . Thus , when ( 3 . 12 ) is multiplied out as in ( 3 . 11 ) , we now obtain ( x k + 1 − x (cid:63) ) T P ( x k + 1 − x (cid:63) ) − ρ 2 ( x k − x (cid:63) ) T P ( x k − x (cid:63) ) + r (cid:88) i = 1 λ i ( z ( i ) T k − z (cid:63) ) M i ( z ( i ) k − z (cid:63) ) ≤ 0 and the rest of the proof is identical . Computational considerations . For a ﬁxed ρ , the LMIs ( 3 . 10 ) or ( 3 . 12 ) can be ef - ﬁciently solved using interior - point methods . Popular implementations include SDPT3 , SeDuMi , Yalmip , and Mosek . We will also be interested in ﬁnding the minimum ρ such that either ( 3 . 10 ) or ( 3 . 12 ) is feasible . This becomes a quasiconvex program that may be reformulated as a generalized eigenvalue problem ( GEVP ) [ 3 ] . The GEVP is well - studied and modiﬁed interior - point methods such as the method of analytic centers [ 21 ] can be used to solve it . For the simulations herein , we simply performed a bisection search on ρ . 11 3 . 3 IQCs for convex functions We list three IQCs that are useful for describing gradients of strongly convex functions : the sector , oﬀ - by - one , and weighted oﬀ - by - one IQCs . The sector IQC is also known as co - coercivity in optimization . In general , gradients of strongly convex functions satisfy an inﬁnite family of IQCs , originally characterized by Zames and Falb for the single - input - single - output case [ 44 ] . A generalization of the Zames - Falb IQCs to multidimensional functions is derived in [ 10 ] . Both the sector and oﬀ - by - one IQCs are special cases of Zames - Falb , while the weighted oﬀ - by - one IQC is a convex combination of the sector and oﬀ - by - one IQCs . While the Zames - Falb family is inﬁnite , only these three simple IQCs are needed in this paper . IQCs can be used to describe many other types of functions as well , and further examples are available in [ 19 ] . Lemma 5 ( sector IQC ) . Suppose f k ∈ S ( m , L ) for each k , and let φ : = ( ∇ f 0 , ∇ f 1 , . . . ) . If u = φ ( y ) , then φ satisﬁes the pointwise IQC (cid:20) y 2 − y 1 u 2 − u 1 (cid:21) T (cid:20) − 2 mLI d ( L + m ) I d ( L + m ) I d − 2 I d (cid:21) (cid:20) y 2 − y 1 u 2 − u 1 (cid:21) ≥ 0 for all y 1 , y 2 ∈ R d ( 3 . 13 ) Proof . For any f ∈ S ( m , L ) , the co - coercivity property implies that ( ∇ f ( y ) − ∇ f ( x ) ) T ( y − x ) ≥ 1 L (cid:107)∇ f ( y ) − ∇ f ( x ) (cid:107) 2 for all x , y ∈ R d Since f is strongly convex , deﬁne g ( x ) : = f ( x ) − m 2 (cid:107) x (cid:107) 2 . Thus , g ∈ S ( 0 , L − m ) . Applying the co - coercivity property to g and rearranging , we obtain ( m + L ) ( ∇ f ( y ) − ∇ f ( x ) ) T ( y − x ) ≥ mL (cid:107) y − x (cid:107) 2 + (cid:107)∇ f ( y ) − ∇ f ( x ) (cid:107) 2 Setting x = 0 , and u = ∇ f ( y ) and specifying to f k for each k yields the desired result . One possible factorization ( Ψ , M ) for the sector IQC is given by A Ψ = 0 B Ψ = 0 C Ψ = 0 D Ψ = (cid:20) LI d − I d − mI d I d (cid:21) M = (cid:20) 0 d I d I d 0 d (cid:21) ( 3 . 14 ) A common special case of the sector IQC is when φ is static . That is , each f k is the same function . Lemma 6 ( oﬀ - by - one IQC ) . Suppose f ∈ S ( m , L ) , and let φ : = ( ∇ f , ∇ f , . . . ) . Let y (cid:63) , y 0 , y 1 , y 2 , . . . be an arbitrary sequence in R d . If u = φ ( y ) , then φ satisﬁes the hard IQC ( u 0 − my 0 ) T ( Ly 0 − u 0 ) + k (cid:88) t = 1 ( u t − my t ) T (cid:0) L ( y t − y t − 1 ) − ( u t − u t − 1 ) (cid:1) ≥ 0 for k = 0 , 1 , . . . ( 3 . 15 ) Proof . For any f ∈ S ( m , L ) , we have the property f ( y ) ≥ f ( x ) + ∇ f ( x ) T ( y − x ) + 12 L (cid:107)∇ f ( y ) − ∇ f ( x ) (cid:107) 2 for all x , y ∈ R n ( 3 . 16 ) Similar to the proof of Lemma 5 , note that the function g ( x ) : = f ( x ) − f ( y (cid:63) ) − ∇ f ( y (cid:63) ) T ( x − y (cid:63) ) − m 2 (cid:107) x − y (cid:63) (cid:107) 2 12 satisﬁes g ∈ S ( 0 , L − m ) . Moreover , ∇ g ( y (cid:63) ) = 0 and g ( x ) ≥ 0 for all x . Note that for all k , ∇ g ( y k ) = ∇ f ( y k ) − ∇ f ( y (cid:63) ) − m ( y k − y (cid:63) ) = ( u k − u (cid:63) ) − m ( y k − y (cid:63) ) . Therefore , we may eliminate u 0 from the ﬁrst term in ( 3 . 15 ) and obtain ( u 0 − u (cid:63) − m ( y 0 − y (cid:63) ) ) T ( L ( y 0 − y (cid:63) ) − ( u 0 − u (cid:63) ) ) = ∇ g ( y 0 ) T ( ( L − m ) ( y 0 − y (cid:63) ) − ∇ g ( y 0 ) ) = ( L − m ) ∇ g ( y 0 ) T ( y 0 − y (cid:63) ) − (cid:107)∇ g ( y 0 ) (cid:107) 2 ≥ ( L − m ) g ( y 0 ) − 12 (cid:107)∇ g ( y 0 ) (cid:107) 2 ( 3 . 17 ) where the inequality follows from applying ( 3 . 16 ) with the values ( f , x , y ) → ( g , y 0 , y (cid:63) ) . Similarly , the t th term in the sum in ( 3 . 15 ) satisﬁes the bound ( u t − u (cid:63) − m ( y t − y (cid:63) ) ) T (cid:0) L ( y t − y t − 1 ) − ( u t − u t − 1 ) (cid:1) = ( L − m ) ∇ g ( y k ) T ( y k − y k − 1 ) − ∇ g ( y k ) T ( ∇ g ( y k ) − ∇ g ( y k − 1 ) ) ≥ ( L − m ) ( g ( y k ) − g ( y k − 1 ) ) − 12 (cid:107)∇ g ( y k ) (cid:107) 2 + 12 (cid:107)∇ g ( y k − 1 ) (cid:107) 2 ( 3 . 18 ) where this time we applied ( 3 . 16 ) with the values ( f , x , y ) → ( g , y t , y t − 1 ) . Substitut - ing ( 3 . 17 ) and ( 3 . 18 ) into the left - hand side of ( 3 . 15 ) , the sum telescopes , and we are left with ( L − m ) g ( y k ) − 12 (cid:107)∇ g ( y k ) (cid:107) 2 ≥ 0 Nonnegativity follows by applying ( 3 . 16 ) with the values ( f , x , y ) → ( g , y (cid:63) , y k ) . Note that when k = 0 , the expression ( 3 . 15 ) is none other than the sector IQC ( 3 . 13 ) applied to ( y 0 , u 0 ) . One possible factorization ( Ψ , M ) for the oﬀ - by - one IQC is given by A Ψ = 0 B Ψ = (cid:2) LI d − I d (cid:3) C Ψ = (cid:20) − I d 0 d (cid:21) D Ψ = (cid:20) LI d − I d − mI d I d (cid:21) M = (cid:20) 0 d I d I d 0 d (cid:21) ( 3 . 19 ) We can generalize the weighted oﬀ - by - one IQC as follows Lemma 7 ( Zames - Falb IQC ) . Suppose f ∈ S ( m , L ) , and let φ : = ( ∇ f , ∇ f , . . . ) . Let h ∈ R s be a vector with nonnegative coeﬃcients that sum to 1 . If u = φ ( y ) , then φ satisﬁes the hard IQC k (cid:88) t = 0 ( u t − u (cid:63) − m ( y t − y (cid:63) ) ) T (cid:32) L (cid:18) y t − s (cid:88) τ = 1 h τ y t − τ (cid:19) − (cid:18) u t − s (cid:88) τ = 1 h τ u t − τ (cid:19)(cid:33) ≥ 0 for k = 0 , 1 , . . . ( 3 . 20 ) with the convention that u s = u (cid:63) and y s = y (cid:63) if s < 0 . Proof . First consider the case where h τ = 0 for all τ except for index j where h j = 1 . Then , for k < j , ( 3 . 20 ) has the form k (cid:88) t = 0 ( u t − u (cid:63) − m ( y t − y (cid:63) ) T ( L ( y t − y (cid:63) ) − ( u t − u (cid:63) ) ) ≥ 0 which is true by ( 3 . 16 ) . For k ≥ j , we can use the bound ( 3 . 18 ) to ﬁnd k (cid:88) t = 0 ( u t − u (cid:63) − m ( y t − y (cid:63) ) ) T ( L ( y t − y t − j ) − ( u t − u t − j ) ) ≥ j − 1 (cid:88) τ = 0 ( L − m ) g ( y k − τ ) − 12 (cid:107)∇ g ( y k − τ ) (cid:107) 2 ≥ 0 . 13 The proof now follows by convexity as any expression ( 3 . 20 ) is a convex combination of these “oﬀ - by - j ” inequalities . Though we will not make use of the more general Zames - Falb family of inequalities , we include them as they are interesting in their own right and may ﬁnd applications in future work . In particular , if there is no suitable Zames - Falb IQC that describes ∇ f then there is no IQC in the sense of Deﬁnition 3 that is satisﬁed by ∇ f [ 4 ] . We conclude this section with a ρ - hard version of the oﬀ - by - one IQC . This inequality will be critical for deriving convergence rates below . Lemma 8 ( weighted oﬀ - by - one IQC ) . Suppose f ∈ S ( m , L ) , and let φ : = ( ∇ f , ∇ f , . . . ) . If u = φ ( y ) , then φ satisﬁes the ρ - hard IQC ( u 0 − u (cid:63) − m ( y 0 − y (cid:63) ) ) T ( L ( y 0 − y (cid:63) ) − ( u 0 − u (cid:63) ) ) + k (cid:88) t = 1 ( u t − my t ) T (cid:0) L ( ( y t − y (cid:63) ) − ρ 2 ( y t − 1 − y (cid:63) ) ) − ( ( u t − u (cid:63) ) − ρ 2 ( u t − 1 − u (cid:63) ) ) (cid:1) ≥ 0 for k = 0 , 1 , . . . ( 3 . 21 ) Proof . Deﬁne s k : = ( u k − u (cid:63) − m ( y k − y (cid:63) ) ) T ( L ( y k − y (cid:63) ) − ( u k − u (cid:63) ) ) p k : = ( u k − u (cid:63) − m ( y k − y (cid:63) ) ) T ( L ( y k − y k − 1 ) − ( u k − u k − 1 ) ) as the sector and oﬀ - by - one IQCs respectively . Also deﬁne h k : = ( L − m ) g ( y k ) − 12 (cid:107)∇ g ( y k ) (cid:107) 2 where g ( x ) : = f ( x ) − f ( y (cid:63) ) − ∇ f ( y (cid:63) ) T ( x − y (cid:63) ) − m 2 (cid:107) x − y (cid:63) (cid:107) 2 as in the proof of Lemma 6 . It is shown in the proof of Lemma 6 that the following inequalities hold for all k : h k ≥ 0 , s k ≥ h k , p k ≥ h k − h k − 1 ( 3 . 22 ) After rearranging , we see that the k th term of ( 3 . 21 ) ( which we call w k ) is merely a convex combination of the sector and oﬀ - by - one IQCs . Speciﬁcally , w k : = ( 1 − ρ 2 ) s k + ρ 2 p k ( 3 . 23 ) To prove ρ - hardness , we must show that w 0 + ρ − 2 w 1 + ρ − 4 w 2 + · · · + ρ − 2 k w k ≥ 0 ( 3 . 24 ) Substituting ( 3 . 22 ) and ( 3 . 23 ) into ( 3 . 24 ) , we obtain w 0 + ρ − 2 w 1 + ρ − 4 w 2 + · · · + ρ − 2 k w k = s 0 + ρ − 2 ( ( 1 − ρ 2 ) s 1 + ρ 2 p 1 ) + · · · + ρ − 2 k ( ( 1 − ρ 2 ) s k + ρ 2 p k ) ≥ h 0 + ρ − 2 ( h 1 − ρ 2 h 0 ) + · · · + ρ − 2 k ( h k − ρ 2 h k − 1 ) = ρ − 2 k h k ≥ 0 and this completes the proof . 14 3 . 4 Historical context of Lyapunov theory Constructing Lyapunov functions has a long history in control and dynamical systems , and the central focus of this paper is borrowing tools from this literature to see how we can generalize our analysis from quadratic functions to more general , nonlinear convex functions . One of the most fundamental problems in control theory is certifying the stability of nonlinear systems . In interconnected systems such as electric circuits or chemical plants , individual components are typically modeled using diﬀerential ( or diﬀerence ) equations . Interconnected systems often contain nonlinearities or components that are otherwise diﬃcult to model . The earliest results on such systems date back to the work of Lur’e and Postnikov [ 17 ] . The goal was to prove stability under a wide range of admissible uncertainties . This notion of robust stability was called absolute stability . Indeed , Lur’e studied precisely the model we are concerned with : a known linear system interconnected in feedback to an uncertain nonlinear system . In the 1960’s and 70’s , several suﬃcient conditions for absolute stability were expressed as frequency - domain conditions . In other words , the main objects of interest are ratios of the Laplace transforms of the outputs to the inputs , also known as transfer functions . Examples include the Popov criterion [ 32 ] , the small - gain theorem , the circle criterion , and passivity theory [ 43 ] . Frequency - domain conditions were popular at the time because they could be veriﬁed graphically . The work of Willems [ 39 ] uniﬁed many of the existing results by casting them in the time domain in a framework called dissipativity theory . This notion is on one hand a generalization of Lyapunov functions to include systems with exogenous inputs , and on the other hand a generalization of passivity theory and the small - gain theorem . These ideas form the core of modern nonlinear control theory , and are covered in many textbooks such as Khalil [ 14 ] . With the advent of computers , graphical methods were no longer required . The con - nection between frequency - domain conditions and Linear Matrix Inequalities ( LMIs ) was made by Kalman [ 13 ] and Yakubovich [ 40 ] and culminated in the Kalman - Yakubovich - Popov ( KYP ) lemma , also known as the Positive - Real lemma . This paved the way for the use of modern computational tools such as semideﬁnite programming . Another important development is the concept of the structured singular value [ 5 ] , also known as µ - analysis . While previous theory had been used to describe static nonlinearities or uncertainties , µ - analysis is a computationally tractable framework for describing a system containing multiple dynamic uncertainties . A survey of µ - related techniques and results is given in [ 28 ] . For a comprehensive overview of the history and development of LMIs in control theory , we refer the reader to [ 3 ] . Integral Quadratic Constraints ( IQCs ) were ﬁrst introduced by Yakubovich , who con - sidered the notion of imposing quadratic constraints on an inﬁnite - horizon control prob - lem [ 42 ] , and combining multiple constraints via the S - procedure [ 41 ] . The deﬁnitive work on IQCs is Megretski and Rantzer [ 19 ] . In this seminal paper , they showed that dissi - pativity theory , as well as all the frequency - domain conditions , could be formulated as IQCs . Furthermore , the KYP lemma in conjunction with the S - procedure allows stability to be veriﬁed by solving an LMI . The seminal paper on IQCs [ 19 ] develops the theory primarily in the frequency domain , but also alludes to time - domain versions of the results by introducing hard IQCs . This notion of hard IQCs is pursued in [ 36 ] , where the main IQC stability theorem is re - derived entirely in the time domain . In the time domain , these constraints parallel the develop - ment of Nesterov , where we are able to construct inequalities linking multiple inputs and outputs of uncertain functions . This allows us to provide a wholly self - contained devel - opment of the theory . Moreover , we are able to enhance the techniques of [ 36 ] , providing new IQCs and considerably sharper rates of convergence than those discussed in the ear - 15 lier work . In this sense , our work provides useful methods for control theorists interested in estimating rates of stabilization of their control systems . 4 Case studies We now use the results of Section 3 to re - derive some existing results from the literature on iterative large - scale algorithms . The IQC approach gives a uniﬁed method to analyze many diﬀerent algorithms . In addition to verifying existing results , we also present a negative result that was not previously known . 4 . 1 The gradient method Optimal rate . The gradient method with constant stepsize is among the simplest op - timization schemes . The recursion is given by ξ k + 1 = ξ k − t ∇ f ( ξ k ) ( 4 . 1 ) When seeking to minimize a function f ∈ S ( m , L ) , a commonly used stepsize is t : = 2 m + L . In this case , the upper bound on the convergence rate is given by (cid:107) ξ k (cid:107) 2 ≤ ρ 2 k (cid:107) ξ 0 (cid:107) 2 with ρ = L − m L + m ( 4 . 2 ) We will re - derive this result by applying Theorem 4 . Without loss of generality , assume that the global minimizer of f is 0 . Since f ∈ S ( m , L ) , we may use the sector IQC of Lemma 5 and ( 3 . 10 ) becomes (cid:20) ( 1 − ρ 2 ) P − tP − tP t 2 P (cid:21) + λ (cid:20) − 2 mLI n ( L + m ) I n ( L + m ) I n − 2 I n (cid:21) (cid:22) 0 and λ ≥ 0 ( 4 . 3 ) By choosing P = I n , we obtain a simple 2 × 2 LMI in the variables ( ρ 2 , λ ) . (cid:20) 1 − ρ 2 − t − t t 2 (cid:21) + λ (cid:20) − 2 mL L + m L + m − 2 (cid:21) (cid:22) 0 and λ ≥ 0 ( 4 . 4 ) Substituting t = 2 L + m and performing algebraic simpliﬁcations , ( 4 . 4 ) is equivalent to (cid:20) ( 1 − ρ 2 ) − 2 λmL − 2 + λ ( L + m ) 2 − 2 + λ ( L + m ) 2 4 − 2 λ ( L + m ) 2 (cid:21) (cid:22) 0 ( 4 . 5 ) Using Schur complements , ( 4 . 5 ) is equivalent to 4 − 2 λ ( L + m ) 2 ≤ 0 and ( 1 − ρ 2 ) − 2 λmL − 1 + 12 λ ( L + m ) 2 ≤ 0 ( 4 . 6 ) Simplifying , we obtain λ ≥ 2 ( L + m ) 2 and ρ 2 ≥ 12 λ ( L − m ) 2 , which together imply that the minimum ρ that solves ( 4 . 3 ) is given by ( 4 . 2 ) . This agrees with the optimal rate bound ( 4 . 2 ) , as required . Note that the choice of P = I n is a natural choice of a Lyapunov function as the gradient map is a contractive map when t = 2 m + L . Our proof is verifying the fact that (cid:107) x − t ∇ f ( x ) (cid:107) 2 ≤ ρ 2 (cid:107) x (cid:107) 2 for all x ∈ R n . 16 Our result here for the gradient method is not particular surprising , but it is a useful example to illustrate how to use the IQC techniques , and to demonstrate that this analysis method matches previous analyses for this simple algorithm . Note that ( 4 . 4 ) can be made linear in t as well by using Schur complements :   − 2 mLλ − ρ 2 ( L + m ) λ 1 ( L + m ) λ − 2 λ − t 1 − t − 1   (cid:22) 0 ( 4 . 7 ) And now ( 4 . 7 ) is linear in ( ρ 2 , λ , t ) . This formulation allows one to directly solve for the optimal stepsize and associated rate , or answer questions such as “what range of stepsizes can yield a given rate ? ” . 4 . 2 Nesterov’s accelerated method Nesterov’s accelerated method with constant stepsize converges at a linear rate . There exists some c > 0 such that for all initial conditions ξ 0 , (cid:107) ξ k (cid:107) 2 ≤ cρ 2 k (cid:107) ξ 0 (cid:107) 2 with ρ = 1 − (cid:113) m L when applied to functions f ∈ S ( m , L ) . In this case , the parameters are chosen to be α : = 1 / L and β : = ( √ L −√ m ) / ( √ L + √ m ) [ 23 ] . Nesterov’s algorithm is “nearly optimal” in the sense that there is no algorithm of the form ( 2 . 3 ) that converges with a rate faster than ρ opt = √ L − √ m √ L + √ m . ( 4 . 8 ) for f ∈ S ( m , L ) . We computed the rate bounds using Theorem 4 using either the sector IQC of Lemma 5 , or a combination of the sector IQC and the weighted oﬀ - by - one IQC of Lemma 8 . It is important to note that unlike the gradient method case , the LMI ( 3 . 10 ) is no longer linear in ρ 2 . Therefore , we ﬁnd the minimal ρ by performing a bisection search on ρ , see the ﬁrst plot in Figure 3 . The rate obtained using the sector IQC is much slower than the optimal rate . To see why , recall that the sector IQC allows for f k to be diﬀerent at each iteration . Unlike the gradient method , Nesterov’s accelerated method is not robust to having a changing f k . However , convergence can nevertheless be guaranteed as long as ρ < 1 ; and the crossover point is at around L / m ≈ 11 . 7 . The rate obtained using the weighted oﬀ - by - one IQC is still suboptimal , but is within a small factor of optimal when we compare the number of iterations required to guarantee convergence to within a speciﬁed tolerance , see the right plot in Figure 3 . Given that (cid:107) x k (cid:107) 2 ≤ cond ( P ) ρ 2 k (cid:107) x 0 (cid:107) 2 , if we seek the smallest k such that (cid:107) x k (cid:107) ≤ ε , then it suﬃces that cond ( P ) ρ 2 k (cid:107) x 0 (cid:107) 2 ≤ ε 2 . This implies that k ≥ (cid:18) − 1 2 log ρ (cid:19) log (cid:18) cond ( P ) (cid:107) x 0 (cid:107) 2 ε 2 (cid:19) ( 4 . 9 ) In Figure 3 we plotted − 1 / log ρ versus L / m , and see this quantity is proportional to the lower bound on the number of iterations required to guarantee convergence to within a tolerance ε . As we can see from the iterations plot in Figure 3 , Nesterov’s method is within a factor of 2 of the theoretical lower bound , and the bound we can prove for Nesterov’s method is within a factor of 1 . 4 of the true bound . Finally , we must also ensure that P is reasonably well - conditioned . In Figure 4 , we see that cond ( P ) is proportional to L / m , which agrees with the scale factor found by Nesterov [ 23 ] . 17 10 0 10 1 10 2 10 3 10 4 10 5 10 6 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ LMI ( sector ) LMI ( weighted oﬀ - by - one ) Optimal Gradient rate Optimal Nesterov rate Theoretical lower bound 10 0 10 1 10 2 10 3 10 4 10 5 10 6 10 − 1 10 0 10 1 10 2 10 3 10 4 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce LMI ( sector ) LMI ( weighted oﬀ - by - one ) Optimal Gradient rate Optimal Nesterov rate Theoretical lower bound Figure 3 : Upper bounds for Nesterov’s accelerated method , using either the sector IQC or the weighted oﬀ - by - one IQC . Convergence rate ( ﬁrst plot ) and number of iterations required to achieve convergence to a speciﬁed tolerance ( second plot ) . The blue dashed line represents the theoretical lower bound of ρ opt given in ( 4 . 8 ) . 4 . 3 The heavy - ball method Although the heavy - ball method and Nesterov’s accelerated method have similar recur - sions , Figures 3 and 5 tell very diﬀerent stories . When we allow for a diﬀerent f k at every iteration , we can guarantee stability when L / m ≈ 3 . 9 or less . When we include the weighted oﬀ - by - one IQC as well , we can only guarantee stability when L / m ≈ 12 or less . While it is possible that using more IQCs could potentially improve this upper bound , it turns out that the poor quality of these bounds are due to something more serious : the heavy - ball method optimized for quadratics does not converge for general f ∈ S ( m , L ) . To ﬁnd an example of an f ( x ) that leads to a non - convergent heavy - ball method , Figure 5 indicates that we should search for L / m > 12 . The following one - dimensional 18 10 0 10 1 10 2 10 3 10 4 10 5 10 6 10 0 10 1 10 2 10 3 10 4 10 5 10 6 10 7 10 8 Condition ratio L / m S c a l e f a c t o r κ ( P ) LMI ( sector ) LMI ( weighted oﬀ - by - one ) Slope of 1 Figure 4 : Condition number cond ( P ) when using the weighted oﬀ - by - one IQC . It is within a constant factor of L / m . Note that log cond ( P ) appears in ( 4 . 9 ) for computing minimum iterations to convergence . example does the job . ∇ f ( x ) =   16 x + 45 x < − 3 x − 3 ≤ x < 0 16 x x ≥ 0 ( 4 . 10 ) It is easy to check that ∇ f ( x ) is continuous and monotone , and so f ∈ S ( m , L ) with m = 1 and L = 16 . When using an initial condition in the interval 1 . 9 ≤ x 0 ≤ 2 . 4 , the heavy - ball method produces a limit cycle with oscillations that never damp out . The ﬁrst 50 iterates for x 0 = 2 are shown in Figure 6 , and a plot of f ( x ) with the limit cycle overlaid is shown in Figure 7 . For a detailed proof that f does indeed converge to a limit cycle , see Appendix B . We further investigate the stability of the heavy - ball method in Section 5 . 5 Further applications 5 . 1 Stability of the heavy - ball method We saw in Section 4 . 3 that the heavy - ball method that uses α and β optimized for quadratic functions is unstable for general strongly convex functions . A natural question to ask is whether the heavy - ball method is stable over the class S ( m , L ) for some choice of α and β . This experiment is easy to carry out in our framework , because choosing new values of α and β simply amounts to changing parameters in the LMI . We chose α = 1 L , and for a sampling of points in β ∈ [ 0 , 1 ] , we evaluated the corresponding heavy - ball method using Theorem 4 together with the weighted oﬀ - by - one IQC . See Figure 8 . The ﬁrst plot shows convergence rate . When β = 0 , the heavy - ball method becomes the gradient method , which is always convergent . However , we can improve upon the gradient rate by optimizing over β . The best achievable rate is given by the black curve . The black curve lies strictly above the optimal heavy - ball rate for quadratics , but below the optimal gradient rate . In the second plot , we show the iterations required to achieve convergence . Again , the black curve represents the optimal parameter choice . As L / m gets large , the envelope 19 10 0 10 1 10 2 10 3 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ LMI ( sector ) LMI ( weighted oﬀ - by - one ) Optimal Gradient rate Optimal heavy - ball rate Theoretical lower bound 10 0 10 1 10 2 10 3 10 − 1 10 0 10 1 10 2 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce LMI ( sector ) LMI ( weighted oﬀ - by - one ) Optimal Gradient rate Optimal heavy - ball rate Theoretical lower bound Figure 5 : Upper bounds for the heavy - ball method , using either the sector IQC or the weighted oﬀ - by - one IQC . Convergence rate ( ﬁrst plot ) and number of iterations required to achieve convergence to a speciﬁed tolerance ( second plot ) . veers away from the optimal heavy - ball curve and becomes parallel to the optimal gradient curve . So when L / m is large , even when β is chosen optimally , the heavy - ball method is comparable to the gradient method in worst - case for general strongly convex functions . 5 . 2 Multiplicative gradient noise A common consideration is the inclusion of noise in the gradient computation . A common model is relative deterministic noise where we assume the gradient error is proportional to the distance to optimality [ 31 ] . Instead of directly observing ∇ f ( y ) , we see v k = ∇ f ( y k ) + r k , where (cid:107) r k (cid:107) ≤ δ (cid:107)∇ f ( y k ) (cid:107) for some small nonnegative δ . The IQC framework can be used to analyze such situations to study the robustness of various algorithms to this type of noise . 20 0 5 10 15 20 25 30 35 40 45 50 − 6 − 4 − 2 0 2 4 Iteration k H e a vy - b a ll i t e r a t e x k Figure 6 : Iteration history of the heavy - ball method when optimizing f ( x ) deﬁned in ( 4 . 10 ) . Dashed lines separate the pieces of f ( x ) . The iterates tend to a limit cycle , so the heavy - ball method does not converge for this particular strongly convex function . − 7 − 6 − 5 − 4 − 3 − 2 − 1 0 1 2 3 4 0 20 40 60 80 100 f ( x ) Figure 7 : Graph of f ( x ) deﬁned in ( 4 . 10 ) with the limit cycle overlaid on top . If w k is the true gradient , we actually measure u k = ∆ k w k , where the gradient error is bounded above by a quantity proportional to the true gradient . In other words , we assume there is some δ > 0 such that (cid:107) u k − w k (cid:107) ≤ δ (cid:107) w k (cid:107) . Rearranging this inequality , we obtain the IQC (cid:20) w k u k (cid:21) T (cid:20) δ 2 − 1 1 1 − 1 (cid:21) (cid:20) w k u k (cid:21) ≥ 0 for all k Note that this is nothing more than the sector IQC with m = 1 − δ and L = 1 + δ . We make no assumptions on how the noise is generated ; it may be the output of a stochastic process , or could even be chosen adversarially . The modiﬁed block - diagram is shown in Figure 9 . By making a small modiﬁcation , we can apply Theorem 4 . We will look to show that the following inequality holds over all trajectories x T k + 1 Px k + 1 − ρ 2 x T k Px k + λ 1 z T k Mz k + λ 2 (cid:20) w k u k (cid:21) T (cid:20) δ 2 − 1 1 1 − 1 (cid:21) (cid:20) w k u k (cid:21) ≤ 0 ( 5 . 1 ) for some λ 1 , λ 2 ≥ 0 . In order to formulate an LMI that implies a solution to ( 5 . 1 ) , we use the signal (cid:2) x T k u T k w T k (cid:3) . This leads to a block 3 × 3 LMI instead of the 2 × 2 LMI of Theorem 4 , but the proof is identical . Gradient method . Our ﬁrst experiment is to test the gradient method . We used noise values of δ ∈ { 0 . 01 , 0 . 02 , 0 . 05 , 0 . 1 , 0 . 2 , 0 . 5 } . See Figure 10 . In examining Figure 10 , we observe that the gradient method with stepsize 2 m + L is not very robust to multiplicative noise . Even with noise as low as 1 % ( δ = 0 . 01 ) , the 21 10 0 10 1 10 2 10 3 10 4 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ Heavy - ball optimized rate using grid search Gradient rate with t = 1 L Heavy - ball rate for quadratics Theoretical lower bound 10 0 10 1 10 2 10 3 10 4 10 − 1 10 0 10 1 10 2 10 3 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce Heavy - ball optimized iterations using grid search Gradient iterations with t = 1 L Heavy - ball iterations for quadratics Theoretical lower bound Figure 8 : Upper bounds for the heavy - ball method . We ﬁxed α = 1 L , and for each L / m , we picked β that led to the optimal rate . The result is the black curve . We plotted convergence rate ( ﬁrst plot ) and number of iterations required to achieve convergence to a speciﬁed tolerance ( second plot ) . gradient method is no longer stable for L / m > 100 . An explanation for this phenomenon is that in choosing the stepsize t , we are trading oﬀ convergence rate with robustness . The choice 2 m + L yields the minimum worst - case rate , but is fragile to noise . If we pick a more conservative stepsize such as the popular choice t = 1 L , we obtain a very diﬀerent picture . See Figure 11 . Notice that with the updated stepsize of t = 1 L , the gradient method is now robust to multiplicative noise . Robustness comes at the expense of a degradation in the best achievable convergence rate . This degradation manifests itself as a gap in Figure 11 between the black curves and the blue ones . Nesterov’s accelerated method . We can carry out an experiment similar to the one we did with the gradient method , but now with Nesterov’s method . As before , we examine the trade - oﬀ between the magnitude of the multiplicative noise and the degradation of the optimal convergence rate . This time , we use δ ∈ { 0 . 05 , 0 . 1 , 0 . 2 , 0 . 3 , 0 . 4 , 0 . 5 } . See Figure 12 . 22 G ∇ f ∆ w u y Figure 9 : Block - diagram representation of the standard interconnection with an additional block ∆ representing multiplicative noise . As with our ﬁrst gradient method test , Nesterov’s method is not robust to multiplicative noise . For moderate L / m , the degradation is minor , but eventually leads to instability when we reach a certain threshold . Robustness of Nesterov’s method can be improved by modiﬁying the α and β parameters . Choosing a smaller α pushes back the instability threshold , while choosing a smaller β simultaneously pushes back the instability threshold and degrades the rate . In the limit β → 0 , Nesterov’s method becomes the gradient method , so we recover the plots of Figure 11 . 5 . 3 Proximal point methods Suppose we are interested in solving a problem of the form minimize f ( x ) + P ( x ) subject to x ∈ R n where f ∈ S ( m , L ) , and P is an extended - real - valued convex function on R n . An example of such a problem is constrained optimization , where we require that x ∈ C . In this case , we simply let P be the indicator function of C . We will now show how the IQC framework can be used to analyze algorithms involving a proximal operator . Deﬁne the proximal operator of P as Π ν ( x ) : = arg min y (cid:0) (cid:107) x − y (cid:107) 2 + νP ( y ) (cid:1) As an illustrative example , we will show how to analyze the proximal version of Nesterov’s algorithm . Iterations take the form : ξ k + 1 = Π ν ( y k − α ∇ f ( y k ) ) y k = ξ k + β ( ξ k − ξ k − 1 ) ( 5 . 2 ) Note that when Π ν = I , we recover the standard Nesterov algorithm . When β = 0 , we recover the proximal gradient method . In order to analyze this algorithm , we must characterize Π ν using IQCs . To this end , let T : = ∂P be the sub - diﬀerential of P . Then , Π ν ( x ) is the unique point such that x − Π ν ( x ) ∈ νT ( Π ν ( x ) ) . Or , written another way , Π ν = ( I + νT ) − 1 ( 5 . 3 ) Since T is a sub - diﬀerential , it satisﬁes the incremental passivity condition . Namely , ( T ( x ) − T ( y ) ) T ( x − y ) ≥ 0 for all x , y ∈ R n Therefore , T satisﬁes the sector IQC with m = 0 and L = ∞ . In fact , T satisﬁes the oﬀ - by - one and weighted oﬀ - by - one IQCs as well . Now transform ( 5 . 2 ) by introducing the auxiliary signals u k : = ∇ f ( y k ) , w k : = Π ν ( y k − αu k ) , v k : = νT ( w k ) . The deﬁnitions of w k 23 10 0 10 1 10 2 10 3 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ Rates for diﬀerent values of δ δ ∈ { 0 . 01 , 0 . 02 , 0 . 05 , 0 . 1 , 0 . 2 , 0 . 5 } Optimal Gradient rate , t = 2 m + L 10 0 10 1 10 2 10 3 10 − 1 10 0 10 1 10 2 10 3 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce Iterations for diﬀerent values of δ δ ∈ { 0 . 01 , 0 . 02 , 0 . 05 , 0 . 1 , 0 . 2 , 0 . 5 } Noise - free Gradient method , t = 2 m + L Figure 10 : Convergence rate and iterations to convergence for the gradient method with t = 2 m + L , for various noise parameters δ . This method is not robust to noise . and v k together with ( 5 . 3 ) immediately imply that w k = y k − αu k − v k . Therefore , we can rewrite ( 5 . 2 ) as ξ k + 1 = ξ k + β ( ξ k − ξ k − 1 ) − v k − αu k w k = ξ k + β ( ξ k − ξ k − 1 ) − v k − αu k y k = ξ k + β ( ξ k − ξ k − 1 ) with : u k = ∇ f ( y k ) v k = νT ( w k ) These equations may be succinctly represented as a block diagram , as in Figure 13 . Analyzing this interconnection is done by accounting for the IQCs for both unknown blocks . If ( Ψ 1 , M 1 ) is the IQC for ∇ f with output z 1 k and ( Ψ 2 , M 2 ) is the IQC for νT with output z 2 k , then we seek to show that for all trajectories satisfy x T k + 1 Px k + 1 − ρ x T k Px k + λ 1 ( z 1 k ) T M 1 ( z 1 k ) + λ 2 ( z 2 k ) T M 2 ( z 2 k ) ≤ 0 ( 5 . 4 ) where x k now includes the states ξ k as well as the internal states of Ψ 1 and Ψ 2 . As in the proof of Theorem 4 , for each ﬁxed ρ , we can write ( 5 . 4 ) as an LMI in the variables P (cid:31) 0 , λ 1 ≥ 0 , λ 2 ≥ 0 . 24 10 0 10 1 10 2 10 3 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ Rates for diﬀerent values of δ δ ∈ { 0 . 01 , 0 . 02 , 0 . 05 , 0 . 1 , 0 . 2 , 0 . 5 } Optimal Gradient rate , t = 2 m + L 10 0 10 1 10 2 10 3 10 − 1 10 0 10 1 10 2 10 3 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce Iterations for diﬀerent values of δ δ ∈ { 0 . 01 , 0 . 02 , 0 . 05 , 0 . 1 , 0 . 2 , 0 . 5 } Noise - free Gradient method , t = 2 m + L Figure 11 : Convergence rate and iterations to convergence for the gradient method with t = 1 L , for various noise parameters δ . This method is robust to noise . Applying this approach to the proximal version of Nesterov’s accelerated method , we recover the exact same plots as in Figure 3 . This is to be expected because it is known that the proximal gradient and accelerated methods achieves the same worst - case convergence rates as their unconstrained counterparts [ 1 , 25 , 38 ] . We conjecture that any algorithm G of the form ( 2 . 3 ) which converges with rate ρ has a proximal variant that converges at precisely the same rate . 5 . 4 Weakly convex functions We note that with a minor algorithmic modiﬁcation , we can immediately extend our results to the case where the function to be optimized is not strongly convex . The following development is due to Elad Hazan [ 9 ] . In this section , assume f ∈ S ( 0 , L ) . In other words , f is convex and diﬀerentiable with L - Lipschitz gradients , but we make no assumption about the strong convexity of f . Suppose we want to minimize f over a compact , convex domain D for which we can readily compute the Euclidean projection . For any such function f ε ( x ) = f ( x ) + ε 2 (cid:107) x (cid:107) 2 is diﬀerentiable and satisﬁes f ε ∈ S ( ε , L + ε ) . 25 10 0 10 1 10 2 10 3 10 4 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ Rates for diﬀerent values of δ δ ∈ { 0 . 05 , 0 . 1 , 0 . 2 , 0 . 3 , 0 . 4 , 0 . 5 } Optimal Nesterov rate 10 0 10 1 10 2 10 3 10 4 10 − 1 10 0 10 1 10 2 10 3 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce Iterations for diﬀerent values of δ δ ∈ { 0 . 05 , 0 . 1 , 0 . 2 , 0 . 3 , 0 . 4 , 0 . 5 } Optimal Nesterov iterations Figure 12 : Convergence rate and iterations to convergence for Nesterov’s method , for various noise parameters δ . Let R denote the diameter of the set D . Suppose we run an algorithm with interleaved projections as in Section 5 . 3 . Let x (cid:63) be any minimizer of f on D and x ( ε ) (cid:63) the minimizer of f ε . Let ρ denote the rate of convergence achieved when the condition number is set as κ = ( 1 + L / ε ) . Let σ denote the square - root of the condition number of the quadratic Lyapunov function P . After k steps we have f ( x k ) − f ( x (cid:63) ) = f ε ( x k ) − f ε ( x (cid:63) ) + ε 2 (cid:0) (cid:107) x k (cid:107) 2 − (cid:107) x (cid:63) (cid:107) 2 (cid:1) ≤ f ε ( x k ) − f ε ( x ( ε ) (cid:63) ) + ε 2 (cid:0) (cid:107) x k (cid:107) 2 − (cid:107) x (cid:63) (cid:107) 2 (cid:1) ≤ f ε ( x k ) − f ε ( x ( ε ) (cid:63) ) + ε 2 (cid:107) x k − x (cid:63) (cid:107) 2 ≤ ( L + ε ) σρ k (cid:107) x ( ε ) (cid:63) − x 0 (cid:107) 2 + ε 2 (cid:107) x k − x (cid:63) (cid:107) 2 ≤ (cid:0) ( L + ε ) σρ k + ε 2 (cid:1) R 2 . Therefore , if k ≥ log (cid:0) 2 ( 1 + L / ε ) σR 2 (cid:1) log ( ρ − 1 ) , 26 ¯ G ∇ f νT u y v w Figure 13 : Block - diagram representation of the standard interconnection with an addi - tional block νT representing a scaled sub - diﬀerential . then f ( x k ) − f (cid:63) ≤ ε . For Nesterov’s method , this means that k = O ( 1 √ ε log 1 ε ) iterations suﬃce to achieve an error of ε , and for the gradient method k = O ( 1 ε log 1 ε ) suﬃce . This analysis matches the standard analyses of Nesterov up to the logarithmic terms [ 23 ] . 6 Algorithm design In this section , we show one way in which the IQC analysis framework can be used for algorithm design . We saw in Section 5 . 2 that the gradient method can be very robust to noise ( Figure 11 ) , or not robust at all ( Figure 10 ) , depending on whether we use a stepsize of t = 1 / L or t = 2 / ( m + L ) , respectively . A natural question to ask is whether such a trade - oﬀ between performance and ro - bustness exists with Nesterov’s method as well . As can be seen in Figure 12 , Nesterov’s method is only somewhat robust to noise . In the sequel , we will synthesize variants of Nesterov’s method that explore the performance - robustness trade - oﬀ space . Consider an algorithm of the form ( 2 . 3 ) . Based on the discussion in Section 2 . 1 , we know A must have an eigenvalue of 1 . Moreover , given any invertible T , the algorithms ( A , B , C , D ) and ( TAT − 1 , TB , CT − 1 , D ) are equivalent realizations in the sense that if one is stable with rate ρ , the other is stable with rate ρ as well . Indeed , if the ﬁrst algorithm has state ξ k , the second algorithm has state Tξ k . We limit our search to the case A ∈ R 2 × 2 and D = 0 . Three parameters are required to characterize all possible algorithms in this family ( modulo equivalences due to a choice of T ) . One possible parameterization is given by (cid:34) A B C D (cid:35) =   β 1 + 1 − β 1 − α 1 0 0 β 2 + 1 − β 2 0   with : ( α , β 1 , β 2 ) ∈ R 3 ( 6 . 1 ) In light of the discussion in Section 2 , we see that the gradient , heavy - ball , and Nesterov methods are all special cases of ( 6 . 1 ) . In particular , ( α , β 1 , β 2 ) is equal to :   ( α , 0 , 0 ) for the gradient method ( α , β , 0 ) for the heavy - ball method ( α , β , β ) for Nesterov’s method 27 We may also rewrite ( 6 . 1 ) in more familiar recursion form as ξ k + 1 = ξ k − α ∇ f ( y k ) + β 1 ( ξ k − ξ k − 1 ) ( 6 . 2a ) y k = ξ k + β 2 ( ξ k − ξ k − 1 ) ( 6 . 2b ) Our approach is straightforward : for each choice of condition ratio L / m and noise strength δ , we generate a large grid of tuples ( α , β 1 , β 2 ) and used the approach of Sec - tion 5 . 2 to evaluate each algorithm . We then choose the algorithm with the lowest ρ . In other words , given bounds on the condition ratio and noise strength , we choose the algorithm for which we could certify the best possible convergence rate over all admissible choices of f and gradient noise . The performance of each optimized algorithm is plotted in Figure 14 . 10 0 10 1 10 2 10 3 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Condition ratio L / m C o n v e r g e n ce r a t e ρ Rates for diﬀerent values of δ δ ∈ { 0 . 01 , 0 . 1 , 0 . 2 , 0 . 3 , 0 . 4 , 0 . 5 } Optimal Nesterov rate 10 0 10 1 10 2 10 3 10 − 1 10 0 10 1 10 2 Condition ratio L / m I t e r a t i o n s t o c o n v e r g e n ce Iterations for diﬀerent values of δ δ ∈ { 0 . 01 , 0 . 1 , 0 . 2 , 0 . 3 , 0 . 4 , 0 . 5 } Optimal Nesterov iterations Figure 14 : Upper bounds found using a brute - force search over the three - parameter family of algorithms described by ( 6 . 2 ) . Convergence rate is shown ( ﬁrst plot ) as is the number of iterations required to achieve convergence to a speciﬁed tolerance ( second plot ) . In the second plot of Figure 14 , the algorithms robust to higher noise levels have greater slopes . When the noise level is low ( δ = 0 . 01 ) , we approach a slope of 0 . 5 , the same as Nesterov . When the noise level is high ( δ = 0 . 5 ) , the slope is roughly 0 . 75 . Note that the gradient method , which was robust for all noise levels , has a slope of 1 . Therefore , the new algorithms we found explore the trade - oﬀ between noise robustness and performance , 28 and may be useful in cases where Nesterov’s method would be too fragile and the gradient method would be too slow . 7 Future work We are only beginning to get a sense of what IQCs can tell us about optimization schemes , and there are many more control theory tools and techniques left to adapt to the context of optimization and machine learning . We conclude this paper with several interesting directions for future work . Reﬁned analysis Our analysis of Nesterov’s algorithm is computational , and predicts an upper bound over a large range of condition numbers that nearly matches Nesterov’s analysis . However , there is still a constant factor gap in the number of iterations , and deriving a tighter analysis may be possible using new IQCs . We are a bit surprised that we can certify Nesterov’s convergence rate for an algorithm that is not Nesterov’s , and explaining this gap in our analysis could provide new interesting insights about Nesterov’s algorithm . Furthermore , it may be possible to directly analyze the case of weakly convex functions using the IQC approach . A direct analysis would provide a path to removing the logarithmic factors introduced by our analysis . Analytic proofs One of the drawbacks of our numerical proofs is that we are always pushing up against numerical error and conditioning error . Analytic proofs would alle - viate this issue and could provide more interpretable results about how parameters of algorithms should vary to meet performance and robustness demands . To provide such analytic proofs , one would have to solve small LMIs in closed form . This amounts to solving small semideﬁnte programming problems , and this may be doable using analytic tools from algebraic geometry [ 8 , 35 ] . Lower Bounds Our IQC conditions are merely suﬃcient for verifying the convergence of an optimization problem . However , as pointed out by Megretski and Rantzer , the derived conditions are necessary in a restricted sense [ 19 ] . If we fail to ﬁnd a solution to our LMI , then there is necessarily a sequence of point that satisfy all of the IQC constraints and that do not converge to an equilibrium [ 20 , 37 ] . It is thus possible that this tool can be used to construct a convex function to serve as a counterexample for convergence . This intuition was what guided our construction of a counterexample for the convergence of the heavy - ball method . It may be possible that this construction can be generalized to systematically produce counterexamples . Time varying algorithms and adaptive control In many practical scenarios , we know neither the Lipschitz constant L nor the strong convexity parameter m . Under such conditions , some sort of estimation scheme is used to choose the appropriate step size . This could be a simple backoﬀ scheme to ensure a suﬃcient decrease , or a more intricate search method to ﬁnd the appropriate parameters [ 27 ] . From our control vantage point , it may be possible to use techniques from adaptive control to certify when such line search methods are stable . In particular , these could be used to diﬀerentiate between the diﬀerent sorts of schemes used to choose the parameters of the nonlinear conjugate gradient method . Another possible direction would be use optimal control techniques directly to choose algorithm parameters , possibly solving a small SDP at every iteration to choose new assignments . 29 Algorithm synthesis Perhaps even more ambitiously than using our framework for parameter selection , our initial results show that we can use IQCs as a way of designing new algorithms . We restricted our attention to algorithms with one - step of memory , as then we only had to search over 3 parameters . However , new techniques would be necessary to explore more complicated algorithms . Local search heuristics could be used here to probe the feasible region of the associated LMIs , but convex methods and convex relaxations may also be applicable and should be investigated for these searches . Noise analysis Our robustness analysis only allows us to consider certain forms of deterministic noise . Expanding our techniques to study stochastic noise would expand the applicability of our techniques and could provide new insight into popular stochastic optimization algorithms such as stochastic coordinate descent and stochastic gradient de - scent [ 22 , 24 ] . Many of the most common techniques for proving convergence of stochastic methods rely on Lyapunov - type arguments , and we may be able to generalize this ap - proach to account for the variety of diﬀerent methods . In order to expand our techniques to this space , we would need to introduce IQCs that were valid in expectation . Stability methods from stochastic control may be applicable to such investigations . Beyond convexity Since our analysis decouples the derivation of constraints on func - tion classes from the algorithm analysis , it is possible that it can be generalized to non - convex optimization . If we can characterize the function class by reasonable quadratic constraints , our framework immediately applies , and may lead to entirely new analyses for nonconvex function classes . For example , IQCs for saturating nonlinearities are read - ily available in the controls literature [ 15 , 19 ] . From a complementary perspective , if we know that our function is not merely convex , but has additional structure , this can be incorporated as additional IQCs . With extra constraints , it is possible that we can derive faster rates or more robustness for smaller function classes . Non - quadratic Lyapunov functions There has been substantial work in the past decade on eﬃcient algorithms to search over non - quadratic Lyapunov functions [ 29 , 30 ] . These techniques use sum - of - squares hierarchies to certify that non - quadratic polynomials are nonnegative , and still reduce to solving small semideﬁnite programming problems . This more general class of Lyapunov functions could be better matched to certain classes of functions than quadratics , and we could perhaps analyze more complicated algorithms and interconnections . Large - scale composite system analysis Perhaps the most ambitious goal of this program is to move beyond convex models and attempt to analyze complicated optimiza - tion systems used in science and industry . Powerful modeling languages like AMPL or GAMS allow for local analysis of large , complex systems , and certifying that the decisions about these systems are valid and safe would have impact in a variety of ﬁelds includ - ing process technology , web - scale analytics , and power management . Since our methods nicely abstract beyond two interconnected systems , it is our hope that they can be ex - tended to analyze the variety of optimization algorithms deployed to handle large , high throughput data processing . Acknowledgments We would like to thank Pete Seiler for many helpful pointers on time - domain IQCs and Elad Hazan for his suggestion of how to analyze functions that are not strongly convex . 30 We would also like to thank Ali Jadbabaie , Pablo Parrilo , and Stephen Wright for many helpful discussions and suggestions . LL and AP are partially supported by AFOSR award FA9550 - 12 - 1 - 0339 and NASA Grant No . NRA NNX12AM55A . BR is generously supported by ONR awards N00014 - 11 - 1 - 0723 and N00014 - 13 - 1 - 0129 , NSF award CCF - 1148243 , AFOSR award FA9550 - 13 - 1 - 0138 , and a Sloan Research Fellowship . This research was also supported in part by NSF CISE Expeditions Award CCF - 1139158 , LBNL Award 7076018 , and DARPA XData Award FA8750 - 12 - 2 - 0331 , and gifts from Amazon Web Services , Google , SAP , The Thomas and Stacey Siebel Foundation , Adobe , Apple , Inc . , C3Energy , Cisco , Cloud - era , EMC , Ericsson , Facebook , GameOnTalis , Guavus , HP , Huawei , Intel , Microsoft , NetApp , Pivotal , Splunk , Virdata , VMware and Yahoo ! . References [ 1 ] A . Beck and M . Teboulle . A fast iterative shrinkage - thresholding algorithm for linear inverse problems . SIAM Journal on Imaging Sciences , 2 ( 1 ) : 183 – 202 , 2009 . [ 2 ] S . Becker , E . J . Cand ` es , and M . Grant . Templates for convex cone problems with appli - cations to sparse signal recovery . Mathematical Programming Computation , 3 ( 3 ) : 165 – 218 , 2011 . [ 3 ] S . P . Boyd , L . El Ghaoui , E . Feron , and V . Balakrishnan . Linear matrix inequalities in system and control theory , volume 15 . SIAM , 1994 . [ 4 ] J . Carrasco , W . P . Heath , and A . Lanzon . On multipliers for bounded and monotone nonlinearities . Systems & Control Letters , 66 : 65 – 71 , 2014 . [ 5 ] J . Doyle . Analysis of feedback systems with structured uncertainties . Control Theory and Applications , IEE Proceedings D , 129 ( 6 ) : 242 – 250 , November 1982 . [ 6 ] Y . Drori and M . Teboulle . Performance of ﬁrst - order methods for smooth convex minimiza - tion : a novel approach . Mathematical Programming , pages 1 – 32 , 2013 . [ 7 ] M . Grant and S . Boyd . Graph implementations for nonsmooth convex programs . In V . Blon - del , S . Boyd , and H . Kimura , editors , Recent Advances in Learning and Control , Lecture Notes in Control and Information Sciences , pages 95 – 110 . Springer - Verlag Limited , 2008 . http : / / stanford . edu / ~ boyd / graph _ dcp . html . [ 8 ] D . R . Grayson and M . E . Stillman . Macaulay 2 , a software system for research in algebraic geometry , 2002 . [ 9 ] E . Hazan . Personal Communication . [ 10 ] W . P . Heath and A . G . Wills . Zames - Falb multipliers for quadratic programming . In IEEE Conference on Decision and Control , pages 963 – 968 , 2005 . [ 11 ] D . P . B . John N . Tsitsiklis and M . Athans . Distributed asynchronous deterministic and stochastic gradient optimization algorithms . IEEE Transactions on Automatic Control , 31 ( 9 ) : 803 – 812 , 1986 . [ 12 ] U . J¨onsson . A nonlinear Popov criterion . In IEEE Conference on Decision and Control , volume 4 , pages 3523 – 3527 , 1997 . [ 13 ] R . E . Kalman . Lyapunov functions for the problem of Lur’e in automatic control . Proceedings of the National Academy of Sciences , 49 ( 2 ) : 201 , 1963 . [ 14 ] H . K . Khalil . Nonlinear systems ( 3rd edition ) . Prentice Hall , 2002 . [ 15 ] V . Kulkarni , S . K . Bohacek , and M . G . Safonov . Robustness of interconnected systems with controller saturation and bounded delays . In Proceedings of the American Control Conference , 1999 . [ 16 ] J . L¨ofberg . YALMIP : A toolbox for modeling and optimization in MATLAB . In Proceedings of the CACSD Conference , Taipei , Taiwan , 2004 . 31 [ 17 ] A . Lur’e and V . Postnikov . On the theory of stability of control systems . Applied mathe - matics and mechanics , 8 ( 3 ) : 246 – 248 , 1944 . In Russian . [ 18 ] A . M . Lyapunov and A . Fuller . General Problem of the Stability Of Motion . Control Theory and Applications Series . Taylor & Francis , 1992 . Original text in Russian , 1892 . [ 19 ] A . Megretski and A . Rantzer . System analysis via integral quadratic constraints . IEEE Transactions on Automatic Control , 42 ( 6 ) : 819 – 830 , 1997 . [ 20 ] A . Megretski and S . Treil . Power distribution inequalities in optimization and robustness of uncertain systems . Journal of Mathematical Systems , Estimation , and Control , 3 ( 3 ) : 301 – 319 , 1993 . [ 21 ] A . Nemirovski . The long - step method of analytic centers for fractional problems . Mathe - matical Programming , 77 ( 1 ) : 191 – 224 , 1997 . [ 22 ] A . Nemirovski , A . Juditsky , G . Lan , and A . Shapiro . Robust stochastic approximation approach to stochastic programming . SIAM Journal on Optimization , 19 ( 4 ) : 1574 – 1609 , 2009 . [ 23 ] Y . Nesterov . Introductory lectures on convex optimization : A basic course , volume 87 of Applied Optimization . Kluwer Academic Publishers , Boston , MA , 2004 . [ 24 ] Y . Nesterov . Eﬃciency of coordinate descent methods on huge - scale optimization problems . SIAM Journal on Optimization , 22 ( 2 ) : 341 – 362 , 2012 . [ 25 ] Y . Nesterov . Gradient methods for minimizing composite functions . Mathematical Pro - gramming , 140 ( 1 ) : 125 – 161 , 2013 . [ 26 ] Y . Nesterov and A . Nemirovskii . Interior - point polynomial methods in convex programming . SIAM , 1994 . [ 27 ] J . Nocedal and S . J . Wright . Numerical Optimization . Springer , New York , second edition , 2006 . [ 28 ] A . Packard and J . Doyle . The complex structured singular value . Automatica , 29 ( 1 ) : 71 – 109 , 1993 . [ 29 ] A . Papachristodoulou and S . Prajna . On the construction of lyapunov functions using the sum of squares decomposition . In Decision and Control , 2002 , Proceedings of the 41st IEEE Conference on , volume 3 , pages 3482 – 3487 . IEEE , 2002 . [ 30 ] P . A . Parrilo and S . Lall . Semideﬁnite programming relaxations and algebraic optimization in control . European Journal of Control , 9 ( 2 ) : 307 – 321 , 2003 . [ 31 ] B . T . Polyak . Introduction to optimization . Optimization Software , Inc . , 1987 . [ 32 ] V . - M . Popov . Absolute stability of nonlinear systems of automatic control . Automation and Remote Control , 22 ( 8 ) : 857 – 875 , 1962 . Original text in Russian , 1961 . [ 33 ] A . Rantzer and A . Megretski . Stability criteria based on Integral Quadratic Constraints . In IEEE Conference on Decision and Control , volume 1 , pages 215 – 220 , 1996 . [ 34 ] A . Rantzer and A . Megretski . System analysis via Integral Quadratic Constraints , part II . Technical Report ISRN LUTFD2 / TFRT - - 7559 - - SE , Department of Automatic Control , Lund University , Sweden , Apr . 1997 . [ 35 ] P . Rostalski and B . Sturmfels . Dualities in convex algebraic geometry . arXiv preprint arXiv : 1006 . 4894 , 2010 . [ 36 ] P . Seiler . Nonlinear stability analysis with dissipation inequalities and integral quadratic constraints . submitted to the IEEE Transactions on Automatic Control , 2013 . [ 37 ] J . Shamma . Robustness analysis for time - varying systems . In Proceedings of the 31st IEEE Conference on Decision and Control , 1992 . [ 38 ] P . Tseng . On accelerated proximal gradient methods for convex - concave optimization . sub - mitted to SIAM Journal on Optimization , 2008 . 32 [ 39 ] J . C . Willems . Dissipative dynamical systems—Part I : General theory and Part II : Lin - ear systems with quadratic supply rates . Archive for Rational Mechanics and Analysis , 45 ( 5 ) : 321 – 351 , 352 – 393 , 1972 . [ 40 ] V . A . Yakubovich . Frequency conditions for the absolute stability of control systems with several nonlinear or linear nonstationary units . Avtomatika i Telemekhanika , pages 5 – 30 , 1967 . In Russian . [ 41 ] V . A . Yakubovich . S - procedure in nonlinear control theory . Vestnik Leningrad University , 4 : 73 – 93 , 1977 . Original text in Russian , 1971 . [ 42 ] V . A . Yakubovich . Nonconvex optimization problem : The inﬁnite - horizon linear - quadratic control problem with quadratic constraints . Systems & Control Letters , 19 ( 1 ) : 13 – 22 , 1992 . [ 43 ] G . Zames . On the input - output stability of time - varying nonlinear feedback systems— Part I : Conditions derived using concepts of loop gain , conicity , and positivity , and Part II : Conditions involving circles in the frequency plane and sector nonlinearities . IEEE Transactions on Automatic Control , 11 ( 2 , 3 ) : 228 – 238 , 465 – 476 , 1966 . [ 44 ] G . Zames and P . L . Falb . Stability conditions for systems with monotone and slope - restricted nonlinearities . SIAM Journal on Control , 6 ( 1 ) : 89 – 108 , 1968 . A Proof of Proposition 1 Let Q have eigenvalues 0 < m ≤ λ d ≤ λ d − 1 ≤ · · · ≤ λ 2 ≤ λ 1 ≤ L . Throughout , let T be the closed loop system T : = A + BQC . A . 1 The gradient method The closed loop system has state transition matrix T = I − αQ with our choice of α , one can readily check that the eigenvalues of T have magnitude at most κ − 1 κ + 1 . A . 2 Nesterov’s method Note that T = (cid:20) ( 1 + β ) ( I d − αQ ) − β ( I − αQ ) I 0 (cid:21) We will upper bound the spectral radius of T by explicitly computing all of the eigenvalues and upper bounding their magnitudes . To proceed , write the eigenvalue decomposition of Q as Q = U 0 Λ U T 0 , where Λ = diag ( λ 1 , λ 2 , . . . , λ d ) . By deﬁning the permutation matrix Π as follows : Π ij =    1 i odd , j = ( i + 1 ) / 2 1 i even , j = d + ( i / 2 ) 0 otherwise . 33 we have by applying a similarity transformation to the matrix T that Π (cid:20) U 0 0 0 U 0 (cid:21) T (cid:20) ( 1 + β ) ( I − αA ) − β ( I − αA ) I 0 (cid:21) (cid:20) U 0 0 0 U 0 (cid:21) Π T = Π (cid:20) ( 1 + β ) ( I − α Λ ) − β ( I − α Λ ) I 0 (cid:21) Π T =   T 1 0 · · · 0 0 T 2 · · · 0 . . . . . . . . . . . . 0 0 · · · T d   , where T i = (cid:20) ( 1 + β ) ( 1 − αλ i ) − β ( 1 − αλ i ) 1 0 (cid:21) , i = 1 , 2 , . . . , d . The eigenvalues of T are the eigenvalues of T i , for i = 1 , 2 , . . . , d . The eigenvalues of T i are the roots of the following quadratic : ν i , j 2 − ( 1 + β ) ( 1 − αλ i ) ν i , j + β ( 1 − αλ i ) = 0 , ( A . 1 ) which are given by the formula for the quadratic equation : ν i , 1 = 1 2 (cid:104) ( 1 + β ) ( 1 − αλ i ) + i (cid:112) 4 β ( 1 − αλ ) − ( 1 + β ) 2 ( 1 − αλ i ) 2 (cid:105) , ν i , 2 = 1 2 (cid:104) ( 1 + β ) ( 1 − αλ i ) − i (cid:112) 4 β ( 1 − αλ ) − ( 1 + β ) 2 ( 1 − αλ i ) 2 (cid:105) . The two roots are distinct complex numbers when 1 − αλ i > 0 and ( 1 + β ) 2 ( 1 − αλ i ) < 4 β < 0 , which happens when with our choice of α and β when m < λ < L . When λ = L , ν i , 1 = ν i , 2 = 0 . When λ = m , ν i , 1 = ν i , 2 = 1 − (cid:112) m / L . It remains to bound the magnitude of the ν i , j for when λ i ∈ ( m , L ) . Note that (cid:112) β (cid:114) 1 − λ i L ≤ (cid:112) β (cid:114) 1 − m L = (cid:18) √ L − √ m √ L + √ m · L − m L (cid:19) 1 / 2 = (cid:18) √ L − √ m √ L + √ m · ( √ L − √ m ) ( √ L + √ m ) L (cid:19) 1 / 2 = √ L − √ m √ L = 1 − (cid:112) m / L which veriﬁes our bound on the spectral radius . A . 3 The heavy - ball method The proof is very similar to the proof of Nesterov’s method . For the heavy - ball method T : = (cid:20) ( 1 + β ) I − αA − βI I 0 (cid:21) Let U 0 and Π be as in Section A . 2 . Applying a similarity transformation T , we have Π (cid:20) U 0 0 0 U 0 (cid:21) T (cid:20) ( 1 + β ) I − αA − βI I 0 (cid:21) (cid:20) U 0 0 0 U 0 (cid:21) Π T = Π (cid:20) ( 1 + β ) I − α Λ − βI I 0 (cid:21) Π T =    T 1 0 · · · 0 0 T 2 · · · 0 . . . . . . . . . . . . 0 0 · · · T n    , 34 where T i = (cid:20) 1 + β − αλ i − β 1 0 (cid:21) , i = 1 , 2 , . . . , n . The eigenvalues of T are the eigenvalues of T i , for i = 1 , 2 , . . . , n . The eigenvalues of T i are the roots of the following quadratic : ν i , j 2 − ( 1 + β − αλ i ) ν i , j + β = 0 , ( A . 2 ) which are given by ν i , 1 = 1 2 (cid:104) ( 1 + β − αλ i ) + (cid:112) ( 1 + β − αλ i ) 2 − 4 β (cid:105) ν i , 2 = 1 2 (cid:104) ( 1 + β − αλ i ) − (cid:112) ( 1 + β − αλ i ) 2 − 4 β (cid:105) . The two roots are distinct complex numbers when ( 1 + β − αλ i ) 2 − 4 β < 0 , which happens when β ∈ (cid:16) ( 1 − √ αλ i ) 2 , ( 1 + √ αλ i ) 2 (cid:17) . ( A . 3 ) This occurs with our choice of parameters , completing the proof . B Proof of the heavy - ball counterexample The limit cycle has a period of 4 , and follows the pattern { ( r + q ) , ( r − p ) , ( r − q ) , ( r + p ) , ( r + q ) , . . . } where ( r + p ) > 0 , ( r + q ) > 0 , ( r − p ) < − 3 , and ( r − q ) < − 3 . Substituting directly into the heavy - ball equations , we obtain a system of linear equations that can be solved for r , p , and q . The result is that r = − 45 32 , p = 315 169 , q = 765 169 If { x (cid:63)k } k ≥ 0 is the limit - cycle sequence , consider a perturbed version of this sequence { x (cid:63)k + ε k } k ≥ 0 . If we assume that the k th iterate still belong to the same piece of the function ( i . e . if x (cid:63)k > 0 then x (cid:63)k + ε k > 0 , and if x (cid:63)k < − 3 then x (cid:63)k + ε k < − 3 ) then we can use the heavy - ball equations to compute the perturbation in the subsequent iterate . Upon doing so , we ﬁnd that { ε k } k ≥ 0 must satisfy (cid:20) ε k + 2 ε k + 1 (cid:21) = (cid:20) − 2425 − 35 1 0 (cid:21) (cid:20) ε k + 1 ε k (cid:21) for all k If P is the above transformation matrix , one can check that (cid:13)(cid:13) P 3 (cid:13)(cid:13) 2 = 66389913 + 62712 √ 413626 244140625 ≈ 0 . 437 < 1 2 where (cid:107) · (cid:107) is the induced 2 - norm . Therefore , P 3 is contractive , and we have : ε 2 k + 3 ≤ (cid:13)(cid:13)(cid:13)(cid:13)(cid:20) ε k + 4 ε k + 3 (cid:21)(cid:13)(cid:13)(cid:13)(cid:13) 2 ≤ (cid:13)(cid:13) P 3 (cid:13)(cid:13) 2 (cid:13)(cid:13)(cid:13)(cid:13)(cid:20) ε k + 1 ε k (cid:21)(cid:13)(cid:13)(cid:13)(cid:13) 2 < 1 2 ( ε 2 k + 1 + ε 2 k ) Therefore , if three consecutive values { ε 2 i , ε 2 i + 1 , ε 2 i + 2 } are each less than some ¯ ε 2 , the entire tail { ε 2 k } k ≥ i also satisﬁes this bound . The closest that the limit cycle comes to a transition point of f ( x ) ( either 0 or − 3 ) is ( − 3 ) − ( r − p ) = 14615408 ≈ 0 . 270 . Therefore , if we set this number to be ¯ ε , and we can ﬁnd three consecutive iterates of the heavy - ball method that are each within ¯ ε of the limit cycle , then the remaining iterates must converge exponentially to the limit cycle . One can check that if x 0 = 2 , then the iterates x 8 , x 9 , x 10 satisfy the desired property . This completes the proof . 35