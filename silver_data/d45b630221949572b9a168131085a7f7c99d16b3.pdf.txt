1 TAPRAV : A Tool for Exploring Physiological Data Aligned to Task Models Piotr D . Adamczyk † , Christopher W . Busbey ‡ , Brian P . Bailey * University of Illinois at Urbana - Champaign A BSTRACT The use of continuous , physiological measures such as pupil size is becoming increasingly important in user interface design , attention management , and affective computing . While this data is best explored in context of ongoing task execution , existing information visualizations do not support such exploration . In this design study , we present an interactive tool called TAPRAV , which provides an interactive focus + context visualization of physiological data aligned to a hierarchical model of task execution . This visualization , along with built - in data analysis tools , allows users to rapidly explore relationships among the data that would otherwise be extremely difficult to recognize . We present lessons from the iterative design process that led to our particular implementation and show how features of our tool help bridge rationale and worldview gaps . Our work contributes a tool that can be used to aid ongoing efforts in specific research areas and lessons learned from following an iterative design process can inform the development of similar tools . ACM Categories and Subject Descriptors : H . 5 . 2 [ Information Interfaces and Presentation ] : User Interfaces – Prototyping , User - centered design . I . 3 . 6 [ Computer Graphics ] : Methodology and Techniques – Interaction techniques . Keywords : workload , focus + context , pupil size , iterative design 1 I NTRODUCTION To explore user interaction with complex systems , researchers have begun using streams of continuous data to study human task engagement or workload . Often the measure of task engagement is physiological like GSR [ 11 ] , HRV [ 41 ] , EEG [ 21 ] , or pupillary response [ 18 ] , and this data is used for attention management [ 18 , 19 ] , affective computing [ 32 ] , and user interface design [ 14 , 26 ] . For example , designers could align mental workload to a model of task execution and target areas of unacceptably high workload in the interface for re - design . Our work has used workload aligned to task models to identify opportune moments for interruption [ 19 ] . In these and many other cases , the physiological data is best understood in context of the ongoing task – as changes in the data are often tied directly to changes in the execution of the task . Unfortunately , this area of research is hindered by the difficulty of examining this kind of data in context of models of task execution [ 18 ] . For example , analysis software that ships with commercial eye trackers does not typically provide an aligned view of pupil dilation , task models , and screen interaction videos . This inhibits the researcher’s ability to explore workload in detail at specific points in the task . This is due not only to the lack of effective tools , but also to the lack of thorough evaluations of the visualizations used in those tools . This can lead to rationale and worldview gaps , as described by Amar and Stasko [ 3 ] . In this design study , we present an interactive visualization tool called TAPRAV ( Task Aligned Pupillary Response Analysis and Visualization ) . As shown in Figure 1 , our tool provides a focus + context visualization of a continuous data stream aligned to a hierarchical model of task execution and video of on - screen interaction . This allows users to explore relationships that would otherwise be difficult to recognize . In addition to discussing our tool’s features , we discuss lessons from an iterative design process that led to our implementation , which helps bridge rationale and worldview gaps . Our work provides the following contributions : • We provide a tool tailored to aid ongoing research in our target domain . For example , Iqbal et al . ’s [ 18 ] analysis of pupillary response data consisted of tedious labor and complex macro writing . Through our discussions and subsequent evaluations with researchers in this domain , we have produced a tool that effectively meets those needs . † email : pdadamcz @ uiuc . edu ‡ email : chris . busbey @ gmail . com * email : bpbailey @ uiuc . edu Figure 1 - TAPRAV running in a dual display environment . The large screen shows the task model and pupil response curve visualization . In the foreground , a researcher tries to make sense of a particular change in workload by examining the task model and viewing the integrated video of task execution . 2 • We show how a sequence of low investment evaluations can overcome gaps found in domain specific visualizations [ 3 , 8 ] . By following an iterative design process , we learned design lessons that can be reused when building similar tools . This further supports the value of iterative design for developing information visualizations . • We designed the architecture of our visualization to support analysis of any continuous data stream aligned to any hierarchical model . This allows our tool to be used by a broad range of target application domains . 2 R ELATED W ORK We discuss our problem domain in some detail , visualizations that motivated the initial prototypes we considered , and our approach to the visualization of continuous data . 2 . 1 Use of Physiological Data Physiological data can be used in many research areas such as interface design [ 14 , 26 ] , affective computing [ 32 ] , and attention management [ 18 , 19 ] . To illustrate our specific design problem , we discuss how a particular physiological measure of workload ( pupillary response ) was used for interruption management . Research shows that pupil size is a reliable indicator of mental workload [ 5 , 20 ] . Rapid advances in eye tracking hardware are now enabling a broader range of researchers to exploit the use of pupil size for interface design , interruption management , and other research . For example , researchers have proposed using mental workload ( as measured by pupil size ) as a new metric by which to evaluate complex interfaces [ 26 , 27 ] . Also , researchers are using workload to identify moments in a task sequence that would be most opportune for interruption [ 15 - 17 ] . Researchers have postulated that opportune moments for interruption occur at periods of low mental workload [ 4 , 9 , 13 ] , and that these moments occur at subtask boundaries in the task model [ 29 ] . It remains an open question as to which boundaries are most appropriate for interruption . We investigated how a user’s mental workload changes during execution of an interactive task [ 18 ] , focusing on subtask boundaries . After developing a validated GOMS model for the task , and aligning it with the pupillary response data , analysis was attempted with software packages that shipped with two existing eye trackers . However , the software was not able to meet our needs and as a result , the analysis process required significant tedious labor and complex macro writing . For this design study , and guided by our experience with existing tools , we aim to provide an effective visualization that significantly reduces the complexity of similar data analysis processes . 2 . 2 Motivating Visualizations For visualizations of datasets requiring large and complex layout space , an appropriate visualization metaphor aids in navigation . Spence and Apperley proposed a number of novel approaches for retrieving information in an office environment [ 37 ] . They addressed the problem of data context , specifically how a user could quickly become aware of the entire contents of an in - tray and rapidly examine any individual item in detail . They proposed a bifocal display partitioned into 3 separate viewports ; focused central viewport with full detail , and two flanking , de - magnified views of the entire contents of the in - tray . Users would select an item for interest and drag it to the central viewport for closer inspection , similar to a Fisheye Lens [ 12 ] . A fisheye lens is used to produce very wide - angle aspect ratios , making areas directly ahead appear in greater detail , while off - focus regions are shown in progressively less detail . This makes it is possible to maintain focus while being aware of surrounding context . The Focus + Context paradigm has since been the basis for a variety of visualization techniques . In Document Lens [ 35 ] , a 3D visualization for exploring multi - page documents , users grab a rectangular lens and move it to focus on an area of interest at a chosen magnification level . Sarkar et al . [ 36 ] proposed a rubber sheet metaphor for visualizing large and complex layouts within small display areas . The original layout is rendered on a rubber sheet that users hold and stretch with a set of tools called handles . This approach allows the user to hold multiple regions of interest and assures their content is rendered with uniform scaling . Zoomable User Interfaces ( ZUIs ) , and related drill - down techniques , are another method for visualizing complex or large data sets [ 6 , 10 , 31 , 39 , 40 ] . ZUIs display information on a high resolution virtual canvas , a portion of which is displayed through a virtual camera that pans and zooms over the canvas surface . Both ZUIs and focus + context visualizations motivated our initial design . As we outline later , through our process of prototype evaluations , users gave invaluable feedback , narrowing the design space by pointing out overly complex or non - intuitive parts of the visualizations and interactions . 2 . 3 Continuous Data Visualization Mackinlay et al . [ 25 ] address common issues involving visualization of time - varying data . These visualizations in particular often contain linear components that can result in 2D layouts with wide and inefficient aspect ratios . As a solution , they outline The Perspective Wall : a visualization metaphor for viewing linear information by smoothly integrating detailed and contextual views in a three - dimensional space . Navigation is accomplished by a panning motion across the wall . The Hierarchical Video Magnifier [ 28 ] allows users to work with video content at varying levels of detail while keeping awareness of the timeline . The coarsest view is at the top of the hierarchy , and users decompose the timeline into children clips , drilling in and out to navigate the dataset . Other techniques have been used for additional facets of video content manipulation [ 1 , 7 ] . Time - varying visualizations are also common in information technology [ 33 ] and various medical visualization needs [ 22 ] . Our own needs when dealing with continuous data were governed by the requirements of our users . Namely , our design required a distortion free representation that could easily show the relationship between time and moments in the task model . Though our visualization is not necessarily novel , our contribution is in composing a visualization from elements of related work , producing a tool that more directly addresses a real world need . 3 G OALS AND I TERATIVE D ESIGN In this section , we outline our design goals for developing an effective tool for analyzing pupil data aligned to task models . Then , we discuss the process through which an interface and visualization that meets these goals was developed ; performing a user and task analysis followed by an iterative design process . 3 . 1 Design Goals To identify goals for building an effective visualization tool , we worked with researchers familiar with pupillary response analysis , learned from the limitations of existing analysis software , and applied several proven information visualization techniques . This process resulted in several key design goals : • Provide a simple and intuitive visualization of pupillary response aligned with a task model and allow for direct 3 manipulation . We wanted to provide researchers with an immediately usable and useful tool that would aid them in related research efforts . • Design interaction mechanisms that support a discovery driven analysis process . This means providing functions that allow researchers to capture meaningful parts of the analysis for later review and collaboration . • Use a visual vocabulary and interface elements understood by researchers interested in pupillary response analysis . An interface that better matches a user’s mental model of the problem domain would allow them to focus more on the analysis task and less on interacting with the visualization . • Support any continuous data aligned to any task model . Our immediate interest is for pupillary response aligned with hierarchical task models , but the visualization should be flexible enough to support other data and task models . Although our current implementation may not fully meet all of these design goals , we felt that it was important to define them up front to guide our design decisions throughout the process . 3 . 2 User and Task Analysis As a first step in the design process , we performed a detailed analysis of the tool’s intended audience and their tasks . The audience for the tool was mainly computer scientists and psychologists working with physiological data and task models . This community is currently small , but growing , and our experience indicates that there is a large need for better tools . We performed a task analysis to identify common and important tasks . These tasks included importing various data sets , clamping data sources to a common timeline , zooming in and out of the visualization , and retrieving statistical information for selected parts of the task . While not exhaustive , we felt that these tasks would most influence the early design of our tool . As such , these tasks were used to evaluate successive interface designs . 3 . 3 Low Fidelity Iterations To develop an interactive visualization that met our design goals , we followed an iterative design process [ 34 ] . This involved building low fidelity paper prototypes , evaluating them with users , and using the lessons learned to refine the prototypes . Rather than having users interact with the low fidelity prototypes directly , we used video prototyping techniques to give users a more realistic simulation of the interaction . Following procedures in [ 24 ] , we recorded numerous short video clips of task sequences that the prototype supported , asked users to view the clips , ask questions , and comment on the tool’s interaction and visualization design . The value of iterative design in information visualization is in the rapid exploration of a design space with minimal investment . In our iterations below , major flaws that may have contributed to rationale or worldview gaps [ 3 ] were caught without the time and effort required to build fully functional visualizations . Also , due to the comments received early in the design process , the overall structure of our tool ( related to both interaction and visualization ) changed dramatically from the initial concept . We believe the practice of iterating on low fidelity prototypes is useful for many information visualization applications , and support this point by showing how our tool evolved from concept to implementation . While many design iterations were performed , we discuss three representative examples next . In each evaluation of a prototype , the number of user ranged from 3 - 5 . Figure 2 – A frame from a low fidelity prototype video . The task model occupies the top third of the visualization . The central portion is the global pupillary response curve , with the local curve immediately below ( in a separate overlay , not pictured ) . 3 . 3 . 1 Iteration 1 – Drill - down Metaphor As shown in Figure 2 , the initial visualization used a focus + context view for the pupillary response graph and a drill - down metaphor for exploring the task hierarchy . Users were presented with a view of the task model with only the top level rendered . To inspect lower levels of the task hierarchy , the user would click individual task nodes to drill down and recursively split the node into component subtasks . By clicking the subtask root , the view would back up a level , effectively moving to the parent subtree , merging the nodes . In addition to the task model , the interface included a viewport into a timeline showing the response curve . Evaluation showed that this design was too complicated for exploring the data . Users were often disoriented when navigating the hierarchy . The drilling interaction was confusing and non - intuitive . But , in general , users liked the block metaphor for representing subtasks , as well as alignment of the local viewports . Users also requested an extension of the focus + context metaphor for the task hierarchy . Figure 3 – In this prototype , a focus + context visualization was extended to the task model with the two local viewports aligned in the center . Additional buttons were added for navigation and zooming by constant factors . 4 3 . 3 . 2 Iteration 2 – Orthogonal View Influenced by this feedback , our second iteration ( Figure 3 ) used a two dimensional orthogonal view for the task model . The height of the subtask blocks was reduced to fit the entire task model in the viewport . Higher levels of the model were placed towards the top of the visualization . These changes removed the need for the drilling interaction . We added a fourth viewport allowing for a focus + context view of the task model as well as the pupil graph , as in iteration 1 . Temporal zooms could be performed in any of these time - aligned viewports . A selection of a range of time in a local viewport leads to highlighted regions in both the task model and pupillary response global viewports . We also added buttons for shifting the focus by a constant factor and for navigating between view states . The feedback from evaluations of this new design was much more positive , with users finding it simpler to understand and follow . However , users wanted the visualization to better convey relationships between the local and global viewports and the alignment between the two data sets . Our next step was to address these issues and refine the interface with a higher level of detail . Figure 4 – A refinement of the interface used in Iteration 2 . 3 . 3 . 3 Iteration 3 – Refined Orthogonal View We added drawings of interface components such as menus and other controls , perspective guide lines that associated the local frame to the relative span in the global frames . See Figure 4 . This technique was also used in [ 28 , 38 ] . Panels were added to the main window for statistics and notes . A selection frame specifies the region for which a detailed statistical analysis is provided , and can be defined in either local viewport . To mimic diagrams in [ 18 ] , we included an interface control that allowed users to overlay task boundaries on the pupillary response curve . This allows users to gain a stronger sense of how the curve aligned to the task model . We also added views to allow users to index and switch between different perspectives on the data . At this stage user comments suggested that a significant number of the large scale usability issues had been addressed , and that a functional prototype would now be more appropriate for capturing finer - grained interaction and visualization issues . 3 . 4 Functional Design Iterations From the lessons learned in the low fidelity iterations , and following our own design discussions , we produced a computer - based prototype . All of the key design components from the most recent low fidelity prototype were implemented for the functional prototype . We performed additional formative evaluations using the functional prototype . Unlike the first set of evaluations , during these sessions the users were asked to perform tasks with the tool directly rather than watch video recordings of the tasks . Figure 5 – The initial functional prototype . Focus + context views for both the task model ( above ) and response curve ( below ) are presented . The local viewports are grouped in the center , with the global viewports at the top and bottom . 3 . 4 . 1 Iteration 1 – Functional prototype Our first functional prototype is shown in Figure 5 . Users found the statistics and notes panels a welcome addition , as well as the tabbed perspectives interface . However , we were surprised to find that the guide lines that had no influence in the low fidelity prototypes were found to be distracting in the functional prototype . The value of the lines was recognized by the users ; however , the angle of the lines produced a disorienting 3D effect . Similarly , feedback on the task boundaries overlay was mostly positive , but the interface control for selecting the drawn boundaries was found to be counter - intuitive . Many of the users thought that the checked boxes indicated that the boundaries for that level would not be drawn ( opposite of the actual function ) . Users indicated a desire to move and resize the magnification lens directly in the global viewports . We also found that color deficient users had difficulty in discerning the color mapping used in the task model hierarchy . 3 . 4 . 2 Iteration 2 – Final prototype From the lessons in the preceding evaluation , we made a number of changes to the functional prototype , and added several features . As shown in Figure 6 , this prototype includes video playback functionality , along with notes and statistics panels . These panels were displayed as separate windows from the main visualization window . Based on user suggestions from previous evaluations , we made a significant change to the how the viewports were positioned . The two local and the two global viewports were now adjacent to each other ( contrast Figure 6 with Figure 5 ) . This allowed us to collapse the two distinct magnification lenses in the previous design into just one lens , which could be manipulated from either viewport . The guidelines from the previous design were removed , the color mapping of tasks was resolved , and the controls for selecting whether to view the boundary overlays were redesigned . 5 4 TAPRAV In this section , we outline the key features of the most current implementation of TAPRAV , how they aid users in their analysis tasks , and how various features help combat rationale and worldview gaps [ 3 ] . 4 . 1 Pupillary Response Visualization Pupil size is plotted on the vertical axis over a horizontal timeline , and is measured as a percentage change in pupil size . This was done to make the visualization consistent with common research practices [ 18 ] . The red line running horizontally across the pupil response viewport represents the baseline value ( 0 % PCPS ) . Both the vertical and horizontal axes are of linear scale . Placing the mouse over a point on the graph displays the PCPS for that particular point , allowing for immediate and detailed data inspection . 4 . 2 Task Model Visualization A rectangular block represents each task in the task model . The width of a given task block corresponds to the duration of the task . The name of a given task block is drawn within the bounds of the block ( space permitting ) . For more detailed information for a given task block , the researcher passes the mouse cursor over the task block for a tool - tip task summary . The task model itself is composed of a collection of these task blocks . The ordering of the task blocks along the timeline gives the ordering relationships of the tasks in the model . The task hierarchy is shown by placing the blocks into successive horizontal rows from top to bottom . 4 . 3 Focus + Context : The Local and Global Frames Given the high sampling rate of eye tracking hardware and the long durations of experimental trials , it is a significant challenge to manage large data sources during analysis . TAPRAV supports a focus + context framework to aide the researcher in navigating these large datasets . The viewport visualizations of the task model Figure 6 – In our final prototype , the two local and the two global viewports are adjacent to each other ( local on top ) . Functionality includes the ability to play video content bounded by the time span of the local viewport . To allow the tool windows to be moved and sized independently , including being moved to additional monitors ( see Figure 1 ) , the video , statistics , and notes windows were separated from the main visualization . Based on lessons learned from evaluations of the previous prototypes , this prototype used a new color mapping for the task model as well as a new interface control for toggling task model boundary overlays . 6 and pupillary response are replicated twice , once in the local and again in the global frame . The viewports of these two frames are aligned by time . This design allows the researcher to explore an area of interest while still being aware of the overall data context . The top - most portion of the visualization panel is reserved for the local “zoomed - in” frame of the task model and pupil data . The local frame viewports are slightly larger and offer higher fidelity labels than their global frame counterparts . The researcher uses the viewports for detailed analysis . The bottom - most portion of the visualization panel holds the global frame of the task model and pupil data . The magnification lens , represented by a blue rectangle , is shown in the global frame and defines the time span of the data shown in the local frame . The global frame is useful for identifying approximate areas of interest during the analysis and discovery process . 4 . 4 Setting the Global and Local Frames With a potentially very large data set , the researcher may be concerned with only a fraction of the collected data . Menu bar actions allow the user to set the global frame to cover a portion of the imported data . To set the local frame , the user zooms in on an area of interest by sweeping across one of the local frames to zoom in on the area of interest . Upon releasing the mouse button , both of the local viewports are adjusted to reflect this selection ( which zooms in on the data ) . The magnification lens is consistent with the time span of the local frame . When inside of the magnification lens , the cursor becomes a “sticky hand” cursor , and the lens can be moved within the bounds of the global frame by dragging . When released , the local frame will adjust to match the repositioned lens . 4 . 5 Video Playback Imported video content is visible in a popup player window . The video clip in this player window corresponds to the time span of the local frame . During video playback , the current frame is represented by a moving red vertical line displayed in visualization panel . The availability of video , and its alignment with the task model and response curve , helps researchers examine important features in the data in greater detail , and gain confidence when attributing changes in the response graph to specific user behavior . 4 . 6 Overlaying Task Boundaries To get a better sense of task model and pupil data alignment , TAPRAV includes a feature to render task boundaries over the local pupil visualization . This gives users an immediate visual cue when inspecting the task model and response curve for notable alignments . The interface control to the right of the local task model viewport is used to control the task level boundaries that are drawn over the local pupil response viewport . The interface control is composed of a column of colored cells matching the task level colors . A black bracket on the right of this column covers the range of task levels boundaries that will be drawn to the local pupil viewport . Showing boundaries is important for gaining a more precise understanding of the alignment and for analyzing how workload changes at these points during task execution . 4 . 7 Selection and Statistical Analysis If an interesting pupil response feature is identified , the user can request statistical details of the area . The user can open a dialog window showing statistics from the global , local , and currently selected frames . Mean , minimum , and maximum pupil size , as well as standard deviation are presented in tabular form for each of these frames . This feature in particular aids researchers in confirming that the salient features in the visualization are actually statistically meaningful . 4 . 8 Multiple Views and Comments By supporting multiple views , TAPRAV allows users to save particular views of the data and return to them later . For each view , the tool records the current global , local , and selection frame . Views are controlled through a tabbed interface , shown at the bottom of the visualization panel . Any number of views can be created and , when selected , the tool sets the current view to the stored values . This feature allows users to save snapshots of interesting parts of the data while continuing to explore other parts of the data in the same session . Those views can also be examined by collaborators wanting to review the data . For each view , a user can enter comments into a notes dialog . Notes associated with a particular view are available whenever the corresponding view is active . 5 I MPLEMENTATION TAPRAV was coded in Java , consisting of approximately 5 , 000 lines of code . Java was chosen for both the relative ease afforded for multi - platform development and the vast number of APIs available . The viewports in TAPRAV are drawn using the Java2D API . Other user interface elements make use of the Swing API , and videos are handled through the QuickTime for Java API [ 2 ] . As much as possible , we placed related sets of controls into separate dialogs to support the use of multi - display environments ( e . g . , see Figure 1 ) . The tool is available for download at ( link removed for blind review ) . 6 I NFORMAL E VALUATION To gain user feedback on the functional prototype , we conducted a heuristic evaluation with multiple participants . Six evaluators with interface design experience participated in the heuristic evaluation . Following procedures outlined in [ 23 ] , evaluators were given a brief introduction to the tool and its features , and evaluated the interface using Nielsen’s ten usability heuristics [ 30 ] . The participants were encouraged to be open in their comments regarding design flaws and usability issues . Even after numerous evaluations of the low fidelity and functional prototypes , over 40 usability issues were discovered . For example , the operation of the view tabs was meant to mimic the tabbed browsing functionality used in many web browsers . Results from the evaluation pointed out that , in browsers , all actions affecting tabs are located in the File menu , while in our prototype , tab actions were located in the View menu . To resolve this , we relocated the relevant View actions to the File menu . The “Panels” menu was renamed to “Tools” to better reflect the user expectations of the actions in that menu . We moved the pupil mask settings action from the Options to the Tools menu , allowing us to remove the Options menu entirely . From these and other fixes we were able to simplify the menu grouping , reducing the number of menu groups from 7 to just 4 . This reduction is important as it should allow users to interact with the visualization more effectively and efficiently . Overall , the use of the heuristic evaluation led us to numerous substantive improvements related to interactions with the visualization – improvements that would not have been easily discovered otherwise . While it is beyond the scope of this design study , we plan a formal comparative evaluation of TAPRAV against existing 7 methods of data analysis in this domain . As a first step , in addition to the heuristic evaluations outlined above , we were also able to solicit informal feedback from an outside researcher , expert in pupillary response analysis , but not computer science . Due to distance , the evaluations were done without an observer present . The user downloaded the tool and sample data , and was able to install and run the tool without assistance . After having explored the tool for 3 weeks , the user sent detailed feedback via email . In all , the user felt the tool would be useful for performing this kind of data analysis . Most suggestions were geared towards adding additional functionality to the tool , such as highlighting potentially interesting patterns in the data , as opposed to reworking general notions of its utility . 7 D ISCUSSION In this section , we describe how our existing implementation meets our design goals . To provide a simple and intuitive visualization , we performed numerous iterations on low - fidelity and functional prototypes . Results from the evaluations led to many improvements in the interface , reducing the complexity of the interaction and making the visualization more effective . To facilitate discovery driven analysis , the tool includes functions for annotating data , indexing multiple views of the data , and controlling the visualization from any of the data sources ( task model , pupil graph , or video ) . To make the interface understandable to target users , we rely on familiar visualization techniques like focus + context zooming , timeline visualization , and a straightforward hierarchical task representation . To support any continuous data , we make very few assumptions about the underlying structure of the data representation . Our existing implementation supports any data formatted as time - value pairs . Alternatively , our architecture allows for reader plug - ins to parse different formats . To support any task model , we use a simple set of XML tags from which users can build models of varying complexity , from deep hierarchies to flat execution sequences . To align the data sets , users place time references into the task model description . Overall , we believe that our tool has made significant strides towards meeting our design goals . Our future work is to continue refining the functional prototype based on usability issues discovered by users as well as our own experience using the tool . In addition , we see several directions for future work : • Conduct a field study to understand how the use of the tool affects analysis of physiological data aligned to task models . This would involve comparing one set of users using our tool and another set of users using existing practices . Lessons would lead to a better understanding of how our tool affects the analysis process . • Support multiple graphs of continuous data . Our existing implementation supports one user’s response data . However , the expert user pointed out that data from multiple users is typically collected and aligned to the same model . It would thus be useful to see data from multiple users aligned to the task model . • Extend TAPRAV to include a feature for interactively constructing task models . The current method of model creation requires the user to specify the models in a textual form . By interacting with the model viewports in TAPRAV , users could construct task models through direct manipulation . 8 C ONCLUSION Researchers need more effective tools for analyzing continuous measures aligned with task models . This is becoming increasingly important for researchers involved in interface design , interruption management , affective computing , and other areas . To meet the specific data analysis needs in these research areas , we developed TAPRAV . Our tool provides an interactive focus + context visualization of continuous data aligned to a hierarchical model of task execution , and provides an integrated set of analysis tools for saving views on the data , statistical analysis , capturing annotations , and viewing videos of on - screen interaction . The tool was informed through an iterative design process in which more than five major prototypes ( and many iterations on smaller parts ) were designed and evaluated based on their ability to support appropriate tasks . This was done in much less time and with much less effort than if we have developed functional versions of each . Lessons from the evaluations helped reduce the complexity of the resulting visualization and interaction . The most recent version of the tool can be freely downloaded and used , which we hope will enable and encourage the use of physiological data in many research areas . 9 R EFERENCES 1 . Imovie , Apple Computer Inc . , 2004 . 2 . Quicktime for Java , Apple Computer Inc . , 2003 . 3 . Amar , R . and J . Stasko . A Knowledge Task - Based Framework for Design and Evaluation of Information Visualizations . InfoVis , 2004 , 143 - 149 . 4 . Bailey , B . P . , J . A . Konstan and J . V . Carlis . The Effects of Interruptions on Task Performance , Annoyance , and Anxiety in the User Interface . Proceedings of the IFIP TC . 13 International Conference on Human - Computer Interaction , Tokyo , Japan , 2001 , 593 - 601 . 5 . Beatty , J . Task - Evoked Pupillary Responses , Processing Load , and the Structure of Processing Resources . Psychological Bulletin , 91 ( 2 ) , 276 - 292 , 6 . Bederson , B . B . Photomesa : A Zoomable Image Browser Using Quantum Treemaps and Bubblemaps . Proceedings of the 14th annual ACM symposium on User interface software and technology , Orlando , Florida , USA , 2001 , 71 - 80 . 7 . Casares , J . , A . C . Long , B . Myers , S . Stevens and A . Corbett . Simplifying Video Editing with Silver . Extended abstracts on Human factors in computing systems , Minneapolis , Minnesota , USA , 2002 , 672 - 673 . 8 . Chuah , M . C . , S . F . Roth , J . Mattis and J . Kolojejchick . Sdm : Selective Dynamic Manipulation of Visualizations . Proceedings of the 8th annual ACM symposium on User interface and software technology , Pittsburgh , Pennsylvania , USA , 1995 , 61 - 70 . 9 . Cutrell , E . , M . Czerwinski and E . Horvitz . Notification , Disruption and Memory : Effects of Messaging Interruptions on Memory and Performance . Proceedings of the IFIP TC . 13 International Conference on Human - Computer Interaction , Tokyo , Japan , 2001 , 263 - 269 . 10 . Druin , A . , J . Stewart , D . Proft , B . B . Bederson and J . Hollan . Kidpad : A Design Collaboration between Children , Technologists , and Educators . Proceedings of the SIGCHI conference on Human factors in computing systems , Atlanta , Georgia , USA , 1997 , 463 - 470 . 8 11 . Edelberg , R . Electrical Activity of the Skin : Its Measurement and Uses in Psychophysiology . In Greenfield , N . S . and Sternbach , R . A . ( eds . ) Handbook of Psychophysiology , New York : Holt , 1972 , 367 - 418 . 12 . Furnas , G . W . Generalized Fisheye Views . Proceedings of the SIGCHI conference on Human factors in computing systems , Boston , Massachusetts , USA , 1986 , 16 - 23 . 13 . Gillie , T . and D . Broadbent . What Makes Interruptions Disruptive ? A Study of Length , Similarity , and Complexity . Psychological Research , 50 , 243 - 250 , 1989 . 14 . Gray , W . D . , M . J . Schoelles and C . W . Myers . Profile before Optimizing : A Cognitive Metrics Approach to Workload Analysis . Proceedings of the ACM Conference on Human Factors in Computing Systems , 2005 , 1411 - 1414 . 15 . Horvitz , E . and J . Apacible . Learning and Reasoning About Interruption . Proceedings of the Fifth ACM International Conference on Multimodal Interfaces , 2003 , 20 - 27 . 16 . Horvitz , E . , A . Jacobs and D . Hovel . Attention - Sensitive Alerting . Conference Proceedings on Uncertainty in Artificial Intelligence , 1999 , 305 - 313 . 17 . Hudson , S . E . , J . Fogarty , C . G . Atkeson , D . Avrahami , J . Forlizzi , S . Kiesler , J . C . Lee and J . Yang . Predicting Human Interruptibility with Sensors : A Wizard of Oz Feasibility Study . Proceedings of the ACM Conference on Human Factors in Computing Systems , 2003 , 257 - 264 . 18 . Iqbal , S . T . , P . D . Adamczyk , S . Zheng and B . P . Bailey . Towards an Index of Opportunity : Understanding Changes in Mental Workload During Task Execution . Proceedings of the ACM Conference on Human Factors in Computing Systems , 2005 , 311 - 320 . 19 . Iqbal , S . T . and B . P . Bailey . Investigating the Effectiveness of Mental Workload as a Predictor of Opportune Moments for Interruption . Proceedings of the ACM Conference on Human Factors in Computing Systems , 2005 , 1489 - 1492 . 20 . Kahneman , D . Pupillary Responses in a Pitch - Discrimination Task . Perception & Psychophysics , 2 , 101 - 105 , 1967 . 21 . Kramer , A . F . Physiological Metrics of Mental Workload : A Review of Recent Progress . In Damos , D . L . ed . Multiple - Task Performance , Taylor and Francis , London , 1991 , 279 - 328 . 22 . Kuederle , O . Visualizing Sequential Data : A New Detail - in - Context Layout . CHI extended abstracts on Human factors in computing systems , The Hague , The Netherlands , 2000 , 335 - 336 . 23 . Mack , R . L . and J . Nielsen . Usability Inspection Methods : Executive Summary . In Baecker , R . M . , Buxton , W . , Grudin , J . and Greenberg , S . ( eds . ) Readings in Human - Computer Interaction : Toward the Year 2000 , 1995 , 170 - 181 . 24 . Mackay , W . E . , A . V . Ratzer and P . Janecek . Video Artifacts for Design : Bridging the Gap between Abstraction and Detail . Designing Interactive Systems , 2000 , 72 - 82 . 25 . Mackinlay , J . D . , G . G . Robertson and S . K . Card . The Perspective Wall : Detail and Context Smoothly Integrated . Proceedings of the SIGCHI conference on Human factors in computing systems : Reaching through technology , New Orleans , Lousiana , USA , 1991 , 173 - 176 . 26 . Marshall , S . P . The Index of Cognitive Activity : Measuring Cognitive Workload . Proceedings of the 2002 IEEE 7th Conference on Human Factors and Power Plants , 2002 , 7 . 5 - 7 . 9 . 27 . Marshall , S . P . New Techniques for Evaluating Innovative Interfaces with Eye Tracking . Proceedings of the ACM Conference on User Interface Software and Technology , 2003 , Keynote Talk . 28 . Mills , M . , J . Cohan and Y . Y . Wong . A Magnifier Tool for Video Data . Proceedings of the SIGCHI conference on Human factors in computing systems , Monterey , California , USA , 1992 , 93 - 98 . 29 . Miyata , Y . and D . A . Norman . The Control of Multiple Activities . In Norman , D . A . and Draper , S . W . ( eds . ) User Centered System Design : New Perspectives on Human - Computer Interaction , Lawrence Erlbaum Associates , Hillsdale , NJ , 1986 . 30 . Nielson , J . and R . L . Mack . Usability Inspection Methods . John Wiley & Sons , New York , NY , 1994 . 31 . Perlin , K . and D . Fox . Pad : An Alternative Approach to the Computer Interface . Proceedings of the 20th annual conference on Computer graphics and interactive techniques , 1993 , 57 - 64 . 32 . Picard , R . W . Affective Computing . MIT Press , Cambridge , 1997 . 33 . Rekimoto , J . Time - Machine Computing : A Time - Centric Approach for the Information Environment . Proceedings of the 12th annual ACM symposium on User interface software and technology , Asheville , North Carolina , USA , 1999 , 45 - 54 . 34 . Rettig , M . Prototyping for Tiny Fingers . Communications of the ACM , 37 ( 4 ) , 21 - 27 , 1994 . 35 . Robertson , G . G . and J . D . Mackinlay . The Document Lens . Proceedings of the 6th annual ACM symposium on User interface software and technology , Atlanta , Georgia , USA , 1993 , 101 - 108 . 36 . Sarkar , M . , S . S . Snibbe , O . J . Tversky and S . P . Reiss . Stretching the Rubber Sheet : A Metaphor for Viewing Large Layouts on Small Screens . Proceedings of the 6th annual ACM symposium on User Interface software and technology , Atlanta , Georgia , USA , 1993 , 81 - 91 . 37 . Spence , R . and M . Apperley . Database Navigation : An Office Environment for the Professional . Behavior and Information Technology , 1 ( 1 ) , 43 - 54 , 1982 . 38 . Stolte , C . , R . Bosch , P . Hanrahan and M . Rosenblum . Visualizing Application Behavior on Superscalar Processors . InfoVis , 1999 . 39 . Suh , B . and B . B . Bederson . Ozone : A Zoomable Interface for Navigating Ontology . Proceedings of International Conference on Advanced Visual Interfaces , Trento , Italy , 2002 , 139 - 143 . 40 . Wardrip - Fruin , N . , J . Meyer , K . Perlin , B . B . Bederson and J . Hollan . A Zooming Sketchpad , a Multiscale Narrative : Pad + + , Paddraw , Gray Matters . ACM SIGGRAPH 97 Visual Proceedings : The art and interdisciplinary programs of SIGGRAPH ' 97 , Los Angeles , California , USA , 1997 , 141 . 41 . Wastell , D . Mental Effort and Task Performance : Towards a Psychophysiology of Human Computer Interaction . INTERACT , 1990 , 107 - 112 .