Creativity and Machine Learning : A Survey GIORGIO FRANCESCHELLI , Alma Mater Studiorum Universit√† di Bologna , Italy MIRCO MUSOLESI , University College London , United Kingdom , The Alan Turing Institute , United Kingdom , and Alma Mater Studiorum Universit√† di Bologna , Italy There is a growing interest in the area of machine learning and creativity . This survey presents an overview of the history and the state of the art of computational creativity theories , key machine learning techniques ( including generative deep learning ) , and corresponding automatic evaluation methods . After presenting a critical discussion of the key contributions in this area , we outline the current research challenges and emerging opportunities in this field . 1 INTRODUCTION The connection between creativity and machines is as old as computer science itself . In 1842 , Lady Lovelace , an English mathematician and writer recognized by many as the first computer programmer , issued the so - called ‚ÄúLovelace‚Äôs objection‚Äù [ 232 ] : the Analytical Engine ( the digital programmable machine proposed by Charles Babbage [ 7 ] ) ‚Äúhas no pretensions to originate anything , since it can only do whatever we know how to order it to perform‚Äù [ 157 ] . Indeed , in the following centuries , several projects and studies concerning the design of machines that able to ‚Äúoriginate something‚Äù have been carried out [ 39 , 45 , 97 , 132 , 156 , 182 ] . This has led to the emergence of a specialized field in computer science , namely Computational Creativity [ 32 ] , which concerns the study of the relationship between creativity and artificial systems [ 44 , 245 ] . In this context , the adoption of Deep Learning ( DL ) techniques has led to substantial breakthroughs in the recent years . Vast computational power and very large amounts of available data are at the basis of the increasing success of deep generative models ( i . e . , generative models based on DL [ 67 ] ) . Indeed , generative deep learning technologies have been used to write newspaper articles 1 , generate human faces [ 120 ] and voices [ 141 ] , design drugs and proteins [ 115 ] , and even create artworks sold for a few hundred thousand dollars 2 . However , while it is apparent that current technologies are able to generate impressive outputs , at the same it is also possible to argue that they cannot be considered creative in general [ 20 ] . In fact , the goal of generative deep learning is to produce synthetic data that resemble real one given in input as close as possible [ 67 ] . On the other hand , creativity involves novelty and diversity [ 168 ] . While for some problems mere content generation [ 240 ] might be sufficient , for other tasks , such as , for example , in the Arts , the ability to create different ( but still valuable ) outputs is essential . Goal and contributions of the survey . The goal of this survey is to present and critically discuss the state of the art in generative deep learning from the point of view of machine creativity . Moreover , to the best of our knowledge , this is the first survey that explores how current DL models have been or can be used as a basis for both generation ( i . e . , producing creative artifacts ) and evaluation ( i . e . , recognizing creativity in artifacts ) . The contribution of this survey can be summarized as follows . After a brief overview of the meaning and definitions of creativity in Section 2 , Section 3 presents an in - depth analysis of generative deep learning through the introduction of a new taxonomy and a critical analysis of machine creativity . Then , several ML - based methodologies to evaluate creativity are presented and discussed in Section 4 . Finally , 5 concludes the paper , outlining open questions and research directions for the field . 1 www . theguardian . com / commentisfree / 2020 / sep / 08 / robot - wrote - this - article - gpt - 3 2 www . christies . com / features / a - collaboration - between - two - artists - one - human - one - a - machine - 9332 - 1 . aspx 1 a r X i v : 2104 . 02726v3 [ c s . L G ] 5 J u l 2022 Franceschelli and Musolesi Related surveys . We now provide an overview of other surveys in areas related to the present work . For readers interested in a survey in deep generative models , we recommend [ 18 , 87 ] ; for an analysis of the state of the art in evaluation in computational creativity [ 130 ] is an essential reading ; for a review concerning AI and creativity in general , we recommend [ 199 ] ; for a practical view of generative deep learning , we suggest [ 67 ] ; finally , for an in - depth examination of artistic AI works ( also in human - computer co - creations [ 85 ] ) , [ 160 ] is a very comprehensive source of information . 2 DEFINING CREATIVITY Creativity has been studied for decades , and yet , there is no agreement about its definition . More than one hundred definitions have been provided [ 4 , 229 ] , and the number is still growing . In other words , we can say that creativity is a suitcase word , i . e . , people conflate multiple meanings into it [ 161 ] . Nonetheless , some concepts are nowadays widely accepted . One of them is the possibility of studying creativity from four different perspectives : person , press , process , product , i . e . , the so - called ‚Äúfour P‚Äôs‚Äù . These have been studied in computational creativity as well [ 114 ] . However , the focus has traditionally been on the product dimension . Indeed , the idea is that we study creativity without considering the inner being of the creator ( person ) , the relation with the environment ( press ) or the process . Even if person , press and process are important , we focus on aspects of creative work in relation to the output ( product ) itself . For this reason , we consider Boden‚Äôs three criteria for studying machine creativity , defined as ‚Äúthe ability to generate ideas or artifacts that are new , surprising and valuable‚Äù [ 16 ] . Value and novelty are always considered for creativity in product ; surprise is commonly used too [ 148 ] . These concepts might be defined in different ways . We underpin our analysis on Boden‚Äôs three criteria since they have been widely adopted . Boden also suggests that three forms of creativity can be identified [ 16 ] to describe how a novel and surprising product is obtained , therefore linking process and product . The three forms of creativity are combinatorial , exploratory and transformational . Combinatorial creativity is about making unfamiliar combinations of familiar ideas . Exploratory creativity involves the exploration of the conceptual space defined by the cultural context considered . Transformational creativity involves changing that space in a way that allows for new and previously inconceivable thoughts to become possible . It is also worth noting that Boden also identified four different questions that emerge when studying computational creativity . These are referred to as Lovelace questions , because many people would respond to them by using Lovelace‚Äôs objection . The first question is whether computational ideas can help us understand how human creativity works . The second is whether computers could ever do things which at least appear to be creative . The third is whether a computer could ever appear to recognize creativity . Finally , the fourth is whether computer themselves could ever really be creative , i . e . , with the originality of the products only deriving from the machine itself [ 16 ] . While the first one is studied in Boden‚Äôs work , we will provide the reader with an overview of the techniques that can possibly be used to answer the second ( Section 3 ) and the third ( Section 4 ) . With respect to the fourth , Boden states that ‚Äúit is not a scientific question as the others are , but in part a philosophical worry about ‚Äúmeaning‚Äù and in part a disguised request for a moral political decision‚Äù . We agree with this position , but we hope that our survey will provide the reader with elements for answering the fourth as well . 3 GENERATIVE MODELS A generative model can be defined as follows : given a dataset of observations ùëã , and assuming that ùëã has been generated according to an unknown distribution ùëù ùëëùëéùë°ùëé , a generative model ùëù ùëöùëúùëëùëíùëô is a model able to mimic ùëù ùëëùëéùë°ùëé . By sampling from ùëù ùëöùëúùëëùëíùëô , observations that appear to have been drawn from ùëù ùëëùëéùë°ùëé can be generated [ 67 ] . Generative deep learning 2 Creativity and Machine Learning : A Survey is just the application of deep learning techniques to form ùëù ùëöùëúùëëùëíùëô . However , creativity is not only the ability to perform generation . Considering the definitions presented in Section 2 , the generated observations should be considered as novel , surprising and valuable ; and the space of solutions should be exploited in a way that is combinatorial , exploratory , or even better , transformational . In this section , we aim at studying the level of creativity of existing generative deep learning models . We will analyze how the models learn their spaces of solutions , and how the observations are generated from them . A new generative deep learning taxonomy is then introduced based on the different training and sampling techniques at the basis of each method . Figure 1 provides a summary of the seven generative classes considered in this survey . Fig . 1 . A schematic view of the seven classes of generative learning methods presented in this survey . Top , left to right : Variational Autoencoder ( 3 . 1 ) , with a decoder generating x ‚Ä≤ given a latent vector z , and an encoder representing x into a latent distribution ; Generative Adversarial Network ( 3 . 2 ) , with a generator to produce x ‚Ä≤ , and a discriminator to distinguish between real x and synthetic x ‚Ä≤ ; Sequence prediction model ( 3 . 3 ) , with a generator to output ùë• one token after the other given in input previous tokens ; Transformer - based model ( 3 . 4 ) , with a Transformer outputting x one token after the other given in input previous tokens , or a masked version of x . Bottom , left to right : Diffusion model ( 3 . 5 ) , with a model to learn an error ùúñ , which is used to incrementally reconstruct x 0 ; RL - based method ( 3 . 6 ) , with a generative model acting ( i . e . , progressively generating x ) by maximizing a given reward function ; Input - based methods ( 3 . 7 ) , with an input optimized by a given loss . The input can be a vector z given to a generative model to obtain the desired output , or directly a product x becoming the desired output . Since our focus is on machine creativity , we do not discuss the implementation details of each class of methods in detail . We instead present the core concepts at the basis of each class of methods ; some relevant examples of models ; potential applications of these creative models ; and , finally , a critical discussion evaluating the level of machine creativity considering the definitions above . As a final remark , it is worth noting that we limit our examples to the Arts ( e . g . , poems , music , or paintings ) . Indeed , generative learning can be applied to design [ 75 , 153 ] ; game content generation ( see [ 145 ] for a comprehensive survey ) ; recipes [ 166 , 238 ] ; scientific discovery [ 40 , 206 ] ; and in general to any activity , which has a non - trivial solution [ 25 ] . 3 Franceschelli and Musolesi 3 . 1 Variational Auto - Encoders 3 . 1 . 1 Core Concepts . A Variational Auto - Encoder [ 126 , 193 ] is a learning architecture composed by two models : an encoder ( or recognition model ) and a decoder ( or generative model ) . The former compresses high - dimensional input data into a lower - dimensional representation , and the latter decompresses the representation vector back to the original domain [ 67 ] . Classic autoencoders directly learn a latent representation vector . Conversely , VAEs learn a ( Gaussian ) distribution over the possible values of the latent representation , i . e . , the encoder learns the mean and the ( log of the ) variance of the distribution . The decoder then learns to reconstruct the data by taking in input a vector sampled from the distribution . VAEs are trained by optimizing two losses : the reconstruction loss and the regularization loss . The former is the log - likelihood of the real data x from the decoder given their latent vectors z , i . e . , it is the error of the decoder in reconstructing x . The latter is the KL divergence between the distribution learned by the encoder and a prior distribution , e . g . , a Gaussian . Notably , the latent vector z in input to the decoder is obtained by means of the so - called reparameterization trick , i . e . , by sampling from the distribution defined by the mean and the variance . Without it , sampling would induce noise in the gradients required for learning [ 127 ] . The mathematical derivation of the whole loss has its roots in variational inference [ 111 ] . Indeed , VAEs can be seen as an efficient and stochastic variational inference method , in which neural networks and stochastic gradient descent are used to learn an approximation ( i . e . , the encoder ) of the true posterior [ 70 ] . In VAEs , similar high - dimensional data are mapped to similar distributions . This makes possible to sample a random point z in that space , and still obtain a comprehensible reconstruction [ 67 ] . On the other hand , VAE tends to produce blurred images [ 260 ] . It may also happen that high - density regions under the prior have a low density under the approximate posterior , i . e . , these regions are not decoded to data - like samples [ 5 ] . Finally , the objective can lead to overly simplified representations without using the entire capacity , obtaining only a sub - optimal generative model [ 28 ] . 3 . 1 . 2 Examples of Models . Several models based on VAEs have been proposed [ 127 ] in the recent years . In the following , we focus on those relevant for our discussion on machine creativity . In ùõΩ - VAE [ 89 ] , a ùõΩ parameter is used to scale the magnitude of the regularization loss , which allows for a better disentanglement of the latent space [ 29 ] . Another example is VAE - GAN [ 133 ] , which merges VAE and GAN [ 77 ] ( described in the next subsection ) . This is done by treating the decoder as the generator of the GAN , thus training it by means of the GAN loss function . This leads to the generation of substantially less blurred images . Similarly , ALI ( Adversarially Learned Inference ) [ 57 ] merges VAE and GAN by asking the discriminator to distinguish between pairs of real data ( and their latent representations ) and pairs of sampled representations and synthetic data . Instead , AAE ( Adversarial Autoencoders ) [ 154 ] substitutes the regularization loss with a discriminative signal , where the discriminator has to distinguish between random latent samples and encoded latent vectors . Another way to address the problem of ‚Äúsample blurriness‚Äù is with PixelVAE [ 83 ] , where the autoregressive PixelCNN [ 234 , 235 ] is used as the decoder . A different decoder architecture has been also used in [ 19 ] . To deal with sequential data like texts , where the generation requires more steps , the encoder learns to produce a latent representation of a sentence , while the RNN - based decoder learns to reproduce it word after word . However , VAE can also generate text by means of convolution and deconvolution [ 208 ] . To solve the problem of low - density regions , the authors of [ 5 ] propose an energy - based model called noise con - trastive prior ( NCP ) , trained by contrasting samples from the aggregate posterior to samples from a base prior . Finally , 4 Creativity and Machine Learning : A Survey another interesting model is VQ - VAE ( Vector Quantised - VAE ) [ 236 ] , in which the encoder outputs discrete , rather than continuous , codes , and the prior is learnt rather than being static . 3 . 1 . 3 Applications . VAEs can be used for semi - supervised classification to provide an auxiliary objective , improving the data efficiency [ 125 , 147 ] ; to perform iterative reasoning about objects in a scene [ 61 ] ; to model the latent dynamics of an environment [ 243 ] . Of course , VAEs have also been used to generate synthetic data , including for conditional generation . For example , a layered foreground - background generative model can be used to generate images based on both the latent representation and a representation of the attributes [ 251 ] . In [ 86 ] the latent space of a VAE is trained on chemical structures by means of gradient - based optimization towards certain properties ( see 3 . 7 ) . AAEs have also been applied to the same problem [ 116 ] . Finally , another interesting application of VAE is DRAW [ 80 ] . DRAW constructs scenes in an iterative way , by accumulating changes emitted by the decoder ( then given to the encoder in input ) . This allows iterative self - corrections and a more natural form of image construction . RNNs and attention mechanism are used to consider previous generations and to decide at each time - step where to focus attention , respectively . 3 . 1 . 4 Critical Discussion . Models based on VAEs can be considered as an example of exploratory creativity . The latent space is learned with the goal of representing data in the best accurate way . The random sampling performed during generation is therefore an exploration of that space : regions not seen during training can be reached as well , even though they can lead to poor generation [ 5 ] and some more complex variants may be needed , as discussed . On the other hand , there is no guarantee that the results obtained will be valuable , novel or surprising . There is no guarantee that the the generation from random sampling is of good quality , or diverse from training data . Indeed , given their characteristics , VAEs discourage novelty in a sense . Notably , diversity could in theory be achieved using VAEs and gradient - based optimization techniques , such as those presented in [ 86 ] , with novelty and surprise as target properties . We will discuss these aspects in Section 3 . 8 in more details . 3 . 2 Generative Adversarial Networks 3 . 2 . 1 Core Concepts . A Generative Adversarial Network ( GAN ) [ 77 ] is an architecture composed by two networks : a generative model and a discriminative model . The latter learns to distinguish between real samples and samples generated by the former . In parallel , the former learns to produce samples from random noise vector such that they are recognized as real by the latter . This competition drives both models to improve their methods , until the generated samples are indistinguishable from the original ones . The adversarial training allows the generator to learn to produce seemingly real samples from random noise without being exposed to data . The simplicity of the idea and the quality of results are at the basis of the success of GANs . However , few limitations exist . For instance , GAN can suffer from mode collapse , where the generator only learns to produce a small subset of the real samples [ 159 ] . In addition , the latent space of random inputs is typically not disentangled and it is necessary to introduce constraints in order to learn an interpretable representation [ 123 ] . 3 . 2 . 2 Examples of Models . The number of variants proposed is still growing 3 . An in - depth survey on GANs is [ 81 ] . Indeed , several refinements have been proposed in the past years , such as using deep convolutional networks [ 185 ] or self - attention [ 254 ] , incrementally growing the networks [ 119 ] , or by scaling the model parameters [ 23 ] . In the following , we present examples that are relevant to the the problem of machine creativity . 3 For an exhaustive and constantly updated list of GAN papers see for example : https : / / github . com / hindupuravinash / the - gan - zoo 5 Franceschelli and Musolesi The problem of non - meaningful representation has been addressed in different ways . For instance , InfoGAN [ 35 ] adds a latent code c to z . An auxiliary model learns to predict ùëê given the sample generated by means of it . In this way , it can learn disentangled representations in a completely unsupervised manner . Another possibility is BiGAN [ 53 ] . In order to include an inverse mapping from data to latent representation , an encoder is added to the architecture . The discriminator is then trained to distinguish between pairs of random noise and synthetic data and pairs of real data and latent encoding . It is also possible to condition the generation by means of a target content [ 176 ] , a text [ 191 ] , or even an image [ 101 ] . In order to do so , it is sufficient to use the conditional information as input for both generator and discriminator [ 162 ] . Similarly , image - to - image translation is possible also without paired datasets . CycleGAN [ 262 ] trains two generators ( from one domain to another , and vice - versa ) so that each of them produces images both from the target domain and correctly reconstructed by the counterpart . In StyleGAN [ 121 , 122 ] , the generator architecture is re - designed in order to control the image synthesis process . The style of the image is adjusted at each layer based on the latent code ( the specific intermediate code to control each layer is provided by a non - linear mapping network ) . This allows for automatic separation of high - level attributes from stochastic variations in the generated images . It also allows for mixing regularization , where two latent codes are used alternatively to guide the generator . StyleGAN - V [ 213 ] builds on top of it to learn how to produce videos by only using few frames of it . To generate longer and more realistic motions , a two - stage approach can be used as well : first , a low - resolution generator is adversarially trained on long sequences ; then , a high - resolution generator transforms a portion of the produced , low - resolution video in a high - resolution one [ 24 ] . Finally , it is also worth mentioning variants that adapt GANs to sequential tasks ( e . g . , text generation ) . Since GANs require the generator to be differentiable , they cannot generate discrete data [ 76 ] . However , several techniques have been proposed to avoid this problem . One possibility is to transform the discrete generation into a continuous one . Music can indeed be processed like an image by considering its waveform ( as in WaveGAN [ 52 ] and GANSynth [ 60 ] ) or its musical score composed of tracks and bars ( as in MuseGAN [ 54 ] ) . Music in a desired style can be obtained through conditional inputs . Another possibility is to consider a soft - argmax function as an approximation of the inference for each step [ 257 ] . TextGAN [ 258 ] uses it together with feature matching to learn the production of sentences . In place of the discriminative signal , it uses the difference between the latent feature distributions of real and of synthetic sentences learned by the discriminator . Another solution is to transform the GAN into a Reinforcement Learning ( RL ) framework ( see SeqGAN [ 253 ] ) . The generative model is the agent ; the tokens generated so far form the state ; the selection of the next token to be generated is the action to be performed ; and the discriminative signal is the reward . The REINFORCE algorithm [ 246 ] can then be used to adversarially train the generative model . Other policy gradient methods can be used as well [ 63 ] . The advantage of using RL to adapt GANs to sequential tasks is that the reward function can be composed by more signals : additional objectives can be used as well to embed particular behaviors in the generator . As suggested by ORGAN [ 82 ] , qualitative heuristics - like tonality and ratio of steps - can be used to improve music generation . On the other hand , the learning signal ( i . e . , the reward ) might be very sparse . A way to solve this issue is to use inverse RL [ 263 ] . For example , the authors of [ 210 ] use inverse RL to learn a reward function able to associate positive rewards to real state - action pairs , and non - positive rewards to synthetic state - action pairs . Notably , this can help solve mode collapse too . Another variant is LeakGAN [ 84 ] . Here , a hierarchical generator composed by a Manager and a Worker is used . The Worker produces a sentence conditioned by a goal vector provided by the Manager . The Worker and the discriminative model are trained following SeqGAN ; the Manager is trained to predict goal vectors that lead to the identification of advantageous directions in the discriminative feature space . More specifically , the Manager receives a feature vector from the discriminator , i . e . , its last convolutional layer , at each generated token . By means of this leaked 6 Creativity and Machine Learning : A Survey information and the hierarchical architecture , LeakGAN produces longer and higher - quality texts . Finally , another possibility is to use Gumbel - softmax relaxation [ 102 , 150 ] , as in RelGAN [ 173 ] . CTERM - GAN [ 15 ] builds on the latter by also conditioning the generator on an external embedding input . In addition , it uses both a syntactic discriminator to predict if a sentence is correct and a semantic discriminator to infer if a sentence is coherent with the external input . 3 . 2 . 3 Applications . GANs have been applied to a variety of practical problems in several application scenarios . They have been widely used for semi - supervised learning [ 175 ] ; for generating adversarial examples [ 249 ] to better train image classifiers [ 151 ] ; and , in general , in computer vision ( see [ 242 ] for a detailed discussion ) . The generative power of GANs has also found its place in recommender systems ( see [ 47 ] ) to generate fashion items ; in science and chemistry [ 158 , 167 ] . Of course , its ability of generating high - quality samples has been exploited in many other areas , from anime design [ 110 ] and 3D object modeling [ 248 ] to photo - realistic consequences of climate change [ 207 ] . Conditional inputs also allow to produce artistic works by controlling stylistic properties like genre [ 226 ] or influencer [ 37 ] . Finally , the most famous example of the artistic power of GAN is the collection of paintings by Obvious , a French art collective [ 241 ] ; one of their works has been sold to more than 400 , 000 dollars 4 . 3 . 2 . 4 Critical Discussion . GANs are difficult to evaluate from a machine creativity perspective . The generator does not receive the original works as input , so it samples from a conceptual space that is built only indirectly from them . In rare cases , this can also lead to a different conceptual space ( with respect to the original one ) and so to transformational creativity , but it typically leads to exploratory creativity . In fact , the goal is to learn to generate artifacts that look as much as possible like the real ones , so the loss function itself makes it working with exploratory creativity . Products are valuable ( this is , in a sense , the objective ) , but there is no guarantee that they will also be new and surprising . Nonetheless , it seems possible to extend a GAN objective to include such properties as well ( see Subsection 3 . 8 for a discussion ) . Finally , it is worth noting that GANs can be considered appreciative [ 40 ] , since the discriminative network can judge the value of artifacts . 3 . 3 Sequence Prediction Models 3 . 3 . 1 Core Concepts . A sequence prediction model is a generative model that considers generation as a sequential process . It can therefore work in an autoregressive fashion : it predicts the future outcome of the sequence ( i . e . , the next token ) from the previously observed outcomes of that sequence . It is trained to minimize the prediction error for each token in the dataset . At inference time , this simple yet effective approach only requires to produce one token after the other , feeding back to the model what have been produced so far [ 118 ] . It makes possible to learn dependencies between tokens in real data , so that the same dependencies can be exploited when generating synthetic data . However , this causes the generation to be highly dependent from real data , e . g . , there is the risk of potentially reproducing portions of the training set . 3 . 3 . 2 Examples of Models . Several models have been proposed , most of them based on recurrent neural networks ( RNN ) , and especially on long short - term memory ( LSTM ) [ 95 ] . The reason is that RNNs can have internal states based on previous computation : inputs received at earlier time steps can affect the response to the current input . However , RNNs tend to have worse performance with longer sequences [ 12 ] . LSTM is a specific RNN architecture that addresses the problem of long - term dependencies . 4 Fun fact : the sold painting is called Portrait of Edmond De Belamy because Belamy sounds like bel ami , a sort of French translation of . . . Goodfellow . 7 Franceschelli and Musolesi RNNs can be used to model joint probabilities of characters ( Char - RNN ) [ 118 ] ; words [ 181 ] ; phonemes [ 98 ] ; syllables [ 264 ] ; and even tokens from transcriptions of folk music ( Folk - RNN ) [ 222 ] . They can also receive conditional inputs like the encoding of the previous lines [ 256 ] . Richer architectures that combine models focusing on different characteristics of the text can be used to generate more complex text , e . g . , poetry based on pentameter and rhymes [ 134 ] . Finally , sequence modeling can also be combined with reinforcement learning . For instance , the authors of [ 105 ] use a Note - RNN model ( based on single notes ) trained using Deep Q - Network [ 164 ] ; as rewards , they consider both the classic loss of sequence prediction models and a reward based on rules of music theory . In this way , the model learns a set of composition rules , while still maintaining information about the transition probabilities of the training data . The advantages of adopting an RL - based approach are described in 3 . 6 . Due to the difficulties in working with long sequences , results in tasks like narrative generation are affected by a lack of coherence [ 197 ] . Many approaches have been proposed to address this problem . For instance , stories can be generated in terms of events [ 155 ] ( i . e . , tuples with subject , verb , object , and an additional wildcard ) by an encoder - decoder RNN ( also known as Sequence - to - Sequence , see [ 223 ] ) ; events are modeled by another encoder - decoder RNN . Instead of events , it is also possible to focus on entities ( i . e . , vectors representing characters ) [ 38 ] . Sequence prediction models are also used for domains not commonly modeled as sequences , like images . Image modeling can be defined in a discrete way by means of joint distribution of the pixels : the model learns to predict the next pixel given all the previously generated ones . It starts at the top left pixel , and then proceeds towards the bottom right . The two seminal architectures for sequence prediction of images are PixelRNN and PixelCNN [ 234 ] . The former is a two - dimensional RNN ( based on rows or on diagonals ) . The latter is a CNN with an additional fixed dependency range ( i . e . , the filters on the convolution are masked in order to only use information about pixels above and to the left of the current one ) . To obtain better results , gated activation units can be used in place of the rectified linear units between the masked convolutions ; conditional inputs encoding high - level image descriptions can be used as well [ 235 ] . Notably , the Gated PixelCNN architecture can also be used for other types of data : WaveNet [ 233 ] implements it to generate audio based on the waveform , possibly guiding the generation with conditional inputs . 3 . 3 . 3 Applications . As discussed , sequence prediction models have been used to learn to write poems or stories ( by predicting a character , syllable , or word after the other ) ; to compose music ( by predicting a note or a waveform after the other ) ; to draw images ( by predicting a pixel after the other ) . In general , they can be used for any sort of time series forecasting [ 144 ] . They can also be used for co - creativity , as in Creative Help [ 197 ] . Despite their simplicity , sequence prediction models are one of the most successful generative techniques . An interesting example is Sunspring . It might be considered as the first AI - scripted movie : it was generated by a Char - RNN trained on thousands of sci - fi scripts [ 160 ] . The quality of the result is demonstrated by the fact that it was able to reach the top ten at the annual Sci - Fi London Film Festival in its 48 - Hour Film Challenge 5 . 3 . 3 . 4 Critical Discussion . Sequence prediction models generate outputs that have characteristics of both exploratory and combinatorial creativity . They are based on probabilistic predictions and they are able to generate new outputs in the induced space , but they can also reuse sequences of tokens from different works , combining them together . There is no guarantee that the results will be valuable or novel ; and classic methods like RNNs lack surprise [ 26 ] . It is worth noting that the possibility of using conditional inputs and being able to work at different levels of abstraction might 5 Quite interestingly , the AI that wrote Sunspring declared that its name was Benjamin , probably in honor of Walter Benjamin , the German philosopher that , already in 1935 [ 13 ] , understood that new mechanical techniques related to art can radically change the public attitude to art and artists . 8 Creativity and Machine Learning : A Survey indirectly lead to creative outputs , but creativity should then be attributed to the higher - level component ( or human , if the input is provided by the user ) that is guiding the generation for specific elements and characteristics of the result . 3 . 4 Transformer - Based Models 3 . 4 . 1 Core Concepts . Transformer - based models are neural networks based on the Transformer architecture [ 239 ] . They are sometimes referred to as foundation models [ 17 ] , because of the leading role they have been assuming in language , vision and robotics . A Transformer is an architecture for sequential modeling that does not require recurrent or convolutional layers . Instead , it only relies on a self - attention mechanism [ 9 ] that models long - distance context without a sequential dependency . Each layer consists of multi - head attention ( i . e . , several self - attention mechanisms running in parallel ) , a feed - forward network , and residual connections . Since self - attention is agnostic to token order , a technique called positional embedding is used to capture the ordering [ 239 ] . In principle , a Transformer is nothing more than an autoregressive model : it works by predicting the current token given the previous ones ( see 3 . 3 ) . However , few fundamental differences exist . A Transformer can also be trained by means of masked modeling : some of the input tokens are randomly masked , and the model has to learn how to reconstruct them from the entire context , and not only from the previous portions [ 48 ] . The possibility of dealing with very long sequences allows for prompting . By providing a natural language prompt in input , the model is able to generate the desired output , e . g . , the answer to a question , a class between a set of classes for a given text , or a poem in a particular style [ 25 ] . This is done by simply passing the prompt in input as a text , and then leveraging the model to predict what comes next ( e . g . , the answer to a question ) . These advantages , together with the massive amount of data available , the increasing computational power and the parallelism induced by their architecture , has led Transformer - based models to become the state of the art for several tasks . Nevertheless , the compute costs of the architecture from [ 239 ] grow quadratically with the input size . 3 . 4 . 2 Examples of Models . Several Transformer - based approaches have been proposed in recent years . The design of specific Transformers for a variety of applications in presented in several surveys ( e . g . , [ 17 , 124 ] ) and books ( e . g . , [ 231 ] ) . The domain mostly influenced by Transformers is natural language processing . BERT [ 48 ] is a Transformer - based encoder trained for both predicting the next sentence ( in an autoregressive fashion ) and reconstructing masked tokens from the context . Several enhanced variations of the original model have been proposed . For example , RoBERTa [ 146 ] is able to achieve higher - quality results only by means of masked modeling with more training time and data ; ALBERT [ 131 ] obtains competitive results with less parameters by using inter - sentence coherence as an additional loss ; and DistilBERT [ 203 ] uses distillation [ 90 ] to train a smaller model to match BERT outputs . The other main approach is that used by the GPT family [ 25 , 183 , 186 ] . Here , a Transformer - based decoder is trained in an autoregressive way by additionally providing the relative task in input . After training , it can be used to perform a wide range of tasks by providing a description or few demonstrations of the task . The effectiveness of this text - to - text generative approach has then been explored by T5 [ 187 ] . Many other large language models [ 198 , 211 , 255 ] have been proposed to achieve better results by means of more parameters and computation [ 214 ] , or data [ 96 ] . Mixture of Experts [ 209 ] can be used as well in place of feed - forward network to train a larger but lighter model ( since only portions of it are used per task ) , as done by GLaM [ 56 ] . Finally , BART [ 139 ] ideally merges together a BERT - encoder ( trained by corrupting text with an arbitrary noising function ) and a GPT - decoder ( trained to reconstruct the original text autoregressively ) . Such an encoder - decoder architecture is able to achieve state - of - the - art results in machine translations , as well as in other text - to - text tasks . 9 Franceschelli and Musolesi Transformer - based models have been used in other domains as well . Few have been proposed for music generation . One of the first examples was Music Transformer [ 99 ] , which can generate one - minute music in Bach‚Äôs style with internal consistency ; another remarkable one is Musenet [ 179 ] , which is able to produce 4 - minute musical composition with a GPT - 2 architecture ; and , finally , it is worth mentioning Jukebox [ 49 ] , which can generate multiple minutes of music from raw audio by training a Sparse Transformer [ 36 ] ( i . e . , a Transformer with sparse factorization of the attention matrix in order to reduce from quadratic to linear scaling ) over the low - dimensional discrete space induced by a VQ - VAE . Conditioning is always considered by means of genre , author , or instruments . Another important application domain is video - making . ViViT [ 6 ] generates videos using classic Transformer architectures ; VidTr [ 259 ] achieves state - of - the - art performance thanks to standard deviation - based pooling method ; and VideoGPT [ 250 ] does so by learning discrete latent representations of raw video with VQ - VAE , and then training a GPT autoregressively . Transformers have been highly influential in computer vision too . The first model was Image Transformer [ 178 ] . It restricts the self - attention mechanism to attend to local neighborhoods , so that larger images can be processed . Class - conditioned generation is also supported , by passing the embedding of the relative class in input . To avoid restricting self - attention to local neighborhoods , Vision Transformer [ 55 ] divides an image into fixed - size patches , linearly embeds each of them , adds position embeddings , and then feeds the resulting sequence of vectors to a standard Transformer encoder . Masked Autoencoders ( MAE ) [ 88 ] instead uses an encoder - decoder architecture based on Transformers trained with masked image modeling ( i . e . , to reconstruct randomly masked pixels ) . A BERT adaptation to images called BEiT [ 11 ] has also been proposed . Masked image modeling has also been used together with classic autoregressive loss [ 33 ] . Conversely , Vector Quantised - GAN ( VQGAN ) [ 62 ] allows a Transformer to be based on vector quantization . A GAN learns an effective codebook of image constituents . To do so , the generator is implemented as an auto - encoder ; vector quantization is applied over the latent representation returned by the encoder . It is then possible to efficiently encode an image in a sequence corresponding to the codebook - indices of their embeddings . The Transformer is finally trained on that sequence to learn long - range interactions . These changes also allow to avoid quadratic scaling , which is intractable for high - resolution images . Finally , also DALL - E [ 184 ] takes advantage from a discrete VAE . To generate images based on an input text , it first learns a discrete image encoding ; it concatenates the input text embedding with the image encoding ; it learns autoregressively on them . DALL - E becomes then able to generate a variety of text - conditioned images . CogView implements a similar architecture [ 51 ] . Finally , Transformer - based models have also been used in multimodal setting , in which the data sources are of different types . A survey can be found in [ 224 ] . The first examples of these systems consider text and images together as output of the Transformer architecture . By aligning their latent representations , images and texts can be generated by Transformer - based decoders given a multimodal representation . For instance , CLIP [ 184 ] has an image encoder pre - trained together with a text encoder to generate a caption for an image . ALIGN [ 108 ] , based on similar mechanisms , is able to achieve remarkable performance through a training based on a noisier dataset . In [ 230 ] the authors propose a frozen language model for multimodal few - shot learning : a vision encoder is trained to represent each image as a sequence of continuous embeddings , such that the frozen language model prompted with this embedding can generate the appropriate caption . In [ 64 ] the authors present BriVL , which performs multimodal tasks by learning from weak semantic correlation data . Finally , there is a trend toward even more complex multimodal models . For example , VATT [ 3 ] learns to extract multimodal representations from video , audio and text ; instead , Gato [ 192 ] serializes all data ( e . g . , text , images , games , other RL - related tasks ) into a flat sequence of tokens that is then embedded and passed to a standard large - scale language model . 10 Creativity and Machine Learning : A Survey 3 . 4 . 3 Applications . Transformer - based large language models can be used for almost any NLP task , including text summarization , generation and interaction . In order to do so , the model can be used as a frozen model ( i . e . , by providing latent representations in input to other models ) ; can be fine - tuned for the specific objective ; can be exploited with zero - shot , one - shot or few - shot setting by prompting the task or few demonstrations in input . Transfer learning can instead be used to perform image classification by means of Transformer - based models trained on images . Other domain - specific techniques can be used as well : for instance , PlotMachines [ 190 ] learns to write narrative paragraphs not by receiving prompts , but by receiving plot outlines and representations of previous paragraphs . From a generative learning perspective , Transformers have shown impressive performance in producing long sequences of texts and music , as well as in generating images based on input text . However , they have not successfully applied to only these data sources . For instance , AlphaFold uses a Transformer architecture to predict protein structure [ 115 ] ; RecipeGPT to generate recipes [ 135 ] ; and GitHub Copilot to help write code [ 34 ] . 3 . 4 . 4 Critical Discussion . Given the fact that the Transformers can be considered as an evolution of sequence prediction models , the observations made for that class of models ( see Subsection 3 . 3 ) apply also for them . However , the inherent characteristics of their architecture allows for larger models and higher - quality outputs , which are also able to capture a variety of dependencies of text and across data sources . More in general , a broader conceptual space is induced . This means that domain - specific tasks might be addressed by means of solutions outside or at the boundary of the sub - space linked with that domain . Moreover , possibly also through a careful use of inputs ( see Subsection 3 . 7 ) , their adoption might lead to transformational creativity . As far as Boden‚Äôs criteria are concerned , there is no guarantee that outputs of Transformer architecture would be valuable , novel , or surprising . 3 . 5 Diffusion Models 3 . 5 . 1 Core Concepts . Diffusion models are a family of methods able to generate samples by gradually removing noise from a signal [ 217 ] . The most representative approach is the Denoising Diffusion Probabilistic Model ( DDPM ) [ 91 ] . An image x 0 is corrupted by gradually adding noise until obtaining an x T from a pre - defined distribution ; the model then has to reverse the process . Each timestep ùë° corresponds to a certain noise level ; x t can be seen as a mixture of ùë• 0 with some noise ùúñ whose ratio is determined by ùë° . The model learns a function ùúñ ùúÉ to predict the noise component of x t by minimizing the mean - squared error . x t ‚àí 1 is then obtained from a diagonal Gaussian with mean as a function of ùúñ ùúÉ ( x t , ùë° ) , and with variance fixed [ 91 ] or learned [ 172 ] . At inference time , a diffusion model can generate a new sample by starting from pure random noise . The generation can also be conditioned by simply modifying the noise perturbation so that it depends on the conditional information . This process is close to the one followed by score - based generative models [ 218 , 219 ] . Instead of noise , here a model is trained to learn the score , i . e . , the gradient of the log probability density with respect to real data . Samples are then obtained by using Langevin dynamics [ 244 ] . Despite the differences , they can anyway be considered diffusion models ( both of them can be seen as specific , discrete cases of Stochastic Differential Equations [ 220 ] ) . 3 . 5 . 2 Examples of Models . In order to generate higher - quality images and to allow text - to - image generation , a variety of effective methods for conditioning have been proposed . A possibility is to use classifier guidance [ 50 ] : the diffusion score ( i . e . , the added noise ) includes the gradient of the log likelihood of an auxiliary classifier model . An alternative is classifier - free guidance [ 93 ] : to avoid learning an additional model , a single neural network is used to parameterize two diffusion models , one conditional and one unconditional ; the two models are then jointly trained simply by randomly setting the class for the unconditional model . Sampling is finally performed using a linear combination of the conditional 11 Franceschelli and Musolesi and unconditional score estimates . GLIDE [ 171 ] demonstrates how classifier - free guidance can be effectively used to generate text - conditional images . In addition , it shows how diffusion models can be used for image editing by fine - tuning in order to reconstruct masked regions . Performance improvement can be obtained by means of a cascade of multiple diffusion models performing conditioning augmentation [ 92 ] . Finally , DALL - E 2 [ 188 ] generates images by conditioning with image representations . At first , it learns a prior diffusion model to generate possible CLIP image embeddings from a given text caption , i . e . , conditioned by its CLIP text embedding . Then , a diffusion decoder produces images conditioned by the image embedding . Imagen [ 200 ] uses instead a cascaded diffusion decoder , together with a frozen language model as text encoder to increase the quality of outputs . Although the approach is particularly suitable to images , applications to other data sources have been developed as well . For instance , DiffWave [ 128 ] and WaveGrad [ 34 ] use diffusion models to generate audio . They overcome the continuous - discrete dichotomy by working on waveform . Another possibility is to use an auto - encoder like MusicVAE [ 196 ] to transform the sequence into a set of continuous latent vectors , on which training a diffusion model [ 163 ] . Finally , diffusion models for video have also been proposed , based on a novel gradient - based conditioning method [ 94 ] . 3 . 5 . 3 Applications . Diffusion models have been introduced very recently and so far , they have been used to generate audio , music and video , as well as to generate and edit images conditioned on input text . We expect applications to other data sources in a near future . Indeed , they lead to higher - quality outputs with respect to the previous state - of - the - art models . In particular , DALL - E 2 has been able to produce images from textual instructions with superior fidelity and variety . 3 . 5 . 4 Critical Discussion . Diffusion models learn a mapping between real images and a Gaussian latent space . Because of this , they are an example of exploratory creativity : they randomly sample from that space , and then they possibly navigate it in the direction imposed by conditional inputs . There is no guarantee that the results will be valuable , novel or surprising , even though these approaches are able to generate outputs characterized by a high variety . As already argued , novelty and surprise may only arise due to the conditioning input ( for example , a human describing a novel combination of elements ) , i . e . , the model is not imaginative on its own . 3 . 6 Reinforcement Learning - Based Methods 3 . 6 . 1 Core Concepts . With Reinforcement Learning ( RL ) - based methods , we aim to indicate all the generative models whose training relies on maximizing a reward . These models are based on the architectures introduced so far , e . g . , they can be GANs or autoregressive models . The difference is that they are not ( only ) trained to fool the discriminative part , or to reduce prediction error . The typical framework considers the generative model as the agent ; each action causes a modification to the current product , i . e . , the state ; and the agent learns a policy that maximizes the cumulative reward . The reward can therefore be used to impose desired behavior to the generative model . The RL - based approach can be implemented for the entire training , as well as for fine - tuning a pre - trained model . 3 . 6 . 2 Examples of Models . We have already introduced a fully RL - trained model in Subsection 3 . 2 : ORGAN [ 82 ] . Here , RL is also used to provide additional learning signals , i . e . , additional rewards from specific - domain objectives . Also [ 252 ] follows this path by using rewards like fluency , coherence , meaningfulness and overall quality to generate poems . Another possibility is to use the metrics used at test time ( e . g . , BLEU or ROUGE ) [ 8 , 189 ] . Instead , RL - DUET [ 109 ] casts online music accompaniment generation as a RL problem with an ensemble of reward models , i . e . , autoregressive models trained with or without the whole context , and with or without the human - produced counterpart . In this way , 12 Creativity and Machine Learning : A Survey inter - coherence ( between human and machines ) and intra - coherence can be obtained . Finally , Intelli - Paint [ 212 ] can paint in human style by using a sequential planner that learns a painting policy to predict vectorized brushstroke parameters from the current state . RL can also be used to fine - tune a pre - trained generative model . Doodle - SDQ [ 261 ] at first learns to draw simple strokes by supervised learning ; then , it improves its generation by means of rewards about similarity , color , and line movement . Conversely , the authors of [ 225 ] suggest to consider a pre - trained LSTM language model as a policy model . Fine - tuning then aims at maximizing the probability that a given event occurs at the end of the narrative . RL Tuner [ 106 ] uses RL to fine - tune a Note - RNN to produce music that follows a set of music theory rules . To avoid forgetting note probabilities learned from data , the probability value returned by a copy of the pre - trained Note - RNN can be used as an additional reward . Sequence Tutor [ 104 ] generalizes this idea of learning a policy that trades off staying close to the data distribution while improving performance on specific metrics . Finally , also the authors of [ 129 ] suggest to fine - tune a language model by mixing up likelihood of training data and specific rewards , e . g . , repetition minimization . 3 . 6 . 3 Applications . As seen , RL - based models can be used to fully train or fine - tune generative models for different tasks ; ideally , for any task that could benefit from domain - specific objectives . This is the case of music and molecule generation [ 82 , 104 ] , but also of dialogue generation [ 140 ] and painting [ 100 ] . In addition , the sequential nature of RL can help as well in all the tasks requiring to deal with new directives during generation ( e . g . , music interaction ) . 3 . 6 . 4 Critical Discussion . The creativity evaluation of RL - based models depend on how the agent is implemented and which rewards are considered . The learned space of solutions depends on the used rewards ( and on the pre - training technique in case of fine - tuning ) . They typically contain an adversarial signal or the likelihood with respect to training data ; thus , combinatorial or exploratory creativity is obtained . However , additional rewards can have the effect of transforming that space ( see Subsection 3 . 8 ) . As far as Boden‚Äôs criteria are concerned , value is typically ensured by some qualitative domain - specific reward . Novelty and surprise might be achieved as well by means of specific rewards ; however , it is not the case of current models . Interestingly , the common presence of a value function ( e . g . , a critic network ) can make them appreciative , as requested by the creative tripod [ 40 ] . 3 . 7 Input - Based Methods 3 . 7 . 1 Core Concepts . The last class of methods we consider in our analysis is not about a different generative model . On the contrary , it is about a different way to sample results from ( pre - trained ) generative models , namely by means of its inputs . Two different approaches can be used . The first is about carefully selecting or optimizing the input to a generative model ( e . g . , the latent vector or the text prompt ) , so that to obtain the desired output . The second approach is about optimizing the input , so that it directly becomes the desired output . The used losses are based on features learned by neural networks . 3 . 7 . 2 Examples of Models . The first possibility is to carefully modify the input of a generative model , until the output matches desired properties . The main example is VQGAN - CLIP [ 46 ] . Given a text description , VQGAN [ 62 ] produces a candidate image from a random latent vector ; the vector is then optimized by minimizing the distance between the embeddings of the description and the candidate image . Both embeddings are computed using CLIP [ 184 ] . Variants can be implemented as in Wav2CLIP [ 247 ] , where an audio encoder is learned to match the CLIP encoders so that VQGAN - CLIP can be used from raw audio ; or as in music2video [ 103 ] , where videos are generated from audio a frame after the other by both minimizing distance between subsequent frames , and distance between image and music 13 Franceschelli and Musolesi segment embeddings by Wav2CLIP . Finally , image generators like VQGAN can also be exploited in other ways , i . e . , with binary - tournament genetic algorithm [ 66 ] or more complex evolution strategies [ 227 ] . Another possibility is to optimize the input so that the generated output maximizes a target neuron of an image classifier [ 170 ] . This helps generate what that neuron has learned . The desired latent vector can also be produced by an additional model [ 169 ] . The second solution is prompt tuning . Prompt tuning is about producing prompts via backpropagation ; the optimized prompts can then condition frozen language models in order to perform specific tasks without having to fine - tune them [ 137 ] . An additional model can be trained to output the desired prompt as well [ 138 ] . The third possibility is to optimize the input so that to transform it into the desired output . DeepDream [ 165 ] generates ‚Äúhallucinated‚Äù images by modifying the input in order to maximize the output of a certain level from a pre - trained classifier . Also artistic style transfer is based on the same idea . Given an input image and a target image , the input image is modified by means of both style and content losses thanks to a pre - trained classifier . The content loss is minimized if the current and the original input images cause the same outputs from the hidden layers . The style loss is minimized if the current and the target images have the same pattern of correlation between feature maps in the hidden layers [ 72 ] . Control over results can be improved by considering additional losses about colour , space , and scale [ 73 ] . 3 . 7 . 3 Applications . Input - based methods can be used with any generative model to produce the desired output . With language models , they can exploit their generality in several specific tasks without fine - tuning them . With image generators , they can obtain drawings adherent to given descriptions , or high - quality but yet peculiar paintings like colourist [ 66 ] , abstract [ 227 ] or alien [ 215 ] artworks . Videos can be generated too 6 , and we believe applications to other domains are yet to come . Both types of input - based methods can be used not only to produce desired outputs or to transfer styles ; they can also be used to better analyze what it is inside the network [ 170 , 177 ] . 3 . 7 . 4 Critical Discussion . Since input - based methods are applied on pre - trained generative models , the space of solutions in which they work is the one induced by those models , i . e . , the common spaces we can derive from real data . Nonetheless , some techniques may be able to cause productions that are outside that space or at its boundaries , i . e . , to cause transformational creativity . This can especially happen if the model is general , and the output for a specific task is not only sampled from the sub - space of solutions for that task ( e . g . , with prompt tuning over a language model ) . Input - based methods are also valuable : the input optimization itself is typically guided by some sort of qualitative loss . On the other hand , they are not explicitly novel or surprising ( even though the results might seem so ) . However , nothing prevents to optimize the loss in such directions ( see 3 . 8 ) . 3 . 8 Practical Assessment of Creativity - Oriented Methods We conclude this analysis of generative models with a discussion of how these models might improve in order to increase their creativity according to Boden‚Äôs definition . A straightforward way to obtain novel and surprising outputs is to train a generative model by means of novelty and surprise objectives . This is the core idea behind CAN ( Creative Adversarial Network ) [ 58 , 204 ] . In addition to the classic discriminative signal , i . e . , a value loss , the generator is also trained to optimize a novelty loss . This is defined as the deviation from style norms , i . e . , the error related to the prediction of the style of the generated image . The sum of the two training signals helps the model learn to produce artworks that are different ( in style ) from the training data . The same approach has been used to develop a creative StyleGAN , i . e . , StyleCAN [ 107 ] . Another , very simple way to augment the training signal of a generative model with creativity - oriented 6 Also artistic abstract videos can be produced by navigating the latent space : www . jakeelwes . com / project - latentSpace . html 14 Creativity and Machine Learning : A Survey objectives is by means of RL - based methods . The choice of the reward structure is the fundamental element of the design of effective generative reinforcement learning systems . Rewards should teach the model to generate an output with a high level of novelty and surprise . An example is ORGAN [ 82 ] , where appropriate reward functions can be used . Another possibility is the development of an input - based method where the input is optimized so that to obtain a product that is valuable , novel and surprising . This may be achieved either by forcing a further exploration of the latent space ( e . g . , by means of evolutionary search [ 65 ] ) , or by defining appropriate loss functions to perform gradient descent over the input . All these methodologies are also called as active divergence [ 14 ] , since they aim to generate in ways that do not simply reproduce training data . A survey on active divergence can be found in [ 22 ] . A different approach is followed by the Composer - Audience architecture [ 26 ] . Here , in order to produce surprising artifacts , two models are considered : the Audience , a simple sequence prediction model trained on a given dataset ; the Composer , another sequence prediction model trained on a different dataset . In addition , the Composer also receives the next - token expectations from the Audience . It therefore learns when it has to follow its dataset and to diverge from expectations , i . e . , when to be surprising . For instance , it can learn to produce jokes by considering non - humorous texts to train the Audience , and humorous texts to train the Composer . Even though this approach is useful to learn how to generate valuable and surprising outputs , it is only applicable when paired datasets are available . As far as the type of creativity is concerned , there can be ways to achieve a better exploration or even transformation of the space of solutions . For instance , since CAN novelty loss is used during training , it learns to diverge from the distribution of real data . The same is true for RL - based methods with novelty and surprise rewards ( especially if training happens from scratch ) . Finally , a more explored or transformed space may be reached by RL - based methods driven by curiosity [ 27 ] . Indeed , an agent can learn to be creative and discover new patterns thanks to intrinsic rewards to measure novelty , interestingness and surprise . This can be done by training a predictive model of the growing data history , and by using its learning progress as the reward for the agent . In this way , it is motivated to make things the predictor does not yet know . If an external qualitative reward is considered as well , the agent should in theory learn to do things that are new , but still valuable [ 205 ] . The same idea can also be applied to different techniques like evolutionary strategies [ 149 ] . DeLeNoX ( Deep Learning Novelty Explorer ) [ 142 ] uses a denoising autoencoder to learn low - dimensional representations of last generated artifacts . Then , a population of candidate artifacts ( in terms of their representation ) is evolved through feasible - infeasible novelty search [ 143 ] in order to maximize distances between them , i . e . , to increase their novelty , while still considering qualitative constraints . Other evolutionary strategies might be considered as well to search the space of artifacts for novel [ 136 ] and surprising [ 79 ] results . Table 1 summarizes all the generative approaches discussed in this section , highlighting their characteristics from a machine creativity perspective . 4 CREATIVITY MEASURES In this section we present different methodologies for evaluating the creativity of artifacts generated by artificial agents . These can typically be extended to human - generated artifacts . For each of them , we explore the core concepts , the dimensions of creativity that are considered and the protocol for evaluation , and , finally , we critically assess them . The presence of several different proposals can be associated to the fact that it is not always straightforward to determine the ‚Äúright‚Äù question to ask in an evaluation of a creative artifact [ 71 ] . This is also highlighted by the absence of creativity evaluation approaches in the GEM ( Generation , Evaluation , and Metrics ) Benchmark for natural language generation [ 74 ] . This is due to the inadequacy of the creative metrics proposed until now . The focus of our overview is on measures that are based on or associated to machine learning techniques . It is worth noting that some of them 15 Franceschelli and Musolesi Generative family Type of creativity Boden‚Äôs criteria Creative tips VAE Exploratory ‚àº‚àº‚àº Value ‚àº‚àº‚àº Novelty ‚àº‚àº‚àº Surprise Creativity - oriented input - based methods GAN Exploratory ‚úì‚úì‚úì Value ‚àº‚àº‚àº Novelty ‚àº‚àº‚àº Surprise CAN ; Creativity - oriented input - based methods Sequencepredictionmodel Combinatorial , Exploratory ‚àº‚àº‚àº Value ‚àº‚àº‚àº Novelty √ó√ó√ó Surprise Composer - Audience ; Creativity - oriented RL - based methods Transformer - basedmodels Combinatorial , Exploratory , Transformational ‚àº‚àº‚àº Value ‚àº‚àº‚àº Novelty √ó√ó√ó Surprise Creativity - oriented prompt tuning or RL - based methods Diffusion models Exploratory ‚àº‚àº‚àº Value ‚àº‚àº‚àº Novelty ‚àº‚àº‚àº Surprise Creativity - oriented input - based methods RL - based methods Combinatorial , Exploratory , Transformational ‚úì‚úì‚úì Value ‚àº‚àº‚àº Novelty ‚àº‚àº‚àº Surprise Intrinsic rewards ; Novelty - based rewards Input - based methods Exploratory , Transformational ‚úì‚úì‚úì Value ‚àº‚àº‚àº Novelty ‚àº‚àº‚àº Surprise Evolutionary search ; Novelty - based optimization Table 1 . Summary of all the methods explained so far , considering their type of creativity ; the possible presence of Boden‚Äôs criteria ; and some practical tips to achieve a higher degree of creativity . might be calculated without using machine learning , but we will refer to an implementation based on the latter . For an in - depth overview about creativity measures not strictly related to machines , we refer to [ 201 ] . Table 2 reports all the evaluation methods considered in this section , highlighting the dimensions they try to capture , their applicability and limitations . We will discuss these aspects in the remainder of this section . 4 . 1 Lovelace 2 . 0 Test 4 . 1 . 1 Overview . The Lovelace Test ( LT ) [ 21 ] was proposed in 2001 as a creativity - oriented alternative to the world - famous Turing Test [ 232 ] . More formally , LT is defined as follows : Definition 4 . 1 . An artificial agent ùê¥ , designed by ùêª , passes LT if and only if : 1 ) ùê¥ outputs ùëú ; 2 ) ùê¥ ‚Äôs outputting ùëú is not the result of a fluke hardware error , but rather the result of processes ùê¥ can repeat ; 3 ) ùêª ( or someone who knows what ùêª knows , and has ùêª ‚Äôs resources ) cannot explain how ùê¥ produced ùëú by appeal to ùê¥ ‚Äôs architecture , knowledge - base , and core functions . LT provides several insights for understanding and quantifying machine creativity , but it is rather abstract . For these reasons , a 2 . 0 version has then been proposed [ 194 ] . The so - called Lovelace 2 . 0 Test is defined as : Definition 4 . 2 . Artificial agent ùê¥ is challenged as follows : 16 Creativity and Machine Learning : A Survey Name What evaluates How evaluates Applicability Limits Lovelace 2 . 0 Test What evalua - tors state creativity is Mean number of challenges per evaluator passed General ‚Ä¢ Require a massive human intervention Ritchie‚Äôscriteria Quality , novelty , typicality Human opinions ( then elaborated through 18 criteria ) General ‚Ä¢ Require human evaluation ‚Ä¢ Require to state thresholds ‚Ä¢ No innovation definition FACE Tuples of generativeacts Volume of acts , number of acts , quality ( through aesthetic measure ) General ‚Ä¢ Not a punctual method ‚Ä¢ Definition of aesthetic measure left to the user SPECS What we state creativity is Identification and test of standards for the creativity components General ‚Ä¢ More a framework for eva - luation method definition than a real method Creativity implication network Value , novelty Similarity between works ( considering subsequent works for value and pre - vious works for novelty ) General ‚Ä¢ No chance to correctly com - pute creativity for last works ‚Ä¢ Wrong creativity and time - positioning correlation Chef Watson ( assessment part ) Novelty , quality Bayesian surprise , smell pleasantness regression Specific ( recipes ) ‚Ä¢ Require human ratings of pleasantness DARCI Art appreciation Neural network to associate image featu - res and description Specific ( visual art ) ‚Ä¢ Not based on product ‚Ä¢ Consider just one of the creative tripod PIERRE - Evaluation part Novelty , quality Count of new combi - nations ; user ratings Specific ( recipes ) ‚Ä¢ Require user ratings over ingredients EVE‚Äô Feelings , meanings Negative log of prediction and posterior probability General ‚Ä¢ Require a way to explain ‚Ä¢ Value only through meaning Common model of creativity for design Novelty , value , surprise K - Means on a description space and a performance space ; degree of violation of anticipated patterns Specific ( design ) ‚Ä¢ Require to define attribute - value pairs ‚Ä¢ Require to define clustering parameters Regent - Dependent creativity metric Novelty , value Bayesian surprise and synergy General ‚Ä¢ Require to define and extract features Unexpectedness Novelty , sur - prise , trans - formativity Possibility to update , and degree of violation of expectations General ‚Ä¢ Not take care of value Essential criteria of creativity Value , novelty , surprise Sum of performance va - riables , distance between artifacts and between re - al and expected artifact General ‚Ä¢ Require to define performance variables ‚Ä¢ Require to define clustering parameters Computationalmetricsforstorytelling Novelty , rarity , recreationaleffort , surprise Distance between do - minant terms , consecutive fragments / clusters of terms Specific ( storytelling ) ‚Ä¢ Require to define domination ‚Ä¢ Require to define clustering parameters Table 2 . Summary of creativity evaluation methods and their characteristics . 17 Franceschelli and Musolesi 1 ) ùê¥ must create an artifact ùëú of type ùë° ; 2 ) ùëú must conform to a set of constraints ùê∂ where ùëê ùëñ ‚àà ùê∂ is any criterion expressible in natural language ; 3 ) a human evaluator ‚Ñé , having chosen ùë° and ùê∂ , is satisfied that ùëú is a valid instance of ùë° and meets ùê∂ ; 4 ) a human referee ùëü determines the combination of ùë° and ùê∂ to not be unrealistic for an average human . 4 . 1 . 2 Dimensions of Creativity Considered . Since the evaluation depends on the tests performed by the human evaluators , the dimensions of creativity considered by it might vary greatly . This allows for considering value , novelty and surprise , as well as domain - specific dimensions . 4 . 1 . 3 Protocol for Evaluation . The Lovelace 2 . 0 Test can be used to quantify the creativity of an artificial agent - by means of its artificial productions - considering a set ùêª of human evaluators . With ùëõ ùëñ as the first test performed by evaluator ‚Ñé ùëñ ‚àà ùêª not passed by the agent , the creativity of the artificial agent can be expressed as the mean number of challenges - per - evaluator passed : (cid:205) ùëñ ( ùëõ ùëñ ) | ùêª | . 4 . 1 . 4 Critical Examination . This methodology represents an effective way to measure creativity , since it is ideally applicable to any field and it is quantitative . Even though it is not based on machine learning , the latter may be used in principle for performing ( some of ) the tests . This methodology requires considerable human intervention , and , for this reason , it cannot be used for automatic evaluation . 4 . 2 Ritchie‚Äôs Criteria 4 . 2 . 1 Overview . Ritchie‚Äôs Criteria [ 195 ] are a set of criteria for evaluating the extent to which a program has been creative ( or not ) in generating artifacts . These criteria are based on three main factors : novelty , quality and typicality . [ 195 ] contains a proposed series of criteria , but according to the authors they should only be intended as a ‚Äúrepertoire‚Äù . 4 . 2 . 2 Dimensions of Creativity Considered . Ritchie‚Äôs Criteria are based on three factors : quality , typicality , novelty . Quality measures how much an item is a high quality example of its genre . Typicality measures how much an item is an example of the artefact class in question . Novelty measures the dissimilarity of an item with respect to existing examples in its class . Quality and typicality are collected using human opinions about the produced artifacts or using ‚Äúmeasurable‚Äù characteristics about , for instance , syntax and metric ( for poetry generator ) . On the other hand , novelty is intended as the sum of ‚Äúuntypicality‚Äù ( the opposite of typicality ) and innovation . 4 . 2 . 3 Protocol for Evaluation . The computation of the criteria is based on the analysis of the result set of produced artifacts , alongside with the inspiring set ( composed by artifacts of that field used during training and / or generation ) . It also requires the definition of quality and typicality indicators for the considered artifacts . More specifically , the proposed criteria are : the average of typicality or quality over the result set ; the proportion of items with good typicality score , which is also characterized by high quality ; the proportion of the output that falls into the category of untypical but high - valued ; the ratio between untypical high - valued items and typical high - valued items ; the proportion of the inspiring set that has been reproduced in the result set . The assessment of these criteria is performed before on the entire result set and then only on the subset not containing any item from the inspiring set . 4 . 2 . 4 Critical Examination . These measures represent a promising way of evaluating creativity , but their application does not appear as straightforward . In fact , they do not clearly specify how to measure novelty in terms of innovation . In addition , all the measures require a large number of thresholds to be set ( and results are very sensitive to such thresholds [ 180 ] ) . The criteria for the selection of these thresholds are not trivial per se . It is difficult to identify a 18 Creativity and Machine Learning : A Survey general methodology for setting their values . Finally , the collection of correct human opinions ( in terms of consistency of measurement methodology , audience selection , etc . ) is not a trivial task either . 4 . 3 FACE 4 . 3 . 1 Overview . In [ 42 ] the authors introduce FACE as a descriptive model of the creative act of artificial systems . A creative act is considered as a non - empty tuple of generative acts . FACE is designed to provide the assessors with both quantitative and qualitative evaluations . 4 . 3 . 2 Dimensions of Creativity Considered . While FACE can be used to evaluate a product as the consequence of a creative act , its focus is on the process . The qualitative evaluation is therefore left to the aesthetic function ; the dimensions considered depend in turn on how it has been defined ( or generated ) . 4 . 3 . 3 Protocol for Evaluation . More specifically , the FACE model considers a creative act as a non - empty tuple of generative acts of eight possible types : an expression of a concept , i . e . , an instance of an ( input , output ) pair produced by the system ; a method for generating expressions of a concept ; a concept ; a method for generating concepts ; an aesthetic measure ; a method for generating aesthetic measures ; an item of framing information , i . e . , an additional information or description regarding the generative act ; a method for generating framing information . It is then possible to use it in a quantitative way ( how many acts are produced ) ; in a cumulative way ( how many types of acts are considered ) ; and in a qualitative way ( by means of the defined aesthetic measure ) . 4 . 3 . 4 Critical Examination . The FACE model represents a very comprehensive set of concepts and methodologies for assessing machine creativity . However , one of the most challenging aspects of FACE is the definition of the aesthetic measure , which is not specified ; potentially , it might be defined by the system itself , counting as a potential creative act . This may award systems performing self - evaluation , i . e . , guiding their generation based on learned objectives . This in theory might mean the systems are incentivized to develop their own tastes , which is an important part of human creativity . 4 . 4 SPECS 4 . 4 . 1 Overview . The Standardized Procedure for Evaluating Creative Systems ( SPECS ) [ 112 ] is a framework for the evaluation of creative systems , which can easily be adapted to many different potential domains . The framework is based on the definition of fourteen ‚Äúcomponents‚Äù used for the evaluation of machine creativity . 4 . 4 . 2 Dimensions of Creativity Considered . The fourteen key components of SPECS are : active involvement and persis - tence ; dealing with uncertainty ; domain competence ; general intellect ; generation of results ; independence and freedom ; intention and emotional involvement ; originality ; progression and development ; social interaction and communication ; spontaneity / subconscious processing ; thinking and evaluation ; value ; variety , divergence , experimentation . However , SPECS does not constrain researchers to use all of them ; moreover , domain - specific components can be added as well . 4 . 4 . 3 Protocol for Evaluation . SPECS is composed of three steps . The first one requires to provide a definition of creativity that the system should satisfy , using the suggested components , and potentially other domain - specific ones . The second requires to specify the standards to be used to evaluate such components . Finally , the third requires to test the system against the standards and to report the results . 19 Franceschelli and Musolesi 4 . 4 . 4 Critical Examination . This is an effective framework for working with computational creativity , but it cannot be a practical evaluation method . Its effectiveness is strongly dependent on which components are considered and how they are evaluated for each specific task . In [ 113 ] the author discusses how SPECS satisfies Ritchie‚Äôs criteria and it is more comprehensive and expressive than the FACE model and the creative tripod [ 40 ] ( according to which a creative system should exhibit skills , appreciation and imagination ) in a meta - evaluation test . They also use a human opinion survey based on five criteria : correctness , usefulness , faithfulness ( as a model of creativity ) , usability ( of the methodology ) and generality . SPECS is evaluated considering music improvisation generators and it is also judged by the developers of the generative systems . In particular , the authors show that SPECS can help obtain additional insights on how a generative model works and how it can be improved . 4 . 5 Creativity Implication Network 4 . 5 . 1 Overview . A different method to quantify creativity is based on building an art graph called Creativity Implication Network [ 59 ] . Given a set of artworks , a directed graph can be defined by considering a vertex for each artwork . More specifically , an arc connecting artwork ùëù ùëñ to ùëù ùëó is inserted if ùëù ùëñ has been created before ùëù ùëó . A positive weight ùë§ ùëñùëó quantifying the similarity score between the two artworks under consideration is associated to each arc . The creativity of an artwork is then derived by means of computations on the resulting graph . 4 . 5 . 2 Dimensions of Creativity Considered . This method captures both value and novelty . The value is defined as the influence on future artworks . The novelty is defined as the dissimilarity between the artwork and the previous ones . 4 . 5 . 3 Protocol for Evaluation . The derivation of the Creativity Implication Network requires a similarity function to compute the similarity scores ; its definition is left to the researchers , but it can be based on ML techniques ( as done in the original paper , where computer vision techniques were used ) . Given the network , the creativity of an artwork ùëù ùëñ depends on the similarity with the previous artworks ( higher the similarity , lower the creativity ) and with the subsequent artworks ( higher the similarity , higher the creativity ) . 4 . 5 . 4 Critical Examination . The Creativity Implication Network represents an effective way to deal with creativity of sets of artworks . It considers both value and novelty , and it allows for using automated techniques in the computation of similarity . On the other hand , two drawbacks should be highlighted . The first one is related to artworks that occupy the position of ‚Äúleaves‚Äù in the graph : if there are not subsequent works in the graph , their creativity would only be based on novelty , and not on value . The second one is more subtle , and it is about time - positioning . As demonstrated by [ 59 ] , moving back an artwork has the effect of increasing its creativity ; however , this appears as conceptually wrong . As discussed in [ 16 ] , the time location of an artwork is fundamental in the quantification of its creativity . It may happen that , due to the surprise component of creativity , an artwork that appears too early might not be considered as surprising , because observers are not able to truly understand it ; on the contrary , if it appears too late , it might be considered as obvious and not surprising at all . In conclusion , even if this approach is able to correctly capture value and novelty , it is not able to capture the concept of surprise . 4 . 6 Generate - and - Test Setting 4 . 6 . 1 Overview . Generate - and - test setting [ 228 ] is a family of methods based on the separation of the generative process in two phases : generation , and evaluation . Assuming that gen ( ) denotes the generative function of the system , and a an artifact generated by the function . Then , a is evaluated by another function eval ( a ) that has to assess the 20 Creativity and Machine Learning : A Survey degree of creativity of a . If it passes the evaluation , it is outputted by the system . For example , the authors of [ 238 ] use this approach to develop a computational creativity system for generating culinary recipes and menus called Chef Watson . [ 43 ] describes an augmentation of Painting Fool [ 41 ] with DARCI [ 174 ] in a generate - and - test setting ( i . e . , by using The Painting Fool for generation , and DARCI for evaluation ) . PIERRE [ 166 ] is based as well on two models , one for generating recipes by means of a genetic algorithm , and one for evaluating them . 4 . 6 . 2 Dimensions of Creativity Considered . The dimensions of creativity considered depend on the specific implemen - tation of the evaluation function . Different evaluation functions have been designed to evaluate , for example , quality and novelty [ 166 , 238 ] and art appreciation [ 43 ] . It is worth noting that , given the generality of the approach , other evaluation functions could be designed to capture other aspects of machine creativity . 4 . 6 . 3 Protocol for Evaluation . The protocol for evaluation strictly depends on the specific implementation of the eval ( a ) function . For instance , Chef Watson [ 238 ] uses two measures : flavorfulness for quality , and Bayesian surprise for novelty . Flavorfulness is computed by means of a regression model , built on olfactory pleasantness considering its constituent ingredients . Bayesian surprise [ 10 ] is a measure of surprise in terms of the impact of a piece of data that changes a prior distribution into a posterior distribution , calculated applying Bayes‚Äô theorem . The surprise is then the distance between posterior and prior distributions . It is worth noting that it has been demonstrated that there exists a mathematical limit in the maximization of quality and novelty when novelty is expressed in terms of Bayesian Surprise [ 237 ] . On the other hand , The Painting Fool [ 41 ] uses DARCI [ 174 ] in place of the evaluation function . DARCI is able to make associations between image features and descriptions of the images learned using a series of artificial neural networks as the basis for the appreciation . It has therefore been used as a sort of artificial art critic to complement The Painting Fool , allowing it to assess the validity of its own creations . Finally , PIERRE [ 166 ] evaluates the generated recipes again using novelty and quality . Novelty is computed by counting new combinations of used ingredients . Quality is based on two NNs that perform a regression of user ratings based on the amount of different ingredients , working at two levels of abstraction . 4 . 6 . 4 Critical Examination . The advantage of the generate - and - test setting is that a variety of evaluation functions can be defined . This allows , for instance , to evaluate the generative system by means of Boden‚Äôs three criteria , while still considering the specific characteristics of the domain of interest . On the other hand , its applicability is not general : as we have seen in the previous section , many generative systems do not follow the proposed setting ( e . g . , input - based methods use the evaluation to guide the generation , thus merging the two stages ) . 4 . 7 Atoms of EVE‚Äô 4 . 7 . 1 Overview . Even if not strictly related to creativity , [ 30 ] proposes an approach to measure aesthetic experience called atoms of EVE‚Äô , which is based on a probabilistic model of the world to derive expectations and explanation . The authors state that aesthetic arises in two ways : by forming E ( expectation ) while avoiding V ( violation ) ; and by forming E‚Äô ( explanation ) while resolving V . 4 . 7 . 2 Dimensions of Creativity Considered . Even if not explicitly considered , the three grounding concepts of Atoms of EVE‚Äô strongly intertwine with creativity . Expectation is close to value : it measures how much we are able to understand the object of interest . Violation is close to surprise : it is the unexpectedness of an object at a certain moment . Explanation is again close to value : it measures the intelligibility ( i . e . , its usefulness ) . These same considerations have been expressed 21 Franceschelli and Musolesi by [ 31 ] , where the author uses EVE‚Äô to define a creativity measure based on feelings ( i . e . , surprise ) , computed thanks to violation , and meanings ( i . e . , value ) , computed thanks to explanation . 4 . 7 . 3 Protocol for Evaluation . Expectation is computed as the posterior probability after the occurrence of a given object : it measures how much the prior belief can help explain that object . Violation is instead computed as the unexpectedness of that object . Together with apprehension , which is the unpredictability of the next object ( before seeing it ) , violation returns the tension , one of the two fundamental measures of aesthetics . Finally , explanation measures how much the encountered violation can be explained by the posterior belief . Together with expectation , explanation returns a quantification of pleasure , the other fundamental measure of aesthetics . 4 . 7 . 4 Critical Examination . As observed before , while such a computation for surprise is common , this is not true for value . The focus on explanations provides an interesting way to mathematically define value . However , value is not only about finding meaning , but also about utility , performance and attractiveness [ 152 ] ; this is not possible through this measure . Finally , novelty is not considered at all . 4 . 8 Common Model of Creativity for Design 4 . 8 . 1 Overview . The authors of [ 153 ] propose a model to evaluate creativity in the specific domain of design . In particular , they consider creativity as a relative measure in a conceptual space of potential and existing designs . Designs are represented by attribute - value pairs ; and novelty , value and surprise can be used to capture different aspects of creativity in their space . 4 . 8 . 2 Dimensions of Creativity Considered . The model proposed by [ 153 ] considers all the three dimensions suggested by [ 16 ] , i . e . , novelty , value , and surprise . Novelty is considered as a matter of comparing objects in a descriptive space ; it is the degree of difference . Value is related to performance , i . e . , utility preferences associated with the attributes of an object . Finally , surprise is linked to violated expectations . 4 . 8 . 3 Protocol for Evaluation . The model is based on the analysis of the conceptual space of potential and existing designs defined by all the potential attribute - value pairs . Novelty is evaluated with respect to a description space , i . e . , by considering each product as the set of its descriptive attributes . Value is considered with respect to a performance space , i . e . , by considering attributes that have utility preferences associated with them . Finally , surprise is based on finding violations of patterns that is possible to anticipate in the space of both current and possible designs . The K - means clustering algorithm is used to organize the known designs by means of their attributes . Then , novelty , value and surprise measures of a new design are obtained looking at the distance to the nearest cluster centroid . 4 . 8 . 4 Critical Examination . Even if it targets explicitly the design domain , this approach is able to combine the three dimensions of creativity by Boden . Nonetheless , it is limited by the fact that artifacts have to be described through an attribute - value pair representation . In particular , a large number of features might be needed . Otherwise , we might lose aspects of the artifacts that are fundamental to correctly quantify creativity . Since it is not possible to know the fundamental features in advance , the method requires to enumerate as many features as possible . However , the risk is to define an excessive number of non - informative attributes , making the computation of the metrics too difficult . In fact , the data points become increasingly ‚Äúsparse‚Äù as the dimensionality increases ; many techniques ( especially the clustering ones ) are based on distance , and they may therefore suffer from the curse of dimensionality [ 221 ] . Finally , as for classic machine learning techniques , there is the need of manually defining and extracting the chosen features 22 Creativity and Machine Learning : A Survey from unstructured data , which is a time - consuming and potentially prone - to - error activity . A possible way to overcome the problems related to feature extraction and the curse of dimensionality might be the adoption of deep learning techniques , given their effectiveness with unstructured data . 4 . 9 Regent - Dependent Creativity Metric 4 . 9 . 1 Overview . The Regent - Dependent Creativity metric [ 69 ] is based on novelty and value . The name comes from the Regent - Dependent Model , a proposed method to describe artifacts as collections of features , i . e . , through sets of pairs with a regent ( e . g . , an action or an attribute ) and a dependent ( e . g . , the specific target or value of the regent ) , labeled with a value to express the intensity of that pair in that context . 4 . 9 . 2 Dimensions of Creativity Considered . As explained above , the Regent - Dependent creativity metric considers novelty and value as dimensions of creativity . In particular , value is dependent on the associations and rules that bond artifacts in a specific context , which defines what is worth of interest , and what is not . 4 . 9 . 3 Protocol for Evaluation . Novelty and value are computed through Bayesian surprise ( see 4 . 6 . 3 ) and synergy , respectively . In particular , synergy is a metric that captures the cooperative nature of constituent elements of an artifact . It is based on modeling the artifacts as graphs . The vertices are the dependency pairs of the artifact . The edges between pairs exist only if they belong to the same set of synergy , i . e . , if they exhibit a better effect together than separately . 4 . 9 . 4 Critical Examination . In contrast with the approach described before , the Regent - Dependent metric appears to be of more general applicability . However , only novelty and value are considered , and surprise is missing . In addition , just as detailed in 4 . 8 . 4 , this method is limited by requiring the definition and the extraction of all the features to compute creativity . 4 . 10 Unexpectedness Framework 4 . 10 . 1 Overview . The authors of [ 78 ] suggest that a framework of unexpectedness ( i . e . , violation of an observer‚Äôs expectations ) can deal with novelty , surprise and domain transformation ( also called transformativity ) . Although they do not claim it can be a measure of creativity on its own , and that value should be added as well , they suggest it can become a vital component in computational creativity evaluation . 4 . 10 . 2 Dimensions of Creativity Considered . The authors of [ 78 ] suggest that unexpectedness can be used to compute three dimensions of creativity : novelty , surprise and transformativity . Indeed , novelty is about the possibility of violating observer‚Äôs expectations about the continuity of a domain ; if the current model of belief is not applicable for the current artifact , it can be considered as novel . Surprise is instead about the possibility of violating observer‚Äôs expectations about an artifact . Finally , transformativity is about the possibility of violating observer‚Äôs expectations about the conceptual space itself ( i . e . , finding that the rules governing it were not accurate ) . 4 . 10 . 3 Protocol for Evaluation . The unexpectedness framework should allow to model expectation . Notably , expectation should be linked with the socio - cultural context of the observer , since it is the observer that forms expectation , not the domain itself . In particular , an expectation is generated by a prediction about the predicted ( i . e . , the dependent variables of the artifact ) given a condition ( i . e . , a relationship between the predicted property and some other property of the object ) that applies within a scope ( i . e . , the set of possible artifacts to which the expectations apply ) . An observation that falls within that scope can then be measured for congruence with respect to that expectation . 23 Franceschelli and Musolesi 4 . 10 . 4 Critical Examination . The unexpectedness measure appears to be able to provide researchers and practitioners with a way for deriving novelty and surprise . Notably , it also captures transformativity , clarifying at the same time how simple surprise differs from it , i . e . , that surprise is related with expectations about a single artifact , while transformativity is related with expectations about the entire domain . However , it requires to define its conceptual space in terms of explicit rules , which can be violated ( and so that such a violation can be calculated ) . In addition , it does not include value in the assessment of machine creativity . 4 . 11 Essential Criteria of Creativity 4 . 11 . 1 Overview . The metric proposed by [ 152 ] is based on three components : novelty , value and surprise . It relies on the idea that a creativity metric has to be independent not only from the domain , but also from the producer . 4 . 11 . 2 Dimensions of Creativity Considered . The criteria of creativity defined by [ 152 ] cover exactly the Boden‚Äôs three criteria . In particular , novelty is intended as how different the artifact is from known artifacts in its class . Value is quantified considering how the potentially creative artifact compares in utility , performance , or attractiveness to other artifacts in its class . Finally , unexpectedness is defined as the variation from expectation developed for the next new artifact in its class . 4 . 11 . 3 Protocol for Evaluation . Novelty is calculated as the distance between the artifact of interest and the other artifacts in its class . The partition in classes is obtained by means of a clustering algorithm . Surprise is calculated considering whether or not the artifact agrees with the expected next artifact in the pattern extracted from recent artifacts . More specifically , it is calculated as the difference between the expected next artifact and the real next artifact . Such a pattern is predicted by a self - supervised neural network ; predictions are refined using reinforcement learning to correct the learned trajectory in case of sequential data . Finally , value is calculated as the weighted sum of the performance variables of the artifact . The weights depend on a co - evolutionary algorithm with a fitness function that can change over time in case the current population of artifacts changes . 4 . 11 . 4 Critical Examination . The method considers all the three Boden‚Äôs criteria ; it is not linked to a specific domain , or the producer itself ; it deals with the evolution of creativity , capturing its volatile nature at the same time . However , in our opinion , it is limited in terms of applicability by the fact it requires the definition of performance variables ( similarly to other approaches based on attribute - value pairs , see 4 . 8 . 4 ) . Moreover , the setting of the parameters of clustering algorithms at the basis of this method and the definition of distances among artifacts require human fine - tuning . 4 . 12 Computational Metrics for Storytelling 4 . 12 . 1 Overview . For the specific case of storytelling , the authors of [ 117 ] propose a set of computational metrics in order to compute evaluation of novelty , surprise , rarity and recreational effort . 4 . 12 . 2 Dimensions of Creativity Considered . Novelty and surprise are evaluated according to the standard Boden‚Äôs definition , while rarity is intended as rare combination of properties and recreational effort as the difficulty to achieve a specific result . 4 . 12 . 3 Protocol for Evaluation . Novelty is computed as the average semantic distance between the dominant terms included in the textual representation of the story , compared to the average semantic distance of the dominant terms in all stories . Surprise is computed as the average semantic distance between the consecutive fragments of each story . 24 Creativity and Machine Learning : A Survey Rarity is computed as the distance between the individual clusters of each term in each story and those in the story set . Finally , recreational effort is computed as the number of different clusters each story contains . 4 . 12 . 4 Critical Examination . Although value is not considered , the proposed metrics appear to be appropriate to evaluate novelty and surprise . Nonetheless , they suffer from two problems : they are intrinsically domain - specific and they require that all the types of clusters are defined correctly , which is very difficult to ensure in general . 5 OUTLOOK AND CONCLUSION In this survey , we have provided the reader with an overview of the state of the art at the intersection between creativity and machine learning . Firstly , we have introduced the concept of machine creativity , including key concepts and definitions . Secondly , we have described a variety of generative learning techniques , considering their potential applications and limitations . Finally , we have discussed several evaluation frameworks for quantifying machine creativity , highlighting their characteristics and the dimensions they are able to capture . Even if the field of machine creativity has witnessed a large interest in the recent years , but there are still several open challenges . First of all , an interesting direction is the exploration of creativity - oriented objective functions , to directly train models to be creative , or to navigate the induced latent space to find creative solutions . Another open problem is the definition of techniques for exploring or transforming the space of solutions . A fundamental area is the definition of novel and robust evaluation techniques for both generated and real artifacts . As discussed in 4 , deep learning might be used as a basis for the definition of metrics for machine creativity . It is worth noting that there is also an ongoing debate around the role of human versus machine evaluation [ 130 ] . Another promising research direction concerns machine interpretation of art [ 1 ] . Moreover , machine learning techniques might also be used to investigate psychological dimensions of creativity [ 2 ] . There are also foundational questions related to generative deep learning and copyright [ 68 ] . For example , it is not clear if machine - generated works could be protected by Intellectual Property , and , if they are , who should be the owner of the related rights [ 202 ] . In addition , other problems related to copyright should be considered , such as if and when training over protected work is permitted [ 216 ] . Another ongoing important debate is about authorship and the human role in creative fields in the era of AI 7 . The models and framework discussed in this work show the remarkable potential of generative learning for machine creativity . We hope that this survey will represent a valuable guide for researchers and practitioners working this fascinating cross - disciplinary and trans - disciplinary area . REFERENCES [ 1 ] Panos Achlioptas , Maks Ovsjanikov , Kilichbek Haydarov , Mohamed Elhoseiny , and Leonidas Guibas . 2021 . ArtEmis : Affective Language for Art . In 2021 IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Nashville , TN ) . IEEE , 11569 ‚Äì 11579 . [ 2 ] Sergio Agnoli , Laura Franchin , Enrico Rubaltelli , and Giovanni Emanuele Corazza . 2019 . The Emotionally Intelligent Use of Attention and Affective Arousal under Creative Frustration and Creative Success . Personality and Individual Differences 142 ( 2019 ) , 242 ‚Äì 248 . [ 3 ] Hassan Akbari , Liangzhe Yuan , Rui Qian , Wei - Hong Chuang , Shih - Fu Chang , Yin Cui , and Boqing Gong . 2021 . VATT : Transformers for Multimodal Self - SupervisedLearningfromRawVideo , AudioandText . In AdvancesinNeuralInformationProcessingSystems ( Online ) , Vol . 34 . CurranAssociates , Inc . , 24206 ‚Äì 24221 . [ 4 ] Andrei G . Aleinikov , Sharon Kackmeister , and Ron Koenig . 2000 . Creating Creativity : 101 Definitions ( what Webster Never Told You ) . Alden B . Dow Creativity Center Press , Midland , MI . [ 5 ] Jyoti Aneja , Alexander G . Schwing , Jan Kautz , and Arash Vahdat . 2021 . A Contrastive Learning Approach for Training Variational Autoencoder Priors . In Advances in Neural Information Processing Systems ( Online ) , Vol . 34 . Curran Associates , Inc . , 480 ‚Äì 493 . 7 This is one of the ethical dilemmas highlighted by UNESCO in its Preliminary study on the Ethics of Artificial Intelligence . 25 Franceschelli and Musolesi [ 6 ] Anurag Arnab , Mostafa Dehghani , Georg Heigold , Chen Sun , Mario Lucic , and Cordelia Schmid . 2021 . ViViT : A Video Vision Transformer . In 2021 IEEE / CVF International Conference on Computer Vision ( ICCV ) ( Montreal , Canada ) . IEEE , 6836 ‚Äì 6846 . [ 7 ] Charles Babbage . 1864 . Of the Analytical Engine . In Passages from the Life of a Philosopher . Vol . 3 . Longman , Green , Longman , Roberts , & Green , 112 ‚Äì 141 . [ 8 ] Dzmitry Bahdanau , Philemon Brakel , Kelvin Xu , Anirudh Goyal , Ryan Lowe , Joelle Pineau , Aaron Courville , and Yoshua Bengio . 2017 . An Actor - Critic Algorithm for Sequence Prediction . [ 9 ] Dzmitry Bahdanau , Kyunghyun Cho , and Yoshua Bengio . 2015 . Neural Machine Translation by Jointly Learning to Align and Translate . In International Conference on Learning Representations ( San Diego , CA ) , Vol . 3 . [ 10 ] Pierre Baldi and Laurent Itti . 2010 . Of Bits and Wows : A Bayesian Theory of Surprise with Applications to Attention . Neural networks : the official journal of the International Neural Network Society 23 ( 2010 ) , 649 ‚Äì 666 . [ 11 ] Hangbo Bao , Li Dong , and Furu Wei . 2022 . BEiT : BERT Pre - Training of Image Transformers . In International Conference on Learning Representations ( Online ) , Vol . 10 . OpenReview . net . [ 12 ] Yoshua Bengio , Patrice Simard , and Paolo Frasconi . 1994 . Learning Long - Term Dependencies with Gradient Descent is Difficult . IEEE Transactions on Neural Networks 5 , 2 ( 1994 ) , 157 ‚Äì 166 . [ 13 ] Walter Benjamin . 2008 . The Work of Art in the Age of Mechanical Reproduction . Penguin Books Ltd , London , UK . [ 14 ] Sebastian Berns and Simon Colton . 2020 . Bridging Generative Deep Learning and Computational Creativity . In Proc . of the 11th International Conference on Computational Creativity ( Online ) . ACC . [ 15 ] FedericoBetti , GiorgiaRamponi , andMassimoPiccardi . 2020 . ControlledTextGenerationwithAdversarialLearning . In Proc . ofthe13thInternational Conference on Natural Language Generation ( Dublin , Ireland ) . ACL , 29 ‚Äì 34 . [ 16 ] Margaret A . Boden . 2003 . The Creative Mind : Myths and Mechanisms . Routledge , London , UK . [ 17 ] Rishi Bommasani , Drew Hudson , Ehsan Adeli , Russ Altman , Simran Arora , Sydney Arx , Michael Bernstein , Jeannette Bohg , Antoine Bosselut , Emma Brunskill , Erik Brynjolfsson , Shyamal Buch , Dallas Card , Rodrigo Castellon , Niladri Chatterji , Annie Chen , Kathleen Creel , Jared Davis , Dora Demszky , and Percy Liang . 2021 . On the Opportunities and Risks of Foundation Models . arXiv : 2108 . 07258 [ 18 ] Sam Bond - Taylor , Adam Leach , Yang Long , and Chris G . Willcocks . 2021 . Deep Generative Modelling : A Comparative Review of VAEs , GANs , Normalizing Flows , Energy - Based and Autoregressive Models . IEEE Transactions on Pattern Analysis and Machine Intelligence ( 2021 ) , 1 ‚Äì 1 . [ 19 ] Samuel R . Bowman , Luke Vilnis , Oriol Vinyals , Andrew M . Dai , Rafal Jozefowicz , and Samy Bengio . 2016 . Generating Sentences from a Continuous Space . In Proc . of The 20th SIGNLL Conference on Computational Natural Language Learning ( Berlin , Germany ) . ACL , 10 ‚Äì 21 . [ 20 ] Oliver Bown . 2021 . Beyond the Creative Species . The MIT Press , Cambridge , MA . [ 21 ] Selmer Bringsjord , Paul Bello , and David Ferrucci . 2001 . Creativity , the Turing Test , and the ( Better ) Lovelace Test . Minds and Machines 11 ( 2001 ) , 3 ‚Äì 27 . [ 22 ] Terence Broad , Sebastian Berns , Simon Colton , and Mick Grierson . 2021 . Active Divergence with Generative Deep Learning - A Survey and Taxonomy . In Proc . of the 12th International Conference on Computational Creativity ( Online ) . ACC . [ 23 ] Andrew Brock , Jeff Donahue , and Karen Simonyan . 2018 . Large Scale GAN Training for High Fidelity Natural Image Synthesis . In International Conference on Learning Representations ( New Orleans , LA ) , Vol . 7 . OpenReview . net . [ 24 ] Tim Brooks , Janne Hellsten , Miika Aittala , Ting - Chun Wang , Timo Aila , Jaakko Lehtinen , Ming - Yu Liu , Alexei A . Efros , and Tero Karras . 2022 . Generating Long Videos of Dynamics Scenes . arXiv : 2206 . 03429 [ 25 ] Tom Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared D Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert - Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel Ziegler , Jeffrey Wu , Clemens Winter , Chris Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few - Shot Learners . In Advances in Neural Information Processing Systems ( Online ) , Vol . 33 . Curran Associates , Inc . , 1877 ‚Äì 1901 . [ 26 ] Razvan C . Bunescu and Oseremen O . Uduehi . 2019 . Learning to Surprise : A Composer - Audience Architecture . In Proc . of the 10th International Conference on Computational Creativity ( Charlotte , NC ) . ACC , 41 ‚Äì 48 . [ 27 ] Yuri Burda , Harri Edwards , Deepak Pathak , Amos Storkey , Trevor Darrell , and Alexei A . Efros . 2019 . Large - Scale Study of Curiosity - Driven Learning . In International Conference on Learning Representations ( New Orleans , LA ) , Vol . 7 . OpenReview . net . [ 28 ] Yuri Burda , Roger Grosse , and Ruslan Salakhutdinov . 2016 . Importance Weighted Autoencoders . In International Conference on Learning Representa - tions ( San Juan , Puerto Rico ) , Vol . 4 . [ 29 ] Christopher P . Burgess , Irina Higgins , Arka Pal , Loic Matthey , Nick Watters , Guillaume Desjardins , and Alexander Lerchner . 2018 . Understanding Disentangling in ùõΩ - VAE . arXiv : 1804 . 03599 [ 30 ] Kevin Burns . 2006 . Atoms of EVE‚Äô : A Bayesian Basis for Esthetic Analysis of Style in Sketching . Artificial Intelligence for Engineering Design , Analysis and Manufacturing 20 ( 2006 ) , 185 ‚Äì 199 . [ 31 ] Kevin Burns . 2015 . Computing the Creativeness of Amusing Advertisements : A Bayesian Model of Burma - Shave‚Äôs Muse . Artificial Intelligence for Engineering Design , Analysis and Manufacturing 29 ( 2015 ) , 109 ‚Äì 128 . [ 32 ] Am√≠lcar Cardoso , Tony Veale , and Geraint A . Wiggins . 2009 . Converging on the Divergent : The History ( and Future ) of the International Joint Workshops in Computational Creativity . AI Magazine 30 , 3 ( 2009 ) , 15 . 26 Creativity and Machine Learning : A Survey [ 33 ] Mark Chen , Alec Radford , Rewon Child , Jeffrey Wu , Heewoo Jun , David Luan , and Ilya Sutskever . 2020 . Generative Pretraining From Pixels . In Proc . of the 37th International Conference on Machine Learning ( Online ) , Vol . 119 . PMLR , 1691 ‚Äì 1703 . [ 34 ] Mark Chen , Jerry Tworek , Heewoo Jun , Qiming Yuan , Henrique Ponde de Oliveira Pinto , Jared Kaplan , Harri Edwards , Yuri Burda , Nicholas Joseph , Greg Brockman , Alex Ray , Raul Puri , Gretchen Krueger , Michael Petrov , Heidy Khlaaf , Girish Sastry , Pamela Mishkin , Brooke Chan , Scott Gray , Nick Ryder , Mikhail Pavlov , Alethea Power , Lukasz Kaiser , Mohammad Bavarian , Clemens Winter , Philippe Tillet , Felipe Petroski Such , Dave Cummings , Matthias Plappert , Fotios Chantzis , Elizabeth Barnes , Ariel Herbert - Voss , William Hebgen Guss , Alex Nichol , Alex Paino , Nikolas Tezak , Jie Tang , Igor Babuschkin , Suchir Balaji , Shantanu Jain , William Saunders , Christopher Hesse , Andrew N . Carr , Jan Leike , Josh Achiam , Vedant Misra , Evan Morikawa , Alec Radford , Matthew Knight , Miles Brundage , Mira Murati , Peter Mayer Katie and , Welinder , Bob McGrew , Dario Amodei , Sam McCandlish , Ilya Sutskever , and Wojciech Zaremba . 2021 . Evaluating Large Language Models Trained on Code . arXiv : 2107 . 03374 [ 35 ] Xi Chen , Yan Duan , Rein Houthooft , John Schulman , Ilya Sutskever , and Pieter Abbeel . 2016 . InfoGAN : Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets . In Advances in Neural Information Processing Systems ( Barcelona , Spain ) , Vol . 29 . Curran Associates Inc . , 2180 ‚Äì 2188 . [ 36 ] Rewon Child , Scott Gray , Alec Radford , and Ilya Sutskever . 2019 . Generating Long Sequences with Sparse Transformers . arXiv : 1904 . 10509 [ 37 ] Eric Chu . 2018 . Artistic Influence GAN . In NeurIPS 2018 Workshop on Machine Learning for Creativity and Design ( Vancouver , Canada ) . Curran Associates , Inc . [ 38 ] Elizabeth Clark , Yangfeng Ji , and Noah A . Smith . 2018 . Neural Text Generation in Stories Using Entity Representations as Context . In Proc . of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) ( New Orleans , LA ) . ACL , 2250 ‚Äì 2260 . [ 39 ] Harold Cohen . 1988 . How to Draw Three People in a Botanical Garden . In Proc . of the 7th AAAI National Conference on Artificial Intelligence ( Saint Paul , MN ) . AAAI Press , 846 ‚Äì 855 . [ 40 ] Simon Colton . 2008 . Creativity Versus the Perception of Creativity in Computational Systems . In AAAI Spring Symposium ( Stanford , CA ) , Vol . SS - 08 - 03 . AAAI Press . [ 41 ] Simon Colton . 2012 . The Painting Fool : Stories from Building an Automated Painter . In Computers and Creativity . Springer , Berlin , Heidelberg , 3 ‚Äì 38 . [ 42 ] Simon Colton , John William Charnley , and Alison Pease . 2011 . Computational Creativity Theory : The FACE and IDEA Descriptive Models . In Proc . of the 2nd International Conference on Computational Creativity ( Mexico City , Mexico ) . computationalcreativity . net , 90 ‚Äì 95 . [ 43 ] Simon Colton , Jakob Halskov , Dan Ventura , Ian Gouldstone , Michael Cook , and Blanca P√©rez - Ferrer . 2015 . The Painting Fool Sees ! New Projects with the Automated Painter . In Proc . of the 6th International Conference on Computational Creativity ( Park City , UT ) . computationalcreativity . net . [ 44 ] Simon Colton and Geraint A . Wiggins . 2012 . Computational Creativity : The Final Frontier ? . In 20th European Conference on Artificial Intelligence ( Montpellier , France ) , Vol . 242 . IOS Press , 21 ‚Äì 26 . [ 45 ] David Cope . 1989 . Experiments in Musical Intelligence ( EMI ) : Non - Linear Linguistic - Based Composition . Interface 18 ( 1989 ) , 117 ‚Äì 139 . [ 46 ] Katherine Crowson , Stella Biderman , Daniel Kornis , Dashiell Stander , Eric Hallahan , Louis Castricato , and Edward Raff . 2022 . VQGAN - CLIP : Open Domain Image Generation and Editing with Natural Language Guidance . arXiv : 2204 . 08583 [ 47 ] Yashar Deldjoo , Tommaso Di Noia , and Felice Antonio Merra . 2021 . A Survey on Adversarial Recommender Systems : From Attack / Defense Strategies to Generative Adversarial Networks . Comput . Surveys 54 , 2 ( 2021 ) , 1 ‚Äì 38 . [ 48 ] Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . BERT : Pre - training of Deep Bidirectional Transformers for Language Understanding . In Proc . of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) ( Minneapolis , MN ) . ACL , 4171 ‚Äì 4186 . [ 49 ] Prafulla Dhariwal , Heewoo Jun , Christine Payne , Jong Wook Kim , Alec Radford , and Ilya Sutskever . 2020 . Jukebox : A Generative Model for Music . arXiv : 2005 . 00341 [ 50 ] Prafulla Dhariwal and Alexander Quinn Nichol . 2021 . Diffusion Models Beat GANs on Image Synthesis . In Advances in Neural Information Processing Systems ( Online ) , Vol . 34 . Curran Associates , Inc . , 8780 ‚Äì 8794 . [ 51 ] Ming Ding , Zhuoyi Yang , Wenyi Hong , Wendi Zheng , Chang Zhou , Da Yin , Junyang Lin , Xu Zou , Zhou Shao , Hongxia Yang , and Jie Tang . 2021 . CogView : Mastering Text - to - Image Generation via Transformers . In Advances in Neural Information Processing Systems ( Online ) , Vol . 34 . Curran Associates , Inc . , 19822 ‚Äì 19835 . [ 52 ] Chris Donahue , Julian McAuley , and Miller Puckette . 2019 . Adversarial Audio Synthesis . In International Conference on Learning Representations ( New Orleans , LA ) , Vol . 7 . OpenReview . net . [ 53 ] Jeff Donahue , Philipp Krahenbuhl , and Trevor Darrell . 2017 . Adversarial Feature Learning . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 54 ] Hao - Wen Dong , Wen - Yi Hsiao , Li - Chia Yang , and Yi - Hsuan Yang . 2018 . MuseGAN : Multi - track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment . In Proc . of the 32nd AAAI Conference on Artificial Intelligence and 30th Innovative Applications of Artificial Intelligence Conference and 8th AAAI Symposium on Educational Advances in Artificial Intelligence ( New Orleans , LA ) . AAAI Press , 34 ‚Äì 41 . [ 55 ] Alexey Dosovitskiy , Lucas Beyer , Alexander Kolesnikov , Dirk Weissenborn , Xiaohua Zhai , Thomas Unterthiner , Mostafa Dehghani , Matthias Minderer , Georg Heigold , Sylvain Gelly , Jakob Uszkoreit , and Neil Houlsby . 2021 . An Image is Worth 16x16 Words : Transformers for Image Recognition at Scale . In International Conference on Learning Representations ( Online ) , Vol . 9 . OpenReview . net . 27 Franceschelli and Musolesi [ 56 ] Nan Du , Yanping Huang , Andrew M . Dai , Simon Tong , Dmitry Lepikhin , Yuanzhong Xu , Maxim Krikun , Yanqi Zhou , Adams Wei Yu , Orhan Firat , Barret Zoph , Liam Fedus , Maarten Bosma , Zongwei Zhou , Tao Wang , Yu Emma Wang , Kellie Webster , Marie Pellat , Kevin Robinson , Kathy Meier - Hellstern , Toju Duke , Lucas Dixon , Kun Zhang , Quoc V Le , Yonghui Wu , Zhifeng Chen , and Claire Cui . 2021 . GLaM : Efficient Scaling of Language Models with Mixture - of - Experts . arXiv : 2112 . 06905 [ 57 ] Vincent Dumoulin , Ishmael Belghazi , Ben Poole , Olivier Mastropietro , Alex Lamb , Martin Arjovsky , and Aaron Courville . 2017 . Adversarially Learned Inference . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 58 ] Ahmed Elgammal , Bingchen Liu , Mohamed Elhoseiny , and Marian Mazzone . 2017 . CAN : Creative Adversarial Networks , Generating " Art " by Learning About Styles and Deviating from Style Norms . In Proc . of the 8th International Conference on Computational Creativity ( Atlanta , GA ) . ACC , 96 ‚Äì 103 . [ 59 ] Ahmed Elgammal and Babak Saleh . 2015 . Quantifying Creativity in Art Networks . In Proc . of the 6th International Conference on Computational Creativity ( Park City , UT ) . Brigham Young University , 39 ‚Äì 46 . [ 60 ] Jesse Engel , Kumar Krishna Agrawal , Shuo Chen , Ishaan Gulrajani , Chris Donahue , and Adam Roberts . 2019 . GANSynth : Adversarial Neural Audio Synthesis . In International Conference on Learning Representations ( New Orleans , LA ) , Vol . 7 . OpenReview . net . [ 61 ] S . M . Ali Eslami , Nicolas Heess , Theophane Weber , Yuval Tassa , David Szepesvari , koray kavukcuoglu , and Geoffrey E . Hinton . 2016 . Attend , Infer , Repeat : Fast Scene Understanding with Generative Models . In Advances in Neural Information Processing Systems ( Barcelona , Spain ) , Vol . 29 . Curran Associates Inc . , 3233 ‚Äì 3241 . [ 62 ] Patrick Esser , Robin Rombach , and Bjorn Ommer . 2021 . Taming Transformers for High - Resolution Image Synthesis . In 2021 IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Nashville , TN ) . IEEE , 12873 ‚Äì 12883 . [ 63 ] William Fedus , Ian Goodfellow , and Andrew M . Dai . 2018 . MaskGAN : Better Text Generation via Filling in the _ _ _ _ _ _ _ . In International Conference on Learning Representations ( Vancouver , Canada ) , Vol . 6 . OpenReview . net . [ 64 ] Nanyi Fei , Zhiwu Lu , Yizhao Gao , Guoxing Yang , Yuqi Huo , Jingyuan Wen , Haoyu Lu , Ruihua Song , Xin Gao , Tao Xiang , Hao Sun , and Ji - Rong Wen . 2021 . Towards Artificial General Intelligence via a Multimodal Foundation Model . arXiv : 2110 . 14378 [ 65 ] Pablo Fernandes , Joao Nuno Correia , and Penousal Machado . 2020 . Evolutionary Latent Space Exploration of Generative Adversarial Networks . In Applications of Evolutionary Computation ‚Äì 23rd European Conference , EvoApplications 2020 , Held as Part of EvoStar 2020 ( Seville , Spain ) . Springer , 595 ‚Äì 609 . [ 66 ] Chrisantha Fernando , S . M . Ali Eslami , Jean - Baptiste Alayrac , Piotr Mirowski , Dylan Banarse , and Simon Osindero . 2021 . Generative Art Using Neural Visual Grammars and Dual Encoders . arXiv : 2105 . 00162 [ 67 ] David Foster . 2019 . Generative Deep Learning . O‚ÄôReilly , Sebastopol , CA . [ 68 ] Giorgio Franceschelli and Mirco Musolesi . 2022 . Copyright in Generative Deep Learning . Data & Policy 4 ( 2022 ) , e17 . [ 69 ] Celso Fran√ßa , Lu√≠s Fabr√≠cio Wanderley G√≥es , Alvaro Amorim , Rodrigo C . O . Rocha , and Alysson Ribeiro Da Silva . 2016 . Regent - Dependent Creativity : A Domain Independent Metric for the Assessment of Creative Artifacts . In Proc . of the 7th International Conference on Computational Creativity ( Paris , France ) . Sony CSL . [ 70 ] Ankush Ganguly and Samuel W . F . Earp . 2021 . An Introduction to Variational Inference . arXiv : 2108 . 13083 [ 71 ] Albert Gatt and Emiel Krahmer . 2018 . Survey of the State of the Art in Natural Language Generation : Core Tasks , Applications and Evaluation . Journal of Artificial Intelligence Research 61 , 1 ( 2018 ) , 65 ‚Äì 170 . [ 72 ] Leon Gatys , Alexander Ecker , and Matthias Bethge . 2016 . A Neural Algorithm of Artistic Style . Journal of Vision 16 , 12 ( 2016 ) , 326 . [ 73 ] Leon A . Gatys , Alexander S . Ecker , Matthias Bethge , Aaron Hertzmann , and Eli Shechtman . 2017 . Controlling Perceptual Factors in Neural Style Transfer . In 2017 IEEE Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Honolulu , HI ) . IEEE , 3730 ‚Äì 3738 . [ 74 ] Sebastian Gehrmann , Tosin Adewumi , Karmanya Aggarwal , Pawan Sasanka Ammanamanchi , Aremu Anuoluwapo , Antoine Bosselut , Khy - athi Raghavi Chandu , Miruna Clinciu , Dipanjan Das , Kaustubh D . Dhole , Wanyu Du , Esin Durmus , Ond≈ôej Du≈°ek , Chris Emezue , Varun Gangal , Cristina Garbacea , Tatsunori Hashimoto , Yufang Hou , Yacine Jernite , Harsh Jhamtani , Yangfeng Ji , Shailza Jolly , Dhruv Kumar , Faisal Ladhak , Aman Madaan , Mounica Maddela , Khyati Mahajan , Saad Mahamood , Bodhisattwa Prasad Majumder , Pedro Henrique Martins , Angelina McMillan - Major , Simon Mille , Emiel van Miltenburg , Moin Nadeem , Shashi Narayan , Vitaly Nikolaev , Rubungo Andre Niyongabo , Salomey Osei , Ankur Parikh , Laura Perez - Beltrachini , Niranjan Ramesh Rao , Vikas Raunak , Juan Diego Rodriguez , Sashank Santhanam , Jo√£o Sedoc , Thibault Sellam , Samira Shaikh , Anastasia Shimorina , Marco Antonio Sobrevilla Cabezudo , Hendrik Strobelt , Nishant Subramani , Wei Xu , Diyi Yang , Akhila Yerukola , and Jiawei Zhou . 2021 . The GEM Benchmark : Natural Language Generation , its Evaluation and Metrics . In Proc . of the 1st Workshop on Natural Language Generation , Evaluation , and Metrics ( GEM 2021 ) ( Online ) . ACL , 96 ‚Äì 120 . [ 75 ] John Gero . 2000 . Computational Models of Innovative and Creative Design Processes . Technological Forecasting and Social Change 64 , 2 - 3 ( 2000 ) , 183 ‚Äì 196 . [ 76 ] Ian Goodfellow . 2017 . NIPS 2016 Tutorial : Generative Adversarial Networks . arXiv : 1701 . 00160 [ 77 ] IanGoodfellow , JeanPouget - Abadie , MehdiMirza , BingXu , DavidWarde - Farley , SherjilOzair , AaronCourville , andYoshuaBengio . 2014 . Generative Adversarial Nets . In Advances in Neural Information Processing Systems ( Montreal , Canada ) , Vol . 27 . MIT Press , 2672 ‚Äì 2680 . [ 78 ] Kazjon Grace and Mary Lou Maher . 2014 . What to Expect when you‚Äôre Expecting : The Role of Unexpectedness in Computationally Evaluating Creativity . In Proc . of the 5th International Conference on Computational Creativity ( Ljubljana , Slovenia ) . computationalcreativity . net , 120 ‚Äì 128 . [ 79 ] Daniele Gravina , Antonios Liapis , and Georgios Yannakakis . 2016 . Surprise Search : Beyond Objectives and Novelty . In Proc . of the Genetic and Evolutionary Computation Conference 2016 ( Denver , CO ) . ACM , 677 ‚Äì 684 . 28 Creativity and Machine Learning : A Survey [ 80 ] Karol Gregor , Ivo Danihelka , Alex Graves , Danilo Jimenez Rezende , and Daan Wierstra . 2015 . DRAW : A Recurrent Neural Network For Image Generation . In Proc . of the 32nd International Conference on Machine Learning ( Lille , France ) , Vol . 37 . PMLR , 1462 ‚Äì 1471 . [ 81 ] Jie Gui , Z . Sun , Yonggang Wen , Dacheng Tao , and Ye Jie - ping . 2021 . A Review on Generative Adversarial Networks : Algorithms , Theory , and Applications . IEEE Transactions on Knowledge and Data Engineering ( 2021 ) , 1 ‚Äì 1 . [ 82 ] Gabriel L . Guimaraes , Benjamin Sanchez - Lengeling , Pedro Luis Cunha Farias , and Alan Aspuru - Guzik . 2017 . Objective - Reinforced Generative Adversarial Networks ( ORGAN ) for Sequence Generation Models . arXiv : 1705 . 10843 [ 83 ] Ishaan Gulrajani , Kundan Kumar , Faruk Ahmed , Adrien Ali Taiga , Francesco Visin , David Vazquez , and Aaron Courville . 2017 . PixelVAE : A Latent Variable Model for Natural Images . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 84 ] JiaxianGuo , SidiLu , HanCai , WeinanZhang , YongYu , andJunWang . 2018 . LongTextGenerationviaAdversarialTrainingwithLeakedInformation . In Proc . of the 32nd AAAI Conference on Artificial Intelligence and 30th Innovative Applications of Artificial Intelligence Conference and 8th AAAI Symposium on Educational Advances in Artificial Intelligence ( New Orleans , LA ) . AAAI Press , 5141 ‚Äì 5148 . [ 85 ] Matthew Guzdial and Mark O . Riedl . 2019 . An Interaction Framework for Studying Co - Creative AI . arXiv : 1903 . 09709 [ 86 ] Rafael G√≥mez - Bombarelli , Jennifer N . Wei , David Duvenaud , Jos√© Miguel Hern√°ndez - Lobato , Benjam√≠n S√°nchez - Lengeling , Dennis Sheberla , Jorge Aguilera - Iparraguirre , Timothy D . Hirzel , Ryan P . Adams , and Al√°n Aspuru - Guzik . 2018 . Automatic Chemical Design Using a Data - Driven Continuous Representation of Molecules . ACS Central Science 4 , 2 ( 2018 ) , 268 ‚Äì 276 . [ 87 ] G . M . Harshvardhan , Mahendra Kumar Gourisaria , Manjusha Pandey , and Siddharth Swarup Rautaray . 2020 . A Comprehensive Survey and Analysis of Generative Models in Machine Learning . Computer Science Review 38 ( 2020 ) , 100285 . [ 88 ] Kaiming He , Xinlei Chen , Saining Xie , Yanghao Li , Piotr Doll√°r , and Ross Girshick . 2021 . Masked Autoencoders Are Scalable Vision Learners . arXiv : 2111 . 06377 [ 89 ] Irina Higgins , Loic Matthey , Arka Pal , Christopher Burgess , Xavier Glorot , Matthew Botvinick , Shakir Mohamed , and Alexander Lerchner . 2017 . beta - VAE : Learning Basic Visual Concepts with a Constrained Variational Framework . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 90 ] Geoffrey Hinton , Oriol Vinyals , and Jeffrey Dean . 2015 . Distilling the Knowledge in a Neural Network . In Deep Learning and Representation Learning Workshop ( Montreal , Canada ) . Curran Associates , Inc . [ 91 ] Jonathan Ho , Ajay Jain , and Pieter Abbeel . 2020 . Denoising Diffusion Probabilistic Models . In Advances in Neural Information Processing Systems ( Online ) , Vol . 33 . Curran Associates , Inc . , 6840 ‚Äì 6851 . [ 92 ] Jonathan Ho , Chitwan Saharia , William Chan , David J . Fleet , Mohammad Norouzi , and Tim Salimans . 2021 . Cascaded Diffusion Models for High Fidelity Image Generation . arXiv : 2106 . 15282 [ 93 ] Jonathan Ho and Tim Salimans . 2021 . Classifier - Free Diffusion Guidance . In NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications ( Online ) . Curran Associates , Inc . [ 94 ] Jonathan Ho , Tim Salimans , Alexey Gritsenko , William Chan , Mohammad Norouzi , and David J . Fleet . 2022 . Video Diffusion Models . In ICLR Workshop on Deep Generative Models for Highly Structured Data ( Online ) . OpenReview . net . [ 95 ] Sepp Hochreiter and Jurgen Schmidhuber . 1997 . Long Short - Term Memory . Neural Computation 9 , 8 ( 1997 ) , 1735 ‚Äì 1780 . [ 96 ] Jordan Hoffmann , Sebastian Borgeaud , Arthur Mensch , Elena Buchatskaya , Trevor Cai , Eliza Rutherford , Diego de Las Casas , Lisa Anne Hendricks , Johannes Welbl , Aidan Clark , Tom Hennigan , Eric Noland , Katie Millican , George van den Driessche , Bogdan Damoc , Aurelia Guy , Simon Osindero , Karen Simonyan , Erich Elsen , Jack W . Rae , Oriol Vinyals , and Laurent Sifre . 2022 . Training Compute - Optimal Large Language Models . arXiv : 2203 . 15556 [ 97 ] Douglas R . Hofstadter and Melanie Mitchell . 1994 . The Copycat Project : A Model of Mental Fluidity and Analogy - Making . In Advances in connectionist and neural computation theory , Vol . 2 . Analogical connections . Ablex Publishing , 31 ‚Äì 112 . [ 98 ] Jack Hopkins and Douwe Kiela . 2017 . Automatically Generating Rhythmic Verse with Neural Networks . In Proc . of the 55th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) ( Vancouver , Canada ) . ACL , 168 ‚Äì 178 . [ 99 ] Cheng - Zhi Anna Huang , Ashish Vaswani , Jakob Uszkoreit , Ian Simon , Curtis Hawthorne , Noam Shazeer , Andrew M . Dai , Matthew D . Hoffman , Monica Dinculescu , and Douglas Eck . 2019 . Music Transformer . In International Conference on Learning Representations ( New Orleans , LA ) , Vol . 7 . OpenReview . net . [ 100 ] Zhewei Huang , Shuchang Zhou , and Wen Heng . 2019 . Learning to Paint With Model - Based Deep Reinforcement Learning . In 2019 IEEE / CVF International Conference on Computer Vision ( ICCV ) ( Seoul , Korea ( South ) ) . IEEE , 8708 ‚Äì 8717 . [ 101 ] Phillip Isola , Jun - Yan Zhu , Tinghui Zhou , and Alexei A . Efros . 2017 . Image - to - Image Translation with Conditional Adversarial Networks . In 2017 IEEE Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Honolulu , HI ) . IEEE , 5967 ‚Äì 5976 . [ 102 ] Eric Jang , Shixiang Gu , and Ben Poole . 2017 . Categorical Reparameterization with Gumbel - Softmax . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 103 ] JoelJang , SuminShin , andYoonjeonKim . 2022 . Music2Video : AutomaticGenerationofMusicVideowithFusionofAudioandText . arXiv : 2201 . 03809 [ 104 ] Natasha Jaques , Shixiang Gu , Dzmitry Bahdanau , Jos√© Miguel Hern√°ndez - Lobato , Richard E . Turner , and Douglas Eck . 2017 . Sequence Tutor : Conservative Fine - Tuning of Sequence Generation Models with KL - control . In Proc . of the 34th International Conference on Machine Learning ( Sydney , Australia ) , Vol . 70 . PMLR , 1645 ‚Äì 1654 . [ 105 ] Natasha Jaques , Shixiang Gu , Richard E . Turner , and Douglas Eck . 2016 . Generating Music by Fine - Tuning Recurrent Neural Networks with Reinforcement Learning . In NeurIPS 2016 Deep Reinforcement Learning Workshop ( Barcelona , Spain ) . Curran Associates Inc . 29 Franceschelli and Musolesi [ 106 ] Natasha Jaques , Shixiang Gu , Richard E . Turner , and Douglas Eck . 2017 . Tuning Recurrent Neural Networks with Reinforcement Learning . In ICLR Workshop ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 107 ] DivyanshJha , HannaChang , andMohamedElhoseiny . 2021 . W√∂lfflin‚ÄôsAffectiveGenerativeAnalysisforVisualArt . In Proc . ofthe20thInternational Conference on Computational Creativity ( Online ) . ACC , 429 ‚Äì 433 . [ 108 ] Chao Jia , Yinfei Yang , Ye Xia , Yi - Ting Chen , Zarana Parekh , Hieu Pham , Quoc V . Le , Yunhsuan Sung , Zhen Li , and Tom Duerig . 2021 . Scaling Up Visual and Vision - Language Representation Learning With Noisy Text Supervision . In Proc . of the 38th International Conference on Machine Learning ( Online ) , Vol . 139 . PMLR , 4904 ‚Äì 4916 . [ 109 ] Nan Jiang , Sheng Jin , Zhiyao Duan , and Changshui Zhang . 2020 . RL - Duet : Online Music Accompaniment Generation Using Deep Reinforcement Learning . In Proc . of the 34th AAAI Conference on Artificial Intelligence , the 32nd Innovative Applications of Artificial Intelligence Conference , the 10th AAAI Symposium on Educational Advances in Artificial Intelligence ( New York , NY ) . AAAI Press , 710 ‚Äì 718 . [ 110 ] Yanghua Jin , Jiakai Zhang , Minjun Li , Yingtao Tian , Huachun Zhu , and Zhihao Fang . 2017 . Towards the Automatic Anime Characters Creation with Generative Adversarial Networks . arXiv : 1708 . 05509 [ 111 ] Michael I . Jordan , Zoubin Ghahrmamani , Tommi S . Jaakkola , and Lawrence K . Saul . 1999 . An Introduction to Variational Methods for Graphical Models . Machine Learning 37 ( 1999 ) , 183 ‚Äì 233 . [ 112 ] Anna Jordanous . 2012 . A Standardised Procedure for Evaluating Creative Systems : Computational Creativity Evaluation Based on What it is to be Creative . Cognitive Computation 4 ( 2012 ) , 246 ‚Äì 279 . [ 113 ] Anna Jordanous . 2014 . Stepping Back to Progress Forwards : Setting Standards for Meta - Evaluation of Computational Creativity . In Proc . of the 5th International Conference on Computational Creativity ( Ljubljana , Slovenia ) . computationalcreativity . net , 129 ‚Äì 136 . [ 114 ] Anna Jordanous . 2016 . Four PPPPerspectives on Computational Creativity in Theory and in Practice . Connection Science 28 , 2 ( 2016 ) , 294 ‚Äì 216 . [ 115 ] John M . Jumper , Richard Evans , Alexander Pritzel , Tim Green , Michael Figurnov , Olaf Ronneberger , Kathryn Tunyasuvunakool , Russ Bates , Augustin Zidek , Anna Potapenko , Alex Bridgland , Clemens Meyer , Simon A . A . Kohl , Andy Ballard , Andrew Cowie , Bernardino Romera - Paredes , Stanislav Nikolov , Rishub Jain , Jonas Adler , Trevor Back , Stig Petersen , David A . Reiman , Ellen Clancy , Michal Zielinski , Martin Steinegger , Michalina Pacholska , Tamas Berghammer , Sebastian Bodenstein , David Silver , Oriol Vinyals , Andrew W . Senior , Koray Kavukcuoglu , Pushmeet Kohli , and Demis Hassabis . 2021 . Highly Accurate Protein Structure Prediction with AlphaFold . Nature 596 ( 2021 ) , 583 ‚Äì 589 . [ 116 ] Artur Kadurin , Sergey Nikolenko , Kuzma Khrabrov , Alex Aliper , and Alex Zhavoronkov . 2017 . druGAN : An Advanced Generative Adversarial Autoencoder Model for de Novo Generation of New Molecules with Desired Molecular Properties in Silico . Molecular Pharmaceutics 14 , 9 ( 2017 ) , 3098 ‚Äì 3104 . [ 117 ] Pythagoras Karampiperis , Antonis Koukourikos , and Evangelia Koliopoulou . 2014 . Towards Machines for Measuring Creativity : The Use of Computational Tools in Storytelling Activities . In 2014 IEEE 14th International Conference on Advanced Learning Technologies ( Athens , Greece ) . IEEE . [ 118 ] Andrej Karpathy . 2015 . The Unreasonable Effectiveness of Recurrent Neural Networks . Retrieved August 5 , 2020 from karpathy . github . io / 2015 / 05 / 21 / rnn - effectiveness . [ 119 ] Tero Karras , Timo Aila , Samuli Laine , and Jaakko Lehtinen . 2018 . Progressive Growing of GANs for Improved Quality , Stability , and Variation . In International Conference on Learning Representations ( Vancouver , Canada ) , Vol . 6 . OpenReview . net . [ 120 ] Tero Karras , Miika Aittala , Samuli Laine , Erik Harkonen , Janne Hellsten , Jaakko Lehtinen , and Timo Aila . 2021 . Alias - Free Generative Adversarial Networks . In Advances in Neural Information Processing Systems ( Online ) , Vol . 34 . Curran Associates , Inc . , 852 ‚Äì 863 . [ 121 ] Tero Karras , Samuli Laine , and Timo Aila . 2019 . A Style - Based Generator Architecture for Generative Adversarial Networks . In 2019 IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Long Beach , CA ) . IEEE , 4396 ‚Äì 4405 . [ 122 ] Tero Karras , Samuli Laine , Miika Aittala , Janne Hellsten , Jaakko Lehtinen , and Timo Aila . 2020 . Analyzing and Improving the Image Quality of StyleGAN . In 2020 IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Seattle , WA ) . IEEE , 8107 ‚Äì 8116 . [ 123 ] Hadi Kazemi , Seyed Mehdi Iranmanesh , and Nasser Nasrabadi . 2019 . Style and Content Disentanglement in Generative Adversarial Networks . In 2019 IEEE Winter Conference on Applications of Computer Vision ( WACV ) ( Waikoloa , HI ) . IEEE , 848 ‚Äì 856 . [ 124 ] Salman Khan , Muzammal Naseer , Munawar Hayat , Syed Waqas Zamir , Fahad Shahbaz Khan , and Mubarak Shah . 2021 . Transformers in Vision : A Survey . Comput . Surveys ( 2021 ) . Just Accepted . [ 125 ] Durk P Kingma , Shakir Mohamed , Danilo Jimenez Rezende , and Max Welling . 2014 . Semi - supervised Learning with Deep Generative Models . In Advances in Neural Information Processing Systems ( Montreal , Canada ) , Vol . 27 . MIT Press , 3581 ‚Äì 3589 . [ 126 ] Diederik P . Kingma and Max Welling . 2014 . Auto - Encoding Variational Bayes . In International Conference on Learning Representations ( Banff , Canada ) , Vol . 2 . [ 127 ] Diederik P . Kingma and Max Welling . 2019 . An Introduction to Variational Autoencoders . Foundations and Trends in Machine Learning 12 , 4 ( 2019 ) , 307 ‚Äì 392 . [ 128 ] Zhifeng Kong , Wei Ping , Jiaji Huang , Kexin Zhao , and Bryan Catanzaro . 2021 . DiffWave : A Versatile Diffusion Model for Audio Synthesis . In International Conference on Learning Representations ( Online ) , Vol . 9 . OpenReview . net . [ 129 ] Evgeny Lagutin , Daniil Gavrilov , and Pavel Kalaidin . 2021 . Implicit Unlikelihood Training : Improving Neural Text Generation with Reinforcement Learning . In Proc . of the 16th Conference of the European Chapter of the Association for Computational Linguistics : Main Volume ( Online ) . ACL , 1432 ‚Äì 1441 . 30 Creativity and Machine Learning : A Survey [ 130 ] Carolyn Lamb , Daniel G . Brown , and Charles L . A . Clarke . 2018 . Evaluating Computational Creativity : An Interdisciplinary Tutorial . Comput . Surveys 51 , 2 ( 2018 ) , 1 ‚Äì 34 . [ 131 ] ZhenzhongLan , MingdaChen , SebastianGoodman , KevinGimpel , PiyushSharma , andRaduSoricut . 2020 . ALBERT : ALiteBERTforSelf - supervised Learning of Language Representations . In International Conference on Learning Representations ( Addis Ababa , Ethiopia ) , Vol . 8 . OpenReview . net . [ 132 ] Pat Langley , Herbert A . Simon , Gary L . Bradshaw , and Jan M . Zytkow . 1987 . Scientific Discovery : Computational Explorations of the Creative Process . The MIT Press , Cambridge , MA . [ 133 ] Anders Boesen Lindbo Larsen , S√∏ren Kaae S√∏nderby , Hugo Larochelle , and Ole Winther . 2016 . Autoencoding beyond Pixels Using a Learned Similarity Metric . In Proc . of The 33rd International Conference on Machine Learning ( New York , NY ) , Vol . 48 . PMLR , 1558 ‚Äì 1566 . [ 134 ] Jey Han Lau , Trevor Cohn , Timothy Baldwin , Julian Brooke , and Adam Hammond . 2018 . Deep - Speare : A Joint Neural Model of Poetic Language , Meter and Rhyme . In Proc . of the 56th Annual Meeting of the Association for Computational Linguistics ( Volume 1 : Long Papers ) ( Melbourne , Australia ) . ACL , 1948 ‚Äì 1958 . [ 135 ] Helena H . Lee , Ke Shu , Palakorn Achananuparp , Philips Kokoh Prasetyo , Yue Liu , Ee - Peng Lim , and Lav R . Varshney . 2020 . RecipeGPT : Generative Pre - Training Based Cooking Recipe Generation and Evaluation System . In Companion Proceedings of the Web Conference 2020 ( Online ) . ACM , 181 ‚Äì 184 . [ 136 ] Joel Lehman and Kenneth O . Stanley . 2011 . Abandoning Objectives : Evolution Through the Search for Novelty Alone . Evolutionary Computation 19 , 2 ( 2011 ) , 189 ‚Äì 223 . [ 137 ] Brian Lester , Rami Al - Rfou , and Noah Constant . 2021 . The Power of Scale for Parameter - Efficient Prompt Tuning . In Proc . of the 2021 Conference on Empirical Methods in Natural Language Processing ( Online and Punta Cana , Dominican Republic ) . ACL , 3045 ‚Äì 3059 . [ 138 ] Yoav Levine , Itay Dalmedigos , Ori Ram , Yoel Zeldes , Daniel Jannai , Dor Muhlgay , Yoni Osin , Opher Lieber , Barak Lenz , Shai Shalev - Shwartz , Amnon Shashua , Kevin Leyton - Brown , and Yoav Shoham . 2022 . Standing on the Shoulders of Giant Frozen Language Models . arXiv : 2204 . 10019 [ 139 ] Mike Lewis , Yinhan Liu , Naman Goyal , Marjan Ghazvininejad , Abdelrahman Mohamed , Omer Levy , Veselin Stoyanov , and Luke Zettlemoyer . 2020 . BART : Denoising Sequence - to - Sequence Pre - training for Natural Language Generation , Translation , and Comprehension . In Proc . of the 58th Annual Meeting of the Association for Computational Linguistics ( Online ) . ACL , 7871 ‚Äì 7880 . [ 140 ] Jiwei Li , Will Monroe , Alan Ritter , Dan Jurafsky , Michel Galley , and Jianfeng Gao . 2016 . Deep Reinforcement Learning for Dialogue Generation . In Proc . of the 2016 Conference on Empirical Methods in Natural Language Processing ( Austin , TX ) . ACL , 1192 ‚Äì 1202 . [ 141 ] Naihan Li , Shujie Liu , Yanqing Liu , Sheng Zhao , and Ming Liu . 2019 . Neural Speech Synthesis with Transformer Network . In Proc . of the 33rd AAAI Conference on Artificial Intelligence and 31st Innovative Applications of Artificial Intelligence Conference and 9th AAAI Symposium on Educational Advances in Artificial Intelligence ( Honolulu , HI ) . AAAI Press . [ 142 ] Antonios Liapis , Hector P . Martinez , Julian Togelius , and Georgios N . Yannakakis . 2013 . Transforming Exploratory Creativity with DeLeNoX . In Proc . of the 4th International Conference on Computational Creativity ( Sydney , Australia ) . Faculty of Architecture , Design and Planning , The University of Sydney , 56 ‚Äì 63 . [ 143 ] Antonios Liapis , Georgios N . Yannakakis , and Julian Togelius . 2013 . Enhancements to Constrained Novelty Search : Two - Population Novelty Search for Generating Game Content . In Proc . of the 15th Annual Conference on Genetic and Evolutionary Computation ( Amsterdam , The Netherlands ) . ACM , 343 ‚Äì 350 . [ 144 ] Bryan Lim and Stefan Zohren . 2021 . Time - Survey . Philosophical Transactions of the Royal Society A 379 ( 2021 ) , 20200209 . [ 145 ] Jialin Liu , Sam Snodgrass , Ahmed Khalifa , Sebastian Risi , Georgios N . Yannakakis , and Julian Togelius . 2021 . Deep Learning for Procedural Content Generation . Neural Computing and Applications 33 ( 2021 ) , 19 ‚Äì 37 . [ 146 ] Yinhan Liu , Myle Ott , Naman Goyal , Jingfei Du , Mandar Joshi , Danqi Chen , Omer Levy , Mike Lewis , Luke Zettlemoyer , and Veselin Stoyanov . 2019 . RoBERTa : A Robustly Optimized BERT Pretraining Approach . arXiv : 1907 . 11692 [ 147 ] Lars Maal√∏e , Casper Kaae S√∏nderby , S√∏ren Kaae S√∏nderby , and Ole Winther . 2016 . Auxiliary Deep Generative Models . In Proc . of The 33rd International Conference on Machine Learning ( New York , NY ) , Vol . 48 . PMLR , 1445 ‚Äì 1453 . [ 148 ] Luis Macedo and Amilcar Cardoso . 2002 . Assessing Creativity : The Importance of Unexpected Novelty . In Workshop on Creative Systems ( Lyon , France ) . University Claude Bernard . [ 149 ] Penousal Machado , Juan Romero , Antonino Santos , Am√≠lcar Cardoso , and Alejandro Pazos . 2007 . On the Development of Evolutionary Artificial Artists . Computers and Graphics 31 , 6 ( 2007 ) , 818 ‚Äì 826 . [ 150 ] Chris J . Maddison , Andriy Mnih , and Yee Whye Teh . 2017 . The Concrete Distribution : A Continuous Relaxation of Discrete Random Variables . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 151 ] Aleksander Madry , Aleksandar Makelov , Ludwig Schmidt , Dimitris Tsipras , and Adrian Vladu . 2018 . Towards Deep Learning Models Resistant to Adversarial Attacks . In International Conference on Learning Representations ( Vancouver , Canada ) , Vol . 6 . OpenReview . net . [ 152 ] Mary Maher . 2010 . Evaluating Creativity in Humans , Computers , and Collectively Intelligent Systems . In Proc . of the 1st DESIRE Network Conference on Creativity and Innovation in Design ( Aarhus , Denmark ) . Desire Network , 22 ‚Äì 28 . [ 153 ] Mary Maher and Doug Fisher . 2012 . Using AI to Evaluate Creative Designs . In Proc . of the 2nd International Conference on Design Creativity , Vol . 1 . 45 ‚Äì 54 . [ 154 ] Alireza Makhzani , Jonathon Shlens , Navdeep Jaitly , and Ian Goodfellow . 2016 . Adversarial Autoencoders . In International Conference on Learning Representations ( San Juan , Puerto Rico ) , Vol . 4 . 31 Franceschelli and Musolesi [ 155 ] Lara J . Martin , Prithviraj Ammanabrolu , William Hancock , Shruti Singh , Brent Harrison , and Mark O . Riedl . 2018 . Event Representations for Automated Story Generation with Deep Neural Nets . In Proc . of the 32nd AAAI Conference on Artificial Intelligence and 30th Innovative Applications of Artificial Intelligence Conference and 8th AAAI Symposium on Educational Advances in Artificial Intelligence ( New Orleans , LA ) . AAAI Press . [ 156 ] James R . Meehan . 1977 . TALE - SPIN , an Interactive Program That Writes Stories . In Proc . of the 5th International Joint Conference on Artificial Intelligence - Volume 1 ( Cambridge , MA ) . Morgan Kaufmann Publishers Inc . , 91 ‚Äì 98 . [ 157 ] Luigi Federico Menabrea and Ada Lovelace . 1843 . Sketch of The Analytical Engine Invented by Charles Babbage . In Scientific Memoirs . Vol . 3 . Richard and John E . Taylor , 666 ‚Äì 731 . [ 158 ] Oscar Mendez - Lucio , Benoit Baillif , Djork - Arn√© Clevert , David Rouqui√© , and Joerg Wichard . 2020 . De novo generation of hit - like molecules from gene expression signatures using artificial intelligence . Nature Communications 11 , 10 ( 2020 ) , 1 ‚Äì 10 . [ 159 ] Luke Metz , Ben Poole , David Pfau , and Jascha Sohl - Dickstein . 2017 . Unrolled Generative Adversarial Networks . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 160 ] Arthur I . Miller . 2019 . The Artist in the Machine . The MIT Press , Cambridge , MA . [ 161 ] Marvin Minsky . 2006 . The Emotion Machine . Simon & Schuster , New York , NY . [ 162 ] Mehdi Mirza and Simon Osindero . 2014 . Conditional Generative Adversarial Nets . arXiv : 1411 . 1784 [ 163 ] Gautam Mittal , Jesse Engel , Curtis Hawthorne , and Ian Simon . 2021 . Symbolic Music Generation with Diffusion Models . In Proc . of the 22nd Int . Society for Music Information Retrieval Conf . ( Online ) . [ 164 ] Volodymyr Mnih , Koray Kavukcuoglu , David Silver , Andrei A . Rusu , Joel Veness , Marc G . Bellemare , Alex Graves , Martin Riedmiller , Andreas K . Fidjeland , Georg Ostrovski , Stig Petersen , Charles Beattie , Amir Sadik , Ioannis Antonoglou , Helen King , Dharshan Kumaran , Daan Wierstra , Shane Legg , and Demis Hassabis . 2015 . Human - Level Control Through Deep Reinforcement Learning . Nature 518 ( 2015 ) , 529 ‚Äì 533 . [ 165 ] Alexander Mordvintsev , Christopher Olah , and Mike Tyka . 2015 . Inceptionism : Going Deeper into Neural Networks . Google Research Blog . [ 166 ] Richard G . Morris , Scott H . Burton , Paul Bodily , and Dan Ventura . 2012 . Soup Over Bean of Pure Joy : Culinary Ruminations of an Artificial Chef . In Proc . of the 3rd International Conference on Computational Creativity ( Dublin , Ireland ) . computationalcreativity . net , 119 ‚Äì 125 . [ 167 ] Saman Motamed , Patrik Rogalla , and Farzad Khalvati . 2021 . RANDGAN : Randomized Generative Adversarial Network for Detection of COVID - 19 in Chest X - Ray . Scientific Reports 11 ( 2021 ) , 8602 . [ 168 ] Allen Newell , J . C . Shaw , and Herbert A . Simon . 1962 . The Processes of Creative Thinking . In Contemporary Approaches to Creative Thinking : A Symposium Held at the University of Colorado . Atherton Press , 63 ‚Äì 119 . [ 169 ] Anh Nguyen , Jeff Clune , Yoshua Bengio , Alexey Dosovitskiy , and Jason Yosinski . 2017 . Plug & Play Generative Networks : Conditional Iterative Generation of Images in Latent Space . In 2017 IEEE Conference on Computer Vision and Pattern Recognition ( CVPR ) ( Honolulu , HI ) . IEEE , 3510 ‚Äì 3520 . [ 170 ] Anh Nguyen , Alexey Dosovitskiy , Jason Yosinski , Thomas Brox , and Jeff Clune . 2016 . Synthesizing the Preferred Inputs for Neurons in Neural Networks via Deep Generator Networks . In Advances in Neural Information Processing Systems ( Barcelona , Spain ) , Vol . 29 . Curran Associates Inc . , 3395 ‚Äì 3403 . [ 171 ] Alex Nichol , Prafulla Dhariwal , Aditya Ramesh , Pranav Shyam , Pamela Mishkin , Bob McGrew , Ilya Sutskever , and Mark Chen . 2021 . GLIDE : Towards Photorealistic Image Generation and Editing with Text - Guided Diffusion Models . arXiv : 2112 . 10741 [ 172 ] Alexander Quinn Nichol and Prafulla Dhariwal . 2021 . Improved Denoising Diffusion Probabilistic Models . In Proc . of the 38th International Conference on Machine Learning ( Online ) , Vol . 139 . PMLR , 8162 ‚Äì 8171 . [ 173 ] Weili Nie , Nina Narodytska , and Ankit Patel . 2019 . RelGAN : Relational Generative Adversarial Networks for Text Generation . In International Conference on Learning Representations ( New Orleans , LA ) , Vol . 7 . OpenReview . net . [ 174 ] David Norton , Derral Heath , and Dan Ventura . 2010 . Establishing Appreciation in a Creative System . In Proc . of the International Conference on Computational Creativity ( Lisbon , Portugal ) . computationalcreativity . net . [ 175 ] Augustus Odena . 2016 . Semi - Supervised Learning with Generative Adversarial Networks . arXiv : 1606 . 01583 [ 176 ] Augustus Odena , Christopher Olah , and Jonathon Shlens . 2017 . Conditional Image Synthesis with Auxiliary Classifier GANs . In Proc . of the 34th International Conference on Machine Learning ( Sydney , Australia ) , Vol . 70 . PMLR , 2642 ‚Äì 2651 . [ 177 ] Chris Olah , Alexander Mordvintsev , and Ludwig Schubert . 2017 . Feature Visualization . Distill ( 2017 ) . https : / / distill . pub / 2017 / feature - visualization . [ 178 ] Niki Parmar , Ashish Vaswani , Jakob Uszkoreit , Lukasz Kaiser , Noam Shazeer , Alexander Ku , and Dustin Tran . 2018 . Image Transformer . In Proc . of the 35th International Conference on Machine Learning ( Stockholm , Sweden ) , Vol . 80 . PMLR , 4055 ‚Äì 4064 . [ 179 ] Christine Payne . 2019 . MuseNet . Retrieved August 2 , 2020 from openai . com / blog / musenet . [ 180 ] Francisco C . Pereira , Mateus Mendes , Pablo Gervas , and Amilcar Cardoso . 2005 . Experiments With Assessment of Creative Systems : An Application of Ritchie‚Äôs Criteria . In Second Computational Creativity Workshop ( Edinburgh , Scotland ) . Morgan Kaufmann Publishers Inc . [ 181 ] Peter Potash , Alexey Romanov , and Anna Rumshisky . 2015 . GhostWriter : Using an LSTM for Automatic Rap Lyric Generation . In Proc . of the 2015 Conference on Empirical Methods in Natural Language Processing ( Lisbon , Portugal ) . ACL , 1919 ‚Äì 1924 . [ 182 ] Racter . 1984 . The Policeman‚Äôs Beard Is Half Constructed . Warner Books , Inc . , New York , NY . [ 183 ] Alec Radford . 2018 . Improving Language Understanding with Unsupervised Learning . Retrieved May 3 , 2022 from openai . com / blog / language - unsupervised / . [ 184 ] Alec Radford , Jong Wook Kim , Chris Hallacy , Aditya Ramesh , Gabriel Goh , Sandhini Agarwal , Girish Sastry , Amanda Askell , Pamela Mishkin , Jack Clark , Gretchen Krueger , and Ilya Sutskever . 2021 . Learning Transferable Visual Models From Natural Language Supervision . In Proc . of the 38th International Conference on Machine Learning ( Online ) , Vol . 139 . PMLR , 8748 ‚Äì 8763 . 32 Creativity and Machine Learning : A Survey [ 185 ] Alec Radford , Luke Metz , and Soumith Chintala . 2016 . Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks . In International Conference on Learning Representations ( San Juan , Puerto Rico ) , Vol . 4 . [ 186 ] Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 . Language Models are Unsupervised Multitask Learners . [ 187 ] Colin Raffel , Noam Shazeer , Adam Roberts , Katherine Lee , Sharan Narang , Michael Matena , Yanqi Zhou , Wei Li , and Peter J . Liu . 2020 . Exploring the Limits of Transfer Learning with a Unified Text - to - Text Transformer . Journal of Machine Learning Research 21 , 140 ( 2020 ) , 1 ‚Äì 67 . [ 188 ] Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical Text - Conditional Image Generation with CLIP Latents . arXiv : 2204 . 06125 [ 189 ] Marc‚ÄôAurelio Ranzato , Sumit Chopra , Michael Auli , and Wojciech Zaremba . 2016 . Sequence Level Training with Recurrent Neural Networks . In International Conference on Learning Representations ( San Juan , Puerto Rico ) , Vol . 4 . [ 190 ] Hannah Rashkin , Asli Celikyilmaz , Yejin Choi , and Jianfeng Gao . 2020 . PlotMachines : Outline - Conditioned Generation with Dynamic Plot State Tracking . In Proc . of the 2020 Conference on Empirical Methods in Natural Language Processing ( Online ) . ACL , 4274 ‚Äì 4295 . [ 191 ] Scott Reed , Zeynep Akata , Xinchen Yan , Lajanugen Logeswaran , Bernt Schiele , and Honglak Lee . 2016 . Generative Adversarial Text to Image Synthesis . In Proc . of The 33rd International Conference on Machine Learning ( New York , NY ) , Vol . 48 . PMLR , 1060 ‚Äì 1069 . [ 192 ] Scott Reed , Konrad Zolna , Emilio Parisotto , Sergio Gomez Colmenarejo , Alexander Novikov , Gabriel Barth - Maron , Mai Gimenez , Yury Sulsky , Jackie Kay , Jost Tobias Springenberg , Tom Eccles , Jake Bruce , Ali Razavi , Ashley Edwards , Nicolas Heess , Yutian Chen , Raia Hadsell , Oriol Vinyals , Mahyar Bordbar , and Nando de Freitas . 2022 . A Generalist Agent . arXiv : 2205 . 06175 [ 193 ] Danilo Jimenez Rezende , Shakir Mohamed , and Daan Wierstra . 2014 . Stochastic Backpropagation and Approximate Inference in Deep Generative Models . In Proc . of the 31st International Conference on Machine Learning ( Beijing , China ) , Vol . 32 . PMLR , II ‚Äì 1278 ‚Äì II ‚Äì 1286 . [ 194 ] Mark O . Riedl . 2014 . The Lovelace 2 . 0 Test of Artificial Creativity and Intelligence . arXiv : 1410 . 6142 [ 195 ] Graeme Ritchie . 2007 . Some Empirical Criteria for Attributing Creativity to a Computer Program . Minds and Machines 17 ( 2007 ) , 67 ‚Äì 99 . [ 196 ] Adam Roberts , Jesse Engel , Colin Raffel , Curtis Hawthorne , and Douglas Eck . 2018 . A Hierarchical Latent Vector Model for Learning Long - Term Structure in Music . In Proc . of the 35th International Conference on Machine Learning ( Stockholm , Sweden ) , Vol . 80 . PMLR , 4364 ‚Äì 4373 . [ 197 ] Melissa Roemmele and Andrew S . Gordon . 2018 . Automated Assistance for Creative Writing with an RNN Language Model . In Proc . of the 23rd International Conference on Intelligent User Interfaces Companion ( Tokyo , Japan ) . ACM . [ 198 ] Corby Rosset . 2020 . Turing - NLG : A 17 - Billion - Parameter Language Model by Microsoft . Retrieved May 3 , 2022 from microsoft . com / en - us / research / blog / turing - nlg - a - 17 - billion - parameter - language - model - by - microsoft / . [ 199 ] Jon Rowe and Derek Partridge . 1993 . Creativity : A Survey of AI Approaches . Artificial Intelligence Review 7 ( 1993 ) , 43 ‚Äì 70 . [ 200 ] Chitwan Saharia , William Chan , Saurabh Saxena , Lala Li , Jay Whang , Emily Denton , Seyed Kamyar Seyed Ghasemipour , Burcu Karagol Ayan , S . Sara Mahdavi , Rapha Gontijo Lopes , Tim Salimans , Jonathan Ho , David J Fleet , and Mohammad Norouzi . 2022 . Photorealistic Text - to - Image Diffusion Models with Deep Language Understanding . arXiv : 2205 . 11487 [ 201 ] Sameh Said Metwaly , Wim Van den Noortgate , and Eva Kyndt . 2017 . Approaches to Measuring Creativity : A Systematic Literature Review . Creativity . Theories ‚Äì Research - Applications 4 , 2 ( 2017 ) , 238 ‚Äì 275 . [ 202 ] Pamela Samuelson . 1986 . Allocating Ownership Rights in Computer - Generated Works . In Symposium Cosponsored by University of Pittsburgh Law Review and The Software En on The Future of Software Protection ( Pittsburgh , PA ) . University of Pittsburgh Press , 1185 ‚Äì 1228 . [ 203 ] Victor Sanh , Lysandre Debut , Julien Chaumond , and Thomas Wolf . 2019 . DistilBERT , a distilled version of BERT : smaller , faster , cheaper and lighter . In NeurIPS 2019 Workshop ( Vancouver , Canada ) . Curran Associates , Inc . [ 204 ] OthmanSbai , MohamedElhoseiny , AntoineBordes , YannLeCun , andCamilleCouprie . 2019 . DesIGN : DesignInspirationfromGenerativeNetworks . In Computer Vision - ECCV 2018 Workshops ( Munich , Germany ) . Springer , 37 ‚Äì 44 . [ 205 ] J√ºrgen Schmidhuber . 2010 . Formal Theory of Creativity , Fun , and Intrinsic Motivation ( 1990 ‚Äì 2010 ) . IEEE Transactions on Autonomous Mental Development 2 , 3 ( 2010 ) , 230 ‚Äì 247 . [ 206 ] Michael D . Schmidt and Hod Lipson . 2009 . Distilling Free - Form Natural Laws from Experimental Data . Science 324 ( 2009 ) , 81 ‚Äì 85 . [ 207 ] Victor Schmidt , Alexandra Sasha Luccioni , M√©lisande Teng , Tianyu Zhang , Alexia Reynaud , Sunand Raghupathi , Gautier Cosne , Adrien Juraver , Vahe Vardanyan , Alex Hernandez - Garcia , and Yoshua Bengio . 2022 . ClimateGAN : Raising Climate Change Awareness by Generating Images of Floods . In International Conference on Learning Representations ( Online ) , Vol . 10 . OpenReview . net . [ 208 ] Stanislau Semeniuta , Aliaksei Severyn , and Erhardt Barth . 2017 . A Hybrid Convolutional Variational Autoencoder for Text Generation . In Proc . of the 2017 Conference on Empirical Methods in Natural Language Processing ( Copenhagen , Denmark ) . ACL , 627 ‚Äì 637 . [ 209 ] Noam Shazeer , Azalia Mirhoseini , Krzysztof Maziarz , Andy Davis , Quoc Le , Geoffrey Hinton , and Jeff Dean . 2017 . Outrageously Large Neu - ral Networks : The Sparsely - Gated Mixture - of - Experts Layer . In International Conference on Learning Representations ( Toulon , France ) , Vol . 5 . OpenReview . net . [ 210 ] Zhan Shi , Xinchi Chen , Xipeng Qiu , and Xuanjing Huang . 2018 . Toward Diverse Text Generation with Inverse Reinforcement Learning . In Proc . of the 27th International Joint Conference on Artificial Intelligence ( Stockholm , Sweden ) . AAAI Press , 4361 ‚Äì 4367 . [ 211 ] MohammadShoeybi , MostofaPatwary , RaulPuri , PatrickLeGresley , JaredCasper , andBryanCatanzaro . 2019 . Megatron - LM : TrainingMulti - Billion Parameter Language Models Using Model Parallelism . arXiv : 1909 . 08053 [ 212 ] Jaskirat Singh , Cameron Smith , Jose Echevarria , and Liang Zheng . 2021 . Intelli - Paint : Towards Developing Human - like Painting Agents . arXiv : 2112 . 08930 33 Franceschelli and Musolesi [ 213 ] Ivan Skorokhodov , Sergey Tulyakov , and Mohamed Elhoseiny . 2022 . StyleGAN - V : A Continuous Video Generator with the Price , Image Quality and Perks of StyleGAN2 . In 2022 IEEE Conference on Computer Vision and Pattern Recognition ( CVPR ) ( New Orleans , LA ) . IEEE . [ 214 ] Shaden Smith , Mostofa Patwary , Brandon Norick , Patrick LeGresley , Samyam Rajbhandari , Jared Casper , Zhun Liu , Shrimai Prabhumoye , George Zerveas , Vijay Korthikanti , Elton Zhang , Rewon Child , Reza Yazdani Aminabadi , Julie Bernauer , Xia Song , Mohammad Shoeybi , Yuxiong He , Michael Houston , Saurabh Tiwary , and Bryan Catanzaro . 2022 . Using DeepSpeed and Megatron to Train Megatron - Turing NLG 530B , A Large - Scale Generative Language Model . arXiv : 2201 . 11990 [ 215 ] Charlie Snell . 2021 . Alien Dreams : An Emerging Art Scene . Retrieved December 17 , 2021 from ml . berkeley . edu / blog / posts / clip - art / . [ 216 ] Benjamin Sobel . 2020 . A Taxonomy of Training Data : Disentangling the Mismatched Rights , Remedies , and Rationales for Restricting Machine Learning . Artificial Intelligence and Intellectual Property ( 2020 ) , 36 . [ 217 ] Jascha Sohl - Dickstein , Eric Weiss , Niru Maheswaranathan , and Surya Ganguli . 2015 . Deep Unsupervised Learning using Nonequilibrium Thermodynamics . In Proc . of the 32nd International Conference on Machine Learning ( Lille , France ) , Vol . 37 . PMLR , 2256 ‚Äì 2265 . [ 218 ] Yang Song and Stefano Ermon . 2019 . Generative Modeling by Estimating Gradients of the Data Distribution . In Advances in Neural Information Processing Systems ( Vancouver , Canada ) , Vol . 32 . Curran Associates , Inc . [ 219 ] Yang Song and Stefano Ermon . 2020 . Improved Techniques for Training Score - Based Generative Models . In Advances in Neural Information Processing Systems ( Online ) , Vol . 33 . Curran Associates , Inc . , 12438 ‚Äì 12448 . [ 220 ] Yang Song , Yascha Sohl - Dickstein , Diederik P . Kingma , Abhishek Kumar , Stefano Ermon , and Ben Poole . 2021 . Score - Based Generative Modeling through Stochastic Differential Equations . In International Conference on Learning Representations ( Online ) , Vol . 9 . OpenReview . net . [ 221 ] Michael Steinbach , Levent Ert√∂z , and Vipin Kumar . 2004 . The Challenges of Clustering High Dimensional Data . New Directions in Statistical Physics 213 ( 2004 ) , 273 ‚Äì 309 . [ 222 ] Bob L . Sturm , Jo√£o Felipe Santos , Oded Ben - Tal , and Iryna Korshunova . 2016 . Music Transcription Modelling and Composition Using Deep Learning . In 1st Conference on Computer Simulation of Musical Creativity ( Huddersfield , UK ) . [ 223 ] Ilya Sutskever , Oriol Vinyals , and Quoc V . Le . 2014 . Sequence to Sequence Learning with Neural Networks . In Advances in Neural Information Processing Systems ( Montreal , Canada ) , Vol . 27 . MIT Press , 3104 ‚Äì 3112 . [ 224 ] Masahiro Suzuki and Yutaka Matsuo . 2022 . A Survey of Multimodal Deep Generative Models . Advanced Robotics 36 , 5 - 6 ( 2022 ) , 261 ‚Äì 278 . [ 225 ] Pradyumna Tambwekar , Murtaza Dhuliawala , Lara J . Martin , Animesh Mehta , Brent Harrison , and Mark O . Riedl . 2019 . Controllable Neural Story Plot Generation via Reward Shaping . In Proc . of the 28th International Joint Conference on Artificial Intelligence ( Macao , China ) . IJCAI , 5982 ‚Äì 5988 . [ 226 ] Wei Ren Tan , Chee Seng Chan , Hern√°n E . Aguirre , and Kiyoshi Tanaka . 2017 . ArtGAN : Artwork Synthesis with Conditional Categorical GANs . In 2017 IEEE International Conference on Image Processing ( ICIP ) ( Beijing , China ) . IEEE , 3760 ‚Äì 3764 . [ 227 ] Yingtao Tian and David Ha . 2022 . Modern Evolution Strategies for Creativity : Fitting Concrete Images and Abstract Concepts . In Artificial Intelligence in Music , Sound , Art and Design . EvoMUSART 2022 . Lecture Notes in Computer Science ( Madrid , Spain ) . Springer , Cham , 275 ‚Äì 291 . [ 228 ] Hannu Toivonen and Oskar Gross . 2015 . Data Mining and Machine Learning in Computational Creativity . WIREs Data Mining and Knowledge Discovery 5 , 6 ( 2015 ) , 265 ‚Äì 275 . [ 229 ] Donald J . Treffinger . 1996 . Creativity , Creative Thinking , and Critical Thinking : In Search of Definitions . Center for Creative Learning , Sarasota , FL . [ 230 ] Maria Tsimpoukelli , Jacob Menick , Serkan Cabi , S . M . Ali Eslami , Oriol Vinyals , and Felix Hill . 2021 . Multimodal Few - Shot Learning with Frozen Language Models . In Advances in Neural Information Processing Systems ( Online ) , Vol . 34 . Curran Associates , Inc . , 200 ‚Äì 212 . [ 231 ] Lewis Tunstall , Leandro von Werra , and Thomas Wolf . 2022 . Natural Language Processing with Transformers . O‚ÄôReilly , Sebastopol , CA . [ 232 ] Alan M . Turing . 1950 . Computing Machinery and Intelligence . Mind LIX , 236 ( 1950 ) , 433 ‚Äì 460 . [ 233 ] Aaron Van Den Oord , Sander Dieleman , Heiga Zen , Karen Simonyan , Oriol Vinyals , Alex Graves , Nal Kalchbrenner , Andrew Senior , and Koray Kavukcuoglu . 2016 . WaveNet : A Generative Model for Raw Audio . In Proc . 9th ISCA Workshop on Speech Synthesis Workshop ( Sunnyvale , CA ) . 125 . [ 234 ] Aaron Van Den Oord , Nal Kalchbrenner , and Koray Kavukcuoglu . 2016 . Pixel Recurrent Neural Networks . In Proc . of The 33rd International Conference on Machine Learning ( New York , NY ) , Vol . 48 . PMLR , 1747 ‚Äì 1756 . [ 235 ] Aaron Van Den Oord , Nal Kalchbrenner , Oriol Vinyals , Lasse Espeholt , Alex Graves , and Koray Kavukcuoglu . 2016 . Conditional Image Generation with PixelCNN Decoders . In Advances in Neural Information Processing Systems ( Barcelona , Spain ) , Vol . 29 . Curran Associates Inc . , 4797 ‚Äì 4805 . [ 236 ] Aaron Van Den Oord , Oriol Vinyals , and Koray Kavukcuoglu . 2017 . Neural Discrete Representation Learning . In Advances in Neural Information Processing Systems ( Long Beach , CA ) , Vol . 30 . Curran Associates , Inc . , 6309 ‚Äì 6318 . [ 237 ] Lav R . Varshney . 2019 . Mathematical Limit Theorems for Computational Creativity . IBM Journal of Research and Development 63 , 1 ( 2019 ) , 2 : 1 ‚Äì 2 : 12 . [ 238 ] Lav R . Varshney , Florian Pinel , Kush R . Varshney , Debarun Bhattacharjya , Angela Schoergendorfer , and Y - Min Chee . 2019 . A Big Data Approach to Computational Creativity : The Curious Case of Chef Watson . IBM Journal of Research and Development 63 , 1 ( 2019 ) , 7 : 1 ‚Äì 7 : 18 . [ 239 ] Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N . Gomez , Lukasz Kaiser , and Illia Polosukhin . 2017 . Attention is All you Need . In Advances in Neural Information Processing Systems ( Long Beach , CA ) , Vol . 30 . Curran Associates , Inc . [ 240 ] Dan Ventura . 2016 . Mere Generation : Essential Barometer or Dated Concept ? . In Proc . of the 7th International Conference on Computational Creativity ( Paris , France ) . Sony CSL . [ 241 ] Gauthier Vernier , Hugo Caselles - Dupr√© , and Peirre Fautrel . 2020 . Electric Dreams of Ukiyo : A series of Japanese Artworks Created by an Artificial Intelligence . Patterns 1 , 2 ( 2020 ) , 100026 . [ 242 ] Zhengwei Wang , Qi She , and Tom√°s E . Ward . 2021 . Generative Adversarial Networks in Computer Vision : A Survey and Taxonomy . Comput . Surveys 54 , 2 ( 2021 ) , 1 ‚Äì 38 . 34 Creativity and Machine Learning : A Survey [ 243 ] Manuel Watter , Jost Tobias Springenberg , Joschka Boedecker , and Martin Riedmiller . 2015 . Embed to Control : A Locally Linear Latent Dynamics Model for Control from Raw Images . In Advances in Neural Information Processing Systems ( Montreal , Canada ) , Vol . 28 . Curran Associates , Inc . [ 244 ] Max Welling and Yee Whye Teh . 2011 . Bayesian Learning via Stochastic Gradient Langevin Dynamics . In Proc . of the 28th International Conference on International Conference on Machine Learning ( Bellevue , WA ) . Omnipress , 681 ‚Äì 688 . [ 245 ] Geraint A . Wiggins . 2006 . Searching for Computational Creativity . New Generation Computing 24 ( 2006 ) , 209 ‚Äì 222 . [ 246 ] Ronald J . Williams . 1992 . Simple statistical gradient - following algorithms for connectionist reinforcement learning . Machine Learning 8 ( 1992 ) , 229 ‚Äì 256 . [ 247 ] Ho - Hsiang Wu , Prem Seetharaman , Kundan Kumar , and Juan Pablo Bello . 2022 . Wav2CLIP : Learning Robust Audio Representations from Clip . In ICASSP 2022 - 2022 IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) ( Singapore , Singapore ) . IEEE , 4563 ‚Äì 4567 . [ 248 ] Jiajun Wu , Chengkai Zhang , Tianfan Xue , Bill Freeman , and Josh Tenenbaum . 2016 . Learning a Probabilistic Latent Space of Object Shapes via 3D Generative - Adversarial Modeling . In Advances in Neural Information Processing Systems ( Barcelona , Spain ) , Vol . 29 . Curran Associates Inc . , 82 ‚Äì 90 . [ 249 ] Chaowei Xiao , Bo Li , Jun - Yan Zhu , Warren He , Mingyan Liu , and Dawn Song . 2018 . Generating Adversarial Examples with Adversarial Networks . In Proc . of the 27th International Joint Conference on Artificial Intelligence ( Stockholm , Sweden ) . AAAI Press , 3905 ‚Äì 3911 . [ 250 ] Wilson Yan , Yunzhi Zhang , Pieter Abbeel , and Aravind Srinivas . 2021 . VideoGPT : Video Generation using VQ - VAE and Transformers . arXiv : 2104 . 10157 [ 251 ] XinchenYan , JimeiYang , KihyukSohn , andHonglakLee . 2016 . Attribute2Image : ConditionalImageGenerationfromVisualAttributes . In Computer Vision ‚Äì ECCV 2016 . Lecture Notes in Computer Science ( Amsterdam , The Netherlands ) , Vol . 9908 . Springer , Cham , 776 ‚Äì 791 . [ 252 ] Xiaoyuan Yi , Maosong Sun , Ruoyu Li , and Wenhao Li . 2018 . Automatic Poetry Generation with Mutual Reinforcement Learning . In Proc . of the 2018 Conference on Empirical Methods in Natural Language Processing ( Brussels , Belgium ) . ACL , 3143 ‚Äì 3153 . [ 253 ] Lantao Yu , Weinan Zhang , Jun Wang , and Yong Yu . 2017 . SeqGAN : Sequence Generative Adversarial Nets with Policy Gradient . In Proc . of the 31st AAAI Conference on Artificial Intelligence ( San Francisco , CA ) . AAAI Press , 2852 ‚Äì 2858 . [ 254 ] Han Zhang , Ian Goodfellow , Dimitris Metaxas , and Augustus Odena . 2019 . Self - Attention Generative Adversarial Networks . In Proc . of the 36th International Conference on Machine Learning ( Long Beach , CA ) , Vol . 97 . PMLR , 7354 ‚Äì 7363 . [ 255 ] Susan Zhang , Stephen Roller , Naman Goyal , Mikel Artetxe , Moya Chen , Shuohui Chen , Christopher Dewan , Mona Diab , Xian Li , Xi Victoria Lin , Todor Mihaylov , Myle Ott , Sam Shleifer , Kurt Shuster , Daniel Simig , Punit Singh Koura , Anjali Sridhar , Tianlu Wang , and Luke Zettlemoyer . 2022 . OPT : Open Pre - trained Transformer Language Models . arXiv : 2205 . 01068 [ 256 ] Xingxing Zhang and Mirella Lapata . 2014 . Chinese Poetry Generation with Recurrent Neural Networks . In Proc . of the 2014 Conference on Empirical Methods in Natural Language Processing ( Doha , Qatar ) . ACL , 670 ‚Äì 680 . [ 257 ] Yizhe Zhang , Zhe Gan , and Lawrence Carin . 2016 . Generating Text via Adversarial Training . In NeurIPS 2016 Workshop on Adversarial Training ( Barcelona , Spain ) . Curran Associates Inc . [ 258 ] Yizhe Zhang , Zhe Gan , Kai Fan , Zhi Chen , Ricardo Henao , Dinghan Shen , and Lawrence Carin . 2017 . Adversarial Feature Matching for Text Generation . In Proc . of the 34th International Conference on Machine Learning ( Sydney , Australia ) , Vol . 70 . PMLR , 4006 ‚Äì 4015 . [ 259 ] Yanyi Zhang , Xinyu Li , Chunhui Liu , Bing Shuai , Yi Zhu , Biagio Brattoli , Hao Chen , Ivan Marsic , and Joseph Tighe . 2021 . VidTr : Video Transformer Without Convolutions . In 2021 IEEE / CVF International Conference on Computer Vision ( ICCV ) ( Montreal , Canada ) . IEEE , 13577 ‚Äì 13587 . [ 260 ] Shengjia Zhao , Jiaming Song , and Stefano Ermon . 2017 . Towards Deeper Understanding of Variational Autoencoding Models . arXiv : 1702 . 08658 [ 261 ] Tao Zhou , Chen Fang , Zhaowen Wang , Jimei Yang , Byungmoon Kim , Zhili Chen , Jonathan Brandt , and Demetri Terzopoulos . 2018 . Learning to Sketch with Deep Q Networks and Demonstrated Strokes . arXiv : 1810 . 05977 [ 262 ] Jun - Yan Zhu , Taesung Park , Phillip Isola , and Alexei A . Efros . 2017 . Unpaired Image - to - Image Translation Using Cycle - Consistent Adversarial Networks . In 2017 IEEE International Conference on Computer Vision ( ICCV ) ( Venice , Italy ) . IEEE , 2242 ‚Äì 2251 . [ 263 ] Brian D . Ziebart , Andrew Maas , J . Andrew Bagnell , and Anind K . Dey . 2008 . Maximum Entropy Inverse Reinforcement Learning . In Proc . of the 23rd AAAI Conference on Artificial Intelligence ( Chicago , IL ) . AAAI Press , 1433 ‚Äì 1438 . [ 264 ] AndreaZugarini , StefanoMelacci , andMarcoMaggini . 2019 . NeuralPoetry : LearningtoGeneratePoemsUsingSyllables . In InternationalConference on Artificial Neural Networks ( Munich , Germany ) . Springer , 313 ‚Äì 325 . 35