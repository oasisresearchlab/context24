Boba : Authoring and Visualizing Multiverse Analyses Yang Liu , Alex Kale , Tim Althoff , and Jeffrey Heer Compile shared block Use the column { { dyslexia } } Filter rows with matching { { device } } Filter rows higher than { { accuracy } } Run & load outputs into A B decision block , lm model Fit a linear model with { { ﬁxed } } terms decision block , lmer model Fit a linear mixed model with { { ﬁxed } } and { { random } } terms … C D E Fig . 1 . Authoring and visualizing multiverse analyses with Boba . Users start by annotating a script with analytic decisions ( a ) , from which Boba synthesizes a multiplex of possible analysis variants ( b ) . To interpret the results from all analyses , users start with a graph of analytic decisions ( c ) , where sensitive decisions are highlighted in darker blues . Clicking a decision node allows users to compare point estimates ( d , blue dots ) and uncertainty distributions ( d , gray area ) between different alternatives . Users may further drill down to assess the ﬁt quality of individual models ( e ) by comparing observed data ( orange ) with model predictions ( teal ) . Abstract —Multiverse analysis is an approach to data analysis in which all “reasonable” analytic decisions are evaluated in parallel and interpreted collectively , in order to foster robustness and transparency . However , specifying a multiverse is demanding because analysts must manage myriad variants from a cross - product of analytic decisions , and the results require nuanced interpretation . We contribute Boba : an integrated domain - speciﬁc language ( DSL ) and visual analysis system for authoring and reviewing multiverse analyses . With the Boba DSL , analysts write the shared portion of analysis code only once , alongside local variations deﬁning alternative decisions , from which the compiler generates a multiplex of scripts representing all possible analysis paths . The Boba Visualizer provides linked views of model results and the multiverse decision space to enable rapid , systematic assessment of consequential decisions and robustness , including sampling uncertainty and model ﬁt . We demonstrate Boba’s utility through two data analysis case studies , and reﬂect on challenges and design opportunities for multiverse analysis software . Index Terms —Multiverse Analysis , Statistical Analysis , Analytic Decisions , Reproducibility 1 I NTRODUCTION The last decade saw widespread failure to replicate ﬁndings in pub - lished literature across multiple scientiﬁc ﬁelds [ 2 , 3 , 31 , 36 ] . As the replication crisis emerged [ 1 ] , scholars began to re - examine how data analysis practices might lead to spurious ﬁndings . An important con - tributing factor is the ﬂexibility in making analytic decisions [ 13 , 14 , 42 ] . Drawing inferences from data often involves many decisions : what are the cutoffs for outliers ? What covariates should one include in the statistical models ? Different combinations of choices might lead to diverging results and conﬂicting conclusions . The ﬂexibility in making decisions might inﬂate false - positive rates when researchers explore multiple alternatives and selectively report desired outcomes [ 42 ] , a practice known as p - hacking [ 30 ] . Even without exploring multiple paths , ﬁxating on a single analytic path might be less rigorous , as multiple justiﬁable alternatives might exist and picking one would be • All authors are with the University of Washington . E - mails : yliu0 , kalea , althoff , jheer @ uw . edu . Manuscript received xx xxx . 201x ; accepted xx xxx . 201x . Date of Publication xx xxx . 201x ; date of current version xx xxx . 201x . For information on obtaining reprints of this article , please send e - mail to : reprints @ ieee . org . Digital Object Identiﬁer : xx . xxxx / TVCG . 201x . xxxxxxx arbitrary [ 43 ] . For example , a crowdsourced study [ 41 ] show that well - intentioned experts still produce large variations in analysis outcomes when analyzing the same dataset independently . In response , prior work proposes multiverse analysis , an approach to outline all “reasonable” alternatives a - priori , exhaust all possible combinations between them , execute the end - to - end analysis per com - bination , and interpret the outcomes collectively [ 43 , 44 ] . A multiverse analysis demonstrates the extent to which conclusions are robust to sometimes arbitrary analytic decisions [ 43 , 44 ] . Furthermore , reporting the full range of possible results , not just those which ﬁt a particular hypothesis or narrative , helps increase the transparency of a study [ 39 ] . However , researchers face a series of barriers when performing mul - tiverse analyses . Authoring a multiverse is tedious , as researchers are no longer dealing with a single analysis , but hundreds of forking paths resulting from possible combinations of analytic decisions . Without proper scaffolding , researchers might resort to multiple , largely redun - dant analysis scripts [ 23 ] , or rely on error - prone control ﬂows involving nested for - loops and if - statements [ 44 ] . Interpreting the outcomes of a vast number of analyses is also challenging . Besides gauging the over - all robustness of the ﬁndings , researchers often seek to understand what decisions are critical in obtaining particular outcomes ( e . g . , [ 43 , 44 , 51 ] ) . As multiple decisions might interact , understanding the nuances in how decisions affect robustness will require a comprehensive exploration , suggesting a need for an interactive interface . a r X i v : 2007 . 05551v1 [ c s . H C ] 10 J u l 2020 To lower these barriers , we present Boba , an integrated domain - speciﬁc language ( DSL ) and visualization system for multiverse author - ing and interpretation . Rather than managing myriad analysis versions in parallel , the Boba DSL allows users to specify the shared portion of the analysis code only once , alongside local variations deﬁning al - ternative analysis decisions . The compiler enumerates all compatible combinations of decisions and synthesizes individual analysis scripts for each path . As a meta - language , the Boba DSL is agnostic to the underlying programming language of the analysis script ( e . g . , Python or R ) , thereby supporting a wide range of data science use cases . The Boba Visualizer facilitates assessment of the output of all analy - sis paths . We support a workﬂow where users view the results , reﬁne the analysis based on model quality , and commit the ﬁnal choices to making inference . In the initial stage , the system provides linked views of both analysis results and the multiverse decision space to enable a systematic exploration of how decisions do ( or do not ) impact outcomes . In addition to revealing decision sensitivity , the visualizer allows users to take into account sampling uncertainty and model ﬁt by comparing observed data with model predictions [ 11 ] . Users can exclude models poorly suited for inference by adjusting a model ﬁt threshold , or adopt a principled approach based on model averaging to incorporate model ﬁt in inference . We discuss the implications of post - hoc reﬁnement , along with other challenges in multiverse analysis , in our design reﬂections . We evaluate Boba in a code comparison example and two data anal - ysis case studies . We ﬁrst demonstrate how the Boba DSL eliminates custom control - ﬂows when implementing a real - world multiverse of considerable complexity . Then , in two multiverses replicated from prior work [ 43 , 51 ] , we show how the Boba Visualizer affords multiverse interpretation , enabling a richer understanding of robustness , decision patterns , and model ﬁt quality via visual inspection . In both case stud - ies , model ﬁt visualizations surface previously overlooked issues and change what one can reasonably take away from these multiverses . 2 R ELATED W ORK We draw from prior work on visualizing and authoring multiverse analyses , and strategies for authoring alternative programs and designs . 2 . 1 Multiverse Analysis Analysts begin a multiverse analysis by identifying reasonable analytic decisions a - priori [ 33 , 43 , 44 ] . Prior work deﬁnes reasonable decisions as those with ﬁrm theoretical and statistical support [ 43 ] , and decisions can span the entire analysis pipeline from data collection and wrangling to statistical modeling and inference [ 27 , 48 ] . While general guidelines such as a decision checklist [ 48 ] exist , deﬁning what decisions are reasonable still involves a high degree of researcher subjectivity . The next step in multiverse analyses is to exhaust all compatible decision combinations and execute the analysis variants ( we call a vari - ant a universe ) . Despite the growing interest in performing multiverse analysis ( e . g . , [ 3 , 6 , 18 , 32 , 38 ] ) , few tools currently exist to aid authoring . Young and Holsteen [ 51 ] developed a STATA module that simpliﬁes multimodel analysis into a single command , but it only works for sim - ple variable substitution . Rdfanalysis [ 10 ] , an R package , supports more complex alternative scenarios beyond simple value substitution , but the architecture assumes a linear sequential relationship between decisions . Our DSL similarly provides scaffolding for specifying a multiverse , but it has a simpler syntax , extends to other languages , and handles procedural dependencies between decisions . After running all universes to obtain a set of results , the next task is to interpret these results collectively . Some prior studies visualize results from individual universes by either juxtaposition [ 37 , 43 , 44 ] or animation [ 9 ] . Visualizations in other studies apply aggregation [ 8 , 35 ] , for example showing a histogram of effect sizes . The primary issue with juxtaposing or animating individual outcomes is scalability , though the issue might be circumvented by sampling [ 43 ] . Our visualizer shows individual outcomes , but overlays or aggregates outcomes in larger multiverses to provide scalability . In addition to gauging overall robustness , many studies also inves - tigate which analytic decisions are most consequential . The simplest approach is a table [ 5 , 7 , 37 , 44 ] where rows and columns map to decisions , and cells represents outcomes from individual universes . Simonsohn et al . [ 43 ] extend this idea , visualizing the decision space as a matrix beneath a plot of sorted effect sizes . These solutions might not scale as they juxtapose individual outcomes , and the patterns of how outcomes vary might be difﬁcult to identify depending on the spatial arrangements of rows and columns . Another approach slices the aggregated distribution of outcomes along a decision dimension to create a trellis plot [ 35 ] . The trellis plot shows how results vary given a decision , but does not convey what decisions are prominent given certain results . Our visualizer uses trellis plots and supplements it with brushing to show how decisions contribute to particular results . Finally , prior work relies on various strategies to perform inference : given a multiverse , does a hypothesized effect indeed occur ? The simplest approach is counting , for example reporting the fraction of universes having a signiﬁcant p - value [ 5 , 44 ] and / or having an effect with the same sign [ 8 ] . Young and Holsteen [ 51 ] calculate a robustness ratio analogous to the t - statistic . Simonsohn et al . [ 43 ] compare the actual multiverse results to a null distribution obtained from randomly shufﬂing the variable of interest . We build upon Simonsohn’s approach and use weighted model averaging based on model ﬁt quality [ 50 ] to aggregate uncertainty across universes . 2 . 2 Authoring Alternative Programs and Designs Prior work observes that analysts often manage alternative solutions from exploratory work by making duplicate code snippets and ﬁles , but these ad - hoc variants can be messy and difﬁcult to keep track of [ 15 , 23 ] . Provenance tracking tools , especially those with enhanced history interactions [ 23 , 24 ] , provide a mechanism to track and restore alternative versions . In Variolite [ 23 ] , users can select a chunk of code directly in an editor to create and version alternatives . Our DSL similarly allows users to insert local alternatives in code , but instead of assuming that users interact with one version at a time , we generate multiple variants mapping to possible combinations of alternatives . A related line of work supports manipulating multiple alternatives simultaneously . Techniques like subjunctive interfaces [ 28 , 29 ] and Parallel Pies [ 46 ] embed and visualize multiple design variants in the same space , and Parallel Pies allows users to edit multiple variants in parallel . Juxtapose [ 16 ] extends the mechanism to software develop - ment , enabling users to author program alternatives as separate ﬁles and edit code duplicates simultaneously with linked editing . A visualization authoring tool for responsive design [ 17 ] also enables simultaneous editing across variants . Our DSL uses a centralized template such that edits in the shared portion of code affect all variants simultaneously . 3 D ESIGN R EQUIREMENTS Our overarching goal is to make it easier for researchers to conduct multiverse analyses . From prior literature and our past experiences , we identify barriers in authoring a multiverse and visualizing its results , and subsequently identify tasks that our tools should support . 3 . 1 Requirements for Authoring Tools As noted in prior work [ 9 , 27 ] , specifying a multiverse is tedious . This is primarily because a multiverse is composed of many forking paths , yet non - linear program structures are not well supported in conventional tools [ 40 ] . One could use a separate script per analytic path , such that it is easy to reason with an individual variant , but these largely redundant variants are difﬁcult to keep track of , let alone update [ 23 ] . Alternatively , one could rely on control ﬂows in a single script to simulate nonlinear execution of the forking paths , but it is hard to selectively inspect and rerun a single path because useful snippets are embedded in convoluted control ﬂow structures . Instead , a tool should eliminate the need to write redundant code and custom control ﬂows , while at the same time allowing analysts to simultaneously update variants and reason with a single variant . Compared to arbitrary non - linear paths from an iterative exploratory analysis , the forking paths in multiverses are usually highly systematic , as they are a cross - product of analytic decisions . We take advantage of this characteristic , and account for other scenarios common in existing multiverse analyses . We distill the following design requirements : R1 : Multiplexing . Users should be able to specify a multiverse by writing the shared portion of the analysis source code along with analytic decisions , while the tool creates the forking paths for them . Users should also be able to reason about a single universe and update all universes simultaneously . R2 : Decision Complexity . Decisions come in varying degrees of complexity , from simple value replacements ( e . g . , cutoffs for excluding outliers ) to elaborate logic requiring multiple lines of code to imple - ment . The tool should allow succinct ways to express simple value replacements while at the same time support more complex decisions . R3 : Procedural Dependency . Existing multiverses [ 6 , 44 ] contain procedural dependencies [ 27 ] , in which a downstream decision only exists if a particular upstream choice is made . For example , researchers do not need to choose priors if using a Frequentist model instead of a Bayesian model . The tool should support procedural dependencies . R4 : Decision Idiosyncrasies . Due to the idiosyncrasies in imple - mentation , the same conceptual decision can manifest in multiple forms . For example , the same set of parameters can appear in different formats to comply with different function APIs . Users should be able to specify different implementations of a high - level decision . R5 : Language Agnostic . Users should be able to author their anal - ysis in any programming languages , as potential users are from various disciplines adopting different workﬂows and programming languages . 3 . 2 Task Analysis for Visual Analysis System After researchers execute all analytic paths in a multiverse and obtain corresponding results , they face additional challenges in interpreting the results collectively . The primary task in prior work ( Sect . 2 ) is to understand the overall robustness of outcomes across all reasonable speciﬁcations . If the robustness test indicates conﬂicting conclusions , a natural follow - up task is to identify consequential decisions : what deci - sions are critical to obtaining a particular conclusion ? What decisions produce large variations in results ? Besides these common tasks among prior multiverse analyses , we also propose additional tasks to cover potential blind spots in the litera - ture . First , besides point estimates , a tool should convey appropriate uncertainty information . Such information would help users gauge the end - to - end uncertainty caused by both sampling and decision variations , and compare the variance between conditions . Second , it is important to assess the model ﬁt quality to distinguish trustworthy models from the ones producing questionable estimates . Uncertainty information and ﬁt issues become particularly impor - tant during statistical inference . Users should be able to propagate uncertainty in the multiverse to support judgments about the overall reliability of effects , and they should be able to reﬁne the multiverse to exclude models with ﬁt issues before proceeding to make inferences . To summarize , we identify the following main tasks that our visual analysis interface should support : • T1 : Decision Overview – gain an overview of the decision space to understand the multiverse and contextualize subsequent tasks . • T2 : Robustness Overview – gauge the overall robustness of ﬁnd - ings obtained through all reasonable speciﬁcations . • T3 : Decision Impacts – identify what combinations of decisions lead to large variations in outcomes , and what combinations of decisions are critical in obtaining speciﬁc outcomes . • T4 : Uncertainty – assess the end - to - end uncertainty as well as uncertainty associated with individual universes . • T5 : Model Fit – assess the model ﬁt quality of individual universes to distinguish trustworthy models from questionable ones . • T6 : Inference – perform statistical inference to judge how reliable the hypothesized effect is , while accounting for model quality . Besides the tasks , our system should be compatible with the follow - ing data characteristics ( D1 ) : the visual encoding should be scalable to large multiverses and large input datasets . 4 T HE B OBA DSL We design a domain - speciﬁc language ( DSL ) to simplify the authoring of multiverse analyses . With the DSL , users annotate the source code of # - - - ( A ) df = read _ csv ( " data . csv " ) % > % filter ( speed > { { cutoff = 10 , 200 } } ) # - - - ( M ) frequentist model = lm ( log _ y ~ x , data = df ) # - - - ( M ) bayesian model = brm ( y ~ x , data = df , family = { { brm _ family = " binomial " , " lognormal " } } ( ) ) df = read _ csv ( " data . csv " ) % > % filter ( speed > 10 ) ) model = brm ( y ~ x , data = df , family = lognormal ( ) ) File cutoff brm _ family M 1 . R 10 frequentist 2 . R 200 frequentist 3 . R 10 binomial bayesian 4 . R 10 lognormal bayesian 5 . R 200 binomial bayesian 6 . R 200 lognormal bayesian input . R df = read _ csv ( " data . csv " ) % > % filter ( speed > 10 ) ) model = lm ( log _ y ~ x , data = df ) ( a ) ( b ) ( c ) ( d ) 1 . R 4 . R output ﬁles Fig . 2 . An example Boba speciﬁcation . The user annotates an R script ( a ) with two placeholder variables ( blue ) and three code blocks ( pink ) . The compiler synthesizes six ﬁles ( b ) . In the example output ﬁles ( c ) and ( d ) , placeholder variables are replaced by their possible values , and only one version of the decision block M is present . their analysis to indicate decision points and alternatives , and provide additional information for procedural dependencies between decisions . The compiler takes as input an annotated script and accompanying metadata , and produces a collection of universe scripts , each containing the code to execute one analytic path in the multiverse ( Fig . 1b , R1 ) . An example Boba speciﬁcation for a small multiverse is shown in Fig . 2 . 4 . 1 Language Constructs The basic language primitives in the Boba DSL consist of source code , placeholder variables , blocks , constraints , and code graphs . 4 . 1 . 1 Source Code The most basic ingredient of an annotated script is the source code ( Fig . 2a , black text ) . The compiler treats the source code as a string of text , which according to further language rules will be synthesized into text in the output ﬁles . As the compiler is agnostic about the semantics of the source code , users are free to write the source code in any programming language ( R5 ) . 4 . 1 . 2 Placeholder Variables Placeholder variables are useful to specify decisions points consisting of simple value substitution ( R2 ) . To deﬁne a placeholder variable , users provide an identiﬁer and a set of possible alternative values that the variable can take up ( Fig . 2a , blue text ) . To use the variable , users insert the identiﬁer into any position in the source code . During synthesis , the compiler removes the identiﬁer and replaces it with one of its alternative values . Variable deﬁnition may occur at the same place as its usage ( Fig . 2a ) or ahead of time inside the conﬁg block ( supplemental Fig . 2 ) . 4 . 1 . 3 Code Blocks The mechanism for code blocks ( Fig . 2a , pink text ) divides the source code into multiple snippets of one or more lines of code , akin to cells in a computational notebook . A block can be a normal block ( Fig . 2a , block A ) , or a decision block ( Fig . 2a , block M ) with multiple ver - sions . The content of a normal block will be shared by all universes , whereas only one version of the decision block will appear in a universe . Decision blocks allow users to specify alternatives that require more elaborate logic to deﬁne ( R2 ) . In the remainder of Sect . 4 , decision points refers to placeholder variables and decision blocks . With the constructs introduced so far , a natural way to express procedural dependency ( R3 ) is to insert a placeholder variable in some , but not all versions of a decision block . For example , in Fig . 2 , the variable brm family only exists when bayesian of block M is chosen . for ( i in 1 : no . nmo ) { # for each NMO option for ( j in 1 : no . f ) { # for each F option for ( k in 1 : no . r ) { # for each R option for ( l in 1 : no . ecl ) { # for each ECL option for ( m in 1 : no . ec ) { # for each EC option # preprocessing code [ . . . ] if ( i = = 1 ) { [ . . . ] # code for the first NMO option } else if ( i = = 2 ) { [ . . . ] # code for the second NMO option } else if ( i = = 3 ) { [ . . . ] # code for the third NMO option } # fertility options bounds = c ( 7 , 8 , 9 , 8 , 9 ) df $ fertility [ df $ cycle > bounds [ j ] ] = ‘High’ [ . . . ] if ( l = = 1 ) { [ . . . ] # code for the first ECL option } else if ( l = = 2 ) { if ( i = = 2 ) { next } [ . . . ] # code for the second ECL option } else if ( l = = 3 ) { if ( i = = 1 ) { next } [ . . . ] # code for the third ECL option } # two more decisions are omitted [ . . . ] } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 ( a ) # preprocessing code [ . . . ] # - - - ( NMO ) computed [ . . . ] # code for the 1st NMO option # - - - ( NMO ) reported [ . . . ] # code for the second NMO option # - - - ( NMO ) estimate [ . . . ] # code for the third NMO option # - - - ( F ) df $ fertility [ df $ cycle > { { bound = 7 , 8 , 9 , 8 , 9 } } ] = ‘High’ [ . . . ] # - - - ( ECL ) none [ . . . ] # code for the first ECL option # - - - ( ECL ) computed @ if NMO ! = reported [ . . . ] # code for the second ECL option # - - - ( ECL ) reported @ if NMO ! = computed [ . . . ] # code for the third ECL option # two more decisions are omitted [ . . . ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ( b ) Fig . 3 . Speciﬁcation of a real - world multiverse analysis [ 44 ] with ﬁve decisions and a procedural dependency . ( a ) Markup of the R code written by original authors , with custom control ﬂow ( nested for - loops and if - statements ) highlighted . ( b ) Markup of the Boba DSL speciﬁcation . 4 . 1 . 4 Constraints By default , Boba assumes all combinations between decision points are valid . Constraints allow users to express dependencies between decision points , for example infeasible combinations , which will restrict the universes to a smaller set . Boba supports two types of constraints : procedural dependencies ( R3 ) and linked decisions ( R4 ) . A procedural dependency constraint is attached to a decision point or one of its alternatives , and has a conditional expression to deter - mine when the decision / alternative should exist ( Fig . 3b , orange text ) . Variables within the scope of the conditional expression are declared de - cision points , and the values are the alternatives that the decision points have taken up . For example , the ﬁrst constraint in Fig . 3b indicates that ECL computed is not compatible with NMO reported . The second type of constraint allows users to link multiple decision points , indicating that these decision points are different manifesta - tions of a single conceptual decision ( R4 , see supplemental Fig . 2 ) . Linked decisions have one - to - one mappings between their alternatives , such that the i - th alternatives are chosen together in the same universe . One - to - one mappings can also be expressed using multiple procedural dependencies , but linked decisions make them easier to specify . 4 . 1 . 5 Code Graph Users may further specify the execution order between code blocks as a directed acyclic graph ( DAG ) , where a parent block executes before its child . To create a universe , the compiler selects a linear path from the start to the end , and concatenates the source code of the blocks along the path . Branches in the graph represent alternative paths that will appear in different universes . With the graph , users can ﬂexibly express com - plex dependencies between blocks , including procedural dependencies ( R3 ) . For example , to indicate that block prior should only appear af - ter block bayesian but not block frequentist , the user may simply make prior a descendant of bayesian but not frequentist . 4 . 2 Compilation and Runtime The compiler parses the input script , computes compatible combina - tions between decisions , and generates output scripts . During parsing , the compiler extracts the corresponding language primitives from the input ﬁle . To enumerate compatible combinations , the compiler pro - ceeds in the following steps . First , it obtains the DAG specifying the execution relationships between code blocks . If users omit the DAG , the compiler creates a default graph which is a linear path of all code blocks depending on their order in the input script . The compiler mod - iﬁes the DAG to incorporate decision blocks and constraints . Then , it computes all possible paths from any source node with no input edges to any destination node with no output edges . For each path , the compiler further expands placeholder variables ( i . e . , it enumerates all possible combinations between them ) . Finally , for each path and vari - able combination , the compiler concatenates source code along the path , replaces placeholder variables with corresponding values , and outputs a universe script . It also outputs a summary table that keeps track of all the decisions made in each universe , along with other intermediate data that can be ingested into the Boba Visualizer . Boba infers the language of the input script based on its ﬁle ex - tension and uses the same extension for output scripts . These output scripts might be run with the corresponding script language interpreter . Universe scripts log the results into separate ﬁles , which will be merged together after all scripts ﬁnish execution . As the universe scripts are responsible for computation such as extracting point estimates and com - puting uncertainty , we provide language - speciﬁc utilities for a common set of model types to generate these visualizer - friendly outputs . We provide a command - line tool for users to ( 1 ) invoke the compiler , ( 2 ) execute the generated universe scripts , ( 3 ) merge the universe out - puts , and ( 4 ) invoke the visualizer as a local server reading the output ﬁles . The compiler and the command - line tool are implemented in Python and are available on GitHub as open source software . 4 . 3 Example : Replicating a Real - World Multiverse We use a real - world multiverse example [ 44 ] to illustrate how the Boba DSL eliminates the need for custom control ﬂows otherwise required for authoring a multiverse in a single script . The multiverse , originally proposed by Steegen et al . [ 44 ] , contains ﬁve decisions and a procedural dependency . Fig . 3a shows a markup of the R code implemented by the original authors ( we modiﬁed the lines in purple to avoid computing infeasible paths ) . The script starts with ﬁve nested for - loops ( yellow highlight ) to repeat the analysis for every possible combination of the ﬁve decisions . Then , depending on the indices of the current decisions , the authors either index into an array , or use if - statements to deﬁne alternative program behaviors ( blue highlight ) . Finally , to implement a procedural dependency , it is necessary to skip the current iteration when incompatible combinations occur ( purple highlight ) . The resulting script has multiple issues . First , the useful snippets deﬁning multiverse behavior are embedded in the custom control ﬂow structure , making them hard to ﬁnd and read . Second , it is difﬁcult to keep track of which option is which . Third , without additional error - handling and checkpoint mechanisms , an error in the middle will terminate the program before any results are saved . The corresponding speciﬁcation in the Boba DSL is shown in Fig . 3b . The script starts directly with the prepossessing code shared by all uni - verses . It then uses decision code blocks to deﬁne alternative snippets in decision NMO and ECL , and uses a placeholder variable to simulate the value array for a simpler decision F . It additionally speciﬁes constraints ( orange text ) to signal incompatible paths . Compared to Fig . 3a , this script reduces the amount of boilerplate code needed for control - ﬂows , and useful snippets are no longer embedded in convoluted structures . The speciﬁcation compiles to 120 separate ﬁles . Errors in one universe no longer affect the successful completion of others due to distributed execution , and users can selectively review and debug a single analysis . 5 T HE B OBA V ISUALIZER Next , we introduce Boba Visualizer , a visual analysis system for in - terpreting the outputs from all analysis paths . We present the system features and design choices in a ﬁctional usage scenario where Emma , an HCI researcher , uses the visualizer to explore a multiverse on data collected in her experiment . We construct the multiverse based on how the authors of a published research article [ 25 ] might analyze their data , but the name “Emma” and her workﬂow are ﬁctional . Emma runs an experiment to understand whether a webpage reader view improves reading speed . To ensure that her conclusion does not depend on idiosyncratic speciﬁcations , Emma identiﬁes six analytic de - cisions in her analysis pipeline , including choices in data preprocessing and statistical modeling . She then writes a multiverse speciﬁcation in the Boba DSL , compiles it to 216 analysis scripts , and runs all scripts to obtain a collection of outputs . Now that Emma has hundreds of effect sizes and conﬁdence intervals , she wants to gauge the robustness of the analysis : do the effect sizes support her hypothesis that reader view improves reading speed ? Which decisions lead to conﬂicting results ? Are the estimates coming from trustworthy models ? To answer these questions , she loads the outputs into the Boba Visualizer . ( a ) ( b ) Fig . 4 . Decision view and outcome view . ( a ) The decision view shows analytic decisions as a graph with order and dependencies between them , and highlights more sensitive decisions in darker colors . ( b ) The outcome view visualizes outputs from all analyses , including individual point estimates and aggregated uncertainty . 5 . 1 Outcome View On system start - up , Emma sees an overview distribution of point esti - mates from all analyses ( Fig . 4b ) . The majority of the coefﬁcients are positive , but a smaller peak around zero suggests no effect . The outcome view visualizes the ﬁnal results of the multiverse , in - cluding point estimates ( e . g . , model coefﬁcient of reader view , the independent variable encoding experimental conditions ) and uncer - tainty information . By default , the chart contains outcomes from all universes in order to show the overall robustness of the conclusion ( T2 ) . We visualize point estimates using a density dot plot [ 49 ] , where a dot maps to a point estimate from one universe ( Fig . 4b , blue dots ) . The x - axis encodes the magnitude of the estimate ; overlapping dots are aligned and stacked along the y - axis . To accomodate large multiverses ( D1 ) , we allow dots to overlap along the y - axis , which always represents count . A density dot plot more accurately depicts gaps and outlying values in data than histograms [ 49 ] . Having a one - to - one mapping between dots and universes affords direct manipulation interactions such as brushing and details - on - demand , as we will introduce later . Alongside the point estimates , we use a background area chart ( Fig . 4b , gray area ) to show end - to - end uncertainty from both sampling and decision variations ( T4 ) . We compute the end - to - end uncertainty by aggregating over modeling uncertainty from all universes . Speciﬁ - cally , we ﬁrst calculate ˆ f ( x ) = ∑ Ni = 1 f i ( x ) , where f i ( x ) is the sampling distribution of the i - th universe , and N is the overall multiverse size . Then , we scale the height of the area chart such that the total area under ˆ f ( x ) is approximately the same as the total area occupied by circles in the dot plot . This way , when the uncertainty introduced by sampling variations is negligible , the background area chart will follow the dot plot distribution closely . In contrast , the mismatch of the two distributions in Fig . 4b indicates considerable sampling uncertainty . Boba supports two additional ways to view uncertainty from individ - ual universes , by showing a collection of probability density functions ( PDFs ) or cumulative distribution functions ( CDFs ) ( Fig . 6 ) . In both visualizations , we draw a cubic basis spline for the corresponding distribution per universe , and reduce the opacity of the curves to visu - ally “merge” the curves within the same space . The PDFs and CDFs views again have a one - to - one mapping between a visual element and a universe to afford interactions . Users can switch between aggregated uncertainty , PDFs , and CDFs from a dropdown menu . To help con - nect these views , we draw a strip plot of point estimates beneath each PDFs / CDFs chart ( Fig . 6 , blue ) , and show the corresponding sampling distribution PDF when users mouse over a universe in the dot plot . 5 . 2 Decision View As the overall outcome distribution suggests conﬂicting conclusions , Emma wants to investigate what decisions lead to changes in results . She ﬁrst familiarizes herself with the available decisions . The left panel always shows a graph of the analytic decisions made in the multiverse , along with their order and dependencies ( Fig . 4a ) . It A B C D Fig . 5 . Facet and Brushing . Clicking a node in the decision view ( a ) divides the outcome view into a trellis plot ( b ) , answering questions like “does the decision lead to large variations in effect size ? ” Brushing a region in the outcome view ( c ) reveals dominant alternatives in the option ratio view ( d ) , answering questions like “what causes negative results ? ” Fig . 6 . PDFs ( a ) and CDFs ( b ) views visualize sampling distributions from individual universes . Toggling these views in a trellis plot allows users to compare the variance between conditions . helps the users understand the decision space and provides a starting point for further interactions ( T1 ) . We adapt the design of Analytic Decision Graphs [ 27 ] to show decisions in the context of the analysis process . Nodes represent de - cisions and edges represent the relationships between decisions : light gray edges encode temporal order ( the order that decisions appear in analysis scripts ) and black edges encode procedural dependencies . Compared to viewing decisions in isolation , this design additionally conveys the analysis pipeline to help users better reason with the ram - iﬁcations of a decision . This design also omits the complexity at the level of alternatives – for example , an alternative design may draw every end - to - end path in the multiverse , which will soon grow cluttered . Instead , we aggregate the information about alternatives , using the size of a node to represent the number of alternatives and listing a few example alternative values beside a node . The underlying data structure for the decision graph is inferred from the Boba DSL speciﬁcation . We infer decision names from the identiﬁers of placeholder variables or code blocks . We extract temporal order as the order that decision points are ﬁrst used in the speciﬁcation , and detect procedural dependencies from user - speciﬁed constraints and code graph structure . After we extract the data structure , we apply a Sugiyama - style [ 45 ] ﬂow layout algorithm , as implemented in the JavaScript library Dagre [ 34 ] , to compute the graph layout . 5 . 2 . 1 Sensitivity When viewing the decision graph , Emma notes a sensitive decision “Device” which is highlighted in a darker color ( Fig . 4a ) . To highlight decisions which lead to large changes in analysis out - comes , we compute the marginal sensitivity of each decision and color the nodes using a sequential color scale . The color encoding helps draw ( a ) ( b ) Fig . 7 . ( a ) Coloring the universes according to their model ﬁt quality . ( b ) Removing universes that fail to meet a model quality threshold . the user’s attention to consequential decisions to aid initial exploration . Boba implements two methods for estimating sensitivity . The ﬁrst method is based on the F - Test in one - way ANOVA , which quantiﬁes how much a decision shifts the means of results compared to vari - ance ( details in supplemental material ) . The second method uses the Kolmogorov – Smirnov ( K – S ) statistic , a non - parametric method to quantify the difference between two distributions . We ﬁrst compute pairwise K – S statistics between all pairs of alternatives in decision D : K = (cid:26) sup x | f i ( x ) − f j ( x ) | : i , j ∈ (cid:18) S 2 (cid:19)(cid:27) where f i ( x ) is the empirical distribution function of results following the i - th alternative , and S = { 1 , 2 , . . . , k } where k is the number of alter - natives in D . We then take the median of K as the sensitivity score s D . In both methods , we map s D to a single - hue color ramp of blue shades . As the F - Test relies on variance , which is not a reasonable measure for dispersion of some distributions , Boba uses the nonparametric K – S statistic by default . Users can override the default in the conﬁg ﬁle . 5 . 3 Facet and Brushing Seeing that the decision “Device” has a large impact , Emma clicks on the node to further examine how results vary ( Fig . 5a ) . She ﬁnds that one condition exclusively produces point estimates around zero ( Fig . 5b ) and it also has a much larger variance ( Fig . 6 ) . Clicking a node in the decision graph divides the outcome distribu - tion into a trellis plot , where each subplot shows the subset of universes adopting an alternative . The interaction allows users to systematically examine the trends and patterns caused by a decision ( T3 ) . Akin to the overall outcome distribution , users can toggle between point estimates and uncertainty views to compare the variance between conditions . The trellis plot can be further divided on a second decision via shift - clicking a second node to show the interaction between two decisions . With faceting , users may comprehensively explore the data to sanity - check and assess unexpected patterns , by viewing all univariate and bivariate plots . Alternatively , as sensitive decisions are automatically highlighted , users might quickly locate and examine consequential decisions . What decisions lead to negative estimates ? Emma brushes negative estimates in a subplot ( Fig . 5c ) and inspects option ratios ( Fig . 5d ) . Users may brush a region in the outcome view to investigate re - sponsible decisions in the option ratio view . By showing the relative percentages of alternatives , the option ratio view reveals dominating alternatives that produce speciﬁc results ( T3 ) . This view visualizes each decision as a stacked bar chart to illustrate the percentages of results coming from different alternatives . When the user brushes a range of results , the bars are updated accordingly to reﬂect changes , and dominating alternatives ( those having a higher percentage than default ) are highlighted . For example , Emma notices that the lmer model and two sets of ﬁxed effects are particularly respon - sible for the negative outcomes in Fig . 5c . We color the bar segments using a categorical color scale to make bars visually distinguishable . 5 . 4 Model Fit View Now that Emma understands what decisions lead to null effects , she wonders if these results are from trustworthy models . She changes the color - by ﬁeld to get an overview of model ﬁt quality ( Fig . 7a ) and sees ( a ) ( c ) ( b ) Fig . 8 . Inference views . ( a ) Aggregate plot comparing the possible outcomes of the actual multiverse ( blue ) and the null distribution ( red ) . ( b ) Detail plot showing the individual point estimates and the range between the 2 . 5th and 97 . 5th percentile in the null distribution ( gray line ) . Point estimates outside the range are colored in orange . ( c ) Alternative aggregate plot where a red line marks the expected null effect . that the universes around zero have a poorer ﬁt . She then uses a slider to remove universes that fail to meet a quality threshold ( Fig . 7b ) . Boba enables an overview of model ﬁt quality across all universes ( T5 ) by coloring the outcome view with a model quality metric ( Fig . 7a ) . We use k - fold cross validation [ 47 ] to compute model quality , as metrics such as Akaike Information Criterion cannot be used to compare model ﬁt across classes of models ( e . g . , hierarchical vs . linear ) [ 12 ] . Prior work shows that cross validation performs better in estimating predic - tive density for a new dataset than information criteria [ 47 ] , suggesting that it is a better approximation of out - of - sample predictive validity . We map the normalized root mean squared error ( NRMSE ) to a single - hue colormap of blue shades where a darker blue indicates a better ﬁt . To obtain NRMSE , we ﬁrst compute the overall mean squared prediction error ( MSE ) from a k - fold cross validation MSE = 1 k k ∑ j = 1 1 n j n j ∑ i = 1 ( y i − ˆ y i ) 2 where k is the number of folds ( we set k = 5 in all examples ) , n j is the size of the test set in the j - th fold , y i is the observed value , and ˆ y i is the predicted value . We then normalize the MSE by the span of the maximum y max and minimum y min values of the observed variable : NRMSE = √ MSE / ( y max − y min ) To further investigate model quality , Emma drills down to individual universes by clicking a dot in the outcome view . She sees in the model ﬁt view ( Fig . 1e ) that a model only produces one possible estimate . Clicking a result in the outcome view populates the model ﬁt view with visual predictive checks , which show how well predictions from a given model replicate the empirical distribution of observed data [ 11 ] , allowing users to further assess model quality ( T5 ) . The model ﬁt visualization juxtaposes violin plots of the observed data and model predictions to facilitate comparison of the two distributions ( see Fig . 1e ) . We additionally overlay raw data points within the violin plots using a centered density dot plot layout , to help reveal any discrepancies in approximation due to kernel density estimation in the violin plots . When the number of observations is large ( D1 ) , we quantize the raw data , sampling at evenly spaced percentiles , and plot this representative subset as centered quantile dotplots [ 22 ] . As clicking individual uni - verses can be tedious , the model ﬁt view suggests additional universes that have similar point estimates to the selected universe . 5 . 5 Inference After an in - depth exploration , Emma proceeds to the ﬁnal step , asking “given the multiverse , how reliable is the effect ? ” She conﬁrms a warning dialog to arrive at the inference view ( Fig . 8 ) . To support users in making inference and judging how reliable the hypothesized effect is ( T6 ) , Boba provides an inference view at the end of the analysis workﬂow , after users have engaged in exploration . Once A C D E B C Fig . 9 . A case study on how model estimates are robust to control variables in a mortgage lending dataset . ( a ) Decision view shows that black and married are two consequential decisions . ( b ) Overall outcome distribution follows a multimodal distribution with three peaks . ( c ) Trellis plot of black and married indicates the source of the peaks . ( d ) Model ﬁt plots show that models produce numeric predictions while observed data is categorical . ( e ) PDFs of individual sampling distributions show signiﬁcant overlap of the three peaks . in the inference view , all earlier views and interactions are inaccessible to avoid multiple comparison problems [ 52 ] arising from repeated inference . The inference view contains different plots depending on the outputs from the authoring step , so that users can choose between robust yet computationally - expensive methods and simpler ones . A more robust inference uses permutation tests for data with random assignment [ 43 ] to generate the expected distribution of outcomes when the null hypothesis of no effect is true . Speciﬁcally , we shufﬂe the column with the randomly assigned variable ( reader view in this case ) N times , run the multiverse of size M on the each of the shufﬂed datasets , and obtain N × M point estimates . As there is no link between reader view and speed in the shufﬂed datasets , these N × M point estimates constitute the null distribution . When the null distribution is available , the inference view shows an aggregate plot followed by a detail plot ( Fig . 8ab ) . The aggregate plot ( Fig . 8a ) compares the null distribution ( red ) to possible outcomes of the actual multiverse ( blue ) across sampling and decision variations . The detail plot ( Fig . 8b ) depicts individual universes instead , showing the point estimate ( colored dot ) against the range within the 2 . 5th and 97 . 5th percentile of the null distribution ( gray line ) . The point estimate is orange if it is outside the range , or blue otherwise . Underneath both plots , we provide detailed descriptions ( supplemental Fig . 1 ) to guide users in interpretation : For the aggregate plot , we prompt users to compare the distance between the averages of the two densities to the spread . For the detail plot , we count the number of universes with the point estimate outside its corresponding range . If the null distribution is unavailable , Boba shows a simpler aggregate plot ( Fig . 8c ) where the expected effect size under the null hypothesis is marked with a red line . In addition , Boba enables users to propagate concerns in model ﬁt quality to the inference view in two possible ways . The ﬁrst way employs a model averaging technique called stacking [ 50 ] to take a weighted combination of the universes according to their model ﬁt quality . The technique learns a simplex of weights , one for each universe model , via optimization that maximizes the log - posterior - density of the held - out data points in a k - fold cross validation . Boba then takes a weighted combination of the universe distributions to create the aggregate plot . While stacking provides a principled way to approach model quality , it can be computationally expensive . As an alternative , Boba excludes the universes below the model quality cutoff users provide in Sect . 5 . 4 . The decisions of the cutoff and whether to omit the universes are made before a user enters the inference view . 6 C ASE S TUDIES We evaluate Boba through a pair of analysis case studies , where we implement the multiverse using the Boba DSL and interpret the results using the Boba Visualizer . The supplemental material contains the Boba speciﬁcations of both examples , additional ﬁgures , and a video demonstrating all the interactions described below . 6 . 1 Case Study : Mortgage Analysis The ﬁrst case study demonstrates how analysts might quickly arrive at insights provided by summary statistics in prior work , while at the same time gaining a richer understanding of robustness patterns . We also show that by incorporating uncertainty and model ﬁt checks , Boba surfaces potential issues that prior work might have neglected . Young et al . [ 51 ] propose a multimodel analysis approach to gauge whether model estimates are robust to alternative model speciﬁcations . Akin to the philosophy of multiverse analysis , the approach takes all combinations of possible control variables in a statistical model . The outputs are multiple summary statistics , including ( 1 ) an overall robustness ratio , ( 2 ) uncertainty measures for sampling and modeling variations , and ( 3 ) metrics reﬂecting the sensitivity of each variable . As an example , the authors present a case study on mortgage lending , asking “are female applicants more likely to be approved for a mort - gage ? ” They ﬁt a multiverse of linear regression models with a term for female and other control variables capturing demographic and ﬁnancial information . The resulting summary statistics indicate that the estimate is not robust to modeling decisions with large end - to - end uncertainty , and two control variables , married and black , are highly inﬂuential . These summary statistics provide a powerful synopsis , but may fail to convey more nuanced patterns in result distributions . The authors manually create additional visualizations to convey interesting trends in data , for instance the estimates follow a multimodal distribution . These visualizations , though necessary to provide a richer understanding of model robustness , are ad - hoc and not included in the software package . We replicate the analysis in Boba . The Boba DSL speciﬁcation simply consists of eight placeholder variables , each indicating whether to include a control variable in the model formula . Then , we compile the speciﬁcation to 256 scripts , run them all , and start the Boba Visualizer . We ﬁrst demonstrate that the default views in the Boba Visualizer afford similar insights on uncertainty , robustness , and decision sen - sitivity . Upon launching the visualizer , we see a decision graph and an overall outcome distribution ( Fig . 9 ) . The decision view ( Fig . 9a ) A B D C Fig . 10 . A case study on whether hurricanes with more feminine names have caused more deaths . ( a ) The majority of point estimates suggest a small , positive effect , but there are considerable variations . ( b ) Faceting and brushing reveal decision combinations that produce large estimates . Coloring by model quality shows that large estimates are from questionable models , and predictive checks ( c ) conﬁrms model ﬁt issues . ( d ) Inference view shows that the observed and null distributions are different in terms of mode and shape , yet with highly overlapping estimates . highlights two sensitive decisions , black and married . The outcome view ( Fig . 9b ) shows that the point estimates are highly varied with conﬂicting implications . The aggregated uncertainty in the outcome view ( Fig . 9b , background gray area ) has a wide spread , suggesting that the possible outcomes are even more varied when taking both sampling and decision variability into account . These observations agree with the summary metrics in previous work , though Boba uses a different , non - parametric method to quantify decision sensitivity , as well as a different method to aggregate end - to - end uncertainty . The patterns revealed by ad - hoc visualizations in previous work are also readily available in the Boba Visualizer , either in the default views or with two clicks guided by prominent visual cues . The default out - come view ( Fig . 9b ) shows that the point estimates follow a multimodal distribution with three separate peaks . Clicking the two highlighted ( most sensitive ) nodes in the decision view ( Fig . 9a ) produces a trellis plot ( Fig . 9c ) , where each subplot contains only one cluster . From the trellis plot , it is evident that the leftmost and rightmost peaks in the overall distribution come from two particular combinations of the inﬂuential variables . Alternatively , users might arrive at similar insights by brushing individual clusters in the default outcome view . Finally , the uncertainty and model ﬁt visualizations in Boba sur - face potential issues that previous work might have overlooked . First , though the point estimates in Fig . 9b fall into three distinct clusters , the aggregated uncertainty distribution appears unimodal despite a wider spread . The PDF plot ( Fig . 9e ) shows that sampling distribution from one analysis typically spans the range of multiple peaks , thus explain - ing why the aggregated uncertainty is unimodal . These observations suggest that the multimodal patterns exhibited by point estimates are not robust when we take sampling variations into account . Second , we assess model ﬁt quality by clicking a dot in the outcome view and examining the model ﬁt view ( Fig . 9d ) . As shown in Fig . 9d , while the observed data only takes two possible values , the linear regression model produces a continuous range of predictions . It is clear from this visual check that an alternative model , for example logistic regression , is more appropriate than the original linear regression models , and we should probably interpret the results with skepticism given the model ﬁt issues . These observations support our arguments in Sect . 3 . 2 that uncertainty and model ﬁt are potential blind spots in prior literature . 6 . 2 Case Study : Female Hurricanes Caused More Deaths ? Next , we replicate another multiverse example introduced by Simon - sohn et al . [ 43 ] , where the authors challenged the results of a published research article [ 20 ] . The original study [ 20 ] reports that hurricanes with female names have caused more deaths , presumably because female names are perceived as less threatening and lead to less prepara - tion . However , the conclusion led to a heated debate on proper ways to conduct the data analysis . To understand if the conclusion is robust to alternative speciﬁcations , Simonsohn et al . identiﬁed seven analytic decisions that appear reasonable , including alternative ways to exclude outliers , operationalize femininity , select the model type , and choose covariates . They then conducted a multiverse analysis and interpreted the results in a visualization called the speciﬁcation curve . We build the same multiverse using these seven analytic decisions in Boba . In the Boba DSL speciﬁcation , we use a decision block to specify two alternative model types : negative binomial regression versus linear regression with log - transformed deaths as the dependent variable . The rest of the analytic decisions are placeholder variables that can be expressed as straightforward value substitutions . However , the two different model types lead to further differences in extracting model estimates . For example , we must invert the log - transformation in the linear model to obtain predictions in the original units . We create additional placeholder variables for implementation differences related to model types and link them with the model decision block . The speciﬁcation compiles to 1 , 728 individual scripts . We then interpret the results using the Boba Visualizer . As shown in the overview distribution ( Fig . 10a ) , the majority of point estimates support a small , positive effect ( female hurricanes lead to more deaths , and the extra deaths are less than 20 ) , while some estimates suggest a larger effect . A small fraction of results have the opposite sign . What analytic decisions are responsible for the variations in the estimates ? The decision view indicates that multiple analytic decisions might be inﬂuential ( Fig . 10a ) . We click on the relatively sensitive decisions , outliers , damage and model , to examine their impact . In the corresponding univariate trellis plots ( supplemental Fig . 3 ) , certain choices tend to produce larger estimates , such as not excluding any outliers , using raw damage instead of log damage , and using negative binomial regression . However , in each of these conditions , a consider - able number of universes still support a smaller effect , suggesting that it is not a single analytic decision that leads to large estimates . Next , we click on two inﬂuential decisions to examine their in - teraction . In the trellis plot of model and damage ( Fig . 10b ) , one combination ( choosing both log damage and negative binomial model ) produces mostly varied estimates without a dominating peak next to zero . Brushing the large estimates in another combination ( raw damage and linear model ) indicates that these results are coming from speciﬁ - cations that additionally exclude no outliers . Removing these decision combinations will eliminate the possibility of obtaining a large effect . But do we have evidence that certain outcomes are less trustworthy ? We toggle the color - by drop - down menu so that each universe is colored by its model quality metric ( Fig . 10b ) . The large estimates are almost exclusively coming from models with a poor ﬁt . We further verify the model ﬁt quality by picking example universes and examining the model ﬁt view ( Fig . 10c ) . The visual predictive checks conﬁrm issues in model ﬁt , for example the models fail to generate predictions smaller than 3 deaths , while the observed data contains plenty such cases . Now that we have reasons to be skeptical of the large estimates , the remaining universes still support a small , positive effect . How reliable is the effect ? We proceed to the inference view to compare the possible outcomes in the observed multiverse and the expected distribution under the null hypothesis ( Fig . 10d ) . The two distributions are different in terms of mode and shape , yet they are highly overlapping , which suggests the effect is not reliable . The detail plot depicting individual universes ( supplemental Fig . 1 ) further conﬁrms this observation . Out of the entire multiverse , only 3 universes have point estimates outside the 2 . 5th and 97 . 5th percentile of the corresponding null distribution . 7 D ISCUSSION Through the process of designing , building , and using Boba , we gain insights into challenges that multiverse analysis poses for software designers and users . We now reﬂect on these challenges and additional design opportunities for supporting multiverse analysis . While Boba is intended to reduce the gulf of execution for multi - verse analysis , conducting a multiverse analysis still requires statistical expertise . Future work might attempt to represent expert statistical knowledge to lower the barriers for less experienced users . One strat - egy is to represent analysis goals in higher - level abstractions , from which appropriate analysis methods might be synthesized [ 19 ] . An - other is to guide less experienced users through key decision points and possible alternatives [ 27 ] , starting from an initial script . Running all scripts produced by Boba can be computationally expen - sive due to their sheer number . Boba already leverages parallelism , ex - ecuting universes across multiple processes . Still , scripts often perform redundant computation and the compiler may produce prohibitively many scripts . Future work should include optimizing multiverse exe - cution , for example caching shared computation across universes , or efﬁciently exploring decision spaces via adaptive sampling . As a new programming tool , Boba requires additional support to increase its usability , including code editor plugins , debugging tools , documentation , and community help . In this paper we assess the feasi - bility of Boba , with the understanding that these additional aspects will need to be subsequently addressed . Currently , as Boba speciﬁcations are compiled to individual scripts in a speciﬁc programming language , users can leverage existing debugging tools for the corresponding lan - guage to work with a single script . However , debugging analysis scripts becomes difﬁcult at the scale of a multiverse because a change that ﬁxes a bug in one script might not ﬁx bugs in others . When we attempt to run a multiverse of Bayesian regression models , for example , models in multiple universes do not converge for a variety of reasons including problems with identiﬁability and difﬁculties sampling parameter spaces with complex geometries . These issues are common in Bayesian modeling workﬂows and must be resolved by adjusting settings , changing priors , or reparameterizing models entirely . At the scale of multiverse analysis , debugging this kind of model ﬁt issue is particularly difﬁcult because existing tools for diagnostics and model checks ( e . g . , trace and pairs plots ) are designed to assess one model at a time . While this points to a need for better debugging and model diagnostic tools in general , it also suggests that these tools must be built with a multiplexing workﬂow in mind if they are going to facilitate multiverse analysis . Analysts must take care when reviewing and summarizing multiverse results , as a multiverse is not a set of randomly drawn , independent speciﬁcations . In general , the Boba Visualizer avoids techniques that assume universe results are independent and identically distributed ( IID ) . A possible venue for future work is to explicitly account for statistical dependence among universes to remove potential bias . Boba might also do more to aid the communication of results , for example helping to produce reports that communicate multiverse results [ 9 ] . Previous approaches to multiverse analysis have largely overlooked the quality of model ﬁt , focusing instead on how to enumerate analysis decisions and display the results from the entire multiverse . We visual - ize model ﬁt in two ways : we use color to encode the NRMSE from a k - fold cross validation in the outcome view , and use predictive checks to compare observed data with model predictions in the model ﬁt view . Together these views show that a cross - product of analytic decisions can produce many universes with poor model ﬁts , and many of the results that prior studies include in their overviews may not provide a sound base for subsequent inferences . The prevalence of ﬁt issues , which are immediately apparent in the Boba Visualizer , calls into ques - tion the idea that a multiverse analysis should consist of a cross - product of all a - priori “reasonable” decisions . We propose adding a step to the multiverse workﬂow where analysts must distinguish between what seems reasonable a - priori vs . post - hoc . Boba supports this step in two ways : in the inference view we can use model averaging to produce a weighted combination of universes based on model ﬁt , or we can simply omit universes below a certain model ﬁt threshold chosen by the users . The latter option relies on analysts making a post - hoc subjective decision and might be susceptible to p - hacking . However , one can pre - register a model quality threshold to eliminate this ﬂexibility . Should we enable more elaborate and interactive ways to give users control over pruning ? If so , how do we prevent analysts from unintentionally biasing the results ? These questions remain future work . Indeed , a core tension in multiverse analysis is balancing the im - perative of transparency with the need for principled reduction of uncertainty . Prior work on researcher degrees of freedom in analysis workﬂows [ 21 ] identiﬁes strategies that analysts use to make decisions ( see also [ 4 , 26 ] ) , including two which are relevant here : reducing uncertainty in the analysis process by following systematic procedures , and suppressing uncertainty by arbitrarily limiting the space of possible analysis paths . In the context of Boba , design choices which direct the user’s attention toward important information ( e . g . , highlighting models with good ﬁt and decisions with a large inﬂuence on outcomes ) and guide the user toward best practices ( e . g . , visual predictive checks ) serve to push the user toward reducing rather than suppressing uncer - tainty . Allowing users to interact with results as individual dots in the outcome view while showing aggregated uncertainty in the background reduces the amount of information that the user needs to engage with in order to begin exploring universes , while also maintaining a sense of the range of possible outcomes . We believe that guiding users’ attention and workﬂow based on statistical principles is critical . 8 C ONCLUSION This paper presents Boba , an integrated DSL and visual analysis system for authoring and interpreting multiverse analyses . With the DSL , users annotate their analysis script to insert local variations , from which the compiler synthesizes executable script variants corresponding to all possible analysis paths . We provide a command line tool for compiling the DSL speciﬁcation , running the generated scripts , and merging the outputs . We contribute a visual analysis system with linked views between analytic decisions and model estimates to facilitate systematic exploration of how decisions impact robustness , along with views for sampling uncertainty and model ﬁt . We also provide facilities for principled pruning of “unreasonable” speciﬁcations , and support inference to assess effect reliability . Using Boba , we replicate two existing multiverse studies , gain a rich understanding of how decisions affect results , and ﬁnd issues around uncertainty and model ﬁt that change what we can reasonably take away from these multiverses . Boba is available as open source software at ANONYMIZED - URL . A CKNOWLEDGMENTS We thank the anonymous reviewers , UW IDL members , Uri Simonsohn , Mike Merrill , Ge Zhang , Pierre Dragicevic , Yvonne Jansen , Matthew Kay , Brian Hall , Abhraneel Sarma , Fanny Chevalier , and Michael Moon for their help . This work was supported by NSF Award 1901386 . R EFERENCES [ 1 ] M . Baker . 1 , 500 scientists lift the lid on reproducibility . Nature , 533 ( 7604 ) : 452 – 454 , 2016 . doi : 10 . 1038 / 533452a [ 2 ] C . G . Begley and L . M . Ellis . Raise standards for preclinical cancer research . Nature , 483 ( 7391 ) : 531 – 533 , 2012 . doi : 10 . 1038 / 483531a [ 3 ] R . Border , E . C . Johnson , L . M . Evans , A . Smolen , N . Berley , P . F . Sullivan , and M . C . Keller . No support for historical candidate gene or candidate gene - by - interaction hypotheses for major depression across multiple large samples . American Journal of Psychiatry , 176 ( 5 ) : 376 – 387 , 2019 . doi : 10 . 1176 / appi . ajp . 2018 . 18070881 [ 4 ] N . Boukhelifa , M . - E . Perrin , S . Huron , and J . Eagan . How Data Workers Cope with Uncertainty : A Task Characterisation Study . Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 2017 . doi : 10 . 1145 / 3025453 . 3025738 [ 5 ] J . Cesario , D . J . Johnson , and W . Terrill . Is there evidence of racial disparity in police use of deadly force ? analyses of ofﬁcer - involved fatal shootings in 2015 – 2016 . Social psychological and personality science , 10 ( 5 ) : 586 – 595 , 2019 . doi : 10 . 1177 / 1948550618775108 [ 6 ] M . Cred´e and L . A . Phillips . Revisiting the power pose effect : How robust are the results reported by carney , cuddy , and yap ( 2010 ) to data analytic decisions ? Social Psychological and Personality Science , 8 ( 5 ) : 493 – 499 , 2017 . doi : 10 . 1177 / 1948550617714584 [ 7 ] E . Dejonckheere , E . K . Kalokerinos , B . Bastian , and P . Kuppens . Poor emotion regulation ability mediates the link between depressive symptoms and affective bipolarity . Cognition and Emotion , 33 ( 5 ) : 1076 – 1083 , 2019 . doi : 10 . 1080 / 02699931 . 2018 . 1524747 [ 8 ] E . Dejonckheere , M . Mestdagh , M . Houben , Y . Erbas , M . Pe , P . Koval , A . Brose , B . Bastian , and P . Kuppens . The bipolarity of affect and depres - sive symptoms . Journal of personality and social psychology , 114 ( 2 ) : 323 , 2018 . doi : 10 . 1037 / pspp0000186 [ 9 ] P . Dragicevic , Y . Jansen , A . Sarma , M . Kay , and F . Chevalier . Increasing the transparency of research papers with explorable multiverse analyses . In Proc . ACM Human Factors in Computing Systems , pp . 65 : 1 – 65 : 15 , 2019 . doi : 10 . 1145 / 3290605 . 3300295 [ 10 ] J . Gassen . A package to explore and document your degrees of freedom . https : / / github . com / joachim - gassen / rdfanalysis , 2019 . [ 11 ] A . Gelman . A Bayesian Formulation of Exploratory Data Analysis and Goodness - of - Fit Testing . International Statistical Review , 2003 . [ 12 ] A . Gelman , J . Hwang , and A . Vehtari . Understanding predictive informa - tion criteria for Bayesian models . Statistics and Computing , 24 ( 6 ) : 997 – 1016 , 2014 . doi : 10 . 1007 / s11222 - 013 - 9416 - 2 [ 13 ] A . Gelman and E . Loken . The garden of forking paths : Why multiple comparisons can be a problem , even when there is no ﬁshing expedi - tion or p - hacking and the research hypothesis was posited ahead of time . Department of Statistics , Columbia University , 2013 . [ 14 ] A . Gelman and E . Loken . The statistical crisis in science . American Scientist , 102 ( 6 ) : 460 , 2014 . doi : 10 . 1511 / 2014 . 111 . 460 [ 15 ] P . J . Guo . Software tools to facilitate research programming . PhD thesis , Stanford University , 2012 . [ 16 ] B . Hartmann , L . Yu , A . Allison , Y . Yang , and S . R . Klemmer . Design as exploration : Creating interface alternatives through parallel authoring and runtime tuning . In Proc . ACM User Interface Software and Technology , pp . 91 – 100 , 2008 . doi : 10 . 1145 / 1449715 . 1449732 [ 17 ] J . Hoffswell , W . Li , and Z . Liu . Techniques for ﬂexible responsive visual - ization design . In Proc . ACM Human Factors in Computing Systems , pp . 1 – 1 , 2020 . doi : 10 . 1145 / 3313831 . 3376777 [ 18 ] Z . Jelveh , B . Kogut , and S . Naidu . Political language in economics . Columbia Business School Research Paper , ( 14 - 57 ) , 2018 . doi : 10 . 2139 / ssrn . 2535453 [ 19 ] E . Jun , M . Daum , J . Roesch , S . E . Chasins , E . D . Berger , R . Just , and K . Reinecke . Tea : A high - level language and runtime system for automat - ing statistical analysis . CoRR , abs / 1904 . 05387 , 2019 . [ 20 ] K . Jung , S . Shavitt , M . Viswanathan , and J . M . Hilbe . Female hurricanes are deadlier than male hurricanes . Proceedings of the National Academy of Sciences , 111 ( 24 ) : 8782 – 8787 , 2014 . doi : 10 . 1073 / pnas . 1402786111 [ 21 ] A . Kale , M . Kay , and J . Hullman . Decision - making under uncertainty in research synthesis : Designing for the garden of forking paths . In Proc . ACM Human Factors in Computing Systems , pp . 202 : 1 – 202 : 14 , 2019 . doi : 10 . 1145 / 3290605 . 3300432 [ 22 ] M . Kay , G . L . Nelson , and E . B . Hekler . Researcher - centered design of statistics : Why bayesian statistics better ﬁt the culture and incentives of HCI . In Proc . ACM Human Factors in Computing Systems , pp . 4521 – 4532 , 2016 . doi : 10 . 1145 / 2858036 . 2858465 [ 23 ] M . B . Kery , A . Horvath , and B . Myers . Variolite : Supporting exploratory programming by data scientists . In Proc . ACM Human Factors in Comput - ing Systems , pp . 1265 – 1276 , 2017 . doi : 10 . 1145 / 3025453 . 3025626 [ 24 ] M . B . Kery and B . A . Myers . Interactions for untangling messy his - tory in a computational notebook . In 2018 IEEE Symposium on Visual Languages and Human - Centric Computing , pp . 147 – 155 , 2018 . doi : 10 . 1109 / VLHCC . 2018 . 8506576 [ 25 ] Q . Li , M . R . Morris , A . Fourney , K . Larson , and K . Reinecke . The impact of web browser reader views on reading speed and user experience . In Proc . ACM Human Factors in Computing Systems , pp . 524 : 1 – 524 : 12 , 2019 . doi : 10 . 1145 / 3290605 . 3300754 [ 26 ] R . Lipshitz and O . Strauss . Coping with Uncertainty : A Naturalistic Decision - Making Analysis . Organizational Behavior and Human Decision Processes , 69 ( 2 ) : 149 – 163 , 1997 . doi : 10 . 1006 / obhd . 1997 . 2679 [ 27 ] Y . Liu , T . Althoff , and J . Heer . Paths explored , paths omitted , paths obscured : Decision points & selective reporting in end - to - end data analysis . In Proc . ACM Human Factors in Computing Systems , pp . 406 : 1 – 406 : 14 , 2020 . doi : 10 . 1145 / 3313831 . 3376533 [ 28 ] A . Lunzer . Towards the subjunctive interface : General support for pa - rameter exploration by overlaying alternative application states . In Late Breaking Hot Topics , IEEE Visualization , vol . 98 , pp . 45 – 48 , 1998 . [ 29 ] A . Lunzer . Choice and comparison where the user wants them : Subjunc - tive interfaces for computer - supported exploration . In Proceedings of INTERACT , pp . 474 – 482 , 1999 . [ 30 ] L . D . Nelson , J . Simmons , and U . Simonsohn . Psychology’s renaissance . Annual Review of Psychology , 69 ( 1 ) : 511 – 534 , 2018 . doi : 10 . 1146 / annurev - psych - 122216 - 011836 [ 31 ] Open Science Collaboration . Estimating the reproducibility of psycholog - ical science . Science , 349 ( 6251 ) , 2015 . doi : 10 . 1126 / science . aac4716 [ 32 ] A . Orben and A . K . Przybylski . The association between adolescent well - being and digital technology use . Nature Human Behaviour , 3 ( 2 ) : 173 , 2019 . [ 33 ] C . J . Patel , B . Burford , and J . P . A . Ioannidis . Assessment of vibration of effects due to model speciﬁcation can demonstrate the instability of observational associations . Journal of Clinical Epidemiology , 68 ( 9 ) : 1046 – 1058 , 2015 . doi : 10 . 1016 / j . jclinepi . 2015 . 05 . 029 [ 34 ] C . Pettitt . Dagre . https : / / github . com / dagrejs / dagre , 2015 . [ 35 ] G . J . Poarch , J . Vanhove , and R . Berthele . The effect of bidialectalism on executive function . International Journal of Bilingualism , 23 ( 2 ) : 612 – 628 , 2019 . doi : 10 . 1177 / 1367006918763132 [ 36 ] F . Prinz , T . Schlange , and K . Asadullah . Believe it or not : How much can we rely on published data on potential drug targets ? Nature Reviews Drug Discovery , 10 ( 9 ) : 712 , 2011 . doi : 10 . 1038 / nrd3439 - c1 [ 37 ] J . R . Rae , S . G¨ulg¨oz , L . Durwood , M . DeMeules , R . Lowe , G . Lindquist , and K . R . Olson . Predicting early - childhood gender transitions . Psycho - logical Science , 2019 . doi : 10 . 1177 / 0956797619830649 [ 38 ] J . M . Rohrer , B . Egloff , and S . C . Schmukle . Probing birth - order effects on narrow traits using speciﬁcation - curve analysis . Psychological Science , 28 ( 12 ) : 1821 – 1832 , 2017 . [ 39 ] M . Rubin . Do p values lose their meaning in exploratory analyses ? it depends how you deﬁne the familywise error rate . Review of General Psychology , 21 ( 3 ) : 269 – 275 , 2017 . doi : 10 . 1037 / gpr0000123 [ 40 ] A . Rule , A . Tabard , and J . D . Hollan . Exploration and explanation in computational notebooks . In Proc . ACM Human Factors in Computing Systems , p . 32 , 2018 . doi : 10 . 1145 / 3173574 . 3173606 [ 41 ] R . Silberzahn , E . L . Uhlmann , D . Martin , P . Anselmi , F . Aust , E . C . Awtrey , tpn Bahnk , F . Bai , C . Bannard , E . Bonnier , R . Carlsson , F . Che - ung , G . Christensen , R . Clay , M . A . Craig , A . D . Rosa , L . Dam , M . H . Evans , I . F . Cervantes , N . Fong , M . Gamez - Djokic , A . Glenz , S . Gordon - McKeon , T . J . Heaton , K . Hederos , M . Heene , A . J . H . Mohr , F . Hgden , K . Hui , M . Johannesson , J . Kalodimos , E . Kaszubowski , D . M . Kennedy , R . Lei , T . A . Lindsay , S . Liverani , C . R . Madan , D . Molden , E . Molleman , R . D . Morey , L . B . Mulder , B . R . Nijstad , N . G . Pope , B . Pope , J . M . Pren - oveau , F . Rink , E . Robusto , H . Roderique , A . Sandberg , E . Schlter , F . D . Schnbrodt , M . F . Sherman , S . A . Sommer , K . Sotak , S . Spain , C . Sprlein , T . Stafford , L . Stefanutti , S . Tauber , J . Ullrich , M . Vianello , E . - J . Wagen - makers , M . Witkowiak , S . Yoon , and B . A . Nosek . Many analysts , one data set : Making transparent how variations in analytic choices affect results . Advances in Methods and Practices in Psychological Science , 1 ( 3 ) : 337 – 356 , 2018 . doi : 10 . 1177 / 2515245917747646 [ 42 ] J . P . Simmons , L . D . Nelson , and U . Simonsohn . False - positive psy - chology : Undisclosed ﬂexibility in data collection and analysis allows presenting anything as signiﬁcant . Psychological Science , 22 ( 11 ) : 1359 – 1366 , 2011 . doi : 10 . 1177 / 0956797611417632 [ 43 ] U . Simonsohn , J . P . Simmons , and L . D . Nelson . Speciﬁcation curve : Descriptive and inferential statistics on all reasonable speciﬁcations . Avail - able at SSRN 2694998 , 2015 . doi : 10 . 2139 / ssrn . 2694998 [ 44 ] S . Steegen , F . Tuerlinckx , A . Gelman , and W . Vanpaemel . Increasing transparency through a multiverse analysis . Perspectives on Psychological Science , 11 ( 5 ) : 702 – 712 , 2016 . doi : 10 . 1177 / 1745691616658637 [ 45 ] K . Sugiyama , S . Tagawa , and M . Toda . Methods for visual understanding of hierarchical system structures . IEEE Transactions on Systems , Man , and Cybernetics , 11 ( 2 ) : 109 – 125 , 1981 . doi : 10 . 1109 / TSMC . 1981 . 4308636 [ 46 ] M . Terry , E . D . Mynatt , K . Nakakoji , and Y . Yamamoto . Variation in element and action : Supporting simultaneous development of alternative solutions . In Proc . ACM Human Factors in Computing Systems , pp . 711 – 718 , 2004 . doi : 10 . 1145 / 985692 . 985782 [ 47 ] A . Vehtari , A . Gelman , and J . Gabry . Practical Bayesian model evalua - tion using leave - one - out cross - validation and Estimating out - of - sample pointwise predictive accuracy using posterior simulations . J Stat Comput , 27 ( 5 ) : 1413 – 1432 , 2017 . doi : 10 . 1007 / s11222 - 016 - 9696 - 4 [ 48 ] J . M . Wicherts , C . L . S . Veldkamp , H . E . M . Augusteijn , M . Bakker , R . C . M . van Aert , and M . A . L . M . van Assen . Degrees of freedom in planning , running , analyzing , and reporting psychological studies : A checklist to avoid p - hacking . Frontiers in Psychology , 7 : 1832 , 2016 . doi : 10 . 3389 / fpsyg . 2016 . 01832 [ 49 ] L . Wilkinson . Dot plots . The American Statistician , 53 ( 3 ) : 276 – 281 , 1999 . [ 50 ] Y . Yao , A . Vehtari , D . Simpson , and A . Gelman . Using stacking to average bayesian predictive distributions ( with discussion ) . Bayesian Analysis , 13 ( 3 ) : 917 – 1007 , 2018 . doi : 10 . 1214 / 17 - BA1091 [ 51 ] C . Young and K . Holsteen . Model uncertainty and robustness : A com - putational framework for multimodel analysis . Sociological Methods & Research , 46 ( 1 ) : 3 – 40 , 2017 . doi : 10 . 1177 / 0049124115610347 [ 52 ] E . Zgraggen , Z . Zhao , R . Zeleznik , and T . Kraska . Investigating the effect of the multiple comparisons problem in visual analysis . In Proc . ACM Human Factors in Computing Systems , pp . 479 : 1 – 479 : 12 , 2018 . doi : 10 . 1145 / 3173574 . 3174053