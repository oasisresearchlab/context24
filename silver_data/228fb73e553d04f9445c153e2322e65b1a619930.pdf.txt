Share Once or Share Often ? Exploring How Designers Approach Iteration in a Large Online Community Patrick A . Crain and Brian P . Bailey Department of Computer Science University of Illinois , Urbana , IL { pcrain2 , bpbailey } @ illinois . edu ABSTRACT Iteration prompted by feedback is fundamental to creative design . Designers often use online communities to gather feedback , but there is little knowledge of how designers use these communities to iterate on their work . We studied iterative design practice in three active forums that target novice design critique in a popular online community . We collected a large corpus of projects ( n = 3 , 730 ) and comments ( n = 29 , 412 ) . The data was analyzed to determine how often designers iterate on their projects , and which characteristics of the feedback correlate with iteration . Two surveys ( n = 38 ) were conducted to further learn how often and at which design stages designers post their work to the community . Our results showed that more and longer comments , comments with less positive tone and comments with more thought - provoking statements correlated with iteration . Our analysis also showed that two or more iterations were shared for only 21 % of the projects . The survey results explained that the rate of iteration was due in part to designers sharing their projects with the community near the end of their design process . Our findings also suggest how online communities can better support iterative design practice . Author Keywords Design ; critique ; feedback ; iteration ; online communities . ACM Classification Keywords H . 5 . 3 [ Information Interface and Presentation ] : Group and Organization Interfaces – Evaluation / methodology . INTRODUCTION Iteration is essential for producing creative solutions and gaining confidence in one’s creative ability [ 10 , 13 ] . Through iteration , designers learn to perform a series of content revisions prompted by feedback from an external audience [ 29 ] . The feedback enables the designer to “see” problems with their proposed solution , learn about the design problem , and gain insight for improving the work [ 33 ] . Although seasoned designers often have the skills and the resources necessary to iterate effectively , many designers do not , and face the challenge of receiving timely , helpful feedback [ 16 ] . For designers with limited resources , particularly novices , online design communities can serve as a source of feedback and creative inspiration for their projects [ 39 ] . Participation generally does not require financial resources or social capital , and often requires only creating an account . These communities allow designers to connect online with diverse feedback providers who are motivated by a mutual interest in design or the topic of the projects . Even experienced designers can benefit from online communities , as they enable them to showcase and promote their work , learn about modern design trends , and refine their creative skills [ 27 ] . Although researchers have studied feedback generation in online design communities [ 27 , 39 ] , there are still important open questions regarding how the feedback requests are integrated into iterative design practice . For instance , when and how often do designers iterate on their projects using the feedback received from an online community , what characteristics of the feedback impact iteration , and to what degree do the projects improve ? We report results from a mixed - methods study of how designers approach iteration in three graphic design critique forums in Reddit ( see Figure 1 ) . We chose Reddit because it contains some of the largest and most active public forums for design critique . We collected a large corpus of design projects ( 3 , 730 ) and critique comments ( 29 , 412 ) , and applied heuristics to determine when designers posted iterations for their projects . These heuristics were developed by observing common practices for how iterations were represented within the community . We measured how often designers iterated on their posted projects , and statistically modeled which characteristics of the feedback received ( e . g . , the length and number of responses , the valence of each response , and the categories of critique discourse referenced in the responses ) correlated with subsequent design iteration . The quantitative measures were complemented by a structured ( N = 21 ) and an open - ended ( N = 17 ) survey posted to the community . The surveys inquired about participants ' motivations for and experiences with receiving feedback from the community into their design process , and asked participants to quantify and describe their iterative process . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from Permissions @ acm . org . C & C ' 17 , June 27 - 30 , 2017 , Singapore , Singapore © 2017 ACM . ISBN 978 - 1 - 4503 - 4403 - 6 / 17 / 06… $ 15 . 00 DOI : http : / / dx . doi . org / 10 . 1145 / 3059454 . 3059476 Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 80 Figure 1 : An example of a graphic design project posted by a user to / r / design _ critiques on Reddit for feedback . The design image linked in the original post was placed in the figure for the purpose of explanation . Our study contributes three findings . First , we found that more and longer comments , comments with fewer positive statements , and comments that contained more thought - provoking statements were all predictive of iteration . This indicates that the type of feedback received online affects how often designers share iterations of their work . Second , we found that only a single design was posted for feedback for 79 % of the projects in our data set , while two or more iterations were posted for the remaining 21 % . The survey results indicated that designers were approaching the community near the end of their process , leaving less time and possibly less desire to continue iterating on their work . Finally , we found that designers posted their projects in the community with the expectation that they would receive quick , high quality feedback from a large , diverse audience . This extends findings from a prior study of professional development in an invitation - only design community [ 27 ] to an open community that targets novice design critique . Our work makes two contributions to the creativity and cognition community . First , our results contribute deeper empirical understanding of the characteristics of feedback received online that relate to design iteration and how designers incorporate the use of online communities into their creative projects . Second , our findings can inform how online communities and crowd - based design services ( e . g . , [ 16 , 40 ] ) can better represent projects and generate the types of feedback that promote iteration . We believe these contributions will enable online communities to serve as more effective resources for creative design projects . RELATED WORK We situate our contribution in the context of prior studies of online design communities . We then describe the benefits of online communities relative to other sources for design feedback , and the benefits of iteration for creative design . Studies of Online Design Communities Researchers have examined online design communities from many perspectives . For example , Xu & Bailey investigated the expectations and motivations of users participating in an online critique community in digital photography [ 39 ] . They found that designers ' participation in a community could enhance the perception of their work , provided they received feedback of sufficient quality and quantity . They also found that designers often approached online communities with the goal of obtaining quick feedback from members with comparable or greater design experience . Marlow & Dabbish studied a graphic design community of practice [ 27 ] . They found that designers derived professional benefit from sharing and promoting their work , and were able to improve their creative skills by reviewing and mirroring the practices found in the design work showcased by others . They also found that designers , especially novices , valued the work - in - progress section of the site to receive quick feedback on their work . Other research has leveraged online communities to trace the effects of analogies on design innovations [ 5 ] . Our study differs from this corpus of prior work because it analyzes online communities from a unique perspective – iterative design practice . We analyze how often designers iterate and how they represent iterations in an archetypal online discussion forum . Our work also follows a long thread of research that leverages attributes of content and behavior to model variables of interest in online communities ( e . g . [ 1 , 3 , 15 , 17 , 18 , 20 , 26 , 28 , 30 , 35 , 43 ] ) . The unique aspect of our modeling is testing how the attributes of the feedback content and commenting behavior relate to design iteration . Our work analyzes Reddit as a platform for design iteration and critique . Given the “community of communities” aspect of Reddit , researchers have studied user behavior on the site , its social interaction mechanisms , and discussions around Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 81 different topics . For instance , one study found that new users participate in a wide range of sub - Reddits before settling on a few to regularly visit [ 36 ] . Gilbert studied how Reddit ' s voting infrastructure leads to under - provisioning for its most popular content [ 14 ] , while Kim et al . examined discussions pertaining to the credibility of medical crowdfunding [ 21 ] . Our study analyzes Reddit as a resource for designers to receive feedback in the context of iterative design . Online Sources of Design Feedback In addition to online communities , researchers have explored mechanisms to help designers gather feedback using social media and paid crowdsourcing platforms [ 9 , 16 , 24 , 32 ] . For example , Xu et al . showed how to leverage paid task markets to gather five categories of perceptual feedback for graphic designs [ 40 , 41 ] , while Hui et al . showed how to leverage students’ collective social networks to more evenly distribute the volume of feedback received in design courses [ 19 ] . The drawback of these methods is that they still require payment or social capital to collect feedback [ 9 , 16 , 24 , 32 ] , and the cost accumulates when iterating on a project . The advantage of online communities is that they allow designers to connect with feedback providers who are motivated by a common interest in design or the topic of their project . In a comparison of design feedback from online sources , Yen et al . showed that the number of responses received from online communities is similar to that obtained from social media , and that the perceived quality of the feedback is as good as that collected from social media and paid task markets [ 42 ] . Our work extends studies of how designers approach online sources for feedback ( e . g . [ 27 , 39 ] ) by focusing on the design iterations that prompted the feedback collection . The results of our analysis can illuminate potential improvements not only for online communities , but also for the emerging class of crowd services that generate design feedback [ 25 , 40 ] . Iteration in Design Iterative design refers to revising the content of a design in response to external feedback . At each iteration , designers seek feedback to discover gaps in understanding and usability , and to identify potential improvements . Iterations are rapid at first , and slow as the design solidifies [ 29 ] . Through this process , the designer moves the design closer to satisfying its goals and gains insight into the design problem and solution approach [ 6 ] . Iteration need not imply “incremental” as it can also inspire new design directions through the meta - cognitive process of reflection [ 33 ] . Iteration is foundational to design [ 4 ] , and has been empirically shown to lead to more effective design solutions [ 11 ] . While iterative design is widely taught , studied , and evangelized , our research is distinct because it investigates how designers naturally approach iteration in the context of an online design community . RESEARCH QUESTIONS Our study was designed to answer the following questions : RQ1 : How many iterations on a design project does a designer typically post to an online community for feedback ? RQ2 : When a designer posts a revised design , how deep are the changes , and does the quality of the design improve ? RQ3 : What characteristics of the feedback ( e . g . valence , category of discourse , or total comments ) correlate with the decision to post subsequent design iterations ? RQ4 : When in the design process does a designer typically share a design with an online community ? RQ5 : What are the perceived strengths and weaknesses of iterating with the feedback received from an online design community ( compared to other sources ) ? Though not exhaustive , we posed these questions to learn about how designers approach online communities for feedback , to measure potential benefits of online iteration , and gain insight into how online communities could further improve feedback exchange and iterative design practices . METHOD A mixed - methods study was conducted to answer our research questions . The first three questions were answered by analyzing a data set collected from an online community that targets novice designers ( but open to designers at all skill levels ) . The community was therefore especially interesting because novices may not be as aware of the need to iterate as more experienced designers . The final two questions were answered by posting two surveys to the community . Online Community Studied We collected designs and the associated feedback from Reddit ( http : / / reddit . com ) . Launched in 2005 , Reddit is a publicly accessible platform for discussing items of interest . The site originally targeted news , but has grown to include a variety of topics , including design . Topics are organized into sub - Reddits , and each sub - Reddit lists discussion threads ordered by a combination of popularity and creation time . We chose Reddit because it has an active , large , and diverse user base engaged in design feedback exchange and , unlike other design communities [ 27 , 39 ] , participation does not require invitations , portfolios , status , or payment . Most designs posted to the sub - Reddits studied are visual designs , including graphic , web , and interaction designs . Examples include personal websites and logos , portfolios , T - shirt designs , business cards ( self - employed ) , and non - commercial apps . From our own inspection , these projects generally arise from designers pursuing their own interests , learning goals , or job responsibilities . From the descriptions in the initial posts , the focus was typically on producing design solutions rather than solely learning about the design process or strategy ; e . g . , typical project posts include : " Any help is appreciated ! Just starting up so we don ' t have that many products yet . What do you think of the logo ? Would it be better bigger and without the palm tree ? ” Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 82 " Hi guys , here is my draft for a poster advertising a show I ' ll be playing later this year . I would like the poster to be a combination of professional and trendy , and appeal to a diverse audience . " Although the sub - Reddits we studied were open to designers of all skill levels , their target audience was novice designers . For example , the most active sub - Reddit we studied , / r / design _ critiques , states its purpose is to “ Help new and amateur designers improve their designs . ” On Reddit , a designer initiates discussion around her design by creating a thread in the desired sub - Reddit . The initial post typically contains a title , and description of the design and goals of the project . It may also include links to external images or to a live Web site . Community members can then comment on the design and reply to each other through a discussion interface . Fresh designs typically receive fast attention but fade as the display algorithm places new posts at the top of the thread list , as also observed in [ 2 , 14 , 22 ] . To post a revised design , the designer can create a new thread with a link to the revised design ( and the prior thread if desired ) , edit the original post with a link pointing to the revised design , or post a new comment in the original design’s thread with a link to the revised design . The last option is most common , as it is more noticeable than an edit and , unlike a new thread , it preserves the feedback history . Design + Feedback Data Collection ( RQ 1 - 3 ) We developed a script using the Python Reddit API Wrapper ( PRAW ) . The script crawled three popular sub - Reddits for design critique : / r / design _ critiques , / r / Logo _ Critique , and / r / logodesign . These sub - Reddits were chosen due to their similar purpose for visual design critique , target audiences , and norms . The script collected data for two one - month periods ( separated by six months ) . The script downloaded the 1000 most recent threads in each of these sub - Reddits , including the design images , comments , timestamps , and user ids . This was the maximum data allowed by the API . For the initial post and any subsequent comments by the designer in the thread , the script parsed the content for Web links . If found , the script downloaded the linked images or , if it pointed to a live Web site , rendered the linked page and captured it . These images were the designs in our data set . It was rare for designers to request feedback without linking to a design image , or to link to content that were not designs . A challenge was detecting when designers posted revisions of their projects . By observing common practices on the site , we developed three heuristics : 1 ) the designer who created a thread replied with a comment containing an image link ; 2 ) the designer edited the link in her original post ; or 3 ) the designer created a thread that contained a link to an image and a link to a prior thread created by the same designer . Links to live sites were also challenging because the designer could update the site without editing the link . To detect this case , our script compared the rendered image of the page to the last capture for the link , if it existed . The comparison was performed using a well - known algorithm ( MD5 checksum ) . If different , the image was categorized as a design iteration . Iterations were only detected within sub - Reddits because we observed that iterations were rarely split between them . The timestamp of a comment was used to associate it with a corresponding design iteration , which was the last design iteration detected prior to that timestamp . We inspected samples of the data to confirm the design iterations and that comments were being associated with the correct iteration . Based on our observations , if a designer posted more than one iteration , it unfolded within a short window ( e . g . a few days ) . A month of data collection should therefore capture most of the iterations on a project shared to Reddit . However , it misses iterations that only partially overlapped the edges of data collection , as well as any iterations not shared within the community ; we revisit the latter point in the Discussion . RESULTS Tables 1 and 2 summarize our data set . The data contained a total of 3 , 730 projects from 2 , 866 designers , and 29 , 412 comments on those projects ( 7 , 855 comments came from the designers , not including the initial posts ) . A design received about six comments on average , which is more than other studies of design critique communities have reported [ 39 ] . The average number of comments per design iteration was largest for / r / logodesign ( μ = 9 . 2 , σ = 14 . 9 ) , and least for / r / design _ critiques ( μ = 3 . 9 , σ = 3 . 5 ) , with / r / Logo _ Critique in - between ( μ = 4 . 7 , σ = 3 . 7 ) . The complete set of comments received by a design were , on average , received within 24 hours of the initial post . The summary data shows that the designer and community often engage in back - and - forth discussion , reminiscent of face - to - face critique [ 31 ] . Iteration Analysis ( RQ1 ) Table 1 shows the distribution of how many projects share different numbers of design iterations for feedback . For instance , the No Iteration column shows the number of projects for which the designer posted only a single design for feedback and did not return , the 2 Iterations column reports the number of projects for which the initial design and one revision were posted , and so on . We ran a script to count the total number of projects in each group to determine how often designers iterate . Despite the widely - evangelized benefits of iteration [ 5 , 11 , 12 , 29 , 41 ] , of the 3730 projects analyzed , only about 1 in 5 ( 20 . 6 % ) posted more than one iteration , and only about 1 in 23 ( 4 . 3 % ) of the Sub - reddit Projects No it . 2 it . 3 it . 4 it . 5 + it . / r / design _ critiques 1485 1238 196 42 6 3 / r / logodesign 1173 893 226 36 11 7 / r / Logo _ Critique 1072 832 186 36 13 5 Total 3730 2963 608 114 30 15 Table 1 : The number of projects collected for each sub - Reddit in our data set . The subsequent columns show the number of iterations shared for each . As shown in the No Iteration ( it . ) column , only one design was posted for 79 % of the projects . Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 83 projects received three or more iterations ; these rates were similar across all three individual sub - Reddits . We also analyzed how designers approached iteration based on the three heuristics identified in the Method section . We found that designers performed 863 ( ~ 85 % ) iterations by replying to their original threads , 139 ( ~ 14 % ) by editing their original threads , and only 15 ( ~ 1 % ) by creating an entirely new thread for their revised designs . Some possible explanations for the observed rate of iteration are that the designers who approach this community for feedback are unaware of the benefits of iteration , that they are approaching it too late in their design process , that the platform does not encourage iteration , or that the content of the design feedback received may not prompt iteration . Our later analysis will examine which , if any , characteristics of the feedback correlate with posting two or more iterations . We also return to this issue in the Discussion . Perceived Quality and Iteration ( RQ2 ) To determine if designs improved when iterating based on community feedback , we separated the projects with only one iteration from those with two or more iterations . We then randomly sampled 300 of the projects with two or more iterations , and filtered out the ones lacking either a description of the designer ' s goals or community feedback , leaving 102 designs . We felt this data set was sufficient to produce representative results . For each project , we selected a design image from the initial shared design and the final shared revision . If a designer posted multiple images for the first design or final iteration ( a rare occurrence ) , we selected the one that we felt best represented the designs at that stage . For each design , we recruited participants to judge the quality of the designs relative to the designer’s stated goals . The judging consisted of three categories of rating tasks :  Rate how well a single design satisfied the designer ' s goals on a 7 - point scale ( 1 = does not satisfy , 7 = satisfies the goals ) . The goals were extracted from the designers’ original post and displayed at the top of the task screen . The design image was shown below . The initial design and final iteration were rated as separate tasks .  Rate the degree of difference between the two design images on a 7 - point scale ( 1 = the same , 7 = completely different ) and list the key differences between them ( see Figure 2 ) . The designs were shown side - by - side on a single task screen , with the placement randomized .  Select which of the two design iterations better satisfied the designer’s goals . The two design images were placed side - by - side , with random placement . The goals were shown at the top of the task screen with the images below . We piloted and revised the task screens to give simple , clear instructions to maximize response quality . We recruited participants from Mechanical Turk . Three participants were recruited per instance of the first task category , and five were recruited per instance of the other two categories . The task configurations limited recruitment to the U . S . to reduce language barriers , and required 95 % prior approval ratings to recruit workers with a history of quality work . Participants were remunerated $ 0 . 60 per task for the first category and $ 0 . 10 per task for the other two categories . We also recruited an independent rater to perform the AB - comparison task using an interface similar to that used on Mechanical Turk . The rater had several years of professional employment and education in industrial design , and ostensibly had much more design experience than the Turk participants . From the results of the first task , we used the mean of the ratings for each design to indicate its perceived quality . Sub - reddit Total Comments By the designer By the members Avg . ( sd ) per project / r / design _ critiques 8502 2769 5733 3 . 9 ( 3 . 5 ) / r / logodesign 13787 2987 10800 9 . 2 ( 14 . 1 ) / r / Logo _ Critique 7123 2099 5024 4 . 7 ( 3 . 7 ) Total 29412 7855 21557 5 . 9 ( 7 . 1 ) Table 2 : The total number of comments collected from the sub - Reddits , by the designers and community members . Despite high variance , nearly all designs received feedback . Slight revision ( rating = 2 ) Significant revision ( rating = 6 ) Figure 2 : Examples of the first and final iterations for two projects with slight ( left column ) and significant ( right column ) perceived revision between the iterations . Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 84 Surprisingly , the means were the same for both the initial design ( u = 4 . 773 , σ = 0 . 863 ) and the final iteration ( u = 4 . 775 , σ = 0 . 981 ) . A paired samples t - test confirmed that there was no difference between the two . From the second task , the mean difference for the pairs of designs was ( u = 3 . 96 , σ = 1 . 62 ) . A Kruskal - Wallis test showed no correlation between the degree of change between iterations and the change in perceived quality . Combined with the prior result , this analysis shows that designers were making revisions , yet the perceived quality did not improve . For the third ( AB comparison ) task , we tallied the number of times each iteration was selected as better satisfying the designers ' stated goals . The votes were nearly equally split between the initial designs ( n = 247 ) and final iterations ( n = 263 ) . A chi square test confirmed there was no preference between the iterations ( χ 2 ( 1 ) = 0 . 50 , p = 0 . 479 ) . The lack of increase in perceived quality between the initial design and final iteration might be due to the quality of the feedback being insufficient to make substantial improvements , or to the designers’ inability to interpret and apply the feedback . We analyzed the ratings from the independent rater for our AB task , and found that the final iteration ( n = 68 ) was selected over twice as often as the initial iteration ( n = 30 ) , with 4 selected as being the same ( χ 2 ( 1 ) = 14 . 74 , p < 0 . 001 ) . The fact that the independent rater detected a difference but the Turk participants did not might be due to the need for expertise to discriminate differences in quality [ 34 ] . As an additional check to ensure that the ratings from the MTurk participants were reliable , we eliminated responses from raters who spent fewer than 25 seconds ( < 25 % of the average time ) on the tasks . Analysis of the ratings from the remaining raters also failed to detect statistical differences . Predictors of Iteration ( RQ3 ) We examined how the number and length of responses , idea units , valence , and content categories of the feedback correlated with the decision to iterate on the design . From our original data set , we randomly sampled 100 projects containing only one iteration and 100 projects containing two or more iterations , filtering out all projects that did not have comments ( excluding comments from the project creators themselves ) . This left 86 projects with only one iteration and 97 projects with two or more iterations for analysis . We had a single coder partition each comment from the projects into individual idea units . An “idea unit” is defined as a coherent unit of thought consisting of a phrase , sentence , or group of sentences . Given the scale of the data set , we divided the idea units ( n = 2 , 416 ) among a team of four coders ( including a member of the research team ) . All coders had experience with design critique and similar labeling tasks . We had our coders categorize the valence of each idea unit . Valences were either " positive " ( positive comments encouraging or praising the design or designer ) , " critical " ( destructive criticism towards the design or designer ) , " neutral " ( comments that were neither positive nor critical , including most constructive criticism ) , or " indeterminate . " Category Description Example Idea Unit No it . 2 + its . Brainstorming Feedback asking ( often rhetorical ) questions or making statements about imagined possibilities for the design . Would you consider the neck of it a bit — even if it ' d be inaccurate — to make it take up a bit less space ? 5 . 3 % 4 . 1 % Comparison Feedback contrasting the design or design process with something else as comparison . The second one is a little too internet - explorer reminiscent for me 2 . 8 % 4 . 5 % Direct recommend . Feedback giving specific advice about a particular aspect of a design as a direct recommendation . I would go all the way back to square 1 and work with letterforms . 25 . 7 % 21 . 7 % Free association Feedback that makes reactive , associative statements about the design as free association . I also like the fact that it looks like a lightbulb , as that is a pretty universal symbol of " eureka ! " 3 . 2 % 4 . 5 % Identity - invoking Feedback pushing designers to consider themselves within the larger context of the design profession . So , yes , it does show that you ' re a beginner . That just means you have room to improve ! 1 . 8 % 2 . 5 % Interpretation Feedback where someone reacts to what they saw and tries to make sense of the concept or product . The first thing I see at a glance is mountains . Lots of mountains . Could be ski shop . 7 . 1 % 6 . 5 % Investigation Feedback that requests information ( typically by questioning ) about the design or the design process as investigation . Have you researched other ramen restaurants logos ? 4 . 8 % 7 . 5 % Judgment Feedback that is evaluative in tone and which often includes some form of interpretation while also conveying an assessment of the design . The lines are very thin as well , but that is irrelevant as the design is just not good . Thickening the lines will not help . 40 . 4 % 34 . 4 % Process - oriented Feedback providing designers with insight or observations about the process that they might have used or could use to create the design . Since it ' s a restaurant i would strongly consider how the logo would look as a sign and how it will work with the interior / mood . 2 . 4 % 7 . 2 % Support Feedback expressing the provider ' s support for the design creator . Good luck either way ! 3 . 2 % 2 . 7 % Table 3 : The taxonomy of critique discourse used to categorize the idea units . The two rightmost columns show the relative proportion of instances of each category for projects with only a single design ( No it . ) and those with two or more iterations . Columns do not sum to 100 % because idea units that did not fit into any of the above categories were omitted . Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 85 Coders also categorized each idea unit according to an established taxonomy of critique discourse [ 7 ] . Categories included judgment , direct recommendation , brainstorming , process - oriented , identity - invoking , free - association , comparison , interpretation , and investigation . We also added the category support for idea units praising or encouraging the creator’s ongoing effort ( see Table 3 ) . To test inter - rater reliability , a member of the research team labeled the valence and category of discourse of 100 idea units randomly sampled from each of the other three coders ( 300 total ) . There was a raw 77 % agreement for the category of discourse ( Cohen’s Kappa = 0 . 71 ) and 78 % agreement for the valence ( Cohen’s Kappa = 0 . 68 ) , which are considered satisfactory for moving forward with analyzing the results [ 23 , 37 ] . The categorized idea units were aggregated by project and iteration . We then counted the number of idea units falling under each category of discourse and valence , the total number of comments , the total number of idea units , and the total word count for each project revision . We used this data set for the regression models described below . To avoid overfitting our data , we used three separate logistic regression models . In our first model , we used the idea unit content categories as the predictor variables , and iteration as the response variable . The model identified three categories as being predictors of iteration : process - oriented ( coef . = 0 . 750 , p < 0 . 001 ) , comparison ( coef . = 0 . 279 , p = 0 . 124 ) , and investigation ( coef . = 0 . 204 , p = 0 . 167 ) . Using chi - squared tests to compare the distribution of content categories among idea units for design projects with a single iteration to those with multiple iterations , we found similar results : projects with multiple iterations had a higher proportion of process - oriented ( χ 2 ( 1 ) = 25 . 97 , p < 0 . 001 ) , investigation ( χ 2 ( 1 ) = 6 . 66 , p = 0 . 010 ) , and comparison ( χ 2 ( 1 ) = 3 . 93 , p = 0 . 048 ) idea units . Conversely , projects with only one iteration had a higher proportion of both judgment ( χ 2 ( 1 ) = 8 . 85 , p = 0 . 003 ) and direct recommendation ( χ 2 ( 1 ) = 4 . 82 , p = 0 . 029 ) idea units . We did not find any significant difference in the proportion of free association , interpretation , brainstorming , identity - invoking , or support between the two groups . Prior work found that designers with more expertise typically write more thought - provoking feedback ( e . g . , brainstorming and process - oriented ) [ 7 ] . The higher amount of thought - provoking feedback on projects with multiple iterations might then indicate that those projects were receiving more attention from providers with more design expertise . In our second model , we used valence as the predictor variable , and iteration as the response variable . The model identified both neutral ( coef . = 0 . 05 , p = 0 . 108 ) and critical ( coef . = 0 . 09 , p = 0 . 148 ) idea units as predictors of iteration , but not positive idea units . Chi - squared tests revealed similar results : overall , projects with multiple iterations had a significantly lower proportion of positive idea units than designs with only one iteration ( 19 . 3 % vs . 24 . 9 % ; χ 2 ( 1 ) = 10 . 77 ; p = 0 . 001 ) . Critical feedback reveals problems with the design and may prompt designers to iterate , whereas positive feedback may signal that the project is near completion and that further feedback is not necessary . In our third model , we used the number of idea units , number of comments , and total word count per project as the predictor variables , and iteration as the response variable . The model identified word count as a predictor of iteration ( coef . < 0 . 01 , p = 0 . 002 ) . We applied a similar model on the entire corpus of design projects , filtered to only first iterations with at least one comment ( n = 3 , 406 ) ; the analysis revealed that the number of comments was predictive of iteration ( coef . = 0 . 01 , p = 0 . 027 ) . One interpretation of these two analyses is that more comments and longer comments give designers more feedback to work with , exposes more potential improvements that can be made , and demonstrates a higher level of interest in and engagement with the work . To determine if designers’ engagement with the feedback providers affected iteration , we reran our models with designer engagement as a covariate . The ratio of the designer’s comments to the total comments on a thread was calculated as a proxy for engagement . Since designers typically reply to their own threads to represent iterations ( see Iteration Analysis ) , not all designer comments were community engagement ; consequently , this proxy measure is an upper bound for engagement . The models revealed that a higher ratio of designer comments to total comments was predictive of iteration ( coef = 5 . 29 , p < 0 . 001 for the model related to category of discourse ; coef = 5 . 34 , p < 0 . 001 for that of valence ; coef = 4 . 61 , p < 0 . 001 for that of feedback quantity ) ; the pattern of the results of the models were otherwise the same . This result suggests that increased engagement with feedback providers may also spur iteration . Across all project iterations ( n = 4 , 217 ) , we compared the number of comments received on the first and subsequent iterations . An ANOVA showed that initial iterations received more comments ( μ = 5 . 39 , σ = 8 . 65 ) than subsequent iterations ( μ = 3 . 94 , σ = 4 . 22 ; F ( 1 ) = 21 . 72 , p < 0 . 001 ) . The fewer comments on subsequent iterations might be attributed to users being unaware the project has been updated ( e . g . , the site does not allow users to subscribe to posts ) . Another possibility is that community members may be choosing to direct their attention to other projects [ 28 ] . This re - affirms prior work showing that implementation choices , even subtle ones , can have a large influence on the distribution of feedback generated in an online community [ 39 ] . Perceptions of iterating online ( RQ4 , RQ5 ) To complement our analysis of the forum data , we conducted two surveys . The first was open - ended , and asked designers about their motivations for and experiences with using Reddit for design feedback . It was posted to / r / design . The second was structured , and asked the designers about their iterative process . It was posted to / r / design _ critiques and / r / logodesign , and was distributed to design - oriented mailing lists . We split the questions between two surveys to reduce the time required to complete each one , and used the responses from the first survey to help formulate the Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 86 structured questions in the second survey . Both surveys required that a participant be at least 18 years of age and had posted a design for feedback to Reddit in the last six months . The surveys asked designers to describe a recent project posted to Reddit for feedback and to self - report their design expertise and demographics . We gave $ 20 for participation . In total , we received 38 responses to the surveys . There were 17 responses ( four female , ages 18 - 45 ) for the open - ended survey and 21 responses ( four female , ages 18 - 32 ) for the structured survey . For the structured survey , two responses ( of 23 , leaving 21 ) were eliminated due to not satisfying the survey criteria . There was no overlap in the participants . The majority of design projects posted by respondents of both surveys were logos and web site designs ; other projects included illustrations , portfolios , T - shirt designs , and flyers . The average self - rated expertise for the open - ended survey was ( µ = 3 . 3 , SD = 0 . 89 on a 5 - point scale ) , and the average for the structured survey was ( µ = 4 . 0 , SD = 1 . 4 on a 7 - point scale ) . We first report the data from the structured survey , and then draw from the open - ended survey responses to help explain the results from the structured survey and the prior analyses . Structured Survey ( n = 21 ) Table 4 summarizes the forced - choice questions and results from the structured survey . We note two interesting patterns in the data . First , the average reported number of iterations for a project ( including those not posted to Reddit ) was about six ( Q1 ; µ = 5 . 8 ) . However , the number of iterations posted to Reddit was less ( Q2 ; µ = 1 . 6 ) . For Q3 , fourteen respondents reported that they posted their designs to Reddit near the end of their process and three reported they did so between the middle and the end . Two respondents reported sharing their designs at the beginning of the process , two at the midpoint , and one in - between . In sum , these results show that a large majority of the respondents posted one or two iterations to Reddit for feedback , typically near the end of their process . Second , the respondents reported that iteration is important for their project ( Q4 ; µ = 6 . 0 ) , it is somewhat important to post iterations for feedback ( Q5 ; µ = 4 . 0 ) , the feedback received was reasonably good ( Q7 ; µ = 5 . 0 ) , and that Reddit is supportive of their process ( Q8 ; µ = 5 . 0 ) . Yet , consistent with the forum analysis , the respondents reported seldom posting more than two iterations to Reddit for feedback . Open - ended Survey ( n = 17 ) The open - ended survey asked respondents to describe their motivations for posting designs to Reddit for feedback , to identify other sites they considered posting their work and why they did or did not do so , to explain how the feedback they received helped ( or failed to help ) improve their work , and to explain why they would or would not use Reddit again as a source of feedback . We will use the notation Rn when referring to respondent n throughout this section . When asked about their motivations for posting their designs to Reddit for critique , there were three common responses ( n = 5 each ) . The first common response was that the potential of reaching a large audience was appealing : " . . . getting comments from people on Reddit offer a wider range compared to my usual methods of asking friends and family what they think . " [ R1 ] The second common response was that the site ' s diverse user base brought fresh perspectives : " . . . Reddit is a collective of individuals with varied taste and experiences of the real world , where the majority are not teachers . A teacher will critique on a different agenda , and a Redditor will critique on a personal bias , full disclosure , criteria . It ' s more raw to get people outside your bubble , outside your country even , for design critique . " [ R11 ] The third common response was that the overall quality of the critique they received was high : " Reddit is my go - to source for critique , advice , and general online discussion . " [ R13 ] When asked about other places they considered posting their designs , the respondents reported many different venues , but most stated that these venues were unsatisfactory for getting feedback . The most common was Facebook ( n = 5 ) , followed by Behance , DeviantArt , and Dribbble ( n = 2 each ) ; four respondents stated that they never considered posting their work to any other site . The respondents ' reasons for ultimately not using these other sites were similarly diverse , and included the lack of a forum structure [ R2 , R5 ] , lack of verbal critique [ R3 ] , lack of real world perspectives [ R4 ] , lack of anonymity [ R11 ] , and excessively harsh [ R12 ] or impersonal [ R7 ] critiques . This decision rationale indicates that Reddit has many unique qualities that make it attractive relative to social media and socially - oriented design communities as a platform for collecting design feedback . When questioned about how the feedback helped them improve their designs , responses were more similar : nearly Question Mean ( SD ) Q1 . In total , how many design iterations did you create for the project ? 5 . 6 ( 3 . 8 ) Q2 . In total , how many design iterations for the project did you post to Reddit for feedback ? 1 . 6 ( . 90 ) Q3 . At which stage in your process did you post the design to Reddit ( beginning , between beginning and midpoint , midpoint , between midpoint and end , near the end ) . ( see text ) Q4 . How important was it for you to create multiple iterations for the project ? ( 1 = not important , 7 = very ) . 6 . 0 ( 1 . 2 ) Q5 . How important was it to post multiple iterations to Reddit for feedback ? ( 1 = not important , 7 = very ) . 4 . 0 ( 1 . 8 ) Q6 . How would rate the depth of changes made to your design based on the feedback received from Reddit ( 1 = minimal , 7 = significant ) 3 . 8 ( 1 . 8 ) Q7 . How would you rate the quality of the feedback received from Reddit ( 1 = low , 7 = high ) 5 . 0 ( 1 . 6 ) Q8 . How well does Reddit support your iterative design process ( 1 = not at all , 7 = very well ) . 5 . 0 ( 1 . 4 ) Table 4 : The questions asked on the structured survey and the mean ( SD ) of the responses . Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 87 half of the respondents stated that users generally provided good critiques about the flaws of their designs ( n = 8 ) , and over half stated that they provided good suggestions ( n = 9 ) : " Commenters pointed out a slight difference in sharpness / blurriness between the images and also suggested a tweak to the hue / saturation of one of the elements . Both are very slight , subtle tweaks but have a big impact on the end result . " [ R15 ] Not all respondents had good experiences , however . One respondent stated that Reddit was of little help [ R12 ] , and two stated that it was of no help at all [ R1 , R6 ] : " I would either just have passive aggressive down votes or someone being very snarky with my work ; not too many constructive things . " [ R1 ] When asked about why they would or would not use Reddit for receiving design critique in the future , respondents were divided . Those stating they would consider posting there again in the future cited the fresh perspectives of the users ( n = 7 ) , the large user - base ( n = 3 ) , the high quality critique ( n = 3 ) , and the expertise of the users ( n = 2 ) . Conversely , commonly cited reasons for not returning for feedback in the future included the low quality of the critique ( n = 3 ) and the lack of expertise among the users ( n = 3 ) . One respondent stated outright that getting feedback was very “hit or miss” : " They ' re fairly good at feedback for the most part . Although it ' s a hit or miss if you get 2 comments or you get 100 . It depends on timing or likability or willingness of the other party . " [ R11 ] In sum , respondents found Reddit feedback mostly helpful for uncovering problems and getting suggestions for improvement , and felt that Reddit accommodates their iterative process more than other sites . DISCUSSION The goal of our study was to learn how designers naturally approach design iteration and feedback collection in online communities . Our quantitative results show that online design communities such as Reddit have immense potential for design critique : on average , designs receive about six comments , all within 24 hours , with each comment averaging 25 words and typically exceeding superficial statements such as “good job” . The values of these attributes exceed those reported in other studies of online communities [ 39 ] , and other artifact - based discussion sites [ 38 ] . According to our survey respondents , the primary draw of using Reddit for design critique is the ability to reach a large and diverse audience who can offer fresh , authentic perspectives . The site ' s users are ostensibly motivated by enjoyment of design or interest in a project , requiring neither social capital or compensation to provide feedback . Along with a low barrier to entry ( e . g . , invitations are not required ) , these factors make Reddit attractive for designers to post their projects . The majority of respondents to the surveys also indicated they were satisfied with the feedback received . Our analysis showed that designers who posted revisions of their work received more process - oriented , comparison , and investigation categories of feedback . These types of feedback are typically more open - ended , questioning , and thought - provoking ( e . g . , “Perhaps you could try a couple different locations for the diamond” ) . This type of content may create more uncertainty about the design’s quality , thereby prompting recognition that further revision and feedback is needed . By contrast , designers who did not share multiple revisions received more recommendations for improvement and assessments of quality ( judgments in the taxonomy ) . These categories may serve to validate the design ( e . g . “Looks good” ) or identify specific suggestions that can be directly accepted or rejected . Additionally , concrete feedback is characteristic of designers with less experience [ 7 ] , potentially signifying that feedback from less experienced designers does not promote iteration . In either case , designers receiving this type of feedback may not see a compelling reason to share or even produce a revised design . One way to solicit a desired balance of feedback categories is to allow designers to choose from defined rubrics that would scaffold the feedback generation process . Prior work has shown , for example , that rubrics can enable non - experts to give feedback comparable in depth and quality to that of expert designers [ 43 ] . A designer could indicate her desire to iterate when posting a project , and the platform could generate rubrics that include prompts for the categories of feedback that relate to iteration . The interface for entering the feedback could also be accompanied by expert examples ( e . g . see [ 8 ] ) or in - situ guidelines that would help community members craft the feedback that is most useful for iteration . Configurable rubrics could also enable a designer to direct providers’ attention to where feedback is most needed . We found that more responses , longer responses , and a lower proportion of positively - worded feedback correlate with iteration . Our results also showed that designer engagement with the feedback providers also correlates with iteration . More content , especially if distributed as previously described , and lower proportions of positive tone may also contribute to increased uncertainty about a design and prompt iteration . Additional responses could also signal community interest in the work , an implicit form of feedback that may also facilitate iteration . Prior work has studied the attributes of design feedback received online that correlate with perceived quality [ 43 ] . The authors found that longer feedback , feedback with strong positive or negative tone , feedback with high language specificity , and feedback that asks questions or makes suggestions correlate with higher perceived quality . Our results showed that several of these variables – including feedback length , more critical tone , and thought - provoking statements – also correlate with iteration . It is therefore possible that perceived quality might be serving as a latent variable between the observed variables and iteration . Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 88 Our results showed that only a single design was posted for 79 % of the projects in the forum data set ; with two or more iterations being shared for 21 % of the projects . These results were supported by the structured survey where a majority of the respondents reported posting only one design . The survey results indicated that designers are aware of the need to iterate and suggest that the observed rate of iteration is due in part to designers posting their designs near the end of their process , thus leaving insufficient time or desire to further iterate . This finding points to the need for more research to understand how to encourage designers to share their work earlier and more often . This is a potential issue not only for online design communities , but also for the crowd - based platforms that generate design feedback ( e . g . [ 24 , 26 , 40 ] ) . The system implementation of the community studied did not directly support iteration . Consequently , designers have had to learn to re - appropriate the site ' s mechanisms to represent iteration . For instance , a large majority ( 85 % ) of designers who iterated replied to their original thread with a comment linking to their revised design . The benefit is that this approach maintains a feedback history to contextualize subsequent discussion . However , the site’s presentation algorithm does not prioritize threads based on comment activity , even if performed by the original poster . Revised designs therefore receive less attention than the initial project post . This outcome is consistent with the platform’s mission to promote discussion around fresh content rather than prolonged discussions around older content . A compromise could be for the site ' s presentation algorithm to consider an iteration ( e . g . signaled by the designer replying to their original post ) as fresh content . It could also allow users to sort threads by the activity of the original poster . The karma feature in the community may also have affected our results . Project posts that receive more upvotes gain more visibility on the landing page . This allows the project to attract more feedback , which facilitates iteration . However , in our data set , we found only a very weak correlation between upvotes and the number of iterations posted ( r = 0 . 08 ) . Despite the lack of correlation , it is still possible some designers posted their work with the main objective of receiving upvotes and public exposure rather than critique . For the projects that did iterate , it was surprising that the Turk participants did not perceive differences in quality between the initial designs and final iterations , despite the perception of moderate revisions . In contrast , the rater with design experience did detect differences in quality . We do not believe these outcomes are necessarily incongruent . The improvement in design quality may have been subtle and required more expertise to differentiate . This pattern of results should serve as a reminder of the need to include evaluations from those with domain expertise in future studies that collect subjective ratings of design quality . LIMITATIONS AND FUTURE WORK The data was extracted from a single platform in two month - long windows of time . The community studied ( Reddit ) was chosen primarily because of its active community and the ability to access the data through an API . Future work is needed to generalize the findings to how designers iterate over longer periods of time and in other online communities . Because the community studied does not explicitly make available a history of edits to the posts or comments , it is likely the heuristics used on our data set missed some iterations and identified some posts as iterations that were not . Given the size of the data set , we believe these points to be inconsequential to the findings of the work . Finally , we were unable to measure and include the expertise of the designers in our quantitative analysis ; further research is needed to tease apart differences in iterative behavior between novice and expert designers in online communities . We see three additional directions for future work . First , our results showed that even though designers could revise their work using the feedback from Reddit , the changes did not produce detectable improvements in the eyes of non - experts . Future work could compare how designers motivated by their own goals would revise their work in response to expert feedback . A second direction would be to modify an online community to test the findings of this work . For example , one could incorporate rubrics or guidelines that promote the type of feedback that we found prompts iteration . Designers could also be allowed to organize iterations around their projects and showcase their process , rather than only individual designs . Last , future work could explore platform designs that address some of the psychological factors such as evaluation apprehension that may be deterring designers from sharing earlier versions of their work online . CONCLUSION Despite many successes in helping designers share final solutions and receive quick feedback on in - progress work , there has been less attention paid to helping designers approach and represent design iteration online . The contributions of this work were the results and lessons of how designers approach iteration in a large online design community . We found that designers exhibited a low rate of iteration on their work , and that this was due to sharing their work near the end of their design process . When designers did post two or more iterations for feedback , they had to re - appropriate the site ' s mechanisms to represent the iterations . We also discovered that both the quantity and content of the feedback received were correlated with whether designers posted subsequent revisions to their in - progress work . These findings can be practically applied to promote iterative design practice in online communities and related crowd feedback services . System designers can also leverage our findings to motivate the implementation of interaction mechanisms that directly support design iteration . We hope our contributions will enable online communities to better serve people at all skill levels in their creative projects . ACKNOWLEDGMENTS This work was supported in part by the National Science Foundation awards CMMI 14 - 62693 and IIS 15 - 30818 . Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 89 REFERENCES 1 . Arguello , J . , Butler , B . S . , Joyce , E . , Kraut , R . , Ling , K . S . , Rosé , C . , and Wang , X . Talk to me : foundations for successful individual - group interactions in online communities Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Montréal , Québec , Canada , 2006 , 959 - 968 . http : / / dx . doi . org / 10 . 1145 / 1124772 . 1124916 2 . Bailey , B . P . and Horvitz , E . What ' s your idea ? : a case study of a grassroots innovation pipeline within a large software company Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Atlanta , Georgia , USA , 2010 , 2065 - 2074 . http : / / dx . doi . org / 10 . 1145 / 1753326 . 1753641 3 . Burke , M . , Marlow , C . and Lento , T . Feed me : motivating newcomer contribution in social network sites Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Boston , MA , USA , 2009 , 945 - 954 . http : / / dx . doi . org / 10 . 1145 / 1518701 . 1518847 4 . Buxton , B . Sketching User Experiences : Getting the Design Right and the Right Design . Morgan Kaufmann Publishers Inc . , 2007 . http : / / dx . doi . org / 10 . 1145 / 2632434 . 2632461 5 . Chan , J . , Dow , S . P . and Schunn , C . D . Do the best design ideas ( really ) come from conceptually distant sources of inspiration ? Design Studies , 36 . 31 - 58 . http : / / dx . doi . org / 10 . 1016 / j . destud . 2014 . 08 . 001 6 . Cross , N . Creative cognition in design : processes of exceptional designers Proceedings of the 4th Conference on Creativity & Cognition , ACM , Loughborough , UK , 2002 , 14 - 19 . http : / / dx . doi . org / 10 . 1145 / 581710 . 581714 7 . Dannels , D . P . and Martin , K . N . Critiquing Critiques : A Genre Analysis of Feedback Across Novice to Expert Design Studios . Journal of Business and Technical Communication , 22 ( 2 ) . 135 - 159 . http : / / dx . doi . org / 10 . 1177 / 1050651907311923 8 . Doroudi , S . , Kamar , E . , Brunskill , E . and Horvitz , E . Toward a Learning Science for Complex Crowdsourcing Tasks Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , ACM , Santa Clara , California , USA , 2016 , 2623 - 2634 . http : / / dx . doi . org / 10 . 1145 / 2858036 . 2858268 9 . Dow , S . , Gerber , E . and Wong , A . A pilot study of using crowds in the classroom Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Paris , France , 2013 , 227 - 236 . http : / / dx . doi . org / 10 . 1145 / 2470654 . 2470686 10 . Dow , S . P . , Glassco , A . , Kass , J . , Schwarz , M . and Klemmer , S . R . The effect of parallel prototyping on design performance , learning , and self - efficacy , 2009 11 . Dow , S . P . , Heddleston , K . and Klemmer , S . R . The efficacy of prototyping under time constraints Proceedings of the Seventh ACM Conference on Creativity and Cognition , ACM , Berkeley , California , USA , 2009 , 165 - 174 . http : / / dx . doi . org / 10 . 1145 / 1640233 . 1640260 12 . Elkins , J . Art Critiques : A Guide . New Academia Publishing , LLC , 2012 13 . Gerber , E . and Carroll , M . The psychological experience of prototyping . Design studies , 33 ( 1 ) . 64 - 84 14 . Gilbert , E . Widespread underprovision on Reddit Proceedings of the 2013 Conference on Computer Supported Cooperative Work , ACM , San Antonio , Texas , USA , 2013 , 803 - 808 . http : / / dx . doi . org / 10 . 1145 / 2441776 . 2441866 15 . Gilbert , E . and Karahalios , K . Understanding deja reviewers Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work , ACM , Savannah , Georgia , USA , 2010 , 225 - 228 . http : / / dx . doi . org / 10 . 1145 / 1718918 . 1718961 16 . Greenberg , M . D . , Easterday , M . W . and Gerber , E . M . Critiki : A Scaffolded Approach to Gathering Design Feedback from Paid Crowdworkers Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition , ACM , Glasgow , United Kingdom , 2015 , 235 - 244 . http : / / dx . doi . org / 10 . 1145 / 2757226 . 2757249 17 . Harper , F . M . , Moy , D . and Konstan , J . A . Facts or friends ? : distinguishing informational and conversational questions in social Q & A sites Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Boston , MA , USA , 2009 , 759 - 768 . http : / / dx . doi . org / 10 . 1145 / 1518701 . 1518819 18 . Harper , F . M . , Raban , D . , Rafaeli , S . and Konstan , J . A . Predictors of answer quality in online Q & A sites Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Florence , Italy , 2008 , 865 - 874 . http : / / dx . doi . org / 10 . 1145 / 1357054 . 1357191 19 . Hui , J . , Glenn , A . , Jue , R . , Gerber , E . and Dow , S . , Using Anonymity and Communal Efforts to Improve Quality of Crowdsourced Feedback . in Third AAAI Conference on Human Computation and Crowdsourcing , ( 2015 ) 20 . Hui , J . S . , Gerber , E . M . and Dow , S . P . , Crowd - based design activities : helping students connect with users online . in Proceedings of the 2014 Conference on Designing interactive systems , ( 2014 ) , ACM , 875 - 884 . http : / / dx . doi . org / 10 . 1145 / 2598510 . 2598538 21 . Kim , J . G . , Kong , H . K . , Karahalios , K . , Fu , W . - T . and Hong , H . The Power of Collective Endorsements : Credibility Factors in Medical Crowdfunding Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 90 Campaigns Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , ACM , Santa Clara , California , USA , 2016 , 4538 - 4549 . http : / / dx . doi . org / 10 . 1145 / 2858036 . 2858289 22 . Lampe , C . and Resnick , P . Slash ( dot ) and burn : distributed moderation in a large online conversation space Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Vienna , Austria , 2004 , 543 - 550 . http : / / dx . doi . org / 10 . 1145 / 985692 . 985761 23 . Landis , J . R . and Koch , G . G . The measurement of observer agreement for categorical data . Biometrics . 159 - 174 . http : / / dx . doi . org / 10 . 2307 / 2529310 24 . Luther , K . , Caine , K . , Ziegler , K . and Bruckman , A . Why it works ( when it works ) : success factors in online creative collaboration Proceedings of the 16th ACM International Conference on Supporting Group Work , ACM , Sanibel Island , Florida , USA , 2010 , 1 - 10 . http : / / dx . doi . org / 10 . 1145 / 1880071 . 1880073 25 . Luther , K . , Tolentino , J . - L . , Wu , W . , Pavel , A . , Bailey , B . P . , Agrawala , M . , Hartmann , B . and Dow , S . P . Structuring , Aggregating , and Evaluating Crowdsourced Design Critique Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing , ACM , Vancouver , BC , Canada , 2015 , 473 - 485 . http : / / dx . doi . org / 10 . 1145 / 2675133 . 2675283 26 . Mamykina , L . , Manoim , B . , Mittal , M . , Hripcsak , G . and Hartmann , B . Design lessons from the fastest Q & A site in the west Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Vancouver , BC , Canada , 2011 , 2857 - 2866 . http : / / dx . doi . org / 10 . 1145 / 1978942 . 1979366 27 . Marlow , J . and Dabbish , L . From rookie to all - star : professional development in a graphic design social networking site Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing , ACM , Baltimore , Maryland , USA , 2014 , 922 - 933 . http : / / dx . doi . org / 10 . 1145 / 2531602 . 2531651 28 . McInnis , B . J . , Murnane , E . L . , Epstein , D . , Cosley , D . and Leshed , G . One and Done : Factors affecting one - time contributors to ad - hoc online communities Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing , ACM , San Francisco , California , USA , 2016 , 609 - 623 . http : / / dx . doi . org / 10 . 1145 / 2818048 . 2820075 29 . Nielsen , J . Iterative User - Interface Design . Computer , 26 ( 11 ) . 32 - 41 . http : / / dx . doi . org / 10 . 1109 / 2 . 241424 30 . Otterbacher , J . ' Helpfulness ' in online communities : a measure of message quality Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Boston , MA , USA , 2009 , 955 - 964 . http : / / dx . doi . org / 10 . 1145 / 1518701 . 1518848 31 . Reimer , Y . J . and Douglas , S . A . Teaching HCI Design With the Studio Approach . Computer Science Education , 13 ( 3 ) . 191 - 205 . http : / / dx . doi . org / 10 . 1076 / csed . 13 . 3 . 191 . 14945 32 . Rzeszotarski , J . M . and Morris , M . R . Estimating the social costs of friendsourcing Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Toronto , Ontario , Canada , 2014 , 2735 - 2744 . http : / / dx . doi . org / 10 . 1145 / 2556288 . 2557181 33 . Schon , D . A . Designing as reflective conversation with the materials of a design situation . Research in Engineering Design , 3 ( 3 ) . 131 - 147 . http : / / dx . doi . org / 10 . 1007 / bf01580516 34 . Shanteau , J . , Weiss , D . J . , Thomas , R . P . and Pounds , J . C . Performance - based assessment of expertise : How to decide if someone is an expert or not . European Journal of Operational Research , 136 ( 2 ) . 253 - 263 . http : / / dx . doi . org / 10 . 1017 / CBO9780511609978 . 021 35 . Sylvan , E . Predicting influence in an online community of creators Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Atlanta , Georgia , USA , 2010 , 1913 - 1916 . http : / / dx . doi . org / 10 . 1145 / 1753326 . 1753614 36 . Tan , C . and Lee , L . All Who Wander : On the Prevalence and Characteristics of Multi - community Engagement Proceedings of the 24th International Conference on World Wide Web , ACM , Florence , Italy , 2015 , 1056 - 1066 . http : / / dx . doi . org / 10 . 1145 / 2736277 . 2741661 37 . Viera , A . J . and Garrett , J . M . Understanding interobserver agreement : the kappa statistic . Fam Med , 37 ( 5 ) . 360 - 363 38 . Willett , W . , Heer , J . , Hellerstein , J . and Agrawala , M . CommentSpace : structured support for collaborative visual analysis Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ACM , Vancouver , BC , Canada , 2011 , 3131 - 3140 . http : / / dx . doi . org / 10 . 1145 / 1978942 . 1979407 39 . Xu , A . and Bailey , B . What do you think ? : a case study of benefit , expectation , and interaction in a large online critique community Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work , ACM , Seattle , Washington , USA , 2012 , 295 - 304 . http : / / dx . doi . org / 10 . 1145 / 2145204 . 2145252 40 . Xu , A . , Huang , S . - W . and Bailey , B . Voyant : generating structured feedback on visual designs using a crowd of non - experts Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing , ACM , Baltimore , Maryland , Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 91 USA , 2014 , 1433 - 1444 . http : / / dx . doi . org / 10 . 1145 / 2531602 . 2531604 41 . Xu , A . , Rao , H . , Dow , S . P . and Bailey , B . P . A Classroom Study of Using Crowd Feedback in the Iterative Design Process Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing , ACM , Vancouver , BC , Canada , 2015 , 1637 - 1648 . http : / / dx . doi . org / 10 . 1145 / 2675133 . 2675140 42 . Yen , Y . - C . , Dow , S . P . , Gerber , E . and Bailey , B . P . Social Network , Web Forum , or Task Market ? : Comparing Different Crowd Genres for Design Feedback Exchange Proceedings of the 2016 ACM Conference on Designing Interactive Systems , ACM , Brisbane , QLD , Australia , 2016 , 773 - 784 . http : / / dx . doi . org / 10 . 1145 / 2901790 . 2901820 43 . Yuan , A . , Luther , K . , Krause , M . , Vennix , S . I . , Dow , S . P . and Hartmann , B . Almost an Expert : The Effects of Rubrics and Expertise on Perceived Value of Crowdsourced Design Critiques Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing , ACM , San Francisco , California , USA , 2016 , 1005 - 1017 . http : / / dx . doi . org / 10 . 1145 / 2818048 . 2819953 Session : The Art and Science of Making C & C 2017 , June 27 – 30 , 2017 , Singapore 92