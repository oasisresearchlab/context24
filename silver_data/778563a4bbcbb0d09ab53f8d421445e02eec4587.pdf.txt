Structured Online Interactions : Improving the Decision - Making of Small Discussion Groups Shelly Farnham , Harry R . Chesley , Debbie E . McGhee , Reena Kawal Virtual Worlds Group Microsoft Research One Microsoft Way Redmond , WA 98052 - 6399 USA + 1 425 882 8080 { shellyf , harrych , a - debmcg , reenak } @ microsoft . com Jennifer Landau Hammond & Landau + 1 415 861 5118 jhlandau @ earthlink . net ABSTRACT A quantitative research experiment was used to examine whether a group’s computer - mediated decision - making could be improved by providing a scripted structure to the group’s text chat discussion . The study compared a regular chat discussion to a scripted chat discussion using Lead Line , a program that allows people to add a layer of pre - authored structure to regular text chat . We found that groups were more likely to come to consensus and to make higher quality decisions in structured chat discussions . In addition , groups applied the structure they learned to subsequent regular chat sessions . Keywords chat , structured chat , computer - mediated communication , group decision - making , computer supported collaborative work INTRODUCTION Much of human social interaction follows a script . Scripts provide people with guidance to social situations , allowing their interactions to be focused and streamlined . In many situations , scripts are implicit and normative . For example , in a sales transaction both the buyer and the seller know the behaviors associated with their roles , and effortlessly follow the steps of exchanging money for goods . In other situations , scripts are explicitly written by one of the participants , such as an agenda or a class syllabus . As more and more social interactions take place online , people will develop new implicit scripts for online social behavior . However , computer - mediated situations provide people with a unique opportunity to employ explicit scripts as well , scripts that enhance the quality of social interactions . In order to explore online scripting , we built a prototype called Lead Line , which adds scripting to simple text chat . The present research tests whether a scripted Lead Line chat environment could effectively structure an online discussion group’s decision - making process . In particular , we examine whether the guidance provided by a script in the context of text chat could improve a group’s ability to achieve consensus and enhance the quality of a group’s decision . Need for Structure in Computer - Mediated Social Interactions Past research on computer - mediated social interactions in the work place suggests that they have some advantages over face - to - face interactions . Computer - mediated discussion groups tend to be more focused on the task at hand and less distracted by personal considerations [ 24 ] , have more equal member participation [ 21 ] , and generate more ideas because group members can all “speak” at the same time . However , there are several disadvantages as well . Computer - mediated discussion groups take more time to make decisions , are more prone toward conflict , and , most importantly , have more difficulty achieving consensus [ 10 , 20 , 21 , 22 , 24 ] . While some researchers argue that computer - mediated groups are less likely to reach consensus because they share less information and the impersonal context creates greater conflict [ 7 , 21 , 24 ] , another possibility is the lack of structure that occurs in online groups through a paucity of leadership [ 10 , 18 ] . Hiltz et al . [ 10 ] , in a study that compared computer - mediated and face - to - face decision - making groups , found that leaders did not emerge in computer - mediated groups to the extent they did in face - to - face groups . They argue that the lack of leadership may have inhibited the groups’ ability to organize and reach agreement . Research on group processes shows that the leadership provided by group facilitators is key to a group’s effectiveness [ 11 ] . Many contemporary concepts of organizational development and meeting facilitation are based on adding structure and scripting to the interactions . Meeting facilitation systems like Open Space Technology [ 17 ] , Scenarios / Future Search Conferences [ 26 ] , Strategic Forum [ 19 ] , and the World Café [ 3 , 4 ] each take a unique approach to adding structure to person - to - person and person - to - group communication . Such meeting facilitation systems are usually driven by a human facilitator who provides procedural guidance and motivation for the meeting . Past research on computer - mediated group interactions indicates that the presence of a facilitator enhances the quality of group discussions [ 15 ] . For example , computer conferencing systems such as bulletin boards have long used moderators to overcome the communication problems that arise due to a lack of face - to - face interactions [ 23 ] , and Mark et al . [ 12 ] found that meeting facilitation enhanced the outcomes of a group using NetMeeting . Several existing online systems provide guidance and structure to social interactions in the work place . Some such systems focus on structuring the process or flow of work within a group or organization ( known as workflow systems ) . Perhaps the best - known existing workflow system for structuring social interactions is the Coordinator [ 8 ] . This system formalizes transactions between users of an e - mail system , in accordance with different linguistic actions . Milano [ 1 ] is another system that focuses on structuring the workflow of an organization through e - mails . Milano [ 1 ] provides a global context to specific social interchanges , with any communication event linked to its context within a conversation . Other existing online systems focus on structuring a group’s task and its performance of that task . Such systems are often referred to as group decision support systems ( GDSS ) [ 13 , 14 ] . Nunamaker et al . [ 14 , 15 ] at the University of Arizona , have focused on same - time , same - place interactions in a meeting room set up with workstations , a large - screen video display as an electronic blackboard , and other audio - visual support , to provide tools for session planning and management , group interaction , organizational memory , individual work , and data collection [ 15 ] . Cao and Burstein developed a system for Lotus Notes that allows a facilitator to control and monitor decision - making processes in an asynchronous GDSS [ 5 ] . The workflow and group decision support systems described above tend to focus on providing tools for organizing and managing the content of the group’s communications . Similar to face - to - face structured interactions , they tend to rely on the presence of human facilitators to employ the tools provided to structure the group’s interactions . The use of human intermediaries in most of these systems makes them difficult to replicate and scale , because they require a live human being with appropriate training . However online systems , by virtue of having the computer as the mediator of communication , promise to allow easily replicable , and thus scalable , implementation of group meeting facilitation . Lead Line fulfills this promise by allowing authors to provide structure to group discussions without requiring the authors’ direct involvement in the discussions . Lead Line , as distinguished from the systems described above , focuses narrowly on scripting synchronous social interactions . Rather than focusing on workflow or content per se , it focuses on providing people with the ability to create scripts that enhance the effectiveness of their online chat interactions . CURRENT RESEARCH Effective group decision - making usually involves a ) clearly stating the problem , b ) fully exploring the alternatives , and c ) ranking the alternatives [ 25 ] . An effective facilitator guides a group through these steps in a timely fashion , keeping the members of the group focused on the task at hand . We wanted to test whether a Lead Line script could enhance a group’s decision - making by providing similar guidance . In order to do so we developed a timed decision - making task with a measurable outcome . We had group members play the role of recruiters who had just interviewed several candidates for a job . We did not have the group members actually conduct the interviews themselves . Each recruiter was provided with mock interview notes . We then gave the groups the task of discussing the job candidates and coming to a decision about whom they wanted to hire , all within 20 minutes . Each group completed the task twice , once in a regular chat discussion , and once in a structured chat discussion . For the structured chat discussions , the group received instructions that had them first focus on the problem , then explore the strengths and weaknesses of each candidate , and finally rank the candidates . The script divided the discussion into scenes , and each scene was timed . Our primary hypotheses were : I . Groups would be more likely to come to consensus in a structured chat discussion than in a regular chat discussion ; and II . Groups would make higher quality decisions in a structured chat discussion than in a regular chat discussion LEAD LINE The Lead Line prototype attempts to capture the essence of online scripted social interaction in the simplest online setting : text chat . It adds a script to text chat that leads the users through a session . Control of progress though the script is in the author’s hands , not in some mechanical scheme that would require machine understanding of the social interaction . Lead Line allows for a significant range of types and styles of scripted social interaction . An author creates a script that each of the Lead Line clients follows during the session . The script defines a set of roles and divides the session into a sequential set of scenes . For each role and scene combination , the script specifies instructions to be given to the user ( s ) playing that role . Advancing through scenes is done under a combination of user and author control . Users tell the client that they are ready to continue on to the next scene by clicking on a scene advance checkbox . The author can specify a set of roles that must agree in order for the scene to advance . Alternatively , the author can specify that any single user of a set can make the decision . Finally , the author can make the scene timed , so that advancement is out of the hands of the users , taking place after a preset length of time . Although quite simple in concept , this structure allows for a very wide range of possible scripts . Authors can encourage cooperation by giving different roles complementary instructions . Or they can foment dissention by giving conflicting , or even contradictory instructions . Since the goals and scene advancement criteria of the scenes are in the hands of human beings and not the machine , they can be very abstract and high level . Lead Line User Interface Figure 1 shows the Lead Line user interface . It is divided into four main areas : 1 . Title . At the top of the window is the title of the script concatenated with the title of the current scene . 2 . Chat History . Below the title , to the left , is the chat history area . Pre - authored instructions from the writer to the user are inserted in the chat history , and are based on the current scene and role . 3 . User List . To the right of the chat history is a list of roles and users . 4 . User Input . At the bottom of the window is the user input area . This includes the scene advance checkbox , an input style pop - up ( that lets the user chose between saying , thinking , shouting , and doing ) , as well as the text input field . Technology Lead Line scripts are written in a tagged , XML format [ 2 ] . This approach makes it easy for authors to create and edit scripts using any familiar text editor . The format is also well known to anyone who has used HTML to create a web page . The format allows for open - ended future extension of the script feature set . XML script tags are provided to define the roles , to delimit the script into separate sequential scenes , to tell what instructions to give to each role in each scene , to change the text of the user’s scene advance checkbox , to determine when a scene should advance , and much more . The Lead Line client was implemented in Java [ 9 ] and designed to operate as an applet within a web page . Lead Line was implemented in Java to allow wide range of users to access the system without having to pre - download or install any special software . We used the Abstract Window Toolkit ( AWT ) 1 . 1 [ 6 ] to provide the user interface . This UI toolkit was the most widely distributed one available at the time , with versions included in Internet Explorer 4 . 0 and 5 . 0 for both Windows and Macintosh , and Netscape Navigator 4 . 0 for Windows . Communication between Lead Line clients is supported with the Internet Relay Chat ( IRC ) protocol [ 16 ] . This protocol is the basis for many existing real - time text chat applications , and many firewalls are already configured to allow it to pass through – an important consideration in getting the widest possible user base for Lead Line . Rather than implement a server component for Lead Line , we implemented it as a distributed application using only a simple IRC server for communication . Client - to - client communication is embedded in the communication stream by prefacing such lines of data with a special escape character . This allows the program to remove and interpret those lines without displaying them to the user . Figure 1 . Lead Line user interface . RESEARCH METHODS Subjects There were 65 people ( 31 female and 34 male ) who participated in the study in exchange for a software package . People were run in groups of three or four at a time , making 19 groups total . The median age of the participants was 37 years , and most participants ( 94 % ) had at least some college . Participants were recruited so that a broad range of chat experience would be represented in each session . The median number of days during the previous year participants reported they had used chat programs was 100 ( range : 0 - 365 ) and the median number of hours per typical week was 2 ( range : 0 - 200 ) . Procedures Overview Participants were told that they would role - play being members of a Human Resources department at a fictional company ( Acme Wireless Services ) and that they would be making hiring decisions about different positions within the company using different chat programs . Participants then completed a background questionnaire and took a brief typing test . After all participants in the group had completed the typing test , they were introduced to the Hiring Task and then began their first chat session . Each of the chat sessions was followed by a questionnaire which : 1 ) asked participants to report the group’s decision and assessed participants’ memory of the job candidates’ traits , 2 ) asked for evaluations of the group decision - making process , and 3 ) solicited feedback about the chat program itself . The Hiring Task For the Hiring Task , each participant received a four - page task packet that included an overview page and three sets of mock interview notes ( one set of notes per job ) . The three jobs were Administrative Assistant , Assistant Store Manager , and Technical Writer . There were three candidates for each job , and each candidate was identified both by number and name . The interview notes were structured as follows . Prior to the study , the experimenters had created , for each position , a list of twelve job skills that varied in the degree to which they were considered to be relevant to the position . The twelve skills were divided into four “relevance categories” : three skills were essential , three were highly relevant , three were somewhat relevant , and three were only tangentially relevant ( if at all ) . Although there was overlap in the skills across jobs , the jobs had been chosen to be distinct enough so that there was very little overlap in the skills that were most relevant . Each of the three candidates for a particular position was assigned a rating ( “fair” , “good” , “very good” , “excellent” ) on all twelve job skills such that the best candidate’s skill level increased as the relevance of the trait increased ( i . e . , the candidate was “excellent” on the three most relevant skills ) , and the worst candidate’s skill level was highest on the least relevant skills and lowest on the most relevant skills . These candidate skill ratings were then put into narrative form and distributed across the participant interview notes . The interview notes were structured so that there was one rank order of candidates that represented the most optimal decision ; however , individual group members would not be aware of the optimal rank order until after they had effectively communicated with the other group members . Chat sessions Participants completed two chat sessions to discuss two different jobs 1 . For each session , participants used one of two chat scripts ( regular chat , structured chat ) using the Lead Line program . The experimenter introduced each chat session by giving a brief overview of the program’s format , and then reminded the participants that they would have twenty minutes to decide their first , second , and third choices for the position . Regular chat session . The regular chat session provided very little structure , simply directing groups to order the candidates within 20 minutes . See Table 1 for specific instructions . A clock counted down the time remaining in the lower left - hand corner of the chat window . Structured chat session . For the structured chat session , the script broke up the discussion into six “scenes” and at the beginning of each scene provided instructions as to what the participants should discuss during that scene . The scene instructions a ) had the groups discuss the problem , b ) had the groups fully explore the alternatives , and c ) directed groups to evaluate and rank their alternatives . See Table 1 for specific instructions . Each scene was timed , and Lead Line displayed the time remaining for each scene in the lower left - hand corner of the chat window . Equipment Each participant completed the study in a room that housed a standard personal computer . There was only one participant in each room , and participants interacted with each other only through the chat programs . The experimenter observed each participant through a one - way mirror , and through a remote display of the user’s screen . Participants and the experimenter interacted via a microphone and speakers . 1 Although participants completed three chat sessions , only two will be discussed in the context of this paper . The third chat session was included to examine features of chat interactions that are not relevant to this paper’s discussion of structured chat . Order of the three chat sessions was fully counterbalanced . Table 1 For the regular chat and structured chat sessions , Lead Line scripted messages appeared in the chat history window at the beginning of each Lead Line scene . Design and Analyses Order of the chat sessions was varied between - groups , and crossed with the three job sequences selected for this study . All data were aggregated at the group level , and for the most part were analyzed using a repeated measures ANOVA of a 2 ( within subjects : regular vs . structured chat session ) X 2 ( between subjects : regular chat session first vs . structured chat session first ) design . When appropriate , the between groups effect of the first chat sessions ( regular vs . structured ) was analyzed using an independent samples t - test . All p - values are two - tailed . RESEARCH RESULTS In the following sections of the paper , we first test the two primary hypotheses that groups would be more likely to achieve consensus in a structured chat environment and that groups would make better decisions in a structured chat environment . We then examine post chat session questionnaires and open - ended comments to gain a better sense of the users’ experience of the two chat sessions . Hypothesis I : Achieving Consensus Our first hypothesis was that groups would be more likely to reach consensus in their hiring decisions when their discussions were structured . In order to examine the effect of the structured script on the groups’ ability to achieve consensus , we coded each group’s level of consensus through a perusal of the transcripts of the discussions . A group was coded as having achieved full consensus if all members of the group explicitly agreed to first , second , and third choices for the job . A group was coded as having partial consensus if all members of the group explicitly agreed to the first choice for the job . For statistical analyses , levels of consensus were coded as 0 for no consensus , . 5 for partial consensus , and 1 for full consensus . A comparison of the groups’ first chat sessions shows that they were more likely to achieve consensus if their discussions were structured . Of the groups that had a structured chat session first , 90 % achieved full consensus , whereas only 22 % of the groups with a regular chat session achieved full consensus . See Figure 2 . The level of consensus for the first structured chat session was significantly higher than the level of consensus for first regular chat session ( t ( 17 ) = 3 . 03 , p < . 01 ) . Figure 2 . Groups were more likely to achieve consensus if their discussions were structured , and if they completed the structured chat session first . We found an interesting , and somewhat unexpected , order effect when examining people’s second chat sessions . See Figure 2 . When a regular chat session followed a structured chat session , groups continued to achieve high levels of consensus ( 90 % ) . By contrast , when a structured chat session followed a regular chat session , level of consensus Regular Chat Lead Line Scenes - - - - - Discuss & Decide - - - - - ( Scene 1 : 20 minutes ) Discuss the candidates and order them according to best fit for the position . You have twenty minutes . Structured Chat Lead Line Scenes - - - - - The Position - - - - - ( Scene 1 : 4 . 5 minutes ) You have all interviewed a number of candidates for a position at your company . Your goal over the next twenty minutes is to discuss the different candidates , and come to a consensus about whom you will hire . You must decide who is your first , second , and third choice for the position . Before discussing the job candidates , it is important to review what are the important traits and abilities needed to fill this position . You will have several minutes to discuss what you think are the most important traits and abilities to fill this position . - - - - - Candidate # 1 - - - - - ( Scene 2 : 3 . 5 minutes ) You will now have a chance to discuss each candidate . From reviewing your interview notes , what do you think are the strengths and weaknesses of the candidate # 1 ? Please listen carefully to the other interviewers’ comments . You will have several minutes to discuss the first candidate . - - - - - Candidate # 2 - - - - - ( Scene 3 : 3 . 5 minutes ) From reviewing your interview notes , what do you think are the strengths and weaknesses of the candidate # 2 ? Please listen carefully to the other interviewers’ comments . You will have several minutes to discuss the second candidate . - - - - - Candidate # 3 - - - - - ( Scene 4 : 3 . 5 minutes ) From reviewing your interview notes , what do you think are the strengths and weaknesses of the candidate # 3 ? Please listen carefully to the other interviewers’ comments . You will have several minutes to discuss the third candidate . - - - - - Consensus - - - - - ( Scene 5 : 4 minutes ) Now it is time to come to a consensus . You must decide who is your first , second , and third choice for the job . You have several minutes to discuss your choices . - - - - - Decision - - - - - ( Scene 6 : 1 minute ) Please state your decision . Who is your first , second , and third choice for the job ? Achieving Consensus 0 % 10 % 20 % 30 % 40 % 50 % 60 % 70 % 80 % 90 % 100 % P erce n t ag e o f G r o up s None Partial Full Level of Consensus Regular Structured Structured Regular Regular Chat 1st Structured Chat 1st improved ( 78 % ) but not to the levels achieved by those who started with a structured session . A repeated measures ANOVA shows an overall marginal within subjects’ effect of type of chat session ( F ( 1 , 17 ) = 3 . 59 , p < . 08 ) , and a marginal interaction effect between order and type of session ( F ( 1 , 17 ) = 3 . 59 , p < . 08 ) . Overall , groups performed better in the structured chat sessions , but this effect was moderated by the order of the chat sessions . One possible explanation for this order effect is that groups learned to structure their discussions in the structured chat session , and then applied that structure to their regular chat session . One factor that might have had an impact on groups’ ability to achieve consensus is whether or not they attempted to rank the candidates . If groups did not have a sense of how they should pace themselves during the regular chat sessions , they might not have finished their discussions of the candidates in time to rank them . To test for this possibility , we coded a group as having fully ranked the candidates if each member of the group had indicated his or her preferred rankings for all three candidates , and we coded a group as having partially ranked the candidates if each member of the group had indicated at least his or her first choice . A comparison of groups’ first chat sessions shows that of those who completed the regular chat session first , only 22 % fully ranked the candidates , 34 % partially ranked the candidates , and 44 % never ranked the candidates . However , 100 % of the groups in the first structured session fully ranked the candidates . Again we find an order effect , where 100 % of the groups who completed the regular chat session after the structured chat session fully ranked the candidates in that session . See Figure 3 . The within subjects’ difference between the two types of chat sessions is highly significant ( F ( 1 , 17 ) = 21 . 65 , p < . 001 ) , as is the interaction between the order of the chat sessions and that difference ( F ( 1 , 17 ) = 21 . 65 , p < . 001 ) . Figure 3 Groups were more likely to have ranked the candidates within the twenty minute time constraint in structured chat sessions , and if they completed the structured chat session first . In sum , an important component of a group’s ability to achieve consensus was the group’s ability to get around to ranking the candidates . Hypothesis II : Making Better Decisions A second hypothesis was that groups would achieve a higher quality of decision through a structured chat discussion than through a regular chat discussion . Each person knew about different aspects of each candidate , so a group would come to the best decision only if people were communicating well with one another . In the structured chat sessions , groups discussed each candidate for almost four minutes , and group members were encouraged to communicate what each of them knew about the candidates and to listen carefully to what the others had to say . If groups are communicating more information in a more coherent manner in the structured chat session , they should make a higher quality decision . We used the study participants’ post - session rankings of candidates to assess the quality of the group’s decision . After each chat session , individuals were asked to rank the candidates in accordance with the group’s decision . If they were not sure about their group’s decision , or their group did not come to a decision , they were told to guess to the best of their ability . There were six possible ranking orders , and each order was assigned a number indicating the quality of the decision , ranging from least optimal order to most optimal order . Individual scores were then aggregated to the group level . Most groups arrived at fairly optimal decisions . Out of the 38 decisions made ( 2 for each of 19 groups ) , 36 scored a 4 or above , indicating that groups tended to select one of the top three ranking orders ( scored a 4 , 5 or a 6 ) . A comparison of the groups’ first chat sessions shows that groups did not have a higher quality of decision depending on whether their discussions were structured . The difference between the first regular and structured sessions , while in the predicted direction , is not statistically significant ( t ( 17 ) = 1 . 07 , ns ) . See Figure 4 . Figure 4 . Groups made better decisions overall when they completed the structured chat session first . Error bars represent standard errors . Ranking Candidates 0 % 10 % 20 % 30 % 40 % 50 % 60 % 70 % 80 % 90 % 100 % P erce n t ag e o f G r o u p s None Partial Full Regular Structured Structured Regular Regular Chat 1st Structured Chat 1st Ranking Behavior Making Better Decisions 3 4 5 6 Q u a li t y o f D ec i s i o n Regular Structured Regular Chat 1st Structured Chat 1st Type of Chat Session However , groups were more likely to make a higher quality decision across the two chat sessions when they completed the structured chat session first . A repeated measures ANOVA shows a significant between groups main effect of order ( F ( 1 , 17 ) = 4 . 47 , p < . 05 ) . Overall , groups who completed the structured chat task first made better decisions in both the structured chat and the regular chat sessions . Again , we may be finding an order effect where people are learning how to structure their discussions in the first , structured chat discussion , and then applying those lessons to their second , regular chat discussion . Similarly , groups may develop norms in the first regular chat session that inhibit their performance in the subsequent structured chat session . We expected people to make higher quality decisions in the structured chat session for several reasons . The structured chat script directed people to a ) focus on the traits important to the job early in the discussion , b ) spend a minimum of four minutes on each candidate , discussing the candidates’ strengths and weaknesses , and c ) discuss the candidates one at a time , allowing for a better impression of each candidate to develop . An analysis of the content of the conversations allows us examine the extent to which groups followed these procedures . Our first question was whether people discussed the important skills for the job early in the discussion . We coded the content of each chat message for whether the message focused on the skills required for the job . We then counted how many messages out of the first twenty were devoted to a discussion of the job requirements . We found that groups were more likely to have early discussions of the skills important for the job in the structured chat sessions than in the regular chat sessions ( within subjects F ( 1 , 17 ) = 6 . 07 , p < . 03 ) . See Figure 5 . Figure 5 . Groups were more likely to have an early discussion of the job requirements in structured chat sessions . Groups had the least discussion of job requirements in regular chat sessions if they were first . Error bars represent standard errors . However , once again we found an order effect . The difference between the two sessions depended on the order of the chat sessions ( F ( 1 , 17 ) = 12 , 75 , p < . 003 ) . A between groups comparison of the first regular chat session and the first structured chat session does not show a significant difference . To what extent did group members talk about the candidates’ traits and abilities ? We coded the content of each chat message for whether the message focused on the traits of a particular candidate . We then calculated the average number of messages per group member , and then aggregated the means for each group . A comparison of the first chat sessions shows that people posted significantly more messages about candidate traits in the structured chat sessions than in the regular chat sessions ( t ( 17 ) = 3 . 12 , p < . 006 ) . See Figure 6 . However , once again we found an order effect . As you can see from Figure 6 , when the regular chat session followed the structured chat session people continued to post a higher number of messages regarding candidate traits . The effect of order on the within subjects effect is marginally significant ( F ( 1 , 17 ) = 3 . 2 , p < . 10 ) . The between subjects effect of order is significant ( F ( 1 , 17 ) = 6 . 5 , p < . 03 ) . Across both chat sessions people generally talked about the traits of the candidates more when the structured chat session was first . Figure 6 . The number of chat messages each person devoted to candidate traits was higher in structured chat sessions , and in groups that completed the structured chat first . Error bars represent standard errors . We expected that people would be more likely to talk about candidates one at a time when their chat conversation was structured . To measure the frequency with which groups changed the topic of conversation , we coded from one message to the next whether the message switched topics relative to the previous chat message about a candidate . We then calculated the rate of topic changes over the course of the conversation . A comparison of the first chat sessions shows that there was a higher rate of topic change in the regular chat session than in the structured chat session , and that this difference is marginally significant ( t ( 17 ) = 1 . 75 , p < . 10 ) . We found that the highest rate of topic changes occurred in the regular chat session when it was the first chat session . See Figure 7 . A repeated measures ANOVA shows no significant within subjects effect of chat session type , but the Messages Focusing on Candidate Traits 01234567891011121314151617 N u m b er o f C h a t M e ss ag e s Regular Structured Type of Chat Session Regular Chat 1st Structured Chat 1st Messages Focusing on Job Requirements 0 1 2 3 4 5 6 7 8 9 10 11 N u m b er o f C h a t M e ss ag e s Regular Structured Type of Chat Session Regular Chat 1st Structured Chat 1st interaction between order and the within - subjects effect is marginally significant ( F ( 1 , 17 ) = 3 . 69 , p < . 08 ) . Figure 7 . Groups who completed the regular chat session first were most likely to change the topic of discussion from candidate to candidate . Error bars represent standard errors . It has been argued that people develop a better impression of the candidates during the structured chat session because they discuss the candidates more , and discuss the candidates one at a time . If that is the case , then people should have a more accurate knowledge of the candidates after the structured chat sessions . We tested people’s knowledge of the candidates after each session by having them rate the candidates on the six traits most relevant to the job , using the same scale as that found in the interviewer notes . We measured the accuracy of each response by taking the difference between the actual response and the accurate response . We averaged scores across the candidates for each person , and averaged across the individuals for ea ch group . Figure 8 . Groups had the lowest errors in recall in the regular chat sessions that followed structured chat sessions . Error bars represent standard errors . We did not find that groups made more errors in their ratings overall depending on chat type . However , once again we found an order effect , such that the reduction in error was greater following the structured chat session than the regular chat session ( F ( 1 , 17 ) = 6 . 71 , p < . 02 ) . This greater reduction in error may be due to a combination of a practice effect and the groups’ application of the structure just learned to the regular chat session . See Figure 8 . In sum , we found that groups made better decisions in both the structured chat and regular chat sessions when the structured chat session was first . In accordance with the structure provided by the Lead Line script , groups in those sessions were more likely to discuss the requirements for the job earlier in the session , devoted more chat messages per person to discussing each candidate’s traits , and focused on one candidate at a time . Self - report responses After each chat session , participants answered a questionnaire geared toward assessing a ) how easy they found the program to use , b ) how confusing they found the chat discussion , c ) how much the program helped them accomplish their goals , and d ) how much they enjoyed the chat discussion . The questionnaire used a 7 - point Likert scale . Participants responses were reverse - coded as needed , aggregated at the individual level along the above four dimensions , and then aggregated at the group level . Groups reported finding both the regular chat program ( M = 6 . 5 , SD = . 42 ) and the structured chat program ( M = 6 . 5 , SD = . 58 ) very easy to use . ( Note that respondents used a seven - point scale , where 1 = not at all easy and 7 = very easy . ) There were no significant differences in ease of use between the two types of chat interactions , and the order of the interactions had no effect . Figure 9 People were more confused during regular chat discussions when the regular chat session was first . Error bars represent standard errors . A comparison of the first chat sessions shows that people were more confused in the first regular chat session than in the first structured chat session ( t ( 17 ) = 2 . 55 , p < . 03 ) . A repeated measures ANOVA shows a significant within - subjects effect of type of chat session ( F ( 1 , 17 ) = 7 . 89 , p < . 02 ) . However , as can be seen from Figure 9 , this effect is due primarily to the greater levels of confusion felt by those Recalling Candidate Traits 0 . 5 1 1 . 5 E rr o r i n C a nd i d a t e R a t i n g s Regular Structured Type of Chat Session Regular Chat 1st Structured Chat 1st Changing Topic of Discussion 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 R a t e o f T o p i c C h a n g e Regular Structured Type of Chat Session Regular Chat 1st Structured Chat 1st Confusion during Chat Session Discussions 0 0 . 5 1 1 . 5 2 2 . 5 3 3 . 5 R a t i n g o f C o n f u s i o n Regular Structured Type of Chat Session Regular Chat 1st Structured Chat 1st in the regular chat session when they completed the regular chat session first . The order by chat session interaction effect is significant ( F ( 1 , 17 ) = 13 . 78 , p < . 005 ) . Groups generally rated both the regular chat session ( M = 5 . 7 , SD = . 72 ) and the structured chat session ( M = 5 . 7 , SD = . 70 ) as helping them accomplish their goals . ( Note that participants used a 7 - point scale , where 1 = not at all helpful , and 7 = very helpful ) . Groups did not indicate finding the structured chat session more or less helpful than the regular chat session . Groups generally reported finding the second chat session more effective than the first chat session ( F ( 1 , 17 ) = 3 . 86 , p < . 07 ) . When asked how much they enjoyed the chat discussions , again we found that people were somewhat positive in their evaluations of both the regular chat session ( M = 5 . 7 , SD = . 70 ) and the structured chat session ( M = 5 . 6 , SD = . 65 ) . However , there was no significant difference between the two session types . Groups generally found their second discussions much more enjoyable than their first discussions ( F ( 1 , 17 ) = 30 . 44 , p < . 001 ) . In general , people enjoyed their chat discussions and found the Lead Line program easy to use in both the regular and the structured chat sessions . They did not indicate finding the structured chat session more helpful in accomplishing their goals , but did report finding the discussion in the regular chat session more confusing . Open - ended comments After each chat session we asked study participants to provide overall comments . Consistent with the closed - ended questionnaire data , people reported finding the program in both sessions very easy to use . Of more interest , following the structured chat session , almost half of the participants spontaneously commented on the guidance provided by the program’s script . These comments indicated that participants had a clear understanding of the purpose of the structured chat session , although the favorability of the comments was mixed . There were twenty - two comments in favor of the guidance provided in the structured chat session . The following are several typical comments . “I could definitely see how this would be a useful tool for keeping a discussion on task while sticking with the typical chat software format . ” “I like the ‘guidance’ . It helped us stay focused and moved us along . ” “The addition of instructions helped lead us and pace the session . ” “Very well organized . I could follow the discussion easily . ” There were eight comments that were not in favor of the structure that was provided . The comments against the structure tended to focus on the time - constraints it imposed . “The instructions are bothersome and put one under time pressure . ” “Time limited discussions are not appealing . ” There were only a few comments regarding the lack of structure in the regular chat session . However , a few people indicated that they appreciated being free of interruptions and time constraints , and felt that the conversation flowed more naturally . Only one person who used the regular chat after the structured chat showed an awareness of having used procedures learned in the structured chat session . “We used this program [ the same ] as our last session . By this time we had the process figured out and were comfortable with each other . ” CONCLUSIONS The current research shows that , when employed judiciously , a structured chat environment will improve the decision - making outcomes of a discussion group . Groups followed the structure provided to them in the structured chat sessions , and the structure had a significant impact on the groups’ ability to achieve consensus and make higher quality decisions . However , it is important to note that the impact of any structured social interaction will rely heavily on the quality of the script itself . In open - ended responses to the chat sessions , people recognized the value of the guidance provided by the structured script . However , they also found the time constraints imposed by Lead Line restricting , and felt the script messages interrupted the natural flow of the conversation . A possible solution to such feelings of constraint is to allow group members to advance scenes at their own pace . Currently , Lead Line allows authors to write user - driven scene advancements into scripts . In examining the impact of order of chat session type on level of consensus and quality of decision - making we found a strong order effect . An examination of the procedures followed during the chat sessions suggests that once groups learned to structure their discussions in the structured chat session , they applied that structure to the subsequent regular chat sessions . In the regular chat sessions that followed the structured chat session , groups a ) were more likely to discuss the important skills for the job early in the session , b ) focused on the candidates one at a time , c ) had more discussion of each candidate , and d ) ranked the candidates at the end of the discussion . Groups learned how to structure the decision - making task in the first session , and applied that structure to their second session . As a consequence , similar to the structured chat sessions , groups were more likely to achieve consensus , made higher quality decisions , were less confused , and showed a greater recall of candidate traits when the regular chat session followed the structured chat session . Past research has shown that computer - mediated discussion groups have greater difficulty reaching consensus than face - to - face discussion groups [ 10 , 24 ] , and some researchers have suggested this may be due to the lack of leadership found in computer - mediated discussion groups [ 18 , 24 ] . The present research indicates that the guidance provided by a structured script may help groups overcome the naturally occurring deficiencies in online leadership . A structured interaction will have the greatest impact early in the history of a group , before it develops its own decision - making procedures and interpersonal style . REFERENCES 1 . Agostini , A . , De Michelis , G . , and Grasso , M . A . Rethinking CSCW systems : The architecture of Milano . ECSCW , 1997 . 2 . Bray , T . , Paoili , J . , and Sperberg - McQueen , C . M ( eds . ) . E xtensible Markup Language ( XML ) 1 . 0 , World Wide Web Consortium Recommendation , 1998 . 3 . Brown , J . and Isaacs , D . Building Corporations as Communities : Merging the Best of Two Worlds . Community Building : Renewing Spirit and Learning in Business . New Leaders Press , San Francisco , 1995 . 4 . Brown , J . , and Isaacs , D . Welcome to the World Café . 1998 . http : / / www . theworldcafe . com . 5 . Cao , P . , and Burstein , F . An Asynchronous Group Decision Support System Study for Intelligent Multicriteria Decision Making . Hawaii Conference on System Sciences , IEEE , 1999 . 6 . Chan , P . , and Lee , R . The Java Class Libraries ( Second Edition , Volume 2 ) . Addison - Wesley , 1997 . 7 . DeSanctis , G . , and Monge , P . Communication Processes for Virtual Organizations . Journal of Computer Mediated Communication , 3 ( 4 ) , 1998 . 8 . Flores F . , Graves , M . , Hartfield , B . and Winograd , T . Computer Systems and the Design of Organizational Interaction . ACM , 1988 . 9 . Gosling , J . , Joy , B . , and Steele , G . The Java Language Specification . Addison - Wesley , 1996 . 10 . Hiltz , S . , Johnson , K . , and Turoff , M . Experiments in Group Decision Making : Communication Process and Outcome in Face - to - Face Versus Computerized Conferences . Human Communication Research , 13 , 225 - 252 , 1986 . 11 . Maier , N . Assets and Liabilities in Group Problem Solving : The Need for an Integrative Function . Psychological Review , 74 , 239 - 249 , 1967 . 12 . Mark , G . , Grudin , J . , and Poltrock , S . Meeting at the Desktop : An Empirical Study of Virtually Collocated Teams . Proceedings of the Sixth European Conference on Computer - Supported Cooperative Work , Copenhagen , Denmark , 1999 . 13 . McGrath , J . , and Berdahl , J . Groups , Technology , and Time : use of Computers for Collaborative Work . In Tindale , R . S . ( Ed . ) Theory and Research on Small Groups . New York , Plenum Press , 1998 . 14 . Nunamaker , J . F . , Briggs , R . , Mittleman , D . , and Vogel , E . Lessons from a Dozen Years of Group Support Systems Research : A Discussion of Lab and Field Findings . http : / / www . groupsystems . com / dozen . pdf . 2000 . 15 . Nunamaker , J . F . , Dennis , A . , Valacich , J . , Vogel , D . , and George , J . Electronic Meeting Systems to Support Group Work . Communications of the ACM , 1991 . 16 . Oikarinen , J . and Reed , D . Internet Relay Chat Protocol . Internet RFC # 1459 . May 1993 . 17 . Owen , H . Open Space Technology . Berrett - Koehler , San Francisco , 1997 . 18 . Rice , R . E . Mediated Group Communication . The New Media . Sage Publications , Beverly Hills : CA , 1984 . 19 . Richmond , B . The Strategic Forum : Aligning Objectives , Strategy and Process . Systems Dynamics Review 13 , no . 2 ( summer 1997 ) , 131 - 148 . 20 . Siegel , J . , Dubrovsky , V . , Kiesler , S . , and McGuire , T . Group Processes in Computer - Mediated Communication . Organization Behavior and Human Decision Processes , 37 , 157 - 187 , 1986 . 21 . Sproull , L . , and Kiesler , S . Connections : New Ways of Working in the Networked Organization . The MIT Press , Cambridge : MA , 1991 . 22 . Straus , S . G . , McGrath , J . Does the Medium Matter ? The Interaction of Task Type and Technology on Group Performance and Member Reactions . Journal of Applied Psychology , 79 , 87 - 97 , 1994 . 23 . Viller , S . The Group Facilitator : A CSCW Perspective . Proceedings of the Second European Conference on Computer - Supported Cooperative Work , Amsterdam , 1991 . 24 . Walther , J . B . Computer - mediated Communication : Impersonal , Interpersonal , and Hyperpersonal Interaction . Communication Research , 23 , 3 - 43 , 1996 . 25 . Zander , A . Making Groups Effective ( 2 nd Edition ) . San Francisco , Jossey - Bass Publishers , 1994 . 26 . Weisbord , M . , and Janoff , S . . Future Search . Berrett - Koehler , San Francisco , 199