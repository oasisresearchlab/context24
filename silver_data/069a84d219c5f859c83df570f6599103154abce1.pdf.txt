UNIVERSITY COLLEGE LONDON Designing for Cross - Device Interactions by Frederik Martin Brudy A THESIS SUBMITTED IN PARTIAL FULFILMENT OF THE REQUIREMENTS FOR THE DEGREE OF DOCTOR OF PHILOSOPHY OF UNIVERSITY COLLEGE LONDON ( UCL ) UCL INTERACTION CENTRE DEPARTMENT OF COMPUTER SCIENCE LONDON , UNITED KINGDOM © Frederik Brudy 2019 - 3 - Author : Frederik Brudy , University College London Institution : University College London , UCL Interaction Centre , London , UK 1 st Supervisor : Associate Professor Dr . Nicolai Marquardt , University College London 2 nd Supervisor : Professor Dr . Yvonne Rogers , University College London Examiners : Associate Professor Dr . Catherine Holloway , University College London and Associate Professor Dr . Andrés Lucero , Aalto University , Finland Submitted November 2019 and viva examination January 2020 - 5 - I , Frederik Brudy , confirm that the work presented in this thesis is my own . Where information has been derived from other sources , I confirm that this has been indicated in the thesis . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ - 7 - Abstract Driven by technological advancements , we now own and operate an ever - growing number of digital devices , leading to an increased amount of digital data we produce , use , and maintain . However , while there is a substantial increase in computing power and availability of devices and data , many tasks we conduct with our devices are not well connected across multiple devices . We conduct our tasks sequentially instead of in parallel , while collaborative work across multiple devices is cumbersome to set up or simply not possible . To address these limitations , this thesis is concerned with cross - device computing . In particular it aims to conceptualise , prototype , and study interactions in cross - device computing . This thesis contributes to the field of Human - Computer Interaction ( HCI ) — and more specifically to the area of cross - device computing — in three ways : first , this work conceptualises previous work through a taxonomy of cross - device computing resulting in an in - depth understanding of the field , that identifies underexplored research areas , enabling the transfer of key insights into the design of interaction techniques . Second , three case studies were conducted that show how cross - device interactions can support curation work as well as augment users ’ existing devices for individual and collaborative work . These case studies incorporate novel interaction techniques for supporting cross - device work . Third , through studying cross - device interactions and group collaboration , this thesis provides insights into how researchers can understand and evaluate multi - and cross - device interactions for individual and collaborative work . We provide a visualization and querying tool that facilitates interaction analysis of spatial measures and video recordings to facilitate such evaluations of cross - device work . Overall , the work in this thesis advances the field of cross - device computing with its taxonomy guiding research directions , novel interaction techniques and case studies demonstrating cross - device interactions for curation , and insights into and tools for effective evaluation of cross - device systems . - 9 - Impact Statement This thesis can have an impact within academia as well as industry . The cross - device taxonomy described in Chapter 4 provides an extensive overview of the field of cross - device computing research , that enables researchers and developers to frame existing and future work . It also points to underexplored and future directions of research . It synthesises an entire research field that provides a forum and foundation for discussion for the wider area of HCI . The dataset that was created as part of the taxonomy was released as open source that can also be used to foster further research within this area — highlighting how the state of the field has changed . The tools described in Part II of this thesis show how multi - and cross - device interactions can be leveraged for knowledge work in different areas such as curation . The proposed systems each have novel aspects that have not been explored before ( e . g . instrumental interaction for cross - device work and cross - device interaction using tangible tools that allow blending of digital and physical artefacts and tools ) . The findings from each study provide new insights into people ’ s understanding of instrumental interaction techniques , dynamics during curation tasks , as well as design requirements of interaction techniques for curation work . Further , the video analysis tool that was developed as part of the research — described in Chapter 9 — has been released as open source to enable researchers to conduct interaction analysis with greater ease . In terms of studying and understanding multi - and cross - device interaction scenarios , the coding scheme and collaboration styles described in Chapter 8 offer a new way of conceptualising group collaborations in multi - and cross - device scenarios . My research is already having an impact as evidenced by my citation count of over 500 and an h - index of 6 . Five peer reviewed full papers have been published at the time of thesis submission , disseminating this work to a wider academic and industrial audience ( see page 11 for a list of publications ) . This thesis can also have a strong industrial impact . People now own an increasing number of devices , and this number is expected to further increase . One of the big - 10 - issues of this is “how do our devices interoperat e in meaningful ways ? ” . Many attempts are already materialising , for example in Microsoft ’ s cross - device clipboard or multi - screen laptop ( Surface Neo ) or Apple ’ s Continuity and Sidecar features that allows users to pick up work on a different device to the one they have been using or to use an iPad as a second screen to a laptop . But this is only the beginning and many more cross - device functionalities will emerge over the next years . The research reported here is also highly relevant for both hardware and software development . Many companies have begun to actively extend cross - device functionality — and the research in this thesis can have a direct impact on how this can evolve . In particular , the cross - device taxonomy can help industry leaders to more easily get accustomed with the field of cross - device research without investing countless hours . Further , the findings from studying the tools reported in Part II can spark discussions and thinking points during development . The video analysis tool described in Part III could be of benefit for industry as well — either by enabling researchers to use it directly or to help companies develop their own in - house solutions . User experience research is crucial for any technology company , and while industrial research is likely to have more financial power in conducting such studies than academia , any way of reducing the time needed for analysis is welcomed . - 11 - Publications My research has been disseminated through the publications presented here . [ P . 5 ] Frederik Brudy , Christian Holz , Roman Rädle , Chi - Jui Wu , Steven Houben , Clemens Nylandsted Klokmose , Nicolai Marquardt . Cross - Device Taxonomy : Survey , Opportunities and Challenges of Interactions Spanning Across Multiple Devices . In Proceedings of the ACM Conference on Human Factors in Computing Systems 2019 ( CHI ‘ 19 ) . [ P . 4 ] Frederik Brudy , Suppachai Suwanwatcharachat , Wenyu Zhang , Steven Houben , and Nicolai Marquardt . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions of People and Devices . In Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces ( ISS ‘ 18 ) . Best Paper Honourable Mention Award ( top 5 % ) . [ P . 3 ] Frederik Brudy , Joshua Kevin Budiman , Steven Houben , Nicolai Marquardt . Investigating the Role of an Overview Device in Multi - Device Collaboration . In Proceedings of the ACM Conference on Human Factors in Computing Systems 2018 ( CHI ‘ 18 ) , April 21 – 26 , 2018 , Montreal , QC , Canada . [ P . 2 ] Nicolai Marquardt , Frederik Brudy , Can Liu , Benedikt Bengler , Christian Holz . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Reconfigurable Cross - Device Workspaces . In Proceedings of the ACM Conference on Human Factors in Computing Systems 2018 ( CHI ‘ 18 ) , April 21 – 26 , 2018 , Montreal , QC , Canada . [ P . 1 ] Frederik Brudy , Steven Houben , Nicolai Marquardt , Yvonne Rogers . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction . In Proceedings of the ACM Conference on Interactive Surfaces and Spaces 2016 ( ISS ‘ 16 ) , November 06 - 09 , 2016 , Niagara Falls , ON , Canada . - 12 - Extended Abstracts of Peer Reviewed Late - Breaking Work , Demonstrations , and Doctoral Symposium [ EA . 2 ] Nicolai Marquardt , Frederik Brudy , Can Liu , Ben Bengler , and Christian Holz . SurfaceConstellation Applications : Use Cases of Ad hoc Reconfigurable Cross - Device Workspaces . In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems ( CHI EA ‘ 18 ) . April 21 – 26 , 2018 , Montreal , QC , Canada . [ EA . 1 ] Frederik Brudy . Designing Ad hoc Cross - Device Collaborations for Small Groups . In Proceedings of the ACM International Conference on Interactive Tabletops & Surfaces 2015 ( ITS 2015 ) , November 15 - 18 , 2015 , Madeira , Portugal . Attendance of the ITS Doctoral Symposium Workshop Submissions [ W . 3 ] Frederik Brudy , Nicolai Marquardt . The Tabletop is Dead ? - Long Live the Table ’ s Top ! In ISS 2017 workshop “The Disappearing Tabletop - Social and Technical Challenges for Cross - Surface Collaboration” collocated with the ACM Conference on Interactive Surfaces and Spaces ( ISS 2017 ) , October 17 - 20 , 2017 , Brighton , United Kingdom [ W . 2 ] Frederik Brudy , Nicolai Marquardt , Yvonne Rogers , Abigail Sellen , Kenton O ’ Hara . The Challenges of Using an Existing Cross - Device Interaction Prototype for Supporting Actual Curation Practices . In CHI 2016 workshop “Cross - Surface 2016 , the second international workshop on interacting with multi - device ecologies ‘ in the wild ’” , collocated with the ACM Conference on Human Factors in Computing Systems ( CHI 2016 ) , May 7 – 12 , 2016 , San Jose , CA , USA [ W . 1 ] Frederik Brudy , Nicolai Marquardt , Hans - Christian Jetter , Steven Houben , Abigail Sellen , Yvonne Rogers . Supporting Collaborative Curation of Historic Documents with Mobile Ad Hoc Cross - Device Interactions . In CHI 2015 workshop on “Mobile Collocated Interactions - From Smartphones to Wearables” collocated with the ACM Conference on Human Factors in Computing Systems ( CHI 2015 ) , April 18 – 23 , 2015 , Seoul , Korea Co - authored papers that have been published during the PhD studies but are not part of this thesis : [ O . 2 ] Léa Saviot , Frederik Brudy , Steven Houben . WRISTBAND . IO : Expanding Input and Output Spaces of a Smartwatch . In CHI 2017 Extended Abstracts ( Late Breaking Work ) . ACM Conference on Human Factors in Computing Systems ( CHI 2017 ) , May 6 - 11 , 2017 , Denver , CO , USA . [ O . 1 ] Zuzana Lechelt , Yvonne Rogers , Nicolai Marquardt , Frederik Brudy . MakeMe , codeme , connectus : Learning digital fluency through tangible magic cubes . Proceedings of the 3rd European Tangible Interaction Studio ( ETIS 2017 ) . - 15 - Acknowledgments First and foremost , I would like to express my deepest gratitude to my supervisors : My first supervisor Nicolai Marquardt for being supportive , inspiring , patient , and for guiding me through this journey . Nic , I have learned more than I could have hoped for from you . From how to generate ideas , create sketches , ask the right questions , to redefining my approach to writing , and a better approach to teaching and supervising students : I tremendously enjoyed being your PhD student . Your support — during both good and more difficult times — assured me that I was not alone in my journey . Thank you for believing in me ! I would also like to give a huge Thank You to my second supervisor Yvonne Rogers for challenging me to think outside the box and making me see beyond my horizon when I got fixed on an idea . Yvonne , thank you for always making time in your busy schedule , supporting me when I needed the support , and challenging me when I got stuck . Secondly , I would like to extend my gratitude to Microsoft Research Cambridge who has supported my work through its PhD Scholarship Programme . Especially Abigail Sellen and Kenton O ’ Hara who have contributed to shaping my research : Thank you ! I further would like to thank Nicolas Gold and Ann Blandford for being the examiners on my first - year report and upgrade report respectively . Challenging at the time , both experiences helped me shape my work and ultimately allowed me to write a better thesis . Also Thank You to Catherine Holloway and Andrés Lucero for agreeing to be examining my PhD viva . Thank You to Steven Houben for countless conversations , challenging questions , and supportive and fun collaborations ! Thank You to everyone at the UCL Interaction Centre for being amazing colleagues and friends . While over the years people have changed , it is and has been a great place to work . Lunchtime conversations , dinner discussions , tea break support , donut Fridays , and more : It would not have been the same time ! - 16 - No PhD thesis in HCI could be complete without studies and no study would be complete without participants . I am immensely grateful for all the participants of my studies . Without no contributions would have been possible . Thank You ! Most importantly however I would like to thank my family . My parents , who have supported me throughout my entire education and career , my siblings for listening and supporting me , and my partner who has been more than patient , supportive , and understanding . Thank you ! - 17 - Contents Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Impact Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 List of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Chapter 1 . Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Overview and Structure of Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Part I : Theory of Cross - Device Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Part II : Case Studies of Cross - Device Interactions for Knowledge Work . . . . . . . . . . . . . . 34 Part III : Studying Cross - Device Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Chapter 2 . Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Part I : Theory of Cross - Device Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 Chapter 3 . Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 Ubiquitous Computing and Cross - Device Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 Group Collaboration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 3 . 2 . 1 Shared Digital Spaces for Group Collaboration : Tabletop and Wall Displays 60 3 . 2 . 2 From Large Displays to Cross - Device . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 3 . 2 . 3 Multi - device Environments for Individual and Collocated Sensemaking . . . 63 Knowledge Work and Curation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 3 . 3 . 1 Collaborative Decision - Making and Sensemaking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 3 . 3 . 2 Sensemaking on Large Surfaces and across Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 3 . 3 . 3 Curation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 Chapter 4 . Cross - Device Taxonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 - 18 - History and Unifying Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 4 . 1 . 1 Three Areas of Cross - Device Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 4 . 1 . 2 Towards Unified Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 Taxonomy of Key Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 2 . 1 Dimension 1 : Temporal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 2 . 2 Dimension 2 : Configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 2 . 3 Dimension 3 : Relationship . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 2 . 4 Dimension 4 : Scale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 4 . 2 . 5 Dimension 5 : Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 4 . 2 . 6 Dimension 6 : Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Application Domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Tracking Systems for Cross - Device Interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 Interaction Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 4 . 5 . 1 Phases of Cross - Device Interaction Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 4 . 5 . 2 Visualisation and Cross - Device Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94 Evaluation Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 4 . 6 . 1 Evaluation Methods Used . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 4 . 6 . 2 Studying Cross - Device Interactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 Key Challenges and Research Agenda . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 4 . 7 . 1 Bridging the Gap between Studies and Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 4 . 7 . 2 Conveying Cross - Device Interaction Capabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 4 . 7 . 3 Mitigating the Effects of Legacy Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 4 . 7 . 4 Addressing Social Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 4 . 7 . 5 Enabling Proactive Cross - Device Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 4 . 7 . 6 Building and Deploying Cross - Device Systems In the Wild . . . . . . . . . . . . . . . . . . . . . . . . . 101 4 . 7 . 7 Improving Tracking Technology and Infrastructure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 4 . 7 . 8 Bespoke Solutions vs . Platforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 4 . 7 . 9 Towards a Symbiosis between Cross - Device Capabilities and Human Activities 102 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 Part II : Case Studies of Cross - Device Tools for Knowledge Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 Chapter 5 . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 Cross - Device Interactions for Content Curation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 Instrumental Interaction for Smartwatches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110 Wrist - based Interactions and Smartwatches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 Scenario Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 CurationSpace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 5 . 5 . 1 CurationSpace Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 5 . 5 . 2 General interaction with CurationSpace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 5 . 5 . 3 Technical implementation of CurationSpace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 5 . 5 . 4 CurationSpace Instruments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 Interaction Techniques for Curation Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 5 . 6 . 1 Creating Documents and Adding Content into Fragments . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 5 . 6 . 2 Manipulate and Organise Documents and Fragments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 5 . 6 . 3 Share Access to a Document with other Users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 5 . 6 . 4 Edit Content , Documents , and Fragments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 5 . 6 . 5 Erase to Delete Content , Fragments , and Documents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 5 . 6 . 6 The Watch as a Clipboard and Document Repository . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124 User Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124 5 . 7 . 1 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 5 . 7 . 2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126 Discussion and Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 Chapter 6 . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Digital and Physical Artefacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 Related Work : Tangible Interactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 Fundamental Curation Activities Informed by Interviews with Curators . . . . . . . . . . 135 6 . 2 . 1 F1 | Expert Selection : Curators are Expert Selectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 6 . 2 . 2 F2 | Physical + Digital : Curators Handle Diverse Types of Both Digital Information and Physical Artefacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138 6 . 2 . 3 F3 | Digital Surrogates : Curators Frequently Work with Digital Representation of Curation Artefacts Rather Than the Physical Artefact . . . . . . . . . . . . . . 138 6 . 2 . 4 F4 | Multiple Views and Juxtaposition : Curators Analyse Content and Find Insights Through Different Views on the same Artefacts Through Juxtaposing , Comparing , and Grouping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 6 . 2 . 5 F5 | Metadata and Tags : Curation Includes Annotating Information with Metadata , such as Time , Location , and Descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140 6 . 2 . 6 F6 | Overviews and Colour Coding : Curators Use Visual Representations of Artefacts and Colour Coding for their Curation Activities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 6 . 2 . 7 F7 | Diverse Sharing : Curators Share and Present Information in Diverse Representations to Collaborators and Audiences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142 6 . 2 . 8 F8 | Ad hoc Workspaces : Curators Work in Ad hoc Heterogeneous Work Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142 CurationLens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143 6 . 3 . 1 Running example : “The Collection of HCI Interaction Devices” . . . . . . . . . . . . . . 144 6 . 3 . 2 General interaction with CurationLens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 Tools Supporting Key Curation Activities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 6 . 4 . 1 CurationArranger . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 6 . 4 . 2 CurationSnapper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 6 . 4 . 3 CurationProjector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 6 . 4 . 4 CurationTwirler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 6 . 4 . 5 CurationBuzzer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 - 20 - Technical Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 Discussion of Heuristic Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 6 . 6 . 1 Importance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154 6 . 6 . 2 Generality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154 6 . 6 . 3 Flexibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155 6 . 6 . 4 Expressive match . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155 6 . 6 . 5 Scale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 Chapter 7 . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Reconfigurable Cross - Device Workspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159 Bridging the Gap Between Multi - Monitor Setups and Ad hoc Cross - Device - Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 SurfaceConstellations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 7 . 2 . 1 Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 7 . 2 . 2 Design Space Taxonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 7 . 2 . 3 Design Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166 7 . 2 . 4 Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167 7 . 2 . 5 Creating 3D - Printed Modular Brackets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168 7 . 2 . 6 Weight - Balancing and Support Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171 Setting up SurfaceConstellation Workspaces : Configurator GUI Tool . . . . . . . . . . . . . . . . . . . . 172 Developing Software and Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175 7 . 4 . 1 Software Connectivity and Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175 7 . 4 . 2 Available Information about Setup and Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177 Four Example Applications Across the Surface - Constellations Design Space . . . . . . . . 177 7 . 5 . 1 Application 1 : Trading Desk for Financial Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178 7 . 5 . 2 Application 2 : Hybrid Setup for Visual Analytics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 7 . 5 . 3 Application 3 : Audio - Track Mixing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182 7 . 5 . 4 Application 4 : Bridge Setup for Two - player Board Games . . . . . . . . . . . . . . . . . . . . . . . . . 184 Reflecting of SurfaceConstellations’ Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185 7 . 6 . 1 Semi - Fixed vs . Mobile Cross - Device Setups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185 7 . 6 . 2 Roles of Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185 7 . 6 . 3 Interaction Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186 7 . 6 . 4 Cross - Device Applications for the Masses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186 Part III : Studying and Evaluating Cross - Device Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189 Chapter 8 . Investigating the Role of an Overview Device in Multi - Device Collaboration 191 Cross - Device Interactions for a BYOD scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192 Voyageur : Collaborative Trip Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194 8 . 2 . 1 Voyageur Implementation and Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195 8 . 2 . 2 Sensemaking Tasks for Trip Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 8 . 3 . 1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 8 . 3 . 2 Study Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199 8 . 3 . 3 Apparatus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199 8 . 3 . 4 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201 8 . 4 . 1 Theme 1 : Information Organisation Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201 8 . 4 . 2 Theme 2 : Applying the Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204 8 . 4 . 3 Theme 3 : Collaboration Styles ( F3 , F5 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205 8 . 4 . 4 Territorial Behaviour ( F6 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209 User Feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211 8 . 6 . 1 Space and Focus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212 8 . 6 . 2 Decision - Making and Sensemaking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 8 . 6 . 3 Limitations and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215 Chapter 9 . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions of People and Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217 Interaction Analysis in Ubicomp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218 Prior Work on Interaction Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220 9 . 2 . 1 Interaction Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220 9 . 2 . 2 Systems Supporting Interaction Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220 9 . 2 . 3 Visualisation Tools for Video Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222 Scenario Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222 EagleView Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223 Technical Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225 Real - time and Overview Visualisations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226 9 . 6 . 1 Real - Time Visualisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226 9 . 6 . 2 Aggregated Overview Visualisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229 EagleView Search - Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230 9 . 7 . 1 Search - Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230 9 . 7 . 2 Query Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231 9 . 7 . 3 Compound Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 Chapter 10 . Discussion and Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237 Answering the Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238 10 . 1 . 1 Developing a Framework and Extensive Literature Review of the Body of Work Conducted in the Area of Cross - Device Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238 10 . 1 . 2 Case Studies of Cross - Device Tools for Knowledge Work . . . . . . . . . . . . . . . . . . . . . . . . . 241 10 . 1 . 3 Studying and Evaluating Cross - Device Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244 - 22 - Directions for Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245 10 . 2 . 1 Disengagement of Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246 10 . 2 . 2 Remote vs . Collocated Collaborations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246 10 . 2 . 3 In the wild Deployments of Cross - Device Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249 - 23 - List of Tables Table 1 . Reinhardt et al . ’s topology of knowledge actions . Table from ( Reinhardt et al . 2011 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 Table 2 . Cross - device application domains : Nine application categories ( and sub categories ) with examples use cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86 Table 3 . Tracking characteristics and modalities of the cross - device papers with tracking as a main contribution . Our tracking classification directly relates to surveys of tracking technologies in ubicomp ( Hon et al . 2015 ; Hightower and Borriello 2001 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 Table 4 . Overview of interaction techniques for cross - device computing . . . . . . . . . . . . . . . . . . . . . . . . 89 Table 5 . Cross - device visualisation and management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 Table 6 . Evaluation methods used in our corpus ( in round brackets are the number of papers employing each strategy ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 Table 7 . Overview of the interviewed curators , their work environments , tasks and duties ( V = curator in volunteer - driven historic society ; C = curator in professional environment ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 Table 8 . CurationLens ’s interaction tools and the curation activities they address , and which of our findings informed them . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146 Table 9 . Overview of use - case applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178 Table 10 . Main findings ( F1 - F6 ) and their connection to the 5 focus points ( FP1 - FP5 ) of our study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199 Table 11 . The groups’ activities . * = These groups’ leader had an overall less dominant role compared to NO groups . * * = Because the group filtered their locations before sharing them , a cleanup was not needed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202 Table 12 . Average number of executed commands per group in each condition and average total number of all commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204 - 24 - List of Figures Figure 1 . The structure of this thesis divided into the three parts : Part I ) Background ; Part II ) Three case studies ; Part III ) Studying and understanding dynamics of cross - device interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Figure 2 . Chapter structure of Part I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Figure 3 . Chapter structure of Part II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 Figure 4 . Chapter structure of Part III . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Figure 5 . Overview of the conducted research , separated into the stages of the extended user - centred iterative design process of Harper et al . ( Harper et al . 2008 ) . . . . . . . . . . . . . . 38 Figure 6 . Screenshot of the web - based tagging system showing the overview with assigned papers and links to quickly access the full paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 Figure 7 . Screenshot of the detail - view of the tagging system , showing the first set of fields available . Some free - text entry and some with clickable tags . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Figure 10 . The curation - task - cycle consists of the three main curation tasks : select , review , and present , each of them consisting of a subset of tasks . The result of one cycle feeds into another curation cycle as input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 Figure 11 . Research context of this research project . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 Figure 12 . Ontology of cross - device research terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 Figure 13 . Taxonomy of cross - device design space dimensions : temporal , configuration , relationship , scale , dynamics , and space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 Figure 14 . CurationSpace provides a shared collaboration space for content curation based on instrumental interactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 Figure 15 . Using the implicitly selected create instrument ( left ) a user creates a new document on the interaction space ( right ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 Figure 16 . The smartwatch acts as a personal content repository ( inlay top ) , allowing users to share their personal data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 Figure 17 . Using the increase instrument . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 Figure 18 . Using the colour instrument , the user can set the paint of his drawings or change the colour of text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 Figure 19 . The erase instrument can be used to erase drawings on a canvas or image ( top ) and to erase documents ( bottom ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 Figure 20 . Results of the 5 - point - Likert - scale of all 8 participants to the post - study questionnaire about CurationSpace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126 Figure 21 . Heatmap of participants’ touch patterns on the shared space , showing the main interaction zones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 Figure 22 . Example view of CurationLens web application : arrangement , objects and metadata editor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 Figure 23 . CurationArranger for rapid , ad hoc access to different arrangements of curated objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 Figure 24 . CurationSnapper for capturing physical artefacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 Figure 25 . CurationProjector allows the display of a digital curation arrangement directly in workspace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 Figure 26 . CurationTwirler for crossfading objects and skimming through collections . . . 151 Figure 27 . CurationBuzzer for temporary , ad hoc sharing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152 Figure 28 . The modular SurfaceConstellations platform enables creation of spatial cross - device workstation setups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 Figure 29 . Basic SurfaceConstellation bracket design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 Figure 30 . SurfaceConstellation design space taxonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165 Figure 31 . System design parameters ( green shades cover the cases supported by our implementation ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165 Figure 32 . 3D - printed bracket design and design parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 Figure 33 . ( a ) OpenSCAD parametric bracket design and ( b ) code view , ( c ) MakerBot Customizer view , with sliders on the left side to adjust parameters ( e . g . device thickness , angle ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 Figure 34 . Library of bracket base designs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170 Figure 35 . Weight balancing and support extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172 Figure 36 . Examples of support extensions for brackets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172 Figure 37 . GUI tool for creating customised workspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174 Figure 38 . Design characteristics for software running on SurfaceConstellation setups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 Figure 39 . Top : Financial trading - desk using eight 3D - printed brackets . Bottom : Alternative trading - desk setup using four different brackets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179 - 26 - Figure 40 . A new client connects to the local URL on the master device by scanning a QR code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180 Figure 41 . The position of a newly added device is configured through a manual configuration step : the user selects the device’s position from all possible new positions ( grey rectangles on bottom middle screen ) . Existing devices are shown in turquoise and identified through their number ID . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180 Figure 42 . Setup for visual analytics application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 Figure 43 . A phone is added to the setup by simply exchanging a 3D printed brackets for one that has an opening to hold the phone ( a + b ) . The software configuration of the newly added device is by simply selecting the newly added device’s position on the screen ( c ) . The phone displays an interface that controls the visualisations on the other devices ( d ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182 Figure 44 . Audio - track mixing setup . Left : ( a ) control 7 - channel level fader bank , ( b ) equaliser , and ( c ) metering . Right : The setup supports varying orientations of the tablets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 Figure 45 . A user controls the commercial Soundcraft Ui24R mixing system ( shown in the background and hosting the web application displayed on the tablet devices ) through three tablet devices . Two 3D - printed brackets are used to create the “mixing board” l ayout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 Figure 46 . Digital multi - player game , leveraging people’s existing devices . . . . . . . . . . . . . . . . . . . . . . 184 Figure 47 . Using a collaborative travel planning application scenario ( left ) , we study the effect of device configurations in a collocated multi - surface setting ( centre ) with three different conditions ( right ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193 Figure 48 . Comparison of the layouts for the study conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196 Figure 49 . Visualisation of the collaboration styles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206 Figure 50 . Shared attention on the overview device ( SSV ; left ) often led to active discussion ( AD ; right ) as the device gave the group a common focus and starting point for a discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207 Figure 51 . Left : P8 ( WO2 ) points toward overview device , other members shifted their attention to it . In NO groups pointing rarely led to shared attention ( right ) : P29 ( INT1 ) points toward her device ; other members’ focus stays on own devices . . 208 Figure 52 . Percentage of time spent in the different kinds of collaboration , by condition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209 Figure 53 . Results of answers to the post - study questionnaire , rating mental demand , temporal demand , effort , and frustration for groups without overview ( NO ) , overview displayed on everyone’s device ( INT ) , and overview on separate device ( WO ) . Likert scales from 1 ( very low ) to 10 ( very high ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211 Figure 54 . EagleView workflow with querying and visualisation techniques facilitating spatial interaction analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218 Figure 55 . EagleView’s user interface , showing the visualization panel with real - time visualizations , playback control , and different angled videos . On the right the analyst can change preferences and switch to a view , showing aggregated data . . . . . . . . . . . . . . . . 224 Figure 56 . Timeline with an overview of how the different components of EagleView support the video analysis workflow . The modularity and flexibility of EagleView’s tools allows analysts to use our visualisations and / or querying functions in any possible order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225 Figure 57 . The distance circle ( set to 0 . 5m ) and lines between P1 and P2 as well as the display are visible . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227 Figure 58 . The person’s movement of the previous 10 ( blue ) and next 15 seconds ( red ) is shown . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228 Figure 59 : Defined zones to observe ( red / green rectangles are defined areas ) . . . . . . . . . . . . . 228 Figure 60 : Person on the right is highlighted ( e . g . when facing an observed object , or another person ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228 Figure 61 . EagleView supports different conditions for attention grouping : a person facing a fixed object , two people facing each other , or when two people face the same fixed object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229 Figure 62 . Queries are created via a graphical user interface laid on top of a still video frame ( steps 1 - 3 ) . Queries can be combined to make up more specialised compound queries ( 4 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231 - 28 - List of Acronyms 3D Three dimensional BLE Bluetooth Low Energy BYOD Bring - Your - Own - Device CSCW Computer - supported cooperative work GT Grounded Theory GUI Graphical User Interface HCI Human - Computer Interaction iqr Inter - quartile range M Mean / average Md Median PC Personal Computer stdev Standard Deviation Ubicomp Ubiquitous Computing UI User Interface Introduction 29 Chapter 1 . Introduction Our interactions with computers have fundamentally changed in the last 30 years . Mark Weiser ’ s vision of ubiquitous computing ( ubicomp ) was that users could interact with the devices they have and that are in their surroundings through context - aware and ambient intelligence so that “ no one will notice [ the devices ’ ] presence ” ( Weiser 1991 ) . His seminal paper , published in 1991 , led to a large body of research into such multi - device usage and interactions that go beyond the one - person - one - device paradigm . Since then multi - device research has become an important part of the field of human - computer interaction ( HCI ) . However , instead of blending all devices together and trying to hide the boundaries between them , designers are rethinking Weiser ’ s original vision , to embrace and leverage the heterogeneity of devices and their “seams” ( Oulasvirta 2008 ; Chalmers and Galani 2004 ) — and in doing so ultimately creating an ecology of devices . Such device ecologies — i . e . groups of computing resources that are fixed and / or mobile and are aware of their social use , interactive capabilities , and / or spatial location ( Bødker and Klokmose 2012 ) — build the conceptual foundation of cross - device computing . Cross - device experiences however need to be purposefully built so that they can be used in the right place ( Rogers 2006 ) — in every meaning of the word place : physical , social , and temporal ( Buxton 2018 ) . Rather than just being fixed to a single place , through technological advancements , much of the cross - device research agenda in the past 30 years has been concerned with how to embed devices in everyday use setting , taking into account mobility , flexibility , and the ad hoc - ness of device ecologies and people . From smart - space , multi - display , distributed surface and multi - device , to cross - display , trans - surface , and cross - device interaction : research involving people ’ s interactions with various device configurations and ecologies has now become an area of growing prominence , being at the forefront of modern HCI research ( Bødker and Klokmose 2012 ; Dourish 2004 ; X . A . Chen et al . 2011 ; Greenberg et al . 2011 ; Raptis , Kjeldskov , and Skov 2016 ; Rogers et al . 2007 ; Beaudouin - Lafon 2000 ) . Introduction 30 However , this rapid growth has led to many disconnected concepts , terms , techniques , and approaches that has resulted in a fragmented research landscape . While technology has advanced and ubicomp has entered our everyday life , we still see many unsolved problems and fundamental open questions ( Raptis , Kjeldskov , and Skov 2016 ) . This thesis therefore begins by mapping the current state of cross - device computing research . Through the creation of a unified terminology and taxonomy for cross - device research this thesis frames the research agenda within the field of cross - device computing . It also provides a reflective discussion of the design space that identifies opportunities and challenges for cross - device research . The second part of this thesis presents three case studies of cross - device interactions for knowledge work — and more specifically for content curation activities . It demonstrates how the concept of instrumental interaction ( Beaudouin - Lafon 2000 ) can be leveraged for cross - device interactions ; how cross - device work can blend physical and digital artefacts in a scenario of curation work ; and demonstrates the versatility of cross - device setups . Several use case applications are then presented for connecting multiple devices in flexible physical workspace configurations . The last part is concerned with studying and understanding people ’ s interactions when using multiple devices . An empirical study explores different design choices influencing the dynamics of cross - device interactions and further contributes to a description of collaboration styles for cross - device work . Finally , through a novel interaction analysis tool , this thesis provides support for researchers to study and understand individual and collaborative cross - device work . Research Questions The work described in this thesis is guided by the following overarching research question : How can we leverage cross - device computing for designing new interactive systems in human - computer interaction ( HCI ) ? Since the overarching research question is exploratory , the following three research questions have been identified , addressing theory , tools , and evaluation . This thesis is divided into three parts , each corresponding to one of the three research questions . Introduction 31 RQ1 ( Theory ) : What is the current state of the field of cross - device computing and which challenges and opportunities exist ? This research question will build the theoretical foundations and a unified understanding of the domain of cross - device computing . The goal is to weave together the related but disparate threads of research — often described with diverse terminology — into one taxonomy that helps to inform and guide further research . This will conceptualise cross - device work and identify challenges and opportunities for future cross - device work . RQ2 ( Tools ) : How can we leverage cross - device principles to design tools for knowledge work ? This research question addresses the design and development of novel interaction techniques and tools that enable people to conduct knowledge work — and more specifically curation tasks . Informed by the outcomes and synthesis from RQ1 , the design of these tools uses a combination of people ’ s existing personal devices , large displays , and tangible tools with new ways of cross - and multi - device interactions . Through two case studies this thesis provides insights on how cross - device interactions can support the selecting , reviewing , and sharing ( curation ) of artefacts through instrumental interaction and blending of physical and digital artefacts . A third case study explores the design - space of spatial configurations using mobile devices and to enable cross - device work beyond curation activities . RQ3 ( Evaluation ) : How can we study and evaluate cross - device systems ? When designing cross - device interaction techniques and tools — such as the ones in Part II — researchers need to study how they are being used and whether they support an individual or group in accomplishing their tasks at hand through interaction analysis . Since such studies often involve multiple devices as well as multiple people , this research question will explore how collaborative cross - device scenarios can be studied and generally how they affect aspects of group collaboration . Further , this research question will explore how researchers can be supported in the interaction analysis of such study scenarios by means of data visualisation and automated tools . Introduction 32 Overview and Structure of Thesis In summary , the work in this thesis contributes a taxonomy of cross - device computing work to infer requirements and build new cross - device tools for knowledge work — and more specifically curation tasks . Insights into studying and understanding multi - and cross - device interactions are given , as well as a tool to support researchers ’ interaction analysis . This thesis is structured into three parts , each corresponding to one of the research questions : Part I ) understanding and taxonomy of cross - device computing ; Part II ) three case studies on designing cross - device interaction techniques ; Part III ) insights and tools for studying and understanding the dynamics of cross - device interaction and group collaboration . Before stepping into the three parts , however , Chapter 2 will first lay out the methodology used for the research conducted in this thesis . The individual studies will be discussed in detail in later chapters . While the write - up of the conducted work appears linear , the reality is that much of this work was conducted in parallel or overlapped in other parts . The research studies influenced each other and the findings of one project might have influenced the design of one or multiple other projects . Figure 1 shows a visual overview of the following chapters . The reason for presenting the methodology ( Chapter 2 ) before the related work is that the taxonomy ( Chapter 4 ) presents an extended systematic literature review and is therefore best situated after the general related work in Chapter 3 . Figure 1 . The structure of this thesis divided into the three parts : Part I ) Background ; Part II ) Three case studies ; Part III ) Studying and understanding dynamics of cross - device interaction . Introduction 33 Part I : Theory of Cross - Device Interaction Part I of this thesis is concerned with relevant prior work conducted in the areas of ubiquitous computing , group collaboration , and knowledge work and curation . It comprises Chapter 3 and Chapter 4 as shown in Figure 2 . Figure 2 . Chapter structure of Part I Chapter 3 describes relevant previous research on ubiquitous computing and briefly introduces the domain of cross - device computing within this field . Group collaborations and tools supporting these are discussed as well as knowledge work and the specific tasks of curation activities within . Designing interfaces or applications that move beyond the bounds of a single device ’ s screen enables new ways to engage with digital content . Chapter 4 contributes an in - depth analysis and taxonomy of a corpus of 510 research papers in the cross - device computing domain in HCI . This chapter provides : i ) an overview , historic trends and unified terminology of cross - device research ; ii ) discussion of major and under - explored application areas ; iii ) mapping of enabling technologies ; iv ) synthesis of interaction techniques spanning across multiple devices ; v ) and review of common evaluation strategies . The outcomes of Part I are addressing RQ1 and are building the theoretical foundations to inform the design of novel interaction techniques in Part II . Introduction 34 Part II : Case Studies of Cross - Device Interactions for Knowledge Work In the second part of the thesis , three case studies are presented that apply the insights gained through the cross - device taxonomy to design novel cross - device interaction techniques for knowledge work . Informed by several informative studies three systems have been developed and are described in Chapter 5 , Chapter 6 , and Chapter 7 as shown in Figure 3 . Figure 3 . Chapter structure of Part II . Chapter 5 describes CurationSpace , which introduces a set of novel interaction techniques , allowing individuals or groups to more easily curate digital resources during content curation . Insights from a study are described on ( i ) how people understand the interactions ; ( ii ) how CurationSpace supports collaborative work ; and ( iii ) how people appropriate the space on a digital tabletop . Chapter 6 reports findings from two sets of interview studies . Insights gained from members of a volunteer - driven historic society as well as professional curators allowed to gather specific requirements for a system supporting curation tasks . The Introduction 35 findings and lessons learnt through these interviews fed into the design of a multi - device content curation tool : CurationLens , that leveraged physical and digital tools for the curation of both physical and digital artefacts while allowing curators to use their existing devices ( such as smartphones and tablets ) . Using multi - display setups in a work setting supports spatial thinking and multi - tasking ( Andrews , Endert , and North 2010 ) . However , multi - monitor setups are not as flexible as mobile devices ( tablets or smartphones ) , while mobile devices mostly lie flat on a table — especially when not in active use — and therefore lack the spatial properties of multi - display setups . Chapter 7 describes SurfaceConstellations , which enables end - users to create 3D - printed brackets to link together two or more tablet or smartphone devices in flexible spatial setups . While the previous chapters explored cross - device interaction for curation work , Chapter 7 explores how cross - device interactions can support work in other domains through four additional mini case studies . The outcomes of Part II provide insights into how multi - and cross - device computing can be leveraged in different domains of knowledge work and contribute to answering RQ2 . The tools that have been designed for this purpose allowed me to gain insights into how cross - device interactions can be designed to effectively support knowledge workers in their tasks , based on the cross - device taxonomy as well as informative studies conducted as part of this thesis . Part III : Studying Cross - Device Interaction . Part III comprises Chapter 8 and Chapter 9 which are concerned with understanding group dynamics through the analysis of cross - device interactions ( Figure 4 ) . The traditional paradigm for interacting with computers and smart devices is one - device - per - person . In the notion of cross - device interaction , the boundaries of these relations do not exist in this traditional sense . However , people are not used to having — and in particular using — multiple devices in parallel ( Plank et al . 2017 ) . Chapter 8 explores the spatial properties of group collaboration in a ‘ bring - your - own - device ’ scenario and how aspects of group collaboration can be influenced through basic cross - device functionality . While studying the cross - device tools Introduction 36 through interaction analysis , a new coding scheme and collaborative coupling styles for cross - device interactions were developed which are presented here . Figure 4 . Chapter structure of Part III When developing cross - device tools , researchers often conduct studies to assess their effectiveness and opportunities for improvements . However , interaction analysis based on video recordings of such studies is a time - consuming and labour - intensive process . In Chapter 9 a system was developed — EagleView — which provides analysts with real - time visualisations during playback of videos and an accompanying data - stream of tracked interactions . It further allows analysts to query people ’ s interactions with an easy - to - use visual interface . EagleView thus supports researchers in the cross - device computing domain with interaction analysis of their studies . Part III provides answers to RQ3 by contributing insights into how design parameters of multi - device configurations can affect group collaboration and how these can be studied and evaluated . It further provides a tool that enables researchers to conduct interaction analysis in multi - and cross - device interaction scenarios . Chapter 10 concludes this thesis by discussing how the works conducted answer the research questions . Directions for future research in the area of cross - device computing will be discussed . Methodology 37 Chapter 2 . Methodology Our interactions with technology increasingly involve more than just a single device and it is becoming more common to transition from one device to another . For example , finding a photo on one ’ s phone while creating a presentation on a laptop ; or using a tablet to draw a sketch to use in a report that is being written on a desktop computer . Furthermore , many people work collaboratively , with each person using their own devices when working together , meaning that multiple devices are being used at the same time . This can not only lead to incompatibility due to different operating systems , form factors , and software used , but also to coordination problems when it comes to sharing or working together on the same piece of content . To help overcome these issues , new opportunities for collaborating and new interaction paradigms have been proposed , together with a large body of research exploring such interactions . In addition , there is now a plethora of available devices , new device form factors , and a number of new device capabilities appearing , offering new research opportunities that go beyond wall or tabletop displays and desktop setups . The aim of the research reported in this thesis is to contribute to new understandings in the growing area of cross - device work . Firstly , by reviewing and analysing the current state of the field of cross - device computing through a systematic literature review and the resulting cross - device taxonomy . Secondly , based on the literature review , design a set of new interaction techniques and tools . And thirdly , to study and evaluate these cross - device interaction techniques and tools in individual work and group collaborations , providing insights and support for researchers on how to evaluate cross - device systems . The domain selected to explore how to support individual and group work is knowledge work — work where the fundamental task is to think ( Drucker 1959 ) — and in particular the area of curation of digital and physical artefacts . The reason for the choice of knowledge work is that it is a kind of work that Methodology 38 requires the use of multiple resources — often a mix of digital and physical — that is currently carried out by both individuals and teams of people . It can often be labour - intensive and laborious work that could be reduced and made more efficient through rethinking how devices can be used . Generally , the research in this thesis followed an extended user - centred iterative process ( Harper et al . 2008 ) as shown in Figure 5 . The extended user - centred iterative design process as described by Harper et al . ( 2008 ) consists of five stages . The authors note that these five stages do not need to be followed in order . In fact , they normally are entered at any of the points and then iterate during the course of a research project ( Harper et al . 2008 ) . Figure 5 . Overview of the conducted research , separated into the stages of the extended user - centred iterative design process of Harper et al . ( Harper et al . 2008 ) . In the following , these five stages of the extended user - centred iterative design process are briefly summarised . Figure 5 shows how the research in this thesis maps to the stages . Stage 1 : Understand . The first stage focusses on understanding the current state of values and a thorough reflection on principles and concepts . Ultimately this stage results in “making choices” ( Harper et al . 2008 , 59 ) . Choices about the domains of interest , about the users involved , and help to surface prior work that is relevant . Methodology 39 Stage 2 : Studying . This stage is concerned with understanding the details of individuals ’ and groups ’ existing practices . Compared to stage 1 , which “provides a framework to guide design and research” ( Harper et al . 2008 , 60 ) , this stage provides insights into people ’ s actual practices and allows for reflection on the value , perspectives , and needs . This then allows researchers to imagine technological intervention in the design stage . Stage 3 : Design . The design phase is the creative phase that has as its outcome the design requirements and goals for a ( technology ) intervention . These requirements are rooted in the outcomes of the first two stages , being framed by the choices considered in stage 1 as well as the insights into practice of stage 2 . The actual methods used for these range from sketching to paper prototypes to clickable prototypes and working applications . Stage 4 : Build . This stage involves the actual development of prototypes and technology . The aim of this stage is to build a prototype that provides insights about how a system , tool , or interaction technique might enhance an experience or workflow . Using this prototype , the next stage can then be entered : evaluation . Stage 5 : Evaluate . This stage evaluates the prototypes built in the previous stage , and ultimately allows for reflection on design requirements . The methods used here have a broad range from focus groups to lab studies to in the wild deployments . The aim is to validate the interaction techniques or tools to gain insights into how they support the identified requirements — and to then revisit the original design as part of the iterative design process . For this thesis a combination of methods was used throughout the five stages : interviews , observations , studying people ’ s current practices ; design of interaction techniques ; system development ; and evaluating the interaction techniques through user studies . For analysing qualitative data ( the tagged dataset in Chapter 4 , study data in Chapter 5 , interviews in Chapter 6 ) the methodological approach of Thematic Analysis was used . In the following the Thematic Analysis ( TA ) method will be described . As stated by Blandford et al . TA is a structured way of coding qualitative data for analysis , used widely in HCI ( Blandford , Furniss , and Makri 2016 , 52 ) . Methodology 40 Opposed to Grounded Theory ( GT ) , which is a cycle of gathering data and analysing data where ( initial ) outcomes of the analysis influence any subsequent data collection processes , TA operates on a finalised dataset ( Blandford , Furniss , and Makri 2016 ) . TA is a “method for identifying , analysing and reporting patterns ( themes ) within data” ( Braun and Clarke 2006 ) . Braun and Clarke identify six phases of TA in their 2006 paper : 1 . Familiarising yourself with your data . Transcribing and reading the data and noting down anything that seems interesting . 2 . Generating initial codes . Going systematically through the entire dataset and coding interesting parts . Collating data relevant to each code . 3 . Searching for themes . Finding themes within the codes and merging the codes and data for each theme for further analysis . 4 . Reviewing themes . Reviewing whether the ‘ theme candidates ’ from step 3 fit the codes extracted in step 2 as well as the entire dataset . 5 . Defining and naming themes . Refining the themes and finding adequate descriptors . 6 . Producing the report . Upon further reflection of the themes producing a report of the analysis . Opportunity to relate back to existing literature . Braun and Clarke leave it open as to whether the analysis should be informed by a pre - existing coding scheme or whether it should be grounded only in the data . However , a researcher should “work systematically through the entire data set , giving full and equal attention to each data item , and identify interesting aspects in the data items that may form the basis of repeated patterns ( themes ) across the data set ” ( Braun and Clarke 2006 , 89 ) . Blandford et al . described a pragmatic approach to Thematic Analysis of qualitative data in HCI ( Blandford , Furniss , and Makri 2016 , chap . 5 . 2 ) , which loosely follows the above - mentioned steps of Thematic Analysis ( TA ) . They begin their “‘ bottom - up ’ or ‘ grounded ’ qualitative data analysis” ( Blandford , Furniss , and Makri 2016 , chap . 5 . 2 ) method with a first pass of rough coding to get a feeling of what is in the data and to find common themes . In a second pass , the researcher looks more systematically for patterns that might be interesting for analysis . While doing both of these steps they Methodology 41 highlight that it is important to consider and analyse the entire dataset , while from time to time stepping back to see the big picture . For example , whether any higher - level themes are emerging or whether any topics have been missed or are not matching to the overall dataset . They describe their pragmatic approach as an iterative process between finding the detail and looking at the big picture , to eventually build a narrative for each theme individually . When the researcher feels that a certain level of saturation has been reached , they can start to link various themes through a narrative , merge similar ones , or remove obsolete ones . While Blandford et al . acknowledge that “this sounds chaotic , it should become highly systematic and rigorous in later stages” ( Blandford , Furniss , and Makri 2016 , chap . 5 . 2 ) . Within the scope of this thesis , this pragmatic approach of Thematic Analysis will be followed where indicated . The rest of this chapter describes the methods used for each of the three parts . Part I : Theory of Cross - Device Computing Part I first introduces the areas of ubiquitous computing ( ubicomp ) and cross - device computing in general . Furthermore , as part of Chapter 3 , other related work around group collaboration , and especially digital spaces and tools supporting it , as well as knowledge work — with specifics to curation work — is presented . To gain a thorough understanding of cross - device computing , initially a systematic review of prior work was conducted . The resulting Cross - Device Taxonomy can be found in Chapter 4 . To create the collection of papers for this analysis , a systematic search in the ACM Digital Library 1 was conducted in May 2018 . The search terms included all possible combinations of cross - and multi - with each of device , surface , monitor and display ; and distributed user interfaces as well as acronyms . By looking at references within this corpus as well as using the co - authors ’ 2 own expertise of the cross - device research domain , an additional 48 articles were identified that were missing from the search results ( which is a common strategy for survey and taxonomy papers , e . g . 1 ACM Digital Library : https : / / dl . acm . org 2 Referring to the co - authors of the corresponding ACM CHI 2019 paper as attributed in Chapter 4 . Methodology 42 ( Ledo et al . 2018 ; Grubert , Kranz , and Quigley 2016 ) ) . After merging duplicates , the initial selection comprised a set of 738 papers . Inclusion and exclusion criteria were applied : the selected papers had to be concerned with interaction tasks or techniques , tracking technology for people and / or devices , or technologies involving multiple devices . Excluded were those papers without a contribution ( e . g . proceedings ’ front matter , keynotes , workshop ’ s calls for participation ) or short contributions with a full paper follow - up . The resulting corpus included 510 papers in total , which are incorporated in the taxonomy . For each paper , a brief summary was written , a definition of cross - device interaction extracted , and each paper was tagged . The tagging categories for the taxonomy were iteratively developed through both top - down specification of categories and bottom - up trial - tagging . Top - down tagging was conducted through the use of general tags and broader questions that were set up prior to the actual tagging work . During the tagging process , the specific answers found in each paper were matched to the general questions and categories set . For interesting observations where there were no categories or general tags set out prior to the tagging process , new categories or questions were added or existing sets of tags extended — this is called bottom - up trial tagging . After the process these specific instances were revisited and merged to higher level general themes / tags . Some of the general tags already emerged during the process and were elevated to higher level themes or tags along the way . By using both approaches it was possible to answer specific questions in a structured way , but also leaving the opportunity to discover new opportunities for discussion . The final tagging categories included : contributions , application areas , interaction technique details , deployments , evaluation techniques , definitions , technological aspects , and several further fields . All 510 papers were tagged with a custom - built web - based paper - tagging system ( Figure 6 ) . The front - end included forms for tagging and annotation , pre - set tags , free text fields , and auto completion ( Figure 7 ) . During tagging emerging patterns were frequently discussed with co - authors of the resulting paper ( as stated in the beginning of Chapter 4 ) , tagging schemes revisited , and if there were changes in the tagging scheme previously reviewed papers were iterated on . The final tagging Methodology 43 dataset was cleaned up ( e . g . filling missing tags , correcting misspellings , and merging identical tags ) and exported as JSON for analysis . Figure 6 . Screenshot of the web - based tagging system showing the overview with assigned papers and links to quickly access the full paper . The analysis primarily focused on three data collections : 1 ) the tagging dataset with all data fields ; 2 ) the complete set of all papers ’ document PDFs ; and 3 ) extracted text from all PDFs excluding references . The analysis was done iteratively by all co - authors individually , in pairs , and in group discussions . During the process the relationships among the codes were then identified to conclude higher level themes using Thematic Analysis in a pragmatic approach as described earlier at the beginning of this chapter . In addition , Tableau , R , and Excel were used to visualise the development of key topics over time and to support uncovering trends and patterns . These visualisations acted as pointers to where a deeper look into either the dataset would be useful or needed , as well as into the papers themselves . They also surfaced visual patterns that could then be discussed further . For example , how certain types of evaluations were employed over the course of the years or how the popularity of certain device types changed . Frequent full - text searches complemented these Methodology 44 explorations to confirm or refute a trend . For example , by conducting a keyword search over the extracted text and including the surrounding text in the search results , it was possible to quickly gauge whether a certain paper would be relevant or useful to answer a question or not . This paper could then be examined in more detail . The findings and insights gained through these studies and reviews were then used to design novel cross - device interaction techniques and tools , as described in Part II . Figure 7 . Screenshot of the detail - view of the tagging system , showing the first set of fields available . Some free - text entry and some with clickable tags . Methodology 45 Part II : Case Studies of Cross - Device Tools The literature reviewed , and especially the cross - device taxonomy , helped in understanding the current state of the field of cross - device computing . Through the taxonomy , the tools that are described in Part II can be categorised and situated within the existing work . As mentioned earlier , content curation activities were chosen as the domain of study ; as well as comprising many knowledge - rich work activities where content is selected from many pre - existing resources , they are often carried out using multiple devices over time , that can be repetitive , time - consuming and inefficient . The outcomes of a curation task are ultimately shared with or presented to an audience — which might be collaborators , friends , or e . g . through an exhibition . In addition , content curation activities are performed by a variety of people inside and outside professional environments . The diversity of activities involved in curation suggests there are a number of opportunities for where new kinds of linked devices and interaction techniques could be developed to better support groups and individuals in their use of both digital and physical resources . Similar to the overall methodological approach followed in this thesis , the methodology used to build the tools as part of this thesis followed an extended user - centred , iterative process ( Harper et al . 2008 ) as discussed at the beginning of this chapter . Each of the tools was informed by an understanding of the problem space through literature , observations , and by working with professional or volunteer curators . Using early design explorations , paper prototyping , clickable prototypes , focus groups , as well as workshops provided insights into suitability of certain technologies or interaction techniques . Not all of these informative studies are reported in this thesis . However , they led to design considerations and generally helped to inform choices for technology as well as techniques , eventually leading to the design and building of the tools which are presented here . 2 . 2 . 1 Understanding Curation To develop an understanding of the practice of curators , semi - structured interviews were conducted with both professionally trained curators as well as members of a group of volunteer historians ( Chapter 6 ) . The goal was to understand what curators do , where and with whom they conduct these tasks , and how they go about their work . Methodology 46 The semi - structured interviews asked questions around the following major themes : the curators ’ role , activities and tasks , workspace , tools , the digital and physical divide , collaboration , and presentation . Semi - structured interviews were chosen to allow for a wide range of insights into curators ’ workings . While an ( online ) questionnaire might have yielded a higher number of replies , it would have limited the level of detail that could have been gained . Using semi - structured interviews allowed for the adaptation of questions and of the direction of the interview to accommodate for different settings and provided the opportunity to dig deeper where an interesting direction opened up during the interview . The interviews were audio recorded , transcribed , and analysed , following the pragmatic approach to Thematic Analysis as described at the beginning of this chapter . The relationships among the open codes were identified to conclude higher level themes . This gave insights into how people conduct a curation task and work collaboratively as a group . Together with findings from the literature , curation was then scoped in terms of the activities of selecting , refining and analysing , and sharing and presenting documents and artefacts . 2 . 2 . 2 Design and Building of Interactive Systems Part II of this thesis involved building several prototypes — cross - device tools for content curation and more generally knowledge work : ( i ) CurationSpace ( Chapter 5 ) , a cross - device system combining smartwatches with a tabletop , where the interactions are based on the notion of instrumental interaction and dynamic media . This shows how cross - device systems can be used to provide expressive tools for collaborative curation work , while protecting users ’ privacy by allowing them to flexibly share what and when they need to . ( ii ) CurationLens ( Chapter 6 ) , which extends CurationSpace ’ s interaction model to the physical space by allowing the use of multiple devices to curate physical as well as digital artefacts . This shows how cross - device systems can support a scenario where people use their existing devices ( ‘ bring - your - own - device ’ ) to individual and collaborative curation while blending interaction with physical and digital artefacts . Methodology 47 ( iii ) SurfaceConstellations ( Chapter 7 ) , a modular platform to easily ( re - ) configure cross - device setups . It combines the advantages of multi - monitor workspaces and multi - surface environments with the flexibility and extensibility of more recent flexible cross - device setups in a ‘ bring - your - own - device ’ ( BYOD ) setting . The development generally followed a user - centred design process , where insights gained from the literature review formed a starting point for iterative designs of the tools and interaction techniques . Each system underwent several iterations from low fidelity prototypes using sketches , cardboard , and mock - ups demonstrating the interaction , to high fidelity prototypes . Through frequent discussions , informal testing , as well as pilot studies the tools and techniques were iteratively developed . Formal user studies were then conducted to evaluate the prototype systems in terms of their usability and usefulness to support curation tasks . Using a user - centred iterative design process allowed for rapid prototyping to gather early feedback on sketches , design ideations , and clickable prototypes to feed back on the design and development , before evaluating it through user studies . CurationSpace ( Chapter 5 ) was designed as a collaborative curation tool using a tabletop display and a wrist - worn smartwatch . The design of CurationSpace ’ s interactions started with low fidelity sketches of how the interactions could look like . Through several discussions within supervisory meetings , the interactions were refined and quickly implemented in early versions of clickable prototypes — rudimentary mock - ups of the interaction that were functional to the point where they could communicate the idea of how the interaction would look and feel . Using these clickable prototypes in informal settings with colleagues as well as collaborators , constructive feedback on the interface and the interaction of the system was gathered . A scenario - based user evaluation ( Ledo et al . 2018 ) was conducted , aiming to gain insights into how the fundamental concepts were understood and whether they were usable by and useful to curators . Participants were presented with a fictional scenario and were asked to take on the role of one of the protagonists . They were guided through the scenario by the study facilitator — who in this case also served as a collaborator in case the scenario required two people . A scenario - based user evaluation is useful to gather feedback on the general interaction scenario without the Methodology 48 tool being in a development state where it can be widely deployed . While CurationSpace is a fully functioning system , the requirements for an in the wild deployment are far higher than what can be expected from many research prototypes ( more on this later ) . The benefit of a scenario - based user evaluation is that the facilitator can guide the user through a ( hypothetical ) task without worrying about breakdowns and unexpected appropriations . They can then discuss with the participant how the system could be useful in the participant ’ s everyday work life . The interaction with the system during the scenario , as well as the subsequent semi - structured interviews , were video - recorded and analysed using the pragmatic approach to Thematic Analysis described earlier at the beginning of this chapter . While the user study showed the concepts of CurationSpace were easy to learn and use , it remains a research prototype that takes a long time to set up , is difficult to maintain , and is not ready to be deployed in the wild . More details about the system , the study , and the findings can be found in Chapter 5 . The CurationSpace study revealed that people use more and more digital devices , such as multiple tablets or smartphones . Therefore , the next tool built was CurationLens , a curation system which leverages the readily available power of these portable devices . CurationLens ( Chapter 6 ) expands CurationSpace ’ s document and interaction model to the physical space , creating consistency between how people interact with digital as well as physical tools , supporting small groups of 2 - 4 people in their curation activities . CurationLens brings together lessons learnt from earlier prototypes as well as insights gained through interviews with curators . Each component of CurationLens addresses one of the main curation tasks : selection ( input ) , refinement and analysis ( manipulation ) , sharing and presenting ( presentation ) . All these stages are integral part of CurationLens . CurationLens was developed as a web - based system meaning any device with a web browser could be used . This enabled users to use their existing ( mostly ) portable devices , demonstrating the power of a bring - your - own - device ( BYOD ) ( Ballagas et al . 2004 ) scenario . The findings from interviews with professional and volunteer curators led to design requirements for CurationLens . The system was subsequently developed iteratively , starting with ideating through sketches and cardboard prototypes , some including rudimentary interactive Methodology 49 components . Interactions were iteratively refined through discussions with colleagues and supervisors . The usability of CurationLens was assessed through conducting a heuristic evaluation using Olsen ’ s heuristics ( Olsen 2007 ) . Olsen ’ s heuristic evaluation was chosen as a lightweight tool to discuss and reflect on usability aspects of more complex systems and allows for attribution for off - the - desktop , nomadic , and changing systems . CurationLens is a UI application that supports complex tasks and interactions . It was not possible to conduct a thorough usability testing as it would have suffered from the three problems that Olsen identified when building new protypes ( Olsen 2007 ) : ( i ) a complex system might not be suitable for a walk - up - and - use evaluation , since the assumption of the same pre - existing knowledge is difficult to control for as well as assuming that a specialised system should be usable without any special training . ( ii ) To be able to compare two systems , a comparative system needs to exist . When creating novel interaction techniques this is difficult to control for . Many independent variables result in findings from a comparative study to be attributable rather to the “differing techniques being tested not the variations in approach to the task or user expertise” ( Olsen 2007 ) . ( iii ) Extensive testing of complex systems requires multiple sessions with expert users . Especially if the questions of such a test ask how tools support a user ’ s work or users might appropriate tools for their needs . Furthermore , specialised user groups are difficult to recruit especially for a long - term evaluation , which would go beyond a first - use study . Hence , the heuristic evaluation approach was chosen for CurationLens , as it was a better match for the type of system being built : allowing for discussion and critical reflection on the design choices while not being restricted by the limitations of a too - early usability evaluation ( Greenberg and Buxton 2008 ) . CurationLens did not set any special technical requirements for the hardware needed and reduced the setup to simply loading a web page in the browser . This Methodology 50 demonstrates how a user ’ s existing devices can be successfully used for cross - device curation tasks . The BYOD scenario also enabled easy ( re ) configuration of the physical device setup . However , such setups are limited to devices being handheld or positioned flat on the table ( as also frequently observed in a later study in a BYOD scenario , reported on in Chapter 8 ) , or at most having them stand up using the device ’ s case . Therefore , a solution was needed that enabled users to customise their physical device setup : SurfaceConstellations . SurfaceConstellations ( Chapter 7 ) was developed as a hardware and software platform that enabled flexible workstation setups for reconfigurable workspaces using people ’ s own devices ( such as smartphones and tablet devices ) . The platform consisted of customisable 3D - printed brackets that clip on to devices and provided a graphical web - based tool that allowed untrained users to customise and download their 3D - printing files . SurfaceConstellations serves as an example of how novel cross - device system setups can be created without the need for rigid or expensive setups , combining the advantages of multi - monitor workspaces and multi - surface environments with the flexibility and extensibility of cross - device setups . Through conducting four case studies , the flexibility of the brackets is demonstrated , broadening the scope of the thesis and demonstrating the suitability of cross - device interaction techniques to further knowledge work use - cases beyond content curation . Part III : Studying and Evaluating Cross - Device Tools Part III is concerned with studying and understanding cross - device interactions . When evaluating cross - device tools , often user interactions with such systems need to be observed and analysed — some of which have been conducted in the evaluations in Part II . However , interaction analysis of cross - device systems is challenging as it entails many different factors , such as multiple users , devices , and interactions between all of them as well as other entities . Some descriptions for collaboration styles and coding schemes exist but are either not suitable for cross - device tools or can only accommodate two people . Therefore , to conduct such an analysis , a new Methodology 51 coding scheme , together with collaboration styles for group work in a cross - device scenario was developed . To do this , a user study was conducted on how aspects of a user interface design in a collaborative cross - device task can be manipulated to increase collaboration , leading to better task outcomes . This resulted in the description of coupled collaboration styles as well as a coding - scheme for cross - device systems in Chapter 8 . The approach adopted to analyse the video recordings of the study was interaction analysis ( Jordan and Henderson 1995 ) . Interaction analysis is an interdisciplinary method to empirically understand the interactions of one or multiple people with each other or their environment . It requires repeated viewing of short subsets of audio - visual recordings to identify moments of interactions on a micro - level that might not be “visible” from a written transcript alone , such as sociolinguistics , proxemics , and ethology — it seeks to understand how and why people interact with each other and their environment ( Jordan and Henderson 1995 ) . Practically in this dissertation interaction analysis was conducted following the pragmatic approach of Thematic Analysis described earlier in this chapter . For the study reported on in Chapter 8 , no pre - existing coding scheme was used , but one was developed iteratively . One focus point of the analysis was the collaboration styles participants employed . Therefore , previously developed coupled collaboration styles ( Isenberg et al . 2012 ; A . Tang et al . 2006 ) were used as a starting for the analysis , but were extended for a study with groups of four ( instead of pairs ) within a multi - device usage scenario ( instead of single - device ) . Interaction analysis is a time - consuming task and the repeated reviewing of audio - visual material can take several times the duration of the original recording . While systems for tracking people and devices in a space have become more readily available ( e . g . Kinect , BLE - tracking , etc . ) , tools that support gaining insights into interactions based on such tracking data are rare . To support researchers who develop and study cross - device systems in a single - or multi - user scenario , EagleView was developed . EagleView is a video analysis tool that enabled researchers in their interaction analysis by providing visualisations of people ’ s movement and interactions as well as search functionalities on recordings of study deployments ( Chapter 9 ) . Methodology 52 Summary The research conducted in this thesis used different methods , in particular : systematic literature reviews , interviews , user - centred design methods , as well as user studies to evaluate systems and tools . By following the methodology described in this chapter , the research was able to advance and answer the three research questions : the taxonomy and related systematic literature review of Part I provides answers to RQ1 . The user - centred design methods used in Part II supported the design and development of novel cross - device tools that demonstrate how cross - device principles can be leveraged for knowledge work . The study as well as the tool reported on in Part III provided answers for RQ3 on how cross - device systems can be studied and evaluated . Ethical Approval for the Studies in this Dissertation All studies involving human participants were approved either by the UCL or UCLIC ethics boards . The studies in Chapter 5 and Chapter 8 were conducted under UCL Ethics Project ID Number UCLIC / 1415 / 005 / ICRI Rogers / Capra / Gallacher . The interviews and observations with curators and the historic society ( Chapter 6 ) were conducted under UCL Ethics Project ID Number 6877 / 001 . The study in Chapter 9 was conducted under UCL Ethics Project ID Number UCLIC / 1617 / 011 / Staff Marquardt / Brudy . Methodology 53 P ART I : T HEORY OF C ROSS - D EVICE C OMPUTING The first part of this thesis is concerned with the understanding of cross - device interaction , the current state of the field , and more generally giving a background on previous work that informed the work in this thesis . In Chapter 3 , we 3 first provide an overview over prior work in the areas of ubiquitous computing and cross - device interaction , group collaboration , and knowledge work and curation . Chapter 4 examines the research domain of cross - device computing in greater detail through a cross - device taxonomy . We will discuss existing and future challenges and opportunities . These insights build the theoretical foundations for designing cross - device interaction techniques and tools in the following Part II . 3 In the following chapters the use of “we” refers to Frederik Brudy as well as co - authors of the publications associated with the work , as indicated in the beginning of each chapter . Related Work 55 Chapter 3 . Related Work In this chapter , relevant prior work will be discussed . First , a general introduction to multi - device interactions in ubiquitous computing will be provided . A large - scale systematic review and taxonomy of cross - device research is presented later on in Chapter 4 . The premise of this thesis is to design for cross - device interactions in individual and collaborative scenarios . Therefore , a brief introduction to collaborative work will be given in section 3 . 2 . Much of the cross - device interactions support not only individual but also collaborative work , and cross - device content transfer and interactions techniques are largely enabling group collaboration with multiple devices . A special focus will be given to multi - device environments for individual and collaborative work . While the general use - case for the tools presented in Part II is knowledge work , a specific focus of the applications built as part of this thesis is curation work . Therefore section 3 . 3 will give an introduction to these areas of knowledge work , sensemaking , and curation . In subsequent chapters , additional related work will be discussed where more specific details are relevant . Ubiquitous Computing and Cross - Device Interaction People own and use more devices and generate more data than ever . As a result , many knowledge workers ’ tasks entail digital content from a large number of sources . Digital technology can help support these tasks and digital devices have the potential to support all stages of such work . Vannevar Bush examined “ the real heart of the matter of selection [ of required information ] ” ( Bush 1945 ) and coined an answer to the increasingly Related Work 56 complex tasks involved in indexing , accessing , and linking information in his early vision of Memex ( 1945 ) . Bush used an analogy of how the human brain works to create the concept of a machine that would enable a person to create a “ trail ” of information by linking associations between items , allowing the person to instantly jump between items — much like how our thoughts work through association . Memex offered multiple screens to project output on ( from microfilm ) and used levers , keyboards , and pens to allow for navigating and editing a collection . Although only an early vision , Bush ’ s vision showed how using multiple screens supports the thinking and linking of ideas and documents . Since then , multi - monitor setups have become almost a standard by which knowledge workers ’ desks are set up . Financial trading desks , control room engineers , business analysts , and photo and video editing : all of these benefit not only from increased resolution that is offered by multiple monitors , but they also allow a user to dedicate certain areas of the workspace to a particular usage ( Andrews , Endert , and North 2010 ; Sellen and Harper 2002 ) . Much alike to how the space on a desk is used , multi - monitor setups “ facilitate versatility in use ” ( Grudin 2001 ) . This versatility of multi - display setups has driven many more recent research agendas . We have now entered Mark Weiser ’ s envisioned time of the third wave of computing ( Weiser 1991 ) — the time where every person has access to and is using multiple computers . This is opposed to the first wave ( one mainframe computer used by multiple users ) and the second wave ( one personal computer ( PC ) per user ) . His vision of ubiquitous computing ( ubicomp ) — users interacting with the devices they have and that are in their surrounding through context - aware and ambient intelligence — laid out in 1991 , led to an explosion of research into new device form factors and interaction paradigms that transcend the individual device and user . Researchers have explored how a single person can explore and work with large collections of digital data , for example on large screens ( Andrews , Endert , and North 2010 ; Hutchings , Stasko , and Czerwinski 2005 ) , using tabletop or wall displays ( Everitt et al . 2006 ; Wigdor et al . 2009 ; Streitz , Geissler , et al . 1999 ) , by combining multiple , handheld devices with tabletops and large wall displays ( e . g . ( Greenberg , Boyle , and LaBerge 1999 ; Robertson et al . 1996 ) ) , or more purely , using multiple , separate , Related Work 57 handheld devices in conjunction ( Hamilton and Wigdor 2014 ; Schwarz et al . 2012 ; Marquardt , Hinckley , and Greenberg 2012 ) . Using multiple devices has not only the advantage of increased screen space , but also the power of mobility and the flexibility of setup and use of such device ecologies — groups of computing resources that are fixed and / or mobile and are aware of their social use , interactive capabilities , and / or spatial location ( Bødker and Klokmose 2012 ) . Devices cannot be considered in isolation anymore , since new devices can be dynamically added or removed , the layout of a setup can be altered at any time , and different affordances and technical capabilities of different device types can be leveraged for increased effectiveness and ease of use . This interplay between device is more crucial to understand — and for interface designers to get right — than ever before ( Bødker and Klokmose 2012 ) . As soon as multiple devices are involved in a system or interaction there need to be techniques to span an interaction between two or more devices , to transfer content between devices , and to combine them into one interaction space . Interactions for such device ecologies — and rooted in the Weiserian vision of ubiquitous computing — created a new direction for research : cross - device interactions . Cross - device interaction research focusses on how multiple devices can be used together to achieve one goal and how they can operate in concert . For example , how the usable screen estate of multiple devices can be combined to a larger interaction space ( Schwarz et al . 2012 ; Rädle et al . 2014 ) , how an interaction can span across multiple devices ( Chang and Li 2011 ) , and how people can interact with devices in their surrounding using others ’ or their own devices ( Dippon , Wiedermann , and Klinker 2012 ) . Although much of the current ubicomp — and cross - device — research is still deeply founded in Weiser ’ s vision of seamless interaction , it has elicited critical reflection . As Rogers ( Rogers 2006 ) argues , instead of using technology in the Weiserian vision of calming people , ubicomp technologies need to be built to engage people : purposefully built experiences that can be used in particular places and support a current task or situation at hand , while ultimately leaving the users in control of their interactions with the world — a “shift from proactive computing to proactive people” ( Rogers 2006 ) . On the other hand , Oulasvirta noted that we have access to many powerful computing devices with different forms factors , affordances , functionalities , and Related Work 58 technical capabilities . While the fundamentals of context - awareness are already intrinsically founded in our actions , it is indeed the user who is “doing the ubicomp” ( Oulasvirta 2008 ) . Similarly , Dourish argues that users , not designers , appropriate technology and thus create meaning for their interactions ( Dourish 2004 ) . And while Weiser ’ s vision has elicited this criticism ( Rogers 2006 ; Oulasvirta 2008 ) , Buxton pointed out that the research spawned by this vision “has little or anything t o do with what [ Weiser ] or the rest of us on the team envisioned or intended” ( Buxton 2018 ) . He points out that term ubiety more accurately points towards what technology should do : being at the right place — in all meanings of the word place : physical , social , and temporal . Therefore , instead of blending all devices together and trying to hide the boundaries between them , designers should embrace and leverage the heterogeneity of devices and their “seams” ( Oulasvirta 2008 ; Chalmers and Galani 2004 ) — ultimately creating an “ecology of devices” that allow s people to do the right thing , at the right place , with the tools they need ( Buxton 2018 ) . While the amount of research in ubicomp has truly increased over the past 30 years , this led to a fragmented research landscape and many open questions . This thesis will use the term cross - device computing as an umbrella for the vast amount of research conducted in this area , which will be explored in depth through a cross - device taxonomy in the next chapter . The goal is to unify the terminology and strategies in the cross - device space , while extending the scope of earlier taxonomies . In particular , the focus is on themes around interactions within cross - device settings . Group Collaboration One premise of ubicomp and a large body of the research conducted in the area is that people — and especially knowledge workers — increasingly conduct their work collaboratively , not only working side - by - side , but co - accessing information on the same screen or moving between devices . Physical connections between people matter and working on such tasks collaboratively in small groups has advantages beyond the individual ’ s work : group collaboration facilitates critical discussion of material , allowing to reveal more connections between the various resources ( such as thematic links between different object ) reviewing and connecting more source material ; or Related Work 59 evolution of a relation over time ) , and bringing together people with expertise from different backgrounds , sharing their knowledge and opinion . As a result , collaborative work brings about broader and deeper insights , enables parallel work ( and thus faster task completion ) , and overall aids a more successful task outcome . People might start their work on a topic individually . For example , office workers might work individually on a subset of a report , but throughout the process come back together to share their current progress and to ensure that they have a common story arc . They work collaboratively to ensure that headings match , that written texts work well together and that bridges to / from neighbouring parts flow , and that overall the paper appears in a uniform presentation . Another example would be the volunteers of a historic society , interested in curating the rich history of their local areas : they might work on a report about a historic building , go to archives to find information ( e . g . maps , photos , reports ) , talk to contemporary witnesses , or search online for all the relevant information . This individual work then leads to collaborative activities : they meet with their colleagues to discuss their discovered sources , materials , interpretations , etc . and collaboratively work on a report . They share what they have collected and combine it with others ’ ideas . When collaboratively working on information as a group , information constantly needs to be interpreted and findings communicated to other people . Leaving out digital devices fosters face - to - face communication and interactions between people , as the ability to interact face - to - face and seeing the action is important and fundamental ( Hilliges et al . 2007 ) . When working with pen and paper people know how to use and share them collaboratively . They use a very fine - grained micro - mobility ( Luff and Heath 1998 ) of their documents to communicate non - verbally their intention to either share them or conceal them from other ’ s views . With micro - mobility the spatial arrangements , orientation , and positioning of objects is described . Depending on their intention , people arrange documents in their hands , on their desks , and in general in their environment differently , depending on the intended level of collaboration and use ( Luff and Heath 1998 ; Marquardt , Hinckley , and Greenberg 2012 ) . However , with digital systems and tools this is more complicated and sharing of data and tools requires different interactions . Menus and pointing devices require disparate interactions compared to real world tools , which breaks the fluidity of the Related Work 60 interaction . Digital devices might get in people ’ s way and keep them from interacting with their collaborator — imagine people in a collocated meeting all staring at their own personal screen rather than communicating with each other . On the other hand , while two people collaboratively working on a text using one screen ensures close collaboration , other benefits of collaborative work are lost , such as parallel work and shared control over content and context . Several research projects as well as commercial systems have been proposed that aim to support small groups in working with digital data and tools in a similar way as with paper . They often involve large multi - touch wall displays and tabletops , handheld mobile devices , or a combination thereof , many of which involving multi - and cross - device interactions . The tools implemented as part of this research aim to support individual as well as collaborative work . Because of the discussed advantages a group has compared to individual workers , related work on group collaboration will be discussed in the following . 3 . 2 . 1 Shared Digital Spaces for Group Collaboration : Tabletop and Wall Displays Tabletop and wall displays have received much attention as potential technologies to support small group collaboration because they offer a large display area and increased space in front of or around a collocated group . Using a wall display as a shared , physical reference point supports synchronization of group activity via body language and gaze ( J . R . Wallace et al . 2011 ) . Vertical collaborative spaces ( i . e . wall displays ) work well for presentations or when one group member is the “information gatekeeper” , but compared to horizontal tabletop displays they do not afford equal and democratic access ( Everitt et al . 2006 ) . Further , a group ’ s strategies and speed are affected by the group ’ s as well as the table ’ s size and especially for larger groups , combining a horizontal display with an additional vertical display provides more space for shared information ( Ryall et al . 2004 ) . MultiSpace explored methods to transfer content between shared devices — a tabletop and wall - display — inspired by the micro - mobility of people using paper document , thus supporting group collaborations using digital resources through interactions such as portal - based techniques for transferring documents between devices , arbitrary positioning of Related Work 61 documents to allow for different viewing angles , and by enabling people to work on and transfer sections of documents rather than entire documents ( Everitt et al . 2006 ) . Groups appropriate the space on and around a tabletop in different ways and fluidly transition between different coupling styles — from closely coupled collaborations , to more loosely coupled ( A . Tang et al . 2006 ) . Consequently , tabletop systems need to be designed to support such flexibility in coupling to enable fluid transitions between them while accounting for people ’ s need for personal space on and around digital systems ( A . Tang et al . 2006 ) . People use the area directly in front of them as a personal space where they collect and store information that is ( not yet ) shared . This has been observed on whiteboards ( J . C . Tang 1991 ) as well as when working on and around a table ( Kruger et al . 2003 ) . Scott et al . observed that people create their own territories when working on interactive tabletops ( Scott and Carpendale 2006 ) and organise their workspace into personal , group and storage territories ( Scott , Carpendale , and Inkpen 2004 ) . They observed that people understood and respected others ’ personal territories without any communication needed , and people rarely performed any actions outside their own or the group ’ s territory . Although the benefits of a shared space on tabletop and wall displays have been shown , they are difficult to set up and do not easily support ad hoc meetings , which contrasts to meetings often happening spontaneously ( Schreiner et al . 2015 ) . And while shared technologies , involving large tabletop and wall displays , have shown much promise for supporting collocated , collaborative tasks , they have not been a commercial success ; being expensive , needing a long setup process , and requiring a permanent place to be set up in . Collaborative meetings ( especially when creative work or problem solving tasks are involved ) ne ed to “happen” rather than being constructed ( Streitz , Geißler , et al . 1999 ) , therefore prompting an ad hocness in the entire process of configuration work . Technology and computer support is important and needed , however it should be in the background ( Hilliges et al . 2007 ) as the “creative potential [ is in the people ] , not the computers” ( Streitz , Geißler , et al . 1999 ) . Activities for problem solving are more successful when done in a group , rather than individuals working on their own ( Streitz , Geißler , et al . 1999 ; Hilliges et al . 2007 ) . While digital technology facilitates the division of labour in teamwork ( Mark , Haake , and Streitz 1997 ) , systems for group collaboration have to be designed in ways that allow the Related Work 62 division of tasks into subgroups , and the division of labour , while still in a collocated environment . Staying in a large group for the entire time degrades performance ( Streitz , Rexroth , and Holmer 1997 ) . Thus , the use of multiple personal mobile devices in combination with tabletop and / or wall displays for collaborative scenarios increased . Chapter 5 will describe a system combining a smartwatch and a tabletop display . Therefore , relevant related work for tabletop and large - display interactions has been discussed . Introducing another device — a smartwatch in this case — allows for a wider range of interactions and extends the screen space available with support for displaying contents on the screen that is most appropriate . Previous researchers have explored this transition from larger wall and tabletop displays to multi - and cross - device interactions , which will be discussed in the following section . 3 . 2 . 2 From Large Displays to Cross - Device Large interactive surfaces ( Nacenta et al . 2012 ; A . Tang et al . 2006 ; J . R . Wallace , Scott , and MacGregor 2013 ) and combinations of mobiles can support collaborative work and help mediate ad hoc collaborations and decision - making activities ( DiMicco , Pandolfo , and Bender 2004 ; Lucero , Keränen , and Korhonen 2010 ; Wozniak et al . 2016 ) . In small group collaborations , using individual tablets negatively affects communications and engagement , when compared to using pen and paper ( Haber , Nacenta , and Carpendale 2014 ) . A combination of mobile devices and a shared tabletop was found to lead to increased and better group collaboration ( Seifert et al . 2012 ) and enabled groups to organise relevant materials on the shared space , while being able to work on individual tablets ( J . R . Wallace , Scott , and MacGregor 2013 ) . Providing a group working on a tabletop with a shared space to display an overview of results can facilitate collocated collaboration ( Isenberg et al . 2012 ) , and support group collaboration through mutual awareness and observability of users ’ actions ( Hornecker et al . 2008 ) . For example , with MobiSurf ( Seifert et al . 2012 ) it was found that the combined use of personal and shared devices together with an interactive tabletop facilitated switching between individual and group work activities . Displaying different types of information on the shared display impacts a group ’ s performance — i . e . a shared task overview facilitates monitoring group progress , while Related Work 63 displaying replicated content facilitates conversational grounding ( J . R . Wallace et al . 2011 ) . However , while an increased display size can benefit individual sensemaking ( Andrews , Endert , and North 2010 ) , recent studies suggested that an increased size of a shared space is not indicative of improved collaborations , as participants ’ attention may be diverted towards the screen instead of other collaborators ( Zagermann et al . 2016 ) . Recently portable and handheld devices have been used in individual as well as in collaborative scenarios , enabling ad hoc collaborations . In the following , more mobile multi - device environments for knowledge work and sensemaking will be described . 3 . 2 . 3 Multi - device Environments for Individual and Collocated Sensemaking In collaborative scenarios , portable devices ( e . g . ( Wozniak et al . 2016 ; Hamilton and Wigdor 2014 ) ) or a combination thereof ( e . g . ( C . - W . Chung , Lee , and Liu 2013 ; Hesselmann , Henze , and Boll 2010 ; Hilliges et al . 2007 ; J . R . Wallace , Scott , and MacGregor 2013 ) ) can mediate collaborative sensemaking activities . Such multi - device setups can provide a shared display ( C . - W . Chung , Lee , and Liu 2013 ; Plaue and Stasko 2009 ; J . R . Wallace , Scott , and MacGregor 2013 ) and collaboration space ( A . Tang et al . 2006 ) , support spatial and visual organisation of content ( Zagermann et al . 2016 ) , provide awareness ( Gergle , Kraut , and Fussell 2004 ; Vogt et al . 2011 ) , and support a shared understanding ( Hilliges et al . 2007 ; J . R . Wallace , Scott , and MacGregor 2013 ) . For example , MindMap ( Lucero , Keränen , and Korhonen 2010 ) allowed a collocated group to use mobile phones for collaborative brainstorming . The system enabled a small group to collaboratively view and edit a digital mind - map using multiple phones acting as peepholes into the system . New devices are easily added to the system using a stitching ( Hinckley et al . 2004 ) gesture . Leveraging mobile personal devices for ad hoc collaborations led to further projects exploring the main principles of the Social and Spatial Interactions ( SSI ) platform ( Lucero , Keränen , and Korhonen 2010 ) , which extended the normally - individual use of personal handheld smartphones to shared collocated interactions . Related Work 64 Collaborative spatially aware actions have been explored in many other projects . While Lucero et al . did not employ any external tracking infrastructure in the aforementioned systems but instead relied on manual configuration , other systems employed fine - grained external tracking for spatially aware interactions . For example , the Proximity Toolkit ( Marquardt , Diaz - Marino , et al . 2011 ) used marker - based tracking to enable precise track the position and orientation of devices on a room - scale , enabling a wide variety of proxemics - aware systems . HuddleLamp ( Rädle et al . 2014 ) created spatial awareness across devices , only requiring a web browser on the client side , while the devices were tracked through a simple depth - sensing camera placed overhead . And while spatially aware interactions are preferred by users and can decrease the mental demand and effort by allowing people to “think in space” , they have to be designed with great care to avoid frustration and frequent mental switching ( Rädle et al . 2015 ) . Further , users are hesitant to use multiple tablets in parallel , hinting at a “legacy bias” to use tablets as computers rather than documents ( Plank et al . 2017 ) . The design and implementation of these systems demonstrate the plausibility of using one ’ s own personal devices to conduct collaborations where interactions span across devices . The research in this thesis explores the design of cross - device systems and tools that support individual and collaborative work . Earlier work will be extended by investigating how ad hoc collaboration tasks in a collocated setting can be supported , while still incorporating a shared space . The related work of practices in a shared interaction space motivated the investigation of a shared display in a BYOD ecology . A detailed analysis of the research domain of cross - device computing and interactions as well as an accompanying cross - device taxonomy can be found in the following Chapter 4 . Knowledge Work and Curation The fundamental task of people conducting knowledge work is to think ( Drucker 1959 ) with knowledge being the most important resource in today ’ s workforce where people “think for a living” ( Davenport 2005 ) . While it is difficult to define precisely what a knowledge worker is or what they do precisely ( Pyöriä 2005 ) , the term is mostly used to describe people who use their knowledge for the “processing of non - Related Work 65 routine problems that require non - linear and creative thinking” ( Reinhardt et al . 2011 ) . Such creative thinking processes comprise a combination of divergent and convergent thinking processes , where the workers iterate between generating a broad range of creative ideas in one step and narrow them down in another step . “ Knowledge work does not simply mean the application of existing knowledge and its exploitation in a new setting” ( Reinhardt et al . 2011 ) , but rather the creative application of it to adapt to entirely new situations ( Reinhardt et al . 2011 ) , increasing the focus on the development of mental skills ( Sellen and Harper 2002 ) . Knowledge workers are “expert [ s ] in making professional judgments about a specific domain” ( Sellen and Harper 2002 , 51 ) . Reinhardt et al . describe a topology of knowledge worker tasks based on descriptions and usage of those terms in a review of previous work ( Reinhardt et al . 2011 ) . These tasks range from the gathering of pre - existing information ( acquisition and information search ) , to thinking about and understanding something ( analysing ) , organising ( information organisation ) , creating textual and visual content ( authoring / co - authoring ) , to the sharing ( dissemination , communication , networking ) . They are conducted not only in in individual settings , but also collaboratively by making use of other experts to discuss a problem or find different solutions , through networking , and by co - authoring content . Table 1 shows their full topology of knowledge actions . Knowledge Action Description Acquisition Means gathering of information with the goal of developing skills or project or obtaining an asset Analyze Means examining or thinking about something carefully , in order to understand it . Authoring Means the creation of textual and medial content using software system , for example , word processing systems presentation software . Co - authoring Means the collaborative creation of textual and medial content using software applications , for example , word processing systems / presentation software . Dissemination Means spreading information or information objects , often work results . Expert Search Means the retrieval of an expert to discuss and solve a specific problem . Feedback Refers to the assessment of a proposition or an information object . Information Orga . Is the personal or organisational management of information collection . Information Search Means looking up information on a specific topic and in a specific form . Often we search using the folder structure of a file system or we search using an information retrieval service . Learning Means acquiring new knowledge , skills or understanding during the execution of work or based on formalised learning material . Monitoring Means keeping oneself or the organisation up - to date about selected topics , for example , based on different electronic information resources . Related Work 66 Networking Refers to interacting with other people and organisations to exchange information and develop contacts . Service search Refers to the retrieval of specialised web services that offer specific functions , for example , a translation service . Table 1 . Reinhardt et al . ’ s topology of knowledge actions . Table from ( Reinhardt et al . 2011 ) . Some more specific tasks of knowledge workers are those of decision - making and sensemaking . In the following , aspects of collaborative decision - and sensemaking will be discussed , as well as systems that support these tasks . Some of the tools developed in Part II of this thesis support curation work — work that consists of tasks similar to those of knowledge workers . Section 3 . 3 . 3 will therefore introduce curation work in general and give a working definition for the scope of this thesis . 3 . 3 . 1 Collaborative Decision - Making and Sensemaking Sensemaking allows a group to derive new insights through an iterative process ( Pirolli and Card 2005 ) of foraging and sensemaking ( Vogt et al . 2011 ) where materials are collected and organised to interpret new information and to gain new insights ( Russell et al . 1993 ) . Group collaborations have been shown to be beneficial for sensemaking , as a group can leverage each other ’ s cognition ( Harper and Sellen 1995 ; Heer and Agrawala 2008 ; Paul and Reddy 2010 ; Willett et al . 2011 ) and collaborators can create a shared understanding of the available information ( Hertzum 2008 ) . Vogt et al . ( Vogt et al . 2011 ) reported that collaborators may take on one of two primary roles of foragers ( gathers information and maintains an overall awareness of the state of the task ) and sensemakers ( dominant participant , who asks foragers to find documents , writes down key information , and steers the group ’ s direction ) . These roles are fluid and collaborators may switch roles throughout the process ( Vogt et al . 2011 ) . Isenberg et al . ( Isenberg et al . 2012 ) observed several communication styles within tabletop collaborations during a sensemaking task . They noticed that participants in closely - coupled collaborations engaged in active face - to - face communication . The ability to share and discuss relationships between task materials , while closely - coupled , benefits group performance ( Hansen and Järvelin 2005 ; Isenberg et al . 2012 ) . In contrast , participants in loosely - coupled collaborations worked in parallel rather than together and focused more on their own task at hand with limited interaction . They were less successful in connecting key facts and Related Work 67 completing their assigned task ( Isenberg et al . 2012 ) . These coupling styles however only account for two people around a tabletop and do not take any mobile devices into account or allow for discussion of more than two people . In Chapter 8 these will be extended to allow for groups of four people as well as account for multiple private and shared devices . 3 . 3 . 2 Sensemaking on Large Surfaces and across Devices Previous research has explored how a single user can work with large collections of digital data , for example , on large screens ( Andrews , Endert , and North 2010 ) , tabletops ( Everitt et al . 2006 ) or using multiple devices ( Hamilton and Wigdor 2014 ) . While public displays offer a high resolution interaction space for collaboration ( Andrews et al . 2011 ) , it was pointed out that territoriality ( Scott , Carpendale , and Inkpen 2004 ) and privacy ( Brudy et al . 2014 ) have to be considered . Augmented Surfaces ( Rekimoto and Saitoh 1999 ) introduced hybrid and collaborative digital / physical interaction space and UbiTable ( C . Shen , Everitt , and Ryall 2003 ) explored the design space of tabletops when used in a kiosk - style walk - up - and - use scenario . Using a phone as an input device for large displays has been explored , e . g . in Touch & Interact ( Hardy , Robert 2008 ) a phone could be used to interact with a display similar to a stylus on a PDA . Schmidt et al . built on this input vocabulary ( Schmidt et al . 2010 ) and detected a phone ’ s touch on a tabletop to , for example , allow data transfer or tool selection and extension of the input and output space ( Schmidt et al . 2012 ) . These prior works demonstrate that sensemaking — and knowledge work — can be effectively supported by novel device setups , such as using large screen , multiple displays , or setups across multiple devices . The tools developed in Part II further enable knowledge work to be conducted across a tabletop / smartwatch configuration and across multiple portable devices . The specific aspect of knowledge work that will be focus of these tools is curation , which will be discussed in the following section . 3 . 3 . 3 Curation Traditionally confined to museums and galleries , the word curator has its origins in the Latin word curare — meaning to take care of something or someone ( Oxford Related Work 68 Dictionary ) — and was originally used to describe caretakers of minors ( George 2015 ) . Later it was used to describe a selector and interpreter for art works for an exhibition . Curating collections and presenting them with a story in mind , led to art being accessible to a broader audience than only to the upper class . Museums were no longer pure archives or repositories for objects but became a place to learn and exchange about art and artists . Over the years , curation was more and more seen as an activity , rather than an abstract concept ( Bhaskar 2016 ) . From exclusive custodianship of official records , to selecting and filtering , to a participatory community - based archival approach : the understanding of curation and the curator ’ s role has shifted over the years ( Bhaskar 2016 ; Cook 2012 ) . Nowadays , as soon as we open a newspaper or a website , we are confronted with the word “curation”— it has become a buzzword , used in many different forms and existing outside the traditional museum setting . For example , on Pinterest people curate photo boards , and their owners are considered the curators of these collections . Radio DJs are considered music curators ; literary curators curate poetry ; and people in general curate their personal playlists on Spotify or their family photo albums ( Bhaskar 2016 ; Sabharwal 2015 ) . Although new types of curation work is often supported by algorithms and computer systems ( e . g . Flipboard , Google News , Reddit ) , these algorithms primarily identify popular content , rather than using specialised knowledge to select it ( Rotman et al . 2012 ) . Manual work and people ’ s individual insights are still needed for curation to present ideas that go beyond finding content related to previous interests . Curators use specialised knowledge to aggregate and validate some form of artefacts or content around a relevant topic in order to present it to an audience ( Bhaskar 2016 ; George 2015 ; Obrist 2015 ) . Content curation consists of aggregating , validating , analysing , presenting , and preserving content . This content can take different forms , such as multimedia , text and metadata ( Rotman et al . 2012 ) . Content curation differs from simply archiving , as it is more concerned with the content itself rather than the artefacts . A content curator is a person who finds , organises , and shares information around a relevant topic ( Bhargava 2009 ) . This means that content curation is not concerned with the creation of new content , but the selection , organisation , and interpretation of existing content . Related Work 69 However , this does not mean that simply copying content is enough , as content curators add “value and relevance beyond the original content” ( Fields 2011 ) . Curators transform , interpret , and rework source information to exceed beyond the boundaries of the original content ( Bhaskar 2016 ; Sternfeld 2010 ) . An important part of curation activities is to select , search , and enrich raw data with metadata ( Lord and Macdonald 2003 ; Sabharwal 2015 ; Sternfeld 2010 ) . Metadata — data about data — allows for the contextualization of content and the addition of further meaning to the raw data ( Sabharwal 2015 ) , enabling the use of search interfaces and tagging systems to browse content . Search can be based on an algorithm , whereas tagging brings in a subjective component , as tags are often created by a person and therefore founded in subjective beliefs , experiences , or views ( Lord and Macdonald 2003 ; Sabharwal 2015 ) . These processes are essential for the contextualization of raw data , transforming a document into a record containing its historical , social , political , and cultural contexts ( Sabharwal 2015 ) . Several descriptive frameworks for different approaches of curation have been put forward ( Digital Curation Centre 2016 ; Lord and Macdonald 2003 ) , laying curation activities out as a progress through a series of distinct and interconnected stages from selecting artefacts ( Bhaskar 2016 ) , to understanding content and making connections ( Sternfeld 2010 ) , presenting these new ideas or representations to others ( Rotman et al . 2012 ) , to eventually archiving and preservation of data and artefacts ( Bhaskar 2016 ) ( Sternfeld 2010 ) . Curation has been described as an iterative process , where the outcome of one cycle feeds as an input to another ( Digital Curation Centre 2016 ; Lord and Macdonald 2003 ) , and although the tasks are described as individual units , they can occur in parallel and curators can switch between selecting , understanding , and sharing ( Digital Curation Centre 2016 ) . These existing curation models either ( i ) focus only on one aspect of the curation process without including e . g . the input ( selection ) or output ( presentation , sharing ) , or ( ii ) describe the outcome of curation rather than the process how to arrive at the result ( Bhargava 2011 ) , or ( iii ) they focus on activities that go beyond finding the hidden value by including preservation and long - term archival . Therefore , for this thesis , curation is described as a process centred around information and content to derive new insights and create new representations . Related Work 70 3 . 3 . 3 . 1 . Definition of Curation in this Thesis Generally the goal of curation is to find the hidden value and making it visible or available to others ( Bhaskar 2016 ; George 2015 ; Obrist 2015 ; Rotman et al . 2012 ) and for the scope of this thesis , curation is defined as the process of selecting and reviewing existing artefacts and data to present it to an audience . Curation activities progress through a series of distinct and interconnected stages from selecting artefacts ( digital and / or physical ) and information about artefacts , to understanding content and making ( new ) connections , and eventually presenting these new ideas or representations to others ( e . g . through an exhibition , website , or brochure ) . Figure 8 shows how these three stages are connected in a curation - task - cycle . It should be noted that these curation tasks are not isolated , atomic units , but are rather high - level tasks that can consist of many subtasks . Curation is an iterative process to achieve a presentable or shareable result . The curators ’ focus and outcome might be different , but in each of these instances , the curator uses specialised knowledge to select and review some form of content in order to present it to an audience ( Rotman et al . 2012 ) . It is not limited to a particular end result or outcome of a curation process . The audience for the curated content can be of various types , for example website visitors of a blog , viewers of a presentation , readers of a report about the history of a building , or a child ’ s grandparents when being given a family calendar or photo book . Related Work 71 Figure 8 . The curation - task - cycle consists of the three main curation tasks : select , review , and present , each of them consisting of a subset of tasks . The result of one cycle feeds into another curation cycle as input . Compared to other models ( e . g . ( Bhargava 2011 ; Digital Curation Centre 2016 ; Lord and Macdonald 2003 ) ) the curation - task - cycle does not include the processes of archival or preservation . Although these are needed steps to preserve history , allowing long - term access to information and data , they are excluded here to focus on the processes and tasks that involve reworking content for producing a result which then can be archived . The outcome of one iteration can serve as input for another cycle . In the following the three main curation tasks are explained in more detail . Selection : Selection is about finding and identifying the initial information needed for a new exhibition , selection , or collection . Depending on the source of the data , the information and content then needs to be validated or cross - referenced with other sources . Selection entails reducing the information from a vast and crude collection of information to be more targeted and focused for its further use and purpose . Its purpose is to help finding the little in the many . Without selection , “the chance of finding that one must - see - piece , or that extraordinary specimen , would be vanishingly small . [ … ] The more [ there is ] in any given area , the more [ … ] selection is needed to make it manageable” ( Bhaskar 2016 , 119 ) . Curators are expert selectors , who have either gone through many hours of learning and practising Related Work 72 or have , through their extensive interest and devotion for a topic , otherwise built up specialist knowledge about a topic which they bring into the process . As a result , their choices are appreciated and trusted by other people — their audience — because of their expertise in a field ( Bhaskar 2016 ) . Search interfaces and tagging functionality help curators to start their selections . Searches can be based on an algorithm ( at least for text documents ; for images or video metadata must exist ) , whereas tagging brings in a subjective component , as tags need to be created by a person and are often founded in subjective beliefs , experiences , or views ( Sabharwal 2015 ; Lord and Macdonald 2003 ) . Metadata provides contextualising content , ensuring that the data can be found and used in the future , making it a key factor for the trustworthiness of a digital collection as its quality heavily influences the ability to filter or search for objects ( Lord and Macdonald 2003 ; Sabharwal 2015 ) . Reviewing : After ( and even during ) the selection of information , further reviewing and reduction of the selected material needs to be conducted . Source materials are filtered , screened , reviewed , and compared . This is where new connections are made , existing connections reconsidered , ( historically ) evaluated , and circumstances explained . This task requires the most knowledge , skill , and experience ( George 2015 ; Rotman et al . 2012 ) . Describing the content of the artefacts helps to find them again in later stages of the process ( i . e . through metadata ) , but also to interpret the contents and relate it to other areas . Presenting : Presenting curated content to an audience can take on a variety of different forms , such as reports , websites , exhibitions , or other forms of public engagement . The audience for the curated content is varied , for example website visitors , the audience of a presentation , visitors to a museum or gallery , or readers of a report about the history of a building , a leaflet of an exhibition , and many more . Presenting can also take the form of sharing content , rather than showcasing it in the traditional sense . For example , when working with colleagues , curators might share data and artefacts , using cloud services or shared network drives Related Work 73 In summary , in this thesis , the term curation will be used to describe the processes of selecting , reviewing , and presenting artefacts . Curation is about working with and reworking information about artefacts ( digital and physical ) to find new insights , connections , and eventually present these to or share them with others . Although further tasks , such as archival and preservation of artefacts , are an important part of professional curators , this will not be part of this thesis . Instead the focus will lay on content curation . The term curator will be used to describe a person who conducts these content curation activities , whether they had any professional training or not . Professional curators on the other hand will be used for curators who work in a professional environment or have had some professional curation training . Conclusion Weiser ’ s vision of ubiquitous computing has led to a large body of research in the area of multi - and cross - device computing . Much of this work has used a broad range of terminology , introduced a vast number of concepts , and so far , a unifying taxonomy and summary of the cross - device computing field has been missing . Therefore , in the next chapter , an in - depth analysis of a large body of previous cross - device research will be conducted to lay out a taxonomy of cross - device computing . This taxonomy is a continuation of the brief introduction of ubicomp and cross - device interactions in the earlier section 3 . 1 . Working in a small group enhances the process , by making it easier for people to find connections between content items , divide labour , and involve people from different backgrounds into the process . Leveraging handheld devices to allow for cross - device interactions and content transfer for knowledge work has shown potential and allowed for ad hoc scenarios . Various techniques and technologies for cross - device interactions with digital whiteboards , tabletop displays , handheld devices , and body worn devices have explored the potential and design space of cross - device interaction . The work in this thesis explores further how cross - device tools and systems can successfully be applied to collaborative work within the domain of knowledge work and curation tasks through three case studies . Related Work 74 This thesis is at the intersection of three areas of Human - Computer Interaction ( HCI ) as shown in Figure 9 . How groups collaborate when located in the same room has been studied . Extending the research on cross - device interaction techniques , considering spatial characteristics of a small group in order to allow for knowledge workers to conduct tasks in ad hoc scenarios will be a goal of this thesis . Figure 9 . Research context of this research project . In this chapter , the history and development of ubiquitous computing in general — and cross - device interaction specifically — was introduced . In the following chapter , a thorough systematic analysis of cross - device computing will allow to unify the terminology used as well as set out a taxonomy of key characteristics . Further , we analyse previous work through four analytical lenses ( application domains , interaction techniques , technical tracking systems , and evaluation strategies ) this will inform the design and development of cross - device tools in Part II . Cross - Device Taxonomy 75 Chapter 4 . Cross - Device Taxonomy 4 In this chapter , we present a cross - device taxonomy , laying out the current state - of - the - art in multi - device and cross - device interaction research based on the in - depth review of 510 research papers in the field . We show how historic trends led to today ’ s research domain of cross - device computing . We propose a unified terminology and a taxonomy of key characteristics . By showcasing the wide range of domains for cross - device applications , we exemplify the diversity of areas that cross - device systems have been used for . To inform the work on Part II — case studies of novel cross - device interaction techniques — existing interaction techniques as well as technical tracking systems are examined and discussed . Evaluating such novel interaction techniques validates their suitability for particular tasks . We therefore discuss evaluation strategies for cross - device systems . Through our review we identified several key challenges and opportunities in the cross - device research domain . These will be discussed at the end of this chapter . The aim of this chapter is to provide a general introduction to cross - device research , unify the terms we use , and show that cross - device computing techniques have been used for a broad range of tasks and activities . With these goals in mind , we opted to carefully select references to avoid overlong lists of references or tables that are 4 Parts of this chapter have been published previously in : Frederik Brudy , Christian Holz , Roman Rädle , Chi - Jui Wu , Steven Houben , Clemens Klokmose , and Nicolai Marquardt . 2019 . “Cross - Device Taxonomy : Survey , Opportunities and Challenges of Interactions Spanning Across Multiple Devices . ” In CHI ’19 Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . New York : ACM . https : / / doi . org / 10 . 1145 / 3290605 . 3300792 . I was leading the work conducted in this chapter as well as the write - up for the CHI’19 paper . The tagging of papers was conducted by all co - authors , where each author worked on a subset of at least 100 papers , with cross - checks conducted by me to review the tagging scheme . I lead the analysis effort , where every author contributed , involving frequent points of synchronisation through calls and written exchanges . Christian Holz developed the tagging system , I contributed to the development . I further ensured data consistency and cleaning of the datasets . Cross - Device Taxonomy 76 difficult to read . We prioritised seminal publications , earlier work and first contributions , and frequently cited papers — but also included other relevant work . We acknowledge that our references are not a listing of every paper in cross - device research , but a representative and curated subset most relevant for this taxonomy . This work directly incorporates and extends earlier taxonomies of multi - device research . Our taxonomy spans across the research areas of distributed user interfaces ( Demeure et al . 2005 ; Elmqvist 2011 ) , second - screen and multi - device research ( Neate , Jones , and Evans 2017 ) , and mobile multi - device ecosystems ( Grubert , Kranz , and Quigley 2016 ) . We build upon other related taxonomies — all with their own specialised focus : for example , covering the scale of multi - display systems ( Terrenghi , Quigley , and Dix 2009 ) , display switching for multi - displays ( Rashid , Nacenta , and Quigley 2012b ) , interaction techniques for spontaneous device association ( Chong , Mayrhofer , and Gellersen 2014 ) , or characteristics of devices ’ ownership , access , and distance ( Scharf et al . 2013 ) . While relevant technical aspects will be covered ( e . g . tracking systems and evaluation strategies for cross - device interactions ) , other engineering aspects are outside of the scope of this taxonomy , for example cross - device architectures or development frameworks ( an overview is available in ( Husmann 2017 ) ) . In summary , this chapter contributes : ( 1 ) a taxonomy and unified terminology for cross - device research , ( 2 ) a mapping and reflective discussion of the current design space ( across application domains , technology , interaction techniques , and evaluations ) , and ( 3 ) identification of challenges and opportunities informing a future research agenda of cross - device research . History and Unifying Terminology In the previous chapter ubiquitous computing generally and the early visions of cross - device computing were introduced as a general introduction ( section 3 . 1 ) . In this section , we synthesise related work to build a unified understanding of the domain of cross - device computing . We untangle the diverse terminology and various strands of research to build a single taxonomy that enables us to frame , guide , and inform current and future researchers in the area of cross - device computing . Cross - Device Taxonomy 77 4 . 1 . 1 Three Areas of Cross - Device Research We begin by unpacking a brief history of the earliest work in the area , and by highlighting the main trends over time . We divide this work into three key areas of cross - device work : ( 1 ) early work on multi - monitor workstations , ( 2 ) emergence of multi - display / surface environments , and ( 3 ) the increasingly mobile , ad hoc cross - device use . 4 . 1 . 1 . 1 . Area 1 : Multi - Monitor Workstations One of the earliest visions for a personal workstation , the Memex ( Bush 1945 ) , featured a setup consisting of multiple monitors , two for display and one for pen input . Early work included in our survey covers multi - screen systems ( Mano , Omaki , and Torii 1981 ) from as early as 1981 , where the effect of having four monitors at a workstation was studied . Wellner ( Wellner 1993 ) took this notion further with DigitalDesk . Similar — albeit later — work includes Grudin ’ s ( Grudin 2001 ) work on peripheral awareness in multi - monitor use , and the advantages of spreading information across connected , but distinct , output screens . Prior work has extensively studied multi - screen setups ( Nacenta , Mandryk , and Gutwin 2008 ; Santosa and Wigdor 2013 ; Hutchings et al . 2004 ; Dostal , Kristensson , and Quigley 2013 ; Rashid , Nacenta , and Quigley 2012a ) . 4 . 1 . 1 . 2 . Area 2 : Multi - Device Environments and Spaces Weiser ’ s “The Computer for the 21st Century” ( 1991 ) inspired research on computing that went beyond the single user at a single computer . Notably , Rekimoto ’ s work from the late 90s ( Rekimoto and Saitoh 1999 ; Rekimoto 1997 ) explored interaction techniques that crossed device boundaries , after Fitzmaurice introduced the notion of spatially aware palmtop devices a few years earlier ( Fitzmaurice 1993 ) . Around the same time , research on large interactive spaces started to appear , with seminal work like i - LAND ( Streitz , Geissler , et al . 1999 ) . Diverse multi - display environments emerged , enabling interactions that spread across landscapes of devices : digital wall - displays , tabletops , and tablets ( e . g . ( Everitt et al . 2006 ; Nacenta et al . 2006 ; Wigdor et al . 2009 ; Cauchard et al . 2011 ; Langner , Horak , and Dachselt 2018 ; Marquardt , Diaz - Marino , et al . 2011 ; Forlines et al . 2006 ; J . R . Wallace , Mandryk , and Inkpen 2008 ; Seyed et al . 2012 ; Grubert and Kranz 2017 ; Beaudouin - Lafon et al . 2012 ) . Cross - Device Taxonomy 78 4 . 1 . 1 . 3 . Area 3 : Ad hoc , Mobile Cross - Device Use Different from fixed spaces and ecologies , the third area of cross - device work focuses on mobile and flexible ad hoc cross - device setups . Enabled by ubiquitous availability of smartphones and tablets , this research strives towards individual or collaborative applications spanning across portable devices , providing a digital information space to support the task at hand ( Ballagas et al . 2004 ; Grubert et al . 2015 ; Grubert , Kranz , and Quigley 2016 ; X . Chen et al . 2014 ; Rädle et al . 2014 ; Spindler et al . 2014 ; N . Chen , Guimbretière , and Sellen 2013 ; Hinckley et al . 2009 ; Marquardt et al . 2018 ; Hinckley et al . 2004 ; Rekimoto 2004 ; N . Chen , Guimbretiere , and Sellen 2012 ; Marquardt , Hinckley , and Greenberg 2012 ) . Ad hoc portable setups lead to new challenges for technology , tracking , and field studies , as we explain in more depth shortly . 4 . 1 . 2 Towards Unified Terminology When sampling the research space , it became clear that there is a need to unify the terminology used to describe ongoing research . Not entirely unexpectedly for a large research field , in some cases the different introduced terms describe identical research areas . At other times , it is the other way around , when identical terms in fact refer to different areas of research . We untangle the diverse terminology of cross - device work and map terms out into a single ontology in Figure 10 . The main goal of this synthesis is to provide better guidance about scope and specialisations of cross - device research . The ontology is formed of two parts terms used to refer to cross - device literature : • The top part of Figure 10 categorises key terms of cross - device sub disciplines . The nested categories begin at the bottom with dual - display and multi - monitor work ( Figure 10a ) , extend to work with multiple mobile devices , tablets or slates ( Figure 10b ) , further to the category of cross / multi - display ( Figure 10c ) and cross / multi / trans - surfaces ( Figure 10 ) , and finally to cross / multi - device and distributed covering the broadest scope ( Figure 10 ) . The nested structure in the figure indicates focus areas associated with each term as well as the often - included device form factors . It is important to note that a large subset of the terms is used interchangeably . Cross - Device Taxonomy 79 • The bottom part of Figure 10 includes a list of terms indicating focus areas of research projects ( Figure 10f ) : interactions and collaboration ; interfaces ; applications or systems ; platform or middleware ; environments or ecologies ; and computing . We annotated these terms with the most common research focus of papers using each term . Figure 10 . Ontology of cross - device research terminology . Cross - Device Taxonomy 80 Taxonomy of Key Characteristics In this section , we dive deeper into our derived taxonomy of key characteristics of the cross - device design space . In particular , our taxonomy in Figure 11 is a fine - grained synthesis of the disparate but interwoven threads of the research field . We explain the six key dimensions and discuss how to use this taxonomy as a lens to look at existing — or inform new — research . 4 . 2 . 1 Dimension 1 : Temporal Cross - device work can be classified as either synchronous ( when interactions happen at the same time ) or asynchronous ( with a sequential flow of interactions across devices ) . The large majority of the work in our survey falls into the former category . 4 . 2 . 2 Dimension 2 : Configuration This dimension classifies the actual setup of the cross - device system as well as its use of input and output modalities . The main categories within synchronous use are mirrored and distributed user interfaces . Most active research is done within the distributed UI category , investigating the spatial and logical distribution of interfaces . The asynchronous work is divided across two categories : interfaces that allow migration across devices , and cross - platform research to make applications run consistently across diverse operating systems . Related taxonomies align with this dimension , in particular Elmqvist ’ s taxonomy of distributed UIs ( Elmqvist 2011 ) and Rashid ’ s focus on multi - device attention switching ( Rashid , Nacenta , and Quigley 2012a ) . 4 . 2 . 3 Dimension 3 : Relationship Research addresses different people - to - device relationships . While one person interacting with a single device ( 1…1 ) is usually not part of cross - device work , one person interacting with two or more devices ( 1…m ) covers work on cross - device workstations . Collaborative settings fall mostly in two categories : group activities where each person primarily uses a single device ( 1…1 x 1…1 ) , and collaborative settings with n - people and m - devices ( n … m ) . Examples of the last two categories relate closely to research and studies done in the CSCW community . 81 Figure 11 . Taxonomy of cross - device design space dimensions : temporal , configuration , relationship , scale , dynamics , and space . Cross - Device Taxonomy 82 4 . 2 . 4 Dimension 4 : Scale Interactions can vary across the dimension of scale : from near , to personal , social , and public rooms or buildings . Edward Hall ’ s proxemics is a commonly used anthropological lens for the scale of interactions ( Hall 1969 ) , which was later operationalised for cross - device work as proxemic interactions ( Marquardt , Diaz - Marino , et al . 2011 ; 2011 ; Ballendat , Marquardt , and Greenberg 2010 ) . Scale dimension relates closely to Terrenghi ’ s taxonomy of display ecosystems across scale ( Terrenghi , Quigley , and Dix 2009 ) and the progression of Weiser ’ s Tab / Pad / Yard computing ( Weiser 1991 ) . 4 . 2 . 5 Dimension 5 : Dynamics Dynamics can vary between setups , and the categories of ad hoc / mobile , semi - fixed , and fixed spaces closely relate to the phases of cross - device research we introduced earlier . Fixed spaces often include larger - scale wall displays and tabletops , while semi - fixed spaces allow a certain degree of reconfigurability , and ad hoc / mobile spaces focus on portable devices , allowing dynamic changes and re - configuration . 4 . 2 . 6 Dimension 6 : Space The last dimension differentiates between collocated and remote interactions ( and corresponds to Johnson ’ s CSCW matrix ( Johansen 1988 ) ) . The large majority of cross - device work covers collocated scenarios , but few examples address the challenges of providing cross - device interactions across remotely distributed locations ( Bardram et al . 2012 ; Clemens N . Klokmose et al . 2015 ) . Note : research projects do not necessarily have to fall into one single category . Instead , it is common that projects address different areas across this design space . Furthermore , research might follow lateral transitions , where the scope of the research shifts over time across any of these dimensions . Application Domains Our survey revealed a range of different application domains for cross - device computing . Although only 63 / 510 papers were tagged as making an application Cross - Device Taxonomy 83 contribution , 361 / 510 papers included some form of application use cases to motivate or frame the main contribution , such as new system designs , interaction techniques , tracking technologies , or interaction concepts . We identified nine high - level application - type clusters : ( i ) knowledge work , ( ii ) home computing , ( iii ) data exploration , ( iv ) mobile computing , ( v ) games / installations , ( vi ) collaboration , ( vii ) education , ( viii ) health , and ( ix ) software development ( Table 2 ) . The largest category of applications focuses on knowledge work with 62 papers . Knowledge work applications were initially developed for single - user personal workspaces , but gradually moved towards multi - user collaborative environments as well as mobile and nomadic work . Typical knowledge work is information management across various displays and devices ( Mano , Omaki , and Torii 1981 ; Robertson et al . 1996 ; Fitzmaurice 1993 ) , sharing information and resources across devices ( Oulasvirta and Sumari 2007 ; Johanson et al . 2001 ) , multi - device activity and task management ( Bardram et al . 2012 ; Prante et al . 2004 ; J . R . Wallace et al . 2009 ; Houben and Bardram 2013 ) , or productivity and creativity tasks ( Oleksik et al . 2013 ; Wellner 1993 ; Zhao and Liu 2004 ; Marquardt , Diaz - Marino , et al . 2011 ; Huang , Mynatt , and Trimble 2007 ) . Other domains include police analyst workstations ( Anslow et al . 2015 ) , industrial facilities ( Kubitza 2016 ) , aviation cockpits ( Fayollas et al . 2014 ) , and collaboration between aerospace scientists and engineers ( Huang , Mynatt , and Trimble 2007 ) . Starting in the year 2000 , we see a growing interest in applying cross - device interaction to data exploration . Information visualisation leveraging mobile devices including tablets and smartphones has called for new interaction vocabulary ( Spindler et al . 2010 ; Beaudouin - Lafon et al . 2012 ; Horak et al . 2018 ; Kister et al . 2017 ) . In particular , Horak et al . ( Horak et al . 2018 ) described interaction concepts for a smartwatch - display configuration in a crime analysis scenario using a real city criminal dataset . Other kinds of data sets that has been explored including geography ( Oskamp et al . 2015 , 2015 ; Masoodian , Luz , and Kavenga 2016 ) , physics ( Wigdor et al . 2009 ; Beaudouin - Lafon et al . 2012 ; Sollich et al . 2016 ) , life science ( Forlines and Lilien 2008 ; Gjerlufsen et al . 2011 ; Schneider et al . 2012 ; Grote et al . 2015 ; Coffey et al . 2011 ) , city planning ( Chan et al . 2010 ; van der Laan et al . 2013 ) , energy ( Seyed et al . 2013 ; Celentano and Dubois 2015 ) , and finance ( Marquardt et al . 2018 ) . Cross - Device Taxonomy 84 Education ( Kreitmayer et al . 2013 ; Cao , Esponda , and Rojas 2016 ; Wong - Villacres et al . 2015 ) and health ( Alsos and Svanæs 2006 ; Winkler et al . 2013 ; Fardoun , AL - Ghamdi , and Cipres 2014 ; Mentis 2017 ) have also been popular application domains , where there has been an emphasis on collaborative and distributed work . Education applications have primarily focused on supporting classroom capture ( Viel et al . 2013 ) , classroom presentation ( Han , Perret , and Naghshineh 2000 ; Cao , Esponda , and Rojas 2016 ) , educational games ( Lyons et al . 2006 ; Bouabid et al . 2014 ; de la Guía , Lozano , and Penichet 2013 ) , and simulations of classroom activities ( Johanson et al . 2002 ; Pietroszek and Lank 2012 ; Villanueva , Tesoriero , and Gallud 2014 ; Wong - Villacres et al . 2015 ; Nebeling et al . 2015 ) . Kreitmayer et al . ( Kreitmayer et al . 2013 ) present one of the few in the wild studies , where they observed collaborative activities in the classroom to inform the design of a group finance management activity with a shared tablet and large display . In the health domain there have been a few studies in the wild , including work on exploring pre - surgery scenarios ( Alsos and Svanæs 2006 ) , supporting patient registration ( Winkler et al . 2013 ) , and designing distributed user interface systems in surgery practice ( Fardoun , AL - Ghamdi , and Cipres 2014 ; Mentis 2017 ) . Other health applications are designed for personal use , namely memory games ( de la Guía , Lozano , and Penichet 2014b ) , cognitive training ( de la Guía , Lozano , and Penichet 2014a ) , and physical activity monitoring ( Klaassen , op den Akker , and op den Akker 2013 ) . Tracking Systems for Cross - Device Interfaces The cornerstone of cross - device interaction is a mechanism for exchanging data between devices . This often requires a tracking system that can reliably track individual devices and ( more recently ) also the individuals operating these devices . Various tracking systems have distinct qualities . For example , spatial resolution ( 3D position in space vs . distances between devices ) , degree of instrumentation required , or scale ( e . g . tracking devices on a table vs . in a room ) . Of 510 papers in the dataset , 55 papers have a core contribution that involved developing or customising a tracking system ; all other papers either leveraged existing tracking systems , designated fixed device locations ( e . g . multi - device systems where the devices are stationary ) , or used non - spatial tracking systems ( e . g . discovering devices that are on the same network ) . Cross - Device Taxonomy 85 We organised all tracking - focused papers in Table 3 , which we obtained through bottom - up analysis of the tracking characteristics ( proximity vs . relative location vs . 2D vs . 3D ) and modalities ( capacitive , inertial , acoustic , magnetic , optical , radio ) . Tracking systems typically fall into one of two categories : ( 1 ) outside - in , which use ( static ) sensors in the environment for tracking , or ( 2 ) inside - out , which use only sensors built into devices and occasionally utilise signal emitters in the environment . Inside - out tracking is especially practical for mobile cross - device applications scenarios , and Table 3 shows the dominant use of acoustic , radio , and more recently optical signals using device cameras . This type of tracking typically provides devices ’ 2D locations or relative adjacency configurations . Reliably tracking devices ’ 3D locations with non - spatial sensors is still a major challenge ( Qiu et al . 2011 ; Jin , Holz , and Hornbæk 2015 ) . In outside - in systems ( depth ) cameras are the dominant technology . Despite their 3D capabilities , most of these systems use cameras to track the 2D locations and orientations of devices ( see Table 3 ) . The table also shows that recent larger - scale capacitive area sensors are superseding former large - surface optical sensing ( e . g . as used in former tabletops and wall screens ) . Contrasting these two main categories , none of the inside - out papers tracked users as part of the sensing . However , most outside - in systems integrated this capability to also detect user interaction above and around the devices . A trend we identified in tracking systems was the ambition to work almost “out of the box” . We recognise the challenges for future cross - device tracking systems to provide high fidelity , reliable and accurate tracking information while keeping user input for device discovery , calibration , and pairing to a minimum , particularly for mobile systems . We foresee future inside - out systems delivering more of the capabilities of current outside - in systems , including user and identity tracking . We also anticipate outside - in systems increasingly sensing more of the users ’ context , such as their spatial configuration and activity . Cross - Device Taxonomy 86 Table 2 . Cross - device application domains : Nine application categories ( and sub categories ) with examples use cases . 87 Table 3 . Tracking characteristics and modalities of the cross - device papers with tracking as a main contribution . Our tracking classification directly relates to surveys of tracking technologies in ubicomp ( Hon et al . 2015 ; Hightower and Borriello 2001 ) . Cross - Device Taxonomy 88 Interaction Techniques The fundamental method by which people use cross - device computing is through interaction techniques . In our sample , 130 / 510 explicitly mention “ interaction techniques ” as the main contribution of the paper . Further in - depth analysis reveals that another 221 papers introduce interaction techniques as part of new tracking methods , applications , or systems , totalling 351 papers that describe and use cross - device interaction techniques . 4 . 5 . 1 Phases of Cross - Device Interaction Techniques We identified three phases of cross - device interaction techniques ( see a complete overview 5 in ) : ( Phase 1 ) the configuration phase , ( Phase 2 ) the content engagement phase , and ( Phase 3 ) the disengagement phase . Our analysis reveals that input modalities through which users perform the interaction can be grouped into five distinct categories : ( i ) on - screen interaction , ( ii ) around the device interaction and gestures , ( iii ) device motion , ( iv ) changing the shape of the devices , and ( v ) using body gestures . We categorise cross - device interaction techniques based on their modalities ( technical mode of interaction ) and three stages according to high level function ( purpose of the interaction ) . We propose that the overall cross - device interaction model can be deduced into three distinct interaction phases : Configuration Phase , Content Engagement Phase and Disengagement Phase . 5 The table is not an exhaustive or complete list of all interaction techniques , but a representative sample from our dataset that is exemplary for the three stages and six modalities identified in our analysis . 89 T a b l e 4 . O v e r v i e w o f i n t e r ac t i o n t e c h n i q u e s f o r c r o ss - d e v i c e c o m p u t i n g . Cross - Device Taxonomy 90 4 . 5 . 1 . 1 . Phase 1 : Configuration of Devices The first phase focuses on setting up cross - device configurations of devices including pairing , combining , connecting , or coupling multiple devices . The purpose of this configuration phase is to establish a meaningful semantic relation between devices that enables cross - device activity . Examples of cross - device interaction techniques can be found in all 6 modalities . For example , using on - screen interactions , techniques such as stitching ( Hinckley et al . 2004 ) or pinching ( Ohta and Tanaka 2012 ; Lucero , Keränen , and Korhonen 2010 ; H . S . Nielsen et al . 2014 ) multiple displays together , or performing synchronous tapping touches ( Rekimoto 2004 ) have been used to pair devices into one configuration . Pairing techniques have also leveraged on - device pointing ( Petford , Nacenta , and Gutwin 2018 ; Waldner et al . 2010 ) or different finger posture and identification ( Houben and Marquardt 2015 ) to implicitly create cross - device configurations . For around - the - device interactions , examples include knocking to pair ( Goel et al . 2014 ) , or even taking a picture to recognise other devices ( Schwarz et al . 2012 ) . Gestural pairing techniques include Rekimoto ’ s seminal tapping ( Rekimoto 2004 ) , and techniques such as roll - and - pointing ( Chong and Gellersen 2013 ) or hold - and - flipping ( X . Chen et al . 2014 ) to combine devices . Most techniques in the configuration phase are designed with 2D or 3D device motion as the main input modality . As seen in Table 4 , examples of pairing techniques using motion include bumping ( Hinckley 2003 ) , stacking ( Chong and Gellersen 2013 ) , or shaking devices ( Holmquist et al . 2001 ; Mayrhofer 2007 ) . The few shape - changing techniques examined how modifying the physical shape of devices through bending , sandwiching , or stretching ( Chong and Gellersen 2013 ) can be used to relate devices to each other . Using eye , gaze , or head orientation , techniques such as perspective - aware interfaces ( Nacenta et al . 2007 ) , perspective - aware cursor ( Nacenta et al . 2006 ) , or display change visualisations ( Dostal 2013 ) are used to select the right device or screen . Finally , techniques such as gradual engagement ( Marquardt et al . 2012 ) and proxemic interactions ( Greenberg et al . 2011 ) leverage the location , position , and orientation of the entire body to create semantic relations between devices . As combining various devices into a cross - device configuration or ecology is a central precondition for any Cross - Device Taxonomy 91 application or technique to work across devices , it is unsurprising that so many techniques explicitly focus on this pairing or configuration phase . 4 . 5 . 1 . 2 . Phase 2 : Content Engagement The second phase occurs after devices have been configured for cross - device usage , and includes direct or indirect interaction with content , data , visualisations , applications or interfaces that are spread across multiple devices . Content engagement encapsulates the actual consumption of content across various changing device configurations . Many of the classic cross - device interaction techniques — inspired by the seminal Hyperdrag ( Rekimoto and Saitoh 1999 ) and Pick - and - drop ( Rekimoto 1997 ; Nacenta et al . 2005 ) — use direct touch or mouse interaction with the displays to move content from one device to another . Examples include using drag - and - drop across the bezel of multiple screens ( Simeone et al . 2013 ) , swiping in the direction of another device ( Waje et al . 2016 ; Jin , Holz , and Hornbæk 2015 ) , as well as panning ( Rädle et al . 2014 ) , tapping ( Shibata et al . 2016 ) , and flicking gestures ( Reetz et al . 2006 ) . Direct interaction with content across devices has been supported through drag - and - drop proxy icon portals ( Hazas et al . 2005 ; H . Chung et al . 2014 ; Marquardt , Hinckley , and Greenberg 2012 ) , pressure - based press - and - flick techniques ( Nacenta et al . 2005 ) , pinch - to - zoom across multiple displays ( Marquardt , Hinckley , and Greenberg 2012 ) , or drag - and - pop and drag - and - pick techniques for multi - screen environments ( Baudisch et al . 2003 ) . Around - the - device interactions are predominately based on interactive surfaces ( like PhoneTouch ( Seifert et al . 2012 ) or ActivitySpace ( Houben , Tell , and Bardram 2014 ) ) , or projection systems that extend the interaction space to visual proxies next to a device ( Sicard et al . 2013 ) , extended projected displays ( Chernicharo , Takashima , and Kitamura 2013 ) , touch - enabled surfaces around the device ( Winkler et al . 2014 ) , or even augmented mouse , touch , and keyboard input ( Bi et al . 2011 ) . Mid - air gestures have also been considered for cross - device interaction . Some of these are variations of waving , such as waving between devices ( K . - Y . Chen et al . 2014 ) or waving above devices ( Houben and Marquardt 2015 ) . Other mid - air examples are performed after a touch or 3D motion interaction , such as point - and - grab ( Mäkelä et Cross - Device Taxonomy 92 al . 2018 ) , lift - and - drop ( Bader , Heck , and Beyerer 2010 ) , or grasp and micro - mobility ( Yoon et al . 2015 ) . The majority of interaction techniques for content engagement use the 2D or 3D device motion modality . A first category of techniques focuses on 2D movement on a flat surface . Techniques include rotating devices to interact with content ( Rädle et al . 2014 ; Houben , Tell , and Bardram 2014 ; Saidi et al . 2017 ) , moving devices to explore spatially aware maps ( Fitzmaurice 1993 ; Rädle et al . 2014 ) , or to explore information visualisations ( Wo ź niak et al . 2014 ) . The second category focuses on advanced 3D motions with devices for content interaction . Examples include pouring ( Jin , Holz , and Hornbæk 2015 ) or throwing content onto a display ( Dachselt and Buchholz 2009 ) , and tilting actions to pan a map ( Dachselt and Buchholz 2009 ) . Further techniques include rotating ( Liang et al . 2012 ) , throwing and chucking ( Hassan et al . 2009 ) , shoot - and - copy ( Boring et al . 2007 ) , and tilting ( Lucero , Holopainen , and Jokela 2012 ) techniques to interact across devices ( see the full list in Table 4 ) . There are only a few full - body gestures , such as content transfer propagated through F - formations ( Marquardt , Hinckley , and Greenberg 2012 ) , or gaze and head gestures to select devices or screens ( Lander et al . 2015 ; Serrano et al . 2015 ) , and pick and drop content ( Turner et al . 2014 ) . Many of these techniques leverage the physicality and affordances of the devices to enable expressive 3D device motion to receive , use , or send data to other devices that are very easy and intuitive to perform . 4 . 5 . 1 . 3 . Phase 3 : Disengagement The last phase covers interaction techniques for a person to stop cross - device content engagement on a device , infrastructure , or application level . While the first configuration phase has received much attention in earlier work , the disengagement phase remains less well explored . The few examples for on and around - the - device include cross - device session management ( Hamilton and Wigdor 2014 ) or covering a smartwatch to reset the cross - device configuration ( Chapter 5 ) . Using 3D motion , there are techniques to break connection by moving the device ( Hinckley 2003 ; Schreiner et al . 2015 ) , picking up the device from the tracked area ( Rädle et al . 2014 ; Houben , Tell , and Bardram 2014 ; Lucero , Holopainen , and Jokela 2011 ) , tilting devices vertically towards oneself to stop sharing ( Lucero , Holopainen , and Jokela 2011 ) , Cross - Device Taxonomy 93 shaking to break connection ( Ohta and Tanaka 2012 ) , or implicit disconnection of the device by breaking physical contact ( Xiao , Hudson , and Harrison 2016 ) . Finally , proxemic interaction supports implicit disengagement by leaving the operation - space ( Marquardt , Hinckley , and Greenberg 2012 ) or by turning away from the display ( C . - J . Wu , Houben , and Marquardt 2017 ) . It is important to note that interaction techniques can occur in — or combine — multiple functions from different phases at the same time . For example , techniques discussed in PhoneTouch ( Schmidt et al . 2010 ) , WatchConnect ( Houben and Marquardt 2015 ) , Gradual Engagement ( Marquardt , Hinckley , and Greenberg 2012 ) , or Gluey ( Serrano et al . 2015 ) combine Phase 1 configuration and Phase 2 content engagement functions in one interaction technique . However , applying this taxonomy can be a helpful analytical lens to understand the breadth and focus of most cross - device interaction techniques . Table 5 . Cross - device visualisation and management Cross - Device Taxonomy 94 4 . 5 . 2 Visualisation and Cross - Device Management Related to the interaction techniques , we identified four major categories of visualisation and feedback that have been used to help users understand how a particular cross - device interaction technique or application works ( Table 5 ) . First , a number of techniques provide users with an overview of the cross - device interactions across devices and space . Examples include the use of a layout or window manager ( Biehl and Bailey 2006 ; Wigdor et al . 2009 ) and the use of an overview or mini - map ( Aliakseyeu , Lucero , and Martens 2008 ; Gellersen et al . 2009 ; Forlines et al . 2006 ; Biehl and Bailey 2006 ; Baur , Boring , and Feiner 2012 ) . Second , to increase the overview and understanding of where information and applications are located across devices , a number of content visualisations and distribution approaches have been developed . This category includes real - time coordinated views across devices ( Forlines et al . 2006 ; Forlines and Lilien 2008 ; Hartmann , Beaudouin - Lafon , and Mackay 2013 ; Plank et al . 2017 ; Spindler et al . 2010 ) , brushing - and - linking between devices ( Badam and Elmqvist 2014 ; H . Chung and North 2018 ) , overview and detail on demand or on other devices ( Spindler et al . 2010 ; Baur , Boring , and Feiner 2012 ; Saidi , Serrano , and Dubois 2016 ; Homaeian et al . 2018 ) , magic lens views ( Baur , Boring , and Feiner 2012 ; Boring et al . 2010 ) , or dynamically corrected perspective views ( Nacenta et al . 2007 ) . Third , to increase the intelligibility of cross - device systems , feedback and feedforward mechanisms have been developed . Examples such as object preview and gesture shadows ( Besacier et al . 2014 ; Scott et al . 2014 ; Liang et al . 2012 ; Marquardt , Hinckley , and Greenberg 2012 ) , perspective cursor ( Nacenta et al . 2006 ; Waldner et al . 2010 ) or multi - display pointers ( Johanson et al . 2002 ; Román et al . 2002 ) help users understand how information is travelling between devices . A final strategy is in explicitly visualising the links between devices . Both physical and digital coloured borders are used to indicate connectivity ( Hamilton and Wigdor 2014 ; Wigdor et al . 2006 ; J . Wallace et al . 2006 ; Rädle et al . 2014 ; Marquardt , Hinckley , and Greenberg 2012 ) . Visual proxies or portals on or around devices are used to visualise what device owns which information ( Wigdor et al . 2006 ; 2009 ; Hazas et al . 2005 ; H . Chung et al . 2014 ; Marquardt et al . 2012 ; Biehl and Bailey 2006 ; Gellersen et al . 2009 ; Fei et al . 2013 ; Houben , Tell , and Bardram 2014 ) , and cross - device portals help users identify the boundaries between devices ( Houben , Tell , and Bardram 2014 ; Marquardt , Hinckley , and Greenberg 2012 ) . Cross - Device Taxonomy 95 Evaluation Strategies In this section we report on our analysis of evaluation strategies for cross - device work . While technical research might have a performance evaluation or a preliminary expert evaluation with developers , other work is evaluated through lab studies or real - world deployments with users . 4 . 6 . 1 Evaluation Methods Used In summary , 317 / 510 of the papers in our corpus reported on a study , which we clustered into our five main evaluation strategies for cross - device work . As much of the cross - device research can be considered a “ constructive problem ” ( constructive – conceptual or constructive – empirical ( Oulasvirta and Hornbæk 2016 ) ) , we extended Ledo et al . ’ s evaluation strategies of technical toolkits for HCI ( Ledo et al . 2018 ) for the purpose of our classification with “ informative ” , resulting in the five main categories : informative ( observational and elicitation ) , demonstration , usage ( qualitative and quantitative ) , technical , and heuristic evaluation ( Table 6 ) . We would like to point to Ledo et al . ’ s in - depth discussions about evaluation strategies of toolkits for the latter four ( Ledo et al . 2018 ) , which similarly surfaced in our analysis . In the following we will give a brief summary of each strategy and explain our newly added fourth strategy in more detail . 4 . 6 . 1 . 1 . Evaluation through Demonstration Demonstrations show what a cross - device system or interaction technique supports and how it is utilised by users for certain tasks ( Ledo et al . 2018 ) . While this does not involve a real - world deployment , it shows the applicability of a proposed solution to solve a real - world problem ( Oulasvirta and Hornbæk 2016 ) . Therefore , demonstration is a powerful evaluation tool , in particular for technical systems ( e . g . tracking toolkits or other development frameworks ) . 4 . 6 . 1 . 2 . Evaluation through Usage Usage evaluates whether a cross - device system or interaction technique can be used by a certain user or user group ( usability ) , how it supports certain tasks ( usefulness ) , how it is appropriated , or elicits other user feedback ( Ledo et al . 2018 ) . Most frequently novel interaction techniques and cross - device systems are evaluated Cross - Device Taxonomy 96 through qualitative lab studies or controlled experiments , which work well to reveal usability problems , but often lack ecological validity . In the wild studies compensate for this limitation as they provide insights into the context of use of a specific system ( Rogers et al . 2007 ) . However , real - world deployments are challenging to conduct , as much of the technology supporting cross - device interactions is difficult to control outside the lab ( mentioned earlier in tracking systems section ) . Yet 20 papers have reported an in the wild deployment , for example at schools ( Kreitmayer et al . 2013 ) and in university classrooms ( Cao , Esponda , and Rojas 2016 ; N . Chen , Guimbretière , and Sellen 2013 ) . Table 6 . Evaluation methods used in our corpus ( in round brackets are the number of papers employing each strategy ) . Cross - Device Taxonomy 97 4 . 6 . 1 . 3 . Heuristic Evaluation Heuristic evaluation uses a set of criteria ( e . g . Nielsen ( J . Nielsen 1994 ) ) to assess the usability without the need for human participants . Few papers ( 5 ) report on heuristics as an evaluation method . We speculate that this could be because the cross - device research lacks specialised heuristic metrics . Heuristic metrics are a helpful tool for discovering usability issues , especially during early stages of the design process . However , “ simple metrics can produce simplistic progress that is not necessarily meaningful ” ( Olsen 2007 ) , as they will not provide insights into users ’ often unexpected uses of a system . 4 . 6 . 1 . 4 . Informative Studies Studies with the purpose to give insights into users ’ needs and unsolved problems were categorised as informative studies . They often precede implementation or development work and involve users in the design process , allowing researchers to gain a broader spectrum of possible solutions , and anchor system design choices in perceived user needs . Rogers argues that “ ultimately research and development [ of ubiquitous technology ] should be driven by a better understanding of human activity ” ( Rogers 2006 ) , and the sentiment is echoed by Oulasvirta who notes that “ improving the state of affairs [ in ubiquitous computing ] is not the duty of engineers alone ” ( Oulasvirta 2008 ) . However , not all projects involve a dedicated informative step , but rather draw their design choices from existing literature or other previous work . Through an explicit evaluation step after the development , the engineering work is then often grounded further in research . Observational Studies Within our corpus , several papers have reported on findings of observational in - situ or lab studies in order to build an understanding of cross - device use to guide further research directions or facilitate design choices . For example , early observations of multi - display use in office environments ( Grudin 2001 ) triggered other research of how cognitive load can be reduced through usage of multiple displays ( Hutchings et al . 2004 ) and multiple devices ( Oulasvirta and Sumari 2007 ; Dearman and Pierce 2008 ; Santosa and Wigdor 2013 ) . Similarly , other observational studies have been used to investigate current multi - device utilisation ( Cecchinato et al . 2016 ; Cross - Device Taxonomy 98 Cecchinato , Cox , and Bird 2017 ) , barriers for true multi - device usage ( Plank et al . 2017 ) , or the effects of display sizes in collaborative work ( Zagermann et al . 2016 ; Huang , Mynatt , and Trimble 2007 ) . Gesture Elicitation Studies Cross - device interaction techniques frequently involve on - , around - , and mid - air - gestures to connect devices or manipulate content . Such gestures designed by the researcher building the system are not always reflective of users ’ preferred choice . Wobbrock et al . ( Wobbrock , Morris , and Wilson 2009 ) proposed gesture elicitation studies as a tool when designing novel interaction techniques : participants are presented with the effects of an action ( referent ) , and they are asked to perform the signs which could cause those actions . Through the weighing and calculation of agreement scores , the proposed gestures can be mapped to user - friendliness and acceptance ( Vatavu and Wobbrock 2015 ) . Through sensible crafting of elicitation tasks , such studies can generate a gesture vocabulary which allows for re - use of gestures for similar tasks . 4 . 6 . 1 . 5 . Technical Evaluation Technical evaluations are used to show how well a system works ( Ledo et al . 2018 ) . 66 papers in our corpus report on a technical evaluation , which is exclusively used to evaluate a tracking technology ( 28 ) or other cross - device toolkits ( 38 ) . Again , we point to Ledo et al . for more details ( Ledo et al . 2018 ) . 4 . 6 . 2 Studying Cross - Device Interactions Studying cross - device interactions often consists of video recording lab studies or in the wild deployments , especially for qualitative studies . However , only a few systems support researchers in analysing this video material : VICPAM ( Moghaddam and Bailey 2011 ) , EXCITE ( Marquardt , Schardong , and Tang 2015 ) , and EagleView ( presented in Chapter 9 ) are systems enabling researchers to visualise and / or query spatial interaction with multiple devices . Ultimately , more work is needed about how to best evaluate cross - device interactions and systems . Cross - Device Taxonomy 99 Key Challenges and Research Agenda Research on cross - device computing and interaction has shown that there are tremendous benefits to be gained by breaking the confinements of solitary computers , devices , and users . Through our survey of cross - device literature , we identified open challenges and issues during tagging of our corpus of papers and our own reflections on these findings . We synthesised all tagged entries ( e . g . explicitly mentioned key challenges from 67 papers ) into the following nine themes . We combine them with challenges identified in prior work ( e . g . ( Grubert , Kranz , and Quigley 2016 ; Houben et al . 2017 ) ) . 4 . 7 . 1 Bridging the Gap between Studies and Systems To support human activities in a cross - device ecology or to meaningfully compare cross - device interaction techniques and approaches , we need to develop testable design patterns ( Marquardt et al . 2012 ) by making applications and scenarios the central focus . Although some work has attempted to compare techniques ( Nacenta et al . 2005 ; Rädle et al . 2014 ) , the underlying fundamental problem is that there is no frame of reference to compare and evaluate cross - device techniques and systems . While many of the technical contributions re - envision and push the boundaries of interaction possibilities , they are often disconnected from findings using empirical studies . More work is needed to unify empirical and technical cross - device work into one stream of research . 4 . 7 . 2 Conveying Cross - Device Interaction Capabilities While cross - device capabilities have in recent years started to appear in commercial products , several studies have contributed sometimes controversial findings about device utilisation . A study of Apple ’ s Continuity , for example , showed that users have challenges in understanding its features , being aware of its presence and effects , and mitigating significant privacy issues when devices are shared ( Raptis , Kjeldskov , and Skov 2016 ) . And while Rädle et al . argue for spatially aware cross - device interactions , they remark that such interactions have to be designed with great care to reduce users ’ cognitive load and mental demand ( Rädle et al . 2014 ) . The underlying challenge is in communicating the action possibilities and benefits of cross - device interaction in systems and applications . More specifically , we need new concepts , feedback and Cross - Device Taxonomy 100 feed - forward mechanisms , and user interface patterns that are designed specifically for cross - device computing ( as discussed later in Chapter 8 ) . 4 . 7 . 3 Mitigating the Effects of Legacy Bias The phenomenon of legacy bias , where users resort to well - known interaction styles even when more effective and novel techniques are available , has been documented in studies of cross - device sensemaking ( Plank et al . 2017 ) , note - taking ( Jensen et al . 2018 ) , and curation tasks ( Chapter 5 ) . Although workplace and user experience studies consistently report that many people are already struggling with multi - device fragmentation ( Cecchinato et al . 2016 ; Dearman and Pierce 2008 ; Santosa and Wigdor 2013 ) , it remains an open issue to what extent users will adopt new multi - device systems . More research into the mental models of individual devices and larger ecologies is needed to provide an empirical ground for new technical cross - device research . 4 . 7 . 4 Addressing Social Challenges Designing new cross - device systems involves tackling the challenges of social relations and norms ( Dey , Ljungstrand , and Schmidt 2001 ) , privacy ( Uzun , Saxena , and Kumar 2011 ; Brudy et al . 2014 ) , authentication , as well as providing support for the configuration work ( Houben , Tell , and Bardram 2014 ) needed in the engagement and disengagement stages of the cross - device interaction . Our analysis finds the systemic lack of interaction techniques for disengaging from cross - device interaction . Users need the ability to configure ( or reconfigure ) cross - device functionality ( Raptis , Kjeldskov , and Skov 2016 ) , and Greenberg et al . argue for explicitly supporting opt - in and - out of interactive systems ( Greenberg et al . 2014 ) . Although some initial work has been conducted in this space , fundamental issues around the entire cross - device interaction model remain . 4 . 7 . 5 Enabling Proactive Cross - Device Interaction Although Weiser ’ s vision ( Weiser 1991 ) is foundational for cross - device computing research , it has also elicited critical reflection . For example , Rogers proposes a “shift from proactive computing to proactive people” ( Rogers 2006 ) in which purposefully built experiences engage people while leaving them in control of their interactions Cross - Device Taxonomy 101 with the world ( Rogers 2006 ) . Similarly , Oulasvirta summarises that it is users who are “ doing the ubicomp ” ( Oulasvirta 2008 ) and Dourish argues that users , not designers , appropriate technology and thus create meaning for their interactions ( Dourish 2004 ) . Therefore , instead of blending devices together and trying to hide the boundaries between them , designers should embrace and leverage the heterogeneity and flexibility of devices and their “seams” ( Chalmers and Galani 2004 ; Oulasvirta 2008 ) — ultimately creating an ecology of devices that build the conceptual foundation of cross - device computing . The current move to mobile , ad hoc , and re - configurable device configurations is reflective of this shift , but the context of use , the user ’ s action , and specific applications and scenarios needs to be considered in a much stronger way . 4 . 7 . 6 Building and Deploying Cross - Device Systems In the Wild Many cross - device systems and interactions were built and tested in controlled lab setups ( Table 6 ) , often involving only a small set of simultaneous users . It is unclear how well the systems and interactions transition and scale to environments that are more representative of everyday interaction ( Homaeian et al . 2017 ) , what users ’ actual cross - device interactions are in their everyday lives ( A . Wu et al . 2012 ) , or how they may change their use of multiple devices outside the lab ( Husmann , Rossi , and Norrie 2016 ) . Researchers have therefore argued for in the wild deployments in users ’ typical environments ( Bragdon et al . 2011 ; Rogers et al . 2007 ) to better understand and support their actual tasks in their settings ( Kreitmayer et al . 2013 ) . However , this opens up new challenges about technical capabilities and the infrastructure problem . 4 . 7 . 7 Improving Tracking Technology and Infrastructure Much of the enabling technology for cross - device interactions ( Table 3 ) is prototypical , difficult to set up , expensive , or requires a lot of space . There is a need for such systems to be more reliable ( Kubo et al . 2017 ) , to improve speed and accuracy during regular use and motion ( Peng et al . 2007 ; Qiu et al . 2011 ; Chang and Li 2011 ; Schwarz et al . 2012 ; G . Hu et al . 2014 ) , and to bring cross - device capabilities to unmodified devices outside the research space ( Ohta and Tanaka 2012 ) . On a technical level , cross - device research needs more practical testing ( Jin , Holz , and Hornbæk 2015 ) and refinement for situations outside the lab ( Li and Kobbelt 2012 ) , Cross - Device Taxonomy 102 to support wider - scale use and in the wild deployments . Outside - in - tracking often requires markers attached to the tracked object or is easily confounded with uncertain conditions ( light , noise ) . And while inside - out - tracking has in the past always been used for in the wild deployments — due to its robustness , mobility , and support of ad hoc situations — it lacks the fidelity and details ( e . g . tracking of users ) of outside - in . On the other hand , devices themselves can be aware of their context of use . Researchers in academia and industry have begun to point out and tackle this infrastructure problem ( Oulasvirta 2008 ; Houben , Tell , and Bardram 2014 ) , but only a few efforts have focused on minimising setup and configuration time on the user ’ s part to enable interactions out - of - the - box ( e . g . ( Jin , Holz , and Hornbæk 2015 ; Zhang et al . 2012 ) ) . 4 . 7 . 8 Bespoke Solutions vs . Platforms Commercial attempts at cross - device computing are limited to a single user managing their personal device ecology within a particular manufacturer ’ s ecosystem , with little support for real collaborative activities . However , the technological innovations that succeed in breaking the barriers of commercial applications and ecosystems are most often built on open standards , notably the World Wide Web , e - mail , and open file formats . Few standards do exist that support cross - device computing , and the integration of access to technologies like Bluetooth in modern web - browsers points in a direction that opens up for exploiting cross - device interactions outside the commercial or research silos . However , design of meaningful standards must be informed by rigorous studies of use , and not only confined to the laboratory ( Houben et al . 2017 ; Oulasvirta 2008 ) . This presents a chicken - and - egg problem as cross - device interaction techniques and applications are notoriously difficult and costly to build , deploy , and test . 4 . 7 . 9 Towards a Symbiosis between Cross - Device Capabilities and Human Activities Cross - device research is diverging further with new interaction techniques for mobile , wearable , and tangible devices , with various input and output modalities . While cross - device computing essentially focuses on the device , it is in itself also device - agnostic . With new device form factors , materials , mixed - reality technology , IoT Cross - Device Taxonomy 103 devices , and shape - changing interfaces there is a renewed challenge and opportunity to rethink the boundaries , purposes , and scope , of devices within a complex ecosystem . Discussion The aim of this chapter is to show that there is not “one way” of cross - device research . Instead , there is a broad range and diverse set of existing work . Our taxonomy allows for the framing of current and future research within the vast amount of existing work . Furthermore , our work showcases that that cross - device systems and tools are suitable for a varied set of interactions in a diverse set of use cases . Over the past three decades , interaction with computers has progressed from single - screen mainframe computing , to dual - screen desktop PCs , to advanced multi - display devices with gesture interactions , to the proliferation of today ’ s mobile and wearable devices . Multi - and cross - device computing has become a fundamental part of human - computer interaction research . Especially in the current — third — phase of cross - device research , and in times where mobile , handheld devices are prevalent the ad hoc nature , flexibility , reconfigurability , and adaptability of cross - device systems offers many benefits . And despite the great variety in research agendas and focus points , the common ground in this community is to understand , create , and deliver experiences that transcend the individual device . The work in this chapter not only serves as an entry to the field of cross - device computing research but allows for the framing of cross - device computing research through our taxonomy . The broad range of application domains showcase a wide variety of projects that have benefitted from cross - device interaction techniques — with knowledge work and collaboration making up almost 25 % of the applications . Part II of this thesis presents three case studies of cross - device systems within the domain of knowledge work and collaboration — specifically collaborative curation — where the insights from Part I guided the work , in particular by using the interaction techniques classification to identify suitable extensions of existing techniques , using the taxonomy overview for framing , and informing the choice of appropriate feedback and evaluation techniques . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 105 P ART II : C ASE S TUDIES OF C ROSS - D EVICE T OOLS FOR K NOWLEDGE W ORK In Part II we leverage the insights gained in Part I about cross - device principles to design novel systems , tools , and interaction techniques that enable cross - device work in three case studies of knowledge work . Chapter 5 describes CurationSpace , which applies the notions of instrumental interaction and dynamic media to curation work using cross - device interactions . Chapter 6 describes how findings from two informative studies led to the design of a CurationLens , a system that enables users to conduct curation activities either alone or in a group , using multiple devices , and enable to blend physical and digital artefacts and tools . While the first two case studies are mainly concerned with curation tasks , Chapter 7 introduces the design space and application examples for flexible and adaptable mobile device setups using SurfaceConstellations exploring cross - device interactions in broader knowledge work scenarios , beyond curation . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 107 Chapter 5 . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 6 For digital content curation of historical artefacts , curators collaboratively collect , analyse and edit documents , images , and other digital resources in order to display and share new representations of that information to an audience . Despite their increasing reliance on digital documents and tools , current technologies provide little support for these specific collaborative content curation activities . We introduce CurationSpace — a novel cross - device system — to provide more expressive tools for curating and composing digital historical artefacts . Based on the concept of Instrumental Interaction , CurationSpace allows users to interact with digital curation artefacts on shared interactive surfaces using personal smartwatches as selectors for instruments or modifiers ( applied to either the whole curation space , individual documents , or fragments ) . We introduce a range of novel interaction techniques that allow individuals or groups of curators to more easily create , navigate and share re - sources during content curation . We report insights from our user study about people ’ s use of instruments and modifiers for curation activities . 6 Parts of this chapter have been published in : Brudy , Frederik , Steven Houben , Nicolai Marquardt , and Yvonne Rogers . 2016 . “CurationSpace : Cross - Device Content Curation Using Instrumental Interaction . ” In Proceedings of the 2016 ACM on Interact ive Surfaces and Spaces , 159 – 168 . ISS ’16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2992154 . 2992175 . Steven Houben , Nicolai Marquardt and Yvonne Rogers were advisors for the work on this project , contributed to the overall concepts ; I was leading the conceptual and implementation work , as well as evaluation and write - up of the research . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 108 Figure 12 . CurationSpace provides a shared collaboration space for content curation based on instrumental interactions . Cross - Device Interactions for Content Curation There are many different curation practices , extending beyond the more traditional interpretation of a professional museum curator . One of these practices is content curation , which can be defined as the process of collecting , analysing , displaying and sharing information in order to derive new insights and knowledge and present these findings to a broader audience ( Rotman et al . 2012 ) . Curating content often requires specialised knowledg e and collaborative artefact discovery . One example of such content curation is that of historical documents , often done by ( non - professional ) historic societies or charities who collaboratively create curated data sets , formulate conclusions , and create new representations . Over the years , technology has resulted in a growing amount of information , allowing for new ways of conducting curation processes . Moreover , it enables groups to work collaboratively , using the various resources , bringing together people with expertise from different backgrounds ( Streitz , Geissler , et al . 1999 ) . The focus of our research is on curation work for ad hoc collocated resource collation . Specifically , we explore how content curation tasks , such as collecting , organising , reviewing , displaying and sharing digital content ( e . g . images , maps or notes ) , can be supported effectively through using multiple tools and devices at hand for group work . Curating digital content in a group setting , however , using multiple digital devices can be challenging because it requires a large amount of configuration work ( Houben , Tell , and Bardram 2014 ) when setting up devices and sharing resources . Furthermore , even though people use computationally powerful and interconnected devices , most of these devices are not designed to support in situ collaborative work ( Santosa and Wigdor 2013 ) . Which devices might be put to good use in order to support ad hoc CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 109 curation work ? Large displays can be used for shared curation work in combination with other hand held technologies . These offer a high resolution interaction space and allow for collaboration and exploration of large datasets ( Andrews , Endert , and North 2010 ) . However , several problems arise from using large and public displays for content curation , such as the positioning of control instruments on large screens ( Andrews et al . 2011 ; H . Shen et al . 2006 ) , territoriality ( Scott , Carpendale , and Inkpen 2004 ) , or privacy when working with private data ( Brudy et al . 2014 ) . The use of personal devices with large displays offers ways of overcoming these while also providing new methods for controlling and interacting with content . In particular , using a worn device with a tabletop allows users to personalise systems with their own content . Compared with using phones for personalised input with a larger interactive surface ( e . g . ( Schmidt et al . 2012 ) ) , the use of a smartwatch does not require to be held , leaving users ’ hands free for interactions . CurationSpace was designed as a personalised sharing system that leverages the functionality of ( i ) an individual user ’ s smartwatch for instrumental interactions ( Beaudouin - Lafon 2000 ) and ( ii ) a shared interaction space ( e . g . a large , touch - enabled tabletop or wall display ) . It was motivated by how we interact with tools in the real world , in which there exists a many - to - many relation between tools ( like pens , scissors , markers ) and objects of interest ( paper , plastic , fabric ) . The smartwatch is used to identify its user , to store and share personal information , provide the user with customised views or interfaces , while also allowing protection of private and sensitive information which a user does not want to share publicly . It is a mediator between the user and the interaction space that supports collaborative working with a focus on content curation . The shared public space is a multi - touch surface that multiple users can interact with . In terms of our cross - device design space ( Chapter 4 ) , CurationSpace supports synchronous interactions ; in a logically distributed user interface ; in an n…m relationship between people and devices ( in the study described in this chapter : two people using a smartwatch each as well as operating on a shared tabletop display ) ; operating in the near and personal scale ; in a fixed setup ; and within collocated situations . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 110 The aim of this chapter is to provide a new instrumental interaction approach for collocated curation work that ( i ) separates space , domain object and individual fragments as interaction entities , and ( ii ) uses a smartwatch to augment human touch with configurable tools that act upon these entities . Instrumental Interaction for Smartwatches The vision behind ubiquitous computing and cross - device interactions is to allow users to seamlessly interact with digital information where and when needed . As Bødker ( Bødker 1990 ) argues , users do not interact with technology but rather “ through the interface ” . Computer devices , systems , and applications are mediating tools or instruments that allow users to act upon information using systems from their environment . The notion of Instrumental Interaction was originally proposed by Beaudouin - Lafon ( 2000 ) as a POST - WIMP interaction model in which there is a strong conceptual separation between the information , data or other domain objects , and the instruments or tools that are used to act upon those domain objects . Instruments are a combination of hardware and software components that mediate the interaction between the human and the domain objects that are of interest to the user . The user interacts with instruments that translate its actions to the underlying data and provide feedback to the user . This instrumental interaction model is inspired from the observation that “ our interaction with the physical world is governed by our use of tools . ” ( Beaudouin - Lafon 2000 ) . Instrumental interaction is based on three design principles ( Beaudouin - Lafon and Mackay 2000 ) : ( i ) reification , the process of objectifying instruments and interactions , ( ii ) polymorphism , the property that allows for a single instrument to be applied to any domain object , and ( iii ) reuse , the process of leveraging previous defined objects for future use . This Instrumental Interaction model was extended by Klokmose et al . ( Clemens Nylandsted Klokmose and Beaudouin - Lafon 2009 ) into a Ubiquitous Instrumental Interaction model , in which instruments were made much more explicit in the form of reusable interchangeable artefacts that could be used on different types of domain models across different types of surfaces . Instruments can migrate from one device to CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 111 another , from one data structure to another . Although instruments can break on certain types of domain objects , they should provide an operational consistency across domain objects and interactive surfaces . Klokmose et al . ( Clemens Nylandsted Klokmose and Beaudouin - Lafon 2009 ) did not differentiate between types of devices , but rather see instruments as hardware - independent digital constructs that themselves should be easy to manipulate by other instruments . In this chapter , we differentiate between types of devices , and more specifically their role towards supporting instruments . By wearing a watch , we can automatically identify users through their touch input and gestures , which can help auto - select instruments , and more generally augment the human touch capabilities . Rather than using physical instruments , the watch can be leveraged to contextually reshape the instruments executed by our hands , as well as our human touch . The watch can in this way be used to configure and execute the instruments that are applied to a range of different document types available in CurationSpace . Wrist - based Interactions and Smartwatches This section provides additional background of previous work specific to this chapter , which was not covered in the related work chapter in Chapter 3 . Previous research has shown that the wrist is a good place to position a device that needs to be accessed quickly or frequently ( Ashbrook et al . 2008 ) . DeskJockey ( Ziola , Kellar , and Inkpen 2007 ) offloaded interface elements by projecting them onto its surroundings . Similarly , Mayer et al . ( Mayer and Soros 2014 ) introduced user interface beaming , leveraging a smartwatch to interact with smart objects in the environment . Duet ( X . Chen et al . 2014 ) extended the input space on a phone with a smartwatch , e . g . the smartwatch acts as a tool palette when editing input on the phone , and Expressy combined a wrist - worn IMU to expand the expressiveness of touch interactions ( Wilkinson et al . 2016 ) . In CurationSpace the smartwatch acts as tool selector , augmenting the user ’ s touch , and can therefore be seen as an extension of the shared surface screen . It declutters the shared surface from menu items while , similar to Local Tools ( Bederson et al . 1996 ) , allowing for quick access to the commonly used instruments . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 112 Although researchers have explored using a smartwatch as a public display ( Pearson , Robinson , and Jones 2015 ) , a smartwatch is a personal , body - worn device , which is predominantly owned and operated by a single person . Reading personal notifications is the second most common usage of a smartwatch ( after reading the time ) , and denotes overall the longest interaction time with a smartwatch ( Pizza et al . 2016 ) . Leveraging the one - user - per - device property , CurationSpace allows users to personalise input and bring private content to a shared surface . GestureWrist ( Rekimoto 2001 ) introduced hand and arm posture recognition on the wrist , Gesture Watch ( Kim et al . 2007 ) detected gestures above and around a smartwatch , and Haptic Wristwatch ( Pasquero , Stobbe , and Stonehouse 2011 ) allowed users to perform gestures , such as covering the watch - face , or interact with the bevel of a wristwatch . No prior work has explored how smartwatches can be used in conjunction with a shared space for collaborative content curation . CurationSpace introduces a collaborative document presentation system that allows users to modify its content through a number of instruments that can be selected , adjusted , and applied using a personal smartwatch . Leveraging the fact that smartwatches are body - worn and personal devices , CurationSpace allows users to bring personal content into a shared space , customising their input using instruments selected on the watch . Further , the watch can provide personal feedback through its easily visible display , not occupying any space of the shared area . CurationSpace allows for touch input on the smartwatch as well as gesture input using the smartwatch ’ s internal sensors . Scenario Description Our content creation scenario describes the process of groups collecting , analysing , displaying and sharing information — for example historic documents — in order to present it to audiences in new ways ( Rotman et al . 2012 ) : Lisa is interested in the history of the street on which she lives . She joined a volunteer - driven historic society that preserves the history of her street , through collecting , analysing , and reworking various sources of historic material , including maps , photographs , and locals ’ memories . Lisa is working together CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 113 with John on a report about the history of the local hospital . They split up their work to research different facets online , in local archives , libraries . In order to collaboratively organise and analyse their information , they meet in a library using the CurationSpace system . Lisa and John connect their smartwatches to the system . John shows Lisa a chapter of the report he has been working on . Lisa edits the text and images of the section using various instruments . Lisa also extends her collection of photos of historic maps with the ones that John has found . They review and finish the editing on one of the chapters of their building report . After two hours of exploring and sharing , they have created a new visual history of the hospital , loaded their work onto their watches so that they can continue their work at a later stage and vacate CurationSpace . Throughout this chapter , we refer back to the key curation activities from this scenario . CurationSpace The design of CurationSpace is inspired by the observations of how people collaborate and interact with physical documents during a group session ( Kruger et al . 2003 ) . First , people often organise the table into distinct spaces that serve several purposes ( e . g . often the middle of the table is used to share or present content to each other , while the edges closer to the users are used to store personal notes or documents ( Scott , Carpendale , and Inkpen 2004 ) ) . Second , to discuss and reflect on content , people often place documents ( reports or collages that are composed of smaller fragments , such as images , photos , texts , maps or other relevant resources ) onto the table , which also facilitates sharing of documents or fragments with others . Third , users utilise tools ( e . g . pens , markers , tape , pencils , scissors ) to modify , annotate and create content while interacting with the documents or fragments . Importantly , tools can be applied to different types of documents , e . g . a pen can be used to write new text , to annotate a map , or to sketch a new figure . Inspired by Beaudouin - Lafon ’ s ideas on Instrumental Interaction ( Beaudouin - Lafon CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 114 2000 ) and Kay ’ s vision of dynamic media ( Kay and Goldberg 1977 ) , CurationSpace ’ s design provides a new document presentation and interaction model that follows this clear separation between ( i ) the cross - device interaction space that is being used as part of the curation work , ( ii ) the documents that are shared in the space , ( iii ) the individual fragments that make up each document , and ( iv ) the instruments that people are using to modify and create content during the curation process ( Figure 1 middle ) . We extend established interaction techniques ( Bederson et al . 1996 ; X . Chen et al . 2014 ; Houben and Marquardt 2015 ; Schmidt et al . 2010 ) to explore a system implementation of this vision for supporting content curation tasks on a shared surface , using personal devices . CurationSpace uses smartwatches as instrument selection devices that enable people to reconfigure their hands into different tools needed to perform curation work . Based on the principles of Instrumental Interaction ( Beaudouin - Lafon and Mackay 2000 ) , CurationSpace is built around three main principles : 1 . Dynamic resources . To allow for reification ( Beaudouin - Lafon and Mackay 2000 ) , information is structured within three levels of abstractions : documents , fragments and spaces . These atomic units of interaction are exchangeable , combinable and controllable to create high level information structures . 2 . Tool multiplicity . A basic set of tools are provided that can be applied to any resource . Tools or instruments can be applied to a variety of dynamic media , allowing for polymorphism across objects types and reuse of the same tool across a suite of information resources ( Beaudouin - Lafon and Mackay 2000 ) . 3 . Personal and shared objects . Tools and objects can be personal or shared with other people . Both the hierarchical resource structure as well as the tool multiplicity are constrained by user roles and access models . 5 . 5 . 1 CurationSpace Components CurationSpace consists of two components : a smartwatch application and a touch - enabled large interactive surface . The smartwatch allows users to select instruments ( “interaction instruments” in Instrumental Interaction ( Beaudouin - Lafon 2000 ) ) , which they can apply to documents on shared spaces to change their properties . Each instrument acts on a multitude of different documents and fragments , but to the user CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 115 it only appears as a single instrument ( e . g . “ colouris e” , “delete” , or “create” ) . On the surface side ( Figure 12 left and middle ) , CurationSpace consists of three nested modules . These represent the domain objects of instrumental interaction . At the broadest level , there is an interaction space which is shared among all users and spans one or multiple interactive surfaces . Using instruments , a user creates or interacts with documents . Each document is owned by a user ; however , they can share access to a document . Each document in return can contain one or multiple fragments , e . g . text , images , or a canvas . The smartwatch ( Figure 12 right ) acts as a mediator between the user , the interaction space and the objects within , by providing a variety of instruments . Since every smartwatch is owned and worn by one individual person , they can be used to personalise the input , provide access to personal data , and allow for personal feedback . Using a smartwatch as an instrument selector reduces the need for cumbersome menu selection on the shared surface , allows for hands - free interaction and does not occupy space on a shared surface . 5 . 5 . 2 General interaction with CurationSpace CurationSpace starts with an empty interaction space . A user interacts with the space by applying instruments . For example , touching the interaction space will automatically use the create instrument to produce an empty rectangular shaped document . Documents can be resized and repositioned . Each document is either private or public , defining who can interact with it and blocking access to unauthorised users . Authenticated users ( the owner ) can manipulate their own documents using multi - touch gestures on the surface , which are defined by the selected instrument on the smartwatch . A private document can be made public ( shared ) by the authenticated user using the share instrument , allowing everyone to interact with it . One or multiple fragments can be added to each document . Fragments contain either text , images , or a canvas and can also be manipulated using instruments . When interacting with their own document , the user ’ s smartwatch lights up in a matching colour to indicate the connection . The watch also shows the currently selected instrument . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 116 Instrument selection may occur automatically , based on the current context , or manually through explicit user selection . The user interacts with the shared space using the selected instrument . An instrument can be deselected either implicitly by selecting a new instrument , or explicitly by tilting the smartwatch . The functionality of some instruments is contextual , based on the type of domain object with which the user is interacting . This contextual difference lies in the nature of instrumental interaction and the system has to mediate ( Clemens Nylandsted Klokmose and Beaudouin - Lafon 2009 ) . This mediation is integrated into our system ’ s underlying architecture : domain objects “understand” how to react to the application of instruments ( through an event model ) and therefore mediate the instruments ’ effect on them . The connection with the shared space can be broken by covering the smartwatch . This results in all documents being removed from the space and offloaded to the smartwatch . 5 . 5 . 3 Technical implementation of CurationSpace CurationSpace is implemented on a modified Microsoft Surface 1 . 0 SP1 tabletop running Windows 7 . The system runs a distributed message and content server based on SignalR that connects the watches ( and potentially other devices ) to the surface application . We used a Sony SWR50 SmartWatch 3 , running Android Wear , connected to an Android smartphone via Bluetooth connection . The phone acts as a proxy between the smartwatch and the tabletop , allowing for a network connection between tabletop and smartwatch . The smartwatch transmits sensor data , instruments , and content selection to the tabletop , and receives system status updates . A touch on the surface is considered authenticated , when it can be associated with a particular user . In our setup , a user wears a glove with fiducial markers attached to the finger ( similar to ( Marquardt , Kiemer , et al . 2011 ) ) . Since each smartwatch belongs to an individual person , it can provide the fiducial marker IDs of its user to the system , therefore identifying the user to the system . It also acts as a private content repository , allowing a user to bring in their own data . The smartwatch has touch input , and its integrated IMU can be used for gesture recognition ( e . g . the user disconnects from the system by covering the light sensor of the watch ; or performs a CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 117 tilt gesture to deselect the selected instrument ) . Further , it extends the shared surface to provide personalised , private feedback . Available instruments are shown in a grid - layout ( Figure 12 , right ) and content in a scrollable list ( Figure 14 , top ) on the watch ’ s screen . CurationSpace represents the core ideas of Instrumental Interaction in its underlying distributed system architecture , in which instruments are object events that can be triggered on domain objects . It is not the instrument that defines its effect , but the domain object that reacts to the event of instrument - application . Introducing new instruments means simply introducing a new object event , implementing the receiver on the domain objects and its reaction to the event . If no event listener is implemented , the domain object will simply ignore the application of that instrument . Instrument mediation and instruments ’ many - to - many relation with objects is therefore integrated into our system ’s architecture : domain objects “understand” how to react to the application of instruments ( object events ) and therefore mediate how to react to an instrument ’ s application . Furthermore , when no tool is selected , some domain objects trigger automatic tool selection upon a user ’ s touch , e . g . when no tool is selected and the user touches the interaction space , the “create” instrument will be automatically selected . 5 . 5 . 4 CurationSpace Instruments Instruments customise users ’ touch input , which extends it beyond the normal binary touch . As laid out in the instrumental interaction model ( Beaudouin - Lafon 2000 ) , the conceptual separation between domain objects ( documents in CurationSpace ) and instruments frees instruments to be reusable artefacts which can be applied on different domain models . While one instrument ’ s usage is consistent across domain objects , the underlying interpretation on the data depends on the domain object . Differing from the work by Klokmose et al . ( Clemens Nylandsted Klokmose and Beaudouin - Lafon 2009 ) , CurationSpace does employ device boundaries , differentiating between each user ’ s smartwatch and the shared spaces . We argue that using the watch as an explicit instrument selector allows the differentiation between an individual ’ s instrument and work , and thus allows group collaboration on a shared interaction space . Each user ’ s smartwatch serves as an instrument selector and a CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 118 personal identifier , receives personal system feedback , and provides a personal content repository . Using and adapting these instruments allows users to contextually re - configure and augment touch input . Our set of instruments is informed by the key curation tasks of our user scenario . Depending on the current system state the instrument is being applied to , these affect and alter the domain objects in different ways . • Create instrument : Allows users to create documents and fragments . The watch acts as an identifier and holds users ’ personal data to be shared with the space . This instrument is the default instrument when interacting with the space itself while no other instrument is selected . • Manipulate instrument : Selecting an object or fragment allows the user to change its position , rotation , size , and to crop it using multi - finger gestures . The smartwatch acts as an identifier and tool selector for further operations . This instrument is the default instrument when interacting with a document or fragment while no instrument is selected . • Colour instrument : Using the smartwatch a user can select a colour on their smartwatch . The colour instrument can be applied to different domain object , e . g . it can be used to draw on a canvas , highlight parts of an image or colour text . • Increase / decrease instrument : These instruments allow the user to zoom in on a picture , increase the font size of a text , or show a document in full screen mode or vice versa . • Erase instrument : The erase instrument acts as an eraser on a canvas , can be used to delete text through selection , remove images by touching them inside a document , or eradicate an entire document from the space . • Copy instrument : This instrument allows the user to duplicate a document or image fragment , or to copy and paste text through selection . • Share instrument : Created documents are owned by one user . Sharing a document allows other users to manipulate the documents . These instruments should be seen as an example list of tools demonstrating the concepts of using Instrumental Interaction for content curation tasks , rather than an exhaustive set . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 119 Interaction Techniques for Curation Tasks In the following we illustrate how these atomic instruments support collaborative content curation , by using the smartwatch for instrument selection , feedback display , and personal content repository . We illustrate the nuances of these techniques with our scenario application . Figure 13 . Using the implicitly selected create instrument ( left ) a user creates a new document on the interaction space ( right ) . 5 . 6 . 1 Creating Documents and Adding Content into Fragments Creating new documents for arranging curation content is one of the key content curation tasks . We designed instrumental interaction smartwatch techniques to facilitate the ad hoc creation of documents and adding content directly in context : John wants to share photos of historic maps he has found in the archives . To start , he touches an empty area on the interaction space . After a 1 . 5 second dwelling time ( to prevent accidental document - creation ) a new document is created ( Figure 2 ) . The system selects this function automatically because on the empty interaction space no other instrument than the create instrument has an effect . After creating a new document , John wants to add pictures . He explicitly selects the create instrument on his watch , which then presents him with thumbnails of the content he can share from the watch ( Figure 14 small inlay top ) . He can cycle through the text and images through touch gestures , and select the desired image of the map , adding it as a new image fragment to the document . The content is added to the document he last activated through interacting ( touch or move ) with it . Figure 14 shows a screenshot of interaction space containing five documents , of which two are docked to the side . Two documents are owned by John ( green border ) , two by Lisa ( purple border ) , and one has been shared publicly , allowing everyone to access CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 120 it ( white border ) . CurationSpace supports different document types . Currently implemented are text ( Figure 14 , middle right ) , images ( Figure 14 , middle left ) , and canvas ( Figure 14 , bottom right ) . Documents ’ borders are marked in their owner ’ s colour ( here : green and purple ; white borders indicate public access ) , and can be docked to the side to declutter the interaction space ( Figure 14 , bottom ) . Figure 14 . The smartwatch acts as a personal content repository ( inlay top ) , allowing users to share their personal data . 5 . 6 . 2 Manipulate and Organise Documents and Fragments When sorting through documents , people employ the space around them ( Andrews , Endert , and North 2010 ) . Using the document system , CurationSpace allows users to spatially arrange their content . The manipulate instrument is the default instrument when interacting with documents while no other instrument is selected , and can be used to position , resize , and rotate documents . For better overview , documents can be docked to the sides of the display , shrinking them to small preview icons ( Figure 14 ) , or enlarged to take up the whole screen . This allows for a large number of documents to be used , while not cluttering the interaction space . The increase / decrease instrument can also be used to resize documents by touching their borders and to zoom in on images or increase text font size ( Figure 15 ) . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 121 Figure 15 . Using the increase instrument . Since Lisa sits opposite John , he uses the manipulate instrument to spatially organise documents on the surface , by moving them around , rotating them using simple gestures , or to resize them . The manipulate instrument can be used on whole documents , as well as image and canvas fragments . John looks through the photos . Using the manipulate instrument , he can crop , resize , and rotate the image fragments . John shows Lisa the text he has been working on . He increases the font size , for easier reading . 5 . 6 . 3 Share Access to a Document with other Users Finding and sharing artefacts ( digital and physical ) with collaborators is one of the key curation activities , allowing more insight to be gained ( Streitz , Geissler , et al . 1999 ; Rotman et al . 2012 ) . However , not all content should be editable by everyone as people care about their personal data and boundaries ( Brudy et al . 2014 ; Scott , Carpendale , and Inkpen 2004 ) . In CurationSpace documents are therefore owned by an individual person and cannot be manipulated by others unless explicitly shared . Using the share instrument , the ownership of multiple documents can be changed through the touch of an authenticated finger . Lisa wants to erase a paragraph of text in a document . She selects the erase instrument on her watch and attempts to erase the text . However , John has not CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 122 granted her access to the document so she can view it , but not edit it . In order to share the document , John selects the share instrument on his watch , and applies it to the document with an authenticated touch . This transfers the ownership of the document to the public , making it editable by anyone . Lisa can apply the same instrument to the public document , transferring ownership to her . 5 . 6 . 4 Edit Content , Documents , and Fragments As part of the curation activities , documents are also analysed and reworked into new representations . Text needs to be deleted , important area marked on a map , or essential paragraphs in a text highlighted . In CurationSpace various editing instruments ( e . g . colour instrument to draw , highlight or change text colour , see Figure 16 ) are available for these tasks . Using instruments , a user can rapidly multitask between different objects . For example , John can highlight sections of text as well as visually mark sections on a map . Figure 16 . Using the colour instrument , the user can set the paint of his drawings or change the colour of text . John has a draft chapter about the hospital at home , on which he wants to work further with Lisa , while also marking key spots on a map . He uses the create instrument to add a text fragment to a document . He then uses the colour instrument to change the colour of text when highlighting it and to draw on the CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 123 map . Together Lisa and John mark places on the map with their occurrence in the text in the same colour . 5 . 6 . 5 Erase to Delete Content , Fragments , and Documents The erase instrument works on fragments or their contents , but also on whole documents . Once selected , a user can for example erase drawings on a canvas ( Figure 17 top ) or selected text , remove images , or delete entire documents ( Figure 17 bottom ) . This helps to keep the curation space clean by quickly erasing content that is not needed anymore . One of the photos is irrelevant for the current chapter . Lisa selects the erase instrument and applies it to the image . In fact , she can delete any fragment or entire objects by touching their borders . Applying the erase instrument to the inside of a fragment allows her to remove part of the content , for example to erase parts of a drawing on a canvas or an image , or to delete parts of a text by selecting it . Figure 17 . The erase instrument can be used to erase drawings on a canvas or image ( top ) and to erase documents ( bottom ) . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 124 5 . 6 . 6 The Watch as a Clipboard and Document Repository Non - public documents are marked in their owner ’ s colour . When disconnecting from CurationSpace by covering the watch with the entire hand , all documents are saved on the owner ’ s smartwatch , removing all private documents from the shared space . To clear up space , documents can be docked as icons to the sides of the interaction space using the manipulate instrument or the decrease instrument . Lisa wants to continue working on a text at home and gives John a copy of the text . She uses the copy instrument to duplicate the document , and transfers ownership of one of them to John using the share instrument . When disconnecting , the documents are offloaded to their smartwatches . At a later time , instead of creating new documents , they load previously used documents from their watch : when using the create instrument , previously created documents are available . User Evaluation To evaluate people ’ s interaction with the instruments in CurationSpace , we conducted a scenario - based user study . The scenario was constructed in a way that allowed participants to learn the system while using it , by incrementally introducing new aspects and tools . The aim was to gain insights into how the fundamental concepts were understood and appropriated by curators . Participants were recruited from different backgrounds who conduct curation tasks or related activities as part of their daily jobs ( historian , librarian , financial consultant , civil servant , researcher ) . After answering a pre - study questionnaire , participants completed the scenario . The researcher acted as collaborator . They were guided through their tasks and asked to think aloud . The study was video recorded for later analysis ( the methodology described in Chapter 2 contains more details ) . Participants ’ touch interaction with the tabletop and the interaction with the smartwatch was recorded for later quantitative analysis . Through a post - study questionnaire and semi - structured interview after completing the scenario further qualitative feedback was elicited . The videos of the tasks as well as the video recordings of the semi - structured interviews CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 125 were analysed using the software ChronoViz ( Fouse et al . 2011 ) using open coding . After iterating and merging the codes , the following higher - level codes resulted : general feedback , understanding of instruments , conflicts and unexpected behaviour , collaboration , curation behaviour , appropriation of space , appropriation and real - world usage . 5 . 7 . 1 Procedure We recruited 8 participants ( 4 female , 4 male ; 27 - 35 years old , mean 30 ) from different backgrounds ( historian , librarian , financial consultant , civil servant , researcher ) . Participants rated themselves as average to experienced computer users ( median = 3 . 5 ; iqr = 1 on 5 - point Likert scale ) and to be experienced using multiple devices ( average number of owned devices = 4 . 12 ; stdev = 0 . 6 including smartphones , smartwatches , tablets , e - reader , laptop and desktop PCs ) . Participants were introduced to the task , signed a consent form and answered a pre - questionnaire . We then asked them to complete a scenario using CurationSpace . Each smartwatch was preloaded with photos , text , and maps . Participants were asked to complete both individual and collaborative tasks ; a researcher acted as their collaborator . They were guided through their tasks and asked to think aloud . After completion , a semi - structured interview and post - study questionnaire followed . Participants enacted the following scenario : they are meeting with a collaborator to work on a report about architecture and landscapes in London . The report should eventually consist of images and text about the topic . Prior to the meeting they created a pre - selection of images and text and preloaded them to their smartwatch . They were asked to add content ( images , drawings , text ) to the shared space ; explore images , maps and text ; create new sketches ; highlight sections of images or text ; delete parts of drawings , text or entire documents ; group and arrange content ; and share it with their collaborator . These tasks required users to go through the content on the watch , add them to the interaction space and use various instruments ( colour , erase , increase , decrease , create ) . The aim was to explore the core tasks of curation supported in CurationSpace ( collecting , analysing , editing , sharing ) . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 126 5 . 7 . 2 Results User Feedback : Figure 18 shows an overview of participants ’ answers from the post - study questionnaire . Participants found the system easy to use ( Q6 . Md = 4 ; iqr = 1 . 5 on 5 - point Likert scale ) . Although one participant found that the watch distracted him from his main task , most participants found the watch useful ( Q8 . Md = 2 ; iqr = 1 . 75 ) and it was generally seen as a useful companion for tool selection ( Q4 . Md = 4 ; iqr = 0 . 75 ) . Participants found it useful to share personal data from the smartwatch to the shared space ( Q3 . Md = 4 ; iqr = 1 ) and all participants agreed that moving information between watch and shared space was easy ( Q1 . Md = 4 ; iqr = 0 ) . Figure 18 . Results of the 5 - point - Likert - scale of all 8 participants to the post - study questionnaire about CurationSpace . Understanding of instruments : The scenario was set up in a way that participants learned the system on - the - fly . They explored the functionality of the smartwatch and its interaction with the shared surface through the task and did not have a high learning barrier ( Q10 . Md = 2 ; iqr = 0 ) . Users understood that instruments were atomic tools that could be applied to the space , a document or the content of a document . For example , P7 used the increase / decrease instruments to change picture and document sizes . Later , she wanted to replace an image with a different one and decided to try the erase instrument because she thought it could be applied in a similar way as learned before with the other instruments . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 127 Order of applying instruments : CurationSpace follows the principles of reification , polymorphism and reuse ( Beaudouin - Lafon and Mackay 2000 ) , in that an instrument can be applied to different objects of interest . Users expected instruments to work similar to existing tools in GUI ( such as Microsoft Word ) , where the order of application is different : object selection first , tool selection after , whereas in CurationSpace it is the other way around . Although all users understood how instruments worked after experiencing one instrument across multiple domain objects , initially different expectation about their mode of operation sometimes led to confusion . P3 summarised his understanding of how tools work : “ the tools seem to work forward , rather than on previous selections . Rather than selecting something and then selecting the tool , I have to select a tool and then apply it to something . Which is counterintuitive to what I am used to in a desktop PC . ” He continued : “this system differs very much from my current working style . For example , I see that [ the erase tool ] works like a regular eraser with a pencil drawing , but I feel like I need to unlearn a lot of things [ in order to use it ] . ” On the contrary , P4 argued : “ once you know which way it works it ’s easy . [ Pick up an ] instrument and go” and P8 notes : “It’ s different from how I use [ tools ] on a computer , but similar to a pencil . So I guess it ’ s just a mind - set . ” P6 suggested a new transparent - instrument , which could reverse the order of operation : First he selects an object using this instrument and then applies , say , the colour instrument afterwards . Awareness and conflicts : The smartwatch provides personalised feedback to the user , showing which tool was currently selected . When moving their attention away from the watch to collaborate on the shared space , we observed situations where users forgot which tool was selected . For example , after deleting some text , a participant sat back to proof - read the result . She then wanted to rotate the document to share it with her collaborator . Since the erase - instrument was still selected , the entire document disappeared : “ I expected it to confirm first . But it ’ s handy , you just have to know that it ’ s gone once you apply it ”—P7 . As a solution P2 said “ I ’ m a forgetful person . So I imagine if you have done a lot of work together and then erase a little bit and forget to switch it off , I might accidentally erase something . [ … ] A small pictogram of the selected instrument on the shared screen or confirmation if you are about to delete something would be good ” . P3 suggested a timeout to automatically deselect a tool after an amount of time not using it . CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 128 Use in real world practices : Overall , most participants could imagine themselves using CurationSpace in their curation workflows ( Q7 . Md = 3 . 5 ; iqr = 1 . 75 ) : “ it is much easier to share information between multiple people rather than watching it behind your screen ” ( P2 ) . P7 adds that she “ can be selective and only share what [ her ] colleague needs , who in return can then select [ what ] he wants to have on his watch and not bombarding him with all the documents ” . P5 reported that she does not see any application of the system in her current work : “ I do everything electronically and send it and talk about it via email ” . P3 suggested “ if [ the shared space ] were in a different format , say a large whiteboard , where it was more a presentation format , rather than an intimate format , then I ’ d see much more of an application for this ” . P3’ s mentioned that he does not see any advantage of using CurationSpace in his work : “ I print everything and it ’ s a lot easier to do all of these things with paper ” . P7’s perspective differs : “ we have all the documents online and it ’ s not like we print anything anymore . I was working with a colleague earlier , and we had to squeeze in front of one computer , but couldn ’ t work together at the same time ” . Figure 19 . Heatmap of participants’ touch patterns on the shared space , showing the main interaction zones . Usage of space : Participants appreciated a shared space for group work ( Q2 . Md = 5 ; iqr = 0 . 75 ) . The instruments of CurationSpace did not hinder the interaction with the tabletop , as the observed usage pattern reflect similar observations in prior work ( Scott , Carpendale , and Inkpen 2004 ) , where group , personal and storage territories exist . Figure 19 shows the usage patterns across the shared surface of CurationSpace CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 129 ( except P3 , as this data file was corrupted ) . Participants were seated to the top left ; their collaborator was seated across from them ( bottom left ) . Participants usually started their interaction in the space in front of them and then shared documents by moving them to free space on their collaborator ’ s side ( bottom right ) . Privacy : Most participants saw the benefits for collocated group work and using a personal device for selecting shareable data . “ There is an element of privacy when selecting documents from a smartwatch . If you are using it in a really collaborative setting , I am happy for everyone to see everything . But with different stakeholders or sensitive data , then it is much better to use it on a personal device ” ( P1 ) . P2 compared it using the smartwatch to opening images from a folder : “ It depends a bit on what information you are sharing with who . If it ’ s a good friend , I wouldn ’ t mind that they see pictures I didn ’ t want them to see . If it ’ s my boss , I would not want them to see everything . [ CurationSpace ] is much better in only showing what I want to show . ” And P1 added “ I have most of the information already located on a cloud - based service [ which is connected to my ] smartwatch . So , I wouldn ’ t need to bring a USB stick or anything else . ” Suggestions for tools : Participants suggested further instruments : P8 wanted to rearrange 12 different documents on the shared space and felt it was cumbersome to do so with the manipulate instrument because it meant rotating , moving and resizing every single one . She suggested to add predefined sizes , positions , rotations and orientations within the manipulate instrument that could be applied with a single touch to any document . P2 suggested a share instrument to “ save everything on the table itself , but also you could select if you want to save it only on your watch or on the other ’ s watch ” . This could also be extended to save the entire state of the system , allowing users to resume a curation session later . Discussion and Conclusions CurationSpace was designed to provide a new document presentation system that applies the concepts of Instrumental Interaction ( Beaudouin - Lafon 2000 ) and dynamic media ( Kay and Goldberg 1977 ) to content curation of historical documents on interactive surface . A distinguishing feature from other cross - device systems is a clear separation between the interaction space , the high - level documents of interest , the atomic fragments that make up the documents , and the instruments that are used CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 130 to modify or create content . CurationSpace serves as an example of how smartwatches can be utilised to augment human touch with a vocabulary of interactive instruments that allow for menu - less content curation resembling interactions with physical documents and tools , in a cross - device setting . Users can transfer their content from a smartwatch onto a collaborative interaction space , allowing them to keep the ownership and control over their content until they explicitly share it with their colleagues , preventing friction and issues , such as territoriality and privacy concerns , that can occur when items were shared too early or are not meant to be edited and used by others . Through the user study we found that CurationSpace in its current form is easy to use and participants found it well suited for collaborative tasks . The tasks in the user study followed our initially introduced scenario . We found the main curation tasks were effectively supported ; participants were able to review , edit and share documents with their collaborator . Although the order of applying instruments to domain objects follows the interaction mode with physical tools ( pick up first , then use ) rather than GUIs ( selection first , then pick tool ) , this model was understood by participants but needed learning . In particular , with sensitive content or in more formal social settings , participants saw benefits of a private , body - worn content repository . Although the smartwatch application showed the currently selected instrument at any time , some participants , while discussing their curations works , forgot which tool was selected . This should be considered in any future work , for example , the system could either provide mediation ( e . g . timeout or confirmation with the erase instrument ) or a more prominent status feedback , in particular with critical instruments . The user study lasted approximately one hour and throughout this time we saw how participants got accustomed in sharing and editing documents . However , real world curation activities usually last longer and might span across multiple sessions on different days . Use of smartwatches for instrumental interaction : Although previous systems have proposed related interaction techniques to allow for cross - device information management , privacy applications , and personalised content , these are mostly based on smartphones interacting with the table . Compared to watches , smartphones are harder to manipulate , take up space on the table , and are not particularly suitable for CurationSpace : Cross - Device Content Curation Using Instrumental Interaction 131 many of the instruments introduced in CurationSpace . Furthermore , the ability for users to pass around or share tablets and phones as ( semi ) shared devices creates operational inconsistencies connected to identifying the user or maintaining the user ’ s personal information repository . In contrast , smartwatches are rarely passed around and thus are a much more suitable personal “passport” of the user . Hardware limitations : To authenticate a user on the tabletop display , our system uses fiducial marker attached to the fingertips of a glove ( similar to TouchID ( Marquardt , Kiemer , et al . 2011 ) ) . However , with the advent of novel touch sensing technologies , in the future screens will be able to identify a finger through internal sensors , e . g . as proposed in DiamondTouch ( Dietz and Leigh 2001 ) , with IMU sensors such as in SwipeID ( Kharrufa et al . 2015 ) , through fingerprint sensors in a touch screen ( Holz and Baudisch 2013 ) , or use top - mounted tracking systems ( e . g . GroupTogether ( Marquardt , Hinckley , and Greenberg 2012 ) or HuddleLamp ( Rädle et al . 2014 ) ) combined with gesture recognition on the smartwatch . Generalizability : The concepts , document model , and watch - centric instrumental interactions can be applied to other domains , applications , and user groups beyond content curation . CurationSpace introduces users to a reconfigurable shared and instrumented configuration space ( Houben , Tell , and Bardram 2014 ) that allows users to modify any content that can be modelled , visualised , and shared in the < space , document , fragment , instrument > structure . Furthermore , the intrinsic separation between instruments and documents allows for great flexibility to extend the system with many new instruments , or even customised combinations of instruments . In the next chapter , CurationSpace ’ s document model will be expanded to the physical space , allowing users to use both physical and digital documents . By creating consistency between how people interact with digital and physical documents , the aim is to provide users with a uniform interaction model across digital devices and physical tools for curation work . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 133 Chapter 6 . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Digital and Physical Artefacts 7 The history of curation — described in section 3 . 3 — provided a broad introduction to what curation means today . To better understand the activities involved we conducted a series of interviews with professional curators , as well as volunteer curators in a historic society . From these interviews , we synthesised insights into curation practices as well as opportunities for design . Informed by these findings , we developed CurationLens — a set of novel interaction techniques that support fundamental curation activities : digitising , analysing , annotating , and sharing . CurationSpace — described in the previous chapter — supported curation activities by combining personal smartwatches with a shared interactive tabletop display , allowing users to apply the instruments to different digital objects . CurationLens is a hybrid tangible - digital system , which allows for fluid transition when curating a mix of digital documents and physical artefacts . In particular , CurationLens enables : digitising , through tangible capturing techniques ; analysing , by rapid comparison and quick recall tools ; annotating with metadata through automated and manual tags , as well as textual , time , and location information ; and temporary and permanent sharing , 7 This work was conducted in collaboration with Steven Houben , Abigail Sellen , Kenton O’Hara , Yvonne Rogers , and Nicolai Marquardt . The listed collaborators were advisors for the work on this project , contributed to the overall concepts , and write - up of research project ; I was leading on the conceptual and implementation work of this research . Microsoft Research Cambridge provided a space to conduct some of the interviews with curators . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 134 with a fluid , reconfigurable digital canvas . CurationLens is a collaborative system that enables small groups to use their shared knowledges to conduct curation tasks . The work in this chapter has two core contributions : ( i ) insights from interviews with curators about the fundamental curation activities of digitising , analysing , annotating , and presenting artefacts and how these led to our design of CurationLens ; and ( ii ) CurationLens , a set of interaction techniques and tangible tools — namely CurationArranger , CurationSnapper , CurationProjector , CurationTwirler , and CurationBuzzer — supporting individual and collaborative curation of artefacts . Related Work : Tangible Interactions Before we explain our set of CurationLens tools and interaction techniques in more detail , we review technical related work around tangible interactions that inspired our system design . Tangible interaction ( Ishii and Ullmer 1997 ) and tangible user interfaces have been proposed to enhance collaborative tasks on interactive systems because of their affordance and visibility ( Hornecker 2002 ) . Augmented Surfaces ( Rekimoto and Saitoh 1999 ) provided a collaborative interaction space where physical and digital objects co - exist and allowed for cross device transfer of documents . Streitz et al . presented i - LAND ( Streitz , Geissler , et al . 1999 ) , their vision of an interactive landscape where users can create their custom workspace by combining different computing components and Tangible Views ( Spindler et al . 2010 ) using cardboard to create spatially aware lightweight ad hoc displays using an overhead projector . The notion of Blended Interaction ( Jetter et al . 2012 ) describes hybrid tangible - digital systems and environments that map elements through different domains , by blending properties of physical objects with the computing power of digital systems . Essentially it enables the use of computers with the same natural cognitive processes as when interacting with physical tools , thus allowing for fluid interactions between physical and digital tools and systems , for example around interactive tabletops ( Jetter et al . 2011 ) or wall displays ( Haller et al . 2010 ) . Building on this earlier work on enabling novel ways to interact with digital and physical content , our own work of CurationLens supports curators to collaborate in a bring - their - own - device ( Ballagas CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 135 et al . 2004 ) scenario . It is portable and supports ad hoc curation activities . CurationLens enables curation in a mixed setting of physical and digital artefacts through blended interactions ( Jetter et al . 2012 ) , in a reconfigurable workspace where devices have flexible , implicit or explicit roles , allowing them to employ their physicality to support curation processes . Eyes - free interaction , fast and smooth toggling between layouts , metadata , and individual as well as shared interactions are at the core of our designed curation tools . In terms of our cross - device design space ( Chapter 4 ) , CurationLens supports synchronous and asynchronous interactions ; in a mirrored , distributed , or migratory user interface ; supporting one or many people as well as one or many devices ( n…m relation ) ; on personal and social scales ; in ad hoc mobile setups ; and within collocated situations . Fundamental Curation Activities Informed by Interviews with Curators To gain insights into actual curation practices , we conducted a series of semi - structured interviews with professional museum curators and volunteer curators . The aim of these interviews was to gather information about curators ’ activities , the curation process in general , and their use of digital and physical artefacts and tools . The first four interviews were with volunteer members of a historic society ( V1 - V4 ; 3 female , 1 male ) , curating the cultural and social history of a town ’ s high street . We then conducted five interviews with professional museum and freelance curators ( C1 - C5 ; 3 female , 2 male ) . Table 7 gives an overview of workplace and background of the interviewed curators . The themes overarching the questions for both groups were generally the same , however the questions differed in detail to accommodate participants ’ different settings and backgrounds . In general , we asked questions about ( i ) their overall role and activities ; ( ii ) the results and outcomes of their work ; ( iii ) their workspace ; ( iv ) their tools for accessing artefacts and editing information ; ( v ) the digital and physical divide , e . g . how physical artefacts interplay with digital information , handling of artefacts ; and ( vi ) collaborative work and group dynamics . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 136 The interviews were either conducted in our office , at the curators ’ workplace or museum , or via phone . Each semi - structured interview , lasting between 60 - 80 minutes , was audio recorded , transcribed , and then analysed following the pragmatic approach to Thematic Analysis as described in Chapter 2 . We used the themes of our questions as initial codes , creating new codes along the way . The following higher - level themes resulted : expert selection , physical & digital divide , use of digital surrogates , multiple views & juxtaposing , metadata and tags , overview & colour coding , ad hoc workspaces , and diverse sharing requirements . Description , task , and duties V1 - V4 Members of a volunteer - driven historic society , researching the history of a high - street in their town . The group is formed of volunteers from various backgrounds , working on the project in their free time . Their aim was also to connect with the local community , which meant they did not only go to archives in order to collect information , but also met with people directly who could contribute relevant information about the street . C1 , C3 Curator at a university ’ s museum . Only curator in the museum . The museum is part of a department , consisting of further museums , each with one or multiple curator ( s ) . Tasks are : Conducting research ; creating exhibitions ; teaching duties ; managing loans ; engaging with other departments about further collection usage through research , exhibitions or other forms of collaboration . C2 Large , national museum ’ s curator . Museum has a departmental structure . Part of a larger team of curators and curatorial assistants , each focusing on a particular time era , within the departmental structure of the museum . C4 , C5 Freelance curator . Working alone and in teams of other curators for private clients or larger museums . Works for “ whoever pays for it ” ( C5 ) . Table 7 . Overview of the interviewed curators , their work environments , tasks and duties ( V = curator in volunteer - driven historic society ; C = curator in professional environment ) . In the following we describe our findings F1 - F8 from these interviews relating to the fundamental curation activities of selecting , reviewing , and presenting ( described in section 3 . 3 . 3 ) . Where relevant , we refer to literature and previous curation frameworks . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 137 6 . 2 . 1 F1 | Expert Selection : Curators are Expert Selectors Curation is about identifying , selecting , and reducing the information from a vast collection of information to be more targeted and focused for its further use . Curators are expert selectors , who have either gone through significant training and practice or have — through their extensive interest and devotion for a topic —otherwise “ built up specialist ’ s knowledge ” ( C1 ) about a topic which they bring into the process . Curators find , organise , and share information around a relevant topic ( Bhaskar 2016 ; Obrist 2015 ) . This not only means simply copying content , but more value , insights , and relevance has to be added for the curated result to go beyond the original content . This selection involves different perspectives , e . g . ethical , professional — but also personal , as curation often entails subjective views on a subject ( Bhaskar 2016 ) based in prior experience , knowledge , and expertise . Curators are trusted for their abilities to select the most relevant , meaningful , or otherwise important material . As a result their choices are appreciated and other people — the curators ’ audience — trust them to select and present the most relevant content , because of their expertise in a field ( Bhaskar 2016 ; Sabharwal 2015 ; Sternfeld 2010 ) . For example , C3 mentioned that in their museum , only “ [ 10 % of objects ] are on display ” . Thus , the collection must be narrowed down to a selected few . This happens with a particular focus , e . g . on certain artefacts or storyline . Sometimes , the selection process can be even more constrained . For example , as C1 described , their museum only has “ very little temporary exhibition space ” ( C1 ) , where only “ one or two objects can be [ physically ] part of an exhibition ” . Similarly , C2’s museum creates exhibitions around “ just one object ” ( C2 ) . There are various possible starting points when starting a new curation project ( e . g . an exhibition ) : a common source for first starting points was a web search ( V1 - V4 ) , and professional curators also relied on prior subject knowledge and reaching out to contacts in their professional network . External factors can also trigger this process of selection . C3 described how his museum was given the “ opportunity to borrow a [ … ] famous painting ” , which then initiated the planning for a new temporary exhibi tion . The team then created a story around this painting , selecting other artefacts from the museum ’s collection that would fit around its storyline . Generally , curation is “ very CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 138 much about [ … ] telling a story” ( C2 ) . Similarly , C1 described collaborative work where the other curators “ said they wanted this object [ … ] or we’ d say , ‘ this we could use from our collection or borrow from another collection to tell the story ’ ” ( C1 ) . 6 . 2 . 2 F2 | Physical + Digital : Curators Handle Diverse Types of Both Digital Information and Physical Artefacts Curation can entail a vast variety of different kinds of information and artefacts . This may range from physical artefacts , to text documents , to video and audio material . For example , for V1 - V4 the information consisted mainly of historic newspaper articles , maps , meeting minutes , planning applications , people directories , photographs , audio recordings , handwritten notes , etc . For professional curators , handling physical artefacts is more common at the very beginning of a curation phase ( e . g . a new exhibition ) and then again later , when the exhibition gets closer . Often a single object is used as a starting point for a narrative and curators try to decide on the final object list early on throughout a curation process , “ usually in the first 2 - 3 weeks of the whole 6 - months process ” ( C2 ) . In the middle part , the physical object is not as relevant and “digital surrogates” are a sufficient placeholder . 6 . 2 . 3 F3 | Digital Surrogates : Curators Frequently Work with Digital Representation of Curation Artefacts Rather Than the Physical Artefact Curation often involves both physical and digital artefacts , and digital metadata about these artefacts . Together these build the content of curation activities . However , among all the interviewees there was a preference to work with digital documents over physical . This meant , that as a first step physical artefacts often needed to be digitised — even if just by taking a picture with a smartphone ( V1 - V4 , C1 , C3 , C5 ) . This could later be used to recall what is available and share material more easily with collaborators . For example , for V1 - V4 , digitising physical artefacts was in many cases the first step . This enabled flexible replication , rearranging , annotation , and sharing . People joined CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 139 and left the project at various stages . When a new person joined a team , they could be easily added to a shared folder and thus share the information , “ without carrying boxes of material ” ( V2 ) . Further , most of the information is only accessible as a digital copy , as the original artefact is either in storage or can be taken only for a short - term loan . For the work of the museum curators we found different strategies for how digital photos were taken . For example , C1 explained that they “ photograph every new [ artefact , ] measure it [ and put it in a database ] ” , whereas C3 said they “ don ’ t photograph everything anymore ” because “ most of the photographs are never used ” ( C3 ) . However , throughout the curation process ( e . g . when planning a new exhibition or leaflet ) , a digital representation was often used as a visual reminder . High quality material is produced at later stages when needed ( e . g . for press material or images for visual design ) . 6 . 2 . 4 F4 | Multiple Views and Juxtaposition : Curators Analyse Content and Find Insights Through Different Views on the same Artefacts Through Juxtaposing , Comparing , and Grouping The analysis process during curation is concerned with reducing and combining artefacts into new meanings , making connections between items , and drawing conclusions . As part of this , the source materials are filtered , screened , reviewed , and compared . This is where new connections are made , existing connections reconsidered and ( historically ) evaluated , and circumstances are explained . For example , curators often needed different views on the same artefacts or data . V3 explained how they had “ maps of [ the same location ] from different times ” and “ wanted to see how [ the area ] had changed over time ” through “ overlaying the maps ” visually and crossfading between them . This visual analysis of information was mentioned by several of our interviewees . C1 said that sometimes the same artefacts need to be displayed along “ multiple dating system [ … ] or periods ” . V4 wanted to visually arrange photos of objects along with two different maps : first where the photo was found / collected and second , the depicted location itself . Using digital representations of artefacts enables these changes in perspective and juxtaposing different angles of storylines by creating duplicates and rearranging these . However , these duplicates could result in stale information , for example , when one object or its metadata was changed , but the copy CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 140 was left out ( a problem described in different variations by V1 , V3 , V4 ) . C2 explained how the same images of artefacts are used in his museum at various stages and in different representations : to create an artefact list for the exhibition , to display them thematically , or to arrange them in the floorplan of the exhibition room . When reviewing and arranging artefacts to create the storyline , curators described their practices : ( i ) chronologies , location - , or other sorting - orders ; ( ii ) juxtaposing of different views of e . g . the same location at different times ; ( iii ) examining in detail and adding newly found information ; ( iv ) linking to other existing artefacts ; and ( v ) grouping similar artefacts , or highlighting certain aspects of a particular one . 6 . 2 . 5 F5 | Metadata and Tags : Curation Includes Annotating Information with Metadata , such as Time , Location , and Descriptions Annotation , together with analysing , is where curators transform , interpret , and rework information . Annotation is concerned with describing the content of the information through metadata , making it easier to find artefacts and content again in later stages of the process , but also to interpret the content and relate it to other areas ( George 2015 ; Rotman et al . 2012 ) . Metadata enables other curators , researchers , or the public to make their own selections based on the existing collections . In museum curation ( C1 - C3 ) , databases are used to store and retrieve metadata about objects , also described as the “ core engine ” ( C1 ) of curation work . One particular curation workflow ( reported by C1 , similar C2 and C3 ) included creating duplicates of database entries into shared folders , enabling collaborative access and local offline access to the data . C1 described that during the planning phase of a new exhibition these duplicates were created to allow for editing of the documents without touching the database entries . Usually only final outcomes — such as research papers , leaflets , exhibition schedules , brochures , etc . — are fed back into the database and creating duplicates allows for manipulation without changing the database entries . Further , information might be copied to planning documents or spreadsheets . V1 described the dilemma of not having metadata initially : “ I just filed the information away when I found it [ … ] I had all those files on my computer . And I had to try to remember where they CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 141 are and what I had . I came across various information that I have found before several times and forgot about it later on . [ … ] I hoped to remember where they were . Sometimes you don ’ t , and then you go back through them [ to understand what you had ] . [ … ] And there goes an evening ” . They then went on to describe how they created an overview spreadsheet , which they filled with information about the information they had , essentially creating their own ‘ database ’ of additional information . This not only helped them to find information faster later on , but also to keep an overview . 6 . 2 . 6 F6 | Overviews and Colour Coding : Curators Use Visual Representations of Artefacts and Colour Coding for their Curation Activities This observation is concerned with the visual representations curators created . For example , curators mentioned they use “ a lot of colour coding in planning an exhibition ” ( C2 ) , to differentiate between different states of work and to indicate responsibilities . Similarly , V1 and V3 reported that they visualised changes within a document through different text colours to communicate changes to others , but also for themselves to keep track of the current progress or if they need further editing ( also known as signalling ( Shami et al . 2009 ) ) . Dedicated overview documents or spreadsheets helped further to keep track of the status and indicate what content has been dealt with and what parts still needs attention . In collaborative scenarios , overviews create a shared understanding of the current progress ( V1 - V4 ) . They not only contain textual information , but also preview images of artefacts — often in low resolution — to allow for a quick recall of what artefact is being talked about , and to make skimming the document easier . C2 and C4 described how , for each exhibition , their museum used “ a spreadsheet with multiple columns , [ containing information about ] what are the key messages ? What are supporting images ? ” ( C2 ) , essentially “ breaking it down into every item in the exhibition ” ( C4 ) . C3 described that they created a structure during the planning phase : “ I had enough of an idea to say ‘ this is what [ the exhibition ] should be about ’ . [ … ] I made a mind map and asked the [ team ] for feedback [ … which ] I added to the mind map ” . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 142 6 . 2 . 7 F7 | Diverse Sharing : Curators Share and Present Information in Diverse Representations to Collaborators and Audiences As part of the curation work , the content has to be arranged and presented in different ways : curation is not about individual artefacts , but about how they fit together and the story they tell in conjunction with each other ( Bhaskar 2016 ) . The curators tell a story with and about the artefacts through presenting them in new ways , for example as part of a report , on a website or in a museum exhibition ( Bhaskar 2016 ; Obrist 2015 ; Rotman et al . 2012 ) . The expected results for curation sessions were of different natures . For example , the historic society compiled reports and a website about important landmarks . In museums on the other hand , it was about creating exhibitions , leaflets and flyers , research documents , or starting points for further research . This observation confirms previous findings ( Bhargava 2009 ; Rotman et al . 2012 ) , that the outcomes of curation are to present artefacts , content , and findings to an audience . C3 said , that , once they had collected artefacts and information about them , the usage was “ flexible ” and they “ can do various [ … ] family events , film events , different lectures ” with it . C2 described the audience to be from a broad background , saying that “ [ museums ] are interrogated by people who are not necessarily specialists , and [ museums ] should be able to give information to as many people as possible ” . When sharing work with a collaborator , sharing a document meant only sharing it at a current ( temporary ) state , as new information is constantly found and added to these “ living documents ” ( V1 ) , making a shared document quickly outdated . 6 . 2 . 8 F8 | Ad hoc Workspaces : Curators Work in Ad hoc Heterogeneous Work Environments Work environments and workflows for curation were diverse between the curators we talked to . Some curators described their work as “ creatively chaotically ” ( C1 ) , where others gave a picture of a more rigid departmental structure of a large museum with accustomed workflows ( C2 ) . From large , departmental meetings with a formal agenda ( C2 , C5 ) to “ talk [ ing ] about things across the room ” ( C4 , similar descriptions by C1 , C3 ) , or consulting with colleagues via email : curators agreed that “ communication within CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 143 the team is key ” ( C4 ) . C2 described that “ different curators work in different ways . Some like to take it away and work it on their own , some like to sit next to [ their colleague ] and see it more as a collaboration and talk [ it ] through ” and meetings “ happening in small groups and big groups ” , in ad hoc meeting spaces : “ meeting space is whatever is available ” ( C2 ) . Similarly , V1 - V4 did not have a permanent meeting space , resulting in their meetings often occurring in a community centre or someone ’ s home . This meant , they needed to wrap up and take down everything afterwards . All interviewees described that collaborative work is often either done face to face with paper or working with digital information but in separate locations . Collaborative collocated work with digital content and devices was rare , as there was no shared access to the content and people usually ended up sitting behind their individual laptop . In summary , through our interviews with curators from different backgrounds ( professional museum curators and volunteers ) we gained further insights into the key activities that matter during the curation workflow . The synthesised findings F1 - F8 directly informed the design of our CurationLens interaction techniques . In the following , the tools — CurationLens — and the interactions with it will be described . CurationLens CurationLens is designed as a hybrid tangible - digital system , supporting the fundamental curation activities — namely selecting , reviewing , and presenting — which we identified through our research and literature ( section 3 . 3 . 3 . 1 ) . Each technique supports one or multiple curation activities . Throughout the description of CurationLens we will explain how the techniques address curation aspects identified through our interview findings ( F1 - F8 , described earlier ) and also illustrate the use of our curation tools by guiding through the following running example . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 144 6 . 3 . 1 Running example : “The Collection of HCI Interaction Devices” John has a large collection of input and other interaction devices for computer systems , which he has collected over many years ( the collection in this example can be imagined similar to the Buxton Collection ( Buxton 2017 ) ) . He bought these items in second - hand shops and online , and also acquired artefacts through friends and colleagues who either sent him the devices they had retired or photos of non - ordinary input devices they came across . John has many handwritten as well as digital notes , manuals , and other documents about the artefacts . John ’ s collection shows how interaction devices have changed over the years . Lisa has heard of John ’ s collection and convinced him to put on an exhibition , showcasing a selection of the many artefacts . She offered to work with him to curate this exhibition . Eventually the exhibition should showcase some of the physical artefacts , as well as descriptions that John has gathered . 6 . 3 . 2 General interaction with CurationLens At its core , CurationLens consists of a web application that is displayed on tablet devices , mobile phones , or computers , making it independent of any special infrastructure ( as curators often collaborate in ad hoc situations — F8 ) . Each curation project consists of one or multiple arrangements ( Figure 20a ) , supporting the multiple curation views we identified in finding F4 . Curators can add objects to these arrangements — digital artefacts or representations of artefacts , for example in the form of images , text , drawings , or highlights ( Figure 20b ) . All objects can be arranged spatially , in clusters and / or time - based ( F4 ; similar to ( Andrews , Endert , and North 2010 ) ) . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 145 Figure 20 . Example view of CurationLens web application : arrangement , objects and metadata editor . The objects in CurationLens consist of the raw data and its metadata ( a key element of curation — F5 ) , allowing the contextualisation of content and the addition of further meaning . Metadata ensures that the data can be found and used in the future ( Lord and Macdonald 2003 ; Sabharwal 2015 ) and makes up the annotations of artefacts . Curators can review and edit metadata for each artefact by tapping on an artefact , toggling the meta - view on the right side of the arrangement ( Figure 20c ) . The meta - view can also be pinned onto a separate device , allow for the decluttering of the arrangement view . When adding a new artefact to CurationLens , the system automatically derives some basic metadata in the form of timestamp and location information . We use image recognition ( via Google ’ s Vision API ( “Vision API - Image Content Analysis” 2017 ) ) to derive a textual description , tags , and further location information . This metadata can be viewed , edited , and amended by the curator . New objects can be added to an arrangement either by selecting them from cloud storage ( e . g . through our direct Dropbox integration ) , by importing them from files , or by using the CurationSnapper tool ( described shortly ) . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 146 Name Mode and Description of Interaction Technique F 1 : E xp e r t S e l e c t i o n F 2 : P h y s i c a l + D i g i t a l F 3 : D i g i t a l S u rr o g a t e s F 4 : M u l t i p l e V i e w s a n d J u x t a p o s i t i o n F 5 : M e t a d a t a a n d T a g s F 6 : O v e r v i e w s a n d C o l o u r C o d i n g F 7 : D i v e r s e S h a r i n g Arrangements Arrange objects spatially to sort , juxtapose , and annotate them . Objects Individual artefacts that are positioned on one or multiple arrangements and have associated metadata . Meta - view Automated ( locations , tags , timestamp ) and manual ( locations , tags , description ) metadata for filtering and sorting . CurationArranger Quickly toggle between different arrangements with smooth transitions , supporting reviewing of artefacts . CurationSnapper Captures physical artefacts . Allows quick selection of physical artefacts and their addition to an arrangement . CurationProjector Create a reconfigurable workspace through displaying of an arrangement , object , or meta - view . CurationBuzzer Put an arrangement or object into the spotlight by temporarily displaying it on all collaborators ’ devices . CurationTwirler Skim through objects , crossfade / juxtapose objects through a rotary button . Table 8 . CurationLens ’ s interaction tools and the curation activities they address , and which of our findings informed them . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 147 Tools Supporting Key Curation Activities CurationLens includes five tools supporting curation tasks : CurationArranger , CurationSnapper , CurationProjector , CurationTwirler , and CurationBuzzer . In the following we describe these tools and interaction techniques in more detail and how they support curation activities ( see Table 8 for an overview ) . 6 . 4 . 1 CurationArranger When reviewing artefacts or images , curators often spatially arrange them in different layouts , for example sorting them in a timeline or clustering them in different thematic groups ( described in finding F4 ) . In CurationLens , spatial arrangements are at the core of the system , as objects can be organised spatially on arrangements . Through CurationArranger , curators can toggle between different arrangements through the push of a button ( Figure 21 ) . It consists of a set of three physical buttons ( Figure 21a ) , each of which can be associated with a different arrangement . The buttons light up to indicate which arrangement is currently selected . When a button has not been associated with an arrangement before , the current arrangement is taken as a default template . Switching between arrangements is animated in a smooth transition moving all objects from one arrangement to another . The rapid access to those different views enables curators to see connections and explore the collection through the lens of alternative views ( e . g . timelines , thematic clusters or grids , Figure 21b - d ) . In the scenario : John knows he has several panels which he can use to display information about his artefacts . He creates three different arrangements of the same artefacts to compare which one works best for the space given — one along a timeline of when they were invented ; another timeline of their first commercial release / popularity ; and one along the artefact ’ s input modality . Through CurationArranger he can easily toggle between the different views and see how the objects relate to each other in the different views . Using tangible tools enables eyes - free interaction , keeping the focus on the data , while transitioning between the arrangements . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 148 Figure 21 . CurationArranger for rapid , ad hoc access to different arrangements of curated objects . 6 . 4 . 2 CurationSnapper CurationSnapper allows curators to rapidly digitise physical artefacts , which is a curation tool directly inspired by F2 and supports the creation of surrogate objects ( F3 ) . Using a set of blue tangible L - shaped frames , a rectangular area can be marked for capturing photos by our systems ( Figure 22a ) . The image is cropped to the boundaries of the frame , allowing easy and direct adjustments of the size of the photo . By pressing a physical button ( Figure 22b ) , the snapshot is immediately added as a new object to the current arrangement ( Figure 22c ) . For each image , automatic metadata is created ( timestamp , current location , tags — see Figure 20 ; facilitating the use of metadata — F5 ) , which can later be viewed and edited in the meta - view as described above . In the scenario : John is going through his collection of pointing devices to select the most interesting ones to include in his exhibition . He already has digital images of them , but has just recently received another collection of mouse devices from a colleague , which he wants to put on show . In order to not forget about it , he wants to integrate them into his planning arrangement . Using CurationSnapper he can quickly take snapshots of the devices and continue planning his exbhibition . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 149 Figure 22 . CurationSnapper for capturing physical artefacts . 6 . 4 . 3 CurationProjector CurationLens enables a user to display either an arrangement , object , or meta - view through different output channels ( F4 ) . Currently these output channels are either websites ( e . g . displayed on a tablet , smartphone , or laptop ) or a top - down projection using CurationProjector . The key advantage of CurationProjector is that it enables a curator to show the content directly in the curation workspace . CurationProjector is activated by flipping CurationSnapper ’ s tangible L - shape frames over ( Figure 23 ) . An overhead camera next to the projector tracks the markers on the frames and calculates the projection area . The projection area is then marked by the yellow side of the frames and can be resized or moved to a different position , simply by moving the frame . As an additional function , a curator can activate a projected measuring tape , allowing a user to take measurements of an artefact and enter it with its metadata ( activity part of F6 ) . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 150 Figure 23 . CurationProjector allows the display of a digital curation arrangement directly in workspace . In the scenario : John is currently heavily editing an arrangement showing the potential layout of an exhibition space . Lisa is in the room with him , writing descriptions for exhibiton panels . He wants her to see what he is working on , so he uses CurationProjector to project his current arrangement onto the table . Lisa can move the projection to a more convenient position by moving the L - shaped frames around the table . She also suggest adding an additional physical object by placing it within the projection area . This blending of physical and digital allows them to quickly preview changes without first digitising an object and potentially never using it . 6 . 4 . 4 CurationTwirler When dealing with a large collection of artefacts , metadata helps to find the relevant items ( F5 ) . When no metadata has been created yet , or filtering using the meta tags does not yield the appropriate results , curators might need to search the entire collection item by item . CurationTwirler is a tangible , rotary button that enables a curator to quickly skim through a large collection of digital artefacts in a cover - flow presentation by rotating the button ( Figure 24a ) . The items in this case are either sorted alphabetically or — if existent — by metadata such as dates ( Figure 24b ) . When a particular artefact is in focus , a push of the button adds the object to the current arrangement ( supporting quick selection , F1 ) , which is displayed on a separate output space ( e . g . another tablet or CurationProjector ) . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 151 Juxtaposing objects is often used by curators to discover artefacts ’ evolution over time ( F4 ) . This can be achieved through our tools by crossfading between different states of objects . When in the arrangement view , a curator can use the CurationTwirler to change the opacity of an object . When it is placed over a second object , using the tangible CurationTwirler , curators can therefore quickly crossfade between two different items ( Figure 24c ) . Figure 24 . CurationTwirler for crossfading objects and skimming through collections . In the scenario : A few months ago , John digitised many of the artefacts in his collection with his camera . Unfortunately he has not found the time yet to sort through them and add further metadata or other sorting information . However , he knows that in the hundreds of photos there is one of a keyboard that he particularly wants to include in the exhibition . Using CurationTwirler he skims through his unsorted photos . While looking for the keyboard , he stumbles across another input device , which he thinks might be interesting to put on show . Each time he comes across a potential candiate to include in the exhibition he presses the CurationTwirler , which adds this particular artefact to the arrangement . Later he can go back to the arrangement and rework his selected objects further , adding metadata and further plan his exhibition . 6 . 4 . 5 CurationBuzzer When working in a collocated group , CurationLens allows each curator to work on the same or different arrangements , objects , or metadata . All changes are immediately CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 152 synchronised between different devices ( e . g . when in the same view ) and between different views ( e . g . the metadata of an object ) . When a curator wants to show an object or arrangement to collaborators , CurationBuzzer is a lightweight way to temporarily share their currently selected arrangement or object with all other members of the group . Through the push of a button ( Figure 25a ) , the last selected object is displayed on all other connected devices ( Figure 25b ) , putting a spotlight on this one item and directing everyone ’ s attention to it . This supports the diverse modes for sharing with collaborators we mentioned in F7 as well as allowing the group to force their focus on a specific object or topic . As soon as the button is released , the sharing is undone , and everyone can continue with their own curation work . The usage of a tangible button is a clear indicator to the collaborators who pushed the button ( providing workspace awareness ) and directs the attention to this temporary leader of a group discussion . In the scenario : John is working on an initial draft of how one of the exhibition panels could display some of the digital artefacts . Lisa is working on a different panel , and she now wants to compare it to John ’ s current selection and layout . He pushes CurationBuzzer , which immediately displays his arrangement on Lisa ’ s tablet . Lisa can look through what John has created , and they discuss the content . As soon as she is done , John releases the button and Lisa ’ s view returns to her own . Figure 25 . CurationBuzzer for temporary , ad hoc sharing . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 153 Technical Implementation CurationLens is built using modern web technology . The backend runs on nodeJS , and the frontend is built using React 8 . Backend and frontend are connected via WebSockets , and the system state is kept through a synchronised Redux 9 state between all instances and the backend . The shared Redux state is implemented by tunnelling all Redux transactions through a proxy server via WebSockets . Each transaction is logged by the proxy server and then forwarded to all connected clients . When a new client connects , the current Redux state is sent to the client , ensuring that the data is available on all connected devices . We are using the Chrome browser ( version 59 ) on an Android smartphone to run CurationSnapper , which tracks fiducial markers on the frames of the phone ’ s camera feed . The camera feed is analysed locally in the user ’ s browser , preserving privacy by only transferring to the server what is absolutely needed . The interactive tangible inputs are built using the Arduino 10 platform . The communication between the tangible inputs and the system is via a wired serial connection to the laptop running the server software . Selecting data from Dropbox is realised through the Dropbox Chooser 11 , allowing curators to select files from their existing folders . Discussion of Heuristic Criteria CurationLens was designed in a user centred design process ( as described previously in Chapter 2 ) by tightly linking the design of tools to our findings from interviews with professional curators as well as volunteer curators in a historic society . Enabling fluid interaction with the system and seamless switching between tools and objects allows users to focus on their main task , rather than being distracted by how to interact with the system , trying to remember how a tool works , or where to find a particular setting . By utilising tangible tools , users ’ actions and interactions with the system are readily 8 https : / / reactjs . org 9 https : / / github . com / reduxjs / react - redux 10 https : / / www . arduino . cc 11 https : / / www . dropbox . com / developers / chooser CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 154 communicated to collaborators . In the following we will discuss relevant design heuristics from Olsen ( Olsen 2007 ) along with reflections on the strengths and limitations of our concepts , which has been suggested as an approach for evaluating cross - devices system as discussed in Chapter 4 . 6 . 6 . 1 Importance Existing tools are limiting what curators can do especially when creatively reworking and curating content in a collaborative and collocated scenario . Our design decisions are based directly on the insights gained from and the needs of curators . As a tool , CurationLens provides new ways of collecting and organising material , of connecting those materials in new ways to discover insights and make connections , as well as allowing the combination and creation of collections for presentation to others . By blending the boundaries between physical artefacts and digital representations , it enables fluid transitions between them . CurationLens reduces the need for menu interactions and interruptions through status displays : updating metadata across instances and devices is seamless and does not require any user interaction . Transitioning between different visual representations in an eyes - free manner supports users in referencing and comparing task material and using the tangible tools further provides a clear showing of intent . 6 . 6 . 2 Generality CurationLens aims to support the three main curation tasks of selecting , reviewing , and presenting content , however the individual tools can also support only a subset of these tasks . For example , the CurationSnapper could be used simply as a lightweight tool to digitise and annotate data with metainformation . Combined with the CurationProjector and CurationBuzzer it could be useful also for knowledge workers in other areas outside curation , such as when creating a magazine or preparing a blog post . While changing existing work practices — especially when considering professional curators — will require a lot of time , we hope that the considerations taken for CurationLens will inspire further work within curation — but also more broadly within the domain of knowledge work . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 155 6 . 6 . 3 Flexibility All of CurationLens ’ tools can be chosen by the curator to the extent that they suit their needs best — and simply ignore the ones that are not needed . For example , while CurationSnapper might be an integral part of one curator ’ s works as many of their artefacts only exist in a physical form , a blogger or photographer might only have collections of digital artefacts and therefore no need for this tool . This flexibility also allows novices to use the system who might only use a small subset of the tools , by only requiring minimal learning . Once a user is familiar with the most basic tools they originally needed , they can tap into the power of increasingly more parts of the system by flexibly adapting their tool use as they go along . CurationLens ’ tools also allow users to flexibly try out new designs by giving them the option of easily switching between layouts in the CurationArranger . Changes can be easily compared and thus reverted to previous designs . Curators do not need to immediately narrow down on design choices but can slowly work out the best solution . Through the different views of the same data in CurationArranger , or when sorting objects based on their metadata ( e . g . date ) , curators can explore different answers and solutions . Using CurationBuzzer allows users to quickly gather other people ’ s opinions or views on a task item without permanency . One could also imagine further extensions to this , for example by exploring more operations on the metadata or by exploring how the metadata could incorporate flexibility — without compromising the benefits of having “one record of truth” that is synchronised across all devices . 6 . 6 . 4 Expressive match CurationLens blends the interactions between the physical and digital by enabling fluid transitions between artefacts , not only by allowing users to easily digitise physical artefacts and by projecting digital artefacts in the surrounding but also by using tangible controls . Creating digital / physical representations is a core of how CurationLens works . However , there is still room left for creating further novel interface designs . For example , mixed reality environments could lead to promising developments , but careful considerations need to be made to retain the ad hoc and work - anywhere nature of CurationLens . CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 156 6 . 6 . 5 Scale CurationLens ’ collections can grow indefinitely , and the system enables users to easily find artefacts through the use of filtering and tags . One might expect this filtering not to scale from a certain size onwards . However , it is unclear at what point this limit might occur . Nesting collections , folders , and linking between instances could be a solution , but further thought has to be given to this . Further , in its current implementation CurationLens only supports one instance and no user accounts have been implemented . Every device — and thus every user — has equal access rights . To be usable for real - world problems , however , user accounts would be needed . While this would solve the problem of access control it might limit the ability for an ad hoc zero - configuration usage scenario . CurationLens does not require any special hardware or software — a reasonably modern web browser is sufficient to run the client software — providing a low entry barrier to use . A curation project can also be easily worked on in parallel by multiple users , as CurationLens has been designed with group collaboration in mind . However , while remote collaborations are technically possible , further thought would need to be taken to enable a communication channel between curators that replaces the face - to - face contact they would be having in a collocated session . As discussed previously in Chapter 2 and Chapter 4 , heuristic evaluations are a helpful tool to reflect on usability aspects . While a full deployment for an in the wild user study would have yielded more interesting insights into unexpected uses , this was left for future work . Conclusion The purpose of curation is to select the most relevant information and artefacts out of a vast collection to present to an audience . Through interviews with professional and semi - professional curators , we discussed the fundamental curation activities of selecting , reviewing , and presenting digital and physical artefacts . With CurationLens we presented a hybrid tangible - digital system that tries to bridge the gap between physical and digital artefacts and tools . Based on the notion of Blended Interaction ( Jetter et al . 2012 ) , CurationLens uses properties from physical objects to allow CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 157 interaction with a digital system through tangible tools . This allows for eyes - free interaction , where curators do not need to switch their attention from a physical artefact or control to a menu or object on the screen or vice versa . The use of tangible tools also serves as an indicator of intent in a multi - user scenario : reaching for a tangible device provides awareness to other curators on what is about to happen . The configurability of these tools allows curators to use one tangible device with different kinds of input and act on different objects , similar to the reconfigurable tools in CurationSpace ( Chapter 5 ) . We designed CurationLens to integrate with existing workflows and tools . For example , it allows the selection of digital content from cloud storage ( e . g . Dropbox ) , supports ad hoc collaborative curation scenarios , integrates physical and digital artefacts , and leverages use of existing devices ( such as smartphones or tablets ) . The state of arrangements , objects , and metadata is synchronised between all devices . It allows different views on the same information , enabling users to derive new insights through different views . With CurationLens we explored a number of interaction techniques and tools that support curation activities . By using our synthesis of findings from interviews with professional and volunteer curators we designed CurationLens so that it closely supports and facilitates their curation work practices . Overall , we see CurationLens as a flexible system where curators can mix and match techniques to fit into their curation workflow , reducing the setup needed to collaboratively work with digital tools in ad hoc scenarios . Leveraging existing devices allows people to use the hardware they are already familiar with , while allowing them to reconfigure their workspace at any point in time . CurationLens does not have any specific requirements on the hardware or software on the user ’ s side , except for a modern web browser . And while desktop PCs work equally well with it , the power of ad hoc curation and collaboration lies in the use of portable devices such as tablet devices , smartphones , or laptops . However , tablets are often either handheld or are lying flat on a table and do not easily allow handsfree viewing with their screen in a horizontal position , as laptops do . In the next chapter , we present SurfaceConstellations , a modular hardware platform that allows users to easily create and reconfigure spatial setups of such tablet devices , and CurationLens : A Hybrid Tangible - Digital System Supporting Curation of Artefacts 158 to create their own custom setups while making it easy to change their setups or move them around . This combines the flexibility of ad hoc mobile setups with the advantages of large display environments discussed earlier in Chapter 3 . We further use the SurfaceConstellations platform to present more use - cases of cross - device work , that go beyond curation work . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 159 Chapter 7 . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Reconfigurable Cross - Device Workspaces 12 When working with multiple devices in conjunction , people use different form factors . From rigid setups of desktop , tabletop , or wall display setups to more flexible solutions employing laptops , smartphones , tablet , and wearable devices , the setups differ , as do the physical setup possible with those devices . While tabletop or wall display setups are usually entirely rigid with little flexibility ( e . g . CurationSpace in Chapter 5 ) , using portable devices supports ad hoc layout and reconfigurability ( e . g . CurationLens in Chapter 6 ) . For example , using tablet devices allows people to share them , providing flexible access and enables people to flexibly reconfigure the workspace layout . Tablet devices are often mainly handheld or placed flat on a table 12 Parts of this chapter have been published in : Nicolai Marquardt , Frederik Brudy , Can Liu , Ben Bengler , and Christian Holz . 2018 . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Reconfigurable Cross - Device Workspaces . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems ( CHI ' 18 ) . ACM , New York , NY , USA , Paper 354 , 14 pages . DOI : https : / / doi . org / 10 . 1145 / 3173574 . 3173928 and Nicolai Marquardt , Frederik Brudy , Can Liu , Ben Bengler , and Christian Holz . 2018 . SurfaceConstellation Applications : Use Cases of Ad hoc Reconfigurable Cross - Device Workspaces . In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems ( CHI EA ' 18 ) . ACM , New York , NY , USA , Paper D323 , 4 pages . DOI : https : / / doi . org / 10 . 1145 / 3170427 . 3186545 . The core concept of SurfaceConstellations has been created by the first author as well as the co - authors of the listed publications . Beyond contributing to the overall concept , I have contributed the design space , implemented the web - based GUI tool for creating SurfaceConstellations , and contributed the key cross - device case study applications that illustrated SurfaceConstellations — all of which are the focus of this chapter . Sections of the CHI’18 pape r where I did not significantly contribute have been omitted from this chapter . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 160 ( more on a group ’ s utilisation of tablet devices shortly in Chapter 8 ) . On the other hand , laptops offer a setup that enables handsfree viewing of a vertical screen , but they lack the flexibility of being handheld or easily rotated for better access . How can we leverage the best of both worlds : flexibility in setup and reconfiguration while allowing for rigidity handsfree use of multiple devices ? In this chapter , we describe SurfaceConstellations , a modular hardware platform for linking multiple mobile devices to easily create novel cross - device workspace environments . Our platform combines the advantages of multi - monitor workspaces and multi - surface environments with the flexibility and extensibility of more recent flexible cross - device setups . The SurfaceConstellations platform includes a comprehensive library of 3D - printed link modules to connect and arrange tablets into new workspaces ; several strategies for designing setups ; and a visual configuration tool for automatically generating link modules . We contribute a design space of cross - device workspaces , explanations of the physical design of 3D printed brackets and support structures , and the design of a web - based tool for creating new SurfaceConstellation setups . We conclude with a design space to develop software applications and present four sample applications developed for SurfaceConstellations , showcasing the flexibility and potential use of the platform . This shows how cross - device interactions and systems in use within a broader range of knowledge work ( application 1 and 2 ) , within existing software ( application 3 ) , and within a social setting of collaborative game play ( application 4 ) . Figure 26 . The modular SurfaceConstellations platform enables creation of spatial cross - device workstation setups . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 161 Bridging the Gap Between Multi - Monitor Setups and Ad hoc Cross - Device - Computing Since early visions such as Vannevar Bush ’ s Memex ( Bush 1945 ) , multi - display setups have been used to effectively support a variety of desktop computing activities : from visual analytics , to financial computing , control rooms , business analytics dashboards , or video and audio editing . The main advantage of these setups is not only the larger available screen real estate ( i . e . more pixels to display information and interact with ) , but also the benefit of effectively distributing information across the distinct inter - connected displays . Multi - monitor setups provide “ space with a dedicated purpose , always accessible with a glance ” and “ can facilitate versatility in use ” ( Grudin 2001 ) . This expressive power of multi - display setups has also inspired work in cross - device interaction ( discussed in detail in Chapter 4 ) . Cross - device setups allow people to use interfaces that span across several inter - connected tablets , phones , and other devices . Like multi - monitor desktop setups , these systems provide a larger interaction space ( e . g . more content displayed simultaneously , additional input space for gesture input ) to interact with applications , while enabling one to dynamically add or remove devices from such a device ecology . Most of this work is designed around two primary usage scenarios : mobile , ad hoc setups for collaborations ( e . g . ( Cauchard et al . 2011 ; Rädle et al . 2014 ; 2015 ; Marquardt , Hinckley , and Greenberg 2012 ; Schwarz et al . 2012 ) ) ; and interactive environments with a variety of mobile and large interactive surfaces ( e . g . ( Streitz , Geißler , et al . 1999 ; Wigdor et al . 2009 ) ) . Our goal with SurfaceConstellations ( Figure 26 ) is to bridge the gap between the power and effectiveness of multi - monitor workstations with the flexibility and ad hoc configurability of cross - device computing . To implement this vision , we designed a novel modular platform that enables people to easily assemble a large variety of spatial multi - surface arrangements . Our SurfaceConstellations brackets thereby physically connect tablets and phones to create larger dedicated workstation setups . The modularity of our platform enables a large spectrum of possible multi - surface setups that are easily reconfigurable and can support diverse working styles and applications . In particular , in this chapter we contribute : SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 162 - The SurfaceConstellations hardware design and a design space taxonomy for the workspace setups it affords ; - Specifications for the physical design of 3D - printed brackets and techniques for including weight - balancing support structures ; - Configuration tools for setting up new workspaces and designing the 3D - printed brackets ; - Demonstration of the versatility of our platform through four use case applications , implemented using different cross - devices computing frameworks and showcasing how cross - device tools support knowledge work and broadening the scenario to a wider range of works . SurfaceConstellations offers further features , which are not part of this thesis , such as capacitive links that enable automatic software configuration of setups , as well as flexible joints , enabling setups that are even quicker to reconfigure . Full details and the link to the publication containing all hardware designs , 3D - print STL files , 3D model source files and the software ( which are released as open - hardware and open - software ) are described in the related publications listed at the beginning of this chapter . Within previous work , SurfaceConstellations sits at the sweet - spot between multi - monitor setups ( such as environments with interaction wall and tabletop displays ) and rigid setups ( such as BendDesk ( Weiss et al . 2010 ) and Curve ( Wimmer et al . 2010 ) ) and reconfigurable joint surfaces ( e . g . Codex ( Hinckley et al . 2009 ) ) . With SurfaceConstellations , we are interested in combining the effective workspaces introduced by work in multi - display environments , with strategies from cross - device computing working on ad hoc reconfigurable device setups . In SurfaceConstellations , devices can be grouped together in physically stable configurations that may still be flexibly reconfigured . Once devices ’ positions are ( manually ) configured during the software setup , no further tracking is needed , which enables spatially aware connections without the need for any tracking infrastructure . As discussed in Chapter 4 , existing platforms for spatial tracking are often prototypical — speaking against permanent deployments — or expensive to setup and maintain — making them inaccessible to a larger audience . By using a simple manual configuration step , our SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 163 software examples show how we can make cross - device systems available to the masses without investing into infrastructure . Within our cross - device taxonomy , SurfaceConstellations itself cannot be fully classified , as the six dimensions are mainly relevant on an application level . SurfaceConstellations however is a platform to create brackets enabling reconfigurable physical hardware setups . The example applications discussed later in section 7 . 5 however will be classified according to our taxonomy . SurfaceConstellations In this section , we introduce our modular SurfaceConstellations platform and present the design space taxonomy , mapping out possible configurations . We then discuss two details of the hardware components : ( 1 ) the design of 3D printed modules , and ( 2 ) strategies for adding support extensions . Figure 27 . Basic SurfaceConstellation bracket design . 7 . 2 . 1 Concept The general concept of the SurfaceConstellations platform is to use modular , 3D - printed hardware brackets that physically connect mobile devices ( e . g . tablets and phones ) to new workstation setups . As described shortly in our design space taxonomy , adding these physical connections enables new spatial arrangements of devices , forming a variety of different workspaces , such as the three - tablet configuration shown in Figure 27 . While there are many different types of brackets as we discuss in the 3D design section , they all work the same way : each bracket ( Figure 27a ) has a cavity recess that holds a part of the frame of at least two devices ( Figure 27b ) ; after SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 164 sliding the mobile devices into the bracket ’ s cavities , it physically holds the two ( or more ) devices in place ( Figure 27c ) . The brackets create a permanent , but easily re - configurable physical connection between devices . By combining multiple brackets connecting devices together , one can easily create more advanced setups , affording diverse individual work and collaborative multi - user applications . 7 . 2 . 2 Design Space Taxonomy In our design space taxonomy ( extending the taxonomy introduced in Codex ( Hinckley et al . 2009 ) ) we categorise the principal surface setups supported by the SurfaceConstellations platform ( Figure 28 ) . The primary dimension depends on the relative angle between devices , while the second dimension classifies the symmetry of setups : a ) Flat : a flat surface with no angle into the 3D space between tablets . Examples from the design space include a flat book on a table , a larger interaction canvas with 4 or more tablets ( Rädle et al . 2014 ) , game board setups with a central shared device , as well as wall / line / fan setups . b ) Convex : the angle between the screen surfaces is larger than 180 degrees . Examples are : the two - sided sign setup ( Hinckley et al . 2009 ) and the bridge setup with three tablets . Because convex shapes are outward facing , they better afford collaborative use . c ) Concave : the angle between the screen surfaces is smaller than 180 degrees . Examples for these designs are : the laptop setup , curved design ( Weiss et al . 2010 ; Wimmer et al . 2010 ) , dual - screen laptop , and a financial trading - desk inspired setup / wall ( Bloomberg , n . d . ) . d ) Closed : the surfaces connect into a 360 - degree chained screen . Examples are : a double - sided screen , a cube - like connection of screens , and circular setups . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 165 Figure 28 . SurfaceConstellation design space taxonomy . Combining the dimensions / categories above results in hybrid structures ( Figure 28e ) . The dimensions of our design space taxonomy can serve as an inspiration for what can be achieved with SurfaceConstellations , and we will illustrate different use cases across this design space in our application scenarios ( section 7 . 5 ) . We expect that this taxonomy has potential to be extended in the future by adding new designs enabled through our platform . Figure 29 . System design parameters ( green shades cover the cases supported by our implementation ) . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 166 7 . 2 . 3 Design Parameters There are further parameters to consider when designing and setting up new SurfaceConstellation setups ( Figure 29 ) . 1 ) First , the number of devices : While technically there is no upper limit for the number of devices that can be connected , we see most practical setups using between 2 and 8 devices . 2 ) Second , the diversity of devices ( e . g . only connecting similar devices vs . connecting different hardware , such as iPads together with Android tablets ) . Heterogeneous setups require a customised bracket design , as every side of the bracket now needs to be customised for the device size and thickness of the individual tablets . Heterogeneous setups also affect the way software needs to be designed to work across the different OS platforms . In a single setup , we can combine different kinds of devices , such as multi - touch tablets , phones and e - ink displays ( Winkler et al . 2013 ) . Besides tablet - like devices , we can also create SurfaceConstellations connected to desktop monitors or laptops ( e . g . adding additional surfaces to the top or the side of the monitor ) . To increase the stability of setups connected to a laptop , we need to add reinforcement brackets fixing the angle of the hinge between the laptop base and screen ( otherwise the weight of additional tablets would cause the laptop screen to fold flat because most laptop hinges do not provide sufficient friction to hold the weight of the full setup in place ) . 3 ) The third parameter considers the structural setup : are all devices placed flat on a desk ( e . g . the game board design ) ; is the setup freestanding ( e . g . the trading desk setup , where the curvature can provide enough support ) ; or are additional support extensions for the brackets needed to balance the weight and make a stable setup ( more on this later ) . 4 ) The fourth design parameter accounts for the complexity of the assembly : most of the link brackets we designed can be directly 3D - printed ( or manufactured through other techniques , like injection moulding ) . However , some bracket designs might require additional assembly steps , for example to combine different hardware components and materials . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 167 5 ) The fifth parameter is flexibility . For example , when connecting two tablets with a flexible joint bracket , we can create a setup similar to the book design in Codex ( Hinckley et al . 2009 ) , and going beyond , adding flexible joints to any part of a SurfaceConstellation . While the flexible joints brackets add more flexibility to setups , they also require additional assembly steps and material beyond 3D printing . Static brackets already add a high degree of flexibility to setups and are therefore the focus of this chapter . Some more design details about flexible setups can be found in the publication corresponding to this chapter ( linked to in the beginning of this chapter ) . 7 . 2 . 4 Scenario The following scenario describes an example of how we envision the use of SurfaceConstellations : Jane volunteers her time to a historic society , looking into the history of a high - street in her town . Recently she went to archives and collected a lot of data on the internet about the vibrant history of the street . She has several spreadsheets with data , folders with photos , and digital newspaper scraps from several decades . To better compare and interpret the data , she decides to use multiple tablets and link brackets provided by the historics society , linking three tablets into a workstation setup ( ‘ Curved ’ ) and opening multiple views of the data . As the analysis continues over the day , she finds additional government data she would like to correlate to her earlier data sets and adds a second 3 - screen setup to her desk ( linking now six tablets together ) . In the evening when she has completed the analysis , she takes the setup apart ( for another person to use ) as she will not need it over the next couple of days when writing the report on her laptop . As illustrated in this scenario , SurfaceConstellations are at the sweet spot between ad hoc , loose multi - tablet setups and fixed multi - monitor desktops : re - configurations are made possible and easy , but we expect these to be only sporadic ( e . g . adding tablets to visualise additional data ) . There are many possible workstation setups in our design space ( Figure 28 ) that — once configured — would not necessarily require SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 168 any ( or only minimal ) changes . Importantly , our proposed designs are not intended to replace existing work - station setups ( e . g . laptop or desktop setups ) but provide more flexible options and new possible workstation designs . 7 . 2 . 5 Creating 3D - Printed Modular Brackets Next , we will explain the details of how to design , build , and manufacture the brackets holding devices for SurfaceConstellation setups . While there are many possible options for holding a tablet device in place ( for example , an all surrounding case , or a mount at the back of the device ) , we opted for a design that holds the devices in place by clipping a bracket onto each connected corner . Typically , a single bracket connects 2 to 4 devices , directly relating to the number of L - shaped sides of the bracket ( Figure 30 top ) . A bracket can be flat ( for example , to connect devices on a desk in Figure 28a ) or angular ( for most other designs in the design space , such as Figure 28b - e ) . Besides the number of connecting sides for the tablet , there are two key hardware parameters . 1 ) First , the width of the area covering the tablet case ( Figure 30w ) ; in our designs , this parameter is usually between 8 - 12mm . Ideally it does not cover any part of the screen ; though it needs to be wide enough to hold the tablet in place , which is more difficult with rounded tablet designs . 2 ) Second , the thickness of the space holding the tablet ( Figure 30t ) . This thickness needs to be slightly smaller than the device ’ s own thickness , so it applies enough pressure onto the case to hold the device in place ( with our PLA / ABS prints , decreasing thickness by 0 . 5mm results in good tension of the bracket onto the device to hold it in place ) . Brackets can be manufactured from different materials ( e . g . ABS , wood , acrylic ) with a variety of techniques ( e . g . CNC milling , glued acrylic laser - cut layers ) . We create most of our brackets using 3D - printing ( using Makerbot Replicator 2X and the Ultimaker 2 + ) . We achieved robust brackets with both PLA and ABS prints , with infill of 20 % up to 100 % . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 169 3 ) A third parameter of our bracket design to adjust is the thickness of the bracket ’ s top and bottom layers ( Figure 30d ) . We have found a thickness of ≥1mm to provide sufficiently robust bracket walls to hold the weight of the tablet . Figure 30 . 3D - printed bracket design and design parameters . Figure 31 . ( a ) OpenSCAD parametric bracket design and ( b ) code view , ( c ) MakerBot Customizer view , with sliders on the left side to adjust parameters ( e . g . device thickness , angle ) . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 170 All our bracket designs are modelled in OpenSCAD ( Figure 31a ) , which renders 3D models based on parametric script files and directly creates STL files for 3D printing software . Our modelling files include variables for all design parameters for each bracket , such as device thickness , number of L - shaped links , and angle between devices ( Figure 31b ) . Using the parametric OpenSCAD language , we designed a basic set of brackets with different parameters : number of links , angles , and device size and thickness ( Figure 28 ) . Choosing brackets from these base designs allows one to assemble most of our design space examples ( Figure 28 ) : for instance , the curved setup requires 2xE and 2xH , while the 6 - tablet trading desk setup needs 2xB , 4xE , and 2xG . The STL files of all base designs are included in our SurfaceConstellation library 13 ( size for 5 different device sizes : iPad 3 , iPad Air , iPad Air 2 , and Microsoft Surface 3 / 4 ; and pre - sets for 5 angles , see Figure 32 ) . Figure 32 . Library of bracket base designs . 13 https : / / github . com / nicmarquardt / surfaceconstellations / SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 171 7 . 2 . 6 Weight - Balancing and Support Extensions Next , we address the need for balancing weight to allow for device setups with free - standing elements . If the weight distribution of a device setup is unbalanced , additional support extensions need to complement a bracket to support the weight and hold the complete SurfaceConstellation setup in a stable position without tipping over . Determining the need for support extensions can be done as follows : 1 ) first , we determine the projection of the centre of mass of the whole setup on the ground . In most cases , we can assume that the weight distribution of each single device is even ( i . e . the centre of mass of a single device is in the centre of the volume ) . 2 ) We then calculate the centre of mass of the combined setup and project the coordinates back to the ground plane ( e . g . onto the surface the setup is standing on ) . A structure is stable if the projection point is within the base of support , which is the polygon composed of all the touching points between the built structure and the ground ( Figure 33a ) . 3 ) If the projection point is outside that area ( Figure 33b ) , we extend the 3D printed brackets on the bottom with additional parts to increase the base of support area ( Figure 33c ) . In practice , the structure should also be able to stand external forces such as a user ’ s touch input , which has different leverage depending on the surface orientation and height . To achieve this , we extend the minimum length calculated as above with 20 % of the height of the entire SurfaceConstellation ( this makes sure that the higher the overall setup , the longer the extensions , thus increasing stability ) . Figure 34 shows example extensions that were added to the brackets . To simplify the use of weigh - balancing extensions , we integrated the calculation of support extension into our GUI tool ( explained shortly ) for creating new device setups . 4 ) For asymmetric and hybrid structures , we need to calculate the projection calculation of centre of mass in two dimensions . For example , if we attach another tablet on the right side of the top tablet of the Bend Desk , the mass of SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 172 centre will move towards the right side , then the structure could possibly tip over both backwards and to the right . Figure 33 . Weight balancing and support extensions . Figure 34 . Examples of support extensions for brackets . Setting up SurfaceConstellation Workspaces : Configurator GUI Tool So far , we have mentioned three different ways in which a user can set up and use a new SurfaceConstellation workspace : 1 ) First , a person can directly use one of our existing complete sets of link brackets for pre - defined setup of devices ( e . g . examples from the design space in Figure 28 ) . Each package includes the designs of all required brackets ( STL files for SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 173 direct 3D - print ) , rendered for different device types . These packages are included in our SurfaceConstellation library that are linked in the original publication linked at the beginning of this chapter . 2 ) Second , a user can choose from the collection of existing base brackets ( Figure 32 ) and combine them into new setups of connected devices . 3 ) Fourth , the most flexible method for creating new brackets is by using the OpenSCAD script directly . However , this does require knowledge of the OpenSCAD scripting language . While the first two options are the easiest to use , the latter one allows the most flexible customizations ( many parameters that can be changed ) but are also more complex to use . To bridge this gap between easy - to - use and powerful options , we designed a web - based GUI tool ( Figure 35 ) that allows the configuration of entire workspaces via a parameter menu . Users can choose the number ( Figure 35a ) and type ( Figure 35b ) of devices they want to use , and then define orientation and angles between them ( Figure 35c ) . The resulting workspace is visualised in real - time as an interactive 3D model ( Figure 35d ) . The user can interact with the 3D model using the mouse or touch gestures to view it from different angles . The values of the selected configuration can then be manipulated through the interface . For an easy start , users can choose a pre - existing configuration of devices from a dropdown ( Figure 35e ) . This selection of typical pre - sets can be used as - is ( e . g . 3 tablet console ) or as a starting point for new designs by adjusting the parameter set ( Figure 35e ) . Each design can be saved as a new pre - set . Furthermore , the tool automatically calculates the weight distribution and centre of mass of the constellation setup and adds any necessary support structure extensions to the brackets ( Figure 35f ) . Finally , the tool renders all the STL models for any required brackets ( Figure 35g ) and provides a single link to a ZIP file including all files ( Figure 35h ) or allows the user to email the zip file to themselves . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 174 The web - based configuration tool 14 is implemented using nodeJS on the backend and React for the frontend . It can be accessed using any modern web browser and guides the user through three - step process of creating the brackets : 1 ) Setting the parameters ; 2 ) Rendering the preview of the brackets as interactive 3D models , and 3 ) Downloading the collection of 3D printing files or emailing them to oneself . For the rendering of the bracket preview files we use the same parameterised OpenSCAD script that we described earlier , displaying the STL output files in an HTML canvas in the user ’ s web browser . This allows the user to explore the 3D printing model by reviewing it from all sides by rotating and zoom in . Figure 35 . GUI tool for creating customised workspaces . To further simplify the specification of the actual angle between tablets , we added an additional configuration - by - demonstration feature : one ( or multiple ) devices can stream their angle and orientation ( measured by the internal IMU ) to the web - based GUI tool , which then automatically uses this current angle to modify the setting in the web interface . This allows users to place one or multiple tablets on a desk and reconfigure them until the desired angle is found . Through the HTML5 Device Orientation API we can get each device ’ s current orientation . This enables the user to 14 https : / / sc . fbrudy . net SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 175 preview physically what a SurfaceConstellation before they decide to 3D - print any brackets . Developing Software and Applications Once a SurfaceConstellations hardware setup has been created and the tablets are physically connected , the next question we need to address is how to use existing software with the setup , or how to develop new applications . Because SurfaceConstellation setups are fundamentally similar to cross - device applications , it is possible to leverage existing toolkits that facilitate the development of multi - surface applications , such as Webstrates ( Clemens N . Klokmose et al . 2015 ) for dynamically shared media webpages ; XDBrowser ( Nebeling 2017 ) , which allows adapting websites for cross - device use ; XDSession for testing ( Nebeling et al . 2015 ) ; or Connichiwa ( Schreiner et al . 2015 ) for local hosted , ad hoc cross - device applications . We decided to demonstrate the SurfaceConstellation platform ’ s versatility with four example applications , built with different frameworks and tools , while at the same time illustrating diverse setups across the design space taxonomy . Before we go through these use cases , we describe four development strategies for using software with or programming software for SurfaceConstellation setups . 7 . 4 . 1 Software Connectivity and Interaction Applications running on touch - screen devices that are connected in a SurfaceConstellation workstation can be designed in four different ways ( summarised in Figure 36 ) : 1 ) No connection : In this configuration , existing applications can be used side - by - side without any direct communication between them ( Figure 36a ) . Examples for this scenario are an email client on one device and a calendar application on the other ; or a word processor next to a dictionary . 2 ) Indirect connection : The software running on each of the devices are communicating indirectly with each other , e . g . through explicit read and write operations on a backend server or shared storage ( Figure 36b ) . An example of this method is using a photo editing software on one device and SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 176 saving the results to a cloud storage where a blogging platform can access and use the edited photos . 3 ) Direct local connection : We can leverage direct , local cross - device communication between devices ( e . g . with Wi - Fi , Bluetooth , Figure 36c ) . Direct connections allow for network independence and low communication latency ( Schreiner et al . 2015 ) . Examples for such software setups are multi - player games with different views for each player on the connected devices . 4 ) Distributed MVC : Lastly , the devices can display views of distributed interfaces as part of a distributed model - view - controller ( dMVC ) architecture . The view is individual to each device and a backend server controls the application logic ( Figure 36d ) . An example of this category is a web - based visual analytics tool . Figure 36 . Design characteristics for software running on SurfaceConstellation setups SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 177 These four methods differ in the degree of how closely coupled the software connection is implemented . While for some use cases it is feasible to set up SurfaceConstellation with multiple devices that have no direct software - side connectivity ( Method 1 ) , adding connectivity can allow more fluid and seamless interactions with the cross - device applications ( Methods 2 - 4 ) . 7 . 4 . 2 Available Information about Setup and Devices When designing applications for SurfaceConstellation setups , it can be useful to address the following 4 parameters : 1 ) Presence , of devices , number of devices , and the identification of devices . Most cross - device development frameworks ( Clemens N . Klokmose et al . 2015 ; Nebeling et al . 2015 ; Schreiner et al . 2015 ) incorporate a device registration and discovery mechanism . 2 ) Device capabilities , in particular the resolution of the displays ( e . g . pixels height , width , ppi ) . This information can be shared through the network connection between devices by using a development framework or web - based connections ( for example , WebSockets ) . 3 ) Orientation of devices in space , e . g . are the devices laid out flat on a table , or are they positioned standing up vertically ? Integrated IMU sensors can provide this information automatically . 4 ) Relative position of devices in a SurfaceConstellation setup . This information can be established either via manual configuration , sensor readings , or through the CapacitiveLink brackets ( not described in this chapter — for details see the CHI ’ 18 paper linked at the beginning of this chapter ) . Four Example Applications Across the Surface - Constellations Design Space To best illustrate the flexibility and expressiveness of the SurfaceConstellations setups across our design space ( Figure 28 ) , we describe four use case applications ( three custom - built and one commercial software ) . Our applications also demonstrate how to use existing cross - device development frameworks ( in particular , Connichiwa SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 178 ( Schreiner et al . 2015 ) and Webstrates ( Clemens N . Klokmose et al . 2015 ) ) when developing SurfaceConstellation applications ( overview of the four use cases in Table 9 ) . The first two applications show how cross - device systems can be broadened up to other use - cases of knowledge work — previously explored through curation activities . The last two applications demonstrate how cross - device interaction can be used in even broader scenarios of games and creative audio remixing . Application Design space Implementation 1 . Financial Computing ‘Trading desk’ Connichiwa ( Schreiner et al . 2015 ) 2 . Visual Analytics ‘Bend - desk’ Webstrates ( Clemens N . Klokmose et al . 2015 ) 3 . Audio - channel mixing ‘Dual - screen laptop’ Commercial application 4 . Board game ‘Bridge’ WebSockets + nodeJS Table 9 . Overview of use - case applications . We categorise all our demo applications according to our taxonomy of cross - device design space dimensions ( Chapter 4 ) . In terms of the 5 th ( dynamics ) and 6 th ( space ) dimension , using the SurfaceConstellation brackets means that the dynamics of the setup are situated between ad hoc / mobile and semi - fixed in a collocated environment : device configurations can be quickly created or altered , but at the same time have a rigidity that is usually associated with more permanent desktop setups . 7 . 5 . 1 Application 1 : Trading Desk for Financial Computing Trading desks often consist of multiple screens and many different views of related data . As an example , we built a financial trading workspace which consists of stock trading widgets ( Figure 37 ) . We developed this application with the Connichiwa ( Schreiner et al . 2015 ) framework to run a local server instance on one of the tablets . This tablet functions as a master device to which clients can connect , to select which financial data widget should be displayed on each device . According to our taxonomy of the cross - device design space , this example application supports synchronous use , where an application ’ s UIs are logically distributed . It is mainly intended for a 1…m relationship of user to devices on a personal scale , meaning SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 179 that one person uses multiple devices that are placed within their reach . As mentioned before , the dynamics are between ad hoc and semi - fixed , allowing for flexible ( re ) configuration . Figure 37 . Top : Financial trading - desk using eight 3D - printed brackets . Bottom : Alternative trading - desk setup using four different brackets . Devices connect to the webserver running locally on one of the iPads directly through the local WiFi network and access webpages on the server . We implemented a manual configuration of the device ’ s locations within the financial trading desk : a new client connects to the server through a URL , e . g . by simply scanning a QR code on the SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 180 master device ( Figure 38 ) , the current layout of the setup is shown , with placeholders of where the new device can be connected ( Figure 39 ) . This allows users to manually configure the physical layout in the software . Once a device has been added it is assigned a numerical unique ID in the setup . Going forward , the system allows users to send a visual element ( i . e . a financial widget ) to any of the connected devices by simply selecting it from a list of devices . Figure 38 . A new client connects to the local URL on the master device by scanning a QR code . Figure 39 . The position of a newly added device is configured through a manual configuration step : the user selects the device ’ s position from all possible new positions ( grey rectangles on bottom middle screen ) . Existing devices are shown in turquoise and identified through their number ID . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 181 7 . 5 . 2 Application 2 : Hybrid Setup for Visual Analytics Visual analytics often requires analysts to distribute information items across different screens , allowing them to compare different views of the same data . We built a distributed web application ( based on the WebStrates platform ( Clemens N . Klokmose et al . 2015 ) ) in which analysts are presented with an overview of available visualizations for a dataset ( Figure 40a ) . By using additional brackets , analysts can dynamically add devices to the setup . For example , an analyst might start with a curved setup , consisting of three tablet devices . After working with the system for a while , they want to move the control interface off the tablet to declutter the views on the tablets . They simply switch out one of the brackets with a different one that has an opening to hold a phone . Figure 41 shows how a phone is added to the workstation setup , displaying a control selection interface for the visualization presented on a tablet next to it ( Figure 40b and c ) . This demo application is logically distributed and supports second - screen controls ( i . e . Figure 40b ) . It is intended for a 1…m relationship of user…devices in a personal scale , where the setup is in easy reach . The described addition of the phone by simply exchanging a bracket ( Figure 41b ) shows how the semi - fixed setup can be dynamically altered , showcasing the power of the flexible setup . Figure 40 . Setup for visual analytics application SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 182 Figure 41 . A phone is added to the setup by simply exchanging a 3D printed brackets for one that has an opening to hold the phone ( a + b ) . The software configuration of the newly added device is by simply selecting the newly added device ’ s position on the screen ( c ) . The phone displays an interface that controls the visualisations on the other devices ( d ) . Our visual analytics demo is a web - based system that can be loaded on any modern web browser . Again , the connection is done by either entering a URL or scanning a QR code . The web server runs remotely and therefore no custom software is needed on any of the devices . The configuration of the physical layout of the SurfaceConstellation is done — as described earlier — through a manual step by selecting the position of the newly added device after loading the web app . 7 . 5 . 3 Application 3 : Audio - Track Mixing Multi - touch tablets are increasingly used to control professional live digital audio mixers ( e . g . to control level faders , gain , and tone controls ) . Providing a flexible spatial arrangement for these tablet devices is an ideal use case for SurfaceConstellation setups . We designed a mixing table hardware setup supporting three control tablets ( Figure 42 ) . Using the commercial Soundcraft Ui24R mixing system 15 we can control 24 audio channels and settings ( Figure 43 ) . Each of the tablets can provide access to a different subpage of the mixer ’ s software control interface . The application itself is an off - the - shelf system that is hosted on a web server in the rack unit and can be accessed through the web browser via a local Wi - Fi connection . Its configuration across our cross - device design space is that of a logical distribution for synchronous use , supporting an n…m configuration on a personal and social scale . Again , through 15 http : / / www . soundcraft . com / products / ui24r SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 183 use of SurfaceConstellations , the dynamics are fluid between ad hoc / mobile and semi - fixed setups . Figure 42 . Audio - track mixing setup . Left : ( a ) control 7 - channel level fader bank , ( b ) equaliser , and ( c ) metering . Right : The setup supports varying orientations of the tablets . Figure 43 . A user controls the commercial Soundcraft Ui24R mixing system ( shown in the background and hosting the web application displayed on the tablet devices ) through three tablet devices . Two 3D - printed brackets are used to create the “mixing board” layout . By allowing to use the tablet devices in different spatial layouts and enabling sound designers and engineers to create their own unique setup , this example demonstrates how SurfaceConstellations can be useful not only to custom application , but also to existing cross - device systems . Setups can be dynamically adapted to a user ’ s needs and can be easily packed for transport between different sites , adding only little weight to the equipment that has to be moved . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 184 7 . 5 . 4 Application 4 : Bridge Setup for Two - player Board Games This example implements a board game ( like the Scrabble TM word game ) using the ‘ bridge ’ setup ( Figure 44 ) . The shared tablet in the centre shows the playing field , while the user - facing devices show a private view of each user ’ s letter rack . On their turn , a user selects a combination of letters , which is then shown in the central shared playing field . From there , the person can drag the letters to position them on the playing board . This example is implemented using WebSocket connections between the devices and a central nodeJS server managing the shared game state . The selection of letters on a player ’ s rack are sent to the server which forwards the selected letters to the board - view . Figure 44 . Digital multi - player game , leveraging people ’ s existing devices . The two - player bridge - setup is again an example for synchronous use of a logically distributed UI . The relationship is 2…2 , where the individual screen provides a private view for each player and shared device in the centre is used by both players on a social scale . This example demonstrates that cross - device systems are not only useful for knowledge work or in professional environments , but many also in leisure situations and with friends . One could imagine that two friends meet in a cafe . They get their devices out and with the simple addition of four lightweight SurfaceConstellation brackets they can create a sophisticated game setup which previously was not SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 185 available . The setup can be easily taken down and setup elsewhere since the brackets are easily carried around , being lightweight and not taking up much space . Reflecting of SurfaceConstellations ’ Characteristics Reflecting on SurfaceConstellations designs , we briefly discuss characteristics of semi - fixed setups , roles of devices , and possible interaction techniques . 7 . 6 . 1 Semi - Fixed vs . Mobile Cross - Device Setups SurfaceConstellations strike a balance between the traditional desktop screen arrangements found in expert environments as well as ad hoc mobile device groupings . The former is a specialised arrangement of screens , typically to support a set of specific tasks ( e . g . air traffic control , finance applications , etc . ) . Ad hoc mobile scenarios , in contrast , typically involve fluid arrangements of devices , quickly positioned usually by hand to support a certain task ( e . g . exchanging or comparing information ) and often span multiple users . Importantly , such scenarios involve personal mobile devices — the devices we always carry with us . SurfaceConstellations offer a framework for semi - rigid arrangements of mobile devices . While such arrangements are more rigid than the fluid gathering of mobile devices , they can be made persistent if desired and redeem many of the benefits of traditional multi - monitor setups . At the same time , they can be reconfigured easily by rearranging device positions and orientations through different brackets . 7 . 6 . 2 Roles of Devices Closely related to the setups of devices are the roles different devices may take . From a technical perspective , all connected tablets in a constellation might be of the same kind ( for instance , using only Microsoft Surface tablets ) , but they might take very different roles depending on their placement , the application , and the task at hand . For example , some devices might become primary interaction devices ( for example , a touch keyboard for rich input ) while others become secondary devices ( e . g . a drag - and - drop clipboard , or a touch - enabled thumbnail overview ) or even passive , SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 186 viewing - only devices ( e . g . a large zoomed - in view of content ) . Further investigating the roles ( and possibly fluid changes of roles ) of devices remains part of future work . 7 . 6 . 3 Interaction Techniques For the scope of this chapter , we focused on the hardware designs of the platform as well as an exploration of the design space for application development . For any SurfaceConstellation workstation , there is a design opportunity to tailor interaction techniques to best support interaction in each particular setup and application . For example , we can develop techniques to better support cross - device interactions such as dragging objects across surfaces ( Hinckley et al . 2004 ) . Indirect manipulations could be used when the configured workstation setup has devices or areas that are inconvenient to reach . Existing overview + detail techniques could be integrated , such as having one surface showing a data map overview and multiple DragMag views to show details of particular regions ( Ware and Lewis 1995 ) . Such interactions techniques are highly dependent on the use - case a system or tool is trying to solve . SurfaceConstellations is impartial to any software implementation . As discussed earlier , it can already be used with existing systems and tools . However , dynamic cross - device setups illustrate exciting opportunities for custom - built interaction techniques . 7 . 6 . 4 Cross - Device Applications for the Masses The SurfaceConstellation platform enables anyone with access to a 3D printer and multiple tablets / phones to design and construct one ’ s own multi - surface workspace . Similar to the research field of cross - device interactions , we anticipate that an increasing number of available touch - screen devices will soon allow people to use their devices in concert — and that SurfaceConstellations arrangements can help to facilitate people ’ s interaction with this larger number of devices . Importantly , we made the SurfaceConstellations designs available as open hardware and open software ( see the citation at the beginning of this chapter for details ) . With our designs , taxonomy , and examples , we aim to inspire users ’ creativity to build , use and re - appropriate such environments for various scenarios of use , which we hope takes us one step closer to making cross - device applications available to the masses . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 187 While iteratively developing the systems reported on in Part II of this thesis ( including prototypes that have been omitted from this thesis ) , we realised that studying and evaluating interactions with cross - device systems is difficult to do . Many of the research frameworks and tools are either not suitable for multi - user and / or multi - device interactions . Further , the reviewing of just one hour of video recording of cross - device studies — or even deployments — takes 3 - 5 hours of analysis . Therefore , the next part is concerned with studying and evaluating cross - device tools and interactions . SurfaceConstellations : A Modular Hardware Platform for Ad hoc Cross - Device Setups 189 P ART III : S TUDYING AND E VALUATING C ROSS - D EVICE T OOLS Part III is concerned with studying and evaluating cross - device systems and tools . As discussed in Chapter 4 , cross - device systems can be evaluated through a broad range of methods . However , many evaluation techniques do not account for the current device setups of these interactions , or for the dynamics of people ’ s actions and interactions in such cross - device scenarios . Therefore , we first present an empirical study ( Chapter 8 ) that explores different strategies in the design of cross - device systems . The results show that we can deliberately design experiences that foster shared attention , more discussions , and overall a better task outcome . Analysing such studies is cumbersome and often requires a lot of work in reviewing and understanding many hours of video recordings . In Chapter 9 we therefore present EagleView , a tool that supports researchers in the interaction analysis of studies employing cross - device computing systems . EagleView provides visualisations and search functionality of cross - device interaction modalities , allowing researchers to more easily gain insights on their study data . Investigating the Role of an Overview Device in Multi - Device Collaboration 191 Chapter 8 . Investigating the Role of an Overview Device in Multi - Device Collaboration 16 The availability of mobile device ecologies enables new types of ad hoc collocated decision - making and sensemaking practices in which people find , collect , discuss , and share information . However , little is known about what kind of device configurations are suitable for these types of tasks . This chapter contributes insights into how people use configurations of devices for one representative example task : collaborative collocated trip - planning . We present an empirical study that explores and compares three strategies to use multiple devices : no - overview , overview on own device , and a separate overview device . The results show that the overview facilitated decision - and sensemaking during a collaborative trip - planning task by aiding groups to iterate their itinerary , organise locations and timings efficiently , and discover new insights . Groups with overview shared and discussed more opinions , resulting in more democratic decision - making . Groups provided with a separate overview device engaged more frequently and spent more time in closely - coupled collaboration . 16 Parts of this chapter have been published previously in : Frederik Brudy , Joshua Kevin Budiman , Steven Houben , and Nicolai Marquardt . 2018 . “Investigating the Role of an Overview Device in Multi - Device Collaboration . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 300 : 1 – 300 : 13 . CHI ’18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173874 . Joshua Kevin Budiman implemented parts of the Voyageur system as part of his MSc dissertation project . I acted as supervisor to his work , advised on direction of the project , implemented significant parts of the Voyageur system , as well as the data logging framework . I ran 60 % of the study participants and analysed the study data and was also the lead on the publication write - up for CHI 2018 . The coding scheme was developed together by all co - authors . Steven Houben and Nicolai Marquardt were advisors on the project . Investigating the Role of an Overview Device in Multi - Device Collaboration 192 Cross - Device Interactions for a BYOD scenario With the increased availability of mobile internet - connected devices , there is a shift in how people use information . The mobility of computing power has led to a nomadic workflow , in which people can access and process information ‘ on - the - go ’ . People pull out devices at any point in time to access , share , filter through , and sort information . Technology helps people make sense of the increasing amount of information and ultimately influences people ’ s decision - making process . In general , such sensemaking activities are concernced with analysing information in a structured way by collaboratively collecting and organising pieces of information to derive new knowledge , insights , and eventually arrive at the right result ( i . e . knowledge product ) ( Pirolli and Card 2005 ) . In our work , we focus on the practices during a collaborative decision - making activity in an iterative process of foraging and sensemaking : a trip - planning task . Compared to a structured sensemaking task , in a collaborative decision - making task , there is not always a right or wrong answer and the decisions are influenced by the opinions people hold or the preferences they have ( DiMicco , Pandolfo , and Bender 2004 ) . Sharing information and opinions between individuals is important to yield a result that satisfies all those involved ( Stewart and Stasser 1998 ) . When a group fails to share information ( e . g . through a lack of collaboration ) , there is an increased possibility of making a decision which does not satisfy everyone or even might be wrong ( DiMicco , Pandolfo , and Bender 2004 ; Stewart and Stasser 1998 ; Whyte 1991 ) . Previous work found that group performance benefits when collaborators share and discuss task materials when engaging in closely - coupled collaborations ( DiMicco , Pandolfo , and Bender 2004 ; Hansen and Järvelin 2005 ; J . R . Wallace , Scott , and MacGregor 2013 ) . Furthermore , the closeness of teams ’ collaboration and communication positively influences task performance and outcome ( Isenberg et al . 2012 ) . Large interactive surfaces ( Nacenta et al . 2012 ; A . Tang et al . 2006 ; J . R . Wallace , Scott , and MacGregor 2013 ) and combinations of mobiles can support collaborative work and help mediate ad hoc collaborations and decision - making activities ( DiMicco , Pandolfo , and Bender 2004 ; Lucero , Keränen , and Korhonen 2010 ; Wozniak et al . 2016 ) . A combination of mobile devices and a shared tabletop was found to lead to increased and better group collaboration ( Seifert et al . 2012 ) . However , meetings often happen spontaneously and the tedious setup of Investigating the Role of an Overview Device in Multi - Device Collaboration 193 tabletop or wall displays contradicts the ad hoc nature of meetings ( Schreiner et al . 2015 ) — thus , previous work proposed to use mobile , personal devices in collaborative scenarios ( e . g . ( Rädle et al . 2014 ; Schreiner et al . 2015 ) ) . In this chapter , we study how a group of people collaboratively plan a day - trip through London in such a multi - device bring - your - own - device ( BYOD ) ecology ( Figure 45 ) . A collaborative trip - planning task is an example of an iterative process of foraging and sensemaking , understanding the progress , and making decisions based on personal preferences , possibilities , and prior knowledge . We investigate if providing collaborators in a multi - device ecology with a shared space ( an overview device ) to organise their travel itinerary influences their sensemaking and decision - making practices . Our empirical study compares the practices in three conditions : ( i ) one collaborator brings an additional device that acts as a shared , always - on device , showing a summary of the progress ; ( ii ) the overview is shown on each collaborator ’ s device , but no additional shared device is available ; ( iii ) each participant has only their own device and no overview is shown on each individual ’ s device . Figure 45 . Using a collaborative travel planning application scenario ( left ) , we study the effect of device configurations in a collocated multi - surface setting ( centre ) with three different conditions ( right ) . Our contribution is a study of how multiple tablets are used in ad hoc decision - making activities . We observed that a separate overview device , with basic cross - device functionality , increases collaboration and leads to better decision - making when compared to having only personal tablets . Trips created by groups provided with the overview consisted of a more thought - through itinerary due to the groups doing multiple iterations of their work , accounting for more factors , spotting errors in their plans , and overall leading to a more democratic decision - making process . Investigating the Role of an Overview Device in Multi - Device Collaboration 194 Those groups also perceived mental demand as slightly lower . Compared to having the overview on everyone ’ s tablet , the use of an additional shared device resulted in more closely - coupled collaborations and more face - to - face discussions . Our study is the first to demonstrate that cross - tablet interfaces can successfully support collaborative decision - making while supporting advanced practices previously only observed in complex tabletop / wall - display setups ( e . g . ( Hornecker et al . 2008 ; Isenberg et al . 2012 ; J . R . Wallace et al . 2011 ) ) . In terms of our cross - device taxonomy ( Chapter 4 ) , our system to conduct the study reported on here — Voyageur — supports synchronous use with a logical distribution of the user interface . Multiple users work together either in a 1…2x1…2 or 1…1x1…1 configuration , depending on whether they are using the overview device or not . The setting of the usage is on a social scale , as it is primarily used around a table in a collocated scenario . The dynamics are focused on an ad hoc and mobile setup and use . Voyageur : Collaborative Trip Planning To study collocated , collaborative trip planning in an ad hoc BYOD setting , we implemented Voyageur , a multi - device collaborative web - based tool for planning a sightseeing tour through a city ( Figure 45 ) . Voyageur allows users to combine their personal devices , such as smartphones or tablets , into one interaction space , allowing them to create a shared itinerary . Each user can suggest and edit the group ’ s shared map on their personal device while a summary of the trip is either shown on individual devices or on a separate overview device . Voyageur is a representative of a system that prior works have proposed in the cross - device domain for using personal devices to collaborate ( e . g . ( N . Chen , Guimbretiere , and Sellen 2012 ; Lucero , Keränen , and Korhonen 2010 ; Hamilton and Wigdor 2014 ; Rädle et al . 2014 ) ) . Previous work found that giving participants visual feedback of their participation in a group task on a shared display influenced participation by levelling out over - and under - participation ( DiMicco , Pandolfo , and Bender 2004 ; Tausch et al . 2014 ) and that activity awareness benefits groups ’ performance in a remote collaboration ( Carroll et al . 2003 ) . In our study , groups were collocated and provided with an overview of the Investigating the Role of an Overview Device in Multi - Device Collaboration 195 current task outcome , shown either on users ’ individual devices or on a shared device . It offers a go - to place for individuals to initiate a group discussion . 8 . 2 . 1 Voyageur Implementation and Interaction Voyageur consists of a web application that allows one to search for locations , using a Google Maps interface . Locations can be shared with other users . Shared locations can be annotated with a visiting order and duration , thus creating a shared itinerary . A summary is provided as a zoomed - out map overview , where locations are connected according to their visiting order . A progress bar at the bottom of the screen shows how much time has already been allocated or whether a given time limit has been reached for the duration of the overall trip ( in our study : 7 hours ) . In order to support ad hoc collaborative sessions , we implemented Voyageur with the Connichiwa ( Schreiner et al . 2015 ) web framework , which facilitates the distribution of web applications across multiple collocated devices . Voyageur provides two different views ( shown in Figure 45 and Figure 46 ) : overview ( shown on the master or in an inset window on the client ) and client ( shown on any connected client ) . Both views show a geographical map ( using Google Maps ) . The client application allows users to search for points - of - interest using a text input . While typing , search suggestions are presented and upon selecting one of the suggestions , a marker pin is dropped on the map . By touching the marker , the location can either be shared with the other users or deleted . Shared location markers appear on all connected devices and can be annotated with a visiting order and the duration ( in hours and minutes ) to add it to the shared trip itinerary . Annotations are synchronised across all devices . When shared markers are deleted , they are deleted on all devices . A summary is provided as an overview , where locations are connected per their visiting order , visualising the air - path of the tour ( Figure 45 left ; Figure 46 right ) . A progress bar at the bottom of the screen shows the trip duration and remaining time of a given time limit ( in our study : 7 hours ) . Investigating the Role of an Overview Device in Multi - Device Collaboration 196 Figure 46 . Comparison of the layouts for the study conditions . Voyageur supports the following sense - and decision - making tasks as part of a collaborative trip - planning activity : 1 ) Facilitate sensemaking and decision - making . The visual overview of Voyageur allows one to detect patterns and derive insights about what to include in a trip . By providing all group members with access to the overview , Voyageur creates a shared understanding of the task , thus , assisting sensemaking ( Pirolli and Card 2005 ) and decision - making ( Stewart and Stasser 1998 ) . It provides feedback about the current state and what has been accomplished . 2 ) Encourage closely - coupled collaborations . Closely - coupled collaborations foster more insights and higher task completion satisfaction ( Isenberg et al . 2012 ; A . Tang et al . 2006 ; J . R . Wallace et al . 2011 ) . Voyageur encourages closely - coupled collaborations by giving groups a shared always - on device , showing an overview of the progress . 3 ) Encourage group discussion . While increasing the amount of time people speak in a collaborative decision - making task is not directly congruent to their influence on the decision , an imbalance in participation can indicate that not enough details are being shared and not all participants ’ relevant viewpoints are discussed ( DiMicco , Pandolfo , and Bender 2004 ) . Voyageur enables group synchronization as well as spatial and activity awareness of explicit and implicit gestures through equal access of all users to the overview , thus , encouraging initiation of group discussions about items shown ( Carroll et al . 2003 ; J . R . Wallace et al . 2011 ) . Investigating the Role of an Overview Device in Multi - Device Collaboration 197 4 ) Accommodate different roles . The roles of foragers and sensemakers for sensemaking tasks have been established ( Vogt et al . 2011 ) , and it was pointed out that in a group scenario , collaborators frequently switch between these roles ( Isenberg et al . 2012 ) . Voyageur allows for users to switch roles at any time by creating a shared understanding of current progress and equal access to information , thus , enabling flexibility of roles . Displaying the overview on a separate device allows users to touch or move the shared device . Encouraging explicit gestures , we aim to support implicit understandable roles ( J . R . Wallace et al . 2011 ) 8 . 2 . 2 Sensemaking Tasks for Trip Planning Voyageur supports collaborative planning of a trip itinerary . Numerous applications have been developed to support individual users ( e . g . Citymapper , Google Maps ) and groups ( e . g . Travefy , Triporam ) in trip planning . However , these tools do not specifically support collocated collaboration . Previous research explored , for example , travel suggestions through geo - tagged photos ( Majid et al . 2012 ) and calculating the best trip based on aggregated trip distance ( Hashem et al . 2015 ) . However , in an everyday scenario , people often use the combined interests and local knowledge of a group to decide on what to include in a trip and they might sit together to plan their itinerary , using their individual devices to find locations and information . Study Using Voyageur , we studied a collaborative trip planning activity supported by a separate overview device , while each person is using an individual tablet device . Through the study we wanted to learn if and how Voyageur ( FP1 ) facilitates collaborative decision - and sensemaking practices during a collocated trip planning activity ; ( FP2 ) encourages closely coupled collaboration , thus fostering more insights and higher task completion satisfaction ( Isenberg et al . 2012 ; A . Tang et al . 2006 ) ; ( FP3 ) encourages more sharing of information , thus enabling more discussions and consideration of more people ’ s opinions ( DiMicco , Pandolfo , and Bender 2004 ) ; ( FP4 ) supports different roles of foragers and sensemakers ( Vogt et al . 2011 ) and allows for flexible transition between roles ; and ( FP5 ) accommodates different collaborative Investigating the Role of an Overview Device in Multi - Device Collaboration 198 strategies as observed previously ( Isenberg et al . 2012 ) ( we will refer back to the focus points FP1 - FP5 when reporting on the main findings in Table 10 ) . The task given to the group was to ‘ plan a day - tour through London ’ , visiting important landmarks , lasting 7 hours . 8 . 3 . 1 Participants We recruited 40 participants ( 21 female , 19 male ) in groups of 4 from the local university and via snowball sampling . The only requirements were that ( 1 ) participants were familiar with London , having lived there for at least six months , and ( 2 ) participants in each group knew each other . The second requirement was directly imposed by our task motivation ( groups of strangers would not plan a day - trip through London together ) and allowed participants a more relaxed communication setting . We recruited 22 students ( postgraduate and PhD ) and 18 professionals ( consultant , PA , teacher , etc . ) , aged between 23 and 37 years ( Mean ( M ) = 30 years ; Standard Deviation ( SD ) = 4 . 1 ) . All participants owned at least one touch device ( smartphone , tablet , or smartwatch ) and all but three reported that they used it often / daily . Two thirds ( 67 . 5 % ) of participants owned two or more touch - enabled devices ( M = 1 . 9 ; SD 0 . 7 ) . All participants but one had prior experience in planning a trip as a group , primarily using Google Docs and Maps to collect links ( e . g . accommodation , transportation , tourist websites , etc . ) and their itinerary . Participants mentioned they use websites , guidebooks , travel apps , and their own or friends ’ local knowledge to plan things to do . They described their collaborative planning taking place in asynchronous remote settings ( e . g . via email or text messages ) as well as in collocated synchronous settings ( e . g . at a friend ’ s house or in a coffee shop ) . F1 : Overview allowed groups to detect patterns of locations that can be easily visited together ( FP1 ) . F2 : The overview created a shared understanding . Groups with an overview ( WO , INT ) tried out different options for timings and visiting order . This led to consideration of more options ( FP3 ) . F3 : WO and INT groups shared more opinions and more people shared their opinion ( FP3 ) . This resulted in a more democratic decision - making process ( FP4 , FP5 ) . F4 : Overview led to iterations of the itinerary : This resulted in groups to spot and correct errors and allowed them to account for additional factors , such as lunch breaks and travel times ( FP1 , FP3 ) . Investigating the Role of an Overview Device in Multi - Device Collaboration 199 F5 : Displaying on separate device ( WO ) led to more closely - coupled collaboration and more face - to - face interactions by giving them a spatial and contextual focus point ( FP2 ) . It enabled group members to initiate a discussion spatially around the shared device . F6 : Territorial behavior : individual devices were rarely shared and only small glimpses occurred to them . The overview device was used equally by all group members . Table 10 . Main findings ( F1 - F6 ) and their connection to the 5 focus points ( FP1 - FP5 ) of our study 8 . 3 . 2 Study Design To understand the influence of displaying Voyageur ’ s overview on an additional device on group collaboration , we conducted a between - subject study , where we modified the presence and location of the overview : no - overview - device ( NO ) , with - overview - device ( WO ) , integrated - overview - on - individuals ’ - devices ( INT ) shown in Figure 46 . In the INT condition , the overview was integrated in users ’ individual devices , and no additional device was given . In WO , the overview was displayed only on a separate device . No overview on individual devices and no additional overview device was given in the NO condition . We were interested in comparing the groups ’ practices and collaboration strategies emerging from the different device setups . We conducted our study in a between - subject design to ( i ) avoid bias through carry - over effect ( Greenwald 1976 ) ; ( ii ) minimise range effects and avoiding contextual comparison of all tasks but the first task ( Greenwald 1976 ) ; ( iii ) avoid experimenter demand effects and avoid drawing attention to the added / removed overview ( Charness , Gneezy , and Kuhn 2012 ; Greenwald 1976 ) ; and ( iv ) avoid fatigue of participants due to study length and task repetition . 8 . 3 . 3 Apparatus Participants were invited to our lab . After giving consent , they completed a pre - study questionnaire with basic demographic data , prior experience in collaborative travel planning , and device usage . Each participant was provided with an iPad Air 2 tablet with a 9 . 7 ″ display ; in the condition with - overview - device ( WO ) an additional iPad was provided . Participants were seated around a 118x60cm table ( Figure 45 middle ) , with the researcher on the side as observer . Pen and paper were provided for completing the questionnaire and in case participants wanted to take notes during the study . After an introduction , participants were given a 5 - minute training phase . After Investigating the Role of an Overview Device in Multi - Device Collaboration 200 answering questions , each participant was given a separate subset of 5 out of the first top - 20 attractions in London ( “The Top 10 Things to Do in London 2016 - TripAdvisor” n . d . ) on a sheet of paper . Participants were then asked to plan a day out in London , exploring all or a subset of these attractions , lasting no longer than 7 hours . No time limit for task completion was given . Upon task completion , participants filled out a post - study questionnaire , rated task difficulty on a 10 - point Likert scale ( based on the NASA TLX ) , and a semi - structured interview was conducted . We conducted 4 sessions for WO , and 3 sessions for each NO and INT , each lasting 45 - 60 minutes ( for a total of 10 sessions ) . 8 . 3 . 4 Data Collection All sessions were video recorded to analyse groups ’ collaborative practices . In addition , notes were taken by the researchers during the study . Search input on each user ’ s device , as well as actions to share , annotate and delete locations were logged by the system . We recorded touch input on the personal devices to quantify participants ’ interactions . “Touch activities” reflect the number of times the data log application captured tablets ’ touch coordinates , post - hoc grouped to a maximum of once every 50ms / device . More touch activity therefore indicates busier interaction on the tablet due to increased touch movements from users ( touch - down , - move , and - up ) . Questionnaires and semi - structured interviews were used to assess participant ’ s prior knowledge and their intended strategies during their group work . The collected log data and video recordings were analysed using ChronoViz ( Fouse et al . 2011 ) . We coded the video for groups ’ collaboration practices , participants ’ interactions with each other , their device ( s ) , and the focus of their interactions ( e . g . being on a device , a collaborator , or content on the screen ) . The analysis of the materials collected during the study followed the pragmatic approach to Thematic Analysis as described in Chapter 2 . The material coded was the recorded study video as well as the notes taken by the experimenter . We did not apply an existing coding scheme , but created codes as we encountered them , except for groups ’ collaboration styles ( which we will discuss shortly ) . 40 % of the videos were coded by two researchers , where the second researcher built upon the first ’ s codes . The coding scheme was fully developed after 40 % . It consisted of the following categories : our 5 collaboration styles ( Figure 47 ) ; gestures ; conversation content ; and miscoordination . Investigating the Role of an Overview Device in Multi - Device Collaboration 201 Results Our study showed that groups with an overview ( INT and WO ) went through multiple iterations of their trip itinerary while iterations were not observed in NO groups . Our findings indicate that overview groups reached decisions more democratically as more opinions were discussed . Displaying the overview on a separate device ( WO ) led to more closely - coupled collaborations and face - to - face interactions . Participants in INT / NO groups spent more time looking at their own devices , and less time in face - to - face interaction . The separate device gave participants a spatially stable anchor point to initiate closely - coupled collaboration and to base their shared interaction around . It provided group members a spatial and contextual focus point to meet other collaborators for discussions and sharing of information about items and the overall progress of their planned trip . In all conditions , we observed territorial behaviour with personal tablets ( Scott , Carpendale , and Inkpen 2004 ) , and pointing to , or touching someone else ’ s device was rare . Table 10 shows a summary of our main findings . Three key themes resulted from our qualitative and quantitative analyses : ( 1 ) information organisation strategies , ( 2 ) applying the overview , and ( 3 ) collaboration styles . 8 . 4 . 1 Theme 1 : Information Organisation Strategies Our first theme describes how groups collect and organise locations to include in their itinerary . 8 . 4 . 1 . 1 . Collecting Locations Each group member was provided with a separate subset of five locations out of the top - 20 attractions in London ( “The Top 10 Things to Do in London 2016 - TripAdvisor” n . d . ) . All ten groups created a subset of locations , as visiting all was not feasible because of the 7 - hour time limit . We observed three approaches in creating subsets of the locations . 1 ) Listing all locations : Four groups ( WO1 , NO1 , NO3 , INT3 — see Table 11 ) shared all the locations with the other group members . Afterwards , participants engaged in group discussions to decide which location should be included in their itinerary . P38 Investigating the Role of an Overview Device in Multi - Device Collaboration 202 suggested this approach explicitly to the group : “Shall we just all add our f ive locations and then see if we can already see where that leads us ? I mean , maybe there ’ s some of them close by [ each other ] ” . 2 ) Filtering locations before sharing : Two groups ( WO4 , INT1 ) spent the first minutes discussing the locations which they would like to include in the trip , without interacting much with the map ( little to no touch activity ) . After this discussion , they then decided on the inclusion of each location in their trip , and only added it to the shared map if they decided to include it . While creating their itinerary , they discussed their decisions in detail , and annotated each location after adding it . P29 described their process : “We started that each of us picked one location [ as a ] recommendation and we talked about it in the group and then decided together [ whether to include it ] . And only then added it to the [ map ] ” . 3 ) Mixed approach : Four groups ( WO2 , WO3 , NO2 , INT2 ) followed a mixed approach of these two strategies . Members first discussed general interests and which locations they had available , while not interacting with the map ( little to no touch activity ) . After several minutes of discussion , they decided to share all 20 locations to identify places in walking - distance to each other or that could be easily visited together . Group Listing all locations Filtering locations Deleting / Clean - up Iteration Identified leader WO1 ( P1 - P4 ) Yes No Yes Yes No WO2 ( P5 - P8 ) Yes Yes No Yes Yes * WO3 ( P9 - P12 ) Yes Yes Yes Yes No WO4 ( P13 - P16 ) No Yes No * * Yes No NO1 ( P17 - P20 ) Yes No No No Yes NO2 ( P21 - P24 ) Yes Yes No No Yes NO3 ( P25 - P28 ) Yes No Some No Yes INT1 ( P29 - P32 ) No Yes No * * Yes No INT2 ( P33 - P36 ) Yes Yes Yes Yes Yes * INT3 ( P37 - P40 ) Yes No Yes Yes No Table 11 . The groups ’ activities . * = These groups ’ leader had an overall less dominant role compared to NO groups . * * = Because the group filtered their locations before sharing them , a cleanup was not needed . Investigating the Role of an Overview Device in Multi - Device Collaboration 203 8 . 4 . 1 . 2 . Organising Locations After sharing locations , groups followed similar approaches to decide which places to include in their itinerary . All groups chose the visiting order based on estimates of shortest walking time , using their prior knowledge of the city or visually estimated walking distances ( all groups were familiar with London ) . E . g . the first location to visit was often the closest to the starting point given by the study facilitator . P32 ( INT1 ) said that the group then “went with the lowest common denominator [ of interests ] ” to decide on places to visit . Number and Timing of Annotating Locations : To finalise their itinerary , groups annotated the visiting order and duration of their locations . We observed greater average numbers of annotations in groups with overview ( INT : M = 21 . 3 , SD = 2 . 5 ; WO : M = 19 . 8 , SD = 6 . 1 ) than in the NO condition ( NO : M = 9 . 0 , SD = 5 . 7 ) — see Table 12 . Groups with an overview ( WO and INT ) tended to annotate their visiting duration and order as they went along , thus they had frequent annotations distributed throughout the session , whereas NO groups only annotated very late towards the end of the session . We suspected that a small number of annotations at a late stage of the process could be an indicator of a better thought through , and thus more stable , decision . Our video recordings however showed that NO groups were discussing their choices and changing their decisions in a similar way as WO and INT groups did , they just did not annotate it on the system . WO and INT groups were testing out different visiting duration and order as they went along . This was due to the overview being updated immediately and thus showing the status of the itinerary . They received immediate feedback on their annotations , enabling immediate evaluation of their decision . This often led to group discussions after new or updated annotations were shown on the overview . Groups without overview kept track of this information either in their head or on paper ( only NO2 used paper ) . For NO groups , there was no benefit to annotating earlier in the process . However , this also resulted in fewer discussions about the consequences of an annotation and once a location was annotated , it was not discussed anymore ( more about iteration in the next section ) . Deleting and Clean - up Activities : Most groups in the WO and INT condition used the delete function to remove markers from the shared map after reaching the group ’ s Investigating the Role of an Overview Device in Multi - Device Collaboration 204 consensus whether they would like to visit the place . Three groups ( WO2 , NO1 , NO2 ) did not delete any locations . WO4 and INT1 did not need to clean up , as they only had shared locations that they wanted to include . NO groups used the delete function only sparingly ( Table 12 ) . Cond . Share Annotate Delete Total WO M = 20 . 8 , SD = 1 . 6 M = 19 . 8 , SD = 6 . 1 M = 9 . 8 , SD = 5 . 8 M = 50 . 3 NO M = 17 . 0 , SD = 5 . 7 M = 9 . 0 , SD = 5 . 7 M = 1 . 3 , SD = 1 . 2 M = 27 . 3 INT M = 18 . 3 , SD = 4 . 5 M = 21 . 3 , SD = 2 . 5 M = 7 . 3 , SD = 4 . 5 M = 47 . 0 Table 12 . Average number of executed commands per group in each condition and average total number of all commands . 8 . 4 . 2 Theme 2 : Applying the Overview The overview allowed WO and INT groups to coordinate times , identify patterns , and gave groups a shared understanding about the current discussion . The overview encouraged these groups to iterate over their plan and refine visiting duration and order to account for more factors , such as opening times and lunch breaks . Displaying the overview on a separate device ( WO ) gave the groups a spatial anchor point to turn to and initiate discussions and collaboration and coordinate their interaction with each other . 8 . 4 . 2 . 1 . Overview to Detect Patterns ( F1 ) Most groups shared all 20 locations ( Table 11 ) and then identified clusters of locations that are within short walking distances of each other . We observed that WO groups discussed whether each cluster should be included in the trip or not , while looking at it together on the shared device . They then decided to visit a subset of places from that cluster . INT and NO groups also employed the clusters to identify locations to be visited . However , the lack of the shared device made it more difficult to coordinate the discussion with group members : they had to verbally communicate what they were looking at , rather than pointing it out on the shared device . NO and INT groups frequently spent time navigating around their maps to coordinate what the group was discussing . Even though INT groups also had an overview integrated on individual devices , participants had to find the location being currently discussed by panning and zooming on their own maps . Only in a few occasions did participants turn their own device around , showing the others what they were looking at . The device was Investigating the Role of an Overview Device in Multi - Device Collaboration 205 then mainly shown to immediate neighbours , resulting in smaller sub - group collaborations . 8 . 4 . 2 . 2 . Overview and Iteration ( F4 ) After groups finished planning their 7 - hour trip , WO1 , INT1 , and INT2 decided to iterate their plan , by one team member explicitly suggesting this iteration phase to identify errors in their annotations ( e . g . ensuring they had planned lunch or to allow enough time for walking ) . Although the other WO and INT groups did not declare an iteration phase , the analysed video and touch data showed that the groups discussed each included location at least twice , showing patterns of iteration . The iteration allowed the groups to identify and correct errors , resulting in a more thoroughly defined and thought - through trip , accounting for more factors . We found that NO groups did not iterate their plan : once groups had decided to include a location in the itinerary , they did not reconsider that decision . This observation was confirmed by the logged interactions with the system : all interactions with a particular location in NO were located around the time of their first annotation . Post - hoc changes to these annotations occurred rarely . 8 . 4 . 2 . 3 . Overview Created a Shared Understanding ( F2 ) We observed that for groups without the overview ( NO ; Table 11 ) a leader often kept an eye on the status and updated the group about progress . If the group did not reach a decision , the leader took charge and decided on the group ’ s behalf . We also observed a leader in INT2 and WO2 , but they were less dominant in this role and eventually these groups came to decisions in a similar way to all other WO and INT groups : by discussing their options and eventually making a group decision about points of interest , visiting duration , and order . 8 . 4 . 3 Theme 3 : Collaboration Styles ( F3 , F5 ) In our analysis , we were interested in what patterns of collaborations participants in the different conditions adapted . We extended and re - appropriated the coupled collaboration styles , previously developed by Tang et al . ( A . Tang et al . 2006 ) and Isenberg et al . ( Isenberg et al . 2012 ) , for a study with groups of four ( rather than paired collaborations ) and for a multi - device scenario . We focus on where attention was Investigating the Role of an Overview Device in Multi - Device Collaboration 206 amongst team members ( e . g . face - to - face or towards their device ’ s ) . Our collaboration styles consist of the following and are depicted in Figure 47 : 1 . Active Discussion ( AD ) . Face - to - face discussions amongst group members . Limited interactions with the system ( e . g . pointing to screens or scrolling ) . 2 . Single - Shared View ( SSV ) . All group members allocate their attention to one single device . 3 . Disjoint and Shared View ( DSV ) . 2 - 3 members focus their attention to a single device while others continue discussions . 4 . Disjoint and Distributed View ( DDV ) . 1 - 2 group members are focusing on their own device , while others continue discussions . 5 . Distributed View ( DV ) . All group members are focusing on their own device . Minimal to no discussions . 8 . 4 . 3 . 1 . Shared Attention Our video data showed a trend for WO to engage in more SSV ( 25 % of their total time ) than NO ( 6 % ) or INT ( 3 % ) ( see Figure 50 ) . In WO groups , we observed that this usually was initiated by a group member looking up from their own device and addressing the group by talking about content on the overview device ( e . g . by pointing to it or verbally referring to it ) . Although no overview device was provided , SSV still occurred in NO and INT groups , usually only with two people sitting next to each other . These SSVs generally occurred when a group member started annotating a location , asking other members for their opinion , and then exchanging small glimpses at each other ’ s tablets . However , occurrences of SSV in NO and INT groups tended to be less likely and shorter , as group members quickly reverted to their own tablet , resulting in DV or DDV . Since NO2 used pen and paper to keep track Figure 47 . Visualisation of the collaboration styles . Investigating the Role of an Overview Device in Multi - Device Collaboration 207 of timings , we observed some occurrences of SSV in this group around the paper . In our study , we observed that SSV led more frequently to active discussion ( AD ) , without groups focusing on a device anymore . This mainly occurred when SSV was initiated by a group member raising a concern or asking a question . Participants then used the shared device to find common ground for their discussion . If the information on the device was then not needed anymore , they continued their discussion ( Figure 48 ) . Figure 48 . Shared attention on the overview device ( SSV ; left ) often led to active discussion ( AD ; right ) as the device gave the group a common focus and starting point for a discussion . 8 . 4 . 3 . 2 . Pointing Our study indicates that pointing gesture could trigger shared attention . We observed fewer occurrences of pointing in NO and INT groups ( M = 7 . 88 / group in WO ; M = 2 . 7 for NO ; M = 3 . 3 for INT ) . Members in WO group tended to point towards the overview device , which resulted in other members engaging in SSV or DSV . For instance , P8 in Figure 49 ( left ) points to the overview , prompting other members to move their attention towards the overview and start discussions about lunch . Figure 49 ( right ) shows how P29 pointed at her screen to discuss a location . Another participant briefly looked at the screen but quickly shifted her attention back to her own tablet . Other participants did not notice , as they were focussing on their own screens . In general , we observed that the overview device led to more shared attention and closely - coupled discussions by giving participants a shared focus space . Investigating the Role of an Overview Device in Multi - Device Collaboration 208 Figure 49 . Left : P8 ( WO2 ) points toward overview device , other members shifted their attention to it . In NO groups pointing rarely led to shared attention ( right ) : P29 ( INT1 ) points toward her device ; other members ’ focus stays on own devices . 8 . 4 . 3 . 3 . Distributed Attention For groups without the separate device we observed that they spent more than half their time looking at their own devices ( DDV + DV ; NO : 57 % ; INT : 60 % ; in contrast WO : 27 % ) . The data logs showed higher average touch activity per minute for groups without an overview device ( NO : 424 / minute ; INT : 226 / minute ) than in WO groups ( 135 / minute ) . As a reminder : higher values for touch activity indicated more user - device interactions . When we analysed our video data , we noticed that NO / INT group members , who engaged in DV or DDV , were more likely to pan and zoom on their map to follow what other members were discussing . This aligns with the observation that NO groups were interacting more with their individual tablets . However , the increased touch activity in NO groups does not necessarily imply greater number of commands ( share , annotate , delete ) executed : WO and INT groups executed more commands on average per group ( WO : M = 50 . 3 commands / group ; INT : M = 47 . 0 ) , compared to NO groups ( M = 27 . 3 ) ( Table 12 ) . 8 . 4 . 3 . 4 . Active Discussions Active discussions ( AD ) were present in all groups . We observed that WO groups not only initiated more AD on average per group ( WO : M = 13 . 0 , SD = 3 . 24 ; NO : M = 10 . 7 , SD = 3 . 09 ; INT : M = 11 . 0 , SD = 2 . 94 ; Figure 50 ) , they also engaged in longer discussions ( M = 30 seconds , SD = 10s ) compared with NO ( M = 20s , SD = 4s ) and INT ( M = 24s , SD = 4s ) . The content of conversations in NO groups mostly consisted of a participant asking a question to confirm key facts or inquire about information , while other group Investigating the Role of an Overview Device in Multi - Device Collaboration 209 members gave brief and passive responses . Longer discussions were focused around facts about locations someone was sharing or personal interests of group members . For example , in one instance of AD ( WO1 , duration 41s ) , P4 asked his collaborators for more information about what Horse Guards Parade is . The same question was also raised in NO1 . However , in NO1 the AD ended quickly and turned into a DV , when the other members focused on their own devices trying to locate it . Ultimately , while doing so , one group member got side - tracked and asked a question about a different location . Figure 50 . Percentage of time spent in the different kinds of collaboration , by condition . We observed that the presence of the overview device gave group members the opportunity to direct their attention to a shared space . Though discussions may not involve face - to - face interactions , group members still shared their attention onto the overview device and engaged in discussions centred on the same topic . 8 . 4 . 4 Territorial Behaviour ( F6 ) In all groups , personal devices were shown to other people but there was never shared access to individuals ’ devices . All participants respected that others ’ devices were usually not for them to interact with . They rarely touched and interacted with someone else ’ s device and if so , only after explicit consent . Although in two groups Investigating the Role of an Overview Device in Multi - Device Collaboration 210 the overview device was picked up by participants ( WO3 and WO4 ) , this was only brief and the device was placed back into the shared space soon after . User Feedback Participants learned how to use the system well within the training phase . The shared itinerary helped to keep track of what other group members were doing . P29 stated that she “liked that [ she ] could see on [ her ] iPad what other people [ did ] ” and P31 said the shared collective itinerary was “ useful for tracking what others are doing ” . In WO conditions , participants appreciated the overview device as useful for the group ’ s discussion ( e . g . P8 and P2 ) . P5 stated that the “two screens were good . So , you have on one side the search [ … ] and on the other the overview” , and further she “only used [ her ] own tablet when searching for a location . [ When ] discussing something [ she ] always used the overview” . INT groups were presented with the same information on their own device , as WO groups on the separate device . P33 ( INT2 ) said that it “would have been great to have the overview constantly on for example this TV here ( points to TV ) . So , you see immediately the bigger picture and don ’t have to zoom around [ on your own tablet ] ” . However , some issues arose through positioning , as P8 ( WO2 ) reported : “For me [ the overview device ] was upside down . [ I got ] at least an idea , but could not read anything” . Some participants asked for more information on who shared or annotated a location . For example , P31 said “ when someone edited something you don ’ t know who ’ s doing it . So , if there ’ s like a bubble saying who did it would be good” . On the contrary , P16 stated , that he “like [ d ] that you don’ t see what someone else did . So , you can ’t be put on the spot” . Investigating the Role of an Overview Device in Multi - Device Collaboration 211 Participants in the NO groups reported that they were missing a time - keeping feature and an easily visible summary of the visiting order or path — both components of the overview . The post study questionnaire showed slightly higher responses to the question ‘ how mentally demanding was the task ’ for the NO condition ( Figure 51 , mental demand ; NO : Median ( Md ) = 5 , interquartile range ( iqr ) = 3 ; INT : Md = 4 , iqr = 3 ; WO : Md = 4 , iqr = 2 . 5 ) . However , although this difference is only very small , our analysed video data indicated that this might have resulted from the NO groups having to keep track of the overview ’ s information either in their head or on paper . Discussion Previous research around tabletops has shown many benefits for collaborative decision - and sensemaking activities , such as shared understanding ( J . R . Wallace , Scott , and MacGregor 2013 ; Hilliges et al . 2007 ) , mutual awareness ( Isenberg et al . 2012 ) , more closely - coupled collaboration and , thus , more sharing of information and discussions ( Hansen and Järvelin 2005 ; Isenberg et al . 2012 ) . However , we increasingly encounter multi - user and multi - device scenarios , and research is shifting towards supporting such scenarios . Using individual devices has shown to negatively Figure 51 . Results of answers to the post - study questionnaire , rating mental demand , temporal demand , effort , and frustration for groups without overview ( NO ) , overview displayed on everyone’s device ( INT ) , and overview on separate device ( WO ) . Likert scales from 1 ( very low ) to 10 ( very high ) . Investigating the Role of an Overview Device in Multi - Device Collaboration 212 affect communication and engagement ( Haber , Nacenta , and Carpendale 2014 ) and people are hesitant to use multiple tablet devices in parallel ( Plank et al . 2017 ) . Guided by the question of how we can support ad hoc decision - and sensemaking with a shared space , our study explored practices of using additional devices as a shared and flexible overview device in a collaborative collocated trip planning task . The results indicate that adding an overview with a summary of the trip itinerary facilitated sense - and decision - making . Similar to previous work around tabletop displays e . g . ( Hansen and Järvelin 2005 ; Isenberg et al . 2012 ; J . R . Wallace , Scott , and MacGregor 2013 ) ) , we observed that groups with a shared overview tended to be more effective in their decision - and sensemaking . We observed that groups with a shared device worked in more closely - coupled collaborations , leading to more active discussions . These discussions were important for groups in their trip planning activity ( similar to ( DiMicco , Pandolfo , and Bender 2004 ; Stewart and Stasser 1998 ) ) . The overview tablet in our study was more successful compared to a previous study ( Plank et al . 2017 ) , likely because their study comprised only of dyads where everything a participant said was directed to the other . We observed however , that verbal discussions were not always directed to specific individuals , meaning some context could be lost . Similar to previous work we found that a shared display supported groups ’ synchronization through explicit and implicit gestures , spatial awareness of activities ( J . R . Wallace et al . 2011 ) , as well as activity awareness ( Carroll et al . 2003 ) . 8 . 6 . 1 Space and Focus As a shared device that every member could engage with equally , we observed that the overview device ( WO ) was used as a spatial focus point : whenever someone initiated a discussion around a location , they could point to that location on the shared device , automatically shifting the group ’ s attention towards the device through a clearly visible gesture . When pointing to one ’ s own device ( especially in NO and INT groups ) , drawing attention from other group members proved difficult , as they were engaged with their own device . Interacting with , or pointing towards someone else ’ s device was rare and short - lived . Although in INT , some screen space was covered by the overview , participants did not comment negatively on lack of space for the Investigating the Role of an Overview Device in Multi - Device Collaboration 213 “primary” interaction , nor could we observe any change d behaviour as a result of the covered space . We observed that WO groups spent more time in discussions which were also more frequent . Groups without a separate device ( NO , INT ) focused more and for longer periods on their own devices . As group members were focused on their own screens , eye contact was less likely to develop , which discouraged potential active discussions and led to comments being ignored by the group . These findings , using mobile devices , are in line with previous findings around fixed tabletop displays , where groups were working in tighter coupled collaboration when working closely together ( A . Tang et al . 2006 ) . Interestingly , only two of the WO groups moved the overview device ( WO3 , WO4 ) , while the other groups treated it like a fixed display . In those groups that moved the overview device , we observed more spatial movement as participants were shifting on their chairs or standing up to have a better view ( similar to as observed previously ( Plank et al . 2017 ) ) . This spatial movement also seemed to contribute to more closely coupled collaborations as participants used the movement to point out locations on the shared device and initiate a discussion . Whether the more closely - coupled discussions were a result of the movement , or the movement was a result of more closely - coupled collaboration , needs further investigation . The overview device also functioned as a contextual focus point , by providing a shared space to initiate discussions about displayed information . Previous work around tabletop displays found that collaborators prefer common , global views when in tighter coupled collaboration ( A . Tang et al . 2006 ) . In our study , several discussions that started about items on the overview device turned into face - to - face conversations . WO groups ’ discussions tended to be more fruitful , communicating relationships between locations and personal preferences , and participants considered more factors such as opening times and lunch breaks . In contrast , we observed more distributed attention and short - lived conversations in NO and INT groups . Although we observed shared views in all groups , this mostly meant shared viewing of someone ’ s device . Participants only rarely shared access to devices . Since all information Investigating the Role of an Overview Device in Multi - Device Collaboration 214 was shared with everyone else we expected participants in INT to more freely share their devices . However , similarly to prior work around tabletop displays ( Scott , Carpendale , and Inkpen 2004 ) , we observed that participants in a multi - device collaboration respected each other ’ s territory and rarely interacted with someone else ’ s device ( and only after explicit invitation ) . 8 . 6 . 2 Decision - Making and Sensemaking A decision - making task is strongly influenced by people ’ s opinions ( DiMicco , Pandolfo , and Bender 2004 ) , and therefore it is one important goal that group members have equal opportunities to share their thoughts and express their opinions . Through video analysis and the exit interviews we found that providing groups with an overview builds a shared understanding for group members and resulted in a more democratic decision - making . In WO and INT , members had equal access to the same information , and we observed that groups shared more opinions and made decisions where everyone ’ s voice had been heard . Neither NO group iteratively created their agenda . Giving groups an overview ( WO , INT ) we noticed iterations of the itinerary after groups finished a first draft . We observed that in WO groups , members collaboratively looked at the shared device , which in return led to more insights and ideas through discussion . This iterative process ( i . e . ( Pirolli and Card 2005 ) ) tended to lead to more refined decisions and finding and correcting of mistakes ( e . g . missing lunch breaks or travel times ) . 8 . 6 . 3 Limitations and Future Work Voyageur was implemented for a simple collaborative trip planning task . We are currently extending our research to other areas of knowledge work , such as curation works ( e . g . Chapter 5 ) . The current design requires participants to explicitly share their locations with the rest of the group . Previous research ( Goyal et al . 2014 ; Isenberg et al . 2012 ) suggested that implicit sharing of information is beneficial for collaborative analysis . It will be interesting to understand how translucence ( Goyal and Fussell 2016 ) and feedforward ( Vermeulen et al . 2013 ) influence coordination and performance . Investigating the Role of an Overview Device in Multi - Device Collaboration 215 People now own multiple touch enabled devices , as our questionnaire data showed ( M = 1 . 9 ; SD 0 . 7 ) . Voyageur requires adding one more device than people to a configuration , resulting in the need for additional hardware and potentially added cost . While other devices such as smartphones or laptops could also be used to display the overview , it remains for future work to investigate how other form factors influence a group ’ s collaboration practices . Having an additional device might also limit the number of people collaborating , as issues such as reach and occlusion might arise . We conducted our study as a between - subject design , to avoid bias through carry - over effects ( Greenwald 1976 ) , minimise range effects ( Greenwald 1976 ) , avoid experimenter demand effects ( Charness , Gneezy , and Kuhn 2012 ; Greenwald 1976 ) , and avoid fatigue of participants . Conducting this study in a within - subject design is a possible alternative setup , but would require several changes in the study setup . First , a new set of locations has to be provided for every condition to avoid carry - over and range effects , though carefully chosen to have similar spatial and contextual properties to be able to observe equal secondary effects ( e . g . cluster pattern detection and discussions about walking distance ) . Second , adding or removing a single aspect of the study ( in our case the overview ) would draw attention to this and might result in participants adapting their behaviour ( Charness , Gneezy , and Kuhn 2012 ; Greenwald 1976 ) . This requires careful consideration , not only through counterbalancing , but potentially through a ‘ decoy condition / item / task ’ . Third , the overall length of the task needs to be monitored . Since our interest was in the qualitative insights in groups ’ practices , the length of discussions and groups ’ sensemaking and decision - making processes are difficult to control . Conclusion In summary , with our study we found trends that the overview allowed users to detect patterns of locations ( F1 ) , led to consideration of more factors through a shared understanding ( F2 ) , and eventually allowed groups to iterate their itinerary ( F4 ) . Displaying the overview on a separate device encouraged more closely - coupled collaborations ( F5 ) which resulted in sharing of more information and more active discussions . This in return led to a more democratic decision - making process ( F3 ) . Investigating the Role of an Overview Device in Multi - Device Collaboration 216 While we observed territorial behaviour with personal devices ( F6 ) , the overview device acted as a spatial and contextual focus point for collaborators to initiate discussions ( F5 ) and focus their attention , and aided groups in mediating their collaboration . Many previous works have proposed cross - device and multi - device interactions and systems for collaborative works , but only few have been studied in everyday practices . While our study was conducted in the lab and with the focus on a specific activity — collaborative trip planning — we believe that the insights show merits for real - world collaborative multi - device settings . We showed how changing device configuration benefits groups ’ exchange of information and their collaboration during their sensemaking and decision - making activity . This is promising for future work on deploying multi - device systems in everyday situations . While the study we conducted gave insights into how we can design systems to foster more closely - coupled collaborations , it also showcased that the interaction analysis for the purpose of finding insights into the study is cumbersome and takes up many hours of work . Especially with multiple participants as well as multiple devices , the reviewing and analysis of the recorded interactions took a multitude of of the recorded time . In the next chapter , we present a system that helps researchers in conducting such interaction analysis by providing real - time and overview visualisations as well as a search functionality for key moments of interactions . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 217 Chapter 9 . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions of People and Devices 17 To study and understand group collaborations involving multiple handheld devices and large interactive displays , researchers frequently analyse video recordings of interaction studies to interpret people ’ s interactions with each other and / or devices . Advances in ubicomp technologies allow researchers to record spatial information through sensors in addition to video material . However , the volume of video data and high number of coding parameters involved in such an interaction analysis makes this a time - consuming and labour - intensive process . We designed EagleView , which provides analysts with real - time visualisations during playback of videos and an accompanying data - stream of tracked interactions . Real - time visualisations take into account key proxemic dimensions , such as distance and orientation . Overview 17 Parts of this chapter have been published previously in : Frederik Brudy , Suppachai Suwanwa tcharachat , Wenyu Zhang , Steven Houben , and Nicolai Marquardt . 2018 . “EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions of People and Devices . ” In Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces , 61 – 72 . ISS ’18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3279778 . 3279795 . Suppachai Suwanwatcharachat and Wenyu Zhang implemented parts of the EagleView system as part of their MSc dissertation projects . I acted as supervisor to their work , advised on direction of the project , and implemented significant parts of the system . Both MSc students conducted an evaluation of separate aspects of the system , which have been omitted from this chapter but can be found in the ISS’18 paper listed above . I lead the write - up of the ISS’18 paper , including additional data analysis of the study data ( not reported on here ) . Steven Houben and Nicolai Marquardt were advisors on the project . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 218 visualisations show people ’ s position and movement over longer periods of time . EagleView also allows the user to query people ’ s interactions with an easy - to - use visual interface . Results are highlighted on the video player ’ s timeline , enabling quick review of relevant instances . Interaction Analysis in Ubicomp To understand and evaluate interactive systems , researchers often use video analysis of individual or collaborative interactions of people and the devices they use ( e . g . ( Isenberg et al . 2012 ; Jakobsen and Hornbæk 2014 ; Scott , Carpendale , and Inkpen 2004 ) ) . The analysis of the recorded video data is a tedious and labour - intensive task , requiring researchers to review the raw video iteratively and identify relevant tags and codes in the footage ( Jordan and Henderson 1995 ) . While various commercial and research tools exist to support the viewing and tagging of videos ( e . g . ( Nvivo 2017 ; “ATLAS . ti” 2017 ; Fouse et al . 2011 ) ) , these mostly focus on facilitating the navigation , transcription , and annotation of videos , not the actual interaction analysis . However , spatial characteristics of group interactions are important for such analysis , including where people stand , how close they are to each other , which devices they use , and so on . These features need to be manually observed and annotated by the researcher , as current tools do not support the analysis of spatial characteristics well . Figure 52 . EagleView workflow with querying and visualisation techniques facilitating spatial interaction analysis . Recent ubiquitous computing ( ubicomp ) environments enable recording of proxemic and spatial interaction data , such as people ’ s location and orientation , as well as the devices they interact with ( for example with the open - source ProximityToolkit ( Marquardt , Diaz - Marino , et al . 2011 ) or EagleSense ( C . - J . Wu , Houben , and EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 219 Marquardt 2017 ) platforms ) and their activities ( e . g . holding phone , standing , sitting ) . While recording this additional data during studies allows for deeper insights into the interactions , the analysis still needs to be done manually as there are currently only very few tools that allow for automated insights into participants ’ interaction with their devices , each other , and their surroundings ( e . g . ( Marquardt , Schardong , and Tang 2015 ; von Zadow and Dachselt 2017 ; A . Tang et al . 2010 ) ) . Inductive video analysis has become the main pathway to gain insights of recorded interactions ( Jordan and Henderson 1995 ) . However , thorough video coding remains a challenging task , in particular once multiple people and multiple devices are involved : rather than being able to focus on one user ’ s interaction with one system , an analyst has to study many relations between multiple users and devices . Using sensor - data can help to find moments of interest in video data , but more detailed manual analysis is still needed , as relying solely on sensor data can lead to false conclusions . To better support spatial interaction analysis , we contribute EagleView ( Figure 52 ) , a novel video analysis tool that allows expert users ( researchers , conducting analysis in multi - user , multi - device scenarios ) to review and analyse multiple videos and an accompanying spatial tracking data - stream by providing a querying interface , real - time visualisations , and multiple overview visualisations of the interactions through a web - based interface . EagleView allows users to create new queries on the videos and tracking data through an easy - to - use direct - manipulation visual - query interface . Examples of such queries are “ when are participants closer than 1 metre ” , “ when is a person facing the screen ” , or “ when are people pointing at the large displa y” . In summary , the contributions of this chapter are the design and techniques of the EagleView query tool as well as the real - time and overview visualisations . EagleView is available as open - source software at https : / / github . com / frederikbrudy / eagleview . The original ISS ’ 18 paper additionally contributed insights gained from expert users through two user studies , exploring two different aspects of EagleView ( real - time and aggregated overview visualisations and the querying tool ) . These have been omitted from this thesis as they were conducted as part of two MSc thesis projects . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 220 Prior Work on Interaction Analysis The work in this chapter builds on the foundations of previous work on ( i ) interaction analysis ; ( ii ) systems supporting interaction analysis ; and ( iii ) video analysis and visualisation tools . General prior multi - and cross - device work has been covered in Chapter 3 and Chapter 4 . 9 . 2 . 1 Interaction Analysis Interaction analysis ( Jordan and Henderson 1995 ) describes the empirical lens through which researchers analyse how people interact with each other and their surroundings . Increasingly , social science and psychology theories are used as lenses for conducting interaction analysis . For example , Hall ’ s theory of proxemics ( Hall 1969 ) describes how people physically engage and communicate with other people and the devices in their surroundings through their use of distance ( intimate , personal , social , and public ) , orientation , and posture . Kendon ’ s F - formations describe how multiple people use and share a physical space through their distance and relative body orientation to indicate when and how they interact as a group ( in a circular , vis - à - vis , L - , or side - by - side arrangement ) . Both concepts have been used in ubiquitous computing as a lens for interaction analysis , for example to discover patterns of collaboration in a tourist information centre ( Marshall , Rogers , and Pantidi 2011 ) or museum ( Davis et al . 2015 ) ; to support large display interactions ( e . g . ( Ju , Lee , and Klemmer 2008 ; Vogel and Balakrishnan 2004 ) ) ; and to enable cross - device interactions in multi - device scenarios ( e . g . ( Marquardt , Hinckley , and Greenberg 2012 ) ) . The current state of the art in interaction analysis is through iterative coding of observations in video recordings . Such video recordings of studies or experiments support repeated observations to gain an in - depth understanding of a scenario ( Jordan and Henderson 1995 ) . However , the analysis of those recordings requires many hours of reviewing video data . 9 . 2 . 2 Systems Supporting Interaction Analysis To facilitate the analysis of interactions using video recordings a multitude of tools have been developed , which allow users to review and annotate videos ( Dasiopoulou et al . 2011 ) , and several commercial ( e . g . ( Nvivo 2017 ; “ATLAS . ti” 2017 ) ) as well as EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 221 research tools ( e . g . ( Burr 2006 ; Hagedorn , Hailpern , and Karahalios 2008 ; Fouse et al . 2011 ; A . Tang et al . 2010 ) ) aim to support video analysis . Advances in ubicomp systems allow users to record more information besides the video data , such as proxemic and spatial interaction data through sensors . For example , the ProximityToolkit ( Marquardt , Diaz - Marino , et al . 2011 ) uses infrared cameras and visual markers attached to record people ’ s and devices ’ identity , location , and orientation . More recently , markerless top - down tracking systems have been introduced , tracking people ’ s identity , position and orientation ( e . g . ( Lin et al . 2015 ; Marquardt , Hinckley , and Greenberg 2012 ) ) , posture ( e . g . ( N . Hu , Englebienne , and Kröse 2013 ) ) , as well as their activity ( e . g . ( Wilson and Benko 2010 ; C . - J . Wu , Houben , and Marquardt 2017 ; G . Hu et al . 2014 ) ) . These systems show that there is an increasing supply of systems not only tracking people and their devices , but also recognising what they are doing ( e . g . holding a paper , pointing , using a tablet , or smartphone ) . As an example , we record the tracking data from EagleSense ( C . - J . Wu , Houben , and Marquardt 2017 ) , which uses a Kinect v2 camera mounted to the ceiling to capture the space underneath it , recording people ’ s position , orientation , and their activity ( e . g . standing , holding phone ) . Several tools aiming to support the analysis of these multi - stream recordings have been developed . For example , VACA ( Burr 2006 ) allows a synchronised playback of video data with accompanying sensor data . The sensor data can then be used as an additional cue for finding the relevant parts of the video . Similarly , VCode and VData ( Hagedorn , Hailpern , and Karahalios 2008 ) enable synchronised playback and annotation using sensor data and video recordings . ChronoViz ( Fouse et al . 2011 ) enables synchronised playback of multiple video and data streams , allowing analysts to add annotations in form of tags and textual descriptions . While previous work proposed to use crowd workers to annotate [ 30 ] or enable natural language querying [ 16 ] on video material , this is cost - intensive and might compromise privacy . EXCITE [ 21 ] , on the other hand , enabled researchers to conduct search - queries on the recorded video + sensor data of interactions in ubiquitous computing environments , using a descriptive query language . This allowed researchers to gain insights that were not as easily attainable before . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 222 Our work builds on this prior work of tools that support interaction analysis , in that we allow analysts to review video data , combined with tracking information about people ’ s position , orientation , and activity . EagleView further allows analysts to visually create queries on the video + sensor data , and then navigate between search results for further review . Similar to EXCITE ( Marquardt , Schardong , and Tang 2015 ) , EagleView allows analysts to analyse group interactions involving the use of mobile as well as fixed devices , enabling analysts to focus on high - level analysis of the interactions , rather than focussing on finding low - level evidence for a hypothesis . 9 . 2 . 3 Visualisation Tools for Video Analysis Other specialised tools support researchers in visualising video recordings of multi - device and / or multi - person interaction scenarios . For example , VICPAM ( Moghaddam and Bailey 2011 ) shows users ’ activities over time and the duration of each activity on an overview timeline . VisTACO ( A . Tang et al . 2010 ) focussed on analysing spatial interactions around a tabletop display and GIAnT ( von Zadow and Dachselt 2017 ) enabled users to analyse and visualise interactions of people with a large , interactive wall display . We build on and extend previous work with our real - time and overview visualisations . Similarly to slit - tears ( A . Tang , Greenberg , and Fels 2008 ) , EagleView helps the researcher by summarising a longer period of time in a static overview visualisation in addition to real - time visualisations during playback . In particular , we use the five proxemic dimensions ( Greenberg et al . 2011 ) ( distance , orientation , movement , identity , location ) to create visualisations about individual people and objects . We further leverage the notion of F - formations ( Kendon 2010 ; Marquardt , Hinckley , and Greenberg 2012 ) of people and devices , enabling analysts to identify critical moments of interactions . Scenario Description Throughout this chapter we will refer to the following scenario about the analysis of a multi - device multi - user interaction in a museum . This scenario helps us to better EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 223 situate our tools and techniques that we introduce shortly within the context they will be used . Mary is developing a new application for a museum , which allows visitors to explore details about each exhibit through an interactive display next to each item . While visitors roam the museum and interact with various touch displays , they can also navigate the collection on their own smartphone through the museum ’ s app and website . After deploying the system , Mary wants to learn more about how people approach the exhibit ’ s displays and use them together with their personal devices . She installs a Kinect camera in the ceiling above the interactive exhibits , as well as 3 cameras to record the interactions from a side perspective . She records an entire day in the museum through EagleSense ( C . - J . Wu , Houben , and Marquardt 2017 ) , which uses a ceiling - mounted Kinect camera to track visitors in a gallery and their activity . At the end of the day she has 10 hours of footage from each camera , totalling 40 hours of video material she needs to analyse . The museum was well attended on that day , but not everyone approached or interacted with the exhibits and / or their smartphone . EagleView Overview EagleView is a web - based video analysis tool that allows users to explore people ’ s spatial interactions using visual analysis of recorded video data together with automatically tracked spatial measures ( location and distance of people and devices ; their orientation ; movement ; identity ; activity ; recorded with EagleSense ( C . - J . Wu , Houben , and Marquardt 2017 ) or similar tools , e . g . ( Marquardt , Diaz - Marino , et al . 2011 ) ) . The user interface consists of the following elements as shown in Figure 53 : all parallel video playbacks on the left ( Figure 53b ) ; real - time visualisation interface in the middle ( Figure 53c , 2d ) ; overview visualisations on the right ( Figure 53e , f , g ) ; video timeline with manual annotations and tags ( Figure 53h ) and query results timeline ( Figure 53i ) at the bottom . Through a tabbed interface at the top ( Figure 53a ) , a user can switch from the Visualisation interface to the Query Creator interface ( Figure 53d , introduced later ) . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 224 Figure 53 . EagleView ’ s user interface , showing the visualization panel with real - time visualizations , playback control , and different angled videos . On the right the analyst can change preferences and switch to a view , showing aggregated data . Getting started . To begin the analysis , a person first selects one or multiple video files from the recorded study and the accompanying spatial tracking data file ( in our case recorded by the EagleSense tracking framework ( C . - J . Wu , Houben , and Marquardt 2017 ) , but potentially provided by other tracking systems ) . In this configuration step , the user can also create objects that are fixed in the environment ( e . g . displays or tables ) by drawing them on a still image of the top - down video recording and adding a descriptive label . Further , an offset can be configured for each video to synchronise start times . All video playbacks are displayed in the top half of the interface ( Figure 53b ) , are time - synchronised , and can be started and stopped using the video controls . A progress bar shows the playback progress and allows analysts to go forward or back in the video . The first view a user is presented with shows the real - time and overview visualisations ( Figure 53c and d ) . EagleView includes features similar to current video analysis tools : users can add annotations to a timeline either by clicking on pre - defined tags ( configurable in the configuration step ) or by entering comments in a text area , and each of the annotations is then shown in a timeline ( Figure 53h ) . By clicking an annotation , analysts can jump to that moment in the video . Beyond conventional video analysis through reviewing and tagging , EagleView allows analysts to review the video by creating search - queries ( section 9 . 7 ) based on spatial EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 225 features and gain insights into user interactions through real - time and overview visualisations . We will describe both key functions in more detail after the technical details . Figure 54 shows the stages of interaction analysis supported by EagleView . Figure 54 . Timeline with an overview of how the different components of EagleView support the video analysis workflow . The modularity and flexibility of EagleView ’ s tools allows analysts to use our visualisations and / or querying functions in any possible order . Technical Implementation EagleView is built using modern web technology ( HTML5 , JavaScript , CSS ) and runs entirely on a client ’ s device ( tested in Chrome 67 ) . We use CreateJS 18 for easy HTML5 Canvas manipulation and Vis . js 19 for the timeline component . To visualise the spatial properties and interactions , EagleView consumes spatial tracking data recorded with the top - down tracking system EagleSense ( C . - J . Wu , Houben , and Marquardt 2017 ) , through its API . Specifically we record an array of time instances , each including a timestamp and people ’ s location , orientation , and whether they are sitting , standing , and if they are holding a paper , a tablet , or a phone ( as an array of skeletons , with properties { id , activity , activity _ tracked , head { x , y , z , orientation ] ] ) in a JSON file . As EagleView is impartial to the tracking technology used , other input sources can be used if the recorded data is in the same format . 18 https : / / www . createjs . com / 19 http : / / visjs . org / EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 226 Further , EagleView displays one or multiple video recordings . In Figure 53 , two top - down recordings ( an RGB video as well as the depth video , captured with the Kinect v2 used by EagleSense ( C . - J . Wu , Houben , and Marquardt 2017 ) ) , as well as two different side - views are shown . The main video view displays the top - down RGB video as a semi - transparent video ( if toggled on ) . The videos ’ playback is synchronised based on their timestamp . Limits . EagleView is running entirely on a user ’ s local machine and web browser , and no data is sent to any remote server . As a result , loading time of a dataset is kept to a minimum of only a few seconds and any video format can be used that is supported by the user ’ s browser . However , since computation entirely happens client - side , a more resourceful computer is required . In our experience , a limit of 3 - 5 videos playing in parallel is easily achievable on any current laptop . For our demo purposes ( as well as the studies , reported on in the original ISS ’ 18 paper ) , we manually cleaned the JSON data after recording the tracking information from EagleSense ( C . - J . Wu , Houben , and Marquardt 2017 ) , to remove any tracking errors ( e . g . removing false activities or sudden jumps of location ) . We did this because we were interested in how , in an ideal case , spatial data can be analysed . We envision that these tracking artefacts of third - party systems will become rarer with better tracking systems in the future and therefore continued to use data without these artefacts . We limited the data saved from the EagleSense API to 4 frames per second . In our experience this was a reasonable trade - off between clean - up time required and still having detailed data . Real - time and Overview Visualisations First , we focus on how researchers can analyse recorded interactions through two different types of visualisations : real - time and aggregated overview visualisations ( Figure 54B ) . 9 . 6 . 1 Real - Time Visualisation The real - time visualisations are shown in the middle column on the tab Visualisations ( Figure 59 ) during video playback and visualise the data around the current playback EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 227 time . They show the spatial properties recorded from the EagleSense API ( people ’ s location , orientation , and activity ) as well as fixed objects ( such as wall displays , whiteboards , or tabletop displays as defined by the user in the configuration phase ) . The video , recorded from the top - down camera , can be optionally displayed in the background . People ’ s locations are displayed as two ovals , representing head and shoulders ( Figure 55 ) . Their viewing direction is indicated by two lines , marking their field of view . ( The angle is configurable by the user . ) If any activity is recorded for them , the respective activity is visualised through an icon in their field of view ( e . g . phone , tablet , paper ) . Each person ’ s identity ( as ID number ) is displayed alongside their location . Fixed objects are drawn as outlines in their locations on the top - down view with their descriptor . Figure 55 . The distance circle ( set to 0 . 5m ) and lines between P1 and P2 as well as the display are visible . In addition , EagleView visualises the following information in the real - time visualisation : Distance : As shown in Figure 55 , analysts can choose to show a circle around a person to indicate proxemic distances ( e . g . personal or social zones ( Hall 1969 ) ) . In addition , distances between different entities ( e . g . two people or a person and an object ) can be shown as a line between them . The distance , as well as the textual description of the proxemic zones ( Hall 1969 ) , is shown underneath the line . Movement trajectories : people ’ s past and future movement trajectories can be displayed as coloured lines ( Figure 56 ) , fading to more transparency the further in the past or future the respective locations are . The length of time used for these EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 228 trajectories is configurable by the user , as well as the colour for past and future movements . Figure 56 . The person ’ s movement of the previous 10 ( blue ) and next 15 seconds ( red ) is shown . Zones : During the setup phase , analysts can define rectangular zones of interest . When a tracked person enters a zone , the zone will be highlighted ( bold border and opaquer colour ; Figure 57 ) . This allows users to quickly skim the video and easily spot when a person enters a particular area . Figure 57 : Defined zones to observe ( red / green rectangles are defined areas ) . Attention grouping ( Figure 58 and Figure 59 ) : EagleView highlights tracked users in the same colour if i ) they directly face a fixed object ; ii ) their attention is focused on each other ; or iii ) if two people stand next to each other and they are facing the same fixed object . Figure 58 : Person on the right is highlighted ( e . g . when facing an observed object , or another person ) . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 229 Figure 59 . EagleView supports different conditions for attention grouping : a person facing a fixed object , two people facing each other , or when two people face the same fixed object . In the scenario : Mary needs to analyse the video recordings of her deployment in the museum . She loads the video footage of the four cameras , as well as the recorded tracking data into EagleView . During the configuration she marks the interactive screens ’ locations by drawing rectangles on a still video frame and saving each as a fixed entity . She switches to the “Visualisation” tab and plays the videos while watching the real - time visualisation in the centre . She activates the movement trajectories to know where the visitors are about to move so she can appropriately switch her attention to the according sideview camera on the left . The attention grouping highlights the tracked entities in the same colour whenever one of the three conditions is met ( Figure 59 ) . As a result , Mary can quickly notice instances where visitors are looking at an interactive screen or are talking to each other ( as they change colour whenever a condition is met ) . When she finds an interesting interaction , she uses her pre - defined tags ( configured during the configuration phase ) to quickly tag those moments for later review . She can switch the background image of the top - down camera in the real - time visualisation on and off if she needs more clarity or wants to check for tracking errors . 9 . 6 . 2 Aggregated Overview Visualisation Aggregated overview visualisations show a summary of people ’ s location over time ( Figure 53e , f , g ) . They are shown in the tab Summary View in the right column . Analysts can choose the time interval for which they want to show aggregated EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 230 overviews through two sliders at the top . Each tracked user is shown in an individual visualisation . We implemented two visualisations : heatmap , showing where users were most active ( Figure 53f ) and movement trajectories , showing a user ’ s movement path ( Figure 53g ) . In the scenario : Mary wants to know what path one particular active visitor took through the exhibition . She switches to the overview visualisation of the movement trajectories of this visitor . She narrows the time visualised down to the duration of his visit , allowing her to get an overall picture of that visitor ’ s movement throughout the museum . She realises that he frequently walked around each interactive display but moved less around non - interactive exhibits . Through the heatmap visualisation , she can confirm her observation : the visitor has spent most of his time around the displays . She compares his heatmap with those of other visitors , by overlaying them on top of each other in the real - time visualisation view . She realises that all visitors spent most of their time around interactive exhibits and very little around non - interactive ones . Something worth investigating ! EagleView Search - Queries Once a researcher has gained a ( basic ) understanding about the interactions in the recorded sequence , they can analyse the recorded interaction sequence by means of spatial queries based on people ’ s distance , orientation , location , and activity within the captured tracking data ( Figure 54C ) . 9 . 7 . 1 Search - Queries Search - queries can be created through a graphical interface on a still - frame whenever the video is paused . Such a query constrains the search within the recorded spatial tracking data to only the events that fulfil the criteria defined in the query , and allows researchers to find all relevant instances in the ( possibly large ) video dataset that meet these conditions . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 231 New queries can be created by selecting one of the properties ( Figure 60 . 1 ) and then adjusting the parameters on a graphical interface overlaid on top of the video ( Figure 60 . 2 and Figure 60 . 3 ) . Once a query is created , the spatial tracking data will be parsed for matching conditions of the query and the results are highlighted in an additional timeline ( Figure 53i ) . A click on each result jumps to the position in the video . Figure 60 . Queries are created via a graphical user interface laid on top of a still video frame ( steps 1 - 3 ) . Queries can be combined to make up more specialised compound queries ( 4 ) . 9 . 7 . 2 Query Creation Our query creation tool is inspired by EXCITE ’ s ( Marquardt , Schardong , and Tang 2015 ) idea of allowing analysts to search video for interaction events . However , rather than using a declarative language to describe a query , EagleView uses a graphical user interface for query creation and setting of parameters . A search - query is a combination of property ( distance , orientation , location , activity ) , entity ( person and / or object ) , and parameters ( specifying a value for the property being searched for ) . Query creation is a three - step process ( Figure 60 ) : First the analyst selects a property ( Figure 60 . 1 ) . They then select the relevant entities ( e . g . person or large screen ) by clicking on the overlaid items on the still frame ( Figure 60 . 2 ) . Lastly , the search parameters can be adjusted ( Figure 60 . 3 a - d ) for a single entity ( e . g . a person ’ s orientation , location , or activity ) or between two entities ( e . g . specifying the relevant distance threshold between two people or between a person and a fixed object ) . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 232 Matched results for each query show up in the event timeline . Each query is shown in its own timeline . For example , in Figure 60a , an analyst creates a query to search for instances where the distance between person 2 and 3 is smaller than 100cm to find all instances when the two people are standing in close proximity . The analyst then selects the orientation property ( Figure 60b ) and changes the relevant opening and orientation angle , to find all events when the two people in the video face each other . Last , the analyst specifies a query for all instances when any of the two people stand in front of the large display ( Figure 60c ) . In the scenario : Mary now wants to understand further why the visitors spent most of their time around the interactive exhibits . She creates a “Location” query by marking the area around the interactive displays . The search results indicate all instances where a user is in front of an interactive display . Through this search - query , the 10 hours of video are narrowed down to 120 results of 30 - 90 seconds — only 120 minutes in total . Mary can now review those instances in more detail by clicking on the search results in the timeline . Through the review , she finds that visitors frequently get their smartphone out around the interactive exhibits to select the accompanying audio - guide and listen to the narration . 9 . 7 . 3 Compound Queries Analysts can also create compound queries , which are comprised of two or more queries . The results are then filtered to only include instances where all queries match ( AND logic connection ) . Compound queries show as a combined section in the event timeline . For instance , in our example the researcher is interested in finding all instances of so called L - shape F - formations ( a sociological lens for analysing pair interactions based on their spatial characteristics ( Kendon 2010 ) ) . For finding these formations , the analyst creates a compound query : finding all instances where the orientation angle between two people is around 90 degrees ( by visually adjusting to a wider tolerance angle ; Query1 ) , AND distance is below 2 meters ( Query2 ) . Once completed , the new compound query highlights these F - formation instances in the timeline . EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 233 In the scenario : Mary now wants to know whether people who are visiting the museum in a group also use their smartphone in some similar way to single visitors . She therefore needs to find all instances where two people are in front of an interactive display , while they are using their smartphones . She creates a three - part compou nd query : first she creates a “Location” query like in the previous example to filter for location matches around interactive exhibits . She then adds a “Distance” query to filter for instances where two people are closer than 100cm . Last , she adds an “Activity” query with its search parameter set to “Smartphone” to filter for moment when both visitors are using their smartphone . By reviewing the 70 search results , she finds that group visitors less frequently listen to the audio guide and rely on reading the museum guide . Discussion EagleView supports researchers to explore their video material in a way which was not easily possible before and supports them throughout their analysis process ( Figure 54 ) . Researchers do not necessarily need to know what conditions they are looking for but can follow an iterative approach of switching between using the visualisations for serendipitous discovery and the search - queries for a more fine - grained analysis . The overview visualisations enable users to see movement over a longer period of time , acting as a summary of what is going on . It allows analysts to discover trends , directly linked to the videos . For example , the movement traces can be used to easily spot familiar movement patterns , such as audience funnels ( Michelis and Müller 2011 ) . The real - time visualisations enable researchers to view a clean representation of the data , while having the ability to switch to the video feed . The visualisation - only playback of the data stream allows researchers to use this sensor data as an additional video feed , joining it with the camera feed whenever more detail is desired . As a result , analysts can get focus points for their analysis and can quickly gain an overall understanding of the material . F - formations ( Kendon 2010 ; Marquardt , Hinckley , and Greenberg 2012 ) are a powerful lens for interaction analysis . While EagleView allows analysts to easily create EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 234 queries to search for these , they currently need to be created manually every time they are used . Query - templates would allow for quick searches , filtering for the most frequent interactions . Further , search - queries currently can only be used for parallel conditions . Creating temporal queries , that highlight a sequence of interactions , would enable researchers to easier analyse temporal aspects , such as with the audience funnel framework ( Michelis and Müller 2011 ) . While the study — reported on in the ISS ’ 18 paper acknowledged in the beginning of this chapter — showed that EagleView is easy to learn and usable , it would be interesting to see how EagleView would perform for the analysis of a real - life interaction study . This would allow us to gather further insights into which templates would be useful outside of a fictional scenario . Such an in the wild deployment however is outside the scope of this thesis . The current implementation of EagleView uses top - down tracking information . Although tracking - system - agnostic , this is a limitation , as a top - down camera cannot be installed in every location . Further , the current implementation of viewing direction only acts on 2D information . For example , if a person is looking over the top of a display rather than onto it , this still counts as an interaction . The researcher then has to use an additional side - view camera to gain further insights . The querying function of EagleView enables analysts to quickly select interaction scenarios of interest and find highlights of interactions through the visualisations . However , currently we do not know how such a tool would perform in everyday or long - term use . What would unexpected uses be ? How does it support analysts in their real - world tasks ? Where does it break ? A real - world deployment would surface opportunities for extension of the system . Further , interaction analysis on the video material is only the first step — and a more detailed quantitative ( time , duration , and frequency ) and qualitative ( on verbal transcriptions and other annotations ) analysis is often needed . Currently , EagleView does not support these steps and they have to be conducted on the exported JSON data of tags and annotations . We see further potential for future extensions of EagleView . For example , our current real - time visualisations of F - formations could be extended with dashboard - like summary views of the different formations recorded . Furthermore , it would be EagleView : A Video Analysis Tool for Visualising and Querying Spatial Interactions 235 interesting to consider visualisations and query constructs for more fine - grained gestures that people perform . In summary , EagleView is a novel tool directly supporting researchers performing interaction analysis through video coding and integrates a querying tool as well as real - time and overview visualisations , making it easier to find relevant sequences in the videos to interpret . EagleView is available as open - source software at https : / / github . com / frederikbrudy / eagleview . Discussion and Conclusion 237 Chapter 10 . Discussion and Conclusion In this chapter , the contributions of this thesis to the wider field of HCI are summarised as well as the progress towards answering the three research questions discussed . Directions for future work are discussed in section 10 . 2 , and section 10 . 3 concludes this thesis . This thesis explored how cross - device computing can be leveraged for designing interactions and system for knowledge work — and more specifically curation tasks . The work in this thesis contributes to the field of HCI , and in particular to the areas of cross - device computing in the following three ways : 1 . In Part I the landscape of cross - device computing was mapped out to provide a taxonomy of cross - device computing , mapping out and discussing several design spaces as well as pointing to underexplored areas . This allowed for the transfer of key insights into the design of interaction techniques and to a research agenda being scoped . 2 . In the second part of the thesis a set of novel interaction techniques for supporting individual and collaborative knowledge work were developed . For this , the insights from Part I were combined with lessons learned about the practices of curators — both professionally trained and volunteers — to inform the design and building of interaction techniques for curation tasks . First , two exemplary systems have been implemented that apply cross - device interactions to the specific use - case of curation , operationalising instrumental interaction ( Chapter 5 ) , learning from existing practices ( Chapter 6 ) , and enabling the use of existing devices in ad hoc collaborative settings ( Chapter 6 ) . The third tool that was built , SurfaceConstellations ( Chapter 7 ) , Discussion and Conclusion 238 demonstrated how multiple devices can be organised physically to provide a novel workspace setup for a range of collaborative and cross - device projects . 3 . The final stage of the thesis was concerned with how to study and evaluate cross - device interactions . It provides insights into how researchers can study and understand multi - and cross - device interactions for individual and collaborative work and provides insights into how a digital tool can support a researcher ’ s interaction analysis of video recordings . Next , I use the outcomes from the three stages to answer the research questions set at the beginning of this thesis . Answering the Research Questions The main research question which was addressed in this thesis : How can we leverage cross - device computing for designing new interactive systems in human - computer interaction ( HCI ) ? To answer this question , it was broken down into three sub - questions , that are discussed below . 10 . 1 . 1 Developing a Framework and Extensive Literature Review of the Body of Work Conducted in the Area of Cross - Device Computing RQ1 : What is the current state of the field of cross - device computing and which challenges and opportunities exist ? Goal # 1 : This question was addressed by building a theoretical foundation and understanding of the domain of cross - device computing and in doing so unifying the diverse threads of existing research to inform the current and future research in the field . To answer this question , a taxonomy of the key characteristics of the cross - device design space was developed that drew upon a systematic review of previous work in the cross - device computing domain . By reviewing hundreds of previous research Discussion and Conclusion 239 papers , different aspects were covered , including cross - device interactions , tools , and research projects . This enabled the design space to be systematically explored , notably showing that there are a number of application domains , enabling technologies , interaction techniques , and evaluation strategies . The main contribution of this review has been to map out the landscape for cross - device research that was turned into a resource for other researchers to use when framing their research , but also for newcomers to find an entry into the field : ( 1 ) For anyone entering the field the ontology ( section 4 . 1 ) clarifies terminology used , while at the same time highlights that some terms are used interchangeably . For current researchers framing their work , the structuring of concepts can help to identify the best terms to describe the work . And within the cross - device community , the ontology can provoke reflection on the use and appropriateness of terminology . ( 2 ) The taxonomy ( section 4 . 2 ) has three different functions helping researchers : a . it compresses the large research field and synthesises seminal work to ease entry into an unfamiliar research domain , b . the specific dimensions ( and subcategories ) can support framing and scoping of new and ongoing research , and c . it allows discussing research in the context of the major related categories within the six dimensions . The taxonomy works in conjunction with the analysis across applications ( section 4 . 3 ) , technology ( section 4 . 4 ) , interaction techniques ( section 4 . 5 ) , and evaluation strategies ( section 4 . 6 ) . ( 3 ) The review can provide practical guidance on how to select from the vast pool of existing tracking tools and technologies enabling cross - device systems . Selecting an appropriate cross - device tracking technology is a challenging task — even for experts in the field . The choice follows several considerations weighing the benefits of outside - in tracking that provides high fidelity information as opposed to a more light - weight but lower fidelity inside - out tracking technology . Our classification in section 4 . 4 shows the breadth of Discussion and Conclusion 240 state - of - the - art research of cross - device tracking technologies , including those off - the - shelf . It serves as a reference table to help inform which tracking technologies might be most suitable for a particular usage scenario . ( 4 ) Similarly , the classification of interaction techniques ( section 4 . 5 ) allows researchers to select the most appropriate technique for their own work , while also highlighting underexplored areas or open questions ( as discussed in section 4 . 7 ) . ( 5 ) The classification of evaluation strategies ( section 4 . 6 ) shows the breadth of methods used in cross - device computing . Especially since usability evaluation is ( sometimes ) considered harmful ( Greenberg and Buxton 2008 ) , there are a multitude of methods available to evaluate cross - device interactions , systems , and interfaces . Researchers can find examples of how previous work that is similar work to their own has been validated . While for the work conducted in Chapter 4 we reviewed over 500 papers in - depth , this is not a complete review of all existing work . The aim was to show the breadth of cross - device work and highlight opportunities for future work . We conducted a systematic search to find relevant papers , combined with an approach of Thematic Analysis to identify the parameters of our taxonomy and of the design spaces discussed in Chapter 4 . While this ensured that the selection of papers was not biased or “cher ry - picked” as well as the themes that we identified in the data were not pre - described but rather “emerged” from the data , it should be acknowledged that the focus points chosen might be influenced by our own experience . Ultimately , we hope that the taxonomy can provoke reflections on the use of terminology and future research agenda within the cross - device community . A question this raises is : how will it be used by others to inform their research and development ? In what way does having provided this kind of taxonomy help inform design ? Systematic literature reviews capture the development of a research landscape over a period of time , allowing researchers to reflect on where a research community has come from . However , while a reflection about the past can be made , a prediction about future directions of a field is impossible . The outcome of doing such an extensive review of the literature in this area was the identification of nine underexplored areas and challenges within the cross - device design space ( section 4 . 7 ) . Only time can tell Discussion and Conclusion 241 whether the key challenges we identified were of lasting importance or even picked up by researchers . The raw data of our taxonomy was released as open source to enable it to be readily accessible but also to extend it with new and changing material over time . In the future , which is beyond the remit of this thesis , it will be possible to chart which aspects of the framework and research the areas the community has chosen to pursue . 10 . 1 . 2 Case Studies of Cross - Device Tools for Knowledge Work RQ2 : How can we leverage cross - device principles to design tools for knowledge work ? Goal # 2 : Within use - cases of knowledge work — and more specifically curation — show how cross - device tools can support people in their tasks and activities . The starting point for this phase for the research was to design and build generic cross device systems that enable individuals and groups to conduct curation work . The first system — CurationSpace ( Chapter 5 ) — operationalised instrumental interaction , demonstrating that cross - device systems could enable a number of interactions that augment humans ’ touch . In doing so we could support a rich interaction language . We were also able to demonstrate that body - worn devices not only provided protection of privacy , but also enabled personalisation of content , context , and use . Body - worn and personal devices enable people to interact with their personal content on devices they are familiar with , even when they are conducting work in an ecosystem with unfamiliar devices ( the tabletop in this scenario ) . The findings suggest this kind of personalisation is not bound to a single device or ecosystem but could be developed to enable transition with the user from one place to another . The second system that was built showed how to leverage people ’ s own devices without the need for special software setup or configuration work . CurationLens ( Chapter 6 ) was informed by a set of interviews with curators from which design requirements were extracted . Many of the existing cross - device systems require large amounts of configuration and maintenance work , as discussed in detail in Chapter 4 . CurationLens runs entirely in a web browser without the need for any special configuration work and was designed for ad hoc collaboration by reducing the setup Discussion and Conclusion 242 cost to a minimum . Reducing the setup and maintenance costs showed how cross - device systems can be made available outside research labs and how cross - device principles can be made available to the general public . CurationLens ’ interactions can be further enriched using tangible tools . Based on Blended Interaction ( Jetter et al . 2012 ) this allowed for greater visibility of intent of action as well as eyes - free interactions where curators do not need to switch attention when interacting with digital data . The tangible tools , together with enabling users to project in the environment and to easily digitise physical artefacts , blended the interactions with digital and physical artefacts , data , and tools . In the descriptions of the tools we used only tablet devices . However , there is nothing that speaks against using more permanent setups . In fact , the system itself is agnostic to the devices and physical layouts used and it is left to the user how the system is utilised . While a deployment of CurationLens would have allowed us to gain such insights into real - world application and use of tools , we opted for a heuristic evaluation as discussed in the methodology chapter ( Chapter 2 ) . Therefore , several questions remain : What combinations of tools are most useful ? Where does the fluidity break when switching between physical and digital artefacts ? What sharing practices are most beneficial to collaborative curation ? Ultimately , the question of whether CurationLens ’ tools can withstand the expectations of a real - world use has not been explored in this thesis . The CurationSpace case study showed that cross - device principles can be used to design a system supporting curation work . By integrating with existing workflows and by blending physical and digital artefacts and tools , CurationLens was then built as a flexible system where curators can choose the tools that support their workflow best , reducing the configuration and learning overhead to a minimum . CurationLens ’ modularity of physical setups was further extended with SurfaceConstellations ( Chapter 7 ) . SurfaceConstellations showed how the flexibility of cross - device systems can — with minimal hardware additions — benefit from traditional rigid multi - screen desktop setups . Anyone with access to a 3D - printer can easily ( re - ) configure semi - rigid physical setups of tablet devices and smartphones . Using the visual web - based configuration tool the brackets can be designed without any prior knowledge , making them again available to the general public . The power Discussion and Conclusion 243 of SurfaceConstellations however comes when considering the software side . While the hardware setup is agnostic to any software applications , a prime example would be to use it for CurationLens . Using SurfaceConstellations to create more elaborate setups for CurationLens demonstrates that the fluid ad hocness of CurationLens ’ mobile cross - device setups do not need to miss out on the benefits of traditional multi - screen setups . Further , we broadened the use - cases of SurfaceConstellations to other software applications , showcasing that cross - device tools can support a range of activities beyond knowledge work ( section 7 . 5 ) . While this — in part — addresses the challenges of legacy bias ( section 4 . 7 . 3 ) , the social challenges ( section 4 . 7 . 4 ) , and moves towards proactive cross - device interactions ( section 4 . 7 . 5 ) , more work needs to be done to explore what it means to disengage from cross - device interactions . Being built for heterogenous environments , CurationLens embraces — and leverages — the unique advantages of devices that are involved . While a tablet might be best suited for drawing and sketching , a smartphone is best for taking quick pictures , and a laptop to write longer texts by providing a physical keyboard . Ultimately however , the users will decide if and how they appropriate the technology used . As discussed in the study with CurationSpace ( Chapter 5 ) , different people see different uses for such a system and see different ways of how it might support their everyday work . It is worth repeating here , that it is ultimately the user who is “doing the ubicomp” ( Oulasvirta 2008 ) — and technology designers need to embrace and support this . A question remains about how much people have to learn — and in fact unlearn — when being introduced to and ultimately use new interactions . Are issues with understanding new interaction paradigms mere ‘ teething problems ’ or are they a sign of a bigger underlying problem ? This invariably opens the discussion about real - world deployments vs . lab studies . An in the wild study would likely yield more insights into how such a technology is adopted in everyday practices and real - world tasks . However , such deployments pose great challenges towards the researchers and technology . How does a research prototype need to be changed in order to be taken from the lab into the wild ? For in the wild purposes they need to be robust , being able to be used in different scenarios than what they were intended for . Deployments in Discussion and Conclusion 244 the wild might happen in cluttered areas , much unlike a controlled lab study , making possible issues unpredictable . Overall , by introducing cross - device setups to personalise a system ( Chapter 5 ) , by enabling to transition context from one device to another ( Chapter 5 , Chapter 6 ) , by leveraging bring - your - own - device ( BYOD ) design principles ( Chapter 6 , Chapter 8 ) , by requiring no — or minimal — setup ( Chapter 6 ) , and by allowing users to easily ( re ) configure physical layouts / setups ( Chapter 7 ) , the work in Part II showed that cross - device principles can be used to design systems which can effectively support people ’ s individual and collaborative tasks . Cross - device systems are powerful not only for demonstrating interaction techniques , but this also shows application areas of where cross - device systems can support knowledge work . 10 . 1 . 3 Studying and Evaluating Cross - Device Tools RQ3 : How can we study and evaluate cross - device systems ? Goal # 3 : Provide insights and tools that support researchers in the cross - device domain to study and evaluate the cross - device systems they built . Chapter 8 first looked at how we can study and understand collaborative cross - device systems . Based on our user study it was found that the design of cross - device systems can influence how closely a group ’ s members collaborate . To explore the nuances of how this occurs we further provided a coding scheme for classifying different kinds of collaborative interactions . The method that was developed here allows for greater flexibility than previous coding techniques , when coding for more than two users with more than a single device . Understanding , evaluating , and studying such cross - device systems is painstaking to achieve well , requiring many hours reviewing and analysing video footage . EagleView ( Chapter 9 ) was therefore developed to reduce the burden of interaction analysis by supporting researchers with more structured tools , offering live and overview / static visualisations as well as new search and filtering capabilities . Through such a tool , researchers can be supported in finding insights , allowing them to focus on interactions rather than the many hours of “no interactions” while reviewing video Discussion and Conclusion 245 material . The visualisations further enable novel insights that previously have not been easily possible . One of the challenges identified in section 4 . 7 . 6 was that more in the wild deployments of cross - device tools are needed to understand how they support people ’ s work and how people appropriate them for their uses . While EagleView can help researchers to study in the wild deployments , many cross - device systems are still prototypical , difficult to setup , and need continued maintenance and support . During the work conducted for this thesis , it became even clearer that ( i ) more work is needed to enable building and deploying stable cross - device systems ( especially when any spatial tracking is involved ) as well as ( ii ) there are no tools that enable researchers to study interactions with cross - device systems . CurationSpace and CurationLens — as well as other previous work — have shown that external tracking of devices is not needed for a successful cross - device system . However , it still remains a challenge to get a widespread adoption of cross - device systems . Software companies have recently begun to integrate cross - device functionality into their systems and cross - device software features are materialising ( e . g . Apple ’ s Continuity and Sidecar features ) , but many of these have already been published in research already many years ago . The time for taking ideas from a research project to production can span a decade or longer , as for example visible in taking the vision of Microsoft ’ s Codex ( Hinckley et al . 2009 ) to its realisation in Microsoft ’ s dual screen tablet Surface Neo with a projected release of fall / winter 2020 . Many of the current attempts to institutionalise cross - device functionality on a software development platform are early steps . Only once cross - device functionality will be made available as a standard on an operating system level , ready for developers to use , it will become widespread — again pointing out the infrastructure problem ( Oulasvirta 2008 ; Houben , Tell , and Bardram 2014 ) discussed in section 4 . 7 . 7 . and the meaningful user experience standards discussed in section 4 . 7 . 8 . Directions for Future Work In the following some directions for future work will be described that have surfaced throughout the work conducted for this thesis . Discussion and Conclusion 246 10 . 2 . 1 Disengagement of Interaction Our cross - device taxonomy ( Chapter 4 ) has shown that only very little work has been conducted around the disengagement from cross - device work . This has a huge impact on what people can do and feel comfortable doing when using multiple devices together . Any interaction not only consists of configuration work and interactions to manipulate and work with content , but there is always an end to any interaction and the question remains of what happens at that point . How do people disengage from a system ? What happens to data that has been shared as part of a collaborative interaction ? Who is the owner of collaboratively created content ? While privacy for single - machine systems is an important research area within HCI , only few researchers have looked at this within the cross - device computing domain . We have explored some privacy aspects within CurationSpace ( Chapter 5 ) , but this only scratched the surface . Looking at disengagement and ultimately at what happens to information people share within cross - device setups , privacy and protection of personal information needs to move front and centre . 10 . 2 . 2 Remote vs . Collocated Collaborations The work conducted in this thesis was only concerned with collocated interactions of people . However , in an increasingly mobile and nomadic work world , no assumption should be made of people always being in the same room at the same time . As pointed out by Bill Buxton , the notion of Place is more than just a location , but rather transitions of points in time , place , and social connections ( Buxton 2018 ) . Cross - device computing needs to take this into account , and we need to design interactions that can fluidly live within the design space of these aspects . Remote collaboration is merely a beginning and ultimately the tools we design need to allow any configuration of people to do the tasks they need , at the right place , and at the time they need them ( Buxton 2018 ) . 10 . 2 . 3 In the wild Deployments of Cross - Device Systems Cross - device systems are difficult to build , set up , and maintain . Few in the wild deployments of such systems have been reported . A question this leaves is how can we take cross - device systems outside the lab and allow people to use it on their own terms ? How are cross - device systems reappropriated ? What unexpected uses do they Discussion and Conclusion 247 support ? Through in the wild ( ITW ) deployments more insights of what people actually want to do with such systems , rather than merely a usability evaluation , would be possible . This presents a range of question across the spectrum of this thesis : What design aspects are most relevant for deployments outside research labs ? How can we overcome the difficulties in setting up — and maintaining — cross - device system for ITW deployments ? How can cross - device systems be evaluated ITW ? Recently large technology companies have introduced aspects of cross - device computing into their systems ( e . g . Apple ’ s Sidecar , Microsoft ’ s cross - device clipboard , etc . ) . However , considering that such interactions — which have been the focus of cross - device research over ten years ago — only now start to make it into production means that w hat we are researching today might become “the next big thing” in ten years’ time . While cross - device support will likely arrive at operating system levels , the research community can already start now to conduct work that takes cross - device concepts outside the lab . Conclusion We can expect that people will likely continue to use an ever - increasing number of devices for everyday access to digital information for work , leisure , and effective communication . Research in the area of cross - device computing is therefore more important than ever , and industry as well as academia continues to improve cross - device experiences . The research in this thesis was structured in three parts , addressing theory , tools , and evaluation of cross - device computing . Through a systematic analysis of prior research , the first part provided newcomers as well as experienced researchers in HCI a guide to the cross - device computing domain , serving as an orientation to the field . By highlighting underexplored areas , Part I further highlights white spots on the map of cross - device computing as opportunities for future research work . Within Part II , the three case studies of cross - device tools for knowledge work showcased that cross - device design principles can be effectively used for building tools that support people ’ s individual and collaborative work . This showcases the potential of interactions spanning across multiple devices not only for demonstration purposes , but also to be made available to the masses outside a research lab . The contributions in Part III , demonstrated how researchers can be Discussion and Conclusion 248 supported in studying cross - device systems . By giving an actionable tool as well as description of collaboration styles , researchers are supported when embarking on the cross - device research journey . We hope that the work in this thesis will inspire new generations of cross - device work , towards fluid interactive experiences across the ecology of devices . References 249 References Aliakseyeu , Dzmitry , Andrés Lucero , and Jean - Bernard Martens . 2008 . “Users’ Quest for an Optimized Representation of a Multi - Device Space . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 359 – 362 . AVI ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1385569 . 1385633 . Alsos , Ole Andre , and Dag Svanæs . 2006 . “Interaction Tec hniques for Using Handhelds and PCs Together in a Clinical Setting . ” In Proceedings of the 4th Nordic Conference on Human - Computer Interaction : Changing Roles , 125 – 134 . NordiCHI ‘ 06 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1182475 . 1182489 . Andrews , Christopher , Alex Endert , and Chris North . 2010 . “Space to Think : Large High - Resolution Displays for Sensemaking . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 55 – 64 . ACM . https : / / doi . org / 10 . 1145 / 1753326 . 1753336 . Andrews , Christopher , Alex Endert , Beth Yost , and Chris North . 2011 . “Information Visualization on Large , High - Resolution Displays : Issues , Challenges , and Opportunities . ” Information Visualization 10 ( 4 ) : 341 – 55 . https : / / doi . org / 10 . 1177 / 1473871611415997 . Anslow , Craig , Chris Rooney , Neesha Kodagoda , and William Wong . 2015 . “Police Analyst Workstation : Towards a Multi - Surface User Interface . ” In Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces , 307 – 311 . ITS ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2817721 . 2823498 . Ashbrook , Daniel L . , James R . Clawson , Kent Lyons , Thad E . Starner , and Nirmal Patel . 2008 . “Quickdraw : The Impact of Mobility and on - Body Placement on Device Access Time . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 219 – 222 . CHI ‘ 08 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1357092 . “ATLAS . ti . ” 2017 . atlas . ti . 2017 . https : / / atlasti . com / . Badam , Sriram Karthik , and Niklas Elmqvist . 2014 . “PolyChrome : A Cross - Device Framework for Collaborative Web Visualization . ” In Proceedings of the Ninth ACM International Conference on Interactive Tabletops & Surfaces , 109 – 118 . ITS ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2669485 . 2669518 . Bader , Thomas , Astrid Heck , and Jürgen Beyerer . 2010 . “Lift - and - Drop : Crossing Boundaries in a Multi - Display Environment by Airlift . ” In Proceedings of the International Conference on Advanced Visual Interfaces , 139 – 146 . AVI ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1842993 . 1843019 . Ballagas , Rafael , Michael Rohs , Jennifer G . Sheridan , and Jan Borchers . 2004 . “Byod : Bring Your Own Device . ” In Proceedings of the Workshop on Ubiquitous Display References 250 Environments , Ubicomp . Vol . 2004 . Ubicomp Workshop ‘ 04 . http : / / www . vs . inf . ethz . ch / publ / papers / rohs - byod - 2004 . pdf . Ballendat , Till , Nicolai Marquar dt , and Saul Greenberg . 2010 . “Proxemic Interaction : Designing for a Proximity and Orientation - Aware Environment . ” In ACM International Conference on Interactive Tabletops and Surfaces , 121 – 130 . ITS ‘ 10 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1936676 . Bard ram , Jakob , Steven Houben , Søren Nielsen , and Sofiane Gueddana . 2012 . “The Design and Architecture of Reticularspaces : An Activity - Based Computing Framework for Distributed and Collaborative Smartspaces . ” In Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems , 269 – 274 . EICS ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2305484 . 2305529 . Baudisch , Patrick , Edward Cutrell , Dan Robbins , Mary Czerwinski , Peter Tandler , Benjamin Bederson , Alex Zierlinger , and others . 20 03 . “Drag - and - Pop and Drag - and - Pick : Techniques for Accessing Remote Screen Content on Touch - and Pen - Operated Systems . ” In Proceedings of INTERACT , 3 : 57 – 64 . Baur , Dominikus , Sebastian Boring , and Steven Feiner . 2012 . “Virtual Projection : Exploring Optical Projection As a Metaphor for Multi - Device Interaction . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1693 – 1702 . CHI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2207676 . 2208297 . Beaudouin - Lafon , Michel . 2000 . “Inst rumental Interaction : An Interaction Model for Designing Post - WIMP User Interfaces . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 446 – 453 . CHI ‘ 00 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 332040 . 332473 . Beaudouin - Lafon , Michel , Stephane Huot , Mathieu Nancel , Wendy Mackay , Emmanuel Pietriga , Romain Primet , Julie Wagner , et al . 2012 . “Multisurface Interaction in the WILD Room . ” Computer 45 ( 4 ) : 48 – 56 . https : / / doi . org / 10 . 1109 / MC . 2012 . 110 . Beaudouin - Lafon , Michel , and Wendy E . Mackay . 2000 . “Reification , Polymorphism and Reuse : Three Principles for Designing Visual Interfaces . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 102 – 109 . AVI ‘ 00 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 345513 . 345267 . Bederson , Benjamin B . , James D . Hollan , Allison Druin , Jason Stewart , David Rogers , and David Proft . 1996 . “Local Tools : An Alternative to Tool Palettes . ” In Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology , 169 – 170 . UIST ‘ 96 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 237091 . 237116 . Besacier , Guillaume , Julie Tournet , Nippun Goyal , Frank Cento , and Stacey D . Scott . 2014 . “Object and ARM Shadows : Visual Feedback for Cross Device Transfer . ” In CHI ‘ 14 Extended Abstracts on Human Factors in Computing Systems , 463 – 466 . CHI EA ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2559206 . 2574832 . Bhargava , Rohit . 2009 . “Manifesto For The Content Curator : The Next Big Social Media Job Of The Future ? ” Influential Marketing Blog . September 30 , 2009 . http : / / www . rohitbhargava . com / 2009 / 09 / manifesto - for - the - content - curator - the - next - big - social - media - job - of - the - future . html . References 251 ——— . 2011 . “The 5 Models Of Content Curation . ” Influential Marketing Bl og . March 31 , 2011 . http : / / www . rohitbhargava . com / 2011 / 03 / the - 5 - models - of - content - curation . html . Bhaskar , Michael . 2016 . Curation : The Power of Selection in a World of Excess . Piatkus . Bi , Xiaojun , Tovi Grossman , Justin Matejka , and George Fitzmaurice . 2011 . “Magic Desk : Bringing Multi - Touch Surfaces into Desktop Work . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 2511 – 2520 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979309 . Biehl , Jacob T . , and Brian P . Bailey . 2006 . “Improving Scalability and Awareness in Iconic Interfaces for Multiple - Device Environments . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 91 – 94 . AVI ‘ 06 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1133265 . 1133283 . Blandford , Ann , Dominic Furniss , and Stephann Makri . 2016 . “Qualitative HCI Research : Going Behind the Scenes . ” Synthesis Lectures on Human - Centered Informatics 9 ( 1 ) : 1 – 115 . https : / / doi . org / 10 . 2200 / S00706ED1V01Y201602HCI034 . Bloomberg . n . d . “Bloomberg Professional Services : The Terminal | Hardware . ” https : / / www . bloomberg . com / professional / solution / bloomberg - terminal . Bødker , Susanne . 1990 . Through the Interface - a Human Activity Approach to User Interface Design . CRC Press . Bødker , Susanne , and Clem ens Nylandsted Klokmose . 2012 . “Dynamics in Artifact Ecologies . ” In Proceedings of the 7th Nordic Conference on Human - Computer Interaction : Making Sense Through Design , 448 – 457 . NordiCHI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2399016 . 2399085 . Boring , Sebastian , Manuela Altendorfer , Gregor Broll , Otmar Hilliges , and Andreas Butz . 2007 . “Shoot & Copy : Phonecam - Based Information Transfer from Public Displays Onto Mobile Phones . ” In Proceedings of the 4th International Conference on Mobile Technology , Applications , and Systems and the 1st International Symposium on Computer Human Interaction in Mobile Technology , 24 – 31 . Mobility ‘ 07 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1378063 . 1378068 . Boring , Sebastian , Dominikus Baur , Andreas Butz , Sean Gustafson , and Patrick Baudisch . 2010 . “Touch Projector : Mobile Interaction Through Video . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 2287 – 2296 . CHI ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1753326 . 1753671 . Bouabid , Amira , Sophie Lepreux , Christophe Kolski , and Clémentine Havrez . 2014 . “Context - Sensitive and Collaborative Application for Distributed User Interfaces on Tabletops . ” In Proceedings of the 2014 Workshop on Distributed User Interfaces and Multimodal Interaction , 23 – 26 . DUI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2677356 . 2677661 . Bragdon , Andrew , Rob DeLine , Ken Hinckley , and Meredith Ringel Morris . 2011 . “Code Space : Touch + Air Gesture Hybrid Interactions for Supporting Developer Me etings . ” In Proceedings of the ACM International Conference on Interactive Tabletops & Surfaces , 212 – 221 . ITS ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2076354 . 2076393 . Braun , Virginia , and Victoria Clarke . 2006 . “Using Thematic Analysis in Psychology . ” Qualitative Research in Psychology 3 ( 2 ) : 77 – 101 . https : / / doi . org / 10 . 1191 / 1478088706qp063oa . References 252 Brudy , Frederik , David Ledo , Saul Greenberg , and Andreas Butz . 2014 . “Is Anyone Looking ? Mitigating Shoulder Surfing on Public Displays through Awareness and Protection . ” In Proceedings of The International Symposium on Pervasive Displays , 1 – 6 . PerDis ‘ 14 . ACM . https : / / doi . org / 10 . 1145 / 2611009 . 2611028 . Burr , Brandon . 2006 . “VACA : A Tool for Qualitative Video Analysis . ” In CHI ’ 06 Extended Abstracts on Human Factors in Computing Systems , 622 – 627 . ACM . https : / / doi . org / 10 . 1145 / 1125451 . 1125580 . Bush , Vannevar . 1945 . “As We May Think . ” The Atlantic Monthly 176 ( 1 ) : 101 – 8 . Buxton , Bill . 2017 . “Buxton Collection . ” 2017 . http : / / research . microsoft . com / en - us / um / people / bibuxton / buxtoncollection / . ——— . 2018 . Bill Buxton : Ubiety : On Design , Place and the Importance of Manners . https : / / www . youtube . com / watch ? v = GEeZFW7PFBI . Cao , Bingyi , Margarita Esponda , and Raúl Rojas . 2016 . “The Use of a Multi - Display System in University Classroom Lectures . ” In Proceedings of the 2016 ACM on Interactive Surfaces and Spaces , 427 – 432 . ISS ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2992154 . 2996793 . Carroll , John M . , Dennis C . Neale , Philip L . Isenhour , Mary Beth Rosson , and D . Scott McCrickard . 2003 . “Notification and Awareness : Synchronizing Task - Oriented Collaborative Activity . ” International Journal of Human - Computer Studies , Notification User Interfaces , 58 ( 5 ) : 605 – 32 . https : / / doi . org / 10 . 1016 / S1071 - 5819 ( 03 ) 00024 - 7 . Cauchard , Jessica R . , Markus Löchtefeld , Pourang Irani , Johannes Schoening , Antonio Krüger , Mike Fraser , and Sriram Subramanian . 2011 . “Visual Separation in Mobile Multi - Display Environments . ” In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology , 451 – 460 . UIST ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2047196 . 2047256 . Cecchinato , Marta E . , Anna L . Cox , and Jon Bird . 2 017 . “Always On ( Line ) ? : User Experience of Smartwatches and Their Role Within Multi - Device Ecologies . ” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , 3557 – 3568 . CHI ‘ 17 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3025453 . 3025538 . Cecchinato , Marta E . , Abigail Sellen , Milad Shokouhi , and Gavin Smyth . 2016 . “Finding Email in a Multi - Account , Multi - Device World . ” In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , 1200 – 1210 . CHI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2858036 . 2858473 . Celentano , Augusto , and Emmanuel Dubois . 2015 . “A Design Space for Exploring Rich and Complex Information Environments . ” In Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter , 34 – 41 . CHItaly 2015 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2808435 . 2808444 . Chalmers , Matthew , and Areti Galani . 2004 . “Seamful Interweaving : Heterogeneity in the Theory and Design of Interactive Systems . ” In Proceedings of the 5th Conference on Designing Interactive Systems : Processes , Practices , Methods , and Techniques , 243 – 252 . DIS ‘ 04 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1013115 . 1013149 . Chan , Li - Wei , Hsiang - Tao Wu , Hui - Shan Kao , Ju - Chun Ko , Home - Ru Lin , Mike Y . Chen , Jane Hsu , and Yi - P ing Hung . 2010 . “Enabling Beyond - Surface Interactions for Interactive Surface with an Invisible Projection . ” In Proceedings of the 23Nd Annual ACM Symposium on User Interface Software and Technology , 263 – References 253 272 . UIST ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1866029 . 1866072 . Chang , Tsung - Hsiang , and Yang Li . 2011 . “Deep Shot : A Framework for Migrating Tasks Across Devices Using Mobile Phone Cameras . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 2163 – 2172 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979257 . Charness , Gary , Uri Gneezy , and Michael A . Kuhn . 2012 . “Experimental Methods : Between - Subject and within - Subject Design . ” Journal of Economic Behavior & Organization 81 ( 1 ) : 1 – 8 . https : / / doi . org / 10 . 1016 / j . jebo . 2011 . 08 . 009 . Chen , Ke - Yu , Daniel Ashbrook , Mayank Goel , Sung - Hyuck Lee , and Shwetak Patel . 2014 . “AirLink : Sharing Files Between Multiple Devices Using In - Air Gestures . ” In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing , 565 – 569 . UbiComp ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2632048 . 2632090 . Chen , Nicholas , Francois Guimbretiere , and Abigail Sellen . 2012 . “Designing a Multi - Slate Reading Environment to Support Active Rea ding Activities . ” ACM Transactions on Computer - Human Interaction , ACM TOCHI , 19 ( 3 ) : 1 – 35 . https : / / doi . org / 10 . 1145 / 2362364 . 2362366 . Chen , Nicholas , François Guimbretière , and Abigail Sellen . 2013 . “Graduate Student Use of a Multi - Slate Reading System . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1799 – 1808 . CHI ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2470654 . 2466237 . Chen , Xiang Anthony , Nicolai Marquardt , Anthony Tang , Sebastian Boring , and Saul Greenberg . 201 1 . “Extending a Mobile Device ‘ s Interaction Space through Body - Centric Interaction . ” Chen , Xiang , Tovi Grossman , Daniel J . Wigdor , and George Fitzmaurice . 2014 . “Duet : Exploring Joint Interactions on a Smart Phone and a Smart Watch . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 159 – 68 . CHI ‘ 14 . ACM . https : / / doi . org / 10 . 1145 / 2556288 . 2556955 . Chernicharo , Jorge H . dos S . , Kazuki Takashima , and Yoshifumi Kitamura . 2013 . “Seamless Interaction Using a Portable Projector in Pers pective Corrected Multi Display Environments . ” In Proceedings of the 1st Symposium on Spatial User Interaction , 25 – 32 . SUI ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2491367 . 2491375 . Chong , Ming Ki , and Hans W . Gellersen . 2013 . “How Groups of Use rs Associate Wireless Devices . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1559 – 1568 . CHI ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2470654 . 2466207 . Chong , Ming Ki , Rene Mayrhofer , and Hans Gellersen . 2014 . “A Survey of User Interaction for Spontaneous Device Association . ” ACM Comput . Surv . 47 ( 1 ) : 8 : 1 – 8 : 40 . https : / / doi . org / 10 . 1145 / 2597768 . Chung , C - W . , C - C . Lee , and C - C . Liu . 2013 . “Investigating Face - to - Face Peer Interaction Patterns in a Collaborative Web Discovery Task : The Benefits of a Shared Display . ” Journal of Computer Assisted Learning 29 ( 2 ) : 188 – 206 . https : / / doi . org / 10 . 1111 / j . 1365 - 2729 . 2012 . 00493 . x . Chung , Haeyong , and Chris North . 2018 . “SAViL : Cross - Display Visual Links for Sensemaking in Display E cologies . ” Personal Ubiquitous Comput . 22 ( 2 ) : 409 – 431 . https : / / doi . org / 10 . 1007 / s00779 - 017 - 1091 - 4 . References 254 Chung , Haeyong , Chris North , Jessica Zeitz Self , Sharon Chu , and Francis Quek . 2014 . “VisPorter : Facilitating Information Sharing for Collaborative Sensemaki ng on Multiple Displays . ” Personal Ubiquitous Comput . 18 ( 5 ) : 1169 – 1186 . https : / / doi . org / 10 . 1007 / s00779 - 013 - 0727 - 2 . Coffey , Dane , Nicholas Malbraaten , Trung Le , Iman Borazjani , Fotis Sotiropoulos , and Daniel F . Keefe . 2011 . “Slice WIM : A Multi - Surface , Multi - Touch Interface for Overview + Detail Exploration of Volume Datasets in Virtual Reality . ” In Symposium on Interactive 3D Graphics and Games , 191 – 198 . I3D ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1944745 . 1944777 . Cook , Terry . 2012 . “Evidence , M emory , Identity , and Community : Four Shifting Archival Paradigms . ” Archival Science 13 ( 2 – 3 ) : 95 – 120 . https : / / doi . org / 10 . 1007 / s10502 - 012 - 9180 - 7 . Dachselt , Raimund , and Robert Buchholz . 2009 . “Natural Throw and Tilt Interaction Between Mobile Phones and Dis tant Displays . ” In CHI ‘ 09 Extended Abstracts on Human Factors in Computing Systems , 3253 – 3258 . CHI EA ‘ 09 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1520340 . 1520467 . Dasiopoulou , Stamatia , Eirini Giannakidou , Georgios Litos , Polyxeni Malasioti , and Yiannis Kompatsiaris . 2011 . “A Survey of Semantic Image and Video Annotation Tools . ” In Knowledge - Driven Multimedia Information Extraction and Ontology Evolution , edited by Georgios Paliouras , Constantine D . Spyropoulos , and George Tsatsaronis , 196 – 239 . Lecture Notes in Computer Science 6050 . Springer Berlin Heidelberg . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 20795 - 2 _ 8 . Davenport , Thomas H . 2005 . Thinking for a Living : How to Get Better Performances And Results from Knowledge Workers . Harvard Business Press . Davis , Pryce , Michael Horn , Florian Block , Brenda Phillips , E . Margaret Evans , Judy Diamond , and Chia Shen . 2015 . “‘ Whoa ! We ’ re Going Deep in the Trees ! ’ : Patterns of Collaboration around an Interactive Information Visualization Exhibit . ” International Journal of Computer - Supported Collaborative Learning 10 ( 1 ) : 53 – 76 . https : / / doi . org / 10 . 1007 / s11412 - 015 - 9209 - z . Dearman , David , and Jeffery S . Pierce . 2008 . “It’ s on My Other Computer ! : Computing with Multiple Devices . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 767 – 776 . CHI ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1357054 . 1357177 . Demeure , Alexandre , Gaëlle Calvary , Jean - Sebastien Sottet , and Jean Vanderdonkt . 2005 . “A Reference Model for Distributed User Interfaces . ” In Proceedings of the 4th International Workshop on Task Models and Diagrams , 79 – 86 . TAMODIA ‘ 05 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1122935 . 1122952 . Dey , Anind K . , Peter Ljungstrand , and Albrecht Schmidt . 2001 . “Distributed and D isappearing User Interfaces in Ubiquitous Computing . ” In CHI ‘ 01 Extended Abstracts on Human Factors in Computing Systems , 487 – 488 . CHI EA ‘ 01 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 634067 . 634346 . Dietz , Paul , and Darren Leigh . 2001 . “DiamondTouc h : A Multi - User Touch Technology . ” In Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology , 219 – 226 . UIST ‘ 01 . ACM . http : / / dl . acm . org / citation . cfm ? id = 502389 . Digital Curation Centre . 2016 . “DCC Curation Lifecycle Model . ” 2 016 . http : / / www . dcc . ac . uk / resources / curation - lifecycle - model . References 255 DiMicco , Joan Morris , Anna Pandolfo , and Walter Bender . 2004 . “Influencing Group Participation with a Shared Display . ” In Proceedings of the 2004 ACM Conference on Computer Supported Cooperative Work , 614 – 623 . CSCW ‘ 04 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1031607 . 1031713 . Dippon , Andreas , Norbert Wiedermann , and Gudrun Klinker . 2012 . “Seamless Integration of Mobile Devices into Interactive Surface Environments . ” In Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces , 331 – 334 . ITS ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2396636 . 2396693 . Dostal , Jakub . 2013 . “Designing Context - Aware Display Ecosystems . ” In Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion , 1 – 4 . IUI ‘ 13 Companion . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2451176 . 2451178 . Dostal , Jakub , Per Ola Kristensson , and Aaron Quigley . 2013 . “Subtle Gaze - Dependent Techniques for Visualising Display Changes in Multi - Display Environments . ” In Proceedings of the 2013 International Conference on Intelligent User Interfaces , 137 – 148 . IUI ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2449396 . 2449416 . Dourish , Paul . 2004 . Where the Action Is . New Ed edition . Cambridge , Mass . : MIT Press . Drucker , Peter F . 1959 . The Landmarks of Tomorrow . Harper & Row . Elmqvist , Niklas . 2011 . “Distributed User Interfaces : State of the Art . ” In Distributed User Interfaces : Designing Interfaces for the Distributed Ecosystem , edited by José A . Gallud , Ricardo Tesoriero , and Victor M . R . Penichet , 1 – 12 . London : Springer London . https : / / doi . org / 10 . 1007 / 978 - 1 - 4471 - 2271 - 5 _ 1 . Everitt , Katherine , Chia Shen , Kathy Ryall , and Clifton Forlines . 2006 . “MultiSpace : Enabling Electronic Document Micro - Mobility in Table - Centric , Multi - Device Environments . ” In Horizontal Interactive Human - Computer Systems , 2006 . TableTop 2006 . First IEEE International Workshop On , 8 – pp . IEEE . http : / / ieeexplore . ieee . org / xpls / abs _ all . jsp ? arnumber = 1579187 . Fardoun , Habib M . , Abdullah AL - Malaise AL - Ghamdi , and Antonio Paules Cipres . 2014 . “Improving Surgery Operations by Means of Cloud Systems a nd Distributed User Interfaces . ” In Proceedings of the 2014 Workshop on Distributed User Interfaces and Multimodal Interaction , 31 – 36 . DUI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2677356 . 2677663 . Fayollas , Camille , Célia Martinie , David Navarre , Philippe Palanque , and Racim Fahssi . 2014 . “Fault - Tolerant User Interfaces for Critical Systems : Duplication , Redundancy and Diversity As New Dimensions of Distributed User Interfaces . ” In Proceedings of the 2014 Workshop on Distributed User Interfaces and Multimodal Interaction , 27 – 30 . DUI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2677356 . 2677662 . Fei , Shenfeng , Andruid Kerne , Ajit Jain , Andrew M . Webb , and Yin Qu . 2013 . “Positioning Portals with Peripheral NFC Tags to Embody Trans - Surface In teraction . ” In Proceedings of the 2013 ACM International Conference on Interactive Tabletops and Surfaces , 317 – 320 . ITS ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2512349 . 2514593 . Fields , Jonathan . 2011 . “Is Content Curation The New Black ? ” Psych ology Today . March 7 , 2011 . http : / / www . psychologytoday . com / blog / awake - the - wheel / 201103 / is - content - curation - the - new - black . References 256 Fitzmaurice , George W . 1993 . “Situated Information Spaces and Spatially Aware Palmtop Computers . ” Commun . ACM 36 ( 7 ) : 39 – 49 . https : / / doi . org / 10 . 1145 / 159544 . 159566 . Forlines , Clifton , Alan Esenther , Chia Shen , Daniel Wigdor , and Kathy Ryall . 2006 . “Multi - User , Multi - Display Interaction with a Single - User , Single - Display Geospatial Application . ” In Proceedings of the 19th Annual ACM Symposium on User Interface Software and Technology , 273 – 276 . UIST ‘ 06 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1166253 . 1166296 . Forlines , Clifton , and Ryan Lilien . 2008 . “Adapting a Single - User , Single - Display Molecular Visualization Application for Use in a Multi - User , Multi - Display Environment . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 367 – 371 . AVI ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1385569 . 1385635 . Fouse , Adam , Nadir Weibel , Edwin Hutchins , and James D . Hollan . 2011 . “ChronoViz : A System for Supporting Navigation of Time - Coded Data . ” In CHI ‘ 11 Extended Abstracts on Human Factors in Computing Systems , 299 – 304 . CHI EA ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1979742 . 1979706 . Gellersen , Hans , Carl Fischer , Dominique Guinard , Roswitha Gostner , Gerd Kortuem , Christian Kray , Enrico Rukzio , and Sara Streng . 2009 . “Supporting Device Discovery and Spontaneous Interaction with Spatial References . ” Personal and Ubiquitous Computing 13 ( 4 ) : 255 – 64 . https : / / doi . org / 10 . 1007 / s00779 - 008 - 0206 - 3 . George , Adrian . 2015 . The Curator ’ s Handbook : Museums , Commercial Galleries , Independent Spaces . 01 edition . New York : Thames and Hudson Ltd . Gergle , Darren , Robert E . Kraut , and Susan R . Fussell . 2004 . “Language Effic iency and Visual Technology Minimizing Collaborative Effort with Visual Information . ” Journal of Language and Social Psychology 23 ( 4 ) : 491 – 517 . https : / / doi . org / 10 . 1177 / 0261927X04269589 . Gjerlufsen , Tony , Clemens Nylandsted Klokmose , James Eagan , Clément Pillias , and Michel Beaudouin - Lafon . 2011 . “Shared Substance : Developing Flexible Multi - Surface Applications . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 3383 – 3392 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979446 . Glaser , Barney G . , and Anselm Strauss . 1967 . The Discovery of Grounded Theory : Strategies for Qualitative Research . New York : Aldine Publishing . Goel , Mayank , Brendan Lee , Md . Tanvir Islam Aumi , Shwetak Patel , Gaetano Borriello , Stacie Hi bino , and Bo Begole . 2014 . “SurfaceLink : Using Inertial and Acoustic Sensing to Enable Multi - Device Interaction on a Surface . ” In Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems , 1387 – 1396 . CHI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2556288 . 2557120 . Goyal , Nitesh , and Susan R . Fussell . 2016 . “Effects of Sensemaking Translucence on Distributed Collaborative Analysis . ” In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing , 288 – 302 . CSCW ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2818048 . 2820071 . Goyal , Nitesh , Gilly Leshed , Dan Cosley , and Susan R . Fussell . 2014 . “Effects of Implicit Sharing in Collaborative Analysis . ” In Proceedings of the SIGCHI References 257 Conference on Human Factors in Computing Systems , 129 – 138 . CHI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2556288 . 2557229 . Greenberg , Saul , Sebastian Boring , Jo Vermeulen , and Jakub Dostal . 2014 . “Dark Patterns in Proxemic Interactions : A Critical Perspective . ” In Proceedings of the 2014 Conference on Designing Interactive Systems , 523 – 532 . DIS ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2598510 . 2598541 . Greenberg , Saul , Michael Boyle , and Jason LaBerge . 1999 . “PDAs and Shared Public Displays : Making Personal Information Public , and Public Information Personal . ” Personal Technologies 3 ( 1 – 2 ) : 54 – 64 . Greenberg , Saul , and Bill Buxton . 2008 . “Usability Evaluation Considered Harmful ( Some of the Time ) . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 111 – 120 . CHI ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1357054 . 1357074 . Greenberg , Saul , Nicolai Marquardt , Till Ballendat , Rob Diaz - Marino , and Miaosen Wang . 2011 . “Proxemic Interactions : The New Ubicomp ? ” Interactions 18 ( 1 ) : 42 – 50 . https : / / doi . org / 10 . 1145 / 1897239 . 1897250 . Greenwald , Anthony G . 1976 . “Within - Subjects Designs : To Use or Not to Use ? ” Psychological Bulletin 83 ( 2 ) : 314 . Grote , Casey , Evan Segreto , Johanna Okerlund , Robert Kincaid , and Orit Shaer . 2015 . “Eugenie : Multi - Touch and Tangible Interaction for Bio - Design . ” In Proceedings of the Ninth International Conference on Tangible , Embedded , and Embodied Interaction , 217 – 224 . TEI ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2677199 . 2680605 . Grubert , Jens , Matthias Heinisch , Aaron Quigley , and Dieter Schmalstieg . 2015 . “MultiFi : Multi Fidelity Interaction with Displays On and Around the Body . ” In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , 3933 – 3942 . CHI ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2702123 . 2702331 . Grubert , Jens , and Matthias Kranz . 2017 . “HeadPhones : Ad Hoc Mobile Multi - Display Environments Through Head Tracking . ” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , 3966 – 3971 . CHI ‘ 17 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3025453 . 3025533 . Grubert , Jens , Matthias Kranz , and Aaron Quigley . 2016 . “Challenges in Mobile Multi - Device Ecosystems . ” MUX : The Journal of Mobile User Experience 5 ( 1 ) : 5 . https : / / doi . org / 10 . 1186 / s13678 - 016 - 0007 - y . Grudin , Jonathan . 2001 . “Partitioning Digital Worlds : Focal and Peripheral Awareness in Multiple Monitor Use . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 458 – 465 . CHI ‘ 01 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 365024 . 365312 . Guía , Elena de la , María D . Lozano , and Victor M . R . Penichet . 2014a . “Interacting with Tangible Objects in Distributed Settings . ” In Proceedings of the 2014 Workshop on Distributed User Interfaces and Multimodal Interaction , 15 – 18 . DUI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2677356 . 2677659 . Guía , Elena de la , María Dolores Lozano , and Víctor M . R . Penichet . 2014b . “Increasing Engagement in Elderly People Through Tangible and Distributed User Interfaces . ” In Proceedings of the 8th International Conference on Pervasive Computing Technologies for Healthcare , 390 – 393 . PervasiveHealth ‘ 14 . ICST , Brussels , Belgium , Belgium : ICST ( Institute for Computer Sciences , Social - References 258 Informatics and Telecommunications Engineering ) . https : / / doi . org / 10 . 4108 / icst . pervasivehealth . 2014 . 255361 . Guía , Elena de la , María Lozano , and Victor R . Penichet . 2013 . “TrainAb : A Solution Based on Tangible and Distributed User Interfaces to Improve Cognitive Disabilities . ” In CHI ‘ 13 Extended Abstracts on Human Factors in Computing Systems , 3039 – 3042 . CHI EA ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2468356 . 2479605 . Haber , Jonathan , Miguel A . Nacenta , and Sheelagh Carpendale . 2014 . “Paper vs . Tablets : The Effect of Document Media in Co - Located Collabora tive Work . ” In Proceedings of the 2014 International Working Conference on Advanced Visual Interfaces , 89 – 96 . AVI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2598153 . 2598170 . Hagedorn , Joey , Joshua Hailpern , and Karrie G . Karahalios . 2008 . “VCode and VData : Illustrating a New Framework for Supporting the Video Annotation Workflow . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 317 – 321 . ACM . https : / / doi . org / 10 . 1145 / 1385569 . 1385622 . Hall , Edward Twitchell . 1969 . The Hidden Dimension . Anchor Books New York . Haller , Michael , Jakob Leitner , Thomas Seifried , James R . Wallace , Stacey D . Scott , Christoph Richter , Peter Brandl , Adam Gokcezade , and Seth Hunter . 2010 . “The NiCE Discussion Room : Integrating Paper and Digital Media to S upport Co - Located Group Meetings . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 609 – 618 . CHI ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1753326 . 1753418 . Hamilton , Peter , and Daniel J . Wigdor . 2014 . “Conductor : En abling and Understanding Cross - Device Interaction . ” In Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems , 2773 – 2782 . CHI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2556288 . 2557170 . Han , Richard , Veronique Perret , and Mahmoud Naghshineh . 2000 . “WebSplitter : A Unified XML Framework for Multi - Device Collaborative Web Browsing . ” In Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work , 221 – 230 . CSCW ‘ 00 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 358916 . 358993 . Hansen , Preben , and Kalervo Järvelin . 2005 . “Collaborative Information Retrieval in an Information - Intensive Domain . ” Information Processing & Management 41 ( 5 ) : 1101 – 19 . https : / / doi . org / 10 . 1016 / j . ipm . 2004 . 04 . 016 . Hardy , Robert . 2008 . “Touch & Interact : Touch - Based Interaction of Mobile Phones with Displays . ” In Proceedings of the 10th International Conference on Human Computer Interaction with Mobile Devices and Services , edited by Rukzio , Enrico , 245 – 54 . MobileHCI ‘ 08 . Amsterdam , the Netherlands : ACM . https : / / doi . org / 978 - 1 - 59593 - 952 - 4 / 08 / 09 . Harman . n . d . “Soundcraft Ui24R . ” Soundcraft - Professional Audio Mixers . Accessed September 15 , 2017 . http : / / www . soundcraft . com / products / ui24r . Harper , Richard , Tom Rodden , Yvonne Rogers , and Abigail Sellen . 2008 . Being Human . Human - Computer Interaction in the Year 2020 . Microsoft Research Ltd . Harper , Richard , and Abigail Sellen . 1995 . “Collaborative Tools and the Practicalities of Professional Work at the International Monetary Fund . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 122 – 129 . CHI ‘ 95 . New References 259 York , NY , USA : ACM Press / Addison - Wesley Publishing Co . https : / / doi . org / 10 . 1145 / 223904 . 223920 . Hartmann , Björn , Michel Beaudouin - Lafon , and Wendy E . Mackay . 2013 . “Hy draScope : Creating Multi - Surface Meta - Applications Through View Synchronization and Input Multiplexing . ” In Proceedings of the 2nd ACM International Symposium on Pervasive Displays , 43 – 48 . PerDis ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2491568 . 2491578 . Hashem , Tanzima , Sukarna Barua , Mohammed Eunus Ali , Lars Kulik , and Egemen Tanin . 2015 . “Efficient Computation of Trips with Friends and Families . ” In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management , 931 – 940 . CIKM ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2806416 . 2806433 . Hassan , Nabeel , Md Mahfuzur Rahman , Pourang Irani , and Peter Graham . 2009 . “Chucking : A One - Handed Document Sharing Technique . ” In Human - Computer Interaction – INTERACT 2009 , 264 – 278 . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 978 - 3 - 642 - 03658 - 3 _ 33 . Hazas , Mike , Christian Kray , Hans Gellersen , Henoc Agbota , Gerd Kortuem , and Albert Krohn . 2005 . “A Relative Positioning System for Co - Located Mobile Devices . ” In Proceedings of the 3rd International Conference on Mobile Systems , Applications , and Services , 177 – 190 . MobiSys ‘ 05 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1067170 . 1067190 . Heer , Jeffrey , and Maneesh Agrawala . 2008 . “Design Considerations for Collaborative Visual Analytics . ” Information Visualization 7 ( 1 ) : 49 – 62 . https : / / doi . org / 10 . 1057 / palgrave . ivs . 9500167 . Hertzum , Morten . 2008 . “Collaborative Information Seeking : The Combined Activity of Information Seeking and Collaborative Grounding . ” Information Processing & Management , Evaluating Exploratory Search SystemsDigital Libraries in the Context of Users ’ Broader Activities , 44 ( 2 ) : 957 – 62 . https : / / doi . org / 10 . 1016 / j . ipm . 2007 . 03 . 007 . Hesselmann , Tobias , Niels Henze , and Susanne Boll . 2010 . “FlashLight : Optical Communication Between Mobile Phones and Interactive Tabletops . ” In ACM International Conference on Interactive Tabletops and Surfaces , 135 – 138 . ITS ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1936652 . 1936679 . Hightower , J . , and G . Borriello . 2001 . “Location Systems for Ubiquitous Computing . ” Computer 34 ( 8 ) : 57 – 66 . https : / / doi . org / 10 . 1109 / 2 . 940014 . Hilliges , Otmar , Lucia Terrenghi , Sebastian Boring , David Kim , Hendrik Richter , and Andreas Butz . 2007 . “Designing for Collaborative Creative Problem Solving . ” In Proceedings of the 6th ACM SIGCHI Conference on Creativity & Cognition , 137 – 146 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1254980 . Hinckley , Ken . 2003 . “Synchronous Gestures for Multiple Persons and Computers . ” In Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology , 149 – 158 . UIST ‘ 03 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 964696 . 964713 . Hinckley , Ken , Morgan Dixon , Raman Sarin , Francois Guimbretiere , and Ravin Balakrishnan . 2009 . “Codex : A Dual Screen Tablet Computer . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1933 – 1942 . CHI ‘ 09 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1518701 . 1518996 . References 260 Hinckley , Ken , Gonzalo Ramos , Francois Guimbretiere , Patrick Baudisch , and Marc Smith . 2004 . “Stitching : Pen Gestures That Span Multiple Displays . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 23 – 31 . AVI ‘ 04 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 989863 . 989866 . Holmquist , Lars Erik , Friedemann Mattern , Bernt Schiele , Petteri Alahuhta , Michael Beigl , and Hans - Werner Gellersen . 2001 . “Smart - Its Friends : A Technique for Users to Easily Establish Connections Between Smart Artefacts . ” In Proceedings of the 3rd International Conference on Ubiquitous Computing , 116 – 122 . UbiComp ‘ 01 . London , UK , UK : Springer - Verlag . http : / / dl . acm . org / citation . cfm ? id = 647987 . 741340 . Holz , Christian , and Patrick Baudisch . 2013 . “Fiberio : A Touchscreen That Senses Fingerprints . ” In Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology , 41 – 50 . UIST ‘ 13 . ACM . https : / / doi . org / 10 . 1145 / 2501988 . 2502021 . Homaeian , Leila , Nippun Goyal , James R . Wallace , and Stacey D . Scott . 2017 . “Investigating Communication Grounding in Cross - Surface Interaction . ” In Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces , 348 – 353 . ISS ‘ 17 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3132272 . 3132282 . ——— . 2018 . “Group vs Individual : Impact of TOUCH a nd TILT Cross - Device Interactions on Mixed - Focus Collaboration . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 73 : 1 – 73 : 13 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173647 . Hon , Tsz - Kin , Lin Wang , Joshua D . Reiss , and Andrea Cavallaro . 2015 . “Audio Fingerprinting for Multi - Device Self - Localization . ” IEEE / ACM Trans . Audio , Speech and Lang . Proc . 23 ( 10 ) : 1623 – 1636 . https : / / doi . org / 10 . 1109 / TASLP . 2015 . 2442417 . Horak , Tom , Sriram Karthik Badam , Niklas Elmqvist , and Raimund Dachselt . 2018 . “When David Meets Goliath : Combining Smartwatches with a Large Vertical Display for Visual Data Exploration . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 19 : 1 – 19 : 13 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173593 . Hornecker , Eva . 2002 . “Understanding the Benefits of Graspable Interfaces for Cooperative Use . ” In COOP , 71 – 87 . COOP ‘ 02 . http : / / books . google . com / books ? hl = en & lr = & id = AtPrRVIKNEAC & oi = fnd & pg = PA71 & dq = % 22evidence + supports + most + elements + from + the + described % 22 + % 22in + MIT % E2 % 80 % 99 + tangible + media + projects + % 5B23 , + 43 % 5D , + Raut erbergs + BUILD - IT + system + % 5B15 % 5D , + the % 22 + % 22onlookers . + This + representational + fun ction + of + graspable + interfaces + distinguishes + them + from % 22 + & ots = - GETOTdJjB & sig = F8qWDn18l1rf6VKXJKhU22JA6pI . Hornecker , Eva , Paul Marshall , Nick Sheep Dalton , and Yvonne Rogers . 2008 . “Collaboration and Interference : Awareness with Mice or Touch Input . ” In Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work , 167 – 176 . CSCW ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1460563 . 1460589 . Houben , Steven , and Jakob E . Bardram . 2013 . “ActivityDesk : Multi - Device Configuration Work Using an Interactive Desk . ” In CHI ‘ 13 Extended Abstracts References 261 on Human Factors in Computing Systems , 721 – 726 . CHI EA ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2468356 . 2468484 . Houben , Steven , and Nicolai Marquardt . 2015 . “WatchConnect : A Toolkit for Prototyping Smartwatch - Centric Cross - Device Applications . ” In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , 1247 – 56 . CHI ‘ 15 . ACM . https : / / doi . org / 10 . 1145 / 2702123 . 2702215 . Houben , Steven , Nicolai Marquardt , Jo Vermeulen , Clemens Klokmose , Johannes Schöning , Harald Reiterer , and C hristian Holz . 2017 . “Opportunities and Challenges for Cross - Device Interactions in the Wild . ” Interactions 24 ( 5 ) : 58 – 63 . https : / / doi . org / 10 . 1145 / 3121348 . Houben , Steven , Paolo Tell , and Jakob E . Bardram . 2014 . “ActivitySpace : Managing Device Ecologies in an Activity - Centric Configuration Space . ” In Proceedings of the Ninth ACM International Conference on Interactive Tabletops and Surfaces , 119 – 28 . ITS ‘ 14 . ACM . https : / / doi . org / 10 . 1145 / 2669485 . 2669493 . Hu , Gang , Derek Reilly , Mohammed Alnusayri , Ben Swinden , and Qigang Gao . 2014 . “DT - DT : Top - down Human Activity Analysis for Interactive Surface Applications . ” In Proceedings of the Ninth ACM International Conference on Interactive Tabletops & Surfaces , 167 – 176 . ITS ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2669485 . 2669501 . Hu , N . , G . Englebienne , and B . Kröse . 2013 . “Posture Recognition with a Top - View Camera . ” In 2013 IEEE / RSJ International Conference on Intelligent Robots and Systems , 2152 – 57 . https : / / doi . org / 10 . 1109 / IROS . 2013 . 6696657 . Huang , Elai ne M . , Elizabeth D . Mynatt , and Jay P . Trimble . 2007 . “When Design Just Isn ’ t Enough : The Unanticipated Challenges of the Real World for Large Collaborative Displays . ” Personal Ubiquitous Comput . 11 ( 7 ) : 537 – 547 . https : / / doi . org / 10 . 1007 / s00779 - 006 - 0114 - 3 . Husmann , Maria . 2017 . “Investigating Tool Support for Cross - Device Development . ” PhD Thesis , ETH Zurich . Husmann , Maria , Nicola Marcacci Rossi , and Moira C . Norrie . 2016 . “Usage Analysis of Cross - Device Web Applications . ” In Proceedings of the 5th ACM International Symposium on Pervasive Displays , 212 – 219 . PerDis ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2914920 . 2915017 . Hutchings , Dugald Ralph , Greg Smith , Brian Meyers , Mary Czerwinski , and George Robertson . 2004 . “Display Space Usage and Window Management Operation Comparisons Between Single Monitor and Multiple Monitor Users . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 32 – 39 . AVI ‘ 04 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 989863 . 989867 . Hutchings , Dugald R alph , John Stasko , and Mary Czerwinski . 2005 . “Distributed Display Environments . ” Interactions 12 ( 6 ) : 50 – 53 . https : / / doi . org / 10 . 1145 / 1096554 . 1096592 . Isenberg , Petra , Danyel Fisher , Paul Sharoda A . , Meredith Ringel Morris , Kori Inkpen , and Mary Czerwinski . 2012 . “Co - Located Collaborative Visual Analytics Around a Tabletop Display . ” IEEE Transactions on Visualization and Computer Graphics 18 ( 5 ) : 689 – 702 . http : / / dx . doi . org / 10 . 1109 / TVCG . 2011 . 287 . Ishii , Hiroshi , and Brygg Ullmer . 1997 . “Tangible Bits : Towards Seamless Interfaces Between People , Bits and Atoms . ” In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems , 234 – 241 . CHI ‘ 97 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 258549 . 258715 . References 262 Jakobsen , Mikkel R . , and Kasper Hornbæk . 2014 . “Up Close and Personal : Collaborative Work on a High - Resolution Multitouch Wall Display . ” ACM Transactions on Computer - Human Interaction 21 ( 2 ) : 1 – 34 . https : / / doi . org / 10 . 1145 / 2576099 . Jensen , Mads Møller , Roman Rädle , Clemens N . Klokmose , and Susanne Bodker . 2018 . “Remediating a Design Tool : Implications of Digitizing Sticky Notes . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 224 : 1 – 224 : 12 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173798 . Jetter , Hans - Christian , Jens Gerken , Michael Zöllner , Harald Reiterer , and Natasa Milic - Frayling . 2011 . “Materializing the Query with Facet - Streams : A Hybrid Surface for Collaborative Search o n Tabletops . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 3013 – 3022 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979390 . Jetter , Hans - Christian , Florian Geyer , Tobias Schwarz , and Harald Reiterer . 2012 . “Blended Interaction – toward a Framework for the Design of Interactive Spaces . ” In Workshop DCIS . Vol . 12 . Workshop DCIS ‘ 12 . http : / / hci . uni - konstanz . de / downloads / dcis2012 _ Jetter . pdf . Jin , Haojian , Christian Holz , and Kasper Hornbæk . 2015 . “Tracko : Ad - Hoc Mobile 3D Tracking Using Bluetooth Low Energy and Inaudible Signals for Cross - Device Interaction . ” In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology , 147 – 156 . UIST ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2807442 . 2807475 . Johansen , Robert . 1988 . GroupWare : Computer Support for Business Teams . New York , NY , USA : The Free Press . Johanson , Brad , Greg Hutchins , Terry Winograd , and Maureen Stone . 2002 . “PointRight : Experience with Flexible Input Redirection in Interactive Workspaces . ” In Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology , 227 – 234 . UIST ‘ 02 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 571985 . 572019 . Johanson , Brad , Shankar Ponnekanti , Caesar Sengupta , and Armando Fox . 2001 . “Multibrowsing : Moving Web Content Across Multiple Displays . ” In Proceedings of the 3rd International Conference on Ubiquitous Computing , 346 – 353 . UbiComp ‘ 01 . London , UK , UK : Springer - Verlag . http : / / dl . acm . org / citation . cfm ? id = 647987 . 741346 . Jordan , Brigitte , and Austin Henderson . 1995 . “Interaction Analysis : Foundations and Practice . ” Journal of the Learning Sciences 4 ( 1 ) : 39 – 103 . https : / / doi . org / 10 . 1207 / s15327809jls0401 _ 2 . Ju , Wendy , Brian A . Lee , and Scott R . Klemmer . 2008 . “Range : Exploring Implicit Interaction through Electronic Whiteboard Design . ” In Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work , 17 – 26 . https : / / doi . org / 10 . 1145 / 1460563 . 1460569 . Kay , Alan , and Adina Goldberg . 1977 . “Personal Dynamic Media . ” Computer , Computer , 10 ( 3 ) : 31 – 41 . Kendon , Adam . 2010 . “Spacing and Orientation in Co - Present Interaction . ” In Development of Multimodal Interfaces : Active Listening and Synchrony , 1 – 15 . Lecture Notes in Computer Science . Springer , Berlin , Heidelberg . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 12397 - 9 _ 1 . References 263 Kharrufa , Ahmed , James Nicholson , Paul Dunphy , Steve Hodges , Pam Briggs , and Pat rick Olivier . 2015 . “Using IMUs to Identify Supervisors on Touch Devices . ” In Human - Computer Interaction – INTERACT 2015 , edited by Julio Abascal , Simone Barbosa , Mirko Fetter , Tom Gross , Philippe Palanque , and Marco Winckler , 565 – 83 . Lecture Notes in Computer Science 9297 . Springer International Publishing . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 22668 - 2 _ 44 . Kim , Jungsoo , Jiasheng He , Kent Lyons , and Thad Starner . 2007 . “The Gesture Watch : A Wireless Contact - Free Gesture Based Wrist Interface . ” In 11th IEEE International Symposium on Wearable Computers , 15 – 22 . ISWC ‘ 07 . IEEE . http : / / ieeexplore . ieee . org / xpls / abs _ all . jsp ? arnumber = 4373770 . Kister , U . , K . Klamka , C . Tominski , and R . Dachselt . 2017 . “GraSp : Combining Spatially - Aware Mobile Devices and a Display Wall for Graph Visualization and Interaction . ” Computer Graphics Forum 36 ( 3 ) : 503 – 514 . https : / / doi . org / 10 . 1111 / cgf . 13206 . Klaassen , Randy , Rieks op den Akker , and Harm op den Akker . 2013 . “Feedback Presentation for Mobile Personalised Digital Physical Activity Coaching Platforms . ” In Proceedings of the 6th International Conference on PErvasive Technologies Related to Assistive Environments , 64 : 1 – 64 : 8 . PETRA ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2504335 . 2504404 . Klokmose , Clemens N . , James R . Eagan , Siemen Baader , Wendy Mackay , and Michel Beaudouin - Lafon . 2015 . “Webstrates : Shareable Dynamic Media . ” In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology ( UIST ‘ 15 ) , 280 – 90 . ACM Press . https : / / doi . org / 10 . 1145 / 2807442 . 2807446 . Klokmose , Clemens Nylandsted , and Michel Beaudouin - Lafon . 2009 . “VIGO : Instrumental Interaction in Multi - Surface Environments . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 869 – 878 . CHI ‘ 09 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1518833 . Kreitmayer , Stefan , Yvonne Rogers , Robin Laney , and Stephen Peake . 2013 . “UniPad : Orchestrating Collaborative Activities Through Shared Tablets and an Integrated Wall Display . ” In Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing , 801 – 810 . UbiComp ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2493432 . 2493506 . Kruger , Russell , Sheelagh Carpendale , Stacey D . Scott , and Saul Greenberg . 2003 . “How People Use Orientation on Tables : Co mprehension , Coordination and Communication . ” In Proceedings of the 2003 International ACM SIGGROUP Conference on Supporting Group Work , 369 – 378 . ACM . http : / / dl . acm . org / citation . cfm ? id = 958219 . Kubitza , Thomas . 2016 . “Apps for Environments : Demonstrating Pl uggable Apps for Multi - Device IoT - Setups . ” In Proceedings of the 6th International Conference on the Internet of Things , 185 – 186 . IoT ’ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2991561 . 2998473 . Kubo , Yuki , Ryosuke Takada , Buntarou Shizuki , and Shin Takahashi . 2017 . “Exploring Context - Aware User Interfaces for Smartphone - Smartwatch Cross - Device Interaction . ” Proc . ACM Interact . Mob . Wearable Ubiquitous Technol . 1 ( 3 ) : 69 : 1 – 69 : 21 . https : / / doi . org / 10 . 1145 / 3130934 . Laan , Michael van der , Ron Kellet , Cynthia Girling , Maged Senbel , and Tao Su . 2013 . “A Collaborative Multi - Touch , Multi - Display , Urban Futures Tool . ” In Proceedings of the Symposium on Simulation for Architecture & Urban Design , 10 : 1 – 10 : 4 . References 264 SimAUD ‘ 13 . San Diego , CA , USA : Society for Computer Simulation International . http : / / dl . acm . org / citation . cfm ? id = 2500004 . 2500014 . Lander , Christian , Sven Gehring , Antonio Krüger , Sebastian Boring , and Andreas Bulling . 2015 . “GazeProjector : Accurate Gaze Estimation and Seamless Gaze Interaction Across Multipl e Displays . ” In Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology , 395 – 404 . UIST ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2807442 . 2807479 . Langner , R . , T . Horak , and R . Dachselt . 2018 . “VisTiles : Coordinatin g and Combining Co - Located Mobile Devices for Visual Data Exploration . ” IEEE Transactions on Visualization and Computer Graphics , InfoVis ‘ 17 , 24 ( 1 ) : 626 – 36 . https : / / doi . org / 10 . 1109 / TVCG . 2017 . 2744019 . Ledo , David , Steven Houben , Jo Vermeulen , Nicolai Marquardt , Lora Oehlberg , and Saul Greenberg . 2018 . “Evaluation Strategies for HCI Toolkit Research . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 36 : 1 – 36 : 17 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173610 . Li , Ming , and Leif Kobbelt . 2012 . “Dynamic Tiling Display : Building an Interactive Display Surface Using Multiple Mobile Devices . ” In Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia , 24 : 1 – 24 : 4 . MUM ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2406367 . 2406397 . Liang , Hai - Ning , Cary Williams , Myron Semegen , Wolfgang Stuerzlinger , and Pourang Irani . 2012 . “User - Defined Surface + Motion Gestures for 3D Manipulation of Objects at a Distance Through a Mobile Dev ice . ” In Proceedings of the 10th Asia Pacific Conference on Computer Human Interaction , 299 – 308 . APCHI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2350046 . 2350098 . Lin , S . C . , A . S . Liu , T . W . Hsu , and L . C . Fu . 2015 . “Representative Body Points on Top - View Depth Sequences for Daily Activity Recognition . ” In 2015 IEEE International Conference on Systems , Man , and Cybernetics , 2968 – 73 . https : / / doi . org / 10 . 1109 / SMC . 2015 . 516 . Lord , Philip , and Alison Macdonald . 2003 . “E - Science Curation Report . ” JISC Committee for the Support of Research . http : / / citeseerx . ist . psu . edu / viewdoc / download ? doi = 10 . 1 . 1 . 96 . 5156 & rep = rep1 & type = pdf . Lucero , Andrés , Jussi Holopainen , and Tero Jokela . 2011 . “Pass - Them - around : Collaborative Use of Mobile Phones for Photo Sharing . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1787 – 1796 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979201 . ——— . 2012 . “ MobiComics : Collaborative Use of Mobile Phones and Large Displays for Public Expression . ” In Proceedings of the 14th International Conference on Human - Computer Interaction with Mobile Devices and Services , 383 – 392 . MobileHCI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2371574 . 2371634 . Lucero , Andrés , Jaakko Keränen , and Hannu Korhonen . 2010 . “Collaborative Use of Mobile Phones for Brainstorming . ” In Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services , 337 – 340 . MobileHCI ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1851600 . 1851659 . References 265 Luff , Paul , and Christian Heath . 1998 . “Mobility in Collaboration . ” In Proceedings of the 1998 ACM Conference on Computer Supported Cooperative Work , 305 – 314 . CSCW ‘ 98 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 289444 . 289505 . Lyons , Leilah , Joseph Lee , Christopher Quintana , and Elliot Soloway . 2006 . “MUSHI : A Multi - Device Framework for Collaborative Inquiry Learning . ” In Proceedings of the 7th International Conference on Learning Sciences , 453 – 459 . ICLS ‘ 06 . Bloomington , Indiana : International Society of the Learning Sciences . http : / / dl . acm . org / citation . cfm ? id = 1150034 . 1150100 . Majid , Abdul , Ling Chen , Gencai Chen , Hamid Turab Mirza , and Ibrar Hussain . 2012 . “GoThere : Travel Suggestions Using Geotagged Photos . ” In Proceedings of the 21st International Conference on World Wide Web , 577 – 578 . WWW ‘ 12 Companion . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2187980 . 2188135 . Mäkelä , Ville , Mohamed Khamis , Lukas Mecke , Jobin James , Markku Turunen , and Florian Alt . 2018 . “Pocket Transf ers : Interaction Techniques for Transferring Content from Situated Displays to Mobile Devices . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 135 : 1 – 135 : 13 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173709 . Mano , Yoshihisa , Kazuhito Omaki , and Koji Torii . 1981 . “An Intelligent Multi - Display Terminal System Towards : A Better Programming Environment . ” SIGSOFT Softw . Eng . Notes 6 ( 2 ) : 8 – 14 . https : / / doi . org / 10 . 1145 / 1010865 . 1010866 . Mark , Gloria , Jörg M . Haake , and Norbert A . Streitz . 1997 . “Hypermedia Use in Group Work : Changing the Product , Process , and Strategy . ” Computer Supported Cooperative Work ( CSCW ) 6 ( 4 ) : 327 – 368 . Marquardt , Nicolai . n . d . “SurfaceConstellations Github Repository . ” Accessed January 1 , 2018 . https : / / github . com / nicmarquardt / surfaceconstellations . Marquardt , Nicolai , Till Ballendat , Sebastian Boring , Saul Greenberg , and Ken Hinckley . 2012 . “Gradual Engagement : Facilitating Information Exchange Between Digital Devices As a Function of Proximity . ” In Proceedings of the 2012 ACM International Conference on Interactive Tabletops & Surfaces , 31 – 40 . ITS ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2396636 . 2396642 . Marquardt , Nicolai , Frederik Brudy , Can Liu , Ben Bengler , and Christian Holz . 2018 . “SurfaceConstellations : A Modular Hardware Platform for Ad - Hoc Reconfigurable Cross - Device Workspaces . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 354 : 1 – 354 : 14 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3173928 . Marquardt , Nicolai , Robert Diaz - Marino , Sebastian Boring , and Saul Greenberg . 2011 . “The Proximity Toolkit : Prototyping Proxemic Interactions in Ubiquitous Computing Ecologies . ” In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology , 315 – 326 . ACM . https : / / doi . org / 10 . 1145 / 2047196 . 2047238 . Marquardt , Nicolai , Ken Hinckley , and Saul Greenberg . 2012 . “Cross - Device Interaction via Micro - Mobility and F - Formations . ” In Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology , 13 – 22 . UIST ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2380116 . 2380121 . Marquardt , Nicolai , Johannes Kiemer , David Ledo , Sebastian Boring , and Saul Greenberg . 2011 . “Designing User - , Hand - , and Handpart - Aware Tabletop Interactions with the TouchID Toolkit . ” In Proceedings of the ACM International References 266 Conference on Interactive Tabletops and Surfaces , 21 – 30 . ITS ‘ 11 . ACM . http : / / dl . acm . org / citation . cfm ? id = 2076358 . Marquardt , Nicolai , Frederico Sc hardong , and Anthony Tang . 2015 . “EXCITE : EXploring Collaborative Interaction in Tracked Environments . ” In Human - Computer Interaction , 89 – 97 . Springer . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 22668 - 2 _ 8 . Marshall , Paul , Yvonne Rogers , and Nadia Pantidi . 2011 . “Us ing F - Formations to Analyse Spatial Patterns of Interaction in Physical Environments . ” In Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work , 445 – 454 . ACM . https : / / doi . org / 10 . 1145 / 1958824 . 1958893 . Masoodian , Masood , Saturnino Luz , and David Kavenga . 2016 . “Nu - View : A Visualization System for Collaborative Co - Located Analysis of Geospatial Disease Data . ” In Proceedings of the Australasian Computer Science Week Multiconference , 48 : 1 – 48 : 10 . ACSW ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2843043 . 2843374 . Mayer , Simon , and Gabor Soros . 2014 . “User Interface Beaming - Seamless Interaction with Smart Things Using Personal Wearable Computers . ” In International Conference on Wearable and Implantable Body Sensor Networks Workshops , 46 – 49 . BSN ‘ 14 . IEEE . https : / / doi . org / 10 . 1109 / BSN . Workshops . 2014 . 17 . Mayrhofer , Rene . 2007 . “Towards an Open Source Toolkit for Ubiquitous Device Authentication . ” In Pervasive Computing and Communications Workshops , 2007 . PerCom Workshops ‘ 07 . Fifth Annual IEEE International Conference On , 247 – 254 . IEEE . Mentis , Helena M . 2017 . “Collocated Use of Imaging Systems in Coordinated Surgical Practice . ” Proc . ACM Hum . - Comput . Interact . 1 ( CSCW ) : 78 : 1 – 78 : 17 . https : / / doi . org / 10 . 1145 / 3134713 . Michelis , Daniel , and Jörg Müller . 2011 . “The Audience Funnel : Observations of Gesture Based Interaction With Multiple Large Displays in a City Center . ” International Journal of Human – Computer Interaction 27 ( 6 ) : 562 – 79 . https : / / doi . org / 10 . 1080 / 10447318 . 2011 . 555299 . Moghaddam , Roshanak Zilouchian , and Brian Bailey . 2011 . “VICPAM : A Visualization Tool for Examining Interaction Data in Multiple Display Environments . ” In Symposium on Human Interface , 278 – 287 . Springer . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 21793 - 7 _ 32 . Nacenta , Miguel A . , Dzmitry Aliakseyeu , Sriram Subramanian , and Carl Gutwin . 2005 . “A Comparison of Techniques for Multi - Display Reaching . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 371 – 380 . CHI ‘ 05 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1054972 . 1055024 . Nacenta , Miguel A . , Mikkel R . Jakobsen , Remy Dautriche , Uta Hinrichs , Marian Dörk , Jonathan Haber , and Sheelagh Carpendale . 2012 . “The LunchTable : A Multi - User , Multi - Display System for Information Sharing in Casual Group Inter actions . ” In Proceedings of the 2012 International Symposium on Pervasive Displays , 18 : 1 – 18 : 6 . PerDis ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2307798 . 2307816 . Nacenta , Miguel A . , Regan L . Mandryk , and Carl Gutwin . 2008 . “Targeting Across Displ ayless Space . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 777 – 786 . CHI ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1357054 . 1357178 . References 267 Nacenta , Miguel A . , Satoshi Sakurai , Tokuo Yamaguchi , Yohei Miki , Yuichi Itoh , Yoshifumi Kitamura , Sriram Subramanian , and Carl Gutwin . 2007 . “E - Conic : A Perspective - Aware Interface for Multi - Display Environments . ” In Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology , 279 – 288 . UIST ‘ 07 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1294211 . 1294260 . Nacenta , Miguel A . , Samer Sallam , Bernard Champoux , Sriram Subramanian , and Carl Gutwin . 2006 . “Perspective Cursor : Perspective - Based Interaction for Multi - Display Environments . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 289 – 298 . CHI ‘ 06 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1124772 . 1124817 . Neate , Timothy , Matt Jones , and Michael Evans . 2017 . “Cross - Device Media : A Review of Second Screening and Multi - Device Television . ” Personal Ubiquitous Comput . 21 ( 2 ) : 391 – 405 . https : / / doi . org / 10 . 1007 / s00779 - 017 - 1016 - 2 . Nebeling , Michael . 2017 . “XDBrowser 2 . 0 : Semi - Automatic Generation of Cross - Device Interfaces . ” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , 4574 – 4584 . CHI ‘ 17 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3025453 . 3025547 . Nebeling , Michael , Maria Husmann , Christoph Zimmerli , Giulio Valente , and Moira C . Norrie . 2015 . “XDSession : Integrated Development and Testing of Cross - Device Applications . ” In Proceedings of the 7th ACM SIGCHI Symposium on Engineering Interactive Computing Systems , 22 – 27 . EICS ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2774225 . 2775075 . Nielsen , Heidi Selmer , Marius Pallisgaard Olsen , Mikael B . Skov , and Jesper Kjeldskov . 2014 . “JuxtaPinch : Exploring Multi - Device Interaction in Collocated Photo Sharing . ” In Proceedings of the 16th International Conference on Human - Computer Interaction with Mobile Devices & Services , 183 – 192 . MobileHCI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2628363 . 2628369 . Nielsen , Jakob . 1994 . “Usability Inspection Methods . ” In Conference Companion on Human Factors in Computing Systems , 413 – 414 . CHI ‘ 94 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 259963 . 260531 . Nvivo . 2017 . “Nvivo , Www . Qsrinternational . Com . ” Nvivo . 2017 . http : / / www . qsrinternational . com / . Obrist , Hans Ulrich . 2015 . Ways of Curating . Penguin . Ohta , Takashi , and Jun Tanaka . 2012 . “Pinch : An Interface That Relates Applications on Multiple Touch - Screen by ` Pinching ’ Gestu re . ” In Advances in Computer Entertainment : 9th International Conference , ACE 2012 , Kathmandu , Nepal , November 3 - 5 , 2012 . Proceedings , edited by Anton Nijholt , Teresa Romão , and Dennis Reidsma , 320 – 335 . Berlin , Heidelberg : Springer Berlin Heidelberg . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 34292 - 9 _ 23 . Oleksik , Gerard , Hans - Christian Jetter , Jens Gerken , Natasa Milic - Frayling , and Rachel Jones . 2013 . “Towards an Information Architecture for Flexible Reuse of Digital Media . ” In Proceedings of the 12th International Conference on Mobile and Ubiquitous Multimedia , 12 : 1 – 12 : 10 . MUM ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2541831 . 2541866 . References 268 Olsen , Dan R . , Jr . 2007 . “Evaluating User Interface Systems Research . ” In Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology , 251 – 258 . UIST ‘ 07 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1294211 . 1294256 . Oskamp , Matthew , Christophe Bortolaso , Robin Harrap , and T . C . Nicholas Graham . 2015 . “TerraGuide : Design and Evaluation of a Multi - Surface Environment for Terrain Visibility Analysis . ” In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , 3553 – 3562 . CHI ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2702123 . 2702480 . Oulasvirta , Antti . 2008 . “FEA TURE : When Users ‘ Do ’ the Ubicomp . ” Interactions 15 ( 2 ) : 6 – 9 . https : / / doi . org / 10 . 1145 / 1340961 . 1340963 . Oulasvirta , Antti , and Kasper Hornbæk . 2016 . “HCI Research As Problem - Solving . ” In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , 4956 – 4967 . CHI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2858036 . 2858283 . Oulasvirta , Antti , and Lauri Sumari . 2007 . “Mobile Kits and Laptop Trays : Managing Multiple Devices in Mobile Information Work . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1127 – 1136 . CHI ‘ 07 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1240624 . 1240795 . Pasquero , Jerome , Scott J . Stobbe , and Noel Stonehouse . 2011 . “A Haptic Wristwatch for Eyes - Free Interactions . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 3257 – 3266 . CHI ‘ 11 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1979425 . Paul , Sharoda A . , and Madhu C . Reddy . 2010 . “Understanding Together : Sensemaking in Collaborative Information Seeking . ” In Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work , 321 – 330 . CSCW ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1718918 . 1718976 . Pearson , Jennifer , Simon Robinson , and Matt Jones . 2015 . “It’ s About Time : Smartwatches as Pu blic Displays . ” In Roceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , 1257 – 66 . CHI ‘ 15 . ACM . https : / / doi . org / 10 . 1145 / 2702123 . 2702247 . Peng , Chunyi , Guobin Shen , Yongguang Zhang , Yanlin Li , and Kun Tan . 2007 . “BeepBeep : A Hi gh Accuracy Acoustic Ranging System Using COTS Mobile Devices . ” In Proceedings of the 5th International Conference on Embedded Networked Sensor Systems , 1 – 14 . SenSys ‘ 07 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1322263 . 1322265 . Petford , Julian , Mig uel A . Nacenta , and Carl Gutwin . 2018 . “Pointing All Around You : Selection Performance of Mouse and Ray - Cast Pointing in Full - Coverage Displays . ” In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 533 : 1 – 533 : 14 . CHI ‘ 18 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3173574 . 3174107 . Pietroszek , Krzysztof , and Edward Lank . 2012 . “Clicking Blindly : Using Spatial Correspondence to Select Targets in Multi - Device Environments . ” In Proceedings of the 14th International Conference on Human - Computer Interaction with Mobile Devices and Services , 331 – 334 . MobileHCI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2371574 . 2371625 . Pirolli , Peter , and Stuart Card . 2005 . “The Sensemaking Process and Leverage Points for Analyst Technolog y as Identified through Cognitive Task Analysis . ” In Proceedings of International Conference on Intelligence Analysis , 5 : 2 – 4 . Int . Conference References 269 on Intelligent Analysis . http : / / vadl . cc . gatech . edu / documents / 2 _ _ card - sensemaking . pdf . Pizza , Stefania , Barry Brown , Donald McMillan , and Airi Lampinen . 2016 . “Smartwatch in Vivo . ” In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , 5456 – 69 . CHI ‘ 16 . ACM . https : / / doi . org / 10 . 1145 / 2858036 . 2858522 . Plank , Thomas , Hans - Christian Jetter , Roman Rädle , Clemens N . Klokmose , Thomas Luger , and Harald Reiterer . 2017 . “Is Two Enough ? : ! Studying Benefits , Barriers , and Biases of Multi - Tablet Use for Collaborative Visualization . ” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , 4548 – 4560 . CHI ‘ 17 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3025453 . 3025537 . Plaue , Christopher , and John Stasko . 2009 . “Presence & Placement : Exploring the Benefits of Multiple Shared Displays on an Intellective Sensemaking Task . ” In Proceedings of the ACM 2009 International Conference on Supporting Group Work , 179 – 188 . GROUP ‘ 09 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1531674 . 1531701 . Prante , Thorsten , Richard Stenzel , Carsten Röcker , Norbert Streitz , and Carsten Magerkurth . 2004 . “Ambient Agoras : InfoRiver , SIAM , Hello . Wall . ” In CHI ‘ 04 Extended Abstracts on Human Factors in Computing Systems , 763 – 764 . CHI EA ‘ 04 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 985921 . 985924 . Pyöriä , Pasi . 2005 . “The Concept of Knowledge Work Revisited . ” Journal of Knowledge Management , June . https : / / doi . org / 10 . 1108 / 13673270510602818 . Qiu , Jian , David Chu , Xiangying Meng , and Thomas Moscibroda . 2011 . “On the Feasibility of Real - Time Phone - to - Phone 3D Localization . ” In Proceedings of the 9th ACM Conference on Embedded Networked Sensor Systems , 190 – 203 . SenSys ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2070942 . 2070962 . Rädle , Roman , Hans - Christian Jetter , Nicolai Marquardt , Harald Reiterer , and Yvonne Rogers . 2014 . “HuddleLamp : Spatially - Aware Mobile Displays for Ad - Hoc Around - the - Table Collaboration . ” In Proceedings of the Ninth ACM International Conference on Interactive Tabletops & Surfaces , 45 – 54 . ITS ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2669485 . 2669500 . Rädle , Roman , Hans - Christian Jetter , Mario Schreiner , Zhihao Lu , Harald Reiterer , and Yvonne Rogers . 2015 . “Spatially - Aware or Spatially - Agnostic ? : Elicitation and Evaluation of User - Defined Cross - Device Interactions . ” In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , 3913 – 3922 . CHI ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2702123 . 2702287 . Raptis , Dimitrios , Jesper Kjeldskov , and Mikael B . Skov . 2016 . “Continuity in Multi - Device Interaction : An Online Study . ” In Proceedings of the 9th Nordic Conference on Human - Computer Interaction , 29 : 1 – 29 : 10 . NordiCHI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2971485 . 2971533 . Rashid , Umar , Miguel A . Nacenta , and Aaron Quigley . 2012a . “Factors Influencing Visual Attention Switch in Multi - Display User Interfaces : A Survey . ” In Proceedings of the 2012 International Symposium on Pervasive Displays , 1 : 1 – 1 : 6 . PerDis ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2307798 . 2307799 . ——— . 2012b . “The Cost of Display Sw itching : A Comparison of Mobile , Large Display and Hybrid UI Configurations . ” In Proceedings of the International References 270 Working Conference on Advanced Visual Interfaces , 99 – 106 . AVI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2254556 . 2254577 . Reetz , Adrian , Carl Gutwin , Tadeusz Stach , Miguel Nacenta , and Sriram Subramanian . 2006 . “Superflick : A Natural and Efficient Technique for Long - Distance Object Placement on Digital Tables . ” In Proceedings of Graphics Interface 2006 , 163 – 170 . GI ‘ 06 . Toronto , Ont . , Canada , Canada : Canadian Information Processing Society . http : / / dl . acm . org / citation . cfm ? id = 1143079 . 1143106 . Reinhardt , Wolfgang , Benedikt Schmidt , Peter Sloep , and Hendrik Drachsler . 2011 . “Knowledge Worker Roles and Actions— Results of Two Empirical Studie s . ” Knowledge and Process Management 18 ( 3 ) : 150 – 74 . https : / / doi . org / 10 . 1002 / kpm . 378 . Rekimoto , Jun . 1997 . “Pick - and - Drop : A Direct Manipulation Technique for Multiple Computer Environments . ” In Proceedings of the 10th Annual ACM Symposium on User Interface Software and Technology , 31 – 39 . UIST ‘ 97 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 263407 . 263505 . ——— . 2001 . “Gesturewrist and Gesturepad : Unobtrusive Wearable Interaction Devices . ” In Proceedings . Fifth International Symposium on Wearable Computers , 21 – 27 . ISWC ‘ 01 . IEEE . http : / / ieeexplore . ieee . org / xpls / abs _ all . jsp ? arnumber = 962092 . ——— . 2004 . “SyncTap : Synchronous User Operation for Spontaneous Network Connection . ” Personal and Ubiquitous Computing 8 ( 2 ) : 126 – 34 . https : / / doi . org / 10 . 1007 / s00779 - 004 - 0262 - 2 . Rekimoto , Jun , and Masanori Saitoh . 1999 . “Augmented Surfaces : A Spatially Continuous Work Space for Hybrid Computing Environments . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 378 – 385 . CHI ‘ 99 . ACM . http : / / dl . acm . org / citation . cfm ? id = 303113 . Robertson , Scott , Cathleen Wharton , Catherine Ashworth , and Marita Franzke . 1996 . “Dual Device User Interface Design : PDAs and Interactive Television . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 79 – 86 . CHI ‘ 96 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 238386 . 238408 . Rogers , Yvonne . 2006 . “Moving on from Weiser’ s Vision of Calm Computing : Engaging Ubicomp Experiences . ” In UbiComp 2006 : Ubiquitous Computing , 404 – 421 . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 11853565 _ 24 . Rogers , Yvonne , Kay Connelly , Lenore Tedesco , William Hazlewood , Andrew Kurtz , Robert E . Hall , Josh Hursey , and Tammy Toscos . 2007 . Why It ’ s Worth the Hassle : The Value of in - Situ Studies When Designing Ubicomp . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 978 - 3 - 540 - 74853 - 3 _ 20 . Román , Manuel , Christopher Hess , Renato Cerqueira , Anand Ranganathan , Roy H . Campbell , and Klara Nahrstedt . 2002 . “Gaia : A Middleware Platform for Active Spaces . ” SIGMOBILE Mob . Comput . Commun . Rev . 6 ( 4 ) : 65 – 67 . https : / / doi . org / 10 . 1145 / 643550 . 643558 . Rotman , Dana , Kezia Procita , Derek Hansen , Cynthia Sims Parr , and Jennifer Preece . 2012 . “Supporting Content Curation Communities : The Case of the Encyclopedia of Life . ” Journal of the American Society for Information Science and Technology 63 ( 6 ) : 1092 – 1107 . https : / / doi . org / 10 . 1002 / asi . 22633 . Russell , Daniel M . , Mark J . Stefik , Peter Pirolli , and Stuart K . Card . 1993 . “The Cost Structure of Sensemaking . ” In Proceedings of the INTERACT ’ 93 and CHI ’ 93 References 271 Conference on Human Factors in Computing Systems , 269 – 276 . CHI ‘ 93 . ACM . http : / / dl . acm . org / citation . cfm ? id = 169209 . Ryall , Kathy , Clifton Forlines , Chia Shen , and Meredith Ringel Morris . 2004 . “Exploring the Effects of Group Size and Table Size o n Interactions with Tabletop Shared - Display Groupware . ” In Proceedings of the 2004 ACM Conference on Computer Supported Cooperative Work , 284 – 293 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1031654 . Sabharwal , Arjun . 2015 . Digital Curation in the Digital Humanities : Preserving and Promoting Archival and Special Collections . Waltham , MA : Chandos Publishing . Saidi , Houssem , Marcos Serrano , and Emmanuel Dubois . 2016 . “Investigating the Effects of Splitting Detailed Views in Overview + Detail Interfaces . ” In Proceedings of the 18th International Conference on Human - Computer Interaction with Mobile Devices and Services , 180 – 184 . MobileHCI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2935334 . 2935341 . Saidi , Houssem , Marcos Serrano , Pourang Irani , and Emmanuel Dubois . 2017 . “TDome : A Touch - Enabled 6DOF Interactive Device for Multi - Display Environments . ” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , 5892 – 5904 . CHI ‘ 17 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 3025453 . 3025661 . Santosa , Stephanie , and Daniel Wigdor . 2013 . “A Field Study of Multi - Device Workflows in Distributed Workspaces . ” In Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing , 63 . UbiComp ‘ 13 . ACM . https : / / doi . org / 10 . 1145 / 2493432 . 2493476 . Scharf , Florian , Christian Wolters , Michael Herczeg , and Jörg Cassens . 2013 . “Cross - Device Interaction Definition , Taxonomy and Applications . ” In AMBIENT 2013 : The Third International Conference on Ambient Computing , Applications , Services and Technologies , 35 – 40 . IARIA . Schmidt , Dominik , Fadi Chehimi , Enrico Rukzio , and Hans Gellersen . 2010 . “PhoneTouch : A Technique for Direct Phone Interaction on Surfaces . ” In Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology , 13 – 16 . UIST ‘ 10 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1866034 . Schmidt , Dominik , Julian Seifert , Enrico Rukzio , and Hans Gellersen . 2012 . “A Cross - Device Interaction Style for Mobiles and Surfaces . ” In Proceedings of the Designing Interactive Systems Conference , 318 – 327 . DIS ‘ 12 . ACM . http : / / dl . acm . org / citation . cfm ? id = 2318005 . Schneider , Bertrand , Matthew Tobiasz , Charles Willis , and Chia Shen . 2012 . “WALDEN : Multi - Surface Multi - Touch Simulation of Climate Change and Species Loss in Thoreau ’s Woods . ” In Proceedings of the 2012 ACM International Conference on Interactive Tabletops & Surfaces , 387 – 390 . ITS ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2396636 . 2396707 . Schreiner , Mario , Roman Rädle , Hans - Christian Jetter , and Harald Reiterer . 2015 . “Connichiwa : A Framework for Cross - Device Web Applications . ” In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems , 2163 – 2168 . CHI EA ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2702613 . 2732909 . Schwarz , Julia , David Klionsky , Chris Harrison , Paul Dietz , and Andrew Wilson . 2012 . “Phone As a Pixel : Enabling Ad - Hoc , Large - Scale Displays Using Mobile References 272 Devices . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 2235 – 2238 . CHI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2207676 . 2208378 . Scott , Stacey D . , Guillaume Besacier , Julie Tournet , Nippun Goyal , and Michael Haller . 2014 . “Surface Ghosts : Promoting Awareness of Transferred Objects During Pick - and - Drop Transfer in Multi - Surface Environments . ” In Proceedings of the Ninth ACM International Conference on Interactive Tabletops & Surfaces , 99 – 108 . ITS ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2669485 . 2669508 . Scott , Stacey D . , M . Sheelagh T . Carpendale , and Kori M . Inkpen . 2004 . “Territoriality in Collaborative Tabletop Workspaces . ” In Proceedings of the 2004 ACM Conference on Computer Supported Cooperative Work , 294 – 303 . ACM . https : / / doi . org / 10 . 1145 / 1031607 . 1031655 . Scott , Stacey D . , and Sheelagh Carpendale . 2006 . “Investigating Tabletop Territoriality in Digital Tabletop Workspaces . ” http : / / prism . ucalgary . ca / handle / 1880 / 45780 . Seifert , Julian , Adalberto Simeone , Dominik Schmidt , Paul Holleis , Christian Reinartz , Matthias Wagner , Hans Gellersen , and Enrico Rukzio . 2012 . “MobiSurf : Improving Co - Located Collaboration Through Integrating Mobile Devices and Interactive Surfaces . ” In Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces , 51 – 60 . ITS ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2396636 . 2396644 . Sellen , Abigail , and Richard Harper . 2002 . The Myth of the Paperless Office . MIT Press . Serrano , Marcos , Barrett Ens , Xing - Dong Yang , and Pourang Irani . 2015 . “Desktop - Gluey : Augmenting Desktop Environments with Wearable Devices . ” In Proceedings of the 17th International Conference on Human - Computer Interaction with Mobile Devices and Services Adjunct , 1175 – 1178 . MobileHCI ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2786567 . 2794348 . Seyed , Teddy , Chris Burns , Mario Costa Sousa , Frank Maurer , and Anthony Tang . 2012 . “Eliciting Usable Gestures for Multi - Display Environments . ” In Proceedings of the 2012 ACM International Conference on Interactive Tabletops & Surfaces , 41 – 50 . ITS ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2396636 . 2396643 . Seyed , Teddy , Mario Costa Sousa , Frank Maurer , and Anthony Tang . 2013 . “SkyHunter : A Mu lti - Surface Environment for Supporting Oil and Gas Exploration . ” In Proceedings of the 2013 ACM International Conference on Interactive Tabletops & Surfaces , 15 – 22 . ITS ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2512349 . 2512798 . Shami , N . Sadat , Kate Ehrlich , Geri Gay , and Jeffrey T . Hancock . 2009 . “Making Sense of Strangers ’ Expertise from Signals in Digital Artifacts . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 69 – 78 . CHI ‘ 09 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1518701 . 1518713 . Shen , Chia , Katherine Everitt , and Kathleen Ryall . 2003 . “UbiTable : Impromptu Face - to - Face Collaboration on Horizontal Interactive Surfaces . ” In UbiComp 2003 : Ubiquitous Computing , 281 – 288 . UbiComp ‘ 03 . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 978 - 3 - 540 - 39653 - 6 _ 22 . References 273 Shen , Hia , Kathy Ryall , Clifton Forlines , Alan Esenther , Frederic D . Vernier , Katherine Everitt , Mike Wu , et al . 2006 . “Informing the Design of Direct - Touch Tabletops . ” Computer Graphics and Applications , IEEE 26 ( 5 ) : 36 – 46 . Shibata , Hirohito , Junko Ichino , Tomonori Hashiyama , and Shun ’ichi Tano . 2016 . “A Rhythmical Tap Approach for Sending Data Across Devices . ” In Proceedings of the 18th International Conference on Human - Computer Interaction with Mobile Devices and Services Adjunct , 815 – 822 . MobileHCI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2957265 . 2961851 . Sicard , Léo , Aurélien Tabard , Juan David Hincapié - Ramos , and Jakob E . Bardram . 2013 . “Tide : Lightweight Device Composition for Enhancing T abletop Environments with Smartphone Applications . ” In Human - Computer Interaction – INTERACT 2013 , 177 – 194 . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 978 - 3 - 642 - 40498 - 6 _ 13 . Simeone , Adalberto L . , Julian Seifert , Dominik Schmidt , Paul Holleis , Enrico Rukzio , and Hans Gellersen . 2013 . “A Cross - Device Drag - and - Drop Technique . ” In Proceedings of the 12th International Conference on Mobile and Ubiquitous Multimedia , 10 : 1 – 10 : 4 . MUM ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2541831 . 2541848 . Sollich , Hendrik , Ulrich von Zadow , Tobias Pietzsch , Pavel Tomancak , and Raimund Dachselt . 2016 . “Exploring Time - Dependent Scientific Data Using Spatially Aware Mobiles and Large Displays . ” In Proceedings of the 2016 ACM on Interactive Surfaces and Spaces , 349 – 354 . ISS ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2992154 . 2996779 . Spindler , Martin , Wolfgang Büschel , Charlotte Winkler , and Raimund Dachselt . 2014 . “Tangible Displays for the Masses : Spatial Interaction with Handheld Displays by Using Consumer Depth Cameras . ” Personal and Ubiquitous Computing 18 ( 5 ) : 1213 – 25 . https : / / doi . org / 10 . 1007 / s00779 - 013 - 0730 - 7 . Spindler , Martin , Christian Tominski , Heidrun Schumann , and Raimund Dachselt . 2010 . “Tangible Views for Information Visualization . ” In ACM International Conference on Interactive Tabletops and Surfaces , 157 – 166 . ITS ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1936652 . 1936684 . Sternfeld , Joshua . 2010 . “Thinking Archivally : Search and Metadata as Building Blocks for a New Digital Historiogra phy . ” Digital Humanities 2010 2 . http : / / dh2010 . cch . kcl . ac . uk / academic - programme / abstracts / papers / html / ab - 747 . html . Stewart , Dennis D . , and Garold Stasser . 1998 . “The Sampling of Critical , Unshared Information in Decision - Making Groups : The Role of an Infor med Minority . ” European Journal of Social Psychology 28 ( 1 ) : 95 – 113 . https : / / doi . org / 10 . 1002 / ( SICI ) 1099 - 0992 ( 199801 / 02 ) 28 : 1 < 95 : : AID - EJSP847 > 3 . 0 . CO ; 2 - 0 . Streitz , Norbert A . , Jörg Geissler , Torsten Holmer , Shin ’ ichi Konomi , Christian Müller - Tomfelde , Wolfgang Reischl , Petra Rexroth , Peter Seitz , and Ralf Steinmetz . 1999 . “I - LAND : An Interactive Landscape for Creativity and Innovation . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 120 – 127 . CHI ‘ 99 . ACM . http : / / dl . acm . org / citation . cfm ? id = 303010 . Streitz , Norbert A . , Jörg Geißler , Torsten Holmer , Shin ’ ichi Konomi , Christian Müller - Tomfelde , Wolfgang Reischl , Petra Rexroth , Peter Seitz , and Ralf Steinmetz . 1999 . “I - LAND : An Interactive Landscape for Creativity and References 274 Innovation . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 120 – 127 . CHI ‘ 99 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 302979 . 303010 . Streitz , Norbert A . , Petra Rexroth , and Torsten Holmer . 1997 . “Does ‘ Roomware ’ Matter ? ” In Proceedings of the Fifth European Conference on Computer Supported Cooperative Work , 297 – 312 . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 978 - 94 - 015 - 7372 - 6 _ 20 . Tang , Anthony , Saul Greenberg , and Sidney Fels . 2008 . “Exploring Video Streams Using Slit - Tear Vi sualizations . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 191 – 198 . AVI ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1385569 . 1385601 . Tang , Anthony , Michel Pahud , Sheelagh Carpendale , and Bill Buxton . 2010 . “VisTACO : Visualizing Tabletop Collaboration . ” In ACM International Conference on Interactive Tabletops and Surfaces , 29 – 38 . ITS ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1936652 . 1936659 . Tang , Anthony , Melanie Tory , Barry Po , Petra Neumann , and Sheelagh Carpendale . 2006 . “Collaborative Coupling over Tabletop Displays . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1181 – 1190 . ACM . http : / / dl . acm . org / citation . cfm ? id = 1124950 . Tang , John C . 1991 . “Findings from Observational Studies of Collaborative . ” Computer - Supported Cooperative Work and Groupware , 11 – 28 . Tausch , Sarah , Doris Hausen , Ismail Kosan , Andrey Raltchev , and Heinrich Hussmann . 2014 . “ Groupgarden : Supporting Brainstorming Through a Metaphorical Group Mirror on Table or Wall . ” In Proceedings of the 8th Nordic Conference on Human - Computer Interaction : Fun , Fast , Foundational , 541 – 550 . NordiCHI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2639189 . 2639215 . Terrenghi , Lucia , Aaron Quigley , and Alan Dix . 2009 . “A Taxonomy for and Analysis of Multi - Person - Display Ecosystems . ” Personal Ubiquitous Comput . 13 ( 8 ) : 583 – 598 . https : / / doi . org / 10 . 1007 / s00779 - 009 - 0244 - 5 . “The Top 10 Things to Do in London 2016 - TripAdvisor . ” n . d . Accessed September 19 , 2016 . https : / / www . tripadvisor . co . uk / Attractions - g186338 - Activities - London _ England . html . Turner , Jayson , Andreas Bulling , Jason Alexander , and Hans Gellersen . 2014 . “Cross - Device Gaze - Supported Point - to - Point Content Transfer . ” In Proceedings of the Symposium on Eye Tracking Research and Applications , 19 – 26 . ETRA ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2578153 . 2578155 . Uzun , Ersin , Nitesh Saxena , and Arun Kumar . 2011 . “Pairing Devices f or Social Interactions : A Comparative Usability Evaluation . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 2315 – 2324 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979282 . Vatavu , Radu - Daniel , and Jacob O . Wobbrock . 2015 . “Formalizing Agreement Analysis for Elicitation Studies : New Measures , Significance Test , and Toolkit . ” In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems , 1325 – 1334 . CHI ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2702123 . 2702223 . Vermeulen , Jo , Kris Luyten , Elise van den Hoven , and Karin Coninx . 2013 . “Crossing the Bridge over Norman ’ s Gulf of Execution : Revealing Feedforward ’ s True References 275 Identity . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1931 – 1940 . CHI ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2470654 . 2466255 . Viel , Caio Cesar , Erick Lazaro Melo , Maria da Graça Pimentel , and Cesar A . C . Teixeira . 2013 . “Multimedia Multi - Device Educational Presentations Preserved As Interactive Multi - Video Objects . ” In Proceedings of the 19th Brazilian Symposium on Multimedia and the Web , 51 – 58 . WebMedia ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2526188 . 2526211 . Villanueva , Ped ro G . , Ricardo Tesoriero , and Jose A . Gallud . 2014 . “Performance Evaluation of Proxywork . ” In Proceedings of the 2014 Workshop on Distributed User Interfaces and Multimodal Interaction , 42 – 45 . DUI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2677356 . 2677665 . “Vision API - Image Content Analysis . ” 2017 . Google Cloud Platform . 2017 . https : / / cloud . google . com / vision / . Vogel , Daniel , and Ravin Balakrishnan . 2004 . “Interactive Public Ambient Displays : Transitioning from Implicit to Explicit , Public to Personal , Interaction with Multiple Users . ” In Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology , 6 : 137 – 146 . https : / / doi . org / 10 . 1145 / 1029632 . 1029656 . Vogt , Katherine , Lauren Bradel , Christopher Andrews , Chris North , Alex Endert , and Duke Hutchings . 2011 . “Co - Located Collaborative Sensemaking on a Large High - Resolution Display with Multiple Input Devices . ” In Human - Computer Interaction – INTERACT 2011 , edited by Pedro Campos , Nicholas Graham , Joaquim Jorge , Nuno Nunes , Philippe Palanque , and Marco Winckler , 589 – 604 . Lecture Notes in Computer Science 6947 . Springer Berlin Heidelberg . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 23771 - 3 _ 44 . Waje , Aniruddha , Khalid Tearo , Raghav V . Sampangi , and Derek Reilly . 2016 . “Grab This , Swipe That : Combining Tangible and Gestural Interaction in Multiple Display Collaborative Gameplay . ” In Proceedings of the 2016 ACM on Interactive Surfaces and Spaces , 433 – 438 . ISS ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2992154 . 2996794 . Waldner , Manuela , Christian Pirchheim , Ernst Kruijff , and Dieter Schmalstieg . 2010 . “Automatic Configuration of Spatially Consistent Mouse Pointer Navigation in Multi - Display Environments . ” In Proceedings of the 15th International Conference on Intelligent User Interfaces , 397 – 400 . IUI ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1719970 . 1720040 . Wallace , James R . , Regan L . Mandryk , and Kori M . Inkpen . 2008 . “Comparing Content and Input Redirection in MDEs . ” In Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work , 157 – 166 . CSCW ‘ 08 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1460563 . 1460588 . Wallace , James R . , Stacey D . Scott , Eugene Lai , and Deon Jajalla . 2011 . “Investigating the Role of a Large , Shared Display in Multi - Display Environm ents . ” Computer Supported Cooperative Work ( CSCW ) 20 ( 6 ) : 529 . https : / / doi . org / 10 . 1007 / s10606 - 011 - 9149 - 8 . Wallace , James R . , Stacey D . Scott , and Carolyn G . MacGregor . 2013 . “Collaborative Sensemaking on a Digital Tabletop and Personal Tablets : Prioritization , Comparisons , and Tableaux . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 3345 – 3354 . CHI ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2470654 . 2466458 . References 276 Wallace , James R . , Stacey D . Scott , Taryn Stutz , Tricia Enns , and Kori Inkpen . 2009 . “Investigating Teamwork and Taskwork in Single - and Multi - Display Groupware Systems . ” Personal and Ubiquitous Computing 13 ( 8 ) : 569 . https : / / doi . org / 10 . 1007 / s00779 - 009 - 0241 - 8 . Wallace , Jim , Vicki Ha , Ryder Ziola , and Kori Inkpen . 2006 . “Swordfish : User Tailored Workspaces in Multi - Display Environments . ” In CHI ‘ 06 Extended Abstracts on Human Factors in Computing Systems , 1487 – 1492 . CHI EA ‘ 06 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1125451 . 1125724 . Ware , Colin , and Marlon Lewis . 1995 . “The DragMag Image Magnifier . ” In Conference Companion on Human Factors in Computing Systems , 407 – 408 . CHI ‘ 95 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 223355 . 223749 . Weiser , Mark . 1991 . “The Computer for the 21st Century . ” Scientific American 265 ( 3 ) : 94 – 104 . Weiss , Malte , Simon Voelker , Christine Sutter , and Jan Borchers . 2010 . “BendDesk : Dragging Across the Curve . ” In ACM International Conference on Interactive Tabletops and Surfaces , 1 – 10 . ITS ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1936652 . 1936654 . Wellner , Pierre . 1993 . “Interacting with Paper on the DigitalDesk . ” Commun . ACM 36 ( 7 ) : 87 – 96 . https : / / doi . org / 10 . 1145 / 159544 . 159630 . Whyte , Glen . 1991 . “Decision Failures : Why They Occur and How to Prevent Them . ” The Executive 5 ( 3 ) : 23 – 31 . https : / / doi . org / 10 . 5465 / AME . 1991 . 4274458 . Wigdor , Daniel , Hao Jiang , Clifton Forlines , Michelle Borkin , and Chia Shen . 2009 . “WeSpace : The Design Development and Deployment of a Walk - up and Share Multi - Surface Visual Collaboration System . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1237 – 1246 . CHI ‘ 09 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1518701 . 1518886 . Wigdor , Daniel , Chia Shen , Clifton Forlines , and Ravin Balakrishnan . 2006 . “Table - Centric Interactive Spaces for Real - Time Collaboration . ” In Proceedings of the Working Conference on Advanced Visual Interfaces , 103 – 107 . AVI ‘ 06 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1133265 . 1133286 . Wilkinson , Gerard , Ahmed Kharrufa , Jonathan Hook , Bradley Pursglove , Gavin Wood , Hendrik Haeuser , Nils Y . Hammerla , Steve Hodges , and Patrick Olivier . 2016 . “Expressy : Using a Wrist - Worn Inertial Measurement Unit to Add Expressiveness to Touch - Based Intera ctions . ” In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , 2832 – 2844 . CHI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2858036 . 2858223 . Willett , Wesley , Jeffrey Heer , Joseph Hellerstein , and Maneesh Agrawala . 2011 . “CommentSpace : Structured Support for Collaborative Visual Analysis . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 3131 – 3140 . CHI ‘ 11 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1978942 . 1979407 . Wilson , Andrew D . , and H rvoje Benko . 2010 . “Combining Multiple Depth Cameras and Projectors for Interactions on , Above and Between Surfaces . ” In Proceedings of the 23Nd Annual ACM Symposium on User Interface Software and Technology , 273 – 282 . UIST ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1866029 . 1866073 . Wimmer , Raphael , Fabian Hennecke , Florian Schulz , Sebastian Boring , Andreas Butz , and Heinrich Hußmann . 2010 . “Curve : Revisiting the Digital Desk . ” In References 277 Proceedings of the 6th Nordic Conference on Human - Computer Interaction : Extending Boundaries , 561 – 570 . NordiCHI ‘ 10 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1868914 . 1868977 . Winkler , Christian , Markus Löchtefeld , David Dobbelstein , Antonio Krüger , and Enrico Rukzio . 2014 . “SurfacePhone : A Mobile Projection Device f or Single - and Multiuser Everywhere Tabletop Interaction . ” In Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems , 3513 – 3522 . CHI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2556288 . 2557075 . Winkler , Christian , Julian Seifert , Christian Reinartz , Pascal Krahmer , and Enrico Rukzio . 2013 . “Penbook : Bringing Pen + Paper Interaction to a Tablet Device to Facilitate Paper - Based Workflows in the Hospital Domain . ” In Proceedings of the 2013 ACM International Conference on Interactive Tabletops and Surfaces , 283 – 286 . ITS ‘ 13 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2512349 . 2512797 . Wobbrock , Jacob O . , Meredith Ringel Morris , and Andrew D . Wilson . 2009 . “User - Defined Gestures for Surface Computing . ” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , 1083 – 1092 . CHI ‘ 09 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1518701 . 1518866 . Wong - Villacres , Marisol , Margarita Ortiz , Vanessa Echeverría , and Katherine Chiluiza . 2015 . “A Tabletop System to Promote Argumentation in Computer Science Students . ” In Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces , 325 – 330 . ITS ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2817721 . 2823501 . Wozniak , Paweł , Nitesh Goyal , Przemysław Kucharski , Lars Lischke , Sven Mayer , and Morten Fjeld . 2016 . “RAMPARTS : Supporting Sensemaking with Spatially - Aware Mobile Interactions . ” In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , 2447 – 2460 . CHI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2858036 . 2858491 . Wo ź niak , Pawe \ l W . , Lars Lischke , Benjamin Schmidt , Shengdong Zhao , and Morten Fjeld . 2014 . “ Thaddeus : A Dual Device Interaction Space for Exploring Information Visual isation . ” In Proceedings of the 8th Nordic Conference on Human - Computer Interaction : Fun , Fast , Foundational , 41 – 50 . NordiCHI ‘ 14 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2639189 . 2639237 . Wu , Andy , Sam Mendenhall , Jayraj Jog , Loring Scotty Hoag , and Ali Mazalek . 2012 . “A Nested APi Structure to Simplify Cross - Device Communication . ” In Proceedings of the Sixth International Conference on Tangible , Embedded and Embodied Interaction , 225 – 232 . TEI ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2148131 . 2148180 . Wu , Chi - Jui , Steven Houben , and Nicolai Marquardt . 2017 . “EagleSense : Tracking People and Devices in Interactive Spaces Using Real - Time Top - View Depth - Sensing . ” In , 3929 – 42 . ACM Press . https : / / doi . org / 10 . 1145 / 3025453 . 3025562 . Xiao , Robert , S cott Hudson , and Chris Harrison . 2016 . “CapCam : Enabling Rapid , Ad - Hoc , Position - Tracked Interactions Between Devices . ” In Proceedings of the 2016 ACM on Interactive Surfaces and Spaces , 169 – 178 . ISS ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2992154 . 2992182 . Yoon , Dongwook , Ken Hinckley , Hrvoje Benko , François Guimbretière , Pourang Irani , Michel Pahud , and Marcel Gavriliu . 2015 . “Sensing Tablet Grasp + Micro - Mobility for Active Reading . ” In Proceedings of the 28th Annual ACM References 278 Symposium on User Interface Software & Technology , 477 – 487 . UIST ‘ 15 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2807442 . 2807510 . Zadow , Ulrich von , and Raimund Dachselt . 2017 . “GIAnT : Visualizing Group Interaction at Large Wall Displays . ” In , 2639 – 47 . ACM Press . https : / / doi . org / 10 . 1145 / 3025453 . 3026006 . Zagermann , Johannes , Ulrike Pfeil , Roman Rädle , Hans - Christian Jetter , Clemens Klokmose , and Harald Reiterer . 2016 . “When Tablets Meet Tabletops : The Effect of Tabletop Size on Around - the - Table Collaboration with Personal Tablets . ” In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems , 5470 – 5481 . CHI ‘ 16 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2858036 . 2858224 . Zhang , Zengbin , David Chu , Xiaomeng Chen , and Thomas Moscibroda . 2012 . “SwordFig ht : Enabling a New Class of Phone - to - Phone Action Games on Commodity Phones . ” In Proceedings of the 10th International Conference on Mobile Systems , Applications , and Services , 1 – 14 . MobiSys ‘ 12 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 2307636 . 2307638 . Zhao , Frank , and Qiong Liu . 2004 . “A Web Based Multi - Display Presentation System . ” In Proceedings of the 12th Annual ACM International Conference on Multimedia , 176 – 177 . MULTIMEDIA ‘ 04 . New York , NY , USA : ACM . https : / / doi . org / 10 . 1145 / 1027527 . 1027565 . Ziola , Ryder , Melanie Kellar , and Kori Inkpen . 2007 . “DeskJockey : Exploiting Passive Surfaces to Display Peripheral Information . ” In Human - Computer Interaction – INTERACT 2007 , 447 – 460 . INTERACT ‘ 07 . Springer . http : / / link . springer . com / chapter / 10 . 1007 / 978 - 3 - 540 - 74796 - 3 _ 43 .