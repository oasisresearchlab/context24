The Missing Link : Integrating Paper and Electronic Documents Wendy E . Mackay In Situ , INRIA Futurs & LRI * Batiment 490 Université Paris - Sud 91405 ORSAY Cedex , FRANCE E - mail : mackay @ lri . fr ABSTRACT Despite the prevalence of computers and on - line documents , paper persists . As physical objects , paper documents are easy to use , flexible , portable and have proven extremely difficult to replace . Even though they all use computers , engineers still annotate large paper engineering drawings , video producers still sketch and rearrange paper storyboards , air traffic controllers still plan traffic flows with paper flight strips , and biologists still record experiments and organise multimedia data in paper notebooks . In this article , I argue that we should seriously reconsider the urge to replace all paper documents with on - line ones , accessible only with a mouse and keyboard and viewable only a screen . Instead , we should begin to think about " interactive paper " : which maintains the ease - of - use of physical paper , while enabling us to benefit from the full spectrum of interactive computing . KEYWORDS : Augmented Reality , Mixed Reality , Interactive Paper , Design Space Exploration , Participatory Design RESUME Malgré l ' omniprésence des ordinateurs et des documents numériques , le papier persiste dans nos usages quotidiens . En tant qu ' objets physiques , les documents papier sont faciles à utiliser , flexibles , portables , et s ' avèrent extrêmement difficiles à remplacer . Bien qu ' ils utilisent des ordinateurs , les ingénieurs utilisent de grands plans en papier , les producteurs de vidéo créent et organisent des storyboards en papier , les contrôleurs du trafic aérien organisent encore les vols des avions avec des " strips " papier , et les biologistes enregistrent encore leurs expérimentations et leurs données multimédia dans des cahiers de laboratoire en papier . Dans cet article , je défends l ' idée qu ' il faut sérieusement remettre en cause notre empressement à remplacer tous les documents papier par des versions numériques uniquement accessibles avec une souris , un clavier et un écran . A la place , je présente le concept de " papier interactif " , qui conserve la simplicité d ' usage du papier physique tout en permettant de bénéficier de toutes les capacités de l ' interaction avec des documents numériques . MOTS - CLÉS : Réalité augmentée , Réalité mixte , Papier interactif , Exploration de l ' espace de conception , Conception participative INTRODUCTION * I spent the early part of my career developing multimedia systems , seeking new ways to integrate text , graphics and video in a distributed computer environment . In the 1990 ' s , as a recent employee of Xerox , I attended an internal seminar that fundamentally changed the direction of my research . Nick Sheridon presented a new technology , digital paper , in which each " pixel " embedded in a sheet of paper was actually a tiny ball , black on one side , white on the other . These balls were stable , unless explicitly flipped over by a simple device . The result : a sheet of paper acts as a computer display , while maintaining all the characteristics of ordinary paper . This work was top - secret at the time , available only to Xerox employees , but it sparked a new way of thinking about the future of interactive computing . Suddenly , a paper document was no longer the static output of a printer , but an interactive object in its own right . At our lab Xerox EuroPARC , we began to work on the concept of interactive paper , in various forms . Pierre Wellner developed a new approach to managing paper documents called the Digital Desk ( Wellner , 1992 ) . His approach differed from Sheridon ' s : he used a video camera to capture information from printed documents . The user , using a finger as a pointing device , could provide simple commands and see the result as a projected image onto the desktop surface . My group developed several applications along these lines , exploring different technologies for capturing information ( sound , cameras , graphics tablets ) , displaying it ( project , embedded screens in the desk ) and linking physical and on - line information . We worked with users with real needs in an attempt to begin to explore this new design space : interactive paper . In July , 1993 , together with Wellner and Rich Gold from Xerox PARC , I edited a special issue of Communications of the ACM , called " Computer Augmented Environments " . This issue included our work on the Digital Desk as well as a number of other innovative " augmented reality " applications . The special issue received the 1993 American Publisher ' s award for the * Projet In Situ , Pôle Commun de Recherche en Informatique du plateau de Saclay ( PCRI ) , CNRS , Ecole Polytechnique , INRIA , Université Paris - Sud . 1 Copyright© 2003 by the Association for Computing Machinery , Inc . Permission to make digital or hard copies of part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page or initial screen of the document . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , to republish , to post on servers , or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . IHM 2003 November 25 - 28 , 2003 , Caen , France . Copyright 2003 ACM 1 - 58113 - 803 - 2 / 03 / 0011… $ 5 . 00 best special issue of a journal in any scientific discipline and effectively launched a new field . Later work at MIT followed : Joe Jacobson developed the concept of electronic ink ( similar to Sheridan ' s electronic paper , but with the dynamic pixels located in the ink substrate , not the paper ) . Hiroshi Ishii began to work on " tangible interfaces " and Mike Hawley began " things that think " . Researchers who had moved from Virtual Reality to Augmented Reality , such as Steve Feiner , at Columbia , became active in exploring ways in which we can mix real and virtual images Since then , the fields of augmented reality , mixed reality , and tangible computing have exploded , as well as the related fields of wearable and ubiquitous computing . The technology continues to improve . We have new and better methods for identifying objects , including glyphs , cybertags , RFID tags and smart chips . Vision researchers have become increasingly skilled at identifying objects and registering their location . Some interactive paper technologies have been commercialised , including paper as an output device ( Gyricon and E - ink ) and paper as an input device ( Anoto ' s system of using a camera in a pen and special paper to capture the user ' s gestures ) . Although the growth in the field is exciting , I am concerned that much of the research focuses on developing the technology itself rather than seeking to understand these technologies from the perspective of the user . While mixed reality poses a number of difficult technical questions that require research , such as how to ensure that the physical and virtual versions of an object are truly synchronised , some of the most difficult questions involve ensuring that users benefit from the advantages of each medium and do not become confused by their integration . In this article , I describe four research projects we have conducted over the past decade . In each case , we began with a particular kind of user : professionals who are computer literate and actively like and use their computers to create and manage on - line documents , but still find themselves using paper documents for various purposes . The research approach is one of participatory design : we do not simply observe these users ( although we certainly do that ) , but we also work with them over periods of time , to collaboratively brainstorm ideas , prototype novel interface designs and evaluate their effectiveness iteratively , throughout the design process . In each case , resistance to throwing away paper documents is not due to a fear of new technology , but rather to a practical understanding of the advantages and disadvantages of documents in each of their forms . Thus , the goal of each research project has been to iteratively develop a novel kind of interactive paper document that does not require the user to give up the advantages of physical paper , but still enables him or her to gain the advantages of an on - line document . This approach provides us not only with novel designs for interactive paper , but also a deeper understanding of how people use and interact with documents over time . Understanding the latter allows us to re - invent familiar documents to provide radically new functionality , without risking the loss of prior benefits . The next sections will briefly describe each of these four interactive paper projects , including a summary of what we learned in the process . I will conclude with a brief assessment of the future of interactive documents and the many new possibilities open to interactive document designers . INTERACTIVE PAPER Paper is an extremely versatile object , used for many purposes in a variety of different ways . Yet , once written on or printed , the information on paper is essentially static . The user can erase pencil marks and make new annotations with a pen , but usually , once paper is printed , it stays the same . If we want to modify information via the computer , we must return to the computer screen , make the changes , and print out a new version . The result is that many computer users keep two parallel filing systems , one for their electronic documents and another for their paper documents . The two are often related , but rarely identical , and it is easy for them to get out of sync . Many software application designers understand this problem and have tried to replace paper altogether , usually by providing electronic versions of paper forms . While this works in some applications , for many others , users end up juggling both paper and electronic versions of the same information . We have been exploring a different approach : Instead of replacing the paper , we augment it directly . The user can continue to take advantage of the flexibility of paper and , at the same time , manipulate information and communicate via a computer network . The next section describes three applications of " interactive paper " . We are not simply interested in developing new technology . In each case , we began with observations of how people use a particular type of paper document in a particular use setting . We then use participatory design techniques to develop a series of prototypes that link the paper to relevant computer software . The goal is to take advantage of the unique benefits of both paper and electronic forms of information , creating a new style of user interface that is lightweight and flexible , computationally powerful , and enhances users ' existing styles of working . Ariel : Blueprints that talk to the net We studied the work practices of a group of construction supervisors working on the Storebaelt bridge in Denmark ( the world ' s longest suspension bridge ) . Our original goal was to provide them with a sophisticated multimedia communication system that would let them talk to one another and share information . We discovered that they must deal with thousands of engineering design drawings as they manage and inspect the work of the bridge contractors . Yet on any given week , they only use four or five drawings . Another important discovery was that , although they all have computers in their offices , they rarely use them , except occasionally for email mail and writing reports . Instead , they travel constantly from their offices to the bridge pylons in the waterway and back to the pre - fabrication sites and administrative offices on shore . The supervisors much prefer the convenience of paper drawings , especially since they can easily make informal notes and sketch ideas for design changes . These informal changes are extremely important : as many as 30 % of the changes made are never transferred to the on - 2 line system . Thus the paper drawings are the most accurate record of the actual design of the bridge . We were interested in giving supervisors improved access to critical information as well as to each other . Rather than designing yet another unused program for the supervisor ' s desktop computer , we decided to use an mixed reality approach . Ariel [ 11 , 14 ] lets the engineering drawings themselves became the interface to the computer . We developed a series of prototypes in collaboration with the engineers , to explore different interfaces and functionality . Figure 3 shows the first prototype , developed in Unix . Figure 3 : The first prototype of Ariel ( Unix ) uses an A0 sized graphics tablet to capture annotations and commands from the user , and projected information back onto the tablet . When the supervisor wants to connect the drawing to Ariel , she simply places it onto the desktop . Ariel identifies the drawing via a bar - code ( figure 4 ) and uses a tiny video camera to capture the position of a light pen and a hand - held scanner to capture hand - written notes . We experimented with various mechanisms for registering the exact location of the drawing with respect to the graphics tablet . The most successful version involved asking the user to point to each of the four corners of the drawing ( after identifying it so Ariel would know the correct size ) . Ariel then adjusts the electronic image of the drawing to correspond to the actual size of the paper drawing . Ariel uses a portable video projection panel to display computer images and interactive menus onto the drawing . Figure 5 shows the MacIntosh interface , in which the user can make hypermedia annotations , indicated by " hotspots " to add audio , video or text notes , in addition to the ones written in pencil . Projection of computer images onto the paper drawing can occasionally be confusing . One solution is to place a piece of plain white paper over areas of the drawing , to make it easier to see the projected information . By placing a small led in the corner of the paper , we create a " real " as opposed to a " virtual " window , that Ariel can track as it is moved around the drawing . Figure 4 : Identifying the drawing via a barcode reader . Figure 5 : ( Macintosh interface ) Movable hotspots , indicating annotations , are projected onto the paper . The user can move a paper " window " anywhere on the surface ; Ariel detects it via the red led in the corner . Every drawing contains information about the author of the drawing and other responsible individuals . Ariel lets the user take advantage of this information to establish live video connections with people at other Ariel sites , via a media space ( figure 6 ) . The supervisor can also send multimedia mail and look at annotations made by her colleagues . The main advantage of using engineering drawings as the interface is that they are never " down " ; they always work . Yet with Ariel , these same drawings provide a simple and effective interface to a sophisticated distributed multimedia network , with all its capabilities for information exchange . 3 Figure 6 : Users can access a media space and communicate with others at different locations on the bridge . Video Mosaic : Interactive paper storyboards Film makers and video producers use paper storyboards to organize and illustrate the flow of a movie or video . Storyboards usually consist of a series of " shots " , each containing a " best frame " or sketch of a representative image from a motion sequence , the corresponding dialog or voice - over , and notes about the shots or scene ( figure 7 ) . Figure 7 : An example of an informal storyboard , with a sketch of the video to the left , a description of the shot in the middle , and the subtitles to the right . Although on - line video - editing systems have been available for over a decade , most people continue to use paper storyboards : they are portable as well as easy to read , annotate and exchange with others . On - line video systems make it easy to search for text strings and see the action ; but suffer from limited screen real estate and are not very portable . ( Even with lap - top computers , it is still easier to read storyboards on paper . ) Video Mosaic [ 12 ] explored ways of linking paper storyboards to an on - line video editing system I originally developed at MIT , called EVA [ 9 ] . Storyboards consist of a series of elements , each with a video clip , subtitles and commentary about the shot . The printed version of a storyboard element includes an identification code , an image of the " best " frame , the text of the subtitles and a snapshot of any relevant hand - written notes . The user can manipulate the individual segments of a paper storyboard , reordering , editing and annotating them as desired . The user maintains the flexibility of the paper storyboard , while gaining access to on - line editing facilities for creating new versions of the video . Figure 8 illustrates the basic layout of Video Mosaic , with a closeup camera ( or handheld scanner ) for detecting precise information , a wide - angle camera for detecting the position of individual storyboard elements ( via a light pen or barcode reader ) and a projector ( or embedded monitor ) for displaying information to the user . We developed Unix and a Macintosh prototypes to explore different user interface styles . The Unix version ( figure 9 ) uses optical character recognition to identify the storyboard element and the user commands ( via " paper buttons " ) . For example , a user might decide to edit together three particular video clips . She picks up the relevant storyboard elements ( figure 10 ) , places them one at a time under the video camera , tapping once to tell the system to identify that element . She then places a paper button with the word " play " on it and taps . The corresponding video sequence plays in a video monitor embedded in the desk . Camera Projector Camera Printer Figure 8 : Diagram of Video Mosaic layout Figure 9 : Unix version of Video Mosaic 4 Figure 11 shows a closeup of a storyboard element from the Macintosh version of Video Mosaic ( figure 12 ) . This version is significantly easier use : each storyboard element has a barcode printed in the corner and a menu of possible commands is projected onto the desktop . The user passes the barcode over the desired storyboard and points to the desired command . A video camera detects the red light emitted from the bar code pen and performs the relevant command on the selected video elements . The same projector projects the corresponding video onto the desktop . User annotations can be recorded either with the overhead camera or with a small , hand - held scanner . Figure 10 : A Unix storyboard element . Figure 11 : Macintosh storyboard element . Figure 12 : Macintosh version of Video Mosaic . The techniques we developed for Video Mosaic proved useful for reading lengthy reports containing video clips . Normally , we prefer to read text on paper . But if the text contains video clips , it is necessary to read the document on - line . Video Mosaic allowed us to print a paper version of the document in which each still image has an identification number ( or barcode ) . When activated , the related video clip plays on the monitor next to the desk . Video Mosaic illustrates how to merge paper storyboards or documents containing video with a variety of on - line video editing functions , taking advantage of the best elements of each . Caméléon : Mixed paper flight strips Caméléon [ 12 ] addresses a very different kind of problem . The current air traffic control system uses a combination of RADAR and paper flight strips to track the progress of each plane . Controllers annotate the flight strips to highlight problems , remind themselves to do things and to communicate the status of each plane to other controllers ( figure 13 ) . Figure 13 : Air traffic controllers working together at the Paris ( Athis Mons ) en route control center . Note that two controllers are simultaneously annotating different paper flight strips at the same time . Although various on - line tools are being developed to help controllers handle the ever - increasing traffic loads , much of the information they need remains in hand - written form on the paper flight strips . The most common solution for developers of new technology is to remove the flight strips and replace them with electronic versions 5 presented on a computer monitor . Unfortunately , this overloads the controller ' s visual channel and makes it more difficult for them to handle the planes . We decided to try a different approach : rather than replacing the strips , we would augment them . We began with a four - month ethnographic study of a team of controllers at the Paris en route control center , emphasizing how they interact with paper flight strips . We found that annotations serve a variety of functions ( figure 14 ) . Figure 14 : Annotated paper flight strips Controllers write for themselves , for each other and as a legal record of decisions made . Only a subset of these annotations need to be interpreted by the computer . We can take advantage of the existing layout of the strips and the agreed - upon ways of annotating them . For example , one section of the strip is devoted to the " exit level " of an airplane . The next sector ( of the air space ) is already recorded , as is the planned exit level . We engaged in a year - long participatory design project , exploring different techniques for capturing information written on the strips , presenting information to the controllers and tracking the strips themselves . Figure 15 shows a prototype in which the plastic flight strip holder has been modified to contain a resistor . Figure 15 : Modified paper strip holder containing a resistor . A frame with metal contacts on the sides ( figure 16 ) detects the level of resistance ( unique to each strip holder ) . The system can then tell which strip is located in which position on the stripboard . This frame is placed on top of a graphics tablet , which captures the annotations made by the controller . Figure 16 : Caméléon stripboard that detects the position of paper flight strips , with a graphics tablet to capture text annotations and a touch screen to display relevant information . A touch - sensitive screen adjacent to the stripboard displays information about each strip . For example , if another controller wishes to suggest a new flight level , it appears on the screen adjacent to the relevant strip . The controller can underline the level if she agrees , write a new one or click on the " telephone " icon to discuss it further . The controller can also generate commands , such as tapping once on a particular strip to see it highlighted on the RADAR , or twice to see route and other information ( figure 17 ) . Figure 17 : Prototype of Caméléon A - Book : Augmented Laboratory Notebooks Research biologists face a complex information processing task , managing physical paper documents , physical research specimens , on - line documents and on - line services . They require paper laboratory notebooks 6 for legal , historical and practical reasons , but they are also active computer users . This forces them to constantly juggle paper and electronic forms of the same information . We are exploring the concept of an " augmented laboratory notebook " , to develop a design space that provides the missing link between this physical and on - line information . We created three prototypes , with active participation by research biologists , archivists and managers at the Institut Pasteur in Paris . Each provides solutions to particular user needs , retaining the best aspects of paper , linking physical and electronic data , and creating on - line access to information that can be preserved for posterity . The final prototype , the a - book , includes a paper notebook and introduces a novel interaction technique called the Interaction Lens . This palm - sized physical " window " between the physical and digital realm can be used as a see - through tool or lens . The software is designed to handle persistent data , manage links and facilitate retrieval of a variety of archived information . including paper and electronic documents as well as other physical objects , such as live animals , research specimens and data images . We use a document - centered approach , with a multi - layer information architecture that crosses the boundary between physical and on - line objects . DISCUSSION When is an mixed reality approach appropriate ? We begin by looking at what users already do with objects in the real world . We then examine what functionality the computer can add . If the off - line version has important characteristics that cannot easily be duplicated with a standard mouse / keyboard / monitor style of interface , then it makes sense to explore an mixed reality approach . Note that integration of physical and virtual objects is not always easy . Mixed reality can create as well as solve problems for the user . A very simple is example is the act of erasing information . Erasing pencil marks on paper is simple and straightforward . Similarly , in most on - line text editing applications , erasing is a simple task that is easy for users to learn . Yet what does it mean to erase when the two are linked ? What happens if marks are erased on paper and the computer version does not detect the change ? Or similarly , what happens if the computer erases information , but it remains physically on the paper ? Mixed reality applications merge electronic and physical objects ; when the methods of interacting with each are not in sync , the result can be confusing . When designing mixed reality applications , it is important to consider how to make the integration of real and virtual as seamless as possible . Each application must choose the best combination of techniques for detecting information from the real world and presenting electronic information to the user . For example , a number of options are available to track the position of a user ' s hands . A data glove or special dots on the hands be detected with a sensing device . A video camera and image analysis algorithms can identify location . In each case , the choice depends upon the nature of the application . If the user is already wearing gloves , a data glove makes sense . If low - resolution pointing is all that is required , the combination of a camera and light pen makes for a lightweight , portable system . If very accurate position information is needed , a graphics tablet may be required . Similarly , many possibilities are available for displaying information . A doctor can wear a head - mounted helmet and see a video image of the real world mixed with electronic information . Electronic images can be presented over one eye . A video projector can project information directly onto the patient ' s body . Electronic ink or paper [ 16 ] will provide a lightweight , stable mechanism for displaying almost any information . Finally , imagine a kind of transparent , flexible screen that shows critical information when placed over the patient . The choice depends on the specific characteristics of the application : constraints of the user , the object or the environment . Mixed reality applications also present interesting challenges to the user interface designer . For example , when superimposing virtual information onto real objects , how can the user tell what is real and what is not ? How can the correspondence between the two be maintained ? Actions that work invisibly in each separate world may conflict when the real and the virtual are combined . For example , if a computer menu is projected onto a piece of paper , and then another piece of paper is placed on top of the first paper , the computer project continues to be on top . In a paper world , each piece of paper obscures the ones beneath , giving a clear view of the one on top . On a computer screen , the same thing happens with overlapping windows . But when the paper and electronic information are combined , odd things occur . For Ariel , we created a blank sheet of paper that the computer could detect via a tiny infrared light on the corner . The computer would track this sheet and project pop - up menus onto it , solving the " overlay " problem . The most innovative aspect of mixed reality is not the technology : it is the objective . Instead of replacing physical objects with a computer , we create systems that allow people to interact with the real world in natural ways and at the same time , benefit from enhanced capabilities from the computer . The future we envision is not a strange world in which we are immersed in " virtual reality " . Instead , we see our familiar world , enhanced in numerous , often invisible ways . ACKNOWLEDGMENTS I am grateful to the many people at MIT , EuroPARC , Xerox PARC and the Centre d ' Études de Navigation Aérienne , who have provided such inspiring environments in which to work . Thanks in particular to my colleagues on the EuroCODE project , particularly Daniele Pagani , Lone Faber and Petri Launiainen and to Anne - Laure Fayard and Lionel Médini on the Caméléon project . Finally , thanks to Michel Beaudouin - Lafon for comments on the paper and and contributions of code . Note that parts of this article appeared in a French language version in La Recherche [ 10 ] . REFERENCES 1 . Bajura , M . , Fuchs , H . and Ohbuchi , R . ( July , 1992 ) Merging virtual objects with the real world : Seeing ultrasound imagery within the patient . In Computer 7 Graphics : Proceedings of SIGGRAPH ' 92 , 26 ( 2 ) , pp . 203 - 210 . 2 . Baudel , T . and Beaudouin - Lafon , M . ( 1993 ) Charade : Remote control of objects using free - hand gestures . In Communications of the ACM , July 1993 , 36 ( 7 ) , pp . 28 - 35 . 3 . Bolt , R . Put - That - There : Voice and gesture at the graphics interface . ( 1980 ) Computer Graphics . 14 ( 3 ) ACM SIGGRAPH . pp . 262 - 270 . 4 . Chung , J . , Harris , M . , Brooks , F . , Fuchs , H . , Kelley , M . , Hughes , J . , Ouh - young , M . , Cheung , C . , Holloway , R . and Pique , M . ( 1989 ) Exploring virtual worlds with head - mounted displays . In Proceedings SPIE Non - Holographic True 3 - Dimensional Display Technologies , Vol . 1083 . Los Angeles , Jan . 15 - 20 . 5 . Elrod , S . , Hall , G . , Costanza , R . , Dixon , M . , des Rivières , J . ( 1993 ) In Communications of the ACM , July 1993 , 36 ( 7 ) , pp . 84 - 85 . 6 . Feiner , S . , MacIntyre , B . , and Seligmann , D . Knowledge - Based Augmented Reality . In Communications of the ACM , July 1993 , 36 ( 7 ) , pp . 96 - 97 . 7 . Krueger , M . ( 1983 ) Artificial Reality . NY : Addison - Wesley . 8 . Landauer , T . ( 1996 ) The Trouble with Computers . MIT Press : Cambridge , MA . 9 . Mackay , W . E . and Davenport , G . ( July 1989 ) . Virtual Video Editing in Interactive Multi - Media Applications . Communications of the ACM , Vol . 32 ( 7 ) , pp . 802 - 810 . 10 . Mackay , W . ( March 1996 ) . Réalité Augmentée : le meilleur des deux mondes . La Recherche , numéro spécial L ' ordinateur au doigt et à l ' œil . 284 , pp . 32 - 37 . 11 . Mackay , W . , Faber , L . , Launianen , P . and Pagani , D . ( 1993 ) Design of the High Road Demonstrator , D4 . 4 , 30 September 1993 , EuroCODE ESPRIT project 6155 . 12 . Mackay , W . , Fayard , A . L , Frobert , L . & Médini , L . , ( 1998 ) Reinventing the Familiar : Exploring an Augmented Reality Design Space for Air Traffic Control . In Proceedings of CHI ' 98 , Los Angeles , CA : ACM Press , pp . 558 - 565 . 13 . Mackay , W . , Letondal , C . , Pothier , G , Bøegh , K . and Sørensen , H . . The missing link : Augmenting biologist ' s laboratory notebooks . In Proc . ACM Symposium on User Interface Software and Technology ( UIST 2002 ) , 4 ( 2 ) of CHI Letters , pp . 41 - 50 , Paris , France , October , 2002 . ACM Press . 13 . Mackay , W . and Pagani , D . ( October 1994 ) . Video Mosaic : Laying out time in a physical space . Proceedings of Multimedia ' 94 . San Francisco , CA : ACM , pp . 165 - 172 . 14 . Mackay , W . E . , Pagani D . S . , Faber L . , Inwood B . , Launiainen P . , Brenta L . , and Pouzol V . ( 1995 ) . Ariel : Augmenting Paper Engineering Drawings . Videotape Presented at CHI ' 95 , ACM . 15 . Mackay , W . , Velay , G . , Carter , K . , Ma , C . , and Pagani , D . ( July 1993 ) Augmenting Reality : Adding Computational Dimensions to Paper . In Communications of the ACM , July 1993 , 36 ( 7 ) , pp . 96 - 97 . 16 . Negroponte , N . ( 1997 ) Surfaces and Displays . Wired , January issue , pp . 212 . 17 . Newman , W . , Eldridge , M . , and Lamming , M . ( 1993 ) PEPYS : Generating autobiographies by automatic tracking . EuroPARC technical report series , Cambridge , England . 18 . Pagani , D . and Mackay , W . ( October 1994 ) . Bringing media spaces into the real world . Proceedings of ECSCW ' 93 , the European Conference on Computer - Supported Cooperative Work , Milano , Italy : ACM . 19 . Papert , S . ( 1980 ) Mindstorms : Children , Computers and Powerful Ideas . NY : Basic Books . 20 . Resnick , M . Behavior Construction Kits . In Communications of the ACM , July 1993 , 36 ( 7 ) , pp . 96 - 97 . 21 . Sutherland , I . ( 1968 ) . A head - mounted three - dimensional display . In Proceedings FJCC ' 68 , Thompson Books , Washington , D . C . , pp . 757 - 764 . 22 . Wellner , P . ( 1992 ) The DigitalDesk calculator : Tactile manipulation on a desktop display . In Proceedings of UIST ' 92 , the ACM Symposium on User Interface Software and Technology . ( Nov 11 - 13 , Hilton Head , SC ) , ACM , NY . 23 . Weiser , M . ( September , 1991 ) The Computer for the 21st Century . Scientific American , 265 ( 3 ) . 24 . Wellner , P . , Mackay , W . and Gold , R . ( Editors ) , ( July 1993 ) Computer Augmented Environments : Back to the Real World . Special Issue of Communications of the ACM , July , 36 : 7 , pp . 24 - 27 . 25 . Zuboff , S . ( 1988 ) . In the Age of the Smart Machine . New York : Basic Books . 8