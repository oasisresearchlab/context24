Unsupervised Method for Disease Named Entity Recognition Thesis by Abeer Nayer Almutairi In Partial Fulﬁllment of the Requirements For the Degree of Masters of Science King Abdullah University of Science and Technology Thuwal , Kingdom of Saudi Arabia November , 2019 2 EXAMINATION COMMITTEE PAGE The thesis of Abeer Nayer Almutairi is approved by the examination committee Committee Chairperson : Robert Hoehndorf Committee Members : Mikhail Moshkov , Taous - Meriem Laleg - Kirati 3 ©November , 2019 Abeer Nayer Almutairi All Rights Reserved 4 ABSTRACT Unsupervised Method for Disease Named Entity Recognition Abeer Nayer Almutairi Diseases take a central role in biomedical research ; many studies aim to enable access to disease information , by designing named entity recognition models to make use of the available information . Disease recognition is a problem that has been tackled by various approaches of which the most famous are the lexical and super - vised approaches . However , the aforementioned approaches have many drawbacks as their performance is aﬀected by the amount of human - annotated data set available . Moreover , lexical approaches cannot distinguish between real mentions of diseases and mentions of other entities that share the same name or acronym . The challenge of this project is to ﬁnd a model that can combine the strengths of the lexical approaches and supervised approaches , to design a named entity recognizer . We demonstrate that our model can accurately identify disease name mentions in text , by using word embedding to capture context information of each mention , which enables the model to distinguish if it is a real disease mention or not . We evaluate our model using a gold standard data set which showed high precision of 84 % and accuracy of 96 % . Finally , we compare the performance of our model to diﬀerent statistical name entity recog - nition models , and the results show that our model outperforms the unsupervised lexical approaches . 5 ACKNOWLEDGEMENTS I would like to express my sincere appreciation to my family for their emotional support and encouragement , especially my husband who has supported me in so many diﬀerent ways . I then extend my appreciation to my best friend Sumyyah for her spiritual and academic support . I am also thankful to my friends : Sara , Mona , Sarah , and Azza because they always enrich my knowledge with their discussions and suggestions . I dedicate this work to my parents , I wish I always make you happy and proud , I’m grateful for your prayers and encouragements . I also dedicate this work to my husband for his generosity and limitless love . I hold a great amount of gratitude towards my advisor Professor Robert Hoehndorf for his guidance , support , and encouragement throughout this journey . I am thankful for his constant follow up , feedback and suggestions . 6 TABLE OF CONTENTS Examination Committee Page 2 Copyright 3 Abstract 4 Acknowledgements 5 List of Figures 8 List of Tables 9 1 Introduction 10 2 Literature Review 13 2 . 1 Lexical approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2 . 2 Supervised approaches . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2 . 3 Ontologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2 . 4 Word embedding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2 . 4 . 1 Word2vec . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2 . 4 . 2 BERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3 Problem Statement 20 4 Materials and Methods 22 4 . 1 Data resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 4 . 1 . 1 Corpus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 4 . 1 . 2 Disease resources . . . . . . . . . . . . . . . . . . . . . . . . . 22 4 . 2 Lexical baseline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 4 . 3 BERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 4 . 4 K - mean clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 4 . 5 Supervised training . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 7 5 Results & Discussion 28 5 . 1 Testing process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 5 . 2 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 6 Concluding Remarks 35 References 37 Appendices 42 8 LIST OF FIGURES 4 . 1 The lexical baseline architecture . . . . . . . . . . . . . . . . . . . . . 23 4 . 2 BERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 4 . 3 Final model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 5 . 1 K - mean clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 5 . 2 Testing procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 9 LIST OF TABLES 4 . 1 Size of the NCBI disease corpus . . . . . . . . . . . . . . . . . . . . . 22 5 . 1 K - Mean cluster with K = 2 . . . . . . . . . . . . . . . . . . . . . . . . 29 5 . 2 K - Mean cluster with K = 3 . . . . . . . . . . . . . . . . . . . . . . . . 29 5 . 3 K - Mean cluster with K = 4 . . . . . . . . . . . . . . . . . . . . . . . . 29 5 . 4 K - Mean cluster with K = 5 . . . . . . . . . . . . . . . . . . . . . . . . 29 5 . 5 Performance of our model . . . . . . . . . . . . . . . . . . . . . . . . 32 5 . 6 Performance compared against lexical baselines . . . . . . . . . . . . 34 5 . 7 Performance compared against another supervised model . . . . . . . 34 10 Chapter 1 Introduction There is an ever - increasing amount of biomedical literature in the ﬁeld of biomedical research . Therefore , it is very important to focus on biomedical text mining , to make use of the available information [ 1 ] . Biomedical text mining is deﬁned by the extraction and discovery of high - quality , non - trivial information from free text [ 2 ] . One of the main components of biomedical text mining is Biomedical Natural Language Processing ( BioNLP ) , which allows computers to extract information about biomedical topics from unstructured texts , such as the type of entities which are mentioned in texts [ 1 ] . In BioNLP , the name of biological entities mentioned in texts need to be auto - matically identiﬁed , which is known as Named Entity Recognition ( NER ) [ 3 ] . NER identiﬁes mentions of named entities , which are predeﬁned meaningful names in par - ticular domains , as well as the particular domain of the entities from texts [ 4 ] . The main focus of this study , is to design a name entity recognizer that can identify mentions of disease names in texts . Mentions of name entities are terms of disease names but within their context . A term could be a word deﬁned by a single distinct element of speech or writing . Also , a term could be a phrase , which is multiple words without the subject - verb pair necessary to form a clause [ 5 ] . Given below is an example to illustrate the idea : • Terms could be a disease name consisting of one or multiple words , such as : – cancer 11 – breast cancer • Mentions are terms of disease names but within their context , such as : – If your mother had breast cancer , the chances of getting the disease is higher . Diseases take a central role in biomedical research ; many studies aim to enable access to disease information [ 6 ] , since many biomedical applications need to discover the available information about diseases for the sake of disease detection , diagnosis , prevention , and treatment . Other applications depend on the information extracted such as drug side eﬀect detection , safety surveillance and drug discovery [ 7 ] . Diseases are deﬁned by any impairment of normal biological function [ 8 ] . Disease names are terms created by combining disease category with modiﬁers , which take many forms . They are usually used as a short descriptive modiﬁer , including symp - toms ( dry - eye syndrome ) , anatomical locations ( ovarian cancer ) , causative agent ( oral thrush infection ) , treatment ( dopamine responsive dystonia ) , heredity ( Bruton agam - maglobulinemia ) , or eponyms ( Alzheimer’s disease ) . Furthermore , modiﬁers provide descriptions such as severe malaria , which are not part of the name [ 9 ] . Disease names are created from Latin or Greek names by combining aﬃxes and roots such as hemochromatosis . When disease names are mentioned in the text , they exhibit variations , and this variation is presented in the abbreviation , synonymous terms for the same disease , and the usage of diﬀerent word orderings . These varia - tions may be morphological or orthographical , and they involve more than one - word substitutions . For example , a disease name could be composed by combining aﬃxes such as a single word ( cancer ) that may correspond to multiple words ( breast , brain and ovarian ) in another form [ 9 ] . Disease names include labels , synonyms , and abbreviations , and they can be used to refer to a unique disease class , and every class is identiﬁed by a unique class ID . 12 Consequently , disease name could be mentioned in two diﬀerent places or sentences . Then , we consider each of these two diﬀerent places or sentences as a diﬀerent mention for the same disease name . It is the unique combination of a term and its context , which form a mention . For instance , in the following two sentences : • This is breast cancer disease • Breast cancer patients are in danger Breast cancer is the disease name term , and each of these sentences is considered as a diﬀerent mention . Here , we develop a novel method that combines the strengths of lexical approaches and supervised approaches to design a name entity recognizer . We demonstrate that our method can be used for any texts . Speciﬁcally , the contributions in this thesis are as follows : • We develop a novel model for disease name entity recognition . • We identify disease names mentioned in text . • We evaluate our ﬁndings against diﬀerent statistical name entity recognizer models . 13 Chapter 2 Literature Review 2 . 1 Lexical approaches Traditional biomedical name entity recognizer strategies mainly depend on rule - based systems or dictionary lookups . Rule - based systems deﬁne rules manually using textual patterns to recognize biomedical entities . A rule - based system was introduced by Narayanaswamy et al . [ 10 ] , and it was manually developed using a set of rules that depend on lexical information and english linguistic constraints . Named entities were categorized using contextual information and surrounding words . Furthermore , Budi & Bressan [ 11 ] proposed a new rule - based system to extract named entities using a set of grammatical and syntactic rules . Rule - based systems depend on two types of rules [ 12 ] : pattern - based rules , which depend on the word patterns being orthographic or morphological , and context - based rules , which depend on the contextual information in the text . Rule - based systems mainly depend on the speciﬁc textual properties , and it is time - consuming to deﬁne such entities with speciﬁc textual properties and patterns . Also , it requires experts with speciﬁc domain knowledge . When the resources are available the rule - based system performs well , but the system will lack portability if the data are slightly changed , since it is highly costly to maintain the status of the rule updated . A dictionary is built manually or automatically by collecting vocabulary for a speciﬁc domain from related databases . There are diﬀerent examples of dictionaries , 14 such as the Human Disease Ontology ( DO ) [ 13 ] , which is used to identify disease names in text , and the DrugBank [ 14 ] dictionary , which is used to identify names of drugs . These dictionaries are used to implement string - matching algorithms , and they identify entity occurrences in the text using lists of terms deﬁned in dictionaries . This process makes an exact search if a term in the text matches a term in the dictionary . Dictionary - based systems are used for named entity extraction by searching for terms in dictionaries , and looking for dictionary term matches in texts . For instance , Hettne et al . [ 15 ] used a dictionary - based approach to identify name entities of small molecules and drugs in texts , combining multiple dictionaries to increase the power of recognizing chemical name entities and map them to thier class ID . Gerner et al . [ 16 ] introduced LINNAEUS , which it is a dictionary - based software system used to recognize species names . Two factors that greatly impact the quality of the dictionary - based systems , are the quality of both the dictionary and the matching algorithm used . Furthermore , it is time - consuming to build and maintain up - to - date dictionaries . Generally , dictionary - based systems oﬀer poor recall , since it is diﬃcult to capture new entities and to avoid spelling errors in the text . On the other - hand , dictionary - based methods can directly map the mention to their class ID . Lexical approaches aﬀect precision since it they keep the longest string in case of nested term mentions . Also , many terms may be ambiguous or abbreviated . Further - more , lexical approaches are expected to have diﬃculty dealing with term variability . Many resources [ 17 , 18 , 19 ] are designed to address issues concerning case normaliza - tion , word order , and plurals . The hybrid system combines dictionary - based systems and rule - based systems to design a named entity recognizer . For example , the LeadMine system [ 20 ] employs spelling correction and merges the adjacent entities and entity extension to improve performance . This increases the chance of recognizing trivial names that are slightly 15 diﬀerent from the list of terms covered in the dictionary . 2 . 2 Supervised approaches In recent years , lexical approaches like rule - based or dictionary - based methods have been replaced by supervised approaches . The basic steps required for systems are training the model to use the present annotations from the annotated documents and to annotate the documents to generate the entity names based on past knowledge learned from the annotated documents . Supervised learning algorithms learn from the labeling of the training data - set with the correct outcomes . For instance , the computer learns from the input of the classiﬁcation problems to create a classiﬁcation system that produces output accordingly [ 21 ] . Supervised model quality depends on the available inputs in the training data set , since the construction process to build the supervised model is aﬀected by the amount of missing inputs . There are two processes to construct the supervised model . The ﬁrst process is the feature selection and extraction , and many environments can be used to transform and extract features , such as the frameworks described by [ 22 , 23 , 24 ] . The second process is selecting the subset of features to represent a certain label . In the feature selection process , feature redundancy is not required since it does not provide any more information . Furthermore , using irrelevant features does not provide useful information . Usually , to improve the primary features set , a set of experiments is carried out by deleting , adding or modifying features [ 22 ] . Also , the combinations of features could increase the performance of the model [ 25 ] . Laﬀerty et al [ 26 ] designed Conditional Random Fields ( CRFs ) for sequential classiﬁcation . CRFs are undirected statistical graphical models conditionally trained to segment and label sequence data . The named entity recognition problem can be 16 described as a sequence classiﬁcation problem . Thus , the CRFs framework could be used to assign labels to words in a sentence . A Biomedical Named Entity Recognizer ( ABNER ) [ 27 ] is used for molecular bi - ology text mining . It is an open - source software tool with a graphical user interface , and each user can use the tool by typing texts manually or automatically to highlight the biological name entities . This system was built using linear - chain CRFs with other features such as contextual and orthographic , which mostly depend on term context or regular expressions . BANNER [ 28 ] is a supervised machine - learning system use CRFs for labeling and feature generation , such as context with a window of two and part - of - speech tagging as features . BANNER could be extended to build another named entity recognizer , such as DNorm [ 9 ] . DNorm uses BANNER to locate disease name mentions , and the features are based on a dictionary derived from the Uniﬁed Medical Language System ( UMLS ) [ 29 ] , and then the output mentions are used for additional string processing . As an example , the short - form abbreviations found in mentions are replaced with their long form . Also , punctuation and stop words are removed , and tokens are then stemmed using Porter Stemmer [ 30 ] . In the ﬁnal step to generate a candidate for each mention , all the mentions and the disease names in MEDIC are represented in the vector space , and then they search for the maximum scoring function from the training data . ChemSpot [ 31 ] is a novel machine - learning framework based on CRFs and a dic - tionary . It is used as a named entity recognizer to identify chemical mentions in natural language texts . Employing hybrid NER approaches by combining CRFs and a dictionary is highly beneﬁcial . CRFs are used to extract morphologically chemical name entities , whereas a dictionary is used to extract trivial names , and short and structured names of drugs . All the previous methods need predeﬁned sets of features , and the extraction 17 of features from the gold standard annotations . These methods highly depend on training data to recognize name entities . However , the construction of gold standard corpora is a diﬃcult , time - consuming process . Also , the size and quality of the annotations are highly aﬀected by the availability of task - speciﬁc annotators which directly inﬂuence the development of the gold standard corpora [ 32 ] . Some studies , such as [ 33 , 34 ] have examined the impact of combining features using domain - independent feature sets , such as contextual and lexical features . Using a combination of diﬀerent feature sets eﬀectively improves the performance of the designed NER system . Furthermore , considering orthographic and morphological features , such as capitalization , punctuation , word shape patterns and stop words , is very important in designing supervised model approaches , since it yields promising results . For example , combining diﬀerent sets of features is advantageous , since they detect the named entity boundaries [ 34 ] . The CheNER - BioC [ 35 ] is a chemical named entity recognizer . It uses a hybrid system that employs CRFs together with regular expression taggers and dictionaries , to identify chemical entities in the biomedical literature . The system performs better than when only one approach is used in the designing process . 2 . 3 Ontologies Ontologies could be deﬁned as a domain vocabulary , where each ontology class and relation is associated with a list of terms . In addition , ontologies could provide descriptive information such as textual descriptions and deﬁnitions to describe what type of things refer to a class or relation [ 36 ] . In this study , the Human Disease Ontology ( DO ) [ 37 ] was used to identify what kind of class each disease name refers to . It is a comprehensive vocabulary domain for human disease representation . The following example illustrates a class from Human Disease Ontology ( DO ) : [ 37 ] : • The class id is DOID _ 1781 . 18 • The class label is thyroid cancer . • The class synonyms are a malignant tumor of thyroid gland | thyroid neoplasm | malignant neoplasm of thyroid gland | neoplasm of thyroid gland | thyroid gland neoplasm . 2 . 4 Word embedding Word embeddings are mathematical objects that represent the words using an un - supervised approach , often called word vectors . They are very good at capturing information about word co - occurrences and therefore their semantic and syntactic characteristics in language . This characterizes the relationship between words by a speciﬁc relation vector [ 38 ] . Several NER tasks [ 39 , 40 ] successfully use word embed - dings as features for training purposes . Some examples of word embedding models are listed below . 2 . 4 . 1 Word2vec Mikolov et al . [ 41 ] designed the Word2Vec model , which is a word embedding model , where each word is represented by a vector . This is useful in grouping the vectors of similar words in the same vector space . Moreover , word2Vec provides two archi - tectures : Continuous Bag - Of - Words ( CBOW ) and Skip - Gram ( SG ) . The Word2Vec model does not consider the order of the word in the context . The CBOW architecture uses neighboring words to predict each word vector . It uses a bag of words to represent the input layer . The order of the words in the context does not aﬀect the projection of the word vector in the vector space . The SG architecture uses a single word to predict the context of the neighboring words , and it can be used in sentences to predict the neighboring words . Theoretically , SG usually gives higher accuracy for rare or infrequent words . On the other hand , CBOW works well with a large amount of data and gives better accuracy for frequent words . 19 2 . 4 . 2 BERT Bidirectional Encoder Representations from Transformers ( BERT ) [ 42 ] is a new word embedding model . It is designed to jointly condition left and right context to pre - train deep bidirectional representations from the unlabeled text in all layers . As a result , the BERT model can be used to create models for a variety of tasks , such as named entity recognition and question answering problems . The objective of the model is to predict word embeddings based on the context , and it uses the left and right context and the order of the word to generate word vector . 20 Chapter 3 Problem Statement There are many advantages and disadvantages associated with lexical approaches . On the positive side , lexical approaches use dictionaries which are hand - constructed , and they capture rules and regulations that are not discovered statistically [ 43 ] . Fur - thermore , lexical approaches might use rule - based systems structured by a deﬁned set of rules . On the other hand , lexical approach systems depend highly on the pre - deﬁned rules or names , and this could aﬀect the system quality because many disease names are lost or not recognized since they are not supported by the system or they might not exist in the dictionary used . Also , lexical approaches do not use context to distinguish if the mention found is a real mention or not . One successful approach to address the named entity recognition is to use a su - pervised learning approach , which requires good preparation of the training data to classify the set of labels . However , using this approach has two major drawbacks : First , it requires a human - annotated data set . Second , the performance is highly dependent on the amount of the labeled training data set available [ 44 ] . The challenge of this project is to ﬁnd a method that can use the strengths of lexical approaches and supervised approaches , to design a named entity recognizer . Our ﬁrst hypothesis is that disease names appear in a certain context structure . As a result , the context of mention can be used to determine whether a term refers to a disease name or not , for example : • Cancer is a group of diseases involving abnormal cell growth . 21 • Cancer is an astrological sign . From the given examples , the term cancer term was used to refer to a disease name only in the ﬁrst example based on the context , while the term " cancer " was not used as a disease name in the second example . Our second hypothesis is that many disease names in the disease ontology are very speciﬁc , clear and unique and cannot be used to refer to any other entity than to the disease itself . As a result , if most of the disease names are used , they will only refer to a disease , for example , retinoblastoma , ataxia - telangiectasia , and anemia . In contrast , a few disease names in the Disease Ontology occur very frequently and when they are used they usually do not refer to a disease , for example cancer , ADD , and trauma . 22 Chapter 4 Materials and Methods 4 . 1 Data resources 4 . 1 . 1 Corpus The National Center for Biotechnology Information ( NCBI ) disease corpus [ 45 ] , is used in the task of disease named entity recognition as a gold standard resource . The research resource is fully annotated in the mentioned level for 693 PubMed abstracts , where each abstract was manually annotated for disease mentions by two human annotators . For the annotation purposes each disease mention was annotated using MeSH [ 46 ] and OMIM [ 47 ] . Pre - annotations were done as a pre - step using PubTator [ 48 ] before the manual annotation step . The corpus is divided into two subsets as described in Table 4 . 1 . Table 4 . 1 : Size of the NCBI disease corpus Setup Abstracts Mentions Training subset 593 5145 Test 100 960 4 . 1 . 2 Disease resources The Human Disease Ontology ( DO ) [ 37 ] was used to identify disease name mentions . In addition to this , MEDIC was used as a disease vocabulary resource , because it merges Online Mendelian Inheritance in Man ( OMIM ) [ 47 ] with the diseased part of Medical Subject Headings ( MeSH ) [ 46 ] . It was created to index diseases in biomedical 23 literature and to ﬁnd relations between the disease names and their classes by the Comparative Toxicogenomic Database . 4 . 2 Lexical baseline The ﬁrst task of the project was to automatically identify the disease name mentions in texts . My hypothesis was to build a lexical baseline to see how it would perform on the NCBI training disease corpus [ 45 ] . The lexical baseline architecture is illustrated in Figure 4 . 1 , where the input for the was my NCBI training disease corpus where I created my dictionary using the DO and the Comparative Toxicogenomic Database because it combines MESH and OMIM . Figure 4 . 1 : The lexical baseline architecture This baseline was designed to ﬁnd the full exact string matches between the texts in question and the mappable dictionaries . All texts were normalized by , lowercasing all the letters . Also , we removed the noise by removing all the stop words . However , before this step , we ignored the stop words that exist in the disease ontologies , such as ( IS ) and ( AND ) . The output from the lexical baseline was a list of mentions representing the matches between the text and the dictionary . After some investigations on the ex - tracted list of mentions , it was clear that lexical baselines cannot distinguish between 24 disease mentions and non - disease mentions using context . An example will be given to illustrate : • The amount of DNA required to be searched for novel coding sequences consti - tutes the HFE defect . • Markers display no signiﬁcant association with HFE . The lexical baseline annotates ’HFE’ in both mentions while it is only used as a disease in the ﬁrst mention . 4 . 3 BERT To further distinguish between diseases and entities that are very similar to each other but are non - diseases , based on our ﬁrst hypothesis , it was found that disease names appear in certain context structures . The context of the mention was used to determine whether a term refers to a disease name or not , by utilizing the BERT model [ 42 ] , because it is proven that BERT could capture the diﬀerent context in which a word may appear . Figure 4 . 2 : BERT 25 The BERT model was used to identify the diﬀerent contexts in which the disease names appear . Figure 4 . 2 shows that the input to the BERT model is the NCBI training disease corpus , where the pre - trained model of BERT on the Pubmed corpora was used , to generate BERT word embeddings by using the context of each abstract in the NCBI training corpus [ 45 ] . The output is the list of vectors representing the list of mentions extracted from the lexical baseline . 4 . 4 K - mean clustering The K - mean cluster divides a given data set into a certain number of clusters . The main idea of the algorithm is to deﬁne k centers , one for each cluster [ 49 ] . In order to understand the hidden patterns and structures of BERT vectors , the K - mean clustering algorithm was used on the BERT [ 42 ] vectors of the disease name mentions , while varying the K with diﬀerent numbers 2 , 3 , 4 and 5 . The results of the generated clusters by the algorithm was documented , and each of the clusters contained a diﬀerent number of disease mentions according to the number of clusters . According to our second hypothesis , many disease names in the disease ontology are very speciﬁc and unique and cannot be used to refer to any other entity than to the disease itself . Also , they are not ambiguous . As an example , it is rare to ﬁnd a speciﬁc disease name like ’urogenital abnormalities’ when it is not used as a disease name . On the other hand , a few diseases have ambiguous terms and they are frequently mentioned in diﬀerent contexts . For instance , acronyms , abbreviations , and some words can be used to refer to diseases and other entities as well . We have done some manual analysis of the clusters , to ﬁnd how many unique disease names are mentioned in each cluster . In our hypothesis , the cluster which contains the few diseases that occur frequently , does not refer to a disease when the disease mentions are used . On the other hand , if we had a large amount of unique 26 disease names in the cluster , we consider this cluster as a true cluster , that contains clear and speciﬁc disease names , because it is rare to ﬁnd speciﬁc disease names used frequently with a diﬀerent context . Based on the above - mentioned hypothesis , and to reﬂect our second hypothesis , we used a ratio , as a measurement to see how many unique terms exist in each cluster . The equation for the ratio is : Ratio = Number of unique terms Number of mentions ( 4 . 1 ) After calculating the ratio for each cluster , we could say that a low ratio means that the cluster contains generic words that are frequently mentioned in a diﬀerent context . On the other hand , a high ratio means the cluster contains real disease mentions , where only disease names are used . 4 . 5 Supervised training The ﬁnal model architecture is shown in Figure 4 . 3 , where a supervised model was trained to predict whether a disease name mention refers to a disease or not . We used the cluster with the lowest ratio to represent the negatives , and the cluster with the highest ratio to represent the positives , to train our logistic regression [ 50 ] . As a result , all the disease mentions in the cluster with the highest ratio are positives , while all the disease mentions in the cluster with the lowest ratio were used as negatives , which refer to non - diseases . Our ﬁnal model used the supervised classiﬁer , with an additional ﬁlter to ﬁnally distinguish between disease mentions and non - disease mentions . The additional ﬁlter is dictionary - based , and was created using DO and the Comparative Toxicogenomic Database . If the ﬁlter found an exact match in the dictionary , the matches were immediately classiﬁed as positives . Moreover , the ﬁlter made approximate matching 27 Figure 4 . 3 : Final model for the ones classiﬁed as positives from the classiﬁer , but not exactly matched in the dictionary , by using the edit distance and the diﬀerence in the last character as a measurement of matching . As an example , if ’cancers’ is classiﬁed as a disease in my classiﬁer but does not exactly match any term in the dictionary , we calculate the edit distance and we check if the diﬀerence is on the last character . Then , we consider it a positive match . 28 Chapter 5 Results & Discussion The lexical baseline was used to extract disease mentions from the NCBI training corpus [ 45 ] . The baseline uses the full exact string - matching method to ﬁnd matches between the texts in question and the mappable dictionary , that was built using disease ontologies . 3028 disease mentions were extracted from the NCBI training corpus [ 45 ] . The aim of the next step was to distinguish the context between diseases and entities that are very similar to them but are false . BERT [ 42 ] word embedding was used , to generate vector representation of each disease name mention found in the abstract by the lexical baseline . Since 3028 disease mentions were extracted from the NCBI training corpus [ 45 ] , 3028 vector representations of each disease name mention were generated based on the context . To see if the vectors are distinguishable , K - mean cluster was used while varying the K with diﬀerent numbers 2 , 3 , 4 and 5 . Each of the 3028 vector representations of the disease name mentions extracted by the lexical baseline and represented by BERT , were clustered into diﬀerent numbers . The results of the clusters generated by the algorithm are shown in Tables 5 . 1 , 5 . 2 , 5 . 3 , 5 . 4 . A manual analysis of the clusters was done , to ﬁnd how many unique disease names are mentioned in each cluster , and to ﬁnd the ratio between the number of unique diseases mentioned in a cluster and the total number of disease names in the cluster . As a result , a low ratio means that the cluster contains generic words which are frequently mentioned with a diﬀerent context , and this is considered to be the false 29 Table 5 . 1 : K - Mean cluster with K = 2 Cluster Number Disease mentions Unique disease names Ratio 1 2533 351 13 % 2 495 28 5 % Table 5 . 2 : K - Mean cluster with K = 3 Cluster Number Disease mentions Unique disease names Ratio 1 872 207 23 % 2 1662 279 16 % 3 492 24 4 % Table 5 . 3 : K - Mean cluster with K = 4 Cluster Number Disease mentions Unique disease names Ratio 1 1320 290 21 % 2 350 110 31 % 3 865 141 16 % 4 493 26 5 % Table 5 . 4 : K - Mean cluster with K = 5 Cluster Number Disease mentions Unique disease names Ratio 1 1292 289 22 % 2 320 101 31 % 3 348 109 31 % 4 575 101 17 % 5 493 26 5 % cluster . On the other hand , a high ratio means that the cluster contains a large amount of unique and real disease names , where only disease names are used because it is rare to ﬁnd a speciﬁc disease name used frequently with a diﬀerent context . As shown in Figure 5 . 1 , the red cluster contains almost 500 mentions with only 26 unique terms , which means this is the cluster that contains the few diseases that occur frequently and when they are used they usually do not refer to a disease . On the other hand , if we look at the green clusters we will see that they contain clear and speciﬁc disease names . Moreover , the other clusters are not used since they do not contain crucial information the could backup our second hypothesis because they might contain abbreviations or generic words . 30 Figure 5 . 1 : K - mean clustering For the ﬁnal training , we chose the K - Mean cluster with K = 4 , because it gave us the highest accuracy on the training set , since it contains the second cluster with the highest ratio equal to 31 % . Also , the fourth cluster with the lowest ratio equals 5 % . Finally , we used all the disease mentions in the cluster with the highest ratio , and the cluster with the lowest ratio to train our supervised classiﬁer . The cluster with the highest ratio was used as a positive cluster , which represents the real disease mentions , and the cluster with the lowest ratio was used as a negative cluster , which refers to non - diseases . 5 . 1 Testing process NCBI testing disease corpus [ 45 ] contains 100 abstracts with 960 annotated disease name mentions , as our ﬁrst approach to overcoming the limitations of multi - word mentions . All the multi - word disease name mentions were connected with the under - score _ symbol , such as the following case : • Before : Clustering of missense mutations in the < category = " Modiﬁer " > ataxia - 31 telangiectasia < / category > gene in a < category = " SpeciﬁcDisease " > sporadic T - cell leukaemia < / category > . • After : Clustering of mutations in the ataxia - telangiectasia gene in a sporadic _ T - cell _ leukaemia . The next step was lower - casing and removing the stop words . In the previous step , we ignored the stop words that exist in the disease ontologies like ( IS ) and ( AND ) , after that we tokenized each abstract , then we removed all the punctuation . Then , we generated BERT vectors for all the input words by using the whole abstract . Finally , our model was used to classify if the input words are diseases or not . Where Class 1 is the positive prediction it represents terms that are classiﬁed as diseases . On the other hand , Class 2 is the predicted negatives that represent terms that are classiﬁed as non - diseases . The testing procedure is shown in Figure 5 . 2 Figure 5 . 2 : Testing procedure 5 . 2 Evaluation To evaluate the ﬁnal model after the testing procedure was made , the binary classiﬁer model had two classes ; Class 1 is the predicted diseases , and Class 2 is the predicted non - diseases . The model output four outcomes are listed below : • True Positives ( TP ) : terms labeled as positive that are positive disease names 32 • False Positives ( FP ) : terms labeled as positive that are negative non - disease names • True Negatives ( TN ) : terms labeled as negative that are negative non - disease names • False Negatives ( FN ) : terms labeled as negative that are actually positive disease names The ﬁnal model results are shown in Table 5 . 5 , and these results were calculated as follows [ 51 ] : P recision ( P ) = T P T P + F P ( 5 . 1 ) Recall ( R ) = T P T P + F N ( 5 . 2 ) F 1 − score = 2 P R P + R ( 5 . 3 ) Macro − Averaged P recision = P recision Class1 + P recision Class1 2 ( 5 . 4 ) Macro − Averaged Recall = Recall Class1 + Recall Class2 2 ( 5 . 5 ) W eighted − Averaged P recision = P Class1 C 1 + P Class2 C 2 C 1 + C 2 ( 5 . 6 ) W eighted − Averaged Recall = R Class1 C 1 + R Class2 C 2 C 1 + C 2 ( 5 . 7 ) Table 5 . 5 : Performance of our model Setup Precision Recall F1 - score Class1 84 % 68 % 75 % Class2 97 % 99 % 98 % MacroAveraged 91 % 84 % 87 % WeightedAveraged 95 % 96 % 96 % Where C1 is the true number of disease names in the testing data set , and C2 is the true number of non disease names in the testing data set , our model has a high accuracy rate of 96 % . As our main task to design a named entity recognizer , Class 33 1 represents predicted disease names mentioned in the text . The precision of Class 1 was 84 % , because it was aﬀected by the false positives , where some terms were labeled as positive diseases , but they were in fact non - disease names . Two examples are given below : • Mutations in a novel gene ( WFS1 ) encoding a putative transmembrane protein were found in all aﬀected individuals in six < category = " Modiﬁer " > WFS < / category > families , and these mutations were associated with the disease phenotype . WFS1 appears to function in the survival of islet beta - cells and neurons . • < category = " Modiﬁer " > Wilms tumor < / category > 1 ( WT1 ) genes are essen - tial . In the ﬁrst case , WFS is an abbreviation used to refer to Wolfram syndrome , and the WFS mentioned in the text is annotated as a modiﬁer in the test set . However , the other terms WFS1 are abbreviations used to refer to ’Wolfram syndrome type 1’ and they are mentioned but not annotated by the human annotators as disease names . Therefor , they are considered as false positive . In the second case , the human annotator only annotated the Wilms tumor as a disease name but they didn’t consider the abbreviation used to refer to the disease name WT1 , and when we found it we considered it as false positive . Moreover , the recall result of 68 % was highly aﬀected by the false negatives , and terms labeled as negative , that are positive disease names , were annotated by the human annotator . They are negatively labeled as non - diseases , due to two reasons ; either they do not exist in the disease ontologies or they are annotated as nested terms , as in this example : • < category = " Modiﬁer " > breast / ovarian cancer < / category > In this example , the annotator annotates ’breast / ovarian cancer’ together , and it is impossible to ﬁnd this match in the disease ontologies used in this model . Moreover , 34 most of the positive disease names are labeled as false negatives because of the term variations not present in the disease ontologies . One of the main challenges in this study is to design a disease name recognizer , which can out - perform other lexical models . It is clear from Table 5 . 6 that our model outperforms the lexical models . Firstly , we compared our model against the full exact string matching lexical baseline . Secondly , we compared our model against the exact and approximate string matching lexical baseline , where we removed the punctuation as a preprocessing step . The results shows that our model performed better than the other lexical ap - proaches . These results were expected in lexical baselines , because the precision was aﬀected by the ambiguous and nested terms . Also , lexical approaches do not consider the term variability . Table 5 . 6 : Performance compared against lexical baselines Setup Precision Recall F - measure Lexical Baseline Without preprocessing 35 % 61 % 44 % With preprocessing 42 % 68 % 51 % Our Model 84 % 68 % 75 % The next evaluation that was done , was a comparison of our unsupervised model with another supervised model , called Banner [ 45 ] . As shown in Table 5 . 7 our unsu - pervised model shows a slightly better performance in precision . On the other hand , the performance is lower compared to the other measurement scores . As a result , our unsupervised model still shows great potential , since the per - formance could be enhanced by many factors such as adding more training data or adding more ﬁlters . Table 5 . 7 : Performance compared against another supervised model Approach Setup Precision Recall F - measure Supervised Banner 83 % 80 % 81 % Unsupervised Our model 84 % 68 % 75 % 35 Chapter 6 Concluding Remarks Diseases are important entities in biomedical research , and identifying mentions of diseases is essential to many text mining tasks in the biomedical research ﬁeld [ 6 ] . To enable access to disease information , NER models are used , since they automatically identify the name of the biological entity mentioned in the text [ 3 ] in our case diseases . However , this is not an easy task because there are many diﬃculties that could arise such as the annotated mention not referring to a disease name . The aim of this study is to design a name entity recognizer that can identify mentions of disease names in texts , and also to overcome the drawbacks of the other approaches such as lexical and supervised approaches . The main drawbacks of those approaches are that the performance is aﬀected by the available amount of human - annotated data sets . Moreover , lexical approaches cannot distinguish between real mentions of diseases and mentions of other entities that share the same name or acronym . To overcome the aforementioned problems , a novel model was designed to rec - ognize disease mentions in the text , by using an unsupervised approach with several steps . Firstly , a lexical approach was used to extract the initial training set . Secondly , the initial training set was represented in vectors using Bert . Thirdly , the Bert vec - tors were clustered using K - mean clustering model . Finally , a supervised model was trained using the generated clusters from the previous step , and a ﬁlter was applied to further distinguish diseases and non - diseases . The results of the model show a high accuracy rate of 96 % and a high precision 36 rate of 84 % . In addition to identifying disease terms , the model was able to identify what the non - diseases terms are with high precision and recall . Most of the disease terms were identiﬁed except for the nested terms and the terms that do exist in our dictionary due to several reasons such as the type of the disease . Moreover , we are interested in expanding our model to include genes and drug ontologies , to annotate disease names , genes , and drugs . Furthermore , we plan to train and test our model using the Pubmed abstracts with more than one entity . Also , much more work is needed to improve the performance by adding additional string processing and more disease vocabularies . 37 REFERENCES [ 1 ] M . Krallinger and A . Valencia , “Text - mining and information - retrieval services for molecular biology , ” Genome biology , vol . 6 , no . 7 , p . 224 , 2005 . [ 2 ] A . Kao and S . R . Poteet , Natural language processing and text mining . Springer Science & Business Media , 2007 . [ 3 ] H . Cho , W . Choi , and H . Lee , “A method for named entity normalization in biomedical articles : application to diseases and plants , ” BMC bioinformatics , vol . 18 , no . 1 , p . 451 , 2017 . [ 4 ] E . F . Sang and F . De Meulder , “Introduction to the conll - 2003 shared task : Language - independent named entity recognition , ” arXiv preprint cs / 0306050 , 2003 . [ 5 ] R . L . Simmons , “The phrase , ” chompchomp , 2014 . [ 6 ] R . I . Dogan and Z . Lu , “An inference method for disease name normalization , ” in 2012 AAAI Fall Symposium Series , 2012 . [ 7 ] Q . Wei , T . Chen , R . Xu , Y . He , and L . Gui , “Disease named entity recogni - tion by combining conditional random ﬁelds and bidirectional recurrent neural networks , ” Database , vol . 2016 , 2016 . [ 8 ] L . E . Hunter , The processes of life : an introduction to molecular biology . Mit Press , 2012 . [ 9 ] R . Leaman , R . Islamaj Doğan , and Z . Lu , “Dnorm : disease name normalization with pairwise learning to rank , ” Bioinformatics , vol . 29 , no . 22 , pp . 2909 – 2917 , 2013 . [ 10 ] M . Narayanaswamy , K . Ravikumar , and K . Vijay - Shanker , “A biological named entity recognizer , ” in Biocomputing 2003 . World Scientiﬁc , 2002 , pp . 427 – 438 . [ 11 ] I . Budi and S . Bressan , “Association rules mining for name entity recognition , ” in Proceedings of the Fourth International Conference on Web Information Systems Engineering , 2003 . WISE 2003 . IEEE , 2003 , pp . 325 – 328 . 38 [ 12 ] S . Eltyeb and N . Salim , “Chemical named entities recognition : a review on ap - proaches and applications , ” Journal of cheminformatics , vol . 6 , no . 1 , p . 17 , 2014 . [ 13 ] W . A . Kibbe , C . Arze , V . Felix , E . Mitraka , E . Bolton , G . Fu , C . J . Mungall , J . X . Binder , J . Malone , D . Vasant et al . , “Disease ontology 2015 update : an expanded and updated database of human diseases for linking biomedical knowl - edge through disease data , ” Nucleic acids research , vol . 43 , no . D1 , pp . D1071 – D1078 , 2014 . [ 14 ] D . S . Wishart , C . Knox , A . C . Guo , D . Cheng , S . Shrivastava , D . Tzur , B . Gau - tam , and M . Hassanali , “Drugbank : a knowledgebase for drugs , drug actions and drug targets , ” Nucleic acids research , vol . 36 , no . suppl _ 1 , pp . D901 – D906 , 2007 . [ 15 ] K . M . Hettne , R . H . Stierum , M . J . Schuemie , P . J . Hendriksen , B . J . Schijve - naars , E . M . v . Mulligen , J . Kleinjans , and J . A . Kors , “A dictionary to identify small molecules and drugs in free text , ” Bioinformatics , vol . 25 , no . 22 , pp . 2983 – 2991 , 2009 . [ 16 ] M . Gerner , G . Nenadic , and C . M . Bergman , “Linnaeus : a species name iden - tiﬁcation system for biomedical literature , ” BMC bioinformatics , vol . 11 , no . 1 , p . 85 , 2010 . [ 17 ] A . T . McCray , R . F . Loane , A . C . Browne , and A . K . Bangalore , “Terminology issues in user access to web - based medical information . ” in Proceedings of the AMIA Symposium . American Medical Informatics Association , 1999 , p . 107 . [ 18 ] K . Kukich , “Techniques for automatically correcting words in text , ” Acm Com - puting Surveys ( CSUR ) , vol . 24 , no . 4 , pp . 377 – 439 , 1992 . [ 19 ] E . Leopold and J . Kindermann , “Text categorization with support vector ma - chines . how to represent texts in input space ? ” Machine Learning , vol . 46 , no . 1 - 3 , pp . 423 – 444 , 2002 . [ 20 ] D . M . Lowe and R . A . Sayle , “Leadmine : a grammar and dictionary driven approach to entity recognition , ” Journal of cheminformatics , vol . 7 , no . 1 , p . S5 , 2015 . [ 21 ] T . O . Ayodele , “Types of machine learning algorithms , ” in New advances in machine learning . IntechOpen , 2010 . [ 22 ] B . Broda , P . Kędzia , M . Marcińczuk , A . Radziszewski , R . Ramocki , and A . Wardyński , “Fextor : A feature extraction framework for natural language 39 processing : A case study in word sense disambiguation , relation recognition and anaphora resolution , ” in Computational Linguistics . Springer , 2013 , pp . 41 – 62 . [ 23 ] A . Radziszewski , A . Wardyński , and T . Śniatowski , “Wccl : A morpho - syntactic feature toolkit , ” in International Conference on Text , Speech and Dialogue . Springer , 2011 , pp . 434 – 441 . [ 24 ] L . Padró , M . Collado , S . Reese , M . Lloberes , and I . Castellón , “Freeling 2 . 1 : Five years of open - source language processing tools , ” in 7th International Conference on Language Resources and Evaluation , 2010 . [ 25 ] A . Usié , R . Alves , F . Solsona , M . Vázquez , and A . Valencia , “Chener : chemical named entity recognizer , ” Bioinformatics , vol . 30 , no . 7 , pp . 1039 – 1040 , 2013 . [ 26 ] J . Laﬀerty , A . McCallum , and F . C . Pereira , “Conditional random ﬁelds : Prob - abilistic models for segmenting and labeling sequence data , ” 2001 . [ 27 ] B . Settles , “Abner : an open source tool for automatically tagging genes , proteins and other entity names in text , ” Bioinformatics , vol . 21 , no . 14 , pp . 3191 – 3192 , 2005 . [ 28 ] R . Leaman and G . Gonzalez , “Banner : an executable survey of advances in biomedical named entity recognition , ” in Biocomputing 2008 . World Scientiﬁc , 2008 , pp . 652 – 663 . [ 29 ] O . Bodenreider , “The uniﬁed medical language system ( umls ) : integrating biomedical terminology , ” Nucleic acids research , vol . 32 , no . suppl _ 1 , pp . D267 – D270 , 2004 . [ 30 ] M . F . Porter , “An algorithm for suﬃx stripping , ” Program , 2006 . [ 31 ] T . Rocktäschel , M . Weidlich , and U . Leser , “Chemspot : a hybrid system for chemical named entity recognition , ” Bioinformatics , vol . 28 , no . 12 , pp . 1633 – 1640 , 2012 . [ 32 ] L . Wissler , M . Almashraee , D . M . Díaz , and A . Paschke , “The gold standard in corpus annotation . ” in IEEE GSC , 2014 . [ 33 ] M . Tkachenko and A . Simanovsky , “Named entity recognition : Exploring fea - tures . ” in KONVENS , 2012 , pp . 118 – 127 . [ 34 ] H . Wang , T . Zhao , H . Tan , and S . Zhang , “Biomedical named entity recognition based on classiﬁers ensemble . ” IJCSA , vol . 5 , no . 2 , pp . 1 – 11 , 2008 . 40 [ 35 ] A . Usié , J . Cruz , J . Comas , F . Solsona , and R . Alves , “A tool for the identiﬁ - cation of chemical entities ( chener - bioc ) , ” in BioCreative Challenge Evaluation Workshop , vol . 2 . Citeseer , 2013 , p . 66 . [ 36 ] R . Hoehndorf , P . N . Schoﬁeld , and G . V . Gkoutos , “The role of ontologies in biological and biomedical research : a functional perspective , ” Brieﬁngs in bioin - formatics , vol . 16 , no . 6 , pp . 1069 – 1080 , 2015 . [ 37 ] P . L . Whetzel , N . F . Noy , N . H . Shah , P . R . Alexander , C . Nyulas , T . Tudorache , and M . A . Musen , “Bioportal : enhanced functionality via new web services from the national center for biomedical ontology to access and use ontologies in soft - ware applications , ” Nucleic acids research , vol . 39 , no . suppl _ 2 , pp . W541 – W545 , 2011 . [ 38 ] T . Mikolov , W . - t . Yih , and G . Zweig , “Linguistic regularities in continuous space word representations , ” in Proceedings of the 2013 Conference of the North Ameri - can Chapter of the Association for Computational Linguistics : Human Language Technologies , 2013 , pp . 746 – 751 . [ 39 ] J . Turian , L . Ratinov , and Y . Bengio , “Word representations : a simple and general method for semi - supervised learning , ” in Proceedings of the 48th annual meeting of the association for computational linguistics . Association for Com - putational Linguistics , 2010 , pp . 384 – 394 . [ 40 ] R . Collobert , J . Weston , L . Bottou , M . Karlen , K . Kavukcuoglu , and P . Kuksa , “Natural language processing ( almost ) from scratch , ” Journal of machine learn - ing research , vol . 12 , no . Aug , pp . 2493 – 2537 , 2011 . [ 41 ] T . Mikolov , K . Chen , G . Corrado , and J . Dean , “Eﬃcient estimation of word representations in vector space , ” arXiv preprint arXiv : 1301 . 3781 , 2013 . [ 42 ] J . Devlin , M . - W . Chang , K . Lee , and K . Toutanova , “Bert : Pre - training of deep bidirectional transformers for language understanding , ” arXiv preprint arXiv : 1810 . 04805 , 2018 . [ 43 ] P . Resnik , “Wordnet and distributional analysis : A class - based approach to lexi - cal discovery , ” in AAAI workshop on statistically - based natural language process - ing techniques , 1992 , pp . 56 – 64 . [ 44 ] R . Al - Rfou , V . Kulkarni , B . Perozzi , and S . Skiena , “Polyglot - ner : Massive multi - lingual named entity recognition , ” in Proceedings of the 2015 SIAM International Conference on Data Mining . SIAM , 2015 , pp . 586 – 594 . 41 [ 45 ] R . I . Doğan , R . Leaman , and Z . Lu , “Ncbi disease corpus : a resource for disease name recognition and concept normalization , ” Journal of biomedical informatics , vol . 47 , pp . 1 – 10 , 2014 . [ 46 ] M . H . Coletti and H . L . Bleich , “Medical subject headings used to search the biomedical literature , ” Journal of the American Medical Informatics Association , vol . 8 , no . 4 , pp . 317 – 323 , 2001 . [ 47 ] J . Amberger , C . Bocchini , and A . Hamosh , “A new face and new challenges for online mendelian inheritance in man ( omim® ) , ” Human mutation , vol . 32 , no . 5 , pp . 564 – 567 , 2011 . [ 48 ] C . - H . Wei , H . - Y . Kao , and Z . Lu , “Pubtator : a web - based text mining tool for assisting biocuration , ” Nucleic acids research , vol . 41 , no . W1 , pp . W518 – W522 , 2013 . [ 49 ] J . A . Hartigan and M . A . Wong , “Algorithm as 136 : A k - means clustering al - gorithm , ” Journal of the Royal Statistical Society . Series C ( Applied Statistics ) , vol . 28 , no . 1 , pp . 100 – 108 , 1979 . [ 50 ] F . Pedregosa , G . Varoquaux , A . Gramfort , V . Michel , B . Thirion , O . Grisel , M . Blondel , P . Prettenhofer , R . Weiss , V . Dubourg et al . , “Scikit - learn : Machine learning in python , ” Journal of machine learning research , vol . 12 , no . Oct , pp . 2825 – 2830 , 2011 . [ 51 ] C . Goutte and E . Gaussier , “A probabilistic interpretation of precision , recall and f - score , with implication for evaluation , ” in European Conference on Information Retrieval . Springer , 2005 , pp . 345 – 359 . 42 APPENDICES 43 A Papers Submitted and Under Preparation • Abeer Almutairi , and Robert Hoehndorf , " Unsupervised Method for Disease Named Entity Recognition " , under preparation .