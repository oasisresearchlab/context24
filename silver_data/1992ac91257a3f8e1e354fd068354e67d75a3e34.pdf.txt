How Do HCI Researchers Describe Their Software Tools ? Insights From a Synopsis Survey of Tools for Multimodal Interaction Mihail Terenti mihail . terenti @ usm . ro MintViz Lab , MANSiD Research Center Ştefan cel Mare University of Suceava Suceava , Romania Radu - Daniel Vatavu radu . vatavu @ usm . ro MintViz Lab , MANSiD Research Center Ştefan cel Mare University of Suceava Suceava , Romania ABSTRACT Providing tools to support design and engineering of interactive computing systems has been encouraged in the HCI community . However , little is known about the practices adopted by HCI re - searchers to describe their software tools in academic publications . To address this aspect , we implemented a simplified literature sur - vey procedure combining principles of population sampling and systematic literature reviews to enable rapid access to insights from a vast body of published academic work . We report that screenshots and diagrams are among the most widely used descriptive elements by HCI researchers to present their software tools , a finding that we capitalize on to reflect about the dissemination of tools for the de - sign and engineering of multimodal interaction at the intersection of software engineering and HCI . CCS CONCEPTS • Human - centered computing → Systems and tools for inter - action design ; Human computer interaction ( HCI ) . KEYWORDS Multimodal interaction , tools , platforms , literature survey . ACM Reference Format : Mihail Terenti and Radu - Daniel Vatavu . 2021 . How Do HCI Researchers Describe Their Software Tools ? Insights From a Synopsis Survey of Tools for Multimodal Interaction . In Companion Publication of the 2021 International Conference on Multimodal Interaction ( ICMI ’21 Companion ) , October 18 – 22 , 2021 , Montréal , QC , Canada . ACM , New York , NY , USA , 6 pages . https : / / doi . org / 10 . 1145 / 3461615 . 3485431 1 INTRODUCTION Tools are important in the HCI research and practice to support design and implementation of user interface software [ 23 ] , rapid prototyping of interactive systems [ 4 ] , encourage creativity [ 26 ] , inform design options [ 32 , 35 ] , analyze user input [ 34 ] , manage user - elicited data [ 18 ] , and support research to understand users [ 1 , 36 ] with evaluations , studies , and experiments [ 33 ] . Consequently , “tool contributions , ” as a specific type of an artifact contribution in HCI Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . ICMI ’21 Companion , October 18 – 22 , 2021 , Montréal , QC , Canada © 2021 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - 8471 - 1 / 21 / 10 . https : / / doi . org / 10 . 1145 / 3461615 . 3485431 research [ 37 ] , are particularly welcomed at HCI venues . For ex - ample , tools are explicitly encouraged by several subcommittees of CHI , e . g . , the User Experience and Usability subcommittee “is suitable for papers that extend the knowledge , practices , methods , components , and tools that make technology more useful , usable , and desirable , ” while the Design subcommittee of CHI specifies that “papers submitted here include [ . . . ] evaluation of new design tools , processes , methods , or principles , including those that explore alternatives to scientistic ways of knowing” 1 ( emphasis ours ) . Sim - ilarly , other HCI venues encourage tools , including “engineering design and evaluation tools ” at EICS , 2 “multimodal platforms” at ICMI , 3 “ tools for evaluating interactive systems” at INTERACT , 4 and “new methodologies and tools ” at IMWUT 5 ( emphasis ours ) ; see Figure 1 for examples extracted from papers published in these subcommunities of HCI . In this context , where tools are both needed and encouraged , it is useful to understand how HCI researchers describe their tool contri - butions when disseminating their results in order to document and understand this practice in our community . To this end , we perform a characterization of the ways in which HCI researchers describe their software tools in academic publications , and report results of a case study in multimodal interaction , an active area with a long tradition in HCI [ 8 ] and , hence , with established practices for providing tools . We use our findings to reflect on the dissemination of tools at the intersection of software engineering and HCI [ 17 ] . 2 RELATED WORK We discuss practices for documenting software applications in the software engineering community , and present an overview of prior surveys conducted on the topic of multimodal interaction related to the case study implemented in this work . 2 . 1 Documenting Software Applications Presenting a software application or tool to others implies employ - ing effective methods to document features and modes of oper - ation to demonstrate the usefulness of the software for the tar - get audience . Thus , software documentation for classes , libraries , frameworks , and platforms takes a variety of forms [ 20 ] . In formal projects , documentation is outside the source code , e . g . , it takes the form of unit development folders containing the developers’ notes 1 https : / / chi2021 . acm . org / for - authors / presenting / papers / selecting - a - subcommittee 2 https : / / eics . acm . org / eics2021 / submission _ fullpapers . html 3 https : / / icmi . acm . org / 2021 / index . php ? id = cfp 4 https : / / www . interact2021 . org / tracks / full _ papers . php 5 https : / / dl . acm . org / journal / imwut 7 ICMI ’21 Companion , October 18 – 22 , 2021 , Montréal , QC , Canada Terenti and Vatavu a b c d Figure 1 : Documenting software tools with screenshots , diagrams , code , and photographs : ( a ) screenshot of SAPIENS [ 28 ] , a software architecture for peripheral interaction , from EICS ’19 ; ( b ) UML class diagram of Flecto [ 14 ] , a rapid prototyping tool for foldable UIs , from ISS ’20 ; ( c ) API response of KeyTime [ 16 ] , a web - based tool for estimating gesture production time , from CHI ’18 ; and ( d ) photographs from using a C + + software library to test attacks on smartglasses [ 24 ] , from IMWUT 2020 . or detailed - design documents describing class - level and routine - level design decisions . Internal documentation lies within the source code , and takes the form of comments inserted by programmers , but especially is the result of a good programming style [ 20 ] . A widespread practice among software developers is the use of the “readme” file , usually written in markdown , that provides a short description of the software , how to compile and install it , and how to use it . More detailed technical documentations employ wiki sys - tems . 6 At community level , “get started” and “docs” sections and FAQ sections [ 10 ] of web pages and blogs [ 5 , 25 ] are common . In the context of HCI , Mehlenbacher [ 22 ] discussed the resistance or lack of interest in documentation development and evaluation , and identified five critical dimensions of all support documentation : audience , task types , information goals , physical and rhetorical dif - ferences of media , and genre or information type being developed . Earle et al . [ 9 ] examined user preferences of software documenta - tion genres ( product help , tutorials , samples , videos , articles , tech notes , forums , and blogs ) , and reported a strong preference for product help and tech notes . Severalstandardsexisttoprovide valuableinformationtoproviders of software applications , tools , and platforms . For instance , the 6 Compare them all | WikiMatrix , https : / / www . wikimatrix . org ISO / IEC / IEEE 26515 : 2018 standard on developing user documen - tation in an agile environment 7 acknowledges that “the documen - tation may be the first tangible item that the user sees , and so influences the first impressions the users have of the product” and “well designed documentation not only assists the users and helps to reduce the cost of training and support , but also enhances the reputation of the product , its producer , and its suppliers . ” The stan - dard focuses on specific concepts , such as the burndown chart ( a document for recording project status ) , system feature ( a distin - guishing characteristic of a system ) , persona ( the archetypal user of a system ) , scrum report ( documenting the daily activities of a scrum team ) , use case ( behavioral requirements of a system and interaction with the user ) , user story ( narrative illustrating user goals ) , and technical writer ( person in charge of the user docu - mentation ) . The IEEE Standard for Software User Documentation 8 provides “requirements for the structure , information content , and format of user documentation , to include both paper and electronic documentation used in the work environment by users of systems containing software . ” The standard focuses on concepts such as the user , action , illustration , tutorial , usage mode , and critical in - formation , and identifies fourteen components of software user documentation , from identification data and table of contents to navigational features , indexes , and search capability . 7 https : / / www . iso . org / obp / ui / # iso : std : iso - iec - ieee : 26515 : ed - 2 : v1 : en 8 https : / / ieeexplore . ieee . org / document / 974401 8 How Do HCI Researchers Describe Their Software Tools ? ICMI ’21 Companion , October 18 – 22 , 2021 , Montréal , QC , Canada 2 . 2 Surveys of Multimodal Interaction In this work , we choose to implement a case study in multimodal interaction . Our motivation is driven by the fact that multimodal interaction has a long tradition in HCI [ 8 ] and , consequently , more established practices are likely to exist for disseminating tools . There is a wide literature on the topic of multimodal interac - tion , including many surveys that have adopted various approaches to describe design , implementation , evaluation , and application of multimodal interactions [ 3 , 8 , 12 , 13 , 19 , 31 ] . For example , the goal of Jaimes and Sebe’s [ 13 ] survey was to present an overview of open issues in multimodal HCI by relating to computer vision ap - proaches , the affective part of human - computer interaction ( e . g . , emotion processing to make multimodal systems more natural and empathic ) , and system architecture to support multimodal interactions . Dumas et al . [ 8 ] focused on principles , models , and programming frameworks for multimodal user interfaces , high - lighting the potential of machine learning for this area . A survey of the state - of - the - art of the role played by and the benefits of multimodality in Virtual Reality was provided by Martin et al . [ 19 ] that focused on the potential of multimodal interactions to con - tribute to compelling experiences in virtual environments . Gürkök and Nijholt [ 12 ] surveyed Brain - Computer Interfaces for multi - modal interactions , stressing how they can significantly improve error handling , task performance , and user experience . Baig and Kavakli [ 3 ] focused on evaluation , input and output modalities , and data collection and fusion as challenges for multimodal systems , and concluded that multimodal application developers focus mostly on input , while the most widely employed input modalities are speech and gesture . Similar conclusions were drawn by Turk’s [ 31 ] survey on designing multimodal interfaces , including input and output , biological sensory integration , and multimodal integration . The research question addressed in our work— how do HCI re - searchers document their software tools to support design and engi - neering of multimodal interaction systems ? —can be seen as a com - plementary survey to the existing literature [ 3 , 8 , 12 , 17 , 19 , 31 ] , yet limited in depth ( see the next section introducing synopsis surveys ) reporting on how researchers have chosen to describe their pro - totypes , tools , libraries , frameworks , and applications designed to support multimodal interaction systems . 3 METHOD To understand existing practices in describing tools for multimodal interaction , we conducted a guided , targeted search of the scien - tific literature by adopting the procedure of Systematic Literature Reviews ( SLR ) [ 6 ] , but without running a comprehensive and exten - sive search of the literature as SLRs do . This approach is justified for our specific case study in multimodal interaction , as would be in other cases where a huge amount of work exists , that prevents a complete analysis of all the available work in reasonable time . 9 Our simplified approach employs the method of SLRs , while adopting the rationale of conducting scientific experiments , where a sample is used for the analysis instead of the entire population . From this 9 Many variants exist for conducting surveys , such as rapid reviews that employ the method of SLRs , but for which the completeness of searching is determined by time constraints , or systematizedreviews , thatattempttoincludeelementsoftheSLRprocess , while they stop short of a systematic review and are typically narrative ; see Grant and Booth [ 11 ] for an analysis of fourteen types of reviews and associated methodologies . perspective , we follow the sound procedure of SLRs and keep their desirable characteristics [ 29 ] , while arriving at rapid insights from a vast literature by exploring a sample of that literature , similar to how experimental research methods [ 15 ] lead to findings by extrap - olating the results obtained on a sample to the large population . We call this procedure a synopsis survey , 10 with several convenient char - acteristics : synopsis surveys are methodical , transparent , replicable , empirical , and rapid . The first three characteristics emerge from adopting the procedure of SLRs [ 29 ] ( described next ) , while the last two from the fact that we work with a sample of the literature . To implement our survey , we ran the following query : " query " : Title : ( multimodal AND ( tool * OR platform * ) AND ( interaction * OR interface * OR input ) ) " filter " : NOT VirtualContent : true , ACM Content : DL on the titles of papers from the ACM Full - Text Collection and found 49 results . We searched our combination of keywords just in the titles to limit the large number of results corresponding to papers that used “’multimodal , ” “interaction , ” or “interface” as part of their abstracts or full text and that were not relevant to our research question about tools for multimodal interaction . We also considered the following eligibility criteria ( ECs ) to screen these results : EC 1 . Content availability . The paper is written in English , the full text is available , and the paper was peer reviewed . Journal articles , conference papers , and other contributions are eligi - ble according to this criterion , while invited keynotes , book abstracts , and white papers are not . EC 2 . Eligible area . The paper is about multimodal interaction . EC 3 . Eligible topic . The paper presents , evaluates , or surveys tools or platforms to support multimodal interaction . A number of six results were discarded by not meeting eligibility criterion EC 1 , three were excluded by EC 2 , and ten did not present tools ( EC 3 ) . After the eligibility stage , we arrived at a number of 30 papers for subsequent analysis . During this analysis , we extracted the following characteristics and coded 11 the papers accordingly : ( 1 ) Inputmodalities . We usedthefollowingcategoriesthatemerged from our analysis : voice , gesture , WIMP , eye gaze , stylus input , and head & face input . ( 2 ) Output modalities : visual , aural , and haptic . Just like for input modalities , these categories emerged from our analysis . ( 3 ) Target users : researchers , developers , and other users . ( 4 ) Target platform addressed by the tool , with the following categories : desktop , mobile , and embodied ( robots ) . ( 5 ) Contribution . We extracted the contributions made by the papers describing tools for multimodal interaction : software application ( i . e . , the tool is a software that developers can use to design and create new systems ) , hardware prototype ( the tool relies on a hardware component , e . g . , a specific sensor , required for multimodal interaction ) , source code ( the authors release source code accompanying the previous two types of contributions ) , user study ( a study with users to validate the tool ) , and technical study ( results are reported about the technical performance of the tool ) . 10 According to Merriam - Webster , a synopsis is “a condensed statement or outline ( as of a narrative or treatise ) , ” https : / / www . merriam - webster . com / dictionary / synopsis . 11 The coding was done by the first author of this paper , while the second author cross - checked 20 % of the codings . 9 ICMI ’21 Companion , October 18 – 22 , 2021 , Montréal , QC , Canada Terenti and Vatavu Voice ( 33 . 3 % ) Gesture ( 20 . 3 % ) Head & face ( 4 . 4 % ) WIMP ( 27 . 5 % ) Aural ( 46 . 7 % ) Haptic ( 2 . 2 % ) Target platform Visual ( 51 . 1 % ) Target audience Developers ( 61 . 1 % ) Researchers ( 30 . 6 % ) End users ( 8 . 3 % ) Desktop Mobile Robots Input modalities Output modalities Eye gaze ( 8 . 7 % ) Stylus ( 5 . 8 % ) Contributions Software Hardware Source code User study Technical study Descriptive elements for documenting tools Screenshots ( 34 . 9 % ) Diagrams ( 26 . 2 % ) Performance charts ( 6 . 0 % ) Photographs ( 12 . 3 % ) Use cases ( 11 . 9 % ) Code snippets ( 8 . 7 % ) C o d e s n i pp e t s D i a g r a m s U s e c a s e s P h o t o s C h a r t s Screenshots Performance charts Photographs Use cases Diagrams Code snippets 2 + elements 3 + elements 4 + elements - 1 - 0 . 6 - 0 . 2 0 0 . 2 0 . 6 1 a b c d e f Figure 2 : Input and output modalities ( a , b ) , target audiences ( c ) , contributions ( d ) , target platforms ( e ) , and descriptive elements for documenting tools ( f ) extracted from the papers that we analyzed in our synopsis survey . ( 6 ) Descriptive elements employed to present and document tools , besides the textual description from the paper , with the fol - lowing categories emerging from our analysis : diagrams , code snippets , use cases , screenshots , photographs , and perfor - mance charts , respectively . 4 RESULTS The papers included in our final set were published between 1998 ( Cheyer and Julia’s [ 7 ] multimodal tools for the video analyst ) and 2020 ( Sarmah et al . ’s [ 27 ] Geno tool for authoring multimodal inter - action on existing web applications ) , and the majority ( 19 / 30 = 63 . 3 % ) were published at ICMI , the ACM International Conference on Mul - timodal Interaction ( formerly on Multimodal Interfaces ) . We found that the most common input modalities were voice ( 33 . 3 % ) , mouse and keyboard for the WIMP interaction paradigm ( 27 . 5 % ) , and gesture commands ( 20 . 3 % ) , followed by eye gaze , stylus input , and head movements and facial expressions ; see Figure 2a . These results match a conclusion from Baig and Kavakli’s [ 3 ] survey of multimodal systems based on 136 references , according to which the most widely employed input modalities in the literature were found to be speech and gesture—a result that builds confidence in our synopsis approach . Visual and aural modalities were approxi - mately balanced at 51 . 1 % and 46 . 7 % , respectively , while haptics was addressed by just one tool [ 21 ] ; see Figure 2b . We identified a total of 48 contributions , of which software ap - plications were the most common ( 50 % ) , followed by user studies ( 16 % ) to validate the tools , and hardware contributions ( 15 % ) to enable new input modalities , e . g . , the chemistry pod from Ander - son et al . ’s [ 2 ] multimodal tool for the classroom was designed to record audio from various locations in the classroom . The most widely addressed platform was desktop ( 73 % ) , while mobile plat - forms and robots were less represented ( 20 % and 17 % , respectively ) . Finally , tools were specifically addressed at developers ( 61 . 1 % ) and researchers ( 30 . 6 % ) and , in a few cases , at end users , such as video analysts [ 7 ] and instructors [ 2 ] ; see Figures 2c to 2e . Figure 2f shows the distribution of descriptive elements used by the authors of these papers to document and present their tools . We found that screenshots and diagrams were the most used ( 34 . 9 % and 26 . 2 % ) , followed by photographs of the tools ( 12 . 3 % ) and descrip - tions of use cases ( 11 . 9 % ) . A Pearson correlation analysis showed a significant positive correlation between the number of diagrams and code snippets ( r ( N = 30 ) = . 436 , p = . 05 ) employed to describe the tools , and several negative correlations ( not reaching statistical sig - nificance at α = . 05 , however ) between screenshots and photographs and screenshots and use cases , respectively . Screenshots and diagrams were also used in conjunction in 70 % of the papers identified in our synopsis survey , while diagrams and photographs were used together to present the tools in 43 . 3 % of the papers . A percent of 93 % 10 How Do HCI Researchers Describe Their Software Tools ? ICMI ’21 Companion , October 18 – 22 , 2021 , Montréal , QC , Canada of the tools were described using at least two descriptive elements , and 37 % with at least four descriptive elements , e . g . , Skantze and Al Moubayed [ 30 ] employed diagrams , photographs , code snippets , and a description of an use case for IrisTK , their toolkit for multi - party face - to - face interaction ; see Figure 2f , right . Our results show that screenshots and diagrams have been pre - ferred by HCI researchers and authors to describe their tools de - signed to support multimodal interaction . These findings make sense since , by definition , a tool implies engineering details that are communicated via platform - independent and programming language - independent diagrams showing the operation of the tool , e . g . , dataflows or UML classes , while screenshots are useful to exem - plify directly the end result to the audience . Using more descriptive elements , e . g . , diagrams and photographs , enables authors to de - scribe their tools better as well as corresponding use cases for the tools . However , our results also show a strong technical perspec - tive for presenting tools , with authors insisting more on technical aspects compared to use cases . By connecting this finding to the IEEE / ISO / IEC standards discussed in Section 2 , descriptions of per - sonas as archetypal users of a tool , narratives illustrating user goals , tutorials , illustrations of actions and steps to achieve user goals are missing from tool descriptions . This finding may seem surprising on a first look , but can be interpreted from the perspective that tools for multimodal interaction are situated at the intersection of software engineering and HCI . In this context , the audience is primarily rep - resented by researchers and practitioners that will use the tools to engineer new interactive computing systems ( EICS ) , and that speak the same language of EICS [ 17 ] , a strongly technically - oriented subcommunity of HCI . 5 CONCLUSION AND FUTURE WORK We reported results from a synopsis survey to form a preliminary understanding of how HCI researchers and authors describe soft - ware tools for multimodal interaction , and found that screenshots and diagrams are representative of the technically - oriented EICS subcommunity of HCI . Future work will examine the description of tools in other areas of HCI , such as tools for fabrication ( where more hardware contributions are expected ) or tools for conducting user experiments ( where use case descriptions and tutorials are likely to be more representative ) . These new case studies will complete our understanding of how the HCI community presents its tools , and will enable us to reapply synopsis surveys for other areas . We also acknowledge the limitations of our synopsis survey ap - proach as well as our focus on results from the ACM DL only and running our query on the paper titles alone . Nevertheless , a synop - sis survey has useful features , among which being replicable and providing rapid access to insights from areas where a vast amount of literature exists . Comparing synopsis surveys to other types of literature reviews [ 11 ] is recommended , along with formalizing synopsis surveys with population sampling methods and the use of inferential statistics to extrapolate the results obtained on a sample of papers to the wider scientific literature . ACKNOWLEDGMENTS This work is part of a project that has received funding from the Eu - ropean Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska - Curie grant agreement No 860114 . REFERENCES [ 1 ] AbdullahX . Ali , MeredithRingelMorris , andJacobO . Wobbrock . 2019 . Crowdlicit : ASystemforConductingDistributedEnd - UserElicitationandIdentificationStud - ies . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Sys - tems . ACM , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3290605 . 3300485 [ 2 ] Khalil J . Anderson , Theodore Dubiel , Kenji Tanaka , Marcelo Worsley , Cody Poultney , and Steve Brenneman . 2019 . Chemistry Pods : A Mutlimodal Real Time and Retrospective Tool for the Classroom . In Proceedings of the 2019 International Conference on Multimodal Interaction ( ICMI ’19 ) . ACM , New York , NY , USA , 506 – 507 . https : / / doi . org / 10 . 1145 / 3340555 . 3358662 [ 3 ] Muhammad Zeeshan Baig and Manolya Kavakli . 2020 . Multimodal Systems : Taxonomy , Methods , and Challenges . arXiv : 2006 . 03813 [ cs . HC ] https : / / arxiv . org / abs / 2006 . 03813 [ 4 ] Michel Beaudouin - Lafon and Wendy Mackay . 2002 . Prototyping Tools and Tech - niques . In The Human - Computer Interaction Handbook : Fundamentals , Evolving Technologies and Emerging Applications . L . Erlbaum Assoc . Inc . , USA , 1006 – 1031 . [ 5 ] Rebecca Blood . 2004 . How Blogging Software Reshapes the Online Commu - nity . Commun . ACM 47 , 12 ( Dec . 2004 ) , 53 – 55 . https : / / doi . org / 10 . 1145 / 1035134 . 1035165 [ 6 ] Pearl Brereton , Barbara A . Kitchenham , David Budgen , Mark Turner , and Mo - hamed Khalil . 2007 . Lessons from Applying the Systematic Literature Review ProcesswithintheSoftwareEngineeringDomain . JournalofSystemsandSoftware 80 , 4 ( 2007 ) , 571 – 583 . https : / / doi . org / 10 . 1016 / j . jss . 2006 . 07 . 009 [ 7 ] Adam Cheyer and Luc Julia . 1998 . MVIEWS : Multimodal Tools for the Video Analyst . In Proceedings of the 3rd International Conference on Intelligent User Interfaces ( San Francisco , California , USA ) ( IUI ’98 ) . ACM , New York , NY , USA , 55 – 62 . https : / / doi . org / 10 . 1145 / 268389 . 268399 [ 8 ] Bruno Dumas , Denis Lalanne , and Sharon Oviatt . 2009 . Multimodal Interfaces : A Survey of Principles , Models and Frameworks . In Human Machine Interaction : Research Results of the MMI Program , Denis Lalanne and Jürg Kohlas ( Eds . ) . Springer , Berlin , Heidelberg , 3 – 26 . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 00437 - 7 _ 1 [ 9 ] Ralph H . Earle , Mark A . Rosso , and Kathryn E . Alexander . 2015 . User Preferences ofSoftwareDocumentationGenres . In Proceedingsofthe33rdAnnualInternational Conference on the Design of Communication ( SIGDOC ’15 ) . ACM , New York , NY , USA , Article 46 , 10 pages . https : / / doi . org / 10 . 1145 / 2775441 . 2775457 [ 10 ] MathiasEllmannandIrmoTimmann . 2019 . AComparativeStudyofFAQsforSoft - ware Development . In Proceedings of the 2nd ACM SIGSOFT International Work - shop on Software Qualities and Their Dependencies ( Tallinn , Estonia ) ( SQUADE 2019 ) . ACM , New York , NY , USA , 8 – 11 . https : / / doi . org / 10 . 1145 / 3340495 . 3342750 [ 11 ] Maria J . Grant and Andrew Booth . 2009 . A Typology of Reviews : An Analysis of 14ReviewTypesandAssociatedMethodologies . HealthInformationandLibraries Journal 26 , 2 ( 2009 ) , 91 – 108 . https : / / doi . org / 10 . 1111 / j . 1471 - 1842 . 2009 . 00848 . x [ 12 ] Hayrettin Gürkök and Anton Nijholt . 2012 . Brain - Computer Interfaces for Mul - timodal Interaction : A Survey and Principles . International Journal of Human - Computer Interaction 28 , 5 ( 2012 ) , 292 – 307 . https : / / doi . org / 10 . 1080 / 10447318 . 2011 . 582022 [ 13 ] AlejandroJaimesandNicuSebe . 2007 . MultimodalHuman - ComputerInteraction : A Survey . Computer Vision and Image Understanding 108 , 1 – 2 ( 2007 ) , 116 – 134 . http : / / dx . doi . org / 10 . 1016 / j . cviu . 2006 . 10 . 019 [ 14 ] Iyad Khaddam , Jean Vanderdonckt , Salah Dowaji , and Donatien Grolaux . 2020 . Towards Rapid Prototyping of Foldable Graphical User Interfaces with Flecto . Proc . ACM Hum . - Comput . Interact . 4 , ISS , Article 194 ( Nov . 2020 ) , 33 pages . https : / / doi . org / 10 . 1145 / 3427322 [ 15 ] Paul J . Lavrakas , Michael W . Traugott , Courtney Kennedy , Allyson L . Holbrook , Edith D . de Leeuw , and Brady T . West ( Eds . ) . 2019 . Experimental Methods in Survey Research : Techniques that Combine Random Sampling with Random As - signment . John Wiley & Sons , Inc . , Hoboken , NJ , USA . http : / / dx . doi . org / 10 . 1002 / 9781119083771 [ 16 ] Luis A . Leiva , Daniel Martín - Albo , Réjean Plamondon , and Radu - Daniel Vatavu . 2018 . KeyTime : Super - Accurate Prediction of Stroke Gesture Production Times . In Proceedingsofthe2018CHIConferenceonHumanFactorsinComputingSystems . ACM , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3173574 . 3173813 [ 17 ] Víctor Manuel López Jaquero , Radu - Daniel Vatavu , Jose Ignacio Panach , Oscar Pastor , and Jean Vanderdonckt . 2019 . A Newcomer’s Guide to EICS , the Engi - neering Interactive Computing Systems Community . Proc . ACM Hum . - Comput . Interact . 3 , EICS , Article 1 ( June 2019 ) , 9 pages . https : / / doi . org / 10 . 1145 / 3300960 [ 18 ] Nathan Magrofuoco , Paolo Roselli , Jean Vanderdonckt , Jorge Luis Pérez - Medina , and Radu - Daniel Vatavu . 2019 . GestMan : A Cloud - Based Tool for Stroke - Gesture Datasets . In Proceedings of the ACM SIGCHI Symposium on Engineering Interactive ComputingSystems ( Valencia , Spain ) ( EICS’19 ) . ACM , NewYork , NY , USA , Article 7 , 6 pages . https : / / doi . org / 10 . 1145 / 3319499 . 3328227 [ 19 ] Daniel Martin , Sandra Malpica , Diego Gutierrez , Belen Masia , and Ana Serrano . 2021 . Multimodality in VR : A survey . arXiv : 2101 . 07906 [ cs . HC ] https : / / arxiv . org / abs / 2101 . 07906 [ 20 ] Steve McConnell . 2004 . Code Complete : A Practical Handbook of Software Con - struction ( 2nd Ed . ) . Microsoft Press , Redmond , Washington . 11 ICMI ’21 Companion , October 18 – 22 , 2021 , Montréal , QC , Canada Terenti and Vatavu [ 21 ] Marilyn Rose McGee - Lennon , Andrew Ramsay , David McGookin , and Philip Gray . 2009 . User Evaluation of OIDE : A Rapid Prototyping Platform for Mul - timodal Interaction . In Proceedings of the 1st Symposium on Engineering In - teractive Computing Systems ( EICS ’09 ) . ACM , New York , NY , USA , 237 – 242 . https : / / doi . org / 10 . 1145 / 1570433 . 1570476 [ 22 ] Brad Mehlenbacher . 2002 . Documentation : Not yet Implemented , but Coming Soon ! L . Erlbaum Associates Inc . , USA , 527 – 543 . [ 23 ] Brad A . Myers . 1995 . User Interface Software Tools . ACM Trans . Comput . - Hum . Interact . 2 , 1 ( March 1995 ) , 64 – 103 . https : / / doi . org / 10 . 1145 / 200968 . 200971 [ 24 ] Octav Opaschi and Radu - Daniel Vatavu . 2020 . Uncovering Practical Security and Privacy Threats for Connected Glasses with Embedded Video Cameras . Proceed - ings of the ACM Interaction on Mobile , Wearable , and Ubiquitous Technologies 4 , 4 , Article 167 ( Dec . 2020 ) , 26 pages . https : / / doi . org / 10 . 1145 / 3432700 [ 25 ] Dennis Pagano and Walid Maalej . 2013 . How Do Open Source Communities Blog ? Empirical Software Engineering 18 , 6 ( Dec . 2013 ) , 1090 – 1124 . https : / / doi . org / 10 . 1007 / s10664 - 012 - 9211 - 2 [ 26 ] Christian Remy , Lindsay MacDonald Vermeulen , Jonas Frich , Michael Mose Biskjaer , and Peter Dalsgaard . 2020 . Evaluating Creativity Support Tools in HCI Research . In Proceedingsofthe2020ACMDesigningInteractiveSystemsConference . ACM , New York , NY , USA , 457 – 476 . https : / / doi . org / 10 . 1145 / 3357236 . 3395474 [ 27 ] Ritam Jyoti Sarmah , Yunpeng Ding , Di Wang , Cheuk Yin Phipson Lee , Toby Jia - Jun Li , and Xiang ’Anthony’ Chen . 2020 . Geno : A Developer Tool for Authoring Multimodal Interaction on Existing Web Applications . In UIST ’20 . ACM , New York , NY , USA , 1169 – 1181 . https : / / doi . org / 10 . 1145 / 3379337 . 3415848 [ 28 ] Ovidiu - Andrei Schipor , Radu - Daniel Vatavu , and Wenjun Wu . 2019 . SAPIENS : Towards Software Architecture to Support Peripheral Interaction in Smart En - vironments . Proc . ACM Hum . - Comput . Interact . 3 , EICS , Article 11 ( June 2019 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3331153 [ 29 ] Andy P . Siddaway , Alex M . Wood , and Larry V . Hedges . 2019 . How to Do a SystematicReview : ABestPracticeGuideforConductingandReportingNarrative Reviews , Meta - Analyses , and Meta - Syntheses . Annual Review of Psychology 70 , 1 ( 2019 ) , 747 – 770 . https : / / doi . org / 10 . 1146 / annurevpsych - 010418 - 102803 [ 30 ] Gabriel Skantze and Samer Al Moubayed . 2012 . IrisTK : A Statechart - Based Toolkit for Multi - Party Face - to - Face Interaction . In Proceedings of the 14th ACM International Conference on Multimodal Interaction ( Santa Monica , California , USA ) ( ICMI ’12 ) . ACM , New York , NY , USA , 69 – 76 . https : / / doi . org / 10 . 1145 / 2388676 . 2388698 [ 31 ] MatthewTurk . 2014 . MultimodalInteraction : AReview . Patt . Rec . Letters 36 ( 2014 ) , 189 – 195 . https : / / www . sciencedirect . com / science / article / pii / S0167865513002584 [ 32 ] Jean Vanderdonckt , Iyad Khaddam , and Radu - Daniel Vatavu . 2020 . The Foldinter - face Editor : A Visual Tool for Designing User Interfaces for Foldable Displays . In Companion Proceedings of the 12th ACM SIGCHI Symposium on Engineering Inter - active Computing Systems ( Sophia Antipolis , France ) ( EICS ’20 Companion ) . ACM , New York , NY , USA , Article 1 , 6 pages . https : / / doi . org / 10 . 1145 / 3393672 . 3398490 [ 33 ] Jean Vanderdonckt , Mathieu Zen , and Radu - Daniel Vatavu . 2019 . AB4Web : An On - Line A / B Tester for Comparing User Interface Design Alternatives . Proc . ACM Hum . - Comput . Interact . 3 , EICS , Article 18 ( June 2019 ) , 28 pages . https : / / doi . org / 10 . 1145 / 3331160 [ 34 ] Radu - Daniel Vatavu , Lisa Anthony , and Jacob O . Wobbrock . 2013 . Relative Accu - racyMeasuresforStrokeGestures . In Proceedingsofthe15thACMonInternational Conference on Multimodal Interaction ( Sydney , Australia ) ( ICMI ’13 ) . ACM , New York , NY , USA , 279 – 286 . https : / / doi . org / 10 . 1145 / 2522848 . 2522875 [ 35 ] Radu - Daniel Vatavu and Laura - Bianca Bilius . 2021 . GestuRING : A Web - based Tool for Designing Gesture Input with Rings , Ring - Like , and Ring - Ready Devices . In Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology ( UIST ’21 ) . ACM , New York , NY , USA , 14 pages . https : / / doi . org / 10 . 1145 / 3472749 . 3474780 [ 36 ] Radu - Daniel Vatavu and Jacob O . Wobbrock . 2015 . Formalizing Agreement Analysis for Elicitation Studies : New Measures , Significance Test , and Toolkit . In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems . ACM , New York , NY , USA , 1325 – 1334 . https : / / doi . org / 10 . 1145 / 2702123 . 2702223 [ 37 ] Jacob O . Wobbrock and Julie A . Kientz . 2016 . Research Contributions in Human - Computer Interaction . Interactions 23 , 3 ( April 2016 ) , 38 – 44 . https : / / doi . org / 10 . 1145 / 2907069 12