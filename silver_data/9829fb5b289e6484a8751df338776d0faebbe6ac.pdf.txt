TWIGMA : A dataset of AI - Generated Images with Metadata From Twitter Yiqun T . Chen Department of Biomedical Data Science Stanford University Stanford , CA 94305 yiqunc @ stanford . edu James Zou Departments of Biomedical Data Science ; Electrical Engineering ; and Computer Science Stanford University Stanford , CA 94305 jamesz @ stanford . edu Abstract Recent progress in generative artificial intelligence ( gen - AI ) has enabled the gener - ation of photo - realistic and artistically - inspiring photos at a single click , catering to millions of users online . To explore how people use gen - AI models such as DALLE and StableDiffusion , it is critical to understand the themes , contents , and variations present in the AI - generated photos . In this work , we introduce TWIGMA ( TWItter Generative - ai images with MetadatA ) , a comprehensive dataset encompassing over 800 , 000 gen - AI images collected from Jan 2021 to March 2023 on Twitter , with associated metadata ( e . g . , tweet text , creation date , number of likes ) . Through a comparative analysis of TWIGMA with natural images and human artwork , we find that gen - AI images possess distinctive characteristics and exhibit , on average , lower variability when compared to their non - gen - AI counterparts . Additionally , we find that the similarity between a gen - AI image and natural images ( i ) is inversely cor - related with the number of likes ; and ( ii ) can be used to identify human images that served as inspiration for the gen - AI creations . Finally , we observe a longitudinal shift in the themes of AI - generated images on Twitter , with users increasingly sharing artistically sophisticated content such as intricate human portraits , whereas their interest in simple subjects such as natural scenes and animals has decreased . Our analyses and findings underscore the significance of TWIGMA as a unique data resource for studying AI - generated images . 1 Introduction Recent advancements in text - to - image generation models , such as DALLE [ 33 ] and StableDiffu - sion [ 36 ] , have revolutionized the creation of realistic and visually captivating images . The ability to generate artistically inspiring images at the click of a button has attracted millions of daily active users . However , the surge in popularity has also given rise to intriguing questions about the boundaries of human and model creativity , as well as the diversity in topics and styles of the generated images . For instance , let’s consider the StableDiffusion model : it passes the user - specified text input ( known as prompts ) into a text encoder CLIP [ 32 ] to obtain an encoding that captures the essence of the prompt . Next , the model utilizes a latent diffusion model that takes the text embedding as input and stochastically generates an image guided by the text encoding . Therefore , the output image is influenced by both the user’s input prompt and the complex diffusion process . Consequently , the stochasticity and black - box nature of the diffusion process led to extensive practice and research in the field of prompt engineering , where content creators iteratively refine their text prompts to generate images that align closely with their desired targets [ 23 , 28 ] . Similar to other emerging technologies with significant capabilities , generative image models have given rise to a plethora of intricate legal and ethical challenges . These include concerns such as the proliferation of AI - generated NSFW Preprint . Under review . a r X i v : 2306 . 08310v1 [ s t a t . A P ] 14 J un 2023 ( Not - Safe - For - Work , which broadly includes offensive , violent , and pornographic topics ) images , the dissemination of fake news , and controversies surrounding copyright . Given the ever - increasing popularity and controversy surrounding AI - generated images , understand - ing their themes , content , and variations is increasingly crucial . However , existing datasets available for research purposes do not sufficiently address these specific inquiries , as many of them were created for specialized investigations ( e . g . , fake art detection [ 41 , 48 ] ) and image quality evalua - tion [ 37 ] ) , resulting in limited content diversity . Some recent exceptions include the Kaggle dataset on Midjourney prompts [ 3 ] and DiffusionDB [ 49 ] , two large - scale datasets compiled from Discord for Midjourney and StableDiffusion models , respectively . However , these pioneering datasets are limited in terms of model variations , user distribution , and relatively short data collection periods . To address these limitations , we present TWIGMA ( Twitter Generative - AI Images with MetadatA ) — a large - scale dataset encompassing 800 , 000 AI - generated images from diverse models . Spanning January 2021 to March 2023 , TWIGMA covered an extended timeframe and included valuable metadata , such as inferred image subjects and number of likes . To the best of our knowledge , TWIGMA is the first AI - generated image dataset with substantial time span and rich metadata , enabling analysis of temporal trends in human - AI generated image content . Moreover , we leverage unsupervised learning techniques and inferred image captions to understand themes of AI - generated images . By contrast , previous studies predominantly focused on the topics and contents of logged prompts [ 49 , 50 ] , which may not accurately represent the output images due to prompt engineering practices . We demonstrate the value and the type of insights TWIGMA enables by using it to characterize the underlying themes and novel aspects of AI - generated images . LAION - 5B DiffusionDB ( collected over two weeks in August 2022 ) TWIGMA ( collected over 2021 / 01 - 2023 / 03 ) ArtBench ( a ) ( b ) Release of DALL · E2 , StableDiffusion v1 Holiday season Midjourney v5 ; themed StableDiffusion variants ( c ) ( d ) pop art , jesus at the cross , vector art , comic shading , colorful , high contrast , illustration , background glow - - v 5 - - ar 8 : 10 - - s 750 - - q 5 - - seed 4106706344 Created at 03 / 27 / 2023 6 likes sticker sheet of various shaped flowers , fanciful , highly detailed , artistic , award winning” a portrait of a female elf with a cowboy hat on with an American ﬂag scarf , D & D , sci - ﬁ , elegant , hopeful , muscular , highly detailed , digital painting , artstation , concept art , smooth , sharp focus , illustration Herbal Medicine — Stock Photo # 10685768 Dairies : Wisconsin state map Plumerias on the beach Artist : Anthony Van Dyck Name : The lamentation of Christ Genre : baroque Artist : Tom Scott Name : Low Tide Roundstone Genre : Impressionism “The garden” 0 , 03 Etc on Polygon . # NFT collection : ‘200 years from now’ Created at 01 / 31 / 2023 1 , 636 likes That DALL E 2 is amazing ! “Salmon in the river” Training is everything… Created at 10 / 16 / 2022 2 , 250 likes Figure 1 : Creation process and content overview of TWIGMA . ( a ) : Curation process of the TWIGMA dataset , resulting in approximately 800 , 000 images posted from 2021 to March 2023 . ( b ) : Steady growth in the count of tweets featuring generative AI images over time . ( c ) : Wordcloud showcasing the prevalent keywords extracted from the tweets ; popular words include new , AI , art , and prompts . ( d ) : Schematic depiction of the data and metadata incorporated in our analyses . The rest of the paper is organized as follows . We review image datasets and evaluation metrics for model novelty and variation in Section 2 . The data collection and analysis process are outlined in Section 3 . Section 4 presents empirical results addressing our research questions . Finally , Section 5 discusses limitations , safety and ethics concerns , and future research directions . 2 Relevant work AI - generated image dataset : The creation of large - scale image - text datasets has rapidly evolved , transitioning from carefully annotated datasets relying on human labels [ 17 , 22 ] to vast collections of image - text pairs gathered from the web [ 32 , 36 , 44 ] . As text - to - image models continue to demonstrate 2 unprecedented capabilities in generating images based on user prompts , researchers have started curating similar datasets featuring images generated by these models . For example , DiffusionDB and Midjourney Kaggle provide large - scale datasets ( 14 millions and 250 , 000 , respectively ) with prompts and images generated by StableDiffusion and Midjourney , respectively . However , these pioneering , general - purpose datasets are limited in terms of style ( as they originate from a single model variation ) , user distribution ( restricted to Discord users of specific channels ) , and relatively short data collection periods ( one month in 2022 for both datasets ) . Researchers have also constructed datasets of AI - generated images for specialized use , such as detecting generated art images [ 43 , 48 ] , evaluating qualities of specific contents such as human portraits [ 7 , 19 ] , investigating safety filters and hidden vocabularies [ 27 , 34 ] , and evaluating potential biases [ 25 ] . Given the problem - oriented nature , these datasets are often limited in size and skewed in themes . Recognizing the gap between existing datasets and our research questions on novelty , themes , and variation of AI - generated images , we curated TWIGMA to demonstrate its potential to answer intriguing research inquiries . Novelty and variation of AI - generated images : Many text - to - image models rely on continuous train - ing with a substantial amount of human artistic artifacts sourced from datasets such as LAION [ 39 ] , which includes images from platforms such as Wikiart and Pinterest , and potentially copyrighted or proprietary contents [ 31 , 34 , 41 ] . Users have also fine - tuned the open - sourced StableDiffusion model on additional samples from specific artists or art genres , such as anime , to generate AI - generated art imitating those styles [ 5 , 9 , 24 ] . While prior research has examined the reproduction of training data in AI - generated art settings [ 43 , 48 ] and from the perspective of adversarial attack [ 8 , 27 ] , large - scale empirical results comparing AI - and non - AI - generated images are relatively limited . This prompts our first research question ( RQ ) to investigate the novelty of AI - generated images : RQ1 : How different are AI - generated images from non - AI - generated images ? Furthermore , the stochastic nature of many text - to - image models has sparked inquiries about the variability of their generated image outputs . In a notable court case , a judge determined that AI - generated images do not qualify for copyright protection , citing the significant disparity between the user’s intended prompts for Midjourney and the resulting visual material it produced . Recent research has explored the variation within the prompt space [ 23 , 49 , 50 ] , and our second RQ builds upon these findings , aiming to supplement them by investigating the variation in the image space : RQ2 : How do AI - generated image variations compare to non - AI - generated counterparts ? Lastly , we leverage the extended time span offered by TWIGMA to explore our final RQ : RQ3 : How do the content and theme of AI - generated images change over time ? By answering RQ1 – 3 , our paper makes the following contributions to the literature : Firstly , we utilize metrics proposed in generative model evaluation to demonstrate the distinctiveness of AI - generated images compared to real images , providing evidence of the novelty embedded in the underlying models . Moreover , we find that the distance between AI - generated and human images ( i ) correlates with the number of likes received ; and ( ii ) can be leveraged to identify human images that served as inspiration for AI - generated creations . Secondly , we introduce quantitative measures to establish that ( i ) images from generative models exhibit less diversity than real images ; and ( ii ) a substantial portion of variations in the image space can be attributed to the variation in user prompts . Finally , we observed a shift in the preferences for generative models and image topics among Twitter users : they are increasingly sharing artistically sophisticated or distinct content , such as intricate human portraits and anime , while interest in simpler subjects like natural scenes and animals has declined . 3 Methods Curating the TWIGMA dataset : To curate the TWIGMA dataset , we began with the initial filtering of available tweets using hashtags commonly associated with AI - generated images , such as # dalle , # stablediffusion , and # aiart . We then proceeded to iteratively refine the set of hashtags by incorporating new hashtags that co - occur with the existing ones and contain highly relevant tweets with AI - generated images . We evaluated the quality of these new hashtags based on the first 20 tweets returned by the hashtag search . This iterative process allowed us to create a final set of 19 hashtags , encompassing both generic community descriptions ( e . g . , # aiart , # generativeart ) and specific models ( e . g . , # midjourney , # dalle2 ) ; please refer to Figure 1 ( a ) for the complete list of hashtags . 3 Next , we utilized the official Twitter API to scrape tweets containing at least one of the identified hashtags . This process encompassed the time frame from January 1st , 2021 to March 31st , 2023 , resulting in approximately 2 . 2 million tweets . Out of these potentially duplicated tweets , around 1 . 3 million contained downloadable photos as of April 2023 . To ensure data quality , we conducted a two - step deduplication process . Firstly , we utilized the media ID in Twitter to retain only one image in cases where the same tweet was associated with multiple hashtags . Secondly , we computed CLIP - ViT - L - 14 embeddings [ 32 ] to remove images with identical embeddings . This deduplication step resulted in a dataset of 623 , 707 tweets and 805 , 650 images in TWIGMA . Furthermore , we extracted comprehensive metadata for each image in the TWIGMA dataset , including original tweet texts , engagement metrics such as likes , as well as user - related information such as follower counts . Recognizing that tweet texts may not always accurately describe the image content , we also generated captions for each image in TWIGMA using the BLIP model [ 20 ] . We release TWIGMA at https : / / yiqunchen . github . io / TWIGMA / . This dataset includes our curated metadata pertaining to the image creation date , number of likes , assigned cluster membership obtained through k - means clustering , and the inferred BLIP captions . Additionally , we provide a list of Twitter IDs and the necessary code to retrieve images and metadata using the Public Twitter API . In this paper , we conduct a series of analyses to showcase the fascinating insights that TWIGMA can offer into human - AI generated images . Our approaches represent an initial exploration effort , and numerous other intriguing questions can be addressed using TWIGMA . Measuring novelty of AI - generated images : To enable efficient computational evaluation without relying on human ratings , we operationalize the concept of “novelty” as the difference between the distribution Q of a generative model ( e . g . , images generated by StableDiffusion in TWIGMA ) and the distribution P of real data ( e . g . , real images in LAION ) ; we then leverage recent advances in metrics proposed for quantifying the difference between two distributions . Our analysis incorporates a diverse range of image datasets , including AI - generated images from TWIGMA and DiffusionDB , as well as human images from LAION [ 39 ] and ArtBench [ 21 ] . Art - Bench features 60 , 000 high - quality , genre - annotated images of artwork spanning ten different art genres from the 14th century to the 21st century ; and LAION encompasses CLIP - similarity - filtered image - text pairs sourced from the Common Crawl . To investigate the novelty of AI - generated images , we first employ two - dimensional UMAP [ 26 ] in the CLIP embedding space to visualize the differences in distributions between AI - generated and non - AI - generated images . Additionally , we employ k - means clustering using the efficient implementation in FAISS [ 13 ] and compute Kullback - Leibler ( KL ) divergence among pairs of image distributions via the quantization approach outlined in Pillutla et al . [ 30 ] . In essence , their approach converts distributions P and Q into two multinomial distributions using k - means clustering ; KL divergence can then be efficiently estimated from the multinomial distributions using plug - in estimators . Measuring the variation of AI - generated images : Quantifying the variation of distributions is a well - studied topic [ 6 , 10 , 14 , 18 , 35 , 45 ] . In our analysis , we employed the following metrics to capture different aspects of variations : ( i ) pairwise distance , computed as (cid:80) i ̸ = j ∥ x i − x j ∥ 2 / N ( N − 1 ) , where x i , x j are embeddings of randomly sampled images ; this metric is equivalent to cosine distance when x i and x j have unit ℓ 2 norms ; ( ii ) inverse of explained variance ( IEV ) by the largest singular value [ 51 ] , (cid:80) di = 1 σ d / σ 1 , where σ i denotes the i th - largest singular value of the embedding matrix ; ( iii ) product of marginal variances ( PMV ) [ 18 ] , (cid:16)(cid:81) di = 1 ˆ s i (cid:17) 1 / d , where ˆ s i denotes the sample standard deviation of the i th feature ; and ( iv ) entropy estimated using the multinomial distributions [ 35 ] from the aforementioned quantization approach . We adjusted the original definitions slightly for some measures to ensure that a higher value always indicates greater variability in the data . 4 Results 4 . 1 Quantified novelty and variations of AI - generated images In this section , we present our analysis of the novelty and variations of AI - generated images . Figure 2 displays different approaches we used to compare AI - generated and non - AI - generated images . The UMAP density plot in Figure 2 ( a ) reveals minimal overlap between sampled LAION , TWIGMA , 4 and ArtBench images , whereas the overlap between TWIGMA and DiffusionDB is substantial . We note a distinct density peak of TWIGMA images absent in DiffusionDB , primarily representing a subset of images generated in specific styles ( such as anime ) and often of NSFW nature ( see Figure 4 for more details ) . This distinction is further confirmed by estimated k - means clusters and KL divergence between image distributions , as shown in panels ( b ) and ( c ) of Figure 2 . Specifically , cluster 1 primarily consists of LAION images , while AI - generated images are present in clusters 2 – 4 . Additionally , the estimated KL divergence between AI - generated and non - AI - generated data pairs tend to much larger compared to the divergence between DiffusionDB and TWIGMA . ( b ) ( a ) ( c ) ( d ) Figure 2 : Comparing AI - generated and non - AI - generated images . ( a ) : Kernel density plot of the 2D - UMAP embedding of randomly - sampled images from TWIGMA , LAION , DiffusionDB , and ArtBench . ( b ) : K - means clustering ( with k = 4 ) separates AI - generated and non - AI - generated images . ( c ) : Estimated KL divergence of pairs of image distributions using the quantization approach ( with 10 clusters ) outlined in Section 3 . Each entry in the table represents the KL divergence between the row and column distributions , e . g . , the 5 . 42 entry is the KL divergence between LAION and ArtBench , defined as (cid:80) x p LAION ( x ) log ( p LAION ( x ) / p ArtBench ( x ) ) . ( d ) : ( Left ) Average cosine similarity of the five nearest neighbors in LAION / ArtBench for TWIGMA images . ( Right ) Average number of likes per similarity quintile , with error bars representing 95 % confidence intervals . On average , TWIGMA images least similar to LAION / ArtBench receive the most likes . While panels ( a ) – ( c ) in Figure 2 focused on examining whether AI - generated and non - AI - generated images are distinct , we additionally investigated whether image distances contain useful information about an image’s likability . Figure 2 ( d ) presents the analysis results for TWIGMA data ( limited to the subset for which we were able to obtain likes data using Twitter API ) : On the left side , we present the average similarities of the five nearest neighbors in LAION and ArtBench , determined using cosine similarities , for the images in TWIGMA . On the right side , we plot the average likes for each quintile of similarities , where quintiles 1 and 5 represent the least and most similar images to LAION or ArtBench , respectively . There is some evidence suggesting that AI - generated images that are less similar to their non - AI - generated counterparts receive more likes . For instance , quintile 1 images for LAION and Artbench received , on average , 30 . 1 ( 95 % CI : [ 28 . 8 , 31 . 5 ] ) and 31 . 9 ( 95 % CI : [ 29 . 7 , 34 . 1 ] ) likes , respectively , compared to 23 . 8 ( 95 % CI : [ 21 . 9 , 25 . 7 ] ) and 24 . 1 ( 95 % CI : [ 21 . 5 , 26 . 7 ] ) likes in quintile 5 . However , it’s important to note that the number of likes for a tweet is influenced by various factors , such as a user’s social networks [ 12 , 47 ] . To account for these factors , we used the following Poisson regression that incorporates the number of followers and similarity quintiles : log ( E ( Likes | X ) ) = α + β 1 1 ( 500 - 5 , 000 followers ) + β 2 1 ( > 5 , 000 followers ) + 4 (cid:88) i = 1 γ i 1 ( Quintile i ) . ( 1 ) The regression model in ( 1 ) shows that within the same follower count category ( i . e . , < 500 , 500 − 5 , 000 , or > 5 , 000 followers ) , compared to TWIGMA images most similar to their ArtBench neighbors ( quintile 5 ) , images in quintile 1 receive , on average , 19 % more likes ( 95 % CI : [ 18 % , 19 % ] , p < 0 . 0001 ) ; similar trends are observed for images in quintile 2 ( 12 % more likes ; 95 % CI : 5 [ 11 % , 12 % ] ; p < 0 . 0001 ) , while the differences are less pronounced for more similar quintiles ( 0 . 8 % fewer likes in quintile 3 and 2 % more likes in quintile 4 ) . Comparable results are found for LAION neighbors as well , where images in quintiles 1 and 2 receive , on average , 10 % ( 95 % CI : [ 9 % , 10 % ] , p < 0 . 0001 ) and 2 % more ( 95 % CI : [ 2 % , 3 % ] , p < 0 . 0001 ) likes , respectively , compared to quintile 5 images posted by accounts with the same follower categories . Upon further investigation , we observe that many of the highly - liked images that stand out from the non - AI - generated images are often anime - style NSFW photos . This observation highlights the need for caution when interpreting the number of likes as an additional indicator of aesthetic and creative value for an image . Next , we explore image variations across distributions ( see Figure 3 ( a ) – ( b ) ) . On average , LAION images exhibit the highest variability , followed closely by ArtBench , DiffusionDB , and TWIGMA , which show similar variation distributions based on pairwise Euclidean distance . Notably , ArtBench shows reduced variation when conditioned on image pairs from the same artist . Similarly , conditioning on prompts in DiffusionDB reduces around 50 % of the variation in generated images , measured by the average distance between two image embeddings ; that is , the average distance between images in DiffusionDB with the same prompt is roughly half that between randomly selected images with different prompts . Additional variation metrics in Figure 3 ( b ) align with pairwise distance . The lower estimated entropy for ArtBench may be due to its smaller sample size compared to the other datasets . Given the observation that a substantial portion of the variations in the image output space is explained by the variation in the input prompts , we further analyzed the latter in Figure 3 ( c ) – ( d ) . Specifically , in ( c ) , we plotted the average pairwise distance of images with the same prompt as a function of the number of words in the prompts . Each dot represents a unique prompt , and we observe that , on average , longer prompts with more details lead to reduced variations in the output images ( Kendall’s τ : - 0 . 1 , p - values : 0 . 01 ) . Furthermore , to calibrate the variation of the prompt variations , we compared the pairwise distance of CLIP embeddings from different text input sources with similar word counts to the DiffusionDB prompts . These sources included real image captions [ 42 ] , English Haikus [ 1 ] , Twitter text ( after removing hyperlinks and hashtags ) , CNN news summarization [ 40 ] , and a book chapter [ 52 ] . We found that image captions exhibit similar variation to DiffusionDB prompts and Twitter texts , indicating higher variability . In contrast , as expected , texts with unified styles and themes , such as Haikus and book chapters , show significantly lower variation . Overall , our analysis suggests a wide range of topics covered by the DiffusionDB prompts . 4 . 2 Themes of AI - generated images on Twitter Here , we examine the themes and their longitudinal changes for images in the TWIGMA dataset . In Figure 4 ( a ) , we display the creation - date color - coded two - dimensional UMAP of TWIGMA image embeddings , suggesting a shift in the image distribution over time in our Twitter dataset . To investigate this qualitative observation further , we applied k - means clustering to the TWIGMA data with k = 10 and plotted the change of cluster membership over time . We note substantial changes in cluster memberships : clusters 1 , 3 , and 4 have experienced a steady decline over time , while clusters 8 and 9 showed a consistent increase . Here , the choice of k = 10 was motivated by the observation in Figure 3 ( a ) , which indicated that TWIGMA exhibits comparable variation to ArtBench , a dataset with 10 distinct art styles ( sensitivity analysis using other values of k yielded similar results ) . Due to the lack of direct access to the prompts used for generating every image in TWIGMA , as well as the distance between the input prompt and the resulting output , we used BLIP [ 20 ] to caption the images in TWIGMA and visualized the resulting caption concepts in Figure 4 ( c ) . Prominent themes we observed include painting , woman , man , and hair , aligning with the known interest of users in generating detailed human portraits in various styles using text - to - image models [ 16 , 46 , 50 ] . We further visualized each cluster along with the most frequent topics derived using BLIP captions in Figure 4 ( d ) , with emojis representing the relative trends over time . Our findings indicate a shift in preferences for image topics among Twitter users . There is a growing interest in sharing artistically sophisticated or distinct content , such as intricate human portraits , while interest in simpler themes such as natural scenes has declined . In addition , clusters 5 and 8 notably contain a substantial number of images with increasing popularity but also significant amounts of NSFW , pornographic , and nude content . This observation aligns with recent studies that highlight the rapid growth of online communities focused on generating these models , which are relatively less regulated [ 15 , 34 , 38 ] . This is confirmed by experimental results using a pre - trained NSFW detector [ 4 ] in Figure 4 ( e ) , revealing a substantial number of likely NSFW images in both TWIGMA and LAION datasets . 6 ( a ) ( d ) ( c ) ( b ) Figure 3 : Comparing variations of AI - generated and non - AI - generated images . ( a ) : Pairwise Euclidean distance of randomly - sampled , ℓ 2 - normalized image embeddings from LAION , ArtBench , DiffusionDB , TWIGMA , paintings by the same artists in ArtBench , and DiffusionDB images with identical prompts . ( b ) : Additional variation metrics ( see Section 3 for details ) for the dataset mentioned in ( a ) ; larger values of these metrics correspond to a more variable dataset . Metric values for the most and least variable dataset are in bold and italic , respectively . ( c ) : Average pairwise Euclidean distance of ℓ 2 - normalized embeddings in DiffusionDB with identical prompts ( each dot is a unique prompt ) ; on average , longer and more detailed prompts correspond to reduced variations in output images . ( d ) : Similar analysis as in ( a ) , but with sampled text embedding data from real image captions , English Haikus , DiffusionDB prompts , Tweets , CNN news , and a book chapter . Lastly , as a proof - of - concept analysis to explore the possibility of using similarity measures to detect non - AI - generated images that may have been used as training data for the text - to - image models , we employed cosine similarity to extract the nearest neighbors of TWIGMA images . In Figure 4 ( f ) , we displayed pairs with a high likelihood that the neighbors from ArtBench and LAION served as potential inspirations ( i . e . , training data ) for the text - to - image models . Notably , this analysis revealed striking similarities between some of these neighbor pairs , confirming concerns of copyright issues and the potential for identifying such pairs using a similarity - measure - based approach . 5 Discussion Recent advancements in generative AI have revolutionized text - to - image generation , empowering users to create millions of captivating images . Our work explores themes and variations in AI - generated images . To facilitate this investigation , we introduce TWIGMA , an extensive dataset comprising 800 , 000 gen - AI images , associated tweets , and metadata collected from Twitter between January 2021 and March 2023 . Our analysis characterizes distinctiveness , variation , and longitudinal shift of themes of gen - AI images shared on Twitter . The analysis in this paper are not meant to be exhaustive but rather to illustrate the types of interesting questions that TWIGMA can help to answer , opening the door to investigating various facets of human - AI art generation . Limitations : It is important to note the limitations in our work , primarily due to the large - scale nature of the datasets employed , which makes a comprehensive examination of all aspects impractical . One limitation stems from the scope and quality of the datasets utilized in our analysis . Although we made efforts to select representative data sources from both AI - generated and non - AI - generated image spaces , the content within the final datasets used in our paper imposes certain constraints : ArtBench primarily consists of the most popular art genres in WikiArt [ 2 ] , resulting in limited coverage of non - European , non - Japanese , modern , techno arts , as well as works from lesser - known independent artists . Consequently , this might lead to an underestimate of the similarity between human art images and AI - generated art images . Similarly , LAION data has undergone filtration based on text - image pair similarity [ 39 ] , and around 10 % of Twitter images are not available through the official Twitter 7 Cluster 3 : City , man , futuristic ⬇ Cluster 1 : Painting , white , black ⬇ Cluster 10 : Man , woman , robot ⬆ Cluster 4 : Man , car , large ➡ Cluster 5 : Woman , posing , girl ⬆ Cluster 6 : Painting , background , forest ➡ Cluster 7 : Man , woman , painting ➡ Cluster 8 : Girl , woman , hair ⬆ Cluster 2 : Man , cat , dog ⬇ Cluster 9 : Woman , hair , dress ⬆ ( a ) ( b ) ( c ) ( d ) TWIGMA ArtBench / LAION NN ArtBench / LAION NN TWIGMA ( e ) Figure 4 : Themes and longitudinal trends of images in TWIGMA . ( a ) : Two - dimensional UMAP embedding of TWIGMA images , color - coded based on their creation dates on Twitter . ( b ) : Composition of image clusters ( estimated using k - means clustering with k = 10 ) over time . We observe notable changes in cluster membership and underlying themes of TWIGMA images from 2021 to 2023 . ( c ) : Randomly sampled images from the 10 clusters identified in ( b ) . Clusters 5 and 8 predominantly contain NSFW photos and have been pixelated accordingly . Cluster annotations are provided using the most frequent words in associated BLIP - inferred captions , with up arrow , down arrow , and right arrow emojis indicating increasing , decreasing , or unchanged trends over time , respectively . ( d ) : Predicted NSFW scores from a pre - trained CLIP - based NSFW detector . Noteworthy presence of NSFW photos is observed in both TWIGMA and LAION datasets . ( e ) : TWIGMA images and their nearest neighbors in terms of image embedding cosine similarities from ArtBench or LAION . These images from ArtBench and LAION serve as potential inspirations ( i . e . , training data ) for the text - to - image model , indicating the possibility of identifying such pairs using a similarity - measure - based approach . 8 API at the time of our study , due to the deletion or removal of tweets . Additionally , it is possible that a small proportion of images within TWIGMA are non - AI - generated , as users sometimes share relevant non - AI - generated content , such as real images closely resembling AI - generated outputs or screenshots from model websites or APIs . All of the aforementioned data issues could bias our findings in Section 4 . 1 , though we estimate the bias from non - AI - generated images in TWIGMA to be quite small based on inspections of random samples of the data . Future work : There are several promising avenues for future research . Firstly , the inclusion of more contemporary and modern art forms , particularly illustration art and anime , along with the identification of non - AI - generated images in TWIGMA , would strengthen the robustness of our findings . Furthermore , conducting a follow - up analysis using state - of - the - art methods [ 8 , 43 ] to identify AI - generated images and their non - AI - generated nearest neighbors would help identify potential instances of copyrighted materials used in training . Finally , while our focus has primarily been on variations in the CLIP latent space , exploring other dimensions of variation and diversity [ 25 , 29 ] is crucial . For instance , examining the presence of stereotypical associations between output images and societal representations in human images , such as whether the female portraits in TWIGMA resemble a specific racial , ethnic , or societal group , would provide valuable insights . Safety and ethical concerns : One challenging aspect of text - to - image generative models is the generation of NSFW content . Our data analysis revealed a substantial subset of explicit images posted on Twitter , even among those with high likes and retweets . While some generative models like DALLE2 and StableDiffusion have built - in safety filters that block generated NSFW images , these filters can still be circumvented through prompt engineering [ 34 , 38 ] . Moreover , there is a subcategory of models and online communities specifically dedicated to generating NSFW content . These observations serve as a cautionary tale for large - scale studies involving AI - generated content , as NSFW content is likely to be present and popular among certain subsets of followers due to the relatively low regulation in the current landscape . Additionally , our analysis also highlighted some AI - generated images that bear a striking resemblance to images found in human image and art datasets . These findings bear implications for potential copyright violations if training images were used without explicit consent , especially when the outputs are essentially reproductions or minor edits of memorized training examples . Finally , there is a risk of perpetuating stereotypical representations if AI - generated images tend to resemble specific groups based on demographic identities . Similar observations , discussions , and potential mitigations have been noted in other recent works [ 11 , 25 ] . 6 Conclusion Understanding themes , contents , and user interests of AI - generated images is a critical topic that requires data beyond the currently available prompt and output image pairs datasets . We introduced TWIGMA , an extensive dataset comprising 800 , 000 gen - AI images , tweets , and associated metadata from Twitter ( Jan 2021 – March 2023 ) . Our contribution is two - fold : Firstly , TWIGMA enables analysis of AI - generated image content and evolution across models and time on Twitter . Additionally , our analysis highlights the distinctiveness and variation of AI - generated images when compared to non - AI - generated content . We hope that our dataset and analysis will contribute to the broader discourse on the safety , novelty , and sociological / legal challenges posed by AI - generated images . Acknowledgments and Disclosure of Funding : We thank Zhi Huang for sharing their code to scrap Twitter content using the public Twitter API . YC is supported by a Stanford Data Science Postdoctoral Fellowship . JZ is supported by the National Science Foundation ( CCF 1763191 and CAREER 1942926 ) , the US National Institutes of Health ( P30AG059307 and U01MH098953 ) and grants from the Silicon Valley Foundation and the Chan - Zuckerberg Initiative . References [ 1 ] Haiku dataset . https : / / huggingface . co / datasets / statworx / haiku . Accessed : 2023 - 06 - 06 . [ 2 ] WikiArt . https : / / www . wikiart . org / . Accessed : 2023 - 5 - 5 . 9 [ 3 ] Midjourney user prompts . https : / / www . kaggle . com / datasets / succinctlyai / midjourney - texttoimage , 2022 . Accessed : 2023 - 06 - 06 . [ 4 ] CLIP - based NSFW Detector . https : / / github . com / LAION - AI / CLIP - based - NSFW - Detector , 2022 . Accessed : 2023 - 06 - 06 . [ 5 ] Waifu diffusion . https : / / huggingface . co / hakurei / waifu - diffusion , 2022 . Accessed : 2023 - 6 - 4 . [ 6 ] Danial Alihosseini , Ehsan Montahaei , and Mahdieh Soleymani Baghshah . Jointly measuring diversity and quality in text generation models . Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation , pages 90 – 98 , 2019 . [ 7 ] Ali Borji . Generated faces in the wild : Quantitative comparison of Stable Diffusion , Midjourney and DALL - E 2 . arXiv preprint arXiv : 2210 . 00586 , 2022 . [ 8 ] Nicholas Carlini , Jamie Hayes , Milad Nasr , Matthew Jagielski , Vikash Sehwag , Florian Tramèr , Borja Balle , Daphne Ippolito , and Eric Wallace . Extracting training data from diffusion models . arXiv preprint arXiv : 2301 . 13188 , 2023 . [ 9 ] Sheng - Yen Chou , Pin - Yu Chen , and Tsung - Yi Ho . How to backdoor diffusion models ? In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition , pages 4015 – 4024 , 2023 . [ 10 ] Daniel M Fleder and Kartik Hosanagar . Recommender systems and their impact on sales diversity . In Proceedings of the 8th ACM Conference on Electronic Commerce , pages 192 – 199 , 2007 . [ 11 ] Noa Garcia , Yusuke Hirota , Yankun Wu , and Yuta Nakashima . Uncurated image - text datasets : Shedding light on demographic bias . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition , pages 6957 – 6966 , 2023 . [ 12 ] Nathan O Hodas and Kristina Lerman . The simple rules of social contagion . Scientific Reports , 4 ( 1 ) : 1 – 7 , March 2014 . [ 13 ] Jeff Johnson , Matthijs Douze , and Hervé Jégou . Billion - scale similarity search with GPUs . IEEE Transactions on Big Data , 7 ( 3 ) : 535 – 547 , 2019 . [ 14 ] Lou Jost . Entropy and diversity . Oikos , 113 ( 2 ) : 363 – 375 , May 2006 . [ 15 ] Alex Kim . Nsfw data scraper . https : / / github . com / alex000kim / nsfw _ data _ scraper , 2022 . Ac - cessed : 2023 - 06 - 06 . [ 16 ] Gwanghyun Kim and Jong Chul Ye . DiffusionCLIP : Text - guided image manipulation using diffusion models . arXiv preprint arXiv : 2110 . 02711 , 2023 . [ 17 ] Ranjay Krishna , Yuke Zhu , Oliver Groth , Justin Johnson , Kenji Hata , Joshua Kravitz , Stephanie Chen , Yannis Kalantidis , Li - Jia Li , David A Shamma , et al . Visual genome : Connecting language and vision using crowdsourced dense image annotations . International Journal of Computer Vision , 123 : 32 – 73 , 2017 . [ 18 ] Yi - An Lai , Xuan Zhu , Yi Zhang , and Mona Diab . Diversity , density , and homogeneity : Quantitative characteristic metrics for text collections . arXiv preprint arXiv : 2003 . 08529 , 2020 . [ 19 ] Kimin Lee , Hao Liu , Moonkyung Ryu , Olivia Watkins , Yuqing Du , Craig Boutilier , Pieter Abbeel , Mohammad Ghavamzadeh , and Shixiang Shane Gu . Aligning text - to - image models using human feedback . arXiv preprint arXiv : 2302 . 12192 , 2023 . [ 20 ] Junnan Li , Dongxu Li , Caiming Xiong , and Steven Hoi . BLIP : Bootstrapping language - image pre - training for unified vision - language understanding and generation . In International Conference on Machine Learning , pages 12888 – 12900 . PMLR , 2022 . [ 21 ] Peiyuan Liao , Xiuyu Li , Xihui Liu , and Kurt Keutzer . The ArtBench dataset : Benchmarking generative models with artworks . arXiv preprint arXiv : 2206 . 11404 , 2022 . 10 [ 22 ] Tsung - Yi Lin , Michael Maire , Serge Belongie , James Hays , Pietro Perona , Deva Ramanan , Piotr Dollár , and C Lawrence Zitnick . Microsoft COCO : Common objects in context . In ECCV 2014 , pages 740 – 755 , 2014 . [ 23 ] Vivian Liu and Lydia B Chilton . Design guidelines for prompt engineering text - to - image generative models . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems , number Article 384 in CHI ’22 , pages 1 – 23 , New York , NY , USA , April 2022 . Association for Computing Machinery . [ 24 ] Haoming Lu , Hazarapet Tunanyan , Kai Wang , Shant Navasardyan , Zhangyang Wang , and Humphrey Shi . Specialist diffusion : Plug - and - Play Sample - Efficient Fine - Tuning of Text - to - Image diffusion models to learn any unseen style . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition , pages 14267 – 14276 . openaccess . thecvf . com , 2023 . [ 25 ] Alexandra Sasha Luccioni , Christopher Akiki , Margaret Mitchell , and Yacine Jernite . Stable bias : Analyzing societal representations in diffusion models . arXiv preprint arXiv : 2303 . 11408 , 2023 . [ 26 ] Leland McInnes , John Healy , and James Melville . UMAP : Uniform manifold approximation and projection for dimension reduction . arXiv preprint arXiv : 1802 . 03426 , 2018 . [ 27 ] Raphaël Millière . Adversarial attacks on image generation with made - up words . arXiv preprint arXiv : 2208 . 04135 , 2022 . [ 28 ] Jonas Oppenlaender . The creativity of text - to - image generation . In Proceedings of the 25th International Academic Mindtrek Conference , Academic Mindtrek ’22 , pages 192 – 202 , New York , NY , USA , November 2022 . Association for Computing Machinery . [ 29 ] Hadas Orgad , Bahjat Kawar , and Yonatan Belinkov . Editing implicit assumptions in Text - to - Image diffusion models . arXiv preprint arXiv : 2303 . 08084 , 2023 . [ 30 ] Krishna Pillutla , Lang Liu , John Thickstun , Sean Welleck , Swabha Swayamdipta , Rowan Zellers , Sewoong Oh , Yejin Choi , and Zaid Harchaoui . MAUVE scores for generative models : Theory and practice . arXiv preprint arXiv : 2212 . 14578 , 2022 . [ 31 ] Giada Pistilli , Carlos Munoz Ferrandis , Yacine Jernite , and Margaret Mitchell . Stronger together : on the articulation of ethical charters , legal tools , and technical documentation in ML . arXiv preprint arXiv : 2305 . 18615 , 2023 . [ 32 ] Alec Radford , Jong Wook Kim , Chris Hallacy , Aditya Ramesh , Gabriel Goh , Sandhini Agar - wal , Girish Sastry , Amanda Askell , Pamela Mishkin , Jack Clark , Gretchen Krueger , and Ilya Sutskever . Learning transferable visual models from natural language supervision . In Proceed - ings of the 38th International Conference on Machine Learning , pages 8748 – 8763 , 2021 . [ 33 ] Aditya Ramesh , Mikhail Pavlov , Gabriel Goh , Scott Gray , Chelsea Voss , Alec Radford , Mark Chen , and Ilya Sutskever . Zero - shot text - to - image generation . In Proceedings of the 38th International Conference on Machine Learning , volume 139 , pages 8821 – 8831 , 2021 . [ 34 ] Javier Rando , Daniel Paleka , David Lindner , Lennart Heim , and Florian Tramèr . Red - Teaming the Stable Diffusion safety filter . arXiv preprint arXiv : 2210 . 04610 , 2022 . [ 35 ] Samuel Rhys Cox , Yunlong Wang , Ashraf Abdul , Christian von der Weth , and Brian Y . Lim . Directed diversity : Leveraging language embedding distances for collective creativity in crowd ideation . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems , number Article 393 in CHI ’21 , pages 1 – 35 , New York , NY , USA , May 2021 . Association for Computing Machinery . [ 36 ] Robin Rombach , Andreas Blattmann , Dominik Lorenz , Patrick Esser , and Björn Ommer . High - resolution image synthesis with latent diffusion models . Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition , pages 10684 – 10695 , 2022 . 11 [ 37 ] Chitwan Saharia , William Chan , Saurabh Saxena , Lala Li , Jay Whang , Emily L Denton , Kamyar Ghasemipour , Raphael Gontijo Lopes , Burcu Karagol Ayan , Tim Salimans , and Others . Photorealistic text - to - image diffusion models with deep language understanding . Advances in Neural Information Processing Systems , 2022 . [ 38 ] Patrick Schramowski , Manuel Brack , Björn Deiseroth , and Kristian Kersting . Safe latent diffusion : Mitigating inappropriate degeneration in diffusion models . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition , 2023 . [ 39 ] Christoph Schuhmann , Romain Beaumont , Richard Vencu , Cade Gordon , Ross Wightman , Mehdi Cherti , Theo Coombes , Aarush Katta , Clayton Mullis , Mitchell Wortsman , Patrick Schramowski , Srivatsa Kundurthy , Katherine Crowson , Ludwig Schmidt , Robert Kaczmarczyk , and Jenia Jitsev . LAION - 5B : An open large - scale dataset for training next generation image - text models . Advances in Neural Information Processing Systems , 2022 . [ 40 ] Abigail See , Peter J Liu , and Christopher D Manning . Get to the point : Summarization with pointer - generator networks . arXiv preprint arXiv : 1704 . 04368 , 2017 . [ 41 ] Shawn Shan , Jenna Cryan , Emily Wenger , Haitao Zheng , Rana Hanocka , and Ben Y Zhao . GLAZE : Protecting artists from style mimicry by text - to - image models . arXiv preprint arXiv : 2302 . 04222 , 2023 . [ 42 ] Piyush Sharma , Nan Ding , Sebastian Goodman , and Radu Soricut . Conceptual captions : A cleaned , hypernymed , image alt - text dataset for automatic image captioning . In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics , 2018 . [ 43 ] Gowthami Somepalli , Vasu Singla , Micah Goldblum , Jonas Geiping , and Tom Goldstein . Diffusion art or digital forgery ? investigating data replication in diffusion models . Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition , pages 6048 – 6058 , 2023 . [ 44 ] Krishna Srinivasan , Karthik Raman , Jiecao Chen , Michael Bendersky , and Marc Najork . Wit : Wikipedia - based image text dataset for multimodal multilingual machine learning . In Pro - ceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval , pages 2443 – 2449 , 2021 . [ 45 ] Andy Stirling . A general framework for analysing diversity in science , technology and society . Journal of the Royal Society , 4 ( 15 ) : 707 – 719 , 2007 . [ 46 ] Michał Stypułkowski , Konstantinos Vougioukas , Sen He , Maciej Zi˛eba , Stavros Petridis , and Maja Pantic . Diffused heads : Diffusion models beat GANs on talking - face generation . arXiv preprint arXiv : 2301 . 03396 , 2023 . [ 47 ] Romilla Syed , Maryam Rahafrooz , and Jeffrey M Keisler . What it takes to get retweeted : An analysis of software vulnerability messages . Computers in Human Behavior , 80 : 207 – 215 , 2018 . [ 48 ] Yabin Wang , Zhiwu Huang , and Xiaopeng Hong . Benchmarking deepart detection . arXiv preprint arXiv : 2302 . 14475 , 2023 . [ 49 ] Zijie J Wang , Evan Montoya , David Munechika , Haoyang Yang , Benjamin Hoover , and Duen Horng Chau . DiffusionDB : A large - scale prompt gallery dataset for text - to - image generative models . arXiv preprint arXiv : 2210 . 14896 , 2022 . [ 50 ] Yutong Xie , Zhaoying Pan , Jinge Ma , Luo Jie , and Qiaozhu Mei . A prompt log analysis of text - to - image generation systems . In Proceedings of the ACM Web Conference 2023 , pages 3892 – 3902 . Association for Computing Machinery , 2023 . [ 51 ] Wenxuan Zhou , Bill Yuchen Lin , and Xiang Ren . IsoBN : Fine - Tuning BERT with isotropic batch normalization . Proceedings of the AAAI Conference on Artificial Intelligence , 35 ( 16 ) : 14621 – 14629 , May 2021 . [ 52 ] Yukun Zhu , Ryan Kiros , Rich Zemel , Ruslan Salakhutdinov , Raquel Urtasun , Antonio Torralba , and Sanja Fidler . Aligning books and movies : Towards story - like visual explanations by watching movies and reading books . In 2015 IEEE International Conference on Computer Vision ( ICCV ) , pages 19 – 27 . IEEE , December 2015 . 12 A Details for dataset distribution We have provided additional details regarding TWIGMA on our website at https : / / yiqunchen . github . io / TWIGMA / . The dataset used for analysis can be down - loaded from https : / / zenodo . org / record / 8031785 . Additionally , readers may find our interactive introduction at https : / / huggingface . co / spaces / yiquntchen / TWIGMA informative . We confirm that as authors of TWIGMA , we will provide necessary maintenance , such as addressing questions and investigating potential bugs related to the dataset . As per Twitter’s official policy on data usage and sharing , we want to emphasize that we have not included any raw Twitter text or media in the dataset . Only the Twitter IDs are provided . If users wish to download and review the original Twitter posts , they should access the source page directly on Twitter and fully comply with the rules and regulations outlined in the official Twitter developer policy , available at https : / / developer . twitter . com / en / developer - terms / policy . The TWIGMA dataset , which consists of non - personally - identifiable , no - raw - Twitter - content , has been released under a Creative Commons Attribution 4 . 0 International License . Lastly , in Section 5 of our paper , we extensively discuss the presence of a significant amount of NSFW ( not - safe - for - work ) content within the TWIGMA dataset . It includes content that is violent , pornographic , or contains nudity . Since our aim is to explore the content and themes of AI - generated images without filtering , we have included two fields in the final TWIGMA dataset : possibly _ sensitive , which is a binary indicator of whether Twitter classifies an image as sensitive content , and nsfw _ score , which represents the predicted NSFW score from a pre - trained CLIP - based NSFW detector ( where a score of 1 indicates a higher likelihood of being NSFW ) . These fields can help identify and handle these types of images appropriately . B Datasheet for datasets Motivation For what purpose was the dataset cre - ated ? Was there a specific task in mind ? Was there a specific gap that needed to be filled ? Please provide a description . The creation of large - scale image - text datasets has rapidly evolved in the past few years . As text - to - image models continue to demonstrate unprecedented capabilities in generating images based on user prompts , researchers have started curating datasets featuring images generated by these models . However , most of the existing datasets are limited in terms of style ( as they often originate from a single model variation ) , user distribution ( restricted to users of specific channels or APIs ) , and relatively short data col - lection periods ( typically within a month ) ; see our detailed discussion of prior work in Section 2 of our paper . Therefore , we propose TWIGMA , a large - scale dataset encompassing 800 , 000 AI - generated images from diverse models , in this paper . Spanning January 2021 to March 2023 , TWIGMA covered an extended timeframe and in - cluded valuable metadata , such as inferred image subjects and number of likes . To the best of our knowledge , TWIGMA is the first AI - generated image dataset with substantial time span and rich metadata , enabling analysis of temporal trends in human - AI generated image content . Who created this dataset ( e . g . , which team , research group ) and on behalf of which entity ( e . g . , company , institution , organization ) ? The first author of this paper ( YC ) curated the dataset under the supervision of the senior author ( JZ ) ; both authors are affiliated with Stanford Uni - versity . Who funded the creation of the dataset ? If there is an associated grant , please provide the name of the grantor and the grant name and number . YC is supported by a Stanford Data Science Post - doctoral Fellowship . JZ is supported by the Na - tional Science Foundation ( CCF 1763191 and CAREER 1942926 ) , the US National Institutes of Health ( P30AG059307 and U01MH098953 ) and grants from the Silicon Valley Foundation and the Chan - Zuckerberg Initiative . Composition 13 What do the instances that comprise the dataset represent ( e . g . , documents , pho - tos , people , countries ) ? Are there multi - ple types of instances ( e . g . , movies , users , and ratings ; people and interactions between them ; nodes and edges ) ? Please provide a description . TWIGMA contains images , texts , and associated metadata from Twitter ( Jan 2021 – March 2023 ) . However , per data sharing policy from Twitter , we will only be able to include Twitter id and the derived metadata in our final dataset . See details at https : / / yiqunchen . github . io / TWIGMA / . How many instances are there in total ( of each type , if appropriate ) ? During our analysis , we utilized a total of 805 , 650 unique images . It is important to ac - knowledge that due to the dynamic nature of Twit - ter , certain content may have been deleted or set to private since our analysis was conducted . Con - sequently , conducting a similar analysis at a later time will naturally result in a reduced number of accessible or downloadable images . Does the dataset contain all possible in - stances or is it a sample ( not necessarily random ) of instances from a larger set ? If the dataset is a sample , then what is the larger set ? Is the sample representative of the larger set ( e . g . , geographic coverage ) ? If so , please describe how this representa - tiveness was validated / verified . If it is not representative of the larger set , please de - scribe why not ( e . g . , to cover a more diverse range of instances , because instances were withheld or unavailable ) . Our objective is to curate a comprehensive dataset of AI - generated images on Twitter by col - lecting tweets that include at least one of the 19 hashtags listed in Figure 1 of the main text . It is important to note that there is a possibility of omitting some images that were posted without using any of these hashtags . What data does each instance consist of ? “Raw” data ( e . g . , unprocessed text or im - ages ) or features ? In either case , please provide a description . TWIGMA contains images , texts , and associated metadata from Twitter ( Jan 2021 – March 2023 ) . However , per data sharing policy from Twitter , we will only be able to include Twitter id and the derived metadata in our final dataset . See details at https : / / yiqunchen . github . io / TWIGMA / . Is there a label or target associated with each instance ? If so , please provide a de - scription . N / A . Is any information missing from individ - ual instances ? If so , please provide a de - scription , explaining why this information is missing ( e . g . , because it was unavailable ) . This does not include intentionally removed information , but might include , e . g . , redacted text . Due to the dynamic nature of Twitter , content may have been deleted or set to private during the course of our analysis . Consequently , metadata such as likes is missing for those contents that become unavailable to the public . Are relationships between individual in - stances made explicit ( e . g . , users’ movie ratings , social network links ) ? If so , please describe how these relationships are made explicit . N / A . Are there recommended data splits ( e . g . , training , development / validation , test - ing ) ? If so , please provide a description of these splits , explaining the rationale behind them . We do not have recommended splits , but want to mention that we do observe a change in the underlying content temporally . Are there any errors , sources of noise , or redundancies in the dataset ? If so , please provide a description . It is possible that a small proportion of images within TWIGMA are non - AI - generated , as users sometimes share relevant non - AI - generated con - tent , such as real images closely resembling AI - generated outputs or screenshots from model web - sites or APIs . In addition , while we deduplicated our datasets based on media id and image em - bedding , there still could be a small set of near duplicates of the same images in our dataset . Is the dataset self - contained , or does it link to or otherwise rely on external resources ( e . g . , websites , tweets , other datasets ) ? If it links to or relies on external resources , a ) are there guarantees that they will exist , and remain constant , over time ; b ) are there official archival versions of the complete dataset ( i . e . , including the exter - nal resources as they existed at the time the dataset was created ) ; c ) are there any 14 restrictions ( e . g . , licenses , fees ) associated with any of the external resources that might apply to a future user ? Please provide de - scriptions of all external resources and any restrictions associated with them , as well as links or other access points , as appropriate . Due to the official data sharing policy prescribed by Twitter , we cannot share the original content ( text and images ) from Twitter . Therefore , we ex - pect that a subset of the data included in our data will not be available for retrieval , as users hide and delete their contents ( as well as moderation efforts put forth by Twitter ) . By the time we fi - nalize our study , less than 10 % of Twitter images became unavailable through the official Twitter API due to the deletion or removal of tweets . The development of this dataset has been done in compliance with Twitter’s policy on data usage and sharing . If users intend to review the original Twitter post , we recommend accessing the source page directly on Twitter and closely adhering to the official Twitter developer policy , available at https : / / developer . twitter . com / en / devel oper - terms / policy . Does the dataset contain data that might be considered confidential ( e . g . , data that is protected by legal privilege or by doctor - patient confidentiality , data that includes the content of individuals non - public communications ) ? If so , please pro - vide a description . The development of this dataset has been done in compliance with Twitter’s policy on data usage and sharing . The use of this dataset is solely at your own risk and should be in accordance with applicable laws , regulations , and ethical consid - erations . If you intend to review the original Twitter post , we recommend accessing the source page directly on Twitter and closely adhering to the official Twitter developer policy , available at https : / / developer . twitter . com / en / devel oper - terms / policy . Does the dataset contain data that , if viewed directly , might be offensive , in - sulting , threatening , or might otherwise cause anxiety ? If so , please describe why . It is important to note that a substantial amount of images in this dataset have been classified as NSFW ( not - safe - for - work ) by both Twitter and a CLIP - based NSFW model . This includes content that is violent , pornographic , or contains nudity . We have chosen not to exclude these images from the dataset in order to understand the content and themes without filtering . However , we have in - cluded two fields in the final TWIGMA dataset possibly _ sensitive and nsfw _ score which can be used to filter out these images . Does the dataset relate to people ? If not , you may skip the remaining questions in this section . N / A since only Twitter ids are provided . Does the dataset identify any subpopula - tions ( e . g . , by age , gender ) ? If so , please describe how these subpopulations are iden - tified and provide a description of their re - spective distributions within the dataset . N / A . Is it possible to identify individuals ( i . e . , one or more natural persons ) , either di - rectly or indirectly ( i . e . , in combination with other data ) from the dataset ? If so , please describe how . N / A . Does the dataset contain data that might be considered sensitive in any way ( e . g . , data that reveals racial or ethnic origins , sexual orientations , religious beliefs , po - litical opinions or union memberships , or locations ; financial or health data ; bio - metric or genetic data ; forms of govern - ment identification , such as social secu - rity numbers ; criminal history ) ? If so , please provide a description . N / A . Collection Process How was the data associated with each instance acquired ? Was the data di - rectly observable ( e . g . , raw text , movie rat - ings ) , reported by subjects ( e . g . , survey re - sponses ) , or indirectly inferred / derived from other data ( e . g . , part - of - speech tags , model - based guesses for age or language ) ? If data was reported by subjects or indirectly in - ferred / derived from other data , was the data validated / verified ? If so , please describe how . TWIGMA contains the following fields : • id : This is the Twitter id uniquely identi - fying each tweet used in this dataset and our analysis ; • image _ name : This is the media id used to uniquely identify each photo . Lever - aging this field is necessary since a tweet can contain multiple images ; 15 • created _ at : This is the time of creation corresponding to the Twitter id ; • like _ count : This is the number of likes collected from official Twitter API ( snapshot : the week of May 29th ) . Note that some likes are not available be - cause the corresponding tweets have been deleted since we first downloaded the photos ; • quote _ count : Same as like _ count , but for quotes ; • reply _ count : Same as like _ count , but for replies ; • all _ captions : This is the BLIP - generated ( Li et al . 2022 ) captions for the corre - sponding image ; • label _ 10 _ cluster : This is the assigned k - means cluster ( k = 10 so this number varies from 1 to 10 ) ; • possibly _ sensitive : Binary variable indi - cating whether the media content has been marked as sensitive / NSFW by Twitter ; • nsfw _ score : The predicted NSFW from a pre - trained CLIP - based NSFW detec - tor ( ranges from 0 to 1 ; closer to 1 means more likely to be NSFW ) ; • UMAP _ dim _ 1 : The first dimension for a two - dimensional UMAP projection of the CLIP - ViT - L - 14 embeddings of the images in TWIGMA . • UMAP _ dim _ 2 : The second dimension for a two - dimensional UMAP projection of the CLIP - ViT - L - 14 embeddings of the images in TWIGMA . Out of these fields , id , image _ name , created _ at , like _ count , quote _ count and reply _ count are directly observable variables from Twitter . On the other hand , all _ captions is derived from a BLIP ( deep learning ) model where we validated the outcome by manually inspecting random pairs of images and cap - tions ; possibly _ sensitive and nsfw _ score are two predicted scores indicating how sen - sitive / NSFW an image might be . Finally , label _ 10 _ cluster is derived from k - means clustering and UMAP _ dim _ 1 / 2 are derived from a UMAP projection . What mechanisms or procedures were used to collect the data ( e . g . , hardware apparatus or sensor , manual human cu - ration , software program , software API ) ? How were these mechanisms or procedures validated ? We used Twitter API and employed an sequen - tial approach to curate the TWIGMA data ( see details in Section 3 of the main text ) . The im - age embeddings were performed on a single GPU with 32GB RAM and the UMAP embeddings were performed on multi - core CPUs with 256GB RAM ; both are conducted over computing clus - ters . If the dataset is a sample from a larger set , what was the sampling strategy ( e . g . , deterministic , probabilistic with specific sampling probabilities ) ? We performend simple random sampling when - ever the analysis of the full data would be too time - consuming and does not add substantial value : UMAP and density visualization , as well as samples of non - AI - generated human images . Who was involved in the data collection process ( e . g . , students , crowdworkers , contractors ) and how were they compen - sated ( e . g . , how much were crowdworkers paid ) ? N / A , only the first author was invovled in the data collection process . Over what timeframe was the data col - lected ? Does this timeframe match the creation timeframe of the data associated with the instances ( e . g . , recent crawl of old news articles ) ? If not , please describe the timeframe in which the data associated with the instances was created . Data present in TWIGMA ranged from Jan . 2021 to Mar . 2023 . The curation process of this project took place from Jan . to May 2023 . Were any ethical review processes con - ducted ( e . g . , by an institutional review board ) ? If so , please provide a description of these review processes , including the out - comes , as well as a link or other access point to any supporting documentation . N / A . Does the dataset relate to people ? If not , you may skip the remaining questions in this section . N / A ; only Twitter ids are provided . Did you collect the data from the individ - uals in question directly , or obtain it via third parties or other sources ( e . g . , web - sites ) ? N / A . 16 Were the individuals in question notified about the data collection ? If so , please describe ( or show with screenshots or other information ) how notice was provided , and provide a link or other access point to , or oth - erwise reproduce , the exact language of the notification itself . N / A . Did the individuals in question consent to the collection and use of their data ? If so , please describe ( or show with screen - shots or other information ) how consent was requested and provided , and provide a link or other access point to , or otherwise reproduce , the exact language to which the individuals consented . N / A . If consent was obtained , were the con - senting individuals provided with a mech - anism to revoke their consent in the future or for certain uses ? If so , please provide a description , as well as a link or other access point to the mechanism ( if appropriate ) . N / A . Has an analysis of the potential impact of the dataset and its use on data subjects ( e . g . , a data protection impact analysis ) been conducted ? If so , please provide a description of this analysis , including the out - comes , as well as a link or other access point to any supporting documentation . N / A . Preprocessing / cleaning / labeling Was any preprocessing / cleaning / labeling of the data done ( e . g . , discretization or bucketing , tokenization , part - of - speech tagging , SIFT feature extraction , removal of instances , processing of missing val - ues ) ? If so , please provide a description . If not , you may skip the remainder of the ques - tions in this section . We provide simple deduplication using twitter media id as well as CLIP image embeddings . We did not impute any missing values but simply reported the results after dropping the missing values in our analysis . Images collected in our study are transformed into CLIP image embed - dings and many subsequent analyses ( including the metadata such as clustering labels and UMAP coordinates ) are based on these embeddings . Was the “raw” data saved in addition to the preprocessed / cleaned / labeled data ( e . g . , to support unanticipated future uses ) ? If so , please provide a link or other access point to the “raw” data . The raw data containing images and texts are not shared due to Twitter policy . We did not publ - icy share duplicated tweets and tweets without an image since these are not relevant to our main research questions of interest . Is the software used to prepro - cess / clean / label the instances available ? If so , please provide a link or other access point . They are but we could not provide public access to the raw instances due to data sharing policy of Twitter . However , users can easily retrieve the raw instances using the provided Twitter id . Uses Has the dataset been used for any tasks already ? If so , please provide a description . We performed a comparative analysis of TWIGMA with natural images and human art - work , and found that gen - AI images possess dis - tinctive characteristics and exhibit , on average , lower variability when compared to their non - gen - AI counterparts . We also revealed a longitu - dinal shift in the themes of images in TWIGMA , with users increasingly sharing artistically sophis - ticated content such as intricate human portraits , whereas their interest in simple subjects such as natural scenes and animals has decreased . These analyses are detailed in Section 4 of our paper . Is there a repository that links to any or all papers or systems that use the dataset ? If so , please provide a link or other access point . We will release our preprint on arXiv and code on GitHub ; links will be updated on the project website at https : / / yiqunchen . github . io / TWIGMA / . What ( other ) tasks could the dataset be used for ? What we presented in our paper is just an initial exploration of the dataset . Users can further ex - plore the relationship between depicted subject and the number of likes , the underlying real im - ages that inspired the AI - generated images , and so on so forth . 17 Is there anything about the composition of the dataset or the way it was col - lected and preprocessed / cleaned / labeled that might impact future uses ? For ex - ample , is there anything that a future user might need to know to avoid uses that could result in unfair treatment of individuals or groups ( e . g . , stereotyping , quality of service issues ) or other undesirable harms ( e . g . , fi - nancial harms , legal risks ) If so , please pro - vide a description . Is there anything a future user could do to mitigate these undesirable harms ? It is possible that the Twitter id and content in this dataset can be used to identify corresponding Twitter accounts that are active in this genera - tive AI space , but we do not see immediate harm as long as these Twitter accounts do not reveal personally identifiable information . Are there tasks for which the dataset should not be used ? If so , please provide a description . We urge that researchers exercise caution and discretion when using this dataset . The de - velopment of this dataset has been done in compliance with Twitter’s policy on data us - age and sharing . The use of this dataset should be in accordance with applicable laws , regulations , ethical considerations , and es - pecially official Twitter developer policy at https : / / developer . twitter . com / en / dev eloper - terms / policy . Distribution Will the dataset be distributed to third parties outside of the entity ( e . g . , com - pany , institution , organization ) on behalf of which the dataset was created ? If so , please provide a description . We distribute the metadata we collected at https : / / zenodo . org / record / 8031785 . How will the dataset will be distributed ( e . g . , tarball on website , API , GitHub ) Does the dataset have a digital object identifier ( DOI ) ? We release the dataset at https : / / zenodo . org / record / 8031785 ; a detailed introduction to our project and dataset can be accessed at https : / / yiqunchen . github . io / TWIGMA / . When will the dataset be distributed ? The dataset has been made available since June 12 , 2023 . Will the dataset be distributed under a copyright or other intellectual prop - erty ( IP ) license , and / or under applicable terms of use ( ToU ) ? If so , please describe this license and / or ToU , and provide a link or other access point to , or otherwise repro - duce , any relevant licensing terms or ToU , as well as any fees associated with these restrictions . We currently released the metadata under a Creative Commons CC BY 4 . 0 License ; if you plan to get the official Twitter content , please cosult the official Twitter policy at https : / / developer . twitter . com / en / devel oper - terms / policy . Have any third parties imposed IP - based or other restrictions on the data associ - ated with the instances ? If so , please de - scribe these restrictions , and provide a link or other access point to , or otherwise repro - duce , any relevant licensing terms , as well as any fees associated with these restrictions . Please exercise caution and discretion when using this dataset . The development of this dataset has been done in compliance with Twit - ter’s policy on data usage and sharing . The use of this dataset is solely at your own risk and should be in accordance with applicable laws , regulations , and ethical considerations . If you intend to review the original Twitter post , we recommend accessing the source page di - rectly on Twitter and closely adhering to the official Twitter developer policy , available at https : / / developer . twitter . com / en / dev eloper - terms / policy . Do any export controls or other regula - tory restrictions apply to the dataset or to individual instances ? If so , please describe these restrictions , and provide a link or other access point to , or otherwise reproduce , any supporting documentation . Please exercise caution and discretion when using this dataset . The development of this dataset has been done in compliance with Twitter’s policy on data us - age and sharing . The use of this dataset is solely at your own risk and should be in accordance with applicable laws , regulations , and ethical con - siderations . If you intend to review the original Twitter post , we recommend accessing the source page directly on Twitter and closely adhering to the official Twitter developer policy , available at https : / / developer . twitter . com / en / dev eloper - terms / policy . 18 Maintenance Who will be supporting / hosting / maintaining the dataset ? The first author , YC , will be hosting and main - taining the dataset . How can the owner / curator / manager of the dataset be contacted ( e . g . , email ad - dress ) ? yiqun . t . chen @ gmail . com Is there an erratum ? If so , please provide a link or other access point . N / A . Will the dataset be updated ( e . g . , to cor - rect labeling errors , add new instances , delete instances ) ? If so , please describe how often , by whom , and how updates will be communicated to users ( e . g . , mailing list , GitHub ) ? We do not have plans to regularly add new in - stances ; but we will review requests and gather feedback from users on a quarterly basis . If the dataset relates to people , are there applicable limits on the retention of the data associated with the instances ( e . g . , were individuals in question told that their data would be retained for a fixed period of time and then deleted ) ? If so , please describe these limits and explain how they will be enforced . N / A . Will older versions of the dataset continue to be supported / hosted / maintained ? If so , please describe how . If not , please describe how its obsolescence will be communicated to users . N / A since no new versions are actually being planned . If others want to extend / augment / build on / contribute to the dataset , is there a mechanism for them to do so ? If so , please provide a description . Will these con - tributions be validated / verified ? If so , please describe how . If not , why not ? Is there a process for communicating / distributing these contributions to other users ? If so , please provide a description . The users can leave comments as Github issues at https : / / github . com / yiqunchen / TWIGMA . 19