Unsupervised Abstractive Meeting Summarization with Multi - Sentence Compression and Budgeted Submodular Maximization ∗ Guokan Shang 1 , 2 , Wensi Ding † 1 , Zekun Zhang † 1 , Antoine J . - P . Tixier 1 , Polykarpos Meladianos 1 , 3 , Michalis Vazirgiannis 1 , 3 , Jean - Pierre Lorr´e 2 1 ´Ecole Polytechnique , 2 Linagora , 3 AUEB Abstract We introduce a novel graph - based frame - work for abstractive meeting speech sum - marization that is fully unsupervised and does not rely on any annotations . Our work combines the strengths of multiple recent approaches while addressing their weaknesses . Moreover , we leverage recent advances in word embeddings and graph degeneracy applied to NLP to take exterior semantic knowledge into account , and to design custom diversity and informative - ness measures . Experiments on the AMI and ICSI corpus show that our system im - proves on the state - of - the - art . Code and data are publicly available 1 , and our sys - tem can be interactively tested 2 . 1 Introduction People spend a lot of their time in meetings . The ubiquity of web - based meeting tools and the rapid improvement and adoption of Automatic Speech Recognition ( ASR ) is creating pressing needs for effective meeting speech summarization mecha - nisms . Spontaneous multi - party meeting speech tran - scriptions widely differ from traditional docu - ments . Instead of grammatical , well - segmented sentences , the input is made of often ill - formed and ungrammatical text fragments called utter - ances . On top of that , ASR transcription and seg - mentation errors inject additional noise into the in - put . In this paper , we combine the strengths of 6 approaches that had previously been applied ∗ Published as a long paper at ACL 2018 . † Work done as part of 3 rd year project , with equal contribution . 1 https : / / bitbucket . org / dascim / acl2018 _ abssumm 2 http : / / datascience . open - paas . org / abs _ summ _ app to 3 different tasks ( keyword extraction , multi - sentence compression , and summarization ) into a uniﬁed , fully unsupervised end - to - end meeting speech summarization framework that can gener - ate readable summaries despite the noise inherent to ASR transcriptions . We also introduce some novel components . Our method reaches state - of - the - art performance and can be applied to lan - guages other than English in an almost out - of - the - box fashion . 2 Framework Overview As illustrated in Figure 1 , our system is made of 4 modules , brieﬂy described in what follows . The ﬁrst module pre - processes text . The goal of the second Community Detection step is to group together the utterances that should be summarized by a common abstractive sentence ( Murray et al . , 2012 ) . These utterances typically correspond to a topic or subtopic discussed during the meeting . A single abstractive sentence is then separately gen - erated for each community , using an extension of the Multi - Sentence Compression Graph ( MSCG ) of Filippova ( 2010 ) . Finally , we generate a sum - mary by selecting the best elements from the set of abstractive sentences under a budget constraint . We cast this problem as the maximization of a cus - tom submodular quality function . Note that our approach is fully unsupervised and does not rely on any annotations . Our in - put simply consists in a list of utterances without any metadata . All we need in addition to that is a part - of - speech tagger , a language model , a set of pre - trained word vectors , a list of stopwords and ﬁllerwords , and optionally , access to a lexical database such as WordNet . Our system can work out - of - the - box in most languages for which such resources are available . a r X i v : 1805 . 05271v2 [ c s . C L ] 14 N ov 2018 utterances utterance communities abstractive sentences abstractive summary 3 . multi - sentence compression 4 . submodular maximization 1 . preprocessing 2 . community detection Figure 1 : Overarching system pipeline . 3 Related Work and Contributions As detailed below , our framework combines the strengths of 6 recent works . It also includes novel components . 3 . 1 Multi - Sentence Compression Graph ( MSCG ) ( Filippova , 2010 ) Description : a fully unsupervised , simple ap - proach for generating a short , self - sufﬁcient sen - tence from a cluster of related , overlapping sen - tences . As shown in Figure 5 , a word graph is con - structed with special edge weights , the K - shortest weighted paths are then found and re - ranked with a scoring function , and the best path is used as the compression . The assumption is that redun - dancy alone is enough to ensure informativeness and grammaticality . Limitations : despite making great strides and showing promising results , Filippova ( 2010 ) re - ported that 48 % and 36 % of the generated sen - tences were missing important information and were not perfectly grammatical . Contributions : to respectively improve informa - tiveness and grammaticality , we combine ideas found in Boudin and Morin ( 2013 ) and Mehdad et al . ( 2013 ) , as described next . 3 . 2 More informative MSCG ( Boudin and Morin , 2013 ) Description : same task and approach as in Filip - pova ( 2010 ) , except that a word co - occurrence net - work is built from the cluster of sentences , and that the PageRank scores of the nodes are computed in the manner of Mihalcea and Tarau ( 2004 ) . The scores are then injected into the path re - ranking function to favor informative paths . Limitations : PageRank is not state - of - the - art in capturing the importance of words in a document . Grammaticality is not considered . Contributions : we take grammaticality into ac - count as explained in subsection 3 . 4 . We also follow recent evidence ( Tixier et al . , 2016a ) that spreading inﬂuence , as captured by graph degeneracy - based measures , is better correlated with “keywordedness” than PageRank scores , as explained in the next subsection . 3 . 3 Graph - based word importance scoring ( Tixier et al . , 2016a ) Word co - occurrence network . As shown in Fig - ure 2 , we consider a word co - occurrence network as an undirected , weighted graph constructed by sliding a ﬁxed - size window over text , and where edge weights represent co - occurrence counts ( Tix - ier et al . , 2016b ; Mihalcea and Tarau , 2004 ) . ● ● ● ● ● ● ● categori tend doubt bit big peopl remot design general fli featur button ti CoreRank numbers 34364041454670 Edge weights 1256 Figure 2 : Word co - occurrence graph example , for the input text shown in Figure 5 . Important words are inﬂuential nodes . In so - cial networks , it was shown that inﬂuential spread - ers , that is , those individuals that can reach the largest part of the network in a given number of steps , are better identiﬁed via their core numbers rather than via their PageRank scores or degrees ( Kitsak et al . , 2010 ) . See Figure 3 for the intuition . Similarly , in NLP , Tixier et al . ( 2016a ) have shown that keywords are better identiﬁed via their core numbers rather than via their TextRank scores , that is , keywords are inﬂuencers within their word co - occurrence network . Graph degeneracy ( Seidman , 1983 ) . Let G ( V , E ) be an undirected , weighted graph with n = | V | nodes and m = | E | edges . A k - core of G is a maximal subgraph of G in which ev - ery vertex v has at least weighted degree k . As shown in Figures 3 and 4 , the k - core decomposi - tion of G forms a hierarchy of nested subgraphs whose cohesiveness and size respectively increase and decrease with k . The higher - level cores can be viewed as a ﬁltered version of the graph that excludes noise . This property is highly valuable when dealing with graphs constructed from noisy text , like utterances . The core number of a node is the highest order of a core that contains this node . ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● 5 5 * 5 4 4 4 4 3 3 3 3 1 1 1 1 5 * * 1 1 1 1 ● ● ● ● PageRank scores ( 2 . 07 , 4 . 41 ] ( 4 . 41 , 6 . 73 ] ( 6 . 73 , 9 . 05 ] ( 9 . 05 , 11 . 4 ] Core numbers 1 2 3 Figure 3 : k - core decomposition . The nodes (cid:63) and (cid:63)(cid:63) have same degree and similar PageRank numbers . However , node (cid:63) is a much more inﬂuential spreader as it is strategically placed in the core of the network , as captured by its higher core number . The CoreRank number of a node ( Tixier et al . , 2016a ; Bae and Kim , 2014 ) is deﬁned as the sum of the core numbers of its neighbors . As shown in Figure 4 , CoreRank more ﬁnely captures the structural position of each node in the graph than raw core numbers . Also , stabilizing scores across node neighborhoods enhances the inherent noise robustness property of graph degeneracy , which is 3 - core 2 - core 1 - core Corenumber Corenumber Corenumber c = 1 c = 2 c = 3 * * * Figure 4 : Value added by CoreRank : while nodes (cid:63) and (cid:63)(cid:63) have the same core number ( = 2 ) , node (cid:63) has a greater Cor - eRank score ( 3 + 2 + 2 = 7 vs 2 + 2 + 1 = 5 ) , which better reﬂects its more central position in the graph . desirable when working with noisy speech - to - text output . Time complexity . Building a graph - of - words is O ( nW ) , and computing the weighted k - core decomposition of a graph requires O ( m log ( n ) ) ( Batagelj and Zaverˇsnik , 2002 ) . For small pieces of text , this two step process is so affordable that it can be used in real - time ( Meladianos et al . , 2017 ) . Finally , computing CoreRank scores can be done with only a small overhead of O ( n ) , provided that the graph is stored as a hash of adjacency lists . Getting the CoreRank numbers from scratch for a community of utterances is therefore very fast , especially since typically in this context , n ∼ 10 and m ∼ 100 . 3 . 4 Fluency - aware , more abstractive MSCG ( Mehdad et al . , 2013 ) Description : a supervised end - to - end framework for abstractive meeting summarization . Commu - nity Detection is performed by ( 1 ) building an ut - terance graph with a logistic regression classiﬁer , and ( 2 ) applying the CONGA algorithm . Then , before performing sentence compression with the MSCG , the authors also ( 3 ) build an entailment graph with a SVM classiﬁer in order to eliminate redundant and less informative utterances . In ad - dition , the authors propose the use of WordNet ( Miller , 1995 ) during the MSCG building phase to capture lexical knowledge between words and thus generate more abstractive compressions , and of a language model when re - ranking the shortest paths , to favor ﬂuent compressions . Limitations : this effort was a signiﬁcant advance , as it was the ﬁrst application of the MSCG to the meeting summarization task , to the best of our knowledge . However , steps ( 1 ) and ( 3 ) above are complex , based on handcrafted features , and respectively require annotated training data in the form of links between human - written abstractive sentences and original utterances and multiple external datasets ( e . g . , from the Recognizing Textual Entailment Challenge ) . Such annotations are costly to obtain and very seldom available in practice . Contributions : while we retain the use of WordNet and of a language model , we show that , without deteriorating the quality of the results , steps ( 1 ) and ( 2 ) above ( Community Detection ) can be performed in a much more simple , completely un - supervised way , and that step ( 3 ) can be removed . That is , the MSCG is powerful enough to remove redundancy and ensure informativeness , should proper edge weights and path re - ranking function be used . In addition to the aforementioned contributions , we also introduce the following novel components into our abstractive summarization pipeline : • we inject global exterior knowledge into the edge weights of the MSCG , by using the Word At - traction Force of Wang et al . ( 2014 ) , based on distance in the word embedding space , • we add a diversity term to the path re - ranking function , that measures how many unique clusters in the embedding space are visited by each path , • rather than using all the abstractive sentences as the ﬁnal summary like in Mehdad et al . ( 2013 ) , we maximize a custom submodular function to se - lect a subset of abstractive sentences that is near - optimal given a budget constraint ( summary size ) . A brief background of submodularity in the con - text of summarization is provided next . 3 . 5 Submodularity for summarization ( Lin and Bilmes , 2010 ; Lin , 2012 ) Selecting an optimal subset of abstractive sen - tences from a larger set can be framed as a bud - geted submodular maximization task : argmax S ⊆S f ( S ) | (cid:88) s ∈ S c s ≤ B ( 1 ) where S is a summary , c s is the cost ( word count ) of sentence s , B is the desired summary size in words ( budget ) , and f is a summary quality scor - ing set function , which assigns a single numeric score to a summary S . This combinatorial optimization task is NP - hard . However , near - optimal performance can be guaranteed with a modiﬁed greedy algorithm ( Lin and Bilmes , 2010 ) that iteratively selects the sen - tence s that maximizes the ratio of quality function gain to scaled cost f ( S ∪ s ) − f ( S ) / c rs ( where S is the current summary and r ≥ 0 is a scaling factor ) . In order for the performance guarantees to hold however , f has to be submodular and monotone non - decreasing . Our proposed f is described in subsection 4 . 4 . 4 Our Framework We detail next each of the four modules in our ar - chitecture ( shown in Figure 1 ) . 4 . 1 Text preprocessing We adopt preprocessing steps tailored to the char - acteristics of ASR transcriptions . Consecutive re - peated unigrams and bigrams are reduced to single terms . Speciﬁc ASR tags , such as { vocalsound } , { pause } , and { gap } are ﬁltered out . In addition , ﬁller words , such as uh - huh , okay , well , and by the way are also discarded . Consecutive stopwords at the beginning and end of utterances are stripped . In the end , utterances that contain less than 3 non - stopwords are pruned out . The surviving utter - ances are used for the next steps . 4 . 2 Utterance community detection The goal here is to cluster utterances into commu - nities that should be summarized by a common ab - stractive sentence . We initially experimented with techniques cap - italizing on word vectors , such as k - means and hi - erarchical clustering based on the Euclidean dis - tance or the Word Mover’s Distance ( Kusner et al . , 2015 ) . We also tried graph - based approaches , such as community detection in a complete graph where nodes are utterances and edges are weighted based on the aforementioned distances . Best results were obtained , however , with a sim - ple approach in which utterances are projected into the vector space and assigned standard TF - IDF weights . Then , the dimensionality of the utterance - term matrix is reduced with Latent Se - mantic Analysis ( LSA ) , and ﬁnally , the k - means algorithm is applied . Note that LSA is only used here , during the utterance community detection phase , to remove noise and stabilize clustering . We do not use a topic graph in our approach . Figure 5 : Compressed sentence ( in bold red ) generated by our multi - sentence com - pression graph ( MSCG ) for a 3 - utterance community from meeting IS1009b of the AMI corpus . Using Filippova ( 2010 ) ’s weighting and re - ranking scheme here would have selected another path : design different remotes for different people bit of it’s from their tend to for ti . Note that the compressed sentence does not appear in the initial set of utterances , and is compact and grammatical , despite the redundancy , tran - scription and segmentation errors of the in - put . The abstractive and robust nature of the MSCG makes it particularly well - suited to the meeting domain . buttons for is a different big from like for three we be people doubt to ti if their are it different which for of we people having that design each remote will for different that because of designing all the remotes bit mean can generally to tend three for its categories different START the be need with of features like flies END • generally we can design a remote which is mean need for people bit of it ' s from their tend to for ti • design different remotes for different people like for each to be the that will be big buttons • doubt like with it because flies that if we design of remote having all the different features for different people are designing three different remotes for three different categories of people We think using word embeddings was not ef - fective , because in meeting speech , as opposed to traditional documents , participants tend to use the same term to refer to the same thing throughout the entire conversation , as noted by Riedhammer et al . ( 2010 ) , and as veriﬁed in practice . This is probably why , for clustering utterances , capturing synonymy is counterproductive , as it artiﬁcially reduces the distance between every pair of utter - ances and blurs the picture . 4 . 3 Multi - Sentence Compression The following steps are performed separately for each community . Word importance scoring From a processed version of the community ( stem - ming and stopword removal ) , we construct an undirected , weighted word co - occurrence network as described in subsection 3 . 3 . We use a sliding window of size W = 6 not overspanning utter - ances . Note that stemming is performed only here , and for the sole purpose of building the word co - occurrence network . We then compute the CoreRank numbers of the nodes as described in subsection 3 . 3 . We ﬁnally reweigh the CoreRank scores , in - dicative of word importance within a given com - munity , with a quantity akin to an Inverse Doc - ument Frequency , where communities serve as documents and the full meeting as the collection . We thus obtain something equivalent to the TW - IDF weighting scheme of Rousseau and Vazirgian - nis ( 2013 ) , where the CoreRank scores are the term weights TW : T W - IDF ( t , d , D ) = T W ( t , d ) × IDF ( t , D ) ( 2 ) where t is a term belonging to community d , and D is the set of all utterance communities . We compute the IDF as IDF ( t , D ) = 1 + log | D | / D t , where | D | is the number of communities and D t the number of communities containing t . The intuition behind this reweighing scheme is that a term should be considered important within a given meeting if it has a high CoreRank score within its community and if the number of com - munities in which the term appears is relatively small . Word graph building The backbone of the graph is laid out as a directed sequence of nodes corresponding to the words in the ﬁrst utterance , with special START and END nodes at the beginning and at the end ( see Figure 5 ) . Edge direction follows the natural ﬂow of text . Words from the remaining utterances are then iteratively added to the graph ( between the START and END nodes ) based on the following rules : 1 ) if the word is a non - stopword , the word is mapped onto an existing node if it has the same lowercased form and the same part - of - speech tag 3 . In case of multiple matches , we check the imme - diate context ( the preceding and following words in the utterance and the neighboring nodes in the 3We used NLTK’s averaged perceptron tagger , available at : http : / / www . nltk . org / api / nltk . tag . html # module - nltk . tag . perceptron graph ) , and we pick the node with the largest con - text overlap or which has the greatest number of words already mapped to it ( when no overlap ) . When there is no match , we use WordNet as de - scribed in Appendix A . 2 ) if the word is a stopword and there is a match , it is mapped only if there is an overlap of at least one non - stopword in the immediate context . Otherwise , a new node is created . Finally , note that any two words appearing within the same utterance cannot be mapped to the same node . This ensures that every utterance is a loop - less path in the graph . Of course , there are many more paths in the graphs than original utterances . Edge Weight Assignment Once the word graph is constructed , we assign weights to its edges as : w (cid:48)(cid:48)(cid:48) ( p i , p j ) = w (cid:48) ( p i , p j ) w (cid:48)(cid:48) ( p i , p j ) ( 3 ) where p i and p j are two neighbors in the MSCG . As detailed next , those weights combine local co - occurrence statistics ( numerator ) with global exte - rior knowledge ( denominator ) . Note that the lower the weight of an edge , the better . Local co - occurrence statistics . We use Filippova ( 2010 ) ’s formula : w (cid:48) ( p i , p j ) = f ( p i ) + f ( p j ) (cid:80) P ∈ G (cid:48) , p i , p j ∈ P diﬀ ( P , p i , p j ) − 1 ( 4 ) where f ( p i ) is the number of words mapped to node p i in the MSCG G (cid:48) , and diﬀ ( P , p i , p j ) − 1 is the inverse of the distance between p i and p j in a path P ( in number of hops ) . This weighting func - tion favors edges between infrequent words that frequently appear close to each other in the text ( the lower , the better ) . Global exterior knowledge . We introduce a second term based on the Word At - traction Force score of Wang et al . ( 2014 ) : w (cid:48)(cid:48) ( p i , p j ) = f ( p i ) × f ( p j ) d 2 p i , p j ( 5 ) where d p i , p j is the Euclidean distance between the words mapped to p i and p j in a word embedding space 4 . This component favor paths going through salient words that have high semantic similarity 4GoogleNewsvectors https : / / code . google . com / archive / p / word2vec ( the higher , the better ) . The goal is to ensure read - ability of the compression , by avoiding to generate a sentence jumping from one word to a completely unrelated one . Path re - ranking As in Boudin and Morin ( 2013 ) , we use a short - est weighted path algorithm to ﬁnd the K paths between the START and END symbols having the lowest cumulative edge weight : W ( P ) = | P | − 1 (cid:88) i = 1 w (cid:48)(cid:48)(cid:48) ( p i , p i + 1 ) ( 6 ) Where | P | is the number of nodes in the path . Paths having less than z words or that do not con - tain a verb are ﬁltered out ( z is a tuning parame - ter ) . However , unlike in Boudin and Morin ( 2013 ) , we rerank the K best paths with the following novel weighting scheme ( the lower , the better ) , and the path with the lowest score is used as the compression : score ( P ) = W ( P ) | P | × F ( P ) × C ( P ) × D ( P ) ( 7 ) The denominator takes into account the length of the path , and its ﬂuency ( F ) , coverage ( C ) , and diversity ( D ) . F , C , and D are detailed in what follows . Fluency . We estimate the grammaticality of a path with an n - gram language model . In our ex - periments , we used a trigram model 5 : F ( P ) = (cid:80) | P | i = 1 log P r ( p i | p i − 1 i − n + 1 ) # n - gram ( 8 ) where | P | denote path length , and p i and # n - gram are respectively the words and number of n - grams in the path . Coverage . We reward the paths that visit impor - tant nouns , verbs and adjectives : C ( P ) = (cid:80) p i ∈ P TW - IDF ( p i ) # p i ( 9 ) where # p i is the number of nouns , verbs and ad - jectives in the path . The TW - IDF scores are com - puted as explained in subsection 4 . 3 . Diversity . We cluster all words from the MSCG in the word embedding space by applying the k - means algorithm . We then measure the diversity of 5CMUSphinxEnglishLM : https : / / cmusphinx . github . io Figure 6 : t - SNE visualization ( Maaten and Hin - ton , 2008 ) of the Google News vectors of the words in the utterance community shown in Fig - ure 5 . Arrows join the words in the best com - pression path shown in Figure 5 . Movements in the embedding space , as measured by the num - ber of unique clusters covered by the path ( here , 6 / 11 ) , provide a sense of the diversity of the compressed sentence , as formalized in Equation 10 . 100 0 100 200 300 200 100 0 100 200 300 different for people design of to three be that remotesremote like we the flies because features is it are need if from it ' s generally tend buttons their doubt which ti all big designing bit with categories a will can each having mean the vocabulary contained in a path as the number of unique clusters visited by the path , normalized by the length of the path : D ( P ) = (cid:80) kj = 1 1 ∃ p i ∈ P | p i ∈ cluster j | P | ( 10 ) The graphical intuition for this measure is pro - vided in Figure 6 . Note that we do not normalize D by the total number of clusters ( only by path length ) because k is ﬁxed for all candidate paths . 4 . 4 Budgeted submodular maximization We apply the previous steps separately for all ut - terance communities , which results in a set S of abstractive sentences ( one for each community ) . This set of sentences can already be considered to be a summary of the meeting . However , it might exceed the maximum size allowed , and still con - tain some redundancy or off - topic sections unre - lated to the general theme of the meeting ( e . g . , chit - chat ) . Therefore , we design the following submodular and monotone non - decreasing objective function : f ( S ) = (cid:88) s i ∈ S n s i w s i + λ k (cid:88) j = 1 1 ∃ s i ∈ S | s i ∈ cluster j ( 11 ) where λ ≥ 0 is the trade - off parameter , n s i is the number of occurrences of word s i in S , and w s i is the CoreRank score of s i . Then , as explained in subsection 3 . 5 , we ob - tain a near - optimal subset of abstractive sentences by maximizing f with a greedy algorithm . Cor - eRank scores and clusters are found as previ - ously described , except that this time they are ob - tained from the full processed meeting transcrip - tion rather than from a single utterance commu - nity . 5 Experimental setup 5 . 1 Datasets We conducted experiments on the widely - used AMI ( McCowan et al . , 2005 ) and ICSI ( Janin et al . , 2003 ) benchmark datasets . We used the tra - ditional test sets of 20 and 6 meetings respectively for the AMI and ICSI corpora ( Riedhammer et al . , 2008 ) . Each meeting in the AMI test set is asso - ciated with a human abstractive summary of 290 words on average , whereas each meeting in the ICSI test set is associated with 3 human abstrac - tive summaries of respective average sizes 220 , 220 and 670 words . For parameter tuning , we constructed develop - ment sets of 47 and 25 meetings , respectively for AMI and ICSI , by randomly sampling from the training sets . The word error rate of the ASR tran - scriptions is respectively of 36 % and 37 % for AMI and ICSI . 5 . 2 Baselines We compared our system against 7 baselines , which are listed below and more thoroughly de - tailed in Appendix B . Note that preprocessing was exactly the same for our system and all baselines . • Random and Longest Greedy are basic base - lines recommended by ( Riedhammer et al . , 2008 ) , • TextRank ( Mihalcea and Tarau , 2004 ) , • ClusterRank ( Garg et al . , 2009 ) , • CoreRank & PageRank submodular ( Tixier et al . , 2017 ) , • Oracle is the same as the random baseline , but uses the human extractive summaries as input . In addition to the baselines above , we included in our comparison 3 variants of our system us - ing different MSCGs : Our System ( Baseline ) uses the original MSCG of Filippova ( 2010 ) , Our System ( KeyRank ) uses that of Boudin and Morin ( 2013 ) , and Our System ( FluCovRank ) that of Mehdad et al . ( 2013 ) . Details about each approach were given in Section 3 . 5 . 3 Parameter tuning For Our System and each of its variants , we con - ducted a grid search on the development sets of each corpus , for ﬁxed summary sizes of 350 and 450 words ( AMI and ICSI ) . We searched the fol - lowing parameters : • n : number of utterance communities ( see Sec - tion 4 . 2 ) . We tested values of n ranging from 20 to 60 , with steps of 5 . This parameter controls how much abstractive should the summary be . If all ut - terances are assigned to their own singleton com - munity , the MSCG is of no utility , and our frame - work is extractive . It becomes more and more ab - stractive as the number of communities decreases . • z : minimum path length ( see Section 4 . 3 ) . We searched values in the range [ 6 , 16 ] with steps of 2 . If a path is shorter than a certain minimum number of words , it often corresponds to an invalid sen - tence , and should thereby be ﬁltered out . • λ and r , the trade - off parameter and the scaling factor ( see Section 4 . 4 ) . We searched [ 0 , 1 ] and [ 0 , 2 ] ( respectively ) with steps of 0 . 1 . The parame - ter λ plays a regularization role favoring diversity . The scaling factor makes sure the quality function gain and utterance cost are comparable . The best parameter values for each corpus are summarized in Table 1 . λ is mostly non - zero , in - dicating that it is necessary to include a regular - ization term in the submodular function . In some cases though , r is equal to zero , which means that utterance costs are not involved in the greedy de - cision heuristic . These observations contradict the conclusion of Lin ( 2012 ) that r = 0 cannot give best results . System AMI ICSI Our System 50 , 8 , ( 0 . 7 , 0 . 5 ) 40 , 14 , ( 0 . 0 , 0 . 0 ) Our System ( Baseline ) 50 , 12 , ( 0 . 3 , 0 . 5 ) 45 , 14 , ( 0 . 1 , 0 . 0 ) Our System ( KeyRank ) 50 , 10 , ( 0 . 2 , 0 . 9 ) 45 , 12 , ( 0 . 3 , 0 . 4 ) Our System ( FluCovRank ) 35 , 6 , ( 0 . 4 , 1 . 0 ) 50 , 10 , ( 0 . 2 , 0 . 3 ) Table 1 : Optimal parameter values n , z , ( λ , r ) . Apart from the tuning parameters , we set the number of LSA dimensions to 30 and 60 ( resp . on AMI and ISCI ) . The small number of LSA di - mensions retained can be explained by the fact that the AMI and ICSI transcriptions feature 532 and 1126 unique words on average , which is much smaller than traditional documents . This is due to relatively small meeting duration , and to the fact that participants tend to stick to the same terms throughout the entire conversation . For the k - means algorithm , k was set equal to the minimum path length z when doing MSCG path re - ranking ( see Equation 10 ) , and to 60 when generating the ﬁnal summary ( see Equation 11 ) . Following Boudin and Morin ( 2013 ) , the num - ber of shortest weighted paths K was set to 200 , which is greater than the K = 100 used by Fil - ippova ( 2010 ) . Increasing K from 100 improves performance with diminishing returns , but sig - niﬁcantly increases complexity . We empirically found 200 to be a good trade - off . 6 Results and Interpretation Metrics . We evaluated performance with the widely - used ROUGE - 1 , ROUGE - 2 and ROUGE - SU4 metrics ( Lin , 2004 ) . These metrics are re - spectively based on unigram , bigram , and unigram plus skip - bigram overlap with maximum skip dis - tance of 4 , and have been shown to be highly correlated with human evaluations ( Lin , 2004 ) . ROUGE - 2 scores can be seen as a measure of sum - mary readability ( Lin and Hovy , 2003 ; Ganesan et al . , 2010 ) . ROUGE - SU4 does not require con - secutive matches but is still sensitive to word or - der . Macro - averaged results for summaries gener - ated from automatic transcriptions can be seen in Figure 7 and Table 2 . Table 2 provides detailed comparisons over the ﬁxed budgets that we used for parameter tuning , while Figure 7 shows the performance of the models for budgets ranging from 150 to 500 words . The same information for summaries generated from manual transcriptions is available in Appendix C . Finally , summary ex - amples are available in Appendix D . ROUGE - 1 . Our systems outperform all baselines on AMI ( including Oracle ) and all baselines on ICSI ( except Oracle ) . Speciﬁcally , Our System is best on ICSI , while Our System ( KeyRank ) is su - perior on AMI . We can also observe on Figure 7 that our systems are consistently better throughout the different summary sizes , even though their pa - rameters were tuned for speciﬁc sizes only . This shows that the best parameter values are quite ro - bust across the entire budget range . ROUGE - 2 . Again , our systems ( except Our Sys - tem ( Baseline ) ) outperform all baselines , except Oracle . In addition , Our System and Our Sys - 150 200 250 300 350 400 450 500 summarysize ( words ) 0 . 26 0 . 28 0 . 30 0 . 32 0 . 34 0 . 36 0 . 38 R O U G E - 1 F 1 - sc o r e AMI OURSYSTEMOURSYSTEM ( BASELINE ) OURSYSTEM ( KEYRANK ) OURSYSTEM ( FLUCOVRANK ) ORACLECORERANKSUBMODULARPAGERANKSUBMODULARTEXTRANKCLUSTERRANKLONGESTGREEDYRANDOM 150 200 250 300 350 400 450 500 summarysize ( words ) 0 . 22 0 . 24 0 . 26 0 . 28 0 . 30 0 . 32 ICSI OURSYSTEMOURSYSTEM ( BASELINE ) OURSYSTEM ( KEYRANK ) OURSYSTEM ( FLUCOVRANK ) ORACLECORERANKSUBMODULARPAGERANKSUBMODULARTEXTRANKCLUSTERRANKLONGESTGREEDYRANDOM Figure 7 : ROUGE - 1 F - 1 scores for various budgets ( ASR transcriptions ) . AMI ROUGE - 1 AMI ROUGE - 2 AMI ROUGE - SU4 ICSI ROUGE - 1 ICSI ROUGE - 2 ICSI ROUGE - SU4 R P F - 1 R P F - 1 R P F - 1 R P F - 1 R P F - 1 R P F - 1 Our System 41 . 83 34 . 44 37 . 25 8 . 22 6 . 95 7 . 43 15 . 83 13 . 70 14 . 51 36 . 99 28 . 12 31 . 60 5 . 41 4 . 39 4 . 79 13 . 10 10 . 17 11 . 35 Our System ( Baseline ) 41 . 56 34 . 37 37 . 11 7 . 88 6 . 66 7 . 11 15 . 36 13 . 20 14 . 02 36 . 39 27 . 20 30 . 80 5 . 19 4 . 12 4 . 55 12 . 59 9 . 70 10 . 86 Our System ( KeyRank ) 42 . 43 35 . 01 37 . 86 8 . 72 7 . 29 7 . 84 16 . 19 13 . 76 14 . 71 35 . 95 27 . 00 30 . 52 4 . 64 3 . 64 4 . 04 12 . 43 9 . 23 10 . 50 Our System ( FluCovRank ) 41 . 84 34 . 61 37 . 37 8 . 29 6 . 92 7 . 45 16 . 28 13 . 48 14 . 58 36 . 27 27 . 56 31 . 00 5 . 56 4 . 35 4 . 83 13 . 47 9 . 85 11 . 29 Oracle 40 . 49 34 . 65 36 . 73 8 . 07 7 . 35 7 . 55 15 . 00 14 . 03 14 . 26 37 . 91 28 . 39 32 . 12 5 . 73 4 . 82 5 . 18 13 . 35 10 . 73 11 . 80 CoreRank Submodular 41 . 14 32 . 93 36 . 13 8 . 06 6 . 88 7 . 33 14 . 84 13 . 91 14 . 18 35 . 22 26 . 34 29 . 82 4 . 36 3 . 76 4 . 00 12 . 11 9 . 58 10 . 61 PageRank Submodular 40 . 84 33 . 08 36 . 10 8 . 27 6 . 88 7 . 42 15 . 37 13 . 71 14 . 32 36 . 05 26 . 69 30 . 40 4 . 82 4 . 16 4 . 42 12 . 19 10 . 39 11 . 14 TextRank 39 . 55 32 . 60 35 . 25 7 . 67 6 . 43 6 . 90 14 . 87 12 . 87 13 . 62 34 . 89 26 . 33 29 . 70 4 . 60 3 . 74 4 . 09 12 . 42 9 . 43 10 . 64 ClusterRank 39 . 36 32 . 53 35 . 14 7 . 14 6 . 05 6 . 46 14 . 34 12 . 80 13 . 35 32 . 63 24 . 44 27 . 64 4 . 03 3 . 44 3 . 68 11 . 04 8 . 88 9 . 77 Longest Greedy 37 . 31 30 . 93 33 . 35 5 . 77 4 . 71 5 . 11 13 . 79 11 . 11 12 . 15 35 . 57 26 . 74 30 . 23 4 . 84 3 . 88 4 . 27 13 . 09 9 . 46 10 . 90 Random 39 . 42 32 . 48 35 . 13 6 . 88 5 . 89 6 . 26 14 . 07 12 . 70 13 . 17 34 . 78 25 . 75 29 . 28 4 . 19 3 . 51 3 . 78 11 . 61 9 . 37 10 . 29 Table 2 : Macro - averaged results for 350 and 450 word summaries ( ASR transcriptions ) . tem ( FluCovRank ) consistently improve on Our System ( Baseline ) , which proves that the novel components we introduce improve summary ﬂu - ency . ROUGE - SU4 . ROUGE - SU4 was used to mea - sure the amount of in - order word pairs overlap - ping . Our systems are competitive with all base - lines , including Oracle . Like with ROUGE - 1 , Our System is better than Our System ( KeyRank ) on ICSI , whereas the opposite is true on AMI . General remarks . • The summaries of all systems except Oracle were generated from noisy ASR transcriptions , but were compared against human abstractive sum - maries . ROUGE being based on word overlap , it makes it very difﬁcult to reach very high scores , because many words in the ground truth sum - maries do not appear in the transcriptions at all . • The scores of all systems are lower on ICSI than on AMI . This can be explained by the fact that on ICSI , the system summaries have to jointly match 3 human abstractive summaries of different con - tent and size , which is much more difﬁcult than matching a single summary . • Our framework is very competitive to Oracle , which is notable since the latter has direct access to the human extractive summaries . Note that Or - acle does not reach very high ROUGE scores be - cause the overlap between the human extractive and abstractive summaries is low ( 19 % and 29 % , respectively on AMI and ICSI test sets ) . 7 Conclusion and Next Steps Our framework combines the strengths of 6 ap - proaches that had previously been applied to 3 dif - ferent tasks ( keyword extraction , multi - sentence compression , and summarization ) into a uni - ﬁed , fully unsupervised end - to - end summarization framework , and introduces some novel compo - nents . Rigorous evaluation on the AMI and ICSI corpora shows that we reach state - of - the - art per - formance , and generate reasonably grammatical abstractive summaries despite taking noisy utter - ances as input and not relying on any annotations or training data . Finally , thanks to its fully unsu - pervised nature , our method is applicable to other languages than English in an almost out - of - the - box manner . Our framework was developed for the meeting domain . Indeed , our generative component , the multi - sentence compression graph ( MSCG ) , needs redundancy to perform well . Such redundancy is typically present in meeting speech but not in traditional documents . In addition , the MSCG is by design robust to noise , and our custom path re - ranking strategy , based on graph degeneracy , makes it even more robust to noise . As a result , our framework is advantaged on ASR input . Fi - nally , we use a language model to favor ﬂuent paths , which is crucial when working with ( meet - ing ) speech but not that important when dealing with well - formed input . Future efforts should be dedicated to improv - ing the community detection phase and generating more abstractive sentences , probably by harness - ing Deep Learning . However , the lack of large training sets for the meeting domain is an obsta - cle to the use of neural approaches . Acknowledgments We are grateful to the three anonymous review - ers for their detailed and constructive feedback . This research was supported in part by the Open - PaaS : : NG project . References Joonhyun Bae and Sangwook Kim . 2014 . Identify - ing and ranking inﬂuential spreaders in complex net - works by neighborhood coreness . Physica A : Statis - tical Mechanics and its Applications 395 : 549 – 559 . Vladimir Batagelj and Matjaˇz Zaverˇsnik . 2002 . Gener - alized cores . arXiv preprint cs / 0202039 . Florian Boudin and Emmanuel Morin . 2013 . Keyphrase extraction for n - best reranking in multi - sentence compression . In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguis - tics : Human Language Technologies . Association for Computational Linguistics , pages 298 – 305 . http : / / aclweb . org / anthology / N13 - 1030 . Katja Filippova . 2010 . Multi - sentence compres - sion : Finding shortest paths in word graphs . In Proceedings of the 23rd International Conference on Computational Linguistics ( Coling 2010 ) . Col - ing 2010 Organizing Committee , pages 322 – 330 . http : / / aclweb . org / anthology / C10 - 1037 . Kavita Ganesan , ChengXiang Zhai , and Jiawei Han . 2010 . Opinosis : A graph based approach to abstrac - tive summarization of highly redundant opinions . In Proceedings of the 23rd International Conference on Computational Linguistics ( Coling 2010 ) . Col - ing 2010 Organizing Committee , pages 340 – 348 . http : / / aclweb . org / anthology / C10 - 1039 . Nikhil Garg , Benoit Favre , Korbinian Reidhammer , and Dilek Hakkani - T¨ur . 2009 . Clusterrank : a graph based method for meeting summarization . In Tenth Annual Conference of the International Speech Communication Association . A . Janin , D . Baron , J . Edwards , D . Ellis , D . Gelbart , N . Morgan , B . Peskin , T . Pfau , E . Shriberg , A . Stolcke , and C . Wooters . 2003 . The icsi meeting corpus . In Acoustics , Speech , and Signal Processing , 2003 . Proceedings . ( ICASSP ’03 ) . 2003 IEEE International Con - ference on . volume 1 , pages I – 364 – I – 367 vol . 1 . https : / / doi . org / 10 . 1109 / ICASSP . 2003 . 1198793 . Maksim Kitsak , Lazaros K Gallos , Shlomo Havlin , Fredrik Liljeros , Lev Muchnik , H Eu - gene Stanley , and Hern´an A Makse . 2010 . Identiﬁcation of inﬂuential spreaders in com - plex networks . Nature Physics 6 ( 11 ) : 888 – 893 . https : / / doi . org / 10 . 1038 / nphys1746 . Matt J . Kusner , Yu Sun , Nicholas I . Kolkin , and Kil - ian Q . Weinberger . 2015 . From word embeddings to document distances . In Proceedings of the 32Nd International Conference on International Confer - ence on Machine Learning - Volume 37 . JMLR . org , ICML’15 , pages 957 – 966 . Chin - Yew Lin . 2004 . Rouge : A package for automatic evaluation of summaries . In Text Summarization Branches Out . http : / / aclweb . org / anthology / W04 - 1013 . Chin - Yew Lin and Eduard Hovy . 2003 . Auto - matic evaluation of summaries using n - gram co - occurrence statistics . In Proceedings of the 2003 Human Language Technology Con - ference of the North American Chapter of the Association for Computational Linguistics . http : / / aclweb . org / anthology / N03 - 1020 . Hui Lin . 2012 . Submodularity in natural language pro - cessing : algorithms and applications . University of Washington . Hui Lin and Jeff Bilmes . 2010 . Multi - document sum - marization via budgeted maximization of submod - ular functions . In Human Language Technologies : The 2010 Annual Conference of the North American Chapter of the Association for Computational Lin - guistics . Association for Computational Linguistics , pages 912 – 920 . http : / / aclweb . org / anthology / N10 - 1134 . Laurens van der Maaten and Geoffrey Hinton . 2008 . Visualizing data using t - sne . Journal of machine learning research 9 ( Nov ) : 2579 – 2605 . Iain McCowan , Jean Carletta , W Kraaij , S Ashby , S Bourban , M Flynn , M Guillemot , T Hain , J Kadlec , V Karaiskos , et al . 2005 . The ami meet - ing corpus . In Proceedings of the 5th International Conference on Methods and Techniques in Behav - ioral Research . volume 88 . Yashar Mehdad , Giuseppe Carenini , Frank Tompa , and Raymond T . NG . 2013 . Abstractive meet - ing summarization with entailment and fusion . In Proceedings of the 14th European Work - shop on Natural Language Generation . Associa - tion for Computational Linguistics , pages 136 – 146 . http : / / aclweb . org / anthology / W13 - 2117 . Polykarpos Meladianos , Antoine Tixier , Ioannis Niko - lentzos , and Michalis Vazirgiannis . 2017 . Real - time keyword extraction from conversations . In Proceedings of the 15th Conference of the Eu - ropean Chapter of the Association for Computa - tional Linguistics : Volume 2 , Short Papers . Associa - tion for Computational Linguistics , pages 462 – 467 . http : / / aclweb . org / anthology / E17 - 2074 . Rada Mihalcea and Paul Tarau . 2004 . Tex - trank : Bringing order into text . In Pro - ceedings of the 2004 Conference on Empiri - cal Methods in Natural Language Processing . http : / / aclweb . org / anthology / W04 - 3252 . George A . Miller . 1995 . Wordnet : A lexical database for english . Commun . ACM 38 ( 11 ) : 39 – 41 . https : / / doi . org / 10 . 1145 / 219717 . 219748 . Gabriel Murray , Giuseppe Carenini , and Raymond Ng . 2012 . Using the omega index for evaluat - ing abstractive community detection . In Proceed - ings of Workshop on Evaluation Metrics and System Comparison for Automatic Summarization . Associ - ation for Computational Linguistics , pages 10 – 18 . http : / / aclweb . org / anthology / W12 - 2602 . Lawrence Page , Sergey Brin , Rajeev Motwani , and Terry Winograd . 1999 . The pagerank citation rank - ing : Bringing order to the web . Technical report , Stanford InfoLab . Korbinian Riedhammer , Benoit Favre , and Dilek Hakkani - T¨ur . 2010 . Long story short - global unsupervised models for keyphrase based meeting summarization . Speech Commun . 52 ( 10 ) : 801 – 815 . https : / / doi . org / 10 . 1016 / j . specom . 2010 . 06 . 002 . Korbinian Riedhammer , Dan Gillick , Benoit Favre , and Dilek Hakkani - T¨ur . 2008 . Packing the meeting sum - marization knapsack . In Ninth Annual Conference of the International Speech Communication Associ - ation . Franc¸ois Rousseau and Michalis Vazirgiannis . 2013 . Graph - of - word and tw - idf : New approach to ad hoc ir . In Proceedings of the 22Nd ACM International Conference on Information & Knowledge Manage - ment . ACM , New York , NY , USA , CIKM ’13 , pages 59 – 68 . https : / / doi . org / 10 . 1145 / 2505515 . 2505671 . Stephen B Seidman . 1983 . Network structure and minimum degree . Social networks 5 ( 3 ) : 269 – 287 . https : / / doi . org / 10 . 1016 / 0378 - 8733 ( 83 ) 90028 - X . Antoine Tixier , Fragkiskos Malliaros , and Michalis Vazirgiannis . 2016a . A graph degeneracy - based approach to keyword extraction . In Proceed - ings of the 2016 Conference on Empirical Meth - ods in Natural Language Processing . Association for Computational Linguistics , pages 1860 – 1870 . https : / / doi . org / 10 . 18653 / v1 / D16 - 1191 . Antoine Tixier , Polykarpos Meladianos , and Michalis Vazirgiannis . 2017 . Combining graph degener - acy and submodularity for unsupervised extrac - tive summarization . In Proceedings of the Work - shop on New Frontiers in Summarization . Associ - ation for Computational Linguistics , pages 48 – 58 . http : / / aclweb . org / anthology / W17 - 4507 . Antoine Tixier , Konstantinos Skianis , and Michalis Vazirgiannis . 2016b . Gowvis : A web ap - plication for graph - of - words - based text visual - ization and summarization . In Proceedings of ACL - 2016 System Demonstrations . Association for Computational Linguistics , pages 151 – 156 . https : / / doi . org / 10 . 18653 / v1 / P16 - 4026 . Rui Wang , Wei Liu , and Chris McDonald . 2014 . Corpus - independent generic keyphrase extraction using word embedding vectors . In Software Engi - neering Research Conference . volume 39 . Supplementary Material Appendices A Use of WordNet When the word to be mapped to the MSCG is a non - stopword , and if there is no node in the graph that has the same lowercased form and the same part - of - speech tag , we try to perform the mapping by using WordNet in the following order : ( i ) there is a node which is a synonym of the word ( e . g . , “price” and “costs” ) . The word is mapped to that node , and the node is relabeled with the word if the latter has a higher TW - IDF score . ( ii ) there is a node which is a hypernym of the word ( e . g . , “diamond” and “gemstone” ) . The word is mapped to that node , and the node is relabeled with the word if the latter has a higher TW - IDF score . ( iii ) there is a node which shares a common hypernym with the word ( e . g . , “red” , “blue” → “color” ) . If the product of the WordNet path distance similarities of the common hypernym with the node and the word exceeds a certain threshold , the word is mapped to that node and the node is relabeled with the hypernym . A completely new word might thus be introduced . We set its TW - IDF score as the highest TW - IDF of the two words it replaces . When multiple nodes are eligible for mapping , we select the one with greatest path distance similarity product . ( iv ) there is a node which is in an entailment relation with the word ( e . g . , “look” is entailed by “see” ) . The word is mapped to that node , and the node is relabeled with the word if the latter has a higher TW - IDF score . In attempts i , ii , and iv above , if there is more than one candidate node , we select the one with highest TW - IDF score . If all attempts above are unsuccessful , a new node is created for the word . B Baseline Details • Random . A basic baseline recommended by ( Riedhammer et al . , 2008 ) to ease cross - study compar - ison . This system randomly selects utterances without replacement from the transcription until the budget is violated . To account for stochasticity , we report scores averaged over 30 runs . • Longest Greedy . A basic baseline recommended by ( Riedhammer et al . , 2008 ) to ease cross - study comparison . The longest remaining utterance is selected at each step from the transcription until the summary size constraint is satisﬁed . • TextRank ( Mihalcea and Tarau , 2004 ) . Utterances within the transcription are represented as nodes in an undirected complete graph , and edge weights are assigned based on lexical similarity between utterances . To provide a summary , the top nodes according to the weighted PageRank algorithm ( Page et al . , 1999 ) are selected . We used a publicly available implementation 6 . • ClusterRank ( Garg et al . , 2009 ) . This system is an extension of TextRank to meeting summarization . Firstly , utterances are segmented into clusters . A complete graph is built from the clusters . Then , a score is assigned to each utterance based on both the PageRank score of the cluster it belongs to and its cosine similarity with the cluster centroid . In the end , a greedy selection strategy is applied to build the summary out of the highest scoring utterances . Since the authors did not make their code publicly available and were not able to share it privately , we wrote our own implementation . • CoreRank submodular & PageRank submodular ( Tixier et al . , 2017 ) . These two extractive base - lines implement the last step of our pipeline ( see Section 4 . 4 ) . That is , budgeted submodular maxi - mization is applied directly on the full list of utterances . As can be inferred from their names , the only difference between those two baselines is that the ﬁrst uses PageRank scores , whereas the second uses CoreRank scores . 6 https : / / github . com / summanlp / textrank • Oracle . This system is the same as the Random baseline , but instead of sampling utterances from the ASR transcription , it draws from the human extractive summaries . Annotators put those summaries together by selecting the best utterances from the entire manual transcription . Scores were averaged over 30 runs due to the randomness of the procedure . C Results for Manual Transcriptions 150 200 250 300 350 400 450 500 summarysize ( words ) 0 . 26 0 . 28 0 . 30 0 . 32 0 . 34 0 . 36 R O U G E - 1 F 1 - sc o r e AMI OURSYSTEMOURSYSTEM ( BASELINE ) OURSYSTEM ( KEYRANK ) OURSYSTEM ( FLUCOVRANK ) ORACLECORERANKSUBMODULARPAGERANKSUBMODULARTEXTRANKCLUSTERRANKLONGESTGREEDYRANDOM 150 200 250 300 350 400 450 500 summarysize ( words ) 0 . 22 0 . 24 0 . 26 0 . 28 0 . 30 0 . 32 0 . 34 ICSI OURSYSTEMOURSYSTEM ( BASELINE ) OURSYSTEM ( KEYRANK ) OURSYSTEM ( FLUCOVRANK ) ORACLECORERANKSUBMODULARPAGERANKSUBMODULARTEXTRANKCLUSTERRANKLONGESTGREEDYRANDOM Figure 8 : ROUGE - 1 F - 1 scores for various budgets ( manual transcriptions ) . AMI ROUGE - 1 AMI ROUGE - 2 AMI ROUGE - SU4 ICSI ROUGE - 1 ICSI ROUGE - 2 ICSI ROUGE - SU4 R P F - 1 R P F - 1 R P F - 1 R P F - 1 R P F - 1 R P F - 1 Our System 42 . 03 34 . 77 37 . 53 8 . 87 7 . 56 8 . 06 15 . 92 14 . 08 14 . 76 38 . 57 29 . 30 32 . 93 5 . 80 4 . 74 5 . 14 13 . 92 10 . 79 12 . 04 Our System ( Baseline ) 40 . 88 33 . 96 36 . 58 8 . 13 6 . 95 7 . 39 15 . 17 13 . 25 13 . 97 40 . 03 30 . 20 34 . 11 6 . 65 5 . 51 5 . 98 14 . 65 11 . 37 12 . 70 Our System ( KeyRank ) 40 . 87 33 . 91 36 . 56 8 . 42 7 . 12 7 . 62 15 . 50 13 . 48 14 . 25 39 . 55 29 . 79 33 . 68 6 . 32 5 . 19 5 . 64 14 . 63 10 . 99 12 . 47 Our System ( FluCovRank ) 41 . 73 34 . 50 37 . 27 8 . 45 7 . 05 7 . 60 16 . 08 13 . 47 14 . 49 38 . 57 29 . 21 32 . 95 6 . 38 5 . 08 5 . 60 14 . 38 10 . 62 12 . 13 Oracle 40 . 49 34 . 65 36 . 73 8 . 07 7 . 35 7 . 55 15 . 00 14 . 03 14 . 26 37 . 91 28 . 39 32 . 12 5 . 73 4 . 82 5 . 18 13 . 35 10 . 73 11 . 80 CoreRank Submodular 38 . 95 31 . 49 34 . 38 7 . 85 6 . 81 7 . 20 14 . 08 13 . 55 13 . 61 37 . 31 29 . 51 32 . 45 5 . 59 5 . 05 5 . 24 13 . 19 11 . 08 11 . 87 PageRank Submodular 40 . 58 32 . 87 35 . 86 9 . 20 7 . 77 8 . 32 15 . 59 14 . 14 14 . 64 37 . 72 28 . 86 32 . 35 6 . 35 5 . 46 5 . 82 13 . 35 11 . 60 12 . 30 TextRank 39 . 47 32 . 57 35 . 19 7 . 74 6 . 62 7 . 05 14 . 80 13 . 03 13 . 69 37 . 60 28 . 79 32 . 32 6 . 63 5 . 53 5 . 98 14 . 18 11 . 18 12 . 41 ClusterRank 38 . 32 31 . 51 34 . 10 6 . 93 5 . 95 6 . 31 13 . 69 12 . 40 12 . 84 35 . 66 26 . 58 30 . 14 4 . 53 3 . 99 4 . 21 12 . 10 9 . 71 10 . 69 Longest Greedy 36 . 73 30 . 39 32 . 78 5 . 52 4 . 58 4 . 93 13 . 52 10 . 91 11 . 93 37 . 15 28 . 21 31 . 76 5 . 50 4 . 60 4 . 98 13 . 59 10 . 03 11 . 46 Random 39 . 29 32 . 38 35 . 01 7 . 14 6 . 16 6 . 52 14 . 16 12 . 95 13 . 35 37 . 48 28 . 10 31 . 80 5 . 41 4 . 65 4 . 95 12 . 97 10 . 67 11 . 61 Table 3 : Macro - averaged results for 350 and 450 word summaries ( manual transcriptions ) . D Example Summaries Examples were generated from the manual transcriptions of meeting AMI TS3003c . Note that our system can also be interactively tested at http : / / datascience . open - paas . org / abs _ summ _ app . Reference Summary ( 254 words ) The project manager opened the meeting and recapped the decisions made in the previous meeting . The marketing expert discussed his personal preferences for the design of the remote and presented the results of trend - watching reports , which indicated that there is a need for products which are fancy , innovative , easy to use , in dark colors , in recognizable shapes , and in a familiar material like wood . The user interface designer discussed the option to include speech recognition and which functions to include on the remote . The industrial designer discussed which options he preferred for the remote in terms of energy sources , casing , case supplements , buttons , and chips . The team then discussed and made decisions regarding energy sources , speech recognition , LCD screens , chips , case materials and colors , case shape and orientation , and button orientation . The team members will look at the corporate website . The user interface designer will continue with what he has been working on . The industrial designer and user interface designer will work together . The remote will have a docking station . The remote will use a conventional battery and a docking station which recharges the battery . The remote will use an advanced chip . The remote will have changeable case covers . The case covers will be available in wood or plastic . The case will be single curved . Whether to use kinetic energy or a conventional battery with a docking station which recharges the remote . Whether to implement an LCD screen on the remote . Choosing between an LCD screen or speech recognition . Using wood for the case . Our System ( 250 words ) attract elderly people can use the remote control changing channels button on the right side that would certainly yield great options for the design of the remote personally i dont think that older people like to shake your remote control imagine that the remote control and the docking station remote control have to lay in your hand and right hand users ﬁnding an attractive way to control the remote control casing the manufacturing department can deliver a ﬂat casing single or double curved casing top of that the lcd screen would help in making the remote control easier increase the price for which were selling our remote control remote controls are using a onoff button still on the top apply remote control on which you can apply different case covers button on your docking station which you can push and then it starts beeping surveys have indicated that especially wood is the material for older people mobile phones so like the nokia mobile phones when you can change the case greyblack colour for people prefer dark colours brings us to the discussion about our concepts docking station and small screen would be our main points of interest industrial designer and user interface designer are going to work innovativeness was about half of half as important as the fancy design efﬁcient and cheaper to put it in the docking station case supplement and the buttons it really depends on the designer start by choosing a case deployed some trendwatchers to milan Our System ( Baseline ) ( 250 words ) apply remote controls on which you can apply different case for his remote control changing channels and changing volume button on both sides that would certainly yield great op - tions for the design of the remote personally i dont think that older people like to shake their remote control ﬁnding an attractive way to control the remote control the i found some something about speech recognitionimaginethat the remote control and the docking station should be telephoneshaped casing the manufacturing department can deliver a ﬂat casing single or double curved casing remote control have to lay in your hand and right hand users remote controls are using a onoff button over in this corner woodlike for the more exclusive people can use the remote control heard our industrial designer talk about ﬂat single curved and double curved innovativeness this means functions which are not featured in other remote control button on your docking station which you can push and then it starts beeping greyblack colour for people prefer dark colours docking station and small screen would be our main points of interest special button for subtitles for people which c f who cant read small subtitles pretty big inﬂuence on production price and image unless we would start two product lines surveys have indicated that especially wood is the material for older people mobile phones so like the nokia mobile phones when you can change the case case the supplement and the buttons it really depends on the designer buttons Our System ( KeyRank ) ( 250 words ) changing case covers prefer a design where the remote control and the docking station greyblack colour for people prefer dark colours remote controls are using a onoff button over in this corner requirements are teletext docking station and small screen with some extras that button information apply remote controls on which you can apply different case covers woodlike for the more exclusive people can use the remote control casing the manufacturing department can deliver a ﬂat casing single or double curved casing remote control have to lay in your hand and right hand users asked if w they would if people would pay more for speech recognition function would not make the remote control start by choosing a case innovativeness this means functions which are not featured in other remote controls top of that the lcd screen would help in making the remote control easier changing channels and changing volume button on both sides that would certainly yield great op - tions for the design of the remote personally i dont think that older remotes are ﬂat board smartboard button on your docking station which you can push and then it starts beeping case supplement and the buttons it really depends on the designer surveys have indicated that especially wood is the material for older people will recognise the button speak speech recognition and a special button for subtitles for people which c f who cant read small subtitlesinnovativeness was about half as important as the fancy design pretty big inﬂuence Our System ( FluCovRank ) ( 250 words ) elderly people can use the remote control remote controls are using a onoff button still on the top general idea of the concepts and the material for older people like to shake your remote control docking station and small screen would be our main points of interest industrial designer and user interface designer are going to work casing the manufacturing department can deliver single curved changing channels and changing volume button on both side that would certainly yield great options for the design of the remote button on your docking station which you can push and then it starts beeping imagine that the remote control will be standing up straight in the docking station will help them give the remote asked if w they would if people would pay more for speech recognition in a remote control you can call it and it gives an sig signal research about bi large lcd sh display for for displaying the the functions of the buttons case the supplement and the buttons it really depends on the designer pointed out earlier that a lot of remotes rsi innovativeness was about half of half as important as the fancy design push on the button for subtitles for people which c f who cant read small subtitles efﬁcient and cheaper to put it in the docking station could be one of the marketing issues difﬁcult to handle and to get in the right shape to older people talk about the energy source is rather fancy