IdeaBits : Tangible Design Tool to Aid Idea Generation for Tangible User Interface Input Actions by Uddipana Baishya B . Des . , Indian Institute of Technology Guwahati , 2016 Thesis Submitted in Partial Fulfillment of the Requirements for the Degree of Master of Science in the School of Interactive Arts and Technology Faculty of Communication , Art and Technology © Uddipana Baishya 2020 SIMON FRASER UNIVERSITY Summer 2020 Copyright in this work rests with the author . Please ensure that any reproduction or re - use is done in accordance with the relevant national copyright legislation . ii Approval Name : Uddipana Baishya Degree : Master of Science Title : IdeaBits : Tangible Design Tool to Aid Idea Generation for Tangible User Interface Input Actions Examining Committee : Chair : Kate Hennessy Associate Professor Alissa N . Antle Supervisor Professor Carman Neustaedter Committee Member Professor Halil Erhan Examiner Associate Professor Date Defended / Approved : June 2 , 2020 iii Ethics Statement iv Abstract Novice tangible interaction design students often find it challenging to generate input action ideas for tangible user interfaces . There is no design tool to facilitate such idea generation . To address this gap , I designed and developed IdeaBits as an exploratory research instrument . IdeaBits consists of interactive physical artifacts coupled with digital examples of tangible systems and technical implementation guidance . I investigated how novice students use IdeaBits to generate tangible user interface ideas , how it supports them , and what challenges they face . I conducted an exploratory case study involving video recorded design sessions , remote observations , and semi - structured interviews with twelve students individually . The findings show that IdeaBits helped in generating input action ideas by enabling to experience the input actions , encouraging and facilitating hands - on explorations , and introducing possibilities . However , it fell short in supporting the technical implementation planning of the generated ideas . Also , introducing examples at times caused design fixation . Keywords : Tangible user interfaces ; tangible interaction design ; input actions for tangible user interfaces ; idea generation ; tangible design tool ACM Classification Keywords : H . 5 . 2 . Information interfaces and presentation : User Interfaces . v Dedication I dedicate this thesis to my maternal grandfather ( Late Hargobinda Baishya 1928 - 2020 ) who said goodbye while waiting for me to finish this thesis , to my parents ( Kalpana Baishya and Durga Mohan Baishya ) who have been there with me through every step in this journey , my brother ( Shiv Sankar Baishya ) who has always been there to encourage me to keep moving forward , and my pet bird ( Pickachu ) who has been my emotional support when I needed it the most . vi Acknowledgments I would like to thank my senior supervisor , Dr . Alissa N . Antle , for her guidance , support , and being patient throughout this journey . She supported me more than just as a supervisor and had faith in me even during the downs of the journey . I got to learn an incredible amount from her brilliance . I feel privileged to get the opportunity to work with her as her student . The excellence she demonstrates in her work has always inspired me to be meticulous and keep pushing myself to improve . I would also like to thank her for partially funding the project through the Social Sciences and Humanities Research Council of Canada . I would like to thank my supervisor , Dr . Carman Neustaedter , for his guidance , and feedback . The clarity of his critiques , which he accompanies with appreciations and suggested ways of improvising , makes learning enjoyable . This approach of his , among other admirable qualities , motivated me as his Mitacs Globalink research intern to return to the School of Interactive Arts and Technology ( SIAT ) as a Master ' s student . I am very grateful to him for believing in me , appreciating my efforts , and encouraging me to join SIAT . I would like to thank Dr . Halil Erhan , my external examiner , for sharing his vast knowledge of and expertise in design tools . I would like to thank those with whom I collaborated at different points during this project - Pankaj Kumar , Ofir Sadka , Dr . Thecla Schiphorst , Shiv Sankar Baishya , Elgin - Skye Mclaren , Dr . Victor Cheung , Boxiao Gong , Dr . Diane Gromala , Matin Lotfaliee , and Bhairavi Warke . I would like to thank the instructors at SIAT , who supported me in recruiting participants for my study . I am especially grateful to the SIAT students who participated in my study , without whom this project could never be completed . I would like to send special thanks to both my parents , Kalpana Baishya and Durga Mohan Baishya , who helped me in numerous ways throughout this journey . I would also like to thank my father for proofreading this thesis . Last but not least , I would like to send love and thanks to my friends for being there for me . vii Table of Contents Approval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ii Ethics Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iv Dedication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi Table of Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi List of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiv Chapter 1 . Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Chapter 2 . Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2 . 1 . Tangible User Interfaces and Physical Tools to Aid Idea Generation in Non - Tangible Interaction Design Domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2 . 2 . Design Tools for Tangible Interaction Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2 . 3 . Role of Examples in Idea Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 Chapter 3 . IdeaBits System Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3 . 1 . Idea Bits : A Tangible Design Tool to Aid Idea Generation for Tangible Manipulation . 14 3 . 1 . 1 . Design Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 3 . 1 . 2 . Design Rationale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 Interactive Physical Artifacts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Examples of Tangible Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Technical Implementation Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3 . 2 . IdeaBits Design Revisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3 . 2 . 1 . Hardware Revisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3 . 2 . 2 . Instruction Revisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3 . 2 . 3 . Graphical User Interface Revisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 3 . 2 . 4 . Code Revisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3 . 3 . Comparison of the Design Process with Other Methodologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 3 . 3 . 1 . Research Through Design Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 3 . 3 . 2 . User - Centered Design Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Chapter 4 . User Study Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 4 . 1 . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 4 . 2 . Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 4 . 2 . 1 . Recruiting Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 4 . 2 . 2 . Screening Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 4 . 3 . Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 4 . 4 . Research Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 viii 4 . 4 . 1 . Changes from Pilot Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 4 . 5 . Procedure and Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 4 . 5 . 1 . Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 4 . 5 . 2 . Design Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Rationales for the Design Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 4 . 5 . 3 . Changes from Pilot Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 4 . 6 . Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4 . 6 . 1 . RQ2 . Tool Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4 . 6 . 2 . RQ3 . Support for Generating Tangible User Interface Ideas . . . . . . . . . . . . . . . . . . . . . . . . 50 4 . 6 . 3 . RQ4 . Challenges of Using the Tool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 4 . 7 . Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 Chapter 5 . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 5 . 1 . Analysis of the Deliverables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 5 . 2 . Analysis of the Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 5 . 2 . 1 . Incorporating IdeaBits in the Design Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 Preferences Among Artifacts and Example Formats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5 . 2 . 2 . Hands - on Interaction with IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 Prototyping and Testing Ideas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 5 . 2 . 3 . Making Design Decisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 5 . 2 . 4 . IdeaBits Introducing Possibilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5 . 2 . 5 . IdeaBits Causing Design Fixation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 IdeaBits Inspired Similar Ideas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 Trying to Incorporate from IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 Disconfirming evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 5 . 2 . 6 . Challenges in Using IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 5 . 2 . 7 . Challenges in Doing the Design Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 Chapter 6 . Discussion and Design Implications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 6 . 1 . Experiencing Input Actions First - Hand . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 6 . 1 . 1 . Sensor Enabled Artifacts as the Graphical User Interface Controllers . . . . . . . . . 91 6 . 2 . Encouraging and Facilitating Hands - on Exploration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 6 . 2 . 1 . Minimizing Technical Malfunctioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 6 . 3 . Facilitating Prototyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 6 . 4 . Inspirational Examples Versus Design Fixation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 6 . 5 . Technical Implementation Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 6 . 6 . Generalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 6 . 7 . Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 6 . 7 . 1 . Process Followed to Design IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6 . 7 . 2 . User Study to Evaluate IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 6 . 8 . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 Chapter 7 . Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 ix Appendix A . Demographic Questionnaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 Appendix B . Recruiting Poster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 Appendix C . Recruiting Flyer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 Appendix D . Signup Sheet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 Appendix E . Screening Questionnaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138 Appendix F . Problem Statement Sheets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140 Appendix G . Stationery and Modeling Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143 Appendix H . Overview Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 Appendix I . Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 Appendix J . Interview Questionnaire for Evaluation of IdeaBits . . . . . . . . . . . . . . . . . . . . . . 151 Appendix K . Deliverables from the User Study Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 Amy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 Ben . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157 Eva . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 Jane . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165 Kate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 Lee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173 Maya . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177 Neil . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 Paul . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184 Ross . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187 Ted . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 Uma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 Appendix L . Interview Questionnaire for Designing IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . 201 Appendix M . Illustration Cards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203 x List of Tables Table 4 . 1 Alignment table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 Table 5 . 1 Types of input actions in participants’ final ideas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 Table 5 . 2 Summary table for the theme “Incorporating IdeaBits in the Design Process” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 Table 5 . 3 Summary table for the subtheme “Preferences Among Artifacts and Example Formats” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 Table 5 . 4 Summary table for the theme “Hands - on Interaction with IdeaBits” . . . . . . . . 62 Table 5 . 5 Summary table for the subtheme “Prototyping and Testing Ideas” . . . . . . . . . 64 Table 5 . 6 Summary table for the theme “Making Design Decisions” . . . . . . . . . . . . . . . . . . . . . . 66 Table 5 . 7 Summary table for the theme “IdeaBits Introducing Possibilities” . . . . . . . . . . . 69 Table 5 . 8 Summary table for the subtheme “IdeaBits Inspired Similar Ideas” . . . . . . . . . 73 Table 5 . 9 Summary table for the subtheme “Trying to Incorporate from IdeaBits” . . 76 Table 5 . 10 Summary table for the subtheme “Disconfirming evidence” . . . . . . . . . . . . . . . . . . . . 78 Table 5 . 11 Summary table for the theme “Challenges in Using IdeaBits” . . . . . . . . . . . . . . . . . 80 Table 5 . 12 Summary table for the theme “Challenges in Doing the Design Task” . . . . 85 Table 6 . 1 Summary table for “Experiencing Input Actions First - Hand” . . . . . . . . . . . . . . . . . . . 89 Table 6 . 2 Summary table for “Sensor Enabled Artifacts as the Graphical User Interface Controllers” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 Table 6 . 3 Summary table for “Encouraging and Facilitating Hands - on Exploration” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 Table 6 . 4 Summary table for “Minimizing Technical Malfunctioning” . . . . . . . . . . . . . . . . . . . . . . 96 Table 6 . 5 Summary table for “Facilitating Prototyping” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 Table 6 . 6 Summary table for “Inspirational Examples Versus Design Fixation” . . . . 100 Table 6 . 7 Summary table for “Technical Implementation Guidance” . . . . . . . . . . . . . . . . . . . . 104 xi List of Figures Figure 2 . 1 TalkingCards designed by Regal et al . [ 78 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Figure 2 . 2 Blue Studio designed by Jaasma et al . [ 49 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Figure 2 . 3 Ideating in Skills toolset designed by Smit et al . [ 90 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Figure 2 . 4 Engagement Catalysers - LeMiMi ( left ) and We feel like talking ( right ) from Trotto et al . [ 97 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Figure 2 . 5 Intuito designed by Analytis et al . [ 3 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 Figure 2 . 6 Bloctopus designed by Sadler et al . [ 82 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 Figure 2 . 7 littleBits designed by Bdeir [ 12 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 Figure 3 . 1 Design process timeline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Figure 3 . 2 IdeaBits prototype . The TUI example shown on the laptop is TwistBlocks [ 105 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 Figure 3 . 3 Artifacts of IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Figure 3 . 4 Accessing the video instruction on an example page in the GUI of IdeaBits that demonstrate how to interact with the bend sensor - enabled artifact . The TUI example on the left screen is TwistBlocks [ 105 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Figure 3 . 5 Home page of the GUI of IdeaBits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 Figure 3 . 6 Example page in the GUI of IdeaBits showing TUI examples that involve bend as an input action ( TwistBlocks [ 105 ] and Bosu [ 66 ] ) . . . . . . . . . . . . . . . . . . . . . 23 Figure 3 . 7 Revision of breadboard from solderless ( left ) to solderable ( right ) . a ) Pin headers of jumper wires . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 Figure 3 . 8 Attached longer and softer wires to sensor - enabled artifacts . . . . . . . . . . . . . . . . . . 26 Figure 3 . 9 Damaged flex sensor in bend sensor - enabled artifact ( left ) . Use of plastic sheets to prevent further damage ( right ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Figure 3 . 10 Revisions of artifacts . ‘Old’ refers to the first iteration while ‘new’ refers to the second iteration of IdeaBits prototype . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 Figure 3 . 11 Front and back sides of the illustration card for stretch input action . . . . . . . . 28 Figure 3 . 12 Accessing the video instruction on the home page of the GUI of IdeaBits demonstrating how to interact with the bend sensor - enabled artifact . . . . . . 30 Figure 3 . 13 Paper format of TUI examples ( TwistBlocks [ 105 ] and Ninja Track [ 53 ] ) . 31 Figure 3 . 14 Revised video player for video format of the TUI examples ( TwistBlocks [ 105 ] and Ninja Track [ 53 ] ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Figure 3 . 15 Revised example page for displaying images of the TUI examples ( RopePlus [ 109 ] and Memento [ 64 ] ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Figure 4 . 1 Two views of the room where I conducted the user study . . . . . . . . . . . . . . . . . . . . . . 39 Figure 4 . 2 The room from where I did remote observation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Figure 4 . 3 The table ( table A ) with IdeaBits and the connected personal computer . 41 Figure 4 . 4 The table ( table B ) with a ) physical - only artifacts , b ) Illustration cards , c ) overview map , d ) problem statement sheets , e ) stationeries , and f ) modeling materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 Figure 4 . 5 Camcorder set up on the ceiling using a phone holder . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 xii Figure 5 . 1 StretchEBand [ 104 ] ( left ) and Maya’s final idea of a smartwatch ( right ) . . 74 Figure 5 . 2 Eva’s drawing illustrating the squeeze input action in her final idea ( left ) , prescribed way of interacting with the squeeze sensor - enabled artifact ( right ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 Figure 5 . 3 Stretch sensor - enabled artifact . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 Figure 5 . 4 Bend sensor - enabled artifact . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Figure 5 . 5 Pull input action in RopePlus [ 109 ] ( above ) and pull sensor - enabled artifact ( bottom ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 xiii List of Acronyms GUI Graphical user interface HCI Human - computer interaction RQ Research question RtD Research through design SFU Simon Fraser University SIAT School of Interactive Arts and Technology TECI lab Tangible , Embodied , Child Interaction lab TIxD Tangible interaction design TUI Tangible user interface UCD User - Centered Design UX User experience xiv Glossary Design fixation Blind adherence in the design process to a limited set of ideas [ 50 ] . Idea A fundamental element of thought that can be either visual , concrete , or abstract [ 51 ] . Idea generation An essential part of the design process involving the production , development , and communication of ideas [ 51 ] . Input action Manipulation of the artifacts in tangible user interfaces through physical movement [ 44 ] . Inspiration The process of evoking creative solutions with the help of an entity [ 28 ] . Semi - structured interviews Interviews consisting of a set of predetermined open ‐ ended questions , where additional questions emerge based on the dialogue between interviewee ( s ) and interviewer [ 22 ] . Tangible interaction design Field of design dealing with the design of computationally mediated interactive systems involving tangible user interfaces [ 100 ] . Tangible user interface Interfaces which give physical form to digital information , employing physical artifacts both as representations and controls for computational media [ 100 ] . 1 Chapter 1 . Introduction Tangible interaction design ( TIxD ) involves designing computationally mediated interactive systems involving tangible user interfaces ( TUIs ) [ 100 ] . TUIs are interfaces which “give physical form to digital information , employing physical artifacts both as representations and controls for computational media” [ 100 ] . Physical actions , in the form of input actions , can be performed on these artifacts [ 44 ] . Research that emphasizes the benefits of TUIs exists in a wide range of domains such as education [ 7 , 8 ] , music [ 6 , 11 ] , health [ 5 ] , and sports [ 48 ] . Through a literature review , I found that a few input actions ( touch , button press , translate ) are frequently incorporated in TUIs while others ( stretch , pull , squeeze ) are rarely incorporated . I wonder whether many potential input actions are not incorporated into most TUI designs . Moreover , when generating ideas for TUIs , novice TIxD students ( students learning tangible interaction design for the first time and with no prior experience in similar domains that involve embodied interactions , such as gestural interfaces and virtual reality ) often find it challenging to generate input action ideas . They restrict their explorations to familiar possibilities such as input actions usually found in everyday devices ( Professor Alissa N . Antle , personal communication , February 6 , 2018 ) . This may lead them to potentially ignore the input actions that may address their design problem better . Considering a wide range of input actions may be beneficial for idea generation of TUIs . There exist TUIs and physical tools to aid idea generation in non - TIxD domains [ 38 , 49 , 90 ] as well as certain TIxD aspects such as application of framework [ 42 ] , conceptualization of transformation [ 65 , 66 ] , and prototyping [ 2 , 82 ] . However , little has been done to support input action idea generation . There are only a few design guidelines for designing input actions for TUIs . To my knowledge , there is no design tool , tangible or otherwise , to aid idea generation of input actions for TUIs . In this thesis , I present IdeaBits , a tangible design tool to aid novice TIxD students ( called users henceforth ) to generate input action ideas for TUIs . I designed and developed IdeaBits as a research instrument with the intent of producing knowledge for the research and practice communities through designing and evaluating the tool along 2 with the tool itself embodying theory and technical opportunities . The focus was to design an exploratory research medium that can be evaluated to identify ways in which potential support can be provided to novice TIxD students for generating input action ideas along with things that should be looked out for or avoided . IdeaBits consists of interactive physical artifacts coupled with digital examples of TUIs and technical implementation guidance . Through an exploratory case study consisting of video recorded design sessions , remote observations , and qualitative semi - structured interviews , I investigated four research questions ( RQs ) : 1 . What are the key design features of a design tool to aid novice TIxD students to generate input action ideas for TUIs ? 2 . In what ways do users use IdeaBits to generate ideas for TUIs ? 3 . In what ways do users think IdeaBits supports them to generate ideas for TUIs ? 1 . In what ways do users think IdeaBits supports them to generate ideas for input actions ? 2 . In what ways do users think IdeaBits supports them in planning the technical implementation of the generated ideas ? 4 . What challenges and limitations do users face while using IdeaBits to generate ideas for TUIs ? RQ1 is for designing of IdeaBits while RQ2 , RQ3 , and RQ4 are for evaluating IdeaBits . In this thesis , my contributions are : 1 ) designed an open - sourced a tool to aid novice TIxD students in generating TUI input action ideas , IdeaBits , as an exploratory research instrument [ 99 ] , 2 ) made a catalog of artifact mediated input actions for TUIs which involve interaction through hands [ 9 ] , 3 ) designed and conducted a case study to explore the use of IdeaBits with novice TIxD students , and 4 ) derived a set of design recommendations based on the findings of my study and existing literature for designing tools to aid novice TIxD students to generate input action ideas . This research will be useful to TIxD students , instructors , practitioners , and researchers , and perhaps also to researchers and designers working in similar domains such as product design or architecture . This thesis contains seven chapters . In Chapter 1 : Introduction , I briefly outlined the background of the research , the RQs , methods used to explore the RQs , and contributions of my work . In Chapter 2 : Background , I provide a literature review of TUIs 3 and physical tools to aid idea generation in non - TIxD domains , design tools for TIxD , and studies investigating the role of examples in idea generation . In Chapter 3 : IdeaBits System Design , I present IdeaBits , including the goals , design requirements , design process , key features , iterations , and system implementation . In Chapter 4 : User Study Methodology , I describe the case study methodology I used to explore the usage of IdeaBits , including participant recruitment and screening , setting , research materials , procedure , task , data collection , and data analysis . In Chapter 5 : Results , I discuss the results obtained from the analysis of the case study , including the themes that emerged from the analysis of the interviews . In Chapter 6 : Discussion and Design Implications , I discuss the findings of the study from chapter 5 by comparing and contrasting existing literature . I also discuss the design implications of these findings , generalizability , limitations , and future work . In Chapter 7 : Conclusions , I summarise the thesis by providing a brief overview of its background , results of the case study , design recommendations , contributions , limitations , and future work . 4 Chapter 2 . Background In this section , I summarize literature related to 1 ) Tangible user interfaces and physical tools to aid idea generation in non - tangible interaction design domains , 2 ) Design tools for tangible interaction design , and 3 ) Role of examples in idea generation . 2 . 1 . Tangible User Interfaces and Physical Tools to Aid Idea Generation in Non - Tangible Interaction Design Domains There exist TUIs and physical tools such as cards to aid idea generation . A detailed review of such tools can be found in [ 32 , 70 , 107 ] . Frich et al . [ 32 ] reviewed both digital and physical tools to support creativity in human - computer interaction ( HCI ) domain , Peters et al . [ 70 ] focused on analog tools for collaborative idea generation , and Wölfel et al . [ 107 ] focused on card - based design tools . These idea generation tools , however , have not been explored with a focus on generating TUI ideas ( exceptions discussed in the next section ) . I shall now discuss some of these tools , starting with cards and then interactive physical objects . Golembweski et al . [ 38 ] developed Ideation Decks , a project - specific deck of cards for design practitioners to aid idea generation based on parallel design . The deck of cards , involving salient concepts of the project domain and their examples , is creatively created by the users . Following specific rules , the cards are arranged in a grid followed by the selection of combinations to be used to generate ideas . From an evaluation , they found that the physical nature of the cards afforded ‘constructive cheating’ by allowing users to rearrange the cards to work outside established rules . Another card - based idea generation tool was designed by Lucero et al . [ 58 ] . They created a set of cards , PLEX Cards , as a source of inspiration to designers and stakeholders designing for playfulness . It communicates the 22 categories of a playful experience framework developed by Korhonen et al . [ 57 ] . The users use the deck in pairs by drawing a card from the deck and using it to generate as many ideas as they can . When they are unable to come up with any new ideas , they draw the next card . The authors also proposed two idea generation techniques involving the cards - PLEX Brainstorming ( rapid 5 generation of many ideas ) and PLEX Scenario ( generation of complete and quality ideas in a short time ) . From an evaluation , the authors found that the cards inspired the users , and coupling with the techniques helped users to generate many ideas in a short time . The cards also helped in the analysis of the problem statement and evaluation of the ideas generated . Figure 2 . 1 TalkingCards designed by Regal et al . [ 78 ] . Regal et al . [ 78 ] added a digital component to physical - only cards for idea generation . They designed a tool , TalkingCards ( Figure 2 . 1 ) , that augment human memory to support blind and visually impaired users in brainstorming sessions and co - design workshops . Their objective was to create a tool that mimicked sticky notes used during brainstorming sessions by people with no visual impairments . TalkingCards involves a smartphone application and near field communication ( NFC ) cards . The cards were enhanced with an additional tactile layer by using certain tactile materials ( sandpaper , bubble wrap , etc . ) to facilitate distinguishing between the cards . The application enables users to write ideas on the NFC cards using voice recording or speech recognition . The application also reads the text stored on the cards out loud using text to speech synthesis . From an evaluation , they found that users found the tool fun , easy to use , and helpful in the spatial arrangement of information and organizing ideas . The additional tactile layer was found to be unnecessary for simple tasks that did not involve complex information or frequent reading out and ( re - ) clustering of the cards . Ihamäki et al . [ 47 ] utilized flat cardboards to construct a basic three - dimensional form . They designed a playful ideation tool , Comicubes , involving blank cardboard cutouts that could be formed into cubes . Using art supplies , the users can create text , images , etc . on the blank surfaces of the cubes . Later Heljakka et al . [ 40 ] studied how young children used Comicubes to co - design ideas for object - based play . They found that interaction with 6 the tool facilitated a playful co - creation situation . The tool helped the children to identify play patterns ( throwing , stacking , rolling , etc . ) for the physical playthings they created . Figure 2 . 2 Blue Studio designed by Jaasma et al . [ 49 ] . Other researchers designed interactive physical objects for facilitating group idea generation sessions ( e . g . [ 49 , 90 , 97 ] ) . For example , Jaasma et al . [ 49 ] designed Blue Studio ( Figure 2 . 2 ) , an interactive space for embodied multi - stakeholder ideation processes . The objective was to counterbalance rational decision making processes through an unfamiliar environment that encouraged participants to use embodied senses . It involved interactive elements , such as magnetic switches , integrated into the room . Using a set of physical objects designed to boost imagination , Embodied Ideation Toolkit ( EIT ) , one could explore the interactive elements and build giant structures . From an evaluation of the system , the authors found that EIT acted as ‘scaffolds’ for ideation . Building with the EIT objects allowed participants to physically create ‘traces’ that they could refer back to throughout the ideation session . The ‘ready - at - hand’ interaction possibilities supported the participants by acting as an extension of the body , unless obstructed by technical malfunctions . Figure 2 . 3 Ideating in Skills toolset designed by Smit et al . [ 90 ] . 7 Smit et al . [ 90 ] ( Figure 2 . 3 ) designed a diverse set of physically interactive objects , Ideating in Skills toolset , to support multi - stakeholder idea generation sessions . The authors’ objective was to support design conversation between different stakeholders by creating a shared language based on embodiment . From an evaluation , they found that the objects stimulated curiosity and triggered physical exploration . The ambiguity and unfamiliarity of the objects triggered users’ imagination . The objects also enabled fidgeting and playful interaction while facilitating the starting of conversations . Figure 2 . 4 Engagement Catalysers - LeMiMi ( left ) and We feel like talking ( right ) from Trotto et al . [ 97 ] . Trotto et al . [ 97 ] studied the creative technique called Engagement Catalysers [ 96 ] through creative tools ( Figure 2 . 4 ) . The technique utilizes embodiment and skillful coping to facilitate collaborative multidisciplinary design processes , such as brainstorming . It enhances engagement along with enhancing connection , empathy , and respect among people with different backgrounds . A total of six engagement catalyzers ( creative tools ) were developed by Industrial design master’s students as a part of a design class carried out by the authors . 1 ) We feel like talking ( Figure 2 . 4 right ) – “A wall , on which on both sides , people interact through magnetic fingertip - caps , ” 2 ) LeMiMi ( Figure 2 . 4 left ) – “The membranes of a disk get tensed by interacting with surrounding levers , ” 3 ) Diskill – “Vertical elastic bands with two pillows fixed at different heights that produce sound when moved , ” 4 ) Unpredictable stick – “A wooden stick , placed on a semi - spherical base in which a weight moves randomly , ” 5 ) Fantastic Elastic – “A piece of elastic cloth suspended by a set of elastic bands , on which a ball can be placed , ” and 6 ) Don’t move ! – “A set of stools , whose rotation is connected . ” From evaluations of these six tools , the authors found that these tools stimulated engagement , facilitated people to connect in a short time , and acted as an inspiration during the design process . Unpredictable reactions of the tools when being interacted with ( e . g . , movement of the pillows in Diskill generating audio 8 feedback ) encouraged users to explore the interaction possibilities of the tool for a longer duration . Open - ended and undefined interaction possibilities and the absence of rigid boundaries ( spatial , functional , formal ) of the tools ( e . g . , Fantastic Elastic ) encouraged more creative exploration and engaged people for a longer time . Having a precise aim associated with the tool led to reduced attention to the interaction possibilities and resulting output . The interaction qualities that the catalyzers were designed to elicit were found in the final designs of the participants . Hence TUIs and physical tools have been found to aid idea generation in various contexts . Although the usage of the tools discussed above was not TIxD focused , most of them seem to be extendable to TUI idea generation , which can be explored in future work . In this thesis , I focused on designing a tangible tool specifically to support novice TIxD students in generating input action ideas for TUIs . 2 . 2 . Design Tools for Tangible Interaction Design There exist TUIs and physical tools to aid with certain TIxD aspects such as application of framework [ 42 ] , conceptualization of transformation [ 65 , 66 ] , and prototyping [ 2 , 82 ] . However , there is no tool to support the generation of input action ideas . Hornecker [ 42 ] designed a brainstorming card game to aid designers in the application of a Tangible Interaction Framework [ 44 ] . The author stated that frameworks being prescriptive , inflexible , and abstract are hard to use in creative practice . She transformed the framework concepts into provocative questions and printed each of these on a card to inspire discussions . From an evaluation , she found that the physical aspect of the cards supported spatial interaction , legibility of action , and performative behavior . The cards acted as a form of embodied facilitation and provided physical focus with a low entry threshold . Other researchers have designed tools to support the conceptualization of transformation in actuated products ( e . g . , [ 65 , 66 ] ) . For example , Parkes et al . developed two tangible systems , Kinetic Sketchup [ 65 ] and Bosu [ 66 ] , to aid visualization , imagination , and design of transformation in actuated products . These are motion prototyping tools involving physically programmable actuated modules with kinetic memory . From an evaluation of one of the modules of Kinetic Sketchup , they found that 9 mechanical and behavioral simplicity enabled envisioning transition . The ability to limit mechanical complexity by isolating elements helped in focusing on behavioral and motion choreograph parameters . From an evaluation of Bosu , they found that working in the physical realm helped motion design novices to understand the physical world while challenging assumptions related to kinetic behavior . The ability to experiment with a wide range of materiality and motion qualities acted as inspiration for creating diversity within motion design ideas . Research on TUI development suggests the importance of iterative and rapid prototyping , along with early user testing to obtain the correct mapping of physical interactions to digital behavior [ 43 ] . In turn , other researchers have designed tools to facilitate prototyping TUIs ( e . g . [ 2 , 3 , 12 , 82 ] ) . For example , Alhabri et al . [ 2 ] designed Intuito , a tangible system for programming sensors and actuators through the “programming by demonstration” technique . It intends to aid opportunistic programmers in translating ideas into code without borrowing code from online sources . It produces editable text - based code from the actions the users demonstrate on the sensors and actuators . By eliminating attention requirement for language syntax , they intend to enable users to focus on the triggers and actions of the interaction . Figure 2 . 5 Intuito designed by Analytis et al . [ 3 ] . Analytis et al . [ 3 ] developed a creative design activity , P . bot activity ( Figure 2 . 5 ) , involving making interactive paper robots . Their objective was to increase engineering students’ confidence and skills in prototyping using microcontrollers and encourage creative exploration . The activity is designed for the later stage of the design process , where students narrow down their ideas for a final prototype . The paper robots are 10 designed for naïve human users by using everyday materials such as cardboard along with electronic components such as sensors and Arduino . The users to build the robots using sensors to detect input ( e . g . , a flex sensor to detect forward bending of the neck ) and provide an output ( e . g . , the robot dances by turning in a circle with the help of a DC gear motor ) . The input - output mapping is based on an underlying message or meaning associated with the input ( e . g . , excited associated with bending of the neck ) . From an evaluation , the authors found that the P . bot activity helped 76 % of the students to increase their knowledge in programming microcontrollers and 69 % of the students to increase their knowledge in using raw electronic components to build circuits . Before going through the P . bot activity , the students had low confidence in prototyping using microcontrollers . The P . bot activity helped increase the average confidence of the students in electronic prototyping . Figure 2 . 6 Bloctopus designed by Sadler et al . [ 82 ] . Sadler et al . [ 82 ] designed Bloctopus ( Figure 2 . 6 ) , a modular electronic prototyping toolkit that reduces the requirement of making circuits and programming . It is intended to aid novices with rapid prototyping through direct electrical interfacing over USB , and physical interfacing with LEGO blocks . They found from an evaluation that flexibility of the hardware , resulting from the use of LEGO blocks as a low - resolution material , enabled the users to explore diverse forms within a short time frame . The ability to swap different modules inspired ideas and encouraged exploration of a range of input interactions . The reduced requirement of paying attention to technical details allowed users to focus on high - level interactions . 11 Figure 2 . 7 littleBits designed by Bdeir [ 12 ] . Bdeir [ 12 ] designed littleBits ( Figure 2 . 7 ) , an opensource library of electronic components pre - assembled in small circuit boards , which can be snapped together to build prototypes easily . The author’s objective was to enable artists , makers , and designers who are not trained in electronic prototyping to build prototypes , as well as to enable prototyping in the early stages of the design process . The author found from an evaluation that participants , who were otherwise skeptical of their electronic prototyping skills , were comfortable in prototyping using littleBits . 2 . 3 . Role of Examples in Idea Generation Idea generation usually involves inspiration , which is defined in the context of design as the process of evoking creative solutions with the help of any entity [ 28 ] . One of the ways to provide inspiration is through examples . However , other researchers have found both positive [ 16 , 17 , 37 , 41 , 98 ] and negative [ 16 , 41 , 50 , 76 , 98 ] impact of examples in the idea generation process . For example , Casakin [ 17 ] studied the role of visual examples with architectural designers having different levels of expertise when solving ill - defined and well - defined design problems . The author’s goal was to determine whether participants can establish an analogical relationship between the provided examples and the problem at hand when they are not given specific instructions to use an analogy . The author found that both experts and novices benefitted from the use of visual examples in the ill - defined context , while only experts benefitted in the well - defined context . 12 Jansson et al . [ 50 ] studied design fixation caused by providing flawed sample designs in the form of sketches with minimal text during idea generation for physical products . They studied advanced undergraduate engineering design students and professional engineers . The participants showed design fixation by generating ideas involving aspects like those present in the examples . However , there was no effect on the number of ideas generated . Purcell et al . [ 76 ] conducted a similar study with advanced undergraduate students in mechanical engineering and industrial design . They found that fixation occurred for only mechanical engineers , however , with no effect on the number of designs and the number of types of designs produced . Goldschmidt et al . [ 37 ] studied the role of textual inspirational stimuli on undergraduate industrial design students during idea generation . They found that inspirational stimuli in the form of texts containing ideas increased the originality of the generated ideas , but not the practicality . They found that texts with ideas related or unrelated to the problem had a similar impact on idea generation . Tseng et al . [ 98 ] studied the impact of the type of analogical stimuli ( closely related versus distantly related to the problem ) and the time of presenting them on undergraduate mechanical engineering students during idea generation . The authors described closely related stimuli as those which are related to the problem functionally , in purpose , and by appearance . While distantly related stimuli are only functionally related to the problem . They provided the stimuli in the form of a textual description of products . The authors studied the impact by analyzing the quantity , breadth , and novelty of the generated ideas . They found that stimulus that was distantly related to the problem had a more positive impact on idea generation ( more functionally distinct ideas and higher novelty scores ) when introduced while the participant had an open goal to solve the problem . The authors defined an open goal as “a goal which has been set but one for which the associated task has not been completed . ” Stimulus closely related to the problem had a more positive impact on idea generation ( higher novelty scores ) compared to a distantly related stimulus when presented before participants began solving the problem and thus did not have an open goal . Presenting distantly related stimulus did not lead to more functionally distinct ideas as the participants found it challenging to recognize and apply the information from the stimulus . Design fixation was found to occur in terms of the ideas generated involving functional principles of the presented stimulus both in case of closely related and distantly related stimuli . 13 Cai et al . [ 16 ] studied the effect of five types of inspirational stimuli ( keyword or abstract textual description , diagram , plan , sketch rendering , and precedent photo ) on idea generation for design schemes for a single - family house . They found positive impacts of textual descriptions and sketch rendering . The other formats led to fixation , depending on the designers’ level of experience . Herring et al . [ 41 ] investigated the benefits and roles of examples in the design process by studying how web , graphic , and product designers searched for , utilized , stored , and shared examples . They found that examples helped to understand the current market , reinterpret designs , determine the originality of ideas , and inspired new ideas . Although some designers were concerned about design fixation caused by viewing examples , many more designers felt that examples helped them more than harming them . Looking for examples outside the domain of the problem statement helped minimize design fixation for some designers . Hence , researchers have found the impact of examples and possibilities of design fixation to be dependent on a wide range of interrelated factors such as the example format [ 16 ] , participants’ domain [ 76 ] and level of expertise [ 16 , 17 ] , the similarity of the example with possible solutions [ 41 , 98 ] ( exception [ 37 ] ) , when in the ideation process the examples are presented [ 98 ] , and the type of problem statement [ 17 ] . Researchers have used examples mostly in visual and textual formats to study design fixation but rarely in the form of physical artifacts . To my knowledge , no study investigated the effect of examples on idea generation for TUIs . 14 Chapter 3 . IdeaBits System Design To address RQ1 , “What are the key design features of a design tool to aid novice TIxD students to generate input action ideas for TUIs ? ” , I designed and developed IdeaBits , an example - based tangible design tool that aims to aid TIxD novices to generate ideas for TUI input action . IdeaBits consists of interactive physical artifacts to enable users to experience a set of input actions . These artifacts are coupled with examples of tangible systems to help users to conceptualize the input actions as a part of TUIs . IdeaBits also provides technical implementation guidance to help users in planning and building working prototypes of the TUI ideas they generate . I described IdeaBits , the methodology I followed to design IdeaBits , and how the various components of the methodology contributed to its features in the paper - Uddipana Baishya , Alissa N . Antle , and Elgin - Skye McLaren . 2019 . Idea Bits : A Tangible Design Tool to Aid Idea Generation for Tangible Manipulation . In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI EA ’19 ) , LBW0135 : 1 – LBW0135 : 6 . [ 10 ] . Below I am writing an edited version of the sections of the paper relevant to this chapter . 3 . 1 . Idea Bits : A Tangible Design Tool to Aid Idea Generation for Tangible Manipulation . Notice : Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . CHI’19 Extended Abstracts , May 4 - 9 , 2019 , Glasgow , Scotland , UK . © 2019 Copyright is held by the author / owner ( s ) . ACM ISBN 978 - 1 - 4503 - 5971 - 9 / 19 / 05 . https : / / doi . org / 10 . 1145 / 3290607 . 3312820 Authors and contributions : I am the first author of this paper , designer of the tool ( IdeaBits ) , and the investigator of the study . Alissa N . Antle , the second author , provided 15 guidance and feedback throughout the project as my senior supervisor . Elgin - Skye McLaren , the third author , provided guidance and feedback related to the design and coding of IdeaBits . Both the authors provided guidance and feedback while I wrote the paper . Dr . Thecla Schiphorst ( not an author ) guided me in planning , conducting , and analyzing the user study . 3 . 1 . 1 . Design Process I designed and developed IdeaBits as a research instrument , rather than as a commercially viable product , with the intent of producing knowledge for the research and practice communities through designing and evaluating the tool along with the tool itself embodying theory and technical opportunities . The focus was not to design the tool as an exemplary or full - fledged solution to address the issues faced by novice TIxD students in generating input action ideas , which would be beyond the scope of this project , but rather as a quick and semi - refined exploratory research medium that can be evaluated to identify ways in which potential support can be provided to novice TIxD students for generating input action ideas along with things that should be looked out for or avoided . I chose to create a product to address RQ1 also because products have the potential to help transfer the knowledge beyond the research community to the practice community , as suggested by Zimmerman et al . [ 112 ] . Moreover , I have an undergraduate degree in design , with a focus on design thinking , design of TUIs and physical products , and user experience ( UX ) design and research . Conceptualizing and designing a tool gave me the opportunity to make HCI research contributions by utilizing my strengths and skillsets as a designer . Figure 3 . 1 Design process timeline . To design the first iteration of IdeaBits prototype , I followed a non - linear process with four inter - related components ( Figure 3 . 1 ) 1 ) Participation in a TIxD course ; 2 ) 16 Conceptualization of IdeaBits ; 3 ) Interviews to understand TIxD practices ; and 4 ) Prototyping of IdeaBits . From the beginning of the process , the first , second , and third authors ‘participated in a TIxD course’ ( IAT 882 Physical Computing , Simon Fraser University , Spring 2018 ) at School of Interactive Arts and Technology ( SIAT ) , as a student , the instructor , and the teaching assistant respectively . It was a four months project - based graduate course where each student had to individually design a TUI to address a problem statement of their choice . I participated in the course for two reasons . First , to get first - hand exposure of a course where novice TIxD students were enrolled . Not all the students in the course were novices , including myself . I was not a novice at that time , given I had taken TIxD courses during my undergraduate and had worked on multiple projects involving designing of TUIs . However , being a student in the course gave me the opportunity to go through the same course activities as novice students in the class . Going through these experiences along with getting the chance to interact and have discussions with these novice students as their classmate helped me develop a better understanding of the target users ( novice TIxD students ) and the concerned activity ( idea generation for TUI input actions ) of my thesis . Second , to design IdeaBits within the structure of a project - based TIxD course . Although I was not a novice TIxD student , I was not an expert tangible interaction designer either . Hence developing the tool as a part of the course provided me the necessary guidance from the instructor and the teaching assistant . I got the opportunity to gain up to date knowledge in the domain through the course lectures , readings , and other activities , while also getting to revisit and revise my prior learnings and experience in TIxD . The course also involved multiple peer feedback sessions where I got the opportunity to get feedback on IdeaBits ( during the conceptualization phase as well as after it was prototyped ) from the students in the course , including the novices . The early phase of the process involved ‘interviewing’ the second author , Alissa N . Antle , as an expert and an experienced instructor in the TIxD domain . Alissa , a professor at SIAT and a highly experienced TUI researcher , has many years of teaching experience in the domain of TIxD . She was the instructor of IAT 882 in Spring 2018 , as well as multiple previous terms . This interview helped identify that novice TIxD students often find it difficult to generate ideas for input actions and restrict their explorations to 17 familiar possibilities such as input actions usually found in everyday devices . Later on , I investigated this further by conducting interviews with novice TIxD students , as discussed later in this section . After identifying the problem , I began the initial ‘conceptualization of IdeaBits , ’ which involved generating , selecting , and detailing ideas for a research instrument to address the identified problem . To decide the input actions IdeaBits would support , I cataloged artifact mediated input actions for TUIs that involve interaction through hands from a literature review of sixty - two papers on tangible systems taken from the proceedings of the top conferences for HCI and TUIs : Conference on Human Factors in Computing Systems ( CHI ) [ 114 ] and Tangible Embedded and Embodied Interaction ( TEI ) [ 115 ] . Of the twenty - eight input actions found , some were far more commonly used ( e . g . , translate , rotate ) than others ( e . g . , stretch , pull ) [ 9 ] . To my knowledge , no research states the later set of input actions as inefficient to be used in TUIs . I questioned if they were instead less used due to non - obviousness . To open the design space of input actions for users , I chose five less used input actions : bend , fold , stretch , squeeze , and pull . I chose these input actions based on non - obviousness , availability of example videos , ease of technical implementation , the possibility of variations , and ease of user interaction . An early version of the concept for the research instrument involved two exploratory features : interactive physical artifacts and examples of TUIs . At this point , to further investigate the identified problem , I conducted one - on - one one - hour semi - structured ‘interviews’ with my classmates from IAT 882 . I investigated novice TIxD students’ perceptions of how they generate ideas for input actions , with a focus on the challenges they face . I also conveyed this to the participants as the goal of the interviews while mentioning that I was exploring a potential problem statement from my IAT 882 project . The interviews were conducted at a point in the course timeline where the students had started conceptualizing a TUI for their course project so that they had some experience of ideating for TUIs as a novice and a recent project to talk about during the interviews . To ensure the later , during the screening procedure , I also asked the students to show me their progress in the IAT 882 project , based on which I screened only those students who had started to conceptualize or finished conceptualizing TUI ideas and the involved input actions . I chose to discuss the IAT 882 project during the interviews to facilitate easy recalling for the participants given the project being recently started and one on which they were actively working those days . During the interview , I asked questions 18 such as “Can you tell me how you came up with this input action idea for your IAT 882 project ? ” and “What challenges , if any , did you face while exploring input action possibilities for your TUI idea ? ” . I provide the interview questionnaire in Appendix L . To avoid leading the participants in any way or conditioning their responses , I did not involve IdeaBits in these interviews . To help the participants openly discuss their experiences and concerns during the interviews , I ensured them of the complete confidentiality of the interviews , which involved the data being analyzed only by myself , no use of personally identifiable information while sharing the results of the study , and no impact of their responses on their IAT 882 grades . Due to the limited time in the context of the course , I used convenience sampling to screen five students ( three males and two females ) from IAT 882 . However , due to scheduling difficulties within the tight course timeline , I could interview only the three male students ( pseudonyms as Bob , Mark , Sam ) . Since the target users of the problem I addressed are novice TIxD students , I screened students for whom the course was their first experience with TIxD and similar domains that involve embodied interactions . To minimize the chances of the participants being aware of IdeaBits , I screened those students who were not in my group during the completed peer feedback sessions of the course . I also checked in with them by asking if they were aware of the project I was doing for IAT 882 . I screened only those students who answered that they were aware of my project . I conducted the interviews soon after the screening process since a long time gap might have increased their chances of getting to know about IdeaBits from the class activities and discussions with other classmates . The interviewed participants were graduate students at SIAT and were of the age group 25 - 34 years old . Two of them had an educational background in computer science and one of them in architecture . I planned to conduct the interviews at the participant’s workspace , where they usually work on their course project , to retain the context and have quick and easy access to their project model , sketches , and other traces , along with the traces of their process . However , none of the participants felt comfortable with the idea due to different reasons such as the presence of other people in the area and instead preferred the interview to be conducted at a lab at SIAT . I hence requested the participants to bring their laptop and whatever materials possible related to their IAT 882 project to the lab where I conducted the interviews , which would provide more insights as well as the participants could refer to them during the 19 interviews to help discuss and recall . The lab was a closed space in SIAT , which I reserved for the interviews to avoid any interference . I video recorded the interviews to capture visual aspects such as participant’s demonstration of input actions or idea generation activities . I transcribed the interviews and did a thematic analysis of the data . During the analysis , I referred to the video recordings of the interviews to get clarification for any part of the interviews that were ambiguous or had missing context . The primary focus of the analysis was to look for pieces of evidence that were in support of or in discrepancy with the exploratory features of IdeaBits , with a secondary focus on any new emerging patterns and findings , as discussed next . After analysis of the interview data , I ‘prototyped IdeaBits’ . Based on my experience of prototyping IdeaBits , I added a third exploratory feature - technical implementation guidance . 3 . 1 . 2 . Design Rationale Figure 3 . 2 IdeaBits prototype . The TUI example shown on the laptop is TwistBlocks [ 105 ] . The current design of IdeaBits ( Figure 3 . 2 ) has three exploratory features : 1 ) interactive physical artifacts that aim to enable users to experience a set of input actions , 2 ) examples of existing tangible systems designed by other researchers that incorporate the input actions to help users to understand how to conceptualize the input actions as a part of TUIs , and 3 ) technical implementation guidance to help users in planning and 20 building working prototypes of the TUI ideas they generate . I next describe how the various components of the design research methodology contributed to these features . Interactive Physical Artifacts Figure 3 . 3 Artifacts of IdeaBits . There are two sets ( physical - only and sensor - enabled ) of five artifacts ( Figure 3 . 3 ) . Each of the artifacts can be physically interacted with , in one unique way ( squeezing , stretching , bending , folding , and pulling ) . By interacting with the sensor - enabled artifacts , users can open the associated example pages on the graphical user interface ( GUI ) of IdeaBits ( more details in the next section ) and play or pause the videos . I used a flex sensor , a switch made from copper tape , a conductive rubber cord , a pressure sensor , and a light - dependent resistor to detect bend , fold , stretch , squeeze , and pull , respectively . IdeaBits aims to enable users to experience a set of input actions by physically enacting them on artifacts . The analysis of the interviews revealed that participants desired to experience input actions while generating ideas . For example , Bob and Mark expressed the difficulty in generating ideas for input action through sketching as it did not let them enact the actual actions . Bob wanted to be able to carry out the input actions for more accurate perception . “It [ input action ] is not something , especially that I would think about through sketching . I don’t really know how it [ input action ] feels like unless I actually touch it . I can’t just pretend I am doing those movements . ” – Bob . Mark acted out the input 21 actions while imagining to be the user and the system to be in front of him . “ [ To generate ideas ] I just start walking and thinking . I have to be able to move my hands as freely as possible . I was thinking like I am the DJ [ user ] . I just imagine the artifact is there , and I am working with it , and you know gradually it shapes itself . ” – Mark . I did a hands - on exploration of a variety of possible materials and objects for designing the artifacts such that each artifact would afford a unique input action . I used generic artifacts to avoid possibilities of functional fixation seen with everyday objects ( e . g . , stress ball or hair elastic ) . I also paid attention to maintaining similar sizes ( scale ) , clear visual distinctions , and the possibility of installing sensors . I considered other factors such as freedom of movement for users , robustness , ease of expanding the set , implementation cost , and extent of physical - digital coupling . Figure 3 . 4 Accessing the video instruction on an example page in the GUI of IdeaBits that demonstrate how to interact with the bend sensor - enabled artifact . The TUI example on the left screen is TwistBlocks [ 105 ] . The sensor - enabled artifacts are connected to a laptop using an Arduino Uno board [ 116 ] ( Figure 3 . 2 ) . The laptop is used to display the GUI of IdeaBits . To prevent user interactions that can damage the sensors , I developed video instructions demonstrating how to interact with the sensor - enabled artifacts . I provide these videos on the GUI of IdeaBits . Users can access these videos by clicking on the button labeled “ ? ” on the example page of the GUI ( Figure 3 . 4 ) . I discuss the GUI , including example pages , in more detail in the next section . 22 Examples of Tangible Systems Figure 3 . 5 Home page of the GUI of IdeaBits . The GUI consists of a home page that displays all the sensor - enabled artifacts as image buttons that are labeled with the name of the associated input actions ( Figure 3 . 5 ) . Clicking on any of these buttons will open a page that shows two TUI examples that incorporate the input action clicked on ( Figure 3 . 6 ) . For example , TwistBlocks [ 105 ] and Bosu [ 66 ] are given as examples for bend input action . The TUI examples are presented using a video , images , and a link to the published paper . The objective is to help users to conceptualize the input actions as a part of TUIs . The idea was inspired by the observation that TIxD courses use examples of tangible systems to teach TIxD concepts . 23 Figure 3 . 6 Example page in the GUI of IdeaBits showing TUI examples that involve bend as an input action ( TwistBlocks [ 105 ] and Bosu [ 66 ] ) . All the interview participants mentioned that they used examples while generating ideas . Bob and Sam found it difficult to conceptualize input actions they did not come across in examples . “I just didn’t think about it [ input actions not seen in examples ] , like just coz it just never came to mind . ” – Bob . “I thought that maybe how can I use twisting . But frankly speaking , I had no idea how can I implement the twist in any [ tangible ] system . I had no example of such thing [ tangible system ] that [ incorporates ] twist . ” – Sam . Participants indicated that they were negatively impacted by limited exposure to examples . Sam mentioned that he considered only ‘connecting’ as the input action in his TUI idea for the IAT 882 project since it was involved in most of the examples he came across . “So I have seen a lot of systems that use this kind of connection [ as an input action ] , right ? So that’s why it came easily in my mind . ” – Sam . Bob felt his ideas of input action were drawn upon input interactions of devices , such as smartphones , due to limited exposure to examples of tangible systems . “I have this sort of preconceived biases about like how people interact with devices . And in a way , I feel kind of restricted , and it’d be kind of cool to open up my mind a bit more to like these more broader kinds of interaction . ” – Bob . I provided two examples of tangible systems for each input action to minimize possibilities of design fixation as compared to single example cases studied by previous researchers [ 16 , 50 , 76 ] . I considered video as an essential representational format to adequately depict the physical actions , along with providing images for quick reference and link to the published paper for reading about the system details . Sam mentioned that 24 he could quickly and easily understand TUI examples through videos and images , while he significantly struggled with text . “I always prefer minimal kind of writing , not too much writing , that really makes me too much confused . There should be a image of that [ example ] , so at a single sight , I can grasp the whole idea . And if there is a video , then that’s awesome . ” – Sam . On the other hand , Bob generated ideas through literature research . “It [ literature research ] is something that I am sort of used to . I am not really sure of many other ways to do that [ generate ideas ] at least as this effective . ” – Bob . Technical Implementation Guidance For each input action , IdeaBits provides technical implementation guidance to help users in planning and building working prototypes of the TUI ideas they generate . The objective is to reduce possible insecurities the users may have related to technical implementation . The guidance is provided by linking to the pages of an existing website , Sparkfun [ 117 ] , that provides information and implementation guidance related to various sensors and other electronic components . This idea was inspired while required to look over multiple websites to prototype IdeaBits . A user begins by viewing videos in the GUI to understand how to interact with the artifacts . They are encouraged to pick up an artifact and interact with it . The GUI presents examples linked to the artifact automatically if the artifact is sensor - enabled ; otherwise , the user can select it . They can then repeat this process using the other artifacts . The next sections are not a part of the paper [ 10 ] . 3 . 2 . IdeaBits Design Revisions In this section , I discuss the revisions I made to the first prototype of IdeaBits . I was the leading designer of the revised version of IdeaBits while collaborating with three researchers as described next . To evaluate the tool , I used self - conducted heuristic evaluation [ 63 ] , collected feedback on the complete tool from my senior supervisor , and collected feedback on the GUI from Boxiao Gong ( Ph . D . student at Tangible , Embodied , Child Interaction ( TECI ) lab , with a master’s degree in visual communication design ) . I generated ideas to address the suggestions and concerns that came up from my analysis of the feedback I received . I developed the revised IdeaBits prototype , which involved designing wireframes ( including interactions ) and final composition of the GUI graphics , building the artifacts , and programming for the electronics ( in Arduino ) to connect the 25 artifacts to the GUI . Pankaj Kumar , who is a computer science and engineering student , did the programming for the GUI . I describe below the revisions I made along with my design choices and rationales . 3 . 2 . 1 . Hardware Revisions Figure 3 . 7 Revision of breadboard from solderless ( left ) to solderable ( right ) . a ) Pin headers of jumper wires . IdeaBits involved a breadboard for connecting the sensor - enabled artifacts , resistors , and Arduino Uno board [ 116 ] for controlling input - output . I improved the robustness of the sensor - enabled artifacts by using a solderable breadboard to avoid the wires and resistors from being pulled out while interacting with the artifacts . I added modularity by using male - female pin headers to enable unplugging of the sensor - enabled artifacts and the Arduino Uno board from the breadboard for ease of replacing , testing , storing , and transportation ( Figure 3 . 7 right ) . Using 3D printing , I developed an enclosing box for the breadboard and the Arduino Uno board since those were not relevant to be interacted with or seen by the users . I improved the prototypes mobility by replacing the wires used to connect the sensor - enabled artifacts to the breadboard with softer wires and increased length ( Figure 3 . 8 ) . 26 Figure 3 . 8 Attached longer and softer wires to sensor - enabled artifacts . Figure 3 . 9 Damaged flex sensor in bend sensor - enabled artifact ( left ) . Use of plastic sheets to prevent further damage ( right ) . The pilot participants from the user study conducted to evaluate IdeaBits ( see Chapter 4 ) found it difficult to use the bend artifact , made from a thick glue - gun stick , due to its rigidity . I replaced it with a more flexible and thinner glue - gun stick . The flex sensor used in the bend sensor - enabled artifact was damaged twice during the user study conducted to evaluate IdeaBits ( see Chapter 4 ) . Flex sensor facilitates bending in only one direction . The damage could have occurred due to the participants bending it in the opposite direction . I noticed a kink on the sensor on investigating it after being damaged for the second time ( Figure 3 . 9 left ) . The kink might have occurred due to the use of tape for attaching it to the glue gun stick , which could have restricted its movement when the glue gun stick tries to return to its natural position from the bent position . To minimize the possibility of further damage , I tried to prevent movement restriction of the sensor by using a plastic sheet between the tape and the sensor such that the tape does not come in direct contact with the sensor ( Figure 3 . 9 right ) . To further make the movement smooth , I reduced the rigidity by reducing the amount of tape I wrapped around the sensor . 27 Figure 3 . 10 Revisions of artifacts . ‘Old’ refers to the first iteration while ‘new’ refers to the second iteration of IdeaBits prototype . I made some changes to the fold sensor - enabled artifact to make it easy to interact with while ensuring that the artifact detects every time a user folds it close ( Figure 3 . 10 ) . I used one side conductive copper tape in the earlier version of fold sensor - enabled artifact , because of which I had to solder the wires on top of the copper tape . The resulting uneven inner surface of the artifact reduced the contact area when it was folded , thus resulting in not detecting the fold input action at times . I used both - side conductive copper tapes to be able to solder below the tape . I used padding to make the inner surface even by balancing the raise from the soldering . I replaced the material of fold sensor - enabled artifact from rigid plastic ( cut out of a plastic file ) to plastic - coated paper ( cut out of paper gift bags ) . The use of plastic - coated paper prevented it from bouncing open after being folded . Compared to paper alone , the plastic coating would protect the artifact from getting stained or torn . I made the artifacts within each set different in color to help users to distinguish between them . I also made the pair of artifacts associated with the same input action of similar material and visual look ( Figure 3 . 10 ) . The bend physical - only artifact was bare 28 glue gun stick , which could have resulted in the participant recognizing it like a glue gun stick and being fixated to its concept or functionality . To avoid this issue and to match the color with bend sensor - enabled artifact , I wrapped it with the tape I used with bend the bend sensor - enabled artifact . I matched the color of the wires connecting the sensor - enabled artifacts to the breadboard to the color of the sensor - enabled artifact minimize the use of multiple colors within each sensor - enabled artifact . 3 . 2 . 2 . Instruction Revisions Figure 3 . 11 Front and back sides of the illustration card for stretch input action . Since the videos on the home page of IdeaBits illustrated the input actions using only the sensor - enabled artifacts , I made instruction materials for the physical - only set . I designed five illustration cards corresponding to the five input actions introduced by IdeaBits . One side of the card , I illustrated how to interact with the associated physical - only artifact , while on the other side , I provided the name and definition of the input action ( Figure 3 . 11 , Appendix M ) . The definitions that I provided for the five input actions are : 1 . Bend : A bend action modifies a flexible object into a curved form . 2 . Fold : A fold action modifies a flat object along a crease in a way that two surfaces form an angle or come in contact . 3 . Pull : A pull action is a force exerted on a part of an object in a single direction away from the center of the object . 4 . Squeeze : A squeeze action involves pressing a soft object inwards towards its center , typically from several directions at once . 5 . Stretch : A stretch action involves exerting two or more forces in different directions on a deformable object , to make it longer or wider . I developed these definitions by appropriating the definitions provided by the online dictionary Lexico [ 118 ] to the specific context of interacting with artifacts using hands . I did 29 this appropriation based on 1 ) the versions of the input actions in the TUI examples from the catalog I made of TUI input actions [ 9 ] , especially the TUI examples in IdeaBits , and 2 ) the recommended ways of interacting with the IdeaBits artifacts . I considered it important to provide a definition of the input actions to help the users understand them as well as distinguish among the five , given merely the names of the actions may not be sufficient for the same . Defining the input actions also helped me to identify and categorize different variations of these input actions that I came across in TUI examples and ideas generated by the participants of the user study to evaluate IdeaBits ( see Chapter 4 , 5 , and 6 ) . It especially helped remove ambiguity with those input actions which were difficult to be labeled using a term or seemed labelable using more than one terms . 30 3 . 2 . 3 . Graphical User Interface Revisions Figure 3 . 12 Accessing the video instruction on the home page of the GUI of IdeaBits demonstrating how to interact with the bend sensor - enabled artifact . In the earlier version of the GUI of IdeaBits , the video instructions demonstrating how to interact with the sensor - enabled artifacts could be accessed by clicking on the button labeled as “ ? ” on the example pages ( Figure 3 . 4 ) . As mentioned earlier , one of the functionalities of the sensor - enabled artifacts is that by interacting with the artifacts , users 31 can open the associated example pages on the GUI of IdeaBits . In this scenario , a user would interact with a sensor - enabled artifact before opening the associated example page where they can find the video instruction . Hence in the revised GUI , to give users access to the video instruction before they interact with the sensor - enabled artifacts , I provide the video instruction on the home page . When users hover the mouse cursor over the images of the sensor - enabled artifacts on the home page , they can see the associated video instructions ( Figure 3 . 12 ) . Figure 3 . 13 Paper format of TUI examples ( TwistBlocks [ 105 ] and Ninja Track [ 53 ] ) . To prevent the user from leaving the GUI of IdeaBits , I incorporated the paper format of example within the GUI ( Figure 3 . 13 ) . To accommodate this new example format in the GUI , due to limited space on a computer screen , I changed the information architecture by providing the three example formats in three different pages . Incorporating the paper within the GUI enabled me to use red , green , and blue color - coded underlining to denote sections of the paper describing system overview , input action , and implementation , respectively . 32 Figure 3 . 14 Revised video player for video format of the TUI examples ( TwistBlocks [ 105 ] and Ninja Track [ 53 ] ) . I changed the design of the video player to match general video player design , which users would already be familiar with ( Figure 3 . 14 ) . To ease studying of the example videos , I provided color - coded bars , across the timeline of the video . The color - coding is the same as the one used for the paper format . Users could click on any of the bars to jump to that section of the video . 33 Figure 3 . 15 Revised example page for displaying images of the TUI examples ( RopePlus [ 109 ] and Memento [ 64 ] ) . I added image thumbnails for image format of the examples to ease browsing ( Figure 3 . 15 ) . I also added captions to help the users to understand the images . To indicate the buttons and tabs being clickable , I added three shades of color corresponding to the three states of the mouse cursor - no mouse hover over , mouse hovered over , and mouse clicked on the button . I made their design uniform across all pages of the GUI . 3 . 2 . 4 . Code Revisions The code I wrote for IdeaBits was monolithic and hard - coded . While implementing the GUI revisions , Pankaj changed it to modular and object - oriented for easier debugging , future modification , and readability to ease the collaborative process of developing IdeaBits as well as to facilitate others in understanding and using the code when made open - source . As a contribution of my work , I open source IdeaBits code by providing the source code on GitHub [ 99 ] to enable other designers and researchers to use the code , which may be helpful in creating a prototype of IdeaBits or similar tool . In the code , we also incorporated an automatic recording of the activity log ( spreadsheet file ) of IdeaBits , along with time stamps and durations . It records interactions with the sensor - enabled artifacts and GUI . For example , it records which sensor - enabled artifact the user is interacting with or which element on the GUI the user is clicking on . 34 This was done to facilitate taking notes during remote observation of the user study to evaluate IdeaBits ( see Chapter 4 ) . 3 . 3 . Comparison of the Design Process with Other Methodologies In this section , I compare the design process of IdeaBits with two existing methodologies with which it bears certain similarities : research through design ( RtD ) methodology [ 111 – 113 ] and user - centered design ( UCD ) process [ 1 ] . 3 . 3 . 1 . Research Through Design Methodology The design process of IdeaBits entails certain aspects of RtD methodology [ 111 – 113 ] : 1 ) Framing of the work in the real world by solving a real - world problem ; 2 ) Creation of a product as a research instrument to produce knowledge , instead of as a commercially viable product ; 3 ) Creation of novel artifacts , rather than refinements of existing products ; 4 ) Evaluation of the artifact situated in the world ( see Chapter 4 , 5 , and 6 ) to discover unanticipated effects ; 5 ) Extensive literature review ( see Chapter 2 , 6 ) to situate the work and demonstrate how it advances the research community ' s current state of the art ; and 6 ) Providing detailed documentation of the designed artifact and the design and evaluation processes , including research and design rationales , to enable understanding , leveraging , and reproduction of the produced knowledge . The process , however , differs from RtD in multiple ways . RtD involves addressing wicked problems that involve multiple stakeholders with unclear or even conflicting agendas , goals , needs , and perspectives . Addressing the problem involves reframing it through a reflective process of iteratively designing and critiquing artifacts as proposed potential solutions , with the intention to make the right thing to address the problem . It focuses on exploring by creating multiple possible solutions followed by the selection of a promising idea to iteratively detail , refine , and evolve into a completed product . The inquiry process revolves around creating mostly implicit knowledge through the design ( process ) of the artifact with the created knowledge almost entirely residing in the designed artifact [ 111 – 113 ] . On the other hand , the problem I addressed is not a wicked one ; in turn , my process did not involve reframing the problem . I understood the state of the world mainly through literature research , user interviews , and participation in IAT 882 , rather than 35 through an iterative process of designing a product as a promising solution ; since the later would require longer timeline , more expertise in designing or ideally a multidisciplinary team , and higher financial budget . The focus of my work was not to produce knowledge from the process of iteratively designing a solution to the addressed problem but rather to quickly build a research instrument to be able to create knowledge by using it in an exploratory evaluation . Even though the process did not involve extensive exploration of various possible solutions to the addressed problem , I conducted some explorations in terms of detailing IdeaBits , as discussed earlier in this chapter . 3 . 3 . 2 . User - Centered Design Process User - centered design can be described as " design processes in which end - users influence how a design takes shape " through their involvement in the process [ 1 ] . I took a user - centered approach for designing the product by involving the target users ( novice TIxD students ) in the process . I conducted interviews with novice TIxD students to know their goals , needs , and concerns based on which I finalized the key features of IdeaBits . I , however , also added an exploratory feature of IdeaBits , technical implementation guidance feature , based on my own experience of prototyping IdeaBits . The focus of UCD is , however , on designing a product for the users as a promising solution to the identified problematic situation that would fulfill users’ crucial goals and needs , with usually the intention of commercializing the product [ 1 ] . The focus of my work , on the other hand , was the quick creation of an exploratory research instrument . Hence , although I involved users in the process , the intention was not to obtain an exhaustive list of representative goals , needs , and concerns of the target users , but rather to discover only a few possibilities . Users’ involvement in the design process of IdeaBits was light , limited to one - time one - hour individual interviews with only three users , as discussed earlier in this chapter , compared to other UCD approaches such as participatory design [ 1 , 85 ] . Screened through convenience sampling , the participants were also not necessarily a representative set of the target users , which would not ideally be the case in a typical UCD process [ 1 ] . UCD also focuses on considering a wide range of stakeholders of the product being designed , including three types of users : primary , secondary , and tertiary [ 1 , 27 ] . Given the limited scope of the project , I focused majorly on only the primary users ( novice TIxD students ) , that is those who will actually use IdeaBits , and not much on the secondary users ( e . g . , instructors of TIxD course ) , that is those who 36 will occasionally use IdeaBits . Since IdeaBits was not created as a commercially viable product , considering the tertiary users ( e . g . , parents of novice TIxD students ) , that is those who will make purchase decisions , was not considered important . With the focus on creating a promising solution for the addressed problem , UCD focuses on creating and evaluating multiple possible solutions . It involves an iterative process of reaching the final solution through multiple cycles of designing , evaluating , and improvising . Initially , low fidelity prototypes are built and evaluated , eventually shifting to high fidelity prototypes [ 1 ] . Since the focus of my work was on creating knowledge through an exploratory evaluation of a quickly created exploratory research instrument , while also considering the limited time and scope of the project , I neither created and evaluated multiple designs nor iteratively refined a final design by building and evaluating its prototypes with increasing level of fidelity . I revised IdeaBits only once and based on findings from rather quick evaluation methods , including a heuristic evaluation that I did myself and collecting feedback from my supervisor and a lab mate from TECI lab , as discussed earlier in this chapter . Heuristic evaluation is an alternative testing technique to usability testing with target users of the product , the later being expensive . It is supposed to be conducted with usually three to five experts from the concerned domain [ 1 , 62 ] . I did the heuristic evaluation myself , even though I was not an expert in TIxD or HCI , given a different focus of my work than that of UCD while also considering the limited resources and scope of the project . Using the second iteration of IdeaBits prototype , I conducted an evaluation of the tool that focused on identifying ways in which potential support can be provided to novice TIxD students for generating input action ideas along with things that should be looked out for or avoided ( see Chapter 4 , 5 , and 6 ) ; rather than focusing on usability aspects of IdeaBits such as task performance speed , error types and rate , time for learning specific functions , retention of commands over time , and subjective satisfaction , which are usually the major evaluation criteria in UCD [ 1 , 88 ] . 37 Chapter 4 . User Study Methodology 4 . 1 . Summary To address RQ2 , RQ3 , and RQ4 ( see Chapter 1 ) , I conducted an exploratory case study [ 110 ] . Given IdeaBits was not intended to be created as a full - fledged solution , but rather as an exploratory research instrument ( see Chapter 3 ) , I did not conduct an evaluation , such as usability testing [ 1 , 26 ] , that would focus on the tool’s usability aspects to improvise it as a promising solution . Even though the key features in IdeaBits were backed with specific design rationales and objectives as discussed in Chapter 3 , the evaluation did not focus on measuring the success of these objectives . I rather conducted an exploratory evaluation by studying the target users’ interactions with IdeaBits and their experiences , while focusing on the essence and key features of IdeaBits by considering it only as an exploratory attempt rather than a promising solution . Accordingly , I asked exploratory interview questions ( Appendix K ) such as “Can you walk me through how you came up with these input actions in your final idea ? ” , and “What are the ways you used IdeaBits to do this design task ? ” . The intention of the evaluation was to create knowledge by identifying ways in which potential support can be provided to novice TIxD students for generating input action ideas along with things that should be looked out for or avoided . I aligned both the collection and analysis of the data with this intention , as discussed in this chapter . I conducted the study in a lab at the School of Interactive Arts and Technology ( SIAT ) , Simon Fraser University ( SFU ) , Surrey , Canada . It consisted of remotely observing participants while they used IdeaBits to generate ideas for TUIs addressing a given problem statement . At the end of the sessions , I conducted semi - structured interviews . It involved five pilot participants and twelve novice TIxD students as actual participants , with all of whom I conducted individual sessions . I collected qualitative data in the form of video recording of the sessions , activity log ( text ) of IdeaBits , notes from remote observation , deliverables ( text , images , and physical models ) of the problem statement , and audio recording of the interviews . 38 4 . 2 . Participants I conducted pilot user studies with five participants individually . There were three female and two male participants . Four of them were students ( one undergraduate ) , and one was a postdoctoral fellow at SIAT . All of them were from the TIxD domain , with two being novices . After incorporating the changes from the pilot studies , I screened twelve novice TIxD students from SIAT to run the modified user study . I targeted ten to twelve participants as my study involved data - intensive individual sessions . After conducting the user study with 9 participants , I found that the data was repeating , and there was no new significant data . Hence I stopped the user study after running it with twelve participants . The participants were of the age group of 18 to 44 years old , including six males and six females . Eight of them were undergraduate students at SIAT , while four of them were graduate students . These graduate students had an educational background in electrical engineering , computer science , industrial design , computational design , and architecture . Five of the participants had no work experience , while the others had experience as product and industrial design lecturer at a university , UX researcher , HCI researcher , computational design researcher , UX designer , UX developer , user interface developer , web communication assistant , visual designer , and marketing coordinator . 4 . 2 . 1 . Recruiting Process The target users of IdeaBits for addressing my RQs are novice TIxD students . I put up the recruiting poster ( Appendix B ) on the notice boards in SIAT and shared it on Facebook [ 119 ] . I also shared it with the university - wide study participation recruitment system managed by the Graduate Student Society and SFU Graduate and Postdoctoral Studies [ 120 , 121 ] . With permission from course instructors , I visited lectures and labs for eight SIAT undergraduate courses of 2019 summer . There I distributed recruiting flyers ( Appendix C ) to the students while having the recruiting poster up on the projector . I then shared with the class the study overview , followed by passing the sign - up sheet ( Appendix D ) . To follow up with the students who signed up , I emailed them providing more information about the study . 39 4 . 2 . 2 . Screening Criteria I conducted the screening and recruiting processes in parallel . I screened participants from among the students who signed up or emailed me until I had twelve participants ( six males and six females ) . Using a screening questionnaire , I screened the participants based on their ability to communicate in English ( self - rating of more than 2 on a scale of 1 - 5 ) and with no self - identified physical or cognitive disabilities ( Appendix E ) . Since I was collecting interview data , the participants had to be able to understand and speak in English without difficulties . Since the user study involved physical and cognitive actions such as interacting with the IdeaBits artifacts , sketching , writing , generating ideas , etc . , it was important for the participants not to have any physical or cognitive disabilities that might influence such actions . IdeaBits was designed targeting TIxD students who have limited knowledge and experience of TIxD [ 10 ] . I screened novice TIxD students based on the courses they had taken and their work experience in TIxD and similar domains that involve embodied interactions , such as gestural interfaces and virtual reality ( Q7 and 8 , respectively , in the screening questionnaire ) . 4 . 3 . Setting Figure 4 . 1 Two views of the room where I conducted the user study . I conducted the user study in a SIAT lab room . Since the room was in SIAT , it was easily accessible to the participants who were SIAT students . The room was equipped with two tables , two chairs , a drawer , whiteboards , wall clock , and SFU LAN ( Figure 4 . 1 ) . I used the tables to keep IdeaBits , a personal computer , stationeries , and modeling material . Since I required to keep many things on the table , I needed two tables to provide 40 enough working space . The whiteboard came in handy to write the goal of the user study so that the participant could look at it throughout the study if needed . SFU LAN provided internet connection required to access the technical implementation guidance feature of IdeaBits . The room had enough space to accommodate all the research materials while leaving space for the participants to walk around if they desired . Being a closed room with no windows , it might not be an ideal place for being creative . However , having no windows along with soundproofing and being reserved for the study , gave the advantage of minimal outside disturbances . Figure 4 . 2 The room from where I did remote observation . I did remote observation from an adjacent room ( Figure 4 . 2 ) , which was similar to the user study room . The adjacency of the two rooms facilitated my movement between the rooms . 41 4 . 4 . Research Materials Figure 4 . 3 The table ( table A ) with IdeaBits and the connected personal computer . Figure 4 . 4 The table ( table B ) with a ) physical - only artifacts , b ) Illustration cards , c ) overview map , d ) problem statement sheets , e ) stationeries , and f ) modeling materials . I set up the two tables at 90 degrees so that the participants could quickly move from one to the other . I also provided them a chair with wheels to ease such movements . I used one of the tables ( table A ) to set up IdeaBits and the personal computer to which I connected IdeaBits ( Figure 4 . 3 ) . On the other table ( table B ) , I provided physical - only artifacts , illustration cards , overview map ( Appendix H ) , problem statement sheets 42 ( Appendix F ) , stationery , and modeling materials , while leaving enough working space ( Figure 4 . 4 ) . I put some of the stationeries and modeling materials also on top of the drawer and the floor . I pasted the list of the provided stationeries and modeling materials ( Appendix G ) on the wall near table B . Figure 4 . 5 Camcorder set up on the ceiling using a phone holder . I used two Canon Vixia HFR 52 Camcorders to record and live stream the sessions . I set up one cam recorder using a tripod to capture the eye - level view ( Figure 4 . 1 ) and the other using a phone holder to capture the top angle view of table B ( Figure 4 . 5 ) . Using CameraAccess plus app [ 122 ] , I connected each of the cam recorders to a tablet located in the room from where I did remote observations . Using Processing [ 123 ] and Arduino [ 124 ] software , I connected IdeaBits with the personal computer . I connected the personal computer to the SFU LAN . I used FlashBack [ 125 ] software to record the personal computer screen . To live stream the personal computer screen to my laptop in the remote observation room , I used TeamViewer [ 126 ] software . I designed a 60 minutes timer app ( coded by Matin Lotfaliee , then an MSc student at SIAT ) [ 127 ] , which had a visual timer with voice reminders at 40 , 20 , and 5 minutes remaining . I ran this app on a tablet in the user study room during the design sessions to help the participants keep track of the time . I used pen and paper along with the Otter app [ 128 ] to take notes during observation . The app transcribes the audio with time stamps . I used the app during the interviews as well . 4 . 4 . 1 . Changes from Pilot Studies I initially placed the table A and B parallelly next to each other . The first two pilots mentioned that they found it difficult to shift between the tables . I then put the tables at 90 43 degrees . This arrangement allowed pilots to move without leaving the chair with casters and hence facilitated switching between the two tables quickly . One of the two video recorders was initially positioned to capture the personal computer screen . However , since the captured video was not very legible , I switched to using TeamViewer . Also , it was hard to understand what the participants were doing on table B . Hence I instead attached the recorder to the ceiling to capture the top view of table B . I added voice reminders to the timer at 40 , 20 , and 5 minutes remaining to help the participants manage their time . I reduced the types and quantity of stationeries and modeling materials since most of the pilots mentioned that they felt overwhelmed with too many modeling materials . I also rearranged the modeling materials using organizing trays and pen stands to reduce the clutter , ease access , and increase the working space on table B . I replaced table B with a bigger table since participants were seen to be building models on top of the deliverable sheets due to lack of working space . 4 . 5 . Procedure and Tasks 4 . 5 . 1 . Procedure I welcomed the participants by asking about how their day had been , to give them time to settle down while opening them to conversate . Then I started with explaining the purpose of the cam recorders in the room . With the participant’s verbal consent , I started the recording . I then gave the participants an overview of what was going to happen in the session using the overview map ( Appendix H ) . I introduced the goal of the study as “To understand how you use the prototype to design TUIs , with a focus on input actions . ” I asked them to use the prototype for doing the design task while mentioning that they were not limited to the input actions and examples it introduces . Based on the participants’ prior knowledge , I defined TUIs . I then introduced them to the design task and the expected deliverables . I then introduced them to IdeaBits , starting with an overview . While I was explaining to them the artifacts and their role , I asked them to try out one artifact from each set . I mentioned them not to worry about breaking the sensor - enabled artifacts . I explained to them the objectives , components , and navigation of the GUI of IdeaBits while they took control of the mouse . 44 I mentioned the participants the time limit and how they could reach me during the activity if needed . I asked them if they had any doubts and clarified those at various points during this introductory session . Towards the end of this introduction , when they could make an informed decision , I asked them to sign the consent form if they were interested in participating . I then started the timer and left the room . The participants had a maximum of one hour to complete the design task . During this , I did remote observations . I took notes using Otter as well as paper and pencil . I noted , including start and end timestamps , what they were using ( which artifact , which modeling material , etc . ) , how they were using it , and what they were doing ( building prototype , sketching , etc . ) . I also noted any instances of technical malfunctioning and anything unexpected that stood out in relevance to my RQs . Based on my observation , I expanded the interview questionnaire with open questions to probe for reasons behind certain behaviors . After they completed the design task , I conducted semi - structured interviews for 14 to 25 minutes ( mean 20 . 83 , median 22 , mode 24 ) . From the pilot studies , I found the maximum time needed for doing the interviews to be 30 minutes . I gave a remuneration of CAD 25 to each participant ( funded by Dr . Alissa N . Antle through the Social Sciences and Humanities Research Council of Canada ) after the interview was over . The protocol is in Appendix I . 4 . 5 . 2 . Design Task The design task ( Appendix F ) was to “Generate ideas for a tangible system , involving one or more physical objects , which you can use to communicate how you are feeling to a partner / friend / family member over distance . The system should enable him / her to receive the feeling you communicate as well as communicate back theirs . It should also enable you to receive the feeling s / he communicates to you . ” Participants were asked to choose at least three emotions from the six basic emotions given as part of the task , which were happy , sad , scared , angry , disgusted , and surprised [ 30 ] . Participants could use any input actions and were not limited to the five input actions in IdeaBits . They required not to involve emoticons in their ideas . I asked them to generate many ideas , and from among those select one final idea . I asked participants to submit four deliverables representing their final idea : 1 ) Sketches or rough physical models ( without electronic components ) with optional description , 2 ) Written description of how their idea supported communication of emotions over distance , 3 ) A table listing the emotions they could communicate using their idea 45 along with the corresponding input actions they required to perform on their idea and the resulting output , and 4 ) A list of the electronic components they would need to build a prototype of their idea . Appendix K describes these deliverables in detail . Rationales for the Design Task To generate ideas for the design task , I conducted a 30 minutes brainstorming session with six lab mates from the TECI lab , including myself and my senior supervisor . I also individually generated many ideas for the task outside of this session . From all the ideas generated , I finalized the design task based on several factors , as discussed next . 1 . Designing for self : Based on the concept of user - centered design , when designing any product , it is crucial to take into account the personas of the target users [ 33 ] . Being only an hour - long session , the participants would not have enough time to learn about the needs and goals of the users for whom they need to design . To address this issue , I asked the participants to design for themselves . 2 . Relatable : Since the participants had to design for themselves , the problem statement had to be relatable to their own experiences . The target user group of my study is students from SIAT , SFU . SFU has many international students [ 129 ] , and hence there was a good chance that at least some of my participants might be international students . International students are likely to have loved ones over distance . Hence , they might be able to relate to communicating emotions to someone over distance . Moreover , people living far away from each other usually face issues in communicating feelings and emotions due to the absence of physical interactions [ 91 ] . Hence the design task would involve a real - life problem . 3 . Easy to understand : For the same reasons discussed with the factor of relatability of the problem statement , communication of emotion over distance may be an easy concept to understand for the target user group of my study since they are usually aware of emotions and communication over distance . 4 . Unfamiliar solution space : Although there are many tools to support communication over distance , there are only a few TUIs for communicating emotions over distance [ 108 ] , especially commercially available ones . Hence it was less likely that the participants might have come across any similar products . This would reduce the possibility of design fixation . 46 5 . Both way communication : The task asked the participants to design the communication to be both ways between the partners to make them the user for both the input action and the output . This might facilitate to balance their focus on both input action and output while generating ideas . Doing so may result in well balanced TUI ideas . 6 . Enable exploration of input actions : I chose emotions since they are abstract and natural to be linked with physical actions , while they do not have any default associations . Designing for emotions may provide a design space with a large number of options for input action . Hence , the problem statement of the task aimed to open the exploration of multiple input action ideas within the one - hour session and without suggesting any specific input action ideas . The input actions would be richer than input actions for control or concrete representations . Moreover , since communicating involves conscious action , it is possible to incorporate a wide range of input actions as opposed to automatic detection or absent - minded interactions . 7 . List of emotions : In the task description , I included a set of six basic emotions to have uniformity while reducing ambiguity , especially to help participants narrow their focus in the hour - long session . I asked them to pick at least three basic emotions to ease ideating for a variety of input actions . I allowed the participants to have more than one physical object in their ideas to ease the incorporation of more than one emotion and input action . Initially , I was considering breaking the one - hour session into four sequential stages : idea generation , idea selection , idea detailing , and planning technical implementation . It would have enabled me to not introduce the participants to the requirement of planning technical implementation at the beginning of the session . Other researchers have found that introducing technical implementation details reduce creative confidence [ 81 ] . However , the design process by nature is an iterative non - linear process [ 130 ] . Hence , I made the sessions unstructured in order to provide freedom to the participants to steer the design process based on their preferences and habits . I retained the essence of the elements of the structure by asking them to generate multiple ideas ( idea generation ) , select one idea ( idea selection ) , and provide a list of deliverables involving idea detailing . I asked them to explore multiple ideas as it might facilitate in exploring multiple input actions . I asked them to select only one final idea to fill the deliverables due to the limited time of the session . Considering the RQ3 . 2 , “In what ways 47 do users think IdeaBits supports them to plan the technical implementation of the generated ideas ? ” , I asked the participants to plan the technical implementation of their final idea as a part of the deliverables . However , to reduce the possibility of restricting their ideas , especially during a short session , I asked them only to name the electronic components they would require to build a prototype of their final idea . Filling the four deliverables for the final idea may have several advantages . It may enable the participants to think through their idea and be sure about its various aspects . It may give them a sense of the essential aspects to focus upon and the expected level of detail . The deliverables would act as tangible records of the participants’ ideas , which they can use to explain their ideas during the interview . Also , the researchers can analyze the participants’ ideas using the deliverables and compare those across the participants based on the uniformity created . 4 . 5 . 3 . Changes from Pilot Studies Pilot participants found the session to be short for filling the deliverables for two final ideas . Hence , I decided to ask the participants to select only one final idea . Most of the pilot participants fixated on emoticons , maybe because emoticons are commonly used for communicating emotions [ 80 ] . Hence in the revised task , I asked the participants to avoid emoticons . When I did remote observation with the pilot participants , I found it very difficult to note the interactions with the GUI along with the timestamps , especially in cases of a series of quick interactions with the GUI . Hence I asked Pankaj to add a function to IdeaBits codes for automatically recording its activity log , including time stamps and durations . I did not mention the first three pilot participants that they could incorporate input actions in their ideas beyond the ones in IdeaBits . I made this decision in order to minimize the effect of instructions on the results since such instruction , instead of the tool , may encourage participants to explore multiple input actions or avoid design fixation . However , not providing the instruction led to confusion and misinterpretations by the pilot participants . They thought I expected them to use only the input actions in IdeaBits . Also , one of them asked me specifically to clarify if she could use other input actions . Hence in order to maintain uniformity across participants and avoid misinterpretations , I decided to mention explicitly , “You can incorporate any input action in your idea , and you are not restricted to the input actions in IdeaBits . ” 48 Some pilot participants mentioned that they were not able to get an idea of the objective of the study . Hence , I stated the goal of the study as “To understand how you use the prototype to design TUIs , with a focus on input actions . ” during the introduction and wrote it on the whiteboard in the user study room . For similar reasons , I also stated the goal of IdeaBits and its components during the introduction . Some of the pilot participants did not use IdeaBits during the session , mainly because I showed them multiple examples on the GUI and encouraged them to interact with multiple artifacts during the introduction . Hence , I decided to show examples of only one input action while encouraging them to interact with only one artifact from each set during the introduction , along with mentioning that they were expected to use IdeaBits during the design session . Some of the pilot participants mentioned their fear of breaking the sensor - enabled artifacts . Hence I decided to mention to the participants not to worry about breaking the sensor - enabled artifacts . For all instructions , I used specific language to minimize bias ( Appendix I ) . 4 . 6 . Data Collection RQ Data details Data type Analysis method RQ2 Observation and video recording 1 ) What they are doing ( e . g . , prototyping , sketching , etc . ) . 2 ) What they are using and how they are using it . ( e . g . , which artifact , TUI example ) 3 ) Anything unexpected that stood out . Interview questions Q 3 , 3 . 1 , and 4 . Audio Text Video Observation , video recording - Analyzed as a supplement for the interview data and the themes . Interviews – Two researchers did a thematic analysis . RQ3 Interview questions Q 5 , 6 , and 10 . Audio Text Video Interviews - Two researchers did a thematic analysis . RQ3 . 1 Deliverables Deliverable 3 . Interview questions Q 7 , 7 . 1 , 7 . 1 . 1 , 7 . 1 . 2 , 8 , 8 . 1 , 8 . 1 . 1 , and 8 . 1 . 2 . Audio Image Model Text Deliverables - Identified different types of input actions ( e . g . , commonly used in TUIs , present in IdeaBits , etc . ) and tallied their occurrences across the participants . Interviews - Two researchers did a thematic analysis . 49 RQ3 . 2 Deliverables Deliverable 4 . Interview questions Q 9 , 9 . 1 , 9 . 1 . 1 , and 9 . 1 . 2 . Audio Text Deliverables - Two researchers analyzed for completion , error , and feasibility . Interviews - Two researchers did a thematic analysis . RQ4 Observation and video recording 1 ) Technical malfunctioning . 2 ) Anything unexpected that stood out . Deliverables Deliverable 3 , and 4 . Interview questions Q 5 , 6 , 7 . 2 , 11 , 12 , 13 , and 14 . Audio Image Model Text Video Observation , video recording - Analyzed as a supplement for the interview data and the themes . Deliverables - I tallied across the participants the input actions and electronic components in the participants’ final ideas that are present in IdeaBits . Interviews - Two researchers did a thematic analysis . Table 4 . 1 Alignment table . The intention of the exploratory evaluation of the tool , IdeaBits , was to identify ways in which potential support can be provided to novice TIxD students for conceptualizing TUI ideas , especially generating input action ideas , along with things that should be looked out for or avoided . For the same , I used these three constructs : tool usage , support for conceptualizing TUIs , and challenges of using the tool . The collected data involved remote observation notes of the video recorded design sessions , screen recording of the GUI of IdeaBits , IdeaBits generated activity log , deliverables from the participants in the form of written sheets and sketches or models of their ideas ( Appendix F , K ) , video recorded semi - structured interviews ( Appendix J ) , and demographic data ( Appendix A ) . Next , I shall discuss what type of data I collected concerning the RQs and how I collected the data . 4 . 6 . 1 . RQ2 . Tool Usage The focus of RQ2 was to investigate how users used IdeaBits and its components to conceptualize TUIs . I used semi - structured interviews to ask them questions related to how they came up with their ideas and how they used IdeaBits for coming up with their ideas . For example , I asked , “Can you walk me through your process of how you came up with this idea ? ” . I used remote observation and video recording of the design sessions to collect data related to 1 ) what they were doing ( e . g . , prototyping , sketching , etc . ) along with a start and end timestamps , 2 ) what they were using ( e . g . , which artifact , modeling material , TUI example and it’s format , etc . ) , and 3 ) how they were using it . I also noted 50 anything unexpected that stood out in relevance to RQ2 . Based on my observations , I modified and added to the interview questionnaire when required . For example , during remote observation , I saw that one of the participants repeatedly opened and closed the scissors for a few minutes using both his hands . Hence , I made a note to ask him about why he was interacting with the scissors in that way . 4 . 6 . 2 . RQ3 . Support for Generating Tangible User Interface Ideas The focus of RQ3 was to investigate how using IdeaBits contributed to the user’s design process and outcomes for the design task . I used semi - structured interviews to ask them questions related to how they thought IdeaBits helped them . For example , I asked , “In what ways , if any , do you think IdeaBits helped you in doing the design task ? ” I also asked their preferences between the two sets of artifacts and among the formats of examples and the reasons for the same investigating what they found helpful . The focus of RQ3 . 1 was to investigate how using IdeaBits contributed to the exploration of a variety of input actions and beyond familiar ones . Using deliverables , I collected data related to the input action ideas the participants generated . I used semi - structured interviews to ask them questions related to how they generated input action ideas and how they used IdeaBits for generating these ideas . For example , I asked , “Can you walk me through how you came up with these input action ideas ? ” The focus of RQ3 . 2 was to investigate how using IdeaBits contributed to planning technical implementation for the user’s final idea . Using deliverables , I collected data related to the technical implementation plan they made by listing the electronic components they would require for building a prototype of their final idea . I used semi - structured interviews to ask the participants how they planned the technical implementation of their ideas and how they used IdeaBits to do so . For example , I asked , “Can you tell me what you did for planning the technical implementation of your final idea ? ” 4 . 6 . 3 . RQ4 . Challenges of Using the Tool The focus of RQ4 was to investigate any challenges and limitations faced by the users while using IdeaBits to do the design task . I used remote observation and video recording of the sessions to collect data related to technical malfunctioning and anything unexpected that stood out in relevance to RQ4 . Based on my observation , I modified and 51 added to the interview questionnaire when required . For example , during remote observation of one of the sessions , I saw that the GUI was not responding to the interaction with the sensor - enabled artifacts . I made a note to ask the participant during the interview about their experience related to it . To study design fixation , I collected data related to the input actions , outputs , and technical implementation plan of the participants’ final ideas through deliverables . I analyzed these deliverables looking for ( dis ) similarity with the possibilities introduced by IdeaBits . I used semi - structured interviews to ask the participants about the challenges they faced in doing the design task and while using IdeaBits . For example , I asked , “In what ways , if any , do you think IdeaBits hindered or limited you ? ” . I also asked their preferences between the two sets of artifacts and among the formats of examples and the reasons for the same investigating the challenges they faced while using IdeaBits . 4 . 7 . Data Analysis I was the main researcher to analyze the data while collaborating with two of my lab mates from TECI lab : Ofir Sadka ( M . A student ) and Victor Cheung ( postdoctoral fellow ) . Ofir analyzed with me the interview data of six out of the twelve participants , while Victor analyzed with me the deliverable data of four participants . The interview data were analyzed inductively using thematic analysis involving open coding , axial coding , and selective coding [ 21 , 36 , 94 ] . I transcribed all the twelve interviews from beginning to end into separate text files . Using NVivo software [ 131 ] , Ofir and I individually did open coding and axial coding of three and twelve interviews , respectively . We read each of the interview transcripts one at a time and did a line by line open coding . We aimed to be as inclusive as possible while ensuring that the codes have relevance to the RQs and objectives of the exploratory evaluation . We then individually did axial coding by organizing the codes obtained during open coding , based on the relations among them , into themes and subthemes . We also added definitions and descriptions for each of these themes and subthemes . After completing the analysis , we shared our NVivo files . I went through Ofir’s analysis and noted any doubts I had , the things that were similar to or different from my analysis , and the things I did not agree upon how they were analyzed . Similarly , Ofir studied my analysis . We then had a call to discuss our analysis of the data . We discussed 52 how we did the analysis , the descriptions and organization of the themes and subthemes along with their significance based on the confirming and disconfirming evidence coded in these themes , and the similarities and differences in the two analyses . Our analysis was mostly similar to each other except for how we named the themes , how we organized them into themes and subthemes in certain places , and one of us missed an important theme that was identified by the other . We created the final set of themes and subthemes by reorganizing some of them , merging the ones that had significant overlaps , adding a critical theme that the other had missed , and adding a “Miscellaneous” theme temporarily . We planned to use the Miscellaneous theme while analyzing the next interviews to code any evidence which did not fall in any of the themes but was significantly relevant to the RQs . We also renamed the themes and subthemes and refined their definitions and descriptions . We then individually analyzed the interview of one more participant ( I was analyzing this interview for a second time since I had analyzed all twelve participants initially ) using the themes we finalized . We were taking notes of if we found the themes to be inappropriate in any way or felt that making certain changes might be beneficial , along with noting any doubts we had . Similar to last time , after completing the fourth participant , we exchanged and studied each other’s analysis . I analyzed Ofir’s analysis to compare the pieces of evidence he coded in the themes with the ones I coded , along with making notes of any evidence that either of us missed or any evidence that did not make sense in the coded theme . I also looked for any new theme ( s ) arising from the Miscellaneous theme . Similarly , Ofir studied my analysis . We then had another call to discuss our analysis and the notes we made . Following this process , we analyzed two more interviews , making it a total of 6 interviews for Ofir . By discussing the pieces of evidence that were missed or coded in a theme where it did not make sense , we were able to refine our understanding of the themes and accordingly modified the theme names , definitions , and descriptions when necessary . As more pieces of evidence were coded , new subthemes emerged from some of the themes . Also , some pieces of evidence coded in the Miscellaneous theme emerged into new themes and subthemes . We merged the themes that started having significant overlaps . I then analyzed the interviews of the remaining six participants , which Ofir did not analyze , while making notes of if I found the themes to be unsuitable in any way or felt that making certain changes might be useful . Before making any changes , I discussed 53 them with Ofir . Throughout the analysis , when we made any changes to the themes , we revisited the already analyzed interviews for follow - up examinations . After I analyzed all twelve interviews , we discarded the pieces of evidence coded in the Miscellaneous theme from which no patterns emerged . I then wrote up the final themes based on the coded pieces of evidence . Finally , I did selective coding by choosing the illustrative participant quotes for each of the themes and subthemes . During the analysis of the interviews , I looked into the video recordings of the design sessions and the interviews , remote observation notes , and the task deliverables from the participants to get clarification for any part of the interviews that were ambiguous or had missing context . For example , there were instances during the interviews when the participants did not use verbal descriptions but rather simply demonstrated the input actions and pointed at certain things like the prototypes they made , the deliverable sheets , or the artifacts . I crosschecked participants’ interview responses , involving descriptions of the design session activities , with the video recording of the sessions to ensure validity . I also analyzed these data , after completing the analysis of the interviews , with a primary focus on looking for evidence that supported or was in discrepancy with the themes that emerged from the interview data , while having a secondary focus on any new emerging patterns and findings . In deliverable 3 , the participants listed the emotions , input actions , and outputs in their final idea . I analyzed the deliverable 3 data looking for the types of input actions and outputs in the participants’ final ideas while comparing it against 1 ) input actions and outputs in IdeaBits ; and 2 ) input actions not in IdeaBits that are ( not ) found commonly in everyday devices and TUIs . In deliverable 4 , the participants listed the electronic components required to prototype their final idea . Victor and I analyzed the deliverable 4 data examining for completion , feasibility , and errors . Victor and I discussed our analysis , after each of us did an individual analysis of 4 participants’ deliverable 4 , looking for similarities and differences . We found our analysis to be consistent with each other , and hence I alone analyzed the remaining 8 participants’ deliverable 4 . I also looked for the presence of the listed electronic components in the sensor - enabled artifacts . I chose to analyze the interview data as the primary data , while the remaining data as supplementary data due to several reasons . The limited scope of the project and its timeline made analysis ( by multiple researchers ) of multiple data types as the primary data 54 infeasible . The interview data was the only data that addressed all the research questions . During the interviews , by asking open - ended questions and probing , I collected rich and in - depth data related to the research questions . Also , based on the remote observation of the design sessions , I followed up with interview questions to investigate and clarify certain observations , as discussed earlier in this chapter . The video recording of the design sessions , other than addressing only two of the four research questions , was limited to only activities that could be seen while excluding the goals , thoughts , and experiences of the participants related to these activities . However , it contained genuine data of the session activities , as opposed to a retrospective account like the interview responses . Hence I utilized this data to crosscheck participants’ interview responses , as mentioned earlier . 55 Chapter 5 . Results In this chapter , I first discuss the results from the analysis of the deliverables ( Appendix K ) , and then the themes emerged from the analysis of the interviews . 5 . 1 . Analysis of the Deliverables The participants completed the design task in 21 to 68 minutes ( mean 49 , median 55 , mode 63 ) . In this section , I report the results from the analysis of deliverable 3 and 4 . In deliverable 3 , the participants listed the emotions , input actions , and outputs in their final idea . In deliverable 4 , the participants listed the electronic components required to prototype their final idea . Table 5 . 1 summarizes how many participants involved what type of input action in their final idea . For example , 4 participants involved only input actions from IdeaBits in their final idea . In comparison , 3 participants involved input actions from IdeaBits along with input actions from outside IdeaBits that are commonly found in everyday devices in their final idea . Number of participants 4 3 1 2 2 Input action in IdeaBits Yes Yes Yes No No Input action not in IdeaBits and commonly found in everyday devices No Yes No Yes No Input action not in IdeaBits and not commonly found in everyday devices No No Yes Yes Yes Table 5 . 1 Types of input actions in participants’ final ideas . The presence of the first two types of input actions from the above table in participants’ ideas may indicate the occurrence of design fixation . These two types of input actions were found to be present in a total of ten out of the twelve participants’ final ideas . Eight participants’ final ideas involved one or more input actions introduced by IdeaBits . These eight ideas together include all the five input actions introduced by IdeaBits . Squeeze and stretch input actions were the ones used by most of these participants ( five and four participants , respectively ) . Eight participants’ final ideas involved input actions , 56 not in IdeaBits . Out of these eight final ideas , five ideas involved input actions which are not commonly found in everyday devices and TUIs ( eight input actions in total , such as tear , wipe , twist ) , while five ideas involved input actions which are commonly found in everyday devices and TUIs ( five input actions in total , such as pressing button , touch , slide ) . There were a total of thirteen input actions in participants’ final ideas that were not introduced by IdeaBits . Each of these input actions occurred only once across the twelve final ideas , except for pressing a button and clenching fist found in three and two final ideas , respectively . Five participants’ final ideas had only visual output , four ideas had only tactile output , two ideas had visual and tactile output , and one idea had only auditory output . As many as eight participants’ final ideas involved auditory or visual output in their ideas , which is the type of output of the sensor - enabled artifacts . Only one participant listed the technical implementation for input actions correctly ( feasible technical implementation plan with no errors ) and completely ( all necessary components listed ) . One participant used ambiguous descriptions ( e . g . , “Sensor matrix for pull ( stretch ) detection” ) while four participants listed wrong electronic components to detect one or more input actions ( e . g . , conductive rubber cord to detect tear , pressure sensor to detect squeeze ) . Seven participants listed input action detection electronic components that do not exist ( e . g . , flexible sensor cords ) , out of which six participants named one or more components after the input actions or sensor - enabled artifacts ( e . g . , squeeze sensor ) . One participant did not mention technical implementation for input action in his final idea . Three participants used technical implementation not in IdeaBits to detect the input actions in their ideas , while they also used technical implementation in IdeaBits . In total , seven participants used technical implementation of the sensor - enabled artifacts to detect the input actions in their ideas . Five participants listed technical implementation for output in their ideas correctly and completely , out of which two participants involved only a display in the output . Two participants described ambiguously , while six participants did not mention the technical implementation for outputs in their ideas . 57 5 . 2 . Analysis of the Interviews In this section I report the seven themes that emerged from the qualitative analysis of the interviews : 1 ) Incorporating IdeaBits in the design process , 2 ) Hands - on interaction with IdeaBits , 3 ) Making design decisions , 4 ) IdeaBits introducing possibilities , 5 ) IdeaBits causing design fixation , 6 ) Challenges in using IdeaBits , and 7 ) Challenges in doing the design task . At the beginning of each theme , I shall provide a summary table to list the significant points in that theme in the order of their occurrence . I am using fictional names to refer to the 12 human participants , which may help the readers to build the personas based on the participants’ quotes . The male participants’ pseudonyms are Ben , Lee , Neil , Paul , Ross , and Ted ; and for the female participants’ are Amy , Eva , Jane , Kate , Maya , and Uma . While reporting the findings in this section and discussing them in Chapter 6 , I use the terms few , some , around half , most , and almost all of the participants to refer to two , three or four , five to seven , eight or nine , ten or eleven participants respectively . 5 . 2 . 1 . Incorporating IdeaBits in the Design Process To get inspiration , participants studied TUI examples and interacted with the modeling materials and artifacts . Some participants mentioned that they used IdeaBits when they found it challenging to do the design task . Using IdeaBits made few participants think about input actions actively and critically analyze the ones in IdeaBits . Table 5 . 2 Summary table for the theme “Incorporating IdeaBits in the Design Process” . In this theme , I describe how participants used IdeaBits to do the design task and how it influenced the overall design process and its outcomes . Participants used IdeaBits to get inspiration by interacting with modeling materials , artifacts , and studying TUI examples . Few participants perceived IdeaBits as an additional exploration tool and inspirational source . “ It [ IdeaBits ] was an additional exploration method , which , rather than hindering I suppose promoted , idea generation . ” - Ben . Some participants used IdeaBits for inspiration at the very beginning of the session , while some used IdeaBits after generating some ideas . “Initially , I knew what I’m going to do . But I wanted to just explore more . I wanted to make sure . ” - Amy . Studying TUI examples helped a few participants to shape the ideas they already had . “I was like thinking through the chessboard [ idea ] , and 58 then I looked over , and I was like , “Yes ! A foam chessboard . That would be fun . ”” - Jane . While few participants studied TUI examples to investigate how the input action in their idea is used in the industry . Some participants mentioned that they used IdeaBits when they found it challenging to do the design task due to not getting ideas and being unable to detail their ideas or make their ideas feasible . “ When I first started , I was just empty . So , I started looking at IdeaBits to get some more idea… When I was searching those [ modeling materials ] , I was trying to implement maybe something else or something better . Because I don’t know how to implement the how fast or how slow the motion [ input action ] . So , I was trying to think of something else . ” - Maya . Few participants were cautious not to fit IdeaBits in the design process forcefully and were unsure of how much they would use IdeaBits . “…trying to figure out how deep I would dive into the system [ IdeaBits ] . I didn’t want it [ IdeaBits ] to be sort of a forceful fit in the ideation process” - Jane . The focus of IdeaBits on input action and technical implementation influenced a few participants to generate ideas starting from input action or technical implementation , which is not how they usually generate TUI ideas . “But I also don’t think I ideate like this , where I start from an input action… it would be kind of , you come up with a concept , and you have an idea of like what the object could be . And then I would start to think about what is the input required for it . ” – Jane . Using IdeaBits made few participants think about input actions actively and critically analyze the ones introduced by IdeaBits . Interacting with IdeaBits for some time helped them to understand the differences between the different input actions that initially seemed to be the same . “ I never really thought about input interaction this much . It felt like pulling and bending is kind of similar , initially to me , but then it’s pretty different . ” - Neil . 59 Preferences Among Artifacts and Example Formats Most participants preferred sensor - enabled artifacts over physical - only artifacts , mainly because they had output and provided feedback . Having output enabled some participants to experience the reaction to their interaction with the sensor - enabled artifacts and to test their input action ideas . Being able to see an output when interacting with the sensor - enabled artifacts helped participants to understand how the sensors involved in the artifacts were working , believe that the associated input actions were implementable , and derive satisfaction from the interaction . The absence of output when interacting with physical - only artifacts made it difficult for some participants to imagine what possibly could be the output and application of the input actions . Few participants limited their interaction with sensor - enabled artifacts due to fear of breaking them . Some participants felt distracted by the popping up of the TUI examples when interacting with the sensor - enabled artifacts . Most participants preferred video format of examples because they felt it efficiently delivered information , and since they could simultaneously experience the input actions by interacting with the physical - only artifacts . Some participants preferred image format since they could view them quickly . Table 5 . 3 Summary table for the subtheme “Preferences Among Artifacts and Example Formats” . In this subtheme , I first describe participants’ preferences between the two sets of artifacts and then their preferences among the example formats . Most of the participants preferred sensor - enabled artifacts over physical - only artifacts , mainly because they had output and provided feedback . The absence of output when interacting with physical - only artifacts made some participants feel the interaction to be incomplete . The absence of output also made it difficult for the participants to imagine possible outputs and applications of the associated input actions . “I do not know how squeeze [ physical - only artifact ] would react when I squeeze it . Would it vibrate or light up or just do something ? ” - Amy . The presence of output in the sensor - enabled artifacts enabled some participants to experience the reaction to their interactions with the sensor - enabled artifacts . “ You can see right away how would they [ sensor - enabled artifacts ] react… Just to get an idea of how would it work gives you some satisfaction . ” - Amy . Some of them utilized the sensor - enabled artifacts to explore possible outputs of their input action ideas . For example , when Ross could not imagine what possibly could be the output of stretch input action in his concept , stretching the stretch sensor - enabled artifact to see how it reacted helped him get ideas . “While I was making the prototype , I didn’t know how this stretching chord [ in his model ] would work . So , I just stretch it [ stretch sensor - enabled artifact ] and see how it 60 would react on screen . So ya , that’s much more effective than using these [ physical - only artifacts ] . ” - Ross . Having output also allowed a few participants to test their input actions , the detection of variations of the input actions introduced by IdeaBits , and the sensitivity of the sensor - enabled artifacts . For example , Ted squeezed the squeeze sensor - enabled artifact in multiple ways to see which of those were detected by IdeaBits as inputs . “I like those [ sensor - enabled artifacts ] just coz I can see at which point does it work . I kind of diagnosed what’s happening a bit . Like this one [ squeeze sensor - enabled artifact ] , I squeezed it in different ways and be like , “Is it that [ squeezed in a particular way ] or did that [ squeezed another way ] work ? ”” - Ted . Being able to see an output when interacting with the sensor - enabled artifacts also helped participants to understand how the sensors involved in the artifacts were working , believe that the associated input actions were implementable , and derive satisfaction from the interaction . “That one [ sensor - enabled artifacts ] works better because I can see the output and how the sensors are being used… When I can see the output , I know that the computer [ IdeaBits ] gets it . ” - Neil . Some participants preferred sensor - enabled artifacts because they found their input - output mapping interesting . “It’s so interesting that when I touch it [ sensor - enabled artifacts ] , the computer knows I want to know something more . So , it pops up this thing [ associated example page ] . ” - Maya . They mentioned that being able to control the GUI with the sensor - enabled artifacts made them interactive and thus enjoyable to interact with . “When you interact with these objects [ sensor - enabled artifacts ] , you can still pause and play the video . You can interact with any of the objects [ sensor - enabled artifacts ] , and then it will display that particular section [ associated example page ] . So , it creates like more of an interesting factor as to , “Okay , I do this [ interact with a sensor - enabled artifact ] , and something changes digitally . ”” - Ben . However , few participants limited their interaction with the sensor - enabled artifacts due to fear of breaking them . “I am afraid I may break them [ sensor - enabled artifacts ] . ” - Uma . Hence they chose to instead interact with the physical - only artifacts . “Because I know I couldn’t break them [ physical - only artifacts ] , so I played around with them a little bit more . ” - Ted . Some participants preferred the physical - only artifacts also because they found it easier to interact with , compared to sensor - enabled artifacts , to experience the input actions while generating ideas . “ I can easily manipulate them [ physical - only artifacts ] and feel them when I’m generating ideas . ” - Uma . Some of them felt distracted by popping up of the TUI examples when interacting with the sensor - enabled artifacts , not letting them 61 focus on experiencing the input actions . “I can focus more on the interaction and how it works in different situations [ when interacting with physical - only artifacts ] , instead of having all the videos and images and everything else just associated with one thing . ” – Eva . Most participants preferred the video format of examples because they felt that it efficiently delivered information such as demonstration of the input action , input action application , and explanation of technical implementation . “With the video , you can see like , how they’re going to do the interaction . ” - Eva . Few of them preferred video since they could simultaneously experience the input actions by interacting with the physical - only artifacts . “I can just play the video and then still feel this [ physical - only artifact ] and then think . ” - Uma . Some participants mentioned having found colored bars with the video player , which indicated different sections of the video , to help skim the videos . “ I like how these different portions [ indicated by colored bars ] filtered out for like , the system , manipulation , implementation . Because then I can jump straight to those . ” - Eva . Few participants used only the video format since they found it sufficient to study the TUI examples . “I just looked at the videos . And I was like , “Okay , got it . ”” - Jane . Some participants preferred the image format as it was fast to view them . “ [ I prefer ] Images , coz even for the video , I was skipping so I can go through it faster . ” - Kate . Participants who referred to paper did so to look at the images or find technical implementation information . “For the paper , I just kind of skimmed . It’s very technical . I tried to get some more technical information , like how they implemented this system [ the TUI example ] , and what sensors they were using . ” - Paul . Participants who did not refer to papers mentioned reasons such as words being inefficient in describing input actions , and reading papers being time - consuming . “The paper is least useful . You cannot describe how this thing [ input action ] is gonna be used in words only . ” - Ross . Few participants mentioned that they would prefer paper to know existing work related to the input actions if they had an objective of research contribution towards the input action . “If the focus of your design is more to provide like a contribution on folding technologies , then the paper would be way more important . ” - Jane . 62 5 . 2 . 2 . Hands - on Interaction with IdeaBits Interacting with sensor - enabled artifacts and modeling materials inspired most of the participants with ideas . Interacting with the artifacts helped around half of the participants to experience the associated input actions and input - output mapping , which helped them to get ideas . Some of the participants interacted with IdeaBits artifacts and modeling materials playfully , which helped them to think and get ideas . Few participants interacted with the artifacts in ways beyond the prescribed input actions associated with them . Such explorations helped them to get input action ideas beyond the ones introduced by IdeaBits . Interacting with the sensor - enabled artifacts helped few participants to think beyond the TUI examples . Similarly , interacting with the modeling materials helped few participants to get ideas for the application of the input actions in IdeaBits beyond how they had been implemented in the artifacts . Getting output when interacting with the sensor - enabled artifacts facilitated participants to experiment with a variety of input actions while encouraging them to check which of those were detected . Some of the participants interacted with the modeling materials to uncover the input actions they could afford . This helped them to get ideas . Around half of the participants interacted with sensor - enabled artifacts to understand their function , input - output mapping , and technical implementation . Getting an output helped them to understand these aspects . Hands - on explorations helped a few participants to figure out the technical implementation of the sensor - enabled artifacts . This helped them to get technical implementation ideas . Table 5 . 4 Summary table for the theme “Hands - on Interaction with IdeaBits” . In this theme , I describe how participants interacted with artifacts and modeling materials and how it helped them to get ideas , experience input actions , go beyond the introduced possibilities , and understand the sensor - enabled artifacts ( function , input - output mapping , and technical implementation ) . Some participants intentionally interacted with sensor - enabled artifacts and modeling materials to get ideas for overall concepts , input actions , and outputs . For example , Ross interacted with the stretch sensor - enabled artifact to get output ideas for stretch input action in his idea . Interacting with sensor - enabled artifacts and modeling materials inspired most of the participants with ideas for overall concepts , input actions , outputs , input - output mappings , and technical implementation . Since the sensor - enabled artifacts had output , interacting with the sensor - enabled artifacts helped some participants to get ideas for output and input - output mapping . “I was just playing around with these [ sensor enabled artifacts ] to see how they react , see how they communicate values to the program [ GUI of IdeaBits ] , which means pause and play the video . So yeah , just based on that idea , I came up with [ the output idea of ] sending values , so that people would know what the other person is trying to communicate once the value reaching a certain threshold . ” – Neil . Interacting with the IdeaBits artifacts helped around half of the participants to experience the associated input 63 actions , which helped them to get ideas involving those input actions . “You provided all the sensors here so I can touch and feel and just play with it and see how it works . So that’s my thing . ” – Paul . Some of the participants interacted with IdeaBits artifacts and modeling materials playfully , which helped them to think and get ideas . “I fiddle a lot . It might be a subconscious thing , where it does help me generate ideas… It was helpful to have a lot of stuff [ artifacts and modeling materials ] here that you could mess around with . ” – Ted . For example , Ted built some models using the modeling materials to play with them , which was not intended towards solving the design task . However , doing so helped him get ideas for the design task . “I made this loop [ using twist tie ] , not that I needed a twist tie or anything . I just have always liked doing this [ pulling twist tie after making it into a loop ] . ” – Ted . Few participants interacted with both sensor - enabled artifacts and physical - only artifacts in ways beyond the prescribed input actions associated with them . Getting an output when interacting with the sensor - enabled artifacts facilitated these participants to experiment with a variety of input actions , while driven by their curiosity to check which of those would be detected by IdeaBits as input actions . For example , Ted tried squeezing the squeeze sensor - enabled artifact in different ways , including patting it . Doing so gave him an input action idea , hit , which is not among the five input actions introduced by IdeaBits . Interacting with the sensor - enabled artifacts helped few participants to think beyond the TUI examples . Similarly , interacting with the modeling materials helped few participants to get ideas for the application of input actions in IdeaBits beyond how they had been implemented in the artifacts . “That [ slide input action idea ] was something that just popped out while playing with the material [ modeling materials ] . And then I thought like , “Okay , so , I was probably thinking in a very limited scenario . It [ sensor - enabled artifact ] is beyond what it looks like it . ”” – Amy . Some participants interacted with the modeling materials to uncover the input actions they could afford , which helped them to get ideas . “ I was looking at the materials [ modeling materials ] to see what all interactions I could do with them . ” – Neil . Similarly , a round half of the participants interacted with sensor - enabled artifacts to understand their function , input - output mapping , and technical implementation . “I did play around with these [ sensor - enabled artifacts ] to get across what they do . ” – Neil . Getting output when interacting with the sensor - enabled artifacts helped them to understand these aspects of the artifacts . Few participants experimented with the sensor - enabled artifacts to figure out 64 their technical implementation . For example , Lee used a metal ruler to touch the copper tapes on the fold sensor - enabled artifact to see if it detected fold input action without actually folding the artifact . Doing so helped him understand that fold input action in the artifact was detected when the copper tapes came in contact . “Using this [ metallic ] ruler , I was thinking about ways to do that [ connect the copper tapes in the fold sensor - enabled artifact ] . And then I was thinking , “Hmm , if you are sad , you might cry , right ? Oh , wait , there is a tear coming with salt , which is also a conductor . ”” – Lee . Such explorations helped participants to get technical implementation and input - output mapping ideas . Interacting with the sensor - enabled artifacts helped some participants to realize the shortcomings of the artifacts , based on which they chose from among the five input actions introduced by IdeaBits to incorporate in their ideas . “This one [ fold sensor - enabled artifact ] , it just have really destructive pattern . I don’t know how hard it can afford ; this [ folding in the opposite direction ] might break the stuff , right ? And stretch , I think , is more durable . ” – Ross . Prototyping and Testing Ideas Few participants used the “Tech” button and interacted with sensor - enabled artifacts to know the technical feasibility of their input action ideas . Few participants realized issues in their ideas while interacting with the artifacts and their prototypes . Building prototypes and interacting with those helped some participants to get ideas for input actions , outputs , and technical implementation . Some participants tried to prototype using the artifacts . Table 5 . 5 Summary table for the subtheme “Prototyping and Testing Ideas” . In this subtheme , I describe how participants used the artifacts and modeling materials to build prototypes and test their ideas , and how it helped them . Participants used IdeaBits artifacts , the “Tech” button , and modeling materials for building prototypes and testing their ideas . Few participants used the “Tech” button and interacted with sensor - enabled artifacts to know the technical feasibility of their input action ideas . “I was wrapping it [ stretch sensor - enabled artifact ] around my finger and see if I stretched , whether this [ detection of clench fist ] happens . ” - Lee . Few participants realized issues in their ideas while interacting with the artifacts and their prototypes , which helped them iterate their ideas . “ I was trying to make like , this face [ of the squeeze physical - only artifact ] would create one emotion . But when I push this face , the other face would be pushed as well . This is not effective . ” – Ross . 65 Some participants got new ideas for input action while prototyping using the modeling materials . “I did not thought about this [ bead ] sliding down until I put it in [ the pipe cleaner ] , and then I’m like , “Okay . Now it can slide down . ”” - Amy . Interacting with the prototypes helped some of the participants to get ideas for input actions , outputs , and technical implementation . “I was thinking about how to make the [ input action for ] sad one [ emotion ] because it is little bit hard . Originally , I was thinking using color . But when I make this humanoid [ prototype ] , I was bending it , and I was , “Oh , this [ bending the humanoid ] can also be [ input action for ] sad . ”” - Uma . Some participants tried to build prototypes using the physical - only artifacts . “Having some of the same materials that these [ physical - only artifacts ] are made of over here [ modeling materials ] that I could use , like helps quite a bit . ” - Ted . While a few participants desired to prototype using the sensor - enabled artifacts since they found it challenging to build from scratch . For example , few participants changed input actions in their ideas when they found it challenging to build prototypes using the modeling materials . “First , I tried to make something squeezy . So , I tried to make with the playdough [ modeling material ] . But unfortunately , I couldn’t . Because playdough is too sticky and get all over the paper . ” - Ross . Participants speculated that by using sensor - enabled artifacts as the base to start with , they might be able to develop better ideas that would go beyond the artifacts . Some of them suggested making the sensor - enabled artifacts pluggable to enable them to prototype . “ If they [ sensor - enabled artifacts ] are pluggable , then they could also be extended if there is something new . ” - Jane . 66 5 . 2 . 3 . Making Design Decisions Around half of the participants made design decisions , mostly related to input action , based on their personal preferences , even though some of them were generating ideas for people in general rather than for themselves . Few participants who were designing for themselves made design decisions based on their existing habits around communicating emotions . Around half of the participants chose input actions based on the physical actions they themselves did or thought someone would do when experiencing the emotions being communicated . Around half of the participants chose input actions and output based on the representations they associated with the emotions or the input actions . Few participants tried to generate novel input action ideas and overall concepts by differing from existing products . Around half of the participants made design decisions related to input action with the focus to ease the use of the product . Around half of the participants made design decisions related to input action and overall concept by trying to fulfill self - judged user needs and preferences . Some participants made certain design decisions to minimize their effort in doing the design task . Few participants were not sure about the rationale behind some of their design decisions . Table 5 . 6 Summary table for the theme “Making Design Decisions” . In this theme , I describe how participants made design decisions related to the overall concept , input action , output , and technical implementation . They made such decisions based on their personal preferences , existing habits around communicating emotions , and actions and representations they associated with the emotions . Based on their self - judgment , they tried to come up with ideas that were novel , easy and interesting to use , and catered to assumed user needs and preferences . Around half of the participants made design decisions , mostly related to input action , based on their personal preferences , even when some of them were generating ideas for people in general rather than for themselves . Participants found some of the input actions to be interesting when they interacted with the artifacts and studied the TUI examples . Hence they decided to incorporate these input actions in their ideas . “When I saw them [ sensor - enabled artifacts ] , I knew that somehow I’m gonna use this [ squeeze input action ] because I love that feeling , I love doing that [ squeezing ] . ” - Amy . “When I was playing around with the digital artifact [ sensor - enabled artifacts ] , and when I try the bend one , and I saw the [ TUI ] example , and I immediately think , “I’m gonna use that [ bend input action ] , ” because that is really interesting . ” - Uma . Few participants who were designing for themselves made design decisions based on their existing habits around 67 communicating emotions . For example , Jane was used to communicating emotions with her mother by talking about what happened in her day . She was not used to communicating emotions in terms of the six discrete basic emotions . Hence in her idea , she involved conveying emotions in the form of recorded messages . “ In a message like this [ in her alarm clock idea ] , you could say like , “Hey ! I had a good day . ” I don’t really talk to my mom about emotions in these terms [ the basic emotions listed in the design task ] . It’s more like what happened . ” - Jane . Around half of the participants chose input actions based on which physical actions they themselves did or thought one would do when experiencing the emotions being communicated . “I wanted stuff that you kind of naturally do when you’re angry… When I’m scared or nervous , I fidget a lot . Based on that , I have this [ input action ] idea of twisting up . ” - Ted . Around half of the participants chose input actions and output based on representations they associated with the emotions or the input actions . For example , Maya chose to have stretch input action in her idea because while she was stretching a slinky from the modeling materials , she associated the act of stretching with separating the partners from each other . “I was trying to do something , and I kind of come up with a tension from the spring [ slinky in modeling materials ] . It ' s like pulling [ the partners ] from each other . ” - Maya . Some of them associated opposite states of input actions with emotions they felt were opposite . “So , I felt happy and sad would be easy to communicate because they’re the complete opposites . So , if happy means this [ slinky from modeling materials ] being in its initial state [ not stretched ] , sad could mean this being complete stretched out . ” - Neil . Few participants tried to generate novel input action ideas and overall concepts by differing from existing products . For example , Ross incorporated pull input action as he felt people usually interact with everyday devices by pushing or pressing buttons . Around half of the participants made design decisions related to input action with the focus on ease of use . They minimized input actions while involving non - prescriptive ones to facilitate learnability and memorability . For example , Eva thought involving only one input action , pulling grass , would make it easy for users to remember how to interact with it . However , to connect the input action with different emotions , she based it on the way the grass was pulled with respect to the number of grass blades being pulled , force applied , pulling direction , etc . “ I just decided to go with pulling as a one [ input ] action thing , because too many actions is too many to remember . ” - Eva . Some participants focused on the ease 68 of doing the action and whether the action could ease the negative emotion being experienced . For example , Paul thought that bend input action , when done several times consecutively , would help the user ease their negative emotion . “I feel sad today , so I’ll just do it [ bend input action ] over and over and over again . It kind of relieves your stress or anxiety or your negative emotions . ” - Paul . Around half of the participants made design decisions related to input action and overall concept by trying to fulfill assumed user needs and preferences . Few participants considered it essential to involve haptic output to address the needs of people with visual or auditory challenges . Some of them came up with ideas for the overall concept based on what they thought the users might prefer to use . For example , Lee chose his idea of a glove and rejected his idea of a mask because he thought users would prefer wearing gloves over a mask . “This is a real device , right ? More people will be more willing to wear a glove than wear some type of mask . ” - Lee . Also , some participants tried to make their ideas interesting to use for the users . For example , Paul found it interesting to interact with the sensor - enabled artifacts only for an initial couple of times . Hence he tried to come up with ideas which the user would be interested in interacting with even over a longer period . “For something like this [ sensor - enabled artifacts ] , well , it’s very interesting for you to use like for once . But it’s not an object , right ? ” – Paul . While some of them drew inspiration from activities that they found interesting to do in their past . For example , Kate made her idea similar to an interactive installation in a science museum , which she found to be interesting . " I saw those bricks [ wooden cubes in modeling materials ] , and it reminded me of Science World [ a Science Museum ] where I see all the kids pushing and then that [ pushed block ] go to the other side . Super cool ! So I think maybe that will be fun too . ” - Kate . Some participants tried to include multiple variations of the input actions in their ideas to add depth in the communication . “At first , it was just push . And then to add more to it , I was thinking maybe like the different pressures , like how much you can push out , so there’s more depth . ” - Kate . Some participants made certain design decisions to minimize their effort in doing the design task . “I had to choose another emotion . I felt angry would be the easiest to communicate over this [ idea I was pursuing ] . ” - Neil . Few participants were not sure about 69 the rationale behind some of their design decisions . “ I don’t know why I put buzz ; I don’t know . ” - Maya . 5 . 2 . 4 . IdeaBits Introducing Possibilities Participants mentioned that IdeaBits introduced possibilities related to input action and its applications , input - output mapping , and technical implementation . Introducing possibilities helped participants to generate ideas quickly , get input action ideas beyond input actions usually found in everyday devices , and recall and think beyond their prior TIxD experience . Introducing multiple possibilities helped participants to understand the introduced concepts and open their minds to alternatives . Affordances of modeling materials inspired input action ideas . Around half of the participants mentioned that TUI examples introduced possibilities related to applications of the introduced input actions in TUIs . Some of them mentioned that they could not understand the same by only interacting with the artifacts . Participants mentioned that sensor - enabled artifacts introduced possibilities of input action , input - output mapping , and technical implementation . Some participants mentioned that the “Tech” button introduced techn ical implementation possibilities . Around half of the participants wanted to be introduced to more input actions and associated artifacts , TUI examples , and technical implementation . Table 5 . 7 Summary table for the theme “IdeaBits Introducing Possibilities” . In this theme , I describe the possibilities that participants perceived to be introduced by IdeaBits , along with the benefits of introducing such possibilities . Participants mentioned that IdeaBits introduced possibilities related to input action and its applications , input - output mapping , and technical implementation by providing artifacts , modeling materials , TUI examples , and technical implementation guidance . Introducing possibilities helped participants mainly in four ways – 1 . To generate ideas quickly by providing inspiration . “ It [ TUI examples ] gives me kind of inspiration… Otherwise , I’ll have a rough start . I will spend maybe 15 more minutes just to come up with a second concept . ” – Paul . 2 . To get input action ideas beyond input actions usually found in everyday devices ( e . g . , touch , button press , etc . ) . “IdeaBits suggest me some kind of interaction more than like these simple phone interactions like push the button and touch sensor . So yeah , that’s pretty good . ” – Ross . The ideas generated by a few participants before using IdeaBits did not involve TUIs but rather everyday devices involving touch screens . Interacting with the sensor - enabled artifacts helped them come up with ideas involving TUIs . “Interacting with this sponge mechanism [ squeeze sensor - enabled artifact ] 70 helped me create the idea that was a bit more , I would say tangible . ” - Ben . However , few participants felt being forced by IdeaBits to involve TUIs in addressing the given problem statement , while they did not consider TUIs as the most efficient means of communicating emotion over distance . “When you try to communicate , like video calling , you get to use filter and everything else . I want to make something more like that because I think that is effective . But only what I have it’s here [ artifacts ] . ” – Ross . 3 . To recall prior TIxD experience . “I haven’t done this kind of stuff for a long time since I TAed [ was a teaching assistant in ] this [ TIxD ] course . So I kind of forgot a lot of stuff . So while I went over all the videos and papers , it kind of give me another hint , “That’s one way to do it . ”… Your demo here definitely gave me a lot of inspiration . It refreshes my memory , like how those things [ sensors ] work . ” – Paul . 4 . To think beyond prior TIxD experience . “I do tangible [ interaction design ] , like , I haven’t seen a lot of these interactions . And so it was helpful to kind of expand my mind out of like , the typical stuff , to see different ways of using these sensors . ” - Ted . While introducing multiple possibilities helped participants to understand the introduced concepts , and open their minds to alternatives . “The videos really helped me open my mind because I can see different examples , like what can be implemented . ” – Uma . Affordances of the modeling materials inspired a few participants with input action ideas . “When I saw this rubber band [ modeling materials ] , then I immediately think I can put it here [ shoulder of the humanoid model ] because [ then I can ] stretch [ demonstrating stretching of the humanoid arms ] . ” – Uma . Few participants mentioned that by studying TUI examples , they found possibilities that they could implement , as is or a variation of it , in their ideas . “While I was watching videos and I was like , “This can be incorporated , this can be incorporated , a variation of this could be part of it . ”” - Amy . Around half of the participants mentioned that TUI examples introduced possibilities related to the application of the introduced input actions , which helped them to understand how to incorporate the input actions in TUIs . Some of them mentioned that they could not understand the same by only interacting with the artifacts . “ I saw this [ pull sensor - enabled artifact ] , I was like , “ [ while interacting with it ] Okay , cool . ” I’m not really sure what’s happening or how this is working . But then when I saw those video examples , I was like , “Oh , that makes lot more sense . ” So a way to quickly show how these very 71 simple things [ sensor - enabled artifacts ] can transfer into full - fledged applications , that helps a lot . And that did help me . ” - Ted . “Sponge [ pointing at squeeze physical - only artifact ] is a very malleable object . You can squeeze it in any form or create it into any form possible . And watching the video [ of the TUI example ] on the squeeze [ input action ] , it helped me create , “Okay , a jacket could be a better one . ”” - Ben . TUI examples helped some participants to study how the introduced input actions have been incorporated in TUIs beyond IdeaBits , especially in the industry . “You have the ideas [ TUI examples ] created by other people as well . You can go into what this object [ artifact ] can do more than what does the person actually thinks they’re limited to . ” - Ben . Few participants mentioned that understanding how to integrate the input actions in TUIs helped them combine input action possibilities with the medium possibilities to get ideas for being used in specific contexts . “I got to see those projects [ TUI examples ] from the universities… It was inspiring to see people put those different interactions [ input actions introduced by IdeaBits ] into those projects . It helped me with this part , where I was deciding , “Okay , so there’s this interaction , and there’s this medium . How do I make it work and give it some kind of theme ? ”” - Eva . Participants mentioned that sensor - enabled artifacts introduced possibilities of input action , input - output mapping , and technical implementation . Since the sensor - enabled artifacts involved output , it introduced a few participants to input - output mapping possibility when they interacted with the artifacts . Some of them wanted the artifacts to have different types of output since it would then introduce multiple input - output mapping possibilities . “I think it would be cool to have different interactions that do like different output . ” - Kate . Technical implementation of sensor - enabled artifacts introduced technical implementation possibilities . “I know there’s a lot of sensors out there ; there’s probably thousands . But I don’t know about all of them . So , but just by looking [ at the sensor - enabled artifacts ] , I was like , “Mmm . ” This give me some ideas . ” - Lee . Introducing technical implementation possibilities helped a few participants to recall their previous knowledge related to sensors . “It [ sensor - enabled artifacts ] provided me a lot of ideas on the sensors . Even though I probably know these sensors , but I might not be able to think about it at the moment . It might take me a lot longer to come up with this [ deliverable 4 ] . But just by looking , I was like , “Oh , there’s this sensor . That’s right . I could definitely use this . ”” - Lee . Sensor - enabled artifacts introduced a few participants to different ways of implementing some familiar sensors . “ I’ve seen force sensors [ pointing to bend sensor - 72 enabled artifact ] , but I hadn’t seen it used quite that way . ” - Ted . Some of the participants mentioned that they were not able to understand the technical implementation of the sensor - enabled artifacts where the involved sensors were not visible , such as the pull artifact and the squeeze artifact . “I think maybe it could be nice , for example , this device [ pull sensor - enabled artifact ] , making maybe through a transparent surface so we can see what’s going on . Same may be here [ squeeze sensor - enabled artifact ] . ” - Lee . Some participants mentioned that the “Tech” button also introduced them to technical implementation possibilities . They used the “Tech” button to plan technical implementation and check the technical feasibility of their idea and the involved input actions . “ One of the first things I did was look at the website [ “Tech” button ] for how they [ a TUI example ] did the folding . I wrote down [ for deliverable 4 ] kind of what was in there . And then I kind of thought about , “Okay , so it would also need a microphone and a speaker . ”” - Jane . “I was trying to figure out like , how would it [ my idea ] work ? Because sometimes you have an idea in your mind , but you don’t know if it would work . ” - Maya . Some participants also used the “Tech” button to understand the technical implementation of sensor - enabled artifacts and identify whether the artifacts’ sensors involved analog or digital data . “ I clicked on the tech component [ “Tech” button ] to understand how the thing [ sensor - enabled artifact ] is working . ” - Neil . “I really like this tech component [ “Tech” button ] . It’s very useful . It shows the main components you can use and how to use them , and more importantly , what kind of data you’re using . Is it a numerical data or is it just a binary data like zero and one ? I think this kind of instruction is very helpful . ” - Paul . Introducing technical implementation possibilities helped some participants to plan the technical implementation of their ideas . Not all the introduced possibilities were new for the participants . Also , around half of the participants wanted to be introduced to more input actions and associated artifacts , TUI examples , and technical implementation . They wanted more possibilities since those helped them in the design task and gave them ideas . Some of them speculated that providing more possibilities may help them to generate a wider variety of input action ideas and reduce design fixation ( more details in the theme “IdeaBits causing design fixation” ) . While seeking more possibilities , a few participants went beyond IdeaBits and used Google search [ 132 ] . “I was using the internet [ Google search [ 132 ] ] because during my design , I was thinking , “Those are the provided components [ artifacts ] for interaction 73 methods . But are there different sensors I can use to enrich my interaction experience ? ”” - Paul . 5 . 2 . 5 . IdeaBits Causing Design Fixation In this theme , I describe how IdeaBits caused design fixation by inspiring ideas similar to the possibilities it introduced and how the participants even tried to incorporate these introduced possibilities in their ideas . At last , I discuss instances when IdeaBits inspired ideas different from the introduced possibilities . IdeaBits Inspired Similar Ideas Most of the participants felt that IdeaBits helped them to get ideas , but the ideas were influenced by and similar to the possibilities introduced by IdeaBits . Some participants mentioned that the sensor - enabled artifacts inspired input action ideas that were the same as those involved in the artifacts . Sensor - enabled artifacts inspired input action ideas that were heavily influenced by the particular designs of the artifacts , rather than considering more extensive integration possibilities of the input actions . Some participants mentioned that their ideas for output were inspired by and similar to the TUI examples . Some participants mentioned that their technical implementation ideas were inspired by and identical to the technical implementation of the sensor - enabled artifacts even though most of these ideas involved input actions that were different from those in the artifacts . Few participants mentioned that their ideas were inspired by and similar to inspirational sources outside of IdeaBits . Table 5 . 8 Summary table for the subtheme “IdeaBits Inspired Similar Ideas” . In this subtheme , I describe how the artifacts , TUI examples , and technical implementation information inspired ideas similar to the inspirational source with respect to overall concepts , input actions , outputs , and technical implementation . Most of the participants felt that IdeaBits helped them to get ideas , but the ideas were influenced by and similar to the possibilities introduced by IdeaBits . “I feel like if you guys provide these [ IdeaBits artifacts ] , what we will come up with definitely be really similar . Because we started from there… Having those [ IdeaBits ] , I think it really helps . But the disadvantage would just be , it will be really similar . ” – Maya . “I definitely was framed by that [ IdeaBits ] when I was thinking about that [ design task ] … If you’re in an empty room , it’s not very inspiring , right ? There’s probably no ideas coming up . But if you’re in a room with like , a bunch of you know pasta , you’re probably going to think of pasta ideas . I think it’s [ IdeaBits is ] both inspiring and limiting . ” – Jane . 74 Figure 5 . 1 StretchEBand [ 104 ] ( left ) and Maya’s final idea of a smartwatch ( right ) . Few participants mentioned that IdeaBits influenced the overall concept of their ideas , which was similar to the inspirational source . For example , Maya’s final idea , involving a smartwatch , was inspired by and very similar to the TUI example for stretch input action ( StretchEBand [ 104 ] , Figure 5 . 1 ) . “I saw that example [ StretchEBand ] . And then I think I got it right away . ” - Maya . Some participants mentioned that the sensor - enabled artifacts inspired input action ideas that were the same as those involved in the artifacts . For example , interacting with the fold sensor - enabled artifact inspired Jane and Ted with ideas involving fold input action . “ I kind of tried a few of those [ sensor - enabled artifacts ] . And the folding [ the fold sensor - enabled artifact ] reminded me of tucking someone in… I thought it would be interesting to have an alarm clock that when you’re setting it , you fold it closed . ” – Jane . Also , some participants who incorporated input actions introduced by IdeaBits did so in a way very similar to the prescribed way of interacting with the artifacts . For example , Eva’s idea involved squeezing a flower model using one hand , in a way similar to the prescribed way of interacting with the squeeze sensor - enabled artifact ( Figure 5 . 2 ) . Figure 5 . 2 Eva’s drawing illustrating the squeeze input action in her final idea ( left ) , prescribed way of interacting with the squeeze sensor - enabled artifact ( right ) . 75 Some participants mentioned that their ideas for output were inspired by and similar to the TUI examples . For example , the output in Uma’s final idea was inspired by and very similar to the TUI example for bend input action ( TwistBlocks [ 105 ] ) , where changes made to the form of the physical model are reflected in a corresponding digital model . Sometimes this happened even when the input actions in their ideas were different from the ones in the TUI examples . For example , the TUI example for squeeze input action ( Tessella [ 18 ] ) inspired Kate to include light as an additional output in her idea , similar to the lights in Tessella . Her idea , however , did not involve squeeze input action . Some participants mentioned that their technical implementation ideas were inspired by and identical to the technical implementation of the sensor - enabled artifacts even though most of these ideas involved input actions that were different from those in the artifacts . For example , technical implementation for the clench fist input actions in Lee’s final idea was based on and similar to the technical implementation of the stretch and the fold sensor - enabled artifacts . “ I would say the majority of these [ answer to deliverable 4 ] is pretty much based on those [ sensor - enabled artifacts ] . ” - Lee . Few participants mentioned that their ideas were inspired by and similar to inspirational sources outside of IdeaBits . For example , the overall concept of a glove in Paul’s final idea was inspired by and similar to a TUI ( Flex - N - Feel [ 89 ] ) he came across earlier . 76 Trying to Incorporate from IdeaBits Almost all the participants tried to incorporate input actions and technical implementation possibilities introduced by IdeaBits . Some participants mentioned that being introduced to the artifacts , input actions , and TUI examples as a set of possibilities made them focused on those while making it challenging to think of other possibilities . The presence of the sensor - enabled artifacts in functioning condition , along with associated technical implementation information , gave a few participants confidence in the feasibility of their ideas that involved input actions from the artifacts . Some participants felt they were expected to incorporate the input actions introduced by IdeaBits , even though they also mentioned understanding the given instruction that they were not constrained to the five input actions introduced by IdeaBits . Few participants mentioned that they tried to incorporate input actions introduced by IdeaBits since they did not have enough time to think beyond those . Few participants tried to incorporate the technical implementation of the sensor - enabled artifacts when they were unable to plan technical implementation for their ideas . They even changed the input actions in their ideas to be able to use the technical implementation of the artifacts . Few participants tried to incorporate the technical implementation of sensor - enabled artifacts to minimize effort . Table 5 . 9 Summary table for the subtheme “Trying to Incorporate from IdeaBits” . In this subtheme , I describe how and why participants tried to incorporate from IdeaBits . Almost all the participants tried to incorporate input actions and technical implementation possibilities introduced by IdeaBits . However , around half of them mentioned that at times , they could not get ideas for how they could incorporating those possibilities into their ideas . “Ya , it hindered me coz as I said before , it’s [ IdeaBits is ] distracting . Because I’ll have to try to make all my ideas based on what I have over here [ artifacts ] . Like each of it . Although not all of it is useful . This thing [ squeeze physical - only artifact ] , I spent a good time trying to explore this . But it doesn’t work in the end , right ? So it kind of hinder me . ” - Ross . Some participants mentioned that being introduced to the artifacts , input actions , and TUI examples as a set of possibilities made them focused on those while making it challenging to think of possibilities . “Sometimes , when you start looking at those stuff [ artifacts ] , you will stick around with those , so you can’t think of something else . ” – Maya . Hence they tried to incorporate those in their ideas , as is or by modifying them . Some of them felt that such fixation occurred due to being introduced to only a limited number of possibilities . “Coz , there’s only five of the IdeaBits [ input actions introduced by IdeaBits ] , I do think it hinders my imagination to some degree because it makes you focus on what’s present . I don’t really think of any additional material . ” - Lee . 77 The presence of the sensor - enabled artifacts in functioning condition , along with associated technical implementation information , gave a few participants confidence in the feasibility of their ideas that involved input actions from the artifacts . “Having it [ fold sensor - enabled artifact ] there already kind of functioning . I have three ideas , and then I moved on to this one just because it’s already there . ” – Jane . Some participants tried to choose from among the five input actions introduced by IdeaBits by interacting with the artifacts while linking them with the six emotions . When choosing input actions by interacting with the sensor - enabled artifacts , some of them tried to think beyond the particular implementation of the input actions in the sensor - enabled artifacts , while some of them generated ideas that were heavily influenced by the specific designs of the artifacts . “ It [ squeeze sensor - enabled artifact ] is just a handheld something . It [ squeeze ] could be interacted with many parts of the body and not just hands . ” – Amy . Some participants felt they were expected to incorporate the input actions in IdeaBits . “I know that you wanted me to interact with those [ artifacts ] , of course . So it’s like , “Okay , that’s it . I’m gonna try and iterate with that . ” And it worked pretty well . ” – Jane . However , almost all of them mentioned understanding the given instruction that they were not constrained to the five input actions introduced by IdeaBits . “Like you were pretty clear about like using beyond what is here [ in IdeaBits ] . ” – Ross . Few participants mentioned that they tried to incorporate input actions from IdeaBits since they did not have enough time to think beyond those , especially when they came across input actions that they weren’t familiar with . “ I was kind of distracted by like , most of them [ input actions introduced by IdeaBits ] are fairly new to me . It takes me some time to just adapt to that before I can think of something else outside the box . ” – Ross . Few participants tried to incorporate the technical implementation of the sensor - enabled artifacts when they were unable to plan technical implementation for their ideas . They even changed the input actions in their ideas to be able to use the technical implementation of the artifacts . Few participants tried to incorporate the technical implementation of the sensor - enabled artifacts to minimize effort . For example , Lee tried to incorporate the technical implementation of the sensor - enabled artifacts , even though the input actions in his ideas were different from the input actions in artifacts , to avoid designing new sensors . “At first , I figured out how those [ sensor - enabled artifacts ] work . 78 And I tried to implement some of these here [ in idea generation ] … If they are not there , then I have to think of ways to create the sensor . ” – Lee . Disconfirming evidence Few participants mentioned that they did not feel limited to the possibilities introduced by IdeaBits and instead perceived IdeaBits as a source of inspiration . Participants’ ideas also involved input actions , outputs , technical implementations , and overall concepts which were not introduced by IdeaBits . Interacting with the sensor - enabled artifacts inspired a few participants with input action ideas which were different from those in the artifacts , by reminding them of another object or activity . The sensor - enabled artifacts inspired some participants with input action ideas , which were different from those in the artifacts , by helping them to understand how they could use the technical implementation of the artifacts to detect a different input action . Few participants incorporated a variation of the possibilities introduced by IdeaBits . Few participants intentionally tried to differ from the inspirational source . Table 5 . 10 Summary table for the subtheme “Disconfirming evidence” . In this subtheme , I describe the scenarios in which design fixation did not occur . Few participants mentioned that they did not feel limited to the possibilities introduced by IdeaBits and instead perceived IdeaBits as a source of inspiration based on the given instruction that they were not constrained to the five input actions introduced by IdeaBits . “ …not literally making me to copy . It [ IdeaBits ] is the inspiration right . And I got that when you introduced me to this [ IdeaBits ] , and that it had nothing to with this [ design task ] . I ' m like , “Okay , so that’s a stimulus . ”” – Amy . Participants’ ideas also involved input actions , outputs , technical implementations , and overall concepts which were not introduced by IdeaBits . Some input actions not introduced by IdeaBits that were present in the participants’ final ideas are roll , clench fist , and hit . The artifacts , TUI examples , and technical implementation information inspired ideas also inspired ideas that were different from the inspirational source with respect to overall concepts , input actions , outputs , and technical implementation . The artifacts inspired a few participants with input action ideas which were different from those in the artifacts , by reminding them of another object or activity . For example , the stretch physical - only artifact reminded Ted of a telephone cord and the action of twisting it while being on a call , which gave him the twist input action idea . “We had a phone cord when I was a child . And my mom used to always play with it like she would wrap it around her finger… So this [ stretch physical - only artifact ] led me to that , and then it eventually led me to this [ twist input action idea ] . ” - Ted . The sensor - enabled artifacts inspired some participants 79 with input action ideas , which were different from those in the artifacts , by helping them to understand how they could use the technical implementation of the artifacts to detect a different input action . “My [ pressing ] button idea actually comes from the folding one [ fold sensor - enabled artifact ] because you can add two different buttons on the fingertips [ of my glove idea ] and turn it on and off on touching . ” - Paul . Few participants incorporated a variation of the possibilities introduced by IdeaBits . For example , Amy incorporated the idea of the flexible screen after seeing it in the TUI example for fold ( Paddle [ 77 ] ) . Her input action idea was , however , squeezing the screen instead of folding it . Few participants intentionally tried to differ from the possibilities introduced by IdeaBits intentionally . For example , Ben had squeeze input action in his final idea . He made the output in his idea tangible to differ from the visual output of the squeeze sensor - enabled artifact , which had inspired his input action idea . I have discussed other disconfirming evidence in “Analysis of the Deliverables , ” and in the themes “IdeaBits Introducing Possibilities” and “Hands - on Interaction with IdeaBits . ” 80 5 . 2 . 6 . Challenges in Using IdeaBits Some participants found it challenging to understand how to interact with the sensor - enabled artifacts based on their visual cues . Some participants had to physically inspect the sensor - enabled artifacts to understand their affordances while using a trial and error approach to figure out how to interact with them . Participants used the videos on the home page of the GUI of IdeaBits , videos of TUI examples , and name and illustration of the input actions to understand how to interact with the sensor - enabled artifacts . Few participants were confused when there were differences in implementation of the input actions in the TUI examples v / s the sensor - enabled artifacts . Few participants expected the sensor - enabled artifacts to control the GUI beyond merely opening the video tab of the example page and playing or pausing the video . Few participants chose not to use the “Tech” button , considering it to be time - consuming , even though they were not able to plan the technical implementation of their ideas . Some participants did not like being taken to a web browser when clicking on the “Tech” button and hence suggested incorporating technical implementation information within the GUI of IdeaBits . Few participants felt that being introduced to technical implementation information limited their creativity . To avoid hindrance in the early idea generation phase , a few participants wanted to have access to the information in IdeaBits in progressive steps rather than all at once . Few participants wanted to see the output values of the sensors when interacting with the sensor - enabled artifacts to be able to understand the involved data type ( digital or analog ) and inspect their sensitivity . Few participants felt the colored bars in the video player were overcrowded , distracting , and challenging to understand . Some of them felt they were unnecessary for videos of short duration . Few participants found it challenging to arrive at a conclusive summary of the information from the multiple TUI examples introduced by IdeaBits . Few participants wanted design guidelines related to the input actions , such as how to choose an input action based on context and which input actions go well together . Table 5 . 11 Summary table for the theme “Challenges in Using IdeaBits” . In this theme , I describe the challenges faced by participants while using IdeaBits . Some participants found it challenging to understand how to interact with the sensor - enabled artifacts , especially the stretch and the fold sensor - enabled artifacts . Few participants mentioned that they could understand the affordances of most of the sensor - enabled artifacts based on their appearance and visual cues . “The affordances in these [ sensor - enabled artifacts ] are pretty much straightforward . Like it also says , “Bends one way . ” And then if you see this [ pull sensor - enabled artifact ] , and then you see tape outside [ the artifact ] , and you see this [ the ribbon of the artifact ] hanging on , this [ pulling the ribbon ] is your only interaction you can perform on it . ” – Neil . 81 Figure 5 . 3 Stretch sensor - enabled artifact However , few other participants were unable to understand some of the sensor - enabled artifacts’ affordances based on their visual cues . For example , they were unable to identify the stretchable part of the stretch sensor - enabled artifact , since the artifact looked like a wire while the color of the wires connecting the artifact to the Arduino Uno board [ 116 ] was the same as that of the artifact ( Figure 5 . 3 ) . “This thing [ conductive rubber cord in stretch sensor - enabled artifact ] is black , this thing [ the wires connecting the artifact to the Arduino Uno board ] is black . I don’t know which component is stretchable . ” – Neil . These participants had to physically inspect the sensor - enabled artifacts to understand their affordances while using a trial and error approach to figure out how to interact with them . For example , they understood where to stretch the stretch sensor - enabled artifact when he could feel the stretchable part while physically inspecting the artifact . “I didn’t really understand that stretchy rope [ stretch sensor - enabled artifact ] at first . But when I actually felt it and touched it , “Okay , it’s actually a stretchable material . ”” – Ben . Similarly , for the fold sensor - enabled artifact , the user had to use a trial and error approach to figure out the direction to fold it such that the input action was detected . Few participants did not notice the “Bends one way” instruction on the bend sensor - enabled artifact ( Figure 5 . 4 ) and hence they were trying to bend it in the opposite direction as well . “I didn’t read that “Bends one way . ” And I was playing the video , I was like bend , pause , bend and then I wanted to reverse the video , and then bend it the other way . I did it for 10 seconds , but no , it didn’t work . I did it with this [ mouse ] then . ” – Amy . 82 Figure 5 . 4 Bend sensor - enabled artifact . Participants used the videos on the home page of the GUI of IdeaBits ( which illustrate how to interact with the sensor - enabled artifacts ) , videos of TUI examples , and name and illustration ( on the illustration cards ) of the input actions to understand how to interact with the sensor - enabled artifacts . Few participants were confused when there were differences in implementation of the input actions in the TUI examples v / s the sensor - enabled artifacts . For example , they were confused by the differences in the pull sensor - enabled artifact’s version of pull input action v / s the pull input action in the TUI example for pull ( RopePlus [ 109 ] ) . The ribbon in the pull artifact can be pulled in two directions , while the rope in RopePlus was fixed from one end ( Figure 5 . 5 ) . “For this [ RopePlus ] pull , it’s more strong than this [ pull sensor - enabled artifact ] pull… and is connected to one point . ” – Uma . 83 Figure 5 . 5 Pull input action in RopePlus [ 109 ] ( above ) and pull sensor - enabled artifact ( bottom ) . Few participants expected the sensor - enabled artifacts to control the GUI beyond merely opening the video tab of the example page and playing or pausing the video . By interacting with the sensor - enabled artifacts , they were trying to switch between the different formats of the examples , reverse the video , scroll through the images , and scroll the paper . “If I want to squeeze [ the squeeze sensor - enabled artifact ] to the next image , it doesn’t work… I would have loved it if it would have interacted beyond the video . ” – Amy . When a sensor enabled - artifact enabled them to change the direction of interaction ( e . g . , fold , bend , and pull artifacts ) , they expected that changing the direction would have a different impact on the TUI example video . “I was thinking if you pull it [ ribbon in pull sensor - enabled artifact ] on one side , it would play the video ; if you pull it on to the other side , it would pause the video . But that’s not the case . ” – Ben . Some of them mistakenly reached out for the sensor - enabled artifacts to control the GUI in ways that were feasible only using the mouse , even though they were aware of the control limitations of the artifacts . They wanted the sensor - enabled artifacts to be the sole controller of the GUI , thus eliminating the requirement to use the mouse . Few participants did not use the “Tech” button , even though some of them were unable to plan the technical implementation of their ideas , since they felt it to be time 84 consuming and unnecessary for the short session . “I thought about it , but then I didn’t… I think it would take too long to look it up . So , I just wrote down what I thought would make sense . ” – Eva . Some participants did not like being taken to a web browser when clicking on the “Tech” button and hence suggested incorporating technical implementation information within the GUI of IdeaBits . “It would be nice to somewhat , rather than open an extra window , put it [ landing page of the “Tech” button ] in here [ GUI of IdeaBits ] . ” – Lee . Few participants wanted to see the output values of the sensors when interacting with the sensor - enabled artifacts to be able to understand the involved data type ( digital or analog ) and inspect their sensitivity . “I need to see how sensitive the inputs [ of the sensor - enabled artifacts ] are… Like a panel [ in the GUI of IdeaBits ] that show you the result of the interaction , right ? ” – Ross . Few participants felt that IdeaBits gave a reality check related to the feasibility of ideas by providing technical implementation information . They felt that the technical implementation information provided in the GUI of IdeaBits limited their creativity and hindered the early idea generation phase . “With this [ technical implementation information ] , sometimes you get kind of a reality check of like , “Oh , so this is how you practically build it . ” , which is really good for a second stage . But in the first one , you kind of need to come up with like gravity machines or whatever . ” - Jane . Some participants delayed planning of technical implementation until they finalized their idea to avoid restricting themselves while generating ideas . “I was more focused on trying to think of some clever idea , instead of like , “Okay , what exactly sensor components do I need . ” , even though that was part of it [ the design task ] . It’s like , “Okay , well . I can write something down at the end real quick or whatever . ”” - Ted . As a result of being introduced to technical implementation information , few participants generated only a few ideas before choosing a final idea , which they felt to be sooner than they would desire . They speculated that such information might be helpful for later in the idea generation phase when they have narrowed down to a few ideas . “I moved on so quickly to the final idea . And so maybe it was a little bit distracting to get that depth of information already . But it would almost be like the second idea generation session where you’ve already narrowed down a little bit” - Jane . To avoid hindrance in the early idea generation phase , a few participants wanted to have access to the information in IdeaBits in progressive steps rather than all at once , as they proceeded in the idea generation process . “I wonder if like there’s another way to design the hierarchy of information , so that you can , like , slowly move into the different 85 stages [ of idea generation ] . Like there already is , but you can still kind of see everything available . ” - Jane . They wanted to have an active choice in accessing detailed information related to any input action rather than the examples being popped up automatically on interacting with the sensor - enabled artifacts . For example , Jane suggested making the sensor - enabled artifacts pluggable to enable the users to plug them when they make an active choice to access more information related to the involved input actions . “If they [ sensor - enabled artifacts ] are pluggable… If you’re like , “Okay , folding . Let’s plug it in and see what other people have done . ” And then there’s sort of an active choice that you are making to access the information , I guess ? ” – Jane . Few participants felt the colored bars in the video player were overcrowded , distracting , and challenging to understand since there were multiple bars and multiple colors . “Sometimes , it [ the colored bars ] is a bit overwhelming because there’s like different colors . ” – Ted . Some of them felt they were unnecessary since most of the videos were of short duration . I discussed some exceptions in the subtheme “Preferences Among Artifacts and Example Formats” . Few participants found it challenging to arrive at a conclusive summary of the information from the multiple TUI examples introduced by IdeaBits . They suggested providing a summarized conclusion of all the information in IdeaBits along with design guidelines related to the input actions , such as how to choose an input action based on context and which input actions go well together . “Maybe there could be some kind of a summary blurb , things to look out for with these kind of interactions . Like , when it makes sense to include this , or what other interactions it can go well with . ” – Eva . 5 . 2 . 7 . Challenges in Doing the Design Task Few participants did not get any ideas before they started using IdeaBits . IdeaBits helped them to get ideas by introducing them to possibilities . Most of the participants found it challenging to plan the technical implementation of their ideas . Around half of the participants faced challenges related to the constraints of the design task . Table 5 . 12 Summary table for the theme “Challenges in Doing the Design Task” . In this theme , I describe the challenges faced by the participants in doing the design task and how they tackled those . Participants faced challenges in terms of coming up with ideas for the overall concept , input action , output , input - output mapping , and 86 technical implementation , along with challenges related to the constraints of the design task . On facing challenges , the participants used IdeaBits to find solutions , incorporated the technical implementation of sensor - enabled artifacts and TUI examples , replaced the input actions in their idea which were not in IdeaBits with those in IdeaBits to be able to incorporate the technical implementation of the corresponding sensor - enabled artifacts , discarded their ideas , and provided incorrect and incomplete answers to deliverable 4 . Few participants mentioned that they did not get any ideas for addressing the design task before they started using IdeaBits . When they were unable to get ideas , they studied TUI examples and interacted with the artifacts , which helped them to get ideas . “When I first started , I was just like empty . So , I started looking at IdeaBits to get some more idea . ” – Maya . Few participants mentioned that before using IdeaBits , they found it challenging to generate ideas as they did not have a clear idea of what would be feasible or appropriate . After using IdeaBits and interacting with the sensor - enabled artifacts , they had a better idea of what would be feasible based on the possibilities introduced by IdeaBits . “ Mostly the initial idea generation without having to interact with the IdeaBits , so just generating ideas based on what I think would be right without having like factual information at the back as to this would actually work or not , I think that was a limiting factor . But after using IdeaBits and using the interaction methods [ sensor - enabled artifacts ] , then I got like a little bit more clarity on what kind of an idea can be produced from this [ IdeaBits ] , and how would it work . ” - Ben . Few participants looked for inspiration in the modeling materials when they were unable to detail their input action ideas . Most of the participants mentioned that they found it challenging to plan the technical implementation of their ideas . Some participants mentioned that IdeaBits did not support in planning the technical implementation of their ideas , especially when they started planning it after they finalized the input action and output in their idea without considering technical implementation possibilities introduced by IdeaBits . Around half of the participants mentioned that they found it challenging to plan the technical implementation of the input actions in their ideas , especially when the input actions were not from among the ones introduced by IdeaBits . For example , Neil mentioned that he was unable to plan technical implementation for roll and tear input actions in his idea due to the absence of associated sensor - enabled artifacts , TUI examples , and technical implementation information . “This rolling [ input action idea ] , I would like to see how that could be implemented in that [ IdeaBits ] . Because , if I was only restrained with these five 87 [ input actions in IdeaBits ] , I wouldn’t be able to implement this [ roll input action ] . ” – Neil . In the end , Neil changed the input actions in his idea to be able to incorporate the technical implementation possibilities introduced by IdeaBits . Participants mentioned that they found it challenging to plan the technical implementation of the input actions in their ideas , even when the input actions were from among the ones introduced by IdeaBits . For example , when unable to plan technical implementation for detecting pull input action , Eva tried to incorporate the technical implementation of the TUI example for squeeze ( Tessella [ 18 ] ) since she considered it to be similar to her idea . She , however , could not understand the technical implementation of Tessella either . “For the pulling interaction , I saw in one of the videos [ Tessella ] , it was like a matrix of sensors… I’m actually not too sure about how they detect pull… I couldn’t piece together how to detect a pulling motion . You could take the stretch sensor [ stretch sensor - enabled artifact ] idea that was in the example . But I’m not really good with the hardware , so I couldn’t figure it out . ” – Eva . Some participants named the sensors for detecting input actions in their ideas after the names of the input actions and sensor - enabled artifacts , instead of the actual name of the sensors which they could access using the “Tech” button in IdeaBits for the five input actions introduced by IdeaBits . Most of these participants were unable to figure out the technical implementation of the sensor - enabled artifacts and how to detect the input actions in their ideas . “I just put squeeze sensor [ in deliverable 4 ] . So , I’m not actually sure like what’s going on in there [ squeeze sensor - enabled artifact ] . So , I was like , “Whatever is in there . ”” – Ted . Moreover , as discussed in the theme “Challenges in using IdeaBits” , few participants chose not to use the “Tech” button , considering it to be time - consuming , even though they were not able to plan the technical implementation of their ideas . Few participants mentioned that they were unable to plan technical implementation for the input actions in a way that would handle false positive errors . For example , Lee had an input action idea of “sudden movement” for communicating the emotion “surprised” . He was unable to plan its technical implementation in a way that would filter out the cases when the user may move in a similar way even when they were not surprised . “Thinking of excitement , for example , sudden jump . You are really surprised ; you might move suddenly . But then you might also move just for no reason . So , it’s harder to be precise with those . ” – Lee . Few participants mentioned that they were unable to get 88 ideas for materials that would afford their input action ideas . “ What kind of materials would allow for the squeezing [ input action ] but also rigid so that it doesn’t just fall apart . ” – Kate . Few participants mentioned that they found it challenging to plan technical implementation for the outputs and pairing of the devices in their ideas , information related to which was not provided in IdeaBits . For example , Neil could not plan the technical implementation for the outputs in his idea ( clay rolled into a ball , clay ball squeezed , and clay ball torn ) . He hence changed the outputs to be digital , like that in IdeaBits , to be able to answer deliverable 4 . Around half of the participants faced challenges related to the constraints of the design task . For example , they faced challenges related to communication of emotion , such as not getting ideas for certain emotions ( especially sad and disgusted ) , and finding it difficult to differentiate between certain emotions ( e . g . , scared and surprised ) . “Some of the emotions were harder than others to figure out . For example , disgusted . I am not really sure how to do [ communicate ] that one . ” – Lee . Few participants found it difficult to get ideas for input - output mapping between two objects separated over a distance , especially ideas that would work when having significant time zone differences . “All the ideas were sort of two connected things in different locations . And then the input , it was hard to think about it by like , from two directions where , yes , you have to input , but then what does that mean on the other side ? And is that also at the same time and input or output device or not or ? ” - Jane . 89 Chapter 6 . Discussion and Design Implications In this chapter , I discuss the findings from my study by comparing and contrasting with existing literature and provide design implications for tools to support idea generation for TUIs . I organized this discussion into five sections : 1 ) Experiencing input actions first - hand , 2 ) Encouraging and facilitating hands - on exploration , 3 ) Facilitating prototyping , 4 ) Inspirational examples versus design fixation , and 5 ) Technical implementation guidance . At the beginning of each section , I shall provide a summary table to list the major points in that section . At the end of this chapter , I discuss how the design implications may be beneficial beyond the case investigated , the limitations of my thesis , and potential future work . 6 . 1 . Experiencing Input Actions First - Hand Findings from my study Findings from other researchers Interacting with the artifacts and experiencing the input actions enabled some participants to - get ideas , critically reflect on their design decisions related to input actions , realize shortcomings in their input action ideas and technical implementation plan , and notice the similarities and differences between the introduced input actions . The involvement of the body is crucial in learning and reasoning [ 55 , 71 ] . Designers prefer to and benefit from first - hand experience [ 34 , 46 ] . Working with physical objects helps designers to understand aspects related to physicalities [ 66 ] and facilitates reflective thinking in the idea generation process [ 24 , 45 , 49 ] . Design implications : Enable designers to experience input actions first - hand by providing interactive artifacts involving a variety of materials . Table 6 . 1 Summary table for “Experiencing Input Actions First - Hand” . In this section , I discuss the benefits of experiencing input actions first hand while generating TUI ideas and how this can be enabled by providing interactive artifacts . Design tools to support idea generation for TUIs need to provide interactive ( affording physical manipulation and having output ) artifacts for enabling designers to experience input actions first - hand . Other researchers have found that involvement of the body is crucial in learning and reasoning [ 55 , 71 ] while experiencing first - hand enables the designer to empathize with the users [ 45 , 92 ] . Also , in [ 34 ] , the author found that designers interact directly with the world to have a first - hand experience rather than imagining the 90 particulars of the future use situation . I found in my study that interacting with the artifacts facilitated experiencing the input actions , think beyond the provided TUI examples , and get input action ideas . Similar to my findings , other researchers have found that designers designing for movement - based interaction benefitted from doing and experiencing the movements [ 46 ] . In [ 66 ] , the authors found that working with physical media helped kinetic design novices to understand physical aspects , such as spatial translation and real - world forces surrounding objects in motion , while challenging related assumptions . Also , it may help to provide a variety of materials to work with due to the dependency of TUI design on material properties , as found by Parkes et al . [ 66 ] for kinetic designers . I found that interacting with the artifacts and experiencing the input actions enabled some participants to - critically reflect on their design decisions related to input actions , realize shortcomings in their input action ideas and technical implementation plan , and notice the similarities and differences between the introduced input actions . My findings are in line with those of other researchers ( e . g . [ 24 , 45 , 49 , 93 ] ) . For example , Stolterman [ 93 ] found that interaction designers desire the tools they use to support reflection and decision making . In turn , other researchers found that physical objects act as scaffolds ( binding anchors ) by enabling physical interaction and facilitate reflective thinking in the idea generation process [ 24 , 45 , 49 ] . 91 6 . 1 . 1 . Sensor Enabled Artifacts as the Graphical User Interface Controllers Findings from my study Findings from other researchers Many participants found it challenging to imagine the possible consequences of interacting with the physical - only artifacts due to the absence of output . Designers interact with the physical world , whenever possible , to figure out the consequences that follow their actions rather than imagining in their mind [ 34 ] . The presence of output in sensor - enabled artifacts made them interactive and engaging to use , along with enabling participants to understand how the input actions could be designed as a part of TUIs . Some participants found popping up of TUI examples on interacting with the sensor - enabled artifacts to be distracting them from focusing on experiencing the input actions . They also felt that it took away their control on information ( TUI example ) access . Users feel in control when they can attribute the output to their actions [ 49 ] . When users feel in control , they explore freely [ 49 ] . Designing the sensor - enabled artifacts as GUI controllers confused the participants as it resulted in having two different controllers . Using the sensor - enabled artifacts as GUI controllers resulted in the participants interacting with them absentmindedly . Design implications : Facilitate users to focus on experiencing input actions by providing artifacts with subtle or non - intrusive outputs . Table 6 . 2 Summary table for “Sensor Enabled Artifacts as the Graphical User Interface Controllers” . In this section , I discuss the disadvantages of designing the sensor - enabled artifacts as the GUI controllers and how those can be addressed . Based on my findings and supporting pieces of evidence found in existing literature , I would recommend not to design the sensor - enabled artifacts as controllers for the GUI used to provide the TUI examples . I would instead suggest associating subtle or non - intrusive outputs with the artifacts . I found that the presence of output in the sensor - enabled artifacts enabled participants to understand how the input actions could be designed as a part of TUIs . Most of them mentioned not being able to understand the same by interacting with the physical - only artifacts . They mentioned that they found it challenging to imagine the possible consequences of interacting with the physical - only artifacts due to the absence of output . Similar to my findings , other researchers reported that designers interact with the physical world , whenever possible , to figure out the consequences that follow their actions , rather than imagining in their mind [ 34 ] . I designed the sensor - enabled artifacts as a control for some parts of the GUI to associate them with output and to make them interactive . However , some participants found the displaying of the TUI examples on the GUI on interacting with the sensor - 92 enabled artifacts to be distracting and shifting their focus away from experiencing the input actions . They also mentioned that it took away their control on information ( TUI example ) access . The users might feel in control when they can attribute the output to their action , as Jaasma et al . found from an evaluation of the Blue Studio ( an interactive room for multi - stakeholder ideation ) [ 49 ] . They also found that enabling users to feel in control of what is happening encouraged them to explore freely . I found that designing the sensor - enabled artifacts as GUI controllers also confused the participants as it resulted in having two different controllers ( including the mouse ) . Even though some participants wanted the sensor - enabled artifacts to have more control over the GUI , it might be better to unlink the GUI and the sensor - enabled artifacts . Using the sensor - enabled artifacts as GUI controllers resulted in the participants interacting with them absentmindedly , while their primary focus was on the GUI . As found during remote observation and video analysis , most of the time , the participants were looking at the GUI while interacting with the sensor - enabled artifacts presumably as controllers for the GUI . Instead , providing subtle or non - intrusive outputs , which are non - distracting due to demanding minimal attention [ 19 , 73 ] , may facilitate users to focus on experiencing the input actions . Some of the ways of providing feedback in a non - intrusive way include keeping it in the background of the primary task [ 101 ] , using low intensity [ 73 ] , or temporally extending it [ 52 ] . 93 6 . 2 . Encouraging and Facilitating Hands - on Exploration Findings from my study Findings from other researchers It is crucial to encourage and facilitate exploration for people doing creative work [ 31 , 79 , 90 ] . Enabling to experience the input actions by interacting with the artifacts and modeling materials facilitated exploration , testing of different input actions , and getting input action ideas . Experiencing movements when designing for movement - based interaction facilitated to explore various aspects of movements [ 46 ] . Experimentation with physical modules in a motion prototyping toolkit helped generate ideas for kinetic systems [ 66 ] . Participants interacted with the modeling materials inquiring about their affordances while exploring various input actions . Designing involves reflective interaction with materials to understand and explore various aspects of the design situation [ 4 , 83 , 84 ] . Designers examine provided objects to discover their physical aspects [ 90 ] and the possibilities they entail [ 95 ] . Explorative interaction with sensor - enabled artifacts was driven by participants ’ curiosity to find out how they work and test their sensitivity . It was facilitated by the flexible affordances of the artifacts and the feedback provided by its output . Providing users an interactive idea generation space that could not be understood without trying it out themselves encouraged them to engage with it [ 49 ] . Providing a set of interactive artifacts , interacting with which led to unexpected digital effects in the space , encouraged to explore the interactivities playfully while the users perceived the output as a reward [ 49 ] . The interactivity of the sensor - enabled artifacts and the open - ended interaction possibilities of the modeling materials facilitated idea generation by supporting fidgeting and playful interactions . Interaction designers prefer to use tools that involve intriguing concepts that are open for interpretation on how they can be used [ 93 ] . Providing unfamiliar objects with no instructions on how to use them triggered imagination [ 49 ] . Design implications : Encourage and support hands - on exploration by providing artifacts with open - ended interaction possibilities mapped to unexpected outcomes . Table 6 . 3 Summary table for “Encouraging and Facilitating Hands - on Exploration” . In this section , parallel to the findings from other research , I argue for the advantages of hands - on exploration while generating TUI ideas and discuss how design tools can encourage and facilitate hands - on exploration . In [ 90 ] , the authors report that having an explorative mindset helps people to generate ( innovative ) ideas [ 90 ] . Similarly , in [ 31 , 79 ] , the authors found that encouraging and facilitating exploration and trying out of multiple alternatives is crucial for creative work . In turn , in [ 4 ] , the author suggests providing TUI designers with physical materials to facilitate exploration and experimentation . In addition , other researchers found that experiencing movements when designing for movement - based interaction facilitated the designer to explore various aspects of movements and the inter - relationships , which they otherwise found to be too 94 complicated [ 46 ] . Consistent with these findings , I found that enabling to experience the input actions by interacting with the artifacts and modeling materials facilitated exploration . By interacting with the sensor - enabled artifacts , participants tested different variations of the associated input actions and , in some cases , new input actions . Exploration of the artifacts helped participants to generate ideas for input actions by varying the possibilities introduced by IdeaBits as well as considering possibilities not introduced by IdeaBits . Similar to my findings , in [ 66 ] , the authors found that mechanical and behavioral experimentation with physical modules in Bosu ( a motion prototyping toolkit ) helped to generate kinetic system ideas . Other researchers have found that designing involves reflective interaction with materials to understand and explore various aspects of the design situation [ 4 , 83 , 84 ] . Similarly , I found that participants interacted with the modeling materials inquiring about their affordances while exploring various input actions , which helped them to get input action ideas involving input actions both introduced or not covered in IdeaBits . My findings are consistent with those of other researchers , e . g . , [ 34 , 66 , 90 , 95 ] . For example , in [ 34 ] , the author found that designers interact with the physical world to unravel some of its properties , which are otherwise not readily apparent . In [ 66 ] , the authors found that hands - on interaction with the physical materials and actuators allowed users to uncover unexpected behavior of the materials . In [ 90 ] , the authors found that providing a set of interactive physical objects triggered curiosity and exploration in the people generating ideas , where they examined the objects’ physical aspects such as materials and affordances . In [ 95 ] , the authors found that when designers were provided with a set of materials to build their ideas , the designers interacted with the materials to figure out the possibilities they entail , based on which they choose the ones they would use to build their ideas . Explorative interaction with sensor - enabled artifacts was driven by participants’ curiosity to find out how they work and test their sensitivity . It was facilitated by the flexible affordances of the artifacts and the feedback provided by its output . Participants preferred interacting with interactive objects that had output and provided feedback , which is why they found sensor - enabled artifacts interesting to interact with compared to physical - only artifacts . Also , the interactivity ( having an output that provided feedback ) of the sensor - enabled artifacts and open - ended interaction possibilities of the modeling materials facilitated idea generation by supporting fidgeting and playful interactions , similar to what 95 other researchers found regarding providing a set of interactive physical objects [ 90 ] . Similar to my findings , in [ 49 ] , the authors found that by providing an interactive idea generation space which could not be understood without trying out themselves encouraged the people to engage with it . However , the authors found that it also acted as a threshold for some people [ 49 ] . In [ 93 ] , the authors found that interaction designers prefer to use tools that involve intriguing concepts that are open for interpretation on how they can be used . Also , in a user study of Blue Studio [ 49 ] , the researchers found that providing unfamiliar objects with no instructions on how to use them for idea generation triggered imagination . In line with these findings , to encourage and support exploration , it might help to be not extremely prescriptive about the input actions associated with the provided artifacts or excessively limit their affordances to accommodate only one input action per artifact . It may help to instead provide freedom to the users for exploration of a variety of input action possibilities while encouraging the exploration with an objective of discovery similar to the Blue Studio [ 49 ] . From an evaluation of the Blue Studio [ 49 ] , the authors found that by providing a set of interactive artifacts , interacting with which led to output in the form of unexpected digital effects in the space , encouraged the people to explore the interactivities playfully while they perceived the output as a reward . Similarly , the sensor - enabled artifacts can be linked with unexpected outputs which may aid the users to change their perspectives and get new ideas as found by Jaasma et al . [ 49 ] . 96 6 . 2 . 1 . Minimizing Technical Malfunctioning Findings from my study Findings from other researchers Design implications Other researchers have found that malfunctioning of ready - at - hand interaction possibilities pulled users back into the real world [ 23 , 49 , 103 ] . The trial and error approach of figuring out how to interact with the sensor - enabled artifacts damaged one of the sensors due to its frail technical implementation . Design the technical implementation of the artifacts to minimize damage from explorations . Damage to one sensor prevented input action detection from all sensors . Assemble the tool such that damage to one sensor does not affect the other artifacts . Making the sensor - enabled artifacts pluggable enabled me to easily replace them when damaged . Design the artifacts such that they can be easily repaired or replaced . Some participants mentioned limiting their interaction with the sensor - enabled artifacts due to fear of breaking them . Make the artifacts visibly robust to encourage playful , explorative , and worry - free interactions . Table 6 . 4 Summary table for “Minimizing Technical Malfunctioning” . In this section , I discuss the importance and ways of minimizing technical malfunctioning to facilitate hands - on exploration while generating TUI ideas . Other researchers have found that malfunctioning of ready - at - hand interaction possibilities pulled users back into the real world [ 103 ] , making the provided artifact obtrusive [ 49 ] rather than an extension of the body or a scaffold [ 23 ] . Hence it may help to minimize , if not avoid , technical malfunctioning , especially to support hands - on exploration . Participants , who were unable to understand the affordances of some of the sensor - enabled artifacts based on their visual cues , used a trial - and - error approach to figure out how to interact with those artifacts . While doing so , some of the participants bent the bend sensor - enabled artifact in the prohibited direction , which led to damaging the flex sensor in the artifact . One way of preventing such damages from occurring is by making it explicitly clear regarding how the users should and should not interact with the artifacts . This can be done in multiple ways , such as by providing clear visual cues , designing the artifact with limited affordances , or by using physical constraints . However , if feasible , rather than restricting the interaction possibilities with the artifacts , one can instead design 97 the technical implementation in a way that does not get damaged from users exploring different input actions . During one user study , when the flex sensor in the bend sensor - enabled artifact broke , all the sensor - enabled artifacts stopped being detected . The tool can be designed in a way that if one of the components breaks down , then the other ones remain unaffected . Also , the sensor - enabled artifacts can be designed in a way that they can be easily replaced when broken . I did this by making the sensor - enabled artifacts pluggable into the Arduino Uno board [ 116 ] using jumper wires , as discussed in chapter 3 . Some participants mentioned limiting their interaction with the sensor - enabled artifacts due to fear of breaking them . Thus , it may help to make the artifacts visibly robust to encourage playful , explorative , and worry - free interactions . 6 . 3 . Facilitating Prototyping Findings from my study Findings from other researchers Participants realized issues in their ideas by building and interacting with the prototypes they made using modeling materials . Interacting with the prototypes the designers built using a modular electronic prototyping toolkit helped them realize issues in their ideas [ 82 ] . Building and interacting with the prototypes helped participants make design decisions and generate ideas related to input action , output , and technical implementation . Iterative prototyping helped users come up with successful design decisions due to the high dependency of kinetic design on materiality [ 66 ] . Having output associated with sensor - enabled artifacts enabled participants to test the technical feasibility of their input action ideas . Interacting with functional prototypes enabled designers to test their ideas [ 66 ] . Some participants wanted to use sensor - enabled artifacts for prototyping to avoid reinventing the wheel by building from scratch . Building functional TUI prototypes requires skill and knowledge related to electronics and programming [ 39 , 56 ] , which act as a barrier for novices [ 82 ] . Making it easy to build functional electronic prototypes by reducing implementation burden enabled designers to focus on the design of the interaction [ 82 ] , and encouraged exploration of ideas [ 66 , 82 ] . Modular plug - and - play tools facilitate exploration during electronic prototyping , as compared to raw electronic components that are relatively complex to use for building prototypes [ 3 , 81 , 82 ] . Design implications : Design the sensor - enabled artifacts as pluggable prototyping modules to facilitate TUI designers to easily build , interact with , and quickly modify their prototypes . Table 6 . 5 Summary table for “Facilitating Prototyping” . 98 In this section , I discuss the advantages of prototyping for TUI designers and how design tools can facilitate prototyping . To support idea generation for TUIs , design tools may facilitate easily building , interacting with , and quickly modifying design prototypes . Other researchers reported various benefits of prototyping such as enabling visualization of an idea [ 12 , 55 ] , facilitating reflective thinking [ 25 , 45 , 49 , 67 , 82 ] , supporting design decision making [ 66 , 82 ] , putting designers in users’ shoes [ 46 , 102 ] , having unexpected realization [ 55 ] , inspiring ideas [ 45 , 59 , 67 , 95 ] , encouraging exploration of ideas [ 3 , 66 , 81 , 82 ] , and enabling evaluation of ideas and alternatives [ 12 , 15 , 39 , 66 ] . I had similar findings from my study ( details in the subtheme “Prototyping and testing ideas” in Chapter 5 ) . I found that participants realized issues in their ideas by building and interacting with the prototypes they made using modeling materials . Similar to my finding , in [ 82 ] , the authors found that interacting with the prototypes built using Bloctopus ( modular electronic prototyping toolkit ) helped users to realize issues in their ideas and improvise them . I also found that building and interacting with the prototypes helped participants make design decisions and get ideas related to input action , output , and technical implementation . Similar to my findings , in [ 66 ] , the authors found that iterative prototyping helped users come up with successful design decisions due to the high dependency of kinetic design on materiality . Having output associated with the sensor - enabled artifacts enabled participants to test their ideas . For example , some participants interacted with the sensor - enabled artifacts to test the technical feasibility of their input action ideas . Similar to my finding , Parkes et al . [ 66 ] found from an evaluation of Bosu ( a motion prototyping toolkit ) that the functional prototypes that the users made , enabled them to test their ideas . Enabling users to control the sensitivity of the sensors in the sensor - enabled artifacts , while showing them the input and output data values on the GUI , may help them better in testing their input action ideas . Since TUIs involve electronic components , TUI designers need to be provided with electronics as a prototyping material to enable them to visualize their ideas and figure out technically sound ideas , as found by Bdeir [ 12 ] . However , other researchers have found that building functional TUI prototypes requires skill and knowledge related to electronics and programming [ 39 , 56 ] , which act as a barrier for novices [ 82 ] . While other researchers have found that making it easy to build functional electronic prototypes by reducing implementation burden enabled designers to focus on the design of the interaction [ 82 ] , 99 and encouraged exploration of ideas [ 66 , 82 ] . In turn , in [ 12 ] , the authors suggest providing electronics as a prototyping material that the designer can easily use to build prototypes quickly . In line with these findings , in my study , I found that some participants wanted to use sensor - enabled artifacts as building blocks for prototyping to avoid reinventing the wheel by building from scratch . The sensor - enabled artifacts can be provided as pluggable modules that the users can use to build functional prototypes easily . Other researchers have found that modular plug - and - play tools facilitate exploration during electronic prototyping , as compared to raw electronic components that are relatively complex to use for building prototypes [ 3 , 81 , 82 ] . In [ 82 ] , the authors found that swapping different components , afforded by the modularity of the electronic prototyping tool , enabled exploration of a variety of interaction techniques and inspired ideas . Also , in [ 12 ] , the author found that making prototyping elements modular enabled the built designs to be extendable , upgradeable , and modifiable without requiring to restart from scratch . However , previous studies have also found that the modularity of electronic prototyping tools reduces flexibility and modifiability [ 67 , 82 ] . 100 6 . 4 . Inspirational Examples Versus Design Fixation Findings from my study Findings from other researchers Design implications Participants sought inspiration by interacting with IdeaBits and even by using Google search [ 132 ] . Design students and professionals highly value inspirational stimuli [ 29 ] . References to existing designs are omnipresent in design processes [ 28 ] . IdeaBits helped participants to get ideas by providing TUI examples , artifacts , and modeling materials as inspirational stimuli . Providing inspirational stimuli facilitates creative and innovative thinking and idea generation [ 16 , 17 , 28 , 49 , 60 , 90 ] . Provide examples of input action , input - output mapping , material , and technical implementation . Participants , at times , blindly adhered to certain concepts , aspects , and elements of the inspirational stimuli . Inspirational stimuli cause design fixation [ 28 , 50 , 68 , 98 ] . Most of the participants wanted more examples as they found them helpful . Providing multiple inspirational stimuli , involving variety , helped in idea generation [ 17 , 66 , 102 ] . Provide multiple examples involving variations . Providing examples that the user is familiar with [ 16 , 69 , 74 ] causes design fixation , while unfamiliar and ambiguous objects trigger imagination [ 49 , 90 ] . Provide examples that the users are less likely to be familiar with . Designers incorporated even negative aspects from the provided sample designs [ 50 ] . Avoid introducing examples that involve aspects that are inappropriate for the given problem statement . When provided with innovative examples , designers incorporated the principle associated with the innovative aspect [ 76 ] . Provide examples of innovative design solutions . Table 6 . 6 Summary table for “Inspirational Examples Versus Design Fixation” . In this section , I discuss the importance and benefits of providing inspirational stimuli , the possibility of inspirational stimuli causing design fixation , various strategies to minimize design fixations , challenges in avoiding design fixation , and other ways of dealing with design fixation . Design tools to aid idea generation need to provide inspirational stimuli due to two main reasons . First , designers tend to seek out inspiration as well as create their own set of stimuli . I found that while doing the design task , participants sought inspiration by interacting with artifacts and modeling materials and by studying TUI examples . They also sought inspiration beyond IdeaBits by using Google search [ 132 ] . Similar to my findings , 101 other researchers found that design students and professionals highly value inspirational stimuli [ 29 ] . In [ 28 ] , the authors found that references to existing designs ( based on memory or external records ) are omnipresent in design processes . Also , other researchers found that designers tend to collect physical or mental visual inspirational samples [ 54 ] and their past designs to be able to use those in similar future projects [ 28 ] . Second , inspirational stimuli are helpful for idea generation . I found that IdeaBits helped participants to get ideas by providing TUI examples , artifacts , and modeling materials as inspirational stimuli . Some participants mentioned that they were not able to get any ideas before they started using IdeaBits . Similar to my findings , various other researchers have found that providing inspirational stimuli facilitates creative and innovative thinking and idea generation [ 16 , 17 , 28 , 49 , 60 , 90 ] . I found that artifacts helped participants to get ideas by reminding the user of another related object or activity . Similar to my finding , in [ 60 ] , the author found that unique inspirational stimuli facilitate the creation of associations , which leads to the generation of new ideas . IdeaBits also helped participants recall their previous TIxD experience , which helped them to get ideas . Similar to my finding , in [ 28 ] , the authors found that existing designs act as pointers to design knowledge . Providing users with appropriate inspirational stimuli can help them to generate ideas . However , such stimuli may also lead to design fixation by hindering users from thinking beyond the introduced stimuli . I found that participants at times blindly adhered to certain concepts , aspects , or elements of the inspirational stimuli , leading to the generation of ideas that are similar to the stimuli . My findings are in line with those of other researchers ( e . g . [ 28 , 50 , 68 , 98 ] ) . I found that some participants who incorporated input actions introduced by IdeaBits did so in a way very similar to the prescribed way of interacting with the artifacts . For example , Eva’s idea involved squeezing a flower model using one hand , in a way similar to the prescribed way of interacting with the squeeze sensor - enabled artifact ( Figure 5 . 2 ) . Squeeze input action can , however , be incorporated in TUIs in many other ways , for example , squeezing something using both hands or by sitting on an object . Some participants mentioned being unable to think beyond the introduced ways of incorporating the input actions in TUIs . Providing multiple variations of the introduced input actions might reduce such design fixation . 102 Some of the participants who incorporated the input actions introduced by IdeaBits also incorporated other aspects of the associated sensor - enabled artifacts ( e . g . , design of the artifacts and its output ) without making any significant modifications . Similar to my finding , Eckert et al . [ 28 ] found that referring to existing designs led to incorporating more than just a solution principle for the problem at hand . They found that the designers also involved assumed aspects such as physical properties , the context of use , material , etc . which may not be valid in the new design’s context [ 28 ] . Also , in [ 66 ] , the authors found that the aesthetics and physicality of the modules in their prototyping tool Bosu evoked motion qualities of ideas that resembled these aspects . Providing multiple artifacts for introducing each input action might reduce such design fixation . Most of the participants involved graphical output in their ideas , maybe because the sensor - enabled artifacts introduced only one type of example for output - opening the linked example page . Linking sensor - enabled artifacts to different types of output may help reduce this design fixation . Most of the participants found the introduced input action examples ( artifacts and TUI examples ) to be helpful and hence wanted more of those . Also , some participants wanted to be provided with more examples as they felt that their creativity was hindered due to being introduced to only a limited number of possibilities ; since once introduced to a set of possibilities , they found it challenging to think beyond that set . I found that providing a variety of modeling materials acted as a source of inspiration for generating input action ideas , as also found by Parkes et al . [ 66 ] for generating kinetic system ideas . Other researchers have found that providing multiple inspirational stimuli , involving variety , helped in idea generation [ 17 , 102 ] as discussed next . In [ 17 ] , the authors found that architecture professionals and students generated better quality ideas when provided with multiple and diverse inspirational images . In [ 102 ] the authors suggest that providing a collection of objects that belong to the same class might encourage reflection and critical thinking on the variations across the objects in the collection , role of the materials , the essence of the class , and possibilities of adding new objects to the collection . Other researchers have found that introducing familiar examples [ 16 , 69 , 74 ] , examples resembling familiar objects [ 90 ] , and an ambiguous object using another familiar object’s name [ 49 ] caused design fixation . On the other hand , other researchers have found that unfamiliar and ambiguous objects triggered imagination [ 49 , 90 ] , unfamiliar 103 environment counterbalanced rational decision - making processes involved in idea generation [ 49 ] , and novel examples caused less design fixation [ 69 ] . Hence design tools need to provide inspirational stimuli that the participants are less likely to be familiar with . With such intentions , I designed the artifacts in IdeaBits in a generic way to avoid resemblance with any everyday objects . However , during the interview , one of the participants ( Ted ) mentioned that the stretch physical - only artifact reminded him of a landline telephone cord . It might not be possible to completely ensure that the artifacts do not resemble any familiar objects . Therefore , it might help to use additional approaches to reduce the chances of the users connecting the artifacts with familiar objects , such as putting the artifacts in an unusual context as done by Plasencia et al . [ 72 ] and Wilde et al . [ 106 ] . They found that the approach helped in idea generation by providing the users a new perspective on the artifacts’ affordance , potential , use , and how they could be interacted with . Some participants mentioned that they did not try to incorporate from IdeaBits due to the given instruction – “You can incorporate any input action in your idea , and you are not restricted to the input actions in IdeaBits . ” Design fixation might be reduced by providing such instructions or by encouraging the users to think beyond the provided examples . These instructions can be provided by the course instructor or incorporated into the design tool . Avoiding design fixation is challenging , if not impossible . Even if a design tool does not provide inspirational stimuli , designers may look for inspiration elsewhere , as found by other researchers [ 28 , 29 , 54 ] and in my study where a few participants used Google search [ 132 ] . Other researchers have also found that designers can be influenced by external stimuli and what surrounds them even unconsciously or by chance [ 37 , 41 , 86 ] . Similarly , I found in my study that some participants generated ideas that were inspired by and resembled certain existing TUIs which they had come across earlier . Also , some participants mentioned that before using IdeaBits , they were fixated on the limited types of input actions ( e . g . , pressing button , touch , slide ) found in everyday devices such as smartphones and laptops . Hence , design tools to aid idea generation for TUIs may benefit from introducing input actions beyond the ones commonly found by opening users’ minds to other possibilities , as found in my study . 104 Jansson et al . [ 50 ] found that providing sample designs led the designers to incorporate both positive and negative aspects of the samples . Thus the drawbacks of design fixation may reduce if example designs that involve flaws or aspects which are inappropriate for the given problem statement are avoided , as suggested by Purcell et al . [ 76 ] . At the same time , design fixation can also be taken advantage of by providing examples of innovative design solutions as it may lead the designers to incorporate the principle associated with the innovative aspect of the example , as found by Purcell et al . [ 76 ] . 6 . 5 . Technical Implementation Guidance Findings from my study Findings from other researchers Design implications Some participants changed their ideas when they found it challenging to plan its technical implementation . Most of the participants faced challenges in figuring out the technical implementation of their input action ideas . Participants were unable to understand the technical implementation of sensor - enabled artifacts where the involved electronic components were not visible . Exposure to raw electronic components helps the user learn the involved concepts , as found by the creators of Arduino [ 133 ] . Enable to access the electronic components in the sensor - enabled artifacts . Few participants felt that being introduced to technical implementation information limited their creativity by giving a reality check related to the feasibility of ideas . Introducing technical implementation details reduce creative confidence [ 81 ] . Provide technical implementation information when the user makes an active choice to access it . Some participants found it time taking to use the “Tech” button . Provide technical implementation information within the GUI . Being able to interact physically and experiment with the sensor - enabled artifacts helped participants to uncover the fundamental concepts of the involved electronic components and then use those concepts to plan the technical implementation of their input action ideas . Experimentation with prototyping modules helped users to understand how they could directly use the basic electronic components involved in these modules [ 49 ] . Provide interactive artifacts that encourage and facilitate experimentation with the involved electronic components . Table 6 . 7 Summary table for “Technical Implementation Guidance” . In this section , I discuss the importance of providing technical implementation guidance followed by recommendations on how to provide such guidance - involving more input actions and outputs , enabling to access the electronic components in the sensor - 105 enabled artifacts , providing technical implementation information when the user makes an active choice to access it , providing technical implementation information within the GUI , and providing interactive artifacts that encourage and facilitate experimentation with the involved electronic components . Design tools to support idea generation for TUIs may benefit from providing technical implementation guidance . Finding it challenging to plan the technical implementation of one’s idea might lead them to change their idea , as I found to be done by some participants in my study . Doing so may lead to generation and selection of TUI ideas involving input actions that are commonly found in everyday devices , due to the likelihood of the designers being aware of their technical implementation . Hence to encourage TUI designers to explore a wide variety of input actions , the design tool needs to support planning the technical implementation of the generated input action ideas . I found that most of the participants faced challenges in planning the technical implementation of their input action ideas , for both input action introduced by IdeaBits and input actions not introduced by IdeaBits , despite technical implementation guidance provided in IdeaBits . Hence it may help to redesign the way IdeaBits provides technical implementation guidance . Participants perceived technical implementation of the sensor - enabled artifacts as a set of introduced possibilities . However , they were unable to understand the technical implementation of the artifacts where the opaqueness of the artifact concealed the involved electronic components , such as squeeze and pull sensor - enabled artifacts . It might help to design the artifacts in a way that users can easily open them up to see the involved technical implementation when they want to access that information . Exposure to raw electronic components helps users learn the involved concepts , as found by the creators of Arduino [ 133 ] . It might not be ideal if the artifacts are designed in a way that they reveal the involved electronic components upfront , such as the fold sensor - enabled artifact , since introducing technical implementation details may reduce creative confidence as found by Sadler et al . [ 81 ] as well as in my study as discussed in the theme “Challenges in Using IdeaBits” . Similarly , it might help to provide even other technical implementation information in IdeaBits in a way such that it is not displayed upfront ( e . g . , the “Tech” button in the GUI of IdeaBits ) but rather only when the user makes an active choice to access it . For example , when a user plugs in the sensor - enabled artifacts to say a technical implementation inquiry platform , then IdeaBits would display the associated technical implementation information . 106 It may help to provide technical implementation information within the GUI of IdeaBits . Other researchers have found that when introduced to a new sensor , designers usually inquire about how it works and what raw data it involves before incorporating it in their ideas , based on which they suggest providing quick and easy access to this information [ 82 ] . Similarly , I found in my study that to understand a sensor , participants wanted to know the involved data type , sensitivity , and how to use them . Participants mentioned that the “Tech” button provided them with the major electronic components they would require to detect the input actions introduced by IdeaBits , how to use these components , and the involved data type . However , some participants found it time taking to use the “Tech” button . The information provided by the “Tech” button can be designed in a way such that the users can quickly consume it . For example , it might be better to provide the information within the GUI instead of redirecting the user to a web browser , which some participants even mentioned to dislike . It will also provide freedom to design the information organization , hierarchy , presentation , and delivery formats in a way that ensures smooth and fast consumption while appropriating it to the specific goals of the tool . It may help to introduce technical implementation possibilities in the form of interactive artifacts , rather than text or video or image , which encourage and enable users to do hands - on experimentations and explorations . Being able to interact physically and experiment with the sensor - enabled artifacts , while getting feedback from the output , to understand their technical implementation helped participants to uncover the fundamental concepts of the involved electronic components . Similar to my findings , the authors found that experimentation with physical Bosu modules helped users to understand how they could directly use the basic electronic components involved in these modules , e . g . , raw actuators and nitinol strands , to build their ideas [ 49 ] . Understanding the fundamental concepts of the electronic components in the sensor - enabled artifacts helped participants use these concepts for detecting different variations of the input actions involved in the artifacts , as well as for detecting input actions not introduced by IdeaBits . Additionally , showing the output and input data values of the sensor - enabled artifact , as suggested by some participants , along with enabling them to tweak the sensitivity , may help users better to understand the technical implementation of the artifacts . 107 6 . 6 . Generalization Other researchers caution about generalization in qualitative studies [ 35 ] and state particularity rather than generalizability to be the key characteristic of qualitative research [ 20 ] . As an exception , some researchers consider qualitative case studies to be generalizable , provided a large number of cases are studied along with detailed documentation of the procedures in order to generalize the findings to new cases [ 110 ] . However , researchers usually hesitate to generalize even in case studies due to the different contexts of each case [ 21 ] . I conducted a qualitative case study for evaluating IdeaBits involving only one case . Hence I do not intend to generalize the findings of my study . However , in this section , I discuss how one may explore the applicability of some of the design implications of my study outside the specific case I investigated . Although I studied novice TIxD students , the design implications may be beneficial for other populations such as intermediate or even expert TIxD students and tangible interaction designers with varying levels of expertise . I focused on input action and only those involving hands . However , the design implications , as is or appropriately modified , may be beneficial for other types of input action as well as for idea generation of other aspects of TUIs such as output , input - output mapping , material , and overall concept . For example , it may be beneficial to support the hands - on exploration of tangible output possibilities and facilitate users to focus on experiencing the output by enabling on - demand automation of input actions in order to prevent being distracted by having to perform the input actions . The design implication of enabling users to experience the input actions may be beneficial with appropriations for other domains that involve embodied interaction ( e . g . , gestural interfaces , virtual reality , sports , dance ) and designing of products involving moving components ( e . g . , mechanical design , robotics , product design ) . The design implication of providing a variety of materials may be beneficial for design and other domains dealing with physical and material aspects ( e . g . , industrial design , product design , architecture , fashion design , interior design ) . The design implication for encouraging and supporting hands - on exploration may be beneficial for creative activities and idea generation in general . For example , providing ambiguous and interactive inspirational cues having open - ended interaction possibilities 108 and no set goals which yield varied unexpected outcome when interacted with based on how the user interacts may trigger creative thinking . In turn , the design implications related to making such cues visibly technically robust may be beneficial to encourage and support playful and worry - free explorations without hindrances from technical malfunctioning . The design implications related to providing domain - based examples may be beneficial for novices in other domains , especially those involving abstract concepts which can be understood through examples ( e . g . , internet of things , augmented reality ) and those which put an emphasis on studying existing products ( e . g . , GUI design , architecture ) . Moreover , the design implications related to minimizing design fixation may be beneficial in these cases . Similar to the design implication of providing a variety of examples for the various aspects of TUIs , designing of products involving aspects with many possibilities may benefit from a catalog or library of the possible aspects and examples . For example , catalogs of interaction possibilities with GUI , joints in furniture design , materials for fashion design , etc . The design implications around enabling prototyping may be beneficial for other domains that involving designing physical products with or without electronics ( e . g . , product design , robotics , architecture , interior design , civil engineering , electrical and electronics engineering , mechanical engineering ) . These domains , along with other domains involving complicated technical implementation requirements ( e . g . , user interface engineering ) , may benefit from the design implication of providing technical implementation guidance only when users make an active choice to access it . Additionally , designing of products involving electronics may benefit from the design implication of enabling to access the electronic components in the prototyping modules along with encouraging and facilitating experimentation with these components . 6 . 7 . Limitations While this study presents promising opportunities in TUI design space , there are certain limitations . 109 6 . 7 . 1 . Process Followed to Design IdeaBits I am aware of certain limitations of the design process I followed to design IdeaBits . Designing IdeaBits as a course project of IAT 882 had several advantages , as discussed in Chapter 3 . It , however , also had certain limitations . Designing IdeaBits for a project of the course which involved grades may have influenced the design process as well as the design of IdeaBits . The course project involved various constraints such as a limited amount of time , fixed timelines , minimal financial budget , and requirement of working individually . To manage these constraints , I had to limit the extent of user involvement in the process and exploration of multiple alternatives and iterative refining while designing the tool , as discussed in chapter 3 . I interviewed only three participants . Screened through convenience sampling , the participants were also not necessarily a representative set of the target users . I knew the participants as my classmates , which may have biased whom I screened for the interviews based on my comfort level with them , especially because I could not provide incentives for participating in the study due to limited financial budget . Having acquaintance and a pre - established comfort level with the participants , however , helped in having an in - depth conversation during the interview . The interviews involved discussing the participants’ IAT 882 project . Hence the findings may have been influenced by the specific aspects of the project and the course . Moreover , since I was an IAT 882 student , I might have had presumed some of the aspects of the project and related experiences that I might have missed to clarify with the interviewees to know their perspectives on the same . Similarly , the interviewees may have skipped certain details while assuming that I might already be aware of those . All the participants being from IAT 882 , the aspects of the course , including those of the course project , and the department’s specific education and culture might have influenced the findings . My findings may have gender bias since all the participants were male . For all the participants , the course project of IAT 882 was their first and only project involving designing TUIs . Also , none of them had completed the project when I conducted the interviews . Hence , they had very limited experience of generating TUI and input action ideas , which were limited to the specific course project , early phases of the design process , and having no experience of designing TUIs in groups , which may have 110 influenced the findings . Also , the participants’ responses may have been influenced by the project being their only experience of designing TUIs and hence having no other experience to compare with , being their first TIxD project while also being enrolled in their first - ever TIxD course , the specific problem statement they chose to address , and their experience of the course in general . Formal collection and analysis of data , to understand the target users and the activity involved in the problem I was addressing , only involved the interview data . I conducted only one one - hour interview with each of the participants . Also , the interview data , however , involved a retrospective account of the interviewees’ experience of working on the IAT 882 project . Hence the findings may involve bias . Also , even though the project was recently started and one on which they were actively working those days , the interviewees found it challenging to recall certain specifics . To address this , I encouraged them to refer to the traces of the project and their process , as discussed in Chapter 3 . I was the only person analyzing the interview data , and hence the results may be biased . My participation in the course to gain an understanding of the target users and idea generation for TUI input actions was informal , with no formal methods used for data collection and analysis . Formalizing the data collection and analysis might have helped build a better understanding of the target users and the activity . To refine the first prototype of IdeaBits , I used quick evaluation methods , including a heuristic evaluation and collecting feedback from my supervisor and a lab mate from the TECI lab . I did the heuristic evaluation myself , even though I was not an expert in TIxD or HCI . Conducting the heuristic evaluation with three to five experts might have helped in identifying around 80 % of the usability problems [ 1 , 62 ] . These potential usability issues of IdeaBits , which remained unidentified and hence unfixed , may have affected the participants ' experience of using the tool during the exploratory evaluation of the tool , thus influencing the findings . Even though the focus of my work being on building a research instrument than a promising solution supported making the decisions discussed above to manage the course constraints , the work may have benefitted from more involvement of the users in the process such as in - depth user studies , involving more users , and involving the secondary users such as TIxD instructors in the design process or considering the effect of the tool on them as suggested in [ 1 , 27 ] , along with conducting an iterative and rigorous 111 process of designing the tool in a multidisciplinary team such as RtD [ 111 – 113 ] and UCD [ 1 ] . I started conceptualizing IdeaBits before conducting the interviews . Hence the conduction and analysis of the interviews may have biases . To refine the focus of my project , based on its scope , I narrowed down input actions to only those that involve interacting with the TUIs through hands . Accordingly , I involved only these input actions in the catalog I made of TUI input actions [ 9 ] as well as in IdeaBits . 6 . 7 . 2 . User Study to Evaluate IdeaBits I am aware of four limitations of the user study conducted to evaluate IdeaBits . The first limitation is that the study was conducted in an experimental setup involving a controlled environment , as described in chapter 4 . Users may use IdeaBits in a different way when they use it in the environment in which they usually design . In addition , being videotaped and observed might have influenced their task performance and interaction with IdeaBits . The study involved the users completing the design task individually . Users may use IdeaBits in a different way when they work in groups . The participants had limited and brief interaction when IdeaBits when I introduced them to the tool for the first time before the design session . Hence they used the tool as a first time user during the design session and had only an hour during which they could interact with it , while also being asked to perform a design task new to them and in a domain in which they were novices . Hence they had limited time in hand while being in a complex and unfamiliar task environment . This might have affected participants’ performance in the task , interaction with IdeaBits , and responses during the interview . Also , while analyzing the interview data , I could not always disambiguate if the participants’ responses were based on their experiences of learning to use IdeaBits or using IdeaBits to perform the task . Users may use IdeaBits differently over an extended period of time . The participants used IdeaBits for participating in the user study while performing a particular design task provided for the study . Users may use IdeaBits differently while not being part of a study , e . g . , when generating TUI ideas for coursework involving grades . Also , the design task involved a specific design problem of designing for communicating emotion while involving the self as a user ( discussed the rationale in Chapter 4 ) . There is an infinite amount of possible TIxD problems . Users may use IdeaBits 112 in a different way to do other types of design tasks and while designing for other users . I found that users could easily relate emotions with actions , which might have helped them to come up with a variety of input action ideas . Conducting a study by giving a task where such an association cannot be easily made might help get additional insights . Also , users may use IdeaBits differently when designing a product which is meant to be used in a serious or risk involving scenario , in contrast to emotion communication tool which is meant to be used in a relatively safe environment . The second limitation is the absence of a control group . The study does not compare the users’ experience of designing TUIs by using IdeaBits and without using IdeaBits , which makes it challenging to know the effectiveness of the tool . One of the participants ( Ben ) did not use IdeaBits for generating his first idea but for a second idea . During the interview , he compared his experience of generating these two ideas , which provided valuable insights . Hence , having a control group might provide additional insights . The third limitation is that the participants were selected from limited demographics , involving students from only SIAT , SFU . Therefore , the department’s specific education and culture might have influenced the findings . Screening users based on their competency in TIxD , in addition to their experience , might help separate the findings based on different personas . Also , it might give additional insight if participants are segregated based on their educational and work background other than just being novices in TIxD . For example , in [ 75 ] , the authors found that design fixation caused by inspirational stimuli was dependent on the domain of the designer . Also , a user study with other stakeholders such as TIxD course instructors , intermediate or expert TIxD students may help to find additional valuable insights from these different perspectives . The fourth limitation is that even though the participants were novice TIxD students , not all of them might have been novices in terms of their expertise in electronics since , during screening , I did not assess or consider their expertise level related to electronics . Hence the findings of my study , especially findings related to RQ3 . 2 , are based on a group of unsegregated participants with varied levels of expertise related to electronics . 113 There were certain limitations in the analysis of the data collected from the user study conducted to evaluate IdeaBits . Only the interview data were analyzed as the primary data , while the remaining data as supplementary data . The interview data involved a retrospective account of the design session activities and participants’ experience of using IdeaBits to perform the design task . Hence the findings may involve bias . However , to increase validity , I crosschecked participants’ interview responses with the video recording of the sessions since the later contained genuine data of the session activities . Also , I was the only person analyzing some of the data , and hence the related results may be biased . I was the only person to analyze six out of the twelve interviews . However , I discussed my analysis with the other researcher with whom I had analyzed the other six participants’ interview data . Moreover , I analyzed all the twelve participants’ interview data twice , as discussed in chapter 4 . I was the only person to analyze eight out of the twelve participants’ deliverable 4 , all twelve participants’ deliverable 3 , video recordings of the design sessions , and remote observation notes . These data were , however , analyzed as supplementary data and not primary data , as discussed in chapter 4 . Also , I was the only person doing the remote observation and taking observational notes , which also informed some questions that I asked during the interview . 6 . 8 . Future Work Based on my findings and the points discussed in this chapter , I now discuss certain ideas that can be explored in future work . Changes in the design of the artifacts : The sensor - enabled artifacts can be designed to be non - prescriptive for the associated input actions , while having multiple affordances and visibly robust technical implementation , to encourage and support worry - free exploration . The output of the sensor - enabled artifacts can be made subtle and unexpected to facilitate non - distractive playful exploration . Bluetooth connectivity can be used for connecting the sensor - enabled artifacts to the Arduino Uno board [ 116 ] in order to facilitate moving around in the space . Also , the sensor - enabled artifacts can be designed as plug - and - play modules to enable building prototypes easily . The sensor - enabled artifacts can be designed in a way that the user can easily open them up to access the raw electronics for better understanding the technical implementation of the artifacts . Once they understand the fundamental concepts of these raw electronic components , they 114 can as well plug out these components to directly use them for more flexibility in prototyping . Changes in the way IdeaBits provides technical implementation guidance : The information can be provided within the GUI , along with designing the organization , hierarchy , and presentation of the information to facilitate quick consumption . For example , the input and output data associated with the sensor - enabled artifacts can be displayed to help users better understand the technical implementation of the sensor - enabled artifacts by directly interacting with them . The technical implementation information can be provided in a way that it is visible only when the user makes an active choice to access it . This can be done by providing a technical implementation inquiry platform where the user can plug the sensor - enabled artifact to access this information . Adding more examples along with more variety : One can introduce more input actions examples ( especially moving beyond input actions that involve only interaction through hands ) , multiple variations of each of the input actions , more TUI examples for each of the input actions , and more examples of output . Exploring other design processes and methods : One can take a different approach for designing a product to address the problem , “Novice TIxD students finding it challenging to generate input action ideas for TUIs” , such as RtD [ 111 – 113 ] and UCD [ 1 ] . One can have more involvement of the users in the design process by involving more users , novice TIxD students with varied experiences and background ( e . g . , from different courses and institutions ) , rigorous screening of participants to get a representative set of the target users , secondary and tertiary users , and methods other than interviews such as observation [ 14 ] , contextual inquiry [ 13 ] , participatory design [ 85 ] , etc . One can also take an iterative and rigorous process of designing the tool by exploring multiple alternatives and iteratively refining the final product . Exploring other data analysis and user study design ideas : One can do a detailed analysis of the video recordings of the design sessions with at least one other researcher , including analysis of the participants’ action sequence ( e . g . [ 61 ] ) . An expert review of IdeaBits can be conducted , along with additional user studies addressing some of the limitations of my study discussed earlier . For example , one may conduct a formal heuristic evaluation [ 1 , 62 ] to figure out critical usability issues with IdeaBits . Also , one may 115 conduct a contextual user study , ideally after conducting the heuristic evaluation and addressing the issues identified , where IdeaBits is used by the participants in their usual environment in which they generate TUIs ideas and while they use it over an extended period to work on a TIxD course project . One can add on to and enhance the catalog I made of artifact mediated input actions for TUIs that involve interaction through hands [ 9 ] . The enhanced catalog can thereafter be analyzed and organized into a structured library or taxonomy of input actions in TUIs , similar to Haptipedia [ 87 ] ( a force - feedback device corpus ) . Extending the design implications beyond the case investigated : Once can investigate and explore the applicability of the design implications I provided to other population ( e . g . , intermediate and expert TIxD students and designers ) , other aspects of TIxD ( e . g . , output , material , overall concept ) , and other domains ( e . g . , gestural interfaces , augmented and virtual reality , robotics , architecture ) as discussed in 6 . 6 Generalization . 116 Chapter 7 . Conclusions In this thesis , I attempted addressing the lack of tools to support idea generation for TUI input actions . Novice TIxD students often find it difficult to generate ideas for TUI input actions . I addressed this problem by designing and evaluating a tool called IdeaBits as an exploratory research instrument . I investigated what might be the key design features of a tool to aid novice TIxD students in generating TUI input action ideas ( RQ1 ) . The method involved a non - linear process with four inter - related components : 1 ) Participation in a TIxD course ; 2 ) Conceptualization of IdeaBits ; 3 ) Interviews to understand TIxD practices ; and 4 ) Prototyping of IdeaBits . The outcome of the process was the first iteration of IdeaBits prototype , a tool consisting of interactive physical artifacts coupled with digital examples of TUIs and technical implementation guidance to aid novice TIxD students to generate ideas for TUI input actions . I then conducted a semi - formal evaluation of the prototype to identify some of its issues . I developed the second iteration of IdeaBits prototype to fix the identified issues by making certain changes to the hardware , instruction , GUI , and code . The objective behind the design process of IdeaBits was to quickly build a research medium that can be evaluated to identify ways in which potential support can be provided to novice TIxD students for generating input action ideas along with things that should be looked out for or avoided . For the exploratory evaluation , I conducted a user study with twelve novice TIxD students investigating how they might use the tool ( RQ2 ) , perceive its’ support in the generation of input action and technical implementation ideas ( RQ3 ) , and face challenges while using the tool ( RQ4 ) . I had five significant findings from this study . First , providing interactive artifacts and modeling materials helped novice TIxD students to generate input action ideas by enabling them to experience the input actions . Interacting with the physical - only artifacts required them to imagine the possible consequences of the interactions due to the absence of output . While getting the output on interacting with the sensor - enabled artifacts enabled them to understand how they could incorporate the input actions in TUIs . However , the opening of the associated example page in the GUI on interacting with the sensor - enabled artifacts distracted the participants from focusing on 117 experiencing the input actions . It also confused them by resulting in two different controllers for the GUI . Second , the sensor - enabled artifacts and modeling materials encouraged exploration of input actions by triggering curiosity and facilitated it with flexible affordances ( of sensor - enabled artifacts ) , open - ended interaction possibilities ( of modeling materials ) , and interactivity ( output of sensor - enabled artifacts providing feedback ) . Such explorations helped participants to get ideas for input actions involving variations of input actions introduced by IdeaBits as well as input actions not introduced by IdeaBits . Third , building and interacting with the prototypes that the participants made using modeling materials helped them realize issues in their ideas , make design decisions , and get ideas related to input action , output , and technical implementation . Although sensor - enabled artifacts were not designed to be used for building prototypes , having output associated with the artifacts enabled participants to test the technical feasibility of their input action ideas . Participants wanted to build prototypes using the sensor - enabled artifacts to avoid building ideas from scratch . Fourth , while doing the design task , participants sought inspiration by interacting with the modeling materials and artifacts and by studying the TUI examples . These components of IdeaBits acted as inspirational stimuli by helping participants to get ideas and recall their previous TIxD experience . However , the inspirational stimuli at times also led to design fixation . On the other hand , providing examples of input actions beyond the ones commonly found in everyday devices ( e . g . , touch , and button press ) helped participants not to be fixated on those limited possibilities . Participants suggested providing more examples as they found them to be helpful and also because they felt that design fixation occurred due to being introduced to only a limited number of possibilities . Fifth , despite technical implementation guidance provided in IdeaBits , participants found it challenging to plan technical implementation for their ideas . To understand a sensor , participants wanted to know the involved data type , sensitivity , and how to use them . Such information was provided in the “Tech” button ; however , some participants found it time - consuming to use it . Participants suggested providing the technical implementation information within the GUI , along with showing the input and output data values of the sensors when they interacted with the sensor - enabled artifacts . When the 118 electronic components were concealed in the opaque sensor - enabled artifacts , participants found it challenging to understand the technical implementation of the artifacts . However , physically interacting and experimenting with the artifacts , while getting feedback from the output , helped them to understand the technical implementation of the artifacts and uncover the fundamental concepts of the involved electronic components . Understanding such fundamental concepts helped participants to come up with technical implementation ideas that varied from the technical implementation of the sensor - enabled artifacts as well as to use the concepts to detect input actions not introduced by IdeaBits . Based on the findings of my study and existing literature , I suggested five main design implications for tools to support novice TIxD students in generating TUI ideas . 1 . Enable to experience the input actions by providing a variety of interactive artifacts involving subtle output . 2 . Encourage and facilitate hands - on exploration by providing interactive artifacts . The artifacts can be designed to trigger curiosity through ambiguity , be open for interpretation in terms of how they can be used or interacted with , have open - ended interaction possibilities , and have an output ( preferably unexpected output that provides a sense of discovery ) for providing feedback . Simultaneously , minimize possibilities of technical malfunctioning and enable easy recovery from possible malfunctioning , while making the artifacts visibly robust to encourage worry - free exploratory interactions . 3 . Facilitate to easily build , interact with , and quickly modify prototypes by providing the sensor - enabled artifacts as pluggable modules that reduce implementation burden for novices in terms of required skill and knowledge related to electronics and programming . 4 . Provide inspirational examples for various aspects of TUIs , such as input action and output , in the form of interactive artifacts and digital examples of TUIs . Simultaneously attempt to minimize the possibility of design fixation by providing multiple and diverse examples , avoiding familiar examples , and making the user aware of design fixation . Additionally , one may attempt to minimize the effect of design fixation by providing examples involving innovative design principles while avoiding examples with negative aspects . 5 . Provide technical implementation guidance for multiple and diverse input actions and outputs , when the user makes an active choice to access it , through interactive 119 artifacts that encourage and facilitate experimentation with the involved electronic components . My work makes five main contributions . First , my work contributes knowledge related to how novice TIxD students generate TUI ideas and what challenges they face . This knowledge can provide valuable insights to designers , researchers , and instructors in the domain of TIxD , for example , by informing the design of TIxD tools and TIxD course instructions , materials , and activities . Second , I contribute design knowledge from the design and implementation of IdeaBits , an open - sourced tool to aid idea generation for TUI input actions [ 99 ] , as an exploratory research instrument . The process of designing this research instrument by involving four situation - specific inter - related components would guide other designers and researchers designing design tools as research instruments . The specific design knowledge generated from the process , related to the design of interactive artifacts for supporting the generation of input action ideas , selection and presentation of input action examples in the form of artifacts and digital examples of TUIs , design of technical implementation guidance for TUIs , as well as the prototype IdeaBits itself , would provide some initial standards for other designers designing similar tools to support idea generation in the domain of TIxD or other similar design domains . Third , I made a catalog of artifact mediated input actions for TUIs involving interaction through hands [ 9 ] , which can act as a preliminary library of TUI input actions for TIxD researchers , designers , instructors , and students . Fourth , the results from the evaluation of IdeaBits provide a foundation for other researchers to build upon while conducting further research on this topic in the future . Fifth , I provided a set of design recommendations for tools to support novice TIxD students in generating TUI ideas , which can be used by designers as guidelines while designing such tools . These recommendations can also be explored for their generalizability to other user groups , such as intermediate or expert TUI designers , or other similar domains , such as product design or architecture . While this study presents promising opportunities , it has certain limitations . Designing IdeaBits as an IAT 882 project introduced multiple constraints . To manage these constraints , I had to limit the extent of user involvement in the process by considering only primary users , screening participants using convenience sampling , having only three participants and involving limited demographics , and using only interviews , that were conducted only once with each participant , to formally collect data 120 which was also analyzed by only myself . I also had to limit the exploration of multiple alternatives and iterative refining while designing IdeaBits . These limitations can be addressed by taking other approaches for designing a product to address the problem , “Novice TIxD students finding it challenging to generate input action ideas for TUIs” , such as RtD [ 111 – 113 ] and UCD [ 1 ] which entails more involvement of the users in an iterative and rigorous design process . There are certain limitations of the evaluation of IdeaBits , including the study being conducted in an experimental setup , absence of control group , limited demographic of the participants , not considering participants’ expertise level related to electronics , and analysis of a part of the data by only myself . Some of these limitations can be addressed by conducting a study in an actual context of use , involving a wider demographic among the participants , and further analyzing the data collected in this study . 121 References 1 . Chadia Abras , Diane Maloney - krichmar , and Jenny Preece . 2004 . User - Centered Design . In In Bainbridge , W . Encyclopedia of Human - Computer Interaction . Thousand Oaks : Sage Publications . 2 . Rawan Alharbi , Nabil Alshurafa , and Michael Horn . 2017 . Intuito : Opportunistic Tangible Programming by Demonstration for Physical Components . In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems , 2322 – 2328 . 3 . S . Analytis , J . Sadler , and M . R . Cutkosky . 2015 . Paper Robot : A Design Activity to Increase Beginner’s Prototyping Confidence with Microcontrollers . The Design Society - a worldwide community . Retrieved February 2 , 2020 from https : / / www . designsociety . org / publication / 36123 / Paper + Robot % 3A + A + Design + A ctivity + to + Increase + Beginner % E2 % 80 % 99s + Prototyping + Confidence + with + Micr ocontrollers 4 . Alissa N . Antle . 2008 . Inquiring materials for tangible prototyping . 139 – 140 . https : / / doi . org / 10 . 1145 / 1347390 . 1347420 5 . Alissa N . Antle , Leslie Chesick , Aaron Levisohn , Srilekha Kirshnamachari Sridharan , and Perry Tan . 2015 . Using Neurofeedback to Teach Self - regulation to Children Living in Poverty . In Proceedings of the 14th International Conference on Interaction Design and Children ( IDC ’15 ) , 119 – 128 . https : / / doi . org / 10 . 1145 / 2771839 . 2771852 6 . Alissa N . Antle , Milena Droumeva , and Greg Corness . 2008 . Playing with the Sound Maker : Do Embodied Metaphors Help Children Learn ? In Proceedings of the 7th International Conference on Interaction Design and Children ( IDC ’08 ) , 178 – 185 . https : / / doi . org / 10 . 1145 / 1463689 . 1463754 7 . Alissa N . Antle , Min Fan , and Emily S . Cramer . 2015 . PhonoBlocks : A Tangible System for Supporting Dyslexic Children Learning to Read . In Proceedings of the Ninth International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’15 ) , 533 – 538 . https : / / doi . org / 10 . 1145 / 2677199 . 2687897 8 . Alissa N . Antle , Alyssa F . Wise , Amanda Hall , Saba Nowroozi , Perry Tan , Jillian Warren , Rachael Eckersley , and Michelle Fan . 2013 . Youtopia : A collaborative , tangible , multi - touch , sustainability learning activity . In Proceedings of the 12th International Conference on Interaction Design and Children ( IDC ’13 ) , 565 – 568 . https : / / doi . org / 10 . 1145 / 2485760 . 2485866 9 . Uddipana Baishya . Library of input actions in TUIs . Google Docs . Retrieved March 22 , 2020 from https : / / docs . google . com / spreadsheets / d / 1mDj8fw7ygOgyKnxygT - 7Ej26Z8Vs8yFWVaYuSBi3s68 / edit ? usp = sharing & usp = embed _ facebook 122 10 . Uddipana Baishya , Alissa N . Antle , and Elgin - Skye McLaren . 2019 . Idea Bits : A Tangible Design Tool to Aid Idea Generation for Tangible Manipulation . In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI EA ’19 ) , LBW0135 : 1 – LBW0135 : 6 . https : / / doi . org / 10 . 1145 / 3290607 . 3312820 11 . Saskia Bakker , Alissa N . Antle , and Elise van den Hoven . 2012 . Embodied metaphors in tangible interaction design . Personal and Ubiquitous Computing 16 , 4 : 433 – 449 . https : / / doi . org / 10 . 1007 / s00779 - 011 - 0410 - 4 12 . Ayah Bdeir . 2009 . Electronics As Material : LittleBits . In Proceedings of the 3rd International Conference on Tangible and Embedded Interaction ( TEI ’09 ) , 397 – 400 . https : / / doi . org / 10 . 1145 / 1517664 . 1517743 13 . Hugh Beyer and Karen Holtzblatt . 1998 . Contextual Design : Defining Customer - Centered Systems . Morgan Kaufmann . 14 . A . E . Blandford . 2013 . Semi - structured qualitative studies . In The Encyclopedia of Human - Computer Interaction , M . Soegaard and R . Dam ( eds . ) . Interaction Design Foundation , Denmark . Retrieved June 13 , 2020 from http : / / www . interaction - design . org / encyclopedia / semi - structured _ qualitative _ studies . html 15 . Marion Buchenau and Jane Fulton Suri . 2000 . Experience prototyping . In Proceedings of the 3rd conference on Designing interactive systems : processes , practices , methods , and techniques ( DIS ’00 ) , 424 – 433 . https : / / doi . org / 10 . 1145 / 347642 . 347802 16 . Hui Cai , Ellen Yi - Luen Do , and Craig M . Zimring . 2010 . Extended linkography and distance graph in design evaluation : an empirical study of the dual effects of inspiration sources in creative design . Design Studies 31 , 2 : 146 – 168 . https : / / doi . org / 10 . 1016 / j . destud . 2009 . 12 . 003 17 . Hernan Casakin . 2005 . DESIGN AIDED BY VISUAL DISPLAYS : A COGNITIVE APPROACH . Journal of Architectural and Planning Research 22 , 3 : 250 – 265 . 18 . Billy Cheng , Maxine Kim , Henry Lin , Sarah Fung , Zac Bush , and Jinsil Hwaryoung Seo . 2012 . Tessella : Interactive Origami Light . In Proceedings of the Sixth International Conference on Tangible , Embedded and Embodied Interaction ( TEI ’12 ) , 317 – 318 . https : / / doi . org / 10 . 1145 / 2148131 . 2148200 19 . Jean Costa , Alexander T . Adams , Malte F . Jung , François Guimbretière , and Tanzeem Choudhury . 2017 . EmotionCheck : A Wearable Device to Regulate Anxiety through False Heart Rate Feedback . GetMobile : Mobile Computing and Communications 21 , 2 : 22 – 25 . https : / / doi . org / 10 . 1145 / 3131214 . 3131222 20 . John W . Creswell and J . David Creswell . 2018 . Research design : qualitative , quantitative , and mixed methods approaches . SAGE , Los Angeles . 123 21 . John W . Creswell and Cheryl N . Poth . 2018 . Qualitative inquiry & research design : choosing among five approaches . SAGE , Los Angeles . 22 . Barbara DiCicco ‐ Bloom and Benjamin F . Crabtree . 2006 . The qualitative research interview . Medical Education 40 , 4 : 314 – 321 . https : / / doi . org / 10 . 1111 / j . 1365 - 2929 . 2006 . 02418 . x 23 . Jelle van Dijk . 2013 . Creating traces , sharing insight : Explorations in embodied cognition design . https : / / doi . org / 10 . 6100 / IR759609 24 . Jelle van Dijk , R J & Van der Lugt , and R van der Lugt . 2013 . Scaffolds for shared understanding . AIEDAM Special Issue on design communication . 25 . Jelle van Dijk and Gerrit Willem Vos . 2011 . Traces in creative spaces . In Proceedings of the 8th ACM conference on Creativity and cognition ( C & amp ; C ’11 ) , 91 – 94 . https : / / doi . org / 10 . 1145 / 2069618 . 2069634 26 . Joseph S . Dumas , Joseph S . Dumas , and Janice Redish . 1999 . A Practical Guide to Usability Testing . Intellect Books . 27 . K . D . Eason . 1989 . Information Technology And Organisational Change . CRC Press . 28 . Claudia M Eckert , Martin Stacey , and Christopher Earl . 2005 . References to past designs . Studying designers 5 , 2005 : 3 – 21 . 29 . Claudia Eckert and Martin Stacey . 2000 . Sources of inspiration : a language of design . Design Studies 21 , 5 : 523 – 538 . https : / / doi . org / 10 . 1016 / S0142 - 694X ( 00 ) 00022 - 3 30 . Paul Ekman , E . Richard Sorenson , and Wallace V . Friesen . 1969 . Pan - Cultural Elements in Facial Displays of Emotion . Science 164 , 3875 : 86 – 88 . https : / / doi . org / 10 . 1126 / science . 164 . 3875 . 86 31 . Gerhard Fischer and Kumiyo Nakakoll . 1994 . Amplifying Designers’ Creativity with DomainOriented Design Environments . In In T . Dartnall ( eds . ) , Artificial Intelligence and Creativity , 343 – 364 . 32 . Jonas Frich , Lindsay MacDonald Vermeulen , Christian Remy , Michael Mose Biskjaer , and Peter Dalsgaard . 2019 . Mapping the Landscape of Creativity Support Tools in HCI . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19 , 1 – 18 . https : / / doi . org / 10 . 1145 / 3290605 . 3300619 33 . Jesse James Garrett . 2010 . Elements of User Experience , The : User - Centered Design for the Web and Beyond . Pearson Education . 34 . Henrik Gedenryd . 1998 . How designers work : Making sense of authentic cognitive activities . Cognitive Science . 124 35 . Graham R . Gibbs . 2018 . Analyzing Qualitative Data . SAGE . 36 . William Gibson and Andrew Brown . 2009 . Working with Qualitative Data . SAGE , Los Angeles . 37 . Gabriela Goldschmidt and Anat Litan Sever . 2011 . Inspiring design ideas with texts . Design Studies 32 , 2 : 139 – 155 . https : / / doi . org / 10 . 1016 / j . destud . 2010 . 09 . 006 38 . Michael Golembewski and Mark Selby . 2010 . Ideation Decks : A Card - based Design Ideation Tool . In Proceedings of the 8th ACM Conference on Designing Interactive Systems ( DIS ’10 ) , 89 – 92 . https : / / doi . org / 10 . 1145 / 1858171 . 1858189 39 . Björn Hartmann , Scott R . Klemmer , Michael Bernstein , Leith Abdulla , Brandon Burr , Avi Robinson - Mosher , and Jennifer Gee . 2006 . Reflective physical prototyping through integrated design , test , and analysis . In Proceedings of the 19th annual ACM symposium on User interface software and technology ( UIST ’06 ) , 299 – 308 . https : / / doi . org / 10 . 1145 / 1166253 . 1166300 40 . Katriina Heljakka and Pirita Ihamäki . 2017 . Digital Natives and Cardboard Cubes : Co - Creating a Physical Play ( ful ) Ideation Tool with Preschool Children . In Proceedings of the 2017 Conference on Interaction Design and Children ( IDC ’17 ) , 541 – 547 . https : / / doi . org / 10 . 1145 / 3078072 . 3084322 41 . Scarlett R . Herring , Chia - Chen Chang , Jesse Krantzler , and Brian P . Bailey . 2009 . Getting inspired ! understanding how and why examples are used in creative design practice . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’09 ) , 87 – 96 . https : / / doi . org / 10 . 1145 / 1518701 . 1518717 42 . Eva Hornecker . 2010 . Creative Idea Exploration Within the Structure of a Guiding Framework : The Card Brainstorming Game . In Proceedings of the Fourth International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’10 ) , 101 – 108 . https : / / doi . org / 10 . 1145 / 1709886 . 1709905 43 . Eva Hornecker . 2012 . Beyond Affordance : Tangibles’ Hybrid Nature . In Proceedings of the Sixth International Conference on Tangible , Embedded and Embodied Interaction ( TEI ’12 ) , 175 – 182 . https : / / doi . org / 10 . 1145 / 2148131 . 2148168 44 . Eva Hornecker and Jacob Buur . 2006 . Getting a Grip on Tangible Interaction : A Framework on Physical Space and Social Interaction . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’06 ) , 437 – 446 . https : / / doi . org / 10 . 1145 / 1124772 . 1124838 45 . Caroline Hummels and Jelle van Dijk . 2015 . Seven Principles to Design for Embodied Sensemaking . In Proceedings of the Ninth International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’15 ) , 21 – 28 . https : / / doi . org / 10 . 1145 / 2677199 . 2680577 125 46 . Caroline Hummels , Kees C . J . Overbeeke , and Sietske Klooster . 2007 . Move to get moved : a search for methods , tools and knowledge to design for expressive and rich movement - based interaction . Personal and Ubiquitous Computing 11 , 8 : 677 – 690 . https : / / doi . org / 10 . 1007 / s00779 - 006 - 0135 - y 47 . Pirita Ihamäki and Katriina Heljakka . 2016 . Ihamäki , P . & Heljakka , K . ( 2016 ) Invitation to Open - ended and Hybrid Play : Comicubes – a tool for creativity and participatory design . 48 . Hiroshi Ishii , Craig Wisneski , Julian Orbanes , Ben Chun , and Joe Paradiso . 1999 . PingPongPlus : Design of an Athletic - tangible Interface for Computer - supported Cooperative Play . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’99 ) , 394 – 401 . https : / / doi . org / 10 . 1145 / 302979 . 303115 49 . Philemonne Jaasma , Dorothé Smit , Jelle van Dijk , Thomas Latcham , Ambra Trotto , and Caroline Hummels . 2017 . The Blue Studio : Designing an Interactive Environment for Embodied Multi - Stakeholder Ideation Processes . In Proceedings of the Eleventh International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’17 ) , 1 – 10 . https : / / doi . org / 10 . 1145 / 3024969 . 3025002 50 . David G . Jansson and Steven M . Smith . 1991 . Design fixation . Design Studies 12 , 1 : 3 – 11 . https : / / doi . org / 10 . 1016 / 0142 - 694X ( 91 ) 90003 - F 51 . Ben Jonson . 2005 . Design ideation : the conceptual sketch in the digital age . Design Studies 26 , 6 : 613 – 624 . https : / / doi . org / 10 . 1016 / j . destud . 2005 . 03 . 001 52 . Martin Jonsson , Anna Ståhl , Johanna Mercurio , Anna Karlsson , Naveen Ramani , and Kristina Höök . 2016 . The Aesthetics of Heat : Guiding Awareness with Thermal Stimuli . In Proceedings of the TEI ’16 : Tenth International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’16 ) , 109 – 117 . https : / / doi . org / 10 . 1145 / 2839462 . 2839487 53 . Yuichiro Katsumoto , Satoru Tokuhisa , and Masa Inakage . 2013 . Ninja track : design of electronic toy variable in shape and flexibility . In Proceedings of the 7th International Conference on Tangible , Embedded and Embodied Interaction ( TEI ’13 ) , 17 – 24 . https : / / doi . org / 10 . 1145 / 2460625 . 2460628 54 . Ianus Keller , Froukje Sleeswijk Visser , Remko van der Lugt , and Pieter Jan Stappers . 2009 . Collecting with Cabinet : or how designers organise visual material , researched through an experiential prototype . Design Studies 30 , 1 : 69 – 86 . https : / / doi . org / 10 . 1016 / j . destud . 2008 . 06 . 001 55 . Scott R . Klemmer , Björn Hartmann , and Leila Takayama . 2006 . How Bodies Matter : Five Themes for Interaction Design . In Proceedings of the 6th Conference on Designing Interactive Systems ( DIS ’06 ) , 140 – 149 . https : / / doi . org / 10 . 1145 / 1142405 . 1142429 126 56 . Scott R . Klemmer , Jack Li , James Lin , and James A . Landay . 2004 . Papier - Mache : toolkit support for tangible input . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’04 ) , 399 – 406 . https : / / doi . org / 10 . 1145 / 985692 . 985743 57 . Hannu Korhonen , Markus Montola , and Juha Arrasvuori . 2009 . Understanding playful user experiences through digital games . 58 . Andrés Lucero and Juha Arrasvuori . 2010 . PLEX Cards : a source of inspiration when designing for playfulness . In Proceedings of the 3rd International Conference on Fun and Games ( Fun and Games ’10 ) , 28 – 37 . https : / / doi . org / 10 . 1145 / 1823818 . 1823821 59 . Andrés Lucero , Kirsikka Vaajakallio , and Peter Dalsgaard . 2012 . The dialogue - labs method : process , space and materials as structuring elements to spark dialogue in co - design events . CoDesign 8 , 1 : 1 – 23 . https : / / doi . org / 10 . 1080 / 15710882 . 2011 . 609888 60 . Sarnoff Mednick . 1962 . The associative basis of the creative process . Psychological Review 69 , 3 : 220 – 232 . https : / / doi . org / 10 . 1037 / h0048850 61 . P . Nguyen , C . Turkay , G . Andrienko , N . Andrienko , and O . Thonnard . 2017 . A Visual Analytics Approach for User Behaviour Understanding through Action Sequence Analysis . Retrieved March 22 , 2020 from http : / / dx . doi . org / 10 . 2312 / eurova . 20171122 62 . Jakob Nielsen . 1994 . Usability Engineering . Morgan Kaufmann . 63 . Jakob Nielsen and Rolf Molich . 1990 . Heuristic Evaluation of User Interfaces . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’90 ) , 249 – 256 . https : / / doi . org / 10 . 1145 / 97243 . 97281 64 . Karin Niemantsverdriet and Maarten Versteeg . 2016 . Interactive Jewellery as Memory Cue : Designing a Sound Locket for Individual Reminiscence . In Proceedings of the TEI ’16 : Tenth International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’16 ) , 532 – 538 . https : / / doi . org / 10 . 1145 / 2839462 . 2856524 65 . Amanda Parkes and Hiroshi Ishii . 2009 . Kinetic Sketchup : Motion Prototyping in the Tangible Design Process . In Proceedings of the 3rd International Conference on Tangible and Embedded Interaction ( TEI ’09 ) , 367 – 372 . https : / / doi . org / 10 . 1145 / 1517664 . 1517738 66 . Amanda Parkes and Hiroshi Ishii . 2010 . Bosu : a physical programmable design tool for transformability with soft mechanics . In Proceedings of the 8th ACM Conference on Designing Interactive Systems , 189 – 198 . 127 67 . Amanda J . Parkes , Hayes Solos Raffle , and Hiroshi Ishii . 2008 . Topobo in the wild : longitudinal evaluations of educators appropriating a tangible interface . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’08 ) , 1129 – 1138 . https : / / doi . org / 10 . 1145 / 1357054 . 1357232 68 . Matti K . Perttula and Lassi Liikkanen . 2006 . Exposure effects in design idea generation : unconscious conformity or a product of sampling probability ? In Proceedings of NordDesign 2006 Conference [ August 16 - 18 , 2006 , Reykjavik , Iceland ] , 42 – 55 . Retrieved February 17 , 2020 from https : / / researchportal . helsinki . fi / en / publications / exposure - effects - in - design - idea - generation - unconscious - conformity 69 . Matti Perttula and Pekka Sipilä . 2007 . The idea exposure paradigm in design idea generation . Journal of Engineering Design 18 , 1 : 93 – 102 . https : / / doi . org / 10 . 1080 / 09544820600679679 70 . Dorian Peters , Lian Loke , and Naseem Ahmadpour . 2020 . Toolkits , cards and games – a review of analogue tools for collaborative ideation . CoDesign 0 , 0 : 1 – 25 . https : / / doi . org / 10 . 1080 / 15710882 . 2020 . 1715444 71 . Jean Piaget . 1952 . The origins of intelligence in children . W W Norton & Co , New York . https : / / doi . org / 10 . 1037 / 11494 - 000 72 . O . Tomico Plasencia and D . Wilde . 2016 . Soft , embodied , situated & connected : enriching interactions with soft wearbles . mUX : The Journal of Mobile User Experience 5 , 3 . https : / / doi . org / 10 . 1186 / s13678 - 016 - 0006 - z 73 . Henning Pohl , Andreea Muresan , and Kasper Hornbæk . 2019 . Charting Subtle Interaction in the HCI Literature . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI ’19 ) , 1 – 15 . https : / / doi . org / 10 . 1145 / 3290605 . 3300648 74 . A . T . Purcell and J . S . Gero . 1991 . The effects of examples on the results of a design activity . In Artificial Intelligence in Design ’91 , J . S . Gero ( ed . ) . Butterworth - Heinemann , 525 – 542 . https : / / doi . org / 10 . 1016 / B978 - 0 - 7506 - 1188 - 6 . 50031 - 4 75 . A T Purcell , P Williams , J S Gero , and B Colbron . 1993 . Fixation Effects : Do They Exist in Design Problem Solving ? Environment and Planning B : Planning and Design 20 , 3 : 333 – 345 . https : / / doi . org / 10 . 1068 / b200333 76 . A . Terry Purcell and John S . Gero . 1996 . Design and other types of fixation . Design Studies 17 , 4 : 363 – 383 . https : / / doi . org / 10 . 1016 / S0142 - 694X ( 96 ) 00023 - 3 77 . Raf Ramakers , Johannes Schöning , and Kris Luyten . 2014 . Paddle : highly deformable mobile devices with physical controls . In Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI ’14 , 2569 – 2578 . https : / / doi . org / 10 . 1145 / 2556288 . 2557340 128 78 . Georg Regal , Elke Mattheiss , David Sellitsch , and Manfred Tscheligi . 2016 . TalkingCards : Using Tactile NFC Cards for Accessible Brainstorming . In Proceedings of the 7th Augmented Human International Conference 2016 ( AH ’16 ) , 1 – 7 . https : / / doi . org / 10 . 1145 / 2875194 . 2875240 79 . Mitchel Resnick , Brad Myers , Kumiyo Nakakoji , Ben Shneiderman , Randy Pausch , Ted Selker , and Mike Eisenberg . 2005 . Design principles for tools to support creative thinking . In NSF Workshop Report on Creativity Support Tools , 25 – 36 . 80 . Giuseppe Riva . 2002 . The Sociocognitive Psychology of Computer - Mediated Communication : The Present and Future of Technology - Based Interactions . CyberPsychology & Behavior 5 , 6 : 581 – 598 . https : / / doi . org / 10 . 1089 / 109493102321018222 81 . J . Sadler , L . Shluzas , P . Blikstein , and R . Katila . 2015 . Creative Chunking : Modularity Increases Prototyping Quantity , Creative Self - Efficacy and Cognitive Flow . The Design Society - a worldwide community . Retrieved February 2 , 2020 from https : / / www . designsociety . org / publication / 36113 / Creative + Chunking % 3A + Modul arity + Increases + Prototyping + Quantity % 2C + Creative + Self - Efficacy + and + Cognitive + Flow 82 . Joel Sadler , Kevin Durfee , Lauren Shluzas , and Paulo Blikstein . 2015 . Bloctopus : A novice modular sensor system for playful prototyping . In Proceedings of the Ninth International Conference on Tangible , Embedded , and Embodied Interaction , 347 – 354 . 83 . Donald A . Schön . 1988 . Designing : Rules , types and worlds . Design Studies 9 , 3 : 181 – 190 . https : / / doi . org / 10 . 1016 / 0142 - 694X ( 88 ) 90047 - 6 84 . Donald A Schön . 2017 . The reflective practitioner : How professionals think in action . Routledge . 85 . Douglas Schuler and Aki Namioka . 1993 . Participatory Design : Principles and Practices . CRC Press . 86 . Colleen M . Seifert , David E . Meyer , Natalie Davidson , Andrea L . Patalano , and Ilan Yaniv . 1995 . Demystification of cognitive insight : Opportunistic assimilation and the prepared - mind perspective . In The nature of insight . The MIT Press , Cambridge , MA , US , 65 – 124 . 87 . Hasti Seifi , Farimah Fazlollahi , Michael Oppermann , John Sastrillo , Jessica Ip , Ashutosh Agrawal , Gunhyuk Park , Katherine Kuchenbecker , and Karon Maclean . 2019 . Haptipedia : Accelerating Haptic Device Discovery to Support Interaction & Engineering Design . 1 – 12 . https : / / doi . org / 10 . 1145 / 3290605 . 3300788 88 . Ben Shneiderman , Catherine Plaisant , Maxine Cohen , Steven Jacobs , Niklas Elmqvist , and Nicholas Diakopoulos . 2016 . Designing the User Interface : Strategies for Effective Human - Computer Interaction . Pearson . 129 89 . Samarth Singhal , Carman Neustaedter , Yee Loong Ooi , Alissa N . Antle , and Brendan Matkin . 2017 . Flex - N - Feel : The Design and Evaluation of Emotive Gloves for Couples to Support Touch Over Distance . In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing ( CSCW ’17 ) , 98 – 110 . https : / / doi . org / 10 . 1145 / 2998181 . 2998247 90 . Dorothé Smit , Doenja Oogjes , Bruna Goveia de Rocha , Ambra Trotto , Yeup Hur , and Caroline Hummels . 2016 . Ideating in Skills : Developing Tools for Embodied Co - Design . In Proceedings of the TEI ’16 : Tenth International Conference on Tangible , Embedded , and Embodied Interaction ( TEI ’16 ) , 78 – 85 . https : / / doi . org / 10 . 1145 / 2839462 . 2839497 91 . Jocelyn Smith and Karon MacLean . 2007 . Communicating emotion through a haptic link : Design space and methodology . International Journal of Human - Computer Studies 65 , 4 : 376 – 387 . https : / / doi . org / 10 . 1016 / j . ijhcs . 2006 . 11 . 006 92 . Jelle Stienstra , Miguel Bruns Alonso , Stephan Wensveen , and Stoffel Kuenen . 2012 . How to design for transformation of behavior through interactive materiality . In Proceedings of the 7th Nordic Conference on Human - Computer Interaction : Making Sense Through Design , 21 – 30 . 93 . Erik Stolterman . 2008 . The nature of design practice and implications for interaction design research . International Journal of Design 2 , 1 . 94 . Anselm L . Strauss and Juliet M . Corbin . 1998 . Basics of qualitative research : techniques and procedures for developing grounded theory . Sage Publications , Thousand Oaks . 95 . Petra Sundström , Alex Taylor , Katja Grufberg , Niklas Wirström , Jordi Solsona Belenguer , and Marcus Lundén . 2011 . Inspirational bits : towards a shared understanding of the digital material . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’11 ) , 1561 – 1570 . https : / / doi . org / 10 . 1145 / 1978942 . 1979170 96 . Ambra Trotto and Caroline Hummels . 2013 . Designing in Skills - Nurturing Personal Engagement in Design . Retrieved March 29 , 2020 from http : / / urn . kb . se / resolve ? urn = urn : nbn : se : ri : diva - 24212 97 . Ambra Trotto and Caroline Hummels . 2013 . Engage me , do ! engagement catalysers to ignite a ( design ) conversation . In Proceedings of the 6th International Conference on Designing Pleasurable Products and Interfaces ( DPPI ’13 ) , 136 – 145 . https : / / doi . org / 10 . 1145 / 2513506 . 2513521 98 . Ian Tseng , Jarrod Moss , Jonathan Cagan , and Kenneth Kotovsky . 2008 . The role of timing and analogical similarity in the stimulation of idea generation in design . Design Studies 29 , 3 : 203 – 221 . https : / / doi . org / 10 . 1016 / j . destud . 2008 . 01 . 003 99 . uddipana . 2020 . uddipana / IdeaBits . Retrieved June 14 , 2020 from https : / / github . com / uddipana / IdeaBits 130 100 . B . Ullmer and H . Ishii . 2000 . Emerging frameworks for tangible user interfaces . IBM Systems Journal 39 , 3 . 4 : 915 – 931 . https : / / doi . org / 10 . 1147 / sj . 393 . 0915 101 . Kaisa Väänänen - Vainio - Mattila , Jani Heikkinen , Ahmed Farooq , Grigori Evreinov , Erno Mäkinen , and Roope Raisamo . 2014 . User experience and expectations of haptic feedback in in - car interaction . In Proceedings of the 13th International Conference on Mobile and Ubiquitous Multimedia ( MUM ’14 ) , 248 – 251 . https : / / doi . org / 10 . 1145 / 2677972 . 2677996 102 . Anna Vallgårda and Ylva Fernaeus . 2015 . Interaction Design as a Bricolage Practice . In Proceedings of the Ninth International Conference on Tangible , Embedded , and Embodied Interaction - TEI ’14 , 173 – 180 . https : / / doi . org / 10 . 1145 / 2677199 . 2680594 103 . Peter - Paul Verbeek . 2006 . Materializing Morality : Design Ethics and Technological Mediation . Science , Technology , & Human Values 31 , 3 : 361 – 380 . https : / / doi . org / 10 . 1177 / 0162243905285847 104 . Anita Vogl , Patrick Parzer , Teo Babic , Joanne Leong , Alex Olwal , and Michael Haller . 2017 . StretchEBand : Enabling Fabric - based Interactions through Rapid Fabrication of Textile Stretch Sensors . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17 , 2617 – 2627 . https : / / doi . org / 10 . 1145 / 3025453 . 3025938 105 . Meng Wang , Kehua Lei , Zhichun Li , Haipeng Mi , and Yingqing Xu . 2018 . TwistBlocks : Pluggable and Twistable Modular TUI for Armature Interaction in 3D Design . 19 – 26 . https : / / doi . org / 10 . 1145 / 3173225 . 3173231 106 . Danielle Wilde , Oscar Tomico , Andrés Lucero , Kristina Höök , and Jacob Buur . 2015 . Embodying Embodied Design Research Techniques . Aarhus Series on Human Centered Computing 1 , 1 : 4 – 4 . https : / / doi . org / 10 . 7146 / aahcc . v1i1 . 21620 107 . Christiane Wölfel and Timothy Merritt . 2013 . Method Card Design Dimensions : A Survey of Card - Based Design Tools . In Human - Computer Interaction – INTERACT 2013 ( Lecture Notes in Computer Science ) , 479 – 486 . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 40483 - 2 _ 34 108 . Kieran Woodward , Eiman Kanjo , Samuel Burton , and Andreas Oikonomou . 2018 . EmoEcho : A Tangible Interface to Convey and Communicate Emotions . In Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers - UbiComp ’18 , 746 – 749 . https : / / doi . org / 10 . 1145 / 3267305 . 3267705 109 . Lining Yao , Sayamindu Dasgupta , Nadia Cheng , Jason Spingarn - Koff , Ostap Rudakevych , and Hiroshi Ishii . 2011 . RopePlus : Bridging Distances with Social and Kinesthetic Rope Games . In CHI ’11 Extended Abstracts on Human Factors in Computing Systems ( CHI EA ’11 ) , 223 – 232 . https : / / doi . org / 10 . 1145 / 1979742 . 1979611 131 110 . Robert K Yin . 2009 . Case study research : design and methods / Robert K . Yin . Los Angeles : Sage Publications . 111 . John Zimmerman and Jodi Forlizzi . 2014 . Research Through Design in HCI . In Ways of Knowing in HCI , Judith S . Olson and Wendy A . Kellogg ( eds . ) . Springer , New York , NY , 167 – 189 . https : / / doi . org / 10 . 1007 / 978 - 1 - 4939 - 0378 - 8 _ 8 112 . John Zimmerman , Jodi Forlizzi , and Shelley Evenson . 2007 . Research through design as a method for interaction design research in HCI . In Proceedings of the SIGCHI conference on Human factors in computing systems , 493 – 502 . 113 . John Zimmerman , Erik Stolterman , and Jodi Forlizzi . 2010 . An analysis and critique of Research through Design : towards a formalization of a research approach . In Proceedings of the 8th ACM Conference on Designing Interactive Systems ( DIS ’10 ) , 310 – 319 . https : / / doi . org / 10 . 1145 / 1858171 . 1858228 114 . CHI Conference - Home . Retrieved June 10 , 2020 from https : / / dl . acm . org / conference / chi 115 . TEI Conference - Home . Retrieved June 10 , 2020 from https : / / dl . acm . org / conference / tei 116 . Arduino Based Mini CNC 2D Plotter . Arduino Project Hub . Retrieved June 15 , 2020 from https : / / create . arduino . cc / projecthub / Mrinnovative / arduino - based - mini - cnc - 2d - plotter - 234462 117 . SparkFun Electronics . Retrieved July 16 , 2018 from https : / / www . sparkfun . com / 118 . Definitions , Meanings , Synonyms , and Grammar by Oxford Dictionary on Lexico . com . Lexico Dictionaries | English . Retrieved June 14 , 2020 from https : / / www . lexico . com / 119 . Facebook . Retrieved September 13 , 2019 from https : / / www . facebook . com / 120 . Seeking Research Participants Roundup - Graduate and Postdoctoral Studies - Simon Fraser University . Retrieved September 13 , 2019 from http : / / www . sfu . ca / dean - gradstudies / news - updates / profiles / seeking - research - participants - roundup . html 121 . People & Research - Graduate and Postdoctoral Studies - Simon Fraser University . Retrieved September 13 , 2019 from http : / / www . sfu . ca / dean - gradstudies / news - updates / profiles . html 122 . CameraAccess plus – Apps on Google Play . Retrieved September 13 , 2019 from https : / / play . google . com / store / apps / details ? id = jp . co . pixela . cameraaccessplus & hl = en _ IN 132 123 . Download \ Processing . org . Retrieved September 14 , 2019 from https : / / processing . org / download / 124 . Arduino - Software . Retrieved September 14 , 2019 from https : / / www . arduino . cc / en / main / software 125 . FlashBack - try the best screen recorder . FlashBack - try the best screen recorder . Retrieved September 14 , 2019 from https : / / www . flashbackrecorder . com / 126 . TeamViewer – Remote Support , Remote Access , Service Desk , Online Collaboration and Meetings . Retrieved September 14 , 2019 from https : / / www . teamviewer . com / en / 127 . matinlotfali / AndroidTimer . GitHub . Retrieved September 14 , 2019 from https : / / github . com / matinlotfali / AndroidTimer 128 . Otter Voice Meeting Notes . Otter Voice Meeting Notes . Retrieved September 14 , 2019 from https : / / otter . ai / 129 . International Facts and Figures - SFU International - Simon Fraser University . Retrieved September 20 , 2019 from https : / / www . sfu . ca / international / index / partner / facts . html 130 . Design - Thinking . pdf . Retrieved September 21 , 2019 from https : / / fusesocial . ca / wp - content / uploads / sites / 2 / 2018 / 06 / Design - Thinking . pdf 131 . NVivo qualitative data analysis software | QSR International . Retrieved March 8 , 2020 from https : / / www . qsrinternational . com / nvivo / home 132 . Google . Retrieved May 9 , 2020 from https : / / www . google . com / 133 . Arduino Education . Retrieved February 2 , 2020 from https : / / www . arduino . cc / education 133 Appendix A . Demographic Questionnaire 1 . What is your age ? a . Under 12 years old b . 12 - 17 years old c . 18 - 24 years old d . 25 - 34 years old e . 35 - 44 years old f . 45 - 54 years old g . 55 - 64 years old h . Above 64 years old 2 . What is your department at SFU ? For example : School of Interactive Arts and Technology _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 3 . What is your program of study at SFU ? For example : Masters of Science _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 4 . What year of your program are you in ? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 5 . What is the highest degree or level of school you have completed ? a . Some high school , no diploma b . High school graduate , diploma or the equivalent ( for example : GED ) c . Some college credit , no degree d . Trade / technical / vocational training e . Associate degree f . Bachelor’s degree 134 g . Master’s degree h . Professional degree i . Doctorate j . Other ( Mention the department / domain ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 6 . Do you have any work experience related to your current program of study at SFU ? Company Job title a . Internship _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ b . Co - operative _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ c . Research position _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ d . Industry position _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ e . Other _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 135 Appendix B . Recruiting Poster 136 Appendix C . Recruiting Flyer 137 Appendix D . Signup Sheet Date _ _ _ _ _ _ _ _ _ _ _ _ _ Course _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Lecture / Lab _ _ _ _ _ _ _ _ _ _ _ _ _ _ Have questions or interested in participating ? Sl . No . Official name ( in upper case ) Email id ( in upper case ) e . g . UDDIPANA BAISHYA ABC @ PQR . COM 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 138 Appendix E . Screening Questionnaire 139 140 Appendix F . Problem Statement Sheets 141 Deliverables Please attach extra sheets as needed . 142 143 Appendix G . Stationery and Modeling Materials Stationery 1 . A4 Papers 2 . Clip board 3 . Color pencils 4 . Erasers 5 . Geometry box Stationery 11 . Sketching papers 12 . Stapler and pins 13 . Sticky notes 14 . Whiteners Stationery 6 . Pencils 7 . Pens 8 . Rulers 9 . Sharpeners 10 . Sketch pens Prototyping 1 . Beads 2 . Bendable sticks 3 . Both sided tape 4 . Cello tape 5 . Chart papers 6 . Clothe pieces 7 . Construction paper 8 . Craft board 9 . Cubes 10 . Cutters 11 . Cutting board 12 . Elastic 13 . Elastic sheet 14 . Felt sheets 15 . Foam shapes 16 . Glue Prototyping 17 . Glue gun , sticks , pad 18 . Ice - cream sticks 19 . Jute rope 20 . Ladder cable ties 21 . Legos 22 . Magnets 23 . Masking tape 24 . Measuring tape 25 . Modeling clay 26 . Needle and thread 27 . Packing tape 28 . Parachute cord 29 . Permanent markers 30 . Pipe cleaners 31 . Playdough 32 . Pom poms Prototyping 33 . Reusable adhesive 34 . Ribbons 35 . Rings ( wooden ) 36 . Rubber bands 37 . Safety pins 38 . Scissors 39 . Sponge cubes 40 . Spring 41 . Sticks 42 . Straws 43 . Suction cups 44 . Super glue 45 . Thread and needles 46 . Toothpicks 47 . Twist ties 48 . Velcro straps 144 Appendix H . Overview Map 145 Appendix I . Protocol Preparation check list ( First time ) 1 . Set up personal computer for participant a . Install web browser b . Install FlashBack software c . Install TeamViewer software d . Create desktop shortcut for web browser , FlashBack and TeamViewer software 2 . Set up IdeaBits a . Install Processing software b . Install Arduino software c . Put processing and Arduino file of IdeaBits on desktop 3 . Set up cam recorders a . Setup cam recorder streaming b . Test cam recorder recording and streaming c . Setup and adjust tripod for one of the cam recorders d . Setup and adjust phone stand for the other cam recorder e . Insert memory cards in cam recorders 4 . Set up tablets a . Silent notifications of the two tablets to be used for remote observation b . Put the tablet used for timer on loud 5 . Set up stationery , 3D modeling materials by organising them using organising trays and pen stands 6 . Set up my laptop used for remote observation a . Install TeamViewer software Preparation check list ( Before each user study ) 1 . Setup personal computer for participant a . Open screen recording software b . Start team viewer 2 . Test run IdeaBits after turning on the LED in pull sensor enabled artifact 146 3 . Set up cam recorders a . Check that the cam recorders have SD card with enough storage b . Plug into power c . Set up streaming d . Adjust tripod and phone stand 4 . Tablets a . Plug into power b . Place one of the tablets to be used for remote observation on tablet stand on the remote observation table . Place the other on the table in the user study room . 5 . Set up my laptop used for remote observation a . Plug into power source b . Connect to the IdeaBits personal computer using TeamViewer 6 . Audio recorder a . Check that the audio recorder has enough battery b . Check that the audio recorder has SD card with enough storage 7 . Stationery , modeling materials a . Refill the ones used by the previous participant b . Arrange everything 8 . Print and arrange the necessary sheets such as preparation checklist , overview map , problem statement , interview questionnaire , observation guide , procedure script , wrap up checklist . 9 . Silent my phone Procedure script 1 . Get started a . Pickup up participant from outside the user study room b . Welcome the participant , “Hi I am Uddipana . Nice to meet you ! How has been your day so far ? ” and escort them to the user study room . c . Close the door and ask them to sit on either of the chairs . Give them time to settle down and sit down next to them . d . Explain about the cam recorders , “I will be using two cam recorders to record the session . That’s one in front of you and that’s the other up there . These will also be used to stream the videos to let me remotely observe from the room right in front of this room . I will be using two tablets , this is one of them , to view 147 the streamed video . Am I making sense ? ” Clarify doubts and address concerns if any . “May I start recording ? ” Start the recording if the participant gives consent . If the participant does not give consent then let them know that to be able to participate in the study it is compulsory to give consent to record the session while they have the option to opt out from appearing in photographs and video segments ( includes audio ) in academic publications , presentations , or promotions . 2 . Give an overview a . Use the overview map to give an overview of the session . “Let me start with an overview of what will happen in the session . It will be around 1 . 5 to 2 hours long . I shall explain you the design task and that design tool , IdeaBits , over there . You will then have up to 1 hour to complete the design task . We will then have a short interview of 30 to 40 minutes to discuss your experience of doing the design task using IdeaBits . I shall then provide you the remuneration . You may quit at any point of time during the study . Please let me know if you have any questions . ” b . Introduce to the goal of the study “The goal of this study is to understand how you use IdeaBits to design tangible user interfaces , with a focus on input actions . So , we want you to use IdeaBits for doing the design task . Am I making sense ? Please stop me anytime you have any questions . I am happy to repeat as well . Let me know if I am going too fast . ” 3 . Introduce the design task a . Introduce the concept of tangible user interfaces . “Can you let me know what comes to your mind when you hear the word tangible user interfaces ? ” If necessary , building upon their knowledge explain what tangible user interfaces are by referring to : Tangible user interfaces are interfaces involving physical objects linked with digital content . You can control or manipulate the digital content by interacting with the physical objects . b . Introduce the task by reading out the problem statement . Clarify doubts if any . c . Introduce the first deliverable by reading it out . Add to that , “If you choose to make a model then you can use these stationery and modeling materials out here . There is the list listing all the things in here in alphabetical order . Be 148 careful with sharp edges . I have kept bandaids over here just in case . ” Clarify doubts if any . d . Introduce the second deliverable by reading it out . Clarify doubts if any . e . Introduce the third deliverable by reading it out . Clarify doubts if any . f . Introduce the fourth deliverable by reading it out . Clarify doubts if any . g . Check if they understood the design task . “Just to make sure I could explain it correctly , can you let me know what you understood about the design task ? ” 4 . Introduce IdeaBits a . Give an overview of IdeaBits . “IdeaBits is a design tool that can be used to design input actions in tangible user interfaces . It consists of those physical objects and this graphical user interface . ” b . Introduce artifacts in IdeaBits . “The physical objects let you experience input actions . These are two different sets of objects . Each of them contains five objects . If you see these cards over here , they have an illustration of how you can interact with these five objects over here . ” Pick up any illustration card . “Say for example this card here shows how to interact with this artifact over here . Would you like to give it a try ? ” Wait till they it out . “And if you flip the card you can see the name of the input action and its definition . This set of objects over here are similar as well . For example , this is similar to this , this to this , this to this and so on ( pointing out the pairs of artifacts having same input actions ) . I shall explain you the difference between the sets after I go through the graphical user interface over here . Am I making sense ? Should I go slow ? ” c . Introduce to the graphical user interface in IdeaBits . “Now coming to the graphical user interface over here . This is to let you study examples of tangible user interfaces which incorporate those five input actions . Would you like to use the mouse while I show you around the interface ? This is the home page . It has the five input actions as you can see . When you click on any of these , say bend , the example page for bend opens . The example page has two examples of tangible user interfaces which incorporate the input action . In this case TwistBlocks and Ninja Track are two tangible user interfaces which have bend as an input action . The examples are given in three formats – video , images and paper , as you can see over here . Am I making sense ? The video player is like regular video player , you can play and pause by clicking on the 149 video or these buttons over here . This button is to stop the video . The only new thing are these colour bars . The colour bars represent different sections of the video which are color coded . So , where every you see a red bar it means that part of the video shows overview of the system , if it is green then it shows the input action and if it is blue then it shows how the project was implemented . If you click on any of these bars then the video jumps to that position . Do you have any questions ? If you click on this image tab you can see images of the example . You can scroll through the thumbnails using these arrow buttons . When you click on any thumbnail then it will display that image in this display area in bigger size . If you click on this paper tab then you can see the paper published about that project . You can scroll though the paper using the mouse wheel . You can zoom in and out and pan . The paper also have sections underlined using colour coding . The colour coding is same as that in the video . So where every you see a red underline , it means that section talks about overview of the system , if it is green then it talks about the input action and if it is blue then it talks about how the project was implemented . Does it make sense ? The last tab over here is tech . If you click on it , it will open up a website page that talks about how you can technically implement the input action . By clicking on this Processing icon , you can go back to the example page . Clicking on this tab over here will take you to the second example . You can go back to the home page using this back button . Let me know if you have any questions . ” d . Mention the difference between the two sets of artifacts . “I can now explain the difference between the two sets of objects . If you see on this home page when I hover over the mouse to any of the five images of these sensor enabled objects then it shows how to interact with it . Would you like to try it out ? As you can see , when you interact with the object it opens the example page of that object . If you continue to interact then it plays and pauses the video . Please don’t worry about breaking these objects . We have many spare ones that we can use to replace these . ” 5 . Wrap up a . Remind the goal of the study , “Again , the goal of this study is to understand how you use IdeaBits to design tangible user interfaces , with a focus on input 150 actions . So , we want you to use IdeaBits for doing the design task . However you are not limited to the input actions in it . ” b . Give the consent form and ask if they are interested in participating in the study . Give them time to read it . During that time re - open IdeaBits processing file to and start the screen recorder . Clarify doubts and address concerns if any . c . If they sign the form then prepare to leave the room , “You have a maximum of 1 hour . If you finish before time then you can let me know . You can wave at the cam recorder and I will be able to see that with a delay of like 10 - 15 seconds . I will be in the room right in front of you . Please feel free to come to the room if you have any questions or face any issues . I am starting the timer . Good luck ! ” 6 . Do remote observation when the user is doing the design task . Use Otter . 7 . Conduct the interview when the user has finished the design task . Use Otter and audio recorder . 8 . Provide remuneration when interview is over . Take sign on the remuneration form . Wrap up check list ( after the participant has let ) 1 . Stop screen recorder , cam recorder , audio recorders , LED in pull sensor enabled artifact . 2 . Check that glue gun is unplugged . 3 . Write overall impression notes . 4 . Take photos of model if participant made any . 5 . Put name and date on answer sheets and scan them . 6 . Save the videos , images , audios and excel log file of IdeaBits in hard drive . Check if everything has been recorded and properly copied to hard drive . Clear the data from the memory cards . 7 . Clean the room and empty the garbage bin . 8 . Refill used modeling materials and stationeries . 151 Appendix J . Interview Questionnaire for Evaluation of IdeaBits 1 . Congratulations on completing the session . How did it go ? 2 . I am curious about the ideas you came up with . Can you help me understand your final idea ( referring to the deliverables in sequence ) ? 3 . Can you walk me through your process of how you came up with this final idea ? a . ( If they did not explore multiple ideas ) How many ideas did you explore ? Why so ? 4 . What are the ways you used IdeaBits to do this design task ? 5 . Do you prefer either the physical only artifacts or the sensor enabled artifacts ? Why so ? 6 . Do you prefer the image , video or paper format for the examples ? Why so ? 7 . Let us discuss further the input actions you explored . Can you walk me through how you came up with these input actions in your final idea ? a . ( If not already mentioned ) Did you use IdeaBits to come up with input action ideas ? a . ( If they used IdeaBits ) How did you use it ? b . ( If they did not use IdeaBits ) Why did you choose not to use it ? b . Did you face any challenges while generating IA ideas ? ( If they faced challenges ) What challenges did you face ? 8 . Did you come across any input actions you were not familiar with ? a . ( If they came across any unfamiliar input actions ) Which input actions you were not familiar with ? Could you explore any of these in your ideas ? a . ( If they explored ) Can you tell me which ones did you explore ? Can you tell me how you explored them ? b . ( If they did not explore ) Why not ? 9 . Can you tell me what you did for planning technical implementation ? a . ( If not already mentioned ) Did you use IdeaBits for planning technical implementation ? 152 a . ( If they used IdeaBits ) How did you use it ? b . ( If they did not use IdeaBits ) Why did you choose not to use it ? 10 . In what ways , if any , do you think IdeaBits helped you in doing the design task ? 11 . In what ways , if any , do you think IdeaBits hindered or limited you in doing the design task ? 12 . Can you tell me about the challenges you faced , if any , while doing the design task ? 13 . Can you tell me about the challenges you faced , if any , while using IdeaBits ? ( If they hesitate to mention negative things ) IdeaBits is in a very rough prototype phase . We would be more than happy to know ways in which we can improve it . So please feel free to mention anything you did not like . 14 . The goal of IdeaBits is to help you generate ideas for input actions . If we were to revise IdeaBits , what changes would you like to see ? Why so ? 15 . To wrap it up , the goal of this study is to understand how you use IdeaBits to generate ideas for input actions . What else you would like to mention to help us understand your experience better ? a . Is there anything else you would like to discuss ? 153 Appendix K . Deliverables from the User Study Participants Amy Front ( left ) and back ( right ) view of the model . 154 Idea generation sheet . 155 1 st and 2 nd deliverables . 156 3 rd and 4 th deliverables . 157 Ben Idea generation sheet . 158 1 st and 2 nd deliverables . 159 3 rd and 4 th deliverables . 160 Eva Idea generation sheet 1 of 3 . 161 Idea generation sheet 2 of 3 . 162 Idea generation sheet 3 of 3 . 163 1 st and 2 nd deliverables . 164 3 rd and 4 th deliverables . 165 Jane Idea generation sheet 1 of 2 . 166 Idea generation sheet 2 of 2 . 167 1 st and 2 nd deliverables . 168 3 rd and 4 th deliverables . 169 Kate Model in default state ( upper left ) , one block pushed out partially ( upper right ) , one block pushed out completely ( lower left ) , and three blocks pushed out at different lengths ( lower right ) . 170 Idea generation sheet . 171 1 st and 2 nd deliverables . 172 3 rd and 4 th deliverables . 173 Lee Front ( upper left ) , back ( upper right ) , and bottom ( bottom ) views of the model . 174 Front ( left ) and back ( right ) view of the index finger of the model . Idea generation sheet . 175 1 st and 2 nd deliverables . 176 3 rd and 4 th deliverables . 177 Maya Model . 178 Idea generation sheet . 179 1 st and 2 nd deliverables . 180 3 rd and 4 th deliverables . 181 Neil Model and 1 st deliverable . 182 Idea generation sheet . 2 nd deliverable . 183 3 rd and 4 th deliverables . 184 Paul Idea generation sheet . 185 1 st and 2 nd deliverables . 186 3 rd and 4 th deliverables . 187 Ross Top ( left ) and oblique ( right ) views of the model . 188 Idea generation sheet . 189 1 st and 2 nd deliverables . 190 3 rd and 4 th deliverables . 191 Ted Model for the child who is communicating the emotion ‘anger’ and ‘scared’ . 192 Model for the parent to whom the child is communicating the emotion ‘anger’ . The disturbed state ( bottom ) and the default state ( top ) indicates that the child is angry and not angry respectively . 193 Model for the parent to whom the child is communicating the emotion ‘scared’ . The elevated state ( bottom ) and the default state ( top ) indicates that the child is scared and not scared respectively . 194 Idea generation sheet . 195 1 st and 2 nd deliverables . 196 3 rd and 4 th deliverables 197 Uma Model . 198 Idea generation sheet . 199 1 st and 2 nd deliverables . 200 3 rd and 4 th deliverables . 201 Appendix L . Interview Questionnaire for Designing IdeaBits 1 . Tell me a little about yourself and your background . The following are probes if the information is missed by the interviewee a . What is your educational background ? b . What about your work experience ? c . Tell me about your past experience with tangible interaction design . 2 . Tell me about one of your favourite tangible system . 3 . Can you tell me about your favourite tangible system that you have conceptualised or designed recently ? a . Can you illustrate the system to me ? 4 . How did the project start ? 5 . How did you start idea generation for the system ? 6 . How did the idea generation process unfold ? a . Can you tell me about your thinking process ? 7 . If you try to go back to the moment when you got this idea for the system , can you recall what inspired the idea and how did you get the idea ? 8 . Can you recall what inspired the idea of the tangible manipulability of the system and how did you get the idea ? 9 . Did you explore or consider other types of tangible manipulability for the system ? a . If no , why not ? b . What was the set of tangible manipulability that you considered ? c . How did you arrive at this set of tangible manipulability ? i . What factors did you consider ? d . Did you consider manipulations like squeeze , pinch , stretch , peel , bend etc . ? i . If not , why not ? e . How did you select the final tangible manipulability for the system ? 10 . What were the difficult parts in generating ideas for tangible manipulability of the system ? 11 . Is there anything else you want to mention ? ( If the interview ends here ) 202 Additional questions if time permits and answers not covered in previous questions . Use these as probes for previous questions . 12 . During the idea generation process , did you use anything in particular to get inspiration from ? a . If none , why not ? b . Can you give me an illustration of what you used ? c . What do you like about this ? d . Is there anything you do not like about this ? 13 . Did you refer to examples ? a . If no , why not ? b . What type of examples did you refer to ? c . Did you see examples of existing tangible interactive systems ? i . If no , why not ? d . How do you search and select these examples ? e . How do you use these examples for idea generation ? f . How using examples help you generate ideas ? g . Is there any difficulty you face while searching , selecting or using examples ? 14 . Did you ever come across idea generation methods like challenging assumptions , conceptual blending etc ? ( Explain the methods in brief ) a . If yes , did you use any such methods ? b . If not , why not ? c . Can you describe how you used the method ? d . What do you like about this method ? e . Is there anything you do not like about this method ? f . Any other methods you know of but chose not to use ? i . What are these ? ii . Why do you not use these ? 15 . Did you ever come across idea generation tools like cards ? a . If yes , did you use any such tool ? b . If not why not ? c . Can you describe how you used the tool ? d . What do you like about this tool ? e . Is there anything you do not like about this tool ? 16 . Is there anything else you want to mention ? 203 Appendix M . Illustration Cards 204