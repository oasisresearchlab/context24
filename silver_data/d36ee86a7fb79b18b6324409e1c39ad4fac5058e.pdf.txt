Composable core - sets for diversity and coverage maximization Citation Indyk , Piotr , et al . " Composable Core - Sets for Diversity and Coverage Maximization . " Proceedings of the 33rd ACM SIGMOD - SIGACT - SIGART Symposium on Principles of Database Systems - PODS ' 14 , 22 - 27 June , 2014 , New York , New York , ACM Press , 2014 , pp . 100 – 08 . As Published http : / / dx . doi . org / 10 . 1145 / 2594538 . 2594560 Publisher Association for Computing Machinery Version Author ' s final manuscript Accessed Sun Mar 03 21 : 05 : 49 EST 2019 Citable Link http : / / hdl . handle . net / 1721 . 1 / 113896 Terms of Use Creative Commons Attribution - Noncommercial - Share Alike Detailed Terms http : / / creativecommons . org / licenses / by - nc - sa / 4 . 0 / The MIT Faculty has made this article openly available . Please share how this access benefits you . Your story matters . Composable Core - sets for Diversity and Coverage Maximization [ Extended Abstract ] Piotr Indyk Massachusetts Institute of Technology Cambridge , MA indyk @ mit . edu Sepideh Mahabadi Massachusetts Institute of Technology Cambridge , MA mahabadi @ mit . edu Mohammad Mahdian Google , Inc . Mountain View , CA mahdian @ alum . mit . edu Vahab S . Mirrokni Google , Inc . New York , NY mirrokni @ gmail . com ABSTRACT In this paper we consider eﬃcient construction of “compos - able core - sets”for basic diversity and coverage maximization problems . A core - set for a point - set in a metric space is a subset of the point - set with the property that an approxi - mate solution to the whole point - set can be obtained given the core - set alone . A composable core - set has the property that for a collection of sets , the approximate solution to the union of the sets in the collection can be obtained given the union of the composable core - sets for the point sets in the collection . Using composable core - sets one can obtain eﬃ - cient solutions to a wide variety of massive data processing applications , including nearest neighbor search , streaming algorithms and map - reduce computation . Our main results are algorithms for constructing com - posable core - sets for several notions of “diversity objective functions” , a topic that attracted a signiﬁcant amount of research over the last few years . The composable core - sets we construct are small and accurate : their approximation factor almost matches that of the best “oﬀ - line” algorithms for the relevant optimization problems ( up to a constant factor ) . Moreover , we also show applications of our results to diverse nearest neighbor search , streaming algorithms and map - reduce computation . Finally , we show that for an alter - native notion of diversity maximization based on the max - imum coverage problem small composable core - sets do not exist . Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage , and that copies bear this notice and the full ci - tation on the ﬁrst page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . Copyright is held by the author / owner ( s ) . PODS’14 , June 22 – 27 , 2014 , Snowbird , UT , USA . ACM 978 - 1 - 4503 - 2375 - 8 / 14 / 06 . http : / / dx . doi . org / 10 . 1145 / 2594538 . 2594560 . Categories and Subject Descriptors F . 2 . 2 [ Nonnumerical Algorithms and Prob - lems ] : Geometrical problems and computations ; G . 1 . 6 [ Optimization ] : Constrained optimization Keywords Core - set ; Diversity ; Streaming ; Nearest Neighbor ; Map - reduce ; 1 . INTRODUCTION One of the most popular approaches to processing massive data is to ﬁrst extract a compact representation ( or synopsis ) of the data and then perform further processing only on the representation itself . This approach signiﬁcantly reduces the cost of processing , communicating and storing the data , as the representation size can be much smaller than the size of the original data set . Typically , the representation provides a smooth tradeoﬀ between its size and the representation accuracy . Examples of this approach include techniques such as sampling , sketching , core - sets and mergeable summaries . In this paper we focus on computing eﬃcient representa - tions for the purpose of diversity - aware summarization and search , a topic that has attracted signiﬁcant attention over the last few years [ 20 , 41 , 7 , 26 , 40 , 38 , 18 , 1 , 32 ] . The goal of this line of research is to design eﬃcient methods for search - ing and summarizing large data sets in a way that preserves the diversity of the data . In most formulations , the summary is a sub - set of the original data of some predeﬁned size ( say k ) that maximizes a certain diversity objective . For example one could require that the minimum distance between any pair of points in the summary is as large as possible , i . e . , the summary does not contain two“highly similar”items . Many other , more reﬁned , diversity objectives have been studied , see Figure 1 for an overview . In this paper we study speciﬁc diversity - aware represen - tations called composable core - sets . An α - approximate com - posable core - set for a diversity objective is a mapping from a set S to a subset of S with the following property : for a collection of sets , the maximum diversity of the union of those sets is within an α factor of the maximum diversity of the union of the corresponding core - sets . That is , one can construct an approximately optimal solution for a given data set by partitioning it into several ( possibly overlapping ) blocks , computing a core - set for each block , and then solv - ing the problem for the union of the core - sets . Composable core - sets naturally lead to divide - and - conquer solutions to a collection of massive data processing problems . In particu - lar , they have been used for the following tasks : • Streaming computation : In the data stream model , a sequence of n data elements needs to be processed“on - the - ﬂy” while using only limited storage . Such an al - gorithm can be easily obtained using composable core - sets [ 22 , 5 ] 1 . Speciﬁcally , if a composable core - set for a given problem has size k , we start by dividing the stream of data into (cid:112) n / k blocks of size s = √ nk . The algorithm then proceeds block by block . Each block is read and stored in the main memory , its core - set is computed and stored , and the block is deleted . At the end , the algorithm solves the problem for the union of the core - sets . The whole algorithm takes only O ( √ kn ) space . The storage can be reduced further by utiliz - ing more than one level of compression , at the cost of increasing the approximation factor . • Distributed data processing : composable core - sets can be also used to process data in a distributed system , where each machine holds a block of the data . The al - gorithm is virtually identical to the one for streaming data : for each block , a composable core - set is com - puted and sent to the central server , where the com - putation is completed . As an example , this idea is di - rectly applicable in the map - reduce framework [ 17 ] and gives an approximation algorithm in one round of map - reduce : Using (cid:112) n / k mappers , each mapper gets √ kn points as input and computes a composable core - set of size k for this set . These sets will be passed to a single reducer . The input of this reducer is the union of the core - sets , which is of size at most k (cid:112) n / k = √ kn . It computes and outputs a solution on this union , which by the deﬁnition of core - sets is a good approximation to the original problem . Recently , variants of this tech - nique have been applied for optimization under map - reduce framework [ 28 , 31 , 8 ] . • Similarity search : recently , composable core - sets have been used to construct eﬃcient near neighbor search algorithms that maximize the diversity of the answers , both in theory [ 2 ] and in practice [ 1 ] . This is done by observing that several similarity search algorithms ( notably those based on the Locality - Sensitive Hashing technique ) proceed by hashing each point into multi - ple buckets . Each query is then answered by retriev - ing the points stored in the buckets that the query is mapped into . Since the number of points stored in a bucket might be large ( which is the case , e . g . , when the data set contains one big cluster of close points ) , the query answering procedure might be slow . To improve the performance , the paper [ 1 ] proposed to replace the content of each bucket by its core - set . By collecting the core - sets stored in all relevant buckets and performing 1 The paper [ 22 ] introduced this approach for the special case of k - median clustering . More general formulation of this method with other applications appeared in [ 5 ] . the computation over the their union , the algorithm reports a diverse summary of the points close to the query in time that depends on the number of buckets , not the size of the whole data set . This is discussed in more details in Appendix A . The broad applicability of composable core - sets motivates the study of eﬃcient methods for constructing them . This is the task we undertake in this paper . Our results . In this paper we present a thorough study of composable core - sets for several well - studied diversity maxi - mization problems . Suppose that the set S of interest lives in some metric space ( ∆ , dist ) , and let div ( S ) be any function that maps a set into a non - negative real number . The goal of the diversity maximization problem is to ﬁnd a subset S (cid:48) of S of size k that maximizes the diversity objective . The speciﬁc diversity functions div considered in this pa - per are described in Figure 1 , following the taxonomy of dispersion measures introduced in [ 13 ] . For each dispersion function we provide the approximation factor of the com - posable core - set that we obtain for that function . We note that for all core - sets the approximation factor matches that of the best “oﬀ - line” algorithm for the corresponding diver - sity maximization problem [ 13 ] ( up to a constant factor ) . All core - sets are of size k . The interpretation of the diversity measures is as follows . First , remote - edge [ 1 ] and remote - clique [ 20 ] correspond to the well - studied diversity notions where the objective is to ensure that no two pairs of points are too “close” to each other , or that an average pair distance of points is not too “low” , respectively . Remote - pseudoforest falls in between the two notions , as its goal is to ensure that the average distance of a point to its nearest neighbor is not too “low” . Remote - pseudoforest can be viewed as a diversity analog of the well - studied Chamfer distance [ 27 ] . Remote - tree and re - mote t - tree measure the diversity by the cost of clustering the data using the Single Link algorithm [ 37 ] . Similarly , remote - star measures the diversity by the cost of connecting the points to the best center 2 . Finally , remote - matching , remote - cycle and remote - bipartition are more “exotic” com - binatorial variations of the aforementioned measures . We include them to complete the table of [ 13 ] . All aforementioned notions of diversity are“pairwise” , i . e . , they are a function of the pair - wise distances between the se - lected items . We also consider a basic “higher order” notion of diversity which has been previously discussed in the con - text of diversity maximization [ 3 , 10 ] . Intuitively , the idea is to model diversity by considering a set of topics that each item covers , and exploring the diversity or the union of top - ics covered by a set of items . More speciﬁcally , we consider the scenario where the items are binary vectors of topics , and the diversity of a set of items is equal to their coverage over another set of topics , i . e . , the weight of the coordinate - wise OR of the item vectors . As before , the goal is to choose a set of size k which maximizes the total coverage . This is directly related to the maximum k - coverage problem that admits a tight 1 − 1 / e - approximation algorithm [ 19 ] . We show in Section 4 that this problem does not support com - posable core - sets of size polynomial in k . In particular , for 2 Note that the values of remote - clique and remote - star ob - jectives are within a factor of Θ ( k ) from each other , and thus the core - sets for the two objectives are equivalent up to constant factors . Problem Diversity of the point set S Approx . factor Remote - edge min p , q ∈ S dist ( p , q ) O ( 1 ) Remote - clique (cid:80) p , q ∈ S dist ( p , q ) O ( 1 ) Remote - tree wt ( MST ( S ) ) , weight of the minimum spanning tree of S O ( 1 ) Remote - cycle min C wt ( C ) where C is a TSP tour on S O ( 1 ) Remote t - trees min S = S 1 | . . . | S t (cid:80) ti = 1 wt ( MST ( S i ) ) O ( 1 ) Remote t - cycles min S = S 1 | . . . | S t (cid:80) ti = 1 wt ( TSP ( S i ) ) O ( 1 ) Remote - star min p ∈ S (cid:80) q ∈ S \ { p } dist ( p , q ) O ( 1 ) Remote - bipartition min B wt ( B ) , where B is a bipartition ( i . e . , bisection ) of S O ( 1 ) Remote - pseudoforest (cid:80) p ∈ S min q ∈ S \ { p } dist ( p , q ) O ( log k ) Remote - matching min M wt ( M ) , where M is a perfect matching of S O ( log k ) Max k - Coverage (cid:80) i ≤ d max p ∈ S p i , where p i denotes the i th coordinate of p no √ k log k - approx . core - set of size k β Table 1 : Notions of diversity considered in this paper . We use S = S 1 | . . . | S t to denote that S 1 . . . S t is a partition of S into t sets . any α ≤ √ k log k and any constant β > 0 , there exists a set of in - stances for which no α - approximate core - set of size k β exists . As an illustrative example of submodular maximization [ 33 , 25 ] , the maximum coverage problem has been recently stud - ied from distributed computation perspective [ 16 ] , e . g . , in the map - reduce framework [ 15 , 29 ] . Our negative result for existence of core - sets for this problem implies that one can - not use the simple core - set approach to solve this problem in distributed or streaming settings . Our techniques . Our techniques for constructing com - posable core - sets rely on oﬀ - line algorithms that solve the corresponding diversity maximization problems . The three algorithms are given in Preliminaries . Our contribution is to show that the solutions produced by those algorithms satisfy the composable core - set properties . The basic idea is to show that , for each algorithm , one can construct a mapping from each element in the optimum solution ( to the whole data set ) and an element of the core - set . This correspondence is then used to bound the error incurred by the core - set . Note that for the remote - edge diversity measure , this analysis is analogous to the analysis in [ 2 ] ( al - though that analysis was focused on the k - center clustering as opposed to the diversity maximization ) . Related Work . Composable core - sets : The notion of core - sets has been introduced in [ 5 ] . Informally , a core - set for an optimization problem is a subset of the data with the property that solv - ing the underlying problem on the subset gives an approxi - mate solution for the original data . The notion is somewhat generic , and many variations of core - sets exist . The notion of composable core - sets used in this paper has been implicit in earlier works that used core - sets for streaming applications . For example , the paper [ 5 ] ( Section 5 ) speciﬁes composabil - ity properties of (cid:15) - kernels ( a variant of core - sets ) that are very similar to ours . To avoid confusion , in this paper the term “core - set” always means “composable core - set” accord - ing to the deﬁnition in the introduction . The notion of composable core - sets is related to the notion of merge - able summaries introduced in [ 4 ] . The main diﬀer - ence between the two notions is that aggregating merge - able summaries does not increase the approximation error , while in our case the error ampliﬁes ( similarly to [ 22 ] ) . In partic - ular , every merge - able summary that is obtained by taking a sub - set of the data is also a composable core - set , but the opposite does not hold . Diversity Maximization : The diversity maximization problem studied in this paper generalizes the maximum dis - persion problem [ 24 , 20 , 9 ] . This problem has been explored in the context of diversity maximization for recommender systems [ 20 ] , and commerce search [ 9 ] . A 2 - approximation greedy algorithm has been developed for the unconstrained variant of this problem [ 24 ] , and the variant with knapsack constraints [ 9 ] . More recently , local search algorithms have been developed to get a 2 - approximation algorithm for the maximum dispersion problem under matroid constraints [ 3 , 10 ] . Diversity in Recommender Systems and Web Search : Ranking and relevance maximization along with di - versiﬁcation have been extensively studied in recommender systems , web search , and database systems . In the context of web search , maximizing diversity has been explored as a post - processing step [ 11 , 39 ] . Other papers explore ranking while taking into account diversity by a query reformulation for re - ranking the top searches [ 34 ] or by sampling the search results by reducing homogeneity [ 6 ] . Other methods are based on clustering results into groups of related topics [ 30 ] , or expectation maximization for estimating the model pa - rameters and reaching an equilibrium [ 35 ] . Moreover , in the context of recommender systems , diversiﬁcation has been ex - plored in various recent papers [ 41 , 40 ] . For example , topical diversity maximization is discussed in [ 41 ] , and explanation - based diversity maximization is explored in [ 40 ] . Finally , this topic has been also explored in database systems for example by presenting decision trees to users [ 14 ] . 2 . PRELIMINARIES We start by formalizing the notion of diversity used in this paper . Deﬁnition 1 . For a given set S ⊂ ∆ , its k - diversity is deﬁned as div k ( S ) = max S (cid:48) ⊂ S , | S (cid:48) | = k div ( S (cid:48) ) . We also refer to the maximizing subset S (cid:48) as the optimal k - subset of S . Note that k - diversity is not deﬁned in the case where | S | < k . Deﬁnition 2 . Let div be a diversity function deﬁned for subsets of ∆ . A function c ( S ) that maps a set S ⊂ ∆ into one of its subsets is called an α - composable core - set ( α ≥ 1 ) for div , if for any collection of sets S 1 . . . S L ⊂ ∆ with | S i | ≥ k , we have div k ( c ( S 1 ) ∪ . . . ∪ c ( S L ) ) ≥ 1 α · div k ( S 1 ∪ . . . ∪ S L ) The core - set is of size k (cid:48) if for every S , | c ( S ) | ≤ k (cid:48) . Note that in general k (cid:48) does not need to be the same as k . For example , in all applications mentioned in the previous sec - tion , a core - set of size k 2 would work as well when k is a constant . However , as it turns out , all our positive results give core - sets of size k . Our algorithms for constructing core - sets are based on ex - isting oﬀ - line approximation algorithms for the correspond - ing diversity maximization problems . In the rest of this sec - tion we review three such algorithms : GMM , Local Search and Preﬁx . 2 . 1 GMM Algorithm In this paper we use the following slight variation of the “GMM” algorithm introduced in [ 21 , 36 ] . The algorithm receives a set of points S , and the parameter k as the input . Initially , it chooses some arbitrary point a ∈ S . Then it repeatedly adds the next point to the output set until there are k points . More precisely , in each step , it greedily adds the point whose minimum distance to the currently chosen points is maximized . This algorithm was also utilized in [ 13 ] to ﬁnd approximation algorithms for several dispersion problems . Algorithm 1 GMM Input S : a set of points , k : size of the subset Output S (cid:48) : a subset of S of size k . 1 : S (cid:48) ← An arbitrary point a 2 : for i = 2 , . . . , k do 3 : ﬁnd p ∈ S \ S (cid:48) which maximizes min x ∈ S (cid:48) dist ( p , x ) 4 : S (cid:48) ← S (cid:48) ∪ { p } 5 : end for 6 : return S (cid:48) It is easy to see that the running time of the algorithm is O ( nk ) . Also , observe that if we deﬁne the radius value r = min p , q ∈ S (cid:48) dist ( p , q ) as the minimum pairwise distance in the set S (cid:48) , it is easy to see that the following two properties hold : • ∀ p ∈ S (cid:48) : dist ( p , S (cid:48) \ { p } ) ≥ r • ∀ p ∈ S : dist ( p , S (cid:48) ) ≤ r Such sets S (cid:48) are said to have the anticover property . 2 . 2 Local Search Algorithm Algorithm 2 shows the local search algorithm . This was used in [ 3 ] to ﬁnd a subset with approximate maximum di - versity under matroid constraints for the case of Remote Clique . The algorithm iteratively improves the current so - lution by a factor of ( 1 + (cid:15) / n ) and ﬁnds a more diverse set of k points . Since the initial set contains the two far - thest points , the total number of iterations needed is at most log 1 + (cid:15) / n ( k 2 ) = O ( n(cid:15) log k ) . Algorithm 2 Local Search Algorithm Input S : a set of points , k : size of the subset Output S (cid:48) : a subset of S of size k . 1 : S (cid:48) ← An arbitrary set of k points which contains the two farthest points 2 : while there exists p ∈ S \ S (cid:48) and p (cid:48) ∈ S (cid:48) such that div ( S (cid:48) \ { p (cid:48) } ∪ { p } ) ≥ div ( S (cid:48) ) ( 1 + (cid:15)n ) do 3 : S (cid:48) ← S (cid:48) \ { p (cid:48) } ∪ { p } 4 : end while 5 : return S (cid:48) 2 . 3 Preﬁx Algorithm The Preﬁx algorithm was introduced in [ 13 ] which is used to solve the approximate maximum dispersion problem in the case of Remote Pseudo - forest and Remote Matching . Note that the algorithm works only in the case when k ≤ n / 2 . Algorithm 3 PREFIX Algorithm Input S : a set of points , k : size of the subset Output S (cid:48) : a subset of S of size k . 1 : Run GMM obtaining a set Y = { y 1 , · · · , y k } with cor - responding radii r 1 , · · · , r k . 2 : q ← the value from the set { 1 , · · · , k − 1 } which maxi - mizes q · r q . 3 : Y q + 1 ← the preﬁx subsequence of Y of length q + 1 4 : Q i ← vertices of distance at most r q / 2 from y i for i = 1 , · · · , q + 1 . 5 : z ← (cid:98) ( q + 1 ) / 2 (cid:99) . 6 : { Q i 1 , · · · , Q i z } ← the z sparsest spheres . 7 : S (cid:48) ← the centers of { Q i 1 , · · · , Q i z } 8 : Add any set of k − z vertices from S \ (cid:83) zj = 1 Q i j to S (cid:48) 9 : return S (cid:48) 3 . COMPOSABLE CORE - SETS FOR DI - VERSITY MAXIMIZATION This section provides algorithms for ﬁnding composable core - sets for diﬀerent notions of diversity deﬁned in Table 1 . That is , we run one of the algorithms deﬁned in Preliminar - ies to get k points in each of the instances of the problem and prove their union is an approximate core - set for the union of the instances . In all of the following cases , we let S 1 , · · · , S L ⊂ ∆ be the subsets of ∆ that correspond to the instances of the problem and let S = (cid:83) Li = 1 S i denote their union . For each such instance S i , we ﬁnd a core - set T i and we let T = (cid:83) Li = 1 T i denote the union of the core - sets . Also we let O = { o 1 , · · · , o k } be the optimal k - subset of S , that is the subset of k points which maximizes the diversity . More - over , we deﬁne O i = { o ∈ O ∩ S i | ∀ j < i : o / ∈ S j } to be the set of points from the optimal set in each of the instances ( we impose extra condition in order to make O i ’s a partition of O ) . Next , for each notion of diversity , we describe how to choose T i and compare k - diversity of T with that of S , which is equal to the diversity of O . 3 . 1 Remote Edge Lemma 1 . The GMM algorithm computes a 3 - approximate composable core - set for the Remote Edge problem . Proof . We run the GMM algorithm on each of the sets S i and let T i = GMM ( S i ) be the point set returned by the GMM and we let r i denote the radius of T i . Let T = (cid:83) Li = 1 T i denote the union of the core - sets , and set r = max i r i to be the maximum radius over the instances . The goal is to prove that div k ( T ) ≥ div k ( S ) / 3 . Deﬁne a mapping f : O i → T i which maps each point o ∈ O i to one of its closest points in the set T i , i . e . , dist ( o , f ( o ) ) = dist ( o , T i ) . By the anticover property of GMM we have dist ( o , f ( o ) ) ≤ r i ≤ r . Note that since O i ’s form a partition of O , for any o ∈ O , we can deﬁne f ( o ) = f i ( o ) if o ∈ O i . It is easy to see that for any i , since T is a superset of T i , then div k ( T ) ≥ div ( T i ) = r i and thus div k ( T ) ≥ r . Next , note that if for two points o 1 , o 2 ∈ O , we have f ( o 1 ) = f ( o 2 ) , then div ( O ) ≤ dist ( o 1 , o 2 ) ≤ dist ( o 1 , f ( o 1 ) ) + dist ( o 2 , f ( o 2 ) ) ≤ 2 r ≤ 2 div k ( T ) and the lemma is proved . Otherwise f is a 1 - to - 1 mapping . Now if div ( O ) ≤ 3 r ≤ 3 div k ( T ) then in this case the lemma is proved as well . Otherwise , we can assume that for any pair of points o 1 , o 2 ∈ O , dist ( o 1 , o 2 ) ≥ 3 r and thus div ( O ) ≥ 3 r . Hence , by triangle inequality dist ( f ( o 1 ) , f ( o 2 ) ) ≥ dist ( o 1 , o 2 ) − dist ( o 1 , f ( o 1 ) ) − dist ( o 2 , f ( o 2 ) ) ≥ div ( O ) − 2 r ≥ div ( O ) − 2 div ( O ) / 3 ≥ div ( O ) / 3 since this holds for any pair o 1 , o 2 , the set { f ( o 1 ) , · · · , f ( o k ) } has diversity at least div ( O ) / 3 and thus div k ( T ) ≥ div ( O ) / 3 and the lemma is proved . 3 . 2 Remote Clique , Remote Star and Remote Bipartition In this section , we show that the local search algorithm gives a constant - factor approximation for the following di - versity notions : Remote Clique , Remote Star and Remote Bipartition . Lemma 2 . The local search algorithm computes a constant - factor approximate composable core - set for the remote - clique problem . Proof . We run the Local Search algorithm on each of the sets S i and let T i = LS ( S i ) be the point set returned by the Local Search and let r i represent the normalized diversity of the corresponding sets T i , i . e . , r i = 1 ( k 2 ) div ( T i ) and set r = max i r i . Claim 1 . There exists a 1 - to - 1 mapping f : O → T such that dist ( o , f ( o ) ) ≤ 25 r for any o ∈ O Proof . Build an unweighted bipartite graph G x = ( V O , U T , E x ) with vertices of one side corresponding to O and vertices of the other side corresponding to T as follows . For any o ∈ O and s ∈ T , we connect v o ∈ V O to u s ∈ U T iﬀ dist ( o , s ) ≤ x × r . Now , take any o ∈ O and suppose that o ∈ O i \ T i , that is , o is in the ith instance but has not been selected by LocalSearch algorithm . However , since no more improvement on the set T i could be made , we have (cid:88) s ∈ T i dist ( o , s ) ≤ ( k − 1 ) ( 1 + (cid:15) n ) r i ≤ kr Note that since | T i | = k , thus for at least ( 1 − 1 / x ) fraction of the values s in the above equation , we have dist ( o , s ) ≤ xr and therefore the corresponding edges in the graph G x exist . Thus the degree of each vertex v o corresponding to o ∈ O \ T is at least k ( 1 − 1 / x ) . First , take the graph G 3 . If G 3 has a matching which satu - rates the vertices of V O , then the claim is proved . Otherwise , let M be a maximal matching in G 3 such that for any point o ∈ O ∩ T , the corresponding vertices v o and u o are matched together . This means that the points corresponding to the set of unmatched vertices in U T ( which we denote by T \ M ) is disjoint from O , and also O \ M is disjoint from T . Let A = O \ M be the set of points which corresponds to the unmatched vertices . Then for any point a ∈ A , since a / ∈ T , the degree of v a is at least 2 k / 3 , and since M is a maximal matching , all the neighbors of v a should be matched in M . Therefore there are at least 2 k / 3 points o ∈ O \ { a } such that dist ( o , a ) ≤ 6 r . Now take the graph G 25 . If all vertices in V A = V O \ M are neighbors to all vertices in U T \ M , then clearly G 25 has a saturating matching for O and thus the claim is proved . Otherwise there exists a point a ∈ A and s ∈ T \ M such that dist ( a , s ) > 25 r . Let B ⊂ O be the set of points whose distance is at most 6 r from a . Then as we proved earlier | B | > 2 k / 3 . Hence , if we replace the point a in the set O with the point s to get the set O (cid:48) ( note that since T \ M is disjoint from O , we have s / ∈ O ) , the diversity will increase as follows . div ( O (cid:48) ) − div ( O ) = (cid:88) o ∈ O \ { a } dist ( s , o ) − dist ( a , o ) = (cid:88) o ∈ B \ { a } dist ( s , o ) − dist ( a , o ) + (cid:88) o ∈ O \ B dist ( s , o ) − dist ( a , o ) ≥ (cid:88) o ∈ B \ { a } dist ( a , s ) − 2 dist ( a , o ) − (cid:88) o ∈ O \ B dist ( a , s ) ≥ 2 k 3 × ( dist ( a , s ) − 12 r ) − k 3 × dist ( a , s ) = k 3 ( dist ( a , s ) − 24 r ) ≥ kr / 3 which contradicts the fact that O has the optimal diversity . Therefore the claim holds . As claim 1 suggests , there is a 1 - to - 1 mapping between the vertices of O and the vertices of T such that for each o ∈ O we have dist ( o , f ( o ) ) ≤ 25 r . First of all note that if (cid:0) k 2 (cid:1) × r ≥ div ( O ) / 51 the theorem is proved since for one of the T i we have div ( T i ) = (cid:0) k 2 (cid:1) × r and thus div k ( T ) ≥ div ( T i ) = (cid:32) k 2 (cid:33) × r ≥ div ( O ) / 51 Otherwise , we have that div k ( T ) ≥ (cid:88) o 1 , o 2 ∈ O dist ( f ( o 1 ) , f ( o 2 ) ) ≥ (cid:88) o 1 , o 2 ∈ O dist ( o 1 , o 2 ) − dist ( o 1 , f ( o 1 ) ) − dist ( o 2 , f ( o 2 ) ) ≥ div ( O ) − (cid:32) k 2 (cid:33) × 50 r ≥ div ( O ) ( 1 − 50 / 51 ) = div ( O ) / 51 So the lemma is proved and the algorithm computes a 51 - approximate core - set of size k . Corollary 1 . Local Search algorithm computes a con - stant factor core - set for the minimum star and minimum bipartition problems as well . Proof . First note that for a set of k points Q , a star is the tree achieved by connecting one point to all the others , and its weight is sum of the weights of its edges . Also a bi - partition of Q is a bipartite graph which divides the vertices of Q into two parts of cardinality k / 2 and its weight is the sum of all the edges between the two parts . It can easily be seen that • by symmetry wt ( minimum star ( Q ) ) ≤ 2 wt ( clique ( Q ) ) / k • by triangle inequality wt ( clique ( Q ) ) ≤ k × wt ( minimum star ( Q ) ) and that • wt ( minimum bipartition ( Q ) ) ≤ wt ( clique ( Q ) ) • by triangle inequality wt ( clique ( Q ) ) ≤ 5 × wt ( minimum bipartition ( Q ) ) Therefore the same algorithm computes a constant factor core - set for these two problems as well . 3 . 3 Remote tree , Remote Cycle , Remote t - trees and Remote t - cycles Lemma 3 . The GMM algorithm computes a 6 - approximate core - set for the remote - tree problem . Proof . We run the GMM algorithm on each of the sets S i and let T i = GMM ( S i ) be the point set returned by the GMM and we let r i denote the radius of T i . Let T = (cid:83) Li = 1 T i denote the union of the core - sets , and set r = max i r i to be the maximum radius over the instances . Now deﬁne a mapping ( this time not a 1 - to - 1 ) f : O i → T i which maps each point o ∈ O i to one of its closest points in the set T i , i . e . , dist ( o , f ( o ) ) = dist ( o , T i ) . By anticover property of GMM we have dist ( o , f ( o ) ) ≤ r i ≤ r . It is easy to see that for any i , div k ( T ) ≥ div ( T i ) ≥ ( k − 1 ) r i ( since the minimum pairwise distance in T i is r i ) , and thus div k ( T ) ≥ ( k − 1 ) r . Now if div ( O ) ≤ 3 ( k − 1 ) r ≤ 3 div k ( T ) , then the lemma is proved . Otherwise let F = range ( f ) = { f ( o ) | o ∈ O } ( note that F is a subset of T ) , and let F + ⊂ T be an arbitrary superset of F of size k . Then by triangle inequality and shortcutting div ( O ) = wt ( MST ( O ) ) ≤ wt ( MST ( F ) ) + kr ≤ wt ( MST ( F ) ) + 2 ( k − 1 ) r which uses the fact that k > 1 , otherwise any one point is a solution . Next , note that given the MST ( F + ) , we can double the edges and traverse them using DFS and remove the vertices not in F by shortcutting . Hence , by triangle inequality , we ﬁnd a Hamiltonian cycle of length at most 2 wt ( MST ( F + ) ) on the set F , therefore we have wt ( MST ( F ) ) ≤ 2 wt ( MST ( F + ) ) and thus div k ( T ) ≥ wt ( MST ( F + ) ) ≥ wt ( MST ( F ) ) / 2 ≥ 1 2 [ div ( O ) − 2 ( k − 1 ) r ] ≥ div ( O ) 2 − div ( O ) 3 ≥ div ( O ) 6 Lemma 4 . The same algorithm computes a 6 core - set for the Remote - t - tree . The proof is very similar to that for the Remote tree and hence moved to Appendix B . Corollary 2 . Note that since the minimum TSP tour is within a factor 2 of the MST , the above algorithm also com - putes a constant factor core - set for the remote - cycle problem and remote t - cycle problem . 3 . 4 Remote Pseudoforest and Remote Match - ing Lemma 5 . The GMM algorithm computes a O ( log k ) core - set for the remote - pseudoforest problem . Proof . We run the GMM algorithm on each of the sets S i and let T i = GMM ( S i ) be the point set returned by the GMM . Let T = (cid:83) Li = 1 T i denote the union of the core - sets . It is shown in page 11 of the paper [ 13 ] that when we run the Preﬁx algorithm on an input set A , the diversity achieved by this algorithm is at least q · r q / 4 and that q · r q / 4 ≥ div k ( A ) / O ( log k ) . Next , we compare running the PREFIX algorithm on the set S and on the set T . Let r S 1 , · · · , r Sk be the radii deﬁned in line 1 of Algorithm 2 . 3 , and let q S be the index chosen in line 2 , when we run it on the set S . Similarly , let us deﬁne r T 1 , · , r Tk and q T , when we run the algorithm on the set T . However by Lemma 1 , GMM algorithm computes a core - set for minimum pairwise distances . Together with the fact that running GMM in the Preﬁx algorithm on the sets S and T preserves the radii upto a constant factor , we get that r Ti ≥ r Si / c , for any value of i ≤ k and some constant c . The diversity achieved by the preﬁx algorithm is there - fore div k ( T ) ≥ q T · r Tq T / 4 ≥ q S · r Tq S / 4 ≥ q S · r Sq S / ( 4 c ) ≥ div k ( S ) O ( log k ) For the same reason the GMM algorithm computes a O ( log k ) core - set for the remote - matching problem as well with the only diﬀerence that the value of the matching achieved by the preﬁx algorithm when we run in on the input set A is at least qr q / 8 instead of qr q / 4 . 4 . NON - EXISTENCE OF CORESET FOR THE MAX K - COVERAGE An instance of the max k - coverage problem is a collection of sets . The objective is to ﬁnd k sets in this collection whose union has the maximum size . Theorem 1 . For any α < √ k log k and any constant β > 1 , there is no α - approximate core - set of size k β for the max k - coverage problem . Proof . Let U = { 1 , . . . , N } for a large N and k = m 2 . We construct a number of instances of the problem as fol - lows : For every subset S ⊂ U of size m 2 , we have an instance I S consisting of all m - subsets of S . Assume , for contradic - tion , that there is an α - approximate core - set , and let C S denote the core - set on the instance I S . Now , ﬁx a m 2 - set S , and let R be a random m - subset of S . For each ﬁxed A ∈ C S , the random variable | A ∩ R | is dis - tributed according to the binomial distribution Bin ( m , 1 m ) . The probability that the value of this variable is at least t is at most (cid:0) mt (cid:1) 1 m t < 1 t ! . With t = log m , this prob - ability is at most O ( m − c ) for every constant c . Using the union bound and the fact that | C S | ≤ m 2 β , we get : Pr [ ∃ A ∈ C S : | A ∩ R | > log m ] < O ( m 2 β − c ) for ev - ery constant c . We say that R is an easy subset of S if ∃ A ∈ C S : | A ∩ R | > log m . Therefore for every S , at most a O ( m − γ ) fraction of the m - subsets of S are easy , for every γ . We construct a graph whose vertex set is the set of all m 2 subsets of U . Two m 2 - sets S 1 and S 2 in this graph are adjacent if | S 1 \ S 2 | = m . We say that S 1 marks a neighbor S 2 as bad if S 1 \ S 2 is an easy subset of S 1 . By the above argument , each vertex S 1 marks at most an O ( m − γ ) fraction of its neighbors as bad . Since the total indegree of nodes in a graph is equal to the total outdegree , there must be a vertex S 1 in this graph such that at most an O ( m − γ ) fraction of its neighbors have marked S 1 as bad . Therefore , at most an O ( m − γ ) fraction of the neighbors of S 1 have either marked S 1 as bad or S 1 has marked them as bad . We call these neighbors the bad neighbors of S 1 , and the remaining neighbors the good ones . We now pick a collection of m 2 - sets S 1 , S 2 , . . . as follows : S 1 is the vertex deﬁned above . S 2 is an arbitrary good neighbor of S 1 . S i + 1 is a good neighbor of S 1 such that S i + 1 \ S 1 does not intersect any of the sets S j \ S 1 for j ≤ i . We argue that for any i < m 2 , there is a set S i + 1 with the above properties that we can pick . This is because for any x ∈ U \ S 1 , the fraction of neighbors of S 1 that contain x is precisely m N − m 2 . Therefore , by the union bound , the fraction of neighbors of S 1 that contain any of the elements of S j \ S 1 for j ≤ i is at most m 2 i N − m 2 , which is less than 1 / 2 for N > 3 m 4 . This means that at most a 12 + O ( m − γ ) < 1 fraction of neighbors of S 1 either have intersection with some S j \ S 1 for j ≤ i or are bad . Thus , we can ﬁnd S i + 1 with the desired properties , for i < m 2 . Now , consider the union of the instances I S 1 , I S 2 , . . . , I S m 2 − m . This instance has a perfect k - coverage solution : pick m non - overlapping m - subsets of S 1 to cover S 1 , and for every i > 1 , pick the m - subset S i \ S 1 . The total number of subsets picked is m + m 2 − m = k , and all of the O ( m 3 ) elements in S 1 ∪ · · · ∪ S m 2 − m are covered . On the other hand , by our construction , we know that for every i > 1 , S i \ S 1 is not an easy subset of S i . Therefore , any set in C S i covers at most log m elements of S i \ S 1 , and for j (cid:54) = i , C S j does not cover any element of S i \ S 1 . Thus , a collection of k sets in (cid:83) i C S i can cover at most k log m elements in (cid:83) i ( S i \ S 1 ) plus m 2 elements of S 1 . This means that the ratio of the best solution on the union of these instances and the solution that is limited to the union of the core - sets is at most m 2 log m + m 2 m 3 < log k √ k . 5 . CONCLUSIONS AND OPEN PROB - LEMS In this paper we presented constructions of composable core - sets for a wide range of diversity measures . As de - scribed in the introduction and Appendix A , our core - sets can be directly used to obtain constant - factor approxima - tion algorithms ( for the respective diversity measures ) in the context of data stream computation , distributed data pro - cessing and diverse nearest neighbor search . Some of those implications are essentially known ( in particular , the stream - ing and distributed algorithms for the remote - edge and the remote - star measures [ 22 , 12 , 23 ] and the nearest neighbor search algorithms for the remote - edge measure [ 2 ] ) . Other results and implications are , to the best of our knowledge , new . Our work raises several interesting open questions . Are there any other applications of composable core - sets , in ad - dition to the ones listed in this paper ? Is there a gen - eral characterization of diversity measures for which small composable core - sets exist ? Is it possible to obtain better approximation factors ? Acknowledgments . This work was supported in part by grants from MADALGO Center and NSF . 6 . REFERENCES [ 1 ] S . Abbar , S . Amer - Yahia , P . Indyk , and S . Mahabadi . Real - time recommendation of diverse related articles . In WWW , pages 1 – 12 , 2013 . [ 2 ] S . Abbar , S . Amer - Yahia , P . Indyk , S . Mahabadi , and K . R . Varadarajan . Diverse near neighbor problem . In SoCG , pages 207 – 214 , 2013 . [ 3 ] Z . Abbassi , V . S . Mirrokni , and M . Thakur . Diversity maximization under matroid constraints . In KDD , pages 32 – 40 , 2013 . [ 4 ] P . K . Agarwal , G . Cormode , Z . Huang , J . Phillips , Z . Wei , and K . Yi . Mergeable summaries . In Proceedings of the 31st symposium on Principles of Database Systems , pages 23 – 34 . ACM , 2012 . [ 5 ] P . K . Agarwal , S . Har - Peled , and K . R . Varadarajan . Approximating extent measures of points . Journal of the ACM ( JACM ) , 51 ( 4 ) : 606 – 635 , 2004 . [ 6 ] A . Anagnostopoulos , A . Z . Broder , and D . Carmel . Sampling Search - Engine Results . In WWW , 2006 . [ 7 ] A . Angel and N . Koudas . Eﬃcient diversity - aware search . In Proceedings of the 2011 international conference on Management of data , SIGMOD ’11 , pages 781 – 792 , New York , NY , USA , 2011 . ACM . [ 8 ] M . - F . Balcan , S . Ehrlich , and Y . Liang . Distributed clustering on graphs . In NIPS , page to appear , 2013 . [ 9 ] S . Bhattacharya , S . Gollapudi , and K . Munagala . Consideration set generation in commerce search . In WWW , pages 317 – 326 , 2011 . [ 10 ] A . Borodin , H . C . Lee , and Y . Ye . Max - sum diversiﬁcation , monotone submodular functions and dynamic updates . In PODS , pages 155 – 166 , 2012 . [ 11 ] J . Carbonell and J . Goldstein . The use of MMR , diversity - based reranking for reordering documents and producing summaries . In SIGIR , 1998 . [ 12 ] , M . Charikar , C . Chekuri , T . Feder and R . Motwani . Incremental Clustering and Dynamic Information Retrieval . SIAM J . Comput . 33 ( 6 ) , 2004 . [ 13 ] B . Chandra and M . M . Halld´orsson . Approximation algorithms for dispersion problems . Journal of algorithms , 38 ( 2 ) : 438 – 465 , 2001 . [ 14 ] Z . Chen and T . Li . Addressing Diverse User Preferences in SQL - Query - Result Navigation . In SIGMOD , 2007 . [ 15 ] F . Chierichetti , R . Kumar , and A . Tomkins . Max - cover in map - reduce . In WWW , pages 231 – 240 , 2010 . [ 16 ] G . Cormode , H . J . Karloﬀ , and A . Wirth . Set cover algorithms for very large datasets . In CIKM , pages 479 – 488 , 2010 . [ 17 ] J . Dean and S . Ghemawat . Mapreduce : Simpliﬁed data processing on large clusters . In OSDI , pages 137 – 150 , 2004 . [ 18 ] M . Drosou and E . Pitoura . Search result diversiﬁcation . SIGMOD Record , pages 41 – 47 , 2010 . [ 19 ] U . Feige . A threshold of ln for approximating set cover . J . ACM , 45 ( 4 ) : 634 – 652 , 1998 . [ 20 ] S . Gollapudi and A . Sharma . An axiomatic framework for result diversiﬁcation . In WWW , pages 381 – 390 , 2009 . [ 21 ] T . F . Gonzalez . Clustering to minimize the maximum intercluster distance . Theoretical Computer Science , pages 293 – 306 , 1985 . [ 22 ] S . Guha , N . Mishra , R . Motwani , and L . O’Callaghan . Clustering data streams . STOC , 2001 . [ 23 ] S . Guha , Tight results for clustering and summarizing data streams . ICDT , 2009 . [ 24 ] R . Hassin , S . Rubinstein , and A . Tamir . Approximation algorithms for maximum dispersion . Oper . Res . Lett . , 21 ( 3 ) : 133 – 137 , 1997 . [ 25 ] R . K . Iyer and J . A . Bilmes . Submodular optimization with submodular cover and submodular knapsack constraints . In Advances in Neural Information Processing Systems , pages 2436 – 2444 , 2013 . [ 26 ] A . Jain , P . Sarda , and J . R . Haritsa . Providing diversity in k - nearest neighbor query results . In PAKDD , pages 404 – 413 , 2004 . [ 27 ] M . W . Jones , J . A . Baerentzen , and M . Sramek . 3d distance ﬁelds : A survey of techniques and applications . Visualization and Computer Graphics , IEEE Transactions on , 12 ( 4 ) : 581 – 599 , 2006 . [ 28 ] H . J . Karloﬀ , S . Suri , and S . Vassilvitskii . A model of computation for mapreduce . In SODA , pages 938 – 948 , 2010 . [ 29 ] R . Kumar , B . Moseley , S . Vassilvitskii , and A . Vattani . Fast greedy algorithms in mapreduce and streaming . In SPAA , pages 1 – 10 , 2013 . [ 30 ] K . Kummamuru , R . Lotlikar , S . Roy , K . Singal , and R . Krishnapuram . A Hierarchical Monothetic Document Clustering Algorithm for Summarization and Browsing Search Results . In WWW , 2004 . [ 31 ] S . Lattanzi , B . Moseley , S . Suri , and S . Vassilvitskii . Filtering : a method for solving graph problems in mapreduce . In SPAA , pages 85 – 94 , 2011 . [ 32 ] H . Lin , J . Bilmes , and S . Xie . Graph - based submodular selection for extractive summarization . [ 33 ] G . L . Nemhauser , L . A . Wolsey , and M . L . Fisher . An analysis of approximations for maximizing submodular set functions , 1978 . [ 34 ] F . Radlinski and S . T . Dumais . Improving Personalized Web Search using Result Diversiﬁcation . In SIGIR , 2006 . [ 35 ] D . Raﬁei , K . Bharat , and A . Shukla . Diversifying web search results . In WWW , pages 781 – 790 , 2010 . [ 36 ] S . S . Ravi , D . J . Rosenkrantz , and G . K . Tayi . Facility dispersion problems : Heuristics and special cases . Algorithms and Data Structures , pages 355 – 366 , 1991 . [ 37 ] R . Sibson . Slink : an optimally eﬃcient algorithm for the single - link cluster method . The Computer Journal , 16 ( 1 ) : 30 – 34 , 1973 . [ 38 ] M . J . Welch , J . Cho , and C . Olston . Search result diversity for informational queries . In WWW , pages 237 – 246 , 2011 . [ 39 ] D . Xin , H . Cheng , X . Yan , and J . Han . Extracting Redundancy - Aware Top - k Patterns . In SIGKDD 2006 , 2006 . [ 40 ] C . Yu , L . V . S . Lakshmanan , and S . Amer - Yahia . Recommendation diversiﬁcation using explanations . In ICDE , pages 1299 – 1302 , 2009 . [ 41 ] C . - N . Ziegler , S . M . McNee , J . A . Konstan , and G . Lausen . Improving recommendation lists through topic diversiﬁcation . In WWW , 2005 . APPENDIX A . APPLICATION TO APPROXIMATE NEAREST NEIGHBOR In this section , we brieﬂy describe how we can apply the aforementioned core - sets to solve k - diverse near neighbor problem . The problem is deﬁned as follows . Given a query point q ∈ ∆ , the goal is to report the maximum diversity set S of k points in the ball of radius r around q . The points in the set S are chosen from a dataset of points P ⊂ ∆ of size n which is given to the algorithm at the preprocessing time . We would like to answer queries in sublinear time which necessitates solving the approximate problem . The approximate k - diverse Near Neighbor is deﬁned as follows . For some approximation factors c > 1 and α > 1 , we allow the points of the reported set S to be within distance cr of the query point , i . e . , S ⊂ P ∩ B ( q , cr ) . Moreover , we require that the diversity of the set S is within an α factor of the k - diversity of the optimal set , i . e . , div ( S ) ≥ 1 α div k ( P ∩ B ( q , r ) ) . The deﬁnitions and algorithm mentioned here are from [ 1 , 2 ] and are only included for completeness . Please see the original papers for the detailed theoretical [ 2 ] or experimen - tal [ 1 ] analysis of its performance . The algorithm uses the techniques of locality - sensitive hashing . Its basic idea is to hash the data and query points in a way that the probabil - ity of collision is much higher for points that are close to each other , than for those which are far apart . Formally , we require the following . Deﬁnition 3 . A family H = h : ∆ → U is ( r 1 , r 2 , p 1 , p 2 ) - sensitive for ( ∆ , dist ) , if for any p , q ∈ ∆ , we have • if dist ( p , q ) ≤ r 1 , then Pr H [ h ( q ) = h ( p ) ] ≥ p 1 • if dist ( p , q ) ≤ r 2 , then Pr H [ h ( q ) = h ( p ) ] ≤ p 2 In order for a locality sensitive family to be useful , it has to satisfy inequalities p 1 > p 2 and r 1 < r 2 . Given an LSH family , the algorithm creates L hash func - tions g 1 , g 2 , · · · , g L , as well as the corresponding hash ar - rays A 1 , A 2 , · · · , A L . Each hash function is of the form g i = < h i , 1 , · · · , h i , K > , where h i , j is chosen uniformly at random from H . Then each point p is stored in bucket g i ( p ) of A i for all 1 ≤ i ≤ L . In order to answer a query q , we then search points in A 1 [ g 1 ( q ) ] ∪ · · · ∪ A L [ g L ( q ) ] . That is , in each array , we only retrieve points from the single bucket which corresponds to the query point q . The aforementioned algorithm does not limit the number of points stored in a bucket , and hence its running time is unbounded . To avoid this problem we proceed as follows . During the preprocessing stage , for each of the buckets in all arrays A i , we replace the bucket content by its core - set , using the algorithms presented in this paper . Then , given a query point q , we collect the core - set points from the corresponding buckets of q , i . e , T = (cid:83) i c ( A i [ g i ( q ) ] ) . Since the core - sets has polynomial size in k , and the total number of hash functions L is sublinear in n , then the total number of points we collect in T is sublinear in n . By properties of core - sets , the k - diversity of the set T is comparable to k - diversity of the set S = (cid:83) i A i [ g i ( q ) ] . Moreover , one can set the parameters of LSH ( i . e . , L and K ) such that with high probability the two following conditions hold : • P ∩ B ( q , r ) ⊂ S , every point in the r - neighborhood of q is included in the set S . • S ⊂ B ( q , cr ) , any retrieved point is in the cr - neighborhood of q , i . e . , there are no outliers . Thus , if β shows the approximation factor of the core - set , then the value of div k ( T ) is within β factor of the value div k ( S ) . Since S is a superset of ( P ∩ B ( q , r ) ) , we get that div k ( T ) is within β - factor of div k ( P ∩ B ( q , r ) ) . Therefore we can run the “oﬄine” algorithm on the set T to get an approximate k - diverse subset of T whose diversity approxi - mates the diversity of the optimal set . More speciﬁcally , if β (cid:48) shows the best approximation fac - tor for the “oﬄine” version of diversity approximation , with running time of T ( m ) on m points , we can get ﬁnal bounds as follows . We can achieve approximation factor α = ββ (cid:48) , with query time of O ( T ( k ( log k ) cc − 1 n 1 c − 1 ) + d r ( log k ) cc − 1 n 1 c − 1 log n ) and data structure space equal to O ( ( n log k ) 1 + 1 c − 1 + nd ) . B . PROOF OF LEMMA 4 Let wt ( MST t ( A ) ) of a set of points A , denote the mini - mum sum of the weights of spanning trees achieved by di - viding A into t sets , i . e . , min A = A 1 | . . . | A t (cid:80) ti = 1 wt ( MST ( A i ) ) , where A = A 1 | . . . | A t is a partition of A into t sets . We run the GMM algorithm on each of the sets S i and let T i = GMM ( S i ) be the point set returned by the GMM and we let r i denote the radius of T i . Let T = (cid:83) Li = 1 T i denote the union of the core - sets , and set r = max i r i to be the maximum radius over the instances . Now deﬁne a mapping ( not necessarily a 1 - to - 1 ) f : O i → T i which maps each point o ∈ O i to one of its closest points in the set T i , i . e . , dist ( o , f ( o ) ) = dist ( o , T i ) . By properties of GMM we have dist ( o , f ( o ) ) ≤ r i ≤ r . First of all , note that it only makes sense if t ≤ k / 2 other - wise in any optimum solution , at least 2 t − k of the partitions include exactly one of the k points and therefore incur no cost . So instead we could consider the problem of choosing k (cid:48) = k − t points and having t (cid:48) = 2 ( k − t ) partitions in which t (cid:48) ≤ k (cid:48) / 2 . It is easy to see that for any i , div k ( T ) ≥ div ( T i ) ≥ ( k − t ) r i ( since the minimum pairwise distance in T i is r i ) , and thus div k ( T ) ≥ ( k − t ) r . Now if div ( O ) ≤ 3 ( k − t ) r ≤ 3 div k ( T ) , then the lemma is proved . Otherwise let F = range ( f ) = { f ( o ) | o ∈ O } ( note that F is a subset of T ) , and let F + ⊂ T be an arbitrary superset of F of size k . Then by triangle inequality and shortcutting div ( O ) = wt ( MST t ( O ) ) ≤ wt ( MST t ( F ) ) + kr ≤ wt ( MST t ( F ) ) + 2 ( k − t ) r which uses the fact that t ≤ k / 2 . Next , note that given the MST t ( F + ) , we can double the edges and traverse them using DFS and remove the vertices not in F by short - cutting . Hence , by triangle inequality , we ﬁnd a Hamil - tonian cycle in each part of the partition with total length at most 2 wt ( MST t ( F + ) ) on the set F , therefore we have wt ( MST t ( F ) ) ≤ 2 wt ( MST t ( F + ) ) and thus div k ( T ) ≥ wt ( MST t ( F + ) ) ≥ wt ( MST t ( F ) ) / 2 ≥ 1 2 [ div ( O ) − 2 ( k − t ) r ] ≥ div ( O ) / 2 − div ( O ) / 3 ≥ div ( O ) / 6