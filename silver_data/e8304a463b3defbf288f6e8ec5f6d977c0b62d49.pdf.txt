IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 1943 InnovA : A Cognitive Architecture for Computational Innovation Through Robust Divergence and Its Application for Analog Circuit Design Hao Li , Student Member , IEEE , Xiaowei Liu , Student Member , IEEE , Fanshu Jiao , Member , IEEE , Alex Doboli , Senior Member , IEEE , and Simona Doboli , Member , IEEE Abstract —This paper presents InnovA , a cognitive architecture for creative problem solving in analog circuit design , e . g . , topol - ogy creation ( synthesis ) , incremental topology modiﬁcation , and design knowledge identiﬁcation and reuse . The architectural modules attempt to replicate cognitive human activities , like concept formation , comparison , and concept combination . The architecture uses multiple knowledge representations organized using topological similarity and causality information . Solutions are clustered , so that each cluster represents a speciﬁc set of performance tradeoffs , thus a fragment of the Pareto front in the solution space . New structural features are created through vari - ation of existing features . New solutions are created by combining features from the same cluster , distinct clusters , and features that originate a new cluster . The related algorithms are discussed in this paper too . The architecture also incorporates modules mim - icking the using of human emotions in memory formation and decision making , but these modules are still under development and are a main direction for our future work . This paper presents a number of examples to illustrate its using in various analog cir - cuit design activities that are hard to be realized with traditional computational methods . Index Terms —Analog circuit design , cognitive architecture , constrained model , robust divergence . I . I NTRODUCTION C REATIVE problem solving is critical in engineering innovation , in particular in circuit design innova - tion . Engineering innovation tackles open - ended as well as ill - deﬁned design problems [ 1 ] – [ 3 ] . Open - ended problems require creating solutions with characteristics beyond the cur - rent domain knowledge , e . g . , new building blocks ( BBs ) , topologies ( structures ) , constraints , and operation principles . Ill - deﬁned problems introduce new requirements to an already Manuscript received March 8 , 2017 ; revised June 19 , 2017 and August 27 , 2017 ; accepted October 7 , 2017 . Date of publication December 14 , 2017 ; date of current version September 18 , 2018 . This work was supported by the National Science Foundation under Grant BCS 1247971 . This paper was recommended by Associate Editor F . Bonani . ( Corresponding author : Alex Doboli . ) H . Li , X . Liu , F . Jiao , and A . Doboli are with the Department of Electrical and Computer Engineering , State University of New York at Stony Brook , Stony Brook , NY 11794 - 2350 USA ( e - mail : alex . doboli @ stonybrook . edu ) . S . Doboli is with the Department of Computer Science , Hofstra University , Hempstead , NY 11549 USA ( e - mail : simona . doboli @ hofstra . edu ) . Color versions of one or more of the ﬁgures in this paper are available online at http : / / ieeexplore . ieee . org . Digital Object Identiﬁer 10 . 1109 / TCAD . 2017 . 2783344 existing problem , while the new requirements cannot be tack - led by simply exploring the tradeoffs of the existing solutions . Creative problem solving not only produces solutions to novel problems , but also generates new domain knowledge that is coherent with existing information and can be reused for future problems . Creative problem solving is difﬁcult to formalize as an algorithmic procedure . The ﬁrst efforts were centered around global problem solver algorithm , which performs a set of com - putational steps to reduce the gap between problem require - ments and solution characteristics [ 4 ] . While this approach mimics to some degree the cognitive , goal - directed reason - ing process [ 5 ] , [ 6 ] , devising computing systems that can address complex , real - world problems remains challenging . The second approach includes expert systems . They use a database of if - then rules to indicate the solving steps that are applied in speciﬁc conditions . Expert systems have been used to successfully solve certain circuit design problems [ 7 ] – [ 9 ] ; however , building effective rule databases and rule selection ( resolution ) strategies remains difﬁcult . Traditionally , static databases and selection rules have been used , but their nature does not accommodate well the adaptive nature of creative problem solving . The third approach utilizes evolutionary approaches , like genetic algorithms ( GAs ) and memetic algo - rithms [ 10 ] – [ 12 ] . The expectation is that design innovation emerges by applying genetic operators , like mutation and combination . However , studies show that GA - based computer - aided design ( CAD ) methods create circuit design solutions of signiﬁcantly less quality and reusability than human design - ers [ 13 ] . We believe that these differences are hard to tackle with traditional optimization - based synthesis . A . Overview on Cognitive Architecture Alternatively , cognitive architectures have been a promis - ing approach in performing tasks speciﬁc to human cognition , difﬁcult to handle through traditional , procedural methods . Cognitive architectures include various kinds of knowledge representations , and memory organization and retrieval mech - anisms . The related methods perform knowledge classiﬁcation , summarization , and comparison as well as techniques for decision making , prediction , learning , and goal setting . Examples of cognitive architectures are discussed in [ 14 ] – [ 18 ] . SOAR architecture models cognition - based 0278 - 0070 c (cid:2) 2017 IEEE . Personal use is permitted , but republication / redistribution requires IEEE permission . See http : / / www . ieee . org / publications _ standards / publications / rights / index . html for more information . 1944 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 Fig . 1 . Main elements of the model supporting the cognitive architecture . problem solving [ 17 ] , e . g . , robot navigation . ACT - R architec - ture proposes a number of important innovations : multiple ways of symbolic knowledge representations , learning of declarative and procedural information , and utility - based decision making [ 15 ] . EPIC architecture models peripheral cognition of perceptual biological systems [ 19 ] . Sigma cognitive architecture utilizes mixed representation models ( symbolic—probabilistic and discrete—continuous ) , knowl - edge summarization and integration , and inference - based reasoning [ 20 ] . Clarion architecture distinguishes between explicit and implicit cognition , each using speciﬁc repre - sentations and processing methods [ 21 ] . Other cognitive architectures are discussed in [ 22 ] – [ 25 ] . It is hard to estimate the suitability of existing cognitive architectures for creative problem solving in circuit design , as they do not refer to analog circuit design knowledge and do not emphasize robust divergence beyond the limits of existing knowledge . However , robust divergence is critical in tackling new goals and tradeoffs by inventing new BBs and struc - tures for the solutions . The cognitive architecture proposed in this paper identiﬁes invariant ideas ( patterns ) , structured idea sets , and idea structuring methods speciﬁc to the solution evolving processes characteristic to open - ended or ill - deﬁned problem solving activities . Creative activities are deﬁned as continuous processes of adapting existing knowledge to new problem requirements . The cognitive architecture learns reli - able approximations and heuristics that can correctly tackle the complexity of the solution space , e . g . , feature variations of the same knowledge concept and available ways of con - cept structuring to address certain problem requirements . The learned knowledge is encoded as reusable knowledge either explicitly as new BBs , causal information between parameters and outcomes , reasoning strategies , preferences , and beliefs , or implicitly as the cognitive architecture parameters learned during operation . B . Proposed Cognitive Architecture The proposed cognitive architecture ( InnovA ) addresses creative problem solving for analog circuit design , such as cir - cuit topology creation , incremental topology modiﬁcation , and design knowledge identiﬁcation and reuse . We argue that these techniques are difﬁcult to address using current methods . The architecture computationally mimics the cognitive functions considered by work in psychology to be critical in creativity and innovation , like concept formation , comparison , and con - cept combination [ 26 ] , [ 27 ] . It includes different knowledge representations ( similarity - based associations , outcome - related associations , and causal justiﬁcations ) organized as short - term , long - term , episodic , subjective , and context - dependent mem - ories . Multiple knowledge representations are stored in the memories organized as features and concepts ( circuit BBs ) at various levels of abstraction . New solutions are created by combining features and concepts using ﬁve generic strate - gies and by varying the structure of existing BBs . New BBs are candidates for future reuse , and are automatically rec - ognized . This paper summarizes the related algorithms and presents circuit design tasks performed using the methodol - ogy of the architecture . The architecture also includes modules related to emotion - based processing and knowledge restructur - ing when knowledge organization produces many inaccurate predictions , but the related algorithms are currently under development [ 28 ] . The presented cognitive architecture inte - grates and completes the individual methods and knowledge structures detailed in our previous publications [ 29 ] – [ 35 ] . Compared to our previous work , this paper indicates how the individual procedures and knowledge representations are utilized together in the cognitive architecture as well as the main characteristics and constraints of the architecture . These aspects are discussed in Sections II - B – II - D and III - C . Also , new are Sections V - A and V - B , which present more tradi - tional EDA applications of the architecture , e . g . , using it for transistor sizing and BB identiﬁcation . We argue that the proposed cognitive architecture repre - sents a signiﬁcant departure from the traditional , optimization and / or exploration - driven , design automation approaches for analog circuit design . We think that this paper is concep - tually more similar to the work by Lake et al . [ 36 ] in the sense that the method relies on the same computational pil - lars like theirs : “compositionality , causality , and learning to learn” [ 36 ] . However , that work tackles automated classiﬁca - tion of visual objects , like handwriting , which is a very distinct domain than circuit design . While some of the discussed appli - cations can be addressed with existing optimization algorithms too , we are not arguing that the cognitive architecture pro - vides superior optimization methods as optimization is not its main purpose . The main beneﬁt of the proposed work is in presenting a novel approach that mainly focuses on knowledge - centered design and reuse ( e . g . , using BBs , design features and patterns , etc . ) for tasks , like design comparison , causal reasoning for design understanding , incremental design reﬁnement , design feature combination , and mimicking certain design styles . Other knowledge - centered activities are possible too . We think that many of the shown algorithms can be further improved to better their design quality and effectiveness . This paper has the following structure . Section II dis - cusses the formal model supporting the proposed architecture . Section III describes its structure and Section IV presents the related algorithms . Section V illustrates a set of design activities performed using the methodology of the cognitive architecture . The conclusion ends this paper . II . F ORMAL M ODEL Fig . 1 summarizes the main elements of the model of the proposed cognitive architecture . 1 ) The architecture produces solutions through incremental evolution ( transformations ) . 2 ) Solutions are clustered in topologically similar sets , each cluster having a unique kernel . All solutions in a cluster can be obtained from the kernel through incremental transformations . Hence , each cluster LI et al . : InnovA : COGNITIVE ARCHITECTURE FOR COMPUTATIONAL INNOVATION THROUGH ROBUST DIVERGENCE 1945 tackles an invariant set of tradeoffs ( niche ) and represents Pareto front fragments implementing the tradeoffs . The model includes ﬁve evolution strategies . 1 ) Using knowledge only from its own cluster ( strategy 1 ) . 2 ) Using knowledge originated in other clusters ( strategy 2 ) . 3 ) Creating new clusters ( niches ) by combining features from different clusters ( strategy 3 ) . 4 ) Using alternative features , hence by excluding an exist - ing niche ( strategy 4 ) . 5 ) Through kernel aggregation , in which a new kernel and cluster result by aggregating the features of individual solutions ( strategy 5 ) . This section ﬁrst summarizes the basic model and then presents the constrained model for robust divergence , the model architecture , and the characteristics of the constrained model evolution . A . Summary of the Basic Model A summary of the basic model supporting the cognitive architecture is presented next . The detailed description is offered in [ 29 ] . The model elements are as follows . 1 ) An attribute ( feature ) is the triplet ( vars ; rel ; context ) , where vars is the set of attributes involved in the attribute description , rel is the relation between attributes , and context are the conditions ( constraints ) under which the relations hold . Each variable v i is deﬁned over its domain Dom i , 1 × Dom i , 2 × · · · Dom i , k . 2 ) Concept C is the triplet C = < Invariants , Uniqueness , Enabling > ( 1 ) or C = < I , U , E > ( 2 ) where each of the three elements is an attribute set . The elements are deﬁned as follows : (cid:2) I ( C ) = (cid:3) A i | A i ∈ ∩ ∀ D i ∈ C Attr ( D i ) (cid:4)(cid:5) (cid:6) = ∅ ( 3 ) where D i are the instances of concept C and Attr ( D i ) the set of attributes of instance D i . The set indicates the attributes common to all concept instances ( U ( C ) = { A i | A i ∈ I C ∧ A i (cid:6)∈ I ( C k ) , ∀ C k (cid:6) = C } ) (cid:6) = ∅ . ( 4 ) The set represents the attributes that are unique to con - cept C , hence distinguish it from the other concepts C k in the knowledge representation E ( C ) = (cid:3) e | ∃ A i ∈ Attr ( C ) , s . t . e → context A i (cid:4) . ( 5 ) It is the set of conditions under which the attributes in sets I and U hold . In addition , an attribute of a concept cannot be independent from the other attributes ∀ A i ∈ Attr ( C ) , ∃ A j ∈ Attr ( C ) s . t . A i (cid:6) = A j ∧ v j ∈ vars A i ∩ vars A j (cid:6) = ∅ . ( 6 ) Moreover , concept features can be partitioned into BBs . BBs are nonoverlapping sets of features , so that their variables pertain either to a single partition ( internal variables ) or to multiple partitions , so that the vari - ables input in one partition are output by the other Fig . 2 . Constrained model of the cognitive architecture . partition ( interfacing variables ) . The consequence of the partitioning requirement is modularity . 3 ) A solution is a concept C that meets the requirements of a problem , hence produces a certain reward , at the expense of a certain cost . 4 ) Each concept C representing a solution has a causal sequence indicating how its attributes serve in meet - ing the performance requirements of the problem or providing the context conditions of other attributes . A consequence of condition 2 ) is that concepts have a topol - ogy ( structure ) deﬁned by the relations between attributes . Similarity deﬁnes matching relations between the variables of attributes [ 30 ] , and are used to ﬁnd the similarities and differences between BBs and concepts [ 30 ] . The model is characterized by metrics : 1 ) about the gen - erated solutions and 2 ) about the evolution ( transformation ) process [ 13 ] . The ﬁrst set includes performance bottlenecks , constraining factor ( ﬂexibility reduction due to a feature ) , vari - able domain modiﬁcation ( variable domain extension after concept combination ) , and amount of performance improve - ment ( improvement in problem requirements matching due to a concept combination ) . The second set includes metrics like ﬂexibility ( number of different features that can be com - bined with a concept ) , expected increase in concept structure ( EICS , expected new concepts that are produced by a struc - ture ) , and concept complexity index ( CCI , concept complexity measure ) . The remaining of the section presents the model extension for improving the robustness of solution evolution . B . Constrained Model The role of constraints in the formal model is to increase the likelihood of robust evolution of creative solutions to open - ended or ill - deﬁned problems . Robustness is deﬁned by the degree to which evolution converges toward effective solutions to such problems . Hence , robustness describes the capability of reaching efﬁcient tradeoffs between the determinism and uncertainty of a problem . Tradeoffs are deﬁned by the concept attributes of the solution . The likelihood of producing problem - satisfying solutions is described by the following equations : Likelihood ( success ) ≈ max ( ∃ ) Flexibility ( Knowledge ) , s . t . | Requirements ( Problem ) − Performance ( Solution ) | < (cid:2) ∧ Solution = Sequence ( Knowledge , Operator set ) ∧ min Complexity ( Solution ) ( 7 ) 1946 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 hence , the existing knowledge has sufﬁcient ﬂexibility to sup - port creation of solutions that meet the problem requirements and have minimal complexity . Solutions are created by apply - ing a sequence of operators to the existing knowledge . New knowledge and operator sequences might be created during the process . The equation states that there are sufﬁcient knowl - edge and available procedures to create solutions that are of minimum ( reasonable ) complexity . Solutions are produced using four operators that create fea - sible solutions by adding or replacing BBs to address the problem requirements , or by changing the structure of an exist - ing BB through variation or analogy with existing BBs . The ﬁve strategies in Fig . 1 are used . Operators are selected so that they improve performance ( i . e . , reduce the distance of the solutions to the requirements ) and / or increase the variable domains of the solutions , hence reduce the constraining of the solutions while the new solution remains within distance Th from the requirements Solution new = Sequence ( Solution , Operator i ) , s . t . ( | Requirements ( Problem ) − Performance ( Solution new ) | < | Requirements ( Problem ) − Performance ( Solution ) | ) ∨ ( VDM ( Solution new ) > VDM ( Solution ) ∧ | Requirements ( Problem ) − Performance ( Solution new ) | < Th ) . ( 8 ) The constraints of the formal model help the implicit evalua - tion of the model metrics during solution evolution . They aid a more tractable problem - solving process . Using the metrics , ( 7 ) is restated as follows : Likelihood ( success ) ≈ max ∪ i EICS ( C i ) , C i ∈ Knowledge s . t . | Requirements ( Problem ) − Performance ( Solution ) | < (cid:2) ∧ Solution = Sequence ( Knowledge , Operator set ) ∧ ( | Requirements ( Problem ) − Performance ( Solution new ) | < | Requirements ( Problem ) − Performance ( Solution ) | ∨ VDM ( Solution new ) > VDM ( Solution ) ∧ | Requirements ( Problem ) − Performance ( Solution new ) | < Th ) ∧ min CCI ( Solution ) . ( 9 ) Thus , the overall EICS value for concepts C i in the knowl - edge structure ( and the related Pareto front fragments ) should be maximized through sequences of transformations involving the ﬁve cases in Fig . 1 and with minimum complexity of the solutions on the front fragments . In addition , there are enough resources available to generate the solution , e . g . , to support search ( reasoning ) until ﬁnding a solution . The model’s deterministic elements include the BBs of the concepts in the knowledge structure , their incorporated attributes ( features ) , the operators used to produce new solu - tions , and the conditions that select the candidate options for the evolution process . The unknowns include deciding the actual operators as well as the actual features used in cre - ating new BBs or blocks which are added or replaced . The proposed constraints aim to increase the robustness of the evolution process , so that ( 7 ) – ( 9 ) are more likely to be met . Equation ( 9 ) is addressed through the incremental evolution process summarized in Fig . 1 . The process expands current niches , including their Pareto front fragments , and creates new niches and kernels using the ﬁve evolution strategies in Fig . 1 . Then , the maximization goal in ( 9 ) becomes max ∪ i EICS ( C i ) , C i ∈ Knowledge ≈ max ∪ j EICS (cid:2) kernel j (cid:5) . ( 10 ) Hence , EICS of the concepts in the domain knowledge rep - resentation is approximated by EICS of the kernels of the solution clusters that were identiﬁed E (cid:6) max ∪ j EICS (cid:2) kernel j (cid:5)(cid:7) ≈ max ∪ j (cid:8) k , C m ∈ cluster j E (cid:6)(cid:2) EICS (cid:2) Seq k ( C m ) (cid:5)(cid:5)(cid:7) , s . t . Reward > Th R . ( 11 ) The expected maximum EICS of the kernels is the reunion of the Pareto front fragments of all clusters j ( corresponding to kernel j ) created by applying sequences Seq k of the ﬁve operators to concepts C m in a cluster . Reward models the usefulness of continuing the incremental evolution of a cluster . It has three elements . 1 ) The distance between problem requirements and solution performance and the solution constraints relation in ( 9 ) . 2 ) The effort ( resources ) available to the cluster ( niche ) to further conduct incremental evolution . 3 ) The beneﬁts produced by a niche for another niche ( e . g . , the created BBs are also used by another niche ) . Th R is a lower bound . Equation ( 11 ) was recast as the following two equations : max j ∪ j (cid:8) k , C m ∈ cluster j E (cid:6) Reward (cid:2) Seq k ( C m ) (cid:5)(cid:7) ≈ max j ∪ j (cid:8) k , C m ∈ cluster j E (cid:6)(cid:9)(cid:9) Requirements ( Problem ) − Performance ( Seq k ( C m ) ) (cid:9)(cid:9) < (cid:2) (cid:7) , s . t . min ∪ m , k Effort ( Seq k ( C m ) ) . ( 12 ) The equation states that the expectation to meet the problem requirements should be achieved using minimum effort max ∪ E j (cid:6) reusable variety (cid:2) cluster j (cid:5)(cid:7) . ( 13 ) The equation corresponds to previous aspect 3 ) and states that the reusable variety of all clusters should be maximized . The above equation states that incremental evolution originates dynamic conditions ( e . g . , equilibrium conditions ) between top - down constraints introduced by kernels and bottom - up constraints deﬁned by BB variations . C . Architecture of the Constrained Model Fig . 2 presents the structure of the constrained model of the cognitive architecture . Note that the model incorporates a set of parameters that are adjusted depending on the current activity : critical number and critical diversity of the solution population , increment granularity for incremental evolution , acceptable similarity errors for the solution matching proce - dure , acceptable decoupling error for outcome prediction , and threshold of correct prediction . Model parameters are critical for the robust evolution of creative solutions . However , it is difﬁcult to explicitly decide the parameter values that produce robust evolution as well as the relations between parameters . The model constraints set the parameters through an implicit process . Moreover , many combinations of parameter values are either infeasi - ble or equivalent with respect to the solutions they generate . Constraints and the cognitive architecture attempt to reduce such situations . The cognitive architecture in Section III includes a scheme for setting the values of these parameters . LI et al . : InnovA : COGNITIVE ARCHITECTURE FOR COMPUTATIONAL INNOVATION THROUGH ROBUST DIVERGENCE 1947 The model constraints are grounded in the following principle that supports more effective solution outcome prediction . The principle ( called orthogonal—quasilinear— saturation assumption ) is grounded in observations in cog - nitive psychology [ 37 ] . It has three components . 1 ) Orthogonality refers to the fact that solution charac - teristics ( e . g . , functionality and performance ) can be related to concept attributes ( features ) , e . g . , BB param - eters . Hence , the purpose of the BBs can be decided , or their presence in a solution can be justiﬁed . Thus , the causality of BBs is decidable , such as the causal - ity between BB parameters and changes in functionality and performance . 2 ) The quasilinear element refers to the approximately lin - ear dependency between concept features changes and performance variations for certain conditions . 3 ) Saturation indicates the concept feature conditions beyond which the quasilinear assumption fails . Thus , it shows the ranges of the current solution front . The other model constraints describe two aspects , solu - tion clustering and incremental evolution of solutions . Constraints also incorporate elements to implicitly imple - ment the orthogonal—quasilinear—saturation principle . The two aspects are elaborated as follows . 1 ) Similarity - Based Solution Clustering ( Niche Emergence ) : a ) Clustering : Solutions are clustered based on topolog - ical ( structural ) similarity . Given cluster C , there is a set of concepts D and a set of connections between the concepts in set D , so that any solution in cluster C can be obtained by transforming the connected concepts in D . The connected concepts are called the kernel of the cluster . Hence , ( ∀ ) C m ∈ cluster (cid:2) kernel j (cid:5) , ( ∃ ) Seq k s . t . C m = Seq k (cid:2) kernel j (cid:5) . ( 14 ) Clusters sample the solution space , each cluster representing a certain set of performance tradeoffs . Tradeoffs create the solu - tion niche occupied by the cluster . A cluster is dominated by another cluster , if all its tradeoffs are worse than the trade - offs of other clusters . The Pareto front is formed by the set of clusters that are not dominated . Each kernel or concept is described by its causality sequence var 1 → SPerf 1 (cid:9)(cid:9) context var 1 ; var 2 → SPerf 2 (cid:9)(cid:9) context var 2 · · · ( 15 ) where SPerf i is the set of performance causally controlled by parameter var i under the conditions deﬁned by context i . The variable earlier in the sequence are deemed to have a higher priority than the latter parameters . Hence , a causal sequence deﬁnes an ordering in which the performance parameters of the tradeoff of a cluster should be tackled . b ) Comparison : Two solutions of the same cluster are compared with each other using the following procedure ( differential analysis ) . 1 ) Find the set of transformations Seq 1 and Seq 2 that gen - erate each of the two solutions starting from the common kernel . 2 ) For each attribute of the two solutions ﬁnd the common sequence of transformations with the other solution . 3 ) Match the features of the two solutions , so that their common sequence of transformations is maximized ( max Seq c ; Seq c ⊂ Seq 1 , Seq 2 ) . ( a ) ( b ) Fig . 3 . Incremental evolution ( transformation ) with concept combinations ( a ) within the same cluster and ( b ) across two clusters . 4 ) Compute the topological distance between pairs of matched attributes as the reunion of the disjoint trans - formation sequences of the attributes ( Dist = ( Seq 1 − Seq c ) ∪ ( Seq 2 − Seq c ) ) . Solution similarity is the common part . 5 ) Correlate the topological similarities and distances to the solutions’ performance . The procedure is based on concept uniﬁcation , a well - known activity in cognitive psychology [ 38 ] , [ 39 ] . The similarity of a cluster is the intersection of the similarities of all solution pairs of the cluster . The diversity of the cluster is the set of distances between all pairs . The values under which all con - ditions context i are valid are part of the belief system and are found using the matching algorithms presented in [ 30 ] . A consequence is that if a solution is an instance of a kernel then there is a matching between the parameters of the two sequences , so that parameters have the same ordering in the sequence and realize the same kind of effect on the performance parameters . 2 ) Incremental Evolution of Solutions : a ) Solution combination : The attributes of two solutions are combined using the following rules . The discussion con - siders that concepts are described as data / signal processing ﬂow graphs , as in [ 30 ] . Fig . 3 illustrates the next situations . 1 ) The solution attributes modiﬁed during combination are those that produce the most signiﬁcant improvement of the required performance or relaxing of the variable domains . This is achieved by storing the causal relations var i → Perf j | context var i ( 15 ) of each attribute for the solutions in which it has been used before . The causal relations are part of the predictors used in estimating the expected solution performance . 2 ) If the two solutions pertain to the same cluster then the following constraints must be met [ Fig . 3 ( a ) ] . a ) The solution includes the instantiation present in one of the solutions for the common part . b ) The distinct attributes are present only if their enabling conditions are met by the rest of the attributes and they are justiﬁed by improving 1948 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 Fig . 4 . Divergent evolution . performance or ﬂexibility , i . e . , relaxing the require - ments of the solution . The ﬁgure shows three different kinds of solution combi - nations ( different colors indicate how BBs are combined in the results ) . 3 ) If the two solutions are in different clusters , a new kernel is generated from the BBs of the solutions [ Fig . 3 ( b ) ] . The new kernel corresponds to a new cluster for a dif - ferent niche . Colors show how BBs combine to form the new kernel and one of its related concepts ( solution ) . In a top - down ﬂow , abstract features combine to ﬁrst form the kernel , followed by instantiating it into solutions . In a bottom - up ﬂow , physical features combine to produce the solution of a new cluster , followed by creating its kernel through abstraction . Constraints ( 2 ) and ( 3 ) help that new solutions are feasible . D . Characteristics of the Constrained Model Evolution The following elements characterize the constrained model . 1 ) Multiple Representations : Having multiple knowledge representations is a consequence of clustering using differen - tial analysis and causality . Representations are at different level of granularity depending on the kernel of the cluster , represent associative structures depending on topological similarity , or describe causal representations that give insight ( justiﬁcation ) of how the connected BBs of a solution meet the require - ments of the problem . Hence , concepts and attributes are organized hierarchically , and implicitly introduce relationships like synonyms , homonyms , and antonyms . A discussion of the knowledge representation structuring for different open - ended and ill - deﬁned problems are presented in [ 40 ] . Knowledge structuring is also discussed in [ 41 ] and [ 42 ] . 2 ) Robust Divergent Evolution : The second issue relates to achieving robust topological divergence , e . g . , new solution topologies are created , so that they pertain to a niche of the problem requirements and their new attributes ( features ) are reusable beyond the current niche . Incremental evolution is achieved through the ﬁve strategies in Fig . 1 . Divergence is spurred by two situations . 1 ) The current solutions cannot meet the problem require - ments . 2 ) There is a change of the problem requirements , i . e . , a gradual change of the importance of individual performance attributes , or a merging of previously con - sidered independent requirements . As a result , new cluster kernels are produced , hence new niches emerge . Fig . 4 depicts divergence during evolution . The evolution process creates alternatives for the BBs with the least impact on the performance requirements of the current niche ( hence , the block of least causality ) , including new BBs produced through variation or analogy of existing blocks . The situa - tions are explained by the fact that the least causal blocks are the most ﬂexible , given that the resulting solutions should be feasible . This process is similar to null spaces in regulatory biological structures [ 43 ] , where redundant structures incor - porate large topological variety . Robust divergence relates to creating enough BB variety to generate requirement - satisfying solutions . Divergence applies the existing BB variety to the ﬁrst solu - tion predicted to solve the problem , e . g . , the least abstract solution without the tradeoffs deﬁning the current niche ( e . g . , the bottlenecks of the solutions associated to the niche ) . This selection process mimics gradual disassembling of the solu - tion , from the least to the more important blocks . The EICS from the concept is likely to include a solution to the problem , if such solutions are reachable with the current knowledge and resources . The correctness of EICS prediction is improved by uncoupling the causal parameters of the tradeoffs and by the linear dependency of the solution performance on the causal parameters . The evolution of a cluster stops in two conditions : apply - ing the four operators does not further improve the solution performance or the rewards associated to the problem are exhausted . In the ﬁrst case , the bottlenecks embedded in the kernel cannot be further tackled to generate superior solu - tions . Rewards are reduced by the cost spent to devise new solutions , hence each solution transformation encumbers a certain cost . Every kernel and its related cluster forms a niche of the evolutionary process through the solution space . The solutions obtained by transforming the kernel using the four operators are valid . Hence , each cluster is a collection ( repository ) of BBs available to tackle the requirements of a problem . Every niche carries a reward representing the resources available to conduct the evolution process . The emergency of new niches can be through two approaches : 1 ) gradual change of the problem requirements until a new problem and niche emerge , i . e . , in open - ended problem and 2 ) merging of previously unrelated requirements , e . g . , in ill - deﬁned problems . Constraints increase the robustness of the evolution process as expressed by ( 7 ) and ( 8 ) . The justiﬁcation is as follows . 1 ) The four operators applied under constraints ( 2 ) and ( 3 ) help producing mainly feasible ( working ) solutions . 2 ) Moreover , solution clustering for different performance niches helps maximizing the diversity ( variety ) of the available BBs , e . g . , the likelihood of developing different structures and BBs . 3 ) The orthogonality—linear—saturation principle aids predicting the features that are likely to improve performance or relax the performance tradeoffs embed - ded in a solution . It is similar to a set of piecewise - linear performance approx - imations . It also supports a more correct identiﬁcation of orthogonal causalities , i . e . , solution features that need to be addressed during evolution . A concept’s ﬂexibility in gener - ating new solutions ( 7 ) and ( 9 ) is approximated by concept typicality and versatility Flexibility ( C ) ≈ Typicality ( C ) , Versatility ( C ) . ( 16 ) LI et al . : InnovA : COGNITIVE ARCHITECTURE FOR COMPUTATIONAL INNOVATION THROUGH ROBUST DIVERGENCE 1949 Fig . 5 . InnovA : cognitive architecture for circuit design innovation . Note that this equation is similar to Bayesian inference , con - sidered to be a good model for human decision making [ 44 ] . III . C OGNITIVE A RCHITECTURE Fig . 5 presents the cognitive architecture ( called InnovA ) based on the constrained model discussed in Section II . Knowledge is organized as three components in module semantic memory : 1 ) associative structure ; 2 ) connections to goals ; and 3 ) causal sequences ( justiﬁcations ) . The associa - tive structure clusters concepts based on the similarity of their features . Each concept is an abstraction of its reﬁne - ments . Cost functions used in clustering analog circuit design knowledge were discussed in [ 30 ] . Multiple associative repre - sentations result depending on the similarity tightness ( error ) used in clustering . Connections to goals indicate associations between concepts and speciﬁc requirements , e . g . , the concept likely having a main impact on requirements . Connections are important in introducing causal relations for speciﬁc solutions . Causal sequences justify the using of speciﬁc BBs and BB connections in creating a solution , i . e . , the way in which BBs relate to each other and the solution tradeoffs that are tackled when solving a problem . The architecture has two parts : 1 ) the part for objective learning and reasoning ( the modules shown with continuous line in the ﬁgure ) and 2 ) the part for subjective learning and reasoning ( the modules presented with dashed line ) . The cognitive architecture instantiates the three modules of the semantic memory as part of three memory sub - systems : 1 ) global memory system ; 2 ) subjective memory ; and 3 ) context - dependent memory . Global memory system includes the entire knowledge to which the cognitive architecture has been exposed , like the knowledge that was preprogrammed into the architecture or learned during oper - ation . Like in other cognitive architectures [ 16 ] – [ 18 ] , the memory system is organized as long - term memory ( all asso - ciative structures , all connections to goals , and all causal sequences ) , short - term memory ( the knowledge accessed for the current task ) , and episodic memory ( all solution outcomes for speciﬁc problems ) . The subjective memory module includes the learned knowl - edge for effective problem solving , including the learned heuristics for a more efﬁcient traversing of the solution space . The subjective memory has the following three parts . 1 ) Beliefs are truth values likely to increase the effective - ness of reusing the available knowledge in solving a new problem . Beliefs are learned dynamically during oper - ation . Belief formation represents an inference process that ﬁnds the conditions under which the interpretation of the causal sequences of solutions is correct [ 45 ] . Beliefs are ranked based on their strengths . The pro - cess represents unsupervised learning . The consistency of beliefs ( e . g . , if beliefs contradict each other or not ) is a measure of the correctness of prediction , hence , sur - passing certain thresholds triggers the need for belief modiﬁcation and knowledge restructuring . 2 ) Preferences indicate the priority in selecting a feature or a concept from a set of approximatively similar alter - natives to be incorporated into a solution . Preferences deﬁne an ordering of alternatives . They result through unsupervised learning . Preferences also include social aspects , like prestige of others , outcome importance to others , and preferences of others [ 37 ] . 1950 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 3 ) Emotion module mimics the using of human emotions in decision making and problem solving [ 46 ] , [ 47 ] . The module associates the degree of matching and the nature of mismatches between outcomes and problem require - ments to ﬁxed set of bins ( analogous to emotions ) . The module also learns social emotions , e . g . , importance ( usefulness , novelty ) for others , problem population - level requirements , etc . Learning is similar to supervised classiﬁcation as the set of available emotions is ﬁxed . Emotion module is correlated to the preference memory . Context - dependent memory stores instances of the subjec - tive memory for a given problem . Certain beliefs , priorities , and emotions are selected depending on the speciﬁc context . Selection uses the previous contexts similar to the current situation . Objective learning and reasoning part has the next modules . Population of solutions module are the solutions that are under development for the current problem , including their BBs , connections to the problem requirements , and causal sequences . The population contains the current Pareto front for the problem as well as the solutions , features , and steps utilized to obtain the front . A population subset controlled by Attention window module is stored in the short - term memory . The population of solutions does not have a cognitive equivalent . Understanding needs module utilizes causality information and unmatched requirements to decide which features and BBs need to be tackled next by the problem solving pro - cess . The process generates a cue that is used together with context - dependent memory to access the long term memory to retrieve useful features and BBs . Possible cues pertain to a cue hierarchy . 1 ) Constraints on the features ( parameters ) of the BBs . 2 ) Orderings among constraints ( i . e . , preferences and pri - orities ) . 3 ) Causality aspects , i . e . , how features relate to require - ments . 4 ) Constraints on the priority of the requirements that must be tackled . More concrete cues are more speciﬁc to the problem , more abstract cues are more suitable for being reused . The con - cept of pattern search discussed in [ 48 ] can be interpreted as an example of constraints on parameter values and ordering among parameter constraints . The module to produce alternatives using incremental trans - formations through operators utilizes the current population of solutions and the four operators to create new solutions . As explained in Section II , the new solutions are more likely to be feasible because of the constraints of the underlying model . Select alternatives module picks from the set of possible alternatives a solution to be further developed by the pro - cess . Selection uses the two prediction modules : 1 ) predictions about causality to understand how the new design features address the limitations of the current design and 2 ) predictions about outcomes module that estimates the expected outcomes of the solutions ( functionality and performance ) . Selection uses different matching criteria between predictions and requirements , like to maximize the reward , to maximize the difference between reward and cost , and to minimize cost . The criteria correspond to different cognitive selection strategies [ 37 ] . Simulation ( embodiment ) offers a precise ( yet more compu - tationally cumbersome ) evaluation of the solution functionality and performance , e . g . , using a standard circuit simulator . Circuit simulation offers knowledge embodiment into the real world , a well - known issue in cognitive architectures [ 49 ] . Signiﬁcant discrepancies between circuit simulation and the two prediction modules triggers knowledge restructuring . Discrepancies also refer to the consistency of beliefs , causali - ties , feature matchings , clusters , and predictions . Restructuring reorganizes the associative memory structures , connections to goals , causal sequences , beliefs , and priorities . The model architecture instantiates the operator sequence Seq k in ( 12 ) following one of the following ﬁve types of pos - sible reasoning types ( Fig . 1 ) . The corresponding algorithms are shown in Section IV . The likelihood of selecting a cer - tain sequence Seq k or a reusable variety for other clusters is predicted by the typicality and versatility of BBs . This is similar to utilizing previous experiences in current decisions . Research shows that simple Bayesian inference models to a certain degree human decision making [ 44 ] . The architecture realizes model constraints ( 12 ) and ( 13 ) on incremental evolution as follows . As explained , the purpose is to minimize the distance between problem requirements and solution performance and maximize the variety of solution features at the expense of minimal evolutionary effort . These objectives are achieved through an architectural mechanism to : 1 ) bridge the gap between clusters ( niches ) ; 2 ) select the abstraction level at which features and BBs are combined with each other ; 3 ) produce alternatives for a concept ; and 4 ) ﬁxate new solutions as distinct clusters ( niches ) . The structure and parameters of the mechanism are discussed next . Incremental evolution selects solutions with short distance to problem requirements , high gradient toward problem goals , and higher dissimilarity with existing solutions as long as there are sufﬁcient resources for the cluster ( niche ) . Resources decrease as new solutions are created and increase depending on the produced feature variety and performance improvement . The parameter adjustment mechanism of the architecture is shown in Fig . 5 . Each BB j is characterized by a set of causal relations var ( k ) j , i → SPerf ( k ) j , i | context ( k ) j , i and their priorities in tackling a set of problems Problem k . 1 ) The inner - most loop identiﬁes the BB causing the bot - tleneck of the solutions of the current Pareto fragment of the cluster . It compares the solution under investigation with previous solutions to ﬁnd possible BB candidates for creating the bottleneck . As a byproduct , the step gen - erates information about features to be avoided in future solutions . 2 ) The second loop ﬁnds BBs that could address the bottle - neck . These BBs are generated either through variation of the candidate block , alternative blocks from the same cluster , or alternative blocks for different clusters . 3 ) The third loop decides the abstraction level at which alternative BBs are considered , hence the hierarchical level of divergence . Note that loop 2 ) implements a bottom - up creation of BB variety and loop 3 ) produces a top - down enforcement of con - straints . The equilibrium between the two loops is decided by the adjustment mechanism . The pressure to change a BB at a higher abstraction level ( hence , more important causal relations ) increases when the niche resources decrease [ e . g . , ∼ ( 1 / Resources ) ] and current level variations do not produce signiﬁcant performance improvements . For loop 2 ) , incremen - tal modiﬁcations correspond to variations of a current BB , a BB of a different solution of the same niche , and a BB from a different niche . For the last case , the causal sequence LI et al . : InnovA : COGNITIVE ARCHITECTURE FOR COMPUTATIONAL INNOVATION THROUGH ROBUST DIVERGENCE 1951 Algorithm 1 : Identifying Circuit BBs Input : analog circuit C , set of known building blocks (cid:3) Output : set of building blocks in C 1 set of building blocks (cid:4) = ∅ ; 2 ﬁnd the feedforward and feedback signal paths of C ; 3 identify main circuit C m of C by including transistors along feedforward paths and biasing transistors ; 4 feedback circuit C f = C − C m ; 5 (cid:4) = ﬁnd all building blocks in C m and C f separately by isomorphic matching with (cid:3) ; 6 exclude ambiguous building blocks in (cid:4) in case of false justiﬁcations ; 7 exclude building blocks in (cid:4) that are subsets of bigger building blocks while allowing overlapping of partially shared transistors ; 8 Identify generic templates in (cid:4) formed of building blocks that are repeatedly used and connected to form larger blocks ; 9 construct the hierarchical structure of C with (cid:4) ; 10 return (cid:4) is maintained if the beneﬁt of the solution exceeds the cost . Otherwise , a new causal sequence is produced depending on the bottlenecks to be addressed . The degree to which robust divergence is achieved depends on the availability of useful BBs , the efﬁciency ( e . g . , speed ) of evolving missing BBs , and the capability to connect them in a solution . Actually , incremental evolution must maximize the likelihood of creating feasible solution starting from partial knowledge . This information is stored in the episodic memory . Therefore , a higher priority is given in combination to BBs that have higher number of synonym , homonym , and antonym BBs as well as BBs with higher variability of their implementations . Note that preference is not necessarily given to the more fre - quent BBs but to those with a better characterized semantics . This strategy allows ﬁltering out causal features that cannot tackle the tradeoffs of the niche . The features of the concepts introduce a higher variety of causal relations to the causal sequence of the kernel , hence , the ones that do not improve performance will correspondingly prune the solution space . The evolution process decides the parameters of the cog - nitive architecture and implicitly of the constrained model in Section II . The next section presents the algorithms related to the modules shown with a thick line . For the modules shown in dashed line ( subjective memory and restructuring ) , the algorithms are still under development . IV . A LGORITHMS OF THE C OGNITIVE A RCHITECTURE This section discusses the algorithms of the cognitive architecture modules shown with continuous line in Fig . 5 . A . Identifying Building Blocks Algorithm 1 executes ﬁve steps to ﬁnd the BBs in circuit C . 1 ) First , it ﬁnds the signal paths of circuit C and iden - tiﬁes the main part and the feedback part . It ﬁnds all feedforward and feedback signal paths . Then , based on the signal paths , the main and feedback parts are sep - arated . BBs are searched in each subcircuit using an isomorphism matching with BB library (cid:3) . 2 ) It solves any ambiguities by excluding unjustiﬁed BBs . For example , if a BB requires the transistors to operate in saturation while the ones in the circuit are actually in Algorithm 2 : Classiﬁcation of Circuit Design Features Input : set of circuits C , problem speciﬁcation (cid:5) Output : classiﬁcation of features (cid:6) of circuits in set C 1 for all pairs of circuits C 1 , C 2 ∈ C do 2 ﬁnd common and distinct substructures of C 1 and C 2 ; 3 compute common and distinct electrical behaviors of C 1 and C 2 ; 4 characterize impact of common , distinct substructures on electrical behaviors with respect to (cid:5) ; 5 combine features of C 1 and C 2 for (cid:5) ; 6 add all found features to (cid:6) ; 7 for all matched nodes s with output arcs to unmatched nodes do 8 for all matched nodes t with input arcs from unmatched nodes do 9 if ∃ signal path passing s and t then 10 create abstraction for an arc from s to t , add to (cid:6) ; 11 create new features by exploring the instance space of the abstraction , add to (cid:6) ; 12 return classiﬁed features (cid:6) ; linear region , they are unjustiﬁed and excluded by the algorithm . 3 ) The step identiﬁes overlapping of BBs and removes BBs that are subsets of larger BBs . Partial sharing of tran - sistors by BBs is allowed , while full inclusion of a BB in larger BBs is not . Therefore , BBs that are subsets of other BBs are excluded . 4 ) The step ﬁnds templates that are formed by repeatedly connecting the same BBs . If there are structures formed by the same connections of the same kind of BBs , they are identiﬁed as templates . 5 ) It constructs the hierarchical structure of the circuit to represent the used combinations of BBs . The algorithms for supervised and unsupervised ﬁnding of the BBs in a circuit are discussed in [ 50 ] . Other BB identiﬁcation methods are discussed in [ 51 ] and [ 52 ] . B . Algorithm to Classify Design Features Classiﬁcation of the circuit design features uses four opera - tors : 1 ) circuit comparison ; 2 ) circuit instantiation - abstraction ; 3 ) concept combination ; and 4 ) design feature induction . Algorithm 2 shows the implementation of the four operators . Circuit comparison and concept combination are used to ﬁnd the existing features and to create new features for all pairs of circuits . Circuit comparison can use the symbolic technique in [ 30 ] or numeric simulation with each circuit being simulated once . For the identiﬁed signal ﬂow paths , the method creates abstractions between two matched nodes for distinct signal paths using the instantiation - abstraction operator . The design feature induction operator generates new features by exploring the abstraction’s instance space . The classiﬁcation techniques used in circuit design are detailed in [ 32 ] . The execution time is around 26 min for a ten circuit set . C . Mining Causal Design Sequences Mining causal design sequences for a certain circuit includes two parts . The ﬁrst part mines the design sequences of circuit features , such as circuit BBs . It gives the BB structure of the 1952 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 Algorithm 3 : Mining Causal Design Sequences Input : circuit C , set of all circuit features (cid:7) , problem requirements (cid:5) Output : causal design sequences seq that meets (cid:5) 1 set of initial features S = features in (cid:7) by the author of C or by the author’s group ; 2 add features in S to design sequence seq ; 3 (cid:7) = (cid:7) − S ; 4 for features x ∈ (cid:7) from more concrete to more abstract features do 5 if x is not justiﬁed by features in S if added to seq then 6 add x to design sequence seq ; 7 identify common features and new design insight by the authors in S ; 8 based on problem requirements (cid:5) , compute causal relations CR of transistors parameters ; 9 compute orderings of parameters depending on different criteria ; 10 add the computed orderings to seq ; 11 return seq ; circuit . The second part extracts of sequences of BB combina - tions for problem requirements (cid:5) . The causal information is found during the second part based on the device importance in achieving the problem requirements . A detailed discussion is offered in [ 33 ] . As shown in Algorithm 3 , the method ﬁnds the initial fea - tures in designing the circuit , deﬁned as starting ideas . Then for each remaining feature , if it is causally justiﬁed , it is added to the sequence . Otherwise , it is added to update the starting ideas . In the end , the sequence contains the design steps on how each feature is justiﬁed ( either improve performance or relax constraints ) to complete the design . The second part of the method ﬁnds the causal relations of the circuit based on problem requirements (cid:5) . The parameters are ordered based on different considerations , like the overall linearity of their control over performance , their correlations to other parame - ters , and similarity of their causal relations . These orderings are also added to the design sequence for sizing steps of the circuit . D . Reasoning Alternatives The ﬁve reasoning strategies ( Fig . 1 ) depend on the kinds of the starting features used in creating a solution . 1 ) Combining physical features . 2 ) Mixing physical features and abstract features . 3 ) Combining abstract features . 4 ) Excluding certain features . 5 ) Novel abstractions based on existing physical features . Algorithm 4 shows the reasoning procedure for the ﬁve types of starting features . The ﬁrst step excludes all unwanted features that may impose undesired effects on the performance of the ﬁnal cir - cuit . If there are such unwanted features [ e . g . , alternative 4 ) ] , they are excluded . Then , the initial circuit is selected from the associative circuit set . If there are unsatisﬁed tradeoffs , another circuit is selected to address them . Physical features and abstract features are all taken into account while making the selections , and tradeoffs are updated each time a new cir - cuit is generated . If no such circuit is found , it means a new abstraction from the existing physical features is needed as a starting feature [ i . e . , alternative 5 ) ] . A ﬁnal circuit is put out if Algorithm 4 : Reasoning Alternatives Input : problem requirements (cid:5) , associative circuit set C Output : ﬁnal circuit design cir 1 exclude all unwanted features from C ; 2 set of current trade - offs (cid:8) = (cid:5) ; 3 cir = selected circuit from C with features close to (cid:5) ; 4 update (cid:8) to exclude satisﬁed requirements ; 5 while (cid:8) (cid:6) = ∅ do 6 ﬁnd circuit C (cid:16) ⊂ C with features that could address (cid:8) ; 7 if such circuit C (cid:16) is not found then 8 ﬁnd a circuit C (cid:16) with physical or abstract features that could be justiﬁed for new abstractions that address (cid:8) ; 9 if C (cid:16) is not found then 10 return cir with unsatisﬁed trade - offs (cid:8) ; 11 cir = combine features in circuit C (cid:16) with cir ; 12 update (cid:8) for new trade - offs ; 13 return cir ; Fig . 6 . Schematics of discussed circuit . all requirements are satisﬁed . However , it is possible that the algorithm fails to locate features to address unsatisﬁed trade - offs , then the ﬁnal circuit is put out with unsatisﬁed tradeoffs . Details of the algorithms are offered in [ 34 ] . V . A PPLICATIONS This section discusses the main capabilities of the proposed cognitive architecture as compared to traditional CAD meth - ods for analog circuit design : using causal relations in circuit design optimization , ﬁnding new BBs , and circuit topology creation through feature combination and reusing . Circuit fea - tures are stored in knowledge representations organized using feature similarity at various levels of abstraction . A . Using Causal Relations in Circuit Design This case study shows how predictions about causality mod - ule in Fig . 5 is used by select alternatives and understand needs modules of the architecture . The discussion refers to the circuit in Fig . 6 ( left ) . 1 ) Causal Relations in Design Optimization : We used the causal sequences of a circuit design to guide parame - ter optimization during transistor sizing . Circuit sizing used Cadence Virtuoso 6 . 1 . 5 tool [ 53 ] . Calculating the causal sequences for a circuit is fast , less than 100 s . In addition , time is spent to ﬁnd the design points used in computing the causal sequences , e . g . , around 30 min per point , if Cadence tool is utilized . For a circuit with N device parameters , the total time for collecting the design points is about N × Nr samples × 30 min , where Nr samples is the number of samples for each parameter . The following method resulted for using causal relations in conjunction with Cadence tool : for a certain causal sequence LI et al . : InnovA : COGNITIVE ARCHITECTURE FOR COMPUTATIONAL INNOVATION THROUGH ROBUST DIVERGENCE 1953 TABLE I O PTIMIZATION R ESULTS FOR THE C IRCUIT IN F IG . 6 ( L EFT ) ( computed using Algorithm 3 in Section IV ) , the parameters of the ﬁrst transistor in the sequence are sampled more inten - sively than the rest . It is because these transistors parameters have a higher impact on the performance attributes of interest . The sampled value of the ﬁrst parameter is kept ﬁxed , while then the other parameters are found using the optimization pro - cess of Cadence tool . The process is repeated for each sampled value of the ﬁrst transistor . The parameter values for the best solution are saved . Then , the parameters of the second tran - sistor are swept while keeping the ﬁrst transistor unchanged . Then , the parameters of the second transistor are saved , and so on until the entire sequence was traversed . The transistors that are not in the sequence are swept less than the ones in the sequence . As a stopping criterion , optimization runs up to a certain time limit or until better solutions are not found for a ﬁxed number of exploration steps . The procedure gives a higher degree of ﬂexibility to exploring the more important parameters in the causal sequence ( i . e . , the parameters at the beginning of the sequence ) , while the latter parameters in the sequence are explored under the constraints set by keeping ﬁxed the values of the more important parameters . A tighter integration of a causal sequence and parameter exploration can be devised , if the code of the transistor sizing tool is available . Let us consider the following causal sequence of devices M 7 → M 10 → M 6 → M 3 . The time limits for exploration were set for the four transistors as follows : 4 h for M 7 , 2 h for M 10 , 1 h for M 6 , and 30 min for M 3 . Different time limits were used for sweeping the parameters of the four devices according to the strategy discussed in the previous paragraph . The results were compared with an optimization run ( using Cadence tool ) that sweeps all transistors simultaneously with a time limit of 8 h . The optimized performance set included gain , bandwidth , and linearity ( THD ) . The multiple performance requirements were simultaneously tackled using the method of the Cadence tool . The results are shown in Table I . The optimization process that ran for 8 h stopped after 3452 steps because it was not able to ﬁnd better solutions . For using the causal sequence , each column shows the results at the end of the correspond - ing sweeping , e . g . , the last column is for sweeping M 3 . There is signiﬁcant improvement in bandwidth performance with acceptable reduction in gain and THD performance . Conceptually , the optimization process using causal sequences can be interpreted as follows . The ﬁrst parameter of the sequence ( e . g . , M 7 ) is given the highest ﬂexibility , as it has most impact on performance . Hence , it is sampled most exhaustively by allocating it the highest chunk of time . Next , the sizes of device M 10 are sampled for a shorter amount of time , as it has less impact on performance than device M 7 . The size of M 7 is kept ﬁxed in the second step . The second step performs a post - optimization of M 10 after deciding the value of the causally more important device M 7 . The same reasoning applies for the remaining devices of the causal sequence too . TABLE II O PTIMIZATION R ESULTS FOR THE C IRCUIT IN F IG . 6 ( L EFT ) W ITH A DDITIONAL N OISE R EQUIREMENT Fig . 7 . Topology synthesis : feature combination and topology reﬁnement . 2 ) Causal Sequences in Incremental Optimization : Next , for the circuit in Fig . 6 ( left ) , we added noise as an additional performance requirement to the previous circuit optimization problem . Causal information was used in a similar way as in the previous case . The causal next sequence was utilized : M 10 → M 3 → M 7 → M 6 . Note that devices have a different importance ( priority ) in this case . The results are shown in Table II . As in the previous case , there are relevant increases in bandwidth at the expense of acceptable gain and THD reduction . There is signiﬁcant noise reduction too . The optimization processes without using causal information is likely to have reached a local optima into which it got trapped . Causal information allows a broader exploration of the parameter values , in which parameter consideration is adapted to their relevance to the problem . B . Building Block Identiﬁcation The circuit shown in Fig . 6 ( right ) is used as an example for identifying BBs . First , all signal paths were found . For instance , there are multiple signal paths from input V in p to output V out n including V in p → M 23 → M 7 → M 4 → V out n , V in p → M 23 → R 1 → R 0 → M 25 → M 6 → M 7 → M 4 → V out n . There are ambiguous BBs that need to be excluded , i . e . , cascode current sources ( CCSs ) M 12 + M 7 , M 11 + M 6 , and M 10 + M 5 . This is because M 5 , M 6 , and M 7 operate in linear region due to transconductance tuning ( TT ) . The requirement for operation in the linear region must be speciﬁed as an input . Therefore , the three CCSs are unjustiﬁed and should be excluded . Instead , M 10 , M 11 , and M 12 are individually iden - tiﬁed as basic current sources ( BCSs ) . Differential input ( DI ) M 23 + M 25 shares transistor M 23 with source degeneration ( SD ) M 23 + R 1 and M 25 with SD M 25 + R 0 . Because BB overlapping is supported , both BBs are identiﬁed . BCSs M 10 , M 11 , M 12 , and M 13 are connected to form a series of topological struc - ture that provides same functionality . Thus , the four BCSs are identiﬁed as a template called BCS + that consists of all four transistors . The circuit is composed of all BBs . Its hierarchi - cal structure was built by connecting BBs from top to bottom : BCS + TT + DI + SD + CCS . The identiﬁed BBs are manu - ally reviewed as the tool is still being validated . The execution time was around 32 s . It increases with the number of signal paths in the circuit . 1954 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 Fig . 8 . Combining topological features . C . Creating New Topologies ( Structures ) Topology synthesis creates new circuit topologies for a set of performance requirements and constraints . Topology syn - thesis includes two situations shown in Fig . 7 : 1 ) new topology devising through existing feature combination and 2 ) topol - ogy reﬁnement . With respect to the cognitive architecture in Fig . 5 , the case study utilized the following modules : memory system including associative structure used to store the design knowledge used by the cognitive architecture , connections to goals and causal sequences , produce alternatives using incre - mental operations , select alternatives , understanding needs , prediction about causalities , and predictions about causalities . 1 ) Structural Synthesis Through Feature Combination : In topological features combination , features are ﬁrst selected from knowledge based by their justiﬁcation . Topological features are treated equally important and combined on a reasoning - based ﬂow . Topological features in existing design can be physical structure , e . g . , cross - coupled input stage in Fig . 8 , or abstractions that correspond to alternative physical structures , i . e . , three stage can be implemented in multiple ways . For example , the synthesis of a new high performance OpAmp / OTA utilizes starting features to identify design sequence that is likely to create a performance - satisfying solu - tion . Each step of the sequence corresponds to combining topological features from different circuits or reﬁning topolog - ical feature of one existing circuit . Each step is justiﬁed that it either improves performance or relaxes the design constraints . Every step is added to the sequence based on its design improvement until the design solution meets speciﬁcation . The example on combining topological features refers to the design of a new low voltage , low power op - amp ( Fig . 8 ) . The starting features of the solution were identiﬁed as follows . Two topological features , adaptive biasing class AB input with local common - mode feedback and three stage with frequency compensation , were selected from two different circuits , as they improve slew rate and achieve near - optimal current efﬁ - ciency . The input stage is general and can be extended to virtually any class AB input stage . Regarding adaptive bias - ing for decreasing current during sampling phase , this scheme is only suitable for switched capacitor circuit . Stability issues of the gain - boosted cascode structures also needed to be care - fully addressed . Thus , the starting ideas selected the abstract feature of a three stage ampliﬁer . Active feedback frequency compensation technique was identiﬁed to solve stability issues as it is easier to design and does not consume additional power . As shown in [ 35 ] , compared to the circuit in [ 54 ] , the new circuit in Fig . 8 has the following performance for 0 . 2 - μ m CMOS technology and 5 - pF capacitive load ( ﬁrst values are for the new circuit ) : superior gain of 58 . 2 versus 30 . 6 dB , Fig . 9 . Design reﬁnement ( case 1 ) . Fig . 10 . Design reﬁnement ( case 2 ) . higher gain - bandwidth product ( 24 versus 16 . 4 MHz ) , phase margin of 84 . 8 ◦ versus 88 . 3 ◦ , and better slew rate , 5 . 1 versus 4 . 9 V / μ s . The static power consumption is 68 μ W @ 1 V versus 73 μ W @ 2 V . Note that the comparison’s purpose is to show the architecture’s capability to design a new low - power , low - supply circuit operating at 1 V starting from an existing circuit working at 2 V . 2 ) Circuit Topology Reﬁnement : Reﬁnement selects from the memory system of the cognitive architecture an existing circuit , which offers close speciﬁcation but does not satisfy the problem yet . Then , topological feature are identiﬁed in the long - term memory of the cognitive architecture to be com - bined with the circuit , so that tradeoffs are modiﬁed to satisfy the missing problem requirements . Let us take the problem of designing a low - power ampli - ﬁer that optimizes the gain - bandwidth product . The existing design in Fig . 9 ( left ) is selected . It is a high gain , high frequency circuit . Feed - forward compensation path is a fea - ture to compensate frequency without using Miller capacitor . The reﬁnement of the circuit is to realize the three gain stages by cascode , current mirror , and common source stages . The circuit is kept single - input , single - ended output . The revision is causally justiﬁed by multistage boosted gain and higher power efﬁciency . The resulting circuit is shown in Fig . 9 ( right ) . As discussed in [ 34 ] , compared to the original circuit in Fig . 9 ( left ) , the new circuit in Fig . 9 ( right ) has for 0 . 6 - μ m CMOS process and ± 1 . 25 - V supply voltage ( ﬁrst values are for the new circuit ) , 13 % higher gain - bandwidth product ( 620 versus 539 MHz ) , gain of 73 versus 71 dB , the same band - width of 0 . 15 MHz for both circuits , power consumption of 0 . 65 versus 0 . 63 mW , and noise of 2 . 3e − 12 V 2 / Hz @ 20 MHz versus 1 . 8e − 12 V 2 / Hz @ 20 MHz . The new circuit has faster settling time in response to a step input , 27 . 24 ns @ 20 MHz versus 33 . 16 ns @ 20 MHz , and superior slew rate @ 20 MHz , 7 . 02e 9 versus 44 . 56e 6 V / s . THD @ 20 MHz of the new circuit was also superior , 13 . 96 % versus 28 . 29 % . LI et al . : InnovA : COGNITIVE ARCHITECTURE FOR COMPUTATIONAL INNOVATION THROUGH ROBUST DIVERGENCE 1955 Another example requires to create a low power , high gain OpAmp with low supply voltage . The existing design in Fig . 10 ( left ) is selected for reﬁnement . It is class AB ampliﬁer with class AB input stage and local common - mode feedback . The causal justiﬁcation to select the circuit is as follows : class AB input stage and local common - mode feedback are mainly for achieving near optimal current efﬁciency . A reﬁne - ment of the circuit adds a simple gain - boosting stage causally justiﬁed by improving the gain for low supply voltage . Also , a low voltage current mirror updates the original current mirror , causally justiﬁed by increased output resistance . The resulting circuit topology is presented in Fig . 10 ( right ) . As shown in [ 34 ] , compared to the original circuit in Fig . 10 ( left ) , the new circuit in Fig . 10 ( right ) has for 0 . 6 μ m CMOS process and ± 1 - V supply voltage , a 27 % higher gain ( 62 versus 45 dB ) while power consumption is only 3 % larger ( 0 . 1 versus 0 . 097 mW ) . The other performance values are as follows : bandwidth , 0 . 02 versus 0 . 18 MHz ; gain - bandwidth product , 25 . 2 versus 32 MHz ; phase margin , 54 ◦ versus 61 ◦ , and noise , 1 . 2e − 14 V 2 / Hz @ 20 MHz versus 5 . 3e − 16 V 2 / Hz @ 20 MHz . VI . C ONCLUSION This paper presents a cognitive architecture for creative problem solving in analog circuit design , including activities like circuit topology creation ( synthesis ) , incremental topol - ogy modiﬁcation , and design knowledge reuse . These activities refer to open - ended and ill - deﬁned problems , and require dis - covering new knowledge besides producing a solution . They are difﬁcult to tackle with existing algorithmic methods . The proposed cognitive architecture is based on a new theoretical model having the goal of more robust divergence , like creat - ing new BBs and circuit structures ( i . e . , connections of BBs ) . The learned knowledge is reusable for solving new problems and includes new BBs , causal relations between BB parame - ters and outcomes ( circuit performance ) , reasoning strategies , beliefs , priorities , and architectural parameters . The cognitive architecture is modeled after the main cogni - tive activities used in creative problem solving , like concept comparison ( matching ) , concept formation , and concept com - bination . The memory system organizes the domain knowledge into three parts : 1 ) associative structure ; 2 ) connections to goals ; and 3 ) causal sequences to reﬂect concept similari - ties and differences with respect to structure and purpose in solving a problem ( justiﬁcation ) . In addition , the archi - tecture incorporates modules producing new solutions using incremental operations following ﬁve reasoning strategies , predictions about outcomes and causality , understanding needs ( i . e . , performance bottlenecks ) , recognizing new BBs , and selection of new solutions from alternatives . The algorithms for these modules are discussed . The cognitive architecture also includes modules modeling the effect of emotions on memory formation and decision making . The latter modules are currently under development . Future work will focus on three possible problems : ﬁrst , studying how the parameters of the three feedback loops in Fig . 5 adjust for different kinds of open - ended and ill - deﬁned circuit design problems , like problem framing and problem solving ( ideation ) . This is important in real - life as often problems refer to a mixture of problem framing and ideation requirements . Second , future work will address the part for subjective learning and reasoning . The component requires studying algorithms for modeling beliefs and pref - erences of individuals , including expert designers . This is relevant not only for replicating a certain design style , but also for devising more effective training guidelines . Finally , work will address using the cognitive architecture for problem solving beyond analog circuit design . We think that the main aspects refer to ﬁnding equivalent concept representations , like circuit schematics , and similar embodiments as circuit simulators . A CKNOWLEDGMENT Any opinions , ﬁndings , and conclusions or recommenda - tions expressed in this paper are those of the author ( s ) and do not necessarily reﬂect the views of the National Science Foundation . R EFERENCES [ 1 ] A . Doboli and A . Umbarkar , “The role of precedents in increasing cre - ativity during iterative design of electronic embedded systems , ” Design Sci . , vol . 35 , no . 3 , pp . 298 – 326 , 2014 . [ 2 ] G . Goldschmidt , “Capturing indeterminism : Representation in the design problem space , ” Design Stud . , vol . 18 , no . 4 , pp . 441 – 455 , 1997 . [ 3 ] D . Schon , The Reﬂective Practitioner . New York , NY , USA : BasicBooks , 1983 . [ 4 ] A . Newell , J . Shaw , and H . Simon , “Report on a general problem - solving program , ” in Proc . Int . Conf . Inf . Process . , 1959 , pp . 256 – 264 . [ 5 ] J . R . Anderson , “Acquisition of cognitive skill , ” Psychol . Rev . , vol . 89 , no . 4 , pp . 369 – 406 , 1982 . [ 6 ] A . Bandura , “Self - efﬁcacy mechanisms in human agency , ” Amer . Psychol . , vol . 37 , no . 2 , pp . 122 – 147 , 1982 . [ 7 ] L . R . Carley and R . A . Rutenbar , “How to automate analog IC designs , ” IEEE Spectr . Mag . , vol . 25 , no . 8 , pp . 26 – 30 , Aug . 1988 . [ 8 ] R . Harjani , R . A . Rutenbar , and L . R . Carley , “OASYS : A framework for analog circuit synthesis , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 8 , no . 12 , pp . 1247 – 1266 , Dec . 1989 . [ 9 ] F . El - Turky and E . E . Perry , “BLADES : An artiﬁcial intelligence approach to analog circuit design , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 8 , no . 6 , pp . 680 – 692 , Jun . 1989 . [ 10 ] M . Barros , J . Guilherme , and N . Horta , Analog Circuits and Systems Optimization Based on Evolutionary Computation Techniques . Berlin , Germany : Springer , 2010 . [ 11 ] W . Kruiskamp and D . Leenaerts , “DARWIN : CMOS opamp synthesis by means of a genetic algorithm , ” in Proc . Design Autom . Conf . , 1995 , pp . 433 – 438 . [ 12 ] T . McConaghy , P . Palmers , G . Peng , M . Steyaert , and G . Gielen , Variation - Aware Analog Structural Synthesis . Dordrecht , The Netherlands : Springer , 2009 . [ 13 ] C . Ferent and A . Doboli , “Measuring the uniqueness and variety of analog circuit design features , ” Integr . VLSI J . , vol . 44 , no . 1 , pp . 39 – 50 , 2011 . [ 14 ] J . Anderson , The Architecture of Cognition . Cambridge , MA , USA : Harvard Univ . Press , 1983 . [ 15 ] J . Anderson , “ACT : A simple theory of complex cognition , ” Amer . Psychol . , vol . 51 , no . 4 , pp . 355 – 365 , 1996 . [ 16 ] J . Anderson , Learning and Memory . An Integrated Approach . New York , NY , USA : Wiley , 2000 . [ 17 ] J . Laird , The SOAR Cognitive Architecture . Cambridge , MA , USA : MIT Press , 2012 . [ 18 ] D . Vernon , Artiﬁcial Cognitive Systems . A Primer . Cambridge , MA , USA : MIT Press , 2014 . [ 19 ] D . E . Kieras and D . E . Meyer , “An overview of the EPIC architec - ture for cognition and performance with application to human - computer interaction , ” J . Human Comput . Interact . , vol . 12 , no . 4 , pp . 391 – 438 , 1997 . [ 20 ] P . S . Rosenbloom , A . Demski , and V . Ustun , “The sigma cognitive architecture and system : Towards functionally elegant grand uniﬁcation , ” J . Artif . Gen . Intell . , vol . 7 , no . 1 , pp . 1 – 103 , 2016 . [ 21 ] R . Sun , “A tutorial on CLARION , ” Cogn . Sci . Dept . , Rensselaer Polytechnic Inst . , Troy , NY , USA , Rep . , 2003 . [ Online ] . Available : http : / / www . cogsci . rpi . edu / ∼ rsun / tutorial . pdf [ 22 ] D . Friedlander and S . Franklin , “LIDA and a theory of mind , ” in Proc . Conf . Adv . Artif . Gen . Intell . , 2008 , pp . 137 – 148 . 1956 IEEE TRANSACTIONS ON COMPUTER - AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , VOL . 37 , NO . 10 , OCTOBER 2018 [ 23 ] N . Hawes and J . Wyatt , “Developing intelligent robots with cast , ” in Proc . IROS Workshop Current Softw . Frameworks Cogn . Robot . Integr . Different Comput . Paradigms , 2008 , pp . 14 – 18 . [ 24 ] P . Langley , “Cognitive architectures and general intelligent systems , ” AI Mag . , vol . 27 , no . 2 , pp . 33 – 44 , 2006 . [ 25 ] G . Metta et al . , “The iCub humanoid robot : An open - systems platform for research in cognitive development , ” Neural Netw . , vol . 23 , nos . 8 – 9 , pp . 1125 – 1134 , 2010 . [ 26 ] J . Hampton , “Emergent attributes in combined concepts , ” in Conceptual Structures and Processes : Emergence Discovery and Change , T . Ward , S . Smith , and J . Viad , Eds . Washington , DC , USA : Amer . Psychol . Assoc . , 1996 . [ 27 ] E . J . Wisniewski , “When concepts combine , ” Psychonomic Bull . Rev . , vol . 4 , no . 2 , pp . 167 – 183 , 1997 . [ 28 ] X . Liu and A . Doboli , “Moving beyond traditional electronic design automation : Data - driven design of analog circuits , ” in Proc . Int . Conf . Synth . Model . Anal . Simulat . Methods Appl . Circuit Design , 2016 , pp . 1 – 4 . [ 29 ] C . Ferent , A . Doboli , and S . Doboli , “An axiomatic model for concept structure description and its application to circuit design , ” Knowl . Based Syst . , vol . 45 , pp . 114 – 133 , Jun . 2013 . [ 30 ] C . Ferent and A . Doboli , “Symbolic matching and constraint gen - eration for systematic comparison of analog circuits , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 32 , no . 4 , pp . 616 – 629 , Apr . 2013 . [ 31 ] C . Ferent and A . Doboli , “Formal representation of the design feature variety in analog circuits , ” in Proc . FDL Conf . , 2013 , pp . 1 – 7 . [ 32 ] C . Ferent and A . Doboli , “Analog circuit design space description based on ordered clustering of feature uniqueness and similarity , ” Integr . VLSI J . , vol . 47 , no . 2 , pp . 213 – 231 , 2014 . [ 33 ] F . Jiao , S . Montano , C . Ferent , A . Doboli , and S . Doboli , “Analog cir - cuit design knowledge mining : Discovering topological similarities and uncovering design reasoning strategies , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 34 , no . 7 , pp . 1045 – 1059 , Jul . 2015 . [ 34 ] F . Jiao , S . Montano , and A . Doboli , “Knowledge - intensive , causal reasoning for analog circuit topology synthesis in emergent and innova - tive applications , ” in Proc . Design Autom . Test Europe Conf . ( DATE ) , 2015 , pp . 1144 – 1149 . [ 35 ] F . Jiao and A . Doboli , “A low - voltage , low - power ampliﬁer created by reasoning - based , systematic topology synthesis , ” in Proc . Int . Symp . Circuits Syst . ( ISCAS ) , 2015 , pp . 2648 – 2651 . [ 36 ] B . M . Lake , R . Salakhutdinov , and J . B . Tenenbaum , “Human - level concept learning through probabilistic program induction , ” Science , vol . 350 , no . 6266 , pp . 1333 – 1338 , 2015 . [ 37 ] D . Kahneman and A . Tversky , Eds . , Choices , Values , and Frames . Cambridge , U . K . : Cambridge Univ . Press , 2000 . [ 38 ] J . A . Hampton , “Similarity - based categorization and fuzziness of natural categories , ” Cognition , vol . 65 , nos . 2 – 3 , pp . 137 – 165 , 1998 . [ 39 ] A . B . Markman and B . H . Ross , “Category use and category learning , ” Psychol . Bull . , vol . 129 , no . 4 , pp . 592 – 613 , 2003 . [ 40 ] A . Doboli , A . Umbarkar , S . Doboli , and J . Betz , “Modeling semantic knowledge structures for creative problem solving : Studies on express - ing concepts , categories , associations , goals and context , ” Knowl . Based Syst . , vol . 78 , pp . 34 – 50 , Apr . 2015 . [ 41 ] M . A . Schilling , “A ‘small - world’ network model of cognitive insight , ” Creativity Res . J . , vol . 17 , nos . 2 – 3 , pp . 131 – 154 , 2005 . [ 42 ] M . Steyvers and J . Tenenbaum , “The large - scale structure of semantic networks : Statistical analyses and a model of semantic growth , ” Cogn . Sci . , vol . 29 , no . 1 , pp . 41 – 78 , 2005 . [ 43 ] A . Wagner , The Origins of Evolutionary Innovations . Oxford , U . K . : Oxford Univ . Press , 2011 . [ 44 ] K . Doya , S . Ishii , A . Pouget , and R . Rao , Bayesian Brain . Cambridge , MA , USA : MIT Press , 2007 . [ 45 ] K . Stenning and M . V . Lambalgen , Human Reasoning and Cognitive Science . Cambridge , MA , USA : MIT Press , 2008 . [ 46 ] R . Adolphs and A . Damasio , “The human amygdala in social judge - ment , ” Nature , vol . 393 , no . 6684 , pp . 470 – 474 , 1998 . [ 47 ] J . Tao and T . Tan , “Affective computing : A review , ” in Affective Computing and Intelligent Interaction ( LNCS 3784 ) . Berlin , Germany : Springer , 2005 , pp . 981 – 995 . [ 48 ] H . Tang , H . Zhang , and A . Doboli , “Reﬁnement - based synthesis of continuous - time analog ﬁlters through successive domain pruning , plateau search , and adaptive sampling , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 25 , no . 8 , pp . 1421 – 1440 , Aug . 2006 . [ 49 ] L . W . Barsalou , “Grounded cognition , ” Annu . Rev . Psychol . , vol . 59 , pp . 617 – 645 , Jan . 2008 . [ 50 ] H . Li , F . Jiao , and A . Doboli , “Analog circuit topological feature extrac - tion with unsupervised learning of new sub - structures , ” in Proc . Design Autom . Test Europe Conf . , 2016 , pp . 1509 – 1512 . [ 51 ] T . Massier , H . Graeb , and U . Schlichtmann , “The sizing rules method for CMOS and bipolar analog integrated circuit synthesis , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 27 , no . 12 , pp . 2209 – 2222 , Dec . 2008 . [ 52 ] N . Rubanov , “SubIslands : The probabilistic match assignment algorithm for subcircuit recognition , ” IEEE Trans . Comput . - Aided Design Integr . Circuits Syst . , vol . 22 , no . 1 , pp . 26 – 38 , Jan . 2003 . [ 53 ] Virtuoso Analog Design Environment XL User Guide Product Version 6 . 1 . 5 , Cadence Advanced Analysis Tools User Guide , Cadence Design Syst . , San Jose , CA , USA , 2011 . [ 54 ] A . J . Lopez - Martin , S . Baswa , J . Ramirez - Angulo , and R . G . Carvajal , “Low - voltage super class AB CMOS OTA cells with very high slew rate and power efﬁciency , ” IEEE J . Solid - State Circuits , vol . 40 , no . 5 , pp . 1068 – 1077 , May 2005 . Hao Li ( S’15 ) received the B . S . degree from the Beijing University of Posts and Telecommunications , Beijing , China , in 2012 . He is currently pursuing the Ph . D . degree in computer engineering with Stony Brook University , Stony Brook , NY , USA . His current research interests include design automation in analog circuits , mainly in design knowledge mining and categorization and cognitive architecture design . Xiaowei Liu ( S’15 ) received the bachelor’s degree in communication engineering from the Beijing University of Posts and Telecommunications , Beijing , China , in 2012 . She is currently pursuing the Ph . D . degree in electrical and computer engineering with Stony Brook University , Stony Brook , NY , USA . Her current research interests include knowledge discovery in communities and cyber - physical systems design for social applications . Fanshu Jiao ( S’14 – M’17 ) received the B . S . degree from the University of Science and Technology of China , Hefei , China , in 2011 , and the Ph . D . degree from the State University of New York at Stony Brook , Stony Brook , NY , USA , in 2016 . Her current research interests include analog cir - cuit design automation , particularly methods for design knowledge mining and development of knowledge mining tools . Alex Doboli ( S’99 – M’01 – SM’07 ) received the M . S . and Ph . D . degrees in computer science from “Politehnica” University , Timisoara , Romania , in 1990 and 1997 , respectively , and the Ph . D . degree in computer engineering from the University of Cincinnati , Cincinnati , OH , USA , in 2000 . He is a Professor with the Department of Electrical and Computer Engineering , Stony Brook University , Stony Brook , NY , USA . His current research interest includes mixed - signal computer - aided design . Simona Doboli , photograph and biography not available at the time of publication .