T OPOLOGY COMPARISON OF T WITTER DIFFUSION NETWORKS RELIABLY REVEALS DISINFORMATION NEWS A P REPRINT Francesco Pierri , Carlo Piccardi , Stefano Ceri Politecnico di Milano , Department of Electronics , Information and Bioengineering , 20133 Milano , Italy E - mail : { francesco . pierri , carlo . piccardi , stefano . ceri } @ polimi . it June 17 , 2019 A BSTRACT In recent years , malicious information had an explosive growth in social media , with serious social and political backlashes . Recent important studies , featuring large - scale analyses , have produced deeper knowledge about this phenomenon , showing that disinformation spreads faster , deeper and more broadly than the truth on social media , where bots and echo chambers play an important role in diffusion networks . Following these directions , we explore the possibility of classifying news articles circulating on social media based exclusively on a topological analysis of their diffusion networks . To this aim we collected a large dataset of networks on Twitter pertaining to news articles published on two distinct classes of sources , namely outlets that convey mainstream , reliable and ob - jective information and those that fabricate and disseminate various kinds of disinformation stories . We carried out an extensive comparison of these networks using several alignment - free approaches including basic network properties , centrality measures distributions , and network distances . We accordingly evaluated to what extent these features allow to discriminate between the networks as - sociated to the aforementioned news domains . Our results highlight that the communities of users spreading mainstream rather than disinformation news tend to shape diffusion networks with subtle yet systematic differences . This opens the way to promptly and correctly identifying disinformation on social media by solely inspecting the resulting diffusion networks . K eywords computational social science | disinformation | complex networks | Twitter Introduction In recent years social media have witnessed an explosive growth of malicious and deceptive information . The research community usually refers to it with a variety of terms , such as disinformation , misinformation and most often false ( or ”fake” ) news , hardly reaching agreement on a single deﬁnition [ 12 , 26 , 9 , 5 , 22 ] . Several reasons explain the rise of such malicious phenomenon . First , barriers to enter the online media industry have dropped considerably and ( dis ) information websites are nowadays created faster than ever , generating revenues through advertisement without the need to adhere to traditional journalistic standards ( as there is no third - party veriﬁcation or editorial judgment for online news ) [ 2 ] . Second , human factors such as conﬁrmation biases [ 15 ] , algorithmic biases [ 7 , 12 ] and naive realism [ 19 ] have exacerbated the so - called echo chamber effect , i . e . the formation of homogeneous communities where people share and discuss about their opinions in a strongly polarized way , insulated from different and contrary perspectives [ 2 , 6 , 25 , 24 , 16 ] . Third , direct intervention that could be put in place by platform government bodies for banning deceptive information is not encouraged , as it may raise ethical concerns about censorship [ 12 , 22 ] . The combat against online disinformation is challenged by : the massive rates at which malicious items are produced , and the impossibility to verify them all [ 22 ] ; the adversarial setting in which they are created , as disinformation sources usually attempt to mimic traditional news outlets [ 12 ] ; the lack of gold - standard datasets and the limitations imposed by social media platforms on the collection of relevant data [ 17 ] . a r X i v : 1905 . 03043v2 [ c s . S I ] 14 J un 2019 A PREPRINT - J UNE 17 , 2019 Most methods for ”fake news” detection are carried out by using features extracted from the news articles and their social context ( notably textual features , users’ proﬁle , etc ) ; existing techniques are built on this content - based evidence , using traditional machine learning or more elaborate deep neural networks [ 17 ] , but they are often applied to small , ad - hoc datasets which do not generalize to the real world [ 17 ] . Recent important studies , featuring large - scale analyses , have produced deeper knowledge about the phenomenon , showing that : false news spread faster and more broadly than the truth on social media [ 26 , 23 ] ; social bots play an important role as ”super - spreaders” in the core of diffusion networks [ 22 ] ; echo chambers are primary drivers for the diffusion of true and false content [ 6 ] . In this work , we focus on analyzing the diffusion of disinformation items along the direction pointed by these studies . Leveraging the sole diffusion network allows to by - pass the intricate information related to individual news articles – such as content , style , editorship , audience , etc – and to capture the overall diffusion properties for two distinct news domains : reputable outlets that produce mainstream , reliable and objective information , opposed to sources which notably fabricate and spread different kinds of disinformation stories . We consider any article published on the former domain as a proxy for credible and factual information ( although it might not be true in all cases ) and all news published on the latter domain as proxies for false news . Our approach is robust , as no adversarial interventions may realistically take place to manipulate information diffusion topologies , due to the inherent complexity of social media networks . The contribution of this work is manifold . We collected thousands of re - tweeting diffusion networks pertaining to the aforementioned news domains and we carried out an extensive network comparison using several alignment - free approaches . These include global network properties , centrality measures distributions and network distances . Based on the results of the analysis , we show that it is possible to classify networks pertaining to the two different news domains with high levels of accuracy , using simple off - the - shelf machine learning classiﬁers . We provide an interpretation of classiﬁcation results in terms of topological network properties , discussing why different features are the footprint of how the communities of users spread news from these two different news domains . Methodology Mainstream versus Disinformation As highlighted by recent research on the subject [ 12 , 5 , 9 , 22 , 26 ] , it is hard to reach consensus on a deﬁnition for malicious and deceptive information ; consequently , to assess whether a news outlet is spreading unreliable or objective information is a controversial matter , subject to imprecision and individual judgment . The consolidated strategy in the literature – which we follow in this work – consists of building a classiﬁcation of websites , based on multiple sources ( e . g . reputable third - party news and fact - checking organizations ) . Along this approach , we characterize a list of websites that notably produce disinformation , i . e . low - credibility content , false , misleading and / or hyper - partisan news reports as well as hoaxes , conspiracy theories and satire . We oppose to these malicious sources a set of traditional news outlets ( deﬁned as in [ 5 ] ) which deliver mainstream reliable news , i . e . factual , objective and credible information ; we are aware that this might not be always true as reported cases of misinformation on mainstream outlets are not rare [ 12 ] , yet we adopt this approach as it is currently the best available proxy for a correct classiﬁcation . Data collection We collected all tweets containing a Uniform Resource Locator ( URL ) pointing to websites which belong either to a disinformation or mainstream domain ( see below ) . Following the approach described in [ 9 , 12 ] we assume that article labels are associated with the label of their source , i . e . all items published on a disinformation ( mainstream ) website are disinformation ( mainstream ) articles . We took into account censoring effects described in [ 8 ] , by retaining only diffusion cascades relative to articles that were published after the beginning of the collection process ( left censoring ) , and observing each of them for at least one week ( right censoring ) . For what concerns disinformation sources we referred to the curated list of 100 + news outlets provided by [ 21 , 23 ] . Leveraging Hoaxy API 1 , we obtained tweets pertaining to news items published in the period from Jan , 1st 2019 to March , 15th 2019 , ﬁltering articles with less than 50 associated tweets . The ﬁnal collection comprises 5775 diffusion networks . We replicated the collection procedure described in [ 21 , 23 ] in order to gather mainstream articles by using the Twit - ter Streaming API . We referred to U . S . most trusted news sources described in [ 14 ] ( list available in Supplementary Material ) . We associated tweets to a given article after canonicalization of the attached URL ( s ) , using tracking param - 1 https : / / rapidapi . com / truthy / api / hoaxy 2 A PREPRINT - J UNE 17 , 2019 eters as in [ 21 , 23 ] , to handle duplicated hyperlinks . We collected the tweets during a window of three weeks , from February 25th 2019 to March 18th 2019 ; ; we restricted the period w . r . t the disinformation collection in order to obtain a balanced dataset of the two news domains 2 . At the end of the collection , we excluded articles for which the number of associated tweets was less than 50 , obtaining 6978 diffusion networks . Eventually , mainstream news generated ∼ 1 . 7 million tweets , corresponding to ∼ 400k independent cascades , ∼ 680k unique users and ∼ 1 . 2 million edges ; disinformation news generated ∼ 1 . 6 million tweets , ∼ 210k independent cas - cades , ∼ 420k unique users and ∼ 1 . 4 million edges . Twitter diffusion networks We represent re - tweeting diffusion networks as directed , unweighted graphs : for each unique URL we build a graph where each node represents a unique user who has shared at least one tweet containing a URL of the article , and a directed edge is built between two nodes whenever a user re - tweets / quotes , mentions or replies to another user . Edges between nodes are built only once and they all have weight equal to 1 . Isolated nodes correspond to users who authored tweets which were not re - tweeted nor replied / quoted / mentioned . As pointed out in [ 26 , 23 , 8 ] it is impossible on Twitter to retrieve true diffusion cascades because the re - tweeting functionality makes any re - tweet pointing to the original content , losing intermediate re - tweeting users . As such , the majority of cascades often end up in star topologies . In contrast to [ 26 ] , we consider as a single diffusion network the union of several cascades generated from different users which shared the same news article on the social network ; thus such network is not necessarily a single connected component . Global Network Properties We computed the following set of global network properties , allowing us to encode each network by a tuple of features : ( a ) the number of strongly connected components , ( b ) the size of the largest strongly connected component , ( c ) the number of weakly connected components , ( d ) the size and ( e ) the diameter of the largest weakly connected component , ( f ) the average clustering coefﬁcient and ( g ) the main K - core number . More details on these features are available in Supplementary Material . We observed what follows : ( a ) is highly correlated with the size of the network ( see Supplementary Material ) , as the diffusion ﬂow of news mostly occurs in a broadcast manner , i . e . edges almost consist of re - tweets , and ( b ) allows to capture cases where the mono - directionality of the information diffusion is broken ; ( c ) indicates approximately the number of distinct cascades , with exceptions corresponding to cases where two or more cascades are merged together via mentions / quotes / replies on Twitter ; ( d ) and ( e ) represent respectively the size and the depth of the largest cascade of a given news article ; ( f ) indicates the degree to which users in diffusion networks tend to form local cliques whereas ( g ) is commonly employed in social networks to identify inﬂuential users and to describe the efﬁciency of information spreading [ 23 ] . We stress that considering an exhaustive search on additional network global indicators is out of the goal of our analysis , which is to show that a set of simple network features , manually selected , can be effectively used in the task of classifying diffusion networks . Network Distances In addition , we considered two alignment - free network distances that are commonly used in the literature to assess the topological similarity of networks , namely the Directed Graphlet Correlation Distance ( DGCD ) and the Portrait Divergence ( PD ) . The ﬁrst distance [ 20 ] is based on directed graphlets [ 10 ] . These are used to catch speciﬁc topological information and to build graph similarity measures ; depending on the graphlets ( and the orbits ) considered , different DGCD can be obtained , e . g . DGCD - 13 is the one that we employed in this work . Among all graphlet - based distances , which often yield a prohibitive computational cost to compute graphlets , DGCD has been demonstrated as the most effective at classifying networks from different domains . The second distance [ 3 ] , which was recently deﬁned , is based on the network portrait [ 4 ] , a graph invariant measure which yields the same value for all graph isomorphisms . This distance is purely topological , as it involves comparing , 2 A different classiﬁcation approach using several data sampling strategies on networks in the same 3 - week period is avail - able in Supplementary Material . The number of disinformation networks is only ∼ 1200 , resulting in an imbalanced dataset with disinformation / mainstream proportion 1 to 5 . Results are nonetheless in accordance with those provided in the main paper . 3 A PREPRINT - J UNE 17 , 2019 via Jensen - Shannon divergence , the distribution of all shortest path lengths of two graphs ; moreover , it can handle disconnected networks and it is computationally efﬁcient . We also conducted experiments on several centrality measures distributions – such as total degree and betweenness centrality – and results are available in the Supplementary Material . They overall perform worse than the above meth - ods , in accordance with current literature on network comparison techniques [ 27 ] . Dataset Splitting As we expect networks to exhibit different topological properties within different ranges of node sizes ( see also Sup - plementary Material ) , prior to our analyses , we partitioned the original collection of networks into subsets of similar sizes . This simple heuristic criterion produced a splitting of the dataset into three subsets according to speciﬁc ranges of cardinalities ( see Table 1 ) ; we also considered the entire original dataset for comparison . Splitting proved effective for improving the classiﬁcation and also for highlighting interesting properties of diffusion networks . Results Before evaluating global network properties in a classiﬁcation task , we employed a non - parametric statistical test , Kolmogorov - Smirnov ( KS ) test , to verify the null hypothesis ( each individual feature has the same distribution in the two classes ) . Hypothesis is rejected ( α = 0 . 05 ) for all indicators in all data subsets , with a few exceptions on networks of larger size . More details are available in Supplementary Material . We then employed these features to train two traditional classiﬁers , namely Logistic Regression ( LR ) and K - Nearest Neighbors ( K - NN ) ( with different choices of the number k of neighbors ) . Experiments on other state - of - the - art clas - siﬁers , which exhibit comparable results , are described in Supplementary Material . Before training each model , we applied feature standardization , as commonly required in traditional machine learning frameworks [ 1 ] . Finally we evaluated performances of both classiﬁers using a 10 - fold stratiﬁed - shufﬂe - split cross validation approach , with 90 % of the samples as training set and 10 % as test set in each fold . In Figure 1 we show the resulting Receiver Operating Characteristic curve ( ROC ) for both classiﬁers with corresponding Area Under the Curve ( AUC ) values . The perfor - mance is in all cases much better than that of a random classiﬁer . A more detailed evaluation involving other metrics ( precision , recall and F1 - score ) is available in Supplementary Material . Next , we considered two speciﬁc classiﬁers , Support Vector Machines ( SVM ) and K - NN , applied to the network similarity matrix computed considering network distances ( DGCD and PD ) . In Figure 2 , we report the Area Under the Receiver Operating Characteristic curve ( AUROC ) values for the K - NN classiﬁer , trained on top of PD and DGCD - 13 similarity matrix ; we excluded SVM as it was considerably outperformed ( results are available in Supplementary Material ) . DGCD - 13 was evaluated only on networks with less than 1000 nodes ( which still account for over 95 % of the data ) as the computational cost for larger networks was prohibitive . We carried out the same cross validation procedure as previously described . Again , the performance of the classiﬁers is in all instances much better than the baseline random classiﬁer value . Discussion In a nutshell , we demonstrated that our choice of basic global network properties provides an accurate classiﬁcation of news articles based solely on their re - tweeting diffusion networks – AUROC in the range 0 . 75 - 0 . 93 with basic K - NN and LR , and comparable or better performances with other state - of - the - art classiﬁers ( see Supplementary Material ) ; the use of more complex network distances conﬁrms the result , which is altogether in accordance with prior work on the detection of online political astroturf campaigns [ 18 ] . For what concerns global network properties , comparing networks with similar sizes turned out to be the right choice , yielding a general increase in all classiﬁcation metrics ( see Supplementary Material for more details ) . We experienced the worst performances when classifying networks with smaller sizes ( with less than 100 nodes ) ; we argue that small diffusion networks appear more similar and that differences across news domains emerge particularly when their size increases . For what concerns network distances , they overall exhibit a similar trend in classiﬁcation performances , with worst results on networks with less than 100 nodes and a slight improvement when considering the entire dataset ; accuracy in classifying networks with more that 1000 nodes is lower , perhaps due to data scarcity . DCGD and PD distances appear equivalent in our speciﬁc classiﬁcation task ; the former is generally used in biology to efﬁciently cluster 4 A PREPRINT - J UNE 17 , 2019 together similar networks and identify associated biological functions [ 20 ] . They reinforce the results of our more naive approach involving a manual selection of the input features . Understanding classiﬁcation results in terms of input features is notably a controversial problem in machine learning [ 13 ] . In the following we give our own qualitative interpretation of the results in terms of global network properties . For networks with less than 1000 nodes , we observed that disinformation networks exhibit higher values of both size and diameter of the largest weakly connected components ; recalling that the largest weakly connected component corresponds to the largest cascade , this result is in accordance with [ 26 ] where it is shown that false rumor cascades spread deeper and broader than true ones . For networks with more than 100 nodes , we noticed higher values of both size of the largest strongly connected component and clustering coefﬁcient in disinformation networks compared to mainstream ones . This denotes that communities of users sharing disinformation tend to be more connected and clustered , with stronger interaction be - tween users , whereas mainstream articles are shared in a more broadcast manner with less discussion between users . A similar result was reported in [ 11 ] where a sample of most shared news was inspected in the context of 2016 US presidential elections . Conversely , mainstream networks manifest a much larger number of weakly connected compo - nents ( or cascades ) . This is not surprising since traditional outlets have a larger audience than disinformation websites [ 9 , 5 ] . Finally , we observed that the main K - core number takes higher values in disinformation networks rather than in mainstream ones . This result conﬁrms considerations from [ 23 ] where authors perform a K - core decomposition of a massive diffusion network produced on Twitter in the period of 2016 US presidential elections ; they show that disinformation proliferates in the core of the network . More details on differences between news domains , according to the size of diffusion networks , are available in Supplementary Material . A pictorial representation of these properties is provided in Figure 3 , where we display two networks , with comparable size , which represent the nearest individuals pertaining to both news domains in the D [ 100 , 1000 ) subset , i . e . the network with the smallest Euclidean distance – in the feature space of global network properties – from all other individuals in the same domain . Although they may appear similar at ﬁrst sight , they actually exhibit different global properties . In particular we observe that the disinformation network has a non - zero clustering coefﬁcient , and higher value of size and diameter of the largest weakly connected component , but a smaller number of weakly connected components w . r . t to the mainstream network . Additional examples relative to other subsets are available in Supplementary Material . Conclusions Following the latest insights on the characterization of disinformation spreading on social media compared to more traditional news , we investigated the topological structure of re - tweeting diffusion networks pertaining to distinct domains . Leveraging different network comparison approaches , from manually selected global properties to more elaborated network distances , we corroborate what previous research has suggested so far : disinformation spreads out differently from mainstream news , and dissimilarities can be remarkably exploited to classify the two classes of information using purely topological tools , i . e . basic global network indicators and standard machine learning . We can qualitatively sum up these results as follows : disinformation spreads broadly and deeper than traditional news , with a smaller global audience than mainstream , and communities sharing disinformation are more connected and clustered . We believe that future research directions might successfully embody these results to develop real world applications that could resolve and mitigate malicious information spreading on social media . Supplementary Material Supplementary Material can be requested by sending an e - mail to the corresponding author ( e - mail : francesco . pierri @ polimi . it ) . References [ 1 ] S . Aksoy and R . M . Haralick . Feature normalization and likelihood - based similarity measures for image retrieval . Pattern Recognition Letters , 22 ( 5 ) : 563 – 582 , 2001 . [ 2 ] H . Allcott and M . Gentzkow . Social media and fake news in the 2016 election . Journal of Economic Perspectives , 31 ( 2 ) : 211 – 36 , 2017 . 5 A PREPRINT - J UNE 17 , 2019 [ 3 ] J . P . Bagrow and E . M . Bollt . An information - theoretic , all - scales approach to comparing networks . arXiv preprint arXiv : 1804 . 03665 , 2018 . [ 4 ] J . P . Bagrow , E . M . Bollt , J . D . Skufca , and D . ben Avraham . Portraits of complex networks . EPL ( Europhysics Letters ) , 81 ( 6 ) : 68004 , feb 2008 . [ 5 ] A . Bovet and H . A . Makse . Inﬂuence of fake news in Twitter during the 2016 US presidential election . Nature Communications , 10 ( 1 ) : 7 , 2019 . [ 6 ] M . Del Vicario , A . Bessi , F . Zollo , F . Petroni , A . Scala , G . Caldarelli , H . E . Stanley , and W . Quattrociocchi . The spreading of misinformation online . Proceedings of the National Academy of Sciences , 113 ( 3 ) : 554 – 559 , 2016 . [ 7 ] M . Fernandez and H . Alani . Online misinformation : Challenges and future directions . In Companion of the The Web Conference 2018 on The Web Conference 2018 , pages 595 – 602 . International World Wide Web Conferences Steering Committee , 2018 . [ 8 ] S . Goel , A . Anderson , J . Hofman , and D . J . Watts . The structural virality of online diffusion . Management Science , 62 ( 1 ) : 180 – 196 , 2015 . [ 9 ] N . Grinberg , K . Joseph , L . Friedland , B . Swire - Thompson , and D . Lazer . Fake news on twitter during the 2016 u . s . presidential election . Science , 363 ( 6425 ) : 374 – 378 , 2019 . [ 10 ] S . Itzkovitz , R . Milo , N . Kashtan , G . Ziv , and U . Alon . Subgraphs in random networks . Physical review E , 68 ( 2 ) : 026127 , 2003 . [ 11 ] S . M . Jang , T . Geng , J . - Y . Q . Li , R . Xia , C . - T . Huang , H . Kim , and J . Tang . A computational approach for examining the roots and spreading patterns of fake news : Evolution tree analysis . Computers in Human Behavior , 84 : 103 – 113 , 2018 . [ 12 ] D . M . J . Lazer , M . A . Baum , Y . Benkler , A . J . Berinsky , K . M . Greenhill , F . Menczer , M . J . Metzger , B . Nyhan , G . Pennycook , D . Rothschild , M . Schudson , S . A . Sloman , C . R . Sunstein , E . A . Thorson , D . J . Watts , and J . L . Zittrain . The science of fake news . Science , 359 ( 6380 ) : 1094 – 1096 , 2018 . [ 13 ] J . Li , K . Cheng , S . Wang , F . Morstatter , R . P . Trevino , J . Tang , and H . Liu . Feature selection : A data perspective . ACM Comput . Surv . , 50 ( 6 ) : 94 : 1 – 94 : 45 , Dec . 2017 . [ 14 ] A . Mitchell , J . Gottfried , J . Kiley , and K . E . Matsa . Political polarization & media habits . Pew Research Center , 21 , 2014 . [ 15 ] R . S . Nickerson . Conﬁrmation bias : A ubiquitous phenomenon in many guises . Review of General Psychology , 2 ( 2 ) : 175 , 1998 . [ 16 ] E . Pariser . The ﬁlter bubble : What the Internet is hiding from you . Penguin UK , 2011 . [ 17 ] F . Pierri and S . Ceri . False news on social media : a data - driven perspective . arXiv preprint arXiv : 1902 . 07539 . to appear on ACM SIGMOD Record , 2019 . [ 18 ] J . Ratkiewicz , M . Conover , M . Meiss , B . Gonc¸alves , S . Patil , A . Flammini , and F . Menczer . Detecting and Tracking Political Abuse in Social Media . ICWSM 2011 , page 249 , 2011 . [ 19 ] E . S . Reed , E . Turiel , and T . Brown . Naive realism in everyday life : Implications for social conﬂict and misun - derstanding . In Values and knowledge , pages 113 – 146 . Psychology Press , 2013 . [ 20 ] A . Sarajli ´ c , N . Malod - Dognin , ¨O . N . Yavero ˘ glu , and N . Pr ˇ zulj . Graphlet - based characterization of directed networks . Scientiﬁc Reports , 6 : 35098 , 2016 . [ 21 ] C . Shao , G . L . Ciampaglia , A . Flammini , and F . Menczer . Hoaxy : A platform for tracking online misinformation . In Proceedings of the 25th International Conference Companion on World Wide Web , WWW ’16 Companion , pages 745 – 750 , Republic and Canton of Geneva , Switzerland , 2016 . International World Wide Web Conferences Steering Committee . [ 22 ] C . Shao , G . L . Ciampaglia , O . Varol , K . - C . Yang , A . Flammini , and F . Menczer . The spread of low - credibility content by social bots . Nature Communications , 9 ( 1 ) : 4787 , 2018 . [ 23 ] C . Shao , P . - M . Hui , L . Wang , X . Jiang , A . Flammini , F . Menczer , and G . L . Ciampaglia . Anatomy of an online misinformation network . PLOS ONE , 13 ( 4 ) : 1 – 23 , 04 2018 . [ 24 ] C . Sunstein . On Rumors : How Falsehoods Spread , Why We Believe Them , What Can Be Done . New Haven : Yale University Press . Stowe , 2007 . [ 25 ] C . R . Sunstein . Echo chambers : Bush v . Gore , impeachment , and beyond . Princeton University Press , 2001 . [ 26 ] S . Vosoughi , D . Roy , and S . Aral . The spread of true and false news online . Science , 359 ( 6380 ) : 1146 – 1151 , 2018 . 6 A PREPRINT - J UNE 17 , 2019 [ 27 ] ¨O . N . Yavero˘glu , T . Milenkovi´c , and N . Prˇzulj . Proper evaluation of alignment - free network comparison methods . Bioinformatics , 31 ( 16 ) : 2697 – 2704 , 2015 . 7 A PREPRINT - J UNE 17 , 2019 No . nodes Mainstream networks Disinformation networks Label all 6978 5575 D all [ 0 , 100 ) 4177 2640 D [ 0 , 100 ) [ 100 , 1000 ) 2605 2900 D [ 100 , 1000 ) [ 1000 , + ∞ ) 196 235 D [ 1000 , + ∞ ) Table 1 : The number of analyzed diffusion networks , in total ( ﬁrst row ) and after splitting based on size ( second to last row ) . In the last column , the label used in the paper to denote the network subset . 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 False Positive Rate 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 T r ue P o s i t i v e R a t e ROC of Logistic Regression D all AUC = 0 . 78 ± 0 . 02 D [ 0 , 100 ) AUC = 0 . 74 ± 0 . 02 D [ 100 , 1000 ) AUC = 0 . 85 ± 0 . 02 D [ 1000 , + ) AUC = 0 . 93 ± 0 . 03 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 False Positive Rate 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 T r ue P o s i t i v e R a t e ROC of K - NN ( k = 10 ) D all AUC = 0 . 77 ± 0 . 02 D [ 0 , 100 ) AUC = 0 . 76 ± 0 . 01 D [ 100 , 1000 ) AUC = 0 . 85 ± 0 . 02 D [ 1000 , + ) AUC = 0 . 89 ± 0 . 04 Figure 1 : ROC curves for Logistic Regression and K - NN ( with k = 10 ) classiﬁers evaluated using global network properties . The dashed line corresponds to the ROC of a random classiﬁer baseline with AUC = 0 . 5 . D [ 0 , 100 ) D [ 100 , 1000 ) D [ 1000 , + ) D all 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 AUROC for PD k = 5 k = 10 k = 20 k = 50 k = 100 D [ 0 , 100 ) D [ 100 , 1000 ) 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 AUROC for DGCD - 13 k = 5 k = 10 k = 20 k = 50 k = 100 Figure 2 : AUROC values for K - NN classiﬁers ( with different choices of k ) using PD and DGCD - 13 distances . 8 A PREPRINT - J UNE 17 , 2019 Mainstream diffusion network features : WCC = 70 LWCC = 72 CC = 0 DWCC = 3 SCC = 205 LSCC = 1 KC = 1 Disinformation diffusion network features : WCC = 21 LWCC = 178 CC = 0 . 03 DWCC = 5 SCC = 220 LSCC = 2 KC = 2 Mainstream Disinformation 0 200 400 600 W CC Mainstream Disinformation 0 200 400 600 800 1000 L W CC Mainstream Disinformation 0 . 00 0 . 02 0 . 04 0 . 06 0 . 08 0 . 10 0 . 12 CC Figure 3 : Top . Prototypical examples ( the nearest individuals ) of two diffusion networks in the subset D [ 100 , 1000 ) of the mainstream ( left ) and disinformation ( right ) domains . The size of nodes is adjusted according to their degree centrality , i . e . the higher the degree value the larger the node . Middle . Feature values corresponding to the two examples ( WCC = Number of Weakly Connected Components ; LWCC = Size of the Largest Weakly Connected Component ; CC = Average Clustering Coefﬁcient ; DWCC = Diameter of the Largest Weakly Connected Components ; SCC = Number of Strongly Connected Components ; LSCC = Size of the Largest Strongly Connected Component ; KC = Main K - Core Number ) . Bottom . Box - plots of values of the three most signiﬁcant features – WCC , LWCC , CC – highlighting different distributions in the D [ 100 , 1000 ) subset of the two news domains . 9